<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Fri, 19 Sep 2025 01:30:20 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>TheAlgorithms/Python</title>
      <link>https://github.com/TheAlgorithms/Python</link>
      <description>&lt;p&gt;All Algorithms implemented in Python&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;!-- Title: --&gt; 
 &lt;a href="https://github.com/TheAlgorithms/"&gt; &lt;img src="https://raw.githubusercontent.com/TheAlgorithms/website/1cd824df116b27029f17c2d1b42d81731f28a920/public/logo.svg?sanitize=true" height="100" /&gt; &lt;/a&gt; 
 &lt;h1&gt;&lt;a href="https://github.com/TheAlgorithms/"&gt;The Algorithms&lt;/a&gt; - Python&lt;/h1&gt; 
 &lt;!-- Labels: --&gt; 
 &lt;!-- First row: --&gt; 
 &lt;a href="https://gitpod.io/#https://github.com/TheAlgorithms/Python"&gt; &lt;img src="https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod&amp;amp;style=flat-square" height="20" alt="Gitpod Ready-to-Code" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/raw/master/CONTRIBUTING.md"&gt; &lt;img src="https://img.shields.io/static/v1.svg?label=Contributions&amp;amp;message=Welcome&amp;amp;color=0059b3&amp;amp;style=flat-square" height="20" alt="Contributions Welcome" /&gt; &lt;/a&gt; 
 &lt;img src="https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;amp;style=flat-square" height="20" /&gt; 
 &lt;a href="https://the-algorithms.com/discord"&gt; &lt;img src="https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;amp;colorB=7289DA&amp;amp;style=flat-square" height="20" alt="Discord chat" /&gt; &lt;/a&gt; 
 &lt;a href="https://gitter.im/TheAlgorithms/community"&gt; &lt;img src="https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;amp;logo=gitter&amp;amp;style=flat-square" height="20" alt="Gitter chat" /&gt; &lt;/a&gt; 
 &lt;!-- Second row: --&gt; 
 &lt;br /&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/actions"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/TheAlgorithms/Python/build.yml?branch=master&amp;amp;label=CI&amp;amp;logo=github&amp;amp;style=flat-square" height="20" alt="GitHub Workflow Status" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/pre-commit/pre-commit"&gt; &lt;img src="https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;amp;logoColor=white&amp;amp;style=flat-square" height="20" alt="pre-commit" /&gt; &lt;/a&gt; 
 &lt;a href="https://docs.astral.sh/ruff/formatter/"&gt; &lt;img src="https://img.shields.io/static/v1?label=code%20style&amp;amp;message=ruff&amp;amp;color=black&amp;amp;style=flat-square" height="20" alt="code style: black" /&gt; &lt;/a&gt; 
 &lt;!-- Short description: --&gt; 
 &lt;h3&gt;All algorithms implemented in Python - for education üìö&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p&gt;Implementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.&lt;/p&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;p&gt;üìã Read through our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; before you contribute.&lt;/p&gt; 
&lt;h2&gt;üåê Community Channels&lt;/h2&gt; 
&lt;p&gt;We are on &lt;a href="https://the-algorithms.com/discord"&gt;Discord&lt;/a&gt; and &lt;a href="https://gitter.im/TheAlgorithms/community"&gt;Gitter&lt;/a&gt;! Community channels are a great way for you to ask questions and get help. Please join us!&lt;/p&gt; 
&lt;h2&gt;üìú List of Algorithms&lt;/h2&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/DIRECTORY.md"&gt;directory&lt;/a&gt; for easier navigation and a better overview of the project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>linera-io/linera-protocol</title>
      <link>https://github.com/linera-io/linera-protocol</link>
      <description>&lt;p&gt;Main repository for the Linera protocol&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://github.com/linera-io/linera-protocol/assets/1105398/fe08c941-93af-4114-bb83-bcc0eaec95f9" width="250" height="85" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/linera-io/linera-protocol/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/linera-io/linera-protocol" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml"&gt;&lt;img src="https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml/badge.svg?sanitize=true" alt="Build Status for Docker" /&gt;&lt;/a&gt; &lt;a href="https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml"&gt;&lt;img src="https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml/badge.svg?sanitize=true" alt="Build Status for Rust" /&gt;&lt;/a&gt; &lt;a href="https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml"&gt;&lt;img src="https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml/badge.svg?sanitize=true" alt="Build Status for Documentation" /&gt;&lt;/a&gt; &lt;a href="https://x.com/linera_io"&gt;&lt;img src="https://img.shields.io/twitter/follow/linera_io" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/linera"&gt;&lt;img src="https://img.shields.io/discord/984941796272521226" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![Build Status for Kubernetes](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml) --&gt; 
&lt;p&gt;&lt;a href="https://linera.io"&gt;Linera&lt;/a&gt; is a decentralized blockchain infrastructure designed for highly scalable, secure, low-latency Web3 applications.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://linera.dev"&gt;developer page&lt;/a&gt; and read our &lt;a href="https://linera.io/whitepaper"&gt;whitepaper&lt;/a&gt; to learn more about the Linera protocol.&lt;/p&gt; 
&lt;h2&gt;Repository Structure&lt;/h2&gt; 
&lt;p&gt;The main crates and directories of this repository can be summarized as follows: (listed from low to high levels in the dependency graph)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_base/index.html"&gt;&lt;code&gt;linera-base&lt;/code&gt;&lt;/a&gt; Base definitions, including cryptography.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_version/index.html"&gt;&lt;code&gt;linera-version&lt;/code&gt;&lt;/a&gt; A library to manage version info in binaries and services.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_views/index.html"&gt;&lt;code&gt;linera-views&lt;/code&gt;&lt;/a&gt; A library mapping complex data structures onto a key-value store. The corresponding procedural macros are implemented in &lt;code&gt;linera-views-derive&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_execution/index.html"&gt;&lt;code&gt;linera-execution&lt;/code&gt;&lt;/a&gt; Persistent data and the corresponding logic for runtime and execution of Linera applications.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_chain/index.html"&gt;&lt;code&gt;linera-chain&lt;/code&gt;&lt;/a&gt; Persistent data and the corresponding logic for chains of blocks, certificates, and cross-chain messaging.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_storage/index.html"&gt;&lt;code&gt;linera-storage&lt;/code&gt;&lt;/a&gt; Defines the storage abstractions for the protocol on top of &lt;code&gt;linera-chain&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_core/index.html"&gt;&lt;code&gt;linera-core&lt;/code&gt;&lt;/a&gt; The core Linera protocol, including client and server logic, node synchronization, etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_rpc/index.html"&gt;&lt;code&gt;linera-rpc&lt;/code&gt;&lt;/a&gt; Defines the data-type for RPC messages (currently all client ‚Üî proxy ‚Üî chain ‚Üî chain interactions), and track the corresponding data schemas.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_client/index.html"&gt;&lt;code&gt;linera-client&lt;/code&gt;&lt;/a&gt; Library for writing Linera clients. Used for the command-line client and the node service in &lt;code&gt;linera-service&lt;/code&gt;, as well as the Web client in &lt;a href="https://github.com/linera-io/linera-web/"&gt;&lt;code&gt;linera-web&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_service/index.html"&gt;&lt;code&gt;linera-service&lt;/code&gt;&lt;/a&gt; Executable for clients (aka CLI wallets), proxy (aka validator frontend) and servers.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_sdk/index.html"&gt;&lt;code&gt;linera-sdk&lt;/code&gt;&lt;/a&gt; The library to develop Linera applications written in Rust for the Wasm virtual machine. The corresponding procedural macros are implemented in &lt;code&gt;linera-sdk-derive&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/linera-io/linera-protocol/main/examples"&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt; Examples of Linera applications written in Rust.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/linera-io/linera-protocol/main/INSTALL.md"&gt;&lt;code&gt;INSTALL.md&lt;/code&gt;&lt;/a&gt; for software requirements to develop in this repo.&lt;/p&gt; 
&lt;h2&gt;Quickstart with the Linera CLI tool&lt;/h2&gt; 
&lt;p&gt;The following commands set up a local test network and run some transfers between the microchains owned by a single wallet.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Make sure to compile the Linera binaries and add them in the $PATH.
# cargo build -p linera-storage-service -p linera-service --bins
export PATH="$PWD/target/debug:$PATH"

# Import the optional helper function `linera_spawn`.
source /dev/stdin &amp;lt;&amp;lt;&amp;lt;"$(linera net helper 2&amp;gt;/dev/null)"

# Run a local test network with the default parameters and a number of microchains
# owned by the default wallet. This also defines `LINERA_TMP_DIR`.
linera_spawn \
linera net up --with-faucet --faucet-port 8080

# Remember the URL of the faucet.
FAUCET_URL=http://localhost:8080

# If you're using a testnet, start here and run this instead:
#   LINERA_TMP_DIR=$(mktemp -d)
#   FAUCET_URL=https://faucet.testnet-XXX.linera.net  # for some value XXX

# Set the path of the future wallet.
export LINERA_WALLET="$LINERA_TMP_DIR/wallet.json"
export LINERA_KEYSTORE="$LINERA_TMP_DIR/keystore.json"
export LINERA_STORAGE="rocksdb:$LINERA_TMP_DIR/client.db"

# Initialize a new user wallet.
linera wallet init --faucet $FAUCET_URL

# Request chains.
INFO1=($(linera wallet request-chain --faucet $FAUCET_URL))
INFO2=($(linera wallet request-chain --faucet $FAUCET_URL))
CHAIN1="${INFO1[0]}"
ACCOUNT1="${INFO1[1]}"
CHAIN2="${INFO2[0]}"
ACCOUNT2="${INFO2[1]}"

# Show the different chains tracked by the wallet.
linera wallet show

# Query the chain balance of some of the chains.
linera query-balance "$CHAIN1"
linera query-balance "$CHAIN2"

# Transfer 10 units then 5 back.
linera transfer 10 --from "$CHAIN1" --to "$CHAIN2"
linera transfer 5 --from "$CHAIN2" --to "$CHAIN1"

# Query balances again.
linera query-balance "$CHAIN1"
linera query-balance "$CHAIN2"

# Now let's fund the user balances.
linera transfer 5 --from "$CHAIN1" --to "$CHAIN1:$ACCOUNT1"
linera transfer 2 --from "$CHAIN1:$ACCOUNT1" --to "$CHAIN2:$ACCOUNT2"

# Query user balances again.
linera query-balance "$CHAIN1:$ACCOUNT1"
linera query-balance "$CHAIN2:$ACCOUNT2"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More complex examples may be found in our &lt;a href="https://linera.dev"&gt;developer manual&lt;/a&gt; as well as the &lt;a href="https://raw.githubusercontent.com/linera-io/linera-protocol/main/examples"&gt;example applications&lt;/a&gt; in this repository.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! If you'd like to contribute to the Linera protocol:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch (&lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Commit your changes (&lt;code&gt;git commit -m 'Add some amazing feature'&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Push to the branch (&lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Open a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For detailed guidelines, see our &lt;a href="https://raw.githubusercontent.com/linera-io/linera-protocol/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>virattt/ai-hedge-fund</title>
      <link>https://github.com/virattt/ai-hedge-fund</link>
      <description>&lt;p&gt;An AI Hedge Fund Team&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Hedge Fund&lt;/h1&gt; 
&lt;p&gt;This is a proof of concept for an AI-powered hedge fund. The goal of this project is to explore the use of AI to make trading decisions. This project is for &lt;strong&gt;educational&lt;/strong&gt; purposes only and is not intended for real trading or investment.&lt;/p&gt; 
&lt;p&gt;This system employs several agents working together:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation&lt;/li&gt; 
 &lt;li&gt;Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety&lt;/li&gt; 
 &lt;li&gt;Bill Ackman Agent - An activist investor, takes bold positions and pushes for change&lt;/li&gt; 
 &lt;li&gt;Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption&lt;/li&gt; 
 &lt;li&gt;Charlie Munger Agent - Warren Buffett's partner, only buys wonderful businesses at fair prices&lt;/li&gt; 
 &lt;li&gt;Michael Burry Agent - The Big Short contrarian who hunts for deep value&lt;/li&gt; 
 &lt;li&gt;Mohnish Pabrai Agent - The Dhandho investor, who looks for doubles at low risk&lt;/li&gt; 
 &lt;li&gt;Peter Lynch Agent - Practical investor who seeks "ten-baggers" in everyday businesses&lt;/li&gt; 
 &lt;li&gt;Phil Fisher Agent - Meticulous growth investor who uses deep "scuttlebutt" research&lt;/li&gt; 
 &lt;li&gt;Rakesh Jhunjhunwala Agent - The Big Bull of India&lt;/li&gt; 
 &lt;li&gt;Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential&lt;/li&gt; 
 &lt;li&gt;Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price&lt;/li&gt; 
 &lt;li&gt;Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Sentiment Agent - Analyzes market sentiment and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Fundamentals Agent - Analyzes fundamental data and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Technicals Agent - Analyzes technical indicators and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Risk Manager - Calculates risk metrics and sets position limits&lt;/li&gt; 
 &lt;li&gt;Portfolio Manager - Makes final trading decisions and generates orders&lt;/li&gt; 
&lt;/ol&gt; 
&lt;img width="1042" alt="Screenshot 2025-03-22 at 6 19 07 PM" src="https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4" /&gt; 
&lt;p&gt;Note: the system does not actually make any trades.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/virattt"&gt;&lt;img src="https://img.shields.io/twitter/follow/virattt?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is for &lt;strong&gt;educational and research purposes only&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not intended for real trading or investment&lt;/li&gt; 
 &lt;li&gt;No investment advice or guarantees provided&lt;/li&gt; 
 &lt;li&gt;Creator assumes no liability for financial losses&lt;/li&gt; 
 &lt;li&gt;Consult a financial advisor for investment decisions&lt;/li&gt; 
 &lt;li&gt;Past performance does not indicate future results&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to use it solely for learning purposes.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-install"&gt;How to Install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-run"&gt;How to Run&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-command-line-interface"&gt;‚å®Ô∏è Command Line Interface&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-web-application"&gt;üñ•Ô∏è Web Application&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-contribute"&gt;How to Contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#feature-requests"&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Install&lt;/h2&gt; 
&lt;p&gt;Before you can run the AI Hedge Fund, you'll need to install it and set up your API keys. These steps are common to both the full-stack web application and command line interface.&lt;/p&gt; 
&lt;h3&gt;1. Clone the Repository&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set up API keys&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file for your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create .env file for your API keys (in the root directory)
cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open and edit the &lt;code&gt;.env&lt;/code&gt; file to add your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
OPENAI_API_KEY=your-openai-api-key

# For getting financial data to power the hedge fund
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: You must set at least one LLM API key (e.g. &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;GROQ_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, or &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt;) for the hedge fund to work.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Financial Data&lt;/strong&gt;: Data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key. For any other ticker, you will need to set the &lt;code&gt;FINANCIAL_DATASETS_API_KEY&lt;/code&gt; in the .env file.&lt;/p&gt; 
&lt;h2&gt;How to Run&lt;/h2&gt; 
&lt;h3&gt;‚å®Ô∏è Command Line Interface&lt;/h3&gt; 
&lt;p&gt;You can run the AI Hedge Fund directly via terminal. This approach offers more granular control and is useful for automation, scripting, and integration purposes.&lt;/p&gt; 
&lt;img width="992" alt="Screenshot 2025-01-06 at 5 50 17 PM" src="https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b" /&gt; 
&lt;h4&gt;Quick Start&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Poetry (if not already installed):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://install.python-poetry.org | python3 -
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the AI Hedge Fund&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;--ollama&lt;/code&gt; flag to run the AI hedge fund using local LLMs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can optionally specify the start and end dates to make decisions over a specific time period.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the Backtester&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Example Output:&lt;/strong&gt; &lt;img width="941" alt="Screenshot 2025-01-06 at 5 47 52 PM" src="https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47" /&gt;&lt;/p&gt; 
&lt;p&gt;Note: The &lt;code&gt;--ollama&lt;/code&gt;, &lt;code&gt;--start-date&lt;/code&gt;, and &lt;code&gt;--end-date&lt;/code&gt; flags work for the backtester, as well!&lt;/p&gt; 
&lt;h3&gt;üñ•Ô∏è Web Application&lt;/h3&gt; 
&lt;p&gt;The new way to run the AI Hedge Fund is through our web application that provides a user-friendly interface. This is recommended for users who prefer visual interfaces over command line tools.&lt;/p&gt; 
&lt;p&gt;Please see detailed instructions on how to install and run the web application &lt;a href="https://github.com/virattt/ai-hedge-fund/tree/main/app"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;img width="1721" alt="Screenshot 2025-06-28 at 6 41 03‚ÄØPM" src="https://github.com/user-attachments/assets/b95ab696-c9f4-416c-9ad1-51feb1f5374b" /&gt; 
&lt;h2&gt;How to Contribute&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Commit your changes&lt;/li&gt; 
 &lt;li&gt;Push to the branch&lt;/li&gt; 
 &lt;li&gt;Create a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Please keep your pull requests small and focused. This will make it easier to review and merge.&lt;/p&gt; 
&lt;h2&gt;Feature Requests&lt;/h2&gt; 
&lt;p&gt;If you have a feature request, please open an &lt;a href="https://github.com/virattt/ai-hedge-fund/issues"&gt;issue&lt;/a&gt; and make sure it is tagged with &lt;code&gt;enhancement&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Alibaba-NLP/DeepResearch</title>
      <link>https://github.com/Alibaba-NLP/DeepResearch</link>
      <description>&lt;p&gt;Tongyi DeepResearch, the Leading Open-source DeepResearch Agent&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/logo.png" width="100%" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="line-height: 1;"&gt; 
 &lt;p&gt;&lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B"&gt;&lt;img src="https://img.shields.io/badge/Models-5EDDD2?style=for-the-badge&amp;amp;logo=huggingface&amp;amp;logoColor=ffffff&amp;amp;labelColor" alt="MODELS" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Alibaba-NLP/DeepResearch"&gt;&lt;img src="https://img.shields.io/badge/Github-24292F?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="GITHUB" /&gt;&lt;/a&gt; &lt;a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/"&gt;&lt;img src="https://img.shields.io/badge/Blog-4285F4?style=for-the-badge&amp;amp;logo=google-chrome&amp;amp;logoColor=white" alt="Blog" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; ü§ó &lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B" target="_blank"&gt;HuggingFace&lt;/a&gt; ÔΩú &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;a href="https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B" target="_blank"&gt;ModelScope&lt;/a&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14217" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14217" alt="Alibaba-NLP%2FWebAgent | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;We present &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;strong&gt;Tongyi DeepResearch&lt;/strong&gt;, an agentic large language model featuring 30.5 billion total parameters, with only 3.3 billion activated per token. Developed by Tongyi Lab, the model is specifically designed for &lt;strong&gt;long-horizon, deep information-seeking&lt;/strong&gt; tasks. Tongyi DeepResearch demonstrates state-of-the-art performance across a range of agentic search benchmarks, including Humanity's Last Exam, BrowserComp, BrowserComp-ZH, WebWalkerQA,xbench-DeepSearch, FRAMES and SimpleQA.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Tongyi DeepResearch builds upon our previous work on the &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/WebAgent/"&gt;WebAgent&lt;/a&gt; project.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;More details can be found in our üì∞&amp;nbsp;&lt;a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/"&gt;Tech Blog&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/performance.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Fully automated synthetic data generation pipeline&lt;/strong&gt;: We design a highly scalable data synthesis pipeline, which is fully automatic and empowers agentic pre-training, supervised fine-tuning, and reinforcement learning.&lt;/li&gt; 
 &lt;li&gt;üîÑ &lt;strong&gt;Large-scale continual pre-training on agentic data&lt;/strong&gt;: Leveraging diverse, high-quality agentic interaction data to extend model capabilities, maintain freshness, and strengthen reasoning performance.&lt;/li&gt; 
 &lt;li&gt;üîÅ &lt;strong&gt;End-to-end reinforcement learning&lt;/strong&gt;: We employ a strictly on-policy RL approach based on a customized Group Relative Policy Optimization framework, with token-level policy gradients, leave-one-out advantage estimation, and selective filtering of negative samples to stabilize training in a non‚Äëstationary environment.&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Agent Inference Paradigm Compatibility&lt;/strong&gt;: At inference, Tongyi DeepResearch is compatible with two inference paradigms: ReAct, for rigorously evaluating the model's core intrinsic abilities, and an IterResearch-based 'Heavy' mode, which uses a test-time scaling strategy to unlock the model's maximum performance ceiling.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Model Download&lt;/h1&gt; 
&lt;p&gt;You can directly download the model by following the links below.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Model&lt;/th&gt; 
   &lt;th align="center"&gt;Download Links&lt;/th&gt; 
   &lt;th align="center"&gt;Model Size&lt;/th&gt; 
   &lt;th align="center"&gt;Context Length&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Tongyi-DeepResearch-30B-A3B&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B"&gt;ü§ó HuggingFace&lt;/a&gt;&lt;br /&gt; &lt;a href="https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B"&gt;ü§ñ ModelScope&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;30B-A3B&lt;/td&gt; 
   &lt;td align="center"&gt;128K&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;News&lt;/h1&gt; 
&lt;p&gt;[2025/09/17]üî• We have released &lt;strong&gt;Tongyi-DeepResearch-30B-A3B&lt;/strong&gt;.&lt;/p&gt; 
&lt;h1&gt;Deep Research Benchmark Results&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/benchmark.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;This guide provides instructions for setting up the environment and running inference scripts located in the &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/inference/"&gt;inference&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h3&gt;1. Environment Setup&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Recommended Python version: &lt;strong&gt;3.10.0&lt;/strong&gt; (using other versions may cause dependency issues).&lt;/li&gt; 
 &lt;li&gt;It is strongly advised to create an isolated environment using &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;virtualenv&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Example with Conda
conda create -n react_infer_env python=3.10.0 
conda activate react_infer_env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Installation&lt;/h3&gt; 
&lt;p&gt;Install the required dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Prepare Evaluation Data&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a folder named &lt;code&gt;eval_data/&lt;/code&gt; in the project root.&lt;/li&gt; 
 &lt;li&gt;Place your QA file in &lt;strong&gt;JSONL&lt;/strong&gt; format inside this directory, e.g. &lt;code&gt;eval_data/example.jsonl&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Each line must be a JSON object that includes &lt;strong&gt;both&lt;/strong&gt; of the following keys: &lt;pre&gt;&lt;code class="language-json"&gt;{"question": "...","answer": "..."}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;A sample file is provided in the &lt;code&gt;eval_data&lt;/code&gt; folder for reference.&lt;/li&gt; 
 &lt;li&gt;If you plan to use the &lt;em&gt;file parser&lt;/em&gt; tool, &lt;strong&gt;prepend the file name to the &lt;code&gt;question&lt;/code&gt; field&lt;/strong&gt; and place the referenced file inside the &lt;code&gt;eval_data/file_corpus/&lt;/code&gt; directory.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. Configure the Inference Script&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open &lt;code&gt;run_react_infer.sh&lt;/code&gt; and modify the following variables as instructed in the comments: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;MODEL_PATH&lt;/code&gt; - path to the local or remote model weights.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;DATASET&lt;/code&gt; - path to the evaluation set, e.g. &lt;code&gt;example&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OUTPUT_PATH&lt;/code&gt; - path for saving the prediction results, e.g. &lt;code&gt;./outputs&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Depending on the tools you enable (retrieval, calculator, web search, etc.), provide the required &lt;code&gt;API_KEY&lt;/code&gt;, &lt;code&gt;BASE_URL&lt;/code&gt;, or other credentials. Each key is explained inline in the bash script.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. Run the Inference Script&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash run_react_infer.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;With these steps, you can fully prepare the environment, configure the dataset, and run the model. For more details, consult the inline comments in each script or open an issue.&lt;/p&gt; 
&lt;h2&gt;Benchmark Evaluation&lt;/h2&gt; 
&lt;p&gt;We provide benchmark evaluation scripts for various datasets. Please refer to the &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/evaluation/"&gt;evaluation scripts&lt;/a&gt; directory for more details.&lt;/p&gt; 
&lt;h2&gt;Deep Research Agent Family&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/family.png" /&gt; &lt;/p&gt; 
&lt;p&gt;Tongyi DeepResearch also has an extensive deep research agent family. You can find more information in the following paper:&lt;/p&gt; 
&lt;p&gt;[1] &lt;a href="https://arxiv.org/pdf/2501.07572"&gt;WebWalker: Benchmarking LLMs in Web Traversal&lt;/a&gt;&lt;br /&gt; [2] &lt;a href="https://arxiv.org/pdf/2505.22648"&gt;WebDancer: Towards Autonomous Information Seeking Agency&lt;/a&gt;&lt;br /&gt; [3] &lt;a href="https://arxiv.org/pdf/2507.02592"&gt;WebSailor: Navigating Super-human Reasoning for Web Agent&lt;/a&gt;&lt;br /&gt; [4] &lt;a href="https://arxiv.org/pdf/2507.15061"&gt;WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization&lt;/a&gt;&lt;br /&gt; [5] &lt;a href="https://arxiv.org/pdf/2508.05748"&gt;WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent&lt;/a&gt;&lt;br /&gt; [6] &lt;a href="https://arxiv.org/pdf/2509.13309"&gt;WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents&lt;/a&gt;&lt;br /&gt; [7] &lt;a href="https://arxiv.org/pdf/2509.13313"&gt;ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization&lt;/a&gt;&lt;br /&gt; [8] &lt;a href="https://arxiv.org/pdf/2509.13312"&gt;WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research&lt;/a&gt;&lt;br /&gt; [9] &lt;a href="https://arxiv.org/pdf/2509.13305"&gt;WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning&lt;/a&gt;&lt;br /&gt; [10] &lt;a href="https://arxiv.org/pdf/2509.13310"&gt;Scaling Agents via Continual Pre-training&lt;/a&gt;&lt;br /&gt; [11] &lt;a href="https://arxiv.org/pdf/2509.13311"&gt;Towards General Agentic Intelligence via Environment Scaling&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üåü Misc&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.star-history.com/#Alibaba-NLP/DeepResearch&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Alibaba-NLP/DeepResearch&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üö© Talent Recruitment&lt;/h2&gt; 
&lt;p&gt;üî•üî•üî• We are hiring! Research intern positions are open (based in Hangzhou„ÄÅBeijing„ÄÅShanghai)&lt;/p&gt; 
&lt;p&gt;üìö &lt;strong&gt;Research Area&lt;/strong&gt;ÔºöWeb Agent, Search Agent, Agent RL, MultiAgent RL, Agentic RAG&lt;/p&gt; 
&lt;p&gt;‚òéÔ∏è &lt;strong&gt;Contact&lt;/strong&gt;Ôºö&lt;a href=""&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contact Information&lt;/h2&gt; 
&lt;p&gt;For communications, please contact Yong Jiang (&lt;a href="mailto:yongjiang.jy@alibaba-inc.com"&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{tongyidr,
  author={Tongyi DeepResearch Team},
  title={Tongyi-DeepResearch},
  year={2025},
  howpublished={\url{https://github.com/Alibaba-NLP/DeepResearch}}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>flutter/flutter</title>
      <link>https://github.com/flutter/flutter</link>
      <description>&lt;p&gt;Flutter makes it easy and fast to build beautiful apps for mobile and beyond&lt;/p&gt;&lt;hr&gt;&lt;a href="https://flutter.dev/"&gt; &lt;h1 align="center"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://storage.googleapis.com/cms-storage-bucket/6e19fee6b47b36ca613f.png" /&gt; 
   &lt;img alt="Flutter" src="https://storage.googleapis.com/cms-storage-bucket/c823e53b3a1a7b0d36a9.png" /&gt; 
  &lt;/picture&gt; &lt;/h1&gt; &lt;/a&gt; 
&lt;p&gt;&lt;a href="https://flutter-dashboard.appspot.com/#/build?repo=flutter"&gt;&lt;img src="https://flutter-dashboard.appspot.com/api/public/build-status-badge?repo=flutter" alt="Flutter CI Status" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/flutter/flutter/master/docs/contributing/Chat.md"&gt;&lt;img src="https://img.shields.io/discord/608014603317936148?logo=discord" alt="Discord badge" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=flutterdev"&gt;&lt;img src="https://img.shields.io/twitter/follow/flutterdev.svg?style=social&amp;amp;label=Follow" alt="Twitter handle" /&gt;&lt;/a&gt; &lt;a href="https://bsky.app/profile/flutter.dev"&gt;&lt;img src="https://img.shields.io/badge/Bluesky-0285FF?logo=bluesky&amp;amp;logoColor=fff&amp;amp;label=Follow%20me%20on&amp;amp;color=0285FF" alt="BlueSky badge" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/flutter/flutter"&gt;&lt;img src="https://codecov.io/gh/flutter/flutter/branch/master/graph/badge.svg?token=11yDrJU2M2" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/5631"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/5631/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://slsa.dev"&gt;&lt;img src="https://slsa.dev/images/gh-badge-level1.svg?sanitize=true" alt="SLSA 1" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Flutter is Google's SDK for crafting beautiful, fast user experiences for mobile, web, and desktop from a single codebase. Flutter works with existing code, is used by developers and organizations around the world, and is free and open source.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://flutter.dev/get-started/"&gt;Install Flutter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.flutter.dev/"&gt;Flutter documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/flutter/flutter/master/docs/README.md"&gt;Development wiki&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/flutter/flutter/raw/main/CONTRIBUTING.md"&gt;Contributing to Flutter&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For announcements about new releases, follow the &lt;a href="https://groups.google.com/forum/#!forum/flutter-announce"&gt;flutter-announce@googlegroups.com&lt;/a&gt; mailing list. Our documentation also tracks &lt;a href="https://docs.flutter.dev/release/breaking-changes"&gt;breaking changes&lt;/a&gt; across releases.&lt;/p&gt; 
&lt;h2&gt;Terms of service&lt;/h2&gt; 
&lt;p&gt;The Flutter tool may occasionally download resources from Google servers. By downloading or using the Flutter SDK, you agree to the Google Terms of Service: &lt;a href="https://policies.google.com/terms"&gt;https://policies.google.com/terms&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For example, when installed from GitHub (as opposed to from a prepackaged archive), the Flutter tool will download the Dart SDK from Google servers immediately when first run, as it is used to execute the &lt;code&gt;flutter&lt;/code&gt; tool itself. This will also occur when Flutter is upgraded (e.g. by running the &lt;code&gt;flutter upgrade&lt;/code&gt; command).&lt;/p&gt; 
&lt;h2&gt;About Flutter&lt;/h2&gt; 
&lt;p&gt;We think Flutter will help you create beautiful, fast apps, with a productive, extensible and open development model, whether you're targeting iOS or Android, web, Windows, macOS, Linux or embedding it as the UI toolkit for a platform of your choice.&lt;/p&gt; 
&lt;h3&gt;Beautiful user experiences&lt;/h3&gt; 
&lt;p&gt;We want to enable designers to deliver their full creative vision without being forced to water it down due to limitations of the underlying framework. Flutter's &lt;a href="https://docs.flutter.dev/resources/inside-flutter"&gt;layered architecture&lt;/a&gt; gives you control over every pixel on the screen and its powerful compositing capabilities let you overlay and animate graphics, video, text, and controls without limitation. Flutter includes a full &lt;a href="https://flutter.dev/widgets/"&gt;set of widgets&lt;/a&gt; that deliver pixel-perfect experiences whether you're building for iOS (&lt;a href="https://docs.flutter.dev/development/ui/widgets/cupertino"&gt;Cupertino&lt;/a&gt;) or other platforms (&lt;a href="https://docs.flutter.dev/development/ui/widgets/material"&gt;Material&lt;/a&gt;), along with support for customizing or creating entirely new visual components.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://github.com/flutter/website/raw/main/src/content/assets/images/docs/homepage/reflectly-hero-600px.png?raw=true" alt="Reflectly hero image" /&gt;&lt;/p&gt; 
&lt;h3&gt;Fast results&lt;/h3&gt; 
&lt;p&gt;Flutter is fast. It's powered by hardware-accelerated 2D graphics libraries like &lt;a href="https://skia.org/"&gt;Skia&lt;/a&gt; (which underpins Chrome and Android) and &lt;a href="https://docs.flutter.dev/perf/impeller"&gt;Impeller&lt;/a&gt;. We architected Flutter to support glitch-free, jank-free graphics at the native speed of your device.&lt;/p&gt; 
&lt;p&gt;Flutter code is powered by the world-class &lt;a href="https://dart.dev/"&gt;Dart platform&lt;/a&gt;, which enables compilation to 32-bit and 64-bit ARM machine code for iOS and Android, JavaScript and WebAssembly for the web, as well as Intel x64 and ARM for desktop devices.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://github.com/flutter/website/raw/main/src/content/assets/images/docs/homepage/dart-diagram-small.png?raw=true" alt="Dart diagram" /&gt;&lt;/p&gt; 
&lt;h3&gt;Productive development&lt;/h3&gt; 
&lt;p&gt;Flutter offers &lt;a href="https://docs.flutter.dev/development/tools/hot-reload"&gt;stateful hot reload&lt;/a&gt;, allowing you to make changes to your code and see the results instantly without restarting your app or losing its state.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.flutter.dev/development/tools/hot-reload"&gt;&lt;img src="https://github.com/flutter/website/raw/main/src/content/assets/images/docs/tools/android-studio/hot-reload.gif?raw=true" alt="Hot reload animation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Extensible and open model&lt;/h3&gt; 
&lt;p&gt;Flutter works with any development tool (or none at all), and also includes editor plug-ins for both &lt;a href="https://marketplace.visualstudio.com/items?itemName=Dart-Code.flutter"&gt;Visual Studio Code&lt;/a&gt; and &lt;a href="https://plugins.jetbrains.com/plugin/9212-flutter"&gt;IntelliJ / Android Studio&lt;/a&gt;. Flutter provides &lt;a href="https://pub.dev/flutter"&gt;tens of thousands of packages&lt;/a&gt; to speed your development, regardless of your target platform. And accessing other native code is easy, with support for both FFI (&lt;a href="https://docs.flutter.dev/development/platform-integration/android/c-interop"&gt;on Android&lt;/a&gt;, &lt;a href="https://docs.flutter.dev/development/platform-integration/ios/c-interop"&gt;on iOS&lt;/a&gt;, &lt;a href="https://docs.flutter.dev/development/platform-integration/macos/c-interop"&gt;on macOS&lt;/a&gt;, and &lt;a href="https://docs.flutter.dev/development/platform-integration/windows/building#integrating-with-windows"&gt;on Windows&lt;/a&gt;) as well as &lt;a href="https://docs.flutter.dev/development/platform-integration/platform-channels"&gt;platform-specific APIs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Flutter is a fully open-source project, and we welcome contributions. Information on how to get started can be found in our &lt;a href="https://raw.githubusercontent.com/flutter/flutter/master/CONTRIBUTING.md"&gt;contributor guide&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>BasedHardware/omi</title>
      <link>https://github.com/BasedHardware/omi</link>
      <description>&lt;p&gt;AI wearables. Put it on, speak, transcribe, automatically&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;&lt;strong&gt;omi&lt;/strong&gt;&lt;/h1&gt; 
 &lt;p&gt;Meet Omi, the world‚Äôs leading open-source AI wearable that captures conversations, gives summaries, action items and does actions for you. Simply connect Omi to your mobile device and enjoy automatic, high-quality transcriptions of meetings, chats, and voice memos wherever you are.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/834d3fdb-31b5-4f22-ae35-da3d2b9a8f59" alt="Omi" /&gt; &lt;img src="https://github.com/user-attachments/assets/7a658366-9e02-4057-bde5-a510e1f0217a" alt="CleanShot 2025-02-08 at 18 22 23" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="http://discord.omi.me"&gt;&lt;img src="https://img.shields.io/discord/1192313062041067520?label=Discord" alt="Discord Follow" /&gt;&lt;/a&gt; ‚ÄÇ‚ÄÇ‚ÄÇ &lt;a href="https://x.com/kodjima33"&gt;&lt;img src="https://img.shields.io/twitter/follow/kodjima33" alt="Twitter Follow" /&gt;&lt;/a&gt; ‚ÄÇ‚ÄÇ‚ÄÇ &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt;‚ÄÇ‚ÄÇ‚ÄÇ &lt;a href="https://github.com/BasedHardware/Omi"&gt;&lt;img src="https://img.shields.io/github/stars/BasedHardware/Omi" alt="GitHub Repo stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://omi.me/"&gt;Homepage&lt;/a&gt; | &lt;a href="https://docs.omi.me/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://www.omi.me/products/omi-dev-kit-2"&gt;Buy omi Developer Kit&lt;/a&gt; | &lt;a href="https://www.omi.me/glass"&gt;Buy Omi Glass Dev Kit&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
&lt;/div&gt; 
&lt;h2&gt;Quick Start (2 min)&lt;/h2&gt; 
&lt;p&gt;Download omi App&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://play.google.com/store/apps/details?id=com.friend.ios"&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/7/78/Google_Play_Store_badge_EN.svg?sanitize=true" alt="Get it on Google Play" height="50px" width="180px" /&gt;&lt;/a&gt; &lt;a href="https://apps.apple.com/us/app/friend-ai-wearable/id6502156163"&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/3/3c/Download_on_the_App_Store_Badge.svg?sanitize=true" alt="Download on the App Store" height="50px" width="180px" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Create webhook using &lt;a href="https://webhook.site"&gt;webhook.site&lt;/a&gt; and copy this url&lt;/p&gt; 
&lt;img src="https://github.com/user-attachments/assets/083a6ec4-4694-4c7a-843a-4a1a0c254453" width="500" /&gt; 
&lt;p&gt;In omi App:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Explore =&amp;gt; Create an App&lt;/th&gt; 
   &lt;th&gt;Select Capability&lt;/th&gt; 
   &lt;th&gt;Paste Webhook URL&lt;/th&gt; 
   &lt;th&gt;Install App&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/31809b81-7de2-4381-b5fc-5c9714972211" width="200" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/59cfbe8e-7e3b-437f-81f7-25eb50ccdd7d" width="200" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/3d864ee8-555f-4ded-b4db-87ff78128323" width="200" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/58cf6da6-e245-415e-92e7-dc1f46583cfc" width="200" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Start speaking, you'll see Real-time transcript on &lt;a href="https://webhook.site"&gt;webhook.site &lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;In this repo:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BasedHardware/omi/tree/main/omi"&gt;omi device&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BasedHardware/omi/tree/main/omiGlass"&gt;omi glass&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BasedHardware/omi/tree/main/app"&gt;omi app&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BasedHardware/omi/tree/main/personas-open-source"&gt;ai personas (web)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/BasedHardware/omi/main/sdks"&gt;SDKs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.omi.me/"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.omi.me/doc/developer/AppSetup"&gt;omi App setup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.omi.me/doc/assembly/Buying_Guide/"&gt;Buying Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.omi.me/doc/assembly/Build_the_device/"&gt;Build the device&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.omi.me/doc/get_started/Flash_device/"&gt;Install firmware&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.omi.me/doc/developer/apps/Introduction"&gt;Create your own app in 1 minute&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check out our &lt;a href="https://docs.omi.me/doc/developer/Contribution/"&gt;contributions guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Earn from contributing! Check the &lt;a href="https://omi.me/bounties"&gt;paid bounties ü§ë&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://github.com/BasedHardware/Omi/issues"&gt;current issues&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join the &lt;a href="http://discord.omi.me"&gt;Discord&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Build your own &lt;a href="https://docs.omi.me/doc/developer/apps/Introduction"&gt;Plugins/Integrations&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Licensing&lt;/h2&gt; 
&lt;p&gt;Omi is available under &lt;a href="https://github.com/BasedHardware/omi/raw/main/LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ArthurBrussee/brush</title>
      <link>https://github.com/ArthurBrussee/brush</link>
      <description>&lt;p&gt;3D Reconstruction for all&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Brush&lt;/h1&gt; 
&lt;p&gt;
 &lt;video src="https://github.com/user-attachments/assets/5756967a-846c-44cf-bde9-3ca4c86f1a4d"&gt;
  A video showing various Brush features and scenes
 &lt;/video&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt; Massive thanks to &lt;a href="https://www.youtube.com/@gradeeterna"&gt;@GradeEterna&lt;/a&gt; for the beautiful scenes &lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Brush is a 3D reconstruction engine using &lt;a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/"&gt;Gaussian splatting&lt;/a&gt;. It works on a wide range of systems: &lt;strong&gt;macOS/windows/linux&lt;/strong&gt;, &lt;strong&gt;AMD/Nvidia/Intel&lt;/strong&gt; cards, &lt;strong&gt;Android&lt;/strong&gt;, and in a &lt;strong&gt;browser&lt;/strong&gt;. To achieve this, it uses WebGPU compatible tech and the &lt;a href="https://github.com/tracel-ai/burn"&gt;Burn&lt;/a&gt; machine learning framework.&lt;/p&gt; 
&lt;p&gt;Machine learning for real time rendering has tons of potential, but most ML tools don't work well with it: Rendering requires realtime interactivity, usually involve dynamic shapes &amp;amp; computations, don't run on most platforms, and it can be cumbersome to ship apps with large CUDA deps. Brush on the other hand produces simple dependency free binaries, runs on nearly all devices, without any setup.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://arthurbrussee.github.io/brush-demo"&gt;&lt;strong&gt;Try the web demo&lt;/strong&gt; &lt;img src="https://cdn-icons-png.flaticon.com/256/888/888846.png" alt="chrome logo" width="24" /&gt; &lt;/a&gt; &lt;em&gt;NOTE: Only works on Chrome and Edge. Firefox and Safari are hopefully supported soon)&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/TbxJST2BbC"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/https://discord.gg/TbxJST2BbC" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Training&lt;/h2&gt; 
&lt;p&gt;Brush takes in COLMAP data or datasets in the Nerfstudio format. Training is fully supported natively, on mobile, and in a browser. While training you can interact with the scene and see the training dynamics live, and compare the current rendering to input views as the training progresses.&lt;/p&gt; 
&lt;p&gt;It also supports masking images:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Images with transparency. This will force the final splat to match the transparency of the input.&lt;/li&gt; 
 &lt;li&gt;A folder of images called 'masks'. This ignores parts of the image that are masked out.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Viewer&lt;/h2&gt; 
&lt;p&gt;Brush also works well as a splat viewer, including on the web. It can load .ply &amp;amp; .compressed.ply files. You can stream in data from a URL (for a web app, simply append &lt;code&gt;?url=&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;Brush also can load .zip of splat files to display them as an animation, or a special ply that includes delta frames (see &lt;a href="https://cat-4d.github.io/"&gt;cat-4D&lt;/a&gt; and &lt;a href="https://felixtaubner.github.io/cap4d/"&gt;Cap4D&lt;/a&gt;!).&lt;/p&gt; 
&lt;h2&gt;CLI&lt;/h2&gt; 
&lt;p&gt;Brush can be used as a CLI. Run &lt;code&gt;brush --help&lt;/code&gt; to get an overview. Every CLI command can work with &lt;code&gt;--with-viewer&lt;/code&gt; which also opens the UI, for easy debugging.&lt;/p&gt; 
&lt;h2&gt;Rerun&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f679fec0-935d-4dd2-87e1-c301db9cdc2c"&gt;https://github.com/user-attachments/assets/f679fec0-935d-4dd2-87e1-c301db9cdc2c&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;While training, additional data can be visualized with the excellent &lt;a href="https://rerun.io/"&gt;rerun&lt;/a&gt;. To install rerun on your machine, please follow their &lt;a href="https://rerun.io/docs/getting-started/installing-viewer"&gt;instructions&lt;/a&gt;. Open the ./brush_blueprint.rbl in the viewer for best results.&lt;/p&gt; 
&lt;h2&gt;Building Brush&lt;/h2&gt; 
&lt;p&gt;First install rust 1.88+. You can run tests with &lt;code&gt;cargo test --all&lt;/code&gt;. Brush uses the wonderful &lt;a href="https://rerun.io/"&gt;rerun&lt;/a&gt; for additional visualizations while training, run &lt;code&gt;cargo install rerun-cli&lt;/code&gt; if you want to use it.&lt;/p&gt; 
&lt;h3&gt;Windows/macOS/Linux&lt;/h3&gt; 
&lt;p&gt;Simply &lt;code&gt;cargo run&lt;/code&gt; or &lt;code&gt;cargo run --release&lt;/code&gt; from the workspace root. Brush can also be used as a CLI, run &lt;code&gt;cargo run --release -- --help&lt;/code&gt; to use the CLI directly from source. See the notes about the CLI in the features section.&lt;/p&gt; 
&lt;h3&gt;Web&lt;/h3&gt; 
&lt;p&gt;Brush can be compiled to WASM. Run &lt;code&gt;npm run dev&lt;/code&gt; to start the demo website using Next.js, see the brush_nextjs directory.&lt;/p&gt; 
&lt;p&gt;Brush uses &lt;a href="https://rustwasm.github.io/wasm-bindgen/introduction.html"&gt;&lt;code&gt;wasm-pack&lt;/code&gt;&lt;/a&gt; to build the WASM bundle. You can also use it without a bundler, see &lt;a href="hhttps://rustwasm.github.io/wasm-bindgen/examples/without-a-bundler.html"&gt;wasm-pack's documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;WebGPU is still an upcoming standard, and as such, only Chrome 134+ on Windows and macOS is currently supported.&lt;/p&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;p&gt;As a one time setup, make sure you have the Android SDK &amp;amp; NDK installed.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check if ANDROID_NDK_HOME and ANDROID_HOME are set&lt;/li&gt; 
 &lt;li&gt;Add the Android target to rust &lt;code&gt;rustup target add aarch64-linux-android&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install cargo-ndk to manage building a lib &lt;code&gt;cargo install cargo-ndk&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each time you change the rust code, run&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cargo ndk -t arm64-v8a -o crates/brush-app/app/src/main/jniLibs/ build&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Nb: Nb, for best performance, build in release mode. This is separate from the Android Studio app build configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cargo ndk -t arm64-v8a -o crates/brush-app/app/src/main/jniLibs/ build --release&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can now either run the project from Android Studio (Android Studio does NOT build the rust code), or run it from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./gradlew build
./gradlew installDebug
adb shell am start -n com.splats.app/.MainActivity
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also open this folder as a project in Android Studio and run things from there. Nb: Running in Android Studio does &lt;em&gt;not&lt;/em&gt; rebuild the rust code automatically.&lt;/p&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;Rendering and training are generally faster than gsplat. You can run benchmarks of some of the kernels using &lt;code&gt;cargo bench&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Acknowledgements&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/nerfstudio-project/gsplat"&gt;&lt;strong&gt;gSplat&lt;/strong&gt;&lt;/a&gt;, for their reference version of the kernels&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Peter Hedman, George Kopanas &amp;amp; Bernhard Kerbl&lt;/strong&gt;, for the many discussions &amp;amp; pointers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The Burn team&lt;/strong&gt;, for help &amp;amp; improvements to Burn along the way&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Raph Levien&lt;/strong&gt;, for the &lt;a href="https://github.com/googlefonts/compute-shader-101/pull/31"&gt;original version&lt;/a&gt; of the GPU radix sort.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GradeEterna&lt;/strong&gt;, for feedback and their scenes.&lt;/p&gt; 
&lt;h1&gt;Disclaimer&lt;/h1&gt; 
&lt;p&gt;This is &lt;em&gt;not&lt;/em&gt; an official Google product. This repository is a forked public version of &lt;a href="https://github.com/google-research/google-research/tree/master/brush_splat"&gt;the google-research repository&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>category-labs/monad</title>
      <link>https://github.com/category-labs/monad</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Monad Execution&lt;/h1&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;This repository contains the execution component of a Monad node. It handles the transaction processing for new blocks, and keeps track of the state of the blockchain. Consequently, this repository contains the source code for Category Labs' custom &lt;a href="https://docs.monad.xyz/monad-arch/execution/native-compilation"&gt;EVM implementation&lt;/a&gt;, its &lt;a href="https://docs.monad.xyz/monad-arch/execution/monaddb"&gt;database implementation&lt;/a&gt;, and the high-level &lt;a href="https://docs.monad.xyz/monad-arch/execution/parallel-execution"&gt;transaction scheduling&lt;/a&gt;. The other main repository is &lt;a href="https://github.com/category-labs/monad-bft"&gt;monad-bft&lt;/a&gt;, which contains the source code for the consensus component.&lt;/p&gt; 
&lt;h2&gt;Building the source code&lt;/h2&gt; 
&lt;h3&gt;Package requirements&lt;/h3&gt; 
&lt;p&gt;Execution has two kinds of dependencies on third-party libraries:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self-managed&lt;/strong&gt;: execution's CMake build system will checkout most of its third-party dependencies as git submodules, and build them as part of its own build process, as CMake subprojects; this will happen automatically during the build, but you must run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;after checking out this repository.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;System&lt;/strong&gt;: some dependencies are expected to already be part of the system in a default location, i.e., they are expected to come from the system's package manager. The primary development platform is Ubuntu, so the required packages use the Debian/Ubuntu package names; an up-to-date list of the required system dependencies can be found in the docker configuration file &lt;code&gt;docker/release.Dockerfile&lt;/code&gt; (you will need all the packages installed via the &lt;code&gt;apt install&lt;/code&gt; commands)&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Minimum development tool requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;gcc-15 or clang-19&lt;/li&gt; 
 &lt;li&gt;CMake 3.27&lt;/li&gt; 
 &lt;li&gt;Even when using clang, the only standard library supported is libstdc++; libc++ may work but it is not a tested platform&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;CPU compilation requirements&lt;/h3&gt; 
&lt;p&gt;As explained in the &lt;a href="https://docs.monad.xyz/monad-arch/hardware-requirements"&gt;hardware requirements&lt;/a&gt;, a Monad node requires a relatively recent CPU. Execution explicitly requires this to compile: it needs to emit machine code that is only supported on recent CPU models, for fast cryptographic operations.&lt;/p&gt; 
&lt;p&gt;The minimum ISA support corresponds to the &lt;a href="https://en.wikipedia.org/wiki/X86-64#Microarchitecture_levels"&gt;x86-64-v3&lt;/a&gt; feature level. Consequently, the minimum flag you must pass to the compiler is &lt;code&gt;-march=x86-64-v3&lt;/code&gt;, or alternatively &lt;code&gt;-march=haswell&lt;/code&gt; ("Haswell" was the codename of the first Intel CPU to support all of these features).&lt;/p&gt; 
&lt;p&gt;You may also pass any higher architecture level if you wish, although the compiled binary may not work on older CPUs. The execution docker files use &lt;code&gt;-march=haswell&lt;/code&gt; because it tries to maximize the number of systems the resulting binary can run on. If you are only running locally (i.e., the binary does not need to run anywhere else) use &lt;code&gt;-march=native&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Compiling the execution code&lt;/h3&gt; 
&lt;p&gt;First, change your working directory to the root directory of the execution git repository root and then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;CC=gcc-15 CXX=g++-15 CFLAGS="-march=haswell" CXXFLAGS="-march=haswell" ASMFLAGS="-march=haswell" \
./scripts/configure.sh &amp;amp;&amp;amp; ./scripts/build.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above command will do several things:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Use gcc-15 instead of the system's default compiler&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Emit machine code using Haswell-era CPU extensions&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run CMake, and generate a &lt;a href="https://ninja-build.org/"&gt;ninja&lt;/a&gt; build system in the &lt;code&gt;&amp;lt;path-to-execution-repo&amp;gt;/build&lt;/code&gt; directory with the &lt;a href="https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html"&gt;&lt;code&gt;CMAKE_BUILD_TYPE&lt;/code&gt;&lt;/a&gt; set to &lt;code&gt;RelWithDebInfo&lt;/code&gt; by default&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build the CMake &lt;code&gt;all&lt;/code&gt; target, which builds everything&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The compiler and CPU options are injected via environment variables that are read by CMake. If you want debug binaries instead, you can also pass &lt;code&gt;CMAKE_BUILD_TYPE=Debug&lt;/code&gt; via the environment.&lt;/p&gt; 
&lt;p&gt;When finished, this will build all of the execution binaries. The main one is the execution daemon, &lt;code&gt;build/cmd/monad&lt;/code&gt;. This binary can provide block execution services for different EVM-compatible blockchains:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;When used as part of a Monad blockchain node, it behaves as the block execution service for the Category Labs consensus daemon (for details, see &lt;a href="https://raw.githubusercontent.com/category-labs/monad/main/docs/overview.md#how-is-execution-used"&gt;here&lt;/a&gt;); when running in this mode, Monad EVM extensions (e.g., Monad-style staking) are enabled&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;It can also replay the history of other EVM-compatible blockchains, by executing their historical blocks as inputs; a common developer workflow (and a good full system test) is to replay the history of the original Ethereum mainnet and verify that the computed Merkle roots match after each block&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can also run the full test suite in parallel with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CTEST_PARALLEL_LEVEL=$(nproc) ctest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;A tour of execution&lt;/h2&gt; 
&lt;p&gt;To understand how the source code is organized, you should start by reading the execution &lt;a href="https://raw.githubusercontent.com/category-labs/monad/main/docs/overview.md"&gt;developer overview&lt;/a&gt;, which explains how execution and consensus fit together, and where in the source tree you can find different pieces of functionality.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;OpenAI Codex CLI&lt;/h1&gt; 
&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install codex&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer. &lt;br /&gt; &lt;br /&gt;If you want Codex in your code editor (VS Code, Cursor, Windsurf), &lt;a href="https://developers.openai.com/codex/ide"&gt;install in your IDE&lt;/a&gt; &lt;br /&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, go to &lt;a href="https://chatgpt.com/codex"&gt;chatgpt.com/codex&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-splash.png" alt="Codex CLI splash" width="80%" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installing and running Codex CLI&lt;/h3&gt; 
&lt;p&gt;Install globally with your preferred package manager. If you use npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @openai/codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, if you use Homebrew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run &lt;code&gt;codex&lt;/code&gt; to get started:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can also go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt; 
 &lt;p&gt;Each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Using Codex with your ChatGPT plan&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-login.png" alt="Codex CLI login" width="80%" /&gt; &lt;/p&gt; 
&lt;p&gt;Run &lt;code&gt;codex&lt;/code&gt; and select &lt;strong&gt;Sign in with ChatGPT&lt;/strong&gt;. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. &lt;a href="https://help.openai.com/en/articles/11369540-codex-in-chatgpt"&gt;Learn more about what's included in your ChatGPT plan&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also use Codex with an API key, but this requires &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key"&gt;additional setup&lt;/a&gt;. If you previously used an API key for usage-based billing, see the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#migrating-from-usage-based-billing-api-key"&gt;migration steps&lt;/a&gt;. If you're having trouble with login, please comment on &lt;a href="https://github.com/openai/codex/issues/1243"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Model Context Protocol (MCP)&lt;/h3&gt; 
&lt;p&gt;Codex CLI supports &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#model-context-protocol-mcp"&gt;MCP servers&lt;/a&gt;. Enable by adding an &lt;code&gt;mcp_servers&lt;/code&gt; section to your &lt;code&gt;~/.codex/config.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Codex CLI supports a rich set of configuration options, with preferences stored in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. For full configuration options, see &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Docs &amp;amp; FAQ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md"&gt;&lt;strong&gt;Getting started&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#cli-usage"&gt;CLI usage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#running-with-a-prompt-as-input"&gt;Running with a prompt as input&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#example-prompts"&gt;Example prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#memory-with-agentsmd"&gt;Memory with AGENTS.md&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/sandbox.md"&gt;&lt;strong&gt;Sandbox &amp;amp; approvals&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md"&gt;&lt;strong&gt;Authentication&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#forcing-a-specific-auth-method-advanced"&gt;Auth methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#connecting-on-a-headless-machine"&gt;Login on a "Headless" machine&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md"&gt;&lt;strong&gt;Advanced&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#non-interactive--ci-mode"&gt;Non-interactive / CI mode&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#tracing--verbose-logging"&gt;Tracing / verbose logging&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#model-context-protocol-mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/zdr.md"&gt;&lt;strong&gt;Zero data retention (ZDR)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/contributing.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md"&gt;&lt;strong&gt;Install &amp;amp; build&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#system-requirements"&gt;System Requirements&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#dotslash"&gt;DotSlash&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#build-from-source"&gt;Build from source&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/faq.md"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/open-source-fund.md"&gt;&lt;strong&gt;Open source fund&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>curl/curl</title>
      <link>https://github.com/curl/curl</link>
      <description>&lt;p&gt;A command line tool and library for transferring data with URL syntax, supporting DICT, FILE, FTP, FTPS, GOPHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, TFTP, WS and WSS. libcurl offers a myriad of powerful features&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://curl.se/"&gt;&lt;img src="https://curl.se/logo/curl-logo.svg?sanitize=true" alt="curl logo" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;curl is a command-line tool for transferring data specified with URL syntax. Learn how to use curl by reading &lt;a href="https://curl.se/docs/manpage.html"&gt;the manpage&lt;/a&gt; or &lt;a href="https://everything.curl.dev/"&gt;everything curl&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Find out how to install curl by reading &lt;a href="https://curl.se/docs/install.html"&gt;the INSTALL document&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;libcurl is the library curl is using to do its job. It is readily available to be used by your software. Read &lt;a href="https://curl.se/libcurl/c/libcurl.html"&gt;the libcurl manpage&lt;/a&gt; to learn how.&lt;/p&gt; 
&lt;h2&gt;Open Source&lt;/h2&gt; 
&lt;p&gt;curl is Open Source and is distributed under an MIT-like &lt;a href="https://curl.se/docs/copyright.html"&gt;license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;Contact us on a suitable &lt;a href="https://curl.se/mail/"&gt;mailing list&lt;/a&gt; or use GitHub &lt;a href="https://github.com/curl/curl/issues"&gt;issues&lt;/a&gt;/ &lt;a href="https://github.com/curl/curl/pulls"&gt;pull requests&lt;/a&gt;/ &lt;a href="https://github.com/curl/curl/discussions"&gt;discussions&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;All contributors to the project are listed in &lt;a href="https://curl.se/docs/thanks.html"&gt;the THANKS document&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Commercial support&lt;/h2&gt; 
&lt;p&gt;For commercial support, maybe private and dedicated help with your problems or applications using (lib)curl visit &lt;a href="https://curl.se/support.html"&gt;the support page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Website&lt;/h2&gt; 
&lt;p&gt;Visit the &lt;a href="https://curl.se/"&gt;curl website&lt;/a&gt; for the latest news and downloads.&lt;/p&gt; 
&lt;h2&gt;Source code&lt;/h2&gt; 
&lt;p&gt;Download the latest source from the Git server:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/curl/curl.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Security problems&lt;/h2&gt; 
&lt;p&gt;Report suspected security problems via &lt;a href="https://hackerone.com/curl"&gt;our HackerOne page&lt;/a&gt; and not in public.&lt;/p&gt; 
&lt;h2&gt;Notice&lt;/h2&gt; 
&lt;p&gt;curl contains pieces of source code that is Copyright (c) 1998, 1999 Kungliga Tekniska H√∂gskolan. This notice is included here to comply with the distribution terms.&lt;/p&gt; 
&lt;h2&gt;Backers&lt;/h2&gt; 
&lt;p&gt;Thank you to all our backers &lt;span&gt;üôè&lt;/span&gt; &lt;a href="https://opencollective.com/curl#section-contribute"&gt;Become a backer&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Support this project by becoming a &lt;a href="https://curl.se/sponsors.html"&gt;sponsor&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dataease/SQLBot</title>
      <link>https://github.com/dataease/SQLBot</link>
      <description>&lt;p&gt;Âü∫‰∫éÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªü„ÄÇText-to-SQL Generation via LLMs using RAG.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://resource-fit2cloud-com.oss-cn-hangzhou.aliyuncs.com/sqlbot/sqlbot.png" alt="SQLBot" width="300" /&gt;&lt;/p&gt; 
&lt;h3 align="center"&gt;Âü∫‰∫éÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªü&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/dataease/SQLBot/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dataease/SQLBot" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dataease/SQLBot"&gt;&lt;img src="https://img.shields.io/github/stars/dataease/SQLBot?color=%231890FF&amp;amp;style=flat-square" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dataease/SQLbot"&gt;&lt;img src="https://img.shields.io/docker/pulls/dataease/sqlbot?label=downloads" alt="Download" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;SQLBot ÊòØ‰∏ÄÊ¨æÂü∫‰∫éÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªü„ÄÇSQLBot ÁöÑ‰ºòÂäøÂåÖÊã¨Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂºÄÁÆ±Âç≥Áî®&lt;/strong&gt;: Âè™ÈúÄÈÖçÁΩÆÂ§ßÊ®°ÂûãÂíåÊï∞ÊçÆÊ∫êÂç≥ÂèØÂºÄÂêØÈóÆÊï∞‰πãÊóÖÔºåÈÄöËøáÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÁªìÂêàÊù•ÂÆûÁé∞È´òË¥®ÈáèÁöÑ text2sqlÔºõ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êòì‰∫éÈõÜÊàê&lt;/strong&gt;: ÊîØÊåÅÂø´ÈÄüÂµåÂÖ•Âà∞Á¨¨‰∏âÊñπ‰∏öÂä°Á≥ªÁªüÔºå‰πüÊîØÊåÅË¢´ n8n„ÄÅMaxKB„ÄÅDify„ÄÅCoze Á≠â AI Â∫îÁî®ÂºÄÂèëÂπ≥Âè∞ÈõÜÊàêË∞ÉÁî®ÔºåËÆ©ÂêÑÁ±ªÂ∫îÁî®Âø´ÈÄüÊã•ÊúâÊô∫ËÉΩÈóÆÊï∞ËÉΩÂäõÔºõ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÆâÂÖ®ÂèØÊéß&lt;/strong&gt;: Êèê‰æõÂü∫‰∫éÂ∑•‰ΩúÁ©∫Èó¥ÁöÑËµÑÊ∫êÈöîÁ¶ªÊú∫Âà∂ÔºåËÉΩÂ§üÂÆûÁé∞ÁªÜÁ≤íÂ∫¶ÁöÑÊï∞ÊçÆÊùÉÈôêÊéßÂà∂„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Â∑•‰ΩúÂéüÁêÜ&lt;/h2&gt; 
&lt;img width="1189" height="624" alt="system-arch" src="https://github.com/user-attachments/assets/cde40783-369e-493e-bb59-44ce43c2e7c5" /&gt; 
&lt;h2&gt;Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;h3&gt;ÂÆâË£ÖÈÉ®ÁΩ≤&lt;/h3&gt; 
&lt;p&gt;ÂáÜÂ§á‰∏ÄÂè∞ Linux ÊúçÂä°Âô®ÔºåÂÆâË£ÖÂ•Ω &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt;ÔºåÊâßË°å‰ª•‰∏ã‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name sqlbot \
  --restart unless-stopped \
  -p 8000:8000 \
  -p 8001:8001 \
  -v ./data/sqlbot/excel:/opt/sqlbot/data/excel \
  -v ./data/sqlbot/images:/opt/sqlbot/images \
  -v ./data/sqlbot/logs:/opt/sqlbot/app/logs \
  -v ./data/postgresql:/var/lib/postgresql/data \
  --privileged=true \
  dataease/sqlbot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‰Ω†‰πüÂèØ‰ª•ÈÄöËøá &lt;a href="https://apps.fit2cloud.com/1panel"&gt;1Panel Â∫îÁî®ÂïÜÂ∫ó&lt;/a&gt; Âø´ÈÄüÈÉ®ÁΩ≤ SQLBot„ÄÇ&lt;/p&gt; 
&lt;p&gt;Â¶ÇÊûúÊòØÂÜÖÁΩëÁéØÂ¢ÉÔºå‰Ω†ÂèØ‰ª•ÈÄöËøá &lt;a href="https://community.fit2cloud.com/#/products/sqlbot/downloads"&gt;Á¶ªÁ∫øÂÆâË£ÖÂåÖÊñπÂºè&lt;/a&gt; ÈÉ®ÁΩ≤ SQLBot„ÄÇ&lt;/p&gt; 
&lt;h3&gt;ËÆøÈóÆÊñπÂºè&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âú®ÊµèËßàÂô®‰∏≠ÊâìÂºÄ: http://&amp;lt;‰Ω†ÁöÑÊúçÂä°Âô®IP&amp;gt;:8000/&lt;/li&gt; 
 &lt;li&gt;Áî®Êà∑Âêç: admin&lt;/li&gt; 
 &lt;li&gt;ÂØÜÁ†Å: SQLBot@123456&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ËÅîÁ≥ªÊàë‰ª¨&lt;/h3&gt; 
&lt;p&gt;Â¶Ç‰Ω†ÊúâÊõ¥Â§öÈóÆÈ¢òÔºåÂèØ‰ª•Âä†ÂÖ•Êàë‰ª¨ÁöÑÊäÄÊúØ‰∫§ÊµÅÁæ§‰∏éÊàë‰ª¨‰∫§ÊµÅ„ÄÇ&lt;/p&gt; 
&lt;img width="180" height="180" alt="contact_me_qr" src="https://github.com/user-attachments/assets/2594ff29-5426-4457-b051-279855610030" /&gt; 
&lt;h2&gt;UI Â±ïÁ§∫&lt;/h2&gt;  
&lt;img alt="q&amp;amp;a" src="https://github.com/user-attachments/assets/55526514-52f3-4cfe-98ec-08a986259280" /&gt;  
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#dataease/sqlbot&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=dataease/sqlbot&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;È£ûËá¥‰∫ëÊóó‰∏ãÁöÑÂÖ∂‰ªñÊòéÊòüÈ°πÁõÆ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dataease/dataease/"&gt;DataEase&lt;/a&gt; - ‰∫∫‰∫∫ÂèØÁî®ÁöÑÂºÄÊ∫ê BI Â∑•ÂÖ∑&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/1panel/"&gt;1Panel&lt;/a&gt; - Áé∞‰ª£Âåñ„ÄÅÂºÄÊ∫êÁöÑ Linux ÊúçÂä°Âô®ËøêÁª¥ÁÆ°ÁêÜÈù¢Êùø&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; - Âº∫Â§ßÊòìÁî®ÁöÑ‰ºÅ‰∏öÁ∫ßÊô∫ËÉΩ‰ΩìÂπ≥Âè∞&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jumpserver/jumpserver/"&gt;JumpServer&lt;/a&gt; - ÂπøÂèóÊ¨¢ËøéÁöÑÂºÄÊ∫êÂ†°ÂûíÊú∫&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/halo-dev/halo/"&gt;Halo&lt;/a&gt; - Âº∫Â§ßÊòìÁî®ÁöÑÂºÄÊ∫êÂª∫Á´ôÂ∑•ÂÖ∑&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metersphere/metersphere/"&gt;MeterSphere&lt;/a&gt; - Êñ∞‰∏Ä‰ª£ÁöÑÂºÄÊ∫êÊåÅÁª≠ÊµãËØïÂ∑•ÂÖ∑&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Êú¨‰ªìÂ∫ìÈÅµÂæ™ &lt;a href="https://raw.githubusercontent.com/dataease/SQLBot/main/LICENSE"&gt;FIT2CLOUD Open Source License&lt;/a&gt; ÂºÄÊ∫êÂçèËÆÆÔºåËØ•ËÆ∏ÂèØËØÅÊú¨Ë¥®‰∏äÊòØ GPLv3Ôºå‰ΩÜÊúâ‰∏Ä‰∫õÈ¢ùÂ§ñÁöÑÈôêÂà∂„ÄÇ&lt;/p&gt; 
&lt;p&gt;‰Ω†ÂèØ‰ª•Âü∫‰∫é SQLBot ÁöÑÊ∫ê‰ª£Á†ÅËøõË°å‰∫åÊ¨°ÂºÄÂèëÔºå‰ΩÜÊòØÈúÄË¶ÅÈÅµÂÆà‰ª•‰∏ãËßÑÂÆöÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‰∏çËÉΩÊõøÊç¢Âíå‰øÆÊîπ SQLBot ÁöÑ Logo ÂíåÁâàÊùÉ‰ø°ÊÅØÔºõ&lt;/li&gt; 
 &lt;li&gt;‰∫åÊ¨°ÂºÄÂèëÂêéÁöÑË°çÁîü‰ΩúÂìÅÂøÖÈ°ªÈÅµÂÆà GPL V3 ÁöÑÂºÄÊ∫ê‰πâÂä°„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Â¶ÇÈúÄÂïÜ‰∏öÊéàÊùÉÔºåËØ∑ËÅîÁ≥ª &lt;a href="mailto:support@fit2cloud.com"&gt;support@fit2cloud.com&lt;/a&gt; „ÄÇ&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tenstorrent/tt-metal</title>
      <link>https://github.com/tenstorrent/tt-metal</link>
      <description>&lt;p&gt;ü§ò TT-NN operator library, and TT-Metalium low level kernel programming model.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/actions/workflows/all-post-commit-workflows.yaml"&gt;&lt;img src="https://github.com/tenstorrent/tt-metal/actions/workflows/all-post-commit-workflows.yaml/badge.svg?sanitize=true" alt="tt-metal CI" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/tenstorrent/tt-metal"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt; &lt;p&gt;&lt;a href="https://tenstorrent.com/hardware/blackhole"&gt;Hardware&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/INSTALLING.md"&gt;Install&lt;/a&gt; | &lt;a href="https://discord.gg/tvhGzHQwaj"&gt;Discord&lt;/a&gt; | &lt;a href="https://boards.greenhouse.io/tenstorrent/jobs/4155609007"&gt;Join Us&lt;/a&gt; | &lt;a href="https://github.com/tenstorrent/tt-metal/issues?q=is%3Aissue%20state%3Aopen%20label%3Abounty"&gt;Bounty $&lt;/a&gt;&lt;/p&gt; &lt;/h1&gt; 
 &lt;img src="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/docs/source/common/_static/tt_nn_w_logo.png" alt="ttnn logo" height="180" /&gt; 
 &lt;p&gt;&lt;strong&gt;TT-NN&lt;/strong&gt; is a Python &amp;amp; C++ Neural Network OP library.&lt;/p&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://docs.tenstorrent.com/tt-metal/latest/ttnn/index.html"&gt;API Reference&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/models/demos/"&gt;Model Demos&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
&lt;/div&gt; 
&lt;h2&gt;Quick Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-forge/tree/main"&gt;TT-Forge&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-forge-fe"&gt;TT-Forge-FE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-torch"&gt;TT-Torch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-xla"&gt;TT-XLA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-mlir"&gt;TT-MLIR&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-tvm"&gt;TT-TVM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/releases"&gt;Releases&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Featured Models&lt;/h2&gt; 
&lt;p&gt;The Models team is focused on developing the following models to a customer-ready state. Ongoing work includes optimizations for performance, accuracy, and compatibility. Follow each model link for more details.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] For a &lt;strong&gt;full model list&lt;/strong&gt; see the &lt;strong&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/tree/main/models/README.md"&gt;Model Matrix&lt;/a&gt;&lt;/strong&gt;, or visit the &lt;strong&gt;&lt;a href="https://tenstorrent.com/developers"&gt;Developer Hub&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Performance Metrics:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Time to First Token (TTFT) measures the time (in milliseconds) it takes to generate the first output token after input is received.&lt;/li&gt; 
  &lt;li&gt;T/S/U (Tokens per Second per User): Represents the throughput of first-token generation after prefill. It is calculated as 1 / inter-token latency.&lt;/li&gt; 
  &lt;li&gt;T/S (Tokens per Second): Represents total token throughput, calculated as T/S = T/S/U x batch size.&lt;/li&gt; 
  &lt;li&gt;TP (Tensor Parallel) and DP (Data Parallel): Indicate the parallelization factors across multiple devices.&lt;/li&gt; 
  &lt;li&gt;Reported LLM Performance: Based on an input sequence length of 128 tokens for all models.&lt;/li&gt; 
  &lt;li&gt;Performance Data Source: Metrics were collected using the tt-metal model demos (linked above). Results may vary when using other runtimes such as the vLLM inference server.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/models/demos/llama3_70b_galaxy"&gt;Llama 3.1 70B (TP=32)&lt;/a&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Batch&lt;/th&gt; 
   &lt;th&gt;Hardware&lt;/th&gt; 
   &lt;th&gt;TTFT (MS)&lt;/th&gt; 
   &lt;th&gt;T/S/U&lt;/th&gt; 
   &lt;th&gt;Target&lt;br /&gt;T/S/U&lt;/th&gt; 
   &lt;th&gt;T/S&lt;/th&gt; 
   &lt;th&gt;TT-Metalium Release&lt;/th&gt; 
   &lt;th&gt;vLLM Tenstorrent Repo Release&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;32&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://tenstorrent.com/hardware/galaxy"&gt;Galaxy (Wormhole)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;53&lt;/td&gt; 
   &lt;td&gt;72.5&lt;/td&gt; 
   &lt;td&gt;80&lt;/td&gt; 
   &lt;td&gt;2268.8&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/tree/v0.62.2"&gt;v0.62.2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tenstorrent/vllm/tree/c348d085a463340a66194bbee9cd4bfc5f9c697a/tt_metal"&gt;c348d08&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/models/tt_transformers"&gt;Qwen 3 32B (TP=8)&lt;/a&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Batch&lt;/th&gt; 
   &lt;th&gt;Hardware&lt;/th&gt; 
   &lt;th&gt;TTFT (MS)&lt;/th&gt; 
   &lt;th&gt;T/S/U&lt;/th&gt; 
   &lt;th&gt;Target&lt;br /&gt;T/S/U&lt;/th&gt; 
   &lt;th&gt;T/S&lt;/th&gt; 
   &lt;th&gt;TT-Metalium Release&lt;/th&gt; 
   &lt;th&gt;vLLM Tenstorrent Repo Release&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;32&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://tenstorrent.com/hardware/tt-quietbox"&gt;QuietBox (Wormhole)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;109&lt;/td&gt; 
   &lt;td&gt;22.1&lt;/td&gt; 
   &lt;td&gt;30&lt;/td&gt; 
   &lt;td&gt;707.2&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/tree/v0.59.0-rc52"&gt;v0.59.0-rc52&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tenstorrent/vllm/tree/f028da11b5b8205272bf18a478de93bd2dd3e29e/tt_metal"&gt;f028da1&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Blackhole software optimization is under active development. Please join us in shaping the future of open source AI! &lt;br /&gt; &lt;a href="https://discord.gg/tenstorrent"&gt;[Discord]&lt;/a&gt; &lt;a href="https://tenstorrent.com/developers"&gt;[Developer Hub]&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For more information regarding vLLM installation and environment creation visit the &lt;a href="https://github.com/tenstorrent/vllm/raw/dev/tt_metal/README.md"&gt;Tenstorrent vLLM repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Model Updates&lt;/h2&gt; 
&lt;p&gt;For the latest model updates and features, please see &lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/models/docs/MODEL_UPDATES.md"&gt;MODEL_UPDATES.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Model Bring-Up and Testing&lt;/h2&gt; 
&lt;p&gt;For information on initial model procedures, please see &lt;a href="https://github.com/tenstorrent/tt-metal/raw/main/models/docs/model_bring_up.md"&gt;Model Bring-Up and Testing&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;TT-NN Tech Reports&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/AdvancedPerformanceOptimizationsForModels/AdvancedPerformanceOptimizationsForModels.md"&gt;Advanced Performance Optimizations for Models&lt;/a&gt; (updated March 4th, 2025)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/Programming_Mesh_of_Devices/Programming_Mesh_of_Devices_with_TT-NN.md"&gt;Programming Mesh of Devices&lt;/a&gt; (updated Sept 9th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/ViT-TTNN/vit.md"&gt;ViT Implementation in TT-NN on GS&lt;/a&gt; (updated Sept 22nd, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/LLMs/llms.md"&gt;LLMs Bring up in TT-NN&lt;/a&gt; (updated Oct 29th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/YoloV4-TTNN/yolov4.md"&gt;YOLOv4 Implementation in TT-NN on WH&lt;/a&gt; (updated November 8th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/CNNs/cnn_optimizations.md"&gt;CNN Bring up &amp;amp; Optimization in TT-NN&lt;/a&gt; (updated Jan 22nd, 2025)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/GEMM_FLOPS/GEMM_FLOPS.md"&gt;Matrix Multiply FLOPS on Wormhole and Blackhole&lt;/a&gt; (updated June 17th, 2025)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/docs/source/common/images/tt_refresh_metalium_w_icon.png" alt="TT-Metalium logo" height="180" /&gt; 
 &lt;p&gt;&lt;strong&gt;TT-Metalium&lt;/strong&gt; is our low-level programming model, enabling kernel development for Tenstorrent hardware.&lt;/p&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/METALIUM_GUIDE.md"&gt;Programming Guide&lt;/a&gt; | &lt;a href="https://docs.tenstorrent.com/tt-metal/latest/tt-metalium/tt_metal/apis/index.html"&gt;API Reference&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
&lt;/div&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Get started with &lt;a href="https://docs.tenstorrent.com/tt-metal/latest/tt-metalium/tt_metal/examples/index.html"&gt;simple kernels&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;TT-Metalium Tech Reports&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/matrix_engine/matrix_engine.md"&gt;Matrix Engine&lt;/a&gt; (updated Sept 6th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/data_formats/data_formats.md"&gt;Data Formats&lt;/a&gt; (updated Sept 7th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/data_formats/reconfig_data_format.md"&gt;Reconfiguring Data Formats&lt;/a&gt; (updated Oct 17th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/Handling_Special_Value/special_values.md"&gt;Handling special floating-point numbers&lt;/a&gt; (updated Oct 5th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/memory/allocator.md"&gt;Allocator&lt;/a&gt; (Updated Dec 19th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/tensor_layouts/tensor_layouts.md"&gt;Tensor Layouts&lt;/a&gt; (updated Sept 6th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/Saturating_DRAM_bandwidth/Saturating_DRAM_bandwidth.md"&gt;Saturating DRAM Bandwidth&lt;/a&gt; (updated Sept 6th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/FlashAttention/FlashAttention.md"&gt;Flash Attention on Wormhole&lt;/a&gt; (updated Sept 6th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/CNNs/ttcnn.md"&gt;CNNs on TT Architectures&lt;/a&gt; (updated Sept 6th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/EthernetMultichip/BasicEthernetGuide.md"&gt;Ethernet and Multichip Basics&lt;/a&gt; (Updated Sept 20th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/EthernetMultichip/CclDeveloperGuide.md"&gt;Collective Communication Library (CCL)&lt;/a&gt; (Updated Sept 20th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/Blackhole/BlackholeBringUpProgrammingGuide.md"&gt;Blackhole Bring-Up Programming Guide&lt;/a&gt; (Updated Dec 18th, 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/SubDevices/SubDevices.md"&gt;Sub-Devices&lt;/a&gt; (Updated Jan 7th, 2025)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;TT-Metalium Programming Examples&lt;/h2&gt; 
&lt;h3&gt;Hello World&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/raw/main/tt_metal/programming_examples/hello_world_compute_kernel/hello_world_compute.md"&gt;Hello World! Compute Kernel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/raw/main/tt_metal/programming_examples/hello_world_datamovement_kernel/hello_world_data_movement.md"&gt;Hello World! Data Movement Kernel&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Add Integers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/raw/main/tt_metal/programming_examples/add_2_integers_in_riscv/add_2_integers_in_riscv.md"&gt;Add 2 Integers in Baby RiscV&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/raw/main/tt_metal/programming_examples/add_2_integers_in_compute/add_2_integers_in_compute.md"&gt;Add 2 Integers in Compute Kernel&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Simple Tensor Manipulation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/prog_examples/shard_data_rm/shard_data_rm.md"&gt;Sharding&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/prog_examples/pad_multi_core/pad_multi_core.md"&gt;Padding&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;DRAM Data Movement&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/raw/main/tt_metal/programming_examples/loopback/dram_loopback.md"&gt;Dram Loopback Data Movement&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Eltwise&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/raw/main/tt_metal/programming_examples/eltwise_sfpu/eltwise_sfpu.md"&gt;Eltwise Unary OP in Vector Engine (SFPU)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/raw/main/tt_metal/programming_examples/eltwise_binary/eltwise_binary.md"&gt;Eltwise Binary OP in Matrix Engine (FPU)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Matmul&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/raw/main/tt_metal/programming_examples/matmul/matmul_single_core/matmul_single_core.md"&gt;Matmul OP on a Single_core&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/raw/main/tt_metal/programming_examples/matmul/matmul_multi_core/matmul_multi_core.md"&gt;Matmul OP on Multi_core (Basic)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/prog_examples/matmul_multi_core_optimized/data_reuse.md"&gt;Matmul Multi_core Reuse (Optimized)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/tech_reports/prog_examples/matmul_multi_core_optimized/data_mcast.md"&gt;Matmul Multi_core Multi-Cast (Optimized)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Tools and Instruments&lt;/h3&gt; 
&lt;h4&gt;&lt;a href="https://github.com/tenstorrent/ttnn-visualizer"&gt;TT_NN Visualizer&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;A comprehensive tool for visualizing and analyzing model execution, offering interactive graphs, memory plots, tensor details, buffer overviews, operation flow graphs, and multi-instance support with file or SSH-based report loading. Install via pip or build from source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install ttnn-visualizer
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Related Tenstorrent Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-forge/tree/main"&gt;TT-Forge&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-forge-fe"&gt;TT-Forge-FE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-torch"&gt;TT-Torch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-xla"&gt;TT-XLA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-mlir"&gt;TT-MLIR&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tenstorrent/tt-tvm"&gt;TT-TVM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Latest Releases&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Release&lt;/th&gt; 
   &lt;th&gt;Release Date&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0.63.0&lt;/td&gt; 
   &lt;td&gt;ETA Sep 15, 2025&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/releases/tag/v0.62.2"&gt;0.62.2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Aug 20, 2025&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0.61.0&lt;/td&gt; 
   &lt;td&gt;Skipped&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/releases/tag/v0.60.1"&gt;0.60.1&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Jul 22, 2025&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/releases/tag/v0.59.0"&gt;0.59.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Jun 18, 2025&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/releases/tag/v0.58.0"&gt;0.58.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;May 13, 2025&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/releases/tag/v0.57.0"&gt;0.57.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Apr 15, 2025&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/tenstorrent/tt-metal/releases/tag/v0.56.0"&gt;0.56.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Mar 7, 2025&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Visit the &lt;a href="https://github.com/tenstorrent/tt-metal/tree/main/releases"&gt;releases&lt;/a&gt; folder for details on releases, release notes, and estimated release dates.&lt;/p&gt; 
&lt;h2&gt;Tenstorrent Bounty Program Terms and Conditions&lt;/h2&gt; 
&lt;p&gt;This repo is a part of Tenstorrent‚Äôs bounty program. If you are interested in helping to improve tt-metal, please make sure to read the &lt;a href="https://docs.tenstorrent.com/bounty_terms.html"&gt;Tenstorrent Bounty Program Terms and Conditions&lt;/a&gt; before heading to the issues tab. Look for the issues that are tagged with both ‚Äúbounty‚Äù and difficulty level!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;TT-Metalium and TTNN are licensed under the Apache 2.0 License, as detailed in &lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/LICENSE"&gt;LICENSE&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/tenstorrent/tt-metal/main/LICENSE_understanding.txt"&gt;LICENSE_understanding.txt&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some distributable forms of this project‚Äîsuch as manylinux-compliant wheels‚Äîmay need to bundle additional libraries beyond the standard Linux system libraries. For example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;libnuma&lt;/li&gt; 
 &lt;li&gt;libhwloc&lt;/li&gt; 
 &lt;li&gt;openmpi (when built with multihost support)&lt;/li&gt; 
 &lt;li&gt;libevent (when built with multihost support)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;These libraries are bound by their own license terms.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/markitdown</title>
      <link>https://github.com/microsoft/markitdown</link>
      <description>&lt;p&gt;Python tool for converting files and office documents to Markdown.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MarkItDown&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/markitdown/"&gt;&lt;img src="https://img.shields.io/pypi/v/markitdown.svg?sanitize=true" alt="PyPI" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/dd/markitdown" alt="PyPI - Downloads" /&gt; &lt;a href="https://github.com/microsoft/autogen"&gt;&lt;img src="https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue" alt="Built by AutoGen Team" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See &lt;a href="https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp"&gt;markitdown-mcp&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Breaking changes between 0.0.1 to 0.1.0:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dependencies are now organized into optional feature-groups (further details below). Use &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt; to have backward-compatible behavior.&lt;/li&gt; 
  &lt;li&gt;convert_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.&lt;/li&gt; 
  &lt;li&gt;The DocumentConverter class interface has changed to read from file-like streams rather than file paths. &lt;em&gt;No temporary files are created anymore&lt;/em&gt;. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to &lt;a href="https://github.com/deanmalmgren/textract"&gt;textract&lt;/a&gt;, but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.&lt;/p&gt; 
&lt;p&gt;MarkItDown currently supports the conversion from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PDF&lt;/li&gt; 
 &lt;li&gt;PowerPoint&lt;/li&gt; 
 &lt;li&gt;Word&lt;/li&gt; 
 &lt;li&gt;Excel&lt;/li&gt; 
 &lt;li&gt;Images (EXIF metadata and OCR)&lt;/li&gt; 
 &lt;li&gt;Audio (EXIF metadata and speech transcription)&lt;/li&gt; 
 &lt;li&gt;HTML&lt;/li&gt; 
 &lt;li&gt;Text-based formats (CSV, JSON, XML)&lt;/li&gt; 
 &lt;li&gt;ZIP files (iterates over contents)&lt;/li&gt; 
 &lt;li&gt;Youtube URLs&lt;/li&gt; 
 &lt;li&gt;EPubs&lt;/li&gt; 
 &lt;li&gt;... and more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why Markdown?&lt;/h2&gt; 
&lt;p&gt;Markdown is extremely close to plain text, with minimal markup or formatting, but still provides a way to represent important document structure. Mainstream LLMs, such as OpenAI's GPT-4o, natively "&lt;em&gt;speak&lt;/em&gt;" Markdown, and often incorporate Markdown into their responses unprompted. This suggests that they have been trained on vast amounts of Markdown-formatted text, and understand it well. As a side benefit, Markdown conventions are also highly token-efficient.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;MarkItDown requires Python 3.10 or higher. It is recommended to use a virtual environment to avoid dependency conflicts.&lt;/p&gt; 
&lt;p&gt;With the standard Python installation, you can create and activate a virtual environment using the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If using &lt;code&gt;uv&lt;/code&gt;, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv --python=3.12 .venv
source .venv/bin/activate
# NOTE: Be sure to use 'uv pip install' rather than just 'pip install' to install packages in this virtual environment
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using Anaconda, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n markitdown python=3.12
conda activate markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install MarkItDown, use pip: &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt;. Alternatively, you can install it from the source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone git@github.com:microsoft/markitdown.git
cd markitdown
pip install -e 'packages/markitdown[all]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Command-Line&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf &amp;gt; document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use &lt;code&gt;-o&lt;/code&gt; to specify the output file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also pipe content:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cat path-to-file.pdf | markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Dependencies&lt;/h3&gt; 
&lt;p&gt;MarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the &lt;code&gt;[all]&lt;/code&gt; option. However, you can also install them individually for more control. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'markitdown[pdf, docx, pptx]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;will install only the dependencies for PDF, DOCX, and PPTX files.&lt;/p&gt; 
&lt;p&gt;At the moment, the following optional dependencies are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[all]&lt;/code&gt; Installs all optional dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pptx]&lt;/code&gt; Installs dependencies for PowerPoint files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[docx]&lt;/code&gt; Installs dependencies for Word files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xlsx]&lt;/code&gt; Installs dependencies for Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xls]&lt;/code&gt; Installs dependencies for older Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pdf]&lt;/code&gt; Installs dependencies for PDF files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[outlook]&lt;/code&gt; Installs dependencies for Outlook messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[az-doc-intel]&lt;/code&gt; Installs dependencies for Azure Document Intelligence&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[audio-transcription]&lt;/code&gt; Installs dependencies for audio transcription of wav and mp3 files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[youtube-transcription]&lt;/code&gt; Installs dependencies for fetching YouTube video transcription&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Plugins&lt;/h3&gt; 
&lt;p&gt;MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --list-plugins
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To enable plugins use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --use-plugins path-to-file.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To find available plugins, search GitHub for the hashtag &lt;code&gt;#markitdown-plugin&lt;/code&gt;. To develop a plugin, see &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Azure Document Intelligence&lt;/h3&gt; 
&lt;p&gt;To use Microsoft Document Intelligence for conversion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md -d -e "&amp;lt;document_intelligence_endpoint&amp;gt;"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More information about how to set up an Azure Document Intelligence Resource can be found &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Python API&lt;/h3&gt; 
&lt;p&gt;Basic usage in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
result = md.convert("test.xlsx")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Document Intelligence conversion in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(docintel_endpoint="&amp;lt;document_intelligence_endpoint&amp;gt;")
result = md.convert("test.pdf")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use Large Language Models for image descriptions (currently only for pptx and image files), provide &lt;code&gt;llm_client&lt;/code&gt; and &lt;code&gt;llm_model&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown
from openai import OpenAI

client = OpenAI()
md = MarkItDown(llm_client=client, llm_model="gpt-4o", llm_prompt="optional custom prompt")
result = md.convert("example.jpg")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t markitdown:latest .
docker run --rm -i markitdown:latest &amp;lt; ~/your-file.pdf &amp;gt; output.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;p&gt;You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as 'open for contribution' and 'open for reviewing' to help facilitate community contributions. These are of course just suggestions and you are welcome to contribute in any way you like.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;All&lt;/th&gt; 
    &lt;th&gt;Especially Needs Help from Community&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues"&gt;All Issues&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22"&gt;Issues open for contribution&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;PRs&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls"&gt;All PRs&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22"&gt;PRs open for reviewing&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h3&gt;Running Tests and Checks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to the MarkItDown package:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;cd packages/markitdown
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;code&gt;hatch&lt;/code&gt; in your environment and run tests:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
hatch shell
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(Alternative) Use the Devcontainer which has all the dependencies installed:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;# Reopen the project in Devcontainer and run:
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run pre-commit checks before submitting a PR: &lt;code&gt;pre-commit run --all-files&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing 3rd-party Plugins&lt;/h3&gt; 
&lt;p&gt;You can also contribute by creating and sharing 3rd party plugins. See &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cypress-io/cypress</title>
      <link>https://github.com/cypress-io/cypress</link>
      <description>&lt;p&gt;Fast, easy and reliable testing for anything that runs in a browser.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.cypress.io"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="./assets/cypress-logo-dark.png" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="./assets/cypress-logo-light.png" /&gt; 
   &lt;img alt="Cypress Logo" src="https://raw.githubusercontent.com/cypress-io/cypress/develop/assets/cypress-logo-light.png" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://on.cypress.io"&gt;Documentation&lt;/a&gt; | &lt;a href="https://on.cypress.io/changelog"&gt;Changelog&lt;/a&gt; | &lt;a href="https://on.cypress.io/roadmap"&gt;Roadmap&lt;/a&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; The web has evolved. Finally, testing has too. &lt;/h3&gt; 
&lt;p align="center"&gt; Fast, easy and reliable testing for anything that runs in a browser. &lt;/p&gt; 
&lt;p align="center"&gt; Join us, we're &lt;a href="https://cypress.io/jobs"&gt;hiring&lt;/a&gt;. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.npmjs.com/package/cypress"&gt; &lt;img src="https://img.shields.io/npm/dm/cypress.svg?sanitize=true" alt="npm" /&gt; &lt;/a&gt; &lt;a href="https://on.cypress.io/discord"&gt; &lt;img src="https://img.shields.io/badge/chat-on%20Discord-brightgreen" alt="Discord chat" /&gt; &lt;/a&gt; &lt;a href="https://stackshare.io/cypress"&gt; &lt;img src="https://img.stackshare.io/misc/follow-on-stackshare-badge.svg?sanitize=true" alt="StackShare" /&gt; &lt;/a&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;h2&gt;What is Cypress?&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;a href="https://player.vimeo.com/video/237527670"&gt; &lt;img alt="Why Cypress Video" src="https://user-images.githubusercontent.com/1271364/31739717-dbdff0ee-b41c-11e7-9b16-bfa1b6ac1814.png" width="75%" height="75%" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Installing&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://badge.fury.io/js/cypress"&gt;&lt;img src="https://badge.fury.io/js/cypress.svg?sanitize=true" alt="npm version" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Install Cypress for Mac, Linux, or Windows, then &lt;a href="https://on.cypress.io/install"&gt;get started&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install cypress --save-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;yarn add cypress --dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm add cypress --save-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cypress-io/cypress/develop/assets/cypress-installation.gif" alt="installing-cli e1693232" /&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://cloud.cypress.io/projects/ypt4pf/runs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://cloud.cypress.io/badge/simple/ypt4pf/develop&amp;amp;style=flat&amp;amp;logo=cypress" alt="cypress" /&gt;&lt;/a&gt; &lt;a href="https://circleci.com/gh/cypress-io/cypress/tree/develop"&gt;&lt;img src="https://circleci.com/gh/cypress-io/cypress/tree/develop.svg?style=svg" alt="CircleCI" /&gt;&lt;/a&gt; - &lt;code&gt;develop&lt;/code&gt; branch&lt;/p&gt; 
&lt;p&gt;Please see our &lt;a href="https://raw.githubusercontent.com/cypress-io/cypress/develop/CONTRIBUTING.md"&gt;Contributing Guideline&lt;/a&gt; which explains repo organization, linting, testing, and other steps.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/cypress-io/cypress/raw/develop/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-green.svg?sanitize=true" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This project is licensed under the terms of the &lt;a href="https://raw.githubusercontent.com/cypress-io/cypress/develop/LICENSE"&gt;MIT license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Badges&lt;/h2&gt; 
&lt;p&gt;Configure a badge for your project's README to show your test status or test count in the &lt;a href="https://www.cypress.io/cloud"&gt;Cypress Cloud&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://cloud.cypress.io/projects/ypt4pf/runs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://cloud.cypress.io/badge/simple/ypt4pf/develop&amp;amp;style=flat&amp;amp;logo=cypress" alt="cypress" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://cloud.cypress.io/projects/ypt4pf/runs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://cloud.cypress.io/badge/count/ypt4pf/develop&amp;amp;style=flat&amp;amp;logo=cypress" alt="cypress" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Or let the world know your project is using Cypress with the badge below.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.cypress.io/"&gt;&lt;img src="https://img.shields.io/badge/tested%20with-Cypress-04C38E.svg?sanitize=true" alt="Cypress.io" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;[![Cypress.io](https://img.shields.io/badge/tested%20with-Cypress-04C38E.svg)](https://www.cypress.io/)
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>jwasham/coding-interview-university</title>
      <link>https://github.com/jwasham/coding-interview-university</link>
      <description>&lt;p&gt;A complete computer science study plan to become a software engineer.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Coding Interview University&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;I originally created this as a short to-do list of study topics for becoming a software engineer, but it grew to the large list you see today. After going through this study plan, &lt;a href="https://startupnextdoor.com/ive-been-acquired-by-amazon/?src=ciu"&gt;I got hired as a Software Development Engineer at Amazon&lt;/a&gt;! You probably won't have to study as much as I did. Anyway, everything you need is here.&lt;/p&gt; 
 &lt;p&gt;I studied about 8-12 hours a day, for several months. This is my story: &lt;a href="https://medium.freecodecamp.org/why-i-studied-full-time-for-8-months-for-a-google-interview-cc662ce9bb13"&gt;Why I studied full-time for 8 months for a Google interview&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Please Note:&lt;/strong&gt; You won't need to study as much as I did. I wasted a lot of time on things I didn't need to know. More info about that is below. I'll help you get there without wasting your precious time.&lt;/p&gt; 
 &lt;p&gt;The items listed here will prepare you well for a technical interview at just about any software company, including the giants: Amazon, Facebook, Google, and Microsoft.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Best of luck to you!&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;Translations:&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-id.md"&gt;Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-bg.md"&gt;Bulgarian&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-es.md"&gt;Espa√±ol&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-de.md"&gt;German&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-ja.md"&gt;Japanese (Êó•Êú¨Ë™û)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-mr.md"&gt;Marathi&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-pl.md"&gt;Polish&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-ptbr.md"&gt;Portugu√™s Brasileiro&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-ru.md"&gt;Russian&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-vi.md"&gt;Ti·∫øng Vi·ªát - Vietnamese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-ur.md"&gt;Urdu - ÿßÿ±ÿØŸà&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-uz.md"&gt;Uzbek&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-bn.md"&gt;‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ - Bangla&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-kh.md"&gt;·ûÅ·üí·ûò·üÇ·ûö - Khmer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-cn.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/translations/README-tw.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Translations in progress:&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/1164"&gt;Afrikaans&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/98"&gt;Arabic&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/89"&gt;French&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/166"&gt;Greek&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/1030"&gt;Italian&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/118"&gt;Korean(ÌïúÍµ≠Ïñ¥)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/239"&gt;Malayalam&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/186"&gt;Persian - Farsi&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/117"&gt;Telugu&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/156"&gt;Thai&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/90"&gt;Turkish&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/106"&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/82"&gt;◊¢◊ë◊®◊ô◊™&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/issues/81"&gt;‡§π‡§ø‡§®‡•ç‡§¶‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;What is it?&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://d3j2pkmjtin6ou.cloudfront.net/coding-at-the-whiteboard-silicon-valley.png" alt="Coding at the whiteboard - from HBO's Silicon Valley" /&gt;&lt;/p&gt; 
&lt;p&gt;This is my multi-month study plan for becoming a software engineer for a large company.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Required:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A little experience with coding (variables, loops, methods/functions, etc)&lt;/li&gt; 
 &lt;li&gt;Patience&lt;/li&gt; 
 &lt;li&gt;Time&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note this is a study plan for &lt;strong&gt;software engineering&lt;/strong&gt;, not frontend engineering or full-stack development. There are really super roadmaps and coursework for those career paths elsewhere (see &lt;a href="https://roadmap.sh/"&gt;https://roadmap.sh/&lt;/a&gt; for more info).&lt;/p&gt; 
&lt;p&gt;There is a lot to learn in a university Computer Science program, but only knowing about 75% is good enough for an interview, so that's what I cover here. For a complete CS self-taught program, the resources for my study plan have been included in Kamran Ahmed's Computer Science Roadmap: &lt;a href="https://roadmap.sh/computer-science"&gt;https://roadmap.sh/computer-science&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;h3&gt;The Study Plan&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#what-is-it"&gt;What is it?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#why-use-it"&gt;Why use it?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#how-to-use-it"&gt;How to use it&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#dont-feel-you-arent-smart-enough"&gt;Don't feel you aren't smart enough&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#a-note-about-video-resources"&gt;A Note About Video Resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#choose-a-programming-language"&gt;Choose a Programming Language&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#books-for-data-structures-and-algorithms"&gt;Books for Data Structures and Algorithms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#interview-prep-books"&gt;Interview Prep Books&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#dont-make-my-mistakes"&gt;Don't Make My Mistakes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#what-you-wont-see-covered"&gt;What you Won't See Covered&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#the-daily-plan"&gt;The Daily Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#coding-question-practice"&gt;Coding Question Practice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#coding-problems"&gt;Coding Problems&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Topics of Study&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#algorithmic-complexity--big-o--asymptotic-analysis"&gt;Algorithmic complexity / Big-O / Asymptotic analysis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#data-structures"&gt;Data Structures&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#arrays"&gt;Arrays&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#linked-lists"&gt;Linked Lists&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#stack"&gt;Stack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#queue"&gt;Queue&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#hash-table"&gt;Hash table&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#more-knowledge"&gt;More Knowledge&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#binary-search"&gt;Binary search&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#bitwise-operations"&gt;Bitwise operations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#trees"&gt;Trees&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#trees---intro"&gt;Trees - Intro&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#binary-search-trees-bsts"&gt;Binary search trees: BSTs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#heap--priority-queue--binary-heap"&gt;Heap / Priority Queue / Binary Heap&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;balanced search trees (general concept, not details)&lt;/li&gt; 
   &lt;li&gt;traversals: preorder, inorder, postorder, BFS, DFS&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#sorting"&gt;Sorting&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;selection&lt;/li&gt; 
   &lt;li&gt;insertion&lt;/li&gt; 
   &lt;li&gt;heapsort&lt;/li&gt; 
   &lt;li&gt;quicksort&lt;/li&gt; 
   &lt;li&gt;mergesort&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#graphs"&gt;Graphs&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;directed&lt;/li&gt; 
   &lt;li&gt;undirected&lt;/li&gt; 
   &lt;li&gt;adjacency matrix&lt;/li&gt; 
   &lt;li&gt;adjacency list&lt;/li&gt; 
   &lt;li&gt;traversals: BFS, DFS&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#even-more-knowledge"&gt;Even More Knowledge&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#recursion"&gt;Recursion&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#dynamic-programming"&gt;Dynamic Programming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#design-patterns"&gt;Design Patterns&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#combinatorics-n-choose-k--probability"&gt;Combinatorics (n choose k) &amp;amp; Probability&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#np-np-complete-and-approximation-algorithms"&gt;NP, NP-Complete and Approximation Algorithms&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#how-computers-process-a-program"&gt;How computers process a program&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#caches"&gt;Caches&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#processes-and-threads"&gt;Processes and Threads&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#testing"&gt;Testing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#string-searching--manipulations"&gt;String searching &amp;amp; manipulations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#tries"&gt;Tries&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#floating-point-numbers"&gt;Floating Point Numbers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#unicode"&gt;Unicode&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#endianness"&gt;Endianness&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#networking"&gt;Networking&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#final-review"&gt;Final Review&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting the Job&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#update-your-resume"&gt;Update Your Resume&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#find-a-job"&gt;Find a Job&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#interview-process--general-interview-prep"&gt;Interview Process &amp;amp; General Interview Prep&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#be-thinking-of-for-when-the-interview-comes"&gt;Be thinking of for when the interview comes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#have-questions-for-the-interviewer"&gt;Have questions for the interviewer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#once-youve-got-the-job"&gt;Once You've Got The Job&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;---------------- Everything below this point is optional ----------------&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Optional Extra Topics &amp;amp; Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#additional-books"&gt;Additional Books&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#system-design-scalability-data-handling"&gt;System Design, Scalability, Data Handling&lt;/a&gt; (if you have 4+ years experience)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#additional-learning"&gt;Additional Learning&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#compilers"&gt;Compilers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#emacs-and-vim"&gt;Emacs and vi(m)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#unix-command-line-tools"&gt;Unix command line tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#information-theory-videos"&gt;Information theory&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#parity--hamming-code-videos"&gt;Parity &amp;amp; Hamming Code&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#entropy"&gt;Entropy&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#cryptography"&gt;Cryptography&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#compression"&gt;Compression&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#computer-security"&gt;Computer Security&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#garbage-collection"&gt;Garbage collection&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#parallel-programming"&gt;Parallel Programming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#messaging-serialization-and-queueing-systems"&gt;Messaging, Serialization, and Queueing Systems&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#a"&gt;A*&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#fast-fourier-transform"&gt;Fast Fourier Transform&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#bloom-filter"&gt;Bloom Filter&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#hyperloglog"&gt;HyperLogLog&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#locality-sensitive-hashing"&gt;Locality-Sensitive Hashing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#van-emde-boas-trees"&gt;van Emde Boas Trees&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#augmented-data-structures"&gt;Augmented Data Structures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#balanced-search-trees"&gt;Balanced search trees&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;AVL trees&lt;/li&gt; 
     &lt;li&gt;Splay trees&lt;/li&gt; 
     &lt;li&gt;Red/black trees&lt;/li&gt; 
     &lt;li&gt;2-3 search trees&lt;/li&gt; 
     &lt;li&gt;2-3-4 Trees (aka 2-4 trees)&lt;/li&gt; 
     &lt;li&gt;N-ary (K-ary, M-ary) trees&lt;/li&gt; 
     &lt;li&gt;B-Trees&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#k-d-trees"&gt;k-D Trees&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#skip-lists"&gt;Skip lists&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#network-flows"&gt;Network Flows&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#disjoint-sets--union-find"&gt;Disjoint Sets &amp;amp; Union Find&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#math-for-fast-processing"&gt;Math for Fast Processing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#treap"&gt;Treap&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#linear-programming-videos"&gt;Linear Programming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#geometry-convex-hull-videos"&gt;Geometry, Convex hull&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#discrete-math"&gt;Discrete math&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#additional-detail-on-some-subjects"&gt;Additional Detail on Some Subjects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#video-series"&gt;Video Series&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#computer-science-courses"&gt;Computer Science Courses&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#papers"&gt;Papers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Why use it?&lt;/h2&gt; 
&lt;p&gt;If you want to work as a software engineer for a large company, these are the things you have to know.&lt;/p&gt; 
&lt;p&gt;If you missed out on getting a degree in computer science, like I did, this will catch you up and save four years of your life.&lt;/p&gt; 
&lt;p&gt;When I started this project, I didn't know a stack from a heap, didn't know Big-O anything, or anything about trees, or how to traverse a graph. If I had to code a sorting algorithm, I can tell ya it would have been terrible. Every data structure I had ever used was built into the language, and I didn't know how they worked under the hood at all. I never had to manage memory unless a process I was running would give an "out of memory" error, and then I'd have to find a workaround. I used a few multidimensional arrays in my life and thousands of associative arrays, but I never created data structures from scratch.&lt;/p&gt; 
&lt;p&gt;It's a long plan. It may take you months. If you are familiar with a lot of this already it will take you a lot less time.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;How to use it&lt;/h2&gt; 
&lt;p&gt;Everything below is an outline, and you should tackle the items in order from top to bottom.&lt;/p&gt; 
&lt;p&gt;I'm using GitHub's special markdown flavor, including tasks lists to track progress.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://guides.github.com/features/mastering-markdown/#GitHub-flavored-markdown"&gt;More about GitHub-flavored markdown&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;If you don't want to use git&lt;/h3&gt; 
&lt;p&gt;On this page, click the Code button near the top, then click "Download ZIP". Unzip the file and you can work with the text files.&lt;/p&gt; 
&lt;p&gt;If you're open in a code editor that understands markdown, you'll see everything formatted nicely.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://d3j2pkmjtin6ou.cloudfront.net/how-to-download-as-zip.png" alt="How to download the repo as a zip file" /&gt;&lt;/p&gt; 
&lt;h3&gt;If you're comfortable with git&lt;/h3&gt; 
&lt;p&gt;Create a new branch so you can check items like this, just put an x in the brackets: [x]&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;&lt;strong&gt;Fork the GitHub repo:&lt;/strong&gt;&lt;/em&gt; &lt;code&gt;https://github.com/jwasham/coding-interview-university&lt;/code&gt; by clicking on the Fork button.&lt;/p&gt; &lt;p&gt;&lt;img src="https://d3j2pkmjtin6ou.cloudfront.net/fork-button.png" alt="Fork the GitHub repo" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone to your local repo:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/&amp;lt;YOUR_GITHUB_USERNAME&amp;gt;/coding-interview-university.git
cd coding-interview-university
git remote add upstream https://github.com/jwasham/coding-interview-university.git
git remote set-url --push upstream DISABLE  # so that you don't push your personal progress back to the original repo
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Mark all boxes with X after you completed your changes:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git commit -am "Marked personal progress"
git pull upstream main  # keep your fork up-to-date with changes from the original repo

git push # just pushes to your fork
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Don't feel you aren't smart enough&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Successful software engineers are smart, but many have an insecurity that they aren't smart enough.&lt;/li&gt; 
 &lt;li&gt;The following videos may help you overcome this insecurity: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=0SARbwvhupQ"&gt;The myth of the Genius Programmer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1i8ylq4j_EY"&gt;It's Dangerous to Go Alone: Battling the Invisible Monsters in Tech&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;A Note About Video Resources&lt;/h2&gt; 
&lt;p&gt;Some videos are available only by enrolling in a Coursera or EdX class. These are called MOOCs. Sometimes the classes are not in session so you have to wait a couple of months, so you have no access.&lt;/p&gt; 
&lt;p&gt;It would be great to replace the online course resources with free and always-available public sources, such as YouTube videos (preferably university lectures), so that you people can study these anytime, not just when a specific online course is in session.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Choose a Programming Language&lt;/h2&gt; 
&lt;p&gt;You'll need to choose a programming language for the coding interviews you do, but you'll also need to find a language that you can use to study computer science concepts.&lt;/p&gt; 
&lt;p&gt;Preferably the language would be the same, so that you only need to be proficient in one.&lt;/p&gt; 
&lt;h3&gt;For this Study Plan&lt;/h3&gt; 
&lt;p&gt;When I did the study plan, I used 2 languages for most of it: C and Python&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;C: Very low level. Allows you to deal with pointers and memory allocation/deallocation, so you feel the data structures and algorithms in your bones. In higher-level languages like Python or Java, these are hidden from you. In day-to-day work, that's terrific, but when you're learning how these low-level data structures are built, it's great to feel close to the metal. 
  &lt;ul&gt; 
   &lt;li&gt;C is everywhere. You'll see examples in books, lectures, videos, &lt;em&gt;everywhere&lt;/em&gt; while you're studying.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.amazon.com/Programming-Language-Brian-W-Kernighan/dp/0131103628"&gt;The C Programming Language, 2nd Edition&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;This is a short book, but it will give you a great handle on the C language and if you practice it a little you'll quickly get proficient. Understanding C helps you understand how programs and memory work.&lt;/li&gt; 
     &lt;li&gt;You don't need to go super deep in the book (or even finish it). Just get to where you're comfortable reading and writing in C.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Python: Modern and very expressive, I learned it because it's just super useful and also allows me to write less code in an interview.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is my preference. You do what you like, of course.&lt;/p&gt; 
&lt;p&gt;You may not need it, but here are some sites for learning a new language:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://exercism.org/tracks"&gt;Exercism&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.codewars.com"&gt;Codewars&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.hackerearth.com/for-developers/"&gt;HackerEarth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.scaler.com/topics/"&gt;Scaler Topics (Java, C++)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://programiz.pro/"&gt;Programiz PRO Community Challenges)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;For your Coding Interview&lt;/h3&gt; 
&lt;p&gt;You can use a language you are comfortable in to do the coding part of the interview, but for large companies, these are solid choices:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;C++&lt;/li&gt; 
 &lt;li&gt;Java&lt;/li&gt; 
 &lt;li&gt;Python&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You could also use these, but read around first. There may be caveats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;JavaScript&lt;/li&gt; 
 &lt;li&gt;Ruby&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here is an article I wrote about choosing a language for the interview: &lt;a href="https://startupnextdoor.com/important-pick-one-language-for-the-coding-interview/"&gt;Pick One Language for the Coding Interview&lt;/a&gt;. This is the original article my post was based on: &lt;a href="https://web.archive.org/web/20210516054124/http://blog.codingforinterviews.com/best-programming-language-jobs/"&gt;Choosing a Programming Language for Interviews&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You need to be very comfortable in the language and be knowledgeable.&lt;/p&gt; 
&lt;p&gt;Read more about choices:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.byte-by-byte.com/choose-the-right-language-for-your-coding-interview/"&gt;Choose the Right Language for Your Coding Interview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/programming-language-resources.md"&gt;See language-specific resources here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Books for Data Structures and Algorithms&lt;/h2&gt; 
&lt;p&gt;This book will form your foundation for computer science.&lt;/p&gt; 
&lt;p&gt;Just choose one, in a language that you will be comfortable with. You'll be doing a lot of reading and coding.&lt;/p&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://geni.us/q7svoz"&gt;Coding Interview Patterns: Nail Your Next Coding Interview&lt;/a&gt; (&lt;strong&gt;Main Recommendation&lt;/strong&gt;) 
  &lt;ul&gt; 
   &lt;li&gt;An insider‚Äôs perspective on what interviewers are truly looking for and why.&lt;/li&gt; 
   &lt;li&gt;101 real coding interview problems with detailed solutions.&lt;/li&gt; 
   &lt;li&gt;Intuitive explanations that guide you through each problem as if you were solving it in a live interview.&lt;/li&gt; 
   &lt;li&gt;1000+ diagrams to illustrate key concepts and patterns.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;C&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/Algorithms-Parts-1-5-Bundle-Fundamentals/dp/0201756080"&gt;Algorithms in C, Parts 1-5 (Bundle), 3rd Edition&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fundamentals, Data Structures, Sorting, Searching, and Graph Algorithms&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Java&lt;/h3&gt; 
&lt;p&gt;Your choice:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Goodrich, Tamassia, Goldwasser 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.amazon.com/Data-Structures-Algorithms-Michael-Goodrich/dp/1118771338/"&gt;Data Structures and Algorithms in Java&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Sedgewick and Wayne: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.amazon.com/Algorithms-4th-Robert-Sedgewick/dp/032157351X/"&gt;Algorithms&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Free Coursera course that covers the book (taught by the authors!): 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/learn/algorithms-part1"&gt;Algorithms I&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/learn/algorithms-part2"&gt;Algorithms II&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;C++&lt;/h3&gt; 
&lt;p&gt;Your choice:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Goodrich, Tamassia, and Mount 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.amazon.com/Data-Structures-Algorithms-Michael-Goodrich/dp/0470383275"&gt;Data Structures and Algorithms in C++, 2nd Edition&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Sedgewick and Wayne 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.amazon.com/Algorithms-Parts-1-4-Fundamentals-Structure/dp/0201350882/"&gt;Algorithms in C++, Parts 1-4: Fundamentals, Data Structure, Sorting, Searching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.amazon.com/Algorithms-Part-Graph-3rd-Pt-5/dp/0201361183/"&gt;Algorithms in C++ Part 5: Graph Algorithms&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Interview Prep Books&lt;/h2&gt; 
&lt;p&gt;Here are some recommended books to supplement your learning.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://geni.us/q7svoz"&gt;Coding Interview Patterns: Nail Your Next Coding Interview&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.amazon.com/Programming-Interviews-Exposed-Through-Interview/dp/111941847X/"&gt;Programming Interviews Exposed: Coding Your Way Through the Interview, 4th Edition&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Answers in C++ and Java&lt;/li&gt; 
   &lt;li&gt;This is a good warm-up for Cracking the Coding Interview&lt;/li&gt; 
   &lt;li&gt;Not too difficult. Most problems may be easier than what you'll see in an interview (from what I've read)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://www.amazon.com/Cracking-Coding-Interview-6th-Programming/dp/0984782850/"&gt;Cracking the Coding Interview, 6th Edition&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;answers in Java&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;If you have tons of extra time:&lt;/h3&gt; 
&lt;p&gt;Choose one:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/Elements-Programming-Interviews-Insiders-Guide/dp/1479274836"&gt;Elements of Programming Interviews (C++ version)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/Elements-Programming-Interviews-Python-Insiders/dp/1537713949/"&gt;Elements of Programming Interviews in Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/Elements-Programming-Interviews-Java-Insiders/dp/1517435803/"&gt;Elements of Programming Interviews (Java version)&lt;/a&gt; - &lt;a href="https://github.com/gardncl/elements-of-programming-interviews"&gt;Companion Project - Method Stub and Test Cases for Every Problem in the Book&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Don't Make My Mistakes&lt;/h2&gt; 
&lt;p&gt;This list grew over many months, and yes, it got out of hand.&lt;/p&gt; 
&lt;p&gt;Here are some mistakes I made so you'll have a better experience. And you'll save months of time.&lt;/p&gt; 
&lt;h3&gt;1. You Won't Remember it All&lt;/h3&gt; 
&lt;p&gt;I watched hours of videos and took copious notes, and months later there was much I didn't remember. I spent 3 days going through my notes and making flashcards, so I could review. I didn't need all of that knowledge.&lt;/p&gt; 
&lt;p&gt;Please, read so you won't make my mistakes:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://startupnextdoor.com/retaining-computer-science-knowledge/"&gt;Retaining Computer Science Knowledge&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;2. Use Flashcards&lt;/h3&gt; 
&lt;p&gt;To solve the problem, I made a little flashcard site where I could add flashcards of 2 types: general and code. Each card has a different formatting. I made a mobile-first website, so I could review on my phone or tablet, wherever I am.&lt;/p&gt; 
&lt;p&gt;Make your own for free:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jwasham/computer-science-flash-cards"&gt;Flashcards site repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;I DON'T RECOMMEND using my flashcards.&lt;/strong&gt; There are too many and most of them are trivia that you don't need.&lt;/p&gt; 
&lt;p&gt;But if you don't want to listen to me, here you go:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jwasham/computer-science-flash-cards/raw/main/cards-jwasham.db"&gt;My flash cards database (1200 cards)&lt;/a&gt;:&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jwasham/computer-science-flash-cards/raw/main/cards-jwasham-extreme.db"&gt;My flash cards database (extreme - 1800 cards)&lt;/a&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Keep in mind I went overboard and have cards covering everything from assembly language and Python trivia to machine learning and statistics. It's way too much for what's required.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note on flashcards:&lt;/strong&gt; The first time you recognize you know the answer, don't mark it as known. You have to see the same card and answer it several times correctly before you really know it. Repetition will put that knowledge deeper in your brain.&lt;/p&gt; 
&lt;p&gt;An alternative to using my flashcard site is &lt;a href="http://ankisrs.net/"&gt;Anki&lt;/a&gt;, which has been recommended to me numerous times. It uses a repetition system to help you remember. It's user-friendly, available on all platforms, and has a cloud sync system. It costs $25 on iOS but is free on other platforms.&lt;/p&gt; 
&lt;p&gt;My flashcard database in Anki format: &lt;a href="https://ankiweb.net/shared/info/25173560"&gt;https://ankiweb.net/shared/info/25173560&lt;/a&gt; (thanks &lt;a href="https://github.com/xiewenya"&gt;@xiewenya&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Some students have mentioned formatting issues with white space that can be fixed by doing the following: open the deck, edit the card, click cards, select the "styling" radio button, and add the member "white-space: pre;" to the card class.&lt;/p&gt; 
&lt;h3&gt;3. Do Coding Interview Questions While You're Learning&lt;/h3&gt; 
&lt;p&gt;THIS IS VERY IMPORTANT.&lt;/p&gt; 
&lt;p&gt;Start doing coding interview questions while you're learning data structures and algorithms.&lt;/p&gt; 
&lt;p&gt;You need to apply what you're learning to solve problems, or you'll forget. I made this mistake.&lt;/p&gt; 
&lt;p&gt;Once you've learned a topic, and feel somewhat comfortable with it, for example, &lt;strong&gt;linked lists&lt;/strong&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open one of the &lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#interview-prep-books"&gt;coding interview books&lt;/a&gt; (or coding problem websites, listed below)&lt;/li&gt; 
 &lt;li&gt;Do 2 or 3 questions regarding linked lists.&lt;/li&gt; 
 &lt;li&gt;Move on to the next learning topic.&lt;/li&gt; 
 &lt;li&gt;Later, go back and do another 2 or 3 linked list problems.&lt;/li&gt; 
 &lt;li&gt;Do this with each new topic you learn.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Keep doing problems while you're learning all this stuff, not after.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You're not being hired for knowledge, but how you apply the knowledge.&lt;/p&gt; 
&lt;p&gt;There are many resources for this, listed below. Keep going.&lt;/p&gt; 
&lt;h3&gt;4. Focus&lt;/h3&gt; 
&lt;p&gt;There are a lot of distractions that can take up valuable time. Focus and concentration are hard. Turn on some music without lyrics and you'll be able to focus pretty well.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;What you won't see covered&lt;/h2&gt; 
&lt;p&gt;These are prevalent technologies but not part of this study plan:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Javascript&lt;/li&gt; 
 &lt;li&gt;HTML, CSS, and other front-end technologies&lt;/li&gt; 
 &lt;li&gt;SQL&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;The Daily Plan&lt;/h2&gt; 
&lt;p&gt;This course goes over a lot of subjects. Each will probably take you a few days, or maybe even a week or more. It depends on your schedule.&lt;/p&gt; 
&lt;p&gt;Each day, take the next subject in the list, watch some videos about that subject, and then write an implementation of that data structure or algorithm in the language you chose for this course.&lt;/p&gt; 
&lt;p&gt;You can see my code here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jwasham/practice-c"&gt;C&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jwasham/practice-cpp"&gt;C++&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jwasham/practice-python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You don't need to memorize every algorithm. You just need to be able to understand it enough to be able to write your own implementation.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Coding Question Practice&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Why is this here? I'm not ready to interview.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#3-do-coding-interview-questions-while-youre-learning"&gt;Then go back and read this.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Why you need to practice doing programming problems:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Problem recognition, and where the right data structures and algorithms fit in&lt;/li&gt; 
 &lt;li&gt;Gathering requirements for the problem&lt;/li&gt; 
 &lt;li&gt;Talking your way through the problem like you will in the interview&lt;/li&gt; 
 &lt;li&gt;Coding on a whiteboard or paper, not a computer&lt;/li&gt; 
 &lt;li&gt;Coming up with time and space complexity for your solutions (see Big-O below)&lt;/li&gt; 
 &lt;li&gt;Testing your solutions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There is a great intro for methodical, communicative problem-solving in an interview. You'll get this from the programming interview books, too, but I found this outstanding: &lt;a href="http://www.hiredintech.com/algorithm-design/"&gt;Algorithm design canvas&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Write code on a whiteboard or paper, not a computer. Test with some sample inputs. Then type it and test it out on a computer.&lt;/p&gt; 
&lt;p&gt;If you don't have a whiteboard at home, pick up a large drawing pad from an art store. You can sit on the couch and practice. This is my "sofa whiteboard". I added the pen in the photo just for scale. If you use a pen, you'll wish you could erase. Gets messy quickly. &lt;strong&gt;I use a pencil and eraser.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://d3j2pkmjtin6ou.cloudfront.net/art_board_sm_2.jpg" alt="my sofa whiteboard" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Coding question practice is not about memorizing answers to programming problems.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Coding Problems&lt;/h2&gt; 
&lt;p&gt;Don't forget your key coding interview books &lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#interview-prep-books"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Solving Problems:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.topcoder.com/thrive/articles/How%20To%20Find%20a%20Solution"&gt;How to Find a Solution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.topcoder.com/thrive/articles/How%20To%20Dissect%20a%20Topcoder%20Problem%20Statement%20Content"&gt;How to Dissect a Topcoder Problem Statement&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Coding Interview Question Videos:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLamzFoFxwoNjPfxzaWqs7cZGsPYy0x_gI"&gt;IDeserve (88 videos)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/user/tusharroy2525/playlists?shelf_id=2&amp;amp;view=50&amp;amp;sort=dd"&gt;Tushar Roy (5 playlists)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Super for walkthroughs of problem solutions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLU_sdQYzUj2keVENTP0a5rdykRSgg9Wp-"&gt;Nick White - LeetCode Solutions (187 Videos)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Good explanations of the solution and the code&lt;/li&gt; 
   &lt;li&gt;You can watch several in a short time&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtube.com/FisherCoder"&gt;FisherCoder - LeetCode Solutions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Challenge/Practice sites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://leetcode.com/"&gt;LeetCode&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;My favorite coding problem site. It's worth the subscription money for the 1-2 months you'll likely be preparing.&lt;/li&gt; 
   &lt;li&gt;See Nick White and FisherCoder Videos above for code walk-throughs.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.hackerrank.com/"&gt;HackerRank&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.topcoder.com/"&gt;TopCoder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codeforces.com/"&gt;Codeforces&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codility.com/programmers/"&gt;Codility&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://practice.geeksforgeeks.org/explore/?page=1"&gt;Geeks for Geeks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.algoexpert.io/product"&gt;AlgoExpert&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Created by Google engineers, this is also an excellent resource to hone your skills.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://projecteuler.net/"&gt;Project Euler&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;very math-focused, and not really suited for coding interviews&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Let's Get Started&lt;/h2&gt; 
&lt;p&gt;Alright, enough talk, let's learn!&lt;/p&gt; 
&lt;p&gt;But don't forget to do coding problems from above while you learn!&lt;/p&gt; 
&lt;h2&gt;Algorithmic complexity / Big-O / Asymptotic analysis&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nothing to implement here, you're just watching videos and taking notes! Yay!&lt;/li&gt; 
 &lt;li&gt;There are a lot of videos here. Just watch enough until you understand it. You can always come back and review.&lt;/li&gt; 
 &lt;li&gt;Don't worry if you don't understand all the math behind it.&lt;/li&gt; 
 &lt;li&gt;You just need to understand how to express the complexity of an algorithm in terms of Big-O.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=iOq5kSKqeR4"&gt;Harvard CS50 - Asymptotic Notation (video)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=V6mKVRU1evU"&gt;Big O Notations (general quick tutorial) (video)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=ei-A_wy5Yxw&amp;amp;index=2&amp;amp;list=PL1BaGV1cIH4UhkL8a9bJGG356covJ76qN"&gt;Big O Notation (and Omega and Theta) - best mathematical explanation (video)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=z1mkCe3kVUA"&gt;Skiena (video)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://archive.org/details/ucberkeley_webcast_VIS4YDpuP98"&gt;UC Berkeley Big O (video)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=B3SpQZaAZP4&amp;amp;index=10&amp;amp;list=PL1BaGV1cIH4UhkL8a9bJGG356covJ76qN"&gt;Amortized Analysis (video)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; TopCoder (includes recurrence relations and master theorem): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.topcoder.com/thrive/articles/Computational%20Complexity%20part%20one"&gt;Computational Complexity: Section 1&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.topcoder.com/thrive/articles/Computational%20Complexity%20part%20two"&gt;Computational Complexity: Section 2&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://bigocheatsheet.com/"&gt;Cheat sheet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/playlist?list=PL9xmBV_5YoZMxejjIyFHWa-4nKg6sdoIv"&gt;[Review] Analyzing Algorithms (playlist) in 18 minutes (video)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Well, that's about enough of that.&lt;/p&gt; 
&lt;p&gt;When you go through "Cracking the Coding Interview", there is a chapter on this, and at the end there is a quiz to see if you can identify the runtime complexity of different algorithms. It's a super review and test.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Data Structures&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;h3&gt;Arrays&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; About Arrays: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=tI_tIZFyKBw&amp;amp;t=3009s"&gt;Arrays CS50 Harvard University&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/lecture/data-structures/arrays-OsBSF"&gt;Arrays (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://archive.org/details/ucberkeley_webcast_Wp8oiO_CZZE"&gt;UC Berkeley CS61B - Linear and Multi-Dim Arrays (video)&lt;/a&gt; (Start watching from 15m 32s)&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/lecture/data-structures/dynamic-arrays-EwbnV"&gt;Dynamic Arrays (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1jtrQqYpt7g"&gt;Jagged Arrays (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Implement a vector (mutable array with automatic resizing): 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Practice coding using arrays and pointers, and pointer math to jump to an index instead of using indexing.&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; New raw data array with allocated memory 
      &lt;ul&gt; 
       &lt;li&gt;can allocate int array under the hood, just not use its features&lt;/li&gt; 
       &lt;li&gt;start with 16, or if the starting number is greater, use power of 2 - 16, 32, 64, 128&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; size() - number of items&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; capacity() - number of items it can hold&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; is_empty()&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; at(index) - returns the item at a given index, blows up if index out of bounds&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; push(item)&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; insert(index, item) - inserts item at index, shifts that index's value and trailing elements to the right&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; prepend(item) - can use insert above at index 0&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; pop() - remove from end, return value&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; delete(index) - delete item at index, shifting all trailing elements left&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; remove(item) - looks for value and removes index holding it (even if in multiple places)&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; find(item) - looks for value and returns first index with that value, -1 if not found&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; resize(new_capacity) // private function 
      &lt;ul&gt; 
       &lt;li&gt;when you reach capacity, resize to double the size&lt;/li&gt; 
       &lt;li&gt;when popping an item, if the size is 1/4 of capacity, resize to half&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Time 
    &lt;ul&gt; 
     &lt;li&gt;O(1) to add/remove at end (amortized for allocations for more space), index, or update&lt;/li&gt; 
     &lt;li&gt;O(n) to insert/remove elsewhere&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Space 
    &lt;ul&gt; 
     &lt;li&gt;contiguous in memory, so proximity helps performance&lt;/li&gt; 
     &lt;li&gt;space needed = (array capacity, which is &amp;gt;= n) * size of item, but even if 2n, still O(n)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Linked Lists&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Description: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=2T-A_GFuoTo&amp;amp;t=650s"&gt;Linked Lists CS50 Harvard University&lt;/a&gt; - this builds the intuition.&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/data-structures/singly-linked-lists-kHhgK"&gt;Singly Linked Lists (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://archive.org/details/ucberkeley_webcast_htzJdKoEmO0"&gt;CS 61B - Linked Lists 1 (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://archive.org/details/ucberkeley_webcast_-c4I3gFYe3w"&gt;CS 61B - Linked Lists 2 (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/F8AbOfQwl1c"&gt;[Review] Linked lists in 4 minutes (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=QN6FPiD0Gzo"&gt;C Code (video)&lt;/a&gt; - not the whole video, just portions about Node struct and memory allocation&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Linked List vs Arrays: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/lecture/data-structures-optimizing-performance/core-linked-lists-vs-arrays-rjBs9"&gt;Core Linked Lists Vs Arrays (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/lecture/data-structures-optimizing-performance/in-the-real-world-lists-vs-arrays-QUaUd"&gt;In The Real World Linked Lists Vs Arrays (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=YQs6IC-vgmo"&gt;Why you should avoid linked lists (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Gotcha: you need pointer to pointer knowledge: (for when you pass a pointer to a function that may change the address where that pointer points) This page is just to get a grasp on ptr to ptr. I don't recommend this list traversal style. Readability and maintainability suffer due to cleverness. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.eskimo.com/~scs/cclass/int/sx8.html"&gt;Pointers to Pointers&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Implement (I did with tail pointer &amp;amp; without): 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; size() - returns the number of data elements in the list&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; empty() - bool returns true if empty&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; value_at(index) - returns the value of the nth item (starting at 0 for first)&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; push_front(value) - adds an item to the front of the list&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; pop_front() - remove the front item and return its value&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; push_back(value) - adds an item at the end&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; pop_back() - removes end item and returns its value&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; front() - get the value of the front item&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; back() - get the value of the end item&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; insert(index, value) - insert value at index, so the current item at that index is pointed to by the new item at the index&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; erase(index) - removes node at given index&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; value_n_from_end(n) - returns the value of the node at the nth position from the end of the list&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; reverse() - reverses the list&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; remove_value(value) - removes the first item in the list with this value&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Doubly-linked List 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/lecture/data-structures/doubly-linked-lists-jpGKD"&gt;Description (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;No need to implement&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Stack&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/data-structures/stacks-UdKzQ"&gt;Stacks (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/KcT3aVgrrpU"&gt;[Review] Stacks in 3 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Will not implement. Implementing with the array is trivial&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Queue&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/data-structures/queues-EShpq"&gt;Queue (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://en.wikipedia.org/wiki/Circular_buffer"&gt;Circular buffer/FIFO&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/D6gu-_tmEpQ"&gt;[Review] Queues in 3 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Implement using linked-list, with tail pointer: 
    &lt;ul&gt; 
     &lt;li&gt;enqueue(value) - adds value at a position at the tail&lt;/li&gt; 
     &lt;li&gt;dequeue() - returns value and removes least recently added element (front)&lt;/li&gt; 
     &lt;li&gt;empty()&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Implement using a fixed-sized array: 
    &lt;ul&gt; 
     &lt;li&gt;enqueue(value) - adds item at end of available storage&lt;/li&gt; 
     &lt;li&gt;dequeue() - returns value and removes least recently added element&lt;/li&gt; 
     &lt;li&gt;empty()&lt;/li&gt; 
     &lt;li&gt;full()&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Cost: 
    &lt;ul&gt; 
     &lt;li&gt;a bad implementation using a linked list where you enqueue at the head and dequeue at the tail would be O(n) because you'd need the next to last element, causing a full traversal of each dequeue&lt;/li&gt; 
     &lt;li&gt;enqueue: O(1) (amortized, linked list and array [probing])&lt;/li&gt; 
     &lt;li&gt;dequeue: O(1) (linked list and array)&lt;/li&gt; 
     &lt;li&gt;empty: O(1) (linked list and array)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Hash table&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;Videos:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=0M_kIqhwbFo&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb&amp;amp;index=8"&gt;Hashing with Chaining (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=BRO7mVIFt08&amp;amp;index=9&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb"&gt;Table Doubling, Karp-Rabin (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=rvdJDijO2Ro&amp;amp;index=10&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb"&gt;Open Addressing, Cryptographic Hashing (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=C4Kc8xzcA68"&gt;PyCon 2010: The Mighty Dictionary (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=66P5FMkWoVU"&gt;PyCon 2017: The Dictionary Even Mightier (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=z0lJ2k0sl1g&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&amp;amp;index=11"&gt;(Advanced) Randomization: Universal &amp;amp; Perfect Hashing (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=N0COwN14gt0&amp;amp;list=PL2B4EEwhKD-NbwZ4ezj7gyc_3yNrojKM9&amp;amp;index=4"&gt;(Advanced) Perfect hashing (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/knV86FlSXJ8"&gt;[Review] Hash tables in 4 minutes (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;Online Courses:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/data-structures-optimizing-performance/core-hash-tables-m7UuP"&gt;Core Hash Tables (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/data-structures/home/week/4"&gt;Data Structures (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/data-structures/phone-book-problem-NYZZP"&gt;Phone Book Problem (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; distributed hash tables: 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://www.coursera.org/lecture/data-structures/instant-uploads-and-storage-optimization-in-dropbox-DvaIb"&gt;Instant Uploads And Storage Optimization In Dropbox (video)&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://www.coursera.org/lecture/data-structures/distributed-hash-tables-tvH8H"&gt;Distributed Hash Tables (video)&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;Implement with array using linear probing&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;hash(k, m) - m is the size of the hash table&lt;/li&gt; 
     &lt;li&gt;add(key, value) - if the key already exists, update value&lt;/li&gt; 
     &lt;li&gt;exists(key)&lt;/li&gt; 
     &lt;li&gt;get(key)&lt;/li&gt; 
     &lt;li&gt;remove(key)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;More Knowledge&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;h3&gt;Binary search&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=D5SrAga1pno"&gt;Binary Search (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.khanacademy.org/computing/computer-science/algorithms/binary-search/a/binary-search"&gt;Binary Search (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.topcoder.com/thrive/articles/Binary%20Search"&gt;detail&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://leetcode.com/discuss/general-discussion/786126/python-powerful-ultimate-binary-search-template-solved-many-problems"&gt;blueprint&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/fDKIpRe8GW4"&gt;[Review] Binary search in 4 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Implement: 
    &lt;ul&gt; 
     &lt;li&gt;binary search (on a sorted array of integers)&lt;/li&gt; 
     &lt;li&gt;binary search using recursion&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Bitwise operations&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://github.com/jwasham/coding-interview-university/raw/main/extras/cheat%20sheets/bits-cheat-sheet.pdf"&gt;Bits cheat sheet&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;you should know many of the powers of 2 from (2^1 to 2^16 and 2^32)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Get a really good understanding of manipulating bits with: &amp;amp;, |, ^, ~, &amp;gt;&amp;gt;, &amp;lt;&amp;lt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://en.wikipedia.org/wiki/Word_(computer_architecture)"&gt;words&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Good intro: &lt;a href="https://www.youtube.com/watch?v=7jkIUgLC29I"&gt;Bit Manipulation (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=d0AwjSpNXR0"&gt;C Programming Tutorial 2-10: Bitwise Operators (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://en.wikipedia.org/wiki/Bit_manipulation"&gt;Bit Manipulation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://en.wikipedia.org/wiki/Bitwise_operation"&gt;Bitwise Operation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://graphics.stanford.edu/~seander/bithacks.html"&gt;Bithacks&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://bits.stephan-brumme.com/"&gt;The Bit Twiddler&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://bits.stephan-brumme.com/interactive.html"&gt;The Bit Twiddler Interactive&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=ZusiKXcz_ac"&gt;Bit Hacks (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://pconrad.github.io/old_pconrad_cs16/topics/bitOps/"&gt;Practice Operations&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 2s and 1s complement 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=lKTsv6iVxV4"&gt;Binary: Plusses &amp;amp; Minuses (Why We Use Two's Complement) (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Ones%27_complement"&gt;1s Complement&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Two%27s_complement"&gt;2s Complement&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Count set bits 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://youtu.be/Hzuzo9NJrlc"&gt;4 ways to count bits in a byte (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetKernighan"&gt;Count Bits&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer"&gt;How To Count The Number Of Set Bits In a 32 Bit Integer&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Swap values: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://bits.stephan-brumme.com/swap.html"&gt;Swap&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Absolute value: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://bits.stephan-brumme.com/absInteger.html"&gt;Absolute Integer&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Trees&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;h3&gt;Trees - Intro&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/data-structures/trees-95qda"&gt;Intro to Trees (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/data-structures/tree-traversal-fr51b"&gt;Tree Traversal (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=uWL6FJhq5fM"&gt;BFS(breadth-first search) and DFS(depth-first search) (video)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;BFS notes: 
      &lt;ul&gt; 
       &lt;li&gt;level order (BFS, using queue)&lt;/li&gt; 
       &lt;li&gt;time complexity: O(n)&lt;/li&gt; 
       &lt;li&gt;space complexity: best: O(1), worst: O(n/2)=O(n)&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;DFS notes: 
      &lt;ul&gt; 
       &lt;li&gt;time complexity: O(n)&lt;/li&gt; 
       &lt;li&gt;space complexity: best: O(log n) - avg. height of tree worst: O(n)&lt;/li&gt; 
       &lt;li&gt;inorder (DFS: left, self, right)&lt;/li&gt; 
       &lt;li&gt;postorder (DFS: left, right, self)&lt;/li&gt; 
       &lt;li&gt;preorder (DFS: self, left, right)&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/HZ5YTanv5QE"&gt;[Review] Breadth-first search in 4 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/Urx87-NMm6c"&gt;[Review] Depth-first search in 4 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/playlist?list=PL9xmBV_5YoZO1JC2RgEi04nLy6D-rKk6b"&gt;[Review] Tree Traversal (playlist) in 11 minutes (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Binary search trees: BSTs&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=x6At0nzX92o&amp;amp;index=1&amp;amp;list=PLA5Lqm4uh9Bbq-E0ZnqTIa8LRaL77ica6"&gt;Binary Search Tree Review (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/data-structures/lecture/E7cXP/introduction"&gt;Introduction (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=76dhtgZt38A&amp;amp;ab_channel=MITOpenCourseWare"&gt;MIT (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;C/C++: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=COZK7NATh4k&amp;amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&amp;amp;index=28"&gt;Binary search tree - Implementation in C/C++ (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=hWokyBoo0aI&amp;amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&amp;amp;index=29"&gt;BST implementation - memory allocation in stack and heap (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=Ut90klNN264&amp;amp;index=30&amp;amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P"&gt;Find min and max element in a binary search tree (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=_pnqMz5nrRs&amp;amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&amp;amp;index=31"&gt;Find the height of a binary tree (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=9RHO6jU--GU&amp;amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&amp;amp;index=32"&gt;Binary tree traversal - breadth-first and depth-first strategies (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=86g8jAQug04&amp;amp;index=33&amp;amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P"&gt;Binary tree: Level Order Traversal (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=gm8DUJJhmY4&amp;amp;index=34&amp;amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P"&gt;Binary tree traversal: Preorder, Inorder, Postorder (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=yEwSGhSsT0U&amp;amp;index=35&amp;amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P"&gt;Check if a binary tree is a binary search tree or not (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=gcULXE7ViZw&amp;amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&amp;amp;index=36"&gt;Delete a node from Binary Search Tree (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=5cPbNCrdotA&amp;amp;index=37&amp;amp;list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P"&gt;Inorder Successor in a binary search tree (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Implement: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://leetcode.com/problems/insert-into-a-binary-search-tree/submissions/987660183/"&gt;insert // insert value into tree&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; get_node_count // get count of values stored&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; print_values // prints the values in the tree, from min to max&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; delete_tree&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; is_in_tree // returns true if a given value exists in the tree&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.geeksforgeeks.org/find-the-maximum-depth-or-height-of-a-tree/"&gt;get_height // returns the height in nodes (single node's height is 1)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; get_min // returns the minimum value stored in the tree&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; get_max // returns the maximum value stored in the tree&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://leetcode.com/problems/validate-binary-search-tree/"&gt;is_binary_search_tree&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; delete_value&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; get_successor // returns the next-highest value in the tree after given value, -1 if none&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Heap / Priority Queue / Binary Heap&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;visualized as a tree, but is usually linear in storage (array, linked list)&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://en.wikipedia.org/wiki/Heap_(data_structure)"&gt;Heap&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/data-structures/introduction-2OpTs"&gt;Introduction (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/data-structures/lecture/GRV2q/binary-trees"&gt;Binary Trees (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/data-structures/supplement/S5xxz/tree-height-remark"&gt;Tree Height Remark (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/data-structures/lecture/0g1dl/basic-operations"&gt;Basic Operations (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/data-structures/lecture/gl5Ni/complete-binary-trees"&gt;Complete Binary Trees (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/data-structures/lecture/HxQo9/pseudocode"&gt;Pseudocode (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/odNJmw5TOEE?list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;t=3291"&gt;Heap Sort - jumps to start (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/data-structures/heap-sort-hSzMO"&gt;Heap Sort (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/data-structures/building-a-heap-dwrOS"&gt;Building a heap (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=Xnpo1atN-Iw&amp;amp;list=PLUl4u3cNGP63EdVPNLG3ToM6LaEUuStEY&amp;amp;index=12"&gt;MIT 6.006 Introduction to Algorithms: Binary Heaps&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://archive.org/details/ucberkeley_webcast_yIUFT6AKBGE"&gt;CS 61B Lecture 24: Priority Queues (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=MiyLo8adrWw"&gt;Linear Time BuildHeap (max-heap)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/playlist?list=PL9xmBV_5YoZNsyqgPW-DNwUeT8F8uhWc6"&gt;[Review] Heap (playlist) in 13 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Implement a max-heap: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; insert&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; sift_up - needed for insert&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; get_max - returns the max item, without removing it&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; get_size() - return number of elements stored&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; is_empty() - returns true if the heap contains no elements&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; extract_max - returns the max item, removing it&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; sift_down - needed for extract_max&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; remove(x) - removes item at index x&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; heapify - create a heap from an array of elements, needed for heap_sort&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; heap_sort() - take an unsorted array and turn it into a sorted array in place using a max heap or min heap&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Sorting&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;Notes:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Implement sorts &amp;amp; know best case/worst case, average complexity of each: 
    &lt;ul&gt; 
     &lt;li&gt;no bubble sort - it's terrible - O(n^2), except when n &amp;lt;= 16&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Stability in sorting algorithms ("Is Quicksort stable?") 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Sorting_algorithm#Stability"&gt;Sorting Algorithm Stability&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1517793/stability-in-sorting-algorithms"&gt;Stability In Sorting Algorithms&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://www.geeksforgeeks.org/stability-in-sorting-algorithms/"&gt;Stability In Sorting Algorithms&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://homepages.math.uic.edu/~leon/cs-mcs401-s08/handouts/stability.pdf"&gt;Sorting Algorithms - Stability&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Which algorithms can be used on linked lists? Which on arrays? Which of both? 
    &lt;ul&gt; 
     &lt;li&gt;I wouldn't recommend sorting a linked list, but merge sort is doable.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://www.geeksforgeeks.org/merge-sort-for-linked-list/"&gt;Merge Sort For Linked List&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For heapsort, see the Heap data structure above. Heap sort is great, but not stable&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;&lt;a href="https://www.coursera.org/learn/algorithms-part1/home/week/3"&gt;Sedgewick - Mergesort (5 videos)&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithms-part1/mergesort-ARWDq"&gt;1. Mergesort&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part1/lecture/PWNEl/bottom-up-mergesort"&gt;2. Bottom-up Mergesort&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithms-part1/sorting-complexity-xAltF"&gt;3. Sorting Complexity&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithms-part1/comparators-9FYhS"&gt;4. Comparators&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part1/lecture/pvvLZ/stability"&gt;5. Stability&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;&lt;a href="https://www.coursera.org/learn/algorithms-part1/home/week/3"&gt;Sedgewick - Quicksort (4 videos)&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithms-part1/quicksort-vjvnC"&gt;1. Quicksort&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithms-part1/selection-UQxFT"&gt;2. Selection&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithms-part1/duplicate-keys-XvjPd"&gt;3. Duplicate Keys&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithms-part1/system-sorts-QBNZ7"&gt;4. System Sorts&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;UC Berkeley:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://archive.org/details/ucberkeley_webcast_EiUvYS2DT6I"&gt;CS 61B Lecture 29: Sorting I (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://archive.org/details/ucberkeley_webcast_2hTY3t80Qsk"&gt;CS 61B Lecture 30: Sorting II (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://archive.org/details/ucberkeley_webcast_Y6LOLpxg6Dc"&gt;CS 61B Lecture 32: Sorting III (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://archive.org/details/ucberkeley_webcast_qNMQ4ly43p4"&gt;CS 61B Lecture 33: Sorting V (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://archive.org/details/ucberkeley_webcast_pvbBMd-3NoI"&gt;CS 61B 2014-04-21: Radix Sort(video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=P00xJgWzz2c&amp;amp;index=1&amp;amp;list=PL89B61F78B552C1AB"&gt;Bubble Sort (video)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=ni_zk257Nqo&amp;amp;index=7&amp;amp;list=PL89B61F78B552C1AB"&gt;Analyzing Bubble Sort (video)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Kg4bqzAqRBM&amp;amp;index=3&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb"&gt;Insertion Sort, Merge Sort (video)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=c4BRHC7kTaQ&amp;amp;index=2&amp;amp;list=PL89B61F78B552C1AB"&gt;Insertion Sort (video)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=GCae1WNvnZM&amp;amp;index=3&amp;amp;list=PL89B61F78B552C1AB"&gt;Merge Sort (video)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=y_G9BkAm6B8&amp;amp;index=4&amp;amp;list=PL89B61F78B552C1AB"&gt;Quicksort (video)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=6nDMgr0-Yyo&amp;amp;index=8&amp;amp;list=PL89B61F78B552C1AB"&gt;Selection Sort (video)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;Merge sort code:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://www.cs.yale.edu/homes/aspnes/classes/223/examples/sorting/mergesort.c"&gt;Using output array (C)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://github.com/jwasham/practice-python/raw/master/merge_sort/merge_sort.py"&gt;Using output array (Python)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://github.com/jwasham/practice-cpp/raw/master/merge_sort/merge_sort.cc"&gt;In-place (C++)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;Quick sort code:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://www.cs.yale.edu/homes/aspnes/classes/223/examples/randomization/quick.c"&gt;Implementation (C)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://github.com/jwasham/practice-c/raw/master/quick_sort/quick_sort.c"&gt;Implementation (C)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://github.com/jwasham/practice-python/raw/master/quick_sort/quick_sort.py"&gt;Implementation (Python)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PL9xmBV_5YoZOZSbGAXAPIq1BeUf4j20pl"&gt;[Review] Sorting (playlist) in 18 minutes&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/Hoixgm4-P4M"&gt;Quick sort in 4 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/2DmK_H7IdTo"&gt;Heap sort in 4 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/4VqmGXwpLqc"&gt;Merge sort in 3 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/xli_FI7CuzA"&gt;Bubble sort in 2 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/g-PGLbMth_g"&gt;Selection sort in 3 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/JU767SDMDvA"&gt;Insertion sort in 2 minutes (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;Implement:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Mergesort: O(n log n) average and worst case&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Quicksort O(n log n) average case&lt;/li&gt; 
   &lt;li&gt;Selection sort and insertion sort are both O(n^2) average and worst-case&lt;/li&gt; 
   &lt;li&gt;For heapsort, see Heap data structure above&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;Not required, but I recommended them:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/home/week/3"&gt;Sedgewick - Radix Sorts (6 videos)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/lecture/vGHvb/strings-in-java"&gt;1. Strings in Java&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithms-part2/key-indexed-counting-2pi1Z"&gt;2. Key Indexed Counting&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/lecture/c1U7L/lsd-radix-sort"&gt;3. Least Significant Digit First String Radix Sort&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/lecture/gFxwG/msd-radix-sort"&gt;4. Most Significant Digit First String Radix Sort&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithms-part2/3-way-radix-quicksort-crkd5"&gt;5. 3 Way Radix Quicksort&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/lecture/TH18W/suffix-arrays"&gt;6. Suffix Arrays&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://www.cs.yale.edu/homes/aspnes/classes/223/notes.html#radixSort"&gt;Radix Sort&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=xhr26ia4k38"&gt;Radix Sort (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=Nz1KZXbghj8&amp;amp;index=7&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb"&gt;Radix Sort, Counting Sort (linear time given constraints) (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=cNB2lADK3_s&amp;amp;index=8&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp"&gt;Randomization: Matrix Multiply, Quicksort, Freivalds' algorithm (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=pOKy3RZbSws&amp;amp;list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&amp;amp;index=14"&gt;Sorting in Linear Time (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As a summary, here is a visual representation of &lt;a href="https://www.youtube.com/watch?v=kPRA0W1kECg"&gt;15 sorting algorithms&lt;/a&gt;. If you need more detail on this subject, see the "Sorting" section in &lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#additional-detail-on-some-subjects"&gt;Additional Detail on Some Subjects&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Graphs&lt;/h2&gt; 
&lt;p&gt;Graphs can be used to represent many problems in computer science, so this section is long, like trees and sorting.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Notes:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;There are 4 basic ways to represent a graph in memory: 
    &lt;ul&gt; 
     &lt;li&gt;objects and pointers&lt;/li&gt; 
     &lt;li&gt;adjacency matrix&lt;/li&gt; 
     &lt;li&gt;adjacency list&lt;/li&gt; 
     &lt;li&gt;adjacency map&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Familiarize yourself with each representation and its pros &amp;amp; cons&lt;/li&gt; 
   &lt;li&gt;BFS and DFS - know their computational complexity, their trade-offs, and how to implement them in real code&lt;/li&gt; 
   &lt;li&gt;When asked a question, look for a graph-based solution first, then move on if none&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;MIT(videos):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=oFVYVzlvk9c&amp;amp;t=14s&amp;amp;ab_channel=MITOpenCourseWare"&gt;Breadth-First Search&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=IBfWDYSffUU&amp;amp;t=32s&amp;amp;ab_channel=MITOpenCourseWare"&gt;Depth-First Search&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;Skiena Lectures - great intro:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=Sjk0xqWWPCc&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=10"&gt;CSE373 2020 - Lecture 10 - Graph Data Structures (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=ZTwjXj81NVY&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=11"&gt;CSE373 2020 - Lecture 11 - Graph Traversal (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=KyordYB3BOs&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=12"&gt;CSE373 2020 - Lecture 12 - Depth First Search (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=oolm2VnJUKw&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=13"&gt;CSE373 2020 - Lecture 13 - Minimum Spanning Trees (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=RktgPx0MarY&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=14"&gt;CSE373 2020 - Lecture 14 - Minimum Spanning Trees (con't) (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=MUe5DXRhyAo&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=15"&gt;CSE373 2020 - Lecture 15 - Graph Algorithms (con't 2) (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;p&gt;Graphs (review and more):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=Aa2sqUhIn-E&amp;amp;index=15&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb"&gt;6.006 Single-Source Shortest Paths Problem (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=NSHizBK9JD8&amp;amp;t=1731s&amp;amp;ab_channel=MITOpenCourseWare"&gt;6.006 Dijkstra (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=f9cVS_URPc0&amp;amp;ab_channel=MITOpenCourseWare"&gt;6.006 Bellman-Ford (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=CHvQ3q_gJ7E&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb&amp;amp;index=18"&gt;6.006 Speeding Up Dijkstra (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=i_AQT_XfvD8&amp;amp;index=6&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm"&gt;Aduni: Graph Algorithms I - Topological Sorting, Minimum Spanning Trees, Prim's Algorithm - Lecture 6 (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=ufj5_bppBsA&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;index=7"&gt;Aduni: Graph Algorithms II - DFS, BFS, Kruskal's Algorithm, Union Find Data Structure - Lecture 7 (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=DiedsPsMKXc&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;index=8"&gt;Aduni: Graph Algorithms III: Shortest Path - Lecture 8 (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=XIAQRlNkJAw&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;index=9"&gt;Aduni: Graph Alg. IV: Intro to geometric algorithms - Lecture 9 (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://archive.org/details/ucberkeley_webcast_zFbq8vOZ_0k"&gt;CS 61B 2014: Weighted graphs (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=tKwnms5iRBU&amp;amp;index=16&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp"&gt;Greedy Algorithms: Minimum Spanning Tree (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=RpgcYiky7uw"&gt;Strongly Connected Components Kosaraju's Algorithm Graph Algorithm (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/playlist?list=PL9xmBV_5YoZO-Y-H3xIC9DGSfVYJng9Yw"&gt;[Review] Shortest Path Algorithms (playlist) in 16 minutes (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/playlist?list=PL9xmBV_5YoZObEi3Hf6lmyW-CBfs7nkOV"&gt;[Review] Minimum Spanning Trees (playlist) in 4 minutes (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Full Coursera Course:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-on-graphs/home/welcome"&gt;Algorithms on Graphs (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;I'll implement:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; DFS with adjacency list (recursive)&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; DFS with adjacency list (iterative with stack)&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; DFS with adjacency matrix (recursive)&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; DFS with adjacency matrix (iterative with stack)&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; BFS with adjacency list&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; BFS with adjacency matrix&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; single-source shortest path (Dijkstra)&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; minimum spanning tree&lt;/li&gt; 
   &lt;li&gt;DFS-based algorithms (see Aduni videos above): 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; check for a cycle (needed for topological sort, since we'll check for the cycle before starting)&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; topological sort&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; count connected components in a graph&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; list strongly connected components&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; check for bipartite graph&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Even More Knowledge&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;h3&gt;Recursion&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Stanford lectures on recursion &amp;amp; backtracking: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=gl3emqCuueQ&amp;amp;list=PLFE6E58F856038C69&amp;amp;index=8"&gt;Lecture 8 | Programming Abstractions (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=uFJhEPrbycQ&amp;amp;list=PLFE6E58F856038C69&amp;amp;index=9"&gt;Lecture 9 | Programming Abstractions (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=NdF1QDTRkck&amp;amp;index=10&amp;amp;list=PLFE6E58F856038C69"&gt;Lecture 10 | Programming Abstractions (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=p-gpaIGRCQI&amp;amp;list=PLFE6E58F856038C69&amp;amp;index=11"&gt;Lecture 11 | Programming Abstractions (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;When it is appropriate to use it?&lt;/li&gt; 
   &lt;li&gt;How is tail recursion better than not? 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.quora.com/What-is-tail-recursion-Why-is-it-so-bad"&gt;What Is Tail Recursion Why Is It So Bad?&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/programming-languages/tail-recursion-YZic1"&gt;Tail Recursion (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/ngCos392W4w"&gt;5 Simple Steps for Solving Any Recursive Problem(video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Backtracking Blueprint: &lt;a href="https://leetcode.com/problems/combination-sum/discuss/16502/A-general-approach-to-backtracking-questions-in-Java-(Subsets-Permutations-Combination-Sum-Palindrome-Partitioning)"&gt;Java&lt;/a&gt; &lt;a href="https://leetcode.com/problems/combination-sum/discuss/429538/General-Backtracking-questions-solutions-in-Python-for-reference-%3A"&gt;Python&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Dynamic Programming&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;You probably won't see any dynamic programming problems in your interview, but it's worth being able to recognize a problem as being a candidate for dynamic programming.&lt;/li&gt; 
   &lt;li&gt;This subject can be pretty difficult, as each DP soluble problem must be defined as a recursion relation, and coming up with it can be tricky.&lt;/li&gt; 
   &lt;li&gt;I suggest looking at many examples of DP problems until you have a solid understanding of the pattern involved.&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Videos: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=wAA0AMfcJHQ&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=18"&gt;Skiena: CSE373 2020 - Lecture 19 - Introduction to Dynamic Programming (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=T3A4jlHlhtA&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=19"&gt;Skiena: CSE373 2020 - Lecture 20 - Edit Distance (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=iPnPVcZmRbE&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=20"&gt;Skiena: CSE373 2020 - Lecture 20 - Edit Distance (continued) (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=2xPE4Wq8coQ&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=21"&gt;Skiena: CSE373 2020 - Lecture 21 - Dynamic Programming (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=Yh3RzqQGsyI&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=22"&gt;Skiena: CSE373 2020 - Lecture 22 - Dynamic Programming and Review (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/J5aJEcOr6Eo?list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;t=3558"&gt;Simonson: Dynamic Programming 0 (starts at 59:18) (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=0EzHjQ_SOeU&amp;amp;index=11&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm"&gt;Simonson: Dynamic Programming I - Lecture 11 (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=v1qiRwuJU7g&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;index=12"&gt;Simonson: Dynamic programming II - Lecture 12 (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; List of individual DP problems (each is short): &lt;a href="https://www.youtube.com/playlist?list=PLrmLmBdmIlpsHaNTPP_jHHDx_os9ItYXr"&gt;Dynamic Programming (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Yale Lecture notes: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://www.cs.yale.edu/homes/aspnes/classes/223/notes.html#dynamicProgramming"&gt;Dynamic Programming&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Coursera: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithmic-thinking-2/lecture/80RrW/the-rna-secondary-structure-problem"&gt;The RNA secondary structure problem (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithmic-thinking-2/a-dynamic-programming-algorithm-PSonq"&gt;A dynamic programming algorithm (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithmic-thinking-2/illustrating-the-dp-algorithm-oUEK2"&gt;Illustrating the DP algorithm (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithmic-thinking-2/lecture/nfK2r/running-time-of-the-dp-algorithm"&gt;Running time of the DP algorithm (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithmic-thinking-2/lecture/M999a/dp-vs-recursive-implementation"&gt;DP vs. recursive implementation (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithmic-thinking-2/global-pairwise-sequence-alignment-UZ7o6"&gt;Global pairwise sequence alignment (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithmic-thinking-2/lecture/WnNau/local-pairwise-sequence-alignment"&gt;Local pairwise sequence alignment (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Design patterns&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=3cmzqZzwNDM&amp;amp;list=PLGLfVvz_LVvQ5G-LdJ8RLqe-ndo7QITYc&amp;amp;index=3"&gt;Quick UML review (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Learn these patterns: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; strategy&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; singleton&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; adapter&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; prototype&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; decorator&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; visitor&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; factory, abstract factory&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; facade&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; observer&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; proxy&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; delegate&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; command&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; state&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; memento&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; iterator&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; composite&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; flyweight&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/playlist?list=PLF206E906175C7E07"&gt;Series of videos (27 videos)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.amazon.com/Head-First-Design-Patterns-Freeman/dp/0596007124"&gt;Book: Head First Design Patterns&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;I know the canonical book is "Design Patterns: Elements of Reusable Object-Oriented Software", but Head First is great for beginners to OO.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://sourcemaking.com/design-patterns-and-tips"&gt;Handy reference: 101 Design Patterns &amp;amp; Tips for Developers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Combinatorics (n choose k) &amp;amp; Probability&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=8RRo6Ti9d0U"&gt;Math Skills: How to find Factorial, Permutation, and Combination (Choose) (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=sZkAAk9Wwa4"&gt;Make School: Probability (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=dNaJg-mLobQ"&gt;Make School: More Probability and Markov Chains (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Khan Academy: 
    &lt;ul&gt; 
     &lt;li&gt;Course layout: 
      &lt;ul&gt; 
       &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.khanacademy.org/math/probability/probability-and-combinatorics-topic"&gt;Basic Theoretical Probability&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;Just the videos - 41 (each are simple and each are short): 
      &lt;ul&gt; 
       &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=uzkc-qNVoOk&amp;amp;list=PLC58778F28211FA19"&gt;Probability Explained (video)&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;NP, NP-Complete and Approximation Algorithms&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Know about the most famous classes of NP-complete problems, such as the traveling salesman and the knapsack problem, and be able to recognize them when an interviewer asks you them in disguise.&lt;/li&gt; 
   &lt;li&gt;Know what NP-complete means.&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=moPtwq_cVH8&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb&amp;amp;index=23"&gt;Computational Complexity (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Simonson: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/qcGnJ47Smlo?list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;t=2939"&gt;Greedy Algs. II &amp;amp; Intro to NP-Completeness (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=e0tGC6ZQdQE&amp;amp;index=16&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm"&gt;NP Completeness II &amp;amp; Reductions (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=fCX1BGT3wjE&amp;amp;index=17&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm"&gt;NP Completeness III (Video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=NKLDp3Rch3M&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;index=18"&gt;NP Completeness IV (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Skiena: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=ItHp5laE1VE&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=23"&gt;CSE373 2020 - Lecture 23 - NP-Completeness (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=inaFJeCzGxU&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=24"&gt;CSE373 2020 - Lecture 24 - Satisfiability (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=B-bhKxjZLlc&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=25"&gt;CSE373 2020 - Lecture 25 - More NP-Completeness (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=_EzetTkG_Cc&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=26"&gt;CSE373 2020 - Lecture 26 - NP-Completeness Challenge (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=eHZifpgyH_4&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&amp;amp;index=22"&gt;Complexity: P, NP, NP-completeness, Reductions (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=MEz1J9wY2iM&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&amp;amp;index=24"&gt;Complexity: Approximation Algorithms (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=4q-jmGrmxKs&amp;amp;index=25&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp"&gt;Complexity: Fixed-Parameter Algorithms (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Peter Norvig discusses near-optimal solutions to the traveling salesman problem: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="http://nbviewer.jupyter.org/url/norvig.com/ipython/TSP.ipynb"&gt;Jupyter Notebook&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Pages 1048 - 1140 in CLRS if you have it.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;How computers process a program&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=XM4lGflQFvA"&gt;How CPU executes a program (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/1I5ZMmrOfnA"&gt;How computers calculate - ALU (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/fpnE6UAfbtU"&gt;Registers and RAM (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/FZGugFqdr60"&gt;The Central Processing Unit (CPU) (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://youtu.be/zltgXvg6r3k"&gt;Instructions and Programs (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Caches&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; LRU cache: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=R5ON3iwx78M"&gt;The Magic of LRU Cache (100 Days of Google Dev) (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=bq6N7Ym81iI"&gt;Implementing LRU (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=8-FZRAjR7qU"&gt;LeetCode - 146 LRU Cache (C++) (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; CPU cache: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=vjYF_fAZI5E&amp;amp;list=PLrRW1w6CGAcXbMtDFj205vALOGmiRc82-&amp;amp;index=24"&gt;MIT 6.004 L15: The Memory Hierarchy (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=ajgC3-pyGlk&amp;amp;index=25&amp;amp;list=PLrRW1w6CGAcXbMtDFj205vALOGmiRc82-"&gt;MIT 6.004 L16: Cache Issues (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Processes and Threads&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Computer Science 162 - Operating Systems (25 videos): 
    &lt;ul&gt; 
     &lt;li&gt;for processes and threads see videos 1-11&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://archive.org/details/ucberkeley-webcast-PL-XXv-cvA_iBDyz-ba4yDskqMDY6A1w_c"&gt;Operating Systems and System Programming (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-a-process-and-a-thread"&gt;What Is The Difference Between A Process And A Thread?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Covers: 
    &lt;ul&gt; 
     &lt;li&gt;Processes, Threads, Concurrency issues 
      &lt;ul&gt; 
       &lt;li&gt;Difference between processes and threads&lt;/li&gt; 
       &lt;li&gt;Processes&lt;/li&gt; 
       &lt;li&gt;Threads&lt;/li&gt; 
       &lt;li&gt;Locks&lt;/li&gt; 
       &lt;li&gt;Mutexes&lt;/li&gt; 
       &lt;li&gt;Semaphores&lt;/li&gt; 
       &lt;li&gt;Monitors&lt;/li&gt; 
       &lt;li&gt;How do they work?&lt;/li&gt; 
       &lt;li&gt;Deadlock&lt;/li&gt; 
       &lt;li&gt;Livelock&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;CPU activity, interrupts, context switching&lt;/li&gt; 
     &lt;li&gt;Modern concurrency constructs with multicore processors&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://youtu.be/O4nwUqQodAg"&gt;Paging, segmentation, and virtual memory (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://youtu.be/iKlAWIKEyuw"&gt;Interrupts (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;Process resource needs (memory: code, static storage, stack, heap, and also file descriptors, i/o)&lt;/li&gt; 
     &lt;li&gt;Thread resource needs (shares above (minus stack) with other threads in the same process but each has its own PC, stack counter, registers, and stack)&lt;/li&gt; 
     &lt;li&gt;Forking is really copy on write (read-only) until the new process writes to memory, then it does a full copy.&lt;/li&gt; 
     &lt;li&gt;Context switching 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://www.javatpoint.com/what-is-the-context-switching-in-the-operating-system"&gt;How context switching is initiated by the operating system and underlying hardware?&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/playlist?list=PL5jc9xFGsL8E12so1wlMS0r0hTQoJL74M"&gt;threads in C++ (series - 10 videos)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/playlist?list=PLacuG5pysFbDQU8kKxbUh4K5c1iL5_k7k"&gt;CS 377 Spring '14: Operating Systems from University of Massachusetts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; concurrency in Python (videos): 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/playlist?list=PL1H1sBF1VAKVMONJWJkmUh6_p8g4F2oy1"&gt;Short series on threads&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=Bs7vPNbB9JM"&gt;Python Threads&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=Obt-vMVdM8s"&gt;Understanding the Python GIL (2010)&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="http://www.dabeaz.com/GIL"&gt;reference&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=MCs5OvhV9S4"&gt;David Beazley - Python Concurrency From the Ground Up LIVE! - PyCon 2015&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=ZzfHjytDceU"&gt;Keynote David Beazley - Topics of Interest (Python Asyncio)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=0zaPs8OtyKY"&gt;Mutex in Python&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Testing&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;To cover: 
    &lt;ul&gt; 
     &lt;li&gt;how unit testing works&lt;/li&gt; 
     &lt;li&gt;what are mock objects&lt;/li&gt; 
     &lt;li&gt;what is integration testing&lt;/li&gt; 
     &lt;li&gt;what is dependency injection&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=SAhJf36_u5U"&gt;Agile Software Testing with James Bach (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=ILkT_HV9DVU"&gt;Open Lecture by James Bach on Software Testing (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://vimeo.com/83960706"&gt;Steve Freeman - Test-Driven Development (that‚Äôs not what we meant) (video)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="http://gotocon.com/dl/goto-berlin-2013/slides/SteveFreeman_TestDrivenDevelopmentThatsNotWhatWeMeant.pdf"&gt;slides&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Dependency injection: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=IKD2-MAkXyQ"&gt;video&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://jasonpolites.github.io/tao-of-testing/ch3-1.1.html"&gt;Tao Of Testing&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://jasonpolites.github.io/tao-of-testing/ch4-1.1.html"&gt;How to write tests&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;String searching &amp;amp; manipulations&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/lecture/TH18W/suffix-arrays"&gt;Sedgewick - Suffix Arrays (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/home/week/4"&gt;Sedgewick - Substring Search (videos)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithms-part2/introduction-to-substring-search-n3ZpG"&gt;1. Introduction to Substring Search&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/lecture/2Kn5i/brute-force-substring-search"&gt;2. Brute-Force Substring Search&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/lecture/TAtDr/knuth-morris-pratt"&gt;3. Knuth-Morris Pratt&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/lecture/CYxOT/boyer-moore"&gt;4. Boyer-Moore&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/lecture/algorithms-part2/rabin-karp-3KiqT"&gt;5. Rabin-Karp&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/data-structures/lecture/tAfHI/search-pattern-in-text"&gt;Search pattern in a text (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;If you need more detail on this subject, see the "String Matching" section in &lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#additional-detail-on-some-subjects"&gt;Additional Detail on Some Subjects&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Tries&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Note there are different kinds of tries. Some have prefixes, some don't, and some use strings instead of bits to track the path&lt;/li&gt; 
   &lt;li&gt;I read through the code, but will not implement&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/home/week/4"&gt;Sedgewick - Tries (3 videos)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/lecture/CPVdr/r-way-tries"&gt;1. R Way Tries&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/lecture/yQM8K/ternary-search-tries"&gt;2. Ternary Search Tries&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2/lecture/jwNmV/character-based-operations"&gt;3. Character Based Operations&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://www.cs.yale.edu/homes/aspnes/classes/223/notes.html#Tries"&gt;Notes on Data Structures and Programming Techniques&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Short course videos: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/data-structures-optimizing-performance/lecture/08Xyf/core-introduction-to-tries"&gt;Introduction To Tries (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/data-structures-optimizing-performance/lecture/PvlZW/core-performance-of-tries"&gt;Performance Of Tries (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/data-structures-optimizing-performance/lecture/DFvd3/core-implementing-a-trie"&gt;Implementing A Trie (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.toptal.com/java/the-trie-a-neglected-data-structure"&gt;The Trie: A Neglected Data Structure&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.topcoder.com/thrive/articles/Using%20Tries"&gt;TopCoder - Using Tries&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=TJ8SkcUSdbU"&gt;Stanford Lecture (real-world use case) (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=NinWEPPrkDQ&amp;amp;index=16&amp;amp;list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf"&gt;MIT, Advanced Data Structures, Strings (can get pretty obscure about halfway through) (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Floating Point Numbers&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; simple 8-bit: &lt;a href="https://www.youtube.com/watch?v=ji3SfClm8TU"&gt;Representation of Floating Point Numbers - 1 (video - there is an error in calculations - see video description)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Unicode&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://www.joelonsoftware.com/articles/Unicode.html"&gt;The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://kunststube.net/encoding/"&gt;What Every Programmer Absolutely, Positively Needs To Know About Encodings And Character Sets To Work With Text&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Endianness&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://web.archive.org/web/20180107141940/http://www.cs.umd.edu:80/class/sum2003/cmsc311/Notes/Data/endian.html"&gt;Big And Little Endian&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=JrNF0KRAlyo"&gt;Big Endian Vs Little Endian (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=oBSuXP-1Tc0"&gt;Big And Little Endian Inside/Out (video)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Very technical talk for kernel devs. Don't worry if most is over your head.&lt;/li&gt; 
     &lt;li&gt;The first half is enough.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Networking&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;If you have networking experience or want to be a reliability engineer or operations engineer, expect questions&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Otherwise, this is just good to know&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.khanacademy.org/computing/code-org/computers-and-the-internet"&gt;Khan Academy&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=Vdc8TCESIg8"&gt;UDP and TCP: Comparison of Transport Protocols (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=e5DEVa9eSN0"&gt;TCP/IP and the OSI Model Explained! (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=nomyRJehhnM"&gt;Packet Transmission across the Internet. Networking &amp;amp; TCP/IP tutorial. (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=WGJrLqtX7As"&gt;HTTP (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=S2iBR2ZlZf0"&gt;SSL and HTTPS (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=Rp3iZUvXWlM"&gt;SSL/TLS (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=E9FxNzv1Tr8"&gt;HTTP 2.0 (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/playlist?list=PLEbnTDJUr_IegfoqO4iPnPYQui46QqT0j"&gt;Video Series (21 videos) (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=t5xYI0jzOf4"&gt;Subnetting Demystified - Part 5 CIDR Notation (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Sockets: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=6G_W54zuadg&amp;amp;t=6s"&gt;Java - Sockets - Introduction (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=G75vN2mnJeQ"&gt;Socket Programming (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Final Review&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;This section will have shorter videos that you can watch pretty quickly to review most of the important concepts.
It's nice if you want a refresher often.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Series of 2-3 minutes short subject videos (23 videos) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=r4r1DZcx1cM&amp;amp;list=PLmVb1OknmNJuC5POdcDv5oCS7_OUkDgpj&amp;amp;index=22"&gt;Videos&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Series of 2-5 minutes short subject videos - Michael Sambol (48 videos): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/@MichaelSambol"&gt;Videos&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/msambol/dsa"&gt;Code Examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part1"&gt;Sedgewick Videos - Algorithms I&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.coursera.org/learn/algorithms-part2"&gt;Sedgewick Videos - Algorithms II&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Update Your Resume&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;See Resume prep information in the books: "Cracking The Coding Interview" and "Programming Interviews Exposed"&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.careercup.com/resume"&gt;"This Is What A GOOD Resume Should Look Like" by Gayle McDowell (author of Cracking the Coding Interview)&lt;/a&gt;, 
  &lt;ul&gt; 
   &lt;li&gt;Note by the author: "This is for a US-focused resume. CVs for India and other countries have different expectations, although many of the points will be the same."&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.techinterviewhandbook.org/resume/guide"&gt;"Step-by-step resume guide" by Tech Interview Handbook&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Detailed guide on how to set up your resume from scratch, write effective resume content, optimize it, and test your resume&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Interview Process &amp;amp; General Interview Prep&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://davidbyttow.medium.com/how-to-pass-the-engineering-interview-in-2021-45f1b389a1"&gt;How to Pass the Engineering Interview in 2021&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=N233T0epWTs"&gt;Demystifying Tech Recruiting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; How to Get a Job at the Big 4: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=YJZCUhxNCv8"&gt;How to Get a Job at the Big 4 - Amazon, Facebook, Google &amp;amp; Microsoft (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=6790FVXWBw8&amp;amp;feature=youtu.be"&gt;How to Get a Job at the Big 4.1 (Follow-up video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Cracking The Coding Interview Set 1: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=rEJzOhC5ZtQ"&gt;Gayle L McDowell - Cracking The Coding Interview (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=aClxtDcdpsQ"&gt;Cracking the Coding Interview with Author Gayle Laakmann McDowell (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Cracking the Facebook Coding Interview: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=wCl9kvQGHPI"&gt;The Approach&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=4UWDyJq8jZg"&gt;Problem Walkthrough&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Prep Courses: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.udemy.com/python-for-data-structures-algorithms-and-interviews/"&gt;Python for Data Structures, Algorithms, and Interviews (paid course)&lt;/a&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;A Python-centric interview prep course that covers data structures, algorithms, mock interviews, and much more.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.udacity.com/course/data-structures-and-algorithms-in-python--ud513"&gt;Intro to Data Structures and Algorithms using Python (Udacity free course)&lt;/a&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;A free Python-centric data structures and algorithms course.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.udacity.com/course/data-structures-and-algorithms-nanodegree--nd256"&gt;Data Structures and Algorithms Nanodegree! (Udacity paid Nanodegree)&lt;/a&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;Get hands-on practice with over 100 data structures and algorithm exercises and guidance from a dedicated mentor to help prepare you for interviews and on-the-job scenarios.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.educative.io/courses/grokking-the-behavioral-interview"&gt;Grokking the Behavioral Interview (Educative free course)&lt;/a&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;Many times, it‚Äôs not your technical competency that holds you back from landing your dream job, it‚Äôs how you perform on the behavioral interview.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://algo.monster/?utm_campaign=jwasham&amp;amp;utm_medium=referral&amp;amp;utm_content=coding-interview-university&amp;amp;utm_source=github"&gt;AlgoMonster (paid course with free content)&lt;/a&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;The crash course for LeetCode. Covers all the patterns condensed from thousands of questions.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Mock Interviews:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.gainlo.co/#!/"&gt;Gainlo.co: Mock interviewers from big companies&lt;/a&gt; - I used this and it helped me relax for the phone screen and on-site interview&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pramp.com/"&gt;Pramp: Mock interviews from/with peers&lt;/a&gt; - a peer-to-peer model to practice interviews&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://interviewing.io"&gt;interviewing.io: Practice mock interview with senior engineers&lt;/a&gt; - anonymous algorithmic/systems design interviews with senior engineers from FAANG anonymously&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://meetapro.com/?utm_source=ciu"&gt;Meetapro: Mock interviews with top FAANG interviewers&lt;/a&gt; - an Airbnb-style mock interview/coaching platform.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.hellointerview.com/?utm_source=ciu"&gt;Hello Interview: Mock Interviews with Expert Coaches and AI&lt;/a&gt; - interview directly with AI or with FAANG staff engineers and managers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codemia.io/?utm_source=ciu"&gt;Codemia: Practice system design problems with AI or community solutions and feedback&lt;/a&gt; - Practice system design problems via AI practice tool. Share your solution with the community to get human feedback as well.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Be thinking of for when the interview comes&lt;/h2&gt; 
&lt;p&gt;Think of about 20 interview questions you'll get, along with the lines of the items below. Have at least one answer for each. Have a story, not just data, about something you accomplished.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Why do you want this job?&lt;/li&gt; 
 &lt;li&gt;What's a tough problem you've solved?&lt;/li&gt; 
 &lt;li&gt;Biggest challenges faced?&lt;/li&gt; 
 &lt;li&gt;Best/worst designs seen?&lt;/li&gt; 
 &lt;li&gt;Ideas for improving an existing product&lt;/li&gt; 
 &lt;li&gt;How do you work best, as an individual and as part of a team?&lt;/li&gt; 
 &lt;li&gt;Which of your skills or experiences would be assets in the role and why?&lt;/li&gt; 
 &lt;li&gt;What did you most enjoy at [job x / project y]?&lt;/li&gt; 
 &lt;li&gt;What was the biggest challenge you faced at [job x / project y]?&lt;/li&gt; 
 &lt;li&gt;What was the hardest bug you faced at [job x / project y]?&lt;/li&gt; 
 &lt;li&gt;What did you learn at [job x / project y]?&lt;/li&gt; 
 &lt;li&gt;What would you have done better at [job x / project y]?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Have questions for the interviewer&lt;/h2&gt; 
&lt;p&gt;Some of mine (I already may know the answers, but want their opinion or team perspective):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;How large is your team?&lt;/li&gt; 
 &lt;li&gt;What does your dev cycle look like? Do you do waterfall/sprints/agile?&lt;/li&gt; 
 &lt;li&gt;Are rushes to deadlines common? Or is there flexibility?&lt;/li&gt; 
 &lt;li&gt;How are decisions made in your team?&lt;/li&gt; 
 &lt;li&gt;How many meetings do you have per week?&lt;/li&gt; 
 &lt;li&gt;Do you feel your work environment helps you concentrate?&lt;/li&gt; 
 &lt;li&gt;What are you working on?&lt;/li&gt; 
 &lt;li&gt;What do you like about it?&lt;/li&gt; 
 &lt;li&gt;What is the work life like?&lt;/li&gt; 
 &lt;li&gt;How is the work/life balance?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Once You've Got The Job&lt;/h2&gt; 
&lt;p&gt;Congratulations!&lt;/p&gt; 
&lt;p&gt;Keep learning.&lt;/p&gt; 
&lt;p&gt;You're never really done.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;pre&gt;&lt;code&gt;*****************************************************************************************************
*****************************************************************************************************

Everything below this point is optional. It is NOT needed for an entry-level interview.
However, by studying these, you'll get greater exposure to more CS concepts and will be better prepared for
any software engineering job. You'll be a much more well-rounded software engineer.

*****************************************************************************************************
*****************************************************************************************************
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Additional Books&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;These are here so you can dive into a topic you find interesting.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/dp/013937681X"&gt;The Unix Programming Environment&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;An oldie but a goodie&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/dp/1593273894/"&gt;The Linux Command Line: A Complete Introduction&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;A modern option&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/TCP/IP_Illustrated"&gt;TCP/IP Illustrated Series&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/gp/product/0596007124/"&gt;Head First Design Patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;A gentle introduction to design patterns&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/Design-Patterns-Elements-Reusable-Object-Oriented/dp/0201633612"&gt;Design Patterns: Elements of Reusable Object-Oriented Software&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;AKA the "Gang Of Four" book or GOF&lt;/li&gt; 
   &lt;li&gt;The canonical design patterns book&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.amazon.com/Algorithm-Design-Manual-Steven-Skiena/dp/1849967202"&gt;Algorithm Design Manual&lt;/a&gt; (Skiena) 
  &lt;ul&gt; 
   &lt;li&gt;As a review and problem-recognition&lt;/li&gt; 
   &lt;li&gt;The algorithm catalog portion is well beyond the scope of difficulty you'll get in an interview&lt;/li&gt; 
   &lt;li&gt;This book has 2 parts: 
    &lt;ul&gt; 
     &lt;li&gt;Class textbook on data structures and algorithms 
      &lt;ul&gt; 
       &lt;li&gt;Pros: 
        &lt;ul&gt; 
         &lt;li&gt;Is a good review as any algorithms textbook would be&lt;/li&gt; 
         &lt;li&gt;Nice stories from his experiences solving problems in industry and academia&lt;/li&gt; 
         &lt;li&gt;Code examples in C&lt;/li&gt; 
        &lt;/ul&gt; &lt;/li&gt; 
       &lt;li&gt;Cons: 
        &lt;ul&gt; 
         &lt;li&gt;Can be as dense or impenetrable as CLRS, and in some cases, CLRS may be a better alternative for some subjects&lt;/li&gt; 
         &lt;li&gt;Chapters 7, 8, and 9 can be painful to try to follow, as some items are not explained well or require more brain than I have&lt;/li&gt; 
         &lt;li&gt;Don't get me wrong: I like Skiena, his teaching style, and mannerisms, but I may not be Stony Brook material&lt;/li&gt; 
        &lt;/ul&gt; &lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;Algorithm catalog: 
      &lt;ul&gt; 
       &lt;li&gt;This is the real reason you buy this book.&lt;/li&gt; 
       &lt;li&gt;This book is better as an algorithm reference, and not something you read cover to cover.&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Can rent it on Kindle&lt;/li&gt; 
   &lt;li&gt;Answers: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://web.archive.org/web/20150404194210/http://www.algorithm.cs.sunysb.edu/algowiki/index.php/The_Algorithms_Design_Manual_(Second_Edition)"&gt;Solutions&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://www3.cs.stonybrook.edu/~skiena/algorist/book/errata"&gt;Errata&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://jeffe.cs.illinois.edu/teaching/algorithms/"&gt;Algorithm&lt;/a&gt; (Jeff Erickson)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/Write-Great-Code-Understanding-Machine/dp/1593270038"&gt;Write Great Code: Volume 1: Understanding the Machine&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The book was published in 2004, and is somewhat outdated, but it's a terrific resource for understanding a computer in brief&lt;/li&gt; 
   &lt;li&gt;The author invented &lt;a href="https://en.wikipedia.org/wiki/High_Level_Assembly"&gt;HLA&lt;/a&gt;, so take mentions and examples in HLA with a grain of salt. Not widely used, but decent examples of what assembly looks like&lt;/li&gt; 
   &lt;li&gt;These chapters are worth the read to give you a nice foundation: 
    &lt;ul&gt; 
     &lt;li&gt;Chapter 2 - Numeric Representation&lt;/li&gt; 
     &lt;li&gt;Chapter 3 - Binary Arithmetic and Bit Operations&lt;/li&gt; 
     &lt;li&gt;Chapter 4 - Floating-Point Representation&lt;/li&gt; 
     &lt;li&gt;Chapter 5 - Character Representation&lt;/li&gt; 
     &lt;li&gt;Chapter 6 - Memory Organization and Access&lt;/li&gt; 
     &lt;li&gt;Chapter 7 - Composite Data Types and Memory Objects&lt;/li&gt; 
     &lt;li&gt;Chapter 9 - CPU Architecture&lt;/li&gt; 
     &lt;li&gt;Chapter 10 - Instruction Set Architecture&lt;/li&gt; 
     &lt;li&gt;Chapter 11 - Memory Architecture and Organization&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/Introduction-Algorithms-fourth-Thomas-Cormen/dp/026204630X"&gt;Introduction to Algorithms&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Important:&lt;/strong&gt; Reading this book will only have limited value. This book is a great review of algorithms and data structures, but won't teach you how to write good code. You have to be able to code a decent solution efficiently&lt;/li&gt; 
   &lt;li&gt;AKA CLR, sometimes CLRS, because Stein was late to the game&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/dp/0128119055"&gt;Computer Architecture, Sixth Edition: A Quantitative Approach&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;For a richer, more up-to-date (2017), but longer treatment&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;System Design, Scalability, Data Handling&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;You can expect system design questions if you have 4+ years of experience.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Scalability and System Design are very large topics with many topics and resources, since there is a lot to consider when designing a software/hardware system that can scale. Expect to spend quite a bit of time on this&lt;/li&gt; 
 &lt;li&gt;Considerations: 
  &lt;ul&gt; 
   &lt;li&gt;Scalability 
    &lt;ul&gt; 
     &lt;li&gt;Distill large data sets to single values&lt;/li&gt; 
     &lt;li&gt;Transform one data set to another&lt;/li&gt; 
     &lt;li&gt;Handling obscenely large amounts of data&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;System design 
    &lt;ul&gt; 
     &lt;li&gt;features sets&lt;/li&gt; 
     &lt;li&gt;interfaces&lt;/li&gt; 
     &lt;li&gt;class hierarchies&lt;/li&gt; 
     &lt;li&gt;designing a system under certain constraints&lt;/li&gt; 
     &lt;li&gt;simplicity and robustness&lt;/li&gt; 
     &lt;li&gt;tradeoffs&lt;/li&gt; 
     &lt;li&gt;performance analysis and optimization&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;START HERE&lt;/strong&gt;: &lt;a href="https://github.com/donnemartin/system-design-primer"&gt;The System Design Primer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://www.hiredintech.com/system-design/"&gt;System Design from HiredInTech&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.quora.com/How-do-I-prepare-to-answer-design-questions-in-a-technical-interview?redirected_qid=1500023"&gt;How Do I Prepare To Answer Design Questions In A Technical Interview?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://javascript.plainenglish.io/8-steps-guide-to-ace-a-system-design-interview-7a5a797f4d7d"&gt;8 steps guide to ace your system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=UrYLYV7WSHM"&gt;Database Normalization - 1NF, 2NF, 3NF and 4NF (video)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://github.com/checkcheckzz/system-design-interview"&gt;System Design Interview&lt;/a&gt; - There are a lot of resources in this one. Look through the articles and examples. I put some of them below&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://web.archive.org/web/20120716060051/http://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/"&gt;How to ace a systems design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://everythingisdata.wordpress.com/2009/10/17/numbers-everyone-should-know/"&gt;Numbers Everyone Should Know&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html"&gt;How long does it take to make a context switch?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=srOgpXECblk"&gt;Transactions Across Datacenters (video)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://ksat.me/a-plain-english-introduction-to-cap-theorem"&gt;A plain English introduction to CAP Theorem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=cQP8WApzIQQ&amp;amp;list=PLrw6a1wE39_tb2fErI4-WkMbsvGQk9_UB"&gt;MIT 6.824: Distributed Systems, Spring 2020 (20 videos)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Consensus Algorithms: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Paxos - &lt;a href="https://www.youtube.com/watch?v=s8JqcZtvnsM"&gt;Paxos Agreement - Computerphile (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Raft - &lt;a href="https://www.youtube.com/watch?v=P9Ydif5_qvE"&gt;An Introduction to the Raft Distributed Consensus Algorithm (video)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://raft.github.io/"&gt;Easy-to-read paper&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://thesecretlivesofdata.com/raft/"&gt;Infographic&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://www.tom-e-white.com/2007/11/consistent-hashing.html"&gt;Consistent Hashing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://horicky.blogspot.com/2009/11/nosql-patterns.html"&gt;NoSQL Patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Scalability: 
  &lt;ul&gt; 
   &lt;li&gt;You don't need all of these. Just pick a few that interest you.&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=-W9F__D3oY4"&gt;Great overview (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Short series: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="http://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones"&gt;Clones&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database"&gt;Database&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache"&gt;Cache&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism"&gt;Asynchronism&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://www.aosabook.org/en/distsys.html"&gt;Scalable Web Architecture and Distributed Systems&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://pages.cs.wisc.edu/~zuyu/files/fallacies.pdf"&gt;Fallacies of Distributed Computing Explained&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=modXC5IWTJI"&gt;Jeff Dean - Building Software Systems At Google and Lessons Learned (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/"&gt;Introduction to Architecting Systems for Scale&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=9nWyWwY2Onc"&gt;Scaling mobile games to a global audience using App Engine and Cloud Datastore (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=H4vMcD7zKM0"&gt;How Google Does Planet-Scale Engineering for Planet-Scale Infra (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.topcoder.com/thrive/articles/The%20Importance%20of%20Algorithms"&gt;The Importance of Algorithms&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html"&gt;Sharding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=p0jGmgIrf_M&amp;amp;list=PLRXxvay_m8gqVlExPC5DG3TGWJTaBgqSA&amp;amp;index=4"&gt;Engineering for the Long Game - Astrid Atkinson Keynote(video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2012/3/26/7-years-of-youtube-scalability-lessons-in-30-minutes.html"&gt;7 Years Of YouTube Scalability Lessons In 30 Minutes&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=G-lGCC4KKok"&gt;video&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2016/8/15/how-paypal-scaled-to-billions-of-transactions-daily-using-ju.html"&gt;How PayPal Scaled To Billions Of Transactions Daily Using Just 8VMs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://blog.clevertap.com/how-to-remove-duplicates-in-large-datasets/"&gt;How to Remove Duplicates in Large Datasets&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=3vV4YiqKm1o"&gt;A look inside Etsy's scale and engineering culture with Jon Cowie (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://thenewstack.io/led-amazon-microservices-architecture/"&gt;What Led Amazon to its Own Microservices Architecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://eng.uber.com/trip-data-squeeze/"&gt;To Compress Or Not To Compress, That Was Uber's Question&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2016/2/25/when-should-approximate-query-processing-be-used.html"&gt;When Should Approximate Query Processing Be Used?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2016/2/23/googles-transition-from-single-datacenter-to-failover-to-a-n.html"&gt;Google's Transition From Single Datacenter To Failover, To A Native Multihomed Architecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2016/6/15/the-image-optimization-technology-that-serves-millions-of-re.html"&gt;The Image Optimization Technology That Serves Millions Of Requests Per Day&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2016/2/1/a-patreon-architecture-short.html"&gt;A Patreon Architecture Short&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2016/1/27/tinder-how-does-one-of-the-largest-recommendation-engines-de.html"&gt;Tinder: How Does One Of The Largest Recommendation Engines Decide Who You'll See Next?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2016/1/25/design-of-a-modern-cache.html"&gt;Design Of A Modern Cache&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2016/1/13/live-video-streaming-at-facebook-scale.html"&gt;Live Video Streaming At Facebook Scale&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2016/1/11/a-beginners-guide-to-scaling-to-11-million-users-on-amazons.html"&gt;A Beginner's Guide To Scaling To 11 Million+ Users On Amazon's AWS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2015/11/9/a-360-degree-view-of-the-entire-netflix-stack.html"&gt;A 360 Degree View Of The Entire Netflix Stack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/latency-everywhere-and-it-costs-you-sales-how-crush-it"&gt;Latency Is Everywhere And It Costs You Sales - How To Crush It&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances"&gt;What Powers Instagram: Hundreds of Instances, Dozens of Technologies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html"&gt;Salesforce Architecture - How They Handle 1.3 Billion Transactions A Day&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html"&gt;ESPN's Architecture At Scale - Operating At 100,000 Duh Nuh Nuhs Per Second&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; See "Messaging, Serialization, and Queueing Systems" way below for info on some of the technologies that can glue services together&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Twitter: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=5cKTP36HVgI"&gt;O'Reilly MySQL CE 2011: Jeremy Cole, "Big and Small Data at @Twitter" (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability"&gt;Timelines at Scale&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;For even more, see the "Mining Massive Datasets" video series in the &lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#video-series"&gt;Video Series&lt;/a&gt; section&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Practicing the system design process: Here are some ideas to try working through on paper, each with some documentation on how it was handled in the real world: 
  &lt;ul&gt; 
   &lt;li&gt;review: &lt;a href="https://github.com/donnemartin/system-design-primer"&gt;The System Design Primer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design/"&gt;System Design from HiredInTech&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/jwasham/coding-interview-university/raw/main/extras/cheat%20sheets/system-design.pdf"&gt;cheat sheet&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;flow: 
    &lt;ol&gt; 
     &lt;li&gt;Understand the problem and scope: 
      &lt;ul&gt; 
       &lt;li&gt;Define the use cases, with the interviewer's help&lt;/li&gt; 
       &lt;li&gt;Suggest additional features&lt;/li&gt; 
       &lt;li&gt;Remove items that the interviewer deems out of scope&lt;/li&gt; 
       &lt;li&gt;Assume high availability is required, add as a use case&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;Think about constraints: 
      &lt;ul&gt; 
       &lt;li&gt;Ask how many requests per month&lt;/li&gt; 
       &lt;li&gt;Ask how many requests per second (they may volunteer it or make you do the math)&lt;/li&gt; 
       &lt;li&gt;Estimate reads vs. writes percentage&lt;/li&gt; 
       &lt;li&gt;Keep the 80/20 rule in mind when estimating&lt;/li&gt; 
       &lt;li&gt;How much data is written per second&lt;/li&gt; 
       &lt;li&gt;Total storage required over 5 years&lt;/li&gt; 
       &lt;li&gt;How much data read per second&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;Abstract design: 
      &lt;ul&gt; 
       &lt;li&gt;Layers (service, data, caching)&lt;/li&gt; 
       &lt;li&gt;Infrastructure: load balancing, messaging&lt;/li&gt; 
       &lt;li&gt;Rough overview of any key algorithm that drives the service&lt;/li&gt; 
       &lt;li&gt;Consider bottlenecks and determine solutions&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
   &lt;li&gt;Exercises: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://blog.twitter.com/2010/announcing-snowflake"&gt;Design a random unique ID generation system&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis"&gt;Design a key-value database&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html"&gt;Design a picture sharing system&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://ijcai13.org/files/tutorial_slides/td3.pdf"&gt;Design a recommendation system&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design/the-system-design-process/"&gt;Design a URL-shortener system: copied from above&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://web.archive.org/web/20220217064329/https://adayinthelifeof.nl/2011/02/06/memcache-internals/"&gt;Design a cache system&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Additional Learning&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;I added them to help you become a well-rounded software engineer and to be aware of certain
technologies and algorithms, so you'll have a bigger toolbox.
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;h3&gt;Compilers&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=IhC7sdYe-Jg"&gt;How a Compiler Works in ~1 minute (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=CSZLNYF4Klo"&gt;Harvard CS50 - Compilers (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=twodd1KFfGk"&gt;C++ (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=FnGCDLhaxKU"&gt;Understanding Compiler Optimization (C++) (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Emacs and vi(m)&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Familiarize yourself with a UNIX-based code editor&lt;/li&gt; 
   &lt;li&gt;vi(m): 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=5givLEMcINQ&amp;amp;index=1&amp;amp;list=PL13bz4SHGmRxlZVmWQ9DvXo1fEg4UdGkr"&gt;Editing With Vim 01 - Installation, Setup, and The Modes (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://vim-adventures.com/"&gt;VIM Adventures&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;set of 4 videos: 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=SI8TeVMX8pk"&gt;The vi/vim editor - Lesson 1&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=F3OO7ZIOaJE"&gt;The vi/vim editor - Lesson 2&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ZYEccA_nMaI"&gt;The vi/vim editor - Lesson 3&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1lYD5gwgZIA"&gt;The vi/vim editor - Lesson 4&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://www.cs.yale.edu/homes/aspnes/classes/223/notes.html#Using_Vi_instead_of_Emacs"&gt;Using Vi Instead of Emacs&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;emacs: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=hbmV1bnQ-i0"&gt;Basics Emacs Tutorial (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;set of 3 (videos): 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ujODL7MD04Q"&gt;Emacs Tutorial (Beginners) -Part 1- File commands, cut/copy/paste, cursor commands&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=XWpsRupJ4II"&gt;Emacs Tutorial (Beginners) -Part 2- Buffer management, search, M-x grep and rgrep modes&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=paSgzPso-yc"&gt;Emacs Tutorial (Beginners) -Part 3- Expressions, Statements, ~/.emacs file, and packages&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=JWD1Fpdd4Pc"&gt;Evil Mode: Or, How I Learned to Stop Worrying and Love Emacs (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://www.cs.yale.edu/homes/aspnes/classes/223/notes.html#Writing_C_programs_with_Emacs"&gt;Writing C Programs With Emacs&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=48JlgiBpw_I&amp;amp;t=0s"&gt;The Absolute Beginner's Guide to Emacs (video by David Wilson)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://systemcrafters.net/emacs-essentials/absolute-beginners-guide-to-emacs/"&gt;The Absolute Beginner's Guide to Emacs (notes by David Wilson)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Unix/Linux command line tools&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;I filled in the list below from good tools.&lt;/li&gt; 
   &lt;li&gt;bash&lt;/li&gt; 
   &lt;li&gt;cat&lt;/li&gt; 
   &lt;li&gt;grep&lt;/li&gt; 
   &lt;li&gt;sed&lt;/li&gt; 
   &lt;li&gt;awk&lt;/li&gt; 
   &lt;li&gt;curl or wget&lt;/li&gt; 
   &lt;li&gt;sort&lt;/li&gt; 
   &lt;li&gt;tr&lt;/li&gt; 
   &lt;li&gt;uniq&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Strace"&gt;strace&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://danielmiessler.com/study/tcpdump/"&gt;tcpdump&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://labex.io/tutorials/practice-linux-commands-hands-on-labs-398420"&gt;Essential Linux Commands Tutorial&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;DevOps&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://roadmap.sh/devops"&gt;DevOps Roadmap&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Information theory (videos)&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.khanacademy.org/computing/computer-science/informationtheory"&gt;Khan Academy&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;More about Markov processes: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures-optimizing-performance/lecture/waxgx/core-markov-text-generation"&gt;Core Markov Text Generation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures-optimizing-performance/lecture/gZhiC/core-implementing-markov-text-generation"&gt;Core Implementing Markov Text Generation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures-optimizing-performance/lecture/EUjrq/project-markov-text-generation-walk-through"&gt;Project = Markov Text Generation Walk Through&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;See more in the MIT 6.050J Information and Entropy series below&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Parity &amp;amp; Hamming Code (videos)&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=q-3BctoUpHE"&gt;Intro&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=DdMcAUlxh1M"&gt;Parity&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Hamming Code: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1A_NcXxdoCc"&gt;Error detection&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=JAMLuxdHH8o"&gt;Error correction&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wbH2VxzmoZk"&gt;Error Checking&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Entropy&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Also see the videos below&lt;/li&gt; 
   &lt;li&gt;Make sure to watch information theory videos first&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://youtu.be/JnJq3Py0dyM?t=176"&gt;Information Theory, Claude Shannon, Entropy, Redundancy, Data Compression &amp;amp; Bits (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Cryptography&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Also see the videos below&lt;/li&gt; 
   &lt;li&gt;Make sure to watch information theory videos first&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.khanacademy.org/computing/computer-science/cryptography"&gt;Khan Academy Series&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=KqqOXndnvic&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&amp;amp;index=30"&gt;Cryptography: Hash Functions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=9TNI2wHmaeI&amp;amp;index=31&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp"&gt;Cryptography: Encryption&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Compression&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Make sure to watch information theory videos first&lt;/li&gt; 
   &lt;li&gt;Computerphile (videos): 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=Lto-ajuqW3w"&gt;Compression&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=M5c_RFKVkko"&gt;Entropy in Compression&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=umTbivyJoiI"&gt;Upside Down Trees (Huffman Trees)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=DV8efuB3h2g"&gt;EXTRA BITS/TRITS - Huffman Trees&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=goOa3DGezUA"&gt;Elegant Compression in Text (The LZ 77 Method)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=cCDCfoHTsaU"&gt;Text Compression Meets Probabilities&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLOU2XLYxmsIJGErt5rrCqaSGTMyyqNt2H"&gt;Compressor Head videos&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=whGwm0Lky2s"&gt;(optional) Google Developers Live: GZIP is not enough!&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Computer Security&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh"&gt;MIT (23 videos)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=GqmQg-cszw4&amp;amp;index=1&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh"&gt;Introduction, Threat Models&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=6bwzNg5qQ0o&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh&amp;amp;index=2"&gt;Control Hijacking Attacks&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=drQyrzRoRiA&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh&amp;amp;index=3"&gt;Buffer Overflow Exploits and Defenses&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=6SIJmoE9L9g&amp;amp;index=4&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh"&gt;Privilege Separation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=8VqTSY-11F4&amp;amp;index=5&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh"&gt;Capabilities&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=VEV74hwASeU&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh&amp;amp;index=6"&gt;Sandboxing Native Code&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=chkFBigodIw&amp;amp;index=7&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh"&gt;Web Security Model&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=EBQIGy1ROLY&amp;amp;index=8&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh"&gt;Securing Web Applications&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=yRVZPvHYHzw&amp;amp;index=9&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh"&gt;Symbolic Execution&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=SIEVvk3NVuk&amp;amp;index=11&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh"&gt;Network Security&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=QOtA76ga_fY&amp;amp;index=12&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh"&gt;Network Protocols&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=PuVMkSEcPiI&amp;amp;index=15&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh"&gt;Side-Channel Attacks&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Garbage collection&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=iHVs_HkjdmI"&gt;GC in Python (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.infoq.com/presentations/garbage-collection-benefits"&gt;Deep Dive Java: Garbage Collection is Good!&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=P-8Z0-MhdQs&amp;amp;list=PLdzf4Clw0VbOEWOS_sLhT_9zaiQDrS5AR&amp;amp;index=3"&gt;Deep Dive Python: Garbage Collection in CPython (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Parallel Programming&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.coursera.org/learn/parprog1/home/week/1"&gt;Coursera (Scala)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=uY85GkaYzBk"&gt;Efficient Python for High-Performance Parallel Computing (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Messaging, Serialization, and Queueing Systems&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://thrift.apache.org/"&gt;Thrift&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="http://thrift-tutorial.readthedocs.io/en/latest/intro.html"&gt;Tutorial&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://developers.google.com/protocol-buffers/"&gt;Protocol Buffers&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://developers.google.com/protocol-buffers/docs/tutorials"&gt;Tutorials&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://www.grpc.io/"&gt;gRPC&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=5tmPvSe7xXQ&amp;amp;list=PLcTqM9n_dieN0k1nSeN36Z_ppKnvMJoly&amp;amp;index=1"&gt;gRPC 101 for Java Developers (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://redis.io/"&gt;Redis&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="http://try.redis.io/"&gt;Tutorial&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://aws.amazon.com/sqs/"&gt;Amazon SQS (queue)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://aws.amazon.com/sns/"&gt;Amazon SNS (pub-sub)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.rabbitmq.com/getstarted.html"&gt;Get Started&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://www.celeryproject.org/"&gt;Celery&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html"&gt;First Steps With Celery&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://zeromq.org/"&gt;ZeroMQ&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="http://zeromq.org/intro:read-the-manual"&gt;Intro - Read The Manual&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://activemq.apache.org/"&gt;ActiveMQ&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://kafka.apache.org/documentation.html#introduction"&gt;Kafka&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://msgpack.org/index.html"&gt;MessagePack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://avro.apache.org/"&gt;Avro&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;A*&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/A*_search_algorithm"&gt;A Search Algorithm&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=-L-WgKMFuhE"&gt;A* Pathfinding (E01: algorithm explanation) (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Fast Fourier Transform&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/"&gt;An Interactive Guide To The Fourier Transform&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://www.askamathematician.com/2012/09/q-what-is-a-fourier-transform-what-is-it-used-for/"&gt;What is a Fourier transform? What is it used for?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=Xxut2PN-V8Q"&gt;What is the Fourier Transform? (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=iTMn0Kt18tg&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&amp;amp;index=4"&gt;Divide &amp;amp; Conquer: FFT (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://jakevdp.github.io/blog/2013/08/28/understanding-the-fft/"&gt;Understanding The FFT&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Bloom Filter&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Given a Bloom filter with m bits and k hashing functions, both insertion and membership testing are O(k)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=-SuTGoFYjZs"&gt;Bloom Filters (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qBTdukbzc78"&gt;Bloom Filters | Mining of Massive Datasets | Stanford University (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://billmill.org/bloomfilter-tutorial/"&gt;Tutorial&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://blog.michaelschmatz.com/2016/04/11/how-to-write-a-bloom-filter-cpp/"&gt;How To Write A Bloom Filter App&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;HyperLogLog&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="http://highscalability.com/blog/2012/4/5/big-data-counting-how-to-count-a-billion-distinct-objects-us.html"&gt;How To Count A Billion Distinct Objects Using Only 1.5KB Of Memory&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Locality-Sensitive Hashing&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Used to determine the similarity of documents&lt;/li&gt; 
   &lt;li&gt;The opposite of MD5 or SHA which are used to determine if 2 documents/strings are exactly the same&lt;/li&gt; 
   &lt;li&gt;&lt;a href="http://ferd.ca/simhashing-hopefully-made-simple.html"&gt;Simhashing (hopefully) made simple&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;van Emde Boas Trees&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=hmReJCupbNU&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&amp;amp;index=6"&gt;Divide &amp;amp; Conquer: van Emde Boas Trees (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-design-and-analysis-of-algorithms-spring-2012/lecture-notes/MIT6_046JS12_lec15.pdf"&gt;MIT Lecture Notes&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Augmented Data Structures&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://archive.org/details/ucberkeley_webcast_zksIj9O8_jc"&gt;CS 61B Lecture 39: Augmenting Data Structures&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Balanced search trees&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Know at least one type of balanced binary tree (and know how it's implemented):&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;"Among balanced search trees, AVL and 2/3 trees are now pass√© and red-black trees seem to be more popular. A particularly interesting self-organizing data structure is the splay tree, which uses rotations to move any accessed key to the root." - Skiena&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Of these, I chose to implement a splay tree. From what I've read, you won't implement a balanced search tree in your interview. But I wanted exposure to coding one up and let's face it, splay trees are the bee's knees. I did read a lot of red-black tree code&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Splay tree: insert, search, delete functions If you end up implementing a red/black tree try just these:&lt;/li&gt; 
     &lt;li&gt;Search and insertion functions, skipping delete&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;I want to learn more about B-Tree since it's used so widely with very large data sets&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Self-balancing_binary_search_tree"&gt;Self-balancing binary search tree&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;AVL trees&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;In practice: From what I can tell, these aren't used much in practice, but I could see where they would be: The AVL tree is another structure supporting O(log n) search, insertion, and removal. It is more rigidly balanced than red‚Äìblack trees, leading to slower insertion and removal but faster retrieval. This makes it attractive for data structures that may be built once and loaded without reconstruction, such as language dictionaries (or program dictionaries, such as the opcodes of an assembler or interpreter)&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=FNeL18KsWPc&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb&amp;amp;index=6"&gt;MIT AVL Trees / AVL Sort (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures/lecture/Qq5E0/avl-trees"&gt;AVL Trees (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures/lecture/PKEBC/avl-tree-implementation"&gt;AVL Tree Implementation (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures/lecture/22BgE/split-and-merge"&gt;Split And Merge&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL9xmBV_5YoZOUFgdIeOPuH6cfSnNRMau-"&gt;[Review] AVL Trees (playlist) in 19 minutes (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Splay trees&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;In practice: Splay trees are typically used in the implementation of caches, memory allocators, routers, garbage collectors, data compression, ropes (replacement of string used for long text strings), in Windows NT (in the virtual memory, networking and file system code) etc&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://archive.org/details/ucberkeley_webcast_G5QIXywcJlY"&gt;CS 61B: Splay Trees (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;MIT Lecture: Splay Trees: 
      &lt;ul&gt; 
       &lt;li&gt;Gets very mathy, but watch the last 10 minutes for sure.&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=QnPl_Y6EqMo"&gt;Video&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Red/black trees&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;These are a translation of a 2-3 tree (see below).&lt;/li&gt; 
     &lt;li&gt;In practice: Red‚Äìblack trees offer worst-case guarantees for insertion time, deletion time, and search time. Not only does this make them valuable in time-sensitive applications such as real-time applications, but it makes them valuable building blocks in other data structures that provide worst-case guarantees; for example, many data structures used in computational geometry can be based on red-black trees, and the Completely Fair Scheduler used in current Linux kernels uses red‚Äìblack trees. In version 8 of Java, the Collection HashMap has been modified such that instead of using a LinkedList to store identical elements with poor hashcodes, a Red-Black tree is used&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://youtu.be/1W3x0f_RmUo?list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;t=3871"&gt;Aduni - Algorithms - Lecture 4 (link jumps to the starting point) (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=hm2GHwyKF1o&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;index=5"&gt;Aduni - Algorithms - Lecture 5 (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Red%E2%80%93black_tree"&gt;Red-Black Tree&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.topcoder.com/thrive/articles/An%20Introduction%20to%20Binary%20Search%20and%20Red-Black%20Trees"&gt;An Introduction To Binary Search And Red Black Tree&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL9xmBV_5YoZNqDI8qfOZgzbqahCUmUEin"&gt;[Review] Red-Black Trees (playlist) in 30 minutes (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;2-3 search trees&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;In practice: 2-3 trees have faster inserts at the expense of slower searches (since height is more compared to AVL trees).&lt;/li&gt; 
     &lt;li&gt;You would use 2-3 trees very rarely because its implementation involves different types of nodes. Instead, people use Red-Black trees.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=C3SsdUqasD4&amp;amp;list=PLA5Lqm4uh9Bbq-E0ZnqTIa8LRaL77ica6&amp;amp;index=2"&gt;23-Tree Intuition and Definition (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=iYvBtGKsqSg&amp;amp;index=3&amp;amp;list=PLA5Lqm4uh9Bbq-E0ZnqTIa8LRaL77ica6"&gt;Binary View of 23-Tree&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=TOb1tuEZ2X4&amp;amp;index=5&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp"&gt;2-3 Trees (student recitation) (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;2-3-4 Trees (aka 2-4 trees)&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;In practice: For every 2-4 trees, there are corresponding red‚Äìblack trees with data elements in the same order. The insertion and deletion operations on 2-4 trees are also equivalent to color-flipping and rotations in red‚Äìblack trees. This makes 2-4 trees an important tool for understanding the logic behind red-black trees, and this is why many introductory algorithm texts introduce 2-4 trees just before red‚Äìblack trees, even though &lt;strong&gt;2-4 trees are not often used in practice&lt;/strong&gt;.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://archive.org/details/ucberkeley_webcast_zqrqYXkth6Q"&gt;CS 61B Lecture 26: Balanced Search Trees (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=DQdMYevEyE4&amp;amp;index=4&amp;amp;list=PLA5Lqm4uh9Bbq-E0ZnqTIa8LRaL77ica6"&gt;Bottom Up 234-Trees (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=2679VQ26Fp4&amp;amp;list=PLA5Lqm4uh9Bbq-E0ZnqTIa8LRaL77ica6&amp;amp;index=5"&gt;Top Down 234-Trees (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;N-ary (K-ary, M-ary) trees&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;note: the N or K is the branching factor (max branches)&lt;/li&gt; 
     &lt;li&gt;binary trees are a 2-ary tree, with branching factor = 2&lt;/li&gt; 
     &lt;li&gt;2-3 trees are 3-ary&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/K-ary_tree"&gt;K-Ary Tree&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;B-Trees&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Fun fact: it's a mystery, but the B could stand for Boeing, Balanced, or Bayer (co-inventor).&lt;/li&gt; 
     &lt;li&gt;In Practice: B-trees are widely used in databases. Most modern filesystems use B-trees (or Variants). In addition to its use in databases, the B-tree is also used in filesystems to allow quick random access to an arbitrary block in a particular file. The basic problem is turning the file block address into a disk block (or perhaps to a cylinder head sector) address&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/B-tree"&gt;B-Tree&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://btechsmartclass.com/data_structures/b-trees.html"&gt;B-Tree Datastructure&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=I22wEC1tTGo&amp;amp;list=PLA5Lqm4uh9Bbq-E0ZnqTIa8LRaL77ica6&amp;amp;index=6"&gt;Introduction to B-Trees (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=s3bCdZGrgpA&amp;amp;index=7&amp;amp;list=PLA5Lqm4uh9Bbq-E0ZnqTIa8LRaL77ica6"&gt;B-Tree Definition and Insertion (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=svfnVhJOfMc&amp;amp;index=8&amp;amp;list=PLA5Lqm4uh9Bbq-E0ZnqTIa8LRaL77ica6"&gt;B-Tree Deletion (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=V3omVLzI0WE&amp;amp;index=7&amp;amp;list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf"&gt;MIT 6.851 - Memory Hierarchy Models (video)&lt;/a&gt; - covers cache-oblivious B-Trees, very interesting data structures - the first 37 minutes are very technical, and may be skipped (B is block size, cache line size)&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PL9xmBV_5YoZNFPPv98DjTdD9X6UI9KMHz"&gt;[Review] B-Trees (playlist) in 26 minutes (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;k-D Trees&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Great for finding a number of points in a rectangle or higher-dimensional object&lt;/li&gt; 
   &lt;li&gt;A good fit for k-nearest neighbors&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=Y4ZgLlDfKDg"&gt;kNN K-d tree algorithm (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Skip lists&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;"These are somewhat of a cult data structure" - Skiena&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=2g9OSRKJuzM&amp;amp;index=10&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp"&gt;Randomization: Skip Lists (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Skip_list"&gt;For animations and a little more detail&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Network Flows&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=Tl90tNtKvxs"&gt;Ford-Fulkerson in 5 minutes ‚Äî Step by step example (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=v1VgJmkEJW0"&gt;Ford-Fulkerson Algorithm (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=2vhN4Ice5jI"&gt;Network Flows (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Disjoint Sets &amp;amp; Union Find&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://archive.org/details/ucberkeley_webcast_MAEGXTwmUsI"&gt;UCB 61B - Disjoint Sets; Sorting &amp;amp; selection (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.coursera.org/learn/algorithms-part1/home/week/1"&gt;Sedgewick Algorithms - Union-Find (6 videos)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Math for Fast Processing&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=eCaXlAaN2uE&amp;amp;index=11&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb"&gt;Integer Arithmetic, Karatsuba Multiplication (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ru7mWZJlRQg"&gt;The Chinese Remainder Theorem (used in cryptography) (video)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Treap&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Combination of a binary search tree and a heap&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Treap"&gt;Treap&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=6podLUYinH8"&gt;Data Structures: Treaps explained (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.cs.cmu.edu/~scandal/papers/treaps-spaa98.pdf"&gt;Applications in set operations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Linear Programming (videos)&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=M4K6HYLHREQ"&gt;Linear Programming&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=2ACJ9ewUC6U"&gt;Finding minimum cost&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=8AA_81xI3ik"&gt;Finding maximum value&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=44pAWI7v5Zk"&gt;Solve Linear Equations with Python - Simplex Algorithm&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Geometry, Convex hull (videos)&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://youtu.be/XIAQRlNkJAw?list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;t=3164"&gt;Graph Alg. IV: Intro to geometric algorithms - Lecture 9&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=J5aJEcOr6Eo&amp;amp;index=10&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm"&gt;Geometric Algorithms: Graham &amp;amp; Jarvis - Lecture 10&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=EzeYI7p9MjU&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&amp;amp;index=2"&gt;Divide &amp;amp; Conquer: Convex Hull, Median Finding&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;h3&gt;Discrete math&lt;/h3&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="http://www.infocobuild.com/education/audio-video-courses/computer-science/cs70-spring2015-berkeley.html"&gt;Computer Science 70, 001 - Spring 2015 - Discrete Mathematics and Probability Theory&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLWX710qNZo_sNlSWRMVIh6kfTjolNaZ8t"&gt;Discrete Mathematics by Shai Simonson (19 videos)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://nptel.ac.in/courses/106/106/106106183/"&gt;Discrete Mathematics By IIT Ropar NPTEL&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Additional Detail on Some Subjects&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;I added these to reinforce some ideas already presented above, but didn't want to include them
above because it's just too much. It's easy to overdo it on a subject.
You want to get hired in this century, right?
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;SOLID&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;a href="https://www.youtube.com/watch?v=TMuno5RZNeE"&gt;Bob Martin SOLID Principles of Object Oriented and Agile Design (video)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; S - &lt;a href="http://www.oodesign.com/single-responsibility-principle.html"&gt;Single Responsibility Principle&lt;/a&gt; | &lt;a href="http://www.javacodegeeks.com/2011/11/solid-single-responsibility-principle.html"&gt;Single responsibility to each Object&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://docs.google.com/open?id=0ByOwmqah_nuGNHEtcU5OekdDMkk"&gt;more flavor&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; O - &lt;a href="http://www.oodesign.com/open-close-principle.html"&gt;Open/Closed Principle&lt;/a&gt; | &lt;a href="https://en.wikipedia.org/wiki/Open/closed_principle"&gt;On production level Objects are ready for extension but not for modification&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="http://docs.google.com/a/cleancoder.com/viewer?a=v&amp;amp;pid=explorer&amp;amp;chrome=true&amp;amp;srcid=0BwhCYaYDn8EgN2M5MTkwM2EtNWFkZC00ZTI3LWFjZTUtNTFhZGZiYmUzODc1&amp;amp;hl=en"&gt;more flavor&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; L - &lt;a href="http://www.oodesign.com/liskov-s-substitution-principle.html"&gt;Liskov Substitution Principle&lt;/a&gt; | &lt;a href="http://stackoverflow.com/questions/56860/what-is-the-liskov-substitution-principle"&gt;Base Class and Derived class follow ‚ÄòIS A‚Äô Principle&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="http://docs.google.com/a/cleancoder.com/viewer?a=v&amp;amp;pid=explorer&amp;amp;chrome=true&amp;amp;srcid=0BwhCYaYDn8EgNzAzZjA5ZmItNjU3NS00MzQ5LTkwYjMtMDJhNDU5ZTM0MTlh&amp;amp;hl=en"&gt;more flavor&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; I - &lt;a href="http://www.oodesign.com/interface-segregation-principle.html"&gt;Interface segregation principle&lt;/a&gt; | Clients should not be forced to implement interfaces they don't use 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=3CtAfl7aXAQ"&gt;Interface Segregation Principle in 5 minutes (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://docs.google.com/a/cleancoder.com/viewer?a=v&amp;amp;pid=explorer&amp;amp;chrome=true&amp;amp;srcid=0BwhCYaYDn8EgOTViYjJhYzMtMzYxMC00MzFjLWJjMzYtOGJiMDc5N2JkYmJi&amp;amp;hl=en"&gt;more flavor&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" disabled /&gt; D -&lt;a href="http://www.oodesign.com/dependency-inversion-principle.html"&gt;Dependency Inversion principle&lt;/a&gt; | Reduce the dependency In composition of objects. 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/62539/what-is-the-dependency-inversion-principle-and-why-is-it-important"&gt;Why Is The Dependency Inversion Principle And Why Is It Important&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="http://docs.google.com/a/cleancoder.com/viewer?a=v&amp;amp;pid=explorer&amp;amp;chrome=true&amp;amp;srcid=0BwhCYaYDn8EgMjdlMWIzNGUtZTQ0NC00ZjQ5LTkwYzQtZjRhMDRlNTQ3ZGMz&amp;amp;hl=en"&gt;more flavor&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Union-Find&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures/lecture/JssSY/overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures/lecture/EM5D0/naive-implementations"&gt;Naive Implementation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures/lecture/Mxu0w/trees"&gt;Trees&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures/lecture/qb4c2/union-by-rank"&gt;Union By Rank&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures/lecture/Q9CVI/path-compression"&gt;Path Compression&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures/lecture/GQQLN/analysis-optional"&gt;Analysis Options&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;More Dynamic Programming&lt;/strong&gt; (videos)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=r4-cftqTcdI&amp;amp;ab_channel=MITOpenCourseWare"&gt;6.006: Dynamic Programming I: Fibonacci, Shortest Paths&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=KLBCUx1is2c&amp;amp;ab_channel=MITOpenCourseWare"&gt;6.006: Dynamic Programming II: Text Justification, Blackjack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=TDo3r5M1LNo&amp;amp;ab_channel=MITOpenCourseWare"&gt;6.006: DP III: Parenthesization, Edit Distance, Knapsack&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=i9OAOk0CUQE&amp;amp;ab_channel=MITOpenCourseWare"&gt;6.006: DP IV: Guitar Fingering, Tetris, Super Mario Bros.&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=Tw1k46ywN6E&amp;amp;index=14&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp"&gt;6.046: Dynamic Programming &amp;amp; Advanced DP&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=NzgFUwOaoIw&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&amp;amp;index=15"&gt;6.046: Dynamic Programming: All-Pairs Shortest Paths&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=krZI60lKPek&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&amp;amp;index=12"&gt;6.046: Dynamic Programming (student recitation)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced Graph Processing&lt;/strong&gt; (videos)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=mUBmcbbJNf4&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&amp;amp;index=27"&gt;Synchronous Distributed Algorithms: Symmetry-Breaking. Shortest-Paths Spanning Trees&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=kQ-UQAzcnzA&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp&amp;amp;index=28"&gt;Asynchronous Distributed Algorithms: Shortest-Paths Spanning Trees&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MIT &lt;strong&gt;Probability&lt;/strong&gt; (mathy, and go slowly, which is good for mathy things) (videos):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=SmFwFdESMHI&amp;amp;index=18&amp;amp;list=PLB7540DEDD482705B"&gt;MIT 6.042J - Probability Introduction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=E6FbvM-FGZ8&amp;amp;index=19&amp;amp;list=PLB7540DEDD482705B"&gt;MIT 6.042J - Conditional Probability&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=l1BCv3qqW4A&amp;amp;index=20&amp;amp;list=PLB7540DEDD482705B"&gt;MIT 6.042J - Independence&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=MOfhhFaQdjw&amp;amp;list=PLB7540DEDD482705B&amp;amp;index=21"&gt;MIT 6.042J - Random Variables&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=gGlMSe7uEkA&amp;amp;index=22&amp;amp;list=PLB7540DEDD482705B"&gt;MIT 6.042J - Expectation I&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=oI9fMUqgfxY&amp;amp;index=23&amp;amp;list=PLB7540DEDD482705B"&gt;MIT 6.042J - Expectation II&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=q4mwO2qS2z4&amp;amp;index=24&amp;amp;list=PLB7540DEDD482705B"&gt;MIT 6.042J - Large Deviations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=56iFMY8QW2k&amp;amp;list=PLB7540DEDD482705B&amp;amp;index=25"&gt;MIT 6.042J - Random Walks&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=oDniZCmNmNw&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;index=19"&gt;Simonson: Approximation Algorithms (video)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;String Matching&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Rabin-Karp (videos): 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/lecture/data-structures/rabin-karps-algorithm-c0Qkw"&gt;Rabin Karps Algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures/lecture/nYrc8/optimization-precomputation"&gt;Precomputing&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.coursera.org/learn/data-structures/lecture/h4ZLc/optimization-implementation-and-analysis"&gt;Optimization: Implementation and Analysis&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=BRO7mVIFt08&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb&amp;amp;index=9"&gt;Table Doubling, Karp-Rabin&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=w6nuXg0BISo&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb&amp;amp;index=32"&gt;Rolling Hashes, Amortized Analysis&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Knuth-Morris-Pratt (KMP): 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=5i7oKodCRJo"&gt;TThe Knuth-Morris-Pratt (KMP) String Matching Algorithm&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Boyer‚ÄìMoore string search algorithm 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string_search_algorithm"&gt;Boyer-Moore String Search Algorithm&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=QDZpzctPf10"&gt;Advanced String Searching Boyer-Moore-Horspool Algorithms (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.coursera.org/learn/algorithms-on-strings/home/week/1"&gt;Coursera: Algorithms on Strings&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;starts off great, but by the time it gets past KMP it gets more complicated than it needs to be&lt;/li&gt; 
     &lt;li&gt;nice explanation of tries&lt;/li&gt; 
     &lt;li&gt;can be skipped&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Sorting&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Stanford lectures on sorting: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ENp00xylP7c&amp;amp;index=15&amp;amp;list=PLFE6E58F856038C69"&gt;Lecture 15 | Programming Abstractions (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=y4M9IVgrVKo&amp;amp;index=16&amp;amp;list=PLFE6E58F856038C69"&gt;Lecture 16 | Programming Abstractions (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Shai Simonson: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=odNJmw5TOEE&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;index=2"&gt;Algorithms - Sorting - Lecture 2 (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=hj8YKFTFKEE&amp;amp;list=PLFDnELG9dpVxQCxuD-9BSy2E7BWY3t5Sm&amp;amp;index=3"&gt;Algorithms - Sorting II - Lecture 3 (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Steven Skiena lectures on sorting: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=jUf-UQ3a0kg&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=8"&gt;CSE373 2020 - Mergesort/Quicksort (video)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=0ksyQKmre84&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=9"&gt;CSE373 2020 - Linear Sorting (video)&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;NAND To Tetris: &lt;a href="https://www.coursera.org/learn/build-a-computer"&gt;Build a Modern Computer from First Principles&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Video Series&lt;/h2&gt; 
&lt;p&gt;Sit back and enjoy.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PLrmLmBdmIlpsHaNTPP_jHHDx_os9ItYXr"&gt;List of individual Dynamic Programming problems (each is short)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PL038BE01D3BAEFDB0"&gt;x86 Architecture, Assembly, Applications (11 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8"&gt;MIT 18.06 Linear Algebra, Spring 2005 (35 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PL3B08AE665AB9002A"&gt;Excellent - MIT Calculus Revisited: Single Variable Calculus&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=22hwcnXIGgk&amp;amp;list=PLOtl7M3yp-DX6ic0HGT0PUX_wiNmkWkXx&amp;amp;index=1"&gt;Skiena lectures from Algorithm Design Manual - CSE373 2020 - Analysis of Algorithms (26 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://archive.org/details/ucberkeley-webcast-PL-XXv-cvA_iAlnI-BQr9hjqADPBtujFJd"&gt;UC Berkeley 61B (Spring 2014): Data Structures (25 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://archive.org/details/ucberkeley-webcast-PL4BBB74C7D2A1049C"&gt;UC Berkeley 61B (Fall 2006): Data Structures (39 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://archive.org/details/ucberkeley-webcast-PL-XXv-cvA_iCl2-D-FS5mk0jFF6cYSJs_"&gt;UC Berkeley 61C: Machine Structures (26 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PLJ9pm_Rc9HesnkwKlal_buSIHA-jTZMpO"&gt;OOSE: Software Dev Using UML and Java (21 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PLDSlqjcPpoL64CJdF0Qee5oWqGS6we_Yu"&gt;MIT 6.004: Computation Structures (49 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PL5PHm2jkkXmi5CxxI7b3JCL1TWybTDtKq"&gt;Carnegie Mellon - Computer Architecture Lectures (39 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=HtSuA80QTyo&amp;amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb&amp;amp;nohtml5=False"&gt;MIT 6.006: Intro to Algorithms (47 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=zm2VP0kHl1M&amp;amp;list=PL6535748F59DCA484"&gt;MIT 6.033: Computer System Engineering (22 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PLUl4u3cNGP63gFHB6xb-kVBiQHYe_4hSi"&gt;MIT 6.034 Artificial Intelligence, Fall 2010 (30 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=L3LMbpZIKhQ&amp;amp;list=PLB7540DEDD482705B"&gt;MIT 6.042J: Mathematics for Computer Science, Fall 2010 (25 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=2P-yW7LQr08&amp;amp;list=PLUl4u3cNGP6317WaSNfmCvGym2ucw3oGp"&gt;MIT 6.046: Design and Analysis of Algorithms (34 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=cQP8WApzIQQ&amp;amp;list=PLrw6a1wE39_tb2fErI4-WkMbsvGQk9_UB"&gt;MIT 6.824: Distributed Systems, Spring 2020 (20 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=T0yzrZL1py0&amp;amp;list=PLUl4u3cNGP61hsJNdULdudlRL493b-XZf&amp;amp;index=1"&gt;MIT 6.851: Advanced Data Structures (22 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PL6ogFv-ieghdoGKGg2Bik3Gl1glBTEu8c"&gt;MIT 6.854: Advanced Algorithms, Spring 2016 (24 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PL2SOU6wwxB0uP4rJgf5ayhHWgw7akUWSf"&gt;Harvard COMPSCI 224: Advanced Algorithms (25 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=GqmQg-cszw4&amp;amp;index=1&amp;amp;list=PLUl4u3cNGP62K2DjQLRxDNRi0z2IRWnNh"&gt;MIT 6.858 Computer Systems Security, Fall 2014&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PL9D558D49CA734A02"&gt;Stanford: Programming Paradigms (27 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PL6N5qY2nvvJE8X75VkXglSrVhLv1tVcfy"&gt;Introduction to Cryptography by Christof Paar&lt;/a&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="http://www.crypto-textbook.com/"&gt;Course Website along with Slides and Problem Sets&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/playlist?list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV"&gt;Mining Massive Datasets - Stanford University (94 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/user/DrSaradaHerke/playlists?shelf_id=5&amp;amp;view=50&amp;amp;sort=dd"&gt;Graph Theory by Sarada Herke (67 videos)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Computer Science Courses&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/open-source-society/computer-science"&gt;Directory of Online CS Courses&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/prakhar1989/awesome-courses"&gt;Directory of CS Courses (many with online lectures)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Algorithms implementation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://algs4.cs.princeton.edu/code"&gt;Multiple Algorithms implementation by Princeton University&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Papers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.cs.cmu.edu/~crary/819-f09/"&gt;Love classic papers?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://spinroot.com/courses/summer/Papers/hoare_1978.pdf"&gt;1978: Communicating Sequential Processes&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://godoc.org/github.com/thomas11/csp"&gt;implemented in Go&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf"&gt;2003: The Google File System&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;replaced by Colossus in 2012&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf"&gt;2004: MapReduce: Simplified Data Processing on Large Clusters&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;mostly replaced by Cloud Dataflow?&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf"&gt;2006: Bigtable: A Distributed Storage System for Structured Data&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://research.google.com/archive/chubby-osdi06.pdf"&gt;2006: The Chubby Lock Service for Loosely-Coupled Distributed Systems&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf"&gt;2007: Dynamo: Amazon‚Äôs Highly Available Key-value Store&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The Dynamo paper kicked off the NoSQL revolution&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.akkadia.org/drepper/cpumemory.pdf"&gt;2007: What Every Programmer Should Know About Memory (very long, and the author encourages skipping of some sections)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2012: AddressSanitizer: A Fast Address Sanity Checker: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37752.pdf"&gt;paper&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.usenix.org/conference/atc12/technical-sessions/presentation/serebryany"&gt;video&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;2013: Spanner: Google‚Äôs Globally-Distributed Database: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf"&gt;paper&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.usenix.org/node/170855"&gt;video&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43790.pdf"&gt;2015: Continuous Pipelines at Google&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44686.pdf"&gt;2015: High-Availability at Massive Scale: Building Google‚Äôs Data Infrastructure for Ads&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43835.pdf"&gt;2015: How Developers Search for Code: A Case Study&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;More papers: &lt;a href="https://github.com/0voice/computer_expert_paper"&gt;1,000 papers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/#table-of-contents"&gt;‚¨Ü back to top&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;LICENSE&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jwasham/coding-interview-university/main/LICENSE.txt"&gt;CC-BY-SA-4.0&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TEN-framework/ten-framework</title>
      <link>https://github.com/TEN-framework/ten-framework</link>
      <description>&lt;p&gt;Open-source framework for conversational voice AI agents.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a name="readme-top"&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/7c8f72d7-3993-4d01-8504-b71578a22944" alt="TEN banner" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/ten-framework/ten-framework?color=369eff&amp;amp;labelColor=gray&amp;amp;logo=github&amp;amp;style=flat-square" alt="TEN Releases" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/ten-framework/ten-framework?labelColor=gray&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/discussions/"&gt;&lt;img src="https://img.shields.io/github/discussions/TEN-framework/ten_framework?labelColor=gray&amp;amp;color=%20%23f79009" alt="Discussion posts" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/graphs/commit-activity"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/TEN-framework/ten_framework?labelColor=gray&amp;amp;color=pink" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/issues"&gt;&lt;img src="https://img.shields.io/github/issues-search?query=repo%3ATEN-framework%2Ften-framework%20is%3Aclosed&amp;amp;label=issues%20closed&amp;amp;labelColor=gray&amp;amp;color=green" alt="Issues closed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/ten-framework/ten-framework?color=c4f042&amp;amp;labelColor=gray&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/pulls"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome!-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten_framework/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0_with_certain_conditions-blue.svg?labelColor=%20%23155EEF&amp;amp;color=%20%23528bff" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/TEN-framework/TEN-framework"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://readmex.com/TEN-framework/ten-framework"&gt;&lt;img src="https://raw.githubusercontent.com/CodePhiliaX/resource-trusteeship/main/readmex.svg?sanitize=true" alt="ReadmeX" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://GitHub.com/TEN-framework/ten_framework/watchers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/watchers/TEN-framework/ten_framework?style=social&amp;amp;label=Watch" alt="GitHub watchers" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/TEN-framework/ten_framework/network/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/forks/TEN-framework/ten_framework?style=social&amp;amp;label=Fork" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/TEN-framework/ten_framework/stargazers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/stars/TEN-framework/ten_framework?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/README.md"&gt;&lt;img alt="README in English" src="https://img.shields.io/badge/English-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-CN.md"&gt;&lt;img alt="ÁÆÄ‰Ωì‰∏≠ÊñáÊìç‰ΩúÊåáÂçó" src="https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-JP.md"&gt;&lt;img alt="Êó•Êú¨Ë™û„ÅÆREADME" src="https://img.shields.io/badge/Êó•Êú¨Ë™û-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-KR.md"&gt;&lt;img alt="README in ÌïúÍµ≠Ïñ¥" src="https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-ES.md"&gt;&lt;img alt="README en Espa√±ol" src="https://img.shields.io/badge/Espa√±ol-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-FR.md"&gt;&lt;img alt="README en Fran√ßais" src="https://img.shields.io/badge/Fran√ßais-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-IT.md"&gt;&lt;img alt="README in Italiano" src="https://img.shields.io/badge/Italiano-lightgrey" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://theten.ai"&gt;Official Site&lt;/a&gt; ‚Ä¢ &lt;a href="https://theten.ai/docs/ten_agent/overview"&gt;Documentation&lt;/a&gt; ‚Ä¢ &lt;a href="https://theten.ai/blog"&gt;Blog&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11978" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11978" alt="TEN-framework%2Ften_framework | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Table of Contents&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;h4&gt;Table of Contents&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-welcome-to-ten"&gt;üëã Welcome to TEN&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-tman-designer"&gt;üé® TMAN Designer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-features"&gt;‚ú® Features&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#1%EF%B8%8F%E2%83%A3-real-time-avatar"&gt;1Ô∏è‚É£ Real-time Avatar&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#2%EF%B8%8F%E2%83%A3-real-time-voice-with-mcp-servers"&gt;2Ô∏è‚É£ Real-time voice with MCP servers&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#3%EF%B8%8F%E2%83%A3-real-time-communication-with-hardware"&gt;3Ô∏è‚É£ Real-time communication with hardware&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#4%EF%B8%8F%E2%83%A3-real-time-vision-and-real-time-screenshare-detection"&gt;4Ô∏è‚É£ Real-time vision and real-time screenshare detection&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#5%EF%B8%8F%E2%83%A3-ten-with-other-llm-platforms"&gt;5Ô∏è‚É£ TEN with other LLM platforms&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#6%EF%B8%8F%E2%83%A3-storyteller---ten-image-generation"&gt;6Ô∏è‚É£ StoryTeller - TEN image generation&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-get-ten-agent-up-and-running"&gt;üë©‚Äçüíª Get TEN Agent up and running&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B0%EF%B8%8F-run-ten-agent-in-localhost"&gt;üÖ∞Ô∏è Run TEN Agent in &lt;code&gt;localhost&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B1%EF%B8%8F-run-ten-agent-in-codespaceno-docker"&gt;üÖ±Ô∏è Run TEN Agent in Codespace(no docker)&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%EF%B8%8F-ten-agent-self-hosting"&gt;üõ≥Ô∏è TEN Agent Self Hosting&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B0%EF%B8%8F-deploying-with-docker"&gt;üÖ∞Ô∏è Deploying with Docker&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B1%EF%B8%8F-deploying-with-other-cloud-services"&gt;üÖ±Ô∏è Deploying with other cloud services&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-ten-ecosystem"&gt;üåç TEN Ecosystem&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-ask-questions"&gt;‚ùì Ask Questions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-contributing"&gt;ü•∞ Contributing&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#code-contributors"&gt;Code Contributors&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#contribution-guidelines"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;br /&gt; 
&lt;/details&gt; 
&lt;h2&gt;üëã Welcome to TEN&lt;/h2&gt; 
&lt;p&gt;TEN is a comprehensive open-source ecosystem for creating, customizing, and deploying real-time conversational AI agents with multimodal capabilities including voice, vision, and avatar interactions.&lt;/p&gt; 
&lt;p&gt;TEN includes &lt;a href="https://github.com/ten-framework/ten-framework"&gt;TEN Framework&lt;/a&gt;, &lt;a href="https://github.com/ten-framework/ten-turn-detection"&gt;TEN Turn Detection&lt;/a&gt;, &lt;a href="https://github.com/ten-framework/ten-vad"&gt;TEN VAD&lt;/a&gt;, &lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents/demo"&gt;TEN Agent&lt;/a&gt;, &lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/core/src/ten_manager/designer_frontend"&gt;TMAN Designer&lt;/a&gt;, and &lt;a href="https://github.com/ten-framework/portal"&gt;TEN Portal&lt;/a&gt;. Check out &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-ten-ecosystem"&gt;üåç TEN Ecosystem&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Community Channel&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://twitter.com/intent/follow?screen_name=TenFramework"&gt;&lt;img src="https://img.shields.io/twitter/follow/TenFramework?logo=X&amp;amp;color=%20%23f5f5f5" alt="Follow on X" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Follow TEN Framework on X for updates and announcements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/company/ten-framework"&gt;&lt;img src="https://custom-icon-badges.demolab.com/badge/LinkedIn-TEN_Framework-0A66C2?logo=linkedin-white&amp;amp;logoColor=fff" alt="Follow on LinkedIn" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Follow TEN Framework on LinkedIn for updates and announcements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/VnPftUzAMJ"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20TEN%20Community-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord TEN Community" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our Discord community to connect with developers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/TEN-framework"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-TEN%20Framework-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face Space" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our Hugging Face community to explore our spaces and models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-agent/discussions/170"&gt;&lt;img src="https://img.shields.io/badge/TEN_Framework-WeChat_Group-%2307C160?logo=wechat&amp;amp;labelColor=darkgreen&amp;amp;color=gray" alt="WeChat" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our WeChat group for Chinese community discussions&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Star TEN Repositories&lt;/strong&gt; ‚≠êÔ∏è&lt;/p&gt; 
 &lt;p&gt;Get instant notifications for new releases and updates. Your support helps us grow and improve TEN!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/eeebe996-8c14-4bf7-82ae-f1a1f7e30705" alt="TEN star us gif" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;picture&gt; 
  &lt;img width="100%" src="https://api.star-history.com/svg?repos=ten-framework/ten-framework&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; 
&lt;/details&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;üé® TMAN Designer&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/44c6a087-ec7a-45b0-a084-dab5dac5e36b"&gt;https://github.com/user-attachments/assets/44c6a087-ec7a-45b0-a084-dab5dac5e36b&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;TMAN Designer&lt;/h3&gt; 
&lt;p&gt;TMAN Designer is a low/no-code option to create voice agents with an easy-to-use workflow UI. It can load apps and graphs, and includes an online editor, log viewer, and much more.&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://theten.ai/blog/tman-designer-of-ten-framework"&gt;this blog&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/c6702995-de94-4d3e-8cae-af097f087ac1" alt="TEN Agent with Trulience" /&gt;&lt;/p&gt; 
&lt;h3&gt;1Ô∏è‚É£ Real-time Avatar&lt;/h3&gt; 
&lt;p&gt;Build engaging AI avatars with TEN Agent using &lt;a href="https://trulience.com"&gt;Trulience&lt;/a&gt;'s diverse collection of free avatar options. To get it up and running, you only need 2 steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Follow the README to finish setting up and running the Playground&lt;/li&gt; 
 &lt;li&gt;Enter the avatar ID and &lt;a href="https://trulience.com/docs#/authentication/jwt-tokens/jwt-tokens?id=use-your-custom-userid"&gt;token&lt;/a&gt; you get from &lt;a href="https://trulience.com"&gt;Trulience&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/afb77ad3-9c23-452f-b870-216687779017" alt="TEN with MCP servers" /&gt;&lt;/p&gt; 
&lt;h3&gt;2Ô∏è‚É£ Real-time voice with MCP servers&lt;/h3&gt; 
&lt;p&gt;TEN Agent now integrates seamlessly with MCP servers, expanding its LLM capabilities. To get started:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open the Module Picker in Playground&lt;/li&gt; 
 &lt;li&gt;Add the MCP server tool for LLM integration&lt;/li&gt; 
 &lt;li&gt;Paste a URL from your MCP server in the extension&lt;/li&gt; 
 &lt;li&gt;Start a realtime conversation with TEN Agent&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This integration allows you to leverage MCP's diverse servers offerings while maintaining TEN Agent's powerful conversational abilities.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/78647eef-2d66-44e6-99a8-1918a940fb9f"&gt;https://github.com/user-attachments/assets/78647eef-2d66-44e6-99a8-1918a940fb9f&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;3Ô∏è‚É£ Real-time communication with hardware&lt;/h3&gt; 
&lt;p&gt;TEN Agent is now running on the Espressif ESP32-S3 Korvo V3 development board, an excellent way to integrate realtime communication with LLM on hardware.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents/esp32-client"&gt;integration guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/a1addb02-a450-47be-8cb2-d25e3b574f53" alt="Real-time Vision" /&gt;&lt;/p&gt; 
&lt;h3&gt;4Ô∏è‚É£ Real-time vision and real-time screenshare detection&lt;/h3&gt; 
&lt;p&gt;Try Google Gemini Multimodal Live API with realtime vision and realtime screenshare detection capabilities, it is a ready-to-use extension, along with powerful tools like Weather Check and Web Search integrated perfectly into TEN Agent.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/234ff443-bef8-4cc4-9a10-09d6ec3f5bc1" alt="TEN with Dify" /&gt;&lt;/p&gt; 
&lt;h3&gt;5Ô∏è‚É£ TEN with other LLM platforms&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://theten.ai/docs/ten_agent/playground/use-cases/voice-assistant/run_dify#steps"&gt;TEN Agent + Dify&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;TEN offers a great support to make the realtime interactive experience even better on other LLM platform as well, check out docs for more.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/fe28a549-ddb9-431e-9282-57539fb87371" alt="TEN StoryTeller" /&gt;&lt;/p&gt; 
&lt;h3&gt;6Ô∏è‚É£ StoryTeller - TEN image generation&lt;/h3&gt; 
&lt;p&gt;Experience the real-time image generation with StoryTeller, it is a ready-to-use extension, along with powerful tools like Weather Check and Web Search integrated perfectly into TEN.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;üë©‚Äçüíª Get TEN Agent up and running&lt;/h2&gt; 
&lt;h4&gt;üÖ∞Ô∏è Run TEN Agent in localhost&lt;/h4&gt; 
&lt;h4&gt;Step ‚ìµ - Prerequisites&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Requirements&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Keys&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚Ä¢ Agora &lt;a href="https://docs.agora.io/en/video-calling/get-started/manage-agora-account?platform=web#create-an-agora-project"&gt;App ID&lt;/a&gt; and &lt;a href="https://docs.agora.io/en/video-calling/get-started/manage-agora-account?platform=web#create-an-agora-project"&gt;App Certificate&lt;/a&gt; (free minutes every month) &lt;br /&gt;‚Ä¢ &lt;a href="https://openai.com/index/openai-api/"&gt;OpenAI&lt;/a&gt; API key (any LLM that is compatible with OpenAI)&lt;br /&gt;‚Ä¢ &lt;a href="https://deepgram.com/"&gt;Deepgram&lt;/a&gt; ASR (free credits available with signup)&lt;br /&gt;‚Ä¢ &lt;a href="https://elevenlabs.io/"&gt;Elevenlabs&lt;/a&gt; TTS (free credits available with signup)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚Ä¢ &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; / &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;br /&gt;‚Ä¢ &lt;a href="https://nodejs.org/en"&gt;Node.js(LTS) v18&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Minimum System Requirements&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚Ä¢ CPU &amp;gt;= 2 Core&lt;br /&gt;‚Ä¢ RAM &amp;gt;= 4 GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;macOS: Docker setting on Apple Silicon&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Uncheck "Use Rosetta for x86/amd64 emulation" in Docker settings, it may result in slower build times on ARM, but performance will be normal when deployed to x64 servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h4&gt;Step ‚ì∂ - Build agent in VM&lt;/h4&gt; 
&lt;h5&gt;1. Clone down the repo,&lt;code&gt;cd&lt;/code&gt; to &lt;code&gt;ai-agents&lt;/code&gt; and create &lt;code&gt;.env&lt;/code&gt; file from &lt;code&gt;.env.example&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ai_agents
cp ./.env.example ./.env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;2. Setup Agora App ID and App Certificate in &lt;code&gt;.env&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;AGORA_APP_ID=
AGORA_APP_CERTIFICATE=
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;3. Start agent development containers&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;4. Enter container&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec -it ten_agent_dev bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;5. Build agent with the default &lt;code&gt;graph&lt;/code&gt; ( ~5min - ~8min)&lt;/h5&gt; 
&lt;p&gt;check the &lt;code&gt;/examples&lt;/code&gt; folder for more examples&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# use the chained voice assistant
task use AGENT=voice-assistant

# or use the speech-to-speech voice assistant realtime
task use AGENT=voice-assistant-realtime
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;6. Start the web server&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# run task build if you changed any local source code, this is necessary if you are working on languages which require compilation like TypeScript or Golang.
task build

task run
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;h4&gt;Step ‚ì∑ - Customize your agent with TMAN Designer&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:49483"&gt;localhost:49483&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Right-click on the STT, LLM, and TTS extensions.&lt;/li&gt; 
 &lt;li&gt;Open their properties and enter APIs respectively.&lt;/li&gt; 
 &lt;li&gt;Right-click the canvas and select 'Manage Apps' to open the Apps Manager.&lt;/li&gt; 
 &lt;li&gt;Right under the Actions, click the ‚ñ∂ to run the App.&lt;/li&gt; 
 &lt;li&gt;Check the 'Run with TEN Agent' option and click the Run button.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h3&gt;üÖ±Ô∏è Run TEN Agent in Codespace(no docker)&lt;/h3&gt; 
&lt;p&gt;GitHub offers free Codespace for each repository, you can run the playground in Codespace without using Docker.Also, the speed of Codespace is much faster than localhost.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/ten-framework/ten-agent"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://theten.ai/docs/ten_agent/setup_development_env/setting_up_development_inside_codespace"&gt;this guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;üõ≥Ô∏è TEN Agent Self Hosting&lt;/h2&gt; 
&lt;h4&gt;üÖ∞Ô∏è Deploying with Docker&lt;/h4&gt; 
&lt;p&gt;Once you have customized your agent (either by using the TMAN Manager, Playground, or editing &lt;code&gt;property.json&lt;/code&gt; directly), you can deploy it by creating a release Docker image for your service.&lt;/p&gt; 
&lt;p&gt;Read the &lt;a href="https://theten.ai/docs/ten_agent/deploy_ten_agent/deploy_agent_service"&gt;Deployment Guide&lt;/a&gt; for detailed information about deployment.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h4&gt;üÖ±Ô∏è Deploying with other cloud services&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;coming soon&lt;/em&gt;&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;üåç TEN Ecosystem&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Project&lt;/th&gt; 
   &lt;th&gt;Preview&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten_framework"&gt;&lt;strong&gt;üèöÔ∏è TEN Framework&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN is an open-source framework for real-time, multimodal conversational AI.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten_framework?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/7c8f72d7-3993-4d01-8504-b71578a22944" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-turn-detection"&gt;&lt;strong&gt;Ô∏èüîÇ TEN Turn Detection&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN is for full-duplex dialogue communication.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-turn-detection?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/8d0ec716-5d0e-43e4-ad9a-d97b17305658" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-vad"&gt;&lt;strong&gt;üîâ TEN VAD&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN VAD is a low-latency, lightweight and high-performance streaming voice activity detector (VAD).&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-vad?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/d45870e4-9453-4047-8163-08737f82863f" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents"&gt;&lt;strong&gt;üéôÔ∏è TEN Agent&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN Agent is a showcase of TEN Framewrok.&lt;br /&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/38de2207-939b-4702-a0aa-04491f5b5275" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/core/src/ten_manager/designer_frontend"&gt;&lt;strong&gt;üé® TMAN Designer&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TMAN Designer is low/no code option to make a voice agent with easy to use workflow UI.&lt;br /&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/804c3543-0a47-42b7-b40b-ef32b742fb8f" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/portal"&gt;&lt;strong&gt;üìí TEN Portal&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;The official site of TEN framework, it has documentation and blog.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/portal?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/e17d8aaa-5928-45dd-ac71-814928e26a89" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;‚ùì Ask Questions&lt;/h2&gt; 
&lt;p&gt;TEN Framework is available on these AI-powered Q&amp;amp;A platforms. They can help you find answers quickly and accurately in multiple languages, covering everything from basic setup to advanced implementation details.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepWiki&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://deepwiki.com/TEN-framework/TEN-framework"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ReadmeX&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://readmex.com/TEN-framework/ten-framework"&gt;&lt;img src="https://raw.githubusercontent.com/CodePhiliaX/resource-trusteeship/main/readmex.svg?sanitize=true" alt="ReadmeX" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ü•∞ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome all forms of open-source collaboration! Whether you're fixing bugs, adding features, improving documentation, or sharing ideas - your contributions help advance personalized AI tools. Check out our GitHub Issues and Projects to find ways to contribute and show your skills. Together, we can build something amazing!&lt;/p&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Welcome all kinds of contributions&lt;/strong&gt; üôè&lt;/p&gt; 
 &lt;p&gt;Join us in building TEN better! Every contribution makes a difference, from code to documentation. Share your TEN Agent projects on social media with to inspire others!&lt;/p&gt; 
 &lt;p&gt;Connect with one of the TEN maintainers &lt;a href="https://x.com/elliotchen100"&gt;@elliotchen100&lt;/a&gt; on ùïè or &lt;a href="https://github.com/cyfyifanchen"&gt;@cyfyifanchen&lt;/a&gt; on GitHub for project updates, discussions and collaboration opportunities.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h3&gt;Code Contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-agent/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=TEN-framework/ten-agent" alt="TEN" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Contribution Guidelines&lt;/h3&gt; 
&lt;p&gt;Contributions are welcome! Please read the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/docs/code-of-conduct/contributing.md"&gt;contribution guidelines&lt;/a&gt; first.&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;The entire TEN framework (except for the folders explicitly listed below) is released under the Apache License, Version 2.0, with additional restrictions. For details, please refer to the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/LICENSE"&gt;LICENSE&lt;/a&gt; file located in the root directory of the TEN framework.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The components within the &lt;code&gt;packages&lt;/code&gt; directory are released under the Apache License, Version 2.0. For details, please refer to the &lt;code&gt;LICENSE&lt;/code&gt; file located in each package's root directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The third-party libraries used by the TEN framework are listed and described in detail. For more information, please refer to the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/third_party/"&gt;third_party&lt;/a&gt; folder.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>unslothai/unsloth</title>
      <link>https://github.com/unslothai/unsloth</link>
      <description>&lt;p&gt;Fine-tuning &amp; Reinforcement Learning for LLMs. ü¶• Train OpenAI gpt-oss, Qwen3, Llama 4, DeepSeek-R1, Gemma 3, TTS 2x faster with 70% less VRAM.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://unsloth.ai"&gt;
   &lt;picture&gt; 
    &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20white%20text.png" /&gt; 
    &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png" /&gt; 
    &lt;img alt="unsloth logo" src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20logo%20black%20text.png" height="110" style="max-width: 100%;" /&gt; 
   &lt;/picture&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-Alpaca.ipynb"&gt;&lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/start free finetune button.png" width="154" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/unsloth"&gt;&lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord button.png" width="165" /&gt;&lt;/a&gt; &lt;a href="https://docs.unsloth.ai"&gt;&lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/refs/heads/main/images/Documentation%20Button.png" width="137" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;Finetune gpt-oss, Gemma 3n, Qwen3, Llama 4, &amp;amp; Mistral 2x faster with 80% less VRAM!&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://i.ibb.co/sJ7RhGG/image-41.png" alt="" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ú® Finetune for Free&lt;/h2&gt; 
&lt;p&gt;Notebooks are beginner friendly. Read our &lt;a href="https://docs.unsloth.ai/get-started/fine-tuning-guide"&gt;guide&lt;/a&gt;. Add your dataset, click "Run All", and export your finetuned model to GGUF, Ollama, vLLM or Hugging Face.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Unsloth supports&lt;/th&gt; 
   &lt;th&gt;Free Notebooks&lt;/th&gt; 
   &lt;th&gt;Performance&lt;/th&gt; 
   &lt;th&gt;Memory use&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;gpt-oss (20B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-Fine-tuning.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;70% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Gemma 3n (4B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Conversational.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;50% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Qwen3 (14B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(14B)-Reasoning-Conversational.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;70% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Qwen3 (4B): GRPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-GRPO.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;80% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Qwen2.5-VL (7B): GSPO&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_5_7B_VL_GRPO.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;80% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Phi-4 (14B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4-Conversational.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;70% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Llama 3.2 Vision (11B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;50% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Llama 3.1 (8B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-Alpaca.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2x faster&lt;/td&gt; 
   &lt;td&gt;70% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Mistral v0.3 (7B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_(7B)-Conversational.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;2.2x faster&lt;/td&gt; 
   &lt;td&gt;75% less&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Orpheus-TTS (3B)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Orpheus_(3B)-TTS.ipynb"&gt;‚ñ∂Ô∏è Start for free&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.5x faster&lt;/td&gt; 
   &lt;td&gt;50% less&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;See all our notebooks for: &lt;a href="https://github.com/unslothai/notebooks?tab=readme-ov-file#-kaggle-notebooks"&gt;Kaggle&lt;/a&gt;, &lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#grpo-reasoning-rl-notebooks"&gt;GRPO&lt;/a&gt;, &lt;strong&gt;&lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#text-to-speech-tts-notebooks"&gt;TTS&lt;/a&gt;&lt;/strong&gt; &amp;amp; &lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#vision-multimodal-notebooks"&gt;Vision&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://docs.unsloth.ai/get-started/all-our-models"&gt;all our models&lt;/a&gt; and &lt;a href="https://github.com/unslothai/notebooks"&gt;all our notebooks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See detailed documentation for Unsloth &lt;a href="https://docs.unsloth.ai/"&gt;here&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ö° Quickstart&lt;/h2&gt; 
&lt;h3&gt;Linux or WSL&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;For Windows, &lt;code&gt;pip install unsloth&lt;/code&gt; works only if you have Pytorch installed. For more info, read our &lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating/windows-installation"&gt;Windows Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;Use our official &lt;a href="https://hub.docker.com/r/unsloth/unsloth"&gt;Unsloth Docker image&lt;/a&gt; &lt;code&gt;unsloth/unsloth&lt;/code&gt; container. Read our &lt;a href="https://docs.unsloth.ai/get-started/install-and-update/docker"&gt;Docker Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Blackwell&lt;/h3&gt; 
&lt;p&gt;For RTX 50x, B200, 6000 GPUs, simply do &lt;code&gt;pip install unsloth&lt;/code&gt;. Read our &lt;a href="https://docs.unsloth.ai/basics/training-llms-with-blackwell-rtx-50-series-and-unsloth"&gt;Blackwell Guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;ü¶• Unsloth.ai News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üì£ &lt;strong&gt;Vision RL&lt;/strong&gt; You can now train VLMs with GRPO or GSPO in Unsloth! &lt;a href="https://docs.unsloth.ai/new/vision-reinforcement-learning-vlm-rl"&gt;Read guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üì£ &lt;strong&gt;Memory-efficient RL&lt;/strong&gt; We're introducing even better RL. Our new kernels &amp;amp; algos allows faster RL with 50% less VRAM &amp;amp; 10√ó more context. &lt;a href="https://docs.unsloth.ai/new/memory-efficient-rl"&gt;Read blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üì£ &lt;strong&gt;gpt-oss&lt;/strong&gt; by OpenAI: For details on &lt;a href="https://docs.unsloth.ai/new/long-context-gpt-oss-training"&gt;Unsloth Flex Attention&lt;/a&gt;, long-context training, bug fixes, &lt;a href="https://docs.unsloth.ai/basics/gpt-oss"&gt;Read our Guide&lt;/a&gt;. 20B works on a 14GB GPU and 120B on 65GB VRAM. &lt;a href="https://huggingface.co/collections/unsloth/gpt-oss-6892433695ce0dee42f31681"&gt;gpt-oss uploads&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üì£ &lt;strong&gt;Gemma 3n&lt;/strong&gt; by Google: &lt;a href="https://docs.unsloth.ai/basics/gemma-3n-how-to-run-and-fine-tune"&gt;Read Blog&lt;/a&gt;. We &lt;a href="https://huggingface.co/collections/unsloth/gemma-3n-685d3874830e49e1c93f9339"&gt;uploaded GGUFs, 4-bit models&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üì£ &lt;strong&gt;&lt;a href="https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning"&gt;Text-to-Speech (TTS)&lt;/a&gt;&lt;/strong&gt; is now supported, including &lt;code&gt;sesame/csm-1b&lt;/code&gt; and STT &lt;code&gt;openai/whisper-large-v3&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;üì£ &lt;strong&gt;&lt;a href="https://docs.unsloth.ai/basics/qwen3-how-to-run-and-fine-tune"&gt;Qwen3&lt;/a&gt;&lt;/strong&gt; is now supported. Qwen3-30B-A3B fits on 17.5GB VRAM.&lt;/li&gt; 
 &lt;li&gt;üì£ Introducing &lt;strong&gt;&lt;a href="https://docs.unsloth.ai/basics/unsloth-dynamic-2.0-ggufs"&gt;Dynamic 2.0&lt;/a&gt;&lt;/strong&gt; quants that set new benchmarks on 5-shot MMLU &amp;amp; KL Divergence.&lt;/li&gt; 
 &lt;li&gt;üì£ &lt;a href="https://unsloth.ai/blog/gemma3#everything"&gt;&lt;strong&gt;EVERYTHING&lt;/strong&gt; is now supported&lt;/a&gt; - all models (BERT, diffusion, Cohere, Mamba), FFT, etc. MultiGPU coming soon. Enable FFT with &lt;code&gt;full_finetuning = True&lt;/code&gt;, 8-bit with &lt;code&gt;load_in_8bit = True&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click for more news&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;üì£ &lt;a href="https://unsloth.ai/blog/deepseek-r1"&gt;DeepSeek-R1&lt;/a&gt; - run or fine-tune them &lt;a href="https://unsloth.ai/blog/deepseek-r1"&gt;with our guide&lt;/a&gt;. All model uploads: &lt;a href="https://huggingface.co/collections/unsloth/deepseek-r1-all-versions-678e1c48f5d2fce87892ace5"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;üì£ Introducing Long-context &lt;a href="https://unsloth.ai/blog/grpo"&gt;Reasoning (GRPO)&lt;/a&gt; in Unsloth. Train your own reasoning model with just 5GB VRAM. Transform Llama, Phi, Mistral etc. into reasoning LLMs!&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;üì£ Introducing Unsloth &lt;a href="https://unsloth.ai/blog/dynamic-4bit"&gt;Dynamic 4-bit Quantization&lt;/a&gt;! We dynamically opt not to quantize certain parameters and this greatly increases accuracy while only using &amp;lt;10% more VRAM than BnB 4-bit. See our collection on &lt;a href="https://huggingface.co/collections/unsloth/unsloth-4-bit-dynamic-quants-67503bb873f89e15276c44e7"&gt;Hugging Face here.&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;üì£ &lt;strong&gt;&lt;a href="https://unsloth.ai/blog/llama4"&gt;Llama 4&lt;/a&gt;&lt;/strong&gt; by Meta, including Scout &amp;amp; Maverick are now supported.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;üì£ &lt;a href="https://unsloth.ai/blog/phi4"&gt;Phi-4&lt;/a&gt; by Microsoft: We also &lt;a href="https://unsloth.ai/blog/phi4"&gt;fixed bugs&lt;/a&gt; in Phi-4 and &lt;a href="https://huggingface.co/collections/unsloth/phi-4-all-versions-677eecf93784e61afe762afa"&gt;uploaded GGUFs, 4-bit&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;üì£ &lt;a href="https://unsloth.ai/blog/vision"&gt;Vision models&lt;/a&gt; now supported! &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb"&gt;Llama 3.2 Vision (11B)&lt;/a&gt;, &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2_VL_(7B)-Vision.ipynb"&gt;Qwen 2.5 VL (7B)&lt;/a&gt; and &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Pixtral_(12B)-Vision.ipynb"&gt;Pixtral (12B) 2409&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;üì£ &lt;a href="https://huggingface.co/collections/unsloth/llama-33-all-versions-67535d7d994794b9d7cf5e9f"&gt;Llama 3.3 (70B)&lt;/a&gt;, Meta's latest model is supported.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;üì£ We worked with Apple to add &lt;a href="https://arxiv.org/abs/2411.09009"&gt;Cut Cross Entropy&lt;/a&gt;. Unsloth now supports 89K context for Meta's Llama 3.3 (70B) on a 80GB GPU - 13x longer than HF+FA2. For Llama 3.1 (8B), Unsloth enables 342K context, surpassing its native 128K support.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;üì£ We found and helped fix a &lt;a href="https://unsloth.ai/blog/gradient"&gt;gradient accumulation bug&lt;/a&gt;! Please update Unsloth and transformers.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;üì£ We cut memory usage by a &lt;a href="https://unsloth.ai/blog/long-context"&gt;further 30%&lt;/a&gt; and now support &lt;a href="https://unsloth.ai/blog/long-context"&gt;4x longer context windows&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üîó Links and Resources&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Links&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üìö &lt;strong&gt;Documentation &amp;amp; Wiki&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.unsloth.ai"&gt;Read Our Docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img width="16" src="https://upload.wikimedia.org/wikipedia/commons/6/6f/Logo_of_Twitter.svg?sanitize=true" /&gt;&amp;nbsp; &lt;strong&gt;Twitter (aka X)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://twitter.com/unslothai"&gt;Follow us on X&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üíæ &lt;strong&gt;Installation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating"&gt;Pip install&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;üîÆ &lt;strong&gt;Our Models&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.unsloth.ai/get-started/all-our-models"&gt;Unsloth Releases&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚úçÔ∏è &lt;strong&gt;Blog&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://unsloth.ai/blog"&gt;Read our Blogs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img width="15" src="https://redditinc.com/hs-fs/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png" /&gt;&amp;nbsp; &lt;strong&gt;Reddit&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://reddit.com/r/unsloth"&gt;Join our Reddit&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚≠ê Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports &lt;strong&gt;full-finetuning&lt;/strong&gt;, pretraining, 4b-bit, 16-bit and &lt;strong&gt;8-bit&lt;/strong&gt; training&lt;/li&gt; 
 &lt;li&gt;Supports &lt;strong&gt;all transformer-style models&lt;/strong&gt; including &lt;a href="https://docs.unsloth.ai/basics/text-to-speech-tts-fine-tuning"&gt;TTS, STT&lt;/a&gt;, multimodal, diffusion, &lt;a href="https://docs.unsloth.ai/get-started/unsloth-notebooks#other-important-notebooks"&gt;BERT&lt;/a&gt; and more!&lt;/li&gt; 
 &lt;li&gt;All kernels written in &lt;a href="https://openai.com/index/triton/"&gt;OpenAI's Triton&lt;/a&gt; language. &lt;strong&gt;Manual backprop engine&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;0% loss in accuracy&lt;/strong&gt; - no approximation methods - all exact.&lt;/li&gt; 
 &lt;li&gt;No change of hardware. Supports NVIDIA GPUs since 2018+. Minimum CUDA Capability 7.0 (V100, T4, Titan V, RTX 20, 30, 40x, A100, H100, L40 etc) &lt;a href="https://developer.nvidia.com/cuda-gpus"&gt;Check your GPU!&lt;/a&gt; GTX 1070, 1080 works, but is slow.&lt;/li&gt; 
 &lt;li&gt;Works on &lt;strong&gt;Linux&lt;/strong&gt; and &lt;strong&gt;Windows&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;If you trained a model with ü¶•Unsloth, you can use this cool sticker! &amp;nbsp; &lt;img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/made with unsloth.png" width="200" align="center" /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíæ Install Unsloth&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!warning] Python 3.14 does not support Unsloth. Use 3.13 or lower.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You can also see our documentation for more detailed installation and updating instructions &lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Pip Installation&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Install with pip (recommended) for Linux devices:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;To update Unsloth:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install --upgrade --force-reinstall --no-cache-dir unsloth unsloth_zoo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://github.com/unslothai/unsloth/edit/main/README.md#advanced-pip-installation"&gt;here&lt;/a&gt; for advanced pip install instructions.&lt;/p&gt; 
&lt;h3&gt;Windows Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install NVIDIA Video Driver:&lt;/strong&gt; You should install the latest version of your GPUs driver. Download drivers here: &lt;a href="https://www.nvidia.com/Download/index.aspx"&gt;NVIDIA GPU Drive&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install Visual Studio C++:&lt;/strong&gt; You will need Visual Studio, with C++ installed. By default, C++ is not installed with &lt;a href="https://visualstudio.microsoft.com/vs/community/"&gt;Visual Studio&lt;/a&gt;, so make sure you select all of the C++ options. Also select options for Windows 10/11 SDK. For detailed instructions with options, see &lt;a href="https://docs.unsloth.ai/get-started/installing-+-updating"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install CUDA Toolkit:&lt;/strong&gt; Follow the instructions to install &lt;a href="https://developer.nvidia.com/cuda-toolkit-archive"&gt;CUDA Toolkit&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install PyTorch:&lt;/strong&gt; You will need the correct version of PyTorch that is compatible with your CUDA drivers, so make sure to select them carefully. &lt;a href="https://pytorch.org/get-started/locally/"&gt;Install PyTorch&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install Unsloth:&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Notes&lt;/h4&gt; 
&lt;p&gt;To run Unsloth directly on Windows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install Triton from this Windows fork and follow the instructions &lt;a href="https://github.com/woct0rdho/triton-windows"&gt;here&lt;/a&gt; (be aware that the Windows fork requires PyTorch &amp;gt;= 2.4 and CUDA 12)&lt;/li&gt; 
 &lt;li&gt;In the &lt;code&gt;SFTConfig&lt;/code&gt;, set &lt;code&gt;dataset_num_proc=1&lt;/code&gt; to avoid a crashing issue:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;SFTConfig(
    dataset_num_proc=1,
    ...
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Advanced/Troubleshooting&lt;/h4&gt; 
&lt;p&gt;For &lt;strong&gt;advanced installation instructions&lt;/strong&gt; or if you see weird errors during installations:&lt;/p&gt; 
&lt;p&gt;First try using an isolated environment via then &lt;code&gt;pip install unsloth&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv unsloth
source unsloth/bin/activate
pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install &lt;code&gt;torch&lt;/code&gt; and &lt;code&gt;triton&lt;/code&gt;. Go to &lt;a href="https://pytorch.org"&gt;https://pytorch.org&lt;/a&gt; to install it. For example &lt;code&gt;pip install torch torchvision torchaudio triton&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Confirm if CUDA is installed correctly. Try &lt;code&gt;nvcc&lt;/code&gt;. If that fails, you need to install &lt;code&gt;cudatoolkit&lt;/code&gt; or CUDA drivers.&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;xformers&lt;/code&gt; manually via:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install ninja
pip install -v --no-build-isolation -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;Check if `xformers` succeeded with `python -m xformers.info` Go to https://github.com/facebookresearch/xformers. Another option is to install `flash-attn` for Ampere GPUs and ignore `xformers`
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;For GRPO runs, you can try installing &lt;code&gt;vllm&lt;/code&gt; and seeing if &lt;code&gt;pip install vllm&lt;/code&gt; succeeds.&lt;/li&gt; 
 &lt;li&gt;Double check that your versions of Python, CUDA, CUDNN, &lt;code&gt;torch&lt;/code&gt;, &lt;code&gt;triton&lt;/code&gt;, and &lt;code&gt;xformers&lt;/code&gt; are compatible with one another. The &lt;a href="https://github.com/pytorch/pytorch/raw/main/RELEASE.md#release-compatibility-matrix"&gt;PyTorch Compatibility Matrix&lt;/a&gt; may be useful.&lt;/li&gt; 
 &lt;li&gt;Finally, install &lt;code&gt;bitsandbytes&lt;/code&gt; and check it with &lt;code&gt;python -m bitsandbytes&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Conda Installation (Optional)&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;‚ö†Ô∏èOnly use Conda if you have it. If not, use Pip&lt;/code&gt;. Select either &lt;code&gt;pytorch-cuda=11.8,12.1&lt;/code&gt; for CUDA 11.8 or CUDA 12.1. We support &lt;code&gt;python=3.10,3.11,3.12&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create --name unsloth_env \
    python=3.11 \
    pytorch-cuda=12.1 \
    pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers \
    -y
conda activate unsloth_env

pip install unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;If you're looking to install Conda in a Linux environment, &lt;a href="https://docs.anaconda.com/miniconda/"&gt;read here&lt;/a&gt;, or run the below üîΩ&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash
~/miniconda3/bin/conda init zsh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Advanced Pip Installation&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;‚ö†Ô∏èDo **NOT** use this if you have Conda.&lt;/code&gt; Pip is a bit more complex since there are dependency issues. The pip command is different for &lt;code&gt;torch 2.2,2.3,2.4,2.5&lt;/code&gt; and CUDA versions.&lt;/p&gt; 
&lt;p&gt;For other torch versions, we support &lt;code&gt;torch211&lt;/code&gt;, &lt;code&gt;torch212&lt;/code&gt;, &lt;code&gt;torch220&lt;/code&gt;, &lt;code&gt;torch230&lt;/code&gt;, &lt;code&gt;torch240&lt;/code&gt; and for CUDA versions, we support &lt;code&gt;cu118&lt;/code&gt; and &lt;code&gt;cu121&lt;/code&gt; and &lt;code&gt;cu124&lt;/code&gt;. For Ampere devices (A100, H100, RTX3090) and above, use &lt;code&gt;cu118-ampere&lt;/code&gt; or &lt;code&gt;cu121-ampere&lt;/code&gt; or &lt;code&gt;cu124-ampere&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, if you have &lt;code&gt;torch 2.4&lt;/code&gt; and &lt;code&gt;CUDA 12.1&lt;/code&gt;, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade pip
pip install "unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Another example, if you have &lt;code&gt;torch 2.5&lt;/code&gt; and &lt;code&gt;CUDA 12.4&lt;/code&gt;, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade pip
pip install "unsloth[cu124-torch250] @ git+https://github.com/unslothai/unsloth.git"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And other examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "unsloth[cu121-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu118-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu118-torch240] @ git+https://github.com/unslothai/unsloth.git"

pip install "unsloth[cu121-torch230] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu121-ampere-torch230] @ git+https://github.com/unslothai/unsloth.git"

pip install "unsloth[cu121-torch250] @ git+https://github.com/unslothai/unsloth.git"
pip install "unsloth[cu124-ampere-torch250] @ git+https://github.com/unslothai/unsloth.git"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, run the below in a terminal to get the &lt;strong&gt;optimal&lt;/strong&gt; pip installation command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget -qO- https://raw.githubusercontent.com/unslothai/unsloth/main/unsloth/_auto_install.py | python -
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, run the below manually in a Python REPL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;try: import torch
except: raise ImportError('Install torch via `pip install torch`')
from packaging.version import Version as V
import re
v = V(re.match(r"[0-9\.]{3,}", torch.__version__).group(0))
cuda = str(torch.version.cuda)
is_ampere = torch.cuda.get_device_capability()[0] &amp;gt;= 8
USE_ABI = torch._C._GLIBCXX_USE_CXX11_ABI
if cuda not in ("11.8", "12.1", "12.4", "12.6", "12.8"): raise RuntimeError(f"CUDA = {cuda} not supported!")
if   v &amp;lt;= V('2.1.0'): raise RuntimeError(f"Torch = {v} too old!")
elif v &amp;lt;= V('2.1.1'): x = 'cu{}{}-torch211'
elif v &amp;lt;= V('2.1.2'): x = 'cu{}{}-torch212'
elif v  &amp;lt; V('2.3.0'): x = 'cu{}{}-torch220'
elif v  &amp;lt; V('2.4.0'): x = 'cu{}{}-torch230'
elif v  &amp;lt; V('2.5.0'): x = 'cu{}{}-torch240'
elif v  &amp;lt; V('2.5.1'): x = 'cu{}{}-torch250'
elif v &amp;lt;= V('2.5.1'): x = 'cu{}{}-torch251'
elif v  &amp;lt; V('2.7.0'): x = 'cu{}{}-torch260'
elif v  &amp;lt; V('2.7.9'): x = 'cu{}{}-torch270'
elif v  &amp;lt; V('2.8.0'): x = 'cu{}{}-torch271'
elif v  &amp;lt; V('2.8.9'): x = 'cu{}{}-torch280'
else: raise RuntimeError(f"Torch = {v} too new!")
if v &amp;gt; V('2.6.9') and cuda not in ("11.8", "12.6", "12.8"): raise RuntimeError(f"CUDA = {cuda} not supported!")
x = x.format(cuda.replace(".", ""), "-ampere" if is_ampere else "")
print(f'pip install --upgrade pip &amp;amp;&amp;amp; pip install "unsloth[{x}] @ git+https://github.com/unslothai/unsloth.git"')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Installation&lt;/h3&gt; 
&lt;p&gt;You can use our pre-built Docker container with all dependencies to use Unsloth instantly with no setup required. &lt;a href="https://docs.unsloth.ai/get-started/install-and-update/docker"&gt;Read our guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;This container requires installing &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html"&gt;NVIDIA's Container Toolkit&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -e JUPYTER_PASSWORD="mypassword" \
  -p 8888:8888 -p 2222:22 \
  -v $(pwd)/work:/workspace/work \
  --gpus all \
  unsloth/unsloth
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access Jupyter Lab at &lt;code&gt;http://localhost:8888&lt;/code&gt; and start fine-tuning!&lt;/p&gt; 
&lt;h2&gt;üìú Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to our official &lt;a href="https://docs.unsloth.ai"&gt;Documentation&lt;/a&gt; for saving to GGUF, checkpointing, evaluation and more!&lt;/li&gt; 
 &lt;li&gt;We support Huggingface's TRL, Trainer, Seq2SeqTrainer or even Pytorch code!&lt;/li&gt; 
 &lt;li&gt;We're in ü§óHugging Face's official docs! Check out the &lt;a href="https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth"&gt;SFT docs&lt;/a&gt; and &lt;a href="https://huggingface.co/docs/trl/main/en/dpo_trainer#accelerate-dpo-fine-tuning-using-unsloth"&gt;DPO docs&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;If you want to download models from the ModelScope community, please use an environment variable: &lt;code&gt;UNSLOTH_USE_MODELSCOPE=1&lt;/code&gt;, and install the modelscope library by: &lt;code&gt;pip install modelscope -U&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;unsloth_cli.py also supports &lt;code&gt;UNSLOTH_USE_MODELSCOPE=1&lt;/code&gt; to download models and datasets. please remember to use the model and dataset id in the ModelScope community.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from unsloth import FastLanguageModel, FastModel
import torch
from trl import SFTTrainer, SFTConfig
from datasets import load_dataset
max_seq_length = 2048 # Supports RoPE Scaling internally, so choose any!
# Get LAION dataset
url = "https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl"
dataset = load_dataset("json", data_files = {"train" : url}, split = "train")

# 4bit pre quantized models we support for 4x faster downloading + no OOMs.
fourbit_models = [
    "unsloth/Meta-Llama-3.1-8B-bnb-4bit",      # Llama-3.1 2x faster
    "unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
    "unsloth/Meta-Llama-3.1-70B-bnb-4bit",
    "unsloth/Meta-Llama-3.1-405B-bnb-4bit",    # 4bit for 405b!
    "unsloth/Mistral-Small-Instruct-2409",     # Mistral 22b 2x faster!
    "unsloth/mistral-7b-instruct-v0.3-bnb-4bit",
    "unsloth/Phi-3.5-mini-instruct",           # Phi-3.5 2x faster!
    "unsloth/Phi-3-medium-4k-instruct",
    "unsloth/gemma-2-9b-bnb-4bit",
    "unsloth/gemma-2-27b-bnb-4bit",            # Gemma 2x faster!

    "unsloth/Llama-3.2-1B-bnb-4bit",           # NEW! Llama 3.2 models
    "unsloth/Llama-3.2-1B-Instruct-bnb-4bit",
    "unsloth/Llama-3.2-3B-bnb-4bit",
    "unsloth/Llama-3.2-3B-Instruct-bnb-4bit",

    "unsloth/Llama-3.3-70B-Instruct-bnb-4bit" # NEW! Llama 3.3 70B!
] # More models at https://huggingface.co/unsloth

model, tokenizer = FastModel.from_pretrained(
    model_name = "unsloth/gemma-3-4B-it",
    max_seq_length = 2048, # Choose any for long context!
    load_in_4bit = True,  # 4 bit quantization to reduce memory
    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory
    full_finetuning = False, # [NEW!] We have full finetuning now!
    # token = "hf_...", # use one if using gated models
)

# Do model patching and add fast LoRA weights
model = FastLanguageModel.get_peft_model(
    model,
    r = 16,
    target_modules = ["q_proj", "k_proj", "v_proj", "o_proj",
                      "gate_proj", "up_proj", "down_proj",],
    lora_alpha = 16,
    lora_dropout = 0, # Supports any, but = 0 is optimized
    bias = "none",    # Supports any, but = "none" is optimized
    # [NEW] "unsloth" uses 30% less VRAM, fits 2x larger batch sizes!
    use_gradient_checkpointing = "unsloth", # True or "unsloth" for very long context
    random_state = 3407,
    max_seq_length = max_seq_length,
    use_rslora = False,  # We support rank stabilized LoRA
    loftq_config = None, # And LoftQ
)

trainer = SFTTrainer(
    model = model,
    train_dataset = dataset,
    tokenizer = tokenizer,
    args = SFTConfig(
        max_seq_length = max_seq_length,
        per_device_train_batch_size = 2,
        gradient_accumulation_steps = 4,
        warmup_steps = 10,
        max_steps = 60,
        logging_steps = 1,
        output_dir = "outputs",
        optim = "adamw_8bit",
        seed = 3407,
    ),
)
trainer.train()

# Go to https://github.com/unslothai/unsloth/wiki for advanced tips like
# (1) Saving to GGUF / merging to 16bit for vLLM
# (2) Continued training from a saved LoRA adapter
# (3) Adding an evaluation loop / OOMs
# (4) Customized chat templates
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a name="RL"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üí° Reinforcement Learning&lt;/h2&gt; 
&lt;p&gt;RL including DPO, GRPO, PPO, Reward Modelling, Online DPO all work with Unsloth. We're in ü§óHugging Face's official docs! We're on the &lt;a href="https://huggingface.co/learn/nlp-course/en/chapter12/6"&gt;GRPO docs&lt;/a&gt; and the &lt;a href="https://huggingface.co/docs/trl/main/en/dpo_trainer#accelerate-dpo-fine-tuning-using-unsloth"&gt;DPO docs&lt;/a&gt;! List of RL notebooks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Advanced Qwen3 GRPO notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen3_(4B)-GRPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ORPO notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-ORPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DPO Zephyr notebook: &lt;a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Zephyr_(7B)-DPO.ipynb"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;KTO notebook: &lt;a href="https://colab.research.google.com/drive/1MRgGtLWuZX4ypSfGguFgC-IblTvO2ivM?usp=sharing"&gt;Link&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SimPO notebook: &lt;a href="https://colab.research.google.com/drive/1Hs5oQDovOay4mFA6Y9lQhVJ8TnbFLFh2?usp=sharing"&gt;Link&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click for DPO code&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0" # Optional set GPU device ID

from unsloth import FastLanguageModel
import torch
from trl import DPOTrainer, DPOConfig
max_seq_length = 2048

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = "unsloth/zephyr-sft-bnb-4bit",
    max_seq_length = max_seq_length,
    load_in_4bit = True,
)

# Do model patching and add fast LoRA weights
model = FastLanguageModel.get_peft_model(
    model,
    r = 64,
    target_modules = ["q_proj", "k_proj", "v_proj", "o_proj",
                      "gate_proj", "up_proj", "down_proj",],
    lora_alpha = 64,
    lora_dropout = 0, # Supports any, but = 0 is optimized
    bias = "none",    # Supports any, but = "none" is optimized
    # [NEW] "unsloth" uses 30% less VRAM, fits 2x larger batch sizes!
    use_gradient_checkpointing = "unsloth", # True or "unsloth" for very long context
    random_state = 3407,
    max_seq_length = max_seq_length,
)

dpo_trainer = DPOTrainer(
    model = model,
    ref_model = None,
    train_dataset = YOUR_DATASET_HERE,
    # eval_dataset = YOUR_DATASET_HERE,
    tokenizer = tokenizer,
    args = DPOConfig(
        per_device_train_batch_size = 4,
        gradient_accumulation_steps = 8,
        warmup_ratio = 0.1,
        num_train_epochs = 3,
        logging_steps = 1,
        optim = "adamw_8bit",
        seed = 42,
        output_dir = "outputs",
        max_length = 1024,
        max_prompt_length = 512,
        beta = 0.1,
    ),
)
dpo_trainer.train()
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;ü•á Performance Benchmarking&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For our most detailed benchmarks, read our &lt;a href="https://unsloth.ai/blog/llama3-3"&gt;Llama 3.3 Blog&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Benchmarking of Unsloth was also conducted by &lt;a href="https://huggingface.co/blog/unsloth-trl"&gt;ü§óHugging Face&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We tested using the Alpaca Dataset, a batch size of 2, gradient accumulation steps of 4, rank = 32, and applied QLoRA on all linear layers (q, k, v, o, gate, up, down):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;VRAM&lt;/th&gt; 
   &lt;th&gt;ü¶• Unsloth speed&lt;/th&gt; 
   &lt;th&gt;ü¶• VRAM reduction&lt;/th&gt; 
   &lt;th&gt;ü¶• Longer context&lt;/th&gt; 
   &lt;th&gt;üòä Hugging Face + FA2&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.3 (70B)&lt;/td&gt; 
   &lt;td&gt;80GB&lt;/td&gt; 
   &lt;td&gt;2x&lt;/td&gt; 
   &lt;td&gt;&amp;gt;75%&lt;/td&gt; 
   &lt;td&gt;13x longer&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Llama 3.1 (8B)&lt;/td&gt; 
   &lt;td&gt;80GB&lt;/td&gt; 
   &lt;td&gt;2x&lt;/td&gt; 
   &lt;td&gt;&amp;gt;70%&lt;/td&gt; 
   &lt;td&gt;12x longer&lt;/td&gt; 
   &lt;td&gt;1x&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Context length benchmarks&lt;/h3&gt; 
&lt;h4&gt;Llama 3.1 (8B) max. context length&lt;/h4&gt; 
&lt;p&gt;We tested Llama 3.1 (8B) Instruct and did 4bit QLoRA on all linear layers (Q, K, V, O, gate, up and down) with rank = 32 with a batch size of 1. We padded all sequences to a certain maximum sequence length to mimic long context finetuning workloads.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;GPU VRAM&lt;/th&gt; 
   &lt;th&gt;ü¶•Unsloth context length&lt;/th&gt; 
   &lt;th&gt;Hugging Face + FA2&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8 GB&lt;/td&gt; 
   &lt;td&gt;2,972&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12 GB&lt;/td&gt; 
   &lt;td&gt;21,848&lt;/td&gt; 
   &lt;td&gt;932&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16 GB&lt;/td&gt; 
   &lt;td&gt;40,724&lt;/td&gt; 
   &lt;td&gt;2,551&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;24 GB&lt;/td&gt; 
   &lt;td&gt;78,475&lt;/td&gt; 
   &lt;td&gt;5,789&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;40 GB&lt;/td&gt; 
   &lt;td&gt;153,977&lt;/td&gt; 
   &lt;td&gt;12,264&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;48 GB&lt;/td&gt; 
   &lt;td&gt;191,728&lt;/td&gt; 
   &lt;td&gt;15,502&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;80 GB&lt;/td&gt; 
   &lt;td&gt;342,733&lt;/td&gt; 
   &lt;td&gt;28,454&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Llama 3.3 (70B) max. context length&lt;/h4&gt; 
&lt;p&gt;We tested Llama 3.3 (70B) Instruct on a 80GB A100 and did 4bit QLoRA on all linear layers (Q, K, V, O, gate, up and down) with rank = 32 with a batch size of 1. We padded all sequences to a certain maximum sequence length to mimic long context finetuning workloads.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;GPU VRAM&lt;/th&gt; 
   &lt;th&gt;ü¶•Unsloth context length&lt;/th&gt; 
   &lt;th&gt;Hugging Face + FA2&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;48 GB&lt;/td&gt; 
   &lt;td&gt;12,106&lt;/td&gt; 
   &lt;td&gt;OOM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;80 GB&lt;/td&gt; 
   &lt;td&gt;89,389&lt;/td&gt; 
   &lt;td&gt;6,916&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://i.ibb.co/sJ7RhGG/image-41.png" alt="" /&gt; &lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Citation&lt;/h3&gt; 
&lt;p&gt;You can cite the Unsloth repo as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@software{unsloth,
  author = {Daniel Han, Michael Han and Unsloth team},
  title = {Unsloth},
  url = {http://github.com/unslothai/unsloth},
  year = {2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Thank You to&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://github.com/ggml-org/llama.cpp"&gt;llama.cpp library&lt;/a&gt; that lets users save models with Unsloth&lt;/li&gt; 
 &lt;li&gt;The Hugging Face team and their &lt;a href="https://github.com/huggingface/trl"&gt;TRL library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/erikwijmans"&gt;Erik&lt;/a&gt; for his help adding &lt;a href="https://github.com/apple/ml-cross-entropy"&gt;Apple's ML Cross Entropy&lt;/a&gt; in Unsloth&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Etherll"&gt;Etherl&lt;/a&gt; for adding support for &lt;a href="https://github.com/unslothai/notebooks/pull/34"&gt;TTS, diffusion and BERT models&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;And of course for every single person who has contributed or has used Unsloth!&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>PaddlePaddle/PaddleOCR</title>
      <link>https://github.com/PaddlePaddle/PaddleOCR</link>
      <description>&lt;p&gt;Turn any PDF or image document into structured data for your AI. A powerful, lightweight OCR toolkit that bridges the gap between images/PDFs and LLMs. Supports 80+ languages.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/images/Banner.png" alt="PaddleOCR Banner" /&gt; &lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_cn.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_tcn.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ko.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_fr.md"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ru.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_es.md"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ar.md"&gt;ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://img.shields.io/github/stars/PaddlePaddle/PaddleOCR?color=ccf" alt="stars" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2507.05595"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2507.05595-b31b1b.svg?logo=arXiv" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/paddleocr"&gt;&lt;img src="https://static.pepy.tech/badge/paddleocr/month" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/paddleocr"&gt;&lt;img src="https://static.pepy.tech/badge/paddleocr" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/network/dependents"&gt;&lt;img src="https://img.shields.io/badge/Used%20by-5.9k%2B%20repositories-blue" alt="Used by" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/python-3.8~3.12-aff.svg?sanitize=true" alt="python" /&gt; &lt;img src="https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg?sanitize=true" alt="os" /&gt; &lt;img src="https://img.shields.io/badge/hardware-cpu%2C%20gpu%2C%20xpu%2C%20npu-yellow.svg?sanitize=true" alt="hardware" /&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache_2.0-green" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;PaddleOCR&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.paddlepaddle.org.cn/en"&gt;&lt;img src="https://img.shields.io/badge/PaddlePaddle-3.0-orange" alt="Framework" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Recognition%20Accuracy-%F0%9F%8F%86-green" alt="Accuracy" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Support_Languages-80+-brightgreen" alt="Multi-Language" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Handwriting-%E2%9C%93-success" alt="Handwriting" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Heterogeneous%20Hardware-Kunlunxin%20%7C%20Ascend_NPU-red" alt="Hardware" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] PaddleOCR now provides an MCP server that supports integration with Agent applications like Claude Desktop. For details, please refer to &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html"&gt;PaddleOCR MCP Server&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;The PaddleOCR 3.0 Technical Report is now available. See details at: &lt;a href="https://arxiv.org/abs/2507.05595"&gt;PaddleOCR 3.0 Technical Report&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;PaddleOCR&lt;/strong&gt; converts documents and images into &lt;strong&gt;structured, AI-friendly data&lt;/strong&gt; (like JSON and Markdown) with &lt;strong&gt;industry-leading accuracy&lt;/strong&gt;‚Äîpowering AI applications for everyone from indie developers and startups to large enterprises worldwide. With over &lt;strong&gt;50,000 stars&lt;/strong&gt; and deep integration into leading projects like &lt;strong&gt;MinerU, RAGFlow, and OmniParser&lt;/strong&gt;, PaddleOCR has become the &lt;strong&gt;premier solution&lt;/strong&gt; for developers building intelligent document applications in the &lt;strong&gt;AI era&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;PaddleOCR 3.0 Core Features&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://aistudio.baidu.com/community/app/91660/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_OCRv5-Demo_on_AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518494/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_StructureV3-Demo_on_AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518493/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_ChatOCRv4-Demo_on_AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://www.modelscope.cn/organization/PaddlePaddle"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%96_Demo_on_ModelScope-purple" alt="ModelScope" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/PaddlePaddle"&gt;&lt;img src="https://img.shields.io/badge/Demo_on_HuggingFace-purple.svg?logo=huggingface" alt="HuggingFace" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-OCRv5 ‚Äî Universal Scene Text Recognition&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;Single model supports five text types&lt;/strong&gt; (Simplified Chinese, Traditional Chinese, English, Japanese, and Pinyin) with &lt;strong&gt;13% accuracy improvement&lt;/strong&gt;. Solves multilingual mixed document recognition challenges.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-StructureV3 ‚Äî Complex Document Parsing&lt;/strong&gt;&lt;br /&gt; Intelligently converts complex PDFs and document images into &lt;strong&gt;Markdown and JSON files that preserve original structure&lt;/strong&gt;. &lt;strong&gt;Outperforms&lt;/strong&gt; numerous commercial solutions in public benchmarks. &lt;strong&gt;Perfectly maintains document layout and hierarchical structure&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-ChatOCRv4 ‚Äî Intelligent Information Extraction&lt;/strong&gt;&lt;br /&gt; Natively integrates ERNIE 4.5 to &lt;strong&gt;precisely extract key information&lt;/strong&gt; from massive documents, with 15% accuracy improvement over previous generation. Makes documents "&lt;strong&gt;understand&lt;/strong&gt;" your questions and provide accurate answers.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to providing an outstanding model library, PaddleOCR 3.0 also offers user-friendly tools covering model training, inference, and service deployment, so developers can rapidly bring AI applications to production.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/Arch.jpg" alt="PaddleOCR Architecture" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Special Note&lt;/strong&gt;: PaddleOCR 3.x introduces several significant interface changes. &lt;strong&gt;Old code written based on PaddleOCR 2.x is likely incompatible with PaddleOCR 3.x&lt;/strong&gt;. Please ensure that the documentation you are reading matches the version of PaddleOCR you are using. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/upgrade_notes.html"&gt;This document&lt;/a&gt; explains the reasons for the upgrade and the major changes from PaddleOCR 2.x to 3.x.&lt;/p&gt; 
&lt;h2&gt;üì£ Recent updates&lt;/h2&gt; 
&lt;h3&gt;üî•üî•2025.08.21: Release of PaddleOCR 3.2.0, includes:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Significant Model Additions:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Introduced training, inference, and deployment for PP-OCRv5 recognition models in English, Thai, and Greek. &lt;strong&gt;The PP-OCRv5 English model delivers an 11% improvement in English scenarios compared to the main PP-OCRv5 model, with the Thai and Greek recognition models achieving accuracies of 82.68% and 89.28%, respectively.&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deployment Capability Upgrades:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Full support for PaddlePaddle framework versions 3.1.0 and 3.1.1.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Comprehensive upgrade of the PP-OCRv5 C++ local deployment solution, now supporting both Linux and Windows, with feature parity and identical accuracy to the Python implementation.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;High-performance inference now supports CUDA 12, and inference can be performed using either the Paddle Inference or ONNX Runtime backends.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;The high-stability service-oriented deployment solution is now fully open-sourced, allowing users to customize Docker images and SDKs as required.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;The high-stability service-oriented deployment solution also supports invocation via manually constructed HTTP requests, enabling client-side code development in any programming language.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Benchmark Support:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;All production lines now support fine-grained benchmarking, enabling measurement of end-to-end inference time as well as per-layer and per-module latency data to assist with performance analysis. &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/version3.x/pipeline_usage/instructions/benchmark.en.md"&gt;Here's&lt;/a&gt; how to set up and use the benchmark feature.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Documentation has been updated to include key metrics for commonly used configurations on mainstream hardware, such as inference latency and memory usage, providing deployment references for users.&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Resolved the issue of failed log saving during model training.&lt;/li&gt; 
   &lt;li&gt;Upgraded the data augmentation component for formula models for compatibility with newer versions of the albumentations dependency, and fixed deadlock warnings when using the tokenizers package in multi-process scenarios.&lt;/li&gt; 
   &lt;li&gt;Fixed inconsistencies in switch behaviors (e.g., &lt;code&gt;use_chart_parsing&lt;/code&gt;) in the PP-StructureV3 configuration files compared to other pipelines.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other Enhancements:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Separated core and optional dependencies. Only minimal core dependencies are required for basic text recognition; additional dependencies for document parsing and information extraction can be installed as needed.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Enabled support for NVIDIA RTX 50 series graphics cards on Windows; users can refer to the &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/version3.x/installation.en.md"&gt;installation guide&lt;/a&gt; for the corresponding PaddlePaddle framework versions.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;PP-OCR series models now support returning single-character coordinates.&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Added AIStudio, ModelScope, and other model download sources, allowing users to specify the source for model downloads.&lt;/li&gt; 
   &lt;li&gt;Added support for chart-to-table conversion via the PP-Chart2Table module.&lt;/li&gt; 
   &lt;li&gt;Optimized documentation descriptions to improve usability.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.08.15: PaddleOCR 3.1.1 Released&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Added the missing methods &lt;code&gt;save_vector&lt;/code&gt;, &lt;code&gt;save_visual_info_list&lt;/code&gt;, &lt;code&gt;load_vector&lt;/code&gt;, and &lt;code&gt;load_visual_info_list&lt;/code&gt; in the &lt;code&gt;PP-ChatOCRv4&lt;/code&gt; class.&lt;/li&gt; 
    &lt;li&gt;Added the missing parameters &lt;code&gt;glossary&lt;/code&gt; and &lt;code&gt;llm_request_interval&lt;/code&gt; to the &lt;code&gt;translate&lt;/code&gt; method in the &lt;code&gt;PPDocTranslation&lt;/code&gt; class.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Improvements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Added a demo to the MCP documentation.&lt;/li&gt; 
    &lt;li&gt;Added information about the PaddlePaddle and PaddleOCR version used for performance metrics testing in the documentation.&lt;/li&gt; 
    &lt;li&gt;Fixed errors and omissions in the production line document translation.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Others:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Changed the MCP server dependency to use the pure Python library &lt;code&gt;puremagic&lt;/code&gt; instead of &lt;code&gt;python-magic&lt;/code&gt; to reduce installation issues.&lt;/li&gt; 
    &lt;li&gt;Retested PP-OCRv5 performance metrics with PaddleOCR version 3.1.0 and updated the documentation.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.29: PaddleOCR 3.1.0 Released&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Key Models and Pipelines:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Added PP-OCRv5 Multilingual Text Recognition Model&lt;/strong&gt;, which supports the training and inference process for text recognition models in 37 languages, including French, Spanish, Portuguese, Russian, Korean, etc. &lt;strong&gt;Average accuracy improved by over 30%.&lt;/strong&gt; &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/algorithm/PP-OCRv5/PP-OCRv5_multi_languages.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Upgraded the &lt;strong&gt;PP-Chart2Table model&lt;/strong&gt; in PP-StructureV3, further enhancing the capability of converting charts to tables. On internal custom evaluation sets, the metric (RMS-F1) &lt;strong&gt;increased by 9.36 percentage points (71.24% -&amp;gt; 80.60%).&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Newly launched &lt;strong&gt;document translation pipeline, PP-DocTranslation, based on PP-StructureV3 and ERNIE 4.5&lt;/strong&gt;, which supports the translation of Markdown format documents, various complex-layout PDF documents, and document images, with the results saved as Markdown format documents. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/PP-DocTranslation.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MCP server:&lt;/strong&gt; &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html"&gt;Details&lt;/a&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Supports both OCR and PP-StructureV3 pipelines.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Supports three working modes: local Python library, AIStudio Community Cloud Service, and self-hosted service.&lt;/li&gt; 
    &lt;li&gt;Supports invoking local services via stdio and remote services via Streamable HTTP.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Optimization:&lt;/strong&gt; Improved the descriptions in some user guides for a smoother reading experience.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.26: PaddleOCR 3.0.3 Released&lt;/strong&gt;&lt;/summary&gt; - Bug Fix: Resolved the issue where the `enable_mkldnn` parameter was not effective, restoring the default behavior of using MKL-DNN for CPU inference. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.19: PaddleOCR 3.0.2 Released&lt;/strong&gt;&lt;/summary&gt; - **New Features:** 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;The default download source has been changed from &lt;code&gt;BOS&lt;/code&gt; to &lt;code&gt;HuggingFace&lt;/code&gt;. Users can also change the environment variable &lt;code&gt;PADDLE_PDX_MODEL_SOURCE&lt;/code&gt; to &lt;code&gt;BOS&lt;/code&gt; to set the model download source back to Baidu Object Storage (BOS).&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Added service invocation examples for six languages‚ÄîC++, Java, Go, C#, Node.js, and PHP‚Äîfor pipelines like PP-OCRv5, PP-StructureV3, and PP-ChatOCRv4.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Improved the layout partition sorting algorithm in the PP-StructureV3 pipeline, enhancing the sorting logic for complex vertical layouts to deliver better results.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Enhanced model selection logic: when a language is specified but a model version is not, the system will automatically select the latest model version supporting that language.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Set a default upper limit for MKL-DNN cache size to prevent unlimited growth, while also allowing users to configure cache capacity.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Updated default configurations for high-performance inference to support Paddle MKL-DNN acceleration and optimized the logic for automatic configuration selection for smarter choices.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Adjusted the logic for obtaining the default device to consider the actual support for computing devices by the installed Paddle framework, making program behavior more intuitive.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Added Android example for PP-OCRv5. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/on_device_deployment.html"&gt;Details&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Fixed an issue with some CLI parameters in PP-StructureV3 not taking effect.&lt;/li&gt; 
    &lt;li&gt;Resolved an issue where &lt;code&gt;export_paddlex_config_to_yaml&lt;/code&gt; would not function correctly in certain cases.&lt;/li&gt; 
    &lt;li&gt;Corrected the discrepancy between the actual behavior of &lt;code&gt;save_path&lt;/code&gt; and its documentation description.&lt;/li&gt; 
    &lt;li&gt;Fixed potential multithreading errors when using MKL-DNN in basic service deployment.&lt;/li&gt; 
    &lt;li&gt;Corrected channel order errors in image preprocessing for the Latex-OCR model.&lt;/li&gt; 
    &lt;li&gt;Fixed channel order errors in saving visualized images within the text recognition module.&lt;/li&gt; 
    &lt;li&gt;Resolved channel order errors in visualized table results within PP-StructureV3 pipeline.&lt;/li&gt; 
    &lt;li&gt;Fixed an overflow issue in the calculation of &lt;code&gt;overlap_ratio&lt;/code&gt; under extremely special circumstances in the PP-StructureV3 pipeline.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Improvements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Updated the description of the &lt;code&gt;enable_mkldnn&lt;/code&gt; parameter in the documentation to accurately reflect the program's actual behavior.&lt;/li&gt; 
    &lt;li&gt;Fixed errors in the documentation regarding the &lt;code&gt;lang&lt;/code&gt; and &lt;code&gt;ocr_version&lt;/code&gt; parameters.&lt;/li&gt; 
    &lt;li&gt;Added instructions for exporting pipeline configuration files via CLI.&lt;/li&gt; 
    &lt;li&gt;Fixed missing columns in the performance data table for PP-OCRv5.&lt;/li&gt; 
    &lt;li&gt;Refined benchmark metrics for PP-StructureV3 across different configurations.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Others:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Relaxed version restrictions on dependencies like numpy and pandas, restoring support for Python 3.12.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;History Log&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;2025.06.05: &lt;strong&gt;PaddleOCR 3.0.1 Released&lt;/strong&gt;, includes:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Optimisation of certain models and model configurations:&lt;/strong&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Updated the default model configuration for PP-OCRv5, changing both detection and recognition from mobile to server models. To improve default performance in most scenarios, the parameter &lt;code&gt;limit_side_len&lt;/code&gt; in the configuration has been changed from 736 to 64.&lt;/li&gt; 
    &lt;li&gt;Added a new text line orientation classification model &lt;code&gt;PP-LCNet_x1_0_textline_ori&lt;/code&gt; with an accuracy of 99.42%. The default text line orientation classifier for OCR, PP-StructureV3, and PP-ChatOCRv4 pipelines has been updated to this model.&lt;/li&gt; 
    &lt;li&gt;Optimized the text line orientation classification model &lt;code&gt;PP-LCNet_x0_25_textline_ori&lt;/code&gt;, improving accuracy by 3.3 percentage points to a current accuracy of 98.85%.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Optimizations and fixes for some issues in version 3.0.0, &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html"&gt;details&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;üî•üî•2025.05.20: Official Release of &lt;strong&gt;PaddleOCR v3.0&lt;/strong&gt;, including:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-OCRv5&lt;/strong&gt;: High-Accuracy Text Recognition Model for All Scenarios - Instant Text from Images/PDFs.&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;üåê Single-model support for &lt;strong&gt;five&lt;/strong&gt; text types - Seamlessly process &lt;strong&gt;Simplified Chinese, Traditional Chinese, Simplified Chinese Pinyin, English&lt;/strong&gt; and &lt;strong&gt;Japanese&lt;/strong&gt; within a single model.&lt;/li&gt; 
    &lt;li&gt;‚úçÔ∏è Improved &lt;strong&gt;handwriting recognition&lt;/strong&gt;: Significantly better at complex cursive scripts and non-standard handwriting.&lt;/li&gt; 
    &lt;li&gt;üéØ &lt;strong&gt;13-point accuracy gain&lt;/strong&gt; over PP-OCRv4, achieving state-of-the-art performance across a variety of real-world scenarios.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-StructureV3&lt;/strong&gt;: General-Purpose Document Parsing ‚Äì Unleash SOTA Images/PDFs Parsing for Real-World Scenarios!&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;üßÆ &lt;strong&gt;High-Accuracy multi-scene PDF parsing&lt;/strong&gt;, leading both open- and closed-source solutions on the OmniDocBench benchmark.&lt;/li&gt; 
    &lt;li&gt;üß† Specialized capabilities include &lt;strong&gt;seal recognition&lt;/strong&gt;, &lt;strong&gt;chart-to-table conversion&lt;/strong&gt;, &lt;strong&gt;table recognition with nested formulas/images&lt;/strong&gt;, &lt;strong&gt;vertical text document parsing&lt;/strong&gt;, and &lt;strong&gt;complex table structure analysis&lt;/strong&gt;.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-ChatOCRv4&lt;/strong&gt;: Intelligent Document Understanding ‚Äì Extract Key Information, not just text from Images/PDFs.&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;üî• &lt;strong&gt;15-point accuracy gain&lt;/strong&gt; in key-information extraction on PDF/PNG/JPG files over the previous generation.&lt;/li&gt; 
    &lt;li&gt;üíª Native support for &lt;strong&gt;ERNIE 4.5&lt;/strong&gt;, with compatibility for large-model deployments via PaddleNLP, Ollama, vLLM, and more.&lt;/li&gt; 
    &lt;li&gt;ü§ù Integrated &lt;a href="https://github.com/PaddlePaddle/PaddleMIX/tree/develop/paddlemix/examples/ppdocbee2"&gt;PP-DocBee2&lt;/a&gt;, enabling extraction and understanding of printed text, handwriting, seals, tables, charts, and other common elements in complex documents.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html"&gt;History Log&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ö° Quick Start&lt;/h2&gt; 
&lt;h3&gt;1. Run online demo&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://aistudio.baidu.com/community/app/91660/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_OCRv5-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518494/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_StructureV3-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518493/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_ChatOCRv4-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Installation&lt;/h3&gt; 
&lt;p&gt;Install PaddlePaddle refer to &lt;a href="https://www.paddlepaddle.org.cn/en/install/quick?docurl=/documentation/docs/en/develop/install/pip/linux-pip_en.html"&gt;Installation Guide&lt;/a&gt;, after then, install the PaddleOCR toolkit.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series
python -m pip install paddleocr
# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.
# python -m pip install "paddleocr[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Starting from version 3.2.0, in addition to the &lt;code&gt;all&lt;/code&gt; dependency group demonstrated above, PaddleOCR also supports installing partial optional features by specifying other dependency groups. All dependency groups provided by PaddleOCR are as follows:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dependency Group Name&lt;/th&gt; 
   &lt;th&gt;Corresponding Functionality&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;doc-parser&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Document parsing: can be used to extract layout elements such as tables, formulas, stamps, images, etc. from documents; includes models like PP-StructureV3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ie&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Information extraction: can be used to extract key information from documents, such as names, dates, addresses, amounts, etc.; includes models like PP-ChatOCRv4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;trans&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Document translation: can be used to translate documents from one language to another; includes models like PP-DocTranslation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;all&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Complete functionality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;3. Run inference by CLI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run PP-OCRv5 inference
paddleocr ocr -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png --use_doc_orientation_classify False --use_doc_unwarping False --use_textline_orientation False  

# Run PP-StructureV3 inference
paddleocr pp_structurev3 -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png --use_doc_orientation_classify False --use_doc_unwarping False

# Get the Qianfan API Key at first, and then run PP-ChatOCRv4 inference
paddleocr pp_chatocrv4_doc -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png -k È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞ --qianfan_api_key your_api_key --use_doc_orientation_classify False --use_doc_unwarping False 

# Get more information about "paddleocr ocr"
paddleocr ocr --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. Run inference by API&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;4.1 PP-OCRv5 Example&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Initialize PaddleOCR instance
from paddleocr import PaddleOCR
ocr = PaddleOCR(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False,
    use_textline_orientation=False)

# Run OCR inference on a sample image 
result = ocr.predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png")

# Visualize the results and save the JSON results
for res in result:
    res.print()
    res.save_to_img("output")
    res.save_to_json("output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.2 PP-StructureV3 Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from pathlib import Path
from paddleocr import PPStructureV3

pipeline = PPStructureV3(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False
)

# For Image
output = pipeline.predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png",
)

# Visualize the results and save the JSON results
for res in output:
    res.print() 
    res.save_to_json(save_path="output") 
    res.save_to_markdown(save_path="output")           
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.3 PP-ChatOCRv4 Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from paddleocr import PPChatOCRv4Doc

chat_bot_config = {
    "module_name": "chat_bot",
    "model_name": "ernie-3.5-8k",
    "base_url": "https://qianfan.baidubce.com/v2",
    "api_type": "openai",
    "api_key": "api_key",  # your api_key
}

retriever_config = {
    "module_name": "retriever",
    "model_name": "embedding-v1",
    "base_url": "https://qianfan.baidubce.com/v2",
    "api_type": "qianfan",
    "api_key": "api_key",  # your api_key
}

pipeline = PPChatOCRv4Doc(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False
)

visual_predict_res = pipeline.visual_predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png",
    use_common_ocr=True,
    use_seal_recognition=True,
    use_table_recognition=True,
)

mllm_predict_info = None
use_mllm = False
# If a multimodal large model is used, the local mllm service needs to be started. You can refer to the documentation: https://github.com/PaddlePaddle/PaddleX/blob/release/3.0/docs/pipeline_usage/tutorials/vlm_pipelines/doc_understanding.en.md performs deployment and updates the mllm_chat_bot_config configuration.
if use_mllm:
    mllm_chat_bot_config = {
        "module_name": "chat_bot",
        "model_name": "PP-DocBee",
        "base_url": "http://127.0.0.1:8080/",  # your local mllm service url
        "api_type": "openai",
        "api_key": "api_key",  # your api_key
    }

    mllm_predict_res = pipeline.mllm_pred(
        input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png",
        key_list=["È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞"],
        mllm_chat_bot_config=mllm_chat_bot_config,
    )
    mllm_predict_info = mllm_predict_res["mllm_res"]

visual_info_list = []
for res in visual_predict_res:
    visual_info_list.append(res["visual_info"])
    layout_parsing_result = res["layout_parsing_result"]

vector_info = pipeline.build_vector(
    visual_info_list, flag_save_bytes_vector=True, retriever_config=retriever_config
)
chat_result = pipeline.chat(
    key_list=["È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞"],
    visual_info=visual_info_list,
    vector_info=vector_info,
    mllm_predict_info=mllm_predict_info,
    chat_bot_config=chat_bot_config,
    retriever_config=retriever_config,
)
print(chat_result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;5. Chinese Heterogeneous AI Accelerators&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_NPU.html"&gt;Huawei Ascend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_XPU.html"&gt;KUNLUNXIN&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© More Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Convert models to ONNX format: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/obtaining_onnx_models.html"&gt;Obtaining ONNX Models&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Accelerate inference using engines like OpenVINO, ONNX Runtime, TensorRT, or perform inference using ONNX format models: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/high_performance_inference.html"&gt;High-Performance Inference&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Accelerate inference using multi-GPU and multi-process: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/instructions/parallel_inference.html"&gt;Parallel Inference for Pipelines&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Integrate PaddleOCR into applications written in C++, C#, Java, etc.: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/serving.html"&gt;Serving&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚õ∞Ô∏è Advanced Tutorials&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/OCR.html"&gt;PP-OCRv5 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-StructureV3.html"&gt;PP-StructureV3 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-ChatOCRv4.html"&gt;PP-ChatOCRv4 Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîÑ Quick Overview of Execution Results&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/images/demo.gif" alt="PP-OCRv5 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/images/blue_v3.gif" alt="PP-StructureV3 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ú® Stay Tuned&lt;/h2&gt; 
&lt;p&gt;‚≠ê &lt;strong&gt;Star this repository to keep up with exciting updates and new releases, including powerful OCR and document parsing capabilities!&lt;/strong&gt; ‚≠ê&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="1200" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/star_paddleocr.en.gif" alt="Star-Project" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Community&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;PaddlePaddle WeChat official account&lt;/th&gt; 
    &lt;th align="center"&gt;Join the tech discussion group&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qrcode_for_paddlepaddle_official_account.jpg" width="150" /&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qr_code_for_the_questionnaire.jpg" width="150" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;üòÉ Awesome Projects Leveraging PaddleOCR&lt;/h2&gt; 
&lt;p&gt;PaddleOCR wouldn't be where it is today without its incredible community! üíó A massive thank you to all our longtime partners, new collaborators, and everyone who's poured their passion into PaddleOCR ‚Äî whether we've named you or not. Your support fuels our fire!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Project Name&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt; &lt;a href="https://github.com/infiniflow/ragflow"&gt;&lt;img src="https://img.shields.io/github/stars/infiniflow/ragflow" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;RAG engine based on deep document understanding.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt; &lt;a href="https://github.com/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/MinerU" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Multi-type Document to Markdown Conversion Tool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt;Umi-OCR&lt;/a&gt; &lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt;&lt;img src="https://img.shields.io/github/stars/hiroi-sora/Umi-OCR" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Free, Open-source, Batch Offline OCR Software.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/OmniParser"&gt;OmniParser&lt;/a&gt;&lt;a href="https://github.com/microsoft/OmniParser"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/OmniParser" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/netease-youdao/QAnything"&gt;QAnything&lt;/a&gt;&lt;a href="https://github.com/netease-youdao/QAnything"&gt;&lt;img src="https://img.shields.io/github/stars/netease-youdao/QAnything" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Question and Answer based on Anything.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;PDF-Extract-Kit&lt;/a&gt; &lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/PDF-Extract-Kit" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;A powerful open-source toolkit designed to efficiently extract high-quality content from complex and diverse PDF documents.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/PantsuDango/Dango-Translator"&gt;Dango-Translator&lt;/a&gt;&lt;a href="https://github.com/PantsuDango/Dango-Translator"&gt;&lt;img src="https://img.shields.io/github/stars/PantsuDango/Dango-Translator" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Recognize text on the screen, translate it and show the translation results in real time.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/awesome_projects.md"&gt;Learn more projects&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/awesome_projects.md"&gt;More projects based on PaddleOCR&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Contributors&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=PaddlePaddle/PaddleOCR&amp;amp;max=400&amp;amp;columns=20" width="800" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;üåü Star&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="800" src="https://api.star-history.com/svg?repos=PaddlePaddle/PaddleOCR&amp;amp;type=Date" alt="Star-history" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is released under the &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/LICENSE"&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üéì Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@misc{cui2025paddleocr30technicalreport,
      title={PaddleOCR 3.0 Technical Report}, 
      author={Cheng Cui and Ting Sun and Manhui Lin and Tingquan Gao and Yubo Zhang and Jiaxuan Liu and Xueqing Wang and Zelun Zhang and Changda Zhou and Hongen Liu and Yue Zhang and Wenyu Lv and Kui Huang and Yichao Zhang and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},
      year={2025},
      eprint={2507.05595},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.05595}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>