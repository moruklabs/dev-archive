<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Mon, 15 Sep 2025 02:10:01 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>firebase/genkit</title>
      <link>https://github.com/firebase/genkit</link>
      <description>&lt;p&gt;Google's multi-model AI framework in Javascript, Go and Python&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/firebase/genkit/main/docs/resources/genkit-logo-dark.png#gh-dark-mode-only" alt="Genkit logo" title="Genkit" /&gt; &lt;img src="https://raw.githubusercontent.com/firebase/genkit/main/docs/resources/genkit-logo.png#gh-light-mode-only" alt="Genkit logo" title="Genkit" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://genkit.dev"&gt;Genkit&lt;/a&gt; is an open-source framework for building full-stack AI-powered applications, built and used in production by Google's Firebase. It provides SDKs for multiple programming languages with varying levels of stability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;JavaScript/TypeScript&lt;/strong&gt;: Production-ready with full feature support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Go&lt;/strong&gt;: Production-ready with full feature support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python (Alpha)&lt;/strong&gt;: Early development with core functionality&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;It offers a unified interface for integrating AI models from providers like &lt;a href="https://genkit.dev/docs/plugins/google-genai"&gt;Google&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/plugins/openai"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-anthropic"&gt;Anthropic&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/plugins/ollama/"&gt;Ollama&lt;/a&gt;, and more. Rapidly build and deploy production-ready chatbots, automations, and recommendation systems using streamlined APIs for multimodal content, structured outputs, tool calling, and agentic workflows.&lt;/p&gt; 
&lt;p&gt;Get started with just a few lines of code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { genkit } from 'genkit';
import { googleAI } from '@genkit-ai/google-genai';

const ai = genkit({ plugins: [googleAI()] });

const { text } = await ai.generate({
    model: googleAI.model('gemini-2.5-flash'),
    prompt: 'Why is Firebase awesome?'
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Explore &amp;amp; build with Genkit&lt;/h2&gt; 
&lt;p&gt;Play with AI sample apps, with visualizations of the Genkit code that powers them, at no cost to you.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://examples.genkit.dev"&gt;Explore Genkit by Example&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key capabilities&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Broad AI model support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Use a unified interface to integrate with hundreds of models from providers like &lt;a href="https://genkit.dev/docs/plugins/google-genai"&gt;Google&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/plugins/openai"&gt; OpenAI&lt;/a&gt;, &lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-anthropic"&gt; Anthropic&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/plugins/ollama"&gt;Ollama&lt;/a&gt;, and more. Explore, compare, and use the best models for your needs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Simplified AI development&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Use streamlined APIs to build AI features with &lt;a href="https://genkit.dev/docs/models#structured-output"&gt; structured output&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/tool-calling"&gt;agentic tool calling&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/rag"&gt;context-aware generation&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/models#multimodal"&gt;multi-modal input/output&lt;/a&gt;, and more. Genkit handles the complexity of AI development, so you can build and iterate faster.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Web and mobile ready&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Integrate seamlessly with frameworks and platforms including Next.js, React, Angular, iOS, Android, using purpose-built &lt;a href="https://genkit.dev/docs/firebase"&gt;client SDKs&lt;/a&gt; and helpers.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cross-language support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Build with the language that best fits your project. Genkit provides SDKs for JavaScript/TypeScript, Go, and Python (Alpha) with consistent APIs and capabilities across all supported languages.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Deploy anywhere&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Deploy AI logic to any environment that supports your chosen programming language, such as &lt;a href="https://genkit.dev/docs/firebase"&gt;Cloud Functions for Firebase&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/cloud-run"&gt;Google Cloud Run&lt;/a&gt;, or &lt;a href="https://genkit.dev/docs/deploy-node"&gt;third-party platforms&lt;/a&gt;, with or without Google services.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Developer tools&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Accelerate AI development with a purpose-built, local &lt;a href="https://genkit.dev/docs/devtools"&gt;CLI and Developer UI&lt;/a&gt;. Test prompts and flows against individual inputs or datasets, compare outputs from different models, debug with detailed execution traces, and use immediate visual feedback to iterate rapidly on prompts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Production monitoring&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Ship AI features with confidence using comprehensive production monitoring. Track model performance, and request volumes, latency, and error rates in a &lt;a href="https://genkit.dev/docs/observability/getting-started"&gt; purpose-built dashboard&lt;/a&gt;. Identify issues quickly with detailed observability metrics, and ensure your AI features meet quality and performance targets in real-world usage.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;How does it work?&lt;/h2&gt; 
&lt;p&gt;Genkit simplifies AI integration with an open-source SDK and unified APIs that work across various model providers and programming languages. It abstracts away complexity so you can focus on delivering great user experiences.&lt;/p&gt; 
&lt;p&gt;Some key features offered by Genkit include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/models"&gt;Text and image generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/models#structured-output"&gt;Type-safe, structured data generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/tool-calling"&gt;Tool calling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/dotprompt"&gt;Prompt templating&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/chat"&gt;Persisted chat interfaces&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/flows"&gt;AI workflows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/rag"&gt;AI-powered data retrieval (RAG)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Genkit is designed for server-side deployment in multiple language environments, and also provides seamless client-side integration through dedicated helpers and &lt;a href="https://genkit.dev/docs/firebase"&gt;client SDKs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Implementation path&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;span&gt;1&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;Choose your language and model provider&lt;/td&gt; 
   &lt;td&gt;Select the Genkit SDK for your preferred language (JavaScript/TypeScript, Go, or Python (Alpha)). Choose a model provider like &lt;a href="https://genkit.dev/docs/plugins/google-genai"&gt;Google Gemini&lt;/a&gt; or Anthropic, and get an API key. Some providers, like &lt;a href="https://genkit.dev/docs/plugins/vertex-ai"&gt;Vertex AI&lt;/a&gt;, may rely on a different means of authentication.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;span&gt;2&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;Install the SDK and initialize&lt;/td&gt; 
   &lt;td&gt;Install the Genkit SDK, model-provider package of your choice, and the Genkit CLI. Import the Genkit and provider packages and initialize Genkit with the provider API key.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;span&gt;3&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;Write and test AI features&lt;/td&gt; 
   &lt;td&gt;Use the Genkit SDK to build AI features for your use case, from basic text generation to complex multi-step workflows and agents. Use the CLI and Developer UI to help you rapidly test and iterate.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;span&gt;4&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;Deploy and monitor&lt;/td&gt; 
   &lt;td&gt;Deploy your AI features to Firebase, Google Cloud Run, or any environment that supports your chosen programming language. Integrate them into your app, and monitor them in production in the Firebase console.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/get-started"&gt;JavaScript/TypeScript quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/go/docs/get-started-go"&gt;Go quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/python/docs/get-started/"&gt;Python quickstart&lt;/a&gt; (Alpha)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development tools&lt;/h2&gt; 
&lt;p&gt;Genkit provides a CLI and a local UI to streamline your AI development workflow.&lt;/p&gt; 
&lt;h3&gt;CLI&lt;/h3&gt; 
&lt;p&gt;The Genkit CLI includes commands for running and evaluating your Genkit functions (flows) and collecting telemetry and logs.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Install:&lt;/strong&gt; &lt;code&gt;npm install -g genkit-cli&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Run a command, wrapped with telemetry, a interactive developer UI, etc:&lt;/strong&gt; &lt;code&gt;genkit start -- &amp;lt;command to run your code&amp;gt;&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Developer UI&lt;/h3&gt; 
&lt;p&gt;The Genkit developer UI is a local interface for testing, debugging, and iterating on your AI application.&lt;/p&gt; 
&lt;p&gt;Key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Run:&lt;/strong&gt; Execute and experiment with Genkit flows, prompts, queries, and more in dedicated playgrounds.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Inspect:&lt;/strong&gt; Analyze detailed traces of past executions, including step-by-step breakdowns of complex flows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evaluate:&lt;/strong&gt; Review the results of evaluations run against your flows, including performance metrics and links to relevant traces.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/firebase/genkit/main/docs/resources/readme-ui-traces-screenshot.png" width="700" alt="Screenshot of Genkit Developer UI showing traces" /&gt; 
&lt;h2&gt;Try Genkit in Firebase Studio&lt;/h2&gt; 
&lt;p&gt;Want to skip the local setup? Click below to try out Genkit using &lt;a href="https://firebase.studio"&gt;Firebase Studio&lt;/a&gt;, Google's AI-assisted workspace for full-stack app development in the cloud.&lt;/p&gt; 
&lt;a href="https://studio.firebase.google.com/new/genkit"&gt; &lt;img height="32" alt="Open in Firebase Studio" src="https://cdn.firebasestudio.dev/btn/open_bright_32.svg?sanitize=true" /&gt; &lt;/a&gt; 
&lt;h2&gt;Connect with us&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/qXt5zzQKpc"&gt;&lt;strong&gt;Join us on Discord&lt;/strong&gt;&lt;/a&gt; – Get help, share ideas, and chat with other developers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/firebase/genkit/issues"&gt;&lt;strong&gt;Contribute on GitHub&lt;/strong&gt;&lt;/a&gt; – Report bugs, suggest features, or explore the source code.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/genkit-ai/"&gt;&lt;strong&gt;Contribute to Documentation and Samples&lt;/strong&gt;&lt;/a&gt; – Report issues in Genkit's &lt;a href="https://github.com/genkit-ai/docsite"&gt;documentation&lt;/a&gt;, or contribute to the &lt;a href="https://github.com/genkit-ai/samples"&gt;samples&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions to Genkit are welcome and highly appreciated! See our &lt;a href="https://raw.githubusercontent.com/firebase/genkit/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Authors&lt;/h2&gt; 
&lt;p&gt;Genkit is built by &lt;a href="https://firebase.google.com/"&gt;Firebase&lt;/a&gt; with contributions from the &lt;a href="https://github.com/firebase/genkit/graphs/contributors"&gt;Open Source Community&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vercel/examples</title>
      <link>https://github.com/vercel/examples</link>
      <description>&lt;p&gt;Enjoy our curated collection of examples and solutions. Use these patterns to build your own robust and scalable applications.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://vercel.com"&gt; &lt;img src="https://assets.vercel.com/image/upload/v1588805858/repositories/vercel/logo.png" height="96" /&gt; &lt;/a&gt;&lt;/p&gt;
&lt;h3 align="center"&gt;&lt;a href="https://vercel.com"&gt;Vercel Examples&lt;/a&gt;&lt;/h3&gt;
&lt;a href="https://vercel.com"&gt; &lt;/a&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vercel/examples/main/solutions"&gt;Solutions&lt;/a&gt; – Demos, reference architecture, and best practices&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/vercel/examples/main/starter"&gt;Starter&lt;/a&gt; – Functional applications which can act as a starting point&lt;/li&gt; 
 &lt;li&gt;And more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Vercel Templates&lt;/h2&gt; 
&lt;p&gt;Multiple examples are being featured in &lt;a href="https://vercel.com/templates"&gt;Vercel's Templates&lt;/a&gt;, visit that page for more advanced filtering options.&lt;/p&gt; 
&lt;h3&gt;For Vercelians&lt;/h3&gt; 
&lt;p&gt;Examples that have front matter metadata will create a new Draft template in &lt;a href="https://app.contentful.com"&gt;Contentful&lt;/a&gt;, for more steps on how to publish a template, read &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/internal/publishing-templates.md"&gt;Publishing Templates&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Adding a new example&lt;/h2&gt; 
&lt;p&gt;To quickly start contributing with a new example, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm i
pnpm new-example
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the script above isn't used, make sure the example complies with the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;It must have a &lt;code&gt;.gitignore&lt;/code&gt; similar to &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/plop-templates/example/.gitignore"&gt;plop-templates/example/.gitignore&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;It must have a &lt;code&gt;package.json&lt;/code&gt; similar to &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/plop-templates/example/package.json"&gt;plop-templates/example/package.json&lt;/a&gt; (usage of Next.js is optional). The license should be &lt;code&gt;MIT&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;It must have a &lt;code&gt;README.md&lt;/code&gt; similar to &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/plop-templates/example/README.md"&gt;plop-templates/example/README.md&lt;/a&gt;. The example has to be able to include a demo URL (the Vercel team will deploy it!) and if it requires environment variables, it must have a &lt;code&gt;.env.example&lt;/code&gt; file and instructions on how to set them up. Take &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/edge-middleware/bot-protection-datadome/README.md"&gt;bot-protection-datadome&lt;/a&gt; as an example. 
  &lt;ul&gt; 
   &lt;li&gt;To customize the Vercel Deploy Button take a look at the &lt;a href="https://vercel.com/docs/deploy-button"&gt;docs&lt;/a&gt;, useful if the deployment has required environment variables.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;If using Next.js, it must have a &lt;code&gt;.eslintrc.json&lt;/code&gt; similar to &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/plop-templates/example/.eslintrc.json"&gt;plop-templates/example/.eslintrc.json&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;All Next.js examples should be using the same styling and layout provided by &lt;code&gt;@vercel/examples-ui&lt;/code&gt;, its usage can be seen in the &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/plop-templates/example"&gt;plop template&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Adding a template&lt;/h3&gt; 
&lt;p&gt;If you would like the example to be featured in &lt;a href="https://vercel.com/templates"&gt;vercel.com/templates&lt;/a&gt; then also add the front matter metadata to the top of the readme, like in &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/edge-middleware/bot-protection-datadome/README.md"&gt;bot-protection-datadome&lt;/a&gt;. To know all the possible values for each metadata take a look at &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/internal/fields.json"&gt;&lt;code&gt;internal/fields.json&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you want to add related templates to your template, copy the &lt;code&gt;slug&lt;/code&gt; from the other template into the &lt;code&gt;relatedTemplates&lt;/code&gt; field, for example for &lt;a href="https://vercel.com/templates/next.js/monorepo-turborepo"&gt;vercel.com/templates/next.js/monorepo-turborepo&lt;/a&gt; the slug is &lt;code&gt;monorepo-turborepo&lt;/code&gt;, as written in &lt;a href="https://raw.githubusercontent.com/vercel/examples/main/solutions/monorepo/README.md"&gt;solutions/monorepo/README.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;The pre-commit hook&lt;/h3&gt; 
&lt;p&gt;We use &lt;a href="https://typicode.github.io/husky/#/"&gt;Husky&lt;/a&gt; to manage the pre-commit &lt;a href="https://git-scm.com/docs/githooks"&gt;Git hook&lt;/a&gt; in this repo. Husky configures hooks automatically during install, so you don't need to do anything special to get them working, but if it fails to install, you can run the following command to install it manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm run prepare
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Code changes automatically go through Prettier and ESLint when you make a commit, &lt;strong&gt;please do not skip these steps&lt;/strong&gt; unless they're broken and in that case let us known by creating an issue.&lt;/p&gt; 
&lt;h2&gt;Read the Docs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://vercel.com/docs"&gt;Vercel Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nextjs.org/docs"&gt;Next.js Docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you have any questions or suggestions about the docs, feel free to &lt;a href="https://github.com/vercel/examples/discussions"&gt;open a discussion&lt;/a&gt;, or &lt;a href="https://github.com/vercel/examples/pulls"&gt;submit a PR&lt;/a&gt; with your suggestions!&lt;/p&gt; 
&lt;h2&gt;Provide Feedback&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vercel/examples/discussions"&gt;Start a Discussion&lt;/a&gt; with a question, piece of feedback, or idea you want to share with the team.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vercel/examples/issues"&gt;Open an Issue&lt;/a&gt; if you believe you've encountered a bug that you want to flag for the team.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Eventual-Inc/Daft</title>
      <link>https://github.com/Eventual-Inc/Daft</link>
      <description>&lt;p&gt;Distributed query engine providing simple and reliable data processing for any modality and scale&lt;/p&gt;&lt;hr&gt;&lt;p&gt;|Banner|&lt;/p&gt; 
&lt;p&gt;|CI| |PyPI| |Latest Tag| |Coverage| |Slack|&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Website &amp;lt;https://www.daft.ai&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Docs &amp;lt;https://docs.daft.ai&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Installation &amp;lt;https://docs.daft.ai/en/stable/install/&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Daft Quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_ • &lt;code&gt;Community and Support &amp;lt;https://github.com/Eventual-Inc/Daft/discussions&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;h1&gt;Daft: Unified Engine for Data Analytics, Engineering &amp;amp; ML/AI&lt;/h1&gt; 
&lt;p&gt;|TrendShift|&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Daft &amp;lt;https://www.daft.ai&amp;gt;&lt;/code&gt;_ is a distributed query engine for large-scale data processing using Python or SQL, implemented in Rust.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Familiar interactive API:&lt;/strong&gt; Lazy Python Dataframe for rapid and interactive iteration, or SQL for analytical queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Focus on the what:&lt;/strong&gt; Powerful Query Optimizer that rewrites queries to be as efficient as possible&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Catalog integrations:&lt;/strong&gt; Integration with data catalogs (AWS Glue, Unity Catalog) and table formats like Apache Iceberg&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rich multimodal type-system:&lt;/strong&gt; Supports multimodal types such as Images, URLs, Tensors and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Interchange&lt;/strong&gt;: Built on the &lt;code&gt;Apache Arrow &amp;lt;https://arrow.apache.org/docs/index.html&amp;gt;&lt;/code&gt;_ In-Memory Format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built for the cloud:&lt;/strong&gt; &lt;code&gt;Record-setting &amp;lt;https://www.daft.ai/blog/announcing-daft-02&amp;gt;&lt;/code&gt;_ I/O performance for integrations with S3 cloud storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;About Daft&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Getting Started&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Benchmarks&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Contributing&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Telemetry&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Related Projects&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;License&lt;/code&gt;_&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;About Daft&lt;/h2&gt; 
&lt;p&gt;Daft was designed with the following principles in mind:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Any Data&lt;/strong&gt;: Beyond the usual strings/numbers/dates, Daft columns can also hold complex or nested multimodal data such as Images, Embeddings and Python objects efficiently with its Arrow based memory representation. Ingestion and basic transformations of multimodal data is extremely easy and performant in Daft.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Computing&lt;/strong&gt;: Daft is built for the interactive developer experience through notebooks or REPLs - intelligent caching/query optimizations accelerates your experimentation and data exploration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Computing&lt;/strong&gt;: Some workloads can quickly outgrow your local laptop's computational resources - Daft integrates natively with &lt;code&gt;Ray &amp;lt;https://www.ray.io&amp;gt;&lt;/code&gt;_ for running dataframes on large clusters of machines with thousands of CPUs/GPUs.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Installation ^^^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;Install Daft with &lt;code&gt;pip install daft&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For more advanced installations (e.g. installing from source or with extra dependencies such as Ray and AWS utilities), please see our &lt;code&gt;Installation Guide &amp;lt;https://docs.daft.ai/en/stable/install/&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;p&gt;Quickstart ^^^^^^^^^^&lt;/p&gt; 
&lt;p&gt;Check out our &lt;code&gt;quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_!&lt;/p&gt; 
&lt;p&gt;In this example, we load images from an AWS S3 bucket's URLs and resize each image in the dataframe:&lt;/p&gt; 
&lt;p&gt;.. code:: python&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;import daft

# Load a dataframe from filepaths in an S3 bucket
df = daft.from_glob_path("s3://daft-public-data/laion-sample-images/*")

# 1. Download column of image URLs as a column of bytes
# 2. Decode the column of bytes into a column of images
df = df.with_column("image", df["path"].url.download().image.decode())

# Resize each image into 32x32
df = df.with_column("resized", df["image"].image.resize(32, 32))

df.show(3)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;|Quickstart Image|&lt;/p&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;|Benchmark Image|&lt;/p&gt; 
&lt;p&gt;To see the full benchmarks, detailed setup, and logs, check out our &lt;code&gt;benchmarking page. &amp;lt;https://docs.daft.ai/en/stable/resources/benchmarks/tpch/&amp;gt;&lt;/code&gt;_&lt;/p&gt; 
&lt;p&gt;More Resources ^^^^^^^^^^^^^^&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Daft Quickstart &amp;lt;https://docs.daft.ai/en/stable/quickstart/&amp;gt;&lt;/code&gt;_ - learn more about Daft's full range of capabilities including dataloading from URLs, joins, user-defined functions (UDF), groupby, aggregations and more.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;User Guide &amp;lt;https://docs.daft.ai/en/stable/&amp;gt;&lt;/code&gt;_ - take a deep-dive into each topic within Daft&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;API Reference &amp;lt;https://docs.daft.ai/en/stable/api/&amp;gt;&lt;/code&gt;_ - API reference for public classes/functions of Daft&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SQL Reference &amp;lt;https://docs.daft.ai/en/stable/sql/&amp;gt;&lt;/code&gt;_ - Daft SQL reference&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We &amp;lt;3 developers! To start contributing to Daft, please read &lt;code&gt;CONTRIBUTING.md &amp;lt;https://github.com/Eventual-Inc/Daft/blob/main/CONTRIBUTING.md&amp;gt;&lt;/code&gt;_. This document describes the development lifecycle and toolchain for working on Daft. It also details how to add new functionality to the core engine and expose it through a Python API.&lt;/p&gt; 
&lt;p&gt;Here's a list of &lt;code&gt;good first issues &amp;lt;https://github.com/Eventual-Inc/Daft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22&amp;gt;&lt;/code&gt;_ to get yourself warmed up with Daft. Comment in the issue to pick it up, and feel free to ask any questions!&lt;/p&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;To help improve Daft, we collect non-identifiable data via Scarf (&lt;a href="https://scarf.sh"&gt;https://scarf.sh&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;To disable this behavior, set the environment variable &lt;code&gt;DO_NOT_TRACK=true&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The data that we collect is:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Non-identifiable:&lt;/strong&gt; Events are keyed by a session ID which is generated on import of Daft&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Metadata-only:&lt;/strong&gt; We do not collect any of our users’ proprietary code or data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For development only:&lt;/strong&gt; We do not buy or sell any user data&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please see our &lt;code&gt;documentation &amp;lt;https://docs.daft.ai/en/stable/resources/telemetry/&amp;gt;&lt;/code&gt;_ for more details.&lt;/p&gt; 
&lt;p&gt;.. image:: &lt;a href="https://static.scarf.sh/a.png?x-pxid=31f8d5ba-7e09-4d75-8895-5252bbf06cf6"&gt;https://static.scarf.sh/a.png?x-pxid=31f8d5ba-7e09-4d75-8895-5252bbf06cf6&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;p&gt;+---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | Engine | Query Optimizer | Multimodal | Distributed | Arrow Backed | Vectorized Execution Engine | Out-of-core | +===================================================+=================+===============+=============+=================+=============================+=============+ | Daft | Yes | Yes | Yes | Yes | Yes | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Pandas &amp;lt;https://github.com/pandas-dev/pandas&amp;gt;&lt;/code&gt;_ | No | Python object | No | optional &amp;gt;= 2.0 | Some(Numpy) | No | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Polars &amp;lt;https://github.com/pola-rs/polars&amp;gt;&lt;/code&gt;_ | Yes | Python object | No | Yes | Yes | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Modin &amp;lt;https://github.com/modin-project/modin&amp;gt;&lt;/code&gt;_ | Yes | Python object | Yes | No | Some(Pandas) | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;PySpark &amp;lt;https://github.com/apache/spark&amp;gt;&lt;/code&gt;_ | Yes | No | Yes | Pandas UDF/IO | Pandas UDF | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+ | &lt;code&gt;Dask DF &amp;lt;https://github.com/dask/dask&amp;gt;&lt;/code&gt;_ | No | Python object | Yes | No | Some(Pandas) | Yes | +---------------------------------------------------+-----------------+---------------+-------------+-----------------+-----------------------------+-------------+&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Daft has an Apache 2.0 license - please see the LICENSE file.&lt;/p&gt; 
&lt;p&gt;.. |Quickstart Image| image:: &lt;a href="https://github.com/Eventual-Inc/Daft/assets/17691182/dea2f515-9739-4f3e-ac58-cd96d51e44a8"&gt;https://github.com/Eventual-Inc/Daft/assets/17691182/dea2f515-9739-4f3e-ac58-cd96d51e44a8&lt;/a&gt; :alt: Dataframe code to load a folder of images from AWS S3 and create thumbnails :height: 256&lt;/p&gt; 
&lt;p&gt;.. |Benchmark Image| image:: &lt;a href="https://github-production-user-asset-6210df.s3.amazonaws.com/2550285/243524430-338e427d-f049-40b3-b555-4059d6be7bfd.png"&gt;https://github-production-user-asset-6210df.s3.amazonaws.com/2550285/243524430-338e427d-f049-40b3-b555-4059d6be7bfd.png&lt;/a&gt; :alt: Benchmarks for SF100 TPCH&lt;/p&gt; 
&lt;p&gt;.. |Banner| image:: &lt;a href="https://daft.ai/images/diagram.png"&gt;https://daft.ai/images/diagram.png&lt;/a&gt; :target: &lt;a href="https://www.daft.ai"&gt;https://www.daft.ai&lt;/a&gt; :alt: Daft dataframes can load any data such as PDF documents, images, protobufs, csv, parquet and audio files into a table dataframe structure for easy querying&lt;/p&gt; 
&lt;p&gt;.. |CI| image:: &lt;a href="https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml/badge.svg"&gt;https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml/badge.svg&lt;/a&gt; :target: &lt;a href="https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml?query=branch:main"&gt;https://github.com/Eventual-Inc/Daft/actions/workflows/pr-test-suite.yml?query=branch:main&lt;/a&gt; :alt: GitHub Actions tests&lt;/p&gt; 
&lt;p&gt;.. |PyPI| image:: &lt;a href="https://img.shields.io/pypi/v/daft.svg?label=pip&amp;amp;logo=PyPI&amp;amp;logoColor=white"&gt;https://img.shields.io/pypi/v/daft.svg?label=pip&amp;amp;logo=PyPI&amp;amp;logoColor=white&lt;/a&gt; :target: &lt;a href="https://pypi.org/project/daft"&gt;https://pypi.org/project/daft&lt;/a&gt; :alt: PyPI&lt;/p&gt; 
&lt;p&gt;.. |Latest Tag| image:: &lt;a href="https://img.shields.io/github/v/tag/Eventual-Inc/Daft?label=latest&amp;amp;logo=GitHub"&gt;https://img.shields.io/github/v/tag/Eventual-Inc/Daft?label=latest&amp;amp;logo=GitHub&lt;/a&gt; :target: &lt;a href="https://github.com/Eventual-Inc/Daft/tags"&gt;https://github.com/Eventual-Inc/Daft/tags&lt;/a&gt; :alt: latest tag&lt;/p&gt; 
&lt;p&gt;.. |Coverage| image:: &lt;a href="https://codecov.io/gh/Eventual-Inc/Daft/branch/main/graph/badge.svg?token=J430QVFE89"&gt;https://codecov.io/gh/Eventual-Inc/Daft/branch/main/graph/badge.svg?token=J430QVFE89&lt;/a&gt; :target: &lt;a href="https://codecov.io/gh/Eventual-Inc/Daft"&gt;https://codecov.io/gh/Eventual-Inc/Daft&lt;/a&gt; :alt: Coverage&lt;/p&gt; 
&lt;p&gt;.. |Slack| image:: &lt;a href="https://img.shields.io/badge/slack-@distdata-purple.svg?logo=slack"&gt;https://img.shields.io/badge/slack-@distdata-purple.svg?logo=slack&lt;/a&gt; :target: &lt;a href="https://join.slack.com/t/dist-data/shared_invite/zt-2e77olvxw-uyZcPPV1SRchhi8ah6ZCtg"&gt;https://join.slack.com/t/dist-data/shared_invite/zt-2e77olvxw-uyZcPPV1SRchhi8ah6ZCtg&lt;/a&gt; :alt: slack community&lt;/p&gt; 
&lt;p&gt;.. |TrendShift| image:: &lt;a href="https://trendshift.io/api/badge/repositories/8239"&gt;https://trendshift.io/api/badge/repositories/8239&lt;/a&gt; :target: &lt;a href="https://trendshift.io/repositories/8239"&gt;https://trendshift.io/repositories/8239&lt;/a&gt; :alt: Eventual-Inc/Daft | Trendshift :width: 250px :height: 55px&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Stirling-Tools/Stirling-PDF</title>
      <link>https://github.com/Stirling-Tools/Stirling-PDF</link>
      <description>&lt;p&gt;#1 Locally hosted web application that allows you to perform various operations on PDF files&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/docs/stirling.png" width="80" /&gt;&lt;/p&gt; 
&lt;h1 align="center"&gt;Stirling-PDF&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/frooodle/s-pdf"&gt;&lt;img src="https://img.shields.io/docker/pulls/frooodle/s-pdf" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/HYmhKj45pU"&gt;&lt;img src="https://img.shields.io/discord/1068636748814483718?label=Discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/Stirling-Tools/Stirling-PDF"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/Stirling-Tools/Stirling-PDF/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Stirling-Tools/stirling-pdf"&gt;&lt;img src="https://img.shields.io/github/stars/stirling-tools/stirling-pdf?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.producthunt.com/posts/stirling-pdf?embed=true&amp;amp;utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-stirling-pdf" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=641239&amp;amp;theme=light" alt="Stirling PDF - Open source locally hosted web PDF editor | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;a href="https://cloud.digitalocean.com/apps/new?repo=https://github.com/Stirling-Tools/Stirling-PDF/tree/digitalOcean&amp;amp;refcode=c3210994b1af"&gt;&lt;img src="https://www.deploytodo.com/do-btn-blue.svg?sanitize=true" alt="Deploy to DO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.stirlingpdf.com"&gt;Stirling-PDF&lt;/a&gt; is a robust, locally hosted web-based PDF manipulation tool using Docker. It enables you to carry out various operations on PDF files, including splitting, merging, converting, reorganizing, adding images, rotating, compressing, and more. This locally hosted web application has evolved to encompass a comprehensive set of features, addressing all your PDF requirements.&lt;/p&gt; 
&lt;p&gt;All files and PDFs exist either exclusively on the client side, reside in server memory only during task execution, or temporarily reside in a file solely for the execution of the task. Any file downloaded by the user will have been deleted from the server by that point.&lt;/p&gt; 
&lt;p&gt;Homepage: &lt;a href="https://stirlingpdf.com"&gt;https://stirlingpdf.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;All documentation available at &lt;a href="https://docs.stirlingpdf.com/"&gt;https://docs.stirlingpdf.com/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/images/stirling-home.jpg" alt="stirling-home" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;50+ PDF Operations&lt;/li&gt; 
 &lt;li&gt;Parallel file processing and downloads&lt;/li&gt; 
 &lt;li&gt;Dark mode support&lt;/li&gt; 
 &lt;li&gt;Custom download options&lt;/li&gt; 
 &lt;li&gt;Custom 'Pipelines' to run multiple features in a automated queue&lt;/li&gt; 
 &lt;li&gt;API for integration with external scripts&lt;/li&gt; 
 &lt;li&gt;Optional Login and Authentication support (see &lt;a href="https://docs.stirlingpdf.com/Advanced%20Configuration/System%20and%20Security"&gt;here&lt;/a&gt; for documentation)&lt;/li&gt; 
 &lt;li&gt;Database Backup and Import (see &lt;a href="https://docs.stirlingpdf.com/Advanced%20Configuration/DATABASE"&gt;here&lt;/a&gt; for documentation)&lt;/li&gt; 
 &lt;li&gt;Enterprise features like SSO (see &lt;a href="https://docs.stirlingpdf.com/Advanced%20Configuration/Single%20Sign-On%20Configuration"&gt;here&lt;/a&gt; for documentation)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;PDF Features&lt;/h2&gt; 
&lt;h3&gt;Page Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;View and modify PDFs - View multi-page PDFs with custom viewing, sorting, and searching. Plus, on-page edit features like annotating, drawing, and adding text and images. (Using PDF.js with Joxit and Liberation fonts)&lt;/li&gt; 
 &lt;li&gt;Full interactive GUI for merging/splitting/rotating/moving PDFs and their pages&lt;/li&gt; 
 &lt;li&gt;Merge multiple PDFs into a single resultant file&lt;/li&gt; 
 &lt;li&gt;Split PDFs into multiple files at specified page numbers or extract all pages as individual files&lt;/li&gt; 
 &lt;li&gt;Reorganize PDF pages into different orders&lt;/li&gt; 
 &lt;li&gt;Rotate PDFs in 90-degree increments&lt;/li&gt; 
 &lt;li&gt;Remove pages&lt;/li&gt; 
 &lt;li&gt;Multi-page layout (format PDFs into a multi-paged page)&lt;/li&gt; 
 &lt;li&gt;Scale page contents size by set percentage&lt;/li&gt; 
 &lt;li&gt;Adjust contrast&lt;/li&gt; 
 &lt;li&gt;Crop PDF&lt;/li&gt; 
 &lt;li&gt;Auto-split PDF (with physically scanned page dividers)&lt;/li&gt; 
 &lt;li&gt;Extract page(s)&lt;/li&gt; 
 &lt;li&gt;Convert PDF to a single page&lt;/li&gt; 
 &lt;li&gt;Overlay PDFs on top of each other&lt;/li&gt; 
 &lt;li&gt;PDF to a single page&lt;/li&gt; 
 &lt;li&gt;Split PDF by sections&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Conversion Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Convert PDFs to and from images&lt;/li&gt; 
 &lt;li&gt;Convert any common file to PDF (using LibreOffice)&lt;/li&gt; 
 &lt;li&gt;Convert PDF to Word/PowerPoint/others (using LibreOffice)&lt;/li&gt; 
 &lt;li&gt;Convert HTML to PDF&lt;/li&gt; 
 &lt;li&gt;Convert PDF to XML&lt;/li&gt; 
 &lt;li&gt;Convert PDF to CSV&lt;/li&gt; 
 &lt;li&gt;URL to PDF&lt;/li&gt; 
 &lt;li&gt;Markdown to PDF&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Security &amp;amp; Permissions&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add and remove passwords&lt;/li&gt; 
 &lt;li&gt;Change/set PDF permissions&lt;/li&gt; 
 &lt;li&gt;Add watermark(s)&lt;/li&gt; 
 &lt;li&gt;Certify/sign PDFs&lt;/li&gt; 
 &lt;li&gt;Sanitize PDFs&lt;/li&gt; 
 &lt;li&gt;Auto-redact text&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Other Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add/generate/write signatures&lt;/li&gt; 
 &lt;li&gt;Split by Size or PDF&lt;/li&gt; 
 &lt;li&gt;Repair PDFs&lt;/li&gt; 
 &lt;li&gt;Detect and remove blank pages&lt;/li&gt; 
 &lt;li&gt;Compare two PDFs and show differences in text&lt;/li&gt; 
 &lt;li&gt;Add images to PDFs&lt;/li&gt; 
 &lt;li&gt;Compress PDFs to decrease their filesize (using qpdf)&lt;/li&gt; 
 &lt;li&gt;Extract images from PDF&lt;/li&gt; 
 &lt;li&gt;Remove images from PDF&lt;/li&gt; 
 &lt;li&gt;Extract images from scans&lt;/li&gt; 
 &lt;li&gt;Remove annotations&lt;/li&gt; 
 &lt;li&gt;Add page numbers&lt;/li&gt; 
 &lt;li&gt;Auto-rename files by detecting PDF header text&lt;/li&gt; 
 &lt;li&gt;OCR on PDF (using Tesseract OCR)&lt;/li&gt; 
 &lt;li&gt;PDF/A conversion (using LibreOffice)&lt;/li&gt; 
 &lt;li&gt;Edit metadata&lt;/li&gt; 
 &lt;li&gt;Flatten PDFs&lt;/li&gt; 
 &lt;li&gt;Get all information on a PDF to view or export as JSON&lt;/li&gt; 
 &lt;li&gt;Show/detect embedded JavaScript&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;📖 Get Started&lt;/h1&gt; 
&lt;p&gt;Visit our comprehensive documentation at &lt;a href="https://docs.stirlingpdf.com"&gt;docs.stirlingpdf.com&lt;/a&gt; for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Installation guides for all platforms&lt;/li&gt; 
 &lt;li&gt;Configuration options&lt;/li&gt; 
 &lt;li&gt;Feature documentation&lt;/li&gt; 
 &lt;li&gt;API reference&lt;/li&gt; 
 &lt;li&gt;Security setup&lt;/li&gt; 
 &lt;li&gt;Enterprise features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Languages&lt;/h2&gt; 
&lt;p&gt;Stirling-PDF currently supports 40 languages!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Progress&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Arabic (العربية) (ar_AR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/61" alt="61%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azerbaijani (Azərbaycan Dili) (az_AZ)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/62" alt="62%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Basque (Euskara) (eu_ES)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/36" alt="36%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Bulgarian (Български) (bg_BG)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/68" alt="68%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Catalan (Català) (ca_CA)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Croatian (Hrvatski) (hr_HR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/60" alt="60%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Czech (Česky) (cs_CZ)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/69" alt="69%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Danish (Dansk) (da_DK)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/61" alt="61%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dutch (Nederlands) (nl_NL)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/60" alt="60%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;English (English) (en_GB)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/100" alt="100%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;English (US) (en_US)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/100" alt="100%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;French (Français) (fr_FR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/88" alt="88%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;German (Deutsch) (de_DE)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/97" alt="97%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Greek (Ελληνικά) (el_GR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hindi (हिंदी) (hi_IN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hungarian (Magyar) (hu_HU)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/99" alt="99%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Indonesian (Bahasa Indonesia) (id_ID)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/62" alt="62%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Irish (Gaeilge) (ga_IE)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/68" alt="68%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Italian (Italiano) (it_IT)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/98" alt="98%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Japanese (日本語) (ja_JP)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/92" alt="92%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Korean (한국어) (ko_KR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/67" alt="67%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Norwegian (Norsk) (no_NB)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/66" alt="66%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Persian (فارسی) (fa_IR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/64" alt="64%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Polish (Polski) (pl_PL)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/72" alt="72%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portuguese (Português) (pt_PT)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/68" alt="68%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portuguese Brazilian (Português) (pt_BR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/76" alt="76%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Romanian (Română) (ro_RO)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/57" alt="57%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Russian (Русский) (ru_RU)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/88" alt="88%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Serbian Latin alphabet (Srpski) (sr_LATN_RS)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/94" alt="94%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Simplified Chinese (简体中文) (zh_CN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/93" alt="93%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Slovakian (Slovensky) (sk_SK)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/51" alt="51%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Slovenian (Slovenščina) (sl_SI)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/71" alt="71%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Spanish (Español) (es_ES)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/74" alt="74%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Swedish (Svenska) (sv_SE)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/65" alt="65%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Thai (ไทย) (th_TH)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/59" alt="59%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tibetan (བོད་ཡིག་) (bo_CN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/65" alt="65%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Traditional Chinese (繁體中文) (zh_TW)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/99" alt="99%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Turkish (Türkçe) (tr_TR)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/99" alt="99%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ukrainian (Українська) (uk_UA)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/70" alt="70%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vietnamese (Tiếng Việt) (vi_VN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/57" alt="57%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Malayalam (മലയാളം) (ml_IN)&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://geps.dev/progress/73" alt="73%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Stirling PDF Enterprise&lt;/h2&gt; 
&lt;p&gt;Stirling PDF offers an Enterprise edition of its software. This is the same great software but with added features, support and comforts. Check out our &lt;a href="https://docs.stirlingpdf.com/Pro"&gt;Enterprise docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🤝 Looking to contribute?&lt;/h2&gt; 
&lt;p&gt;Join our community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/devGuide/HowToAddNewLanguage.md"&gt;Translation Guide (How to add custom languages)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Stirling-Tools/Stirling-PDF/main/devGuide/DeveloperGuide.md"&gt;Developer Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Stirling-Tools/Stirling-PDF/issues"&gt;Issue Tracker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/HYmhKj45pU"&gt;Discord Community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Physical-Intelligence/openpi</title>
      <link>https://github.com/Physical-Intelligence/openpi</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;openpi&lt;/h1&gt; 
&lt;p&gt;openpi holds open-source models and packages for robotics, published by the &lt;a href="https://www.physicalintelligence.company/"&gt;Physical Intelligence team&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Currently, this repo contains three types of models:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the &lt;a href="https://www.physicalintelligence.company/blog/pi0"&gt;π₀ model&lt;/a&gt;, a flow-based vision-language-action model (VLA).&lt;/li&gt; 
 &lt;li&gt;the &lt;a href="https://www.physicalintelligence.company/research/fast"&gt;π₀-FAST model&lt;/a&gt;, an autoregressive VLA, based on the FAST action tokenizer.&lt;/li&gt; 
 &lt;li&gt;the &lt;a href="https://www.physicalintelligence.company/blog/pi05"&gt;π₀.₅ model&lt;/a&gt;, an upgraded version of π₀ with better open-world generalization trained with &lt;a href="https://www.physicalintelligence.company/research/knowledge_insulation"&gt;knowledge insulation&lt;/a&gt;. Note that, in this repository, we currently only support the flow matching head for both $\pi_{0.5}$ training and inference.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For all models, we provide &lt;em&gt;base model&lt;/em&gt; checkpoints, pre-trained on 10k+ hours of robot data, and examples for using them out of the box or fine-tuning them to your own datasets.&lt;/p&gt; 
&lt;p&gt;This is an experiment: $\pi_0$ was developed for our own robots, which differ from the widely used platforms such as &lt;a href="https://tonyzhaozh.github.io/aloha/"&gt;ALOHA&lt;/a&gt; and &lt;a href="https://droid-dataset.github.io/"&gt;DROID&lt;/a&gt;, and though we are optimistic that researchers and practitioners will be able to run creative new experiments adapting $\pi_0$ to their own platforms, we do not expect every such attempt to be successful. All this is to say: $\pi_0$ may or may not work for you, but you are welcome to try it and see!&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[Sept 2025] We released PyTorch support in openpi.&lt;/li&gt; 
 &lt;li&gt;[Sept 2025] We released pi05, an upgraded version of pi0 with better open-world generalization.&lt;/li&gt; 
 &lt;li&gt;[Sept 2025]: We have added an &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/droid/README_train.md#data-filtering"&gt;improved idle filter&lt;/a&gt; for DROID training.&lt;/li&gt; 
 &lt;li&gt;[Jun 2025]: We have added &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/droid/README_train.md"&gt;instructions&lt;/a&gt; for using &lt;code&gt;openpi&lt;/code&gt; to train VLAs on the full &lt;a href="https://droid-dataset.github.io/"&gt;DROID dataset&lt;/a&gt;. This is an approximate open-source implementation of the training pipeline used to train pi0-FAST-DROID.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;To run the models in this repository, you will need an NVIDIA GPU with at least the following specifications. These estimations assume a single GPU, but you can also use multiple GPUs with model parallelism to reduce per-GPU memory requirements by configuring &lt;code&gt;fsdp_devices&lt;/code&gt; in the training config. Please also note that the current training script does not yet support multi-node training.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Mode&lt;/th&gt; 
   &lt;th&gt;Memory Required&lt;/th&gt; 
   &lt;th&gt;Example GPU&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;&amp;gt; 8 GB&lt;/td&gt; 
   &lt;td&gt;RTX 4090&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fine-Tuning (LoRA)&lt;/td&gt; 
   &lt;td&gt;&amp;gt; 22.5 GB&lt;/td&gt; 
   &lt;td&gt;RTX 4090&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fine-Tuning (Full)&lt;/td&gt; 
   &lt;td&gt;&amp;gt; 70 GB&lt;/td&gt; 
   &lt;td&gt;A100 (80GB) / H100&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The repo has been tested with Ubuntu 22.04, we do not currently support other operating systems.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;When cloning this repo, make sure to update submodules:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recurse-submodules git@github.com:Physical-Intelligence/openpi.git

# Or if you already cloned the repo:
git submodule update --init --recursive
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We use &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt; to manage Python dependencies. See the &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv installation instructions&lt;/a&gt; to set it up. Once uv is installed, run the following to set up the environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;GIT_LFS_SKIP_SMUDGE=1 uv sync
GIT_LFS_SKIP_SMUDGE=1 uv pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;NOTE: &lt;code&gt;GIT_LFS_SKIP_SMUDGE=1&lt;/code&gt; is needed to pull LeRobot as a dependency.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;: As an alternative to uv installation, we provide instructions for installing openpi using Docker. If you encounter issues with your system setup, consider using Docker to simplify installation. See &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/docs/docker.md"&gt;Docker Setup&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Model Checkpoints&lt;/h2&gt; 
&lt;h3&gt;Base Models&lt;/h3&gt; 
&lt;p&gt;We provide multiple base VLA model checkpoints. These checkpoints have been pre-trained on 10k+ hours of robot data, and can be used for fine-tuning.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Checkpoint Path&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$&lt;/td&gt; 
   &lt;td&gt;Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;Base &lt;a href="https://www.physicalintelligence.company/blog/pi0"&gt;π₀ model&lt;/a&gt; for fine-tuning&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-FAST&lt;/td&gt; 
   &lt;td&gt;Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;Base autoregressive &lt;a href="https://www.physicalintelligence.company/research/fast"&gt;π₀-FAST model&lt;/a&gt; for fine-tuning&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_fast_base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_{0.5}$&lt;/td&gt; 
   &lt;td&gt;Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;Base &lt;a href="https://www.physicalintelligence.company/blog/pi05"&gt;π₀.₅ model&lt;/a&gt; for fine-tuning&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi05_base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Fine-Tuned Models&lt;/h3&gt; 
&lt;p&gt;We also provide "expert" checkpoints for various robot platforms and tasks. These models are fine-tuned from the base models above and intended to run directly on the target robot. These may or may not work on your particular robot. Since these checkpoints were fine-tuned on relatively small datasets collected with more widely available robots, such as ALOHA and the DROID Franka setup, they might not generalize to your particular setup, though we found some of these, especially the DROID checkpoint, to generalize quite broadly in practice.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Checkpoint Path&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-FAST-DROID&lt;/td&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;$\pi_0$-FAST model fine-tuned on the &lt;a href="https://droid-dataset.github.io/"&gt;DROID dataset&lt;/a&gt;: can perform a wide range of simple table-top manipulation tasks 0-shot in new scenes on the DROID robot platform&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_fast_droid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-DROID&lt;/td&gt; 
   &lt;td&gt;Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;$\pi_0$ model fine-tuned on the &lt;a href="https://droid-dataset.github.io/"&gt;DROID dataset&lt;/a&gt;: faster inference than $\pi_0$-FAST-DROID, but may not follow language commands as well&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_droid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-ALOHA-towel&lt;/td&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;$\pi_0$ model fine-tuned on internal &lt;a href="https://tonyzhaozh.github.io/aloha/"&gt;ALOHA&lt;/a&gt; data: can fold diverse towels 0-shot on ALOHA robot platforms&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_aloha_towel&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-ALOHA-tupperware&lt;/td&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;$\pi_0$ model fine-tuned on internal &lt;a href="https://tonyzhaozh.github.io/aloha/"&gt;ALOHA&lt;/a&gt; data: can unpack food from a tupperware container&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_aloha_tupperware&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_0$-ALOHA-pen-uncap&lt;/td&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;$\pi_0$ model fine-tuned on public &lt;a href="https://dit-policy.github.io/"&gt;ALOHA&lt;/a&gt; data: can uncap a pen&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi0_aloha_pen_uncap&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_{0.5}$-LIBERO&lt;/td&gt; 
   &lt;td&gt;Inference&lt;/td&gt; 
   &lt;td&gt;$\pi_{0.5}$ model fine-tuned for the &lt;a href="https://libero-project.github.io/datasets"&gt;LIBERO&lt;/a&gt; benchmark: gets state-of-the-art performance (see &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/libero/README.md"&gt;LIBERO README&lt;/a&gt;)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi05_libero&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;$\pi_{0.5}$-DROID&lt;/td&gt; 
   &lt;td&gt;Inference / Fine-Tuning&lt;/td&gt; 
   &lt;td&gt;$\pi_{0.5}$ model fine-tuned on the &lt;a href="https://droid-dataset.github.io/"&gt;DROID dataset&lt;/a&gt; with &lt;a href="https://www.physicalintelligence.company/research/knowledge_insulation"&gt;knowledge insulation&lt;/a&gt;: fast inference and good language-following&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gs://openpi-assets/checkpoints/pi05_droid&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;By default, checkpoints are automatically downloaded from &lt;code&gt;gs://openpi-assets&lt;/code&gt; and are cached in &lt;code&gt;~/.cache/openpi&lt;/code&gt; when needed. You can overwrite the download path by setting the &lt;code&gt;OPENPI_DATA_HOME&lt;/code&gt; environment variable.&lt;/p&gt; 
&lt;h2&gt;Running Inference for a Pre-Trained Model&lt;/h2&gt; 
&lt;p&gt;Our pre-trained model checkpoints can be run with a few lines of code (here our $\pi_0$-FAST-DROID model):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openpi.training import config as _config
from openpi.policies import policy_config
from openpi.shared import download

config = _config.get_config("pi05_droid")
checkpoint_dir = download.maybe_download("gs://openpi-assets/checkpoints/pi05_droid")

# Create a trained policy.
policy = policy_config.create_trained_policy(config, checkpoint_dir)

# Run inference on a dummy example.
example = {
    "observation/exterior_image_1_left": ...,
    "observation/wrist_image_left": ...,
    ...
    "prompt": "pick up the fork"
}
action_chunk = policy.infer(example)["actions"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also test this out in the &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/inference.ipynb"&gt;example notebook&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We provide detailed step-by-step examples for running inference of our pre-trained checkpoints on &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/droid/README.md"&gt;DROID&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/aloha_real/README.md"&gt;ALOHA&lt;/a&gt; robots.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Remote Inference&lt;/strong&gt;: We provide &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/docs/remote_inference.md"&gt;examples and code&lt;/a&gt; for running inference of our models &lt;strong&gt;remotely&lt;/strong&gt;: the model can run on a different server and stream actions to the robot via a websocket connection. This makes it easy to use more powerful GPUs off-robot and keep robot and policy environments separate.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Test inference without a robot&lt;/strong&gt;: We provide a &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/simple_client/README.md"&gt;script&lt;/a&gt; for testing inference without a robot. This script will generate a random observation and run inference with the model. See &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/simple_client/README.md"&gt;here&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Fine-Tuning Base Models on Your Own Data&lt;/h2&gt; 
&lt;p&gt;We will fine-tune the $\pi_{0.5}$ model on the &lt;a href="https://libero-project.github.io/datasets"&gt;LIBERO dataset&lt;/a&gt; as a running example for how to fine-tune a base model on your own data. We will explain three steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Convert your data to a LeRobot dataset (which we use for training)&lt;/li&gt; 
 &lt;li&gt;Defining training configs and running training&lt;/li&gt; 
 &lt;li&gt;Spinning up a policy server and running inference&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;1. Convert your data to a LeRobot dataset&lt;/h3&gt; 
&lt;p&gt;We provide a minimal example script for converting LIBERO data to a LeRobot dataset in &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/libero/convert_libero_data_to_lerobot.py"&gt;&lt;code&gt;examples/libero/convert_libero_data_to_lerobot.py&lt;/code&gt;&lt;/a&gt;. You can easily modify it to convert your own data! You can download the raw LIBERO dataset from &lt;a href="https://huggingface.co/datasets/openvla/modified_libero_rlds"&gt;here&lt;/a&gt;, and run the script with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run examples/libero/convert_libero_data_to_lerobot.py --data_dir /path/to/your/libero/data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you just want to fine-tune on LIBERO, you can skip this step, because our LIBERO fine-tuning configs point to a pre-converted LIBERO dataset. This step is merely an example that you can adapt to your own data.&lt;/p&gt; 
&lt;h3&gt;2. Defining training configs and running training&lt;/h3&gt; 
&lt;p&gt;To fine-tune a base model on your own data, you need to define configs for data processing and training. We provide example configs with detailed comments for LIBERO below, which you can modify for your own dataset:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/policies/libero_policy.py"&gt;&lt;code&gt;LiberoInputs&lt;/code&gt; and &lt;code&gt;LiberoOutputs&lt;/code&gt;&lt;/a&gt;: Defines the data mapping from the LIBERO environment to the model and vice versa. Will be used for both, training and inference.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py"&gt;&lt;code&gt;LeRobotLiberoDataConfig&lt;/code&gt;&lt;/a&gt;: Defines how to process raw LIBERO data from LeRobot dataset for training.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py"&gt;&lt;code&gt;TrainConfig&lt;/code&gt;&lt;/a&gt;: Defines fine-tuning hyperparameters, data config, and weight loader.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We provide example fine-tuning configs for &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py"&gt;π₀&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py"&gt;π₀-FAST&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/src/openpi/training/config.py"&gt;π₀.₅&lt;/a&gt; on LIBERO data.&lt;/p&gt; 
&lt;p&gt;Before we can run training, we need to compute the normalization statistics for the training data. Run the script below with the name of your training config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run scripts/compute_norm_stats.py --config-name pi05_libero
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now we can kick off training with the following command (the &lt;code&gt;--overwrite&lt;/code&gt; flag is used to overwrite existing checkpoints if you rerun fine-tuning with the same config):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;XLA_PYTHON_CLIENT_MEM_FRACTION=0.9 uv run scripts/train.py pi05_libero --exp-name=my_experiment --overwrite
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The command will log training progress to the console and save checkpoints to the &lt;code&gt;checkpoints&lt;/code&gt; directory. You can also monitor training progress on the Weights &amp;amp; Biases dashboard. For maximally using the GPU memory, set &lt;code&gt;XLA_PYTHON_CLIENT_MEM_FRACTION=0.9&lt;/code&gt; before running training -- this enables JAX to use up to 90% of the GPU memory (vs. the default of 75%).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We provide functionality for &lt;em&gt;reloading&lt;/em&gt; normalization statistics for state / action normalization from pre-training. This can be beneficial if you are fine-tuning to a new task on a robot that was part of our pre-training mixture. For more details on how to reload normalization statistics, see the &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/docs/norm_stats.md"&gt;norm_stats.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h3&gt;3. Spinning up a policy server and running inference&lt;/h3&gt; 
&lt;p&gt;Once training is complete, we can run inference by spinning up a policy server and then querying it from a LIBERO evaluation script. Launching a model server is easy (we use the checkpoint for iteration 20,000 for this example, modify as needed):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run scripts/serve_policy.py policy:checkpoint --policy.config=pi05_libero --policy.dir=checkpoints/pi05_libero/my_experiment/20000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will spin up a server that listens on port 8000 and waits for observations to be sent to it. We can then run an evaluation script (or robot runtime) that queries the server.&lt;/p&gt; 
&lt;p&gt;For running the LIBERO eval in particular, we provide (and recommend using) a Dockerized workflow that handles both the policy server and the evaluation script together. See the &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/libero/README.md"&gt;LIBERO README&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;If you want to embed a policy server call in your own robot runtime, we have a minimal example of how to do so in the &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/docs/remote_inference.md"&gt;remote inference docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;More Examples&lt;/h3&gt; 
&lt;p&gt;We provide more examples for how to fine-tune and run inference with our models on the ALOHA platform in the following READMEs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/aloha_sim"&gt;ALOHA Simulator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/aloha_real"&gt;ALOHA Real&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/examples/ur5"&gt;UR5&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;PyTorch Support&lt;/h2&gt; 
&lt;p&gt;openpi now provides PyTorch implementations of π₀ and π₀.₅ models alongside the original JAX versions! The PyTorch implementation has been validated on the LIBERO benchmark (both inference and finetuning). A few features are currently not supported (this may change in the future):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The π₀-FAST model&lt;/li&gt; 
 &lt;li&gt;Mixed precision training&lt;/li&gt; 
 &lt;li&gt;FSDP (fully-sharded data parallelism) training&lt;/li&gt; 
 &lt;li&gt;LoRA (low-rank adaptation) training&lt;/li&gt; 
 &lt;li&gt;EMA (exponential moving average) weights during training&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Make sure that you have the latest version of all dependencies installed: &lt;code&gt;uv sync&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Double check that you have transformers 4.53.2 installed: &lt;code&gt;uv pip show transformers&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Apply the transformers library patches:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cp -r ./src/openpi/models_pytorch/transformers_replace/* .venv/lib/python3.11/site-packages/transformers/
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This overwrites several files in the transformers library with necessary model changes: 1) supporting AdaRMS, 2) correctly controlling the precision of activations, and 3) allowing the KV cache to be used without being updated.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: With the default uv link mode (hardlink), this will permanently affect the transformers library in your uv cache, meaning the changes will survive reinstallations of transformers and could even propagate to other projects that use transformers. To fully undo this operation, you must run &lt;code&gt;uv cache clean transformers&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Converting JAX Models to PyTorch&lt;/h3&gt; 
&lt;p&gt;To convert a JAX model checkpoint to PyTorch format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run examples/convert_jax_model_to_pytorch.py \
    --checkpoint_dir /path/to/jax/checkpoint \
    --config_name &amp;lt;config name&amp;gt; \
    --output_path /path/to/converted/pytorch/checkpoint
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running Inference with PyTorch&lt;/h3&gt; 
&lt;p&gt;The PyTorch implementation uses the same API as the JAX version - you only need to change the checkpoint path to point to the converted PyTorch model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openpi.training import config as _config
from openpi.policies import policy_config
from openpi.shared import download

config = _config.get_config("pi05_droid")
checkpoint_dir = "/path/to/converted/pytorch/checkpoint"

# Create a trained policy (automatically detects PyTorch format)
policy = policy_config.create_trained_policy(config, checkpoint_dir)

# Run inference (same API as JAX)
action_chunk = policy.infer(example)["actions"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Policy Server with PyTorch&lt;/h3&gt; 
&lt;p&gt;The policy server works identically with PyTorch models - just point to the converted checkpoint directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run scripts/serve_policy.py policy:checkpoint \
    --policy.config=pi05_droid \
    --policy.dir=/path/to/converted/pytorch/checkpoint
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Finetuning with PyTorch&lt;/h3&gt; 
&lt;p&gt;To finetune a model in PyTorch:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Convert the JAX base model to PyTorch format:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run examples/convert_jax_model_to_pytorch.py \
    --config_name &amp;lt;config name&amp;gt; \
    --checkpoint_dir /path/to/jax/base/model \
    --output_path /path/to/pytorch/base/model
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Specify the converted PyTorch model path in your config using &lt;code&gt;pytorch_weight_path&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Launch training using one of these modes:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Single GPU training:
uv run scripts/train_pytorch.py &amp;lt;config_name&amp;gt; --exp_name &amp;lt;run_name&amp;gt; --save_interval &amp;lt;interval&amp;gt;

# Example:
uv run scripts/train_pytorch.py debug --exp_name pytorch_test
uv run scripts/train_pytorch.py debug --exp_name pytorch_test --resume  # Resume from latest checkpoint

# Multi-GPU training (single node):
uv run torchrun --standalone --nnodes=1 --nproc_per_node=&amp;lt;num_gpus&amp;gt; scripts/train_pytorch.py &amp;lt;config_name&amp;gt; --exp_name &amp;lt;run_name&amp;gt;

# Example:
uv run torchrun --standalone --nnodes=1 --nproc_per_node=2 scripts/train_pytorch.py pi0_aloha_sim --exp_name pytorch_ddp_test
uv run torchrun --standalone --nnodes=1 --nproc_per_node=2 scripts/train_pytorch.py pi0_aloha_sim --exp_name pytorch_ddp_test --resume

# Multi-Node Training:
uv run torchrun \
    --nnodes=&amp;lt;num_nodes&amp;gt; \
    --nproc_per_node=&amp;lt;gpus_per_node&amp;gt; \
    --node_rank=&amp;lt;rank_of_node&amp;gt; \
    --master_addr=&amp;lt;master_ip&amp;gt; \
    --master_port=&amp;lt;port&amp;gt; \
    scripts/train_pytorch.py &amp;lt;config_name&amp;gt; --exp_name=&amp;lt;run_name&amp;gt; --save_interval &amp;lt;interval&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Precision Settings&lt;/h3&gt; 
&lt;p&gt;JAX and PyTorch implementations handle precision as follows:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;JAX:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Inference: most weights and computations in bfloat16, with a few computations in float32 for stability&lt;/li&gt; 
 &lt;li&gt;Training: defaults to mixed precision: weights and gradients in float32, (most) activations and computations in bfloat16. You can change to full float32 training by setting &lt;code&gt;dtype&lt;/code&gt; to float32 in the config.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;PyTorch:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Inference: matches JAX -- most weights and computations in bfloat16, with a few weights converted to float32 for stability&lt;/li&gt; 
 &lt;li&gt;Training: supports either full bfloat16 (default) or full float32. You can change it by setting &lt;code&gt;pytorch_training_precision&lt;/code&gt; in the config. bfloat16 uses less memory but exhibits higher losses compared to float32. Mixed precision is not yet supported.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;With torch.compile, inference speed is comparable between JAX and PyTorch.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;We will collect common issues and their solutions here. If you encounter an issue, please check here first. If you can't find a solution, please file an issue on the repo (see &lt;a href="https://raw.githubusercontent.com/Physical-Intelligence/openpi/main/CONTRIBUTING.md"&gt;here&lt;/a&gt; for guidelines).&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Issue&lt;/th&gt; 
   &lt;th&gt;Resolution&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;uv sync&lt;/code&gt; fails with dependency conflicts&lt;/td&gt; 
   &lt;td&gt;Try removing the virtual environment directory (&lt;code&gt;rm -rf .venv&lt;/code&gt;) and running &lt;code&gt;uv sync&lt;/code&gt; again. If issues persist, check that you have the latest version of &lt;code&gt;uv&lt;/code&gt; installed (&lt;code&gt;uv self update&lt;/code&gt;).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Training runs out of GPU memory&lt;/td&gt; 
   &lt;td&gt;Make sure you set &lt;code&gt;XLA_PYTHON_CLIENT_MEM_FRACTION=0.9&lt;/code&gt; (or higher) before running training to allow JAX to use more GPU memory. You can also use &lt;code&gt;--fsdp-devices &amp;lt;n&amp;gt;&lt;/code&gt; where &lt;code&gt;&amp;lt;n&amp;gt;&lt;/code&gt; is your number of GPUs, to enable &lt;a href="https://engineering.fb.com/2021/07/15/open-source/fsdp/"&gt;fully-sharded data parallelism&lt;/a&gt;, which reduces memory usage in exchange for slower training (the amount of slowdown depends on your particular setup). If you are still running out of memory, you may way to consider disabling EMA.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Policy server connection errors&lt;/td&gt; 
   &lt;td&gt;Check that the server is running and listening on the expected port. Verify network connectivity and firewall settings between client and server.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Missing norm stats error when training&lt;/td&gt; 
   &lt;td&gt;Run &lt;code&gt;scripts/compute_norm_stats.py&lt;/code&gt; with your config name before starting training.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dataset download fails&lt;/td&gt; 
   &lt;td&gt;Check your internet connection. For HuggingFace datasets, ensure you're logged in (&lt;code&gt;huggingface-cli login&lt;/code&gt;).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CUDA/GPU errors&lt;/td&gt; 
   &lt;td&gt;Verify NVIDIA drivers are installed correctly. For Docker, ensure nvidia-container-toolkit is installed. Check GPU compatibility. You do NOT need CUDA libraries installed at a system level --- they will be installed via uv. You may even want to try &lt;em&gt;uninstalling&lt;/em&gt; system CUDA libraries if you run into CUDA issues, since system libraries can sometimes cause conflicts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Import errors when running examples&lt;/td&gt; 
   &lt;td&gt;Make sure you've installed all dependencies with &lt;code&gt;uv sync&lt;/code&gt;. Some examples may have additional requirements listed in their READMEs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Action dimensions mismatch&lt;/td&gt; 
   &lt;td&gt;Verify your data processing transforms match the expected input/output dimensions of your robot. Check the action space definitions in your policy classes.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Diverging training loss&lt;/td&gt; 
   &lt;td&gt;Check the &lt;code&gt;q01&lt;/code&gt;, &lt;code&gt;q99&lt;/code&gt;, and &lt;code&gt;std&lt;/code&gt; values in &lt;code&gt;norm_stats.json&lt;/code&gt; for your dataset. Certain dimensions that are rarely used can end up with very small &lt;code&gt;q01&lt;/code&gt;, &lt;code&gt;q99&lt;/code&gt;, or &lt;code&gt;std&lt;/code&gt; values, leading to huge states and actions after normalization. You can manually adjust the norm stats as a workaround.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>Zie619/n8n-workflows</title>
      <link>https://github.com/Zie619/n8n-workflows</link>
      <description>&lt;p&gt;all of the workflows of n8n i could find (also from the site itself)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;⚡ N8N Workflow Collection &amp;amp; Documentation&lt;/h1&gt; 
&lt;p&gt;A professionally organized collection of &lt;strong&gt;2,053 n8n workflows&lt;/strong&gt; with a lightning-fast documentation system that provides instant search, analysis, and browsing capabilities.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;⚠️ IMPORTANT NOTICE (Aug 14, 2025):&lt;/strong&gt; Repository history has been rewritten due to DMCA compliance. If you have a fork or local clone, please see &lt;a href="https://github.com/Zie619/n8n-workflows/issues"&gt;Issue #X&lt;/a&gt; for instructions on syncing your copy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Support My Work&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.buymeacoffee.com/zie619"&gt;&lt;img src="https://img.shields.io/badge/-Buy%20Me%20a%20Coffee-ffdd00?logo=buy-me-a-coffee&amp;amp;logoColor=black&amp;amp;style=flat" alt="Buy Me a Coffee" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you'd like to say thanks, consider buying me a coffee—your support helps me keep improving this project!&lt;/p&gt; 
&lt;h2&gt;🚀 &lt;strong&gt;NEW: High-Performance Documentation System&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Experience 100x performance improvement over traditional documentation!&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Quick Start - Fast Documentation System&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies
pip install -r requirements.txt

# Start the fast API server
python run.py

# Open in browser
http://localhost:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;⚡ &lt;strong&gt;Sub-100ms response times&lt;/strong&gt; with SQLite FTS5 search&lt;/li&gt; 
 &lt;li&gt;🔍 &lt;strong&gt;Instant full-text search&lt;/strong&gt; with advanced filtering&lt;/li&gt; 
 &lt;li&gt;📱 &lt;strong&gt;Responsive design&lt;/strong&gt; - works perfectly on mobile&lt;/li&gt; 
 &lt;li&gt;🌙 &lt;strong&gt;Dark/light themes&lt;/strong&gt; with system preference detection&lt;/li&gt; 
 &lt;li&gt;📊 &lt;strong&gt;Live statistics&lt;/strong&gt; - 365 unique integrations, 29,445 total nodes&lt;/li&gt; 
 &lt;li&gt;🎯 &lt;strong&gt;Smart categorization&lt;/strong&gt; by trigger type and complexity&lt;/li&gt; 
 &lt;li&gt;🎯 &lt;strong&gt;Use case categorization&lt;/strong&gt; by service name mapped to categories&lt;/li&gt; 
 &lt;li&gt;📄 &lt;strong&gt;On-demand JSON viewing&lt;/strong&gt; and download&lt;/li&gt; 
 &lt;li&gt;🔗 &lt;strong&gt;Mermaid diagram generation&lt;/strong&gt; for workflow visualization&lt;/li&gt; 
 &lt;li&gt;🔄 &lt;strong&gt;Real-time workflow naming&lt;/strong&gt; with intelligent formatting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Old System&lt;/th&gt; 
   &lt;th&gt;New System&lt;/th&gt; 
   &lt;th&gt;Improvement&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;File Size&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;71MB HTML&lt;/td&gt; 
   &lt;td&gt;&amp;lt;100KB&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;700x smaller&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Load Time&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;10+ seconds&lt;/td&gt; 
   &lt;td&gt;&amp;lt;1 second&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;10x faster&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Search&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Client-side only&lt;/td&gt; 
   &lt;td&gt;Full-text with FTS5&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Instant&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Memory Usage&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~2GB RAM&lt;/td&gt; 
   &lt;td&gt;&amp;lt;50MB RAM&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;40x less&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Mobile Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Poor&lt;/td&gt; 
   &lt;td&gt;Excellent&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Fully responsive&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📂 Repository Organization&lt;/h2&gt; 
&lt;h3&gt;Workflow Collection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2,053 workflows&lt;/strong&gt; with meaningful, searchable names&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;365 unique integrations&lt;/strong&gt; across popular platforms&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;29,445 total nodes&lt;/strong&gt; with professional categorization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality assurance&lt;/strong&gt; - All workflows analyzed and categorized&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Naming System ✨&lt;/h3&gt; 
&lt;p&gt;Our intelligent naming system converts technical filenames into readable titles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Before&lt;/strong&gt;: &lt;code&gt;2051_Telegram_Webhook_Automation_Webhook.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;After&lt;/strong&gt;: &lt;code&gt;Telegram Webhook Automation&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% meaningful names&lt;/strong&gt; with smart capitalization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic integration detection&lt;/strong&gt; from node analysis&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Use Case Category ✨&lt;/h3&gt; 
&lt;p&gt;The search interface includes a dropdown filter that lets you browse 2,000+ workflows by category.&lt;/p&gt; 
&lt;p&gt;The system includes an automated categorization feature that organizes workflows by service categories to make them easier to discover and filter.&lt;/p&gt; 
&lt;h3&gt;How Categorization Works&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run the categorization script&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python create_categories.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Service Name Recognition&lt;/strong&gt; The script analyzes each workflow JSON filename to identify recognized service names (e.g., "Twilio", "Slack", "Gmail", etc.)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Category Mapping&lt;/strong&gt; Each recognized service name is matched to its corresponding category using the definitions in &lt;code&gt;context/def_categories.json&lt;/code&gt;. For example:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Twilio → Communication &amp;amp; Messaging&lt;/li&gt; 
   &lt;li&gt;Gmail → Communication &amp;amp; Messaging&lt;/li&gt; 
   &lt;li&gt;Airtable → Data Processing &amp;amp; Analysis&lt;/li&gt; 
   &lt;li&gt;Salesforce → CRM &amp;amp; Sales&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Search Categories Generation&lt;/strong&gt; The script produces a &lt;code&gt;search_categories.json&lt;/code&gt; file that contains the categorized workflow data&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Filter Interface&lt;/strong&gt; Users can then filter workflows by category in the search interface, making it easier to find workflows for specific use cases&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Available Categories&lt;/h3&gt; 
&lt;p&gt;The categorization system includes the following main categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AI Agent Development&lt;/li&gt; 
 &lt;li&gt;Business Process Automation&lt;/li&gt; 
 &lt;li&gt;Cloud Storage &amp;amp; File Management&lt;/li&gt; 
 &lt;li&gt;Communication &amp;amp; Messaging&lt;/li&gt; 
 &lt;li&gt;Creative Content &amp;amp; Video Automation&lt;/li&gt; 
 &lt;li&gt;Creative Design Automation&lt;/li&gt; 
 &lt;li&gt;CRM &amp;amp; Sales&lt;/li&gt; 
 &lt;li&gt;Data Processing &amp;amp; Analysis&lt;/li&gt; 
 &lt;li&gt;E-commerce &amp;amp; Retail&lt;/li&gt; 
 &lt;li&gt;Financial &amp;amp; Accounting&lt;/li&gt; 
 &lt;li&gt;Marketing &amp;amp; Advertising Automation&lt;/li&gt; 
 &lt;li&gt;Project Management&lt;/li&gt; 
 &lt;li&gt;Social Media Management&lt;/li&gt; 
 &lt;li&gt;Technical Infrastructure &amp;amp; DevOps&lt;/li&gt; 
 &lt;li&gt;Web Scraping &amp;amp; Data Extraction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contribute Categories&lt;/h3&gt; 
&lt;p&gt;You can help expand the categorization by adding more service-to-category mappings (e.g., Twilio → Communication &amp;amp; Messaging) in context/defs_categories.json.&lt;/p&gt; 
&lt;p&gt;Many workflow JSON files are conveniently named with the service name, often separated by underscores (_).&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🛠 Usage Instructions&lt;/h2&gt; 
&lt;h3&gt;Option 1: Modern Fast System (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone repository
git clone &amp;lt;repo-url&amp;gt;
cd n8n-workflows

# Install Python dependencies
pip install -r requirements.txt

# Start the documentation server
python run.py

# Browse workflows at http://localhost:8000
# - Instant search across 2,053 workflows
# - Professional responsive interface
# - Real-time workflow statistics
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Option 2: Development Mode&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with auto-reload for development
python run.py --dev

# Or specify custom host/port
python run.py --host 0.0.0.0 --port 3000

# Force database reindexing
python run.py --reindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Import Workflows into n8n&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use the Python importer (recommended)
python import_workflows.py

# Or manually import individual workflows:
# 1. Open your n8n Editor UI
# 2. Click menu (☰) → Import workflow
# 3. Choose any .json file from the workflows/ folder
# 4. Update credentials/webhook URLs before running
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📊 Workflow Statistics&lt;/h2&gt; 
&lt;h3&gt;Current Collection Stats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Total Workflows&lt;/strong&gt;: 2,053 automation workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Active Workflows&lt;/strong&gt;: 215 (10.5% active rate)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Total Nodes&lt;/strong&gt;: 29,445 (avg 14.3 nodes per workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unique Integrations&lt;/strong&gt;: 365 different services and APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: SQLite with FTS5 full-text search&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Trigger Distribution&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Complex&lt;/strong&gt;: 831 workflows (40.5%) - Multi-trigger systems&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Webhook&lt;/strong&gt;: 519 workflows (25.3%) - API-triggered automations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manual&lt;/strong&gt;: 477 workflows (23.2%) - User-initiated workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scheduled&lt;/strong&gt;: 226 workflows (11.0%) - Time-based executions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Complexity Analysis&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Low (≤5 nodes)&lt;/strong&gt;: ~35% - Simple automations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium (6-15 nodes)&lt;/strong&gt;: ~45% - Standard workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High (16+ nodes)&lt;/strong&gt;: ~20% - Complex enterprise systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Popular Integrations&lt;/h3&gt; 
&lt;p&gt;Top services by usage frequency:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Communication&lt;/strong&gt;: Telegram, Discord, Slack, WhatsApp&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Storage&lt;/strong&gt;: Google Drive, Google Sheets, Dropbox&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Databases&lt;/strong&gt;: PostgreSQL, MySQL, MongoDB, Airtable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI/ML&lt;/strong&gt;: OpenAI, Anthropic, Hugging Face&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Development&lt;/strong&gt;: HTTP Request, Webhook, GraphQL&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔍 Advanced Search Features&lt;/h2&gt; 
&lt;h3&gt;Smart Search Categories&lt;/h3&gt; 
&lt;p&gt;Our system automatically categorizes workflows into 12 service categories:&lt;/p&gt; 
&lt;h4&gt;Available Categories:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;messaging&lt;/strong&gt;: Telegram, Discord, Slack, WhatsApp, Teams&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ai_ml&lt;/strong&gt;: OpenAI, Anthropic, Hugging Face&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;database&lt;/strong&gt;: PostgreSQL, MySQL, MongoDB, Redis, Airtable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;email&lt;/strong&gt;: Gmail, Mailjet, Outlook, SMTP/IMAP&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;cloud_storage&lt;/strong&gt;: Google Drive, Google Docs, Dropbox, OneDrive&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;project_management&lt;/strong&gt;: Jira, GitHub, GitLab, Trello, Asana&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;social_media&lt;/strong&gt;: LinkedIn, Twitter/X, Facebook, Instagram&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ecommerce&lt;/strong&gt;: Shopify, Stripe, PayPal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;analytics&lt;/strong&gt;: Google Analytics, Mixpanel&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;calendar_tasks&lt;/strong&gt;: Google Calendar, Cal.com, Calendly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;forms&lt;/strong&gt;: Typeform, Google Forms, Form Triggers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;development&lt;/strong&gt;: Webhook, HTTP Request, GraphQL, SSE&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Usage Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Search workflows by text
curl "http://localhost:8000/api/workflows?q=telegram+automation"

# Filter by trigger type and complexity
curl "http://localhost:8000/api/workflows?trigger=Webhook&amp;amp;complexity=high"

# Find all messaging workflows
curl "http://localhost:8000/api/workflows/category/messaging"

# Get database statistics
curl "http://localhost:8000/api/stats"

# Browse available categories
curl "http://localhost:8000/api/categories"
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🏗 Technical Architecture&lt;/h2&gt; 
&lt;h3&gt;Modern Stack&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite Database&lt;/strong&gt; - FTS5 full-text search with 365 indexed integrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FastAPI Backend&lt;/strong&gt; - RESTful API with automatic OpenAPI documentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Responsive Frontend&lt;/strong&gt; - Modern HTML5 with embedded CSS/JavaScript&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Analysis&lt;/strong&gt; - Automatic workflow categorization and naming&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Change Detection&lt;/strong&gt; - MD5 hashing for efficient re-indexing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Processing&lt;/strong&gt; - Non-blocking workflow analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compressed Responses&lt;/strong&gt; - Gzip middleware for optimal speed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Error Handling&lt;/strong&gt; - Graceful degradation and comprehensive logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mobile Optimization&lt;/strong&gt; - Touch-friendly interface design&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database Performance&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;-- Optimized schema for lightning-fast queries
CREATE TABLE workflows (
    id INTEGER PRIMARY KEY,
    filename TEXT UNIQUE,
    name TEXT,
    active BOOLEAN,
    trigger_type TEXT,
    complexity TEXT,
    node_count INTEGER,
    integrations TEXT,  -- JSON array of 365 unique services
    description TEXT,
    file_hash TEXT,     -- MD5 for change detection
    analyzed_at TIMESTAMP
);

-- Full-text search with ranking
CREATE VIRTUAL TABLE workflows_fts USING fts5(
    filename, name, description, integrations, tags,
    content='workflows', content_rowid='id'
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔧 Setup &amp;amp; Requirements&lt;/h2&gt; 
&lt;h3&gt;System Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.7+&lt;/strong&gt; - For running the documentation system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modern Browser&lt;/strong&gt; - Chrome, Firefox, Safari, Edge&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;50MB Storage&lt;/strong&gt; - For SQLite database and indexes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;n8n Instance&lt;/strong&gt; - For importing and running workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone repository
git clone &amp;lt;repo-url&amp;gt;
cd n8n-workflows

# Install dependencies
pip install -r requirements.txt

# Start documentation server
python run.py

# Access at http://localhost:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# or .venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Run with auto-reload for development
python api_server.py --reload

# Force database reindexing
python workflow_db.py --index --force
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📋 Naming Convention&lt;/h2&gt; 
&lt;h3&gt;Intelligent Formatting System&lt;/h3&gt; 
&lt;p&gt;Our system automatically converts technical filenames to user-friendly names:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Automatic transformations:
2051_Telegram_Webhook_Automation_Webhook.json → "Telegram Webhook Automation"
0250_HTTP_Discord_Import_Scheduled.json → "HTTP Discord Import Scheduled"  
0966_OpenAI_Data_Processing_Manual.json → "OpenAI Data Processing Manual"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Technical Format&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;[ID]_[Service1]_[Service2]_[Purpose]_[Trigger].json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Smart Capitalization Rules&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP&lt;/strong&gt; → HTTP (not Http)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API&lt;/strong&gt; → API (not Api)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;webhook&lt;/strong&gt; → Webhook&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;automation&lt;/strong&gt; → Automation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;scheduled&lt;/strong&gt; → Scheduled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 API Documentation&lt;/h2&gt; 
&lt;h3&gt;Core Endpoints&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /&lt;/code&gt; - Main workflow browser interface&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/stats&lt;/code&gt; - Database statistics and metrics&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows&lt;/code&gt; - Search with filters and pagination&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}&lt;/code&gt; - Detailed workflow information&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}/download&lt;/code&gt; - Download workflow JSON&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}/diagram&lt;/code&gt; - Generate Mermaid diagram&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Search&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/category/{category}&lt;/code&gt; - Search by service category&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/categories&lt;/code&gt; - List all available categories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/integrations&lt;/code&gt; - Get integration statistics&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /api/reindex&lt;/code&gt; - Trigger background reindexing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Response Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;// GET /api/stats
{
  "total": 2053,
  "active": 215,
  "inactive": 1838,
  "triggers": {
    "Complex": 831,
    "Webhook": 519,
    "Manual": 477,
    "Scheduled": 226
  },
  "total_nodes": 29445,
  "unique_integrations": 365
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;h3&gt;Adding New Workflows&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Export workflow&lt;/strong&gt; as JSON from n8n&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Name descriptively&lt;/strong&gt; following the established pattern&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add to workflows/&lt;/strong&gt; directory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remove sensitive data&lt;/strong&gt; (credentials, personal URLs)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Run reindexing&lt;/strong&gt; to update the database&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Quality Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ Workflow must be functional and tested&lt;/li&gt; 
 &lt;li&gt;✅ Remove all credentials and sensitive data&lt;/li&gt; 
 &lt;li&gt;✅ Follow naming convention for consistency&lt;/li&gt; 
 &lt;li&gt;✅ Verify compatibility with recent n8n versions&lt;/li&gt; 
 &lt;li&gt;✅ Include meaningful description or comments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;⚠️ Important Notes&lt;/h2&gt; 
&lt;h3&gt;Security &amp;amp; Privacy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Review before use&lt;/strong&gt; - All workflows shared as-is for educational purposes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update credentials&lt;/strong&gt; - Replace API keys, tokens, and webhooks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test safely&lt;/strong&gt; - Verify in development environment first&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Check permissions&lt;/strong&gt; - Ensure proper access rights for integrations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Compatibility&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;n8n Version&lt;/strong&gt; - Compatible with n8n 1.0+ (most workflows)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community Nodes&lt;/strong&gt; - Some workflows may require additional node installations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Changes&lt;/strong&gt; - External services may have updated their APIs since creation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dependencies&lt;/strong&gt; - Verify required integrations before importing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📚 Resources &amp;amp; References&lt;/h2&gt; 
&lt;h3&gt;Workflow Sources&lt;/h3&gt; 
&lt;p&gt;This comprehensive collection includes workflows from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Official n8n.io&lt;/strong&gt; - Documentation and community examples&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub repositories&lt;/strong&gt; - Open source community contributions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Blog posts &amp;amp; tutorials&lt;/strong&gt; - Real-world automation patterns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User submissions&lt;/strong&gt; - Tested and verified workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise use cases&lt;/strong&gt; - Business process automations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Learn More&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/"&gt;n8n Documentation&lt;/a&gt; - Official documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://community.n8n.io/"&gt;n8n Community&lt;/a&gt; - Community forum and support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/"&gt;Workflow Templates&lt;/a&gt; - Official template library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/integrations/"&gt;Integration Docs&lt;/a&gt; - Service-specific guides&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🏆 Project Achievements&lt;/h2&gt; 
&lt;h3&gt;Repository Transformation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2,053 workflows&lt;/strong&gt; professionally organized and named&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;365 unique integrations&lt;/strong&gt; automatically detected and categorized&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% meaningful names&lt;/strong&gt; (improved from basic filename patterns)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero data loss&lt;/strong&gt; during intelligent renaming process&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced search&lt;/strong&gt; with 12 service categories&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Revolution&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Sub-100ms search&lt;/strong&gt; with SQLite FTS5 full-text indexing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instant filtering&lt;/strong&gt; across 29,445 workflow nodes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mobile-optimized&lt;/strong&gt; responsive design for all devices&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time statistics&lt;/strong&gt; with live database queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Professional interface&lt;/strong&gt; with modern UX principles&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;System Reliability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Robust error handling&lt;/strong&gt; with graceful degradation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change detection&lt;/strong&gt; for efficient database updates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background processing&lt;/strong&gt; for non-blocking operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive logging&lt;/strong&gt; for debugging and monitoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Production-ready&lt;/strong&gt; with proper middleware and security&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;This repository represents the most comprehensive and well-organized collection of n8n workflows available, featuring cutting-edge search technology and professional documentation that makes workflow discovery and usage a delightful experience.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;🎯 Perfect for&lt;/strong&gt;: Developers, automation engineers, business analysts, and anyone looking to streamline their workflows with proven n8n automations.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/README_ZH.md"&gt;中文&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>emcie-co/parlant</title>
      <link>https://github.com/emcie-co/parlant</link>
      <description>&lt;p&gt;LLM agents built for control. Designed for real-world use. Deployed in minutes.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentLight.png?raw=true" /&gt; 
  &lt;img alt="Parlant - AI Agent Framework" src="https://github.com/emcie-co/parlant/raw/develop/docs/LogoTransparentDark.png?raw=true" width="400" /&gt; 
 &lt;/picture&gt; 
 &lt;h3&gt;Finally, LLM agents that actually follow instructions&lt;/h3&gt; 
 &lt;p&gt; &lt;a href="https://www.parlant.io/" target="_blank"&gt;🌐 Website&lt;/a&gt; • &lt;a href="https://www.parlant.io/docs/quickstart/installation" target="_blank"&gt;⚡ Quick Start&lt;/a&gt; • &lt;a href="https://discord.gg/duxWqxKk6J" target="_blank"&gt;💬 Discord&lt;/a&gt; • &lt;a href="https://www.parlant.io/docs/quickstart/examples" target="_blank"&gt;📖 Examples&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://zdoc.app/de/emcie-co/parlant"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://zdoc.app/es/emcie-co/parlant"&gt;Español&lt;/a&gt; | &lt;a href="https://zdoc.app/fr/emcie-co/parlant"&gt;français&lt;/a&gt; | &lt;a href="https://zdoc.app/ja/emcie-co/parlant"&gt;日本語&lt;/a&gt; | &lt;a href="https://zdoc.app/ko/emcie-co/parlant"&gt;한국어&lt;/a&gt; | &lt;a href="https://zdoc.app/pt/emcie-co/parlant"&gt;Português&lt;/a&gt; | &lt;a href="https://zdoc.app/ru/emcie-co/parlant"&gt;Русский&lt;/a&gt; | &lt;a href="https://zdoc.app/zh/emcie-co/parlant"&gt;中文&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://pypi.org/project/parlant/"&gt;&lt;img alt="PyPI" src="https://img.shields.io/pypi/v/parlant?color=blue" /&gt;&lt;/a&gt; &lt;img alt="Python 3.10+" src="https://img.shields.io/badge/python-3.10+-blue" /&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img alt="License" src="https://img.shields.io/badge/license-Apache%202.0-green" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/duxWqxKk6J"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1312378700993663007?color=7289da&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/emcie-co/parlant?style=social" /&gt; &lt;/p&gt; 
 &lt;a href="https://trendshift.io/repositories/12768" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/12768" alt="Trending on TrendShift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;🎯 The Problem Every AI Developer Faces&lt;/h2&gt; 
&lt;p&gt;You build an AI agent. It works great in testing. Then real users start talking to it and...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;❌ It ignores your carefully crafted system prompts&lt;/li&gt; 
 &lt;li&gt;❌ It hallucinates responses in critical moments&lt;/li&gt; 
 &lt;li&gt;❌ It can't handle edge cases consistently&lt;/li&gt; 
 &lt;li&gt;❌ Each conversation feels like a roll of the dice&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Sound familiar?&lt;/strong&gt; You're not alone. This is the #1 pain point for developers building production AI agents.&lt;/p&gt; 
&lt;h2&gt;⚡ The Solution: Stop Fighting Prompts, Teach Principles&lt;/h2&gt; 
&lt;p&gt;Parlant flips the script on AI agent development. Instead of hoping your LLM will follow instructions, &lt;strong&gt;Parlant ensures it&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Traditional approach: Cross your fingers 🤞
system_prompt = "You are a helpful assistant. Please follow these 47 rules..."

# Parlant approach: Ensured compliance ✅
await agent.create_guideline(
    condition="Customer asks about refunds",
    action="Check order status first to see if eligible",
    tools=[check_order_status],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://www.parlant.io/blog/how-parlant-guarantees-compliance"&gt;✅ Blog: How Parlant Ensures Agent Compliance&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Parlant gives you all the structure you need to build customer-facing agents that behave exactly as your business requires:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/journeys"&gt;Journeys&lt;/a&gt;&lt;/strong&gt;: Define clear customer journeys and how your agent should respond at each step.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/guidelines"&gt;Behavioral Guidelines&lt;/a&gt;&lt;/strong&gt;: Easily craft agent behavior; Parlant will match the relevant elements contextually.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/tools"&gt;Tool Use&lt;/a&gt;&lt;/strong&gt;: Attach external APIs, data fetchers, or backend services to specific interaction events.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/glossary"&gt;Domain Adaptation&lt;/a&gt;&lt;/strong&gt;: Teach your agent domain-specific terminology and craft personalized responses.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/concepts/customization/canned-responses"&gt;Canned Responses&lt;/a&gt;&lt;/strong&gt;: Use response templates to eliminate hallucinations and guarantee style consistency.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://parlant.io/docs/advanced/explainability"&gt;Explainability&lt;/a&gt;&lt;/strong&gt;: Understand why and when each guideline was matched and followed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;🚀 Get Your Agent Running in 60 Seconds&lt;/h2&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install parlant
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import parlant.sdk as p

@p.tool
async def get_weather(context: p.ToolContext, city: str) -&amp;gt; p.ToolResult:
    # Your weather API logic here
    return p.ToolResult(f"Sunny, 72°F in {city}")

@p.tool
async def get_datetime(context: p.ToolContext) -&amp;gt; p.ToolResult:
    from datetime import datetime
    return p.ToolResult(datetime.now())

async def main():
    async with p.Server() as server:
        agent = await server.create_agent(
            name="WeatherBot",
            description="Helpful weather assistant"
        )

        # Have the agent's context be updated on every response (though
        # update interval is customizable) using a context variable.
        await agent.create_variable(name="current-datetime", tool=get_datetime)

        # Control and guide agent behavior with natural language
        await agent.create_guideline(
            condition="User asks about weather",
            action="Get current weather and provide a friendly response with suggestions",
            tools=[get_weather]
        )

        # Add other (reliably enforced) behavioral modeling elements
        # ...

        # 🎉 Test playground ready at http://localhost:8800
        # Integrate the official React widget into your app,
        # or follow the tutorial to build your own frontend!

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;That's it!&lt;/strong&gt; Your agent is running with ensured rule-following behavior.&lt;/p&gt; 
&lt;h2&gt;🎬 See It In Action&lt;/h2&gt; 
&lt;img alt="Parlant Demo" src="https://github.com/emcie-co/parlant/raw/develop/docs/demo.gif?raw=true" width="100%" /&gt; 
&lt;h2&gt;🔥 Why Developers Are Switching to Parlant&lt;/h2&gt; 
&lt;table width="100%"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;🏗️ &lt;strong&gt;Traditional AI Frameworks&lt;/strong&gt;&lt;/h3&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;⚡ &lt;strong&gt;Parlant&lt;/strong&gt;&lt;/h3&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Write complex system prompts&lt;/li&gt; 
     &lt;li&gt;Hope the LLM follows them&lt;/li&gt; 
     &lt;li&gt;Debug unpredictable behaviors&lt;/li&gt; 
     &lt;li&gt;Scale by prompt engineering&lt;/li&gt; 
     &lt;li&gt;Cross fingers for reliability&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Define rules in natural language&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Ensured&lt;/strong&gt; rule compliance&lt;/li&gt; 
     &lt;li&gt;Predictable, consistent behavior&lt;/li&gt; 
     &lt;li&gt;Scale by adding guidelines&lt;/li&gt; 
     &lt;li&gt;Production-ready from day one&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;🎯 Perfect For Your Use Case&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Financial Services&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Healthcare&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;E-commerce&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Legal Tech&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Compliance-first design&lt;/td&gt; 
    &lt;td align="center"&gt;HIPAA-ready agents&lt;/td&gt; 
    &lt;td align="center"&gt;Customer service at scale&lt;/td&gt; 
    &lt;td align="center"&gt;Precise legal guidance&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;Built-in risk management&lt;/td&gt; 
    &lt;td align="center"&gt;Patient data protection&lt;/td&gt; 
    &lt;td align="center"&gt;Order processing automation&lt;/td&gt; 
    &lt;td align="center"&gt;Document review assistance&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;🛠️ Enterprise-Grade Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🧭 Conversational Journeys&lt;/strong&gt; - Lead the customer step-by-step to a goal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🎯 Dynamic Guideline Matching&lt;/strong&gt; - Context-aware rule application&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔧 Reliable Tool Integration&lt;/strong&gt; - APIs, databases, external services&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📊 Conversation Analytics&lt;/strong&gt; - Deep insights into agent behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔄 Iterative Refinement&lt;/strong&gt; - Continuously improve agent responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🛡️ Built-in Guardrails&lt;/strong&gt; - Prevent hallucination and off-topic responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📱 React Widget&lt;/strong&gt; - &lt;a href="https://github.com/emcie-co/parlant-chat-react"&gt;Drop-in chat UI for any web app&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔍 Full Explainability&lt;/strong&gt; - Understand every decision your agent makes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📈 Join 10,000+ Developers Building Better AI&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Companies using Parlant:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Financial institutions • Healthcare providers • Legal firms • E-commerce platforms&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#emcie-co/parlant&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=emcie-co/parlant&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🌟 What Developers Are Saying&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;"By far the most elegant conversational AI framework that I've come across! Developing with Parlant is pure joy."&lt;/em&gt; &lt;strong&gt;— Vishal Ahuja, Senior Lead, Customer-Facing Conversational AI @ JPMorgan Chase&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;🏃‍♂️ Quick Start Paths&lt;/h2&gt; 
&lt;table border="0"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🎯 I want to test it myself&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.parlant.io/docs/quickstart/installation"&gt;→ 5-minute quickstart&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🛠️ I want to see an example&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.parlant.io/docs/quickstart/examples"&gt;→ Healthcare agent example&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;🚀 I want to get involved&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;→ Join our Discord community&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;🤝 Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;💬 &lt;strong&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;Discord Community&lt;/a&gt;&lt;/strong&gt; - Get help from the team and community&lt;/li&gt; 
 &lt;li&gt;📖 &lt;strong&gt;&lt;a href="https://parlant.io/docs/quickstart/installation"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; - Comprehensive guides and examples&lt;/li&gt; 
 &lt;li&gt;🐛 &lt;strong&gt;&lt;a href="https://github.com/emcie-co/parlant/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Bug reports and feature requests&lt;/li&gt; 
 &lt;li&gt;📧 &lt;strong&gt;&lt;a href="https://parlant.io/contact"&gt;Direct Support&lt;/a&gt;&lt;/strong&gt; - Direct line to our engineering team&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;Apache 2.0 - Use it anywhere, including commercial projects.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Ready to build AI agents that actually work?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;⭐ &lt;strong&gt;Star this repo&lt;/strong&gt; • 🚀 &lt;strong&gt;&lt;a href="https://parlant.io/"&gt;Try Parlant now&lt;/a&gt;&lt;/strong&gt; • 💬 &lt;strong&gt;&lt;a href="https://discord.gg/duxWqxKk6J"&gt;Join Discord&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Built with ❤️ by the team at &lt;a href="https://emcie.co"&gt;Emcie&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>zama-ai/fhevm</title>
      <link>https://github.com/zama-ai/fhevm</link>
      <description>&lt;p&gt;FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/.gitbook/assets/fhevm-header-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/.gitbook/assets/fhevm-header-light.png" /&gt; 
  &lt;img width="500" alt="fhevm" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/fhevm-whitepaper.pdf"&gt; 📃 Read white paper&lt;/a&gt; |&lt;a href="https://docs.zama.ai/protocol"&gt; 📒 Documentation&lt;/a&gt; | &lt;a href="https://zama.ai/community"&gt; 💛 Community support&lt;/a&gt; | &lt;a href="https://github.com/zama-ai/awesome-zama"&gt; 📚 FHE resources by Zama&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/zama-ai/fhevm/releases"&gt; &lt;img src="https://img.shields.io/github/v/release/zama-ai/fhevm?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zama-ai/fhevm/raw/main/LICENSE"&gt; 
  &lt;!-- markdown-link-check-disable-next-line --&gt; &lt;img src="https://img.shields.io/badge/License-BSD--3--Clause--Clear-%23ffb243?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zama-ai/bounty-program"&gt; 
  &lt;!-- markdown-link-check-disable-next-line --&gt; &lt;img src="https://img.shields.io/badge/Contribute-Zama%20Bounty%20Program-%23ffd208?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://slsa.dev"&gt;&lt;img alt="SLSA 3" src="https://slsa.dev/images/gh-badge-level3.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;h3&gt;What is FHEVM?&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;FHEVM&lt;/strong&gt; is the core framework of the &lt;em&gt;Zama Confidential Blockchain Protocol&lt;/em&gt;. It enables confidential smart contracts on EVM-compatible blockchains by leveraging Fully Homomorphic Encryption (FHE), allowing encrypted data to be processed directly onchain.&lt;/p&gt; 
&lt;p&gt;FHEVM ensures both confidentiality and composability, with the following guarantees:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;End-to-end encryption of transactions and state:&lt;/strong&gt; Data included in transactions is encrypted and never visible to anyone.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Composability and data availability on-chain:&lt;/strong&gt; States are updated while remaining encrypted at all times.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No impact on existing dApps and state:&lt;/strong&gt; Encrypted state co-exists alongside public one, and doesn't impact existing dApps. &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Table of contents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt;About&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#what-is-fhevm"&gt;What is FHEVM?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#project-structure"&gt;Project structure&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#main-features"&gt;Main features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#use-cases"&gt;Use cases&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#resources"&gt;Resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#working-with-fhevm"&gt;Working with FHEVM&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#citations"&gt;Citations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#support"&gt;Support&lt;/a&gt; &lt;br /&gt;&lt;br /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Project structure&lt;/h3&gt; 
&lt;p&gt;The directories of this repository are organized in the following way:&lt;/p&gt; 
&lt;h6&gt;FHEVM Contracts&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;gateway-contracts/&lt;/code&gt;&lt;/strong&gt;: Smart contracts managing the gateway between on-chain and off-chain components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;host-contracts/&lt;/code&gt;&lt;/strong&gt;: Smart Contracts deployed on the host chain for orchestrating FHE workflows.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;FHEVM Compute Engines&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;coprocessor/&lt;/code&gt;&lt;/strong&gt;: Rust-based coprocessor implementation for FHE operations.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;kms-connector/&lt;/code&gt;&lt;/strong&gt;: Interface for integrating with Key Management Services (KMS) to handle encryption keys securely.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;FHEVM Utilities&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;charts/&lt;/code&gt;&lt;/strong&gt;: Helm charts and deployment configurations for the stack.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;golden-container-images/&lt;/code&gt;&lt;/strong&gt;: Docker golden images for Node.js and Rust environments used as base images by the stack.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;test-suite/&lt;/code&gt;&lt;/strong&gt;: Integration with docker-compose and tests covering end-to-end FHEVM stack behavior.&lt;/p&gt; &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Main features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy by design:&lt;/strong&gt; Building decentralized apps with full privacy and confidentiality on Ethereum, leveraging FHE.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solidity integration:&lt;/strong&gt; Write FHEVM contracts like any standard Solidity contract using Solidity. Compatible with existing toolchains — such as Hardhat and Foundry (&lt;em&gt;coming soon&lt;/em&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Programmable privacy:&lt;/strong&gt; Define exactly what data is encrypted and write the access control logic directly in your smart contracts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High precision encrypted integers :&lt;/strong&gt; Up to 256 bits of precision for integers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full range of operators:&lt;/strong&gt; All typical operators are available: &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;/&lt;/code&gt;, &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;==&lt;/code&gt;, ternary-if, boolean operations…. Consecutive FHE operations are not limited.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security:&lt;/strong&gt; The underlying FHE crypto-scheme of FHEVM is quantum-resistant. Decryption is managed via a key management system (KMS) using multi-party computation (MPC), ensuring security even if some parties are compromised or misbehaving.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Symbolic execution of FHE computations:&lt;/strong&gt; All FHE operations are executed symbolically on the host chain, significantly reducing execution time. The actual computations on encrypted data are offloaded asynchronously to our coprocessor, allowing for faster, efficient, and scalable processing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Learn more about FHEVM features in the &lt;a href="https://docs.zama.ai/protocol"&gt;documentation&lt;/a&gt; and in our &lt;a href="https://github.com/zama-ai/fhevm/raw/main/fhevm-whitepaper.pdf"&gt;whitepaper&lt;/a&gt;.&lt;/em&gt; &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Use cases&lt;/h3&gt; 
&lt;p&gt;FHEVM is built for developers to write confidential smart contracts without the need to learn cryptography. Leveraging FHEVM, you can unlock a myriad of new use cases such as DeFi, gaming, and more. For instance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Confidential transfers&lt;/strong&gt;: Keep balances and amounts private, without using mixers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tokenization&lt;/strong&gt;: Swap tokens and RWAs on-chain without others seeing the amounts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Blind auctions&lt;/strong&gt;: Bid on items without revealing the amount or the winner.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;On-chain games&lt;/strong&gt;: Keep moves, selections, cards, or items hidden until ready to reveal.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Confidential voting&lt;/strong&gt;: Prevents bribery and blackmailing by keeping votes private.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Encrypted DIDs&lt;/strong&gt;: Store identities on-chain and generate attestations without ZK.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Learn more use cases in the &lt;a href="https://docs.zama.ai/protocol/examples"&gt;list of examples&lt;/a&gt;.&lt;/em&gt; &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.zama.ai/protocol"&gt;Documentation&lt;/a&gt; — Official documentation of FHEVM.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/fhevm-whitepaper.pdf"&gt;Whitepaper&lt;/a&gt; — Technical overview of FHEVM's cryptographic design.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.zama.ai/protocol/examples"&gt;Examples&lt;/a&gt; — Examples of building confidential smart contracts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zama-ai/awesome-zama?tab=readme-ov-file#fhevm"&gt;Awesome Zama – FHEVM&lt;/a&gt; — Curated articles, talks, and ecosystem projects.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt; ↑ Back to top &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Working with FHEVM&lt;/h2&gt; 
&lt;h3&gt;Citations&lt;/h3&gt; 
&lt;p&gt;To cite FHEVM or the whitepaper in academic papers, please use the following entries:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;@Misc{FHEVM,
title={{FHEVM: A full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications},
author={Zama},
year={2025},
note={\url{https://github.com/zama-ai/fhevm}},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;There are two ways to contribute to FHEVM:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zama-ai/fhevm/issues/new/choose"&gt;Open issues&lt;/a&gt; to report bugs and typos, or to suggest new ideas&lt;/li&gt; 
 &lt;li&gt;Request to become an official contributor by emailing &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Becoming an approved contributor involves signing our Contributor License Agreement (CLA). Only approved contributors can send pull requests, so please make sure to get in touch before you do! &lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;This software is distributed under the &lt;strong&gt;BSD-3-Clause-Clear&lt;/strong&gt; license. Read &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/LICENSE"&gt;this&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Is Zama’s technology free to use?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Zama’s libraries are free to use under the BSD 3-Clause Clear license only for development, research, prototyping, and experimentation purposes. However, for any commercial use of Zama's open source code, companies must purchase Zama’s commercial patent license.&lt;/p&gt; 
 &lt;p&gt;Everything we do is open source, and we are very transparent on what it means for our users, you can read more about how we monetize our open source products at Zama in &lt;a href="https://www.zama.ai/post/open-source"&gt;this blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;What do I need to do if I want to use Zama’s technology for commercial purposes?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;To commercially use Zama’s technology you need to be granted Zama’s patent license. Please contact us at &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Do you file IP on your technology?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Yes, all Zama’s technologies are patented.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Can you customize a solution for my specific use case?&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;We are open to collaborating and advancing the FHE space with our partners. If you have specific needs, please email us at &lt;a href="mailto:hello@zama.ai"&gt;hello@zama.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;a target="_blank" href="https://community.zama.ai"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/.gitbook/assets/support-banner-dark.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/.gitbook/assets/support-banner-light.png" /&gt; 
  &lt;img alt="Support" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;🌟 If you find this project helpful or interesting, please consider giving it a star on GitHub! Your support helps to grow the community and motivates further development.&lt;/p&gt; 
&lt;p align="right"&gt; &lt;a href="https://raw.githubusercontent.com/zama-ai/fhevm/main/#about"&gt; ↑ Back to top &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>11cafe/jaaz</title>
      <link>https://github.com/11cafe/jaaz</link>
      <description>&lt;p&gt;The world's first open-source multimodal creative assistant This is a substitute for Canva and Manus that prioritizes privacy and is usable locally.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://jaaz.app" target="_blank"&gt; Jaaz.app&lt;/a&gt; &lt;p align="center"&gt;Open source Canva AI alternative&lt;/p&gt; &lt;p align="center"&gt; &lt;a href="https://jaaz.app"&gt; &lt;img src="https://github.com/user-attachments/assets/e0cffb94-8c6f-4867-800a-c144aceb6d54" alt="Jaaz Logo" /&gt; &lt;/a&gt; &lt;/p&gt; &lt;/h1&gt; 
&lt;p align="center"&gt;The world's first open-source multimodal canvas creative agent&lt;/p&gt; 
&lt;p align="center"&gt;This is a substitute for Canva and Manus that prioritizes privacy and is usable locally.&lt;/p&gt; 
&lt;p&gt; &lt;b&gt;📣 [New!] Enterprise Cloud “Full” Edition&lt;/b&gt; — Private/on-prem deployment &amp;amp; commercial licensing (Docker image or full source). Includes all jaaz.app online features. &lt;b&gt;30% OFF&lt;/b&gt; through &lt;b&gt;Sep 15, 2025&lt;/b&gt;. &lt;a href="mailto:info@jaaz.app"&gt;Contact us →&lt;/a&gt; info@jaaz.app &lt;br /&gt; &lt;br /&gt; &lt;b&gt;📣 [New!] 企业云端完整版&lt;/b&gt; — 支持&lt;span&gt;私有化部署&lt;/span&gt;与&lt;span&gt;商业授权&lt;/span&gt;（Docker 镜像或源码交付），包含 jaaz.app 全量线上功能。限时 &lt;b&gt;30% OFF&lt;/b&gt;，截止 &lt;b&gt;2025-09-15&lt;/b&gt;。 &lt;a href="mailto:info@jaaz.app"&gt;了解/洽谈 →&lt;/a&gt; info@jaaz.app &lt;/p&gt; 
&lt;br /&gt;
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/11cafe/jaaz/raw/main/README_zh.md"&gt;中文版&lt;/a&gt;| &lt;a href="https://mxnpt25l6k.feishu.cn/docx/LvcTdlVbFoRAZWxnhBYcqVydnpc"&gt;新手指南&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/https://discord.gg/SMRe5n3m"&gt; &lt;img src="https://img.shields.io/badge/Discord-5865F2?logo=discord&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Discord" /&gt; &lt;/a&gt; &lt;a href="https://github.com/11cafe/jaaz/stargazers"&gt; &lt;img src="https://img.shields.io/github/stars/11cafe/jaaz?style=for-the-badge&amp;amp;logo=github" alt="GitHub Stars" /&gt; &lt;/a&gt; 
 &lt;!-- Download for Mac --&gt; &lt;a href="https://jaaz.app/api/downloads/mac-latest"&gt; &lt;img src="https://img.shields.io/badge/For%20Mac-000000?logo=apple&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Download for Mac" /&gt; &lt;/a&gt; 
 &lt;!-- Download for Windows --&gt; &lt;a href="https://jaaz.app/api/downloads/windows-latest"&gt; &lt;img src="https://img.shields.io/badge/For%20Windows-0078D6?logo=laptop&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="Download for Windows" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Magic Canva! &lt;/p&gt;
&lt;p&gt;"Build" your ideas like playing with LEGO—paint directly, point with arrows, and the AI instantly understands and generates results. &lt;img width="900" alt="Screenshot 2025-06-02 at 3 03 49 PM" src="https://github.com/user-attachments/assets/543b170c-14f7-4a73-96bd-909662138592" /&gt; &lt;img width="900" alt="Screenshot 2025-06-02 at 3 03 49 PM" src="https://github.com/user-attachments/assets/7dd9af32-cc60-4145-9b30-7db96d8fa09a" /&gt;&lt;/p&gt; 
&lt;p&gt;Magic video!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/b7abf987-c65d-49b1-8178-82770873c583"&gt;https://github.com/user-attachments/assets/b7abf987-c65d-49b1-8178-82770873c583&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Create Viral Shorts with a Single Sentence 
 &lt;video src="https://github.com/user-attachments/assets/1c15e792-098a-4557-b310-d9c223f73442" controls width="100%"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;h2&gt;✨ Getting started &amp;amp; staying tuned with us.&lt;/h2&gt; 
&lt;p&gt;Star us, and you will receive all release notifications from GitHub without any delay! &lt;img width="900" alt="Screenshot 2025-06-02 at 3 03 49 PM" src="https://github.com/user-attachments/assets/1c9a3661-80a4-4fba-a30f-f469898b0aec" /&gt;&lt;/p&gt; 
&lt;h2&gt;✨ Key Features&lt;/h2&gt; 
&lt;p&gt;🎬 One-Prompt Image &amp;amp; Video Generation Turn one prompt into complete images or videos in seconds.&lt;/p&gt; 
&lt;p&gt;-Supports GPT-4o, Midjourney, VEO3, Kling,veo3,seedance etc.&lt;/p&gt; 
&lt;p&gt;-Auto-optimized prompts &amp;amp; multi-turn refinement&lt;/p&gt; 
&lt;p&gt;🧙 Magic Canvas&amp;amp;Magic Video Prompt-free creation — build like Lego.&lt;/p&gt; 
&lt;p&gt;-Simple sketching and free combination — AI instantly understands and generates.&lt;/p&gt; 
&lt;p&gt;-AI understands and generates instantly&lt;/p&gt; 
&lt;p&gt;-No prompt writing needed&lt;/p&gt; 
&lt;p&gt;-Describe steps simply on the video, and AI will generate following them.&lt;/p&gt; 
&lt;p&gt;🖼️ Infinite Canvas &amp;amp; Visual Storyboarding Plan scenes with an unlimited canvas&lt;/p&gt; 
&lt;p&gt;-Link layouts, manage media visually&lt;/p&gt; 
&lt;p&gt;-Real-time collaboration supported&lt;/p&gt; 
&lt;p&gt;🤖 Smart AI Agent System -Chat to insert objects, transfer styles, control logic&lt;/p&gt; 
&lt;p&gt;-Works with local (ComfyUI) &amp;amp; cloud models&lt;/p&gt; 
&lt;p&gt;-Maintains multi-character coherence&lt;/p&gt; 
&lt;p&gt;⚙️ Flexible Deployment &amp;amp; Local Assets -Fully offline or hybrid setup (Ollama + APIs)&lt;/p&gt; 
&lt;p&gt;-Built-in library for media &amp;amp; prompts&lt;/p&gt; 
&lt;p&gt;-Cross-platform: Windows &amp;amp; macOS&lt;/p&gt; 
&lt;p&gt;🔐 Privacy &amp;amp; Security -Local-first, no data leaves your device&lt;/p&gt; 
&lt;p&gt;-Open-source, no tracking&lt;/p&gt; 
&lt;p&gt;-Safe for commercial use — you own your data&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Download here: &lt;a href="https://jaaz.app/"&gt;https://jaaz.app/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Click the "Log In" button at the top right of the homepage to access API models. With a low-cost plan, you can seamlessly use a variety of powerful APIs.&lt;/p&gt; 
&lt;img width="400" alt="Screenshot 2025-06-02 at 3 08 51 PM" src="https://github.com/user-attachments/assets/0055557d-c247-4801-ac3f-01ed4fa775ae" /&gt; 
&lt;p&gt;Start chatting with agent to generate stories or storyboards!&lt;/p&gt; 
&lt;h2&gt;Cases&lt;/h2&gt; 
&lt;img width="889" height="1103" alt="Frame 122" src="https://github.com/user-attachments/assets/90503110-0f5c-4297-bbfe-6d35e3f54d4c" /&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prompt: Help me place this character in six different scenes, all in front of landmark buildings from around the world. The lighting is harmonious. He takes photos from all over the world, realistic, with warm light, high picture quality, and a picture ratio of 9:16&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/4e2634b3-9068-47cd-a18f-ddde8f218d25" alt="814c563b08f6ef44de0c2c31f0fdd00b-min" /&gt;&lt;/p&gt; 
&lt;img width="1000" alt="Screenshot 2025-06-02 at 3 51 56 AM" src="https://github.com/user-attachments/assets/5d8efe74-99b0-41bc-aa3e-6f7b92b69c36" /&gt; 
&lt;img width="900" alt="Screenshot 2025-06-02 at 3 51 56 AM" src="https://github.com/user-attachments/assets/186982a9-5e4e-4ac1-a42c-c840092fd616" /&gt; 
&lt;img width="900" alt="Screenshot 2025-06-02 at 3 03 49 PM" src="https://github.com/user-attachments/assets/b8508efd-def8-40ed-8ab5-62ed3c26de67" /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/2065cabd-af32-43b6-bc01-59a935d9a287" alt="image26" /&gt;&lt;/p&gt; 
&lt;h2&gt;Team and Enterprise Support:&lt;/h2&gt; 
&lt;p&gt;Support for multi-user private deployment of enterprise teams, ensuring privacy and security.&lt;/p&gt; 
&lt;p&gt;Please contact via email: &lt;a href="mailto:aifoxdw@gmail.com"&gt;aifoxdw@gmail.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;WeChat: aifox1 &lt;img width="500" alt="Screenshot 2025-06-02 at 3 51 56 AM" src="https://github.com/user-attachments/assets/d5c54eda-120b-4fc2-a571-68fcab440868" /&gt;&lt;/p&gt; 
&lt;h2&gt;Manual Install (For Linux or local builds)&lt;/h2&gt; 
&lt;p&gt;🟠 &lt;strong&gt;Need Python version &amp;gt;=3.12&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;First git clone this repo:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;git clone https://github.com/11cafe/localart&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cd react&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;npm install --force&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;npx vite build&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cd ../server&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python main.py&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;🟠 &lt;strong&gt;Need Python version &amp;gt;=3.12&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;VSCode/Cursor Install Extensions：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Black Formatter by ms-python (ms-python.black-formatter)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;cd react&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;npm install --force &amp;amp;&amp;amp; npm run dev&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cd server&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python main.py&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aaPanel/BillionMail</title>
      <link>https://github.com/aaPanel/BillionMail</link>
      <description>&lt;p&gt;BillionMail gives you open-source MailServer, NewsLetter, Email Marketing — fully self-hosted, dev-friendly, and free from monthly fees. Join the discord: https://discord.gg/asfXzBUhZr&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a name="readme-top"&gt;&lt;/a&gt; 
 &lt;h1&gt;&lt;a href="https://www.billionmail.com/" target="_blank"&gt;BillionMail 📧&lt;/a&gt;&lt;/h1&gt; 
 &lt;h2&gt;An Open-Source MailServer, NewsLetter, Email Marketing Solution for Smarter Campaigns&lt;/h2&gt; 
 &lt;p&gt;&lt;a href="https://www.gnu.org/licenses/agpl-3.0.html"&gt;&lt;img src="https://img.shields.io/github/license/aaPanel/BillionMail" alt="" /&gt;&lt;/a&gt; &lt;a href="https://www.billionmail.com/"&gt;&lt;img src="https://img.shields.io/badge/documentation-148F76" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aaPanel/BillionMail/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/aaPanel/BillionMail" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aaPanel/BillionMail"&gt;&lt;img src="https://img.shields.io/github/stars/aaPanel/BillionMail?color=%231890FF&amp;amp;style=flat-square%C2%A0%C2%A0%C2%A0" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/aaPanel/BillionMail/dev/README-zh_CN.md"&gt;简体中文&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/aaPanel/BillionMail/dev/README-ja.md"&gt;日本語&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13842" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13842" alt="aaPanel%2FBillionMail | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is BillionMail?&lt;/h2&gt; 
&lt;p&gt;BillionMail is a &lt;strong&gt;future open-source Mail server, Email marketing platform&lt;/strong&gt; designed to help businesses and individuals manage their email campaigns with ease. Whether you're sending newsletters, promotional emails, or transactional messages, this tool will provide &lt;strong&gt;full control&lt;/strong&gt; over your email marketing efforts. With features like &lt;strong&gt;advanced analytics&lt;/strong&gt;, and &lt;strong&gt;customer management&lt;/strong&gt;, you'll be able to create, send, and track emails like a pro.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://www.billionmail.com/home.png?v1" alt="BillionMail Banner" /&gt;&lt;/p&gt; 
&lt;h1&gt;Just 3 steps to send a billion emails!&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Billion emails. Any business. Guaranteed.&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Step 1️⃣ Install BillionMail:&lt;/h3&gt; 
&lt;p&gt;✅ It takes &lt;strong&gt;only 8️⃣ minutes&lt;/strong&gt; from installation to &lt;strong&gt;✅ successful email sending&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; bash install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2️⃣: Connect Your Domain&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add the sending domain&lt;/li&gt; 
 &lt;li&gt;Verify DNS records&lt;/li&gt; 
 &lt;li&gt;Auto-enable free SSL&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 3️⃣: Build Your Campaign&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Write or paste your email&lt;/li&gt; 
 &lt;li&gt;Choose list &amp;amp; tags&lt;/li&gt; 
 &lt;li&gt;Set send time or send now&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.youtube.com/embed/UHgxZa_9jGs?si=0-f1B5hDtcWImvQv" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/UHgxZa_9jGs/maxresdefault.jpg" alt="" width="80%" /&gt; &lt;br /&gt; &lt;img src="https://www.iconfinder.com/icons/317714/download/png/16" alt="YouTube" width="16" /&gt; &lt;b&gt;Watch on Youtube&lt;/b&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Other installation methods&lt;/h2&gt; 
&lt;h3&gt;One-click installation on aaPanel&lt;/h3&gt; 
&lt;p&gt;👉 &lt;a href="https://www.aapanel.com/new/download.html"&gt;https://www.aapanel.com/new/download.html&lt;/a&gt; (Log in to ✅aaPanel --&amp;gt; 🐳Docker --&amp;gt; 1️⃣OneClick install)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docker&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; cp env_init .env &amp;amp;&amp;amp; docker compose up -d || docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Management script&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Management help&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm help&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;View Login default info&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm default&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Show domain DNS record&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm show-record&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Update BillionMail&lt;/p&gt; &lt;p&gt;&lt;code&gt;bm update&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Live Demo&lt;/h2&gt; 
&lt;p&gt;BillionMail Demo: &lt;a href="https://demo.billionmail.com/billionmail"&gt;https://demo.billionmail.com/billionmail&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Username: &lt;code&gt;billionmail&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Password: &lt;code&gt;billionmail&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;WebMail&lt;/h2&gt; 
&lt;p&gt;BillionMail has integrated &lt;strong&gt;RoundCube&lt;/strong&gt;, you can access WebMail via &lt;code&gt;/roundcube/&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Why BillionMail?&lt;/h2&gt; 
&lt;p&gt;Most email marketing platforms are either &lt;strong&gt;expensive&lt;/strong&gt;, &lt;strong&gt;closed-source&lt;/strong&gt;, or &lt;strong&gt;lack essential features&lt;/strong&gt;. BillionMail aims to be different:&lt;/p&gt; 
&lt;p&gt;✅ &lt;strong&gt;Fully Open-Source&lt;/strong&gt; – No hidden costs, no vendor lock-in.&lt;br /&gt; 📊 &lt;strong&gt;Advanced Analytics&lt;/strong&gt; – Track email delivery, open rates, click-through rates, and more.&lt;br /&gt; 📧 &lt;strong&gt;Unlimited Sending&lt;/strong&gt; – No restrictions on the number of emails you can send.&lt;br /&gt; 🎨 &lt;strong&gt;Customizable Templates&lt;/strong&gt; – Custom professional marketing templates for reuse. 🔒 &lt;strong&gt;Privacy-First&lt;/strong&gt; – Your data stays with you, no third-party tracking.&lt;br /&gt; 🚀 &lt;strong&gt;Self-Hosted&lt;/strong&gt; – Run it on your own server for complete control.&lt;/p&gt; 
&lt;h2&gt;How You Can Help 🌟&lt;/h2&gt; 
&lt;p&gt;BillionMail is a &lt;strong&gt;community-driven project&lt;/strong&gt;, and we need your support to get started! Here's how you can help:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Star This Repository&lt;/strong&gt;: Show your interest by starring this repo.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Spread the Word&lt;/strong&gt;: Share BillionMail with your network—developers, marketers, and open-source enthusiasts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Share Feedback&lt;/strong&gt;: Let us know what features you'd like to see in BillionMail by opening an issue or joining the discussion.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contribute&lt;/strong&gt;: Once development begins, we'll welcome contributions from the community. Stay tuned for updates!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;p&gt;📧 &lt;strong&gt;BillionMail – The Future of Open-Source Email Marketing.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Issues&lt;/h2&gt; 
&lt;p&gt;If you encounter any issues or have feature requests, please &lt;a href="https://github.com/aaPanel/BillionMail/issues"&gt;open an issue&lt;/a&gt;. Be sure to include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A clear description of the problem or request.&lt;/li&gt; 
 &lt;li&gt;Steps to reproduce the issue (if applicable).&lt;/li&gt; 
 &lt;li&gt;Screenshots or error logs (if applicable).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install Now:&lt;/h2&gt; 
&lt;p&gt;✅It takes &lt;strong&gt;only 8 minutes&lt;/strong&gt; from installation to &lt;strong&gt;successful email sending&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; bash install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Install with Docker:&lt;/strong&gt; (Please install Docker and docker-compose-plugin manually, and modify .env file)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd /opt &amp;amp;&amp;amp; git clone https://github.com/aaPanel/BillionMail &amp;amp;&amp;amp; cd BillionMail &amp;amp;&amp;amp; cp env_init .env &amp;amp;&amp;amp; docker compose up -d || docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#aapanel/billionmail&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=aapanel/billionmail&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;BillionMail is licensed under the &lt;strong&gt;AGPLv3 License&lt;/strong&gt;. This means you can:&lt;/p&gt; 
&lt;p&gt;✅ Use the software for free.&lt;br /&gt; ✅ Modify and distribute the code.&lt;br /&gt; ✅ Use it privately without restrictions.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/aaPanel/BillionMail/dev/LICENSE"&gt;LICENSE&lt;/a&gt; file for more details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;!-- BillionMail official link --&gt; 
&lt;!-- BillionMail Other link--&gt; 
&lt;!-- Shield link--&gt;</description>
    </item>
    
    <item>
      <title>microsoft/ai-agents-for-beginners</title>
      <link>https://github.com/microsoft/ai-agents-for-beginners</link>
      <description>&lt;p&gt;12 Lessons to Get Started Building AI Agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Agents for Beginners - A Course&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/images/repo-thumbnailv2.png" alt="Generative AI For Beginners" /&gt;&lt;/p&gt; 
&lt;h2&gt;A course teaching everything you need to know to start building AI Agents&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/ai-agents-for-beginners/raw/master/LICENSE?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/license/microsoft/ai-agents-for-beginners.svg?sanitize=true" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/graphs/contributors/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/contributors/microsoft/ai-agents-for-beginners.svg?sanitize=true" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/issues/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/issues/microsoft/ai-agents-for-beginners.svg?sanitize=true" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/pulls/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/issues-pr/microsoft/ai-agents-for-beginners.svg?sanitize=true" alt="GitHub pull-requests" /&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;🌐 Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/fr/README.md"&gt;French&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/es/README.md"&gt;Spanish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/de/README.md"&gt;German&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ru/README.md"&gt;Russian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ar/README.md"&gt;Arabic&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/fa/README.md"&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ur/README.md"&gt;Urdu&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/zh/README.md"&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/mo/README.md"&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hk/README.md"&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/tw/README.md"&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ja/README.md"&gt;Japanese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ko/README.md"&gt;Korean&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hi/README.md"&gt;Hindi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/bn/README.md"&gt;Bengali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/mr/README.md"&gt;Marathi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ne/README.md"&gt;Nepali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/pa/README.md"&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/pt/README.md"&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/br/README.md"&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/it/README.md"&gt;Italian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/pl/README.md"&gt;Polish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/tr/README.md"&gt;Turkish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/el/README.md"&gt;Greek&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/th/README.md"&gt;Thai&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sv/README.md"&gt;Swedish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/da/README.md"&gt;Danish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/no/README.md"&gt;Norwegian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/fi/README.md"&gt;Finnish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/nl/README.md"&gt;Dutch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/he/README.md"&gt;Hebrew&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/vi/README.md"&gt;Vietnamese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/id/README.md"&gt;Indonesian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ms/README.md"&gt;Malay&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/tl/README.md"&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sw/README.md"&gt;Swahili&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hu/README.md"&gt;Hungarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/cs/README.md"&gt;Czech&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sk/README.md"&gt;Slovak&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ro/README.md"&gt;Romanian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/bg/README.md"&gt;Bulgarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sr/README.md"&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hr/README.md"&gt;Croatian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sl/README.md"&gt;Slovenian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/uk/README.md"&gt;Ukrainian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/my/README.md"&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;If you wish to have additional translations languages supported are listed &lt;a href="https://github.com/Azure/co-op-translator/raw/main/getting_started/supported-languages.md"&gt;here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/watchers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/watchers/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Watch" alt="GitHub watchers" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/network/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/stargazers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/kzRShWzttr"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/kzRShWzttr" alt="Azure AI Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🌱 Getting Started&lt;/h2&gt; 
&lt;p&gt;This course has lessons covering the fundamentals of building AI Agents. Each lesson covers its own topic so start wherever you like!&lt;/p&gt; 
&lt;p&gt;There is multi-language support for this course. Go to our &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/#-multi-language-support"&gt;available languages here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If this is your first time building with Generative AI models, check out our &lt;a href="https://aka.ms/genai-beginners"&gt;Generative AI For Beginners&lt;/a&gt; course, which includes 21 lessons on building with GenAI.&lt;/p&gt; 
&lt;p&gt;Don't forget to &lt;a href="https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-105485-koreyst"&gt;star (🌟) this repo&lt;/a&gt; and &lt;a href="https://github.com/microsoft/ai-agents-for-beginners/fork"&gt;fork this repo&lt;/a&gt; to run the code.&lt;/p&gt; 
&lt;h3&gt;Meet Other Learners, Get Your Questions Answered&lt;/h3&gt; 
&lt;p&gt;If you get stuck or have any questions about building AI Agents, join our dedicated Discord Channel in the &lt;a href="https://aka.ms/ai-agents/discord"&gt;Azure AI Foundry Community Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;What You Need&lt;/h3&gt; 
&lt;p&gt;Each lesson in this course includes code examples, which can be found in the code_samples folder. You can &lt;a href="https://github.com/microsoft/ai-agents-for-beginners/fork"&gt;fork this repo&lt;/a&gt; to create your own copy.&lt;/p&gt; 
&lt;p&gt;The code example in these exercises, utilize Azure AI Foundry and GitHub Model Catalogs for interacting with Language Models:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-agents-beginners/github-models"&gt;Github Models&lt;/a&gt; - Free / Limited&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-agents-beginners/ai-foundry"&gt;Azure AI Foundry&lt;/a&gt; - Azure Account Required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This course also uses the following AI Agent frameworks and services from Microsoft:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-agents-beginners/ai-agent-service"&gt;Azure AI Agent Service&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-agents-beginners/semantic-kernel"&gt;Semantic Kernel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-agents/autogen"&gt;AutoGen&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information on running the code for this course, go to the &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/00-course-setup/README.md"&gt;Course Setup&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🙏 Want to help?&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? &lt;a href="https://github.com/microsoft/ai-agents-for-beginners/issues?WT.mc_id=academic-105485-koreyst"&gt;Raise an issue&lt;/a&gt; or &lt;a href="https://github.com/microsoft/ai-agents-for-beginners/pulls?WT.mc_id=academic-105485-koreyst"&gt;Create a pull request&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📂 Each lesson includes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A written lesson located in the README and a short video&lt;/li&gt; 
 &lt;li&gt;Python code samples supporting Azure AI Foundry and Github Models (Free)&lt;/li&gt; 
 &lt;li&gt;Links to extra resources to continue your learning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🗃️ Lessons&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Lesson&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Text &amp;amp; Code&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Extra Learning&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Intro to AI Agents and Agent Use Cases&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/01-intro-to-ai-agents/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/3zgm60bXmQk?si=z8QygFvYQv-9WtO1"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Exploring AI Agentic Frameworks&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/02-explore-agentic-frameworks/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/ODwF-EZo_O8?si=Vawth4hzVaHv-u0H"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Understanding AI Agentic Design Patterns&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/03-agentic-design-patterns/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/m9lM8qqoOEA?si=BIzHwzstTPL8o9GF"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tool Use Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/04-tool-use/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/vieRiPRx-gI?si=2z6O2Xu2cu_Jz46N"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agentic RAG&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/05-agentic-rag/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/WcjAARvdL7I?si=gKPWsQpKiIlDH9A3"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Building Trustworthy AI Agents&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/06-building-trustworthy-agents/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/iZKkMEGBCUQ?si=jZjpiMnGFOE9L8OK"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Planning Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/07-planning-design/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/kPfJ2BrBCMY?si=6SC_iv_E5-mzucnC"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multi-Agent Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/08-multi-agent/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/V6HpE9hZEx0?si=rMgDhEu7wXo2uo6g"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Metacognition Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/09-metacognition/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/His9R6gw6Ec?si=8gck6vvdSNCt6OcF"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AI Agents in Production&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/10-ai-agents-production/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/l4TP6IyJxmQ?si=31dnhexRo6yLRJDl"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Using Agentic Protocols (MCP, A2A and NLWeb)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/11-agentic-protocols/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/X-Dh9R3Opn8"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Context Engineering for AI Agents&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/12-context-engineering/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/F5zqRV7gEag"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Managing Agentic Memory&lt;/td&gt; 
   &lt;td&gt;Coming - September 11th&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Evaluating AI Agents&lt;/td&gt; 
   &lt;td&gt;Coming - September 18th&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Building Computer Use Agents (CUA)&lt;/td&gt; 
   &lt;td&gt;Coming - September 25th&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deploying Scalable Agents&lt;/td&gt; 
   &lt;td&gt;Coming - September 25th&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Creating Local AI Agents&lt;/td&gt; 
   &lt;td&gt;Coming - October 3rd&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Securing AI Agents&lt;/td&gt; 
   &lt;td&gt;Coming - October 10th&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🎒 Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mcp-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;&lt;strong&gt;NEW&lt;/strong&gt; Model Context Protocol (MCP) For Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-for-beginners-java?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst"&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst"&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung"&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst"&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst"&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst"&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🌟 Community Thanks&lt;/h2&gt; 
&lt;p&gt;Thanks to &lt;a href="https://www.linkedin.com/in/shivam2003/"&gt;Shivam Goyal&lt;/a&gt; for contributing important code samples demonstrating Agentic RAG.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos is subject to those third-parties' policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>modelcontextprotocol/registry</title>
      <link>https://github.com/modelcontextprotocol/registry</link>
      <description>&lt;p&gt;A community driven registry service for Model Context Protocol (MCP) servers.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MCP Registry&lt;/h1&gt; 
&lt;p&gt;The MCP registry provides MCP clients with a list of MCP servers, like an app store for MCP servers.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docs/guides/publishing/publish-server.md"&gt;&lt;strong&gt;📤 Publish my MCP server&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://registry.modelcontextprotocol.io/docs"&gt;&lt;strong&gt;⚡️ Live API docs&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docs/explanations/ecosystem-vision.md"&gt;&lt;strong&gt;👀 Ecosystem vision&lt;/strong&gt;&lt;/a&gt; | 📖 &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docs"&gt;Full documentation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Development Status&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;2025-09-08 update&lt;/strong&gt;: The registry has launched in preview 🎉 (&lt;a href="https://blog.modelcontextprotocol.io/posts/2025-09-08-mcp-registry-preview/"&gt;announcement blog post&lt;/a&gt;). While the system is now more stable, this is still a preview release and breaking changes or data resets may occur. A general availability (GA) release will follow later. We'd love your feedback in &lt;a href="https://github.com/modelcontextprotocol/registry/discussions/new?category=ideas"&gt;GitHub discussions&lt;/a&gt; or in the &lt;a href="https://discord.com/channels/1358869848138059966/1369487942862504016"&gt;#registry-dev Discord&lt;/a&gt; (&lt;a href="https://modelcontextprotocol.io/community/communication"&gt;joining details here&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Current key maintainers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Adam Jones&lt;/strong&gt; (Anthropic) &lt;a href="https://github.com/domdomegg"&gt;@domdomegg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tadas Antanavicius&lt;/strong&gt; (PulseMCP) &lt;a href="https://github.com/tadasant"&gt;@tadasant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Toby Padilla&lt;/strong&gt; (GitHub) &lt;a href="https://github.com/toby"&gt;@toby&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We use multiple channels for collaboration - see &lt;a href="https://modelcontextprotocol.io/community/communication"&gt;modelcontextprotocol.io/community/communication&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Often (but not always) ideas flow through this pipeline:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://modelcontextprotocol.io/community/communication"&gt;Discord&lt;/a&gt;&lt;/strong&gt; - Real-time community discussions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/modelcontextprotocol/registry/discussions"&gt;Discussions&lt;/a&gt;&lt;/strong&gt; - Propose and discuss product/technical requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/modelcontextprotocol/registry/issues"&gt;Issues&lt;/a&gt;&lt;/strong&gt; - Track well-scoped technical work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/modelcontextprotocol/registry/pulls"&gt;Pull Requests&lt;/a&gt;&lt;/strong&gt; - Contribute work towards issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick start:&lt;/h3&gt; 
&lt;h4&gt;Pre-requisites&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Go 1.24.x&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;golangci-lint v2.4.0&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Running the server&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start full development environment
make dev-compose
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts the registry at &lt;a href="http://localhost:8080"&gt;&lt;code&gt;localhost:8080&lt;/code&gt;&lt;/a&gt; with PostgreSQL and seed data. It can be configured with environment variables in &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt; - see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/.env.example"&gt;.env.example&lt;/a&gt; for a reference.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Alternative: Local setup without Docker&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;PostgreSQL running locally&lt;/li&gt; 
  &lt;li&gt;Go 1.24.x installed&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Build and run locally
make build
make dev-local
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The service runs on &lt;a href="http://localhost:8080"&gt;&lt;code&gt;localhost:8080&lt;/code&gt;&lt;/a&gt; by default. This can be configured with environment variables in &lt;code&gt;.env&lt;/code&gt; - see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/.env.example"&gt;.env.example&lt;/a&gt; for a reference.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Alternative: Running a pre-built Docker image&lt;/summary&gt; 
 &lt;p&gt;Pre-built Docker images are automatically published to GitHub Container Registry:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Run latest stable release
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:latest

# Run latest from main branch (continuous deployment)
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:main

# Run specific release version
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:v1.0.0

# Run development build from main branch
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:main-20250906-abc123d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Available tags:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Releases&lt;/strong&gt;: &lt;code&gt;latest&lt;/code&gt;, &lt;code&gt;v1.0.0&lt;/code&gt;, &lt;code&gt;v1.1.0&lt;/code&gt;, etc.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Continuous&lt;/strong&gt;: &lt;code&gt;main&lt;/code&gt; (latest main branch build)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Development&lt;/strong&gt;: &lt;code&gt;main-&amp;lt;date&amp;gt;-&amp;lt;sha&amp;gt;&lt;/code&gt; (specific commit builds)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h4&gt;Publishing a server&lt;/h4&gt; 
&lt;p&gt;To publish a server, we've built a simple CLI. You can use it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build the latest CLI
make publisher

# Use it!
./bin/mcp-publisher --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docs/guides/publishing/publish-server.md"&gt;the publisher guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h4&gt;Other commands&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run lint, unit tests and integration tests
make check
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are also a few more helpful commands for development. Run &lt;code&gt;make help&lt;/code&gt; to learn more, or look in &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/Makefile"&gt;Makefile&lt;/a&gt;.&lt;/p&gt; 
&lt;!--
For Claude and other AI tools: Always prefer make targets over custom commands where possible.
--&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;h3&gt;Project Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;├── cmd/                     # Application entry points
│   └── publisher/           # Server publishing tool
├── data/                    # Seed data
├── deploy/                  # Deployment configuration (Pulumi)
├── docs/                    # Documentation
├── internal/                # Private application code
│   ├── api/                 # HTTP handlers and routing
│   ├── auth/                # Authentication (GitHub OAuth, JWT, namespace blocking)
│   ├── config/              # Configuration management
│   ├── database/            # Data persistence (PostgreSQL, in-memory)
│   ├── service/             # Business logic
│   ├── telemetry/           # Metrics and monitoring
│   └── validators/          # Input validation
├── pkg/                     # Public packages
│   ├── api/                 # API types and structures
│   │   └── v0/              # Version 0 API types
│   └── model/               # Data models for server.json
├── scripts/                 # Development and testing scripts
├── tests/                   # Integration tests
└── tools/                   # CLI tools and utilities
    └── validate-*.sh        # Schema validation tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Authentication&lt;/h3&gt; 
&lt;p&gt;Publishing supports multiple authentication methods:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub OAuth&lt;/strong&gt; - For publishing by logging into GitHub&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub OIDC&lt;/strong&gt; - For publishing from GitHub Actions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DNS verification&lt;/strong&gt; - For proving ownership of a domain and its subdomains&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP verification&lt;/strong&gt; - For proving ownership of a domain&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The registry validates namespace ownership when publishing. E.g. to publish...:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;io.github.domdomegg/my-cool-mcp&lt;/code&gt; you must login to GitHub as &lt;code&gt;domdomegg&lt;/code&gt;, or be in a GitHub Action on domdomegg's repos&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;me.adamjones/my-cool-mcp&lt;/code&gt; you must prove ownership of &lt;code&gt;adamjones.me&lt;/code&gt; via DNS or HTTP challenge&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;More documentation&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docs"&gt;documentation&lt;/a&gt; for more details if your question has not been answered here!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PowerShell/PowerShell</title>
      <link>https://github.com/PowerShell/PowerShell</link>
      <description>&lt;p&gt;PowerShell for every system!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://raw.githubusercontent.com/PowerShell/PowerShell/master/assets/ps_black_64.svg?sanitize=true" alt="logo" /&gt; PowerShell&lt;/h1&gt; 
&lt;p&gt;Welcome to the PowerShell GitHub Community! &lt;a href="https://learn.microsoft.com/powershell/scripting/overview"&gt;PowerShell&lt;/a&gt; is a cross-platform (Windows, Linux, and macOS) automation and configuration tool/framework that works well with your existing tools and is optimized for dealing with structured data (e.g. JSON, CSV, XML, etc.), REST APIs, and object models. It includes a command-line shell, an associated scripting language, and a framework for processing cmdlets.&lt;/p&gt; 
&lt;h2&gt;Windows PowerShell vs. PowerShell 7+&lt;/h2&gt; 
&lt;p&gt;Although this repository started as a fork of the Windows PowerShell codebase, changes made in this repository are not ported back to Windows PowerShell 5.1. This also means that &lt;a href="https://github.com/PowerShell/PowerShell/issues"&gt;issues tracked here&lt;/a&gt; are only for PowerShell 7.x and higher. Windows PowerShell specific issues should be reported with the &lt;a href="https://support.microsoft.com/windows/send-feedback-to-microsoft-with-the-feedback-hub-app-f59187f8-8739-22d6-ba93-f66612949332"&gt;Feedback Hub app&lt;/a&gt;, by choosing "Apps &amp;gt; PowerShell" in the category.&lt;/p&gt; 
&lt;h2&gt;New to PowerShell?&lt;/h2&gt; 
&lt;p&gt;If you are new to PowerShell and want to learn more, we recommend reviewing the &lt;a href="https://learn.microsoft.com/powershell/scripting/learn/more-powershell-learning"&gt;getting started&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;h2&gt;Get PowerShell&lt;/h2&gt; 
&lt;p&gt;PowerShell is supported on Windows, macOS, and a variety of Linux platforms. For more information, see &lt;a href="https://learn.microsoft.com/powershell/scripting/install/installing-powershell"&gt;Installing PowerShell&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Upgrading PowerShell&lt;/h2&gt; 
&lt;p&gt;For best results when upgrading, you should use the same install method you used when you first installed PowerShell. The update method is different for each platform and install method.&lt;/p&gt; 
&lt;h2&gt;Community Dashboard&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aka.ms/PSPublicDashboard"&gt;Dashboard&lt;/a&gt; with visualizations for community contributions and project status using PowerShell, Azure, and PowerBI.&lt;/p&gt; 
&lt;p&gt;For more information on how and why we built this dashboard, check out this &lt;a href="https://devblogs.microsoft.com/powershell/powershell-open-source-community-dashboard/"&gt;blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Discussions&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://docs.github.com/discussions/quickstart"&gt;GitHub Discussions&lt;/a&gt; is a feature to enable free and open discussions within the community for topics that are not related to code, unlike issues.&lt;/p&gt; 
&lt;p&gt;This is an experiment we are trying in our repositories, to see if it helps move discussions out of issues so that issues remain actionable by the team or members of the community. There should be no expectation that PowerShell team members are regular participants in these discussions. Individual PowerShell team members may choose to participate in discussions, but the expectation is that community members help drive discussions so that team members can focus on issues.&lt;/p&gt; 
&lt;p&gt;Create or join a &lt;a href="https://github.com/PowerShell/PowerShell/discussions"&gt;discussion&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Chat&lt;/h2&gt; 
&lt;p&gt;Want to chat with other members of the PowerShell community?&lt;/p&gt; 
&lt;p&gt;There are dozens of topic-specific channels on our community-driven PowerShell Virtual User Group, which you can join on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitter.im/PowerShell/PowerShell"&gt;Gitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/PowerShell"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.libera.chat/#powershell"&gt;IRC&lt;/a&gt; on Libera.Chat&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/psslack"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build status of nightly builds&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Azure CI (Windows)&lt;/th&gt; 
   &lt;th align="left"&gt;Azure CI (Linux)&lt;/th&gt; 
   &lt;th align="left"&gt;Azure CI (macOS)&lt;/th&gt; 
   &lt;th align="left"&gt;CodeFactor Grade&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://powershell.visualstudio.com/PowerShell/_build?definitionId=32"&gt;&lt;img src="https://powershell.visualstudio.com/PowerShell/_apis/build/status/PowerShell-CI-Windows-daily" alt="windows-nightly-image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://powershell.visualstudio.com/PowerShell/_build?definitionId=23"&gt;&lt;img src="https://powershell.visualstudio.com/PowerShell/_apis/build/status/PowerShell-CI-linux-daily?branchName=master" alt="linux-nightly-image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://powershell.visualstudio.com/PowerShell/_build?definitionId=24"&gt;&lt;img src="https://powershell.visualstudio.com/PowerShell/_apis/build/status/PowerShell-CI-macos-daily?branchName=master" alt="macOS-nightly-image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.codefactor.io/repository/github/powershell/powershell"&gt;&lt;img src="https://www.codefactor.io/repository/github/powershell/powershell/badge" alt="cf-image" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Developing and Contributing&lt;/h2&gt; 
&lt;p&gt;Want to contribute to PowerShell? Please start with the &lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/.github/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; to learn how to develop and contribute.&lt;/p&gt; 
&lt;p&gt;If you are developing .NET Core C# applications targeting PowerShell Core, &lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/docs/FAQ.md#where-do-i-get-the-powershell-core-sdk-package"&gt;check out our FAQ&lt;/a&gt; to learn more about the PowerShell SDK NuGet package.&lt;/p&gt; 
&lt;p&gt;Also, make sure to check out our &lt;a href="https://github.com/powershell/powershell-rfc"&gt;PowerShell-RFC repository&lt;/a&gt; for request-for-comments (RFC) documents to submit and give comments on proposed and future designs.&lt;/p&gt; 
&lt;h2&gt;Building PowerShell&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Linux&lt;/th&gt; 
   &lt;th&gt;Windows&lt;/th&gt; 
   &lt;th&gt;macOS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/docs/building/linux.md"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/docs/building/windows-core.md"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/docs/building/macos.md"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;If you have any problems building PowerShell, please start by consulting the developer &lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/docs/FAQ.md"&gt;FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Downloading the Source Code&lt;/h2&gt; 
&lt;p&gt;You can clone the repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/PowerShell/PowerShell.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information, see &lt;a href="https://github.com/PowerShell/PowerShell/tree/master/docs/git"&gt;working with the PowerShell repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;For support, see the &lt;a href="https://github.com/PowerShell/PowerShell/tree/master/.github/SUPPORT.md"&gt;Support Section&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Legal and Licensing&lt;/h2&gt; 
&lt;p&gt;PowerShell is licensed under the &lt;a href="https://github.com/PowerShell/PowerShell/tree/master/LICENSE.txt"&gt;MIT license&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker Containers&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] The PowerShell container images are now &lt;a href="https://github.com/PowerShell/Announcements/issues/75"&gt;maintained by the .NET team&lt;/a&gt;. The containers at &lt;code&gt;mcr.microsoft.com/powershell&lt;/code&gt; are currently not maintained.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;License: By requesting and using the Container OS Image for Windows containers, you acknowledge, understand, and consent to the Supplemental License Terms available on &lt;a href="https://mcr.microsoft.com/en-us/product/powershell/tags"&gt;Microsoft Artifact Registry&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Telemetry&lt;/h3&gt; 
&lt;p&gt;Please visit our &lt;a href="https://learn.microsoft.com/powershell/module/microsoft.powershell.core/about/about_telemetry"&gt;about_Telemetry&lt;/a&gt; topic to read details about telemetry gathered by PowerShell.&lt;/p&gt; 
&lt;h2&gt;Governance&lt;/h2&gt; 
&lt;p&gt;The governance policy for the PowerShell project is described the &lt;a href="https://github.com/PowerShell/PowerShell/raw/master/docs/community/governance.md"&gt;PowerShell Governance&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Please see our &lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; before participating in this project.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/.github/SECURITY.md"&gt;Security Policy&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;For any security issues, please see our &lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/.github/SECURITY.md"&gt;Security Policy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>grpc/grpc-go</title>
      <link>https://github.com/grpc/grpc-go</link>
      <description>&lt;p&gt;The Go language implementation of gRPC. HTTP/2 based RPC&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;gRPC-Go&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/google.golang.org/grpc"&gt;&lt;img src="https://pkg.go.dev/badge/google.golang.org/grpc" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/grpc/grpc-go"&gt;&lt;img src="https://goreportcard.com/badge/grpc/grpc-go" alt="GoReportCard" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/grpc/grpc-go"&gt;&lt;img src="https://codecov.io/gh/grpc/grpc-go/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://golang.org"&gt;Go&lt;/a&gt; implementation of &lt;a href="https://grpc.io"&gt;gRPC&lt;/a&gt;: A high performance, open source, general RPC framework that puts mobile and HTTP/2 first. For more information see the &lt;a href="https://grpc.io/docs/languages/go"&gt;Go gRPC docs&lt;/a&gt;, or jump directly into the &lt;a href="https://grpc.io/docs/languages/go/quickstart"&gt;quick start&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://golang.org"&gt;Go&lt;/a&gt;&lt;/strong&gt;: any one of the &lt;strong&gt;two latest major&lt;/strong&gt; &lt;a href="https://golang.org/doc/devel/release.html"&gt;releases&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Simply add the following import to your code, and then &lt;code&gt;go [build|run|test]&lt;/code&gt; will automatically fetch the necessary dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import "google.golang.org/grpc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you are trying to access &lt;code&gt;grpc-go&lt;/code&gt; from &lt;strong&gt;China&lt;/strong&gt;, see the &lt;a href="https://raw.githubusercontent.com/grpc/grpc-go/master/#FAQ"&gt;FAQ&lt;/a&gt; below.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Learn more&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grpc.io/docs/languages/go"&gt;Go gRPC docs&lt;/a&gt;, which include a &lt;a href="https://grpc.io/docs/languages/go/quickstart"&gt;quick start&lt;/a&gt; and &lt;a href="https://pkg.go.dev/google.golang.org/grpc"&gt;API reference&lt;/a&gt; among other resources&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/grpc/grpc-go/master/Documentation"&gt;Low-level technical docs&lt;/a&gt; from this repository&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608"&gt;Performance benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/grpc/grpc-go/master/examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/grpc/grpc-go/master/CONTRIBUTING.md"&gt;Contribution guidelines&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;I/O Timeout Errors&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;golang.org&lt;/code&gt; domain may be blocked from some countries. &lt;code&gt;go get&lt;/code&gt; usually produces an error like the following when this happens:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ go get -u google.golang.org/grpc
package google.golang.org/grpc: unrecognized import path "google.golang.org/grpc" (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build Go code, there are several options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Set up a VPN and access google.golang.org through that.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;With Go module support: it is possible to use the &lt;code&gt;replace&lt;/code&gt; feature of &lt;code&gt;go mod&lt;/code&gt; to create aliases for golang.org packages. In your project's directory:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest
go mod tidy
go mod vendor
go build -mod=vendor
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Again, this will need to be done for all transitive dependencies hosted on golang.org as well. For details, refer to &lt;a href="https://github.com/golang/go/issues/28652"&gt;golang/go issue #28652&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Compiling error, undefined: grpc.SupportPackageIsVersion&lt;/h3&gt; 
&lt;p&gt;Please update to the latest version of gRPC-Go using &lt;code&gt;go get google.golang.org/grpc&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;How to turn on logging&lt;/h3&gt; 
&lt;p&gt;The default logger is controlled by environment variables. Turn everything on like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99
$ export GRPC_GO_LOG_SEVERITY_LEVEL=info
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;The RPC failed with error &lt;code&gt;"code = Unavailable desc = transport is closing"&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;This error means the connection the RPC is using was closed, and there are many possible reasons, including:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;mis-configured transport credentials, connection failed on handshaking&lt;/li&gt; 
 &lt;li&gt;bytes disrupted, possibly by a proxy in between&lt;/li&gt; 
 &lt;li&gt;server shutdown&lt;/li&gt; 
 &lt;li&gt;Keepalive parameters caused connection shutdown, for example if you have configured your server to terminate connections regularly to &lt;a href="https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779"&gt;trigger DNS lookups&lt;/a&gt;. If this is the case, you may want to increase your &lt;a href="https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters"&gt;MaxConnectionAgeGrace&lt;/a&gt;, to allow longer RPC calls to finish.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;It can be tricky to debug this because the error happens on the client side but the root cause of the connection being closed is on the server side. Turn on logging on &lt;strong&gt;both client and server&lt;/strong&gt;, and see if there are any transport errors.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>trufflesecurity/trufflehog</title>
      <link>https://github.com/trufflesecurity/trufflehog</link>
      <description>&lt;p&gt;Find, verify, and analyze leaked credentials&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img alt="GoReleaser Logo" src="https://storage.googleapis.com/trufflehog-static-sources/pixel_pig.png" height="140" /&gt; &lt;/p&gt;
&lt;h2 align="center"&gt;TruffleHog&lt;/h2&gt; 
&lt;p align="center"&gt;Find leaked credentials.&lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/trufflesecurity/trufflehog/v3"&gt;&lt;img src="https://goreportcard.com/badge/github.com/trufflesecurity/trufflehog/v3" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL--3.0-brightgreen" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/pkg/detectors"&gt;&lt;img src="https://img.shields.io/github/directory-file-count/trufflesecurity/truffleHog/pkg/detectors?label=Total%20Detectors&amp;amp;type=dir" alt="Total Detectors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h1&gt;&lt;span&gt;🔎&lt;/span&gt; &lt;em&gt;Now Scanning&lt;/em&gt;&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/assets/scanning_logos.svg?sanitize=true" /&gt; 
 &lt;p&gt;&lt;strong&gt;...and more&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;To learn more about TruffleHog and its features and capabilities, visit our &lt;a href="https://trufflesecurity.com/trufflehog?gclid=CjwKCAjwouexBhAuEiwAtW_Zx5IW87JNj97Ci7heFnA5ar6-DuNzT2Y5nIl9DuZ-FOUqx0Qg3vb9nxoClcEQAvD_BwE"&gt;product page&lt;/a&gt;.&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;&lt;span&gt;🌐&lt;/span&gt; TruffleHog Enterprise&lt;/h1&gt; 
&lt;p&gt;Are you interested in continuously monitoring &lt;strong&gt;Git, Jira, Slack, Confluence, Microsoft Teams, Sharepoint, and more..&lt;/strong&gt; for credentials? We have an enterprise product that can help! Learn more at &lt;a href="https://trufflesecurity.com/trufflehog-enterprise"&gt;https://trufflesecurity.com/trufflehog-enterprise&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We take the revenue from the enterprise product to fund more awesome open source projects that the whole community can benefit from.&lt;/p&gt;  
&lt;h1&gt;What is TruffleHog 🐽&lt;/h1&gt; 
&lt;p&gt;TruffleHog is the most powerful secrets &lt;strong&gt;Discovery, Classification, Validation,&lt;/strong&gt; and &lt;strong&gt;Analysis&lt;/strong&gt; tool. In this context, secret refers to a credential a machine uses to authenticate itself to another machine. This includes API keys, database passwords, private encryption keys, and more...&lt;/p&gt; 
&lt;h2&gt;Discovery 🔍&lt;/h2&gt; 
&lt;p&gt;TruffleHog can look for secrets in many places including Git, chats, wikis, logs, API testing platforms, object stores, filesystems and more&lt;/p&gt; 
&lt;h2&gt;Classification 📁&lt;/h2&gt; 
&lt;p&gt;TruffleHog classifies over 800 secret types, mapping them back to the specific identity they belong to. Is it an AWS secret? Stripe secret? Cloudflare secret? Postgres password? SSL Private key? Sometimes it's hard to tell looking at it, so TruffleHog classifies everything it finds.&lt;/p&gt; 
&lt;h2&gt;Validation ✅&lt;/h2&gt; 
&lt;p&gt;For every secret TruffleHog can classify, it can also log in to confirm if that secret is live or not. This step is critical to know if there’s an active present danger or not.&lt;/p&gt; 
&lt;h2&gt;Analysis 🔬&lt;/h2&gt; 
&lt;p&gt;For the 20 some of the most commonly leaked out credential types, instead of sending one request to check if the secret can log in, TruffleHog can send many requests to learn everything there is to know about the secret. Who created it? What resources can it access? What permissions does it have on those resources?&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;📢&lt;/span&gt; Join Our Community&lt;/h1&gt; 
&lt;p&gt;Have questions? Feedback? Jump into Slack or Discord and hang out with us.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://join.slack.com/t/trufflehog-community/shared_invite/zt-pw2qbi43-Aa86hkiimstfdKH9UCpPzQ"&gt;Slack Community&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Join the &lt;a href="https://discord.gg/8Hzbrnkr7E"&gt;Secret Scanning Discord&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;📺&lt;/span&gt; Demo&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://storage.googleapis.com/truffle-demos/non-interactive.svg?sanitize=true" alt="GitHub scanning demo" /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it -v "$PWD:/pwd" trufflesecurity/trufflehog:latest github --org=trufflesecurity
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;&lt;span&gt;💾&lt;/span&gt; Installation&lt;/h1&gt; 
&lt;p&gt;Several options are available for you:&lt;/p&gt; 
&lt;h3&gt;MacOS users&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install trufflehog
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker:&lt;/h3&gt; 
&lt;p&gt;&lt;sub&gt;&lt;i&gt;&lt;em&gt;Ensure Docker engine is running before executing the following commands:&lt;/em&gt;&lt;/i&gt;&lt;/sub&gt;&lt;/p&gt; 
&lt;h4&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Unix&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it -v "$PWD:/pwd" trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Windows Command Prompt&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it -v "%cd:/=\%:/pwd" trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Windows PowerShell&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -it -v "${PWD}:/pwd" trufflesecurity/trufflehog github --repo https://github.com/trufflesecurity/test_keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;M1 and M2 Mac&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --platform linux/arm64 --rm -it -v "$PWD:/pwd" trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Binary releases&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;Download and unpack from https://github.com/trufflesecurity/trufflehog/releases
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Compile from source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/trufflesecurity/trufflehog.git
cd trufflehog; go install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using installation script&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using installation script, verify checksum signature (requires cosign to be installed)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -v -b /usr/local/bin
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using installation script to install a specific version&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin &amp;lt;ReleaseTag like v3.56.0&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;&lt;span&gt;🔐&lt;/span&gt; Verifying the artifacts&lt;/h1&gt; 
&lt;p&gt;Checksums are applied to all artifacts, and the resulting checksum file is signed using cosign.&lt;/p&gt; 
&lt;p&gt;You need the following tool to verify signature:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.sigstore.dev/cosign/system_config/installation/"&gt;Cosign&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Verification steps are as follows:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Download the artifact files you want, and the following files from the &lt;a href="https://github.com/trufflesecurity/trufflehog/releases"&gt;releases&lt;/a&gt; page.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;trufflehog_{version}_checksums.txt&lt;/li&gt; 
   &lt;li&gt;trufflehog_{version}_checksums.txt.pem&lt;/li&gt; 
   &lt;li&gt;trufflehog_{version}_checksums.txt.sig&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Verify the signature:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;cosign verify-blob &amp;lt;path to trufflehog_{version}_checksums.txt&amp;gt; \
--certificate &amp;lt;path to trufflehog_{version}_checksums.txt.pem&amp;gt; \
--signature &amp;lt;path to trufflehog_{version}_checksums.txt.sig&amp;gt; \
--certificate-identity-regexp 'https://github\.com/trufflesecurity/trufflehog/\.github/workflows/.+' \
--certificate-oidc-issuer "https://token.actions.githubusercontent.com"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Once the signature is confirmed as valid, you can proceed to validate that the SHA256 sums align with the downloaded artifact:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sha256sum --ignore-missing -c trufflehog_{version}_checksums.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Replace &lt;code&gt;{version}&lt;/code&gt; with the downloaded files version&lt;/p&gt; 
&lt;p&gt;Alternatively, if you are using the installation script, pass &lt;code&gt;-v&lt;/code&gt; option to perform signature verification. This requires Cosign binary to be installed prior to running the installation script.&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;🚀&lt;/span&gt; Quick Start&lt;/h1&gt; 
&lt;h2&gt;1: Scan a repo for only verified secrets&lt;/h2&gt; 
&lt;p&gt;Command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog git https://github.com/trufflesecurity/test_keys --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expected output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;🐷🔑🐷  TruffleHog. Unearth your secrets. 🐷🔑🐷

Found verified result 🐷🔑
Detector Type: AWS
Decoder Type: PLAIN
Raw result: AKIAYVP4CIPPERUVIFXG
Line: 4
Commit: fbc14303ffbf8fb1c2c1914e8dda7d0121633aca
File: keys
Email: counter &amp;lt;counter@counters-MacBook-Air.local&amp;gt;
Repository: https://github.com/trufflesecurity/test_keys
Timestamp: 2022-06-16 10:17:40 -0700 PDT
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;2: Scan a GitHub Org for only verified secrets&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog github --org=trufflesecurity --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3: Scan a GitHub Repo for only verified keys and get JSON output&lt;/h2&gt; 
&lt;p&gt;Command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog git https://github.com/trufflesecurity/test_keys --results=verified,unknown --json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expected output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{"SourceMetadata":{"Data":{"Git":{"commit":"fbc14303ffbf8fb1c2c1914e8dda7d0121633aca","file":"keys","email":"counter \u003ccounter@counters-MacBook-Air.local\u003e","repository":"https://github.com/trufflesecurity/test_keys","timestamp":"2022-06-16 10:17:40 -0700 PDT","line":4}}},"SourceID":0,"SourceType":16,"SourceName":"trufflehog - git","DetectorType":2,"DetectorName":"AWS","DecoderName":"PLAIN","Verified":true,"Raw":"AKIAYVP4CIPPERUVIFXG","Redacted":"AKIAYVP4CIPPERUVIFXG","ExtraData":{"account":"595918472158","arn":"arn:aws:iam::595918472158:user/canarytokens.com@@mirux23ppyky6hx3l6vclmhnj","user_id":"AIDAYVP4CIPPJ5M54LRCY"},"StructuredData":null}
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4: Scan a GitHub Repo + its Issues and Pull Requests&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog github --repo=https://github.com/trufflesecurity/test_keys --issue-comments --pr-comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;5: Scan an S3 bucket for verified keys&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog s3 --bucket=&amp;lt;bucket name&amp;gt; --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;6: Scan S3 buckets using IAM Roles&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog s3 --role-arn=&amp;lt;iam role arn&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;7: Scan a Github Repo using SSH authentication in Docker&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm -v "$HOME/.ssh:/root/.ssh:ro" trufflesecurity/trufflehog:latest git ssh://github.com/trufflesecurity/test_keys
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;8: Scan individual files or directories&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog filesystem path/to/file1.txt path/to/file2.txt path/to/dir
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;9: Scan a local git repo&lt;/h2&gt; 
&lt;p&gt;Clone the git repo. For example &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/git@github.com:trufflesecurity/test_keys.git"&gt;test keys&lt;/a&gt; repo.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ git clone git@github.com:trufflesecurity/test_keys.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run trufflehog from the parent directory (outside the git repo).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ trufflehog git file://test_keys --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;10: Scan GCS buckets for verified secrets&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog gcs --project-id=&amp;lt;project-ID&amp;gt; --cloud-environment --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;11: Scan a Docker image for verified secrets&lt;/h2&gt; 
&lt;p&gt;Use the &lt;code&gt;--image&lt;/code&gt; flag multiple times to scan multiple images.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# to scan from a remote registry
trufflehog docker --image trufflesecurity/secrets --results=verified,unknown

# to scan from the local docker daemon
trufflehog docker --image docker://new_image:tag --results=verified,unknown

# to scan from an image saved as a tarball
trufflehog docker --image file://path_to_image.tar --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;12: Scan in CI&lt;/h2&gt; 
&lt;p&gt;Set the &lt;code&gt;--since-commit&lt;/code&gt; flag to your default branch that people merge into (ex: "main"). Set the &lt;code&gt;--branch&lt;/code&gt; flag to your PR's branch name (ex: "feature-1"). Depending on the CI/CD platform you use, this value can be pulled in dynamically (ex: &lt;a href="https://circleci.com/docs/variables/"&gt;CIRCLE_BRANCH in Circle CI&lt;/a&gt; and &lt;a href="https://docs.travis-ci.com/user/environment-variables/"&gt;TRAVIS_PULL_REQUEST_BRANCH in Travis CI&lt;/a&gt;). If the repo is cloned and the target branch is already checked out during the CI/CD workflow, then &lt;code&gt;--branch HEAD&lt;/code&gt; should be sufficient. The &lt;code&gt;--fail&lt;/code&gt; flag will return an 183 error code if valid credentials are found.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog git file://. --since-commit main --branch feature-1 --results=verified,unknown --fail
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;13: Scan a Postman workspace&lt;/h2&gt; 
&lt;p&gt;Use the &lt;code&gt;--workspace-id&lt;/code&gt;, &lt;code&gt;--collection-id&lt;/code&gt;, &lt;code&gt;--environment&lt;/code&gt; flags multiple times to scan multiple targets.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog postman --token=&amp;lt;postman api token&amp;gt; --workspace-id=&amp;lt;workspace id&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;14: Scan a Jenkins server&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog jenkins --url https://jenkins.example.com --username admin --password admin
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;15: Scan an Elasticsearch server&lt;/h2&gt; 
&lt;h3&gt;Scan a Local Cluster&lt;/h3&gt; 
&lt;p&gt;There are two ways to authenticate to a local cluster with TruffleHog: (1) username and password, (2) service token.&lt;/p&gt; 
&lt;h4&gt;Connect to a local cluster with username and password&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog elasticsearch --nodes 192.168.14.3 192.168.14.4 --username truffle --password hog
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Connect to a local cluster with a service token&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog elasticsearch --nodes 192.168.14.3 192.168.14.4 --service-token ‘AAEWVaWM...Rva2VuaSDZ’
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scan an Elastic Cloud Cluster&lt;/h3&gt; 
&lt;p&gt;To scan a cluster on Elastic Cloud, you’ll need a Cloud ID and API key.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog elasticsearch \
  --cloud-id 'search-prod:dXMtY2Vx...YjM1ODNlOWFiZGRlNjI0NA==' \
  --api-key 'MlVtVjBZ...ZSYlduYnF1djh3NG5FQQ=='
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;16. Scan a GitHub Repository for Cross Fork Object References and Deleted Commits&lt;/h2&gt; 
&lt;p&gt;The following command will enumerate deleted and hidden commits on a GitHub repository and then scan them for secrets. This is an alpha release feature.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog github-experimental --repo https://github.com/&amp;lt;USER&amp;gt;/&amp;lt;REPO&amp;gt;.git --object-discovery
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In addition to the normal TruffleHog output, the &lt;code&gt;--object-discovery&lt;/code&gt; flag creates two files in a new &lt;code&gt;$HOME/.trufflehog&lt;/code&gt; directory: &lt;code&gt;valid_hidden.txt&lt;/code&gt; and &lt;code&gt;invalid.txt&lt;/code&gt;. These are used to track state during commit enumeration, as well as to provide users with a complete list of all hidden and deleted commits (&lt;code&gt;valid_hidden.txt&lt;/code&gt;). If you'd like to automatically remove these files after scanning, please add the flag &lt;code&gt;--delete-cached-data&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Enumerating all valid commits on a repository using this method takes between 20 minutes and a few hours, depending on the size of your repository. We added a progress bar to keep you updated on how long the enumeration will take. The actual secret scanning runs extremely fast.&lt;/p&gt; 
&lt;p&gt;For more information on Cross Fork Object References, please &lt;a href="https://trufflesecurity.com/blog/anyone-can-access-deleted-and-private-repo-data-github"&gt;read our blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;17. Scan Hugging Face&lt;/h2&gt; 
&lt;h3&gt;Scan a Hugging Face Model, Dataset or Space&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog huggingface --model &amp;lt;model_id&amp;gt; --space &amp;lt;space_id&amp;gt; --dataset &amp;lt;dataset_id&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scan all Models, Datasets and Spaces belonging to a Hugging Face Organization or User&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog huggingface --org &amp;lt;orgname&amp;gt; --user &amp;lt;username&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(Optionally) When scanning an organization or user, you can skip an entire class of resources with &lt;code&gt;--skip-models&lt;/code&gt;, &lt;code&gt;--skip-datasets&lt;/code&gt;, &lt;code&gt;--skip-spaces&lt;/code&gt; OR a particular resource with &lt;code&gt;--ignore-models &amp;lt;model_id&amp;gt;&lt;/code&gt;, &lt;code&gt;--ignore-datasets &amp;lt;dataset_id&amp;gt;&lt;/code&gt;, &lt;code&gt;--ignore-spaces &amp;lt;space_id&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Scan Discussion and PR Comments&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog huggingface --model &amp;lt;model_id&amp;gt; --include-discussions --include-prs
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;18. Scan stdin Input&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;aws s3 cp s3://example/gzipped/data.gz - | gunzip -c | trufflehog stdin
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;&lt;span&gt;❓&lt;/span&gt; FAQ&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;All I see is &lt;code&gt;🐷🔑🐷 TruffleHog. Unearth your secrets. 🐷🔑🐷&lt;/code&gt; and the program exits, what gives? 
  &lt;ul&gt; 
   &lt;li&gt;That means no secrets were detected&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Why is the scan taking a long time when I scan a GitHub org 
  &lt;ul&gt; 
   &lt;li&gt;Unauthenticated GitHub scans have rate limits. To improve your rate limits, include the &lt;code&gt;--token&lt;/code&gt; flag with a personal access token&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;It says a private key was verified, what does that mean? 
  &lt;ul&gt; 
   &lt;li&gt;Check out our Driftwood blog post to learn how to do this, in short we've confirmed the key can be used live for SSH or SSL &lt;a href="https://trufflesecurity.com/blog/driftwood-know-if-private-keys-are-sensitive/"&gt;Blog post&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Is there an easy way to ignore specific secrets? 
  &lt;ul&gt; 
   &lt;li&gt;If the scanned source &lt;a href="https://github.com/trufflesecurity/trufflehog/raw/d6375ba92172fd830abb4247cca15e3176448c5d/pkg/engine/engine.go#L358-L365"&gt;supports line numbers&lt;/a&gt;, then you can add a &lt;code&gt;trufflehog:ignore&lt;/code&gt; comment on the line containing the secret to ignore that secrets.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;&lt;span&gt;📰&lt;/span&gt; What's new in v3?&lt;/h1&gt; 
&lt;p&gt;TruffleHog v3 is a complete rewrite in Go with many new powerful features.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We've &lt;strong&gt;added over 700 credential detectors that support active verification against their respective APIs&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;We've also added native &lt;strong&gt;support for scanning GitHub, GitLab, Docker, filesystems, S3, GCS, Circle CI and Travis CI&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instantly verify private keys&lt;/strong&gt; against millions of github users and &lt;strong&gt;billions&lt;/strong&gt; of TLS certificates using our &lt;a href="https://trufflesecurity.com/blog/driftwood"&gt;Driftwood&lt;/a&gt; technology.&lt;/li&gt; 
 &lt;li&gt;Scan binaries, documents, and other file formats&lt;/li&gt; 
 &lt;li&gt;Available as a GitHub Action and a pre-commit hook&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is credential verification?&lt;/h2&gt; 
&lt;p&gt;For every potential credential that is detected, we've painstakingly implemented programmatic verification against the API that we think it belongs to. Verification eliminates false positives. For example, the &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/pkg/detectors/aws/aws.go"&gt;AWS credential detector&lt;/a&gt; performs a &lt;code&gt;GetCallerIdentity&lt;/code&gt; API call against the AWS API to verify if an AWS credential is active.&lt;/p&gt; 
&lt;h1&gt;&lt;span&gt;📝&lt;/span&gt; Usage&lt;/h1&gt; 
&lt;p&gt;TruffleHog has a sub-command for each source of data that you may want to scan:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;git&lt;/li&gt; 
 &lt;li&gt;github&lt;/li&gt; 
 &lt;li&gt;gitlab&lt;/li&gt; 
 &lt;li&gt;docker&lt;/li&gt; 
 &lt;li&gt;s3&lt;/li&gt; 
 &lt;li&gt;filesystem (files and directories)&lt;/li&gt; 
 &lt;li&gt;syslog&lt;/li&gt; 
 &lt;li&gt;circleci&lt;/li&gt; 
 &lt;li&gt;travisci&lt;/li&gt; 
 &lt;li&gt;gcs (Google Cloud Storage)&lt;/li&gt; 
 &lt;li&gt;postman&lt;/li&gt; 
 &lt;li&gt;jenkins&lt;/li&gt; 
 &lt;li&gt;elasticsearch&lt;/li&gt; 
 &lt;li&gt;stdin&lt;/li&gt; 
 &lt;li&gt;multi-scan&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each subcommand can have options that you can see with the &lt;code&gt;--help&lt;/code&gt; flag provided to the sub command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ trufflehog git --help
usage: TruffleHog git [&amp;lt;flags&amp;gt;] &amp;lt;uri&amp;gt;

Find credentials in git repositories.

Flags:
  -h, --help                Show context-sensitive help (also try --help-long and --help-man).
      --log-level=0         Logging verbosity on a scale of 0 (info) to 5 (trace). Can be disabled with "-1".
      --profile             Enables profiling and sets a pprof and fgprof server on :18066.
  -j, --json                Output in JSON format.
      --json-legacy         Use the pre-v3.0 JSON format. Only works with git, gitlab, and github sources.
      --github-actions      Output in GitHub Actions format.
      --concurrency=20           Number of concurrent workers.
      --no-verification     Don't verify the results.
      --results=RESULTS          Specifies which type(s) of results to output: verified, unknown, unverified, filtered_unverified. Defaults to all types.
      --allow-verification-overlap
                                 Allow verification of similar credentials across detectors
      --filter-unverified   Only output first unverified result per chunk per detector if there are more than one results.
      --filter-entropy=FILTER-ENTROPY
                                 Filter unverified results with Shannon entropy. Start with 3.0.
      --config=CONFIG            Path to configuration file.
      --print-avg-detector-time
                                 Print the average time spent on each detector.
      --no-update           Don't check for updates.
      --fail                Exit with code 183 if results are found.
      --verifier=VERIFIER ...    Set custom verification endpoints.
      --custom-verifiers-only   Only use custom verification endpoints.
      --archive-max-size=ARCHIVE-MAX-SIZE
                                 Maximum size of archive to scan. (Byte units eg. 512B, 2KB, 4MB)
      --archive-max-depth=ARCHIVE-MAX-DEPTH
                                 Maximum depth of archive to scan.
      --archive-timeout=ARCHIVE-TIMEOUT
                                 Maximum time to spend extracting an archive.
      --include-detectors="all"  Comma separated list of detector types to include. Protobuf name or IDs may be used, as well as ranges.
      --exclude-detectors=EXCLUDE-DETECTORS
                                 Comma separated list of detector types to exclude. Protobuf name or IDs may be used, as well as ranges. IDs defined here take precedence over the include list.
      --version             Show application version.
  -i, --include-paths=INCLUDE-PATHS
                                 Path to file with newline separated regexes for files to include in scan.
  -x, --exclude-paths=EXCLUDE-PATHS
                                 Path to file with newline separated regexes for files to exclude in scan.
      --exclude-globs=EXCLUDE-GLOBS
                                 Comma separated list of globs to exclude in scan. This option filters at the `git log` level, resulting in faster scans.
      --since-commit=SINCE-COMMIT
                                 Commit to start scan from.
      --branch=BRANCH            Branch to scan.
      --max-depth=MAX-DEPTH      Maximum depth of commits to scan.
      --bare                Scan bare repository (e.g. useful while using in pre-receive hooks)

Args:
  &amp;lt;uri&amp;gt;  Git repository URL. https://, file://, or ssh:// schema expected.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For example, to scan a &lt;code&gt;git&lt;/code&gt; repository, start with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;trufflehog git https://github.com/trufflesecurity/trufflehog.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;TruffleHog supports defining &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/#regex-detector-alpha"&gt;custom regex detectors&lt;/a&gt; and multiple sources in a configuration file provided via the &lt;code&gt;--config&lt;/code&gt; flag. The regex detectors can be used with any subcommand, while the sources defined in configuration are only for the &lt;code&gt;multi-scan&lt;/code&gt; subcommand.&lt;/p&gt; 
&lt;p&gt;The configuration format for sources can be found on Truffle Security's &lt;a href="https://docs.trufflesecurity.com/scan-data-for-secrets"&gt;source configuration documentation page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Example GitHub source configuration and &lt;a href="https://docs.trufflesecurity.com/github#Fvm1I"&gt;options reference&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;sources:
- connection:
    '@type': type.googleapis.com/sources.GitHub
    repositories:
    - https://github.com/trufflesecurity/test_keys.git
    unauthenticated: {}
  name: example config scan
  type: SOURCE_TYPE_GITHUB
  verify: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You may define multiple connections under the &lt;code&gt;sources&lt;/code&gt; key (see above), and TruffleHog will scan all of the sources concurrently.&lt;/p&gt; 
&lt;h2&gt;S3&lt;/h2&gt; 
&lt;p&gt;The S3 source supports assuming IAM roles for scanning in addition to IAM users. This makes it easier for users to scan multiple AWS accounts without needing to rely on hardcoded credentials for each account.&lt;/p&gt; 
&lt;p&gt;The IAM identity that TruffleHog uses initially will need to have &lt;code&gt;AssumeRole&lt;/code&gt; privileges as a principal in the &lt;a href="https://aws.amazon.com/blogs/security/how-to-use-trust-policies-with-iam-roles/"&gt;trust policy&lt;/a&gt; of each IAM role to assume.&lt;/p&gt; 
&lt;p&gt;To scan a specific bucket using locally set credentials or instance metadata if on an EC2 instance:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog s3 --bucket=&amp;lt;bucket-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To scan a specific bucket using an assumed role:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog s3 --bucket=&amp;lt;bucket-name&amp;gt; --role-arn=&amp;lt;iam-role-arn&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Multiple roles can be passed as separate arguments. The following command will attempt to scan every bucket each role has permissions to list in the S3 API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog s3 --role-arn=&amp;lt;iam-role-arn-1&amp;gt; --role-arn=&amp;lt;iam-role-arn-2&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Exit Codes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;0: No errors and no results were found.&lt;/li&gt; 
 &lt;li&gt;1: An error was encountered. Sources may not have completed scans.&lt;/li&gt; 
 &lt;li&gt;183: No errors were encountered, but results were found. Will only be returned if &lt;code&gt;--fail&lt;/code&gt; flag is used.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;img alt="octocat" src="https://github.githubassets.com/images/icons/emoji/octocat.png?v8" /&gt;) TruffleHog Github Action&lt;/h2&gt; 
&lt;h3&gt;General Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;on:
  push:
    branches:
      - main
  pull_request:

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    - name: Secret Scanning
      uses: trufflesecurity/trufflehog@main
      with:
        extra_args: --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In the example config above, we're scanning for live secrets in all PRs and Pushes to &lt;code&gt;main&lt;/code&gt;. Only code changes in the referenced commits are scanned. If you'd like to scan an entire branch, please see the "Advanced Usage" section below.&lt;/p&gt; 
&lt;h3&gt;Shallow Cloning&lt;/h3&gt; 
&lt;p&gt;If you're incorporating TruffleHog into a standalone workflow and aren't running any other CI/CD tooling alongside TruffleHog, then we recommend using &lt;a href="https://git-scm.com/docs/git-clone#Documentation/git-clone.txt---depthltdepthgt"&gt;Shallow Cloning&lt;/a&gt; to speed up your workflow. Here's an example of how to do it:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;...
      - shell: bash
        run: |
          if [ "${{ github.event_name }}" == "push" ]; then
            echo "depth=$(($(jq length &amp;lt;&amp;lt;&amp;lt; '${{ toJson(github.event.commits) }}') + 2))" &amp;gt;&amp;gt; $GITHUB_ENV
            echo "branch=${{ github.ref_name }}" &amp;gt;&amp;gt; $GITHUB_ENV
          fi
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            echo "depth=$((${{ github.event.pull_request.commits }}+2))" &amp;gt;&amp;gt; $GITHUB_ENV
            echo "branch=${{ github.event.pull_request.head.ref }}" &amp;gt;&amp;gt; $GITHUB_ENV
          fi
      - uses: actions/checkout@v3
        with:
          ref: ${{env.branch}}
          fetch-depth: ${{env.depth}}
      - uses: trufflesecurity/trufflehog@main
        with:
          extra_args: --results=verified,unknown
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Depending on the event type (push or PR), we calculate the number of commits present. Then we add 2, so that we can reference a base commit before our code changes. We pass that integer value to the &lt;code&gt;fetch-depth&lt;/code&gt; flag in the checkout action in addition to the relevant branch. Now our checkout process should be much shorter.&lt;/p&gt; 
&lt;h3&gt;Canary detection&lt;/h3&gt; 
&lt;p&gt;TruffleHog statically detects &lt;a href="https://canarytokens.org/"&gt;https://canarytokens.org/&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/trufflesecurity/trufflehog/assets/52866392/74ace530-08c5-4eaf-a169-84a73e328f6f" alt="image" /&gt;&lt;/p&gt; 
&lt;h3&gt;Advanced Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;- name: TruffleHog
  uses: trufflesecurity/trufflehog@main
  with:
    # Repository path
    path:
    # Start scanning from here (usually main branch).
    base:
    # Scan commits until here (usually dev branch).
    head: # optional
    # Extra args to be passed to the trufflehog cli.
    extra_args: --log-level=2 --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you'd like to specify specific &lt;code&gt;base&lt;/code&gt; and &lt;code&gt;head&lt;/code&gt; refs, you can use the &lt;code&gt;base&lt;/code&gt; argument (&lt;code&gt;--since-commit&lt;/code&gt; flag in TruffleHog CLI) and the &lt;code&gt;head&lt;/code&gt; argument (&lt;code&gt;--branch&lt;/code&gt; flag in the TruffleHog CLI). We only recommend using these arguments for very specific use cases, where the default behavior does not work.&lt;/p&gt; 
&lt;h4&gt;Advanced Usage: Scan entire branch&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;- name: scan-push
        uses: trufflesecurity/trufflehog@main
        with:
          base: ""
          head: ${{ github.ref_name }}
          extra_args: --results=verified,unknown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;TruffleHog GitLab CI&lt;/h2&gt; 
&lt;h3&gt;Example Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;stages:
  - security

security-secrets:
  stage: security
  allow_failure: false
  image: alpine:latest
  variables:
    SCAN_PATH: "." # Set the relative path in the repo to scan
  before_script:
    - apk add --no-cache git curl jq
    - curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin
  script:
    - trufflehog filesystem "$SCAN_PATH" --results=verified,unknown --fail --json | jq
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In the example pipeline above, we're scanning for live secrets in all repository directories and files. This job runs only when the pipeline source is a merge request event, meaning it's triggered when a new merge request is created.&lt;/p&gt; 
&lt;h2&gt;Pre-commit Hook&lt;/h2&gt; 
&lt;p&gt;TruffleHog can be used in a pre-commit hook to prevent credentials from leaking before they ever leave your computer.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/PreCommit.md"&gt;pre-commit hook documentation&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Regex Detector (alpha)&lt;/h2&gt; 
&lt;p&gt;TruffleHog supports detection and verification of custom regular expressions. For detection, at least one &lt;strong&gt;regular expression&lt;/strong&gt; and &lt;strong&gt;keyword&lt;/strong&gt; is required. A &lt;strong&gt;keyword&lt;/strong&gt; is a fixed literal string identifier that appears in or around the regex to be detected. To allow maximum flexibility for verification, a webhook is used containing the regular expression matches.&lt;/p&gt; 
&lt;p&gt;TruffleHog will send a JSON POST request containing the regex matches to a configured webhook endpoint. If the endpoint responds with a &lt;code&gt;200 OK&lt;/code&gt; response status code, the secret is considered verified.&lt;/p&gt; 
&lt;p&gt;Custom Detectors support a few different filtering mechanisms: entropy, regex targeting the entire match, regex targeting the captured secret, and excluded word lists checked against the secret (captured group if present, entire match if capture group is not present). Note that if your custom detector has multiple &lt;code&gt;regex&lt;/code&gt; set (in this example &lt;code&gt;hogID&lt;/code&gt;, and &lt;code&gt;hogToken&lt;/code&gt;), then the filters get applied to each regex. &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/examples/generic_with_filters.yml"&gt;Here&lt;/a&gt; is an example of a custom detector using these filters.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; This feature is alpha and subject to change.&lt;/p&gt; 
&lt;h3&gt;Regex Detector Example&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/pkg/custom_detectors/CUSTOM_DETECTORS.md"&gt;Here&lt;/a&gt; is how to setup a custom regex detector with verification server.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;🔍&lt;/span&gt; Analyze&lt;/h2&gt; 
&lt;p&gt;TruffleHog supports running a deeper analysis of a credential to view its permissions and the resources it has access to.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trufflehog analyze
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;&lt;span&gt;❤️&lt;/span&gt; Contributors&lt;/h1&gt; 
&lt;p&gt;This project exists thanks to all the people who contribute. [&lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/CONTRIBUTING.md"&gt;Contribute&lt;/a&gt;].&lt;/p&gt; 
&lt;a href="https://github.com/trufflesecurity/trufflehog/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=trufflesecurity/trufflehog" /&gt; &lt;/a&gt; 
&lt;h1&gt;&lt;span&gt;💻&lt;/span&gt; Contributing&lt;/h1&gt; 
&lt;p&gt;Contributions are very welcome! Please see our &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/CONTRIBUTING.md"&gt;contribution guidelines first&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We no longer accept contributions to TruffleHog v2, but that code is available in the &lt;code&gt;v2&lt;/code&gt; branch.&lt;/p&gt; 
&lt;h2&gt;Adding new secret detectors&lt;/h2&gt; 
&lt;p&gt;We have published some &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/hack/docs/Adding_Detectors_external.md"&gt;documentation and tooling to get started on adding new secret detectors&lt;/a&gt;. Let's improve detection together!&lt;/p&gt; 
&lt;h1&gt;Use as a library&lt;/h1&gt; 
&lt;p&gt;Currently, trufflehog is in heavy development and no guarantees can be made on the stability of the public APIs at this time.&lt;/p&gt; 
&lt;h1&gt;License Change&lt;/h1&gt; 
&lt;p&gt;Since v3.0, TruffleHog is released under a AGPL 3 license, included in &lt;a href="https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt;. TruffleHog v3.0 uses none of the previous codebase, but care was taken to preserve backwards compatibility on the command line interface. The work previous to this release is still available licensed under GPL 2.0 in the history of this repository and the previous package releases and tags. A completed CLA is required for us to accept contributions going forward.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>awslabs/agent-squad</title>
      <link>https://github.com/awslabs/agent-squad</link>
      <description>&lt;p&gt;Flexible and powerful framework for managing multiple AI agents and handling complex conversations&lt;/p&gt;&lt;hr&gt;&lt;h2 align="center"&gt;Agent Squad&lt;/h2&gt; 
&lt;p align="center"&gt;Flexible, lightweight open-source framework for orchestrating multiple AI agents to handle complex conversations.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;strong&gt;📢 New Name Alert:&lt;/strong&gt; Multi-Agent Orchestrator is now &lt;strong&gt;Agent Squad!&lt;/strong&gt; 🎉&lt;br /&gt; Same powerful functionalities, new catchy name. Embrace the squad! &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/awslabs/agent-squad"&gt;&lt;img alt="GitHub Repo" src="https://img.shields.io/badge/GitHub-Repo-green.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/agent-squad"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/agent-squad.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/agent-squad/"&gt;&lt;img alt="PyPI" src="https://img.shields.io/pypi/v/agent-squad.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- GitHub Stats --&gt; &lt;img src="https://img.shields.io/github/stars/awslabs/agent-squad?style=social" alt="GitHub stars" /&gt; &lt;img src="https://img.shields.io/github/forks/awslabs/agent-squad?style=social" alt="GitHub forks" /&gt; &lt;img src="https://img.shields.io/github/watchers/awslabs/agent-squad?style=social" alt="GitHub watchers" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- Repository Info --&gt; &lt;img src="https://img.shields.io/github/last-commit/awslabs/agent-squad" alt="Last Commit" /&gt; &lt;img src="https://img.shields.io/github/issues/awslabs/agent-squad" alt="Issues" /&gt; &lt;img src="https://img.shields.io/github/issues-pr/awslabs/agent-squad" alt="Pull Requests" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://awslabs.github.io/agent-squad/" style="display: inline-block; background-color: #0066cc; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; font-weight: bold; font-size: 15px; transition: background-color 0.3s;"&gt; 📚 Explore Full Documentation &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;🔖 Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🧠 &lt;strong&gt;Intelligent intent classification&lt;/strong&gt; — Dynamically route queries to the most suitable agent based on context and content.&lt;/li&gt; 
 &lt;li&gt;🔤 &lt;strong&gt;Dual language support&lt;/strong&gt; — Fully implemented in both &lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;TypeScript&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;🌊 &lt;strong&gt;Flexible agent responses&lt;/strong&gt; — Support for both streaming and non-streaming responses from different agents.&lt;/li&gt; 
 &lt;li&gt;📚 &lt;strong&gt;Context management&lt;/strong&gt; — Maintain and utilize conversation context across multiple agents for coherent interactions.&lt;/li&gt; 
 &lt;li&gt;🔧 &lt;strong&gt;Extensible architecture&lt;/strong&gt; — Easily integrate new agents or customize existing ones to fit your specific needs.&lt;/li&gt; 
 &lt;li&gt;🌐 &lt;strong&gt;Universal deployment&lt;/strong&gt; — Run anywhere - from AWS Lambda to your local environment or any cloud platform.&lt;/li&gt; 
 &lt;li&gt;📦 &lt;strong&gt;Pre-built agents and classifiers&lt;/strong&gt; — A variety of ready-to-use agents and multiple classifier implementations available.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What's the Agent Squad ❓&lt;/h2&gt; 
&lt;p&gt;The Agent Squad is a flexible framework for managing multiple AI agents and handling complex conversations. It intelligently routes queries and maintains context across interactions.&lt;/p&gt; 
&lt;p&gt;The system offers pre-built components for quick deployment, while also allowing easy integration of custom agents and conversation messages storage solutions.&lt;/p&gt; 
&lt;p&gt;This adaptability makes it suitable for a wide range of applications, from simple chatbots to sophisticated AI systems, accommodating diverse requirements and scaling efficiently.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🏗️ High-level architecture flow diagram&lt;/h2&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/awslabs/agent-squad/main/img/flow.jpg" alt="High-level architecture flow diagram" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The process begins with user input, which is analyzed by a Classifier.&lt;/li&gt; 
 &lt;li&gt;The Classifier leverages both Agents' Characteristics and Agents' Conversation history to select the most appropriate agent for the task.&lt;/li&gt; 
 &lt;li&gt;Once an agent is selected, it processes the user input.&lt;/li&gt; 
 &lt;li&gt;The orchestrator then saves the conversation, updating the Agents' Conversation history, before delivering the response back to the user.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;img src="https://raw.githubusercontent.com/awslabs/agent-squad/main/img/new.png" alt="" /&gt; Introducing SupervisorAgent: Agents Coordination&lt;/h2&gt; 
&lt;p&gt;The Agent Squad now includes a powerful new SupervisorAgent that enables sophisticated team coordination between multiple specialized agents. This new component implements a "agent-as-tools" architecture, allowing a lead agent to coordinate a team of specialized agents in parallel, maintaining context and delivering coherent responses.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/awslabs/agent-squad/main/img/flow-supervisor.jpg" alt="SupervisorAgent flow diagram" /&gt;&lt;/p&gt; 
&lt;p&gt;Key capabilities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🤝 &lt;strong&gt;Team Coordination&lt;/strong&gt; - Coordinate multiple specialized agents working together on complex tasks&lt;/li&gt; 
 &lt;li&gt;⚡ &lt;strong&gt;Parallel Processing&lt;/strong&gt; - Execute multiple agent queries simultaneously&lt;/li&gt; 
 &lt;li&gt;🧠 &lt;strong&gt;Smart Context Management&lt;/strong&gt; - Maintain conversation history across all team members&lt;/li&gt; 
 &lt;li&gt;🔄 &lt;strong&gt;Dynamic Delegation&lt;/strong&gt; - Intelligently distribute subtasks to appropriate team members&lt;/li&gt; 
 &lt;li&gt;🤖 &lt;strong&gt;Agent Compatibility&lt;/strong&gt; - Works with all agent types (Bedrock, Anthropic, Lex, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The SupervisorAgent can be used in two powerful ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Direct Usage&lt;/strong&gt; - Call it directly when you need dedicated team coordination for specific tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Classifier Integration&lt;/strong&gt; - Add it as an agent within the classifier to build complex hierarchical systems with multiple specialized teams&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Here are just a few examples where this agent can be used:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Customer Support Teams with specialized sub-teams&lt;/li&gt; 
 &lt;li&gt;AI Movie Production Studios&lt;/li&gt; 
 &lt;li&gt;Travel Planning Services&lt;/li&gt; 
 &lt;li&gt;Product Development Teams&lt;/li&gt; 
 &lt;li&gt;Healthcare Coordination Systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://awslabs.github.io/agent-squad/agents/built-in/supervisor-agent"&gt;Learn more about SupervisorAgent →&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;💬 Demo App&lt;/h2&gt; 
&lt;p&gt;In the screen recording below, we demonstrate an extended version of the demo app that uses 6 specialized agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Travel Agent&lt;/strong&gt;: Powered by an Amazon Lex Bot&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Weather Agent&lt;/strong&gt;: Utilizes a Bedrock LLM Agent with a tool to query the open-meteo API&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Restaurant Agent&lt;/strong&gt;: Implemented as an Amazon Bedrock Agent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Math Agent&lt;/strong&gt;: Utilizes a Bedrock LLM Agent with two tools for executing mathematical operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tech Agent&lt;/strong&gt;: A Bedrock LLM Agent designed to answer questions on technical topics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Health Agent&lt;/strong&gt;: A Bedrock LLM Agent focused on addressing health-related queries&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Watch as the system seamlessly switches context between diverse topics, from booking flights to checking weather, solving math problems, and providing health information. Notice how the appropriate agent is selected for each query, maintaining coherence even with brief follow-up inputs.&lt;/p&gt; 
&lt;p&gt;The demo highlights the system's ability to handle complex, multi-turn conversations while preserving context and leveraging specialized agents across various domains.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/awslabs/agent-squad/main/img/demo-app.gif?raw=true" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;🎯 Examples &amp;amp; Quick Start&lt;/h2&gt; 
&lt;p&gt;Get hands-on experience with the Agent Squad through our diverse set of examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Demo Applications&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/python"&gt;Streamlit Global Demo&lt;/a&gt;: A single Streamlit application showcasing multiple demos, including: 
    &lt;ul&gt; 
     &lt;li&gt;AI Movie Production Studio&lt;/li&gt; 
     &lt;li&gt;AI Travel Planner&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://awslabs.github.io/agent-squad/cookbook/examples/chat-demo-app/"&gt;Chat Demo App&lt;/a&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;Explore multiple specialized agents handling various domains like travel, weather, math, and health&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://awslabs.github.io/agent-squad/cookbook/examples/ecommerce-support-simulator/"&gt;E-commerce Support Simulator&lt;/a&gt;: Experience AI-powered customer support with: 
    &lt;ul&gt; 
     &lt;li&gt;Automated response generation for common queries&lt;/li&gt; 
     &lt;li&gt;Intelligent routing of complex issues to human support&lt;/li&gt; 
     &lt;li&gt;Real-time chat and email-style communication&lt;/li&gt; 
     &lt;li&gt;Human-in-the-loop interactions for complex cases&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sample Projects&lt;/strong&gt;: Explore our example implementations in the &lt;code&gt;examples&lt;/code&gt; folder: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/chat-demo-app"&gt;&lt;code&gt;chat-demo-app&lt;/code&gt;&lt;/a&gt;: Web-based chat interface with multiple specialized agents&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/ecommerce-support-simulator"&gt;&lt;code&gt;ecommerce-support-simulator&lt;/code&gt;&lt;/a&gt;: AI-powered customer support system&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/chat-chainlit-app"&gt;&lt;code&gt;chat-chainlit-app&lt;/code&gt;&lt;/a&gt;: Chat application built with Chainlit&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/fast-api-streaming"&gt;&lt;code&gt;fast-api-streaming&lt;/code&gt;&lt;/a&gt;: FastAPI implementation with streaming support&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/text-2-structured-output"&gt;&lt;code&gt;text-2-structured-output&lt;/code&gt;&lt;/a&gt;: Natural Language to Structured Data&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/bedrock-inline-agents"&gt;&lt;code&gt;bedrock-inline-agents&lt;/code&gt;&lt;/a&gt;: Bedrock Inline Agents sample&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/awslabs/agent-squad/tree/main/examples/bedrock-prompt-routing"&gt;&lt;code&gt;bedrock-prompt-routing&lt;/code&gt;&lt;/a&gt;: Bedrock Prompt Routing sample code&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Examples are available in both Python and TypeScript. Check out our &lt;a href="https://awslabs.github.io/agent-squad/"&gt;documentation&lt;/a&gt; for comprehensive guides on setting up and using the Agent Squad framework!&lt;/p&gt; 
&lt;h2&gt;📚 Deep Dives: Stories, Blogs &amp;amp; Podcasts&lt;/h2&gt; 
&lt;p&gt;Discover creative implementations and diverse applications of the Agent Squad:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://community.aws/content/2lCi8jEKydhDm8eE8QFIQ5K23pF/from-bonjour-to-boarding-pass-multilingual-ai-chatbot-for-flight-reservations"&gt;From 'Bonjour' to 'Boarding Pass': Multilingual AI Chatbot for Flight Reservations&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This article demonstrates how to build a multilingual chatbot using the Agent Squad framework. The article explains how to use an &lt;strong&gt;Amazon Lex&lt;/strong&gt; bot as an agent, along with 2 other new agents to make it work in many languages with just a few lines of code.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://community.aws/content/2lq6cYYwTYGc7S3Zmz28xZoQNQj/beyond-auto-replies-building-an-ai-powered-e-commerce-support-system"&gt;Beyond Auto-Replies: Building an AI-Powered E-commerce Support system&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This article demonstrates how to build an AI-driven multi-agent system for automated e-commerce customer email support. It covers the architecture and setup of specialized AI agents using the Agent Squad framework, integrating automated processing with human-in-the-loop oversight. The guide explores email ingestion, intelligent routing, automated response generation, and human verification, providing a comprehensive approach to balancing AI efficiency with human expertise in customer support.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://community.aws/content/2mt7CFG7xg4yw6GRHwH9akhg0oD/speak-up-ai-voicing-your-agents-with-amazon-connect-lex-and-bedrock"&gt;Speak Up, AI: Voicing Your Agents with Amazon Connect, Lex, and Bedrock&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This article demonstrates how to build an AI customer call center. It covers the architecture and setup of specialized AI agents using the Agent Squad framework interacting with voice via &lt;strong&gt;Amazon Connect&lt;/strong&gt; and &lt;strong&gt;Amazon Lex&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://community.aws/content/2pTsHrYPqvAbJBl9ht1XxPOSPjR/unlock-bedrock-invokeinlineagent-api-s-hidden-potential-with-agent-squad"&gt;Unlock Bedrock InvokeInlineAgent API's Hidden Potential&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Learn how to scale &lt;strong&gt;Amazon Bedrock Agents&lt;/strong&gt; beyond knowledge base limitations using the Agent Squad framework and &lt;strong&gt;InvokeInlineAgent API&lt;/strong&gt;. This article demonstrates dynamic agent creation and knowledge base selection for enterprise-scale AI applications.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://community.aws/content/2phMjQ0bqWMg4PBwejBs1uf4YQE/supercharging-amazon-bedrock-flows-with-aws-agent-squad"&gt;Supercharging Amazon Bedrock Flows&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Learn how to enhance &lt;strong&gt;Amazon Bedrock Flows&lt;/strong&gt; with conversation memory and multi-flow orchestration using the Agent Squad framework. This guide shows how to overcome Bedrock Flows' limitations to build more sophisticated AI workflows with persistent memory and intelligent routing between flows.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🎙️ Podcast Discussions&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🇫🇷 Podcast (French)&lt;/strong&gt;: L'orchestrateur multi-agents : Un orchestrateur open source pour vos agents IA&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Platforms&lt;/strong&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://podcasts.apple.com/be/podcast/lorchestrateur-multi-agents/id1452118442?i=1000684332612"&gt;Apple Podcasts&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://open.spotify.com/episode/4RdMazSRhZUyW2pniG91Vf"&gt;Spotify&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🇬🇧 Podcast (English)&lt;/strong&gt;: An Orchestrator for Your AI Agents&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Platforms&lt;/strong&gt;: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://podcasts.apple.com/us/podcast/an-orchestrator-for-your-ai-agents/id1574162669?i=1000677039579"&gt;Apple Podcasts&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://open.spotify.com/episode/2a9DBGZn2lVqVMBLWGipHU"&gt;Spotify&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;TypeScript Version&lt;/h3&gt; 
&lt;h4&gt;Installation&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🔄 &lt;code&gt;multi-agent-orchestrator&lt;/code&gt; becomes &lt;code&gt;agent-squad&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install agent-squad
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Usage&lt;/h4&gt; 
&lt;p&gt;The following example demonstrates how to use the Agent Squad with two different types of agents: a Bedrock LLM Agent with Converse API support and a Lex Bot Agent. This showcases the flexibility of the system in integrating various AI services.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { AgentSquad, BedrockLLMAgent, LexBotAgent } from "agent-squad";

const orchestrator = new AgentSquad();

// Add a Bedrock LLM Agent with Converse API support
orchestrator.addAgent(
  new BedrockLLMAgent({
      name: "Tech Agent",
      description:
        "Specializes in technology areas including software development, hardware, AI, cybersecurity, blockchain, cloud computing, emerging tech innovations, and pricing/costs related to technology products and services.",
      streaming: true
  })
);

// Add a Lex Bot Agent for handling travel-related queries
orchestrator.addAgent(
  new LexBotAgent({
    name: "Travel Agent",
    description: "Helps users book and manage their flight reservations",
    botId: process.env.LEX_BOT_ID,
    botAliasId: process.env.LEX_BOT_ALIAS_ID,
    localeId: "en_US",
  })
);

// Example usage
const response = await orchestrator.routeRequest(
  "I want to book a flight",
  'user123',
  'session456'
);

// Handle the response (streaming or non-streaming)
if (response.streaming == true) {
    console.log("\n** RESPONSE STREAMING ** \n");
    // Send metadata immediately
    console.log(`&amp;gt; Agent ID: ${response.metadata.agentId}`);
    console.log(`&amp;gt; Agent Name: ${response.metadata.agentName}`);
    console.log(`&amp;gt; User Input: ${response.metadata.userInput}`);
    console.log(`&amp;gt; User ID: ${response.metadata.userId}`);
    console.log(`&amp;gt; Session ID: ${response.metadata.sessionId}`);
    console.log(
      `&amp;gt; Additional Parameters:`,
      response.metadata.additionalParams
    );
    console.log(`\n&amp;gt; Response: `);

    // Stream the content
    for await (const chunk of response.output) {
      if (typeof chunk === "string") {
        process.stdout.write(chunk);
      } else {
        console.error("Received unexpected chunk type:", typeof chunk);
      }
    }

} else {
    // Handle non-streaming response (AgentProcessingResult)
    console.log("\n** RESPONSE ** \n");
    console.log(`&amp;gt; Agent ID: ${response.metadata.agentId}`);
    console.log(`&amp;gt; Agent Name: ${response.metadata.agentName}`);
    console.log(`&amp;gt; User Input: ${response.metadata.userInput}`);
    console.log(`&amp;gt; User ID: ${response.metadata.userId}`);
    console.log(`&amp;gt; Session ID: ${response.metadata.sessionId}`);
    console.log(
      `&amp;gt; Additional Parameters:`,
      response.metadata.additionalParams
    );
    console.log(`\n&amp;gt; Response: ${response.output}`);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Python Version&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🔄 &lt;code&gt;multi-agent-orchestrator&lt;/code&gt; becomes &lt;code&gt;agent-squad&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Optional: Set up a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`
pip install agent-squad[aws]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Default Usage&lt;/h4&gt; 
&lt;p&gt;Here's an equivalent Python example demonstrating the use of the Agent Squad with a Bedrock LLM Agent and a Lex Bot Agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import sys
import asyncio
from agent_squad.orchestrator import AgentSquad
from agent_squad.agents import BedrockLLMAgent, BedrockLLMAgentOptions, AgentStreamResponse

orchestrator = AgentSquad()

tech_agent = BedrockLLMAgent(BedrockLLMAgentOptions(
  name="Tech Agent",
  streaming=True,
  description="Specializes in technology areas including software development, hardware, AI, \
  cybersecurity, blockchain, cloud computing, emerging tech innovations, and pricing/costs \
  related to technology products and services.",
  model_id="anthropic.claude-3-sonnet-20240229-v1:0",
))
orchestrator.add_agent(tech_agent)


health_agent = BedrockLLMAgent(BedrockLLMAgentOptions(
  name="Health Agent",
  streaming=True,
  description="Specializes in health and well being",
))
orchestrator.add_agent(health_agent)

async def main():
    # Example usage
    response = await orchestrator.route_request(
        "What is AWS Lambda?",
        'user123',
        'session456',
        {},
        True
    )

    # Handle the response (streaming or non-streaming)
    if response.streaming:
        print("\n** RESPONSE STREAMING ** \n")
        # Send metadata immediately
        print(f"&amp;gt; Agent ID: {response.metadata.agent_id}")
        print(f"&amp;gt; Agent Name: {response.metadata.agent_name}")
        print(f"&amp;gt; User Input: {response.metadata.user_input}")
        print(f"&amp;gt; User ID: {response.metadata.user_id}")
        print(f"&amp;gt; Session ID: {response.metadata.session_id}")
        print(f"&amp;gt; Additional Parameters: {response.metadata.additional_params}")
        print("\n&amp;gt; Response: ")

        # Stream the content
        async for chunk in response.output:
            async for chunk in response.output:
              if isinstance(chunk, AgentStreamResponse):
                  print(chunk.text, end='', flush=True)
              else:
                  print(f"Received unexpected chunk type: {type(chunk)}", file=sys.stderr)

    else:
        # Handle non-streaming response (AgentProcessingResult)
        print("\n** RESPONSE ** \n")
        print(f"&amp;gt; Agent ID: {response.metadata.agent_id}")
        print(f"&amp;gt; Agent Name: {response.metadata.agent_name}")
        print(f"&amp;gt; User Input: {response.metadata.user_input}")
        print(f"&amp;gt; User ID: {response.metadata.user_id}")
        print(f"&amp;gt; Session ID: {response.metadata.session_id}")
        print(f"&amp;gt; Additional Parameters: {response.metadata.additional_params}")
        print(f"\n&amp;gt; Response: {response.output.content}")

if __name__ == "__main__":
  asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These examples showcase:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The use of a Bedrock LLM Agent with Converse API support, allowing for multi-turn conversations.&lt;/li&gt; 
 &lt;li&gt;Integration of a Lex Bot Agent for specialized tasks (in this case, travel-related queries).&lt;/li&gt; 
 &lt;li&gt;The orchestrator's ability to route requests to the most appropriate agent based on the input.&lt;/li&gt; 
 &lt;li&gt;Handling of both streaming and non-streaming responses from different types of agents.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Modular Installation Options&lt;/h3&gt; 
&lt;p&gt;The Agent Squad is designed with a modular architecture, allowing you to install only the components you need while ensuring you always get the core functionality.&lt;/p&gt; 
&lt;h4&gt;Installation Options&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;1. AWS Integration&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; pip install "agent-squad[aws]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Includes core orchestration functionality with comprehensive AWS service integrations (&lt;code&gt;BedrockLLMAgent&lt;/code&gt;, &lt;code&gt;AmazonBedrockAgent&lt;/code&gt;, &lt;code&gt;LambdaAgent&lt;/code&gt;, etc.)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Anthropic Integration&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "agent-squad[anthropic]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;3. OpenAI Integration&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "agent-squad[openai]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Adds OpenAI's GPT models for agents and classification, along with core packages.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4. Full Installation&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "agent-squad[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Includes all optional dependencies for maximum flexibility.&lt;/p&gt; 
&lt;h3&gt;🙌 &lt;strong&gt;We Want to Hear From You!&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Have something to share, discuss, or brainstorm? We’d love to connect with you and hear about your journey with the &lt;strong&gt;Agent Squad framework&lt;/strong&gt;. Here’s how you can get involved:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🙌 Show &amp;amp; Tell&lt;/strong&gt;: Got a success story, cool project, or creative implementation? Share it with us in the &lt;a href="https://github.com/awslabs/agent-squad/discussions/categories/show-and-tell"&gt;&lt;strong&gt;Show and Tell&lt;/strong&gt;&lt;/a&gt; section. Your work might inspire the entire community! 🎉&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;💬 General Discussion&lt;/strong&gt;: Have questions, feedback, or suggestions? Join the conversation in our &lt;a href="https://github.com/awslabs/agent-squad/discussions/categories/general"&gt;&lt;strong&gt;General Discussions&lt;/strong&gt;&lt;/a&gt; section. It’s the perfect place to connect with other users and contributors.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;💡 Ideas&lt;/strong&gt;: Thinking of a new feature or improvement? Share your thoughts in the &lt;a href="https://github.com/awslabs/agent-squad/discussions/categories/ideas"&gt;&lt;strong&gt;Ideas&lt;/strong&gt;&lt;/a&gt; section. We’re always open to exploring innovative ways to make the orchestrator even better!&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Let’s collaborate, learn from each other, and build something incredible together! 🚀&lt;/p&gt; 
&lt;h2&gt;📝 Pull Request Guidelines&lt;/h2&gt; 
&lt;h3&gt;Issue-First Policy&lt;/h3&gt; 
&lt;p&gt;This repository follows an &lt;strong&gt;Issue-First&lt;/strong&gt; policy:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Every pull request must be linked to an existing issue&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;If there isn't an issue for the changes you want to make, please create one first&lt;/li&gt; 
 &lt;li&gt;Use the issue to discuss proposed changes before investing time in implementation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How to Link Pull Requests to Issues&lt;/h3&gt; 
&lt;p&gt;When creating a pull request, you must link it to an issue using one of these methods:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Include a reference in the PR description using keywords:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;Fixes #123&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Resolves #123&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Closes #123&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Manually link the PR to an issue through GitHub's UI:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;On the right sidebar of your PR, click "Development" and then "Link an issue"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Automated Enforcement&lt;/h3&gt; 
&lt;p&gt;We use GitHub Actions to automatically verify that each PR is linked to an issue. PRs without linked issues will not pass required checks and cannot be merged.&lt;/p&gt; 
&lt;p&gt;This policy helps us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Maintain clear documentation of changes and their purposes&lt;/li&gt; 
 &lt;li&gt;Ensure community discussion before implementation&lt;/li&gt; 
 &lt;li&gt;Keep a structured development process&lt;/li&gt; 
 &lt;li&gt;Make project history more traceable and understandable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;⚠️ Note: Our project has been renamed from &lt;strong&gt;Multi-Agent Orchestrator&lt;/strong&gt; to &lt;strong&gt;Agent Squad&lt;/strong&gt;. Please use the new name in your contributions and discussions.&lt;/p&gt; 
&lt;p&gt;⚠️ We value your contributions! Before submitting changes, please start a discussion by opening an issue to share your proposal.&lt;/p&gt; 
&lt;p&gt;Once your proposal is approved, here are the next steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;📚 Review our &lt;a href="https://raw.githubusercontent.com/awslabs/agent-squad/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;💡 Create a &lt;a href="https://github.com/awslabs/agent-squad/issues"&gt;GitHub Issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🔨 Submit a pull request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;✅ Follow existing project structure and include documentation for new features.&lt;/p&gt; 
&lt;p&gt;🌟 &lt;strong&gt;Stay Updated&lt;/strong&gt;: Star the repository to be notified about new features, improvements, and exciting developments in the Agent Squad framework!&lt;/p&gt; 
&lt;h1&gt;Authors&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/corneliucroitoru/"&gt;Corneliu Croitoru&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/in/anthonybernabeu/"&gt;Anthony Bernabeu&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;👥 Contributors&lt;/h1&gt; 
&lt;p&gt;Big shout out to our awesome contributors! Thank you for making this project better! 🌟 ⭐ 🚀&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/awslabs/agent-squad/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=awslabs/agent-squad&amp;amp;max=2000" alt="contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Please see our &lt;a href="https://raw.githubusercontent.com/awslabs/agent-squad/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for guidelines on how to propose bugfixes and improvements.&lt;/p&gt; 
&lt;h2&gt;📄 LICENSE&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 licence - see the &lt;a href="https://raw.githubusercontent.com/awslabs/agent-squad/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;📄 Font License&lt;/h2&gt; 
&lt;p&gt;This project uses the JetBrainsMono NF font, licensed under the SIL Open Font License 1.1. For full license details, see &lt;a href="https://github.com/JetBrains/JetBrainsMono/raw/master/OFL.txt"&gt;FONT-LICENSE.md&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cinnamon/kotaemon</title>
      <link>https://github.com/Cinnamon/kotaemon</link>
      <description>&lt;p&gt;An open-source RAG-based tool for chatting with your documents.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;kotaemon&lt;/h1&gt; 
 &lt;p&gt;An open-source clean &amp;amp; customizable RAG UI for chatting with your documents. Built with both end users and developers in mind.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview-graph.png" alt="Preview" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11607" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11607" alt="Cinnamon%2Fkotaemon | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://huggingface.co/spaces/cin-model/kotaemon"&gt;Live Demo #1&lt;/a&gt; | &lt;a href="https://huggingface.co/spaces/cin-model/kotaemon-demo"&gt;Live Demo #2&lt;/a&gt; | &lt;a href="https://cinnamon.github.io/kotaemon/online_install/"&gt;Online Install&lt;/a&gt; | &lt;a href="https://colab.research.google.com/drive/1eTfieec_UOowNizTJA1NjawBJH9y_1nn"&gt;Colab Notebook (Local RAG)&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://cinnamon.github.io/kotaemon/"&gt;User Guide&lt;/a&gt; | &lt;a href="https://cinnamon.github.io/kotaemon/development/"&gt;Developer Guide&lt;/a&gt; | &lt;a href="https://github.com/Cinnamon/kotaemon/issues"&gt;Feedback&lt;/a&gt; | &lt;a href="mailto:kotaemon.support@cinnamon.is"&gt;Contact&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.python.org/downloads/release/python-31013/"&gt;&lt;img src="https://img.shields.io/badge/python-3.10+-blue.svg?sanitize=true" alt="Python 3.10+" /&gt;&lt;/a&gt; &lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" alt="Code style: black" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Cinnamon/kotaemon/pkgs/container/kotaemon" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/docker_pull-kotaemon:latest-brightgreen" alt="docker pull ghcr.io/cinnamon/kotaemon:latest" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/Cinnamon/kotaemon/total.svg?label=downloads&amp;amp;color=blue" alt="download" /&gt; &lt;a href="https://huggingface.co/spaces/cin-model/kotaemon-demo"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" /&gt;&lt;/a&gt; &lt;a href="https://hellogithub.com/en/repository/d3141471a0244d5798bc654982b263eb" target="_blank"&gt;&lt;img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=d3141471a0244d5798bc654982b263eb&amp;amp;claim_uid=RLiD9UZ1rEHNaMf&amp;amp;theme=small" alt="Featured｜HelloGitHub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- start-intro --&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;This project serves as a functional RAG UI for both end users who want to do QA on their documents and developers who want to build their own RAG pipeline. &lt;br /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;+----------------------------------------------------------------------------+
| End users: Those who use apps built with `kotaemon`.                       |
| (You use an app like the one in the demo above)                            |
|     +----------------------------------------------------------------+     |
|     | Developers: Those who built with `kotaemon`.                   |     |
|     | (You have `import kotaemon` somewhere in your project)         |     |
|     |     +----------------------------------------------------+     |     |
|     |     | Contributors: Those who make `kotaemon` better.    |     |     |
|     |     | (You make PR to this repo)                         |     |     |
|     |     +----------------------------------------------------+     |     |
|     +----------------------------------------------------------------+     |
+----------------------------------------------------------------------------+
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;For end users&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Clean &amp;amp; Minimalistic UI&lt;/strong&gt;: A user-friendly interface for RAG-based QA.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support for Various LLMs&lt;/strong&gt;: Compatible with LLM API providers (OpenAI, AzureOpenAI, Cohere, etc.) and local LLMs (via &lt;code&gt;ollama&lt;/code&gt; and &lt;code&gt;llama-cpp-python&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Installation&lt;/strong&gt;: Simple scripts to get you started quickly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;For developers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework for RAG Pipelines&lt;/strong&gt;: Tools to build your own RAG-based document QA pipeline.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable UI&lt;/strong&gt;: See your RAG pipeline in action with the provided UI, built with &lt;a href="https://github.com/gradio-app/gradio"&gt;Gradio &lt;img src="https://img.shields.io/github/stars/gradio-app/gradio" /&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gradio Theme&lt;/strong&gt;: If you use Gradio for development, check out our theme here: &lt;a href="https://github.com/lone17/kotaemon-gradio-theme"&gt;kotaemon-gradio-theme&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Host your own document QA (RAG) web-UI&lt;/strong&gt;: Support multi-user login, organize your files in private/public collections, collaborate and share your favorite chat with others.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Organize your LLM &amp;amp; Embedding models&lt;/strong&gt;: Support both local LLMs &amp;amp; popular API providers (OpenAI, Azure, Ollama, Groq).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hybrid RAG pipeline&lt;/strong&gt;: Sane default RAG pipeline with hybrid (full-text &amp;amp; vector) retriever and re-ranking to ensure best retrieval quality.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-modal QA support&lt;/strong&gt;: Perform Question Answering on multiple documents with figures and tables support. Support multi-modal document parsing (selectable options on UI).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced citations with document preview&lt;/strong&gt;: By default the system will provide detailed citations to ensure the correctness of LLM answers. View your citations (incl. relevant score) directly in the &lt;em&gt;in-browser PDF viewer&lt;/em&gt; with highlights. Warning when retrieval pipeline return low relevant articles.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Support complex reasoning methods&lt;/strong&gt;: Use question decomposition to answer your complex/multi-hop question. Support agent-based reasoning with &lt;code&gt;ReAct&lt;/code&gt;, &lt;code&gt;ReWOO&lt;/code&gt; and other agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configurable settings UI&lt;/strong&gt;: You can adjust most important aspects of retrieval &amp;amp; generation process on the UI (incl. prompts).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Extensible&lt;/strong&gt;: Being built on Gradio, you are free to customize or add any UI elements as you like. Also, we aim to support multiple strategies for document indexing &amp;amp; retrieval. &lt;code&gt;GraphRAG&lt;/code&gt; indexing pipeline is provided as an example.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/preview.png" alt="Preview" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;If you are not a developer and just want to use the app, please check out our easy-to-follow &lt;a href="https://cinnamon.github.io/kotaemon/"&gt;User Guide&lt;/a&gt;. Download the &lt;code&gt;.zip&lt;/code&gt; file from the &lt;a href="https://github.com/Cinnamon/kotaemon/releases/latest"&gt;latest release&lt;/a&gt; to get all the newest features and bug fixes.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;System requirements&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python&lt;/a&gt; &amp;gt;= 3.10&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;: optional, if you &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/#with-docker-recommended"&gt;install with Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.unstructured.io/open-source/installation/full-installation#full-installation"&gt;Unstructured&lt;/a&gt; if you want to process files other than &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.html&lt;/code&gt;, &lt;code&gt;.mhtml&lt;/code&gt;, and &lt;code&gt;.xlsx&lt;/code&gt; documents. Installation steps differ depending on your operating system. Please visit the link and follow the specific instructions provided there.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;With Docker (recommended)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;We support both &lt;code&gt;lite&lt;/code&gt; &amp;amp; &lt;code&gt;full&lt;/code&gt; version of Docker images. With &lt;code&gt;full&lt;/code&gt; version, the extra packages of &lt;code&gt;unstructured&lt;/code&gt; will be installed, which can support additional file types (&lt;code&gt;.doc&lt;/code&gt;, &lt;code&gt;.docx&lt;/code&gt;, ...) but the cost is larger docker image size. For most users, the &lt;code&gt;lite&lt;/code&gt; image should work well in most cases.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;To use the &lt;code&gt;full&lt;/code&gt; version.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker run \
-e GRADIO_SERVER_NAME=0.0.0.0 \
-e GRADIO_SERVER_PORT=7860 \
-v ./ktem_app_data:/app/ktem_app_data \
-p 7860:7860 -it --rm \
ghcr.io/cinnamon/kotaemon:main-full
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;To use the &lt;code&gt;full&lt;/code&gt; version with bundled &lt;strong&gt;Ollama&lt;/strong&gt; for &lt;em&gt;local / private RAG&lt;/em&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# change image name to
docker run &amp;lt;...&amp;gt; ghcr.io/cinnamon/kotaemon:main-ollama
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;To use the &lt;code&gt;lite&lt;/code&gt; version.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;pre&gt;&lt;code class="language-bash"&gt; # change image name to
 docker run &amp;lt;...&amp;gt; ghcr.io/cinnamon/kotaemon:main-lite
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;We currently support and test two platforms: &lt;code&gt;linux/amd64&lt;/code&gt; and &lt;code&gt;linux/arm64&lt;/code&gt; (for newer Mac). You can specify the platform by passing &lt;code&gt;--platform&lt;/code&gt; in the &lt;code&gt;docker run&lt;/code&gt; command. For example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# To run docker with platform linux/arm64
docker run \
-e GRADIO_SERVER_NAME=0.0.0.0 \
-e GRADIO_SERVER_PORT=7860 \
-v ./ktem_app_data:/app/ktem_app_data \
-p 7860:7860 -it --rm \
--platform linux/arm64 \
ghcr.io/cinnamon/kotaemon:main-lite
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Once everything is set up correctly, you can go to &lt;code&gt;http://localhost:7860/&lt;/code&gt; to access the WebUI.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;We use &lt;a href="https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry"&gt;GHCR&lt;/a&gt; to store docker images, all images can be found &lt;a href="https://github.com/Cinnamon/kotaemon/pkgs/container/kotaemon"&gt;here.&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Without Docker&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone and install required packages on a fresh python environment.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;# optional (setup env)
conda create -n kotaemon python=3.10
conda activate kotaemon

# clone this repo
git clone https://github.com/Cinnamon/kotaemon
cd kotaemon

pip install -e "libs/kotaemon[all]"
pip install -e "libs/ktem"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file in the root of this project. Use &lt;code&gt;.env.example&lt;/code&gt; as a template&lt;/p&gt; &lt;p&gt;The &lt;code&gt;.env&lt;/code&gt; file is there to serve use cases where users want to pre-config the models before starting up the app (e.g. deploy the app on HF hub). The file will only be used to populate the db once upon the first run, it will no longer be used in consequent runs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optional) To enable in-browser &lt;code&gt;PDF_JS&lt;/code&gt; viewer, download &lt;a href="https://github.com/mozilla/pdf.js/releases/download/v4.0.379/pdfjs-4.0.379-dist.zip"&gt;PDF_JS_DIST&lt;/a&gt; then extract it to &lt;code&gt;libs/ktem/ktem/assets/prebuilt&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/pdf-viewer-setup.png" alt="pdf-setup" width="300" /&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt; &lt;p&gt;Start the web server:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;python app.py
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The app will be automatically launched in your browser.&lt;/li&gt; 
   &lt;li&gt;Default username and password are both &lt;code&gt;admin&lt;/code&gt;. You can set up additional users directly through the UI.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/chat-tab.png" alt="Chat tab" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Check the &lt;code&gt;Resources&lt;/code&gt; tab and &lt;code&gt;LLMs and Embeddings&lt;/code&gt; and ensure that your &lt;code&gt;api_key&lt;/code&gt; value is set correctly from your &lt;code&gt;.env&lt;/code&gt; file. If it is not set, you can set it there.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Setup GraphRAG&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Official MS GraphRAG indexing only works with OpenAI or Ollama API. We recommend most users to use NanoGraphRAG implementation for straightforward integration with Kotaemon.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;Setup Nano GRAPHRAG&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Install nano-GraphRAG: &lt;code&gt;pip install nano-graphrag&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;nano-graphrag&lt;/code&gt; install might introduce version conflicts, see &lt;a href="https://github.com/Cinnamon/kotaemon/issues/440"&gt;this issue&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;To quickly fix: &lt;code&gt;pip uninstall hnswlib chroma-hnswlib &amp;amp;&amp;amp; pip install chroma-hnswlib&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Launch Kotaemon with &lt;code&gt;USE_NANO_GRAPHRAG=true&lt;/code&gt; environment variable.&lt;/li&gt; 
  &lt;li&gt;Set your default LLM &amp;amp; Embedding models in Resources setting and it will be recognized automatically from NanoGraphRAG.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Setup LIGHTRAG&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Install LightRAG: &lt;code&gt;pip install git+https://github.com/HKUDS/LightRAG.git&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;LightRAG&lt;/code&gt; install might introduce version conflicts, see &lt;a href="https://github.com/Cinnamon/kotaemon/issues/440"&gt;this issue&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;To quickly fix: &lt;code&gt;pip uninstall hnswlib chroma-hnswlib &amp;amp;&amp;amp; pip install chroma-hnswlib&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Launch Kotaemon with &lt;code&gt;USE_LIGHTRAG=true&lt;/code&gt; environment variable.&lt;/li&gt; 
  &lt;li&gt;Set your default LLM &amp;amp; Embedding models in Resources setting and it will be recognized automatically from LightRAG.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Setup MS GRAPHRAG&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Non-Docker Installation&lt;/strong&gt;: If you are not using Docker, install GraphRAG with the following command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;pip install "graphrag&amp;lt;=0.3.6" future
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Setting Up API KEY&lt;/strong&gt;: To use the GraphRAG retriever feature, ensure you set the &lt;code&gt;GRAPHRAG_API_KEY&lt;/code&gt; environment variable. You can do this directly in your environment or by adding it to a &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Using Local Models and Custom Settings&lt;/strong&gt;: If you want to use GraphRAG with local models (like &lt;code&gt;Ollama&lt;/code&gt;) or customize the default LLM and other configurations, set the &lt;code&gt;USE_CUSTOMIZED_GRAPHRAG_SETTING&lt;/code&gt; environment variable to true. Then, adjust your settings in the &lt;code&gt;settings.yaml.example&lt;/code&gt; file.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Setup Local Models (for local/private RAG)&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/local_model.md"&gt;Local model setup&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Setup multimodal document parsing (OCR, table parsing, figure extraction)&lt;/h3&gt; 
&lt;p&gt;These options are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://azure.microsoft.com/en-us/products/ai-services/ai-document-intelligence"&gt;Azure Document Intelligence (API)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.adobe.com/document-services/docs/overview/pdf-extract-api/"&gt;Adobe PDF Extract (API)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DS4SD/docling"&gt;Docling (local, open-source)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;To use Docling, first install required dependencies: &lt;code&gt;pip install docling&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Select corresponding loaders in &lt;code&gt;Settings -&amp;gt; Retrieval Settings -&amp;gt; File loader&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Customize your application&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;By default, all application data is stored in the &lt;code&gt;./ktem_app_data&lt;/code&gt; folder. You can back up or copy this folder to transfer your installation to a new machine.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For advanced users or specific use cases, you can customize these files:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;flowsettings.py&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;.env&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;code&gt;flowsettings.py&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;This file contains the configuration of your application. You can use the example &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/flowsettings.py"&gt;here&lt;/a&gt; as the starting point.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Notable settings&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# setup your preferred document store (with full-text search capabilities)
KH_DOCSTORE=(Elasticsearch | LanceDB | SimpleFileDocumentStore)

# setup your preferred vectorstore (for vector-based search)
KH_VECTORSTORE=(ChromaDB | LanceDB | InMemory | Milvus | Qdrant)

# Enable / disable multimodal QA
KH_REASONINGS_USE_MULTIMODAL=True

# Setup your new reasoning pipeline or modify existing one.
KH_REASONINGS = [
    "ktem.reasoning.simple.FullQAPipeline",
    "ktem.reasoning.simple.FullDecomposeQAPipeline",
    "ktem.reasoning.react.ReactAgentPipeline",
    "ktem.reasoning.rewoo.RewooAgentPipeline",
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;&lt;code&gt;.env&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;This file provides another way to configure your models and credentials.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Configure model via the .env file&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;Alternatively, you can configure the models via the &lt;code&gt;.env&lt;/code&gt; file with the information needed to connect to the LLMs. This file is located in the folder of the application. If you don't see it, you can create one.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Currently, the following providers are supported:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;In the &lt;code&gt;.env&lt;/code&gt; file, set the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; variable with your OpenAI API key in order to enable access to OpenAI's models. There are other variables that can be modified, please feel free to edit them to fit your case. Otherwise, the default parameter should work for most people.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_API_KEY=&amp;lt;your OpenAI API key here&amp;gt;
OPENAI_CHAT_MODEL=gpt-3.5-turbo
OPENAI_EMBEDDINGS_MODEL=text-embedding-ada-002
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Azure OpenAI&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;For OpenAI models via Azure platform, you need to provide your Azure endpoint and API key. Your might also need to provide your developments' name for the chat model and the embedding model depending on how you set up Azure development.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-35-turbo
AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=text-embedding-ada-002
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;strong&gt;Local Models&lt;/strong&gt;&lt;/p&gt; 
     &lt;ul&gt; 
      &lt;li&gt; &lt;p&gt;Using &lt;code&gt;ollama&lt;/code&gt; OpenAI compatible server:&lt;/p&gt; 
       &lt;ul&gt; 
        &lt;li&gt; &lt;p&gt;Install &lt;a href="https://github.com/ollama/ollama"&gt;ollama&lt;/a&gt; and start the application.&lt;/p&gt; &lt;/li&gt; 
        &lt;li&gt; &lt;p&gt;Pull your model, for example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;ollama pull llama3.1:8b
ollama pull nomic-embed-text
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
        &lt;li&gt; &lt;p&gt;Set the model names on web UI and make it as default:&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/docs/images/models.png" alt="Models" /&gt;&lt;/p&gt; &lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
      &lt;li&gt; &lt;p&gt;Using &lt;code&gt;GGUF&lt;/code&gt; with &lt;code&gt;llama-cpp-python&lt;/code&gt;&lt;/p&gt; &lt;p&gt;You can search and download a LLM to be ran locally from the &lt;a href="https://huggingface.co/models"&gt;Hugging Face Hub&lt;/a&gt;. Currently, these model formats are supported:&lt;/p&gt; 
       &lt;ul&gt; 
        &lt;li&gt; &lt;p&gt;GGUF&lt;/p&gt; &lt;p&gt;You should choose a model whose size is less than your device's memory and should leave about 2 GB. For example, if you have 16 GB of RAM in total, of which 12 GB is available, then you should choose a model that takes up at most 10 GB of RAM. Bigger models tend to give better generation but also take more processing time.&lt;/p&gt; &lt;p&gt;Here are some recommendations and their size in memory:&lt;/p&gt; &lt;/li&gt; 
        &lt;li&gt; &lt;p&gt;&lt;a href="https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat-GGUF/resolve/main/qwen1_5-1_8b-chat-q8_0.gguf?download=true"&gt;Qwen1.5-1.8B-Chat-GGUF&lt;/a&gt;: around 2 GB&lt;/p&gt; &lt;p&gt;Add a new LlamaCpp model with the provided model name on the web UI.&lt;/p&gt; &lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt;
 &lt;/ul&gt;
&lt;/details&gt;   
&lt;h3&gt;Adding your own RAG pipeline&lt;/h3&gt; 
&lt;h4&gt;Custom Reasoning Pipeline&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check the default pipeline implementation in &lt;a href="https://raw.githubusercontent.com/Cinnamon/kotaemon/main/libs/ktem/ktem/reasoning/simple.py"&gt;here&lt;/a&gt;. You can make quick adjustment to how the default QA pipeline work.&lt;/li&gt; 
 &lt;li&gt;Add new &lt;code&gt;.py&lt;/code&gt; implementation in &lt;code&gt;libs/ktem/ktem/reasoning/&lt;/code&gt; and later include it in &lt;code&gt;flowssettings&lt;/code&gt; to enable it on the UI.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Custom Indexing Pipeline&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check sample implementation in &lt;code&gt;libs/ktem/ktem/index/file/graph&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;(more instruction WIP).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- end-intro --&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;Please cite this project as&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-BibTeX"&gt;@misc{kotaemon2024,
    title = {Kotaemon - An open-source RAG-based tool for chatting with any content.},
    author = {The Kotaemon Team},
    year = {2024},
    howpublished = {\url{https://github.com/Cinnamon/kotaemon}},
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#Cinnamon/kotaemon&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Cinnamon/kotaemon&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Since our project is actively being developed, we greatly value your feedback and contributions. Please see our &lt;a href="https://github.com/Cinnamon/kotaemon/raw/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; to get started. Thank you to all our contributors!&lt;/p&gt; 
&lt;a href="https://github.com/Cinnamon/kotaemon/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=Cinnamon/kotaemon" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;OpenAI Codex CLI&lt;/h1&gt; 
&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install codex&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer. &lt;br /&gt; &lt;br /&gt;If you want Codex in your code editor (VS Code, Cursor, Windsurf), &lt;a href="https://developers.openai.com/codex/ide"&gt;install in your IDE&lt;/a&gt; &lt;br /&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, go to &lt;a href="https://chatgpt.com/codex"&gt;chatgpt.com/codex&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-splash.png" alt="Codex CLI splash" width="80%" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installing and running Codex CLI&lt;/h3&gt; 
&lt;p&gt;Install globally with your preferred package manager. If you use npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @openai/codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, if you use Homebrew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run &lt;code&gt;codex&lt;/code&gt; to get started:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can also go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt; 
 &lt;p&gt;Each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Using Codex with your ChatGPT plan&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-login.png" alt="Codex CLI login" width="80%" /&gt; &lt;/p&gt; 
&lt;p&gt;Run &lt;code&gt;codex&lt;/code&gt; and select &lt;strong&gt;Sign in with ChatGPT&lt;/strong&gt;. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. &lt;a href="https://help.openai.com/en/articles/11369540-codex-in-chatgpt"&gt;Learn more about what's included in your ChatGPT plan&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also use Codex with an API key, but this requires &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key"&gt;additional setup&lt;/a&gt;. If you previously used an API key for usage-based billing, see the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#migrating-from-usage-based-billing-api-key"&gt;migration steps&lt;/a&gt;. If you're having trouble with login, please comment on &lt;a href="https://github.com/openai/codex/issues/1243"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Model Context Protocol (MCP)&lt;/h3&gt; 
&lt;p&gt;Codex CLI supports &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#model-context-protocol-mcp"&gt;MCP servers&lt;/a&gt;. Enable by adding an &lt;code&gt;mcp_servers&lt;/code&gt; section to your &lt;code&gt;~/.codex/config.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Codex CLI supports a rich set of configuration options, with preferences stored in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. For full configuration options, see &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Docs &amp;amp; FAQ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md"&gt;&lt;strong&gt;Getting started&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#cli-usage"&gt;CLI usage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#running-with-a-prompt-as-input"&gt;Running with a prompt as input&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#example-prompts"&gt;Example prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#memory-with-agentsmd"&gt;Memory with AGENTS.md&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/sandbox.md"&gt;&lt;strong&gt;Sandbox &amp;amp; approvals&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md"&gt;&lt;strong&gt;Authentication&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#forcing-a-specific-auth-method-advanced"&gt;Auth methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#connecting-on-a-headless-machine"&gt;Login on a "Headless" machine&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md"&gt;&lt;strong&gt;Advanced&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#non-interactive--ci-mode"&gt;Non-interactive / CI mode&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#tracing--verbose-logging"&gt;Tracing / verbose logging&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#model-context-protocol-mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/zdr.md"&gt;&lt;strong&gt;Zero data retention (ZDR)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/contributing.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md"&gt;&lt;strong&gt;Install &amp;amp; build&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#system-requirements"&gt;System Requirements&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#dotslash"&gt;DotSlash&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#build-from-source"&gt;Build from source&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/faq.md"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/open-source-fund.md"&gt;&lt;strong&gt;Open source fund&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ast-grep/ast-grep</title>
      <link>https://github.com/ast-grep/ast-grep</link>
      <description>&lt;p&gt;⚡A CLI tool for code structural search, lint and rewriting. Written in Rust&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://ast-grep.github.io/logo.svg?sanitize=true" alt="ast-grep" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/ast-grep/ast-grep/actions/workflows/coverage.yaml/badge.svg?sanitize=true" alt="coverage badge" /&gt; &lt;a href="https://app.codecov.io/gh/ast-grep/ast-grep"&gt;&lt;img src="https://codecov.io/gh/ast-grep/ast-grep/branch/main/graph/badge.svg?token=37VX8H2EWV" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/4YZjf6htSQ" target="_blank"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1107749847722889217?label=Discord" /&gt;&lt;/a&gt; &lt;a href="https://repology.org/project/ast-grep/versions" target="_blank"&gt;&lt;img alt="Repology" src="https://repology.org/badge/tiny-repos/ast-grep.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/ast-grep/ast-grep?style=social" alt="Badge" /&gt; &lt;img src="https://img.shields.io/github/forks/ast-grep/ast-grep?style=social" alt="Badge" /&gt; &lt;img alt="GitHub Sponsors" src="https://img.shields.io/github/sponsors/HerringtonDarkholme?style=social" /&gt; &lt;a href="https://gurubase.io/g/ast-grep"&gt;&lt;img alt="Gurubase" src="https://img.shields.io/badge/Gurubase-Ask%20ast--grep%20Guru-006BFF" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;ast-grep(sg)&lt;/h2&gt; 
&lt;p&gt;ast-grep(sg) is a CLI tool for code structural search, lint, and rewriting.&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;ast-grep is an &lt;a href="https://dev.to/balapriya/abstract-syntax-tree-ast-explained-in-plain-english-1h38"&gt;abstract syntax tree&lt;/a&gt; based tool to search code by pattern code. Think of it as your old-friend &lt;a href="https://en.wikipedia.org/wiki/Grep#:~:text=grep%20is%20a%20command%2Dline,which%20has%20the%20same%20effect."&gt;&lt;code&gt;grep&lt;/code&gt;&lt;/a&gt;, but matching AST nodes instead of text. You can write patterns as if you are writing ordinary code. It will match all code that has the same syntactical structure. You can use &lt;code&gt;$&lt;/code&gt; sign + upper case letters as a &lt;a href="https://en.wikipedia.org/wiki/Wildcard_character"&gt;wildcard&lt;/a&gt;, e.g. &lt;code&gt;$MATCH&lt;/code&gt;, to match any single AST node. Think of it as &lt;a href="https://regexone.com/lesson/wildcards_dot"&gt;regular expression dot&lt;/a&gt; &lt;code&gt;.&lt;/code&gt;, except it is not textual.&lt;/p&gt; 
&lt;p&gt;Try the &lt;a href="https://ast-grep.github.io/playground.html"&gt;online playground&lt;/a&gt; for a taste!&lt;/p&gt; 
&lt;h2&gt;Screenshot&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://ast-grep.github.io/image/search-replace.png" alt="demo" /&gt;&lt;/p&gt; 
&lt;p&gt;See more screenshots on the &lt;a href="https://ast-grep.github.io/"&gt;website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;You can install it from &lt;a href="https://docs.npmjs.com/downloading-and-installing-node-js-and-npm"&gt;npm&lt;/a&gt;, &lt;a href="https://pypi.org/"&gt;pip&lt;/a&gt;, &lt;a href="https://doc.rust-lang.org/cargo/getting-started/installation.html"&gt;cargo&lt;/a&gt;, &lt;a href="https://github.com/cargo-bins/cargo-binstall"&gt;cargo-binstall&lt;/a&gt;, &lt;a href="https://brew.sh/"&gt;homebrew&lt;/a&gt;, &lt;a href="https://scoop.sh/"&gt;scoop&lt;/a&gt; or &lt;a href="https://www.macports.org"&gt;MacPorts&lt;/a&gt;!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install --global @ast-grep/cli
pip install ast-grep-cli
brew install ast-grep
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click for more installation methods&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cargo install ast-grep --locked
cargo binstall ast-grep

# install via scoop, thank @brian6932
scoop install main/ast-grep

# install via MacPorts
sudo port install ast-grep

# try ast-grep in nix-shell
nix-shell -p ast-grep
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;Or you can build ast-grep from source. You need to install rustup, clone the repository and then&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install --path ./crates/cli --locked
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/ast-grep/versions"&gt;Packages&lt;/a&gt; are available on other platforms too.&lt;/p&gt; 
&lt;h2&gt;Command line usage example&lt;/h2&gt; 
&lt;p&gt;ast-grep has following form.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ast-grep --pattern 'var code = $PATTERN' --rewrite 'let code = new $PATTERN' --lang ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/Hchan_mgn/status/1547061516993699841?s=20&amp;amp;t=ldDoj4U2nq-FRKQkU5GWXA"&gt;Rewrite code in null coalescing operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ast-grep -p '$A &amp;amp;&amp;amp; $A()' -l ts -r '$A?.()'
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/Hchan_mgn/status/1561802312846278657"&gt;Rewrite&lt;/a&gt; &lt;a href="https://github.com/ecyrbe/zodios#migrate-to-v8"&gt;Zodios&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ast-grep -p 'new Zodios($URL,  $CONF as const,)' -l ts -r 'new Zodios($URL, $CONF)' -i
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/Hchan_mgn/status/1560108625460355073"&gt;Implement eslint rule using YAML.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsor&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HerringtonDarkholme/sponsors/main/sponsorkit/sponsors.svg?sanitize=true" alt="Sponsors" /&gt;&lt;/p&gt; 
&lt;p&gt;If you find ast-grep interesting and useful for your work, please &lt;a href="https://github.com/sponsors/HerringtonDarkholme"&gt;buy me a coffee&lt;/a&gt; so I can spend more time on the project!&lt;/p&gt; 
&lt;h2&gt;Feature Highlight&lt;/h2&gt; 
&lt;p&gt;ast-grep's core is an algorithm to search and replace code based on abstract syntax tree produced by tree-sitter. It can help you to do lightweight static analysis and massive scale code manipulation in an intuitive way.&lt;/p&gt; 
&lt;p&gt;Key highlights:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;An intuitive pattern to find and replace AST. ast-grep's pattern looks like ordinary code you would write every day (you could say the pattern is isomorphic to code).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;jQuery like API for AST traversal and manipulation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;YAML configuration to write new linting rules or code modification.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Written in compiled language, with tree-sitter based parsing and utilizing multiple cores.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Beautiful command line interface :)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ast-grep's vision is to democratize abstract syntax tree magic and to liberate one from cumbersome AST programming!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you are an open-source library author, ast-grep can help your library users adopt breaking changes more easily.&lt;/li&gt; 
 &lt;li&gt;if you are a tech lead in your team, ast-grep can help you enforce code best practice tailored to your business need.&lt;/li&gt; 
 &lt;li&gt;If you are a security researcher, ast-grep can help you write rules much faster.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>