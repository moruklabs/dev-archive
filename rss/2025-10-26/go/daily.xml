<rss version="2.0">
  <channel>
    <title>GitHub Go Daily Trending</title>
    <description>Daily Trending of Go in GitHub</description>
    <pubDate>Sat, 25 Oct 2025 01:34:14 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>dstotijn/hetty</title>
      <link>https://github.com/dstotijn/hetty</link>
      <description>&lt;p&gt;An HTTP toolkit for security research.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://user-images.githubusercontent.com/983924/156430531-6193e187-7400-436b-81c6-f86862783ea5.svg#gh-light-mode-only" width="240" /&gt; 
&lt;img src="https://user-images.githubusercontent.com/983924/156430660-9d5bd555-dcfd-47e2-ba70-54294c20c1b4.svg#gh-dark-mode-only" width="240" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/dstotijn/hetty/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dstotijn/hetty?color=25ae8f" alt="Latest GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dstotijn/hetty/actions/workflows/build-test.yml"&gt;&lt;img src="https://img.shields.io/endpoint.svg?url=https%3A%2F%2Factions-badge.atrox.dev%2Fdstotijn%2Fhetty%2Fbadge%3Fref%3Dmain&amp;amp;label=build&amp;amp;color=24ae8f" alt="Build Status" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/dstotijn/hetty/total?color=25ae8f" alt="GitHub download count" /&gt; &lt;a href="https://github.com/dstotijn/hetty/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/dstotijn/hetty?color=25ae8f" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://hetty.xyz/"&gt;&lt;img src="https://img.shields.io/badge/hetty-docs-25ae8f" alt="Documentation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Hetty&lt;/strong&gt; is an HTTP toolkit for security research. It aims to become an open source alternative to commercial software like Burp Suite Pro, with powerful features tailored to the needs of the infosec and bug bounty community.&lt;/p&gt; 
&lt;img src="https://hetty.xyz/img/hero.png" width="907" alt="Hetty proxy logs (screenshot)" /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Machine-in-the-middle (MITM) HTTP proxy, with logs and advanced search&lt;/li&gt; 
 &lt;li&gt;HTTP client for manually creating/editing requests, and replay proxied requests&lt;/li&gt; 
 &lt;li&gt;Intercept requests and responses for manual review (edit, send/receive, cancel)&lt;/li&gt; 
 &lt;li&gt;Scope support, to help keep work organized&lt;/li&gt; 
 &lt;li&gt;Easy-to-use web based admin interface&lt;/li&gt; 
 &lt;li&gt;Project based database storage, to help keep work organized&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üë∑‚Äç‚ôÇÔ∏è Hetty is under active development. Check the &lt;a href="https://github.com/dstotijn/hetty/projects/1"&gt;backlog&lt;/a&gt; for the current status.&lt;/p&gt; 
&lt;p&gt;üì£ Are you pen testing professionaly in a team? I would love to hear your thoughts on tooling via &lt;a href="https://forms.gle/36jtgNc3TJ2imi5A8"&gt;this 5 minute survey&lt;/a&gt;. Thank you!&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;üí° The &lt;a href="https://hetty.xyz/docs/getting-started"&gt;Getting started&lt;/a&gt; doc has more detailed install and usage instructions.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;The quickest way to install and update Hetty is via a package manager:&lt;/p&gt; 
&lt;h4&gt;macOS&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install hettysoft/tap/hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Linux&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo snap install hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Windows&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;scoop bucket add hettysoft https://github.com/hettysoft/scoop-bucket.git
scoop install hettysoft/hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Other&lt;/h4&gt; 
&lt;p&gt;Alternatively, you can &lt;a href="https://github.com/dstotijn/hetty/releases/latest"&gt;download the latest release from GitHub&lt;/a&gt; for your OS and architecture, and move the binary to a directory in your &lt;code&gt;$PATH&lt;/code&gt;. If your OS is not available for one of the package managers or not listed in the GitHub releases, you can compile from source &lt;em&gt;(link coming soon)&lt;/em&gt;.&lt;/p&gt; 
&lt;h4&gt;Docker&lt;/h4&gt; 
&lt;p&gt;Docker images are distributed via &lt;a href="https://github.com/dstotijn/hetty/pkgs/container/hetty"&gt;GitHub's Container registry&lt;/a&gt; and &lt;a href="https://hub.docker.com/r/dstotijn/hetty"&gt;Docker Hub&lt;/a&gt;. To run Hetty via with a volume for database and certificate storage, and port 8080 forwarded:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -v $HOME/.hetty:/root/.hetty -p 8080:8080 \
  ghcr.io/dstotijn/hetty:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;Once installed, start Hetty via:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;üí° Read the &lt;a href="https://hetty.xyz/docs/getting-started"&gt;Getting started&lt;/a&gt; doc for more details.&lt;/p&gt; 
&lt;p&gt;To list all available options, run: &lt;code&gt;hetty --help&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ hetty --help

Usage:
    hetty [flags] [subcommand] [flags]

Runs an HTTP server with (MITM) proxy, GraphQL service, and a web based admin interface.

Options:
    --cert         Path to root CA certificate. Creates file if it doesn't exist. (Default: "~/.hetty/hetty_cert.pem")
    --key          Path to root CA private key. Creates file if it doesn't exist. (Default: "~/.hetty/hetty_key.pem")
    --db           Database file path. Creates file if it doesn't exist. (Default: "~/.hetty/hetty.db")
    --addr         TCP address for HTTP server to listen on, in the form \"host:port\". (Default: ":8080")
    --chrome       Launch Chrome with proxy settings applied and certificate errors ignored. (Default: false)
    --verbose      Enable verbose logging.
    --json         Encode logs as JSON, instead of pretty/human readable output.
    --version, -v  Output version.
    --help, -h     Output this usage text.

Subcommands:
    - cert  Certificate management

Run `hetty &amp;lt;subcommand&amp;gt; --help` for subcommand specific usage instructions.

Visit https://hetty.xyz to learn more about Hetty.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;üìñ &lt;a href="https://hetty.xyz/docs"&gt;Read the docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Use &lt;a href="https://github.com/dstotijn/hetty/issues"&gt;issues&lt;/a&gt; for bug reports and feature requests, and &lt;a href="https://github.com/dstotijn/hetty/discussions"&gt;discussions&lt;/a&gt; for questions and troubleshooting.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;üí¨ &lt;a href="https://discord.gg/3HVsj5pTFP"&gt;Join the Hetty Discord server&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Want to contribute? Great! Please check the &lt;a href="https://raw.githubusercontent.com/dstotijn/hetty/main/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thanks to the &lt;a href="https://www.hacker101.com/discord"&gt;Hacker101 community on Discord&lt;/a&gt; for the encouragement and early feedback.&lt;/li&gt; 
 &lt;li&gt;The font used in the logo and admin interface is &lt;a href="https://www.jetbrains.com/lp/mono/"&gt;JetBrains Mono&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;üíñ Are you enjoying Hetty? You can &lt;a href="https://github.com/sponsors/dstotijn"&gt;sponsor me&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/dstotijn/hetty/main/LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;¬© 2019‚Äì2025 Hetty Software&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vektra/mockery</title>
      <link>https://github.com/vektra/mockery</link>
      <description>&lt;p&gt;A mock code autogenerator for Go&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;mockery&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/vektra/mockery/v3/template"&gt;&lt;img src="https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="go.dev reference" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/go-mod/go-version/vektra/mockery" alt="GitHub go.mod Go version" /&gt; &lt;img src="https://img.shields.io/github/v/release/vektra/mockery" alt="GitHub release (latest SemVer)" /&gt; &lt;a href="https://goreportcard.com/report/github.com/vektra/mockery/v3"&gt;&lt;img src="https://goreportcard.com/badge/github.com/vektra/mockery/v3" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/vektra/mockery"&gt;&lt;img src="https://codecov.io/gh/vektra/mockery/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;mockery provides the ability to easily generate mocks for Golang interfaces using the &lt;a href="https://pkg.go.dev/github.com/stretchr/testify/mock?tab=doc"&gt;stretchr/testify/mock&lt;/a&gt; package. It removes the boilerplate coding required to use mocks.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Documentation is found at our &lt;a href="https://vektra.github.io/mockery/"&gt;GitHub Pages site&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;taskfile.dev is used for build tasks. Initialize all go build tools:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go mod download -x
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can run any of the steps listed in &lt;code&gt;Taskfile.yml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ task test
task: [test] go test -v -coverprofile=coverage.txt ./...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Stargazers&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/vektra/mockery"&gt;&lt;img src="https://starchart.cc/vektra/mockery.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pdfcpu/pdfcpu</title>
      <link>https://github.com/pdfcpu/pdfcpu</link>
      <description>&lt;p&gt;A PDF processor written in Go.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;pdfcpu: a Go PDF processor and CLI&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/pdfcpu/pdfcpu/actions"&gt;&lt;img src="https://github.com/pdfcpu/pdfcpu/workflows/Test/badge.svg?sanitize=true" alt="Test" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/pdfcpu/pdfcpu?branch=master"&gt;&lt;img src="https://coveralls.io/repos/github/pdfcpu/pdfcpu/badge.svg?branch=master" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/pdfcpu/pdfcpu"&gt;&lt;img src="https://godoc.org/github.com/pdfcpu/pdfcpu?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/pdfcpu/pdfcpu"&gt;&lt;img src="https://goreportcard.com/badge/github.com/pdfcpu/pdfcpu" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/hexpm/l/plug.svg?sanitize=true" alt="Hex.pm" /&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/pdfcpu"&gt;&lt;img src="https://img.shields.io/badge/Gurubase-Ask%20pdfcpu%20Guru-006BFF" alt="Gurubase" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/pdfcpu/pdfcpu/releases"&gt;&lt;img src="https://img.shields.io/github/release/pdfcpu/pdfcpu.svg?sanitize=true" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/hhrutter"&gt;&lt;img src="https://img.shields.io/static/v1?label=Sponsor&amp;amp;message=%E2%9D%A4&amp;amp;logo=GitHub&amp;amp;color=%23fe8e86" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pdfcpu.io"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/logoSmall.png" width="150" /&gt;&lt;/a&gt; &lt;a href="https://pdfa.org"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/pdfa.png" width="75" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;pdfcpu is a PDF processing library written in &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt; that supports encryption and offers both an API and a command-line interface (CLI). It is compatible with all PDF versions with basic support and ongoing improvement for PDF 2.0 (ISO-32000-2).&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;p&gt;This is an effort to build a comprehensive PDF processing library from the ground up written in Go. Over time pdfcpu aims to support the standard range of PDF processing features and also any interesting use cases that may present themselves along the way.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/generate/grid"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/gridpdf.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt;&amp;nbsp; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/core/watermark"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/wmi1abs.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt;&amp;nbsp; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/generate/nup"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/nup9pdf.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt;&amp;nbsp; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/fonts/fonts"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/cjkv.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt;&amp;nbsp; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/core/stamp"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/4exp.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt;&amp;nbsp; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/form/form"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/form.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt;&lt;br /&gt;&lt;br /&gt; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/generate/create"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/table.png" height="100" /&gt;&lt;/a&gt;&lt;/kbd&gt;&amp;nbsp; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/core/stamp"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/sti.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt;&amp;nbsp; &lt;kbd&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/hold3.png" height="150" /&gt;&lt;/kbd&gt;&amp;nbsp; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/core/watermark"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/wmi4.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt;&amp;nbsp; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/generate/create"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/imagebox.png" height="100" /&gt;&lt;/a&gt;&lt;/kbd&gt;&amp;nbsp;&lt;br /&gt;&lt;br /&gt; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/generate/booklet"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/book2A4p1.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/core/stamp"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/stp.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt;&amp;nbsp; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/generate/grid"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/gridimg.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/core/stamp"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/stRoundBorder.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt; &lt;kbd&gt;&lt;a href="https://pdfcpu.io/generate/booklet"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/book4A4p1.png" height="150" /&gt;&lt;/a&gt;&lt;/kbd&gt; &lt;/p&gt; 
&lt;h2&gt;Focus&lt;/h2&gt; 
&lt;p&gt;The primary emphasis is on providing robust assistance for batch processing and scripting through a comprehensive command-line interface. Simultaneously, pdfcpu aims to simplify the integration of PDF processing into your Go-based backend system by offering a versatile set of commands.&lt;/p&gt; 
&lt;h2&gt;Command Set&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/annot/annot"&gt;annotations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/attach/attach"&gt;attachments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/generate/booklet"&gt;booklet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/bookmarks/bookmarks"&gt;bookmarks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/boxes/boxes"&gt;boxes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/certs"&gt;certificates&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/encrypt/change_opw"&gt;change owner password&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/encrypt/change_upw"&gt;change user password&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/collect"&gt;collect&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/config/config"&gt;config&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/create/create"&gt;create&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/crop"&gt;crop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/generate/cut"&gt;cut&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/encrypt/decryptPDF"&gt;decrypt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/encrypt/encryptPDF"&gt;encrypt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/extract/extract"&gt;extract&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/fonts/fonts"&gt;fonts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/form/form"&gt;form&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/generate/grid"&gt;grid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/images/images"&gt;images&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/generate/import"&gt;import&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/info"&gt;info&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/keywords/keywords"&gt;keywords&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/merge"&gt;merge&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/generate/ndown"&gt;ndown&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/generate/nup"&gt;nup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/optimize"&gt;optimize&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/pagelayout/pagelayout"&gt;pagelayout&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/pagemode/pagemode"&gt;pagemode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/pages/pages"&gt;pages&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/encrypt/perm_set"&gt;permissions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/portfolio/portfolio"&gt;portfolio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/generate/poster"&gt;poster&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/properties/properties"&gt;properties&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/resize"&gt;resize&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/rotate"&gt;rotate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://pdfcpu.io/core/sign"&gt;signatures&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/split"&gt;split&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/stamp"&gt;stamp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/trim"&gt;trim&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/validate"&gt;validate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/viewerpref/viewerpref"&gt;viewerpref&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/watermark"&gt;watermark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io/core/zoom"&gt;zoom&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pdfcpu.io"&gt;pdfcpu.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pdfcpu/pdfcpu/tree/master/pkg/api/test"&gt;API tests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pdfcpu/pdfcpu/tree/master/pkg/samples"&gt;API samples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;CLI usage: &lt;code&gt;$ pdfcpu help cmd&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;GoDoc&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/pdfcpu/pdfcpu"&gt;pdfcpu package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/pdfcpu/pdfcpu/pkg/api"&gt;pdfcpu API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/pdfcpu/pdfcpu/pkg/cli"&gt;pdfcpu CLI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reminder&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Always make sure your work is based on the latest commit!&lt;br /&gt;&lt;/li&gt; 
 &lt;li&gt;pdfcpu is still &lt;em&gt;Alpha&lt;/em&gt; - bugfixes are committed on the fly and will be mentioned in the next release notes.&lt;br /&gt;&lt;/li&gt; 
 &lt;li&gt;Follow &lt;a href="https://twitter.com/pdfcpu"&gt;pdfcpu&lt;/a&gt; for news and release announcements.&lt;/li&gt; 
 &lt;li&gt;For quick questions or discussions get in touch on the &lt;a href="https://invite.slack.golangbridge.org/"&gt;Gopher Slack&lt;/a&gt; in the #pdfcpu channel.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo Screencast&lt;/h2&gt; 
&lt;p&gt;(using older version with a smaller command set)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://asciinema.org/a/P5jaAo9kgZXKj2iSA1OqIdLAU"&gt;&lt;img src="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/resources/demo.png" alt="asciicast" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Download&lt;/h3&gt; 
&lt;p&gt;Get the latest binary &lt;a href="https://github.com/pdfcpu/pdfcpu/releases"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Using Go Modules&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/pdfcpu/pdfcpu
$ cd pdfcpu/cmd/pdfcpu
$ go install
$ pdfcpu version
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or directly through Go install:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/pdfcpu/pdfcpu/cmd/pdfcpu@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Homebrew (macOS)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ brew install pdfcpu
$ pdfcpu version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using DNF/YUM (Fedora)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ sudo dnf install golang-github-pdfcpu
$ pdfcpu version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run in a Docker container&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ docker build -t pdfcpu .
# mount current host folder into container as /app to process files in the local host folder
$ docker run -it -v "$(pwd)":/app pdfcpu validate a.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;h3&gt;What&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Please &lt;a href="https://github.com/pdfcpu/pdfcpu/issues/new/choose"&gt;create&lt;/a&gt; an issue if you find a bug or want to propose a change.&lt;/li&gt; 
 &lt;li&gt;Feature requests - always welcome!&lt;/li&gt; 
 &lt;li&gt;Bug fixes - always welcome!&lt;/li&gt; 
 &lt;li&gt;PRs - let's &lt;a href="https://github.com/pdfcpu/pdfcpu/discussions"&gt;discuss&lt;/a&gt; first or &lt;a href="https://github.com/pdfcpu/pdfcpu/issues/new/choose"&gt;create&lt;/a&gt; an issue.&lt;/li&gt; 
 &lt;li&gt;pdfcpu is stable but still &lt;em&gt;Alpha&lt;/em&gt; and occasionally undergoing heavy changes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The pdfcpu &lt;a href="https://github.com/pdfcpu/pdfcpu/discussions"&gt;discussion board&lt;/a&gt; is open! Please engage in any form helpful for the community.&lt;/li&gt; 
 &lt;li&gt;If you want to report a bug please attach the &lt;em&gt;very verbose&lt;/em&gt; (&lt;code&gt;pdfcpu cmd -vv ...&lt;/code&gt;) output and ideally a test PDF that you can share.&lt;/li&gt; 
 &lt;li&gt;Always make sure your contribution is based on the latest commit.&lt;/li&gt; 
 &lt;li&gt;Please sign your commits.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Reporting Crashes&lt;/h3&gt; 
&lt;p&gt;Unfortunately crashes do happen :( For the majority of the cases this is due to a diverse pool of PDF Writers out there and millions of PDF files using different versions waiting to be processed by pdfcpu. Sometimes these PDFs were written more than 20(!) years ago. Often there is an issue with validation - sometimes a bug in the parser. Many times even using relaxed validation with pdfcpu does not work. In these cases we need to extend relaxed validation and for this we are relying on your help. By reporting crashes you are helping to improve the stability of pdfcpu. If you happen to crash on any pdfcpu operation be it on the command line or in your Go backend these are the steps to report this:&lt;/p&gt; 
&lt;p&gt;Regardless of the pdfcpu operation, please start using the pdfcpu command line to validate your file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ pdfcpu validate -v &amp;amp;&amp;gt; crash.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or to produce very verbose output&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ pdfcpu validate -vv &amp;amp;&amp;gt; crash.log
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;will produce what's needed to investigate a crash. Then open an issue and post &lt;code&gt;crash.log&lt;/code&gt; or its contents. Ideally post a test PDF you can share to reproduce this. You can also email to &lt;a href="mailto:hhrutter@gmail.com"&gt;hhrutter@gmail.com&lt;/a&gt; or if you prefer Slack you can get in touch on the Gopher slack #pdfcpu channel.&lt;/p&gt; 
&lt;p&gt;If processing your PDF with pdfcpu crashes during validation and can be opened by Adobe Reader and Mac Preview chances are we can extend relaxed validation and provide a fix. If the file in question cannot be opened by both Adobe Reader and Mac Preview we cannot help you!&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks üíö goes to these wonderful people:&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/hhrutter"&gt;&lt;img src="https://avatars1.githubusercontent.com/u/11322155?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Horst Rutter&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/haldyr"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/5140211?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;haldyr&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/SimePel"&gt;&lt;img src="https://avatars3.githubusercontent.com/u/20608155?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vyacheslav&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/ungerik"&gt;&lt;img src="https://avatars1.githubusercontent.com/u/617459?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Erik Unger&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/richardwilkes"&gt;&lt;img src="https://avatars1.githubusercontent.com/u/13079058?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Richard Wilkes&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/minenok-tutu"&gt;&lt;img src="https://avatars1.githubusercontent.com/u/16303386?s=400&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;minenok-tutu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/matbur"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/1965445?s=400&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mateusz Burniak&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/dharnitski"&gt;&lt;img src="https://avatars2.githubusercontent.com/u/1175110?s=400&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Dmitry Harnitski&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/ryarnyah"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/1074083?s=400&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;ryarnyah&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/s01ipsist"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/13267?s=400&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sam Giffney&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/cewitte"&gt;&lt;img src="https://avatars3.githubusercontent.com/u/32948066?s=400&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Carlos Eduardo Witte&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/minusworld"&gt;&lt;img src="https://avatars1.githubusercontent.com/u/2374948?s=400&amp;amp;u=a36e5f8da8dc1c102bc4d283f25e4c61cae7f985&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;minusworld&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/jozuenoon"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/18538487?s=400&amp;amp;u=b9e628dfc60f672a887be2ed04a791195829943e&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Witold Konior&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/joonas-fi"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/630151?s=400&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;joonas.fi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/henrixapp"&gt;&lt;img src="https://avatars3.githubusercontent.com/u/10349817?s=400&amp;amp;u=93bacb23bd2909d5b6c5b644a8d4cdd947422ee1&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Henrik Reinst√§dtler&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/VMorozov-wh"&gt;&lt;img src="https://avatars1.githubusercontent.com/u/72016286?s=400&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;VMorozov-wh&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/benoitkugler"&gt;&lt;img src="https://avatars0.githubusercontent.com/u/31929422?s=400&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Benoit KUGLER&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/adamgreenhall"&gt;&lt;img src="https://avatars.githubusercontent.com/u/704919?s=400&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Adam Greenhall&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/moritamori"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5201812?s=400&amp;amp;u=8a0a9fca4560be71d4923299ddebf877854eea54&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;moritamori&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/JanBaryla"&gt;&lt;img src="https://avatars.githubusercontent.com/u/41904529?s=400&amp;amp;u=044396494285ad806e86d1936c390b3071ce57c0&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;JanBaryla&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/TheDiscordian"&gt;&lt;img src="https://avatars.githubusercontent.com/u/43145244?s=400&amp;amp;u=89a689f1a854ce0f57ae2a0333c82bfdc5723bb9&amp;amp;v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;TheDiscordian&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/rgargente"&gt;&lt;img src="https://avatars.githubusercontent.com/u/15472552?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Rafael Garcia Argente&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/truyet"&gt;&lt;img src="https://avatars.githubusercontent.com/u/710057?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;truyet&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/christiannicola"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5031217?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Christian Nicola&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/kben"&gt;&lt;img src="https://avatars.githubusercontent.com/u/3233970?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Benjamin Krill&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/petervwyatt"&gt;&lt;img src="https://avatars.githubusercontent.com/u/26521615?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Peter Wyatt&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/kpym"&gt;&lt;img src="https://avatars.githubusercontent.com/u/3142701?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kroum Tzanev&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/signalwerk"&gt;&lt;img src="https://avatars.githubusercontent.com/u/992878?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Stefan Huber&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/juaismar"&gt;&lt;img src="https://avatars.githubusercontent.com/u/59667587?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Juan Iscar&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/Juneezee"&gt;&lt;img src="https://avatars.githubusercontent.com/u/20135478?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Eng Zer Jun&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/hant0508"&gt;&lt;img src="https://avatars.githubusercontent.com/u/28459131?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Dmitry Ivanov&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/HeavyHorst"&gt;&lt;img src="https://avatars.githubusercontent.com/u/16866547?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Rene Kaufmann&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/christian-heusel"&gt;&lt;img src="https://avatars.githubusercontent.com/u/26827864?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Christian Heusel&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/freshteapot"&gt;&lt;img src="https://avatars.githubusercontent.com/u/305673?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Chris&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/scoiatael"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2892794?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Lukasz Czaplinski&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/joelschutz"&gt;&lt;img src="https://avatars.githubusercontent.com/u/49206635?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Joel Silva Schutz&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/semvis123"&gt;&lt;img src="https://avatars.githubusercontent.com/u/28219076?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;semvis123&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/testwill"&gt;&lt;img src="https://avatars.githubusercontent.com/u/8717479?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;guangwu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/yyoshiki41"&gt;&lt;img src="https://avatars.githubusercontent.com/u/4014912?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Yoshiki Nakagawa&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/stevevls"&gt;&lt;img src="https://avatars.githubusercontent.com/u/432860?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Steve van Loben Sels&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/mygityf"&gt;&lt;img src="https://avatars.githubusercontent.com/u/6083533?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Yaofu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/vsenko"&gt;&lt;img src="https://avatars.githubusercontent.com/u/15724278?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;vsenko&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/afh"&gt;&lt;img src="https://avatars.githubusercontent.com/u/16507?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Alexis Hildebrandt&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/sivukhin"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1395040?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sivukhin Nikita&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/fancycode"&gt;&lt;img src="https://avatars.githubusercontent.com/u/247730?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Joachim Bauch&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/kalimit"&gt;&lt;img src="https://avatars.githubusercontent.com/u/127291996?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;kalimit&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/xelan"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5080535?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Andreas Erhard&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/toshi1127"&gt;&lt;img src="https://avatars.githubusercontent.com/u/32378535?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matsumoto Toshi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/carlwilson"&gt;&lt;img src="https://avatars.githubusercontent.com/u/440634?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Carl Wilson&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/LNAhri"&gt;&lt;img src="https://avatars.githubusercontent.com/u/9918222?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;LNAhri&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/vishal-at"&gt;&lt;img src="https://avatars.githubusercontent.com/u/142796877?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;vishal&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/deining"&gt;&lt;img src="https://avatars.githubusercontent.com/u/18169566?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Andreas Deininger&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/solintllc-robert"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5825735?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Robert Raines&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/frob"&gt;&lt;img src="https://avatars.githubusercontent.com/u/316176?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Frank Anderson&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/SveLil"&gt;&lt;img src="https://avatars.githubusercontent.com/u/20972350?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sven Lilienthal&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/fank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1900106?v=4" width="100px" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Florian Kinder&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END - Do not remove or modify this section --&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;Please note that this project is released with a Contributor &lt;a href="https://raw.githubusercontent.com/pdfcpu/pdfcpu/master/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;. By participating in this project you agree to abide by its terms.&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;Usage of pdfcpu assumes you know about and respect all copyrights of any PDF content you may be processing. This applies to the PDF files as such, their content and in particular all embedded resources like font files or images. Credit goes to &lt;a href="https://instagram.com/reneefrench"&gt;Renee French&lt;/a&gt; for creating our beloved Gopher.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache-2.0&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>chaitin/SafeLine</title>
      <link>https://github.com/chaitin/SafeLine</link>
      <description>&lt;p&gt;SafeLine is a self-hosted WAF(Web Application Firewall) / reverse proxy to protect your web apps from attacks and exploits.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/banner.png" width="400" /&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt; SafeLine - Make your web apps secure &lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a target="_blank" href="https://ly.safepoint.cloud/laA8asp"&gt;üè† Website&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://ly.safepoint.cloud/w2AeHhb"&gt;üìñ Docs&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://ly.safepoint.cloud/hSMd4SH"&gt;üîç Live Demo&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://discord.gg/SVnZGzHFvn"&gt;üôã‚Äç‚ôÇÔ∏è Discord&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a target="_blank" href="https://raw.githubusercontent.com/chaitin/SafeLine/main/README_CN.md"&gt;‰∏≠ÊñáÁâà&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üëã INTRODUCTION&lt;/h2&gt; 
&lt;p&gt;SafeLine is a self-hosted &lt;strong&gt;&lt;code&gt;WAF(Web Application Firewall)&lt;/code&gt;&lt;/strong&gt; to protect your web apps from attacks and exploits.&lt;/p&gt; 
&lt;p&gt;A web application firewall helps protect web apps by filtering and monitoring HTTP traffic between a web application and the Internet. It typically protects web apps from attacks such as &lt;code&gt;SQL injection&lt;/code&gt;, &lt;code&gt;XSS&lt;/code&gt;, &lt;code&gt;code injection&lt;/code&gt;, &lt;code&gt;os command injection&lt;/code&gt;, &lt;code&gt;CRLF injection&lt;/code&gt;, &lt;code&gt;ldap injection&lt;/code&gt;, &lt;code&gt;xpath injection&lt;/code&gt;, &lt;code&gt;RCE&lt;/code&gt;, &lt;code&gt;XXE&lt;/code&gt;, &lt;code&gt;SSRF&lt;/code&gt;, &lt;code&gt;path traversal&lt;/code&gt;, &lt;code&gt;backdoor&lt;/code&gt;, &lt;code&gt;bruteforce&lt;/code&gt;, &lt;code&gt;http-flood&lt;/code&gt;, &lt;code&gt;bot abused&lt;/code&gt;, among others.&lt;/p&gt; 
&lt;h4&gt;üí° How It Works&lt;/h4&gt; 
&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/how-it-works.png" width="800" /&gt; 
&lt;p&gt;By deploying a WAF in front of a web application, a shield is placed between the web application and the Internet. While a proxy server protects a client machine‚Äôs identity by using an intermediary, a WAF is a type of reverse-proxy, protecting the server from exposure by having clients pass through the WAF before reaching the server.&lt;/p&gt; 
&lt;p&gt;A WAF protects your web apps by filtering, monitoring, and blocking any malicious HTTP/S traffic traveling to the web application, and prevents any unauthorized data from leaving the app. It does this by adhering to a set of policies that help determine what traffic is malicious and what traffic is safe. Just as a proxy server acts as an intermediary to protect the identity of a client, a WAF operates in similar fashion but acting as a reverse proxy intermediary that protects the web app server from a potentially malicious client.&lt;/p&gt; 
&lt;p&gt;its core capabilities include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Defenses for web attacks&lt;/li&gt; 
 &lt;li&gt;Proactive bot abused defense&lt;/li&gt; 
 &lt;li&gt;HTML &amp;amp; JS code encryption&lt;/li&gt; 
 &lt;li&gt;IP-based rate limiting&lt;/li&gt; 
 &lt;li&gt;Web Access Control List&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ö°Ô∏è Screenshots&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-1.png" width="370" /&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-2.png" width="370" /&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-3.png" width="370" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/screenshot-4.png" width="370" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Get &lt;a href="https://demo.waf.chaitin.com:9443/"&gt;Live Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üî• FEATURES&lt;/h2&gt; 
&lt;p&gt;List of the main features as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Block Web Attacks&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;It defenses for all of web attacks, such as &lt;code&gt;SQL injection&lt;/code&gt;, &lt;code&gt;XSS&lt;/code&gt;, &lt;code&gt;code injection&lt;/code&gt;, &lt;code&gt;os command injection&lt;/code&gt;, &lt;code&gt;CRLF injection&lt;/code&gt;, &lt;code&gt;XXE&lt;/code&gt;, &lt;code&gt;SSRF&lt;/code&gt;, &lt;code&gt;path traversal&lt;/code&gt; and so on.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Rate Limiting&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Defend your web apps against &lt;code&gt;DoS attacks&lt;/code&gt;, &lt;code&gt;bruteforce attempts&lt;/code&gt;, &lt;code&gt;traffic surges&lt;/code&gt;, and other types of abuse by throttling traffic that exceeds defined limits.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Anti-Bot Challenge&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Anti-Bot challenges to protect your website from &lt;code&gt;bot attacks&lt;/code&gt;, humen users will be allowed, crawlers and bots will be blocked.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Authentication Challenge&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;When authentication challenge turned on, visitors need to enter the password, otherwise they will be blocked.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;Dynamic Protection&lt;/code&gt;&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;When dynamic protection turned on, html and js codes in your web server will be dynamically encrypted by each time you visit.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üß© Showcases&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Legitimate User&lt;/th&gt; 
   &lt;th&gt;Malicious User&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Block Web Attacks&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/skeleton.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/blocked-for-attack-detected.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Rate Limiting&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/skeleton.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/blocked-for-access-too-fast.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Anti-Bot Challenge&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/captcha-1.gif" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/captcha-2.gif" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;Auth Challenge&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/auth-1.gif" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/auth-2.gif" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;HTML Dynamic Protection&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-html-1.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-html-2.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;&lt;code&gt;JS Dynamic Protection&lt;/code&gt;&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-js-1.png" width="270" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/dynamic-js-2.png" width="270" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Quickstart&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] ‰∏≠ÂõΩÂ§ßÈôÜÁî®Êà∑ÂÆâË£ÖÂõΩÈôÖÁâàÂèØËÉΩ‰ºöÂØºËá¥Êó†Ê≥ïËøûÊé•‰∫ëÊúçÂä°ÔºåËØ∑Êü•Áúã &lt;a href="https://docs.waf-ce.chaitin.cn/zh/%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/%E5%AE%89%E8%A3%85%E9%9B%B7%E6%B1%A0"&gt;‰∏≠ÊñáÁâàÂÆâË£ÖÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;üì¶ Installing&lt;/h4&gt; 
&lt;p&gt;Information on how to install SafeLine can be found in the &lt;a href="https://docs.waf.chaitin.com/en/GetStarted/Deploy"&gt;Install Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;‚öôÔ∏è Protecting Web Apps&lt;/h4&gt; 
&lt;p&gt;to see &lt;a href="https://docs.waf.chaitin.com/en/GetStarted/AddApplication"&gt;Configuration&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìã More Informations&lt;/h2&gt; 
&lt;h4&gt;Effect Evaluation&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;ModSecurity, Level 1&lt;/th&gt; 
   &lt;th&gt;CloudFlare, Free&lt;/th&gt; 
   &lt;th&gt;SafeLine, Balance&lt;/th&gt; 
   &lt;th&gt;SafeLine, Strict&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Total Samples&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
   &lt;td&gt;33669&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Detection&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;69.74%&lt;/td&gt; 
   &lt;td&gt;10.70%&lt;/td&gt; 
   &lt;td&gt;71.65%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;76.17%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;False Positive&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;17.58%&lt;/td&gt; 
   &lt;td&gt;0.07%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.07%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;0.22%&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;82.20%&lt;/td&gt; 
   &lt;td&gt;98.40%&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;99.45%&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;99.38%&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Is SafeLine Production-Ready?&lt;/h4&gt; 
&lt;p&gt;Yes, SafeLine is production-ready.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Over 180,000 installations worldwide&lt;/li&gt; 
 &lt;li&gt;Protecting over 1,000,000 Websites&lt;/li&gt; 
 &lt;li&gt;Handling over 30,000,000,000 HTTP Requests Daily&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;üôã‚Äç‚ôÇÔ∏è Community&lt;/h4&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.gg/SVnZGzHFvn"&gt;Discord&lt;/a&gt; to get community support, the core team members are identified by the STAFF role in Discord.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1243120292822253598"&gt;#feedback&lt;/a&gt;: for new features discussion.&lt;/li&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1263761679619981413"&gt;#FAQ&lt;/a&gt;: for FAQ.&lt;/li&gt; 
 &lt;li&gt;channel &lt;a href="https://discord.com/channels/1243085666485534830/1243115843919806486"&gt;#general&lt;/a&gt;: for any other questions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Several contact options exist for our community, the primary one being Discord. These are in addition to GitHub issues for creating a new issue.&lt;/p&gt; 
&lt;p align="left"&gt; &lt;a target="_blank" href="https://discord.gg/SVnZGzHFvn"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a target="_blank" href="https://x.com/safeline_waf"&gt;&lt;img src="https://img.shields.io/badge/X.com-000000?style=flat&amp;amp;logo=x&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a target="_blank" href="https://raw.githubusercontent.com/chaitin/SafeLine/main/images/wechat.png"&gt;&lt;img src="https://img.shields.io/badge/WeChat-07C160?style=flat&amp;amp;logo=wechat&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h4&gt;üí™ PRO Edition&lt;/h4&gt; 
&lt;p&gt;Coming soon!&lt;/p&gt; 
&lt;h4&gt;üìù License&lt;/h4&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/chaitin/SafeLine/main/LICENSE.md"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA/gpu-operator</title>
      <link>https://github.com/NVIDIA/gpu-operator</link>
      <description>&lt;p&gt;NVIDIA GPU Operator creates, configures, and manages GPUs in Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/gpu-operator/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/NVIDIA/gpu-operator?style=flat-square" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://gitlab.com/nvidia/kubernetes/gpu-operator/-/pipelines"&gt;&lt;img src="https://gitlab.com/nvidia/kubernetes/gpu-operator/badges/master/pipeline.svg?sanitize=true" alt="pipeline status" /&gt;&lt;/a&gt; &lt;a href="https://gitlab.com/nvidia/kubernetes/gpu-operator/-/pipelines"&gt;&lt;img src="https://gitlab.com/nvidia/kubernetes/gpu-operator/badges/master/coverage.svg?sanitize=true" alt="coverage report" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;NVIDIA GPU Operator&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/egx/nvidia-egx-platform-gold-image-full-2c50-d@2x.jpg" alt="nvidia-gpu-operator" /&gt;&lt;/p&gt; 
&lt;p&gt;Kubernetes provides access to special hardware resources such as NVIDIA GPUs, NICs, Infiniband adapters and other devices through the &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/"&gt;device plugin framework&lt;/a&gt;. However, configuring and managing nodes with these hardware resources requires configuration of multiple software components such as drivers, container runtimes or other libraries which are difficult and prone to errors. The NVIDIA GPU Operator uses the &lt;a href="https://cloud.redhat.com/blog/introducing-the-operator-framework"&gt;operator framework&lt;/a&gt; within Kubernetes to automate the management of all NVIDIA software components needed to provision GPU. These components include the NVIDIA drivers (to enable CUDA), Kubernetes device plugin for GPUs, the NVIDIA Container Runtime, automatic node labelling, &lt;a href="https://developer.nvidia.com/dcgm"&gt;DCGM&lt;/a&gt; based monitoring and others.&lt;/p&gt; 
&lt;h2&gt;Audience and Use-Cases&lt;/h2&gt; 
&lt;p&gt;The GPU Operator allows administrators of Kubernetes clusters to manage GPU nodes just like CPU nodes in the cluster. Instead of provisioning a special OS image for GPU nodes, administrators can rely on a standard OS image for both CPU and GPU nodes and then rely on the GPU Operator to provision the required software components for GPUs.&lt;/p&gt; 
&lt;p&gt;Note that the GPU Operator is specifically useful for scenarios where the Kubernetes cluster needs to scale quickly - for example provisioning additional GPU nodes on the cloud or on-prem and managing the lifecycle of the underlying software components. Since the GPU Operator runs everything as containers including NVIDIA drivers, the administrators can easily swap various components - simply by starting or stopping containers.&lt;/p&gt; 
&lt;h2&gt;Product Documentation&lt;/h2&gt; 
&lt;p&gt;For information on platform support and getting started, visit the official documentation &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/overview.html"&gt;repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Webinar&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://info.nvidia.com/how-to-use-gpus-on-kubernetes-webinar.html"&gt;How to easily use GPUs on Kubernetes&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/gpu-operator/raw/master/CONTRIBUTING.md"&gt;Read the document on contributions&lt;/a&gt;. You can contribute by opening a &lt;a href="https://help.github.com/en/articles/about-pull-requests"&gt;pull request&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support and Getting Help&lt;/h2&gt; 
&lt;p&gt;Please open &lt;a href="https://github.com/NVIDIA/gpu-operator/issues/new"&gt;an issue on the GitHub project&lt;/a&gt; for any questions. Your feedback is appreciated.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>grafana/alloy</title>
      <link>https://github.com/grafana/alloy</link>
      <description>&lt;p&gt;OpenTelemetry Collector distribution with programmable pipelines&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/grafana/alloy/main/docs/sources/assets/logo_alloy_light.svg#gh-dark-mode-only" alt="Grafana Alloy logo" height="100px" /&gt; &lt;img src="https://raw.githubusercontent.com/grafana/alloy/main/docs/sources/assets/logo_alloy_dark.svg#gh-light-mode-only" alt="Grafana Alloy logo" height="100px" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/grafana/alloy/releases"&gt;&lt;img src="https://img.shields.io/github/release/grafana/alloy.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://grafana.com/docs/alloy/latest"&gt;&lt;img src="https://img.shields.io/badge/Documentation-link-blue?logo=gitbook" alt="Documentation link" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Grafana Alloy is an open source OpenTelemetry Collector distribution with built-in Prometheus pipelines and support for metrics, logs, traces, and profiles.&lt;/p&gt; 
&lt;p&gt; &lt;img src="https://raw.githubusercontent.com/grafana/alloy/main/docs/sources/assets/alloy_screenshot.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;What can Alloy do?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Programmable pipelines&lt;/strong&gt;: Use a rich &lt;a href="https://grafana.com/docs/alloy/latest/concepts/configuration-syntax/"&gt;expression-based syntax&lt;/a&gt; for configuring powerful observability pipelines.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenTelemetry Collector Distribution&lt;/strong&gt;: Alloy is a &lt;a href="https://opentelemetry.io/docs/collector/distributions/"&gt;distribution&lt;/a&gt; of OpenTelemetry Collector and supports dozens of its components, alongside new components that make use of Alloy's programmable pipelines.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Big tent&lt;/strong&gt;: Alloy embraces Grafana's "big tent" philosophy, where Alloy can be used with other vendors or open source databases. It has components to perfectly integrate with multiple telemetry ecosystems:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://opentelemetry.io"&gt;OpenTelemetry Collector&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://prometheus.io"&gt;Prometheus&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/grafana/loki"&gt;Grafana Loki&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/grafana/pyroscope"&gt;Grafana Pyroscope&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Kubernetes-native&lt;/strong&gt;: Use components to interact with native and custom Kubernetes resources; no need to learn how to use a separate Kubernetes operator.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Shareable pipelines&lt;/strong&gt;: Use &lt;a href="https://grafana.com/docs/alloy/latest/concepts/modules/"&gt;modules&lt;/a&gt; to share your pipelines with the world.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic workload distribution&lt;/strong&gt;: Configure Alloy instances to form a &lt;a href="https://grafana.com/docs/alloy/latest/concepts/clustering/"&gt;cluster&lt;/a&gt; for automatic workload distribution.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Centralized configuration support&lt;/strong&gt;: Alloy supports retrieving its configuration from a &lt;a href="https://grafana.com/docs/alloy/latest/reference/config-blocks/remotecfg/"&gt;server&lt;/a&gt; for centralized configuration management.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Debugging utilities&lt;/strong&gt;: Use the &lt;a href="https://grafana.com/docs/alloy/latest/tasks/debug/"&gt;built-in UI&lt;/a&gt; for visualizing and debugging pipelines.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-alloy"&gt;otelcol.receiver.otlp "example" {
  grpc {
    endpoint = "127.0.0.1:4317"
  }

  output {
    metrics = [otelcol.processor.batch.example.input]
    logs    = [otelcol.processor.batch.example.input]
    traces  = [otelcol.processor.batch.example.input]
  }
}

otelcol.processor.batch "example" {
  output {
    metrics = [otelcol.exporter.otlp.default.input]
    logs    = [otelcol.exporter.otlp.default.input]
    traces  = [otelcol.exporter.otlp.default.input]
  }
}

otelcol.exporter.otlp "default" {
  client {
    endpoint = "my-otlp-grpc-server:4317"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Check out our &lt;a href="https://grafana.com/docs/alloy/latest"&gt;documentation&lt;/a&gt; to see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/alloy/latest/get-started/install/"&gt;Installation instructions&lt;/a&gt; for Alloy&lt;/li&gt; 
 &lt;li&gt;Steps for &lt;a href="https://grafana.com/docs/alloy/latest/get-started/"&gt;Getting started&lt;/a&gt; with Alloy&lt;/li&gt; 
 &lt;li&gt;The list of Alloy &lt;a href="https://grafana.com/docs/alloy/latest/reference/components/"&gt;components&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Release cadence&lt;/h2&gt; 
&lt;p&gt;A new minor release is planned every six weeks.&lt;/p&gt; 
&lt;p&gt;The release cadence is best-effort: if necessary, releases may be performed outside of this cadence, or a scheduled release date can be moved forwards or backwards.&lt;/p&gt; 
&lt;p&gt;Minor releases published on cadence include updating dependencies for upstream OpenTelemetry Collector code if new versions are available. Minor releases published outside of the release cadence may not include these dependency updates.&lt;/p&gt; 
&lt;p&gt;Patch and security releases may be published at any time.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;To engage with the Alloy community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Chat with us on our community Slack channel. To invite yourself to the Grafana Slack, visit &lt;a href="https://slack.grafana.com/"&gt;https://slack.grafana.com/&lt;/a&gt; and join the &lt;code&gt;#alloy&lt;/code&gt; channel.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ask questions on the &lt;a href="https://community.grafana.com/c/grafana-alloy"&gt;Grafana community site&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/grafana/alloy/issues/new"&gt;File an issue&lt;/a&gt; for bugs, issues, and feature suggestions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Attend the monthly &lt;a href="https://docs.google.com/document/d/1TqaZD1JPfNadZ4V81OCBPCG_TksDYGlNlGdMnTWUSpo"&gt;community call&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Refer to our &lt;a href="https://github.com/grafana/alloy/raw/main/docs/developer/contributing.md"&gt;contributors guide&lt;/a&gt; to learn how to contribute.&lt;/p&gt; 
&lt;p&gt;Thanks to all the people who have already contributed!&lt;/p&gt; 
&lt;a href="https://github.com/grafana/alloy/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=grafana/alloy" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>integrations/terraform-provider-github</title>
      <link>https://github.com/integrations/terraform-provider-github</link>
      <description>&lt;p&gt;Terraform GitHub provider&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Terraform Provider GitHub&lt;/h1&gt; 
&lt;img src="https://cloud.githubusercontent.com/assets/98681/24211275/c4ebd04e-0ee8-11e7-8606-061d656a42df.png" width="72" height="" /&gt; 
&lt;img src="https://raw.githubusercontent.com/hashicorp/terraform-website/d841a1e5fca574416b5ca24306f85a0f4f41b36d/content/source/assets/images/logo-terraform-main.svg?sanitize=true" width="300px" /&gt; 
&lt;p&gt;This project is used to manipulate GitHub resources (repositories, teams, files, etc.) using Terraform. Its Terraform Registry page can be found &lt;a href="https://registry.terraform.io/providers/integrations/github/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.terraform.io/downloads.html"&gt;Terraform&lt;/a&gt; 0.10.x&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://golang.org/doc/install"&gt;Go&lt;/a&gt; 1.19.x (to build the provider plugin)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Detailed documentation for the GitHub provider can be found &lt;a href="https://registry.terraform.io/providers/integrations/github"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Detailed documentation for contributing to the GitHub provider can be found &lt;a href="https://raw.githubusercontent.com/integrations/terraform-provider-github/main/CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;This project uses &lt;a href="https://github.com/integrations/terraform-provider-github/milestones"&gt;Milestones&lt;/a&gt; to scope upcoming features and bug fixes. Issues that receive the most recent discussion or the most reactions will be more likely to be included in an upcoming release.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;GitHub Support does not provide support for this integration. This is a community-supported project. GitHub's SDK team triages issues and PRs periodically.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>containers/buildah</title>
      <link>https://github.com/containers/buildah</link>
      <description>&lt;p&gt;A tool that facilitates building OCI images.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/containers/buildah/main/logos/buildah-logo_large.png#gh-light-mode-only" alt="buildah logo (light)" /&gt; &lt;img src="https://raw.githubusercontent.com/containers/buildah/main/logos/buildah-logo_reverse_large.png#gh-dark-mode-only" alt="buildah logo (dark)" /&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;a href="https://www.youtube.com/embed/YVk5NgSiUw8"&gt;Buildah&lt;/a&gt; - a tool that facilitates building &lt;a href="https://www.opencontainers.org/"&gt;Open Container Initiative (OCI)&lt;/a&gt; container images&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/containers/buildah"&gt;&lt;img src="https://goreportcard.com/badge/github.com/containers/buildah" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/10579"&gt;&lt;img src="https://www.bestpractices.dev/projects/10579/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The Buildah package provides a command line tool that can be used to&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;create a working container, either from scratch or using an image as a starting point&lt;/li&gt; 
 &lt;li&gt;create an image, either from a working container or via the instructions in a Dockerfile&lt;/li&gt; 
 &lt;li&gt;images can be built in either the OCI image format or the traditional upstream docker image format&lt;/li&gt; 
 &lt;li&gt;mount a working container's root filesystem for manipulation&lt;/li&gt; 
 &lt;li&gt;unmount a working container's root filesystem&lt;/li&gt; 
 &lt;li&gt;use the updated contents of a container's root filesystem as a filesystem layer to create a new image&lt;/li&gt; 
 &lt;li&gt;delete a working container or an image&lt;/li&gt; 
 &lt;li&gt;rename a local container&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Buildah Information for Developers&lt;/h2&gt; 
&lt;p&gt;For blogs, release announcements and more, please checkout the &lt;a href="https://buildah.io"&gt;buildah.io&lt;/a&gt; website!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/containers/image_build/raw/main/buildah/README.md"&gt;Buildah Container Images&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/demos"&gt;Buildah Demos&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/CHANGELOG.md"&gt;Changelog&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/developmentplan.md"&gt;Development Plan&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/install.md"&gt;Installation notes&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/troubleshooting.md"&gt;Troubleshooting Guide&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/tutorials"&gt;Tutorials&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Buildah and Podman relationship&lt;/h2&gt; 
&lt;p&gt;Buildah and Podman are two complementary open-source projects that are available on most Linux platforms and both projects reside at &lt;a href="https://github.com"&gt;GitHub.com&lt;/a&gt; with Buildah &lt;a href="https://github.com/containers/buildah"&gt;here&lt;/a&gt; and Podman &lt;a href="https://github.com/containers/podman"&gt;here&lt;/a&gt;. Both, Buildah and Podman are command line tools that work on Open Container Initiative (OCI) images and containers. The two projects differentiate in their specialization.&lt;/p&gt; 
&lt;p&gt;Buildah specializes in building OCI images. Buildah's commands replicate all of the commands that are found in a Dockerfile. This allows building images with and without Dockerfiles while not requiring any root privileges. Buildah‚Äôs ultimate goal is to provide a lower-level coreutils interface to build images. The flexibility of building images without Dockerfiles allows for the integration of other scripting languages into the build process. Buildah follows a simple fork-exec model and does not run as a daemon but it is based on a comprehensive API in golang, which can be vendored into other tools.&lt;/p&gt; 
&lt;p&gt;Podman specializes in all of the commands and functions that help you to maintain and modify OCI images, such as pulling and tagging. It also allows you to create, run, and maintain those containers created from those images. For building container images via Dockerfiles, Podman uses Buildah's golang API and can be installed independently from Buildah.&lt;/p&gt; 
&lt;p&gt;A major difference between Podman and Buildah is their concept of a container. Podman allows users to create "traditional containers" where the intent of these containers is to be long lived. While Buildah containers are really just created to allow content to be added back to the container image. An easy way to think of it is the &lt;code&gt;buildah run&lt;/code&gt; command emulates the RUN command in a Dockerfile while the &lt;code&gt;podman run&lt;/code&gt; command emulates the &lt;code&gt;docker run&lt;/code&gt; command in functionality. Because of this and their underlying storage differences, you can not see Podman containers from within Buildah or vice versa.&lt;/p&gt; 
&lt;p&gt;In short, Buildah is an efficient way to create OCI images while Podman allows you to manage and maintain those images and containers in a production environment using familiar container cli commands. For more details, see the &lt;a href="https://github.com/containers/buildah/tree/main/docs/containertools"&gt;Container Tools Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;From &lt;a href="https://raw.githubusercontent.com/containers/buildah/main/examples/lighttpd.sh"&gt;&lt;code&gt;./examples/lighttpd.sh&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ cat &amp;gt; lighttpd.sh &amp;lt;&amp;lt;"EOF"
#!/usr/bin/env bash

set -x

ctr1=$(buildah from "${1:-fedora}")

## Get all updates and install our minimal httpd server
buildah run "$ctr1" -- dnf update -y
buildah run "$ctr1" -- dnf install -y lighttpd

## Include some buildtime annotations
buildah config --annotation "com.example.build.host=$(uname -n)" "$ctr1"

## Run our server and expose the port
buildah config --cmd "/usr/sbin/lighttpd -D -f /etc/lighttpd/lighttpd.conf" "$ctr1"
buildah config --port 80 "$ctr1"

## Commit this container to an image name
buildah commit "$ctr1" "${2:-$USER/lighttpd}"
EOF

$ chmod +x lighttpd.sh
$ ./lighttpd.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Commands&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-add.1.md"&gt;buildah-add(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add the contents of a file, URL, or a directory to the container.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-build.1.md"&gt;buildah-build(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Build an image using instructions from Containerfiles or Dockerfiles.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-commit.1.md"&gt;buildah-commit(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Create an image from a working container.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-config.1.md"&gt;buildah-config(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Update image configuration settings.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-containers.1.md"&gt;buildah-containers(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;List the working containers and their base images.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-copy.1.md"&gt;buildah-copy(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Copies the contents of a file, URL, or directory into a container's working directory.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-from.1.md"&gt;buildah-from(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Creates a new working container, either from scratch or using a specified image as a starting point.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-images.1.md"&gt;buildah-images(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;List images in local storage.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-info.1.md"&gt;buildah-info(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Display Buildah system information.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-inspect.1.md"&gt;buildah-inspect(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Inspects the configuration of a container or image.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-mount.1.md"&gt;buildah-mount(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Mount the working container's root filesystem.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-pull.1.md"&gt;buildah-pull(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Pull an image from the specified location.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-push.1.md"&gt;buildah-push(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Push an image from local storage to elsewhere.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-rename.1.md"&gt;buildah-rename(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Rename a local container.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-rm.1.md"&gt;buildah-rm(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Removes one or more working containers.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-rmi.1.md"&gt;buildah-rmi(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Removes one or more images.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-run.1.md"&gt;buildah-run(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Run a command inside of the container.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-tag.1.md"&gt;buildah-tag(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Add an additional name to a local image.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-umount.1.md"&gt;buildah-umount(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Unmount a working container's root file system.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-unshare.1.md"&gt;buildah-unshare(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Launch a command in a user namespace with modified ID mappings.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/containers/buildah/main/docs/buildah-version.1.md"&gt;buildah-version(1)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Display the Buildah Version Information&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Future goals include:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;more CI tests&lt;/li&gt; 
 &lt;li&gt;additional CLI commands (?)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA/nvidia-container-toolkit</title>
      <link>https://github.com/NVIDIA/nvidia-container-toolkit</link>
      <description>&lt;p&gt;Build and run containers leveraging NVIDIA GPUs&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;NVIDIA Container Toolkit&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/nvidia-container-toolkit/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/NVIDIA/nvidia-container-toolkit?style=flat-square" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html"&gt;&lt;img src="https://img.shields.io/badge/documentation-wiki-blue.svg?style=flat-square" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://nvidia.github.io/libnvidia-container"&gt;&lt;img src="https://img.shields.io/badge/packages-repository-b956e8.svg?style=flat-square" alt="Package repository" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://cloud.githubusercontent.com/assets/3028125/12213714/5b208976-b632-11e5-8406-38d379ec46aa.png" alt="nvidia-container-stack" /&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;The NVIDIA Container Toolkit allows users to build and run GPU-accelerated containers. The toolkit includes a container runtime &lt;a href="https://github.com/NVIDIA/libnvidia-container"&gt;library&lt;/a&gt; and utilities to automatically configure containers to leverage NVIDIA GPUs.&lt;/p&gt; 
&lt;p&gt;Product documentation including an architecture overview, platform support, and installation and usage guides can be found in the &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html"&gt;documentation repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Make sure you have installed the &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#nvidia-drivers"&gt;NVIDIA driver&lt;/a&gt; for your Linux Distribution&lt;/strong&gt; &lt;strong&gt;Note that you do not need to install the CUDA Toolkit on the host system, but the NVIDIA driver needs to be installed&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;For instructions on getting started with the NVIDIA Container Toolkit, refer to the &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installation-guide"&gt;installation guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html"&gt;user guide&lt;/a&gt; provides information on the configuration and command line options available when running GPU containers with Docker.&lt;/p&gt; 
&lt;h2&gt;Issues and Contributing&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/nvidia-container-toolkit/main/CONTRIBUTING.md"&gt;Checkout the Contributing document!&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Please let us know by &lt;a href="https://github.com/NVIDIA/nvidia-container-toolkit/issues/new"&gt;filing a new issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;You can contribute by creating a &lt;a href="https://github.com/NVIDIA/nvidia-container-toolkit/compare"&gt;pull request&lt;/a&gt; to our public GitHub repository&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>docker/mcp-registry</title>
      <link>https://github.com/docker/mcp-registry</link>
      <description>&lt;p&gt;Official Docker MCP registry&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üê≥ Official Docker MCP Registry&lt;/h1&gt; 
&lt;p&gt;Welcome to the Official Docker MCP (Model Context Protocol) Registry! This repository serves as a curated catalog of MCP servers that can be easily discovered, deployed, and integrated with any MCP Client and compatible with Docker tooling.&lt;/p&gt; 
&lt;p&gt;Entries in this catalog will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/mcp"&gt;MCP catalog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop's MCP Toolkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/u/mcp"&gt;Docker Hub &lt;code&gt;mcp&lt;/code&gt; namespace&lt;/a&gt; (for MCP servers built by Docker)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ñ What is MCP?&lt;/h2&gt; 
&lt;p&gt;The Model Context Protocol (MCP) is an open standard that enables AI assistants to securely connect with external data sources and tools. Read more at &lt;a href="https://modelcontextprotocol.io/introduction"&gt;MCP Official Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ú® Why Use the Docker MCP Registry?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise Security&lt;/strong&gt;: MCP servers built by Docker include cryptographic signatures, provenance tracking, and Software Bills of Materials (SBOMs) for maximum trust and compliance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Container Isolation&lt;/strong&gt;: All MCP servers run in isolated containers, protecting your host system from potential security vulnerabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Curated Quality&lt;/strong&gt;: All MCP servers undergo review to ensure they meet quality and security standards&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Discovery&lt;/strong&gt;: Browse and find MCP servers for your specific use cases or share yours to millions of developers using Docker tools&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Integration&lt;/strong&gt;: Seamless deployment with Docker containers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contributing to the Docker MCP Registry&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the Official Docker MCP Registry! If you'd like to contribute, you can submit a PR with the metadata information and it will be added to the &lt;a href="https://hub.docker.com/mcp"&gt;MCP catalog&lt;/a&gt;, to &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop's MCP Toolkit&lt;/a&gt;, and (for MCP servers images built by Docker) in &lt;code&gt;mcp&lt;/code&gt; namespace in &lt;a href="https://hub.docker.com/u/mcp"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To add your MCP server to the registry, please review the &lt;a href="https://raw.githubusercontent.com/docker/mcp-registry/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; guide for detailed instructions. We support two types of submissions:&lt;/p&gt; 
&lt;h3&gt;üèóÔ∏è Option A: Docker-Built Image (Recommended)&lt;/h3&gt; 
&lt;p&gt;Have Docker build and maintain your server image with enhanced security features. You'll submit the required information via pull request and upon approval Docker will build, sign, and publish your image to mcp/your-server-name on Docker Hub and the catalog entry will be available in the catalog in 24 hours.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Benefits: Your image will include cryptographic signatures, provenance tracking, SBOMs, and automatic security updates&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;üì¶ Option B: Self-Provided Pre-Built Image&lt;/h3&gt; 
&lt;p&gt;In this option, you'll provide an already built image which will be used directly in the catalog.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note: Self-built images still benefit from container isolation but won't include the enhanced security features of Docker-built images.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;‚úèÔ∏è Modifying or Removing Servers&lt;/h2&gt; 
&lt;p&gt;To request modifications or removal of an existing MCP Server please open an issue explaining the reason for the edit/removal.&lt;/p&gt; 
&lt;h2&gt;‚úÖ Compliance and Quality Standards&lt;/h2&gt; 
&lt;p&gt;All MCP servers in this registry must:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow security best practices&lt;/li&gt; 
 &lt;li&gt;Include comprehensive documentation&lt;/li&gt; 
 &lt;li&gt;Provide working Docker deployment&lt;/li&gt; 
 &lt;li&gt;Maintain compatibility with MCP standards&lt;/li&gt; 
 &lt;li&gt;Include proper error handling and logging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Non-compliant servers will be reviewed and may be removed from the registry.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/docker/mcp-registry/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>onsi/ginkgo</title>
      <link>https://github.com/onsi/ginkgo</link>
      <description>&lt;p&gt;A Modern Testing Framework for Go&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://onsi.github.io/ginkgo/images/ginkgo.png" alt="Ginkgo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/onsi/ginkgo/actions?query=workflow%3Atest+branch%3Amaster"&gt;&lt;img src="https://github.com/onsi/ginkgo/actions/workflows/test.yml/badge.svg?branch=master" alt="test" /&gt;&lt;/a&gt; | &lt;a href="https://onsi.github.io/ginkgo/"&gt;Ginkgo Docs&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Ginkgo&lt;/h1&gt; 
&lt;p&gt;Ginkgo is a mature testing framework for Go designed to help you write expressive specs. Ginkgo builds on top of Go's &lt;code&gt;testing&lt;/code&gt; foundation and is complemented by the &lt;a href="https://github.com/onsi/gomega"&gt;Gomega&lt;/a&gt; matcher library. Together, Ginkgo and Gomega let you express the intent behind your specs clearly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    . "github.com/onsi/ginkgo/v2"
    . "github.com/onsi/gomega"
    ...
)

var _ = Describe("Checking books out of the library", Label("library"), func() {
    var library *libraries.Library
    var book *books.Book
    var valjean *users.User
    BeforeEach(func() {
        library = libraries.NewClient()
        book = &amp;amp;books.Book{
            Title: "Les Miserables",
            Author: "Victor Hugo",
        }
        valjean = users.NewUser("Jean Valjean")
    })

    When("the library has the book in question", func() {
        BeforeEach(func(ctx SpecContext) {
            Expect(library.Store(ctx, book)).To(Succeed())
        })

        Context("and the book is available", func() {
            It("lends it to the reader", func(ctx SpecContext) {
                Expect(valjean.Checkout(ctx, library, "Les Miserables")).To(Succeed())
                Expect(valjean.Books()).To(ContainElement(book))
                Expect(library.UserWithBook(ctx, book)).To(Equal(valjean))
            }, SpecTimeout(time.Second * 5))
        })

        Context("but the book has already been checked out", func() {
            var javert *users.User
            BeforeEach(func(ctx SpecContext) {
                javert = users.NewUser("Javert")
                Expect(javert.Checkout(ctx, library, "Les Miserables")).To(Succeed())
            })

            It("tells the user", func(ctx SpecContext) {
                err := valjean.Checkout(ctx, library, "Les Miserables")
                Expect(err).To(MatchError("Les Miserables is currently checked out"))
            }, SpecTimeout(time.Second * 5))

            It("lets the user place a hold and get notified later", func(ctx SpecContext) {
                Expect(valjean.Hold(ctx, library, "Les Miserables")).To(Succeed())
                Expect(valjean.Holds(ctx)).To(ContainElement(book))

                By("when Javert returns the book")
                Expect(javert.Return(ctx, library, book)).To(Succeed())

                By("it eventually informs Valjean")
                notification := "Les Miserables is ready for pick up"
                Eventually(ctx, valjean.Notifications).Should(ContainElement(notification))

                Expect(valjean.Checkout(ctx, library, "Les Miserables")).To(Succeed())
                Expect(valjean.Books(ctx)).To(ContainElement(book))
                Expect(valjean.Holds(ctx)).To(BeEmpty())
            }, SpecTimeout(time.Second * 10))
        })  
    })

    When("the library does not have the book in question", func() {
        It("tells the reader the book is unavailable", func(ctx SpecContext) {
            err := valjean.Checkout(ctx, library, "Les Miserables")
            Expect(err).To(MatchError("Les Miserables is not in the library catalog"))
        }, SpecTimeout(time.Second * 5))
    })
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Jump to the &lt;a href="https://onsi.github.io/ginkgo/"&gt;docs&lt;/a&gt; to learn more. It's easy to &lt;a href="https://onsi.github.io/ginkgo/#bootstrapping-a-suite"&gt;bootstrap&lt;/a&gt; and start writing your &lt;a href="https://onsi.github.io/ginkgo/#adding-specs-to-a-suite"&gt;first specs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have a question, comment, bug report, feature request, etc. please open a &lt;a href="https://github.com/onsi/ginkgo/issues/new"&gt;GitHub issue&lt;/a&gt;, or visit the &lt;a href="https://app.slack.com/client/T029RQSE6/CQQ50BBNW"&gt;Ginkgo Slack channel&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Capabilities&lt;/h2&gt; 
&lt;p&gt;Whether writing basic unit specs, complex integration specs, or even performance specs - Ginkgo gives you an expressive Domain-Specific Language (DSL) that will be familiar to users coming from frameworks such as &lt;a href="https://github.com/Quick/Quick"&gt;Quick&lt;/a&gt;, &lt;a href="https://rspec.info"&gt;RSpec&lt;/a&gt;, &lt;a href="https://jasmine.github.io"&gt;Jasmine&lt;/a&gt;, and &lt;a href="https://lunarmodules.github.io/busted/"&gt;Busted&lt;/a&gt;. This style of testing is sometimes referred to as "Behavior-Driven Development" (BDD) though Ginkgo's utility extends beyond acceptance-level testing.&lt;/p&gt; 
&lt;p&gt;With Ginkgo's DSL you can use nestable &lt;a href="https://onsi.github.io/ginkgo/#organizing-specs-with-container-nodes"&gt;&lt;code&gt;Describe&lt;/code&gt;, &lt;code&gt;Context&lt;/code&gt; and &lt;code&gt;When&lt;/code&gt; container nodes&lt;/a&gt; to help you organize your specs. &lt;a href="https://onsi.github.io/ginkgo/#extracting-common-setup-beforeeach"&gt;&lt;code&gt;BeforeEach&lt;/code&gt; and &lt;code&gt;AfterEach&lt;/code&gt; setup nodes&lt;/a&gt; for setup and cleanup. &lt;a href="https://onsi.github.io/ginkgo/#spec-subjects-it"&gt;&lt;code&gt;It&lt;/code&gt; and &lt;code&gt;Specify&lt;/code&gt; subject nodes&lt;/a&gt; that hold your assertions. &lt;a href="https://onsi.github.io/ginkgo/#suite-setup-and-cleanup-beforesuite-and-aftersuite"&gt;&lt;code&gt;BeforeSuite&lt;/code&gt; and &lt;code&gt;AfterSuite&lt;/code&gt; nodes&lt;/a&gt; to prep for and cleanup after a suite... and &lt;a href="https://onsi.github.io/ginkgo/#writing-specs"&gt;much more!&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;At runtime, Ginkgo can run your specs in reproducibly &lt;a href="https://onsi.github.io/ginkgo/#spec-randomization"&gt;random order&lt;/a&gt; and has sophisticated support for &lt;a href="https://onsi.github.io/ginkgo/#spec-parallelization"&gt;spec parallelization&lt;/a&gt;. In fact, running specs in parallel is as easy as&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ginkgo -p
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By following &lt;a href="https://onsi.github.io/ginkgo/#patterns-for-parallel-integration-specs"&gt;established patterns for writing parallel specs&lt;/a&gt; you can build even large, complex integration suites that parallelize cleanly and run performantly. And you don't have to worry about your spec suite hanging or leaving a mess behind - Ginkgo provides a per-node &lt;code&gt;context.Context&lt;/code&gt; and the capability to interrupt the spec after a set period of time - and then clean up.&lt;/p&gt; 
&lt;p&gt;As your suites grow Ginkgo helps you keep your specs organized with &lt;a href="https://onsi.github.io/ginkgo/#spec-labels"&gt;labels&lt;/a&gt; and lets you easily run &lt;a href="https://onsi.github.io/ginkgo/#filtering-specs"&gt;subsets of specs&lt;/a&gt;, either &lt;a href="https://onsi.github.io/ginkgo/#focused-specs"&gt;programmatically&lt;/a&gt; or on the &lt;a href="https://onsi.github.io/ginkgo/#combining-filters"&gt;command line&lt;/a&gt;. And Ginkgo's reporting infrastructure generates machine-readable output in a &lt;a href="https://onsi.github.io/ginkgo/#generating-machine-readable-reports"&gt;variety of formats&lt;/a&gt; &lt;em&gt;and&lt;/em&gt; allows you to build your own &lt;a href="https://onsi.github.io/ginkgo/#generating-reports-programmatically"&gt;custom reporting infrastructure&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Ginkgo ships with &lt;code&gt;ginkgo&lt;/code&gt;, a &lt;a href="https://onsi.github.io/ginkgo/#ginkgo-cli-overview"&gt;command line tool&lt;/a&gt; with support for generating, running, filtering, and profiling Ginkgo suites. You can even have Ginkgo automatically run your specs when it detects a change with &lt;code&gt;ginkgo watch&lt;/code&gt;, enabling rapid feedback loops during test-driven development.&lt;/p&gt; 
&lt;p&gt;And that's just Ginkgo! &lt;a href="https://onsi.github.io/gomega/"&gt;Gomega&lt;/a&gt; brings a rich, mature, family of &lt;a href="https://onsi.github.io/gomega/#provided-matchers"&gt;assertions and matchers&lt;/a&gt; to your suites. With Gomega you can easily mix &lt;a href="https://onsi.github.io/ginkgo/#patterns-for-asynchronous-testing"&gt;synchronous and asynchronous assertions&lt;/a&gt; in your specs. You can even build your own set of expressive domain-specific matchers quickly and easily by composing Gomega's &lt;a href="https://onsi.github.io/ginkgo/#building-custom-matchers"&gt;existing building blocks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Happy Testing!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Ginkgo is MIT-Licensed&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/onsi/ginkgo/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Sponsors commit to a &lt;a href="https://github.com/sponsors/onsi"&gt;sponsorship&lt;/a&gt; for a year. If you're an organization that makes use of Ginkgo please consider becoming a sponsor!&lt;/p&gt; 
&lt;p style="font-size:21px; color:black;"&gt;Browser testing via &lt;a href="https://www.lambdatest.com/" target="_blank"&gt; &lt;img src="https://www.lambdatest.com/blue-logo.png" style="vertical-align: middle;" width="250" height="45" /&gt; &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>minio/minio</title>
      <link>https://github.com/minio/minio</link>
      <description>&lt;p&gt;MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MinIO Quickstart Guide&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://slack.min.io"&gt;&lt;img src="https://slack.min.io/slack?type=svg" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/minio/minio/"&gt;&lt;img src="https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL%20V3-blue" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://min.io"&gt;&lt;img src="https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true" alt="MinIO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license. Designed for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;S3 API Compatible ‚Äì Seamless integration with existing S3 tools&lt;/li&gt; 
 &lt;li&gt;Built for AI &amp;amp; Analytics ‚Äì Optimized for large-scale data pipelines&lt;/li&gt; 
 &lt;li&gt;High Performance ‚Äì Ideal for demanding storage workloads.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This README provides instructions for building MinIO from source and deploying onto baremetal hardware. Use the &lt;a href="https://github.com/minio/docs"&gt;MinIO Documentation&lt;/a&gt; project to build and host a local copy of the documentation.&lt;/p&gt; 
&lt;h2&gt;MinIO is Open Source Software&lt;/h2&gt; 
&lt;p&gt;We designed MinIO as Open Source software for the Open Source software community. We encourage the community to remix, redesign, and reshare MinIO under the terms of the AGPLv3 license.&lt;/p&gt; 
&lt;p&gt;All usage of MinIO in your application stack requires validation against AGPLv3 obligations, which include but are not limited to the release of modified code to the community from which you have benefited. Any commercial/proprietary usage of the AGPLv3 software, including repackaging or reselling services/features, is done at your own risk.&lt;/p&gt; 
&lt;p&gt;The AGPLv3 provides no obligation by any party to support, maintain, or warranty the original or any modified work. All support is provided on a best-effort basis through Github and our &lt;a href="https://raw.githubusercontent.com/minio/minio/master/https//slack.min.io"&gt;Slack&lt;/a&gt; channel, and any member of the community is welcome to contribute and assist others in their usage of the software.&lt;/p&gt; 
&lt;p&gt;MinIO &lt;a href="https://www.min.io/product/aistor"&gt;AIStor&lt;/a&gt; includes enterprise-grade support and licensing for workloads which require commercial or proprietary usage and production-level SLA/SLO-backed support. For more information, &lt;a href="https://min.io/pricing"&gt;reach out for a quote&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Source-Only Distribution&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The MinIO community edition is now distributed as source code only. We will no longer provide pre-compiled binary releases for the community version.&lt;/p&gt; 
&lt;h3&gt;Installing Latest MinIO Community Edition&lt;/h3&gt; 
&lt;p&gt;To use MinIO community edition, you have two options:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install from source&lt;/strong&gt; using &lt;code&gt;go install github.com/minio/minio@latest&lt;/code&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build a Docker image&lt;/strong&gt; from the provided Dockerfile&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the sections below for detailed instructions on each method.&lt;/p&gt; 
&lt;h3&gt;Legacy Binary Releases&lt;/h3&gt; 
&lt;p&gt;Historical pre-compiled binary releases remain available for reference but are no longer maintained:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub Releases: &lt;a href="https://github.com/minio/minio/releases"&gt;https://github.com/minio/minio/releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Direct downloads: &lt;a href="https://dl.min.io/server/minio/release/"&gt;https://dl.min.io/server/minio/release/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;These legacy binaries will not receive updates.&lt;/strong&gt; We strongly recommend using source builds for access to the latest features, bug fixes, and security updates.&lt;/p&gt; 
&lt;h2&gt;Install from Source&lt;/h2&gt; 
&lt;p&gt;Use the following commands to compile and run a standalone MinIO server from source. If you do not have a working Golang environment, please follow &lt;a href="https://golang.org/doc/install"&gt;How to install Golang&lt;/a&gt;. Minimum version required is &lt;a href="https://golang.org/dl/#stable"&gt;go1.24&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/minio/minio@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can alternatively run &lt;code&gt;go build&lt;/code&gt; and use the &lt;code&gt;GOOS&lt;/code&gt; and &lt;code&gt;GOARCH&lt;/code&gt; environment variables to control the OS and architecture target. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env GOOS=linux GOARCh=arm64 go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start MinIO by running &lt;code&gt;minio server PATH&lt;/code&gt; where &lt;code&gt;PATH&lt;/code&gt; is any empty folder on your local filesystem.&lt;/p&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://docs.min.io/community/minio-object-store/developers/minio-drivers.html"&gt;https://docs.min.io/community/minio-object-store/developers/minio-drivers.html&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Production environments using compiled-from-source MinIO binaries do so at their own risk. The AGPLv3 license provides no warranties nor liabilites for any such usage.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Build Docker Image&lt;/h2&gt; 
&lt;p&gt;You can use the &lt;code&gt;docker build .&lt;/code&gt; command to build a Docker image on your local host machine. You must first &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#install-from-source"&gt;build MinIO&lt;/a&gt; and ensure the &lt;code&gt;minio&lt;/code&gt; binary exists in the project root.&lt;/p&gt; 
&lt;p&gt;The following command builds the Docker image using the default &lt;code&gt;Dockerfile&lt;/code&gt; in the root project directory with the repository and image tag &lt;code&gt;myminio:minio&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t myminio:minio .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;docker image ls&lt;/code&gt; to confirm the image exists in your local repository. You can run the server using standard Docker invocation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run -p 9000:9000 -p 9001:9001 myminio:minio server /tmp/minio --console-address :9001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Complete documentation for building Docker containers, managing custom images, or loading images into orchestration platforms is out of scope for this documentation. You can modify the &lt;code&gt;Dockerfile&lt;/code&gt; and &lt;code&gt;dockerscripts/docker-entrypoint.sh&lt;/code&gt; as-needed to reflect your specific image requirements.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/baremetal-deploy-minio-as-a-container.html#deploy-minio-container"&gt;MinIO Container&lt;/a&gt; documentation for more guidance on running MinIO within a Container image.&lt;/p&gt; 
&lt;h2&gt;Install using Helm Charts&lt;/h2&gt; 
&lt;p&gt;There are two paths for installing MinIO onto Kubernetes infrastructure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;a href="https://github.com/minio/operator"&gt;MinIO Operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use the community-maintained &lt;a href="https://github.com/minio/minio/tree/master/helm/minio"&gt;Helm charts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/kubernetes.html"&gt;MinIO Documentation&lt;/a&gt; for guidance on deploying using the Operator. The Community Helm chart has instructions in the folder-level README.&lt;/p&gt; 
&lt;h2&gt;Test MinIO Connectivity&lt;/h2&gt; 
&lt;h3&gt;Test using MinIO Console&lt;/h3&gt; 
&lt;p&gt;MinIO Server comes with an embedded web based object browser. Point your web browser to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; to ensure your server has started successfully.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MinIO runs console on random port by default, if you wish to choose a specific port use &lt;code&gt;--console-address&lt;/code&gt; to pick a specific interface and port.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;mc&lt;/code&gt; provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services.&lt;/p&gt; 
&lt;p&gt;The following commands set a local alias, validate the server information, create a bucket, copy data to that bucket, and list the contents of the bucket.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info
mc mb data
mc cp ~/Downloads/mydata data/
mc ls data/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the MinIO Client &lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html#quickstart"&gt;Quickstart Guide&lt;/a&gt; for further instructions.&lt;/p&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/index.html"&gt;The MinIO documentation website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html"&gt;Use &lt;code&gt;mc&lt;/code&gt; with MinIO Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/developers/go/minio-go.html"&gt;Use &lt;code&gt;minio-go&lt;/code&gt; SDK with MinIO Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute to MinIO Project&lt;/h2&gt; 
&lt;p&gt;Please follow MinIO &lt;a href="https://github.com/minio/minio/raw/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt; for guidance on making new contributions to the repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MinIO source is licensed under the &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;GNU AGPLv3&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;MinIO &lt;a href="https://github.com/minio/minio/tree/master/docs"&gt;documentation&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;CC BY 4.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/minio/minio/raw/master/COMPLIANCE.md"&gt;License Compliance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>charmbracelet/bubbletea</title>
      <link>https://github.com/charmbracelet/bubbletea</link>
      <description>&lt;p&gt;A powerful little TUI framework üèó&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Bubble Tea&lt;/h1&gt; 
&lt;p&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://stuff.charm.sh/bubbletea/bubble-tea-v2-light.png" width="308" /&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://stuff.charm.sh/bubbletea/bubble-tea-v2-dark.png" width="312" /&gt; 
  &lt;img src="https://stuff.charm.sh/bubbletea/bubble-tea-v2-light.png" width="308" /&gt; 
 &lt;/picture&gt; &lt;br /&gt; &lt;a href="https://github.com/charmbracelet/bubbletea/releases"&gt;&lt;img src="https://img.shields.io/github/release/charmbracelet/bubbletea.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/charmbracelet/bubbletea?tab=doc"&gt;&lt;img src="https://godoc.org/github.com/charmbracelet/bubbletea?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/charmbracelet/bubbletea/actions"&gt;&lt;img src="https://github.com/charmbracelet/bubbletea/actions/workflows/build.yml/badge.svg?branch=main" alt="Build Status" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;The fun, functional and stateful way to build terminal apps. A Go framework based on &lt;a href="https://guide.elm-lang.org/architecture/"&gt;The Elm Architecture&lt;/a&gt;. Bubble Tea is well-suited for simple and complex terminal applications, either inline, full-window, or a mix of both.&lt;/p&gt; 
&lt;p&gt; &lt;img src="https://stuff.charm.sh/bubbletea/bubbletea-example.gif" width="100%" alt="Bubble Tea Example" /&gt; &lt;/p&gt; 
&lt;p&gt;Bubble Tea is in use in production and includes a number of features and performance optimizations we‚Äôve added along the way. Among those is a framerate-based renderer, mouse support, focus reporting and more.&lt;/p&gt; 
&lt;p&gt;To get started, see the tutorial below, the &lt;a href="https://github.com/charmbracelet/bubbletea/tree/main/examples"&gt;examples&lt;/a&gt;, the &lt;a href="https://pkg.go.dev/github.com/charmbracelet/bubbletea?tab=doc"&gt;docs&lt;/a&gt;, the &lt;a href="https://charm.sh/yt"&gt;video tutorials&lt;/a&gt; and some common &lt;a href="https://raw.githubusercontent.com/charmbracelet/bubbletea/main/#libraries-we-use-with-bubble-tea"&gt;resources&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;By the way&lt;/h2&gt; 
&lt;p&gt;Be sure to check out &lt;a href="https://github.com/charmbracelet/bubbles"&gt;Bubbles&lt;/a&gt;, a library of common UI components for Bubble Tea.&lt;/p&gt; 
&lt;p&gt; &lt;a href="https://github.com/charmbracelet/bubbles"&gt;&lt;img src="https://stuff.charm.sh/bubbles/bubbles-badge.png" width="174" alt="Bubbles Badge" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/charmbracelet/bubbles"&gt;&lt;img src="https://stuff.charm.sh/bubbles-examples/textinput.gif" width="400" alt="Text Input Example from Bubbles" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Tutorial&lt;/h2&gt; 
&lt;p&gt;Bubble Tea is based on the functional design paradigms of &lt;a href="https://guide.elm-lang.org/architecture/"&gt;The Elm Architecture&lt;/a&gt;, which happens to work nicely with Go. It's a delightful way to build applications.&lt;/p&gt; 
&lt;p&gt;This tutorial assumes you have a working knowledge of Go.&lt;/p&gt; 
&lt;p&gt;By the way, the non-annotated source code for this program is available &lt;a href="https://github.com/charmbracelet/bubbletea/tree/main/tutorials/basics"&gt;on GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Enough! Let's get to it.&lt;/h3&gt; 
&lt;p&gt;For this tutorial, we're making a shopping list.&lt;/p&gt; 
&lt;p&gt;To start we'll define our package and import some libraries. Our only external import will be the Bubble Tea library, which we'll call &lt;code&gt;tea&lt;/code&gt; for short.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

// These imports will be used later on the tutorial. If you save the file
// now, Go might complain they are unused, but that's fine.
// You may also need to run `go mod tidy` to download bubbletea and its
// dependencies.
import (
    "fmt"
    "os"

    tea "github.com/charmbracelet/bubbletea"
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Bubble Tea programs are comprised of a &lt;strong&gt;model&lt;/strong&gt; that describes the application state and three simple methods on that model:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Init&lt;/strong&gt;, a function that returns an initial command for the application to run.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update&lt;/strong&gt;, a function that handles incoming events and updates the model accordingly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;View&lt;/strong&gt;, a function that renders the UI based on the data in the model.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;The Model&lt;/h3&gt; 
&lt;p&gt;So let's start by defining our model which will store our application's state. It can be any type, but a &lt;code&gt;struct&lt;/code&gt; usually makes the most sense.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;type model struct {
    choices  []string           // items on the to-do list
    cursor   int                // which to-do list item our cursor is pointing at
    selected map[int]struct{}   // which to-do items are selected
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Initialization&lt;/h3&gt; 
&lt;p&gt;Next, we‚Äôll define our application‚Äôs initial state. In this case, we‚Äôre defining a function to return our initial model, however, we could just as easily define the initial model as a variable elsewhere, too.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func initialModel() model {
	return model{
		// Our to-do list is a grocery list
		choices:  []string{"Buy carrots", "Buy celery", "Buy kohlrabi"},

		// A map which indicates which choices are selected. We're using
		// the  map like a mathematical set. The keys refer to the indexes
		// of the `choices` slice, above.
		selected: make(map[int]struct{}),
	}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Next, we define the &lt;code&gt;Init&lt;/code&gt; method. &lt;code&gt;Init&lt;/code&gt; can return a &lt;code&gt;Cmd&lt;/code&gt; that could perform some initial I/O. For now, we don't need to do any I/O, so for the command, we'll just return &lt;code&gt;nil&lt;/code&gt;, which translates to "no command."&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func (m model) Init() tea.Cmd {
    // Just return `nil`, which means "no I/O right now, please."
    return nil
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;The Update Method&lt;/h3&gt; 
&lt;p&gt;Next up is the update method. The update function is called when ‚Äùthings happen.‚Äù Its job is to look at what has happened and return an updated model in response. It can also return a &lt;code&gt;Cmd&lt;/code&gt; to make more things happen, but for now don't worry about that part.&lt;/p&gt; 
&lt;p&gt;In our case, when a user presses the down arrow, &lt;code&gt;Update&lt;/code&gt;‚Äôs job is to notice that the down arrow was pressed and move the cursor accordingly (or not).&lt;/p&gt; 
&lt;p&gt;The ‚Äúsomething happened‚Äù comes in the form of a &lt;code&gt;Msg&lt;/code&gt;, which can be any type. Messages are the result of some I/O that took place, such as a keypress, timer tick, or a response from a server.&lt;/p&gt; 
&lt;p&gt;We usually figure out which type of &lt;code&gt;Msg&lt;/code&gt; we received with a type switch, but you could also use a type assertion.&lt;/p&gt; 
&lt;p&gt;For now, we'll just deal with &lt;code&gt;tea.KeyMsg&lt;/code&gt; messages, which are automatically sent to the update function when keys are pressed.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func (m model) Update(msg tea.Msg) (tea.Model, tea.Cmd) {
    switch msg := msg.(type) {

    // Is it a key press?
    case tea.KeyMsg:

        // Cool, what was the actual key pressed?
        switch msg.String() {

        // These keys should exit the program.
        case "ctrl+c", "q":
            return m, tea.Quit

        // The "up" and "k" keys move the cursor up
        case "up", "k":
            if m.cursor &amp;gt; 0 {
                m.cursor--
            }

        // The "down" and "j" keys move the cursor down
        case "down", "j":
            if m.cursor &amp;lt; len(m.choices)-1 {
                m.cursor++
            }

        // The "enter" key and the spacebar (a literal space) toggle
        // the selected state for the item that the cursor is pointing at.
        case "enter", " ":
            _, ok := m.selected[m.cursor]
            if ok {
                delete(m.selected, m.cursor)
            } else {
                m.selected[m.cursor] = struct{}{}
            }
        }
    }

    // Return the updated model to the Bubble Tea runtime for processing.
    // Note that we're not returning a command.
    return m, nil
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You may have noticed that &lt;kbd&gt;ctrl+c&lt;/kbd&gt; and &lt;kbd&gt;q&lt;/kbd&gt; above return a &lt;code&gt;tea.Quit&lt;/code&gt; command with the model. That‚Äôs a special command which instructs the Bubble Tea runtime to quit, exiting the program.&lt;/p&gt; 
&lt;h3&gt;The View Method&lt;/h3&gt; 
&lt;p&gt;At last, it‚Äôs time to render our UI. Of all the methods, the view is the simplest. We look at the model in its current state and use it to return a &lt;code&gt;string&lt;/code&gt;. That string is our UI!&lt;/p&gt; 
&lt;p&gt;Because the view describes the entire UI of your application, you don‚Äôt have to worry about redrawing logic and stuff like that. Bubble Tea takes care of it for you.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func (m model) View() string {
    // The header
    s := "What should we buy at the market?\n\n"

    // Iterate over our choices
    for i, choice := range m.choices {

        // Is the cursor pointing at this choice?
        cursor := " " // no cursor
        if m.cursor == i {
            cursor = "&amp;gt;" // cursor!
        }

        // Is this choice selected?
        checked := " " // not selected
        if _, ok := m.selected[i]; ok {
            checked = "x" // selected!
        }

        // Render the row
        s += fmt.Sprintf("%s [%s] %s\n", cursor, checked, choice)
    }

    // The footer
    s += "\nPress q to quit.\n"

    // Send the UI for rendering
    return s
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;All Together Now&lt;/h3&gt; 
&lt;p&gt;The last step is to simply run our program. We pass our initial model to &lt;code&gt;tea.NewProgram&lt;/code&gt; and let it rip:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func main() {
    p := tea.NewProgram(initialModel())
    if _, err := p.Run(); err != nil {
        fmt.Printf("Alas, there's been an error: %v", err)
        os.Exit(1)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What‚Äôs Next?&lt;/h2&gt; 
&lt;p&gt;This tutorial covers the basics of building an interactive terminal UI, but in the real world you'll also need to perform I/O. To learn about that have a look at the &lt;a href="https://github.com/charmbracelet/bubbletea/tree/main/tutorials/commands/"&gt;Command Tutorial&lt;/a&gt;. It's pretty simple.&lt;/p&gt; 
&lt;p&gt;There are also several &lt;a href="https://github.com/charmbracelet/bubbletea/tree/main/examples"&gt;Bubble Tea examples&lt;/a&gt; available and, of course, there are &lt;a href="https://pkg.go.dev/github.com/charmbracelet/bubbletea?tab=doc"&gt;Go Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Debugging&lt;/h2&gt; 
&lt;h3&gt;Debugging with Delve&lt;/h3&gt; 
&lt;p&gt;Since Bubble Tea apps assume control of stdin and stdout, you‚Äôll need to run delve in headless mode and then connect to it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start the debugger
$ dlv debug --headless --api-version=2 --listen=127.0.0.1:43000 .
API server listening at: 127.0.0.1:43000

# Connect to it from another terminal
$ dlv connect 127.0.0.1:43000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you do not explicitly supply the &lt;code&gt;--listen&lt;/code&gt; flag, the port used will vary per run, so passing this in makes the debugger easier to use from a script or your IDE of choice.&lt;/p&gt; 
&lt;p&gt;Additionally, we pass in &lt;code&gt;--api-version=2&lt;/code&gt; because delve defaults to version 1 for backwards compatibility reasons. However, delve recommends using version 2 for all new development and some clients may no longer work with version 1. For more information, see the &lt;a href="https://github.com/go-delve/delve/tree/master/Documentation/api"&gt;Delve documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Logging Stuff&lt;/h3&gt; 
&lt;p&gt;You can‚Äôt really log to stdout with Bubble Tea because your TUI is busy occupying that! You can, however, log to a file by including something like the following prior to starting your Bubble Tea program:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;if len(os.Getenv("DEBUG")) &amp;gt; 0 {
	f, err := tea.LogToFile("debug.log", "debug")
	if err != nil {
		fmt.Println("fatal:", err)
		os.Exit(1)
	}
	defer f.Close()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see what‚Äôs being logged in real time, run &lt;code&gt;tail -f debug.log&lt;/code&gt; while you run your program in another window.&lt;/p&gt; 
&lt;h2&gt;Libraries we use with Bubble Tea&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/bubbles"&gt;Bubbles&lt;/a&gt;: Common Bubble Tea components such as text inputs, viewports, spinners and so on&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/lipgloss"&gt;Lip Gloss&lt;/a&gt;: Style, format and layout tools for terminal applications&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/harmonica"&gt;Harmonica&lt;/a&gt;: A spring animation library for smooth, natural motion&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lrstanley/bubblezone"&gt;BubbleZone&lt;/a&gt;: Easy mouse event tracking for Bubble Tea components&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NimbleMarkets/ntcharts"&gt;ntcharts&lt;/a&gt;: A terminal charting library built for Bubble Tea and &lt;a href="https://github.com/charmbracelet/lipgloss"&gt;Lip Gloss&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Bubble Tea in the Wild&lt;/h2&gt; 
&lt;p&gt;There are over &lt;a href="https://github.com/charmbracelet/bubbletea/network/dependents"&gt;10,000 applications&lt;/a&gt; built with Bubble Tea! Here are a handful of ‚Äôem.&lt;/p&gt; 
&lt;h3&gt;Staff favourites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/twpayne/chezmoi"&gt;chezmoi&lt;/a&gt;: securely manage your dotfiles across multiple machines&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bensadeh/circumflex"&gt;circumflex&lt;/a&gt;: read Hacker News in the terminal&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.github.com/dlvhdr/gh-dash"&gt;gh-dash&lt;/a&gt;: a GitHub CLI extension for PRs and issues&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Broderick-Westrope/tetrigo"&gt;Tetrigo&lt;/a&gt;: Tetris in the terminal&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/emprcl/signls"&gt;Signls&lt;/a&gt;: a generative midi sequencer designed for composition and live performance&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yorukot/superfile"&gt;Superfile&lt;/a&gt;: a super file manager&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;In Industry&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Microsoft Azure ‚Äì&amp;nbsp;&lt;a href="https://github.com/Azure/aztfy"&gt;Aztify&lt;/a&gt;: bring Microsoft Azure resources under Terraform&lt;/li&gt; 
 &lt;li&gt;Daytona ‚Äì&amp;nbsp;&lt;a href="https://github.com/daytonaio/daytona"&gt;Daytona&lt;/a&gt;: open source dev environment manager&lt;/li&gt; 
 &lt;li&gt;Cockroach Labs ‚Äì &lt;a href="https://github.com/cockroachdb/cockroach"&gt;CockroachDB&lt;/a&gt;: a cloud-native, high-availability distributed SQL database&lt;/li&gt; 
 &lt;li&gt;Truffle Security Co. ‚Äì&amp;nbsp;&lt;a href="https://github.com/trufflesecurity/trufflehog"&gt;Trufflehog&lt;/a&gt;: find leaked credentials&lt;/li&gt; 
 &lt;li&gt;NVIDIA ‚Äì&amp;nbsp;&lt;a href="https://github.com/NVIDIA/container-canary"&gt;container-canary&lt;/a&gt;: a container validator&lt;/li&gt; 
 &lt;li&gt;AWS ‚Äì&amp;nbsp;&lt;a href="https://github.com/awslabs/eks-node-viewer"&gt;eks-node-viewer&lt;/a&gt;: a tool for visualizing dynamic node usage within an EKS cluster&lt;/li&gt; 
 &lt;li&gt;MinIO ‚Äì&amp;nbsp;&lt;a href="https://github.com/minio/mc"&gt;mc&lt;/a&gt;: the official &lt;a href="https://min.io"&gt;MinIO&lt;/a&gt; client&lt;/li&gt; 
 &lt;li&gt;Ubuntu ‚Äì&amp;nbsp;&lt;a href="https://github.com/ubuntu/authd"&gt;Authd&lt;/a&gt;: an authentication daemon for cloud-based identity providers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Charm stuff&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/glow"&gt;Glow&lt;/a&gt;: a markdown reader, browser, and online markdown stash&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/huh"&gt;Huh?&lt;/a&gt;: an interactive prompt and form toolkit&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/mods"&gt;Mods&lt;/a&gt;: AI on the CLI, built for pipelines&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/wishlist"&gt;Wishlist&lt;/a&gt;: an SSH directory (and bastion!)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;There‚Äôs so much more where that came from&lt;/h3&gt; 
&lt;p&gt;For more applications built with Bubble Tea see &lt;a href="https://github.com/charm-and-friends/charm-in-the-wild"&gt;Charm &amp;amp; Friends&lt;/a&gt;. Is there something cool you made with Bubble Tea you want to share? &lt;a href="https://github.com/charm-and-friends/charm-in-the-wild"&gt;PRs&lt;/a&gt; are welcome!&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/charmbracelet/bubbletea/contribute"&gt;contributing&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feedback&lt;/h2&gt; 
&lt;p&gt;We‚Äôd love to hear your thoughts on this project. Feel free to drop us a note!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/charmcli"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@charmcli"&gt;The Fediverse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.sh/chat"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Bubble Tea is based on the paradigms of &lt;a href="https://guide.elm-lang.org/architecture/"&gt;The Elm Architecture&lt;/a&gt; by Evan Czaplicki et alia and the excellent &lt;a href="https://github.com/tj/go-tea"&gt;go-tea&lt;/a&gt; by TJ Holowaychuk. It‚Äôs inspired by the many great &lt;a href="https://de.wikipedia.org/wiki/Zeichenorientierte_Benutzerschnittstelle"&gt;&lt;em&gt;Zeichenorientierte Benutzerschnittstellen&lt;/em&gt;&lt;/a&gt; of days past.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/bubbletea/raw/main/LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Part of &lt;a href="https://charm.sh"&gt;Charm&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://charm.sh/"&gt;&lt;img alt="The Charm logo" src="https://stuff.charm.sh/charm-banner-next.jpg" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source ‚Ä¢ ŸÜÿ≠ŸÜŸè ŸÜÿ≠ÿ® ÿßŸÑŸÖÿµÿßÿØÿ± ÿßŸÑŸÖŸÅÿ™Ÿàÿ≠ÿ©&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>litmuschaos/litmus</title>
      <link>https://github.com/litmuschaos/litmus</link>
      <description>&lt;p&gt;Litmus helps SREs and developers practice chaos engineering in a Cloud-native way. Chaos experiments are published at the ChaosHub (https://hub.litmuschaos.io). Community notes is at https://hackmd.io/a4Zu_sH4TZGeih-xCimi3Q&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://litmuschaos.io/"&gt;LitmusChaos&lt;/a&gt;&lt;/h1&gt; 
&lt;img alt="LitmusChaos" src="https://avatars.githubusercontent.com/u/49853472?s=200&amp;amp;v=4" width="200" align="left" /&gt; 
&lt;h3&gt;Open Source Chaos Engineering Platform&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://slack.litmuschaos.io"&gt;&lt;img src="https://img.shields.io/badge/Slack-Join-purple" alt="Slack Channel" /&gt;&lt;/a&gt; &lt;img src="https://github.com/litmuschaos/litmus/actions/workflows/push.yml/badge.svg?branch=master" alt="GitHub Workflow" /&gt; &lt;a href="https://hub.docker.com/r/litmuschaos/chaos-operator"&gt;&lt;img src="https://img.shields.io/docker/pulls/litmuschaos/chaos-operator.svg?sanitize=true" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/litmuschaos/litmus/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/litmuschaos/litmus?style=social" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/litmuschaos/litmus/issues"&gt;&lt;img src="https://img.shields.io/github/issues/litmuschaos/litmus" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/LitmusChaos"&gt;&lt;img src="https://img.shields.io/twitter/follow/litmuschaos?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/3202"&gt;&lt;img src="https://www.bestpractices.dev/projects/3202/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.io/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus?ref=badge_shield"&gt;&lt;img src="https://app.fossa.io/api/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/channel/UCa57PMqmz_j0wnteRa9nCaw"&gt;&lt;img src="https://img.shields.io/badge/YouTube-Subscribe-red" alt="YouTube Channel" /&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/litmuschaos"&gt;&lt;img src="https://img.shields.io/badge/Gurubase-Ask%20LitmusChaos%20Guru-006BFF" alt="Gurubase" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;em&gt;Read this in &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/TRANSLATIONS.md"&gt;other languages&lt;/a&gt;.&lt;/em&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-ko.md"&gt;üá∞üá∑&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-chn.md"&gt;üá®üá≥&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-pt-br.md"&gt;üáßüá∑&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-hi.md"&gt;üáÆüá≥&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;LitmusChaos is an open source Chaos Engineering platform that enables teams to identify weaknesses &amp;amp; potential outages in infrastructures by inducing chaos tests in a controlled way. Developers &amp;amp; SREs can practice Chaos Engineering with LitmusChaos as it is easy to use, based on modern Chaos Engineering principles &amp;amp; community collaborated. It is 100% open source &amp;amp; a CNCF project.&lt;/p&gt; 
&lt;p&gt;LitmusChaos takes a cloud-native approach to create, manage and monitor chaos. The platform itself runs as a set of microservices and uses Kubernetes custom resources (CRs) to define the chaos intent, as well as the steady state hypothesis.&lt;/p&gt; 
&lt;p&gt;At a high-level, Litmus comprises of:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Chaos Control Plane&lt;/strong&gt;: A centralized chaos management tool called chaos-center, which helps construct, schedule and visualize Litmus chaos workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chaos Execution Plane Services&lt;/strong&gt;: Made up of a chaos agent and multiple operators that execute &amp;amp; monitor the experiment within a defined target Kubernetes environment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/litmuschaos/litmus/master/images/litmus-control-and-execution-plane-overview.png" alt="architecture summary" /&gt;&lt;/p&gt; 
&lt;p&gt;At the heart of the platform are the following chaos custom resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ChaosExperiment&lt;/strong&gt;: A resource to group the configuration parameters of a particular fault. ChaosExperiment CRs are essentially installable templates that describe the library carrying out the fault, indicate permissions needed to run it &amp;amp; the defaults it will operate with. Through the ChaosExperiment, Litmus supports BYOC (bring-your-own-chaos) that helps integrate (optional) any third-party tooling to perform the fault injection.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ChaosEngine&lt;/strong&gt;: A resource to link a Kubernetes application workload/service, node or an infra component to a fault described by the ChaosExperiment. It also provides options to tune the run properties and specify the steady state validation constraints using 'probes'. ChaosEngine is watched by the Chaos-Operator, which reconciles it (triggers experiment execution) via runners.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The ChaosExperiment &amp;amp; ChaosEngine CRs are embedded within a Workflow object that can string together one or more experiments in a desired order.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ChaosResult&lt;/strong&gt;: A resource to hold the results of the experiment run. It provides details of the success of each validation constraint, the revert/rollback status of the fault as well as a verdict. The Chaos-exporter reads the results and exposes information as prometheus metrics. ChaosResults are especially useful during automated runs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ChaosExperiment CRs are hosted on &lt;a href="https://hub.litmuschaos.io" target="_blank"&gt;hub.litmuschaos.io&lt;/a&gt;. It is a central hub where the application developers or vendors share their chaos experiments so that their users can use them to increase the resilience of the applications in production.&lt;/p&gt; 
&lt;h2&gt;Use cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;For Developers&lt;/strong&gt;: To run chaos experiments during application development as an extension of unit testing or integration testing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For CI/CD pipeline builders&lt;/strong&gt;: To run chaos as a pipeline stage to find bugs when the application is subjected to fail paths in a pipeline.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For SREs&lt;/strong&gt;: To plan and schedule chaos experiments into the application and/or surrounding infrastructure. This practice identifies the weaknesses in the deployment system and increases resilience.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started with Litmus&lt;/h2&gt; 
&lt;p&gt;To get started, check out the &lt;a href="https://docs.litmuschaos.io/docs/introduction/what-is-litmus" target="_blank"&gt;Litmus Docs&lt;/a&gt; and specifically the &lt;a href="https://docs.litmuschaos.io/docs/getting-started/installation#prerequisites" target="_blank"&gt;Installation section&lt;/a&gt; of the &lt;a href="https://docs.litmuschaos.io/docs/getting-started/installation" target="_blank"&gt;Getting Started with Litmus&lt;/a&gt; page.&lt;/p&gt; 
&lt;h2&gt;Contributing to Chaos Hub&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/litmuschaos/community-charts/raw/master/CONTRIBUTING.md" target="_blank"&gt;Contributing Guidelines for the Chaos Hub&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;h3&gt;Community Resources:&lt;/h3&gt; 
&lt;p&gt;Feel free to reach out if you have any queries,concerns, or feature requests&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Give us a star ‚≠êÔ∏è - If you are using LitmusChaos or think it is an interesting project, we would love a star ‚ù§Ô∏è&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Follow LitmusChaos on Twitter &lt;a href="https://twitter.com/LitmusChaos"&gt;@LitmusChaos&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Subscribe to the &lt;a href="https://www.youtube.com/channel/UCa57PMqmz_j0wnteRa9nCaw"&gt;LitmusChaos YouTube channel&lt;/a&gt; for regular updates &amp;amp; meeting recordings.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To join our &lt;a href="https://slack.litmuschaos.io/"&gt;Slack Community&lt;/a&gt; and meet our community members, put forward your questions &amp;amp; opinions, join the #litmus channel on the &lt;a href="https://slack.k8s.io/"&gt;Kubernetes Slack&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community Meetings&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Community Meetings&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;These will be hosted every 3rd Wednesday of every month at 5:30 PM GMT /6:30 PM CEST /10 PM IST&lt;/li&gt; 
 &lt;li&gt;These meetings cover community updates, new feature or release announcements, and user/adopter stories. Everyone in the community is welcome to join and participate in discussions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Contributor Meetings&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;These will be hosted every second &amp;amp; last Thursday of every month at 2:30 PM GMT /3:30 PM CEST /7 PM IST&lt;/li&gt; 
 &lt;li&gt;These meetings focus on both technical and non-technical contributions to LitmusChaos. Maintainers, current contributors, and aspiring contributors are encouraged to join to discuss issues, fixes, enhancements, and future contributions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Fill out the &lt;a href="https://forms.gle/qawjtFUeL431jmpv7"&gt;LitmusChaos Meetings invite form&lt;/a&gt; to get your Calendar invite!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hackmd.io/a4Zu_sH4TZGeih-xCimi3Q"&gt;Sync Up Agenda &amp;amp; Meeting Notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/litmuschaos/litmus/milestones"&gt;Release Tracker&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Videos&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=3mjGEh905u4&amp;amp;t=1s"&gt;What if Your System Experiences an Outage? Let's Build a Resilient Systems with Chaos Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/BelNIk4Bkng"&gt;Enhancing Cyber Resilience Through Zero Trust Chaos Experiments in Cloud Native Environments&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ks2R57hhFZk&amp;amp;t=503s"&gt;LitmusChaos, with Karthik Satchitanand&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@TheKubernetesPodcast"&gt;The Kubernetes Podcast from Google&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=WUXFKxgZRsk"&gt;Cultural Shifts: Fostering a Chaos First Mindset in Platform Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=xCDQp5E3VUs"&gt;Fire in the Cloud: Bringing Managed Services Under the Ambit of Cloud-Native Chaos Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=whCkvLKAw74"&gt;Security Controls for Safe Chaos Experimentation&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=BZL-ngvbpbU&amp;amp;t=751s"&gt;Chaos Engineering For Hybrid Targets With LitmusChaos&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/hOghvd9qCzI"&gt;Cloud Native Live: Litmus Chaos Engine and a microservices demo app&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/_x_7SiesjF0"&gt;Chaos Engineering hands-on - An SRE ideating Chaos Experiments and using LitmusChaos | July 2022&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/PQrmBHgk0ps"&gt;Achieve Digital Product Resiliency with Chaos Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/KSl-oKk6TPA"&gt;Case Study: Bringing Chaos Engineering to the Cloud Native Developers&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ItUUqejdXr0"&gt;Cloud Native Chaos Engineering with LitmusChaos&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/mwu5eLgUKq4"&gt;How to create Chaos Experiments with Litmus | Litmus Chaos tutorial&lt;/a&gt; @ &lt;a href="https://www.youtube.com/c/IsitObservable"&gt;Is it Observable&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/pMWqhS-F3tQ"&gt;Cloud Native Chaos Engineering Preview With LitmusChaos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/5CI8d-SKBfc"&gt;Get started with Chaos Engineering with Litmus&lt;/a&gt; @ &lt;a href="https://www.youtube.com/c/ContainersfromtheCouch"&gt;Containers from the Couch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/B8DfYnDh2F4"&gt;Litmus 2 - Chaos Engineering Meets Argo Workflows&lt;/a&gt; @ &lt;a href="https://youtube.com/c/devopstoolkit"&gt;DevOps Toolkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/D0t3emVLLko"&gt;Hands-on with Litmus 2.0 | Rawkode Live&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCrber_mFvp_FEF7D9u8PDEA"&gt;Rawkode Academy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/97BiCNtJbDw"&gt;Introducing LitmusChaos 2.0 / Dok Talks #74&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCUnXJbHQ89R2uSfKsqQwGvQ"&gt;DoK.community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/LK0oDLQE4S8"&gt;Introduction to Cloud Native Chaos Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCBGOUQHNNtNGcGzVq5rIXjw"&gt;Kunal Kushwaha&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/IiyrEiK4stQ"&gt;#EveryoneCanContribute cafe: Litmus - Chaos Engineering for your Kubernetes&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCMtZ0sc1HHNtGGWZFDRTh5A"&gt;GitLab Unfiltered&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/rDQ9XKbSJIc"&gt;Litmus - Chaos Engineering for Kubernetes (CNCFMinutes 9)&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCi-1nnN0eC9nRleXdZA6ncg"&gt;Saiyam Pathak&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/eyAG0svCsQA"&gt;Chaos Engineering with Litmus Chaos by Prithvi Raj || HACKODISHA Workshop&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UC9yM_PkV0QIIsPA3qPrp"&gt;Webwiz&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/channel/UCa57PMqmz_j0wnteRa9nCaw"&gt;And More....&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Blogs&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CNCF: &lt;a href="https://www.cncf.io/blog/2020/08/28/introduction-to-litmuschaos/"&gt;Introduction to LitmusChaos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hackernoon: &lt;a href="https://hackernoon.com/solid-tips-on-how-to-manage-and-monitor-chaos-via-litmus-custom-resources-5g1s33m9"&gt;Manage and Monitor Chaos via Litmus Custom Resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dev.to/ksatchit/observability-considerations-in-chaos-the-metrics-story-6cb"&gt;Observability Considerations in Chaos: The Metrics Story&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Community Blogs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LiveWyer: &lt;a href="https://livewyer.io/blog/2021/03/22/litmuschaos-showcase-chaos-experiments-in-a-helm-chart-test-suite/"&gt;LitmusChaos Showcase: Chaos Experiments in a Helm Chart Test Suite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Jessica Cherry: &lt;a href="https://opensource.com/article/21/6/kubernetes-litmus-chaos"&gt;Test Kubernetes cluster failures and experiments in your terminal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Yang Chuansheng(KubeSphere): &lt;a href="https://kubesphere.io/zh/blogs/litmus-kubesphere/"&gt;KubeSphere ÈÉ®ÁΩ≤ Litmus Ëá≥ Kubernetes ÂºÄÂêØÊ∑∑Ê≤åÂÆûÈ™å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Saiyam Pathak(Civo): &lt;a href="https://www.civo.com/learn/chaos-engineering-kubernetes-litmus"&gt;Chaos Experiments on Kubernetes using Litmus to ensure your cluster is production ready&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Andreas Krivas(Container Solutions):&lt;a href="https://blog.container-solutions.com/comparing-chaos-engineering-tools"&gt;Comparing Chaos Engineering Tools for Kubernetes Workloads&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Akram Riahi(WeScale):&lt;a href="https://blog.wescale.fr/2021/03/11/chaos-engineering-litmus-sous-tous-les-angles/"&gt;Chaos Engineering : Litmus sous tous les angles&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Prashanto Priyanshu(LensKart):&lt;a href="https://blog.lenskart.com/lenskarts-approach-to-chaos-engineering-part-2-6290e4f3a74e"&gt;Lenskart‚Äôs approach to Chaos Engineering-Part 2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DevsDay.ru(Russian):&lt;a href="https://devsday.ru/blog/details/40746"&gt;LitmusChaos at Kubecon EU '21&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/litmuschaos/litmus/raw/master/ADOPTERS.md" target="_blank"&gt;Adopters of LitmusChaos&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;(&lt;em&gt;Send a PR to the above page if you are using Litmus in your chaos engineering practice&lt;/em&gt;)&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Litmus is licensed under the Apache License, Version 2.0. See &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/LICENSE"&gt;LICENSE&lt;/a&gt; for the full license text. Some of the projects used by the Litmus project may be governed by a different license, please refer to its specific license.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.io/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus?ref=badge_large"&gt;&lt;img src="https://app.fossa.io/api/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus.svg?type=large" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Litmus Chaos is part of the CNCF Projects.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://landscape.cncf.io/?selected=litmus"&gt;&lt;img src="https://github.com/cncf/artwork/raw/main/other/cncf/horizontal/color/cncf-color.png" alt="CNCF" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Important Links&lt;/h2&gt; 
&lt;a href="https://docs.litmuschaos.io"&gt; Litmus Docs &lt;img src="https://avatars0.githubusercontent.com/u/49853472?s=200&amp;amp;v=4" alt="Litmus Docs" height="15" /&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;a href="https://landscape.cncf.io/?selected=litmus"&gt; CNCF Landscape &lt;img src="https://landscape.cncf.io/images/cncf-landscape-horizontal-color.svg?sanitize=true" alt="Litmus on CNCF Landscape" height="15" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>hashicorp/vault</title>
      <link>https://github.com/hashicorp/vault</link>
      <description>&lt;p&gt;A tool for secrets management, encryption as a service, and privileged access management&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Vault &lt;a href="https://github.com/hashicorp/vault/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/hashicorp/vault/actions/workflows/build.yml/badge.svg?sanitize=true" alt="build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hashicorp/vault/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/hashicorp/vault/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="ci" /&gt;&lt;/a&gt; &lt;a href="https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=banner&amp;amp;utm_campaign=github-vault-enterprise"&gt;&lt;img src="https://img.shields.io/badge/vault-enterprise-yellow.svg?colorB=7c8797&amp;amp;colorA=000000" alt="vault enterprise" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Please note&lt;/strong&gt;: We take Vault's security and our users' trust very seriously. If you believe you have found a security issue in Vault, &lt;em&gt;please responsibly disclose&lt;/em&gt; by contacting us at &lt;a href="mailto:security@hashicorp.com"&gt;security@hashicorp.com&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;Website: &lt;a href="https://developer.hashicorp.com/vault"&gt;developer.hashicorp.com/vault&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Announcement list: &lt;a href="https://groups.google.com/group/hashicorp-announce"&gt;Google Groups&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discussion forum: &lt;a href="https://discuss.hashicorp.com/c/vault"&gt;Discuss&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://developer.hashicorp.com/vault/docs"&gt;https://developer.hashicorp.com/vault/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tutorials: &lt;a href="https://developer.hashicorp.com/vault/tutorials"&gt;https://developer.hashicorp.com/vault/tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Certification exam: &lt;a href="https://developer.hashicorp.com/certifications/security-automation"&gt;https://developer.hashicorp.com/certifications/security-automation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation source: &lt;a href="https://github.com/hashicorp/web-unified-docs"&gt;https://github.com/hashicorp/web-unified-docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img width="300" alt="Vault Logo" src="https://github.com/hashicorp/vault/raw/f22d202cde2018f9455dec755118a9b84586e082/Vault_PrimaryLogo_Black.png" /&gt; 
&lt;p&gt;Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, and more. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log.&lt;/p&gt; 
&lt;p&gt;A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where Vault steps in.&lt;/p&gt; 
&lt;p&gt;The key features of Vault are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secure Secret Storage&lt;/strong&gt;: Vault can store arbitrary key/value pairs. Vault encrypts data before writing it to persistent storage, so gaining access to the raw storage isn't enough to access your secrets. Vault can write to disk, &lt;a href="https://www.consul.io"&gt;Consul&lt;/a&gt;, and more.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Secrets&lt;/strong&gt;: Vault can generate secrets on-demand for some systems, such as AWS or SQL databases. For example, when an application needs to access an S3 bucket, it asks Vault for credentials, and Vault will generate an AWS keypair with valid permissions on demand. After creating these dynamic secrets, Vault will also automatically revoke them after the lease is up.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: Vault can encrypt and decrypt data without storing it. This allows security teams to define encryption parameters and developers to store encrypted data in a location such as a SQL database without having to design their own encryption methods.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Leasing and Renewal&lt;/strong&gt;: Vault associates a &lt;strong&gt;lease&lt;/strong&gt; with each secret. At the end of the lease, Vault automatically revokes the secret. Clients are able to renew leases via built-in renew APIs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revocation&lt;/strong&gt;: Vault has built-in support for secret revocation. Vault can revoke not only single secrets, but a tree of secrets, for example, all secrets read by a specific user, or all secrets of a particular type. Revocation assists in key rolling as well as locking down systems in the case of an intrusion.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation, Getting Started, and Certification Exams&lt;/h2&gt; 
&lt;p&gt;Documentation is available on the &lt;a href="https://developer.hashicorp.com/vault/docs"&gt;Vault website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you're new to Vault and want to get started with security automation, please check out our &lt;a href="https://learn.hashicorp.com/collections/vault/getting-started"&gt;Getting Started guides&lt;/a&gt; on HashiCorp's learning platform. There are also &lt;a href="https://learn.hashicorp.com/vault"&gt;additional guides&lt;/a&gt; to continue your learning.&lt;/p&gt; 
&lt;p&gt;For examples of how to interact with Vault from inside your application in different programming languages, see the &lt;a href="https://github.com/hashicorp/vault-examples"&gt;vault-examples&lt;/a&gt; repo. An out-of-the-box &lt;a href="https://github.com/hashicorp/hello-vault-go"&gt;sample application&lt;/a&gt; is also available.&lt;/p&gt; 
&lt;p&gt;Show off your Vault knowledge by passing a certification exam. Visit the &lt;a href="https://www.hashicorp.com/certification/#hashicorp-certified-vault-associate"&gt;certification page&lt;/a&gt; for information about exams and find &lt;a href="https://learn.hashicorp.com/collections/vault/certification"&gt;study materials&lt;/a&gt; on HashiCorp's learning platform.&lt;/p&gt; 
&lt;h2&gt;Developing Vault&lt;/h2&gt; 
&lt;p&gt;If you wish to work on Vault itself or any of its built-in systems, you'll first need &lt;a href="https://www.golang.org"&gt;Go&lt;/a&gt; installed on your machine.&lt;/p&gt; 
&lt;p&gt;For local dev first make sure Go is properly installed, including setting up a &lt;a href="https://golang.org/doc/code.html#GOPATH"&gt;GOPATH&lt;/a&gt;, then setting the &lt;a href="https://pkg.go.dev/cmd/go#hdr-Environment_variables"&gt;GOBIN&lt;/a&gt; variable to &lt;code&gt;$GOPATH/bin&lt;/code&gt;. Ensure that &lt;code&gt;$GOPATH/bin&lt;/code&gt; is in your path as some distributions bundle the old version of build tools.&lt;/p&gt; 
&lt;p&gt;Next, clone this repository. Vault uses &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;Go Modules&lt;/a&gt;, so it is recommended that you clone the repository &lt;em&gt;&lt;strong&gt;outside&lt;/strong&gt;&lt;/em&gt; of the GOPATH. You can then download any required build tools by bootstrapping your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make bootstrap
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault, run &lt;code&gt;make&lt;/code&gt; or &lt;code&gt;make dev&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make dev
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault with the UI, run &lt;code&gt;make static-dist dev-ui&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make static-dist dev-ui
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run tests, type &lt;code&gt;make test&lt;/code&gt;. Note: this requires Docker to be installed. If this exits with exit status 0, then everything is working!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're developing a specific package, you can run tests for just that package by specifying the &lt;code&gt;TEST&lt;/code&gt; variable. For example below, only &lt;code&gt;vault&lt;/code&gt; package tests will be run.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test TEST=./vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;If you encounter an error like &lt;code&gt;could not read Username for 'https://github.com'&lt;/code&gt; you may need to adjust your git config like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ git config --global --add url."git@github.com:".insteadOf "https://github.com/"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Importing Vault&lt;/h3&gt; 
&lt;p&gt;This repository publishes two libraries that may be imported by other projects: &lt;code&gt;github.com/hashicorp/vault/api&lt;/code&gt; and &lt;code&gt;github.com/hashicorp/vault/sdk&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that this repository also contains Vault (the product), and as with most Go projects, Vault uses Go modules to manage its dependencies. The mechanism to do that is the &lt;a href="https://raw.githubusercontent.com/hashicorp/vault/main/go.mod"&gt;go.mod&lt;/a&gt; file. As it happens, the presence of that file also makes it theoretically possible to import Vault as a dependency into other projects. Some other projects have made a practice of doing so in order to take advantage of testing tooling that was developed for testing Vault itself. This is not, and has never been, a supported way to use the Vault project. We aren't likely to fix bugs relating to failure to import &lt;code&gt;github.com/hashicorp/vault&lt;/code&gt; into your project.&lt;/p&gt; 
&lt;p&gt;See also the section "Docker-based tests" below.&lt;/p&gt; 
&lt;h3&gt;Acceptance Tests&lt;/h3&gt; 
&lt;p&gt;Vault has comprehensive &lt;a href="https://en.wikipedia.org/wiki/Acceptance_testing"&gt;acceptance tests&lt;/a&gt; covering most of the features of the secret and auth methods.&lt;/p&gt; 
&lt;p&gt;If you're working on a feature of a secret or auth method and want to verify it is functioning (and also hasn't broken anything else), we recommend running the acceptance tests.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; The acceptance tests create/destroy/modify &lt;em&gt;real resources&lt;/em&gt;, which may incur real costs in some cases. In the presence of a bug, it is technically possible that broken backends could leave dangling data behind. Therefore, please run the acceptance tests at your own risk. At the very least, we recommend running them in their own private account for whatever backend you're testing.&lt;/p&gt; 
&lt;p&gt;To run the acceptance tests, invoke &lt;code&gt;make testacc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make testacc TEST=./builtin/logical/consul
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;TEST&lt;/code&gt; variable is required, and you should specify the folder where the backend is. The &lt;code&gt;TESTARGS&lt;/code&gt; variable is recommended to filter down to a specific resource to test, since testing all of them at once can sometimes take a very long time.&lt;/p&gt; 
&lt;p&gt;Acceptance tests typically require other environment variables to be set for things such as access keys. The test itself should error early and tell you what to set, so it is not documented here.&lt;/p&gt; 
&lt;p&gt;For more information on Vault Enterprise features, visit the &lt;a href="https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=github-vault-enterprise"&gt;Vault Enterprise site&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker-based Tests&lt;/h3&gt; 
&lt;p&gt;We have created an experimental new testing mechanism inspired by NewTestCluster. An example of how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  "testing"
  "github.com/hashicorp/vault/sdk/helper/testcluster/docker"
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: "hashicorp/vault", // or "hashicorp/vault-enterprise"
    ImageTag:    "latest",
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
  
  client := cluster.Nodes()[0].APIClient()
  _, err := client.Logical().Read("sys/storage/raft/configuration")
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or for Enterprise:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  "testing"
  "github.com/hashicorp/vault/sdk/helper/testcluster/docker"
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: "hashicorp/vault-enterprise",
    ImageTag:  "latest",
	VaultLicense: licenseString, // not a path, the actual license bytes
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here is a more realistic example of how we use it in practice. DefaultOptions uses &lt;code&gt;hashicorp/vault&lt;/code&gt;:&lt;code&gt;latest&lt;/code&gt; as the repo and tag, but it also looks at the environment variable VAULT_BINARY. If populated, it will copy the local file referenced by VAULT_BINARY into the container. This is useful when testing local changes.&lt;/p&gt; 
&lt;p&gt;Instead of setting the VaultLicense option, you can set the VAULT_LICENSE_CI environment variable, which is better than committing a license to version control.&lt;/p&gt; 
&lt;p&gt;Optionally you can set COMMIT_SHA, which will be appended to the image name we build as a debugging convenience.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func Test_Custom_Build_With_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are a variety of helpers in the &lt;code&gt;github.com/hashicorp/vault/sdk/helper/testcluster&lt;/code&gt; package, e.g. these tests below will create a pair of 3-node clusters and link them using PR or DR replication respectively, and fail if the replication state doesn't become healthy before the passed context expires.&lt;/p&gt; 
&lt;p&gt;Again, as written, these depend on having a Vault Enterprise binary locally and the env var VAULT_BINARY set to point to it, as well as having VAULT_LICENSE_CI set.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func TestStandardPerfReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
      t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardPerfReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}

func TestStandardDRReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
    t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardDRReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, here's an example of running an existing OSS docker test with a custom binary:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ GOOS=linux make dev
$ VAULT_BINARY=$(pwd)/bin/vault go test -run 'TestRaft_Configuration_Docker' ./vault/external_tests/raft/raft_binary
ok      github.com/hashicorp/vault/vault/external_tests/raft/raft_binary        20.960s
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>seaweedfs/seaweedfs</title>
      <link>https://github.com/seaweedfs/seaweedfs</link>
      <description>&lt;p&gt;SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeaweedFS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;&lt;img src="https://img.shields.io/badge/slack-purple" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=seaweedfs"&gt;&lt;img src="https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;amp;label=Follow" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/seaweedfs/seaweedfs/weed"&gt;&lt;img src="https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;&lt;img src="https://img.shields.io/badge/docs-wiki-blue.svg?sanitize=true" alt="Wiki" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/search?q=g:com.github.chrislusf"&gt;&lt;img src="https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client" alt="SeaweedFS on Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=seaweedfs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png" alt="SeaweedFS Logo" /&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt;&lt;a href="https://www.patreon.com/seaweedfs"&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;SeaweedFS is an independent Apache-licensed open source project with its ongoing development made possible entirely thanks to the support of these awesome &lt;a href="https://github.com/seaweedfs/seaweedfs/raw/master/backers.md"&gt;backers&lt;/a&gt;. If you'd like to grow SeaweedFS even stronger, please consider joining our &lt;a href="https://www.patreon.com/seaweedfs"&gt;sponsors on Patreon&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your support will be really appreciated by me and other supporters!&lt;/p&gt; 
&lt;!--
&lt;h4 align="center"&gt;Platinum&lt;/h4&gt;

&lt;p align="center"&gt;
  &lt;a href="" target="_blank"&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.nodion.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png" alt="nodion" /&gt;&lt;/a&gt; &lt;a href="https://www.piknik.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png" alt="piknik" /&gt;&lt;/a&gt; &lt;a href="https://www.keepsec.ca"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png" alt="keepsec" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/releases/latest"&gt;Download Binaries for different platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;SeaweedFS on Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/SeaweedFS"&gt;SeaweedFS on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/Seaweedfs"&gt;SeaweedFS on Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/SeaweedFS/"&gt;SeaweedFS on Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/d/forum/seaweedfs"&gt;SeaweedFS Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;Wiki Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf"&gt;SeaweedFS White Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2025.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2021.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/chrislusf/seaweedfs-introduction"&gt;SeaweedFS Introduction Slides 2019.3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-for-s3-api-on-docker"&gt;Quick Start for S3 API on Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-single-binary"&gt;Quick Start with Single Binary&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-seaweedfs-s3-on-aws"&gt;Quick Start SeaweedFS S3 on AWS&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#additional-features"&gt;Additional Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#filer-features"&gt;Filer Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#example-using-seaweed-object-store"&gt;Example: Using Seaweed Object Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#object-store-architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-other-file-systems"&gt;Compared to Other File Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-hdfs"&gt;Compared to HDFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs-ceph"&gt;Compared to GlusterFS, Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs"&gt;Compared to GlusterFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-ceph"&gt;Compared to Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-minio"&gt;Compared to Minio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#dev-plan"&gt;Dev Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#installation-guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#disk-related-topics"&gt;Disk Related Topics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#benchmark"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#enterprise"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;h2&gt;Quick Start for S3 API on Docker&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker run -p 8333:8333 chrislusf/seaweedfs server -s3&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start with Single Binary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;. Or run &lt;code&gt;go install github.com/seaweedfs/seaweedfs/weed@latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key&lt;/code&gt; as the admin credentials to access the object store.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;weed server -dir=/some/data/dir -s3&lt;/code&gt; to start one master, one volume server, one filer, and one S3 gateway.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, to increase capacity, just add more volume servers by running &lt;code&gt;weed volume -dir="/some/data/dir2" -mserver="&amp;lt;master_host&amp;gt;:9333" -port=8081&lt;/code&gt; locally, or on a different machine, or on thousands of machines. That is it!&lt;/p&gt; 
&lt;h2&gt;Quick Start SeaweedFS S3 on AWS&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setup fast production-ready &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc"&gt;SeaweedFS S3 on AWS with cloudformation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;to store billions of files!&lt;/li&gt; 
 &lt;li&gt;to serve the files fast!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;SeaweedFS started as an Object Store to handle small files efficiently. Instead of managing all file metadata in a central master, the central master only manages volumes on volume servers, and these volume servers manage files and their metadata. This relieves concurrency pressure from the central master and spreads file metadata into volume servers, allowing faster file access (O(1), usually just one disk read operation).&lt;/p&gt; 
&lt;p&gt;There is only 40 bytes of disk storage overhead for each file's metadata. It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.&lt;/p&gt; 
&lt;p&gt;SeaweedFS started by implementing &lt;a href="http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook's Haystack design paper&lt;/a&gt;. Also, SeaweedFS implements erasure coding with ideas from &lt;a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf"&gt;f4: Facebook‚Äôs Warm BLOB Storage System&lt;/a&gt;, and has a lot of similarities with &lt;a href="https://www.usenix.org/system/files/fast21-pan.pdf"&gt;Facebook‚Äôs Tectonic Filesystem&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On top of the object store, optional &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer&lt;/a&gt; can support directories and POSIX attributes. Filer is a separate linearly-scalable stateless server with customizable metadata stores, e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.&lt;/p&gt; 
&lt;p&gt;For any distributed key value stores, the large values can be offloaded to SeaweedFS. With the fast access speed and linearly scalable capacity, SeaweedFS can work as a distributed &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store"&gt;Key-Large-Value store&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can transparently integrate with the cloud. With hot data on local cluster, and warm data on the cloud with O(1) access time, SeaweedFS can achieve both fast local access time and elastic cloud storage capacity. What's more, the cloud storage access API cost is minimized. Faster and cheaper than direct cloud storage!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Can choose no replication or different replication levels, rack and data center aware.&lt;/li&gt; 
 &lt;li&gt;Automatic master servers failover - no single point of failure (SPOF).&lt;/li&gt; 
 &lt;li&gt;Automatic Gzip compression depending on file MIME type.&lt;/li&gt; 
 &lt;li&gt;Automatic compaction to reclaim disk space after deletion or update.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live"&gt;Automatic entry TTL expiration&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Any server with some disk space can add to the total storage space.&lt;/li&gt; 
 &lt;li&gt;Adding/Removing servers does &lt;strong&gt;not&lt;/strong&gt; cause any data re-balancing unless triggered by admin commands.&lt;/li&gt; 
 &lt;li&gt;Optional picture resizing.&lt;/li&gt; 
 &lt;li&gt;Support ETag, Accept-Range, Last-Modified, etc.&lt;/li&gt; 
 &lt;li&gt;Support in-memory/leveldb/readonly mode tuning for memory/performance balance.&lt;/li&gt; 
 &lt;li&gt;Support rebalancing the writable and readonly volumes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage"&gt;Customizable Multiple Storage Tiers&lt;/a&gt;: Customizable storage disk types to balance performance and cost.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier"&gt;Transparent cloud integration&lt;/a&gt;: unlimited capacity via tiered cloud storage for warm data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage"&gt;Erasure Coding for warm storage&lt;/a&gt; Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filer Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer server&lt;/a&gt; provides "normal" directories and files via HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores"&gt;File TTL&lt;/a&gt; automatically expires file metadata and actual file data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount"&gt;Mount filer&lt;/a&gt; reads and writes files directly as a local directory via FUSE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication"&gt;Filer Store Replication&lt;/a&gt; enables HA for filer meta data stores.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization"&gt;Active-Active Replication&lt;/a&gt; enables asynchronous one-way or two-way cross cluster continuous replication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API"&gt;Amazon S3 compatible API&lt;/a&gt; accesses files with S3 tooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System"&gt;Hadoop Compatible File System&lt;/a&gt; accesses files from Hadoop/Spark/Flink/etc or even runs HBase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud"&gt;Async Replication To Cloud&lt;/a&gt; has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/WebDAV"&gt;WebDAV&lt;/a&gt; accesses as a mapped drive on Mac and Windows, or from mobile devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption"&gt;AES256-GCM Encrypted Storage&lt;/a&gt; safely stores the encrypted data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files"&gt;Super Large Files&lt;/a&gt; stores large or super large files in tens of TB.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt; mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage"&gt;Gateway to Remote Object Store&lt;/a&gt; mirrors bucket operations to remote object storage, in addition to &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Kubernetes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-csi-driver"&gt;Kubernetes CSI Driver&lt;/a&gt; A Container Storage Interface (CSI) Driver. &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-operator"&gt;SeaweedFS Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example: Using Seaweed Object Store&lt;/h2&gt; 
&lt;p&gt;By default, the master node runs on port 9333, and the volume nodes run on port 8080. Let's start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We'll use localhost as an example.&lt;/p&gt; 
&lt;p&gt;SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.&lt;/p&gt; 
&lt;h3&gt;Start Master Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; ./weed master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Volume Servers&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; weed volume -dir="/tmp/data1" -max=5  -mserver="localhost:9333" -port=8080 &amp;amp;
&amp;gt; weed volume -dir="/tmp/data2" -max=10 -mserver="localhost:9333" -port=8081 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write File&lt;/h3&gt; 
&lt;p&gt;To upload a file: first, send a HTTP POST, PUT, or GET request to &lt;code&gt;/dir/assign&lt;/code&gt; to get an &lt;code&gt;fid&lt;/code&gt; and a volume server URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/assign
{"count":1,"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Second, to store the file content, send a HTTP multi-part POST request to &lt;code&gt;url + '/' + fid&lt;/code&gt; from the response:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{"name":"myphoto.jpg","size":43234,"eTag":"1cc0118e"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update, send another POST request with updated file content.&lt;/p&gt; 
&lt;p&gt;For deletion, send an HTTP DELETE request to the same &lt;code&gt;url + '/' + fid&lt;/code&gt; URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Save File Id&lt;/h3&gt; 
&lt;p&gt;Now, you can save the &lt;code&gt;fid&lt;/code&gt;, 3,01637037d6 in this case, to a database field.&lt;/p&gt; 
&lt;p&gt;The number 3 at the start represents a volume id. After the comma, it's one file key, 01, and a file cookie, 637037d6.&lt;/p&gt; 
&lt;p&gt;The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.&lt;/p&gt; 
&lt;p&gt;The file key and file cookie are both coded in hex. You can store the &amp;lt;volume id, file key, file cookie&amp;gt; tuple in your own format, or simply store the &lt;code&gt;fid&lt;/code&gt; as a string.&lt;/p&gt; 
&lt;p&gt;If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.&lt;/p&gt; 
&lt;p&gt;If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.&lt;/p&gt; 
&lt;h3&gt;Read File&lt;/h3&gt; 
&lt;p&gt;Here is an example of how to render the URL.&lt;/p&gt; 
&lt;p&gt;First look up the volume server's URLs by the file's volumeId:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/lookup?volumeId=3
{"volumeId":"3","locations":[{"publicUrl":"localhost:8080","url":"localhost:8080"}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since (usually) there are not too many volume servers, and volumes don't move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.&lt;/p&gt; 
&lt;p&gt;Now you can take the public URL, render the URL or directly read from the volume server via URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3,01637037d6.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notice we add a file extension ".jpg" here. It's optional and just one way for the client to specify the file content type.&lt;/p&gt; 
&lt;p&gt;If you want a nicer URL, you can use one of these alternative URL formats:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to get a scaled version of an image, you can add some params:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fill
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rack-Aware and Data Center-Aware Replication&lt;/h3&gt; 
&lt;p&gt;SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:9333/dir/assign?replication=001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication parameter options are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about replication can be found &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Replication"&gt;on the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also set the default replication strategy when starting the master server.&lt;/p&gt; 
&lt;h3&gt;Allocate File Key on Specific Data Center&lt;/h3&gt; 
&lt;p&gt;Volume servers can be started with a specific data center name:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When requesting a file key, an optional "dataCenter" parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to 'dc1':&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:9333/dir/assign?dataCenter=dc1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server"&gt;No Single Point of Failure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys"&gt;Insert with your own keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files"&gt;Chunking large files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space"&gt;Collection as a Simple Name Space&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Object Store Architecture&lt;/h2&gt; 
&lt;p&gt;Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.&lt;/p&gt; 
&lt;p&gt;The main drawback is that the central master can't handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.&lt;/p&gt; 
&lt;p&gt;Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.&lt;/p&gt; 
&lt;p&gt;The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.&lt;/p&gt; 
&lt;p&gt;For comparison, consider that an xfs inode structure in Linux is 536 bytes.&lt;/p&gt; 
&lt;h3&gt;Master Server and Volume Server&lt;/h3&gt; 
&lt;p&gt;The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.&lt;/p&gt; 
&lt;p&gt;All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.&lt;/p&gt; 
&lt;p&gt;On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.&lt;/p&gt; 
&lt;h3&gt;Write and Read files&lt;/h3&gt; 
&lt;p&gt;When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.&lt;/p&gt; 
&lt;p&gt;When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages and let browsers fetch the content.&lt;/p&gt; 
&lt;p&gt;Please see the example for details on the write-read process.&lt;/p&gt; 
&lt;h3&gt;Storage Size&lt;/h3&gt; 
&lt;p&gt;In the current implementation, each volume can hold 32 gibibytes (32GiB or 8x2^32 bytes). This is because we align content to 8 bytes. We can easily increase this to 64GiB, or 128GiB, or more, by changing 2 lines of code, at the cost of some wasted padding space due to alignment.&lt;/p&gt; 
&lt;p&gt;There can be 4 gibibytes (4GiB or 2^32 bytes) of volumes. So the total system size is 8 x 4GiB x 4GiB which is 128 exbibytes (128EiB or 2^67 bytes).&lt;/p&gt; 
&lt;p&gt;Each individual file size is limited to the volume size.&lt;/p&gt; 
&lt;h3&gt;Saving memory&lt;/h3&gt; 
&lt;p&gt;All file meta information stored on a volume server is readable from memory without disk access. Each file takes just a 16-byte map entry of &amp;lt;64bit key, 32bit offset, 32bit size&amp;gt;. Of course, each map entry has its own space cost for the map. But usually the disk space runs out before the memory does.&lt;/p&gt; 
&lt;h3&gt;Tiered Storage to the cloud&lt;/h3&gt; 
&lt;p&gt;The local volume servers are much faster, while cloud storages have elastic capacity and are actually more cost-efficient if not accessed often (usually free to upload, but relatively costly to access). With the append-only structure and O(1) access time, SeaweedFS can take advantage of both local and cloud storage by offloading the warm data to the cloud.&lt;/p&gt; 
&lt;p&gt;Usually hot data are fresh and warm data are old. SeaweedFS puts the newly created volumes on local servers, and optionally upload the older volumes on the cloud. If the older data are accessed less often, this literally gives you unlimited capacity with limited local servers, and still fast for new data.&lt;/p&gt; 
&lt;p&gt;With the O(1) access time, the network latency cost is kept at minimum.&lt;/p&gt; 
&lt;p&gt;If the hot/warm data is split as 20/80, with 20 servers, you can achieve storage capacity of 100 servers. That's a cost saving of 80%! Or you can repurpose the 80 servers to store new data also, and get 5X storage throughput.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compared to Other File Systems&lt;/h2&gt; 
&lt;p&gt;Most other distributed file systems seem more complicated than necessary.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is meant to be fast and simple, in both setup and operation. If you do not understand how it works when you reach here, we've failed! Please raise an issue with any questions or update this file with clarifications.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is constantly moving forward. Same with other systems. These comparisons can be outdated quickly. Please help to keep them updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to HDFS&lt;/h3&gt; 
&lt;p&gt;HDFS uses the chunk approach for each file, and is ideal for storing large files.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is ideal for serving relatively smaller files quickly and concurrently.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can also store extra large files by splitting them into manageable data chunks, and store the file ids of the data chunks into a meta chunk. This is managed by "weed upload/download" tool, and the weed master or volume servers are agnostic about it.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS, Ceph&lt;/h3&gt; 
&lt;p&gt;The architectures are mostly the same. SeaweedFS aims to store and read files fast, with a simple and flat architecture. The main differences are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SeaweedFS optimizes for small files, ensuring O(1) disk seek operation, and can also handle large files.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS statically assigns a volume id for a file. Locating file content becomes just a lookup of the volume id, which can be easily cached.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Filer metadata store can be any well-known and proven data store, e.g., Redis, Cassandra, HBase, Mongodb, Elastic Search, MySql, Postgres, Sqlite, MemSql, TiDB, CockroachDB, Etcd, YDB etc, and is easy to customize.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Volume server also communicates directly with clients via HTTP, supporting range queries, direct uploads, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;File Metadata&lt;/th&gt; 
   &lt;th&gt;File Content Read&lt;/th&gt; 
   &lt;th&gt;POSIX&lt;/th&gt; 
   &lt;th&gt;REST API&lt;/th&gt; 
   &lt;th&gt;Optimized for large number of small files&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS&lt;/td&gt; 
   &lt;td&gt;lookup volume id, cacheable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS Filer&lt;/td&gt; 
   &lt;td&gt;Linearly Scalable, Customizable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GlusterFS&lt;/td&gt; 
   &lt;td&gt;hashing&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE, NFS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ceph&lt;/td&gt; 
   &lt;td&gt;hashing + rules&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MooseFS&lt;/td&gt; 
   &lt;td&gt;in memory&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinIO&lt;/td&gt; 
   &lt;td&gt;separate meta file for each file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS&lt;/h3&gt; 
&lt;p&gt;GlusterFS stores files, both directories and content, in configurable volumes called "bricks".&lt;/p&gt; 
&lt;p&gt;GlusterFS hashes the path and filename into ids, and assigned to virtual volumes, and then mapped to "bricks".&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MooseFS&lt;/h3&gt; 
&lt;p&gt;MooseFS chooses to neglect small file issue. From moosefs 3.0 manual, "even a small file will occupy 64KiB plus additionally 4KiB of checksums and 1KiB for the header", because it "was initially designed for keeping large amounts (like several thousands) of very big files"&lt;/p&gt; 
&lt;p&gt;MooseFS Master Server keeps all meta data in memory. Same issue as HDFS namenode.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to Ceph&lt;/h3&gt; 
&lt;p&gt;Ceph can be setup similar to SeaweedFS as a key-&amp;gt;blob store. It is much more complicated, with the need to support layers on top of it. &lt;a href="https://github.com/seaweedfs/seaweedfs/issues/120"&gt;Here is a more detailed comparison&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;SeaweedFS has a centralized master group to look up free volumes, while Ceph uses hashing and metadata servers to locate its objects. Having a centralized master makes it easy to code and manage.&lt;/p&gt; 
&lt;p&gt;Ceph, like SeaweedFS, is based on the object store RADOS. Ceph is rather complicated with mixed reviews.&lt;/p&gt; 
&lt;p&gt;Ceph uses CRUSH hashing to automatically manage data placement, which is efficient to locate the data. But the data has to be placed according to the CRUSH algorithm. Any wrong configuration would cause data loss. Topology changes, such as adding new servers to increase capacity, will cause data migration with high IO cost to fit the CRUSH algorithm. SeaweedFS places data by assigning them to any writable volumes. If writes to one volume failed, just pick another volume to write. Adding more volumes is also as simple as it can be.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is optimized for small files. Small files are stored as one continuous block of content, with at most 8 unused bytes between files. Small file access is O(1) disk read.&lt;/p&gt; 
&lt;p&gt;SeaweedFS Filer uses off-the-shelf stores, such as MySql, Postgres, Sqlite, Mongodb, Redis, Elastic Search, Cassandra, HBase, MemSql, TiDB, CockroachCB, Etcd, YDB, to manage file directories. These stores are proven, scalable, and easier to manage.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SeaweedFS&lt;/th&gt; 
   &lt;th&gt;comparable to Ceph&lt;/th&gt; 
   &lt;th&gt;advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Master&lt;/td&gt; 
   &lt;td&gt;MDS&lt;/td&gt; 
   &lt;td&gt;simpler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volume&lt;/td&gt; 
   &lt;td&gt;OSD&lt;/td&gt; 
   &lt;td&gt;optimized for small files&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filer&lt;/td&gt; 
   &lt;td&gt;Ceph FS&lt;/td&gt; 
   &lt;td&gt;linearly scalable, Customizable, O(1) or O(logN)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MinIO&lt;/h3&gt; 
&lt;p&gt;MinIO follows AWS S3 closely and is ideal for testing for S3 API. It has good UI, policies, versionings, etc. SeaweedFS is trying to catch up here. It is also possible to put MinIO as a gateway in front of SeaweedFS later.&lt;/p&gt; 
&lt;p&gt;MinIO metadata are in simple files. Each file write will incur extra writes to corresponding meta file.&lt;/p&gt; 
&lt;p&gt;MinIO does not have optimization for lots of small files. The files are simply stored as is to local disks. Plus the extra meta file and shards for erasure coding, it only amplifies the LOSF problem.&lt;/p&gt; 
&lt;p&gt;MinIO has multiple disk IO to read one file. SeaweedFS has O(1) disk reads, even for erasure coded files.&lt;/p&gt; 
&lt;p&gt;MinIO has full-time erasure coding. SeaweedFS uses replication on hot data for faster speed and optionally applies erasure coding on warm data.&lt;/p&gt; 
&lt;p&gt;MinIO does not have POSIX-like API support.&lt;/p&gt; 
&lt;p&gt;MinIO has specific requirements on storage layout. It is not flexible to adjust capacity. In SeaweedFS, just start one volume server pointing to the master. That's all.&lt;/p&gt; 
&lt;h2&gt;Dev Plan&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More tools and documentation, on how to manage and scale the system.&lt;/li&gt; 
 &lt;li&gt;Read and write stream data.&lt;/li&gt; 
 &lt;li&gt;Support structured data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is a super exciting project! And we need helpers and &lt;a href="https://www.patreon.com/seaweedfs"&gt;support&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Installation guide for users who are not familiar with golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Step 1: install go on your machine and setup the environment by following the instructions at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://golang.org/doc/install"&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;make sure to define your $GOPATH&lt;/p&gt; 
&lt;p&gt;Step 2: checkout this repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/seaweedfs/seaweedfs.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step 3: download, compile, and install the project by executing the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd seaweedfs/weed &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this is done, you will find the executable "weed" in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disk Related Topics&lt;/h2&gt; 
&lt;h3&gt;Hard Drive Performance&lt;/h3&gt; 
&lt;p&gt;When testing read performance on SeaweedFS, it basically becomes a performance test of your hard drive's random read speed. Hard drives usually get 100MB/s~200MB/s.&lt;/p&gt; 
&lt;h3&gt;Solid State Disk&lt;/h3&gt; 
&lt;p&gt;To modify or delete small files, SSD must delete a whole block at a time, and move content in existing blocks to a new block. SSD is fast when brand new, but will get fragmented over time and you have to garbage collect, compacting blocks. SeaweedFS is friendly to SSD since it is append-only. Deletion and compaction are done on volume level in the background, not slowing reading and not causing fragmentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;My Own Unscientific Single Machine Results on Mac Book with Solid State Disk, CPU: 1 Intel Core i7 2.6GHz.&lt;/p&gt; 
&lt;p&gt;Write 1 million 1KB file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   66.753 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106789009 bytes
Requests per second:    15708.23 [#/sec]
Transfer rate:          16191.69 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.3      1.0       84.3      0.9

Percentage of the requests served within a certain time (ms)
   50%      0.8 ms
   66%      1.0 ms
   75%      1.1 ms
   80%      1.2 ms
   90%      1.4 ms
   95%      1.7 ms
   98%      2.1 ms
   99%      2.6 ms
  100%     84.3 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Randomly read 1 million files:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   22.301 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106812873 bytes
Requests per second:    47019.38 [#/sec]
Transfer rate:          48467.57 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.0      0.3       54.1      0.2

Percentage of the requests served within a certain time (ms)
   50%      0.3 ms
   90%      0.4 ms
   98%      0.6 ms
   99%      0.7 ms
  100%     54.1 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run WARP and launch a mixed benchmark.&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make benchmark
warp: Benchmark data written to "warp-mixed-2023-10-16[102354]-l70a.csv.zst"                                                                                                                                                                                               
Mixed operations.
Operation: DELETE, 10%, Concurrency: 20, Ran 4m59s.
 * Throughput: 6.19 obj/s

Operation: GET, 45%, Concurrency: 20, Ran 5m0s.
 * Throughput: 279.85 MiB/s, 27.99 obj/s

Operation: PUT, 15%, Concurrency: 20, Ran 5m0s.
 * Throughput: 89.86 MiB/s, 8.99 obj/s

Operation: STAT, 30%, Concurrency: 20, Ran 5m0s.
 * Throughput: 18.63 obj/s

Cluster Total: 369.74 MiB/s, 61.79 obj/s, 0 errors over 5m0s.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see segmented request statistics, use the --analyze.v parameter.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;warp analyze --analyze.v warp-mixed-2023-10-16[102354]-l70a.csv.zst
18642 operations loaded... Done!
Mixed operations.
----------------------------------------
Operation: DELETE - total: 1854, 10.0%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 6.19 obj/s

Requests considered: 1855:
 * Avg: 104ms, 50%: 30ms, 90%: 207ms, 99%: 1.355s, Fastest: 1ms, Slowest: 4.613s, StdDev: 320ms

----------------------------------------
Operation: GET - total: 8388, 45.3%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.12 +0500 +05
 * Throughput: 279.77 MiB/s, 27.98 obj/s

Requests considered: 8389:
 * Avg: 221ms, 50%: 106ms, 90%: 492ms, 99%: 1.739s, Fastest: 8ms, Slowest: 8.633s, StdDev: 383ms
 * TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 171ms, 99th: 669ms, Worst: 4.783s StdDev: 163ms
 * First Access: Avg: 240ms, 50%: 105ms, 90%: 511ms, 99%: 2.08s, Fastest: 12ms, Slowest: 8.633s, StdDev: 480ms
 * First Access TTFB: Avg: 88ms, Best: 2ms, 25th: 24ms, Median: 38ms, 75th: 64ms, 90th: 179ms, 99th: 919ms, Worst: 4.783s StdDev: 199ms
 * Last Access: Avg: 219ms, 50%: 106ms, 90%: 463ms, 99%: 1.782s, Fastest: 9ms, Slowest: 8.633s, StdDev: 416ms
 * Last Access TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 161ms, 99th: 657ms, Worst: 4.783s StdDev: 176ms

----------------------------------------
Operation: PUT - total: 2688, 14.5%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 89.83 MiB/s, 8.98 obj/s

Requests considered: 2689:
 * Avg: 1.165s, 50%: 878ms, 90%: 2.015s, 99%: 5.74s, Fastest: 99ms, Slowest: 8.264s, StdDev: 968ms

----------------------------------------
Operation: STAT - total: 5586, 30.2%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.113 +0500 +05
 * Throughput: 18.63 obj/s

Requests considered: 5587:
 * Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 80ms, Fastest: 0s, Slowest: 245ms, StdDev: 17ms
 * First Access: Avg: 14ms, 50%: 10ms, 90%: 33ms, 99%: 69ms, Fastest: 0s, Slowest: 203ms, StdDev: 16ms
 * Last Access: Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 74ms, Fastest: 0s, Slowest: 203ms, StdDev: 17ms

Cluster Total: 369.64 MiB/s, 61.77 obj/s, 0 errors over 5m0s.
Total Errors:0.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;For enterprise users, please visit &lt;a href="https://seaweedfs.com"&gt;seaweedfs.com&lt;/a&gt; for the SeaweedFS Enterprise Edition, which has a self-healing storage format with better data protection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;p&gt;The text of this page is available for modification and reuse under the terms of the Creative Commons Attribution-Sharealike 3.0 Unported License and the GNU Free Documentation License (unversioned, with no invariant sections, front-cover texts, or back-cover texts).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/chrislusf/seaweedfs"&gt;&lt;img src="https://starchart.cc/chrislusf/seaweedfs.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>etcd-io/etcd</title>
      <link>https://github.com/etcd-io/etcd</link>
      <description>&lt;p&gt;Distributed reliable key-value store for the most critical data of a distributed system&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;etcd&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/etcd-io/etcd"&gt;&lt;img src="https://goreportcard.com/badge/github.com/etcd-io/etcd?style=flat-square" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://app.codecov.io/gh/etcd-io/etcd/tree/main"&gt;&lt;img src="https://codecov.io/gh/etcd-io/etcd/branch/main/graph/badge.svg?sanitize=true" alt="Coverage" /&gt;&lt;/a&gt; &lt;a href="https://github.com/etcd-io/etcd/actions/workflows/tests.yaml"&gt;&lt;img src="https://github.com/etcd-io/etcd/actions/workflows/tests.yaml/badge.svg?sanitize=true" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/etcd-io/etcd/actions/workflows/codeql-analysis.yml"&gt;&lt;img src="https://github.com/etcd-io/etcd/actions/workflows/codeql-analysis.yml/badge.svg?sanitize=true" alt="codeql-analysis" /&gt;&lt;/a&gt; &lt;a href="https://etcd.io/docs"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-green.svg?sanitize=true" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://godocs.io/go.etcd.io/etcd/v3"&gt;&lt;img src="http://img.shields.io/badge/go-documentation-blue.svg?style=flat-square" alt="Godoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/etcd-io/etcd/releases"&gt;&lt;img src="https://img.shields.io/github/release/etcd-io/etcd/all.svg?style=flat-square" alt="Releases" /&gt;&lt;/a&gt; &lt;a href="https://github.com/etcd-io/etcd/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/etcd-io/etcd.svg?style=flat-square" alt="LICENSE" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/etcd-io/etcd"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/etcd-io/etcd/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;main&lt;/code&gt; branch may be in an &lt;em&gt;unstable or even broken state&lt;/em&gt; during development. For stable versions, see &lt;a href="https://github.com/etcd-io/etcd/releases"&gt;releases&lt;/a&gt;.&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/cncf/artwork/9870640f123303a355611065195c43ac3f27aa19/projects/etcd/horizontal/white/etcd-horizontal-white.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="logos/etcd-horizontal-color.svg" /&gt; 
 &lt;img alt="etcd logo" src="https://raw.githubusercontent.com/etcd-io/etcd/main/logos/etcd-horizontal-color.svg?sanitize=true" width="269" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;etcd is a distributed reliable key-value store for the most critical data of a distributed system, with a focus on being:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;Simple&lt;/em&gt;: well-defined, user-facing API (gRPC)&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Secure&lt;/em&gt;: automatic TLS with optional client cert authentication&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Fast&lt;/em&gt;: benchmarked 10,000 writes/sec&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Reliable&lt;/em&gt;: properly distributed using Raft&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;etcd is written in Go and uses the &lt;a href="https://raft.github.io/"&gt;Raft&lt;/a&gt; consensus algorithm to manage a highly-available replicated log.&lt;/p&gt; 
&lt;p&gt;etcd is used &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/ADOPTERS.md"&gt;in production by many companies&lt;/a&gt;, and the development team stands behind it in critical deployment scenarios, where etcd is frequently teamed with applications such as &lt;a href="http://kubernetes.io/"&gt;Kubernetes&lt;/a&gt;, &lt;a href="https://github.com/coreos/locksmith"&gt;locksmith&lt;/a&gt;, &lt;a href="https://github.com/vulcand/vulcand"&gt;vulcand&lt;/a&gt;, &lt;a href="https://github.com/youtube/doorman"&gt;Doorman&lt;/a&gt;, and many others. Reliability is further ensured by rigorous &lt;a href="https://github.com/etcd-io/etcd/tree/main/tests/robustness"&gt;&lt;strong&gt;robustness testing&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/etcd-io/etcd/tree/main/etcdctl"&gt;etcdctl&lt;/a&gt; for a simple command line client.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/etcd-io/etcd/main/logos/etcd-xkcd-2347.png" alt="etcd reliability is important" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;sub&gt;Original image credited to xkcd.com/2347, alterations by Josh Berkus.&lt;/sub&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The most common API documentation you'll need can be found here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/api/v3"&gt;go.etcd.io/etcd/api/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/client/pkg/v3"&gt;go.etcd.io/etcd/client/pkg/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/client/v3"&gt;go.etcd.io/etcd/client/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/etcdctl/v3"&gt;go.etcd.io/etcd/etcdctl/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/pkg/v3"&gt;go.etcd.io/etcd/pkg/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/raft/v3"&gt;go.etcd.io/etcd/raft/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/server/v3"&gt;go.etcd.io/etcd/server/v3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Maintainers&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/OWNERS"&gt;Maintainers&lt;/a&gt; strive to shape an inclusive open source project culture where users are heard and contributors feel respected and empowered. Maintainers aim to build productive relationships across different companies and disciplines. Read more about &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/Documentation/contributor-guide/community-membership.md#maintainers"&gt;Maintainers role and responsibilities&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;h3&gt;Getting etcd&lt;/h3&gt; 
&lt;p&gt;The easiest way to get etcd is to use one of the pre-built release binaries which are available for OSX, Linux, Windows, and Docker on the &lt;a href="https://github.com/etcd-io/etcd/releases"&gt;release page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more installation guides, please check out &lt;a href="http://play.etcd.io"&gt;play.etcd.io&lt;/a&gt; and &lt;a href="https://etcd.io/docs/latest/op-guide"&gt;operating etcd&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Running etcd&lt;/h3&gt; 
&lt;p&gt;First start a single-member cluster of etcd.&lt;/p&gt; 
&lt;p&gt;If etcd is installed using the &lt;a href="https://github.com/etcd-io/etcd/releases"&gt;pre-built release binaries&lt;/a&gt;, run it from the installation location as below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/tmp/etcd-download-test/etcd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The etcd command can be simply run as such if it is moved to the system path as below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mv /tmp/etcd-download-test/etcd /usr/local/bin/
etcd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will bring up etcd listening on port 2379 for client communication and on port 2380 for server-to-server communication.&lt;/p&gt; 
&lt;p&gt;Next, let's set a single key, and then retrieve it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;etcdctl put mykey "this is awesome"
etcdctl get mykey
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;etcd is now running and serving client requests. For more, please check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://play.etcd.io"&gt;Interactive etcd playground&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://etcd.io/docs/latest/demo"&gt;Animated quick demo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;etcd TCP ports&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt"&gt;official etcd ports&lt;/a&gt; are 2379 for client requests, and 2380 for peer communication.&lt;/p&gt; 
&lt;h3&gt;Running a local etcd cluster&lt;/h3&gt; 
&lt;p&gt;First install &lt;a href="https://github.com/mattn/goreman"&gt;goreman&lt;/a&gt;, which manages Procfile-based applications.&lt;/p&gt; 
&lt;p&gt;Our &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/Procfile"&gt;Procfile script&lt;/a&gt; will set up a local example cluster. Start it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;goreman start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will bring up 3 etcd members &lt;code&gt;infra1&lt;/code&gt;, &lt;code&gt;infra2&lt;/code&gt; and &lt;code&gt;infra3&lt;/code&gt; and optionally etcd &lt;code&gt;grpc-proxy&lt;/code&gt;, which runs locally and composes a cluster.&lt;/p&gt; 
&lt;p&gt;Every cluster member and proxy accepts key value reads and key value writes.&lt;/p&gt; 
&lt;p&gt;Follow the comments in &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/Procfile"&gt;Procfile script&lt;/a&gt; to add a learner node to the cluster.&lt;/p&gt; 
&lt;h3&gt;Install etcd client v3&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go get go.etcd.io/etcd/client/v3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Next steps&lt;/h3&gt; 
&lt;p&gt;Now it's time to dig into the full etcd API and other guides.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read the full &lt;a href="https://etcd.io/docs/latest"&gt;documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Review etcd &lt;a href="https://etcd.io/docs/latest/faq"&gt;frequently asked questions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Explore the full gRPC &lt;a href="https://etcd.io/docs/latest/learning/api"&gt;API&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Set up a &lt;a href="https://etcd.io/docs/latest/op-guide/clustering"&gt;multi-machine cluster&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Learn the &lt;a href="https://etcd.io/docs/latest/op-guide/configuration"&gt;config format, env variables and flags&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Find &lt;a href="https://etcd.io/docs/latest/integrations"&gt;language bindings and tools&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Use TLS to &lt;a href="https://etcd.io/docs/latest/op-guide/security"&gt;secure an etcd cluster&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://etcd.io/docs/latest/tuning"&gt;Tune etcd&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Email: &lt;a href="https://groups.google.com/g/etcd-dev"&gt;etcd-dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Slack: &lt;a href="https://kubernetes.slack.com/archives/C3HD8ARJ5"&gt;#sig-etcd&lt;/a&gt; channel on Kubernetes (&lt;a href="http://slack.kubernetes.io/"&gt;get an invite&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/#community-meetings"&gt;Community meetings&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community meetings&lt;/h3&gt; 
&lt;p&gt;etcd contributors and maintainers meet every week at &lt;code&gt;11:00&lt;/code&gt; AM (USA Pacific) on Thursday and meetings alternate between community meetings and issue triage meetings. Meeting agendas are recorded in a &lt;a href="https://docs.google.com/document/d/16XEGyPBisZvmmoIHSZzv__LoyOeluC5a4x353CX0SIM/edit"&gt;shared Google doc&lt;/a&gt; and everyone is welcome to suggest additional topics or other agendas.&lt;/p&gt; 
&lt;p&gt;Issue triage meetings are aimed at getting through our backlog of PRs and Issues. Triage meetings are open to any contributor; you don't have to be a reviewer or approver to help out! They can also be a good way to get started contributing.&lt;/p&gt; 
&lt;p&gt;The meeting lead role is rotated for each meeting between etcd maintainers or sig-etcd leads and is recorded in a &lt;a href="https://docs.google.com/spreadsheets/d/1jodHIO7Dk2VWTs1IRnfMFaRktS9IH8XRyifOnPdSY8I/edit"&gt;shared Google sheet&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Meeting recordings are uploaded to the official etcd &lt;a href="https://www.youtube.com/@etcdio"&gt;YouTube channel&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Get calendar invitations by joining &lt;a href="https://groups.google.com/g/etcd-dev"&gt;etcd-dev&lt;/a&gt; mailing group.&lt;/p&gt; 
&lt;p&gt;Join the CNCF-funded Zoom channel: &lt;a href="https://zoom.us/my/cncfetcdproject"&gt;zoom.us/my/cncfetcdproject&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; for details on setting up your development environment, submitting patches and the contribution workflow.&lt;/p&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/Documentation/contributor-guide/community-membership.md#member"&gt;community-membership.md&lt;/a&gt; for information on becoming an etcd project member. We welcome and look forward to your contributions to the project!&lt;/p&gt; 
&lt;p&gt;Please also refer to &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/Documentation/contributor-guide/roadmap.md"&gt;roadmap&lt;/a&gt; to get more details on the priorities for the next few major or minor releases.&lt;/p&gt; 
&lt;h2&gt;Reporting bugs&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/etcd-io/etcd/raw/main/Documentation/contributor-guide/reporting_bugs.md"&gt;reporting bugs&lt;/a&gt; for details about reporting any issues. Before opening an issue please check it is not covered in our &lt;a href="https://etcd.io/docs/latest/faq"&gt;frequently asked questions&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Reporting a security vulnerability&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/security/README.md"&gt;security disclosure and release process&lt;/a&gt; for details on how to report a security vulnerability and how the etcd team manages it.&lt;/p&gt; 
&lt;h2&gt;Issue and PR management&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/etcd-io/etcd/raw/main/Documentation/contributor-guide/triage_issues.md"&gt;issue triage guidelines&lt;/a&gt; for details on how issues are managed.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/etcd-io/etcd/raw/main/Documentation/contributor-guide/triage_prs.md"&gt;PR management&lt;/a&gt; for guidelines on how pull requests are managed.&lt;/p&gt; 
&lt;h2&gt;etcd Emeritus Maintainers&lt;/h2&gt; 
&lt;p&gt;etcd &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/OWNERS"&gt;emeritus maintainers&lt;/a&gt; dedicated a part of their career to etcd and reviewed code, triaged bugs and pushed the project forward over a substantial period of time. Their contribution is greatly appreciated.&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;etcd is under the Apache 2.0 license. See the &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>urfave/cli</title>
      <link>https://github.com/urfave/cli</link>
      <description>&lt;p&gt;A declarative, simple, fast, and fun package for building command line tools in Go&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome to urfave/cli&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/urfave/cli/v3"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/urfave/cli/v3.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/urfave/cli/v3"&gt;&lt;img src="https://goreportcard.com/badge/github.com/urfave/cli/v3" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/urfave/cli"&gt;&lt;img src="https://codecov.io/gh/urfave/cli/branch/main/graph/badge.svg?token=t9YGWLh05g" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://github.com/urfave/cli/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/urfave/cli/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Tests status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;urfave/cli is a &lt;strong&gt;declarative&lt;/strong&gt;, simple, fast, and fun package for building command line tools in Go featuring:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;commands and subcommands with alias and prefix match support&lt;/li&gt; 
 &lt;li&gt;flexible and permissive help system&lt;/li&gt; 
 &lt;li&gt;dynamic shell completion for &lt;code&gt;bash&lt;/code&gt;, &lt;code&gt;zsh&lt;/code&gt;, &lt;code&gt;fish&lt;/code&gt;, and &lt;code&gt;powershell&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;no dependencies except Go standard library&lt;/li&gt; 
 &lt;li&gt;input flags for simple types, slices of simple types, time, duration, and others&lt;/li&gt; 
 &lt;li&gt;compound short flag support (&lt;code&gt;-a&lt;/code&gt; &lt;code&gt;-b&lt;/code&gt; &lt;code&gt;-c&lt;/code&gt; can be shortened to &lt;code&gt;-abc&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;documentation generation in &lt;code&gt;man&lt;/code&gt; and Markdown (supported via the &lt;a href="https://github.com/urfave/cli-docs"&gt;&lt;code&gt;urfave/cli-docs&lt;/code&gt;&lt;/a&gt; module)&lt;/li&gt; 
 &lt;li&gt;input lookup from: 
  &lt;ul&gt; 
   &lt;li&gt;environment variables&lt;/li&gt; 
   &lt;li&gt;plain text files&lt;/li&gt; 
   &lt;li&gt;structured file formats (supported via the &lt;a href="https://github.com/urfave/cli-altsrc"&gt;&lt;code&gt;urfave/cli-altsrc&lt;/code&gt;&lt;/a&gt; module)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;See the hosted documentation website at &lt;a href="https://cli.urfave.org"&gt;https://cli.urfave.org&lt;/a&gt;. Contents of this website are built from the &lt;a href="https://raw.githubusercontent.com/urfave/cli/main/docs"&gt;&lt;code&gt;./docs&lt;/code&gt;&lt;/a&gt; directory.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Check the &lt;a href="https://github.com/urfave/cli/discussions/categories/q-a"&gt;Q&amp;amp;A discussions&lt;/a&gt;. If you don't find answer to your question, &lt;a href="https://github.com/urfave/cli/discussions/new?category=q-a"&gt;create a new discussion&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you found a bug or have a feature request, &lt;a href="https://github.com/urfave/cli/issues/new/choose"&gt;create a new issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please keep in mind that this project is run by unpaid volunteers.&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/urfave/cli/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>julien040/anyquery</title>
      <link>https://github.com/julien040/anyquery</link>
      <description>&lt;p&gt;Query anything (GitHub, Notion, +40 more) with SQL and let LLMs (ChatGPT, Claude) connect to using MCP&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Anyquery&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://anyquery.dev/images/logo-shadow.png" alt="Anyquery logo" width="96" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/downloads/julien040/anyquery/total" alt="GitHub Downloads (all assets, all releases)" /&gt; &lt;img src="https://img.shields.io/github/commit-activity/m/julien040/anyquery" alt="GitHub commit activity" /&gt; &lt;a href="https://anyquery.dev"&gt;&lt;img src="https://img.shields.io/badge/documentation-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/julien040/anyquery/issues"&gt;&lt;img src="https://img.shields.io/github/issues/julien040/anyquery" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://anyquery.dev/integrations/"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fregistry.anyquery.dev%2Fv0%2Fregistry%2F&amp;amp;query=%24.plugins_count&amp;amp;label=Integrations%20count&amp;amp;cacheSeconds=3600" alt="Dynamic JSON Badge" /&gt;&lt;/a&gt; &lt;a href="https://anyquery.dev/queries"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fregistry.anyquery.dev%2Fv0%2Fquery%2F&amp;amp;query=%24.queries_count&amp;amp;style=flat&amp;amp;label=Queries%20from%20the%20hub&amp;amp;cacheSeconds=3600&amp;amp;link=https%3A%2F%2Fanyquery.dev%2Fqueries" alt="Dynamic JSON Badge" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/julien040/anyquery/namespace"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/julien040/anyquery@v0.1.3/namespace.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://archestra.ai/mcp-catalog/julien040__anyquery"&gt;&lt;img src="https://archestra.ai/mcp-catalog/api/badge/quality/julien040/anyquery" alt="Trust Score" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Anyquery is a SQL query engine that allows you to run SQL queries on pretty much anything. It supports querying &lt;a href="https://anyquery.dev/docs/usage/querying-files/"&gt;files&lt;/a&gt;, &lt;a href="https://anyquery.dev/docs/database"&gt;databases&lt;/a&gt;, and &lt;a href="https://anyquery.dev/integrations"&gt;apps&lt;/a&gt; (e.g. Apple Notes, Notion, Chrome, Todoist, etc.). It's built on top of &lt;a href="https://www.sqlite.org"&gt;SQLite&lt;/a&gt; and uses &lt;a href="https://anyquery.dev/integrations"&gt;plugins&lt;/a&gt; to extend its functionality.&lt;/p&gt; 
&lt;p&gt;It can also connect to &lt;a href="https://anyquery.dev/llm"&gt;LLMs&lt;/a&gt; (e.g. ChatGPT, Claude, Cursor, TypingMind, etc.) to allow them to access your data.&lt;/p&gt; 
&lt;p&gt;Finally, it can act as a &lt;a href="https://anyquery.dev/docs/usage/mysql-server/"&gt;MySQL server&lt;/a&gt;, allowing you to run SQL queries from your favorite MySQL-compatible client (e.g. &lt;a href="https://anyquery.dev/connection-guide/tableplus/"&gt;TablePlus&lt;/a&gt;, &lt;a href="https://anyquery.dev/connection-guide/metabase/"&gt;Metabase&lt;/a&gt;, etc.).&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://anyquery.dev/images/release-header.png" alt="Anyquery header" /&gt;&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Connecting LLM&lt;/h3&gt; 
&lt;p&gt;LLMs can connect to Anyquery using the &lt;a href="https://anyquery.dev/docs/reference/commands/anyquery_mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;. This protocol provides context for LLMs that support it. You can start the MCP server with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# To be started by the LLM client
anyquery mcp --stdio
# To connect using an HTTP and SSE tunnel
anyquery mcp --host 127.0.0.1 --port 8070
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also connect to clients that supports function calling (e.g. ChatGPT, TypingMind). Refer to each &lt;a href="https://anyquery.dev/integrations#llm"&gt;connection guide&lt;/a&gt; in the documentation for more information.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy the ID returned by the command, and paste it in the LLM client (e.g. ChatGPT, TypingMind)
anyquery gpt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://anyquery.dev/images/docs/llm/5ire-final.png" alt="5ire example" /&gt;&lt;/p&gt; 
&lt;h3&gt;Running SQL queries&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://anyquery.dev/docs/usage/running-queries"&gt;documentation&lt;/a&gt; provides detailed instructions on how to run queries with Anyquery. But let's see a quick example. Type &lt;code&gt;anyquery&lt;/code&gt; in your terminal to open the shell mode. Then, run the following query:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://anyquery.dev/images/anyquery_examples.sql.png" alt="Anyquery SQL examples" /&gt;&lt;/p&gt; 
&lt;p&gt;You can also launch the MySQL server with &lt;code&gt;anyquery server&lt;/code&gt; and connect to it with your favorite MySQL-compatible client.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;anyquery server &amp;amp;
mysql -u root -h 127.0.0.1 -P 8070
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://anyquery.dev/docs/#installation"&gt;documentation&lt;/a&gt; provides detailed instructions on how to install Anyquery on your system. You can install anyquery from Homebrew, APT, YUM/DNF, Scoop, Winget and Chocolatey. You can also download the binary from the &lt;a href="https://github.com/julien040/anyquery/releases"&gt;releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Homebrew&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-zsh"&gt;brew install anyquery
&lt;/code&gt;&lt;/pre&gt; 
&lt;!-- 
### Snap

```bash
sudo snap install anyquery
``` --&gt; 
&lt;h3&gt;ARCH LINUX (AUR)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install using an AUR helper like yay
yay -S anyquery-git

# paru
paru -S anyquery-git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;APT&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;echo "deb [trusted=yes] https://apt.julienc.me/ /" | sudo tee /etc/apt/sources.list.d/anyquery.list
sudo apt update
sudo apt install anyquery
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;YUM/DNF&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;echo "[anyquery]
name=Anyquery
baseurl=https://yum.julienc.me/
enabled=1
gpgcheck=0" | sudo tee /etc/yum.repos.d/anyquery.repo
sudo dnf install anyquery
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scoop&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;scoop bucket add anyquery https://github.com/julien040/anyquery-scoop
scoop install anyquery
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Winget&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;winget install JulienCagniart.anyquery
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Chocolatey&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;choco install anyquery
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Plugins&lt;/h2&gt; 
&lt;p&gt;Anyquery is plugin-based, and you can install plugins to extend its functionality. You can install plugins from the &lt;a href="https://anyquery.dev/integrations"&gt;official registry&lt;/a&gt; or create your own. Anyquery can also &lt;a href="https://anyquery.dev/docs/usage/plugins#using-sqlite-extensions"&gt;load any SQLite extension&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://anyquery.dev/images/integrations_logo.png" alt="Integrations" /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Anyquery is licensed under the AGPLv3 license for the core engine. The RPC library is licensed under the MIT license so that anyone can reuse plugins in different projects.&lt;/p&gt; 
&lt;p&gt;The plugins are not subject to the AGPL license. Each plugins has its own license and the copyright is owned by the plugin author. See the &lt;a href="https://github.com/julien040/anquery/raw/main/LICENSE.md"&gt;LICENSE&lt;/a&gt; file for more information.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you want to contribute to Anyquery, please read the &lt;a href="https://anyquery.dev/docs/developers/project/contributing"&gt;contributing guidelines&lt;/a&gt;. I currently only accept minor contributions, but I'm open to any suggestions or feedback.&lt;/p&gt; 
&lt;p&gt;You can have a brief overview of the project in the &lt;a href="https://anyquery.dev/docs/developers/project/architecture/"&gt;architecture&lt;/a&gt; documentation.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>open-policy-agent/opa</title>
      <link>https://github.com/open-policy-agent/opa</link>
      <description>&lt;p&gt;Open Policy Agent (OPA) is an open source, general-purpose policy engine.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://raw.githubusercontent.com/open-policy-agent/opa/main/logo/logo-144x144.png" alt="logo" /&gt; Open Policy Agent&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/open-policy-agent/opa/actions"&gt;&lt;img src="https://github.com/open-policy-agent/opa/workflows/Post%20Merge/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/open-policy-agent/opa"&gt;&lt;img src="https://goreportcard.com/badge/open-policy-agent/opa" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/1768"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/1768/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://app.netlify.com/sites/openpolicyagent/deploys"&gt;&lt;img src="https://api.netlify.com/api/v1/badges/4a0a092a-8741-4826-a28f-826d4a576cab/deploy-status" alt="Netlify Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Open Policy Agent (OPA) is an open source, general-purpose policy engine that enables unified, context-aware policy enforcement across the entire stack.&lt;/p&gt; 
&lt;p&gt;OPA is proud to be a graduated project in the &lt;a href="https://cncf.io"&gt;Cloud Native Computing Foundation&lt;/a&gt; (CNCF) landscape. For details read the CNCF &lt;a href="https://www.cncf.io/announcements/2021/02/04/cloud-native-computing-foundation-announces-open-policy-agent-graduation/"&gt;announcement&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Get started with OPA&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Write your first Rego policy with the &lt;a href="https://play.openpolicyagent.org"&gt;Rego Playground&lt;/a&gt; or use it to share your work with others for feedback and support. Have a look at the &lt;a href="https://play.openpolicyagent.org/?example-group=access-control"&gt;Access Control examples&lt;/a&gt; if you're not sure where to start.&lt;/li&gt; 
 &lt;li&gt;Install the &lt;a href="https://marketplace.visualstudio.com/items?itemName=tsandall.opa"&gt;VS Code extension&lt;/a&gt; to get started locally with live diagnostics, debugging and formatting. See &lt;a href="https://www.openpolicyagent.org/docs/editor-and-ide-support/"&gt;Editor and IDE Support&lt;/a&gt; for other supported editors.&lt;/li&gt; 
 &lt;li&gt;Go to the &lt;a href="https://www.openpolicyagent.org/docs/latest/"&gt;OPA Documentation&lt;/a&gt; to learn about the Rego language as well as how to deploy and integrate OPA.&lt;/li&gt; 
 &lt;li&gt;Check out the learning resources in the &lt;a href="https://www.openpolicyagent.org/ecosystem/by-feature/learning-rego/"&gt;Learning Rego&lt;/a&gt; section of the ecosystem directory.&lt;/li&gt; 
 &lt;li&gt;Follow the &lt;a href="https://www.openpolicyagent.org/docs/latest/#running-opa"&gt;Running OPA&lt;/a&gt; instructions to get started with the OPA CLI locally.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://hub.docker.com/r/openpolicyagent/opa/tags/"&gt;Docker Hub&lt;/a&gt; for container images and the &lt;a href="https://github.com/open-policy-agent/opa/releases"&gt;GitHub releases&lt;/a&gt; for binaries.&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://docs.google.com/presentation/d/16QV6gvLDOV3I0_guPC3_19g6jHkEg3X9xqMYgtoCKrs/edit?usp=sharing"&gt;OPA Roadmap&lt;/a&gt; to see a high-level snapshot of OPA features in-progress and planned.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Want to talk about OPA or get support?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join the &lt;a href="https://slack.openpolicyagent.org"&gt;OPA Slack&lt;/a&gt; to talk to other OPA users and maintainers. See &lt;code&gt;#help&lt;/code&gt; for support.&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://github.com/orgs/open-policy-agent/discussions"&gt;Community Discussions&lt;/a&gt; to ask questions.&lt;/li&gt; 
 &lt;li&gt;See the &lt;a href="https://www.openpolicyagent.org/support/"&gt;Support&lt;/a&gt; page for commercial support options.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Interested to learn what others are doing with OPA?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Browse community projects on the &lt;a href="http://openpolicyagent.org/ecosystem/"&gt;OPA Ecosystem Directory&lt;/a&gt; - don't forget to &lt;a href="https://github.com/open-policy-agent/opa/tree/main/docs#opa-ecosystem"&gt;list your own&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/open-policy-agent/opa/main/ADOPTERS.md"&gt;ADOPTERS.md&lt;/a&gt; file for a list of production adopters. Does your organization use OPA in production? Support the OPA project by submitting a PR to add your organization to the list with a short description of your OPA use cases!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Want to integrate OPA?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;See the high-level &lt;a href="https://www.openpolicyagent.org/docs/latest/integration/#integrating-with-the-go-sdk"&gt;Go SDK&lt;/a&gt; or the low-level Go API &lt;a href="https://godoc.org/github.com/open-policy-agent/opa/rego"&gt;&lt;img src="https://godoc.org/github.com/open-policy-agent/opa?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; to integrate OPA with services written in Go.&lt;/li&gt; 
 &lt;li&gt;See the &lt;a href="https://www.openpolicyagent.org/docs/rest-api.html"&gt;REST API&lt;/a&gt; reference to integrate OPA with services written in other languages.&lt;/li&gt; 
 &lt;li&gt;See the &lt;a href="https://www.openpolicyagent.org/docs/latest/integration/"&gt;integration docs&lt;/a&gt; for more options.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Want to contribute to OPA?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read the &lt;a href="https://www.openpolicyagent.org/docs/latest/contributing/"&gt;Contributing Guide&lt;/a&gt; to learn how to make your first contribution.&lt;/li&gt; 
 &lt;li&gt;Use &lt;a href="https://openpolicyagent.slack.com/archives/C02L1TLPN59"&gt;#contributors&lt;/a&gt; in Slack to talk to other contributors and OPA maintainers.&lt;/li&gt; 
 &lt;li&gt;File a &lt;a href="https://github.com/open-policy-agent/opa/issues"&gt;GitHub Issue&lt;/a&gt; to request features or report bugs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How does OPA work?&lt;/h2&gt; 
&lt;p&gt;OPA gives you a high-level declarative language to author and enforce policies across your stack.&lt;/p&gt; 
&lt;p&gt;With OPA, you define &lt;em&gt;rules&lt;/em&gt; that govern how your system should behave. These rules exist to answer questions like:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Can user X call operation Y on resource Z?&lt;/li&gt; 
 &lt;li&gt;What clusters should workload W be deployed to?&lt;/li&gt; 
 &lt;li&gt;What tags must be set on resource R before it's created?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You integrate services with OPA so that these kinds of policy decisions do not have to be &lt;em&gt;hardcoded&lt;/em&gt; in your service. Services integrate with OPA by executing &lt;em&gt;queries&lt;/em&gt; when policy decisions are needed.&lt;/p&gt; 
&lt;p&gt;When you query OPA for a policy decision, OPA evaluates the rules and data (which you give it) to produce an answer. The policy decision is sent back as the result of the query.&lt;/p&gt; 
&lt;p&gt;For example, in a simple API authorization use case:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You write rules that allow (or deny) access to your service APIs.&lt;/li&gt; 
 &lt;li&gt;Your service queries OPA when it receives API requests.&lt;/li&gt; 
 &lt;li&gt;OPA returns allow (or deny) decisions to your service.&lt;/li&gt; 
 &lt;li&gt;Your service &lt;em&gt;enforces&lt;/em&gt; the decisions by accepting or rejecting requests accordingly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For concrete examples of how to integrate OPA with systems like &lt;a href="https://www.openpolicyagent.org/docs/kubernetes"&gt;Kubernetes&lt;/a&gt;, &lt;a href="https://www.openpolicyagent.org/docs/terraform"&gt;Terraform&lt;/a&gt;, &lt;a href="https://www.openpolicyagent.org/docs/docker-authorization"&gt;Docker&lt;/a&gt;, &lt;a href="https://www.openpolicyagent.org/docs/ssh-and-sudo-authorization"&gt;SSH&lt;/a&gt;, and more, see &lt;a href="https://www.openpolicyagent.org"&gt;openpolicyagent.org&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Presentations&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open Policy Agent (OPA) Intro &amp;amp; Deep Dive @ Kubecon NA 2023: &lt;a href="https://www.youtube.com/watch?v=wJkjsvVpj_Q"&gt;video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open Policy Agent (OPA) Intro &amp;amp; Deep Dive @ Kubecon EU 2023: &lt;a href="https://www.youtube.com/watch?v=6RNp3m_THw4"&gt;video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Running Policy in Hard to Reach Places with WASM &amp;amp; OPA @ CN Wasm Day EU 2023: &lt;a href="https://www.youtube.com/watch?v=BdeBhukLwt4"&gt;video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;OPA maintainers talk @ Kubecon NA 2022: &lt;a href="https://www.youtube.com/watch?v=RMiovzGGCfI"&gt;video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open Policy Agent (OPA) Intro &amp;amp; Deep Dive @ Kubecon EU 2022: &lt;a href="https://www.youtube.com/watch?v=MhyQxIp1H58"&gt;video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open Policy Agent Intro @ KubeCon EU 2021: &lt;a href="https://www.youtube.com/watch?v=2CgeiWkliaw"&gt;Video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Using Open Policy Agent to Meet Evolving Policy Requirements @ KubeCon NA 2020: &lt;a href="https://www.youtube.com/watch?v=zVuM7F_BTyc"&gt;video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Applying Policy Throughout The Application Lifecycle with Open Policy Agent @ CloudNativeCon 2019: &lt;a href="https://www.youtube.com/watch?v=cXfsaE6RKfc"&gt;video&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open Policy Agent Introduction @ CloudNativeCon EU 2018: &lt;a href="https://youtu.be/XEHeexPpgrA"&gt;video&lt;/a&gt;, &lt;a href="https://www.slideshare.net/TorinSandall/opa-the-cloud-native-policy-engine"&gt;slides&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Rego Deep Dive @ CloudNativeCon EU 2018: &lt;a href="https://youtu.be/4mBJSIhs2xQ"&gt;video&lt;/a&gt;, &lt;a href="https://www.slideshare.net/TorinSandall/rego-deep-dive"&gt;slides&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;How Netflix Is Solving Authorization Across Their Cloud @ CloudNativeCon US 2017: &lt;a href="https://www.youtube.com/watch?v=R6tUNpRpdnY"&gt;video&lt;/a&gt;, &lt;a href="https://www.slideshare.net/TorinSandall/how-netflix-is-solving-authorization-across-their-cloud"&gt;slides&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Policy-based Resource Placement in Kubernetes Federation @ LinuxCon Beijing 2017: &lt;a href="https://www.slideshare.net/TorinSandall/policybased-resource-placement-across-hybrid-cloud"&gt;slides&lt;/a&gt;, &lt;a href="https://www.youtube.com/watch?v=hRz13baBhfg&amp;amp;feature=youtu.be"&gt;screencast&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Enforcing Bespoke Policies In Kubernetes @ KubeCon US 2017: &lt;a href="https://www.youtube.com/watch?v=llDI8VvkUj8"&gt;video&lt;/a&gt;, &lt;a href="https://www.slideshare.net/TorinSandall/enforcing-bespoke-policies-in-kubernetes"&gt;slides&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Istio's Mixer: Policy Enforcement with Custom Adapters @ CloudNativeCon US 2017: &lt;a href="https://www.youtube.com/watch?v=czZLXUqzd24"&gt;video&lt;/a&gt;, &lt;a href="https://www.slideshare.net/TorinSandall/istios-mixer-policy-enforcement-with-custom-adapters-cloud-nativecon-17"&gt;slides&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;A third party security audit was performed by Cure53, you can see the full report &lt;a href="https://raw.githubusercontent.com/open-policy-agent/opa/main/SECURITY_AUDIT.pdf"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please report vulnerabilities by email to &lt;a href="mailto:open-policy-agent-security@googlegroups.com"&gt;open-policy-agent-security&lt;/a&gt;. We will send a confirmation message to acknowledge that we have received the report and then we will send additional messages to follow up once the issue has been investigated.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>temporalio/temporal</title>
      <link>https://github.com/temporalio/temporal</link>
      <description>&lt;p&gt;Temporal service&lt;/p&gt;&lt;hr&gt;&lt;div class="title-block" style="text-align: center;" align="center"&gt; 
 &lt;h1&gt;Temporal‚Äîdurable execution platform&lt;/h1&gt; 
 &lt;p&gt;&lt;img title="temporal logo" src="https://avatars.githubusercontent.com/u/56493103?s=320" width="320" height="320" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/temporalio/temporal/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/temporalio/temporal" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/temporalio/temporal/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/temporalio/temporal" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://app.codecov.io/gh/temporalio/temporal"&gt;&lt;img src="https://img.shields.io/badge/codecov-report-blue" alt="Code Coverage" /&gt;&lt;/a&gt; &lt;a href="https://community.temporal.io"&gt;&lt;img src="https://img.shields.io/static/v1?label=community&amp;amp;message=get%20help&amp;amp;color=informational" alt="Community" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/temporalio/temporal"&gt;&lt;img src="https://goreportcard.com/badge/github.com/temporalio/temporal" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/#introduction"&gt;Introduction&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/#getting-started"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/#contributing"&gt;Contributing&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://docs.temporal.io/"&gt;Temporal Docs&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://learn.temporal.io/courses/temporal_101/"&gt;Temporal 101&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Temporal is a durable execution platform that enables developers to build scalable applications without sacrificing productivity or reliability. The Temporal server executes units of application logic called Workflows in a resilient manner that automatically handles intermittent failures, and retries failed operations.&lt;/p&gt; 
&lt;p&gt;Temporal is a mature technology that originated as a fork of Uber's Cadence. It is developed by &lt;a href="https://temporal.io/"&gt;Temporal Technologies&lt;/a&gt;, a startup by the creators of Cadence.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/wIpz4ioK0gI" title="Getting to know Temporal"&gt;&lt;img src="https://github.com/temporalio/temporal/assets/251288/693d18b5-01de-4a3b-b47b-96347b84f610" alt="image" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Download and Start Temporal Server Locally&lt;/h3&gt; 
&lt;p&gt;Execute the following commands to start a pre-built image along with all the dependencies.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install temporal
temporal server start-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Refer to &lt;a href="https://docs.temporal.io/cli/#installation"&gt;Temporal CLI&lt;/a&gt; documentation for more installation options.&lt;/p&gt; 
&lt;h3&gt;Run the Samples&lt;/h3&gt; 
&lt;p&gt;Clone or download samples for &lt;a href="https://github.com/temporalio/samples-go"&gt;Go&lt;/a&gt; or &lt;a href="https://github.com/temporalio/samples-java"&gt;Java&lt;/a&gt; and run them with the local Temporal server. We have a number of &lt;a href="https://github.com/temporalio/samples-java#helloworld"&gt;HelloWorld type scenarios&lt;/a&gt; available, as well as more advanced ones. Note that the sets of samples are currently different between Go and Java.&lt;/p&gt; 
&lt;h3&gt;Use CLI&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://docs.temporal.io/cli/"&gt;Temporal CLI&lt;/a&gt; to interact with the running Temporal server.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;temporal operator namespace list
temporal workflow list
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use Temporal Web UI&lt;/h3&gt; 
&lt;p&gt;Try &lt;a href="https://docs.temporal.io/web-ui"&gt;Temporal Web UI&lt;/a&gt; by opening &lt;a href="http://localhost:8233"&gt;http://localhost:8233&lt;/a&gt; for viewing your sample workflows executing on Temporal.&lt;/p&gt; 
&lt;h2&gt;Repository&lt;/h2&gt; 
&lt;p&gt;This repository contains the source code of the Temporal server. To implement Workflows, Activities and Workers, use one of the &lt;a href="https://docs.temporal.io/dev-guide/"&gt;supported languages&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We'd love your help in making Temporal great.&lt;/p&gt; 
&lt;p&gt;Helpful links to get started:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/temporalio/proposals"&gt;work on or propose a new feature&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/docs/architecture/README.md"&gt;learn about the Temporal Server architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/CONTRIBUTING.md"&gt;learn how to build and run the Temporal Server locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/temporalio/temporal/main/docs/development/testing.md"&gt;learn about Temporal Server testing tools and best practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;join the Temporal community &lt;a href="https://community.temporal.io"&gt;forum&lt;/a&gt; and &lt;a href="https://t.mp/slack"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/temporalio/temporal/raw/main/LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pingcap/tidb</title>
      <link>https://github.com/pingcap/tidb</link>
      <description>&lt;p&gt;TiDB - the open-source, cloud-native, distributed SQL database designed for modern applications.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://www.pingcap.com/?utm_source=github&amp;amp;utm_medium=tidb"&gt; &lt;img src="https://raw.githubusercontent.com/pingcap/tidb/master/docs/tidb-logo.png" alt="TiDB, a distributed SQL database" height="100" /&gt; &lt;/a&gt; 
 &lt;hr /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/pingcap/tidb/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://golang.org/"&gt;&lt;img src="https://img.shields.io/badge/Language-Go-blue.svg?sanitize=true" alt="Language" /&gt;&lt;/a&gt; &lt;a href="https://prow.tidb.net/?repo=pingcap%2Ftidb&amp;amp;type=postsubmit&amp;amp;job=pingcap%2Ftidb%2Fmerged_build"&gt;&lt;img src="https://prow.tidb.net/badge.svg?jobs=pingcap/tidb/merged_build" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/pingcap/tidb"&gt;&lt;img src="https://goreportcard.com/badge/github.com/pingcap/tidb" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/pingcap/tidb/releases"&gt;&lt;img src="https://img.shields.io/github/tag/pingcap/tidb.svg?label=release" alt="GitHub release" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;TiDB&lt;/h1&gt; 
&lt;p&gt;TiDB (/‚Äôta…™diÀêbi:/, "Ti" stands for Titanium) is an open-source, cloud-native, distributed SQL database designed for high availability, horizontal and vertical scalability, strong consistency, and high performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pingcap/tidb/master/#key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pingcap/tidb/master/#quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pingcap/tidb/master/#need-help"&gt;Need Help?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pingcap/tidb/master/#architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pingcap/tidb/master/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pingcap/tidb/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pingcap/tidb/master/#see-also"&gt;See Also&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pingcap/tidb/master/#acknowledgments"&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.pingcap.com/blog/distributed-transactions-tidb?utm_source=github&amp;amp;utm_medium=tidb"&gt;Distributed Transactions&lt;/a&gt;&lt;/strong&gt;: TiDB uses a two-phase commit protocol to ensure ACID compliance, providing strong consistency. Transactions span multiple nodes, and TiDB's distributed nature ensures data correctness even in the presence of network partitions or node failures.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.pingcap.com/tidb/stable/scale-tidb-using-tiup?utm_source=github&amp;amp;utm_medium=tidb"&gt;Horizontal and Vertical Scalability&lt;/a&gt;&lt;/strong&gt;: TiDB can be scaled horizontally by adding more nodes or vertically by increasing resources of existing nodes, all without downtime. TiDB's architecture separates computing from storage, enabling you to adjust both independently as needed for flexibility and growth.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.pingcap.com/tidbcloud/high-availability-with-multi-az?utm_source=github&amp;amp;utm_medium=tidb"&gt;High Availability&lt;/a&gt;&lt;/strong&gt;: Built-in Raft consensus protocol ensures reliability and automated failover. Data is stored in multiple replicas, and transactions are committed only after writing to the majority of replicas, guaranteeing strong consistency and availability, even if some replicas fail. Geographic placement of replicas can be configured for different disaster tolerance levels.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.pingcap.com/blog/htap-demystified-defining-modern-data-architecture-tidb?utm_source=github&amp;amp;utm_medium=tidb"&gt;Hybrid Transactional/Analytical Processing (HTAP)&lt;/a&gt;&lt;/strong&gt;: TiDB provides two storage engines: TiKV, a row-based storage engine, and TiFlash, a columnar storage engine. TiFlash uses the Multi-Raft Learner protocol to replicate data from TiKV in real time, ensuring consistent data between the TiKV row-based storage engine and the TiFlash columnar storage engine. The TiDB Server coordinates query execution across both TiKV and TiFlash to optimize performance.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.pingcap.com/cloud-native?utm_source=github&amp;amp;utm_medium=tidb"&gt;Cloud-Native&lt;/a&gt;&lt;/strong&gt;: TiDB can be deployed in public clouds, on-premises, or natively in Kubernetes. &lt;a href="https://docs.pingcap.com/tidb-in-kubernetes/stable/tidb-operator-overview/?utm_source=github&amp;amp;utm_medium=tidb"&gt;TiDB Operator&lt;/a&gt; helps manage TiDB on Kubernetes, automating cluster operations, while &lt;a href="https://tidbcloud.com/?utm_source=github&amp;amp;utm_medium=tidb"&gt;TiDB Cloud&lt;/a&gt; provides a fully-managed service for easy and economical deployment, allowing users to set up clusters with just a few clicks.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.pingcap.com/tidb/stable/mysql-compatibility?utm_source=github&amp;amp;utm_medium=tidb"&gt;MySQL Compatibility&lt;/a&gt;&lt;/strong&gt;: TiDB is compatible with MySQL 8.0, allowing you to use familiar protocols, frameworks and tools. You can migrate applications to TiDB without changing any code, or with minimal modifications. Additionally, TiDB provides a suite of &lt;a href="https://docs.pingcap.com/tidb/stable/ecosystem-tool-user-guide?utm_source=github&amp;amp;utm_medium=tidb"&gt;data migration tools&lt;/a&gt; to help easily migrate application data into TiDB.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.pingcap.com/blog/open-source-is-in-our-dna-reaffirming-tidb-commitment?utm_source=github&amp;amp;utm_medium=tidb"&gt;Open Source Commitment&lt;/a&gt;&lt;/strong&gt;: Open source is at the core of TiDB's identity. All source code is available on GitHub under the Apache 2.0 license, including enterprise-grade features. TiDB is built with the belief that open source enables transparency, innovation, and collaboration. We actively encourage contributions from the community to help build a vibrant and inclusive ecosystem, reaffirming our commitment to open development and accessibility for everyone.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Tip]&lt;br /&gt; As part of our commitment to open source, we want to reward all GitHub users. In addition to the free tier, you can get up to $2000 in TiDB Cloud Serverless credits for your open-source contributions - &lt;a href="https://ossinsight.io/open-source-heroes/?utm_source=ossinsight&amp;amp;utm_medium=referral&amp;amp;utm_campaign=plg_OSScontribution_credit_05"&gt;Claim here&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Start a TiDB Cluster&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;On Local Playground&lt;/strong&gt;. To start a local test cluster, please refer to the &lt;a href="https://docs.pingcap.com/tidb/stable/quick-start-with-tidb#deploy-a-local-test-cluster?utm_source=github&amp;amp;utm_medium=tidb"&gt;TiDB quick start guide&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;On Kubernetes&lt;/strong&gt;. TiDB can be easily deployed in a self-managed Kubernetes environment or Kubernetes services on public clouds using TiDB Operator. For more details, please refer to the &lt;a href="https://docs.pingcap.com/tidb-in-kubernetes/stable/get-started?utm_source=github&amp;amp;utm_medium=tidb"&gt;TiDB on Kubernetes quick start guide&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Using TiDB Cloud (Recommended)&lt;/strong&gt;. TiDB Cloud offers a fully managed version of TiDB with a free tier, no credit card required, so you can get a free cluster in seconds and start easily: &lt;a href="https://tidbcloud.com/free-trial?utm_source=github&amp;amp;utm_medium=tidb"&gt;Sign up for TiDB Cloud&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Learn About TiDB SQL: To explore the SQL capabilities of TiDB, refer to the &lt;a href="https://docs.pingcap.com/tidb/stable/sql-statement-overview?utm_source=github&amp;amp;utm_medium=tidb"&gt;TiDB SQL documentation&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Use MySQL Driver or ORM to &lt;a href="https://docs.pingcap.com/tidbcloud/dev-guide-overview?utm_source=github&amp;amp;utm_medium=tidb"&gt;Build an App with TiDB with TiDB&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Explore key features, such as &lt;a href="https://docs.pingcap.com/tidbcloud/tidb-cloud-migration-overview?utm_source=github&amp;amp;utm_medium=tidb"&gt;data migration&lt;/a&gt;, &lt;a href="https://docs.pingcap.com/tidbcloud/changefeed-overview?utm_source=github&amp;amp;utm_medium=tidb"&gt;changefeed&lt;/a&gt;, &lt;a href="https://docs.pingcap.com/tidbcloud/vector-search-overview?utm_source=github&amp;amp;utm_medium=tidb"&gt;vector search&lt;/a&gt;, &lt;a href="https://docs.pingcap.com/tidbcloud/tidb-cloud-htap-quickstart?utm_source=github&amp;amp;utm_medium=tidb"&gt;HTAP&lt;/a&gt;, &lt;a href="https://docs.pingcap.com/tidb/stable/dr-solution-introduction?utm_source=github&amp;amp;utm_medium=tidb"&gt;disaster recovery&lt;/a&gt;, etc.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Need Help?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can connect with TiDB users, ask questions, find answers, and help others on our community platforms: &lt;a href="https://discord.gg/KVRZBR2DrG?utm_source=github"&gt;Discord&lt;/a&gt;, Slack (&lt;a href="https://slack.tidb.io/invite?team=tidb-community&amp;amp;channel=everyone&amp;amp;ref=pingcap-tidb"&gt;English&lt;/a&gt;, &lt;a href="https://slack.tidb.io/invite?team=tidb-community&amp;amp;channel=tidb-japan&amp;amp;ref=github-tidb"&gt;Japanese&lt;/a&gt;), &lt;a href="https://stackoverflow.com/questions/tagged/tidb"&gt;Stack Overflow&lt;/a&gt;, &lt;a href="https://asktug.com"&gt;TiDB Chinese Forum&lt;/a&gt;, X &lt;a href="https://twitter.com/PingCAP"&gt;@PingCAP&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For filing bugs, suggesting improvements, or requesting new features, use &lt;a href="https://github.com/pingcap/tidb/issues"&gt;Github Issues&lt;/a&gt; or join discussions on &lt;a href="https://github.com/orgs/pingcap/discussions"&gt;Github Discussions&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To troubleshoot TiDB, refer to &lt;a href="https://docs.pingcap.com/tidb/stable/tidb-troubleshooting-map?utm_source=github&amp;amp;utm_medium=tidb"&gt;Toubleshooting documentation&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/pingcap/tidb/master/docs/tidb-architecture.png" alt="TiDB architecture" /&gt;&lt;/p&gt; 
&lt;p&gt;Learn more details about TiDB architecture in our &lt;a href="https://docs.pingcap.com/tidb/stable/tidb-architecture?utm_source=github&amp;amp;utm_medium=tidb"&gt;Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;TiDB is built on a commitment to open source, and we welcome contributions from everyone. Whether you are interested in improving documentation, fixing bugs, or developing new features, we invite you to shape the future of TiDB.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;See our &lt;a href="https://github.com/pingcap/community/raw/master/contributors/README.md#how-to-contribute"&gt;Contributor Guide&lt;/a&gt; and &lt;a href="https://pingcap.github.io/tidb-dev-guide/index.html"&gt;TiDB Development Guide&lt;/a&gt; to get started.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If you're looking for issues to work on, try looking at the &lt;a href="https://github.com/pingcap/tidb/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22"&gt;good first issues&lt;/a&gt; or &lt;a href="https://github.com/pingcap/tidb/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;help wanted issues&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The &lt;a href="https://github.com/pingcap/tidb-map/raw/master/maps/contribution-map.md#a-map-that-guides-what-and-how-contributors-can-contribute"&gt;contribution map&lt;/a&gt; lists everything you can contribute.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The &lt;a href="https://github.com/pingcap/community"&gt;community repository&lt;/a&gt; contains everything else you need.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Don't forget to claim your contribution swag by filling in and submitting this &lt;a href="https://forms.pingcap.com/f/tidb-contribution-swag"&gt;form&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;a href="https://next.ossinsight.io/widgets/official/compose-recent-active-contributors?repo_id=41986369&amp;amp;limit=30" target="_blank" style="display: block" align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://next.ossinsight.io/widgets/official/compose-recent-active-contributors/thumbnail.png?repo_id=41986369&amp;amp;limit=30&amp;amp;image_size=auto&amp;amp;color_scheme=dark" width="655" height="auto" /&gt; 
  &lt;img alt="Active Contributors of pingcap/tidb - Last 28 days" src="https://next.ossinsight.io/widgets/official/compose-recent-active-contributors/thumbnail.png?repo_id=41986369&amp;amp;limit=30&amp;amp;image_size=auto&amp;amp;color_scheme=light" width="655" height="auto" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;TiDB is under the Apache 2.0 license. See the &lt;a href="https://raw.githubusercontent.com/pingcap/tidb/master/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;See Also&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://play.tidbcloud.com/?utm_source=github&amp;amp;utm_medium=tidb_readme"&gt;TiDB Online Playground&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;TiDB Case Studies: &lt;a href="https://www.pingcap.com/customers/?utm_source=github&amp;amp;utm_medium=tidb"&gt;TiDB Customers&lt;/a&gt;, &lt;a href="https://pingcap.co.jp/case-study/?utm_source=github&amp;amp;utm_medium=tidb"&gt;TiDB ‰∫ã‰æãË®ò‰∫ã&lt;/a&gt;, &lt;a href="https://cn.pingcap.com/case/?utm_source=github&amp;amp;utm_medium=tidb"&gt;TiDB ‰∏≠ÊñáÁî®Êà∑Ê°à‰æã&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.pingcap.com/tidb/stable?utm_source=github&amp;amp;utm_medium=tidb"&gt;TiDB User Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pingcap/tidb/master/docs/design"&gt;TiDB Design Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.pingcap.com/tidb/dev/release-notes?utm_source=github&amp;amp;utm_medium=tidb"&gt;TiDB Release Notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pingcap.com/blog/?utm_source=github&amp;amp;utm_medium=tidb"&gt;TiDB Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pingcap/tidb/master/roadmap.md"&gt;TiDB Roadmap&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thanks &lt;a href="https://github.com/cznic"&gt;cznic&lt;/a&gt; for providing some great open source tools.&lt;/li&gt; 
 &lt;li&gt;Thanks &lt;a href="https://github.com/syndtr/goleveldb"&gt;GolevelDB&lt;/a&gt;, &lt;a href="https://github.com/boltdb/bolt"&gt;BoltDB&lt;/a&gt;, and &lt;a href="https://github.com/facebook/rocksdb"&gt;RocksDB&lt;/a&gt; for their powerful storage engines.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>open-telemetry/opentelemetry-collector</title>
      <link>https://github.com/open-telemetry/opentelemetry-collector</link>
      <description>&lt;p&gt;OpenTelemetry Collector&lt;/p&gt;&lt;hr&gt;&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://opentelemetry.io/docs/collector/getting-started/"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/CONTRIBUTING.md"&gt;Getting Involved&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://cloud-native.slack.com/archives/C01N6P7KR6W"&gt;Getting In Touch&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/actions/workflows/build-and-test.yml?query=branch%3Amain"&gt; &lt;img alt="Build Status" src="https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector/build-and-test.yml?branch=main&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector"&gt; &lt;img alt="Go Report Card" src="https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://codecov.io/gh/open-telemetry/opentelemetry-collector/branch/main/"&gt; &lt;img alt="Codecov Status" src="https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/releases"&gt; &lt;img alt="GitHub release (latest by date including pre-releases)" src="https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector?include_prereleases&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://www.bestpractices.dev/projects/8404"&gt;&lt;img src="https://www.bestpractices.dev/projects/8404/badge" /&gt; &lt;/a&gt; &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;amp;can=1&amp;amp;q=proj:opentelemetry"&gt; &lt;img alt="Fuzzing Status" src="https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/vision.md"&gt;Vision&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://opentelemetry.io/docs/collector/configuration/"&gt;Configuration&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://opentelemetry.io/docs/collector/internal-telemetry/#use-internal-telemetry-to-monitor-the-collector"&gt;Monitoring&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/security-best-practices.md"&gt;Security&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://pkg.go.dev/go.opentelemetry.io/collector"&gt;Package&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;&lt;img src="https://opentelemetry.io/img/logos/opentelemetry-logo-nav.png" alt="OpenTelemetry Icon" width="45" height="" /&gt; OpenTelemetry Collector&lt;/h1&gt; 
&lt;p&gt;The OpenTelemetry Collector offers a vendor-agnostic implementation on how to receive, process and export telemetry data. In addition, it removes the need to run, operate and maintain multiple agents/collectors in order to support open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) to multiple open-source or commercial back-ends.&lt;/p&gt; 
&lt;p&gt;Objectives:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Usable: Reasonable default configuration, supports popular protocols, runs and collects out of the box.&lt;/li&gt; 
 &lt;li&gt;Performant: Highly stable and performant under varying loads and configurations.&lt;/li&gt; 
 &lt;li&gt;Observable: An exemplar of an observable service.&lt;/li&gt; 
 &lt;li&gt;Extensible: Customizable without touching the core code.&lt;/li&gt; 
 &lt;li&gt;Unified: Single codebase, deployable as an agent or collector with support for traces, metrics and logs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The OpenTelemetry Collector SIG is present at the &lt;a href="https://cloud-native.slack.com/archives/C01N6P7KR6W"&gt;#otel-collector&lt;/a&gt; channel on the CNCF Slack and &lt;a href="https://github.com/open-telemetry/community#implementation-sigs"&gt;meets once a week&lt;/a&gt; via video calls. Everyone is invited to join those calls, which typically serves the following purposes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;meet the humans behind the project&lt;/li&gt; 
 &lt;li&gt;get an opinion about specific proposals&lt;/li&gt; 
 &lt;li&gt;look for a sponsor for a proposed component after trying already via GitHub and Slack&lt;/li&gt; 
 &lt;li&gt;get attention to a specific pull-request that got stuck and is difficult to discuss asynchronously&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We rotate our video calls between three time slots, in order to allow everyone to join at least once every three meetings. The rotation order is as follows:&lt;/p&gt; 
&lt;p&gt;Tuesday:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=1700"&gt;17:00 PT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Wednesday:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=0900"&gt;09:00 PT&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dateful.com/convert/pst-pdt-pacific-time?t=0500"&gt;05:00 PT&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Contributors to the project are also welcome to have ad-hoc meetings for synchronous discussions about specific points. Post a note in #otel-collector-dev on Slack inviting others, specifying the topic to be discussed. Unless there are strong reasons to keep the meeting private, please make it an open invitation for other contributors to join. Try also to identify who would be the other contributors interested on that topic and in which timezones they are.&lt;/p&gt; 
&lt;p&gt;Remember that our source of truth is GitHub: every decision made via Slack or video calls has to be recorded in the relevant GitHub issue. Ideally, the agenda items from the meeting notes would include a link to the issue or pull request where a discussion is happening already. We acknowledge that not everyone can join Slack or the synchronous calls and don't want them to feel excluded.&lt;/p&gt; 
&lt;h2&gt;Supported OTLP version&lt;/h2&gt; 
&lt;p&gt;This code base is currently built against using OTLP protocol v1.5.0, considered Stable. &lt;a href="https://github.com/open-telemetry/opentelemetry-proto?tab=readme-ov-file#stability-definition"&gt;See the OpenTelemetry Protocol Stability definition here.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stability levels&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/component-stability.md"&gt;Stability Levels and versioning&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Compatibility&lt;/h2&gt; 
&lt;p&gt;When used as a library, the OpenTelemetry Collector attempts to track the currently supported versions of Go, as &lt;a href="https://go.dev/doc/devel/release#policy"&gt;defined by the Go team&lt;/a&gt;. Removing support for an unsupported Go version is not considered a breaking change.&lt;/p&gt; 
&lt;p&gt;Support for Go versions on the OpenTelemetry Collector is updated as follows:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;The first release after the release of a new Go minor version &lt;code&gt;N&lt;/code&gt; will add build and tests steps for the new Go minor version.&lt;/li&gt; 
 &lt;li&gt;The first release after the release of a new Go minor version &lt;code&gt;N&lt;/code&gt; will remove support for Go version &lt;code&gt;N-2&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Official OpenTelemetry Collector distro binaries will be built with a release in the latest Go minor version series.&lt;/p&gt; 
&lt;h2&gt;Verifying the images signatures&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To verify a signed artifact or blob, first &lt;a href="https://docs.sigstore.dev/cosign/system_config/installation/"&gt;install Cosign&lt;/a&gt;, then follow the instructions below.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We are signing the images &lt;code&gt;otel/opentelemetry-collector&lt;/code&gt; and &lt;code&gt;otel/opentelemetry-collector-contrib&lt;/code&gt; using &lt;a href="https://github.com/sigstore/cosign"&gt;sigstore cosign&lt;/a&gt; tool and to verify the signatures you can run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ cosign verify \
  --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/&amp;lt;RELEASE_TAG&amp;gt; \
  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
  &amp;lt;OTEL_COLLECTOR_IMAGE&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;where:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;RELEASE_TAG&amp;gt;&lt;/code&gt;: is the release that you want to validate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;OTEL_COLLECTOR_IMAGE&amp;gt;&lt;/code&gt;: is the image that you want to check&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ cosign verify --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0 --certificate-oidc-issuer=https://token.actions.githubusercontent.com ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0

Verification for ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - Existence of the claims in the transparency log was verified offline
  - The code-signing certificate was verified using trusted certificate authority certificates

[{"critical":{"identity":{"docker-reference":"ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib"},"image":{"docker-manifest-digest":"sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a"},"type":"cosign container image signature"},"optional":{"1.3.6.1.4.1.57264.1.1":"https://token.actions.githubusercontent.com","1.3.6.1.4.1.57264.1.2":"push","1.3.6.1.4.1.57264.1.3":"9e20bf5c142e53070ccb8320a20315fffb41469e","1.3.6.1.4.1.57264.1.4":"Release Contrib","1.3.6.1.4.1.57264.1.5":"open-telemetry/opentelemetry-collector-releases","1.3.6.1.4.1.57264.1.6":"refs/tags/v0.98.0","Bundle":{"SignedEntryTimestamp":"MEUCIQDdlmNeKXQrHnonwWiHLhLLwFDVDNoOBCn2sv85J9P8mgIgDQFssWJImo1hn38VlojvSCL7Qq5FMmtnGu0oLsNdOm8=","Payload":{"body":"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","integratedTime":1712809120,"logIndex":84797936,"logID":"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d"}},"Issuer":"https://token.actions.githubusercontent.com","Subject":"https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0","githubWorkflowName":"Release Contrib","githubWorkflowRef":"refs/tags/v0.98.0","githubWorkflowRepository":"open-telemetry/opentelemetry-collector-releases","githubWorkflowSha":"9e20bf5c142e53070ccb8320a20315fffb41469e","githubWorkflowTrigger":"push"}},{"critical":{"identity":{"docker-reference":"ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib"},"image":{"docker-manifest-digest":"sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a"},"type":"cosign container image signature"},"optional":{"1.3.6.1.4.1.57264.1.1":"https://token.actions.githubusercontent.com","1.3.6.1.4.1.57264.1.2":"push","1.3.6.1.4.1.57264.1.3":"9e20bf5c142e53070ccb8320a20315fffb41469e","1.3.6.1.4.1.57264.1.4":"Release Contrib","1.3.6.1.4.1.57264.1.5":"open-telemetry/opentelemetry-collector-releases","1.3.6.1.4.1.57264.1.6":"refs/tags/v0.98.0","Bundle":{"SignedEntryTimestamp":"MEUCIQD1ehDnPO6fzoPIpeQ3KFuYHHBiX7RcEbpo9B2r7JAlzwIgZ1bsuQz7gAXbNU1IEdsTQgfAnRk3xVXO16GnKXM2sAQ=","Payload":{"body":"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","integratedTime":1712809122,"logIndex":84797940,"logID":"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d"}},"Issuer":"https://token.actions.githubusercontent.com","Subject":"https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0","githubWorkflowName":"Release Contrib","githubWorkflowRef":"refs/tags/v0.98.0","githubWorkflowRepository":"open-telemetry/opentelemetry-collector-releases","githubWorkflowSha":"9e20bf5c142e53070ccb8320a20315fffb41469e","githubWorkflowTrigger":"push"}}]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] We started signing the images with release &lt;code&gt;v0.95.0&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;Here is a list of community roles with current and previous members:&lt;/p&gt; 
&lt;h3&gt;Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/codeboten"&gt;Alex Boten&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bogdandrutu"&gt;Bogdan Drutu&lt;/a&gt;, Snowflake&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmitryax"&gt;Dmitrii Anoshin&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mx-psi"&gt;Pablo Baeyens&lt;/a&gt;, DataDog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the maintainer role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#maintainer"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/atoulme"&gt;Antoine Toulme&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmathieu"&gt;Damien Mathieu&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evan-bradley"&gt;Evan Bradley&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jade-guiton-dd"&gt;Jade Guiton&lt;/a&gt;, Datadog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jmacd"&gt;Joshua MacDonald&lt;/a&gt;, Microsoft&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TylerHelmuth"&gt;Tyler Helmuth&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/songy23"&gt;Yang Song&lt;/a&gt;, Datadog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the approver role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#approver"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In addition to what is described at the organization-level, the SIG Collector requires all core approvers to take part in rotating the role of the &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector/main/docs/release.md#release-manager"&gt;release manager&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/axw"&gt;Andrew Wilkins&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andrzej-stencel"&gt;Andrzej Stencel&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sincejune"&gt;Chao Weng&lt;/a&gt;, AppDynamics&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/VihasMakwana"&gt;Vihas Makwana&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;Actively seeking contributors to triage issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the triager role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#triager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pjanotti"&gt;Paulo Janotti&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tigrannajaryan"&gt;Tigran Najaryan&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aneurysm9"&gt;Anthony Mirabella&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/djaglowski"&gt;Daniel Jaglowski&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/james-bebbington"&gt;James Bebbington&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jrcamp"&gt;Jay Camp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jpkrohling"&gt;Juraci Paix√£o Kr√∂hling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nilebox"&gt;Nail Islamov&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/owais"&gt;Owais Lone&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rghetia"&gt;Rahul Patel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sjkaris"&gt;Steven Karis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alolita"&gt;Alolita Sharma&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andrewhsu"&gt;Andrew Hsu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/punya"&gt;Punya Biswal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/flands"&gt;Steve Flanders&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Thanks to all of our contributors!&lt;/h3&gt; 
&lt;a href="https://github.com/open-telemetry/opentelemetry-collector/graphs/contributors"&gt; &lt;img alt="Repo contributors" src="https://contrib.rocks/image?repo=open-telemetry/opentelemetry-collector" /&gt; &lt;/a&gt;</description>
    </item>
    
  </channel>
</rss>