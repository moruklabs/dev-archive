<rss version="2.0">
  <channel>
    <title>GitHub Python Weekly Trending</title>
    <description>Weekly Trending of Python in GitHub</description>
    <pubDate>Mon, 18 Aug 2025 01:46:09 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>exo-explore/exo</title>
      <link>https://github.com/exo-explore/exo</link>
      <description>&lt;p&gt;Run your own AI cluster at home with everyday devices üì±üíª üñ•Ô∏è‚åö&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="/docs/exo-logo-black-bg.jpg" /&gt; 
  &lt;img alt="exo logo" src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/exo-logo-transparent.png" width="50%" height="50%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;exo: Run your own AI cluster at home with everyday devices. Maintained by &lt;a href="https://x.com/exolabs"&gt;exo labs&lt;/a&gt;.&lt;/p&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://discord.gg/EUnjGpsmWw"&gt;Discord&lt;/a&gt; | &lt;a href="https://t.me/+Kh-KqHTzFYg3MGNk"&gt;Telegram&lt;/a&gt; | &lt;a href="https://x.com/exolabs"&gt;X&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/exo-explore/exo/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/exo-explore/exo" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://dl.circleci.com/status-badge/redirect/circleci/TrkofJDoGzdQAeL6yVHKsg/4i5hJuafuwZYZQxbRAWS71/tree/main"&gt;&lt;img src="https://dl.circleci.com/status-badge/img/circleci/TrkofJDoGzdQAeL6yVHKsg/4i5hJuafuwZYZQxbRAWS71/tree/main.svg?style=svg" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://www.gnu.org/licenses/gpl-3.0"&gt;&lt;img src="https://img.shields.io/badge/License-GPLv3-blue.svg?sanitize=true" alt="License: GPL v3" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11849" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11849" alt="exo-explore%2Fexo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;Unify your existing devices into one powerful GPU: iPhone, iPad, Android, Mac, NVIDIA, Raspberry Pi, pretty much any device!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;Update: exo is hiring. See &lt;a href="https://exolabs.net"&gt;here&lt;/a&gt; for more details.&lt;/h2&gt; 
 &lt;h2&gt;Interested in running exo in your business? &lt;a href="mailto:hello@exolabs.net"&gt;Contact us&lt;/a&gt; to discuss.&lt;/h2&gt; 
&lt;/div&gt; 
&lt;h2&gt;Get Involved&lt;/h2&gt; 
&lt;p&gt;exo is &lt;strong&gt;experimental&lt;/strong&gt; software. Expect bugs early on. Create issues so they can be fixed. The &lt;a href="https://x.com/exolabs"&gt;exo labs&lt;/a&gt; team will strive to resolve issues quickly.&lt;/p&gt; 
&lt;p&gt;We also welcome contributions from the community. We have a list of bounties in &lt;a href="https://docs.google.com/spreadsheets/d/1cTCpTIp48UnnIvHeLEUNg1iMy_Q6lRybgECSFCoVJpE/edit?usp=sharing"&gt;this sheet&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Wide Model Support&lt;/h3&gt; 
&lt;p&gt;exo supports different models including LLaMA (&lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/mlx/models/llama.py"&gt;MLX&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/tinygrad/models/llama.py"&gt;tinygrad&lt;/a&gt;), Mistral, LlaVA, Qwen, and Deepseek.&lt;/p&gt; 
&lt;h3&gt;Dynamic Model Partitioning&lt;/h3&gt; 
&lt;p&gt;exo &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/ring_memory_weighted_partitioning_strategy.py"&gt;optimally splits up models&lt;/a&gt; based on the current network topology and device resources available. This enables you to run larger models than you would be able to on any single device.&lt;/p&gt; 
&lt;h3&gt;Automatic Device Discovery&lt;/h3&gt; 
&lt;p&gt;exo will &lt;a href="https://github.com/exo-explore/exo/raw/945f90f676182a751d2ad7bcf20987ab7fe0181e/exo/orchestration/node.py#L154"&gt;automatically discover&lt;/a&gt; other devices using the best method available. Zero manual configuration.&lt;/p&gt; 
&lt;h3&gt;ChatGPT-compatible API&lt;/h3&gt; 
&lt;p&gt;exo provides a &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/api/chatgpt_api.py"&gt;ChatGPT-compatible API&lt;/a&gt; for running models. It's a &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/examples/chatgpt_api.sh"&gt;one-line change&lt;/a&gt; in your application to run models on your own hardware using exo.&lt;/p&gt; 
&lt;h3&gt;Device Equality&lt;/h3&gt; 
&lt;p&gt;Unlike other distributed inference frameworks, exo does not use a master-worker architecture. Instead, exo devices &lt;a href="https://github.com/exo-explore/exo/raw/945f90f676182a751d2ad7bcf20987ab7fe0181e/exo/orchestration/node.py#L161"&gt;connect p2p&lt;/a&gt;. As long as a device is connected somewhere in the network, it can be used to run models.&lt;/p&gt; 
&lt;p&gt;Exo supports different &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/partitioning_strategy.py"&gt;partitioning strategies&lt;/a&gt; to split up a model across devices. The default partitioning strategy is &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/topology/ring_memory_weighted_partitioning_strategy.py"&gt;ring memory weighted partitioning&lt;/a&gt;. This runs an inference in a ring where each device runs a number of model layers proportional to the memory of the device.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/exo-screenshot.jpg" alt="&amp;quot;A screenshot of exo running 5 nodes" /&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The current recommended way to install exo is from source.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python&amp;gt;=3.12.0 is required because of &lt;a href="https://github.com/exo-explore/exo/issues/5"&gt;issues with asyncio&lt;/a&gt; in previous versions.&lt;/li&gt; 
 &lt;li&gt;For Linux with NVIDIA GPU support (Linux-only, skip if not using Linux or NVIDIA): 
  &lt;ul&gt; 
   &lt;li&gt;NVIDIA driver - verify with &lt;code&gt;nvidia-smi&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;CUDA toolkit - install from &lt;a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#cuda-cross-platform-installation"&gt;NVIDIA CUDA guide&lt;/a&gt;, verify with &lt;code&gt;nvcc --version&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;cuDNN library - download from &lt;a href="https://developer.nvidia.com/cudnn-downloads"&gt;NVIDIA cuDNN page&lt;/a&gt;, verify installation by following &lt;a href="https://docs.nvidia.com/deeplearning/cudnn/latest/installation/linux.html#verifying-the-install-on-linux:~:text=at%20a%20time.-,Verifying%20the%20Install%20on%20Linux,Test%20passed!,-Upgrading%20From%20Older"&gt;these steps&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Hardware Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The only requirement to run exo is to have enough memory across all your devices to fit the entire model into memory. For example, if you are running llama 3.1 8B (fp16), you need 16GB of memory across all devices. Any of the following configurations would work since they each have more than 16GB of memory in total: 
  &lt;ul&gt; 
   &lt;li&gt;2 x 8GB M3 MacBook Airs&lt;/li&gt; 
   &lt;li&gt;1 x 16GB NVIDIA RTX 4070 Ti Laptop&lt;/li&gt; 
   &lt;li&gt;2 x Raspberry Pi 400 with 4GB of RAM each (running on CPU) + 1 x 8GB Mac Mini&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;exo is designed to run on devices with heterogeneous capabilities. For example, you can have some devices with powerful GPUs and others with integrated GPUs or even CPUs. Adding less capable devices will slow down individual inference latency but will increase the overall throughput of the cluster.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;From source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/exo-explore/exo.git
cd exo
pip install -e .
# alternatively, with venv
source install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;If running on Mac, MLX has an &lt;a href="https://ml-explore.github.io/mlx/build/html/install.html"&gt;install guide&lt;/a&gt; with troubleshooting steps.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;There are a number of things users have empirically found to improve performance on Apple Silicon Macs:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol&gt; 
 &lt;li&gt;Upgrade to the latest version of macOS Sequoia.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;./configure_mlx.sh&lt;/code&gt;. This runs commands to optimize GPU memory allocation on Apple Silicon Macs.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;h3&gt;Example Usage on Multiple macOS Devices&lt;/h3&gt; 
&lt;h4&gt;Device 1:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Device 2:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it! No configuration required - exo will automatically discover the other device(s).&lt;/p&gt; 
&lt;p&gt;exo starts a ChatGPT-like WebUI (powered by &lt;a href="https://github.com/tinygrad/tinygrad/tree/master/examples/tinychat"&gt;tinygrad tinychat&lt;/a&gt;) on &lt;a href="http://localhost:52415"&gt;http://localhost:52415&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For developers, exo also starts a ChatGPT-compatible API endpoint on &lt;a href="http://localhost:52415/v1/chat/completions"&gt;http://localhost:52415/v1/chat/completions&lt;/a&gt;. Examples with curl:&lt;/p&gt; 
&lt;h4&gt;Llama 3.2 3B:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "llama-3.2-3b",
     "messages": [{"role": "user", "content": "What is the meaning of exo?"}],
     "temperature": 0.7
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Llama 3.1 405B:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "llama-3.1-405b",
     "messages": [{"role": "user", "content": "What is the meaning of exo?"}],
     "temperature": 0.7
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;DeepSeek R1 (full 671B):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "deepseek-r1",
     "messages": [{"role": "user", "content": "What is the meaning of exo?"}],
     "temperature": 0.7
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Llava 1.5 7B (Vision Language Model):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl http://localhost:52415/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "llava-1.5-7b-hf",
     "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "What are these?"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "http://images.cocodataset.org/val2017/000000039769.jpg"
            }
          }
        ]
      }
    ],
     "temperature": 0.0
   }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example Usage on Multiple Heterogenous Devices (macOS + Linux)&lt;/h3&gt; 
&lt;h4&gt;Device 1 (macOS):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: We don't need to explicitly tell exo to use the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine. &lt;strong&gt;MLX&lt;/strong&gt; and &lt;strong&gt;tinygrad&lt;/strong&gt; are interoperable!&lt;/p&gt; 
&lt;h4&gt;Device 2 (Linux):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Linux devices will automatically default to using the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine.&lt;/p&gt; 
&lt;p&gt;You can read about tinygrad-specific env vars &lt;a href="https://docs.tinygrad.org/env_vars/"&gt;here&lt;/a&gt;. For example, you can configure tinygrad to use the cpu by specifying &lt;code&gt;CLANG=1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Example Usage on a single device with "exo run" command&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo run llama-3.2-3b
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With a custom prompt:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;exo run llama-3.2-3b --prompt "What is the meaning of exo?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Model Storage&lt;/h3&gt; 
&lt;p&gt;Models by default are stored in &lt;code&gt;~/.cache/exo/downloads&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can set a different model storage location by setting the &lt;code&gt;EXO_HOME&lt;/code&gt; env var.&lt;/p&gt; 
&lt;h2&gt;Model Downloading&lt;/h2&gt; 
&lt;p&gt;Models are downloaded from Hugging Face. If you are running exo in a country with strict internet censorship, you may need to download the models manually and put them in the &lt;code&gt;~/.cache/exo/downloads&lt;/code&gt; directory.&lt;/p&gt; 
&lt;p&gt;To download models from a proxy endpoint, set the &lt;code&gt;HF_ENDPOINT&lt;/code&gt; environment variable. For example, to run exo with the huggingface mirror endpoint:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;HF_ENDPOINT=https://hf-mirror.com exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Debugging&lt;/h2&gt; 
&lt;p&gt;Enable debug logs with the DEBUG environment variable (0-9).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;DEBUG=9 exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the &lt;strong&gt;tinygrad&lt;/strong&gt; inference engine specifically, there is a separate DEBUG flag &lt;code&gt;TINYGRAD_DEBUG&lt;/code&gt; that can be used to enable debug logs (1-6).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;TINYGRAD_DEBUG=2 exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Formatting&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/google/yapf"&gt;yapf&lt;/a&gt; to format the code. To format the code, first install the formatting requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip3 install -e '.[formatting]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run the formatting script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;python3 format.py ./exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Known Issues&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;On certain versions of Python on macOS, certificates may not installed correctly, potentially causing SSL errors (e.g., when accessing huggingface.co). To resolve this, run the &lt;code&gt;Install Certificates&lt;/code&gt; command, typicall as follows:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;/Applications/Python 3.x/Install Certificates.command
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöß As the library is evolving so quickly, the iOS implementation has fallen behind Python. We have decided for now not to put out the buggy iOS version and receive a bunch of GitHub issues for outdated code. We are working on solving this properly and will make an announcement when it's ready. If you would like access to the iOS implementation now, please email &lt;a href="mailto:alex@exolabs.net"&gt;alex@exolabs.net&lt;/a&gt; with your GitHub username explaining your use-case and you will be granted access on GitHub.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Inference Engines&lt;/h2&gt; 
&lt;p&gt;exo supports the following inference engines:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/mlx/sharded_inference_engine.py"&gt;MLX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/inference/tinygrad/inference.py"&gt;tinygrad&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöß &lt;a href="https://github.com/exo-explore/exo/pull/139"&gt;PyTorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöß &lt;a href="https://github.com/exo-explore/exo/issues/167"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Discovery Modules&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/udp"&gt;UDP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/manual"&gt;Manual&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/tailscale"&gt;Tailscale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöß Radio&lt;/li&gt; 
 &lt;li&gt;üöß Bluetooth&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Peer Networking Modules&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/exo/networking/grpc"&gt;GRPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üöß NCCL&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>omkarcloud/botasaurus</title>
      <link>https://github.com/omkarcloud/botasaurus</link>
      <description>&lt;p&gt;The All in One Framework to Build Undefeatable Scrapers&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/mascot.png" alt="botasaurus" /&gt; &lt;/p&gt; 
&lt;div align="center" style="margin-top: 0;"&gt; 
 &lt;h1&gt;ü§ñ Botasaurus ü§ñ&lt;/h1&gt; 
&lt;/div&gt; 
&lt;h3 align="center"&gt; The All in One Framework to Build Undefeatable Scrapers &lt;/h3&gt; 
&lt;p align="center"&gt; &lt;b&gt;The web has evolved. Finally, web scraping has too.&lt;/b&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://views.whatilearened.today/views/github/omkarcloud/botasaurus.svg?sanitize=true" width="80px" height="28px" alt="View" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://gitpod.io/#https://github.com/omkarcloud/botasaurus-starter"&gt; &lt;img alt="Run in Gitpod" src="https://gitpod.io/button/open-in-gitpod.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üêøÔ∏è Botasaurus In a Nutshell&lt;/h2&gt; 
&lt;p&gt;How wonderful that of all the web scraping tools out there, you chose to learn about Botasaurus. Congratulations!&lt;/p&gt; 
&lt;p&gt;And now that you are here, you are in for an exciting, unusual, and rewarding journey that will make your web scraping life a lot easier.&lt;/p&gt; 
&lt;p&gt;Now, let me tell you about Botasaurus in bullet points. (Because as per marketing gurus, YOU as a member of the Developer Tribe have a VERY short attention span.)&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;So, what is Botasaurus?&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Botasaurus is an all-in-one web scraping framework that enables you to build awesome scrapers in less time, with less code, and with more fun.&lt;/p&gt; 
&lt;p&gt;We have put all our web scraping experience and best practices into Botasaurus to save you hundreds of hours of development time!&lt;/p&gt; 
&lt;p&gt;Now, for the magical powers awaiting you after learning Botasaurus:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;In terms of humaneness, what Superman is to Man, Botasaurus is to Selenium and Playwright. Easily pass every (Yes, E-V-E-R-Y) bot test, and build undetected scrapers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In the video below, watch as we &lt;strong&gt;bypass some of the best bot detection systems&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://nopecha.com/demo/cloudflare"&gt;Cloudflare Web Application Firewall (WAF)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://www.browserscan.net/bot-detection"&gt;BrowserScan Bot Detection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://fingerprint.com/products/bot-detection/"&gt;Fingerprint Bot Detection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://antoinevastel.com/bots/datadome"&gt;Datadome Bot Detection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;a href="https://turnstile.zeroclover.io/"&gt;Cloudflare Turnstile CAPTCHA&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; 
 &lt;video src="https://github.com/user-attachments/assets/b4f6171f-f2a2-4255-9feb-2973ee9a25ae"&gt;&lt;/video&gt; &lt;/p&gt; 
&lt;p&gt;üîó Want to try it yourself? See the code behind these tests &lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/bot_detection_tests.py"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Perform realistic, human-like mouse movements and say sayonara to detection &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/human-mode-demo.gif" alt="human-mode-demo" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Convert your scraper into a desktop app for Mac, Windows, and Linux in 1 day, so not only developers but everyone can use your web scraper.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/desktop-app-photo.png" alt="desktop-app-photo" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Turn your scraper into a beautiful website, making it easy for your customers to use it from anywhere, anytime.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/google-maps-scraper/master/screenshots/demo.gif" alt="pro-gmaps-demo" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Save up to 97%, yes 97%, on browser proxy costs by using &lt;a href="https://github.com/omkarcloud/botasaurus#how-to-significantly-reduce-proxy-costs-when-scraping-at-scale"&gt;browser-based fetch requests.&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Easily save hours of development time with easy parallelization, profiles, extensions, and proxy configuration. Botasaurus makes asynchronous, parallel scraping child's play.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Use caching, sitemap, data cleaning, and other utilities to save hours of time spent writing and debugging code.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Easily scale your scraper to multiple machines with Kubernetes, and get your data faster than ever.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And those are just the highlights. I mean!&lt;/p&gt; 
&lt;p&gt;There is so much more to Botasaurus that you will be amazed at how much time you will save with it.&lt;/p&gt; 
&lt;h2&gt;üöÄ Getting Started with Botasaurus&lt;/h2&gt; 
&lt;p&gt;Let's dive right in with a straightforward example to understand Botasaurus.&lt;/p&gt; 
&lt;p&gt;In this example, we will go through the steps to scrape the heading text from &lt;a href="https://www.omkar.cloud/"&gt;https://www.omkar.cloud/&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/starter-bot-running.gif" alt="Botasaurus in action" /&gt;&lt;/p&gt; 
&lt;h3&gt;Step 1: Install Botasaurus&lt;/h3&gt; 
&lt;p&gt;First things first, you need to install Botasaurus. Run the following command in your terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python -m pip install --upgrade botasaurus
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Set Up Your Botasaurus Project&lt;/h3&gt; 
&lt;p&gt;Next, let's set up the project:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a directory for your Botasaurus project and navigate into it:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;mkdir my-botasaurus-project
cd my-botasaurus-project
code .  # This will open the project in VSCode if you have it installed
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 3: Write the Scraping Code&lt;/h3&gt; 
&lt;p&gt;Now, create a Python script named &lt;code&gt;main.py&lt;/code&gt; in your project directory and paste the following code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser
def scrape_heading_task(driver: Driver, data):
    # Visit the Omkar Cloud website
    driver.get("https://www.omkar.cloud/")
    
    # Retrieve the heading element's text
    heading = driver.get_text("h1")

    # Save the data as a JSON file in output/scrape_heading_task.json
    return {
        "heading": heading
    }
     
# Initiate the web scraping task
scrape_heading_task()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Let's understand this code:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We define a custom scraping task, &lt;code&gt;scrape_heading_task&lt;/code&gt;, decorated with &lt;code&gt;@browser&lt;/code&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser
def scrape_heading_task(driver: Driver, data):
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Botasaurus automatically provides a Humane Driver to our function:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def scrape_heading_task(driver: Driver, data):
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Inside the function, we: 
  &lt;ul&gt; 
   &lt;li&gt;Visit Omkar Cloud&lt;/li&gt; 
   &lt;li&gt;Extract the heading text&lt;/li&gt; 
   &lt;li&gt;Return the data to be automatically saved as &lt;code&gt;scrape_heading_task.json&lt;/code&gt; by Botasaurus:&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;    driver.get("https://www.omkar.cloud/")
    heading = driver.get_text("h1")
    return {"heading": heading}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Finally, we initiate the scraping task:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Initiate the web scraping task
scrape_heading_task()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 4: Run the Scraping Task&lt;/h3&gt; 
&lt;p&gt;Time to run it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After executing the script, it will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Launch Google Chrome&lt;/li&gt; 
 &lt;li&gt;Visit &lt;a href="https://www.omkar.cloud/"&gt;omkar.cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Extract the heading text&lt;/li&gt; 
 &lt;li&gt;Save it automatically as &lt;code&gt;output/scrape_heading_task.json&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/starter-bot-running.gif" alt="Botasaurus in action" /&gt;&lt;/p&gt; 
&lt;p&gt;Now, let's explore another way to scrape the heading using the &lt;code&gt;request&lt;/code&gt; module. Replace the previous code in &lt;code&gt;main.py&lt;/code&gt; with the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.request import request, Request
from botasaurus.soupify import soupify

@request
def scrape_heading_task(request: Request, data):
    # Visit the Omkar Cloud website
    response = request.get("https://www.omkar.cloud/")

    # Create a BeautifulSoup object    
    soup = soupify(response)
    
    # Retrieve the heading element's text
    heading = soup.find('h1').get_text()

    # Save the data as a JSON file in output/scrape_heading_task.json
    return {
        "heading": heading
    }     
# Initiate the web scraping task
scrape_heading_task()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this code:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We scrape the HTML using &lt;code&gt;request&lt;/code&gt;, which is specifically designed for making browser-like humane requests.&lt;/li&gt; 
 &lt;li&gt;Next, we parse the HTML into a &lt;code&gt;BeautifulSoup&lt;/code&gt; object using &lt;code&gt;soupify()&lt;/code&gt; and extract the heading.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 5: Run the Scraping Task (which makes Humane HTTP Requests)&lt;/h3&gt; 
&lt;p&gt;Finally, run it again:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This time, you will observe the exact same result as before, but instead of opening a whole browser, we are making browser-like humane HTTP requests.&lt;/p&gt; 
&lt;h2&gt;üí° Understanding Botasaurus&lt;/h2&gt; 
&lt;h3&gt;What is Botasaurus Driver, and why should I use it over Selenium and Playwright?&lt;/h3&gt; 
&lt;p&gt;Botasaurus Driver is a web automation driver like Selenium, and the single most important reason to use it is because it is truly humane. You will not, and I repeat NOT, have any issues accessing any website.&lt;/p&gt; 
&lt;p&gt;Plus, it is super fast to launch and use, and the API is designed by and for web scrapers, and you will love it.&lt;/p&gt; 
&lt;h3&gt;How do I access Cloudflare-protected pages using Botasaurus?&lt;/h3&gt; 
&lt;p&gt;Cloudflare is the most popular protection system on the web. So, let's see how Botasaurus can help you solve various Cloudflare challenges.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Connection Challenge&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This is the single most popular challenge and requires making a browser-like connection with appropriate headers. It's commonly used for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Product Pages&lt;/li&gt; 
 &lt;li&gt;Blog Pages&lt;/li&gt; 
 &lt;li&gt;Search Result Pages&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- Example Page: https://www.g2.com/products/github/reviews --&gt; 
&lt;h4&gt;What Works?&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visiting the website via Google Referrer (which makes it seem as if the user has arrived from a Google search).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser
def scrape_heading_task(driver: Driver, data):
    # Visit the website via Google Referrer
    driver.google_get("https://www.cloudflare.com/en-in/")
    driver.prompt()
    heading = driver.get_text('h1')
    return heading

scrape_heading_task()
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the request module. The Request Object is smart and, by default, visits any link with a Google Referrer. Although it works, you will need to use retries.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.request import request, Request

@request(max_retry=10)
def scrape_heading_task(request: Request, data):
    response = request.get("https://www.cloudflare.com/en-in/")
    print(response.status_code)
    response.raise_for_status()
    return response.text

scrape_heading_task()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;JS with Captcha Challenge&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This challenge requires performing JS computations that differentiate a Chrome controlled by Selenium/Puppeteer/Playwright from a real Chrome. It also involves solving a Captcha. It's used to for pages which are rarely but sometimes visited by people, like:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;5th Review page&lt;/li&gt; 
 &lt;li&gt;Auth pages&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example Page: &lt;a href="https://nopecha.com/demo/cloudflare"&gt;https://nopecha.com/demo/cloudflare&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;What Does Not Work?&lt;/h4&gt; 
&lt;p&gt;Using &lt;code&gt;@request&lt;/code&gt; does not work because although it can make browser-like HTTP requests, it cannot run JavaScript to solve the challenge.&lt;/p&gt; 
&lt;h4&gt;What Works?&lt;/h4&gt; 
&lt;p&gt;Pass the &lt;code&gt;bypass_cloudflare=True&lt;/code&gt; argument to the &lt;code&gt;google_get&lt;/code&gt; method.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser
def scrape_heading_task(driver: Driver, data):
    driver.google_get("https://nopecha.com/demo/cloudflare", bypass_cloudflare=True)
    driver.prompt()

scrape_heading_task()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/cloudflare-js-captcha-demo.gif" alt="Cloudflare JS with Captcha Challenge Demo" /&gt;&lt;/p&gt; 
&lt;h3&gt;What are the benefits of a UI scraper?&lt;/h3&gt; 
&lt;p&gt;Here are some benefits of creating a scraper with a user interface:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Simplify your scraper usage for customers, eliminating the need to teach them how to modify and run your code.&lt;/li&gt; 
 &lt;li&gt;Protect your code by hosting the scraper on the web and offering a monthly subscription, rather than providing full access to your code. This approach: 
  &lt;ul&gt; 
   &lt;li&gt;Safeguards your Python code from being copied and reused, increasing your customer's lifetime value.&lt;/li&gt; 
   &lt;li&gt;Generate monthly recurring revenue via subscription from your customers, surpassing a one-time payment.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Enable sorting, filtering, and downloading of data in various formats (JSON, Excel, CSV, etc.).&lt;/li&gt; 
 &lt;li&gt;Provide access via a REST API for seamless integration.&lt;/li&gt; 
 &lt;li&gt;Create a polished frontend, backend, and API integration with minimal code.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How to run a UI-based scraper?&lt;/h3&gt; 
&lt;p&gt;Let's run the Botasaurus Starter Template (the recommended template for greenfield Botasaurus projects), which scrapes the heading of the provided link by following these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the Starter Template:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;git clone https://github.com/omkarcloud/botasaurus-starter my-botasaurus-project
cd my-botasaurus-project
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install dependencies (will take a few minutes):&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python -m pip install -r requirements.txt
python run.py install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the scraper:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python run.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Your browser will automatically open up at &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt;. Then, enter the link you want to scrape (e.g., &lt;a href="https://www.omkar.cloud/"&gt;https://www.omkar.cloud/&lt;/a&gt;) and click on the Run Button.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/starter-scraper-demo.gif" alt="starter-scraper-demo" /&gt;&lt;/p&gt; 
&lt;p&gt;After some seconds, the data will be scraped. &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/starter-scraper-demo-result.png" alt="starter-scraper-demo-result" /&gt;&lt;/p&gt; 
&lt;p&gt;Visit &lt;a href="http://localhost:3000/output"&gt;http://localhost:3000/output&lt;/a&gt; to see all the tasks you have started.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/starter-scraper-demo-tasks.png" alt="starter-scraper-demo-tasks" /&gt;&lt;/p&gt; 
&lt;p&gt;Go to &lt;a href="http://localhost:3000/about"&gt;http://localhost:3000/about&lt;/a&gt; to see the rendered README.md file of the project.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/starter-scraper-demo-readme.png" alt="starter-scraper-demo-readme" /&gt;&lt;/p&gt; 
&lt;p&gt;Finally, visit &lt;a href="http://localhost:3000/api-integration"&gt;http://localhost:3000/api-integration&lt;/a&gt; to see how to access the scraper via API.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/starter-scraper-demo-api.png" alt="starter-scraper-demo-api" /&gt;&lt;/p&gt; 
&lt;p&gt;The API documentation is generated dynamically based on your scraper's inputs, sorts, filters, etc., and is unique to your scraper.&lt;/p&gt; 
&lt;p&gt;So, whenever you need to run the scraper via API, visit this tab and copy the code specific to your scraper.&lt;/p&gt; 
&lt;h3&gt;How to create a UI scraper using Botasaurus?&lt;/h3&gt; 
&lt;p&gt;Creating a UI scraper with Botasaurus is a simple 3-step process:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create your scraper function&lt;/li&gt; 
 &lt;li&gt;Add the scraper to the server using 1 line of code&lt;/li&gt; 
 &lt;li&gt;Define the input controls for the scraper&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To understand these steps, let's go through the code of the Botasaurus Starter Template that you just ran.&lt;/p&gt; 
&lt;h4&gt;Step 1: Create the Scraper Function&lt;/h4&gt; 
&lt;p&gt;In &lt;code&gt;src/scrape_heading_task.py&lt;/code&gt;, we define a scraping function that basically does the following:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Receives a &lt;code&gt;data&lt;/code&gt; object and extracts the "link".&lt;/li&gt; 
 &lt;li&gt;Retrieves the HTML content of the webpage using the "link".&lt;/li&gt; 
 &lt;li&gt;Converts the HTML into a BeautifulSoup object.&lt;/li&gt; 
 &lt;li&gt;Locates the heading element, extracts its text content, and returns it.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.request import request, Request
from botasaurus.soupify import soupify

@request
def scrape_heading_task(request: Request, data):
    # Visit the Link
    response = request.get(data["link"])

    # Create a BeautifulSoup object    
    soup = soupify(response)
    
    # Retrieve the heading element's text
    heading = soup.find('h1').get_text()

    # Save the data as a JSON file in output/scrape_heading_task.json
    return {
        "heading": heading
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 2: Add the Scraper to the Server&lt;/h4&gt; 
&lt;p&gt;In &lt;code&gt;backend/scrapers.py&lt;/code&gt;, we:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Import our scraping function&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;Server.add_scraper()&lt;/code&gt; to register the scraper&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus_server.server import Server
from src.scrape_heading_task import scrape_heading_task

# Add the scraper to the server
Server.add_scraper(scrape_heading_task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 3: Define the Input Controls&lt;/h4&gt; 
&lt;p&gt;In &lt;code&gt;backend/inputs/scrape_heading_task.js&lt;/code&gt;, we:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Define a &lt;code&gt;getInput&lt;/code&gt; function that takes the controls parameter&lt;/li&gt; 
 &lt;li&gt;Add a link input control to it&lt;/li&gt; 
 &lt;li&gt;Use JSDoc comments to enable IntelliSense Code Completion in VSCode as you won't be able to remember all the controls in botasaurus.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;/**
 * @typedef {import('../../frontend/node_modules/botasaurus-controls/dist/index').Controls} Controls
 */

/**
 * @param {Controls} controls
 */
function getInput(controls) {
    controls
        // Render a Link Input, which is required, defaults to "https://stackoverflow.blog/open-source". 
        .link('link', { isRequired: true, defaultValue: "https://stackoverflow.blog/open-source" })
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Above was a simple example; below is a real-world example with multi-text, number, switch, select, section, and other controls.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;/**
 * @typedef {import('../../frontend/node_modules/botasaurus-controls/dist/index').Controls} Controls
 */


/**
 * @param {Controls} controls
 */
function getInput(controls) {
    controls
        .listOfTexts('queries', {
            defaultValue: ["Web Developers in Bangalore"],
            placeholder: "Web Developers in Bangalore",
            label: 'Search Queries',
            isRequired: true
        })
        .section("Email and Social Links Extraction", (section) =&amp;gt; {
            section.text('api_key', {
                placeholder: "2e5d346ap4db8mce4fj7fc112s9h26s61e1192b6a526af51n9",
                label: 'Email and Social Links Extraction API Key',
                helpText: 'Enter your API key to extract email addresses and social media links.',
            })
        })
        .section("Reviews Extraction", (section) =&amp;gt; {
            section
                .switch('enable_reviews_extraction', {
                    label: "Enable Reviews Extraction"
                })
                .numberGreaterThanOrEqualToZero('max_reviews', {
                    label: 'Max Reviews per Place (Leave empty to extract all reviews)',
                    placeholder: 20,
                    isShown: (data) =&amp;gt; data['enable_reviews_extraction'], defaultValue: 20,
                })
                .choose('reviews_sort', {
                    label: "Sort Reviews By",
                    isRequired: true, isShown: (data) =&amp;gt; data['enable_reviews_extraction'], defaultValue: 'newest', options: [{ value: 'newest', label: 'Newest' }, { value: 'most_relevant', label: 'Most Relevant' }, { value: 'highest_rating', label: 'Highest Rating' }, { value: 'lowest_rating', label: 'Lowest Rating' }]
                })
        })
        .section("Language and Max Results", (section) =&amp;gt; {
            section
                .addLangSelect()
                .numberGreaterThanOrEqualToOne('max_results', {
                    placeholder: 100,
                    label: 'Max Results per Search Query (Leave empty to extract all places)'
                })
        })
        .section("Geo Location", (section) =&amp;gt; {
            section
                .text('coordinates', {
                    placeholder: '12.900490, 77.571466'
                })
                .numberGreaterThanOrEqualToOne('zoom_level', {
                    label: 'Zoom Level (1-21)',
                    defaultValue: 14,
                    placeholder: 14
                })
        })
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;I encourage you to paste the above code into &lt;code&gt;backend/inputs/scrape_heading_task.js&lt;/code&gt; and reload the page, and you will see a complex set of input controls like the image shown.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/complex-input.png" alt="complex-input" /&gt;&lt;/p&gt; 
&lt;p&gt;Now, to use the Botasaurus UI for adding new scrapers, remember these points:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a &lt;code&gt;backend/inputs/{your_scraping_function_name}.js&lt;/code&gt; file for each scraping function.&lt;/li&gt; 
 &lt;li&gt;Define the &lt;code&gt;getInput&lt;/code&gt; function in the file with the necessary controls.&lt;/li&gt; 
 &lt;li&gt;Use JSDoc comments to enable IntelliSense code completion in VSCode, as you won't be able to remember all the controls in Botasaurus.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Use this template as a starting point for new scraping function's input controls js file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;/**
 * @typedef {import('../../frontend/node_modules/botasaurus-controls/dist/index').Controls} Controls
 */

/**
 * @param {Controls} controls
 */
function getInput(controls) {
    // Define your controls here.
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it! With these simple steps, you can create a fully functional UI scraper using Botasaurus.&lt;/p&gt; 
&lt;p&gt;Later, you will learn how to add sorts and filters to make your UI scraper even more powerful and user-friendly.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/sorts-filters.png" alt="sorts-filters" /&gt;&lt;/p&gt; 
&lt;h3&gt;What is a Desktop Extractor?&lt;/h3&gt; 
&lt;p&gt;A &lt;strong&gt;Desktop Extractor&lt;/strong&gt; is a standalone application that runs on your computer and extracts specific data from websites, PDFs, Excel files, and other documents. Unlike web-based tools, desktop extractors run locally, giving &lt;strong&gt;faster performance&lt;/strong&gt; and &lt;strong&gt;zero cloud costs&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/desktop-app-photo.png" alt="Desktop Extractor showing an application interface with extraction options" /&gt;&lt;/p&gt; 
&lt;h3&gt;What advantages do Desktop Scrapers have over web-based scrapers?&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Desktop Scrapers&lt;/strong&gt; offer key advantages over web-based scraper solutions like Outscraper:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Zero Infrastructure Costs&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Runs on the user's machine, eliminating expensive cloud computing fees.&lt;/li&gt; 
   &lt;li&gt;Lower cloud costs allow you to offer lower pricing, attracting more customers and increasing revenue.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Faster Execution&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Instant execution, no delays for cloud resource allocation.&lt;/li&gt; 
   &lt;li&gt;Uses the user's system, which is much faster than shared cloud servers.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Increased Customer Engagement&lt;/strong&gt;:&lt;br /&gt; The app sits right on the user's desktop, encouraging frequent use compared to web tools they must actively visit via browser.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cross-Platform Deployment in 1 Day&lt;/strong&gt;:&lt;br /&gt; With &lt;strong&gt;Botasaurus&lt;/strong&gt;, you can launch a desktop scraper for &lt;strong&gt;Windows, macOS, and Linux&lt;/strong&gt; within a day. No need to build a website, manage servers, or handle scaling issues. Bota Desktop includes built-in features such as:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Task management&lt;/li&gt; 
   &lt;li&gt;Data Table&lt;/li&gt; 
   &lt;li&gt;Data export (Excel, CSV, etc.)&lt;/li&gt; 
   &lt;li&gt;Sorting &amp;amp; Filtering&lt;/li&gt; 
   &lt;li&gt;Caching and many more&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;With zero usage costs, faster performance, and easier development, Desktop Scrapers outperform web-based alternatives.&lt;/p&gt; 
&lt;h3&gt;How to Build a Desktop Extractor&lt;/h3&gt; 
&lt;p&gt;Creating Desktop Extractors is easier than you think! All you need is a basic understanding of JavaScript. Once you're ready, read the &lt;a href="https://www.omkar.cloud/botasaurus/docs/botasaurus-desktop/quick-start"&gt;Desktop Extraction Tutorial&lt;/a&gt;, where we'll guide you through building two practical extractors:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Yahoo Finance Stock Scraper&lt;/strong&gt; ‚Äì Extracts real-time stock prices from Yahoo Finance.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/stock-scraper-preview.gif" alt="Stock Scraper Demo showing the application extracting stock prices from Yahoo Finance" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Amazon Invoice PDF Extractor&lt;/strong&gt; ‚Äì Automates the extraction of key invoice data like Document Number, Document Date, and Place of Supply from Amazon PDFs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/pdf-extract-preview.gif" alt="PDF Extraction Demo showing the application extracting data from Amazon PDF invoices" /&gt;&lt;/p&gt; 
&lt;p&gt;As a web scraper, you might naturally want to focus on web scraping. Still, I want you to create the &lt;strong&gt;Amazon Invoice PDF Extractor&lt;/strong&gt; project. Why? Because many developers overlook the immense potential of extracting data from PDFs, Excel files, and other documents.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Document Data Extraction is a large untapped market.&lt;/strong&gt; For example, even in most developed countries, accountants often spend hundreds of hours manually entering invoice data for tax filings. A desktop extractor can transform this tedious, error-prone process into a task that takes just minutes, delivering 100% accurate results.&lt;/p&gt; 
&lt;p&gt;Please read the step-by-step tutorial &lt;a href="https://www.omkar.cloud/botasaurus/docs/botasaurus-desktop/quick-start"&gt;here&lt;/a&gt;. By the end of this short guide, you'll be able to create powerful desktop extractors in very little time.&lt;/p&gt; 
&lt;h3&gt;What is Botasaurus, and what are its main features?&lt;/h3&gt; 
&lt;p&gt;Botasaurus is an all-in-one web scraping framework designed to achieve three main goals:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Provide essential web scraping utilities to streamline the scraping process.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To accomplish these goals, Botasaurus gives you 3 decorators:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;@browser&lt;/code&gt;: For scraping web pages using a humane browser.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;@request&lt;/code&gt;: For scraping web pages using lightweight and humane HTTP requests.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;@task&lt;/code&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;For scraping web pages using third-party libraries like &lt;code&gt;playwright&lt;/code&gt; or &lt;code&gt;selenium&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;or, For running non-web scraping tasks, such as data processing (e.g., converting video to audio). Botasaurus is not limited to web scraping tasks; any Python function can be made accessible with a stunning UI and user-friendly API.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In practice, while developing with Botasaurus, you will spend most of your time in the following areas:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Configuring your scrapers via decorators with settings like: 
  &lt;ul&gt; 
   &lt;li&gt;Which proxy to use&lt;/li&gt; 
   &lt;li&gt;How many scrapers to run in parallel, etc.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Writing your core web scraping logic using BeautifulSoup (bs4) or the Botasaurus Driver.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, you will utilize the following Botasaurus utilities for debugging and development:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bt&lt;/code&gt;: Mainly for writing JSON, EXCEL, and HTML temporary files, and for data cleaning.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Sitemap&lt;/code&gt;: For accessing the website's links and sitemap.&lt;/li&gt; 
 &lt;li&gt;Minor utilities like: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;LocalStorage&lt;/code&gt;: For storing scraper state.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;soupify&lt;/code&gt;: For creating BeautifulSoup objects from Driver, Requests response, Driver Element, or HTML string.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;IPUtils&lt;/code&gt;: For obtaining information (IP, country, etc.) about the current IP address.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Cache&lt;/code&gt;: For managing the cache.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By simply configuring these three decorators (&lt;code&gt;@browser&lt;/code&gt;, &lt;code&gt;@request&lt;/code&gt;, and &lt;code&gt;@task&lt;/code&gt;) with arguments, you can easily create &lt;code&gt;real-time scrapers&lt;/code&gt; and &lt;code&gt;large-scale datasets&lt;/code&gt;, thus saving you countless hours that would otherwise be spent writing and debugging code from scratch.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;Offering a Python-based UI scraper that allows non-technical users to run scrapers online by simply visiting a website link. (As described in the previous FAQ)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Make it easy to create desktop applications for Mac, Windows, and Linux, using JavaScript. More details can be found in the &lt;a href="https://www.omkar.cloud/botasaurus/docs/botasaurus-desktop/introduction"&gt;Botasaurus Desktop Documentation here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;How to use decorators in Botasaurus?&lt;/h3&gt; 
&lt;p&gt;Decorators are the heart of Botasaurus. To use a decorator function, you can call it with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A single item&lt;/li&gt; 
 &lt;li&gt;A list of items&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If a scraping function is given a list of items, it will sequentially call the scraping function for each data item.&lt;/p&gt; 
&lt;p&gt;For example, if you pass a list of three links to the &lt;code&gt;scrape_heading_task&lt;/code&gt; function:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser
def scrape_heading_task(driver: Driver, link):
    driver.get(link)
    heading = driver.get_text("h1")
    return heading

scrape_heading_task(["https://www.omkar.cloud/", "https://www.omkar.cloud/blog/", "https://stackoverflow.com/"]) # &amp;lt;-- list of items
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, Botasaurus will launch a new browser instance for each item, and the final results will be stored in &lt;code&gt;output/scrape_heading_task.json&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/list-demo.gif" alt="list-demo" /&gt;&lt;/p&gt; 
&lt;h3&gt;How does Botasaurus help me in debugging?&lt;/h3&gt; 
&lt;p&gt;Botasaurus helps you in debugging by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Easily viewing the result of the scraping function, as it is saved in &lt;code&gt;output/{your_scraping_function_name}.json&lt;/code&gt;. Say goodbye to print statements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/scraped-data.png" alt="scraped data" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bringing your attention to errors in browser mode with a beep sound and pausing the browser, allowing you to debug the error on the spot.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/error-prompt.png" alt="" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Even if an exception is raised in headless mode, it will still open the website in your default browser, making it easier to debug code in a headless browser. (Isn't it cool?)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/headless-error.png" alt="headless-error" /&gt;&lt;/p&gt; 
&lt;h3&gt;How to configure the Browser Decorator?&lt;/h3&gt; 
&lt;p&gt;The Browser Decorator allows you to easily configure various aspects of the browser, such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Blocking images and CSS&lt;/li&gt; 
 &lt;li&gt;Setting up proxies&lt;/li&gt; 
 &lt;li&gt;Specifying profiles&lt;/li&gt; 
 &lt;li&gt;Enabling headless mode&lt;/li&gt; 
 &lt;li&gt;Using Chrome extensions&lt;/li&gt; 
 &lt;li&gt;Captcha Solving&lt;/li&gt; 
 &lt;li&gt;Selecting language&lt;/li&gt; 
 &lt;li&gt;Passing Arguments to Chrome&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Blocking Images and CSS&lt;/h4&gt; 
&lt;p&gt;Blocking images is one of the most important configurations when scraping at scale. Blocking images can significantly:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Speed up your web scraping tasks&lt;/li&gt; 
 &lt;li&gt;Reduce bandwidth usage&lt;/li&gt; 
 &lt;li&gt;And save money on proxies. (Best of All!)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, a page that originally takes 4 seconds and 12 MB to load might only take one second and 100 KB after blocking images and CSS.&lt;/p&gt; 
&lt;p&gt;To block images, use the &lt;code&gt;block_images&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser(
    block_images=True,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To block both images and CSS, use &lt;code&gt;block_images_and_css&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser(
    block_images_and_css=True,
)    
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Proxies&lt;/h4&gt; 
&lt;p&gt;To use proxies, simply specify the &lt;code&gt;proxy&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser(
    proxy="http://username:password@proxy-provider-domain:port"
)    
def visit_what_is_my_ip(driver: Driver, data):
    driver.get("https://whatismyipaddress.com/")
    driver.prompt()

visit_what_is_my_ip()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also pass a list of proxies, and the proxy will be automatically rotated:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser(
    proxy=[
        "http://username:password@proxy-provider-domain:port", 
        "http://username2:password2@proxy-provider-domain:port"
    ]
)
def visit_what_is_my_ip(driver: Driver, data):
    driver.get("https://whatismyipaddress.com/")
    driver.prompt()

visit_what_is_my_ip() 
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Profile&lt;/h4&gt; 
&lt;p&gt;Easily specify the Chrome profile using the &lt;code&gt;profile&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser(
    profile="pikachu"
)    
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;However, each Chrome profile can become very large (e.g., 100 MB) and can eat up all your computer storage.&lt;/p&gt; 
&lt;p&gt;To solve this problem, use the &lt;code&gt;tiny_profile&lt;/code&gt; option, which is a lightweight alternative to Chrome profiles.&lt;/p&gt; 
&lt;p&gt;When creating hundreds of Chrome profiles, it is highly recommended to use the &lt;code&gt;tiny_profile&lt;/code&gt; option because:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Creating 1000 Chrome profiles will take at least 100 GB, whereas 1000 tiny profiles will take up only 1 MB of storage, making tiny profiles easy to store and back up.&lt;/li&gt; 
 &lt;li&gt;Tiny profiles are cross-platform, meaning you can create profiles on a Linux server, copy the &lt;code&gt;./profiles&lt;/code&gt; folder to a Windows PC, and easily run them.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Under the hood, tiny profiles persist cookies from visited websites, making them extremely lightweight (around 1 KB) while providing the same session persistence.&lt;/p&gt; 
&lt;p&gt;Here's how to use the tiny profile:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser(
    tiny_profile=True, 
    profile="pikachu",
)    
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Headless Mode&lt;/h4&gt; 
&lt;p&gt;Enable headless mode with &lt;code&gt;headless=True&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser(
    headless=True
)    
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that if you use headless mode, you will surely be identified by services like Cloudflare and Datadome. Therefore, use headless mode only when scraping websites that don't use such services.&lt;/p&gt; 
&lt;h4&gt;Chrome Extensions&lt;/h4&gt; 
&lt;p&gt;Botasaurus allows the use of ANY Chrome Extension with just 1 line of code. The example below shows how to use the Mouse Coordinates Chrome Extension to show current mouse X and Y coordinates on web pages:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver
from chrome_extension_python import Extension

@browser(
    extensions=[
        Extension(
            "https://chromewebstore.google.com/detail/mouse-coordinates/mfohnjojhopfcahiddmeljeholnciakl"
        )
    ],
)
def scrape_while_blocking_ads(driver: Driver, data):
    driver.get("https://example.com/")
    driver.prompt()

scrape_while_blocking_ads()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In some cases, an extension may require additional configuration, such as API keys or credentials. For such scenarios, you can create a custom extension. Learn more about creating and configuring custom extensions &lt;a href="https://github.com/omkarcloud/chrome-extension-python"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Captcha Solving&lt;/h4&gt; 
&lt;p&gt;Encountering captchas is common in web scraping. You can use the &lt;a href="https://github.com/omkarcloud/capsolver-extension-python?tab=readme-ov-file#installation"&gt;capsolver_extension_python&lt;/a&gt; package to automatically solve CAPTCHAs with Capsolver.&lt;/p&gt; 
&lt;p&gt;To use it, first install the package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m pip install capsolver_extension_python
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, integrate it into your code as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver
from capsolver_extension_python import Capsolver

# Replace "CAP-MY_KEY" with your actual CapSolver API key
@browser(extensions=[Capsolver(api_key="CAP-MY_KEY")])  
def solve_captcha(driver: Driver, data):
    driver.get("https://recaptcha-demo.appspot.com/recaptcha-v2-checkbox.php")
    driver.prompt()

solve_captcha()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Language&lt;/h4&gt; 
&lt;p&gt;Specify the language using the &lt;code&gt;lang&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.lang import Lang

@browser(
    lang=Lang.Hindi,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;User Agent and Window Size&lt;/h4&gt; 
&lt;p&gt;To make the browser really humane, Botasaurus does not change browser fingerprints by default, because using fingerprints makes the browser easily identifiable by running CSS tests to find mismatches between the provided user agent and the actual user agent.&lt;/p&gt; 
&lt;p&gt;However, if you need fingerprinting, use the &lt;code&gt;user_agent&lt;/code&gt; and &lt;code&gt;window_size&lt;/code&gt; options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver
from botasaurus.user_agent import UserAgent
from botasaurus.window_size import WindowSize

@browser(
    user_agent=UserAgent.RANDOM,
    window_size=WindowSize.RANDOM,
)
def visit_whatsmyua(driver: Driver, data):
    driver.get("https://www.whatsmyua.info/")
    driver.prompt()

visit_whatsmyua()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When working with profiles, you want the fingerprints to remain consistent. You don't want the user's user agent to be Chrome 106 on the first visit and then become Chrome 102 on the second visit.&lt;/p&gt; 
&lt;p&gt;So, when using profiles, use the &lt;code&gt;HASHED&lt;/code&gt; option to generate a consistent user agent and window size based on the profile's hash:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver
from botasaurus.user_agent import UserAgent
from botasaurus.window_size import WindowSize

@browser(
    profile="pikachu",
    user_agent=UserAgent.HASHED,
    window_size=WindowSize.HASHED,
)
def visit_whatsmyua(driver: Driver, data):
    driver.get("https://www.whatsmyua.info/")
    driver.prompt()
    
visit_whatsmyua()

# Everytime Same UserAgent and WindowSize
visit_whatsmyua()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Passing Arguments to Chrome&lt;/h4&gt; 
&lt;p&gt;To pass arguments to Chrome, use the &lt;code&gt;add_arguments&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser(
    add_arguments=['--headless=new'],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To dynamically generate arguments based on the &lt;code&gt;data&lt;/code&gt; parameter, pass a function:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def get_arguments(data):
    return ['--headless=new']

@browser(
    add_arguments=get_arguments,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Wait for Complete Page Load&lt;/h4&gt; 
&lt;p&gt;By default, Botasaurus waits for all page resources (DOM, JavaScript, CSS, images, etc.) to load before calling your scraping function with the driver.&lt;/p&gt; 
&lt;p&gt;However, sometimes the DOM is ready, but JavaScript, images, etc., take forever to load.&lt;/p&gt; 
&lt;p&gt;In such cases, you can set &lt;code&gt;wait_for_complete_page_load&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; to interact with the DOM as soon as the HTML is parsed and the DOM is ready:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser(
    wait_for_complete_page_load=False,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Reuse Driver&lt;/h4&gt; 
&lt;p&gt;Consider the following example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser
def scrape_data(driver: Driver, link):
    driver.get(link)

scrape_data(["https://www.omkar.cloud/", "https://www.omkar.cloud/blog/", "https://stackoverflow.com/"])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you run this code, the browser will be recreated on each page visit, which is inefficient.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/list-demo.gif" alt="list-demo-omkar" /&gt;&lt;/p&gt; 
&lt;p&gt;To solve this problem, use the &lt;code&gt;reuse_driver&lt;/code&gt; option which is great for cases like:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Scraping a large number of links and reusing the same browser instance for all page visits.&lt;/li&gt; 
 &lt;li&gt;Running your scraper in a cloud server to scrape data on demand, without recreating Chrome on each request.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here's how to use &lt;code&gt;reuse_driver&lt;/code&gt; which will reuse the same Chrome instance for visiting each link.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser(
    reuse_driver=True
)
def scrape_data(driver: Driver, link):
    driver.get(link)

scrape_data(["https://www.omkar.cloud/", "https://www.omkar.cloud/blog/", "https://stackoverflow.com/"])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Result&lt;/strong&gt; &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/list-demo-reuse-driver.gif" alt="list-demo-reuse-driver.gif" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Also, by default, whenever the program ends or is canceled, Botasaurus smartly closes any open Chrome instances, leaving no instances running in the background.&lt;/p&gt; 
&lt;p&gt;In rare cases, you may want to explicitly close the Chrome instance. For such scenarios, you can use the &lt;code&gt;.close()&lt;/code&gt; method on the scraping function:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;scrape_data.close()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will close any Chrome instances that remain open after the scraping function ends.&lt;/p&gt; 
&lt;h3&gt;How to Significantly Reduce Proxy Costs When Scraping at Scale?&lt;/h3&gt; 
&lt;p&gt;Recently, we had a project requiring access to around 100,000 pages from a well-protected website, necessitating the use of Residential Proxies.&lt;/p&gt; 
&lt;p&gt;Even after blocking images, we still required 250GB of proxy bandwidth, costing approximately $1050 (at $4.2 per GB with IP Royal).&lt;/p&gt; 
&lt;p&gt;This was beyond our budget :(&lt;/p&gt; 
&lt;p&gt;To solve this, we implemented a smart strategy:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We first visited the website normally.&lt;/li&gt; 
 &lt;li&gt;We then made requests for subsequent pages using the browser's &lt;code&gt;fetch&lt;/code&gt; API.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Since we were only requesting the HTML, which was well compressed by the browser, we reduced our proxy bandwidth needs to just 5GB, costing only $30.&lt;/p&gt; 
&lt;p&gt;This resulted in savings of around $1000!&lt;/p&gt; 
&lt;p&gt;Here's an example of how you can do something similar in Botasaurus:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver
from botasaurus.soupify import soupify

@browser(
    reuse_driver=True,  # Reuse the browser
    max_retry=5,        # Retry up to 5 times on failure
)
def scrape_data(driver: Driver, link):
    # If the browser is newly opened, first visit the link
    if driver.config.is_new:
        driver.google_get(link)
    
    # Make requests using the browser fetch API
    response = driver.requests.get(link)
    response.raise_for_status()  # Ensure the request was successful
    html = response.text

    # Parse the HTML to extract the desired data
    soup = soupify(html)
    stock_name = soup.select_one('[data-testid="quote-hdr"] h1').get_text()
    stock_price = soup.select_one('[data-testid="qsp-price"]').get_text()
    
    return {
        "stock_name": stock_name,
        "stock_price": stock_price,
    }

# List of URLs to scrape
links = [
    "https://finance.yahoo.com/quote/AAPL/",
    "https://finance.yahoo.com/quote/GOOG/",
    "https://finance.yahoo.com/quote/MSFT/",
]

# Execute the scraping function for the list of links
scrape_data(links)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dealing with 429 (Too Many Requests) Errors&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;If you encounter a 429 error, add a delay before making another request. Most websites using Nginx, setting a rate limit of 1 request per second. To respect this limit, a delay of 1.13 seconds is recommended.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;driver.sleep(1.13)  # Delay to respect the rate limit
response = driver.requests.get(link)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Handling 400 Errors Due to Large Cookies&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;If you encounter a 400 error with a "cookie too large" message, delete the cookies and retry the request.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;response = driver.requests.get(link)

if response.status_code == 400:
    driver.delete_cookies()  # Delete cookies to resolve the error
    driver.short_random_sleep()  # Short delay before retrying
    response = driver.requests.get(link)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can also use &lt;code&gt;driver.requests.get_mank(links)&lt;/code&gt; to make multiple requests in parallel, which is faster than making them sequentially.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;How to Configure the Browser's Chrome Profile, Language, and Proxy Dynamically Based on Data Parameters?&lt;/h3&gt; 
&lt;p&gt;The decorators in Botasaurus are really flexible, allowing you to pass a function that can derive the browser configuration based on the data item parameter. This is particularly useful when working with multiple Chrome profiles.&lt;/p&gt; 
&lt;p&gt;You can dynamically configure the browser's Chrome profile and proxy using decorators in two ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Using functions to extract configuration values from data:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Define functions to extract the desired configuration values from the &lt;code&gt;data&lt;/code&gt; parameter.&lt;/li&gt; 
   &lt;li&gt;Pass these functions as arguments to the &lt;code&gt;@browser&lt;/code&gt; decorator.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

def get_profile(data):
    return data["profile"]

def get_proxy(data):
    return data["proxy"]

@browser(profile=get_profile, proxy=get_proxy)
def scrape_heading_task(driver: Driver, data):
    profile, proxy = driver.config.profile, driver.config.proxy
    print(profile, proxy)
    return profile, proxy

data = [
    {"profile": "pikachu", "proxy": "http://142.250.77.228:8000"},
    {"profile": "greyninja", "proxy": "http://142.250.77.229:8000"},
]

scrape_heading_task(data)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Directly passing configuration values when calling the decorated function:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Pass the profile and proxy values directly as arguments to the decorated function when calling it.&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser
def scrape_heading_task(driver: Driver, data):
    profile, proxy = driver.config.profile, driver.config.proxy
    print(profile, proxy)
    return profile, proxy

scrape_heading_task(
    profile='pikachu',  # Directly pass the profile
    proxy="http://142.250.77.228:8000",  # Directly pass the proxy
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;PS: Most Botasaurus decorators allow passing functions to derive configurations from data parameters. Check the decorator's argument type hint to see if it supports this functionality.&lt;/p&gt; 
&lt;h3&gt;What is the best way to manage profile-specific data like name, age across multiple profiles?&lt;/h3&gt; 
&lt;p&gt;To store data related to the active profile, use &lt;code&gt;driver.profile&lt;/code&gt;. Here's an example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

def get_profile(data):
    return data["profile"]

@browser(profile=get_profile)
def run_profile_task(driver: Driver, data):
    # Set profile data
    driver.profile = {
        'name': 'Amit Sharma',
        'age': 30
    }

    # Update the name in the profile
    driver.profile['name'] = 'Amit Verma'

    # Delete the age from the profile
    del driver.profile['age']

    # Print the updated profile
    print(driver.profile)  # Output: {'name': 'Amit Verma'}

    # Delete the entire profile
    driver.profile = None

run_profile_task([{"profile": "amit"}])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For managing all profiles, use the &lt;code&gt;Profiles&lt;/code&gt; utility. Here's an example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.profiles import Profiles

# Set profiles
Profiles.set_profile('amit', {'name': 'Amit Sharma', 'age': 30})
Profiles.set_profile('rahul', {'name': 'Rahul Verma', 'age': 30})

# Get a profile
profile = Profiles.get_profile('amit')
print(profile)  # Output: {'name': 'Amit Sharma', 'age': 30}

# Get all profiles
all_profiles = Profiles.get_profiles()
print(all_profiles)  # Output: [{'name': 'Amit Sharma', 'age': 30}, {'name': 'Rahul Verma', 'age': 30}]

# Get all profiles in random order
random_profiles = Profiles.get_profiles(random=True)
print(random_profiles)  # Output: [{'name': 'Rahul Verma', 'age': 30}, {'name': 'Amit Sharma', 'age': 30}] in random order

# Delete a profile
Profiles.delete_profile('amit')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: All profile data is stored in the &lt;code&gt;profiles.json&lt;/code&gt; file in the current working directory. &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/profiles.png" alt="profiles" /&gt;&lt;/p&gt; 
&lt;h3&gt;What are some common methods in Botasaurus Driver?&lt;/h3&gt; 
&lt;p&gt;Botasaurus Driver provides several handy methods for web automation tasks, such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Visiting URLs:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;driver.get("https://www.example.com")
driver.google_get("https://www.example.com")  # Use Google as the referer [Recommended]
driver.get_via("https://www.example.com", referer="https://duckduckgo.com/")  # Use custom referer
driver.get_via_this_page("https://www.example.com")  # Use current page as referer
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Finding elements:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import Wait
search_results = driver.select(".search-results", wait=Wait.SHORT)  # Wait for up to 4 seconds for the element to be present, return None if not found
all_links = driver.select_all("a")  # Get all elements matching the selector
search_results = driver.wait_for_element(".search-results", wait=Wait.LONG)  # Wait for up to 8 seconds for the element to be present, raise exception if not found
hello_mom = driver.get_element_with_exact_text("Hello Mom", wait=Wait.VERY_LONG)  # Wait for up to 16 seconds for an element having the exact text "Hello Mom"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Interacting with elements:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;driver.type("input[name='username']", "john_doe")  # Type into an input field
driver.click("button.submit")  # Click an element
element = driver.select("button.submit")
element.click()  # Click on an element
element.select_option("select#fruits", index=2)  # Select an option
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Retrieving element properties:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;header_text = driver.get_text("h1")  # Get text content
error_message = driver.get_element_containing_text("Error: Invalid input")
image_url = driver.select("img.logo").get_attribute("src")  # Get attribute value
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Working with parent-child elements:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;parent_element = driver.select(".parent")
child_element = parent_element.select(".child")
child_element.click()  # Click child element
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Executing JavaScript:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;result = driver.run_js("script.js") # Run a JavaScript file located in the current working directory.
result = driver.run_js("return document.title")
pikachu = driver.run_js("return args.pokemon", {"pokemon": 'pikachu'}) # args can be a dictionary, list, string, etc.
text_content = driver.select("body").run_js("(el) =&amp;gt; el.textContent")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Enable human mode to perform, human-like mouse movements and say sayonara to detection:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;# Navigate to Cloudflare's Turnstile Captcha demo
driver.get(
  "https://nopecha.com/demo/cloudflare",
)

# Wait for page to fully load
driver.long_random_sleep()

# Locate iframe containing the Cloudflare challenge
iframe = driver.get_element_at_point(160, 290)

# Find checkbox element within the iframe
checkbox = iframe.get_element_at_point(30, 30)

# Enable human mode for realistic, human-like mouse movements
driver.enable_human_mode()

# Click the checkbox to solve the challenge
checkbox.click()

# (Optional) Disable human mode if no longer needed  
driver.disable_human_mode()

# Pause execution, for inspection
driver.prompt()
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/human-mode-demo.gif" alt="human-mode-demo" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Drag and Drop:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;# Open React DnD tutorial  
driver.get("https://react-dnd.github.io/react-dnd/examples/tutorial")  

# Select draggable and droppable elements  
draggable = driver.select('[draggable="true"]')  
droppable = driver.select('[data-testid="(3,6)"]')  

# Perform drag-and-drop  
draggable.drag_and_drop_to(droppable)  

# Pause execution, for inspection
driver.prompt()  
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/drag-and-drop-demo.gif" alt="drag-and-drop-demo" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Selecting Shadow Root Elements:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;# Visit the website
driver.get("https://nopecha.com/demo/cloudflare")

# Wait for page to fully load
driver.long_random_sleep()

# Locate the element containing shadow root
shadow_root_element = driver.select('[name="cf-turnstile-response"]').parent

# Access the iframe
iframe = shadow_root_element.get_shadow_root()

# Access the nested shadow DOM inside the iframe 
content = iframe.get_shadow_root()

# print the text content of the "label" element.
print(content.select("label", wait = 8).text)

# Pause execution, for inspection
driver.prompt()
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/selecting-shadow-root-elements.gif" alt="Selecting Shadow Root Elements" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Monitoring requests:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver, cdp

@browser()
def scrape_responses_task(driver: Driver, data):
    # Define a handler function that will be called after a response is received
    def after_response_handler(
        request_id: str,
        response: cdp.network.Response,
        event: cdp.network.ResponseReceived,
    ):
        # Extract URL, status, and headers from the response
        url = response.url
        status = response.status
        headers = response.headers
        
        # Print the response details 
        print(
            "after_response_handler",
            {
                "request_id": request_id,
                "url": url,
                "status": status,
                "headers": headers,
            },
        )

        # Append the request ID to the driver's responses list
        driver.responses.append(request_id)

    # Register the after_response_handler to be called after each response is received
    driver.after_response_received(after_response_handler)

    # Navigate to the specified URL
    driver.get("https://example.com/")

    # Collect all the responses that were appended during the navigation
    collected_responses = driver.responses.collect()
    
    # Save it in output/scrape_responses_task.json
    return collected_responses

# Execute the scraping task
scrape_responses_task()
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Working with iframes:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;driver.get("https://www.freecodecamp.org/news/using-entity-framework-core-with-mongodb/")
iframe = driver.get_iframe_by_link("www.youtube.com/embed") 
# OR the following works as well
# iframe = driver.select_iframe(".embed-wrapper iframe") 
freecodecamp_youtube_subscribers_count = iframe.select(".ytp-title-expanded-subtitle").text
print(freecodecamp_youtube_subscribers_count)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Executing CDP Command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver, cdp
driver.run_cdp_command(cdp.page.navigate(url='https://stackoverflow.blog/open-source'))
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Miscellaneous:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;form.type("input[name='password']", "secret_password")  # Type into a form field
container.is_element_present(".button")  # Check element presence
page_html = driver.page_html  # Current page HTML
driver.select(".footer").scroll_into_view()  # Scroll element into view
driver.close()  # Close the browser
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How Can I Pause the Browser to Inspect Website when Developing the Scraper?&lt;/h3&gt; 
&lt;p&gt;To pause the scraper and wait for user input before proceeding, use &lt;code&gt;driver.prompt()&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;driver.prompt()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How do I configure authenticated proxies with SSL in Botasaurus?&lt;/h3&gt; 
&lt;p&gt;Proxy providers like BrightData, IPRoyal, and others typically provide authenticated proxies in the format "&lt;a href="http://username:password@proxy-provider-domain:port"&gt;http://username:password@proxy-provider-domain:port&lt;/a&gt;". For example, "&lt;a href="http://greyninja:awesomepassword@geo.iproyal.com:12321"&gt;http://greyninja:awesomepassword@geo.iproyal.com:12321&lt;/a&gt;".&lt;/p&gt; 
&lt;p&gt;However, if you use an authenticated proxy with a library like seleniumwire to visit a website using Cloudflare, or Datadome, you are GUARANTEED to be identified because you are using a non-SSL connection.&lt;/p&gt; 
&lt;p&gt;To verify this, run the following code:&lt;/p&gt; 
&lt;p&gt;First, install the necessary packages:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m pip install selenium_wire
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, execute this Python script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from seleniumwire import webdriver  # Import from seleniumwire

# Define the proxy
proxy_options = {
    'proxy': {
        'http': 'http://username:password@proxy-provider-domain:port', # TODO: Replace with your own proxy
        'https': 'http://username:password@proxy-provider-domain:port', # TODO: Replace with your own proxy
    }
}

# Install and set up the driver
driver = webdriver.Chrome(seleniumwire_options=proxy_options)

# Visit the desired URL
link = 'https://fingerprint.com/products/bot-detection/'
driver.get("https://www.google.com/")
driver.execute_script(f'window.location.href = "{link}"')

# Prompt for user input
input("Press Enter to exit...")

# Clean up
driver.quit()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will SURELY be identified:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/seleniumwireblocked.png" alt="identified" /&gt;&lt;/p&gt; 
&lt;p&gt;However, using proxies with Botasaurus solves this issue. See the difference by running the following code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser(proxy="http://username:password@proxy-provider-domain:port") # TODO: Replace with your own proxy 
def scrape_heading_task(driver: Driver, data):
    driver.google_get("https://fingerprint.com/products/bot-detection/")
    driver.prompt()

scrape_heading_task()    
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Result: &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/botasaurussuccesspage.png" alt="not identified" /&gt;&lt;/p&gt; 
&lt;p&gt;Important Note: To run the code above, you will need &lt;a href="https://nodejs.org/en"&gt;Node.js&lt;/a&gt; installed.&lt;/p&gt; 
&lt;h3&gt;Why am I getting a socket connection error when using a proxy to access a website?&lt;/h3&gt; 
&lt;p&gt;Certain proxy providers like BrightData will block access to specific websites. To determine if this is the case, run the following code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser(proxy="http://username:password@proxy-provider-domain:port")  # TODO: Replace with your own proxy
def visit_what_is_my_ip(driver: Driver, data):
    driver.get("https://whatismyipaddress.com/")
    driver.prompt()

visit_what_is_my_ip()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you can successfully access &lt;a href="https://whatismyipaddress.com/"&gt;whatismyipaddress.com&lt;/a&gt; but not the website you're attempting to scrape, it means the proxy provider is blocking access to that particular website.&lt;/p&gt; 
&lt;p&gt;In such situations, the only solution is to switch to a different proxy provider.&lt;/p&gt; 
&lt;p&gt;Some good proxy providers we personally use are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For Rotating Datacenter Proxies: &lt;strong&gt;BrightData Datacenter Proxies&lt;/strong&gt;, which cost around $0.6 per GB on a pay-as-you-go basis. No KYC is required.&lt;/li&gt; 
 &lt;li&gt;For Rotating Residential Proxies: &lt;strong&gt;IPRoyal Royal Residential Proxies&lt;/strong&gt;, which cost around $7 per GB on a pay-as-you-go basis. No KYC is required.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As always, nothing good in life comes free. Proxies are expensive, and will take up almost all of your scraping costs.&lt;/p&gt; 
&lt;p&gt;So, use proxies only when you need them, and prefer request-based scrapers over browser-based scrapers to save bandwidth.&lt;/p&gt; 
&lt;p&gt;Note: BrightData and IPRoyal have not paid us. We are recommending them based on our personal experience.&lt;/p&gt; 
&lt;h3&gt;Which country should I choose when using proxies for web scraping?&lt;/h3&gt; 
&lt;p&gt;The United States is often the best choice because:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The United States has a highly developed internet infrastructure and is home to numerous data centers, ensuring faster internet speeds.&lt;/li&gt; 
 &lt;li&gt;Most global companies host their websites in the US, so using a US proxy will result in faster scraping speeds.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Should I use a proxy for web scraping?&lt;/h3&gt; 
&lt;p&gt;ONLY IF you encounter IP blocks.&lt;/p&gt; 
&lt;p&gt;Sadly, most scrapers unnecessarily use proxies, even when they are not needed. Everything seems like a nail when you have a hammer.&lt;/p&gt; 
&lt;p&gt;We have seen scrapers which can easily access hundreds of thousands of protected pages using the @browser module on home Wi-Fi without any issues.&lt;/p&gt; 
&lt;p&gt;So, as a best practice scrape using the @browser module on your home Wi-Fi first. Only resort to proxies when you encounter IP blocks.&lt;/p&gt; 
&lt;p&gt;This practice will save you a considerable amount of time (as proxies are really slow) and money (as proxies are expensive as well).&lt;/p&gt; 
&lt;h3&gt;How to configure the Request Decorator?&lt;/h3&gt; 
&lt;p&gt;The Request Decorator is used to make humane requests. Under the hood, it uses botasaurus-requests, a library based on hrequests, which incorporates important features like:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Using browser-like headers in the correct order.&lt;/li&gt; 
 &lt;li&gt;Makes a browser-like connection with correct ciphers.&lt;/li&gt; 
 &lt;li&gt;Uses &lt;code&gt;google.com&lt;/code&gt; referer by default to make it appear as if the user has arrived from google search.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, The Request Decorator allows you to configure proxy as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@request(
    proxy="http://username:password@proxy-provider-domain:port"
)    
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;What Options Can I Configure in all 3 Decorators?&lt;/h3&gt; 
&lt;p&gt;All 3 decorators allow you to configure the following options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Parallel Execution:&lt;/li&gt; 
 &lt;li&gt;Caching Results&lt;/li&gt; 
 &lt;li&gt;Passing Common Metadata&lt;/li&gt; 
 &lt;li&gt;Asynchronous Queues&lt;/li&gt; 
 &lt;li&gt;Asynchronous Execution&lt;/li&gt; 
 &lt;li&gt;Handling Crashes&lt;/li&gt; 
 &lt;li&gt;Configuring Output&lt;/li&gt; 
 &lt;li&gt;Exception Handling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Let's dive into each of these options and in later sections we will see their real-world applications.&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;parallel&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;parallel&lt;/code&gt; option allows you to scrape data in parallel by launching multiple browser/request/task instances simultaneously. This can significantly speed up the scraping process.&lt;/p&gt; 
&lt;p&gt;Run the example below to see parallelization in action:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser(parallel=3, data=["https://stackoverflow.blog/open-source", "https://stackoverflow.blog/ai", "https://stackoverflow.blog/productivity",])
def scrape_heading_task(driver: Driver, link):
    driver.get(link)
    heading = driver.get_text('h1')
    return heading

scrape_heading_task()    
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;code&gt;cache&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;cache&lt;/code&gt; option enables caching of web scraping results to avoid re-scraping the same data. This can significantly improve performance and reduce redundant requests.&lt;/p&gt; 
&lt;p&gt;Run the example below to see how caching works:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser(cache=True, data=["https://stackoverflow.blog/open-source", "https://stackoverflow.blog/ai", "https://stackoverflow.blog/productivity",])
def scrape_heading_task(driver: Driver, link):
    driver.get(link)
    heading = driver.get_text('h1')
    return heading

print(scrape_heading_task())
print(scrape_heading_task())  # Data will be fetched from cache immediately 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: Caching is one of the most important features of Botasaurus.&lt;/p&gt; 
&lt;h4&gt;&lt;code&gt;metadata&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;The metadata option allows you to pass common information shared across all data items. This can include things like API keys, browser cookies, or any other data that remains constant throughout the scraping process.&lt;/p&gt; 
&lt;p&gt;It is commonly used with caching to exclude details like API keys and browser cookies from the cache key.&lt;/p&gt; 
&lt;p&gt;Here's an example of how to use the &lt;code&gt;metadata&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.task import task

@task()
def scrape_heading_task(driver: Driver, data, metadata):
    print("metadata:", metadata)
    print("data:", data)

data = [
    {"profile": "pikachu", "proxy": "http://142.250.77.228:8000"},
    {"profile": "greyninja", "proxy": "http://142.250.77.229:8000"},
]
scrape_heading_task(
  data, 
  metadata={"api_key": "BDEC26..."}
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;code&gt;async_queue&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;In the world of web scraping, there are only two types of scrapers:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Dataset Scrapers: These extract data from websites and store it as datasets. Companies like Bright Data use them to build datasets for Crunchbase, Indeed, etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Real-time Scrapers: These fetch data from sources in real-time, like SERP APIs that provide Google and DuckDuckGo search results.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;When building real-time scrapers, speed is paramount because customers are waiting for requests to complete. The &lt;code&gt;async_queue&lt;/code&gt; feature is incredibly useful in such cases.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;async_queue&lt;/code&gt; allows you to run scraping tasks asynchronously in a queue and gather the results using the &lt;code&gt;.get()&lt;/code&gt; method.&lt;/p&gt; 
&lt;p&gt;A great use case for &lt;code&gt;async_queue&lt;/code&gt; is scraping Google Maps. Instead of scrolling through the list of places and then scraping the details of each place sequentially, you can use &lt;code&gt;async_queue&lt;/code&gt; to:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Scroll through the list of places.&lt;/li&gt; 
 &lt;li&gt;Simultaneously make HTTP requests to scrape the details of each place in the background.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;By executing the scrolling and requesting tasks concurrently, you can significantly speed up the scraper.&lt;/p&gt; 
&lt;p&gt;Run the code below to see browser scrolling and request scraping happening concurrently (really cool, must try!):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver, AsyncQueueResult
from botasaurus.request import request, Request
import json

def extract_title(html):
    return json.loads(
        html.split(";window.APP_INITIALIZATION_STATE=")[1].split(";window.APP_FLAGS")[0]
    )[5][3][2][1]

@request(
    parallel=5,
    async_queue=True,
    max_retry=5,
)
def scrape_place_title(request: Request, link, metadata):
    cookies = metadata["cookies"]
    html = request.get(link, cookies=cookies, timeout=12).text
    title = extract_title(html)
    print("Title:", title)
    return title

def has_reached_end(driver):
    return driver.select('p.fontBodyMedium &amp;gt; span &amp;gt; span') is not None

def extract_links(driver):
    return driver.get_all_links('[role="feed"] &amp;gt; div &amp;gt; div &amp;gt; a')

@browser()
def scrape_google_maps(driver: Driver, link):
    driver.google_get(link, accept_google_cookies=True)  # accepts google cookies popup

    scrape_place_obj: AsyncQueueResult = scrape_place_title()  # initialize the async queue for scraping places
    cookies = driver.get_cookies_dict()  # get the cookies from the driver

    while True:
        links = extract_links(driver)  # get the links to places
        scrape_place_obj.put(links, metadata={"cookies": cookies})  # add the links to the async queue for scraping

        print("scrolling")
        driver.scroll_to_bottom('[role="feed"]')  # scroll to the bottom of the feed

        if has_reached_end(driver):  # we have reached the end, let's break buddy
            break

    results = scrape_place_obj.get()  # get the scraped results from the async queue
    return results

scrape_google_maps("https://www.google.com/maps/search/web+developers+in+bangalore")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;code&gt;run_async&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;Similarly, the &lt;code&gt;run_async&lt;/code&gt; option allows you to execute scraping tasks asynchronously, enabling concurrent execution.&lt;/p&gt; 
&lt;p&gt;Similar to &lt;code&gt;async_queue&lt;/code&gt;, you can use the &lt;code&gt;.get()&lt;/code&gt; method to retrieve the results of an asynchronous task.&lt;/p&gt; 
&lt;p&gt;Code Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver
from time import sleep

@browser(run_async=True)
def scrape_heading(driver: Driver, data):
    sleep(5)
    return {}

if __name__ == "__main__":
    result1 = scrape_heading()  # Launches asynchronously
    result2 = scrape_heading()  # Launches asynchronously

    result1.get()  # Wait for the first result
    result2.get()  # Wait for the second result
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;code&gt;close_on_crash&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;close_on_crash&lt;/code&gt; option determines the behavior of the scraper when an exception occurs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If set to &lt;code&gt;False&lt;/code&gt; (default): 
  &lt;ul&gt; 
   &lt;li&gt;The scraper will make a beep sound and pause the browser.&lt;/li&gt; 
   &lt;li&gt;This makes debugging easier by keeping the browser open at the point of the crash.&lt;/li&gt; 
   &lt;li&gt;Use this setting during development and testing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;If set to &lt;code&gt;True&lt;/code&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;The scraper will close the browser and continue with the rest of the data items.&lt;/li&gt; 
   &lt;li&gt;This is suitable for production environments when you are confident that your scraper is robust.&lt;/li&gt; 
   &lt;li&gt;Use this setting to avoid interruptions and ensure the scraper processes all data items.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.browser import browser, Driver

@browser(
    close_on_crash=False  # Determines whether the browser is paused (default: False) or closed when an error occurs
)
def scrape_heading_task(driver: Driver, data):
    raise Exception("An error occurred during scraping.")

scrape_heading_task()  
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;code&gt;output&lt;/code&gt; and &lt;code&gt;output_formats&lt;/code&gt;&lt;/h4&gt; 
&lt;p&gt;By default, Botasaurus saves the result of scraping in the &lt;code&gt;output/{your_scraping_function_name}.json&lt;/code&gt; file. Let's learn about various ways to configure the output.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Change Output Filename&lt;/strong&gt;: Use the &lt;code&gt;output&lt;/code&gt; parameter in the decorator to specify a custom filename for the output.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.task import task

@task(output="my-output")
def scrape_heading_task(data): 
    return {"heading": "Hello, Mom!"}

scrape_heading_task()
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Disable Output&lt;/strong&gt;: If you don't want any output to be saved, set &lt;code&gt;output&lt;/code&gt; to &lt;code&gt;None&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.task import task

@task(output=None)
def scrape_heading_task(data): 
    return {"heading": "Hello, Mom!"}

scrape_heading_task()
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamically Write Output&lt;/strong&gt;: To dynamically write output based on data and result, pass a function to the &lt;code&gt;output&lt;/code&gt; parameter:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.task import task
from botasaurus import bt

def write_output(data, result):
    json_filename = bt.write_json(result, 'data')
    excel_filename = bt.write_excel(result, 'data')
    bt.zip_files([json_filename, excel_filename]) # Zip the JSON and Excel files for easy delivery to the customer

@task(output=write_output)  
def scrape_heading_task(data): 
    return {"heading": "Hello, Mom!"}

scrape_heading_task()
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;&lt;strong&gt;Upload File to S3&lt;/strong&gt;: Use &lt;code&gt;bt.upload_to_s3&lt;/code&gt; to upload file to S3 bucket.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.task import task
from botasaurus import bt

def write_output(data, result):
    json_filename = bt.write_json(result, 'data')
    bt.upload_to_s3(json_filename, 'my-magical-bucket', "AWS_ACCESS_KEY", "AWS_SECRET_KEY")

@task(output=write_output)  
def scrape_heading_task(data): 
    return {"heading": "Hello, Mom!"}

scrape_heading_task()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;5.&lt;strong&gt;Save Outputs in Multiple Formats&lt;/strong&gt;: Use the &lt;code&gt;output_formats&lt;/code&gt; parameter to save outputs in different formats like JSON and EXCEL.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.task import task

@task(output_formats=[bt.Formats.JSON, bt.Formats.EXCEL])  
def scrape_heading_task(data): 
    return {"heading": "Hello, Mom!"}

scrape_heading_task()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;PRO TIP: When delivering data to customers, provide the dataset in JSON and Excel formats. Avoid CSV unless the customer asks, because Microsoft Excel has a hard time rendering CSV files with nested JSON.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CSV vs Excel&lt;/strong&gt; &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/csv-vs-excel.png" alt="csv-vs-excel" /&gt;&lt;/p&gt; 
&lt;h4&gt;Exception Handling Options&lt;/h4&gt; 
&lt;p&gt;Botasaurus provides various exception handling options to make your scrapers more robust:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;max_retry&lt;/code&gt;: By default, any failed task is not retried. You can specify the maximum number of times to retry scraping when an error occurs using the &lt;code&gt;max_retry&lt;/code&gt; option.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;retry_wait&lt;/code&gt;: Specifies the waiting time between retries.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;raise_exception&lt;/code&gt;: By default, Botasaurus does not raise an exception when an error occurs during scraping, because let's say you are keeping your PC running overnight to scrape 10,000 links. If one link fails, you really don't want to stop the entire scraping process, and ruin your morning by seeing an unfinished dataset.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;must_raise_exceptions&lt;/code&gt;: Specifies exceptions that must be raised, even if &lt;code&gt;raise_exception&lt;/code&gt; is set to &lt;code&gt;False&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;create_error_logs&lt;/code&gt;: Determines whether error logs should be created when exceptions occur. In production, when scraping hundreds of thousands of links, it's recommended to set &lt;code&gt;create_error_logs&lt;/code&gt; to &lt;code&gt;False&lt;/code&gt; to avoid using computational resources for creating error logs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser(
    raise_exception=True,  # Raise an exception and halt the scraping process when an error occurs
    max_retry=5,  # Retry scraping a failed task a maximum of 5 times
    retry_wait=10,  # Wait for 10 seconds before retrying a failed task
    must_raise_exceptions=[CustomException],  # Definitely raise CustomException, even if raise_exception is set to False
    create_error_logs=False  # Disable the creation of error logs to optimize scraper performance
)
def scrape_heading_task(driver: Driver, data):
  # ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;What are some examples of common web scraping utilities provided by Botasaurus that make scraping easier?&lt;/h3&gt; 
&lt;h4&gt;bt Utility&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;bt&lt;/code&gt; utility provides helper functions for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Writing and reading JSON, EXCEL, and CSV files&lt;/li&gt; 
 &lt;li&gt;Data cleaning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Some key functions are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bt.write_json&lt;/code&gt; and &lt;code&gt;bt.read_json&lt;/code&gt;: Easily write and read JSON files.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus import bt

data = {"name": "pikachu", "power": 101}
bt.write_json(data, "output")
loaded_data = bt.read_json("output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bt.write_excel&lt;/code&gt; and &lt;code&gt;bt.read_excel&lt;/code&gt;: Easily write and read EXCEL files.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus import bt

data = {"name": "pikachu", "power": 101}
bt.write_excel(data, "output")
loaded_data = bt.read_excel("output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bt.write_csv&lt;/code&gt; and &lt;code&gt;bt.read_csv&lt;/code&gt;: Easily write and read CSV files.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus import bt

data = {"name": "pikachu", "power": 101}
bt.write_csv(data, "output")
loaded_data = bt.read_csv("output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bt.write_html&lt;/code&gt; and &lt;code&gt;bt.read_html&lt;/code&gt;: Write HTML content to a file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus import bt

html_content = "&amp;lt;html&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;Hello, Mom!&amp;lt;/h1&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;"
bt.write_html(html_content, "output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bt.write_temp_json&lt;/code&gt;, &lt;code&gt;bt.write_temp_csv&lt;/code&gt;, &lt;code&gt;bt.write_temp_html&lt;/code&gt;: Write temporary JSON, CSV, or HTML files for debugging purposes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus import bt

data = {"name": "pikachu", "power": 101}
bt.write_temp_json(data)
bt.write_temp_csv(data)
bt.write_temp_html("&amp;lt;html&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;Hello, Mom!&amp;lt;/h1&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;")
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Data cleaning functions like &lt;code&gt;bt.extract_numbers&lt;/code&gt;, &lt;code&gt;bt.extract_links&lt;/code&gt;, &lt;code&gt;bt.remove_html_tags&lt;/code&gt;, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;text = "The price is $19.99 and the website is https://www.example.com"
numbers = bt.extract_numbers(text)  # [19.99]
links = bt.extract_links(text)  # ["https://www.example.com"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Local Storage Utility&lt;/h4&gt; 
&lt;p&gt;The Local Storage utility allows you to store and retrieve key-value pairs, which can be useful for maintaining state between scraper runs.&lt;/p&gt; 
&lt;p&gt;Here's how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.local_storage import LocalStorage

LocalStorage.set_item("credits_used", 100)
print(LocalStorage.get_item("credits_used", 0))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;soupify Utility&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;soupify&lt;/code&gt; utility creates a BeautifulSoup object from a Driver, Requests response, Driver Element, or HTML string.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.soupify import soupify
from botasaurus.request import request, Request
from botasaurus.browser import browser, Driver

@request
def get_heading_from_request(req: Request, data):
   """
   Get the heading of a web page using the request object.
   """
   response = req.get("https://www.example.com")
   soup = soupify(response)
   heading = soup.find("h1").text
   print(f"Page Heading: {heading}")

@browser
def get_heading_from_driver(driver: Driver, data):
   """
   Get the heading of a web page using the driver object.
   """
   driver.get("https://www.example.com")

   # Get the heading from the entire page
   page_soup = soupify(driver)
   page_heading = page_soup.find("h1").text
   print(f"Heading from Driver's Soup: {page_heading}")

   # Get the heading from the body element
   body_soup = soupify(driver.select("body"))
   body_heading = body_soup.find("h1").text
   print(f"Heading from Element's Soup: {body_heading}")

# Call the functions
get_heading_from_request()
get_heading_from_driver()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;IP Utils&lt;/h4&gt; 
&lt;p&gt;IP Utils provide functions to get information about the current IP address, such as the IP itself, country, ISP, and more:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.ip_utils import IPUtils

# Get the current IP address
current_ip = IPUtils.get_ip()
print(current_ip)
# Output: 47.31.226.180

# Get detailed information about the current IP address
ip_info = IPUtils.get_ip_info()
print(ip_info)
# Output: {
#     "ip": "47.31.226.180",
#     "country": "IN",
#     "region": "Delhi",
#     "city": "Delhi",
#     "postal": "110001",
#     "coordinates": "28.6519,77.2315",
#     "latitude": "28.6519",
#     "longitude": "77.2315",
#     "timezone": "Asia/Kolkata",
#     "org": "AS55836 Reliance Jio Infocomm Limited"
# }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Cache Utility&lt;/h4&gt; 
&lt;p&gt;The Cache utility in Botasaurus allows you to manage cached data for your scraper. You can put, get, has, remove, and clear cache data.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Basic Usage&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.task import task
from botasaurus.cache import Cache

# Example scraping function
@task
def scrape_data(data):
    # Your scraping logic here
    return {"processed": data}

# Sample data for scraping
input_data = {"key": "value"}

# Adding data to the cache
Cache.put('scrape_data', input_data, scrape_data(input_data))

# Checking if data is in the cache
if Cache.has('scrape_data', input_data):
    # Retrieving data from the cache
    cached_data = Cache.get('scrape_data', input_data)
    print(f"Cached data: {cached_data}")

# Removing specific data from the cache
Cache.remove('scrape_data', input_data)

# Clearing the complete cache for the scrape_data function
Cache.clear('scrape_data')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Advanced Usage for large-scale scraping projects&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Count Cached Items&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can count the number of items cached for a particular function, which can serve as a scraping progress bar.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.cache import Cache

Cache.print_cached_items_count('scraping_function')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Filter Cached/Uncached Items&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can filter items that have been cached or not cached for a particular function.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.cache import Cache

all_items = ['1', '2', '3', '4', '5']

# Get items that are cached
cached_items = Cache.filter_items_in_cache('scraping_function', all_items)
print(cached_items)

# Get items that are not cached
uncached_items = Cache.filter_items_not_in_cache('scraping_function', all_items)
print(uncached_items)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Delete Cache&lt;/em&gt; The cache for a function is stored in the &lt;code&gt;cache/{your_scraping_function_name}/&lt;/code&gt; folder. To delete the cache, simply delete that folder.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/delete-cache.png" alt="delete-cache" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Delete Specific Items&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can delete specific items from the cache for a particular function.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.cache import Cache

all_items = ['1', '2', '3', '4', '5']
deleted_count = Cache.delete_items('scraping_function', all_items)
print(f"Deleted {deleted_count} items from the cache.")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Delete Items by Filter&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;In some cases, you may want to delete specific items from the cache based on a condition. For example, if you encounter honeypots (mock HTML served to dupe web scrapers) while scraping a website, you may want to delete those items from the cache.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def should_delete_item(item, result):
    if 'Honeypot Item' in result:
        return True  # Delete the item
    return False  # Don't delete the item

all_items = ['1', '2', '3', '4', '5']
# List of items to iterate over, it is fine if the list contains items which have not been cached, as they will be simply ignored.
Cache.delete_items_by_filter('scraping_function', should_delete_item, all_items)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Importantly, be cautious and first use &lt;code&gt;delete_items_by_filter&lt;/code&gt; on a small set of items which you want to be deleted. Here's an example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus import bt
from botasaurus.cache import Cache

def should_delete_item(item, result):
    # TODO: Update the logic
    if 'Honeypot Item' in result:
        return True # Delete the item
    return False # Don't delete the item

test_items = ['1', '2'] # TODO: update with target items
scraping_function_name = 'scraping_function' # TODO:  update with target scraping function name
Cache.delete_items_by_filter(scraping_function_name, test_items, should_delete_item)

for item in test_items:
    if Cache.has(scraping_function_name, item):
        bt.prompt(f"Item {item} was not deleted. Please review the logic of the should_delete_item function.")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How to Extract Links from a Sitemap?&lt;/h3&gt; 
&lt;p&gt;In web scraping, it is a common use case to scrape product pages, blogs, etc. But before scraping these pages, you need to get the links to these pages.&lt;/p&gt; 
&lt;p&gt;Sadly, many developers unnecessarily increase their work by writing code to visit each page one by one and scrape links, which they could have easily obtained by just looking at the Sitemap.&lt;/p&gt; 
&lt;p&gt;The Botasaurus Sitemap Module makes this process easy as cake by allowing you to get all links or sitemaps using:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The homepage URL (e.g., &lt;code&gt;https://www.omkar.cloud/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;A direct sitemap link (e.g., &lt;code&gt;https://www.omkar.cloud/sitemap.xml&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;A &lt;code&gt;.gz&lt;/code&gt; compressed sitemap&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, if you're an Angel Investor seeking innovative tech startups to invest in, G2 is an ideal platform to find such startups. You can run the following code to fetch over 190K+ product links from G2:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus import bt
from botasaurus.sitemap import Sitemap, Filters, Extractors

links = (
    Sitemap("https://www.g2.com/sitemaps/sitemap_index.xml.gz")
    .filter(Filters.first_segment_equals("products"))
    .extract(Extractors.extract_link_upto_second_segment())
    .write_links('g2-products')
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/g2-sitemap-links.png" alt="g2-sitemap-links.png" /&gt;&lt;/p&gt; 
&lt;p&gt;Or, let's say you're in the mood for some reading and looking for good stories. The following code will get you over 1000+ stories from &lt;a href="https://moralstories26.com/"&gt;moralstories26.com&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus import bt
from botasaurus.sitemap import Sitemap, Filters

links = (
    Sitemap("https://moralstories26.com/")
    .filter(
        Filters.has_exactly_1_segment(),
        Filters.first_segment_not_equals(
            ["about", "privacy-policy", "akbar-birbal", "animal", "education", "fables", "facts", "family", "famous-personalities", "folktales", "friendship", "funny", "heartbreaking", "inspirational", "life", "love", "management", "motivational", "mythology", "nature", "quotes", "spiritual", "uncategorized", "zen"]
        ),
    )
    .write_links('moral-stories')
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/moralstories26-sitemap-links.png" alt="moralstories26-sitemap-links.png" /&gt;&lt;/p&gt; 
&lt;p&gt;Also, before scraping a site, it's useful to identify the available sitemaps. This can be easily done with the following code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus import bt
from botasaurus.sitemap import Sitemap

sitemaps = Sitemap("https://www.omkar.cloud/").write_sitemaps('omkar-sitemaps')
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/omkar-sitemap-links.png" alt="omkar-sitemap-links.png" /&gt;&lt;/p&gt; 
&lt;p&gt;To ensure your scrapers run super fast, we cache the Sitemap, but you may want to periodically refresh the cache. To do so, pass the Cache.REFRESH parameter.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus import bt
from botasaurus.sitemap import Sitemap, Filters, Extractors
from botasaurus.cache import Cache

links = (
    Sitemap("https://moralstories26.com/", cache=Cache.REFRESH)
    .write_links('moral-stories')
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How can I filter a list of links, similar to working with Sitemaps?&lt;/h3&gt; 
&lt;p&gt;Filtering links from a webpage is a common requirement in web scraping. For example, you might want to filter out all non-product pages.&lt;/p&gt; 
&lt;p&gt;Botasaurus's &lt;code&gt;Links&lt;/code&gt; module simplifies link filtering and extraction:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.links import Links, Filters, Extractors

# Sample list of links
links = [
    "https://finance.yahoo.com/topic/stock-market-news/",
    "https://finance.yahoo.com/topic/morning-brief/", 
    "https://finance.yahoo.com/quote/AAPL/", 
    "https://finance.yahoo.com/quote/GOOG/"
]

# Filter and extract links
filtered_links = (
    Links(links)
    .filter(Filters.first_segment_equals("quote"))
    .extract(Extractors.extract_link_upto_second_segment())
    .write('stocks')
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;What is the best way to use caching in Botasaurus?&lt;/h3&gt; 
&lt;p&gt;Sadly, when using caching, most developers write a scraping function that scrapes the HTML and extracts the data from the HTML in the same function, like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus.request import request, Request
from botasaurus.soupify import soupify

@request
def scrape_data(request: Request, data):
    # Visit the Link
    response = request.get(data)
    
    # Create a BeautifulSoup object
    soup = soupify(response)
    
    # Retrieve the heading element's text
    heading = soup.find('h1').get_text()
    
    # Save the data as a JSON file in output/scrape_data.json
    return {"heading": heading}

data_items = [
    "https://stackoverflow.blog/open-source",
    "https://stackoverflow.blog/ai",
    "https://stackoverflow.blog/productivity",
]

scrape_data(data_items)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now, let's say, after 50% of the dataset has been scraped, what if:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Your customer wants to add another data point (which is very likely), or&lt;/li&gt; 
 &lt;li&gt;One of your BeautifulSoup selectors happens to be flaky and needs to be updated (which is super likely)?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In such cases, you will have to scrape all the pages again, which is painful as it will take a lot of time and incur high proxy costs.&lt;/p&gt; 
&lt;p&gt;To resolve this issue, you can:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Write a function that only scrapes and caches the HTML.&lt;/li&gt; 
 &lt;li&gt;Write a separate function that calls the HTML scraping function, extracts data using BeautifulSoup, and caches the result.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Here's a practical example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from bs4 import BeautifulSoup
from botasaurus.task import task
from botasaurus.request import request, Request
from botasaurus.soupify import soupify

@request(cache=True)
def scrape_html(request: Request, link):
    # Scrape the HTML and cache it
    html = request.get(link).text
    return html

def extract_data(soup: BeautifulSoup):
    # Extract the heading from the HTML
    heading = soup.find("h1").get_text()
    return {"heading": heading}

# Cache the scrape_data task as well
@task(cache=True)
def scrape_data(link):
    # Call the scrape_html function to get the cached HTML
    html = scrape_html(link)
    # Extract data from the HTML using the extract_data function
    return extract_data(soupify(html))

data_items = [
    "https://stackoverflow.blog/open-source",
    "https://stackoverflow.blog/ai",
    "https://stackoverflow.blog/productivity",
]

scrape_data(data_items)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With this approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you need to add data points or fix BeautifulSoup bugs, delete the &lt;code&gt;cache/scrape_data&lt;/code&gt; folder and re-run the scraper. &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/delete-cache.png" alt="delete-cache" /&gt;&lt;/li&gt; 
 &lt;li&gt;You only need to re-run the BeautifulSoup extraction, not the entire HTML scraping, saving time and proxy costs. Yahoo!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;PRO TIP&lt;/strong&gt;: This approach also makes your &lt;code&gt;extract_data&lt;/code&gt; code easier and faster to test, like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from bs4 import BeautifulSoup
from botasaurus import bt

def extract_data(soup: BeautifulSoup):
    heading = soup.find('h1').get_text()
    return {"heading": heading}

if __name__ == '__main__':
    # Will use the cached HTML and run the extract_data function again.
    bt.write_temp_json(scrape_data("https://stackoverflow.blog/open-source", cache=False))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;What are the recommended settings for each decorator to build a production-ready scraper in Botasaurus?&lt;/h3&gt; 
&lt;p&gt;For websites with minimal protection, use the &lt;code&gt;Request&lt;/code&gt; module.&lt;/p&gt; 
&lt;p&gt;Here's a template for creating production-ready datasets using the &lt;code&gt;Request&lt;/code&gt; module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from bs4 import BeautifulSoup
from botasaurus.task import task
from botasaurus.request import request, Request,NotFoundException
from botasaurus.soupify import soupify

@request(
    # proxy='http://username:password@datacenter-proxy-domain:proxy-port', # Uncomment to use Proxy ONLY if you face IP blocking
    cache=True,

    max_retry=20, # Retry up to 20 times, which is a good default

    output=None,

    close_on_crash=True,
    raise_exception=True,
    create_error_logs=False,
)
def scrape_html(request: Request, link):
    # Scrape the HTML and cache it
    response = request.get(link)
    if response.status_code == 404:
        # A Special Exception to skip retrying this link
        raise NotFoundException(link)
    response.raise_for_status()
    return response.text

def extract_data(soup: BeautifulSoup):
    # Extract the heading from the HTML
    heading = soup.find("h1").get_text()
    return {"heading": heading}

# Cache the scrape_data task as well
@task(
    cache=True,
    close_on_crash=True,
    create_error_logs=False,
    parallel=40, # Run 40 requests in parallel, which is a good default
)
def scrape_data(link):
    # Call the scrape_html function to get the cached HTML
    html = scrape_html(link)
    # Extract data from the HTML using the extract_data function
    return extract_data(soupify(html))

data_items = [
    "https://stackoverflow.blog/open-source",
    "https://stackoverflow.blog/ai",
    "https://stackoverflow.blog/productivity",
]

scrape_data(data_items)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For visiting well protected websites, use the &lt;code&gt;Browser&lt;/code&gt; module.&lt;/p&gt; 
&lt;p&gt;Here's a template for creating production-ready datasets using the &lt;code&gt;Browser&lt;/code&gt; module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from bs4 import BeautifulSoup
from botasaurus.task import task
from botasaurus.browser import browser, Driver, NotFoundException
from botasaurus.soupify import soupify

@browser(
    # proxy='http://username:password@datacenter-proxy-domain:proxy-port', # Uncomment to use Proxy ONLY if you face IP blocking

    # block_images_and_css=True, # Uncomment to block images and CSS, which can speed up scraping
    # wait_for_complete_page_load=False, # Uncomment to proceed once the DOM (Document Object Model) is loaded, without waiting for all resources to finish loading. This is recommended for faster scraping of Server Side Rendered (HTML) pages.

    cache=True,
    max_retry=5,  # Retry up to 5 times, which is a good default

    reuse_driver= True, # Reuse the same driver for all tasks
    
    output=None,

    close_on_crash=True,
    raise_exception=True,
    create_error_logs=False,
)
def scrape_html(driver: Driver, link):
    # Scrape the HTML and cache it
    if driver.config.is_new:
        driver.google_get(
            link,
            bypass_cloudflare=True,  # delete this line if the website you're accessing is not protected by Cloudflare
        )
    response = driver.requests.get(link)
    
    if response.status_code == 404:
        # A Special Exception to skip retrying this link
        raise NotFoundException(link)
    response.raise_for_status()
    
    html = response.text        
    return html

def extract_data(soup: BeautifulSoup):
    # Extract the heading from the HTML
    stock_name = soup.select_one('[data-testid="quote-hdr"] h1').get_text()
    stock_price = soup.select_one('[data-testid="qsp-price"]').get_text()
    
    return {
        "stock_name": stock_name,
        "stock_price": stock_price,
    }

# Cache the scrape_data task as well
@task(
    cache=True,
    close_on_crash=True,
    create_error_logs=False,
)
def scrape_data(link):
    # Call the scrape_html function to get the cached HTML
    html = scrape_html(link)
    # Extract data from the HTML using the extract_data function
    return extract_data(soupify(html))

data_items = [
    "https://finance.yahoo.com/quote/AAPL/",
    "https://finance.yahoo.com/quote/GOOG/",
    "https://finance.yahoo.com/quote/MSFT/",
]

scrape_data(data_items)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Why Am I Getting Detected on Some Websites?&lt;/h3&gt; 
&lt;p&gt;If you're getting detected, it's likely due to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Using a non-residential proxy ‚Äî Services like Datadome and Cloudflare often flag datacenter IPs/VPNs.&lt;/li&gt; 
 &lt;li&gt;Clicking without Human Mode enabled ‚Äî Unnatural mouse movements can trigger detection.&lt;/li&gt; 
 &lt;li&gt;Visiting websites too quickly ‚Äî Rapid, bot-like navigation is easy to detect.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To reduce detection, follow these best practices:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Upgrade all Botasaurus packages to the latest version:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python -m pip install --upgrade bota botasaurus botasaurus-api botasaurus-requests botasaurus-driver botasaurus-proxy-authentication botasaurus-server botasaurus-humancursor
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Enable Human Mode for human-like mouse movements:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;driver.enable_human_mode()
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Avoid rapid &lt;code&gt;driver.get&lt;/code&gt; calls. Instead, try:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Clicking within pages with Human Mode enabled, if possible.&lt;/li&gt; 
   &lt;li&gt;Using &lt;code&gt;driver.google_get&lt;/code&gt; or &lt;code&gt;driver.get_via_this_page&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Using &lt;a href="https://github.com/omkarcloud/botasaurus?tab=readme-ov-file#how-to-significantly-reduce-proxy-costs-when-scraping-at-scale"&gt;&lt;code&gt;driver.requests.get&lt;/code&gt;&lt;/a&gt; to fetch the page HTML content.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Slow down your scraper with random delays:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;driver.short_random_sleep()
driver.long_random_sleep()
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Avoid using &lt;code&gt;headless&lt;/code&gt; mode, as it can be easily detected by Cloudflare, Datadome, and Imperva.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Use a residential proxy, as datacenter IPs are often flagged.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Remove the &lt;code&gt;--no-default-browser-check&lt;/code&gt; argument as it is detectable by systems like Datadome, as follows:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;@browser(remove_default_browser_check_argument=True)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If your IP has been flagged, you can perform this technique to change it:&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Visit &lt;a href="https://whatismyipaddress.com/"&gt;whatismyipaddress.com&lt;/a&gt; to see your current IP Address.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Connect your PC to a smartphone's hotspot.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;On your smartphone, turn airplane mode on and off.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Turn the hotspot on again.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Now visit &lt;a href="https://whatismyipaddress.com/"&gt;whatismyipaddress.com&lt;/a&gt;. You'll see a new IP address.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;How Do I Close All Running Chrome Instances?&lt;/h3&gt; 
&lt;p&gt;While developing a scraper, multiple browser instances may remain open in the background (because of interrupting it with CTRL + C). This situation can cause your computer to hang.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/chrome-running.png" alt="Many Chrome processes running in Task Manager" /&gt;&lt;/p&gt; 
&lt;p&gt;To prevent your PC from hanging, you can run the following command to close all Chrome instances:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python -m close_chrome
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How to Run Scraper in Docker?&lt;/h3&gt; 
&lt;p&gt;To run a Scraper in Docker, use the Botasaurus Starter Template, which includes the necessary Dockerfile and Docker Compose configurations.&lt;/p&gt; 
&lt;p&gt;Use the following commands to clone the Botasaurus Starter Template, build a Docker image from it, and execute the scraper within a Docker environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/omkarcloud/botasaurus-starter my-botasaurus-project
cd my-botasaurus-project
docker-compose build
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How to Run Scraper in Gitpod?&lt;/h3&gt; 
&lt;p&gt;Running a scraper in Gitpod offers several benefits:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Allows your scraper to use a powerful 8-core machine with 1000 Mbps internet speed&lt;/li&gt; 
 &lt;li&gt;Makes it easy to showcase your scraper to customers without them having to install anything, by simply sharing the Gitpod machine link&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In this example, we will run the Botasaurus Starter template in Gitpod:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;First, visit &lt;a href="https://gitpod.io/#https://github.com/omkarcloud/botasaurus-starter"&gt;this link&lt;/a&gt; and sign up using your GitHub account.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/google-maps-scraper/master/screenshots/open-in-gitpod.png" alt="Screenshot (148)" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Once signed up, open the starter project in Gitpod.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/assets/master/images/gitpod-continue.png" alt="gp-continue" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To use UI Scraper, run the following command in Terminal:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You will see a popup notification with the heading "A service is available on port 3000". In the popup notification, click the &lt;strong&gt;"Open Browser"&lt;/strong&gt; button to open the UI Dashboard in your browser&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/open-browser.png" alt="open-browser.png" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Now, you can press the &lt;code&gt;Run&lt;/code&gt; button to get the results.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/starter-photo.png" alt="starter-photo.png" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Note: Gitpod is not suitable for long-running tasks, as the environment will automatically shut down after a short period of inactivity. Use your local machine or a cloud VM for long-running scrapers.&lt;/p&gt; 
&lt;h2&gt;Should I Scrape Datasets Locally or in the Cloud?&lt;/h2&gt; 
&lt;p&gt;For most scraping tasks, we recommend running the scraper &lt;strong&gt;locally&lt;/strong&gt; on your system because:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;It requires far fewer setup steps&lt;/li&gt; 
 &lt;li&gt;It saves time and costs&lt;/li&gt; 
 &lt;li&gt;Most importantly, it allows you to quickly fix bugs and continue scraping.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;However, consider cloud scraping when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Running tasks longer than 5 days.&lt;/li&gt; 
 &lt;li&gt;Scraping large-scale data (terabytes).&lt;/li&gt; 
 &lt;li&gt;Performing recurring monthly scrapes.&lt;/li&gt; 
 &lt;li&gt;Having slow Internet or data caps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Cloud scraping is also significantly faster due to superior internet speeds (often 10x+ faster than home Wi-Fi).&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;How to Run a Data Scraper in a Virtual Machine?&lt;/h2&gt; 
&lt;p&gt;To run a scraper in a virtual machine (VM), follow these steps:&lt;/p&gt; 
&lt;h3&gt;1. Prepare Your Scraper&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Use the &lt;a href="https://github.com/omkarcloud/botasaurus-starter"&gt;Botasaurus Starter Template&lt;/a&gt; to create your dataset scraper.&lt;/li&gt; 
 &lt;li&gt;For large datasets, ensure memory efficiency (e.g., by using file formats like &lt;code&gt;ndjson&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;Add project dependencies to &lt;code&gt;requirements.txt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Push your project to GitHub.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;2. Set Up a Virtual Machine&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;If you don't already have one, create a Google Cloud Account. You'll receive a $300 credit to use over 3 months. &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/Select-your-billing-country.png" alt="Select-your-billing-country" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Go to &lt;a href="https://console.cloud.google.com/marketplace/product/click-to-deploy-images/nodejs"&gt;Google Click to Deploy&lt;/a&gt;, create a deployment and configure it as follows or as appropriate based on your workload:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Zone: us-central1-a # Use us-central1 (Iowa) for the lowest-cost VMs
Series: N1
Machine Type: n1-standard-2 (2 vCPU, 1 core, 7.5 GB memory)
Boot Disk Type: Standard persistent disk	# This is the most cost-effective disk option.
Boot disk size in GB: 20 GB # Adjust based on storage needs  
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/deploy-node-vm.gif" alt="Deployment setup" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to &lt;a href="https://console.cloud.google.com/compute/instances"&gt;VM Instances&lt;/a&gt; and click the SSH button to SSH into the VM. &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/ssh-vm.png" alt="ssh-vm" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Now, run the following command in the terminal and wait for it to complete:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sL https://raw.githubusercontent.com/omkarcloud/botasaurus/master/vm-scripts/install-bota.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Install your scraper by running the following command. It may take 5 minutes to install the scraper, so grab a coffee or watch &lt;a href="https://www.youtube.com/watch?v=nwAYpLVyeFU"&gt;this awesome video&lt;/a&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m bota install-scraper --repo-url https://github.com/omkarcloud/botasaurus-starter
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/install-scraper-vm.gif" alt="install-scraper" /&gt;&lt;/p&gt; 
&lt;p&gt;Note: If you are using a different repo, replace &lt;code&gt;https://github.com/omkarcloud/botasaurus-starter&lt;/code&gt; with your repo URL.&lt;/p&gt; 
&lt;p&gt;That's it! You have successfully installed the scraper in a virtual machine. The scraper will now start running and succeed.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/vm-succeed.png" alt="ls-output" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Notes&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;main.py&lt;/code&gt; file serves as the scraper's entry point.&lt;/li&gt; 
 &lt;li&gt;Update your project's &lt;code&gt;requirements.txt&lt;/code&gt; to ensure it has all the dependencies required to run the scraper.&lt;/li&gt; 
 &lt;li&gt;Ensure your VM has enough memory for your scraper's needs.&lt;/li&gt; 
 &lt;li&gt;If running a headful browser, enable a virtual display by setting &lt;code&gt;enable_xvfb_virtual_display=True&lt;/code&gt;. This creates a virtual display required for running a headful browser in a VM. &lt;pre&gt;&lt;code class="language-python"&gt;@browser(enable_xvfb_virtual_display=True)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;The scraper will run until it completes successfully or fails three times. You can also configure retries as follows: For example, to allow a maximum of 5 retries: &lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m bota install-scraper --repo-url &amp;lt;your-repo&amp;gt; --max-retry=5
&lt;/code&gt;&lt;/pre&gt; or, to allow unlimited retries: &lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m bota install-scraper --repo-url &amp;lt;your-repo&amp;gt; --max-retry=unlimited
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;If your scraper fails, you can check the logs of the current boot by running: &lt;pre&gt;&lt;code class="language-bash"&gt;journalctl -u botasaurus-starter.service -b # replace botasaurus-starter with your repo name
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Downloading Data&lt;/em&gt; To download the scraped data, you can either:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download it directly from the VM. &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/download-data-vm.png" alt="Download Data from VM" /&gt;&lt;/li&gt; 
 &lt;li&gt;Upload it to Amazon S3: &lt;pre&gt;&lt;code class="language-python"&gt;from botasaurus import bt
bt.upload_to_s3('data.json', 'my-bucket', "AWS_ACCESS_KEY", "AWS_SECRET_KEY")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;How to Stop the Scraper&lt;/h2&gt; 
&lt;p&gt;If you are performing recurring monthly scrapes, it's best to stop the scraper instead of deleting it. Note that you will only incur storage costs (~$0.4 per month for a 10GB Standard Persistent Disk) but not compute costs.&lt;/p&gt; 
&lt;p&gt;To stop the scraper:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Visit &lt;a href="https://console.cloud.google.com/compute/instances"&gt;VM Instances&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Select your VM and stop it.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/stop-scraper-in-vm.png" alt="stop-scraper-in-vm" /&gt;&lt;/p&gt; 
&lt;p&gt;To restart later:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start the VM from &lt;a href="https://console.cloud.google.com/compute/instances"&gt;VM Instances&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/run-scraper-in-vm.png" alt="run-scraper-in-vm" /&gt; 2. SSH into it. 3. Delete caches and update sitemaps if needed. 4. Restart with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;shutdown -r now
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How to Delete the Scraper and Avoid Incurring Further Charges&lt;/h2&gt; 
&lt;p&gt;If you no longer need the scraper, please ensure you have downloaded your data before deleting it.&lt;/p&gt; 
&lt;p&gt;Next, follow these steps to delete the scraper:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to &lt;a href="https://console.cloud.google.com/products/solutions/deployments"&gt;Deployments&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Delete your deployment.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/delete-deployment.png" alt="Delete deployment" /&gt;&lt;/p&gt; 
&lt;p&gt;That's it! You have successfully deleted the scraper, and you will not incur any disk or compute charges.&lt;/p&gt; 
&lt;h2&gt;How to Run a UI Scraper in a Virtual Machine&lt;/h2&gt; 
&lt;p&gt;To run your scraper in a virtual machine, we will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a static IP&lt;/li&gt; 
 &lt;li&gt;Create a VM with that IP&lt;/li&gt; 
 &lt;li&gt;SSH into the VM&lt;/li&gt; 
 &lt;li&gt;Install the scraper&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Now, follow these steps to run your scraper in a virtual machine:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create a Google Cloud Account if you don't already have one. &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/Select-your-billing-country.png" alt="Select-your-billing-country" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Visit the &lt;a href="https://console.cloud.google.com/welcome?cloudshell=true"&gt;Google Cloud Console&lt;/a&gt; and click the Cloud Shell button. A terminal will open up. &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/click-cloud-shell-btn.png" alt="click-cloud-shell-btn" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the following commands in the terminal:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python -m pip install bota
python -m bota create-ip
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You will be asked for a VM name. Enter any name you like, such as "pikachu".&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Name: pikachu&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;p&gt;Then, you will be asked for the region for the scraper. Press Enter to go with the default, which is "us-central1", as it has the lowest-cost VMs.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Region: Default&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/install-bota.gif" alt="Install bota" /&gt;&lt;/p&gt; &lt;p&gt;With this a static IP address will be created for your VM, which you can use to access your app later.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Go to &lt;a href="https://console.cloud.google.com/marketplace/product/click-to-deploy-images/nodejs"&gt;Google Click to Deploy&lt;/a&gt;, create a deployment and configure it as follows or as appropriate based on your workload:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Zone: us-central1-a # Use the zone from the region you selected in the previous step.
Series: N1
Machine Type: n1-standard-2 (2 vCPU, 1 core, 7.5 GB memory)
Boot Disk Type: Standard persistent disk	# This is the most cost-effective disk option.
Boot disk size in GB: 20 GB # Adjust based on storage needs  
Network Interface [External IP]: pikachu-ip # Use the IP name you created in the previous step.
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/deploy-node.gif" alt="deploy-node" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to &lt;a href="https://console.cloud.google.com/compute/instances"&gt;VM Instances&lt;/a&gt; and click the SSH button to SSH into the VM. &lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/ssh-vm.png" alt="ssh-vm" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Now, run the following command in the terminal:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sL https://raw.githubusercontent.com/omkarcloud/botasaurus/master/vm-scripts/install-bota.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="7"&gt; 
 &lt;li&gt; &lt;p&gt;Finally, install the UI scraper by running the following command, then wait for 5 minutes for it to complete:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m bota install-ui-scraper --repo-url https://github.com/omkarcloud/botasaurus-starter
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/install-scraper.gif" alt="install-scraper" /&gt; Note: If you are using a different repo, replace &lt;code&gt;https://github.com/omkarcloud/botasaurus-starter&lt;/code&gt; with your repo URL.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That's it! You have successfully launched the scraper in a virtual machine. When the previous commands are done, you will see a &lt;strong&gt;link&lt;/strong&gt; to your scraper. Visit it to run your scraper.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/vm-success.gif" alt="vm-success" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Notes&lt;/em&gt; - Update your project's &lt;code&gt;requirements.txt&lt;/code&gt; to ensure it has all the dependencies required to run the scraper. - Ensure your VM has enough memory for your scraper's needs. - If running a headful browser, enable a virtual display by setting &lt;code&gt;enable_xvfb_virtual_display=True&lt;/code&gt;. This creates a virtual display required for running a headful browser in a VM.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@browser(enable_xvfb_virtual_display=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;- The UI scraper will run indefinitely and will be available at the printed link.
- If your UI scraper fails, you can check the logs of the current boot by running:
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;journalctl -u backend.service -b 
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How to Delete the UI Scraper and Avoid Incurring Further Charges&lt;/h2&gt; 
&lt;p&gt;If you no longer need the scraper, please ensure you have downloaded your data before deleting it.&lt;/p&gt; 
&lt;p&gt;Next, follow these steps to delete the scraper:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Delete the static IP by running the following command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python -m bota delete-ip
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You will be asked for the name of the VM you created in the first step. Enter the name and press Enter.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/delete-ip.png" alt="Delete IP" /&gt;&lt;/p&gt; &lt;p&gt;Note: If you forgot the name of the IP, you can also delete all the IPs by running &lt;code&gt;python -m bota delete-all-ips&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Go to &lt;a href="https://console.cloud.google.com/products/solutions/deployments"&gt;Deployments&lt;/a&gt; and delete your deployment.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/botasaurus/master/images/delete-deployment.png" alt="Delete deployment" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That's it! You have successfully deleted the scraper, and you will not incur any further charges.&lt;/p&gt; 
&lt;h3&gt;How to Run Scraper in Kubernetes?&lt;/h3&gt; 
&lt;p&gt;Visit &lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/run-scraper-in-kubernetes.md"&gt;this link&lt;/a&gt; to learn how to run scraper at scale using Kubernetes.&lt;/p&gt; 
&lt;h3&gt;I have a feature request!&lt;/h3&gt; 
&lt;p&gt;We'd love to hear it! Share them on &lt;a href="https://github.com/omkarcloud/botasaurus/discussions"&gt;GitHub Discussions&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.omkar.cloud/l/botasaurus-make-discussions/"&gt;&lt;img src="https://raw.githubusercontent.com/omkarcloud/google-maps-scraper/master/screenshots/ask-on-github.png" alt="Make" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- 
### Do you have a Discord community?

Yes, we have a Discord community where you can connect with other developers, ask questions, and share your experiences. Join our Discord community [here](https://discord.com/invite/rw9VeyuSM8). --&gt; 
&lt;h3&gt;‚ùì Advanced Questions&lt;/h3&gt; 
&lt;p&gt;Congratulations on completing the Botasaurus Documentation! Now, you have all the knowledge needed to effectively use Botasaurus.&lt;/p&gt; 
&lt;p&gt;You may choose to read the following questions based on your interests:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#how-to-run-botasaurus-in-google-colab"&gt;How to Run Botasaurus in Google Colab?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#how-can-i-allow-users-to-filter-the-scraped-data"&gt;How can I allow users to filter the scraped data?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#how-can-i-allow-the-user-to-sort-the-scraped-data"&gt;How can I allow the user to sort the scraped data?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#how-can-i-present-the-scraped-data-in-different-views"&gt;How can I present the scraped data in different views?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#when-building-a-large-dataset-customers-often-request-data-in-different-formats-like-overview-and-review-how-can-i-do-that"&gt;When building a large dataset, customers often request data in different formats like overview and review. How can I do that?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#what-more-can-i-configure-when-adding-a-scraper"&gt;What more can I configure when adding a scraper?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#how-to-control-the-maximum-number-of-browsers-and-requests-running-at-any-point-of-time"&gt;How to control the maximum number of browsers and requests running at any point of time?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#how-do-i-change-the-title-header-title-and-description-of-the-scraper"&gt;How do I change the title, header title, and description of the scraper?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#how-can-i-use-a-database-like-postgresql-with-ui-scraper"&gt;How can I use a database like PostgreSQL with UI Scraper?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#which-postgresql-provider-should-i-choose-among-supabase-google-cloud-sql-heroku-and-amazon-rds"&gt;Which PostgreSQL provider should I choose among Supabase, Google Cloud SQL, Heroku, and Amazon RDS?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#how-to-create-a-postgresql-database-on-supabase"&gt;How to create a PostgreSQL database on Supabase?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#how-to-create-a-postgresql-database-on-google-cloud"&gt;How to create a PostgreSQL database on Google Cloud?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/omkarcloud/botasaurus/raw/master/advanced.md#i-am-a-youtuber-should-i-create-youtube-videos-about-botasaurus-if-so-how-can-you-help-me"&gt;I am a Youtuber, Should I create YouTube videos about Botasaurus? If so, how can you help me?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Thank You&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;To That, who has given me a sufficiently intelligent mind to create Botasaurus and do a lot of good.&lt;/li&gt; 
 &lt;li&gt;I made Botasaurus because I would be really happy if you could use it to successfully complete your project. So, a Gigantic Thank you for using Botasaurus!&lt;/li&gt; 
 &lt;li&gt;A heartfelt thank you to &lt;a href="https://zcbenz.com/"&gt;Cheng Zhao&lt;/a&gt; from GitHub for creating Electron, which powers Botasaurus Desktop.&lt;/li&gt; 
 &lt;li&gt;Kudos to the Apify Team for creating the &lt;code&gt;proxy-chain&lt;/code&gt; library. The implementation of SSL-based Proxy Authentication wouldn't have been possible without their groundbreaking work on &lt;code&gt;proxy-chain&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Shout out to &lt;a href="https://github.com/ultrafunkamsterdam"&gt;ultrafunkamsterdam&lt;/a&gt; for creating &lt;code&gt;nodriver&lt;/code&gt;, which inspired the creation of Botasaurus Driver.&lt;/li&gt; 
 &lt;li&gt;A big thank you to &lt;a href="https://github.com/daijro"&gt;daijro&lt;/a&gt; for creating &lt;a href="https://github.com/daijro/hrequests"&gt;hrequest&lt;/a&gt;, which inspired the creation of botasaurus-requests.&lt;/li&gt; 
 &lt;li&gt;Deepest gratitude to &lt;a href="https://github.com/riflosnake"&gt;Flori Batusha&lt;/a&gt; and &lt;a href="https://github.com/iLeaf30/"&gt;Ambri&lt;/a&gt; for their contributions in creating &lt;strong&gt;Botasaurus Humancursor&lt;/strong&gt;, which brings human-like mouse movements to Botasaurus.&lt;/li&gt; 
 &lt;li&gt;A humongous thank you to Cloudflare, DataDome, Imperva, and all bot recognition systems. Had you not been there, we wouldn't be either üòÖ.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Now, what are you waiting for? ü§î Go and make something mastastic! üöÄ&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Love It? &lt;a href="https://github.com/omkarcloud/botasaurus"&gt;Star It! ‚≠ê&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Become one of our amazing stargazers by giving us a star ‚≠ê on GitHub!&lt;/p&gt; 
&lt;p&gt;It's just one click, but it means the world to me.&lt;/p&gt; 
&lt;a href="https://github.com/omkarcloud/botasaurus/stargazers"&gt; &lt;img src="https://bytecrank.com/nastyox/reporoster/php/stargazersSVG.php?user=omkarcloud&amp;amp;repo=botasaurus" alt="Stargazers for @omkarcloud/botasaurus" /&gt; &lt;/a&gt; 
&lt;h2&gt;Disclaimer for Botasaurus Project&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;By using Botasaurus, you agree to comply with all applicable local and international laws related to data scraping, copyright, and privacy. The developers of Botasaurus are not responsible for any misuse of this software. It is the sole responsibility of the user to ensure adherence to all relevant laws regarding data scraping, copyright, and privacy, and to use Botasaurus in an ethical and legal manner.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We take the concerns of the Botasaurus Project very seriously. For any inquiries or issues, please contact Chetan Jain at &lt;a href="mailto:chetan@omkar.cloud"&gt;chetan@omkar.cloud&lt;/a&gt;. We will take prompt and necessary action in response to your emails.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>coleam00/Archon</title>
      <link>https://github.com/coleam00/Archon</link>
      <description>&lt;p&gt;Beta release of Archon OS - the knowledge and task management backbone for AI coding assistants.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/coleam00/Archon/main/archon-ui-main/public/archon-main-graphic.png" alt="Archon Main Graphic" width="853" height="422" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;em&gt;Power up your AI coding assistants with your own custom knowledge base and task management as an MCP server&lt;/em&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/coleam00/Archon/main/#quick-start"&gt;Quick Start&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/coleam00/Archon/main/#whats-included"&gt;What's Included&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/coleam00/Archon/main/#architecture"&gt;Architecture&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéØ What is Archon?&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Archon is currently in beta! Expect things to not work 100%, and please feel free to share any feedback and contribute with fixes/new features!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Archon is the &lt;strong&gt;command center&lt;/strong&gt; for AI coding assistants. For you, it's a sleek interface to manage knowledge, context, and tasks for your projects. For the AI coding assistant(s), it's a &lt;strong&gt;Model Context Protocol (MCP) server&lt;/strong&gt; to collaborate on and leverage the same knowledge, context, and tasks. Connect Claude Code, Kiro, Cursor, Windsurf, etc. to give your AI agents access to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Your documentation&lt;/strong&gt; (crawled websites, uploaded PDFs/docs)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart search capabilities&lt;/strong&gt; with advanced RAG strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Task management&lt;/strong&gt; integrated with your knowledge base&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time updates&lt;/strong&gt; as you add new content and collaborate with your coding assistant on tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Much more&lt;/strong&gt; coming soon to build Archon into an integrated environment for all context engineering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This new vision for Archon replaces the old one (the agenteer). Archon used to be the AI agent that builds other agents, and now you can use Archon to do that and more.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It doesn't matter what you're building or if it's a new/existing codebase - Archon's knowledge and task management capabilities will improve the output of &lt;strong&gt;any&lt;/strong&gt; AI driven coding.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üîó Important Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/coleam00/Archon/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/strong&gt; - Join the conversation and share ideas about Archon&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/coleam00/Archon/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;&lt;/strong&gt; - How to get involved and contribute to Archon&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://youtu.be/8pRc_s2VQIo"&gt;Introduction Video&lt;/a&gt;&lt;/strong&gt; - Getting Started Guide and Vision for Archon&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://dynamous.ai"&gt;Dynamous AI Mastery&lt;/a&gt;&lt;/strong&gt; - The birthplace of Archon - come join a vibrant community of other early AI adopters all helping each other transform their careers and businesses!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://supabase.com/"&gt;Supabase&lt;/a&gt; account (free tier or local Supabase both work)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://platform.openai.com/api-keys"&gt;OpenAI API key&lt;/a&gt; (Gemini and Ollama are supported too!)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup Instructions&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone Repository&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/coleam00/archon.git
cd archon
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Environment Configuration&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env
# Edit .env and add your Supabase credentials:
# SUPABASE_URL=https://your-project.supabase.co
# SUPABASE_SERVICE_KEY=your-service-key-here
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;NOTE: Supabase introduced a new type of service key but use the legacy one (the longer one).&lt;/p&gt; &lt;p&gt;OPTIONAL: If you want to enable the reranking RAG strategy, uncomment lines 20-22 in &lt;code&gt;python\requirements.server.txt&lt;/code&gt;. This will significantly increase the size of the Archon Server container which is why it's off by default.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Database Setup&lt;/strong&gt;: In your &lt;a href="https://supabase.com/dashboard"&gt;Supabase project&lt;/a&gt; SQL Editor, copy, paste, and execute the contents of &lt;code&gt;migration/complete_setup.sql&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start Services&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up --build -d
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This starts the core microservices:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Server&lt;/strong&gt;: Core API and business logic (Port: 8181)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;MCP Server&lt;/strong&gt;: Protocol interface for AI clients (Port: 8051)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Agents (coming soon!)&lt;/strong&gt;: AI operations and streaming (Port: 8052)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: Web interface (Port: 3737)&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Ports are configurable in your .env as well!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configure API Keys&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Open &lt;a href="http://localhost:3737"&gt;http://localhost:3737&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Go to &lt;strong&gt;Settings&lt;/strong&gt; ‚Üí Select your LLM/embedding provider and set the API key (OpenAI is default)&lt;/li&gt; 
   &lt;li&gt;Test by uploading a document or crawling a website&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üîÑ Database Reset (Start Fresh if Needed)&lt;/h2&gt; 
&lt;p&gt;If you need to completely reset your database and start fresh:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;‚ö†Ô∏è &lt;strong&gt;Reset Database - This will delete ALL data for Archon!&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run Reset Script&lt;/strong&gt;: In your Supabase SQL Editor, run the contents of &lt;code&gt;migration/RESET_DB.sql&lt;/code&gt;&lt;/p&gt; &lt;p&gt;‚ö†Ô∏è WARNING: This will delete all Archon specific tables and data! Nothing else will be touched in your DB though.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rebuild Database&lt;/strong&gt;: After reset, run &lt;code&gt;migration/complete_setup.sql&lt;/code&gt; to create all the tables again.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Restart Services&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reconfigure&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Select your LLM/embedding provider and set the API key again&lt;/li&gt; 
    &lt;li&gt;Re-upload any documents or re-crawl websites&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;The reset script safely removes all tables, functions, triggers, and policies with proper dependency handling.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ö° Quick Test&lt;/h2&gt; 
&lt;p&gt;Once everything is running:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Test Web Crawling&lt;/strong&gt;: Go to &lt;a href="http://localhost:3737"&gt;http://localhost:3737&lt;/a&gt; ‚Üí Knowledge Base ‚Üí "Crawl Website" ‚Üí Enter a doc URL (such as &lt;a href="https://ai.pydantic.dev/llms-full.txt"&gt;https://ai.pydantic.dev/llms-full.txt&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test Document Upload&lt;/strong&gt;: Knowledge Base ‚Üí Upload a PDF&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test Projects&lt;/strong&gt;: Projects ‚Üí Create a new project and add tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integrate with your AI coding assistant&lt;/strong&gt;: MCP Dashboard ‚Üí Copy connection config for your AI coding assistant&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;h3&gt;Core Services&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;Container Name&lt;/th&gt; 
   &lt;th&gt;Default URL&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Web Interface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;archon-ui&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:3737"&gt;http://localhost:3737&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Main dashboard and controls&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Service&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;archon-server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:8181"&gt;http://localhost:8181&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Web crawling, document processing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;archon-mcp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:8051"&gt;http://localhost:8051&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Model Context Protocol interface&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Agents Service&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;archon-agents&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:8052"&gt;http://localhost:8052&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;AI/ML operations, reranking&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;What's Included&lt;/h2&gt; 
&lt;h3&gt;üß† Knowledge Management&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Web Crawling&lt;/strong&gt;: Automatically detects and crawls entire documentation sites, sitemaps, and individual pages&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document Processing&lt;/strong&gt;: Upload and process PDFs, Word docs, markdown files, and text documents with intelligent chunking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Example Extraction&lt;/strong&gt;: Automatically identifies and indexes code examples from documentation for enhanced search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vector Search&lt;/strong&gt;: Advanced semantic search with contextual embeddings for precise knowledge retrieval&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Source Management&lt;/strong&gt;: Organize knowledge by source, type, and tags for easy filtering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ü§ñ AI Integration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt;: Connect any MCP-compatible client (Claude Code, Cursor, even non-AI coding assistants like Claude Desktop)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;10 MCP Tools&lt;/strong&gt;: Comprehensive yet simple set of tools for RAG queries, task management, and project operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-LLM Support&lt;/strong&gt;: Works with OpenAI, Ollama, and Google Gemini models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RAG Strategies&lt;/strong&gt;: Hybrid search, contextual embeddings, and result reranking for optimal AI responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time Streaming&lt;/strong&gt;: Live responses from AI agents with progress tracking&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Project &amp;amp; Task Management&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hierarchical Projects&lt;/strong&gt;: Organize work with projects, features, and tasks in a structured workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI-Assisted Creation&lt;/strong&gt;: Generate project requirements and tasks using integrated AI agents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document Management&lt;/strong&gt;: Version-controlled documents with collaborative editing capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Progress Tracking&lt;/strong&gt;: Real-time updates and status management across all project activities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîÑ Real-time Collaboration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;WebSocket Updates&lt;/strong&gt;: Live progress tracking for crawling, processing, and AI operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-user Support&lt;/strong&gt;: Collaborative knowledge building and project management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Processing&lt;/strong&gt;: Asynchronous operations that don't block the user interface&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Health Monitoring&lt;/strong&gt;: Built-in service health checks and automatic reconnection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;h3&gt;Microservices Structure&lt;/h3&gt; 
&lt;p&gt;Archon uses true microservices architecture with clear separation of concerns:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend UI   ‚îÇ    ‚îÇ  Server (API)   ‚îÇ    ‚îÇ   MCP Server    ‚îÇ    ‚îÇ Agents Service  ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ  React + Vite   ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ    FastAPI +    ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ    Lightweight  ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   PydanticAI    ‚îÇ
‚îÇ  Port 3737      ‚îÇ    ‚îÇ    SocketIO     ‚îÇ    ‚îÇ    HTTP Wrapper ‚îÇ    ‚îÇ   Port 8052     ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ    Port 8181    ‚îÇ    ‚îÇ    Port 8051    ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                        ‚îÇ                        ‚îÇ                        ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ                        ‚îÇ
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
                         ‚îÇ    Database     ‚îÇ               ‚îÇ
                         ‚îÇ                 ‚îÇ               ‚îÇ
                         ‚îÇ    Supabase     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ    PostgreSQL   ‚îÇ
                         ‚îÇ    PGVector     ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Service Responsibilities&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;Location&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Key Features&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Frontend&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;archon-ui-main/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Web interface and dashboard&lt;/td&gt; 
   &lt;td&gt;React, TypeScript, TailwindCSS, Socket.IO client&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Server&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;python/src/server/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Core business logic and APIs&lt;/td&gt; 
   &lt;td&gt;FastAPI, service layer, Socket.IO broadcasts, all ML/AI operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;python/src/mcp/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;MCP protocol interface&lt;/td&gt; 
   &lt;td&gt;Lightweight HTTP wrapper, 10 MCP tools, session management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Agents&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;python/src/agents/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;PydanticAI agent hosting&lt;/td&gt; 
   &lt;td&gt;Document and RAG agents, streaming responses&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Communication Patterns&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP-based&lt;/strong&gt;: All inter-service communication uses HTTP APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Socket.IO&lt;/strong&gt;: Real-time updates from Server to Frontend&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Protocol&lt;/strong&gt;: AI clients connect to MCP Server via SSE or stdio&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No Direct Imports&lt;/strong&gt;: Services are truly independent with no shared code dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Architectural Benefits&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight Containers&lt;/strong&gt;: Each service contains only required dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Independent Scaling&lt;/strong&gt;: Services can be scaled independently based on load&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Development Flexibility&lt;/strong&gt;: Teams can work on different services without conflicts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Technology Diversity&lt;/strong&gt;: Each service uses the best tools for its specific purpose&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîß Configuring Custom Ports &amp;amp; Hostname&lt;/h2&gt; 
&lt;p&gt;By default, Archon services run on the following ports:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Archon-UI&lt;/strong&gt;: 3737&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Archon-Server&lt;/strong&gt;: 8181&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Archon-MCP&lt;/strong&gt;: 8051&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Archon-Agents&lt;/strong&gt;: 8052&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Archon-Docs&lt;/strong&gt;: 3838 (optional)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Changing Ports&lt;/h3&gt; 
&lt;p&gt;To use custom ports, add these variables to your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Service Ports Configuration
ARCHON_UI_PORT=3737
ARCHON_SERVER_PORT=8181
ARCHON_MCP_PORT=8051
ARCHON_AGENTS_PORT=8052
ARCHON_DOCS_PORT=3838
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example: Running on different ports:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ARCHON_SERVER_PORT=8282
ARCHON_MCP_PORT=8151
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuring Hostname&lt;/h3&gt; 
&lt;p&gt;By default, Archon uses &lt;code&gt;localhost&lt;/code&gt; as the hostname. You can configure a custom hostname or IP address by setting the &lt;code&gt;HOST&lt;/code&gt; variable in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Hostname Configuration
HOST=localhost  # Default

# Examples of custom hostnames:
HOST=192.168.1.100     # Use specific IP address
HOST=archon.local      # Use custom domain
HOST=myserver.com      # Use public domain
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is useful when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Running Archon on a different machine and accessing it remotely&lt;/li&gt; 
 &lt;li&gt;Using a custom domain name for your installation&lt;/li&gt; 
 &lt;li&gt;Deploying in a network environment where &lt;code&gt;localhost&lt;/code&gt; isn't accessible&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;After changing hostname or ports:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Restart Docker containers: &lt;code&gt;docker-compose down &amp;amp;&amp;amp; docker-compose up -d&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Access the UI at: &lt;code&gt;http://${HOST}:${ARCHON_UI_PORT}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Update your AI client configuration with the new hostname and MCP port&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üîß Development&lt;/h2&gt; 
&lt;p&gt;For development with hot reload:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Backend services (with auto-reload)
docker-compose up archon-server archon-mcp archon-agents --build

# Frontend (with hot reload) 
cd archon-ui-main &amp;amp;&amp;amp; npm run dev

# Documentation (with hot reload)
cd docs &amp;amp;&amp;amp; npm start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The backend services are configured with &lt;code&gt;--reload&lt;/code&gt; flag in their uvicorn commands and have source code mounted as volumes for automatic hot reloading when you make changes.&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;Archon Community License (ACL) v1.2 - see &lt;a href="https://raw.githubusercontent.com/coleam00/Archon/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;: Archon is free, open, and hackable. Run it, fork it, share it - just don't sell it as-a-service without permission.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>trailofbits/buttercup</title>
      <link>https://github.com/trailofbits/buttercup</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Buttercup Cyber Reasoning System (CRS)&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/trailofbits/buttercup/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/trailofbits/buttercup/actions/workflows/tests.yml/badge.svg?sanitize=true" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/trailofbits/buttercup/actions/workflows/tests.yml"&gt;&lt;img src="https://github.com/trailofbits/buttercup/actions/workflows/tests.yml/badge.svg?event=schedule" alt="Tests (Nightly)" /&gt;&lt;/a&gt; &lt;a href="https://github.com/trailofbits/buttercup/actions/workflows/integration.yml"&gt;&lt;img src="https://github.com/trailofbits/buttercup/actions/workflows/integration.yml/badge.svg?sanitize=true" alt="Integration" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Buttercup&lt;/strong&gt; is a Cyber Reasoning System (CRS) developed by &lt;strong&gt;Trail of Bits&lt;/strong&gt; for the &lt;strong&gt;DARPA AIxCC (AI Cyber Challenge)&lt;/strong&gt;. Buttercup finds and patches software vulnerabilities in open-source code repositories like &lt;a href="https://github.com/tob-challenges/example-libpng"&gt;example-libpng&lt;/a&gt;. It starts by running an AI/ML-assisted fuzzing campaign (built on oss-fuzz) for the program. When vulnerabilities are found, Buttercup analyzes them and uses a multi-agent AI-driven patcher to repair the vulnerability. &lt;strong&gt;Buttercup&lt;/strong&gt; system consists of several components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Orchestrator&lt;/strong&gt;: Coordinates the overall task process and manages the workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seed Generator&lt;/strong&gt;: Creates inputs for vulnerability discovery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fuzzer&lt;/strong&gt;: Discovers vulnerabilities through intelligent fuzzing techniques&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Program Model&lt;/strong&gt;: Analyzes code structure and semantics for better understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Patcher&lt;/strong&gt;: Generates and applies security patches to fix vulnerabilities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;h3&gt;Minimum Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CPU:&lt;/strong&gt; 8 cores&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory:&lt;/strong&gt; 16 GB RAM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage:&lt;/strong&gt; 100 GB available disk space&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network:&lt;/strong&gt; Stable internet connection for downloading dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Buttercup uses third-party AI providers (LLMs from companies like OpenAI, Anthropic and Google), which cost money. Please ensure that you manage per-deployment costs by using the built-in LLM budget setting.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Buttercup works best with access to models from OpenAI &lt;strong&gt;and&lt;/strong&gt; Anthropic, but can be run with at least one API key from one third-party provider (support for Gemini coming soon).&lt;/p&gt; 
&lt;h3&gt;Supported Systems&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Linux x86_64&lt;/strong&gt; (fully supported)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ARM64&lt;/strong&gt; (partial support for upstream Google OSS-Fuzz projects)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Required System Packages&lt;/h3&gt; 
&lt;p&gt;Before setup, ensure you have these packages installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y make curl git

# RHEL/CentOS/Fedora
sudo yum install -y make curl git
# or
sudo dnf install -y make curl git

# MacOS
brew install make curl git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Supported Targets&lt;/h3&gt; 
&lt;p&gt;Buttercup works with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;C source code repositories&lt;/strong&gt; that are OSS-Fuzz compatible&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Java source code repositories&lt;/strong&gt; that are OSS-Fuzz compatible&lt;/li&gt; 
 &lt;li&gt;Projects that build successfully and have existing fuzzing harnesses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository with submodules:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --recurse-submodules https://github.com/trailofbits/buttercup.git
cd buttercup
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Run automated setup (Recommended)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make setup-local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This script will install all dependencies, configure the environment, and guide you through the setup process.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you prefer manual setup, see the &lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/MANUAL_SETUP.md"&gt;Manual Setup Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Start Buttercup locally&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make deploy-local
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Verify local deployment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make status
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When a deployment is successful, you should see all pods in "Running" or "Completed" status.&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Send Buttercup a simple task&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When tasked, Buttercup will start consuming third-party AI resources.&lt;/p&gt; 
&lt;p&gt;This command will make Buttercup pull down an example repo &lt;a href="https://github.com/tob-challenges/example-libpng"&gt;example-libpng&lt;/a&gt; with a known vulnerability. Buttercup will start fuzzing it to find and patch vulnerabilities.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make send-libpng-task
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt;Access Buttercup's web-based GUI&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make web-ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then navigate to &lt;code&gt;http://localhost:31323&lt;/code&gt; in your web browser.&lt;/p&gt; 
&lt;p&gt;In the GUI you can monitor active tasks and see when Buttercup finds bugs and generates patches for them.&lt;/p&gt; 
&lt;ol start="7"&gt; 
 &lt;li&gt;Stop Buttercup&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This is an important step to ensure Buttercup shuts down and stops consuming third-party AI resources.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make undeploy
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Accessing Logs&lt;/h2&gt; 
&lt;p&gt;Buttercup includes local SigNoz deployment by default for comprehensive system observability. You can access logs, traces, and metrics through the SigNoz UI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make signoz-ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then navigate to &lt;code&gt;http://localhost:33301&lt;/code&gt; in your web browser to view:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Distributed traces&lt;/li&gt; 
 &lt;li&gt;Application metrics&lt;/li&gt; 
 &lt;li&gt;Error monitoring&lt;/li&gt; 
 &lt;li&gt;Performance insights&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you configured LangFuse during setup, you can also monitor LLM usage and costs there.&lt;/p&gt; 
&lt;p&gt;For additional log access methods, see the &lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/QUICK_REFERENCE.md"&gt;Quick Reference Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Additional Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/QUICK_REFERENCE.md"&gt;Quick Reference Guide&lt;/a&gt; - Common commands and troubleshooting&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/MANUAL_SETUP.md"&gt;Manual Setup Guide&lt;/a&gt; - Detailed manual installation steps&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/AKS_DEPLOYMENT.md"&gt;AKS Deployment Guide&lt;/a&gt; - Production deployment on Azure&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt; - Development workflow and standards&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/deployment/README.md"&gt;Deployment Documentation&lt;/a&gt; - Advanced deployment configuration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/trailofbits/buttercup/main/CUSTOM_CHALLENGES.md"&gt;Writing Custom Challenges&lt;/a&gt; - Custom project configuration and setup&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>lipku/LiveTalking</title>
      <link>https://github.com/lipku/LiveTalking</link>
      <description>&lt;p&gt;Real time interactive streaming digital human&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lipku/LiveTalking/main/README-EN.md"&gt;English&lt;/a&gt; | ‰∏≠ÊñáÁâà&lt;br /&gt; ÂÆûÊó∂‰∫§‰∫íÊµÅÂºèÊï∞Â≠ó‰∫∫ÔºåÂÆûÁé∞Èü≥ËßÜÈ¢ëÂêåÊ≠•ÂØπËØù„ÄÇÂü∫Êú¨ÂèØ‰ª•ËææÂà∞ÂïÜÁî®ÊïàÊûú &lt;a href="https://www.bilibili.com/video/BV1scwBeyELA/"&gt;wav2lipÊïàÊûú&lt;/a&gt; | &lt;a href="https://www.bilibili.com/video/BV1G1421z73r/"&gt;ernerfÊïàÊûú&lt;/a&gt; | &lt;a href="https://www.bilibili.com/video/BV1gm421N7vQ/"&gt;musetalkÊïàÊûú&lt;/a&gt;&lt;br /&gt; ÂõΩÂÜÖÈïúÂÉèÂú∞ÂùÄ:&lt;a href="https://gitee.com/lipku/LiveTalking"&gt;https://gitee.com/lipku/LiveTalking&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‰∏∫ÈÅøÂÖç‰∏é3dÊï∞Â≠ó‰∫∫Ê∑∑Ê∑ÜÔºåÂéüÈ°πÁõÆmetahuman-streamÊîπÂêç‰∏∫livetalkingÔºåÂéüÊúâÈìæÊé•Âú∞ÂùÄÁªßÁª≠ÂèØÁî®&lt;/h2&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;2024.12.8 ÂÆåÂñÑÂ§öÂπ∂ÂèëÔºåÊòæÂ≠ò‰∏çÈöèÂπ∂ÂèëÊï∞Â¢ûÂä†&lt;/li&gt; 
 &lt;li&gt;2024.12.21 Ê∑ªÂä†wav2lip„ÄÅmusetalkÊ®°ÂûãÈ¢ÑÁÉ≠ÔºåËß£ÂÜ≥Á¨¨‰∏ÄÊ¨°Êé®ÁêÜÂç°È°øÈóÆÈ¢ò„ÄÇÊÑüË∞¢&lt;a href="https://github.com/heimaojinzhangyz"&gt;@heimaojinzhangyz&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2024.12.28 Ê∑ªÂä†Êï∞Â≠ó‰∫∫Ê®°ÂûãUltralight-Digital-Human„ÄÇ ÊÑüË∞¢&lt;a href="https://github.com/lijihua2017"&gt;@lijihua2017&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2025.2.7 Ê∑ªÂä†fish-speech tts&lt;/li&gt; 
 &lt;li&gt;2025.2.21 Ê∑ªÂä†wav2lip256ÂºÄÊ∫êÊ®°Âûã ÊÑüË∞¢@‰∏çË†¢‰∏çË†¢&lt;/li&gt; 
 &lt;li&gt;2025.3.2 Ê∑ªÂä†ËÖæËÆØËØ≠Èü≥ÂêàÊàêÊúçÂä°&lt;/li&gt; 
 &lt;li&gt;2025.3.16 ÊîØÊåÅmac gpuÊé®ÁêÜÔºåÊÑüË∞¢&lt;a href="https://github.com/GcsSloop"&gt;@GcsSloop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2025.5.1 Á≤æÁÆÄËøêË°åÂèÇÊï∞ÔºåernerfÊ®°ÂûãÁßªËá≥gitÂàÜÊîØernerf-rtmp&lt;/li&gt; 
 &lt;li&gt;2025.6.7 Ê∑ªÂä†ËôöÊãüÊëÑÂÉèÂ§¥ËæìÂá∫&lt;/li&gt; 
 &lt;li&gt;2025.7.5 Ê∑ªÂä†Ë±ÜÂåÖËØ≠Èü≥ÂêàÊàê, ÊÑüË∞¢&lt;a href="https://github.com/ELK-milu"&gt;@ELK-milu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;2025.7.26 ÊîØÊåÅmusetalk v1.5ÁâàÊú¨&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;ÊîØÊåÅÂ§öÁßçÊï∞Â≠ó‰∫∫Ê®°Âûã: ernerf„ÄÅmusetalk„ÄÅwav2lip„ÄÅUltralight-Digital-Human&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅÂ£∞Èü≥ÂÖãÈöÜ&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅÊï∞Â≠ó‰∫∫ËØ¥ËØùË¢´ÊâìÊñ≠&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅÂÖ®Ë∫´ËßÜÈ¢ëÊãºÊé•&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅwebrtc„ÄÅËôöÊãüÊëÑÂÉèÂ§¥ËæìÂá∫&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅÂä®‰ΩúÁºñÊéíÔºö‰∏çËØ¥ËØùÊó∂Êí≠ÊîæËá™ÂÆö‰πâËßÜÈ¢ë&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅÂ§öÂπ∂Âèë&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;Tested on Ubuntu 24.04, Python3.10, Pytorch 2.5.0 and CUDA 12.4&lt;/p&gt; 
&lt;h3&gt;1.1 Install dependency&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n nerfstream python=3.10
conda activate nerfstream
#Â¶ÇÊûúcudaÁâàÊú¨‰∏ç‰∏∫12.4(ËøêË°ånvidia-smiÁ°ÆËÆ§ÁâàÊú¨)ÔºåÊ†πÊçÆ&amp;lt;https://pytorch.org/get-started/previous-versions/&amp;gt;ÂÆâË£ÖÂØπÂ∫îÁâàÊú¨ÁöÑpytorch 
conda install pytorch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 pytorch-cuda=12.4 -c pytorch -c nvidia
pip install -r requirements.txt
#Â¶ÇÊûúÈúÄË¶ÅËÆ≠ÁªÉernerfÊ®°ÂûãÔºåÂÆâË£Ö‰∏ãÈù¢ÁöÑÂ∫ì
# pip install "git+https://github.com/facebookresearch/pytorch3d.git"
# pip install tensorflow-gpu==2.8.0
# pip install --upgrade "protobuf&amp;lt;=3.20.1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂÆâË£ÖÂ∏∏ËßÅÈóÆÈ¢ò&lt;a href="https://livetalking-doc.readthedocs.io/zh-cn/latest/faq.html"&gt;FAQ&lt;/a&gt;&lt;br /&gt; linux cudaÁéØÂ¢ÉÊê≠Âª∫ÂèØ‰ª•ÂèÇËÄÉËøôÁØáÊñáÁ´† &lt;a href="https://zhuanlan.zhihu.com/p/674972886"&gt;https://zhuanlan.zhihu.com/p/674972886&lt;/a&gt;&lt;br /&gt; ËßÜÈ¢ëËøû‰∏ç‰∏äËß£ÂÜ≥ÊñπÊ≥ï &lt;a href="https://mp.weixin.qq.com/s/MVUkxxhV2cgMMHalphr2cg"&gt;https://mp.weixin.qq.com/s/MVUkxxhV2cgMMHalphr2cg&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;2. Quick Start&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;‰∏ãËΩΩÊ®°Âûã&lt;br /&gt; Â§∏ÂÖã‰∫ëÁõò&lt;a href="https://pan.quark.cn/s/83a750323ef0"&gt;https://pan.quark.cn/s/83a750323ef0&lt;/a&gt;&lt;br /&gt; GoogleDriver &lt;a href="https://drive.google.com/drive/folders/1FOC_MD6wdogyyX_7V1d4NDIO7P9NlSAJ?usp=sharing"&gt;https://drive.google.com/drive/folders/1FOC_MD6wdogyyX_7V1d4NDIO7P9NlSAJ?usp=sharing&lt;/a&gt;&lt;br /&gt; Â∞Üwav2lip256.pthÊã∑Âà∞Êú¨È°πÁõÆÁöÑmodels‰∏ã, ÈáçÂëΩÂêç‰∏∫wav2lip.pth;&lt;br /&gt; Â∞Üwav2lip256_avatar1.tar.gzËß£ÂéãÂêéÊï¥‰∏™Êñá‰ª∂Â§πÊã∑Âà∞Êú¨È°πÁõÆÁöÑdata/avatars‰∏ã&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ËøêË°å&lt;br /&gt; python app.py --transport webrtc --model wav2lip --avatar_id wav2lip256_avatar1&lt;br /&gt; &lt;font color="red"&gt;ÊúçÂä°Á´ØÈúÄË¶ÅÂºÄÊîæÁ´ØÂè£ tcp:8010; udp:1-65536 &lt;/font&gt;&lt;br /&gt; ÂÆ¢Êà∑Á´ØÂèØ‰ª•ÈÄâÁî®‰ª•‰∏ã‰∏§ÁßçÊñπÂºè:&lt;br /&gt; (1)Áî®ÊµèËßàÂô®ÊâìÂºÄ&lt;a href="http://serverip:8010/webrtcapi.html"&gt;http://serverip:8010/webrtcapi.html&lt;/a&gt; , ÂÖàÁÇπ‚Äòstart',Êí≠ÊîæÊï∞Â≠ó‰∫∫ËßÜÈ¢ëÔºõÁÑ∂ÂêéÂú®ÊñáÊú¨Ê°ÜËæìÂÖ•‰ªªÊÑèÊñáÂ≠óÔºåÊèê‰∫§„ÄÇÊï∞Â≠ó‰∫∫Êí≠Êä•ËØ•ÊÆµÊñáÂ≠ó&lt;br /&gt; (2)Áî®ÂÆ¢Êà∑Á´ØÊñπÂºè, ‰∏ãËΩΩÂú∞ÂùÄ&lt;a href="https://pan.quark.cn/s/d7192d8ac19b"&gt;https://pan.quark.cn/s/d7192d8ac19b&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Âø´ÈÄü‰ΩìÈ™å&lt;br /&gt; &lt;a href="https://www.compshare.cn/images/4458094e-a43d-45fe-9b57-de79253befe4?referral_code=3XW3852OBmnD089hMMrtuU&amp;amp;ytag=GPU_GitHub_livetalking"&gt;https://www.compshare.cn/images/4458094e-a43d-45fe-9b57-de79253befe4?referral_code=3XW3852OBmnD089hMMrtuU&amp;amp;ytag=GPU_GitHub_livetalking&lt;/a&gt; Áî®ËØ•ÈïúÂÉèÂàõÂª∫ÂÆû‰æãÂç≥ÂèØËøêË°åÊàêÂäü&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Â¶ÇÊûúËÆøÈóÆ‰∏ç‰∫ÜhuggingfaceÔºåÂú®ËøêË°åÂâç&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export HF_ENDPOINT=https://hf-mirror.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. More Usage&lt;/h2&gt; 
&lt;p&gt;‰ΩøÁî®ËØ¥Êòé: &lt;a href="https://livetalking-doc.readthedocs.io/"&gt;https://livetalking-doc.readthedocs.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;4. Docker Run&lt;/h2&gt; 
&lt;p&gt;‰∏çÈúÄË¶ÅÂâçÈù¢ÁöÑÂÆâË£ÖÔºåÁõ¥Êé•ËøêË°å„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run --gpus all -it --network=host --rm registry.cn-zhangjiakou.aliyuncs.com/codewithgpu3/lipku-livetalking:toza2irpHZ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‰ª£Á†ÅÂú®/root/livetalkingÔºåÂÖàgit pullÊãâ‰∏Ä‰∏ãÊúÄÊñ∞‰ª£Á†ÅÔºåÁÑ∂ÂêéÊâßË°åÂëΩ‰ª§ÂêåÁ¨¨2„ÄÅ3Ê≠•&lt;/p&gt; 
&lt;p&gt;Êèê‰æõÂ¶Ç‰∏ãÈïúÂÉè&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;autodlÈïúÂÉè: &lt;a href="https://www.codewithgpu.com/i/lipku/livetalking/base"&gt;https://www.codewithgpu.com/i/lipku/livetalking/base&lt;/a&gt;&lt;br /&gt; &lt;a href="https://livetalking-doc.readthedocs.io/en/latest/autodl/README.html"&gt;autodlÊïôÁ®ã&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ucloudÈïúÂÉè: &lt;a href="https://www.compshare.cn/images/4458094e-a43d-45fe-9b57-de79253befe4?referral_code=3XW3852OBmnD089hMMrtuU&amp;amp;ytag=GPU_GitHub_livetalking"&gt;https://www.compshare.cn/images/4458094e-a43d-45fe-9b57-de79253befe4?referral_code=3XW3852OBmnD089hMMrtuU&amp;amp;ytag=GPU_GitHub_livetalking&lt;/a&gt;&lt;br /&gt; ÂèØ‰ª•ÂºÄÊîæ‰ªªÊÑèÁ´ØÂè£Ôºå‰∏çÈúÄË¶ÅÂè¶Â§ñÈÉ®ÁΩ≤srsÊúçÂä°.&lt;br /&gt; &lt;a href="https://livetalking-doc.readthedocs.io/en/latest/ucloud/ucloud.html"&gt;ucloudÊïôÁ®ã&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;5. ÊÄßËÉΩ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊÄßËÉΩ‰∏ªË¶ÅË∑ücpuÂíågpuÁõ∏ÂÖ≥ÔºåÊØèË∑ØËßÜÈ¢ëÂéãÁº©ÈúÄË¶ÅÊ∂àËÄócpuÔºåcpuÊÄßËÉΩ‰∏éËßÜÈ¢ëÂàÜËæ®ÁéáÊ≠£Áõ∏ÂÖ≥ÔºõÊØèË∑ØÂè£ÂûãÊé®ÁêÜË∑ügpuÊÄßËÉΩÁõ∏ÂÖ≥„ÄÇ&lt;/li&gt; 
 &lt;li&gt;‰∏çËØ¥ËØùÊó∂ÁöÑÂπ∂ÂèëÊï∞Ë∑ücpuÁõ∏ÂÖ≥ÔºåÂêåÊó∂ËØ¥ËØùÁöÑÂπ∂ÂèëÊï∞Ë∑ügpuÁõ∏ÂÖ≥„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂêéÁ´ØÊó•ÂøóinferfpsË°®Á§∫ÊòæÂç°Êé®ÁêÜÂ∏ßÁéáÔºåfinalfpsË°®Á§∫ÊúÄÁªàÊé®ÊµÅÂ∏ßÁéá„ÄÇ‰∏§ËÄÖÈÉΩË¶ÅÂú®25‰ª•‰∏äÊâçËÉΩÂÆûÊó∂„ÄÇÂ¶ÇÊûúinferfpsÂú®25‰ª•‰∏äÔºåfinalfpsËææ‰∏çÂà∞25Ë°®Á§∫cpuÊÄßËÉΩ‰∏çË∂≥„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂÆûÊó∂Êé®ÁêÜÊÄßËÉΩ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Ê®°Âûã&lt;/th&gt; 
   &lt;th align="left"&gt;ÊòæÂç°ÂûãÂè∑&lt;/th&gt; 
   &lt;th align="left"&gt;fps&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;wav2lip256&lt;/td&gt; 
   &lt;td align="left"&gt;3060&lt;/td&gt; 
   &lt;td align="left"&gt;60&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;wav2lip256&lt;/td&gt; 
   &lt;td align="left"&gt;3080Ti&lt;/td&gt; 
   &lt;td align="left"&gt;120&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;musetalk&lt;/td&gt; 
   &lt;td align="left"&gt;3080Ti&lt;/td&gt; 
   &lt;td align="left"&gt;42&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;musetalk&lt;/td&gt; 
   &lt;td align="left"&gt;3090&lt;/td&gt; 
   &lt;td align="left"&gt;45&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;musetalk&lt;/td&gt; 
   &lt;td align="left"&gt;4090&lt;/td&gt; 
   &lt;td align="left"&gt;72&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;wav2lip256ÊòæÂç°3060‰ª•‰∏äÂç≥ÂèØÔºåmusetalkÈúÄË¶Å3080Ti‰ª•‰∏ä„ÄÇ&lt;/p&gt; 
&lt;h2&gt;6. ÂïÜ‰∏öÁâà&lt;/h2&gt; 
&lt;p&gt;Êèê‰æõÂ¶Ç‰∏ãÊâ©Â±ïÂäüËÉΩÔºåÈÄÇÁî®‰∫éÂØπÂºÄÊ∫êÈ°πÁõÆÂ∑≤ÁªèÊØîËæÉÁÜüÊÇâÔºåÈúÄË¶ÅÊâ©Â±ï‰∫ßÂìÅÂäüËÉΩÁöÑÁî®Êà∑&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;È´òÊ∏Öwav2lipÊ®°Âûã&lt;/li&gt; 
 &lt;li&gt;ÂÆåÂÖ®ËØ≠Èü≥‰∫§‰∫íÔºåÊï∞Â≠ó‰∫∫ÂõûÁ≠îËøáÁ®ã‰∏≠ÊîØÊåÅÈÄöËøáÂî§ÈÜíËØçÊàñËÄÖÊåâÈíÆÊâìÊñ≠ÊèêÈóÆ&lt;/li&gt; 
 &lt;li&gt;ÂÆûÊó∂ÂêåÊ≠•Â≠óÂπïÔºåÁªôÂâçÁ´ØÊèê‰æõÊï∞Â≠ó‰∫∫ÊØèÂè•ËØùÊí≠Êä•ÂºÄÂßã„ÄÅÁªìÊùü‰∫ã‰ª∂&lt;/li&gt; 
 &lt;li&gt;ÊØè‰∏™ËøûÊé•ÂèØ‰ª•ÊåáÂÆöÂØπÂ∫îavatarÂíåÈü≥Ëâ≤ÔºåavatarÂõæÁâáÂä†ËΩΩÂä†ÈÄü&lt;/li&gt; 
 &lt;li&gt;Âä®‰ΩúÁºñÊéíÔºö‰∏çËØ¥ËØùÊó∂Âä®‰Ωú„ÄÅÂî§ÈÜíÊó∂Âä®‰Ωú„ÄÅÊÄùËÄÉÊó∂Âä®‰Ωú&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅ‰∏çÈôêÊó∂ÈïøÁöÑÊï∞Â≠ó‰∫∫ÂΩ¢Ë±°avatar&lt;/li&gt; 
 &lt;li&gt;Êèê‰æõÂÆûÊó∂Èü≥È¢ëÊµÅËæìÂÖ•Êé•Âè£&lt;/li&gt; 
 &lt;li&gt;Êï∞Â≠ó‰∫∫ÈÄèÊòéËÉåÊôØÔºåÂè†Âä†Âä®ÊÄÅËÉåÊôØ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Êõ¥Â§öËØ¶ÊÉÖ&lt;a href="https://livetalking-doc.readthedocs.io/zh-cn/latest/service.html#wav2lip"&gt;https://livetalking-doc.readthedocs.io/zh-cn/latest/service.html#wav2lip&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Â£∞Êòé&lt;/h2&gt; 
&lt;p&gt;Âü∫‰∫éÊú¨È°πÁõÆÂºÄÂèëÂπ∂ÂèëÂ∏ÉÂú®BÁ´ô„ÄÅËßÜÈ¢ëÂè∑„ÄÅÊäñÈü≥Á≠âÁΩëÁ´ô‰∏äÁöÑËßÜÈ¢ëÈúÄÂ∏¶‰∏äLiveTalkingÊ∞¥Âç∞ÂíåÊ†áËØÜÔºåÂ¶ÇÈúÄÂéªÈô§ËØ∑ËÅîÁ≥ª‰ΩúËÄÖÂ§áÊ°àÊéàÊùÉ„ÄÇ&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Â¶ÇÊûúÊú¨È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåÂ∏ÆÂøôÁÇπ‰∏™star„ÄÇ‰πüÊ¨¢ËøéÊÑüÂÖ¥Ë∂£ÁöÑÊúãÂèã‰∏ÄËµ∑Êù•ÂÆåÂñÑËØ•È°πÁõÆ.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Áü•ËØÜÊòüÁêÉ: &lt;a href="https://t.zsxq.com/7NMyO"&gt;https://t.zsxq.com/7NMyO&lt;/a&gt; Ê≤âÊ∑ÄÈ´òË¥®ÈáèÂ∏∏ËßÅÈóÆÈ¢ò„ÄÅÊúÄ‰Ω≥ÂÆûË∑µÁªèÈ™å„ÄÅÈóÆÈ¢òËß£Á≠î&lt;/li&gt; 
 &lt;li&gt;ÂæÆ‰ø°ÂÖ¨‰ºóÂè∑ÔºöÊï∞Â≠ó‰∫∫ÊäÄÊúØ&lt;br /&gt; &lt;img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/l3ZibgueFiaeyfaiaLZGuMGQXnhLWxibpJUS2gfs8Dje6JuMY8zu2tVyU9n8Zx1yaNncvKHBMibX0ocehoITy5qQEZg/640?wxfrom=12&amp;amp;tp=wxpic&amp;amp;usePicPrefetch=1&amp;amp;wx_fmt=jpeg&amp;amp;from=appmsg" alt="" /&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>tadata-org/fastapi_mcp</title>
      <link>https://github.com/tadata-org/fastapi_mcp</link>
      <description>&lt;p&gt;Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;a href="https://github.com/tadata-org/fastapi_mcp"&gt;&lt;img src="https://github.com/user-attachments/assets/7e44e98b-a0ba-4aff-a68a-4ffee3a6189c" alt="fastapi-to-mcp" height="100/" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;span style="font-size: 0.85em; font-weight: normal;"&gt;Built by &lt;a href="https://tadata.com"&gt;Tadata&lt;/a&gt;&lt;/span&gt; 
&lt;/div&gt; 
&lt;h1 align="center"&gt; FastAPI-MCP &lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/14064" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14064" alt="tadata-org%2Ffastapi_mcp | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt;Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/fastapi-mcp/"&gt;&lt;img src="https://img.shields.io/pypi/v/fastapi-mcp?color=%2334D058&amp;amp;label=pypi%20package" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/fastapi-mcp/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/fastapi-mcp.svg?sanitize=true" alt="Python Versions" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/tadata-org/fastapi_mcp/main/#"&gt;&lt;img src="https://img.shields.io/badge/FastAPI-009485.svg?logo=fastapi&amp;amp;logoColor=white" alt="FastAPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tadata-org/fastapi_mcp/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/tadata-org/fastapi_mcp/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/tadata-org/fastapi_mcp"&gt;&lt;img src="https://codecov.io/gh/tadata-org/fastapi_mcp/branch/main/graph/badge.svg?sanitize=true" alt="Coverage" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt;&lt;a href="https://github.com/tadata-org/fastapi_mcp"&gt;&lt;img src="https://github.com/user-attachments/assets/b205adc6-28c0-4e3c-a68b-9c1a80eb7d0c" alt="fastapi-mcp-usage" height="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Authentication&lt;/strong&gt; built in, using your existing FastAPI dependencies!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;FastAPI-native:&lt;/strong&gt; Not just another OpenAPI -&amp;gt; MCP converter&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Zero/Minimal configuration&lt;/strong&gt; required - just point it at your FastAPI app and it works&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preserving schemas&lt;/strong&gt; of your request models and response models&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Preserve documentation&lt;/strong&gt; of all your endpoints, just as it is in Swagger&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flexible deployment&lt;/strong&gt; - Mount your MCP server to the same app, or deploy separately&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ASGI transport&lt;/strong&gt; - Uses FastAPI's ASGI interface directly for efficient communication&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hosted Solution&lt;/h2&gt; 
&lt;p&gt;If you prefer a managed hosted solution check out &lt;a href="https://tadata.com"&gt;tadata.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;We recommend using &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt;, a fast Python package installer:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add fastapi-mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can install with pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install fastapi-mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Basic Usage&lt;/h2&gt; 
&lt;p&gt;The simplest way to use FastAPI-MCP is to add an MCP server directly to your FastAPI application:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from fastapi import FastAPI
from fastapi_mcp import FastApiMCP

app = FastAPI()

mcp = FastApiMCP(app)

# Mount the MCP server directly to your FastAPI app
mcp.mount()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That's it! Your auto-generated MCP server is now available at &lt;code&gt;https://app.base.url/mcp&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation, Examples and Advanced Usage&lt;/h2&gt; 
&lt;p&gt;FastAPI-MCP provides &lt;a href="https://fastapi-mcp.tadata.com/"&gt;comprehensive documentation&lt;/a&gt;. Additionaly, check out the &lt;a href="https://raw.githubusercontent.com/tadata-org/fastapi_mcp/main/examples"&gt;examples directory&lt;/a&gt; for code samples demonstrating these features in action.&lt;/p&gt; 
&lt;h2&gt;FastAPI-first Approach&lt;/h2&gt; 
&lt;p&gt;FastAPI-MCP is designed as a native extension of FastAPI, not just a converter that generates MCP tools from your API. This approach offers several key advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Native dependencies&lt;/strong&gt;: Secure your MCP endpoints using familiar FastAPI &lt;code&gt;Depends()&lt;/code&gt; for authentication and authorization&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ASGI transport&lt;/strong&gt;: Communicates directly with your FastAPI app using its ASGI interface, eliminating the need for HTTP calls from the MCP to your API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unified infrastructure&lt;/strong&gt;: Your FastAPI app doesn't need to run separately from the MCP server (though &lt;a href="https://fastapi-mcp.tadata.com/advanced/deploy#deploying-separately-from-original-fastapi-app"&gt;separate deployment&lt;/a&gt; is also supported)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This design philosophy ensures minimum friction when adding MCP capabilities to your existing FastAPI services.&lt;/p&gt; 
&lt;h2&gt;Development and Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for considering contributing to FastAPI-MCP! We encourage the community to post Issues and create Pull Requests.&lt;/p&gt; 
&lt;p&gt;Before you get started, please see our &lt;a href="https://raw.githubusercontent.com/tadata-org/fastapi_mcp/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join &lt;a href="https://join.slack.com/t/themcparty/shared_invite/zt-30yxr1zdi-2FG~XjBA0xIgYSYuKe7~Xg"&gt;MCParty Slack community&lt;/a&gt; to connect with other MCP enthusiasts, ask questions, and share your experiences with FastAPI-MCP.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10+ (Recommended 3.12)&lt;/li&gt; 
 &lt;li&gt;uv&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License. Copyright (c) 2025 Tadata Inc.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>instaloader/instaloader</title>
      <link>https://github.com/instaloader/instaloader</link>
      <description>&lt;p&gt;Download pictures (or videos) along with their captions and other metadata from Instagram.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. image:: &lt;a href="https://raw.githubusercontent.com/instaloader/instaloader/master/docs/logo_heading.png"&gt;https://raw.githubusercontent.com/instaloader/instaloader/master/docs/logo_heading.png&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. badges-start&lt;/p&gt; 
&lt;p&gt;|pypi| |pyversion| |license| |aur| |contributors| |downloads|&lt;/p&gt; 
&lt;p&gt;.. |pypi| image:: &lt;a href="https://img.shields.io/pypi/v/instaloader.svg"&gt;https://img.shields.io/pypi/v/instaloader.svg&lt;/a&gt; :alt: Instaloader PyPI Project Page :target: &lt;a href="https://pypi.org/project/instaloader/"&gt;https://pypi.org/project/instaloader/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |license| image:: &lt;a href="https://img.shields.io/github/license/instaloader/instaloader.svg"&gt;https://img.shields.io/github/license/instaloader/instaloader.svg&lt;/a&gt; :alt: MIT License :target: &lt;a href="https://github.com/instaloader/instaloader/raw/master/LICENSE"&gt;https://github.com/instaloader/instaloader/blob/master/LICENSE&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |pyversion| image:: &lt;a href="https://img.shields.io/pypi/pyversions/instaloader.svg"&gt;https://img.shields.io/pypi/pyversions/instaloader.svg&lt;/a&gt; :alt: Supported Python Versions&lt;/p&gt; 
&lt;p&gt;.. |contributors| image:: &lt;a href="https://img.shields.io/github/contributors/instaloader/instaloader.svg"&gt;https://img.shields.io/github/contributors/instaloader/instaloader.svg&lt;/a&gt; :alt: Contributor Count :target: &lt;a href="https://github.com/instaloader/instaloader/graphs/contributors"&gt;https://github.com/instaloader/instaloader/graphs/contributors&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |aur| image:: &lt;a href="https://img.shields.io/aur/version/instaloader.svg"&gt;https://img.shields.io/aur/version/instaloader.svg&lt;/a&gt; :alt: Arch User Repository Package :target: &lt;a href="https://aur.archlinux.org/packages/instaloader/"&gt;https://aur.archlinux.org/packages/instaloader/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |downloads| image:: &lt;a href="https://pepy.tech/badge/instaloader/month"&gt;https://pepy.tech/badge/instaloader/month&lt;/a&gt; :alt: PyPI Download Count :target: &lt;a href="https://pepy.tech/project/instaloader"&gt;https://pepy.tech/project/instaloader&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. badges-end&lt;/p&gt; 
&lt;p&gt;::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ pip3 install instaloader

$ instaloader profile [profile ...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Instaloader&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;downloads &lt;strong&gt;public and private profiles, hashtags, user stories, feeds and saved media&lt;/strong&gt;,&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;downloads &lt;strong&gt;comments, geotags and captions&lt;/strong&gt; of each post,&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;automatically &lt;strong&gt;detects profile name changes&lt;/strong&gt; and renames the target directory accordingly,&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;allows &lt;strong&gt;fine-grained customization&lt;/strong&gt; of filters and where to store downloaded media,&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;automatically &lt;strong&gt;resumes previously-interrupted&lt;/strong&gt; download iterations.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;instaloader [--comments] [--geotags]
            [--stories] [--highlights] [--tagged] [--reels] [--igtv]
            [--login YOUR-USERNAME] [--fast-update]
            profile | "#hashtag" | :stories | :feed | :saved
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;Instaloader Documentation &amp;lt;https://instaloader.github.io/&amp;gt;&lt;/code&gt;__&lt;/p&gt; 
&lt;h2&gt;How to Automatically Download Pictures from Instagram&lt;/h2&gt; 
&lt;p&gt;To &lt;strong&gt;download all pictures and videos of a profile&lt;/strong&gt;, as well as the &lt;strong&gt;profile picture&lt;/strong&gt;, do&lt;/p&gt; 
&lt;p&gt;::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;instaloader profile [profile ...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;where &lt;code&gt;profile&lt;/code&gt; is the name of a profile you want to download. Instead of only one profile, you may also specify a list of profiles.&lt;/p&gt; 
&lt;p&gt;To later &lt;strong&gt;update your local copy&lt;/strong&gt; of that profiles, you may run&lt;/p&gt; 
&lt;p&gt;::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;instaloader --fast-update profile [profile ...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If &lt;code&gt;--fast-update&lt;/code&gt; is given, Instaloader stops when arriving at the first already-downloaded picture.&lt;/p&gt; 
&lt;p&gt;Alternatively, you can use &lt;code&gt;--latest-stamps&lt;/code&gt; to have Instaloader store the time each profile was last downloaded and only download newer media:&lt;/p&gt; 
&lt;p&gt;::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;instaloader --latest-stamps -- profile [profile ...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With this option it's possible to move or delete downloaded media and still keep the archive updated.&lt;/p&gt; 
&lt;p&gt;When updating profiles, Instaloader automatically &lt;strong&gt;detects profile name changes&lt;/strong&gt; and renames the target directory accordingly.&lt;/p&gt; 
&lt;p&gt;Instaloader can also be used to &lt;strong&gt;download private profiles&lt;/strong&gt;. To do so, invoke it with&lt;/p&gt; 
&lt;p&gt;::&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;instaloader --login=your_username profile [profile ...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When logging in, Instaloader &lt;strong&gt;stores the session cookies&lt;/strong&gt; in a file in your temporary directory, which will be reused later the next time &lt;code&gt;--login&lt;/code&gt; is given. So you can download private profiles &lt;strong&gt;non-interactively&lt;/strong&gt; when you already have a valid session cookie file.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;Instaloader Documentation &amp;lt;https://instaloader.github.io/basic-usage.html&amp;gt;&lt;/code&gt;__&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;As an open source project, Instaloader heavily depends on the contributions from its community. See &lt;code&gt;contributing &amp;lt;https://instaloader.github.io/contributing.html&amp;gt;&lt;/code&gt;__ for how you may help Instaloader to become an even greater tool.&lt;/p&gt; 
&lt;h2&gt;Supporters&lt;/h2&gt; 
&lt;p&gt;.. current-sponsors-start&lt;/p&gt; 
&lt;p&gt;| Instaloader is proudly sponsored by | &lt;code&gt;@rocketapi-io &amp;lt;https://github.com/rocketapi-io&amp;gt;&lt;/code&gt;__&lt;/p&gt; 
&lt;p&gt;See &lt;code&gt;Alex' GitHub Sponsors &amp;lt;https://github.com/sponsors/aandergr&amp;gt;&lt;/code&gt;__ page for how you can sponsor the development of Instaloader!&lt;/p&gt; 
&lt;p&gt;.. current-sponsors-end&lt;/p&gt; 
&lt;p&gt;It is a pleasure for us to share our Instaloader to the world, and we are proud to have attracted such an active and motivating community, with so many users who share their suggestions and ideas with us. Buying a community-sponsored beer or coffee from time to time is very likely to further raise our passion for the development of Instaloader.&lt;/p&gt; 
&lt;p&gt;| For Donations, we provide GitHub Sponsors page, a PayPal.Me link and a Bitcoin address. | GitHub Sponsors: &lt;code&gt;Sponsor @aandergr on GitHub Sponsors &amp;lt;https://github.com/sponsors/aandergr&amp;gt;&lt;/code&gt;__ | PayPal: &lt;code&gt;PayPal.me/aandergr &amp;lt;https://www.paypal.me/aandergr&amp;gt;&lt;/code&gt;__ | BTC: 1Nst4LoadeYzrKjJ1DX9CpbLXBYE9RKLwY&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;.. disclaimer-start&lt;/p&gt; 
&lt;p&gt;Instaloader is in no way affiliated with, authorized, maintained or endorsed by Instagram or any of its affiliates or subsidiaries. This is an independent and unofficial project. Use at your own risk.&lt;/p&gt; 
&lt;p&gt;Instaloader is licensed under an MIT license. Refer to &lt;code&gt;LICENSE&lt;/code&gt; file for more information.&lt;/p&gt; 
&lt;p&gt;.. disclaimer-end&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lfnovo/open-notebook</title>
      <link>https://github.com/lfnovo/open-notebook</link>
      <description>&lt;p&gt;An Open Source implementation of Notebook LM with more flexibility and features&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a id="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![Contributors][contributors-shield]][contributors-url] --&gt; 
&lt;p&gt;&lt;a href="https://github.com/lfnovo/open-notebook/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/lfnovo/open-notebook.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/lfnovo/open-notebook.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;&lt;img src="https://img.shields.io/github/issues/lfnovo/open-notebook.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/raw/master/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/github/license/lfnovo/open-notebook.svg?style=for-the-badge" alt="MIT License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![LinkedIn][linkedin-shield]][linkedin-url] --&gt; 
&lt;!-- PROJECT LOGO --&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/lfnovo/open-notebook"&gt; &lt;img src="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/hero.svg?sanitize=true" alt="Logo" /&gt; &lt;/a&gt; 
 &lt;h3 align="center"&gt;Open Notebook&lt;/h3&gt; 
 &lt;p align="center"&gt; An open source, privacy-focused alternative to Google's Notebook LM! &lt;br /&gt;&lt;strong&gt;Join our &lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord server&lt;/a&gt; for help, to share workflow ideas, and suggest features!&lt;/strong&gt; &lt;br /&gt; &lt;a href="https://www.open-notebook.ai"&gt;&lt;strong&gt;Checkout our website ¬ª&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/index.md"&gt;üìö Get Started&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/index.md"&gt;üìñ User Guide&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/index.md"&gt;‚ú® Features&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/index.md"&gt;üöÄ Deploy&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üì¢ Open Notebook is under very active development&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Open Notebook is under active development! We're moving fast and making improvements every week. Your feedback is incredibly valuable to me during this exciting phase and it gives me motivation to keep improving and building this amazing tool. Please feel free to star the project if you find it useful, and don't hesitate to reach out with any questions or suggestions. I'm excited to see how you'll use it and what ideas you'll bring to the project! Let's build something amazing together! üöÄ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;About The Project&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/asset_list.png" alt="New Notebook" /&gt;&lt;/p&gt; 
&lt;p&gt;An open source, privacy-focused alternative to Google's Notebook LM. Why give Google more of our data when we can take control of our own research workflows?&lt;/p&gt; 
&lt;p&gt;In a world dominated by Artificial Intelligence, having the ability to think üß† and acquire new knowledge üí°, is a skill that should not be a privilege for a few, nor restricted to a single provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Open Notebook empowers you to:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîí &lt;strong&gt;Control your data&lt;/strong&gt; - Keep your research private and secure&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Choose your AI models&lt;/strong&gt; - Support for 16+ providers including OpenAI, Anthropic, Ollama, LM Studio, and more&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Organize multi-modal content&lt;/strong&gt; - PDFs, videos, audio, web pages, and more&lt;/li&gt; 
 &lt;li&gt;üéôÔ∏è &lt;strong&gt;Generate professional podcasts&lt;/strong&gt; - Advanced multi-speaker podcast generation&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Search intelligently&lt;/strong&gt; - Full-text and vector search across all your content&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;strong&gt;Chat with context&lt;/strong&gt; - AI conversations powered by your research&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Learn more about our project at &lt;a href="https://www.open-notebook.ai"&gt;https://www.open-notebook.ai&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üÜö Open Notebook vs Google Notebook LM&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Open Notebook&lt;/th&gt; 
   &lt;th&gt;Google Notebook LM&lt;/th&gt; 
   &lt;th&gt;Advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Privacy &amp;amp; Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Self-hosted, your data&lt;/td&gt; 
   &lt;td&gt;Google cloud only&lt;/td&gt; 
   &lt;td&gt;Complete data sovereignty&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI Provider Choice&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;16+ providers (OpenAI, Anthropic, Ollama, LM Studio, etc.)&lt;/td&gt; 
   &lt;td&gt;Google models only&lt;/td&gt; 
   &lt;td&gt;Flexibility and cost optimization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Podcast Speakers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1-4 speakers with custom profiles&lt;/td&gt; 
   &lt;td&gt;2 speakers only&lt;/td&gt; 
   &lt;td&gt;Extreme flexibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Context Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;3 granular levels&lt;/td&gt; 
   &lt;td&gt;All-or-nothing&lt;/td&gt; 
   &lt;td&gt;Privacy and performance tuning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Content Transformations&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Custom and built-in&lt;/td&gt; 
   &lt;td&gt;Limited options&lt;/td&gt; 
   &lt;td&gt;Unlimited processing power&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Access&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Full REST API&lt;/td&gt; 
   &lt;td&gt;No API&lt;/td&gt; 
   &lt;td&gt;Complete automation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Deployment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Docker, cloud, or local&lt;/td&gt; 
   &lt;td&gt;Google hosted only&lt;/td&gt; 
   &lt;td&gt;Deploy anywhere&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Citations&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Comprehensive with sources&lt;/td&gt; 
   &lt;td&gt;Basic references&lt;/td&gt; 
   &lt;td&gt;Research integrity&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Open source, fully customizable&lt;/td&gt; 
   &lt;td&gt;Closed system&lt;/td&gt; 
   &lt;td&gt;Unlimited extensibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Pay only for AI usage&lt;/td&gt; 
   &lt;td&gt;Monthly subscription + usage&lt;/td&gt; 
   &lt;td&gt;Transparent and controllable&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Why Choose Open Notebook?&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîí &lt;strong&gt;Privacy First&lt;/strong&gt;: Your sensitive research stays completely private&lt;/li&gt; 
 &lt;li&gt;üí∞ &lt;strong&gt;Cost Control&lt;/strong&gt;: Choose cheaper AI providers or run locally with Ollama&lt;/li&gt; 
 &lt;li&gt;üéôÔ∏è &lt;strong&gt;Better Podcasts&lt;/strong&gt;: Full script control and multi-speaker flexibility vs limited 2-speaker deep-dive format&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Unlimited Customization&lt;/strong&gt;: Modify, extend, and integrate as needed&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;No Vendor Lock-in&lt;/strong&gt;: Switch providers, deploy anywhere, own your data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Built With&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://surrealdb.com/"&gt;&lt;img src="https://img.shields.io/badge/SurrealDB-FF5E00?style=for-the-badge&amp;amp;logo=databricks&amp;amp;logoColor=white" alt="SurrealDB" /&gt;&lt;/a&gt; &lt;a href="https://www.langchain.com/"&gt;&lt;img src="https://img.shields.io/badge/LangChain-3A3A3A?style=for-the-badge&amp;amp;logo=chainlink&amp;amp;logoColor=white" alt="LangChain" /&gt;&lt;/a&gt; &lt;a href="https://streamlit.io/"&gt;&lt;img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Streamlit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;p&gt;Ready to try Open Notebook? Choose your preferred method:&lt;/p&gt; 
&lt;h3&gt;‚ö° Instant Setup (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a new directory for your Open Notebook installation
mkdir open-notebook
cd open-notebook

# Using Docker - Get started in 2 minutes
docker run -d \
  --name open-notebook \
  -p 8502:8502 -p 5055:5055 \
  -v ./notebook_data:/app/data \
  -v ./surreal_data:/mydata \
  -e OPENAI_API_KEY=your_key \
  lfnovo/open_notebook:latest-single
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What gets created:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;open-notebook/
‚îú‚îÄ‚îÄ notebook_data/     # Your notebooks and research content
‚îî‚îÄ‚îÄ surreal_data/      # Database files
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Access your installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üñ•Ô∏è Main Interface&lt;/strong&gt;: &lt;a href="http://localhost:8502"&gt;http://localhost:8502&lt;/a&gt; (Streamlit UI)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß API Access&lt;/strong&gt;: &lt;a href="http://localhost:5055"&gt;http://localhost:5055&lt;/a&gt; (REST API)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö API Documentation&lt;/strong&gt;: &lt;a href="http://localhost:5055/docs"&gt;http://localhost:5055/docs&lt;/a&gt; (Interactive Swagger UI)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Important&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Run from a dedicated folder&lt;/strong&gt;: Create and run this from inside a new &lt;code&gt;open-notebook&lt;/code&gt; folder so your data volumes are properly organized&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Volume persistence&lt;/strong&gt;: The volumes (&lt;code&gt;-v ./notebook_data:/app/data&lt;/code&gt; and &lt;code&gt;-v ./surreal_data:/mydata&lt;/code&gt;) are essential to persist your data between container restarts. Without them, you'll lose all your notebooks and research when the container stops.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üõ†Ô∏è Full Installation&lt;/h3&gt; 
&lt;p&gt;For development or customization:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/lfnovo/open-notebook
cd open-notebook
make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üìñ Need Help?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ AI Installation Assistant&lt;/strong&gt;: We have a &lt;a href="https://chatgpt.com/g/g-68776e2765b48191bd1bae3f30212631-open-notebook-installation-assistant"&gt;CustomGPT built to help you install Open Notebook&lt;/a&gt; - it will guide you through each step!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;New to Open Notebook?&lt;/strong&gt; Start with our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/index.md"&gt;Getting Started Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Need installation help?&lt;/strong&gt; Check our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/installation.md"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Want to see it in action?&lt;/strong&gt; Try our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/quick-start.md"&gt;Quick Start Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Provider Support Matrix&lt;/h2&gt; 
&lt;p&gt;Thanks to the &lt;a href="https://github.com/lfnovo/esperanto"&gt;Esperanto&lt;/a&gt; library, we support this providers out of the box!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;LLM Support&lt;/th&gt; 
   &lt;th&gt;Embedding Support&lt;/th&gt; 
   &lt;th&gt;Speech-to-Text&lt;/th&gt; 
   &lt;th&gt;Text-to-Speech&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Groq&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google (GenAI)&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vertex AI&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Perplexity&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ElevenLabs&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure OpenAI&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mistral&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Voyage&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xAI&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI Compatible*&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Supports LM Studio and any OpenAI-compatible endpoint&lt;/p&gt; 
&lt;h2&gt;‚ú® Key Features&lt;/h2&gt; 
&lt;h3&gt;Core Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Privacy-First&lt;/strong&gt;: Your data stays under your control - no cloud dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ Multi-Notebook Organization&lt;/strong&gt;: Manage multiple research projects seamlessly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Universal Content Support&lt;/strong&gt;: PDFs, videos, audio, web pages, Office docs, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Multi-Model AI Support&lt;/strong&gt;: 16+ providers including OpenAI, Anthropic, Ollama, Google, LM Studio, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéôÔ∏è Professional Podcast Generation&lt;/strong&gt;: Advanced multi-speaker podcasts with Episode Profiles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Intelligent Search&lt;/strong&gt;: Full-text and vector search across all your content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üí¨ Context-Aware Chat&lt;/strong&gt;: AI conversations powered by your research materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìù AI-Assisted Notes&lt;/strong&gt;: Generate insights or write notes manually&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Reasoning Model Support&lt;/strong&gt;: Full support for thinking models like DeepSeek-R1 and Qwen3&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Content Transformations&lt;/strong&gt;: Powerful customizable actions to summarize and extract insights&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Comprehensive REST API&lt;/strong&gt;: Full programmatic access for custom integrations &lt;a href="http://localhost:5055/docs"&gt;&lt;img src="https://img.shields.io/badge/API-Documentation-blue?style=flat-square" alt="API Docs" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîê Optional Password Protection&lt;/strong&gt;: Secure public deployments with authentication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä Fine-Grained Context Control&lt;/strong&gt;: Choose exactly what to share with AI models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìé Citations&lt;/strong&gt;: Get answers with proper source citations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Three-Column Interface&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Sources&lt;/strong&gt;: Manage all your research materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Notes&lt;/strong&gt;: Create manual or AI-generated notes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chat&lt;/strong&gt;: Converse with AI using your content as context&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=D-760MlGwaI"&gt;&lt;img src="https://img.youtube.com/vi/D-760MlGwaI/0.jpg" alt="Check out our podcast sample" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/introduction.md"&gt;üìñ Introduction&lt;/a&gt;&lt;/strong&gt; - Learn what Open Notebook offers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/quick-start.md"&gt;‚ö° Quick Start&lt;/a&gt;&lt;/strong&gt; - Get up and running in 5 minutes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/installation.md"&gt;üîß Installation&lt;/a&gt;&lt;/strong&gt; - Comprehensive setup guide&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/first-notebook.md"&gt;üéØ Your First Notebook&lt;/a&gt;&lt;/strong&gt; - Step-by-step tutorial&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Guide&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/interface-overview.md"&gt;üì± Interface Overview&lt;/a&gt;&lt;/strong&gt; - Understanding the layout&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/notebooks.md"&gt;üìö Notebooks&lt;/a&gt;&lt;/strong&gt; - Organizing your research&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/sources.md"&gt;üìÑ Sources&lt;/a&gt;&lt;/strong&gt; - Managing content types&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/notes.md"&gt;üìù Notes&lt;/a&gt;&lt;/strong&gt; - Creating and managing notes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/chat.md"&gt;üí¨ Chat&lt;/a&gt;&lt;/strong&gt; - AI conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/search.md"&gt;üîç Search&lt;/a&gt;&lt;/strong&gt; - Finding information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Topics&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/podcasts.md"&gt;üéôÔ∏è Podcast Generation&lt;/a&gt;&lt;/strong&gt; - Create professional podcasts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/transformations.md"&gt;üîß Content Transformations&lt;/a&gt;&lt;/strong&gt; - Customize content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/ai-models.md"&gt;ü§ñ AI Models&lt;/a&gt;&lt;/strong&gt; - AI model configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/development/api-reference.md"&gt;üîß REST API Reference&lt;/a&gt;&lt;/strong&gt; - Complete API documentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/security.md"&gt;üîê Security&lt;/a&gt;&lt;/strong&gt; - Password protection and privacy&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/index.md"&gt;üöÄ Deployment&lt;/a&gt;&lt;/strong&gt; - Complete deployment guides for all scenarios&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;üó∫Ô∏è Roadmap&lt;/h2&gt; 
&lt;h3&gt;Upcoming Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;React Frontend&lt;/strong&gt;: Modern React-based frontend to replace Streamlit&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live Front-End Updates&lt;/strong&gt;: Real-time UI updates for smoother experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Async Processing&lt;/strong&gt;: Faster UI through asynchronous content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Notebook Sources&lt;/strong&gt;: Reuse research materials across projects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bookmark Integration&lt;/strong&gt;: Connect with your favorite bookmarking apps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Recently Completed ‚úÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive REST API&lt;/strong&gt;: Full programmatic access to all functionality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Model Support&lt;/strong&gt;: 16+ AI providers including OpenAI, Anthropic, Ollama, LM Studio&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Podcast Generator&lt;/strong&gt;: Professional multi-speaker podcasts with Episode Profiles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content Transformations&lt;/strong&gt;: Powerful customizable actions for content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Citations&lt;/strong&gt;: Improved layout and finer control for source citations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Chat Sessions&lt;/strong&gt;: Manage different conversations within notebooks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;open issues&lt;/a&gt; for a full list of proposed features and known issues.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;ü§ù Community &amp;amp; Contributing&lt;/h2&gt; 
&lt;h3&gt;Join the Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí¨ &lt;strong&gt;&lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord Server&lt;/a&gt;&lt;/strong&gt; - Get help, share ideas, and connect with other users&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;&lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Report bugs and request features&lt;/li&gt; 
 &lt;li&gt;‚≠ê &lt;strong&gt;Star this repo&lt;/strong&gt; - Show your support and help others discover Open Notebook&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome contributions! We're especially looking for help with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend Development&lt;/strong&gt;: Help build a modern React-based UI (planned replacement for current Streamlit interface)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing &amp;amp; Bug Fixes&lt;/strong&gt;: Make Open Notebook more robust&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Development&lt;/strong&gt;: Build the coolest research tool together&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Improve guides and tutorials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Current Tech Stack&lt;/strong&gt;: Python, FastAPI, SurrealDB, Streamlit&lt;br /&gt; &lt;strong&gt;Future Roadmap&lt;/strong&gt;: React frontend, enhanced real-time updates&lt;/p&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for detailed information on how to get started.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;Open Notebook is MIT licensed. See the &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;üìû Contact&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Luis Novo&lt;/strong&gt; - &lt;a href="https://twitter.com/lfnovo"&gt;@lfnovo&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Community Support&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord Server&lt;/a&gt; - Get help, share ideas, and connect with users&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;GitHub Issues&lt;/a&gt; - Report bugs and request features&lt;/li&gt; 
 &lt;li&gt;üåê &lt;a href="https://www.open-notebook.ai"&gt;Website&lt;/a&gt; - Learn more about the project&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Open Notebook is built on the shoulders of amazing open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/podcast-creator"&gt;Podcast Creator&lt;/a&gt;&lt;/strong&gt; - Advanced podcast generation capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/surreal-commands"&gt;Surreal Commands&lt;/a&gt;&lt;/strong&gt; - Background job processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/content-core"&gt;Content Core&lt;/a&gt;&lt;/strong&gt; - Content processing and management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/esperanto"&gt;Esperanto&lt;/a&gt;&lt;/strong&gt; - Multi-provider AI model abstraction&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/docling-project/docling"&gt;Docling&lt;/a&gt;&lt;/strong&gt; - Document processing and parsing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>gyoridavid/ai_agents_az</title>
      <link>https://github.com/gyoridavid/ai_agents_az</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Agents A-Z&lt;/h1&gt; 
&lt;p&gt;In this repo, you can find the n8n templates we created for the episodes of &lt;a href="https://www.youtube.com/channel/UCloXqLhp_KGhHBe1kwaL2Tg"&gt;AI Agents A-Z&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://www.skool.com/ai-agents-az/about"&gt;üìö Join our Skool community for support, premium content and more!&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Be part of a growing community and help us create more content&lt;/h3&gt; 
&lt;h2&gt;Season 1&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_1"&gt;Episode 1: Creating a prescription agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_2"&gt;Episode 2: Making a daily digest agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_3"&gt;Episode 3: Making LinkedIn posts using Human in the Loop approval process&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_4"&gt;Episode 4: Deep Research Agent using Google&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_5"&gt;Episode 5: Creating a blog writing system using deep research&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_6"&gt;Episode 6: Lead generation with X-Ray search and LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_7"&gt;Episode 7: Creating Youtube short videos using our custom MCP server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_8"&gt;Episode 8: Creating an AI influencer on Instagram using n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_9"&gt;Episode 9: Create revenge story videos for YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_10"&gt;Episode 10: n8n best practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_11"&gt;Episode 11: Create short (motivational) stories for YouTube and TikTok&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_12"&gt;Episode 12: Scheduling social media posts with Postiz and n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_13"&gt;Episode 13: Create AI videos with MiniMax Hailuo 2 and n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_14"&gt;Episode 14: Create AI videos with Seedance and n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_15"&gt;Episode 15: Generate AI startup ideas from Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_16"&gt;Episode 16: Create AI poem videos with n8n for TikTok&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_17"&gt;Episode 17: Create Shopify product videos with Seedance, ElevenLabs, Latentsync, Flux Kontext and n8n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_18"&gt;Episode 18: Scary story TikTok videos workflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_19"&gt;Episode 19: Run FLUX.1 Kontext [dev] with modal.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gyoridavid/ai_agents_az/main/episode_20"&gt;Episode 20: Use Wan 2.2, ComfyUI and n8n to generate videos for free&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;servers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/r/gyoridavid/ai-agents-no-code-tools"&gt;AI Agents No-Code Tools&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gyoridavid/short-video-maker"&gt;Short video maker MCP/REST server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/r/gyoridavid/narrated-story-creator"&gt;Narrated story creator REST/MCP server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>LeCAR-Lab/ASAP</title>
      <link>https://github.com/LeCAR-Lab/ASAP</link>
      <description>&lt;p&gt;Official implementation of [RSS 2025] "ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills"&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; ASAP: Aligning Simulation and Real-World Physics for &lt;p&gt;Learning Agile Humanoid Whole-Body Skills &lt;/p&gt;&lt;/h1&gt;
&lt;p&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;Robotics: Science and Systems (RSS) 2025&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://agile.human2humanoid.com/"&gt;[Website]&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2502.01143"&gt;[Arxiv]&lt;/a&gt; &lt;a href="https://www.youtube.com/watch?v=tu7LSNYWDTs&amp;amp;ab_channel=LeCARLabatCMU"&gt;[Video]&lt;/a&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/imgs/CMU-NV-logo-crop-png.png" height="50&amp;quot;" /&gt; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://developer.nvidia.com/isaac-gym"&gt;&lt;img src="https://img.shields.io/badge/IsaacGym-Preview4-b.svg?sanitize=true" alt="IsaacGym" /&gt;&lt;/a&gt; &lt;a href="https://docs.isaacsim.omniverse.nvidia.com/4.2.0/index.html"&gt;&lt;img src="https://img.shields.io/badge/IsaacSim-4.2.0-b.svg?sanitize=true" alt="IsaacSim" /&gt;&lt;/a&gt; &lt;a href="https://docs.isaacsim.omniverse.nvidia.com/4.2.0/index.html"&gt;&lt;img src="https://img.shields.io/badge/Genesis-0.2.1-b.svg?sanitize=true" alt="IsaacSim" /&gt;&lt;/a&gt; &lt;a href="https://ubuntu.com/blog/tag/22-04-lts"&gt;&lt;img src="https://img.shields.io/badge/Platform-linux--64-orange.svg?sanitize=true" alt="Linux platform" /&gt;&lt;/a&gt; &lt;a href=""&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;img src="https://agile.human2humanoid.com/static/images/asap-preview-gif-480P.gif" width="400px" /&gt; 
&lt;/div&gt; 
&lt;!-- # Table of Contents --&gt; 
&lt;h2&gt;üìö Table of Contents&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#overview"&gt;Overview&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Links: &lt;a href="https://agile.human2humanoid.com/"&gt;Website&lt;/a&gt; ‚Ä¢ &lt;a href="https://arxiv.org/pdf/2502.01143"&gt;Arxiv&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.youtube.com/watch?v=tu7LSNYWDTs&amp;amp;ab_channel=LeCARLabatCMU"&gt;Video&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#installation"&gt;Installation &amp;amp; Setup&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt; 2.1 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#isaacgym-conda-env"&gt;Base Frameworks&lt;/a&gt;&lt;br /&gt; 2.2 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#install-isaacgym"&gt;IsaacGym Setup&lt;/a&gt;&lt;br /&gt; 2.3 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#install-humanoidverse"&gt;HumanoidVerse Setup&lt;/a&gt;&lt;br /&gt; 2.4 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#isaaclab-environment"&gt;IsaacSim + IsaacLab Setup&lt;/a&gt;&lt;br /&gt; 2.5 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#genesis-environment"&gt;Genesis Environment Setup&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#motion-tracking-training"&gt;Training Pipelines&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt; 3.1 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#motion-tracking-training"&gt;Phase-Based Motion Tracking&lt;/a&gt;&lt;br /&gt; 3.2 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#asap-delta-action-model-training"&gt;ASAP Delta Action Model&lt;/a&gt;&lt;br /&gt; - &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#train-delta-action-model"&gt;Train Delta Action Model&lt;/a&gt;&lt;br /&gt; - &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#use-delta-action-model-for-policy-finetuning"&gt;Finetune Policy with Delta Action Model&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#motion-retargeting-to-any-humanoid"&gt;Motion Retargeting to Any Humanoid&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt; 4.1 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#1-smpl-shape-preparation"&gt;Step 1: SMPL Shape Preparation&lt;/a&gt;&lt;br /&gt; 4.2 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#2-smpl-motion-preparation-amass"&gt;Step 2: SMPL Motion Preparation (AMASS)&lt;/a&gt;&lt;br /&gt; 4.3 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#3-robot-xml-and-motion-config-preparation"&gt;Step 3: Robot XML &amp;amp; Motion Config&lt;/a&gt;&lt;br /&gt; 4.4 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#4-humanoid-smpl-shape-fitting"&gt;Step 4: Humanoid-SMPL Shape Fitting&lt;/a&gt;&lt;br /&gt; 4.5 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#5-humanoid-smpl-motion-retargeting"&gt;Step 5: Humanoid-SMPL Motion Retargeting&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#sim2simsim2real"&gt;Deployment: Sim2Sim &amp;amp; Sim2Real&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt; 5.1 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#environment-setup"&gt;Environment Setup&lt;/a&gt;&lt;br /&gt; 5.2 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#sim2sim"&gt;Sim2Sim Deployment&lt;/a&gt;&lt;br /&gt; 5.3 &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#sim2real"&gt;Sim2Real Deployment&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#citation"&gt;Citation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/#license"&gt;License&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;TODO&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Release code backbone&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Release phase-based motion tracking training pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Release ASAP motion datasets&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Release motion retargeting pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Release sim2sim in MuJoCo&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Release sim2real with UnitreeSDK&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Release ASAP delta action model training pipeline&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;ASAP codebase is built on top of &lt;a href="https://github.com/LeCAR-Lab/HumanoidVerse"&gt;HumanoidVerse&lt;/a&gt; (a multi-simulator framework for humanoid learning) and &lt;a href="https://github.com/LeCAR-Lab/human2humanoid"&gt;Human2Humanoid&lt;/a&gt; (our prior work on humanoid whole-body tracking).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/LeCAR-Lab/HumanoidVerse"&gt;HumanoidVerse&lt;/a&gt; allows you to train humanoid skills in multiple simulators, including IsaacGym, IsaacSim, and Genesis. Its key design logic is the separation and modularization of simulators, tasks, and algorithms, which enables smooth transfers between different simulators and the real world with minimum effort (just one line of code change). We leverage this framework to develop &lt;a href="https://agile.human2humanoid.com/"&gt;ASAP&lt;/a&gt; and study how to best transfer policies across simulators and the real world.&lt;/p&gt; 
&lt;h2&gt;IsaacGym Conda Env&lt;/h2&gt; 
&lt;p&gt;Create mamba/conda environment, in the following we use conda for example, but you can use mamba as well.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n hvgym python=3.8
conda activate hvgym
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install IsaacGym&lt;/h3&gt; 
&lt;p&gt;Download &lt;a href="https://developer.nvidia.com/isaac-gym/download"&gt;IsaacGym&lt;/a&gt; and extract:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget https://developer.nvidia.com/isaac-gym-preview-4
tar -xvzf isaac-gym-preview-4
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install IsaacGym Python API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e isaacgym/python
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Test installation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python 1080_balls_of_solitude.py  # or
python joint_monkey.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For libpython error:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check conda path: &lt;pre&gt;&lt;code class="language-bash"&gt;conda info -e
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Set LD_LIBRARY_PATH: &lt;pre&gt;&lt;code class="language-bash"&gt;export LD_LIBRARY_PATH=&amp;lt;/path/to/conda/envs/your_env/lib&amp;gt;:$LD_LIBRARY_PATH
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Install HumanoidVerse&lt;/h3&gt; 
&lt;p&gt;Install dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
pip install -e isaac_utils
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Test with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;HYDRA_FULL_ERROR=1 python humanoidverse/train_agent.py \
+simulator=isaacgym \
+exp=locomotion \
+domain_rand=NO_domain_rand \
+rewards=loco/reward_g1_locomotion \
+robot=g1/g1_29dof_anneal_23dof \
+terrain=terrain_locomotion_plane \
+obs=loco/leggedloco_obs_singlestep_withlinvel \
num_envs=1 \
project_name=TestIsaacGymInstallation \
experiment_name=G123dof_loco \
headless=False
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Note:&lt;/summary&gt; This is ONLY for testing, NOT how we train the locomotion policy in the ASAP paper. But still, you can train a locomotion policy by: 
 &lt;pre&gt;&lt;code class="language-bash"&gt;HYDRA_FULL_ERROR=1 python humanoidverse/train_agent.py \
+simulator=isaacgym \
+exp=locomotion \
+domain_rand=NO_domain_rand \
+rewards=loco/reward_g1_locomotion \
+robot=g1/g1_29dof_anneal_23dof \
+terrain=terrain_locomotion_plane \
+obs=loco/leggedloco_obs_singlestep_withlinvel \
num_envs=4096 \
project_name=TestIsaacGymInstallation \
experiment_name=G123dof_loco \
headless=True \
rewards.reward_penalty_curriculum=True \
rewards.reward_initial_penalty_scale=0.1 \
rewards.reward_penalty_degree=0.00003 
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;IsaacLab Environment&lt;/h2&gt; 
&lt;h3&gt;Install IsaacSim&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download Omniverse Launcher&lt;/li&gt; 
 &lt;li&gt;Install Isaac Sim through launcher&lt;/li&gt; 
 &lt;li&gt;Set environment variables:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export ISAACSIM_PATH="${HOME}/.local/share/ov/pkg/isaac-sim-4.2.0"
export ISAACSIM_PYTHON_EXE="${ISAACSIM_PATH}/python.sh"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install IsaacLab&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/isaac-sim/IsaacLab.git
cd IsaacLab &amp;amp;&amp;amp; ./isaaclab.sh --conda hvlab
mamba activate hvlab
sudo apt install cmake build-essential
./isaaclab.sh --install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Setup HumanoidVerse&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
pip install -e isaac_utils
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Genesis Environment&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mamba create -n hvgen python=3.10
mamba activate hvgen
pip install genesis-world torch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e .
pip install -e isaac_utils
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Motion Tracking Training&lt;/h1&gt; 
&lt;p&gt;Train a phase-based motion tracking policy to imitate Cristiano Ronaldo's signature Siuuu move&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python humanoidverse/train_agent.py \
+simulator=isaacgym \
+exp=motion_tracking \
+domain_rand=NO_domain_rand \
+rewards=motion_tracking/reward_motion_tracking_dm_2real \
+robot=g1/g1_29dof_anneal_23dof \
+terrain=terrain_locomotion_plane \
+obs=motion_tracking/deepmimic_a2c_nolinvel_LARGEnoise_history \
num_envs=4096 \
project_name=MotionTracking \
experiment_name=MotionTracking_CR7 \
robot.motion.motion_file="humanoidverse/data/motions/g1_29dof_anneal_23dof/TairanTestbed/singles/0-TairanTestbed_TairanTestbed_CR7_video_CR7_level1_filter_amass.pkl" \
rewards.reward_penalty_curriculum=True \
rewards.reward_penalty_degree=0.00001 \
env.config.resample_motion_when_training=False \
env.config.termination.terminate_when_motion_far=True \
env.config.termination_curriculum.terminate_when_motion_far_curriculum=True \
env.config.termination_curriculum.terminate_when_motion_far_threshold_min=0.3 \
env.config.termination_curriculum.terminate_when_motion_far_curriculum_degree=0.000025 \
robot.asset.self_collisions=0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After training, you can visualize the policy by:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python humanoidverse/eval_agent.py \
+checkpoint=logs/MotionTracking/xxxxxxxx_xxxxxxx-MotionTracking_CR7-motion_tracking-g1_29dof_anneal_23dof/model_5800.pt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is the visualization of the policy after traning 5800 iters. The policy is able to imitate the motion of Cristiano Ronaldo's Siuuu move. With more training, the policy will be more accurate and smooth (see the video in the &lt;a href="https://arxiv.org/pdf/2502.01143"&gt;paper&lt;/a&gt;).&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/imgs/motion_tracking_5800.gif" width="400px" /&gt; 
&lt;h1&gt;ASAP delta action model training&lt;/h1&gt; 
&lt;p&gt;Note that the only difference between the delta action model training and naive motion tracking training is that delta action model needs a motion file with extra keyname &lt;code&gt;"action"&lt;/code&gt; in the motion file, so that the resulting RL policy we are training is able to use the delta action model to &lt;code&gt;"control the robot"&lt;/code&gt; to match the real-world/sim2sim motions.&lt;/p&gt; 
&lt;h2&gt;Train delta action model&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;python humanoidverse/train_agent.py \                                                                                   
  +simulator=isaacgym \
  +exp=train_delta_a_open_loop \
  +domain_rand=NO_domain_rand \
  +rewards=motion_tracking/delta_a/reward_delta_a_openloop \
  +robot=g1/g1_29dof_anneal_23dof \
  +terrain=terrain_locomotion_plane \
  +obs=delta_a/open_loop \
  num_envs=5000 \
  project_name=DeltaA_Training \
  experiment_name=openloopDeltaA_training \
  robot.motion.motion_file="&amp;lt;PATH_TO_YOUR_MOTION_FILE_WITH_ACTION_KEYNAME&amp;gt;" \
  env.config.max_episode_length_s=1.0 \
  rewards.reward_scales.penalty_minimal_action_norm=-0.1 \
  +device=cuda:0 \
  env.config.resample_motion_when_training=True \
  env.config.resample_time_interval_s=10000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Use delta action model for policy finetuning&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;HYDRA_FULL_ERROR=1 \
python humanoidverse/train_agent.py \
+simulator=isaacgym \
+exp=train_delta_a_closed_loop \
algo.config.policy_checkpoint='&amp;lt;PATH_TO_YOUR_DELTA_A_MODEL&amp;gt;' \
+domain_rand=NO_domain_rand_finetune_with_deltaA \
+rewards=motion_tracking/reward_motion_tracking_dm_simfinetuning \
+robot=g1/g1_29dof_anneal_23dof \
+terrain=terrain_locomotion_plane \
+obs=delta_a/train_policy_with_delta_a \
num_envs=4096 \
project_name=DeltaA_Finetune \
experiment_name=finetune_with_deltaA \
robot.motion.motion_file="&amp;lt;PATH_TO_YOUR_MOTION_FILE&amp;gt;" \
+opt=wandb \
env.config.add_extra_action=True \
+checkpoint="&amp;lt;PATH_TO_YOUR_POLICY_TO_BE_FINETUNED&amp;gt;" \
domain_rand.push_robots=False \
env.config.noise_to_initial_level=1 \
rewards.reward_penalty_curriculum=True \
+device=cuda:0 \
algo.config.save_interval=5 \
algo.config.num_learning_iterations=1000 

&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Motion Retargeting to Any Humanoid&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Here we share a generic humanoid motion retargeting pipeline to any humanoid from &lt;a href="https://github.com/ZhengyiLuo/PHC"&gt;PHC&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] We have provided all the SMPL motions (&lt;code&gt;ASAP/humanoidverse/data/motions/raw_tairantestbed_smpl&lt;/code&gt;) and retargtted G1 motions (&lt;code&gt;ASAP/humanoidverse/data/motions/g1_29dof_anneal_23dof/TairanTestbed/singles&lt;/code&gt;) used in the ASAP paper in this codebase. If you are interested in using these motions G1, you can ignore this section. If you are interested in retargeting other humanoids or other motions, you can follow the steps below to prepare the SMPL shapes and motions.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;It has three steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;SMPL Shape preparation&lt;/li&gt; 
 &lt;li&gt;SMPL Motion preparation&lt;/li&gt; 
 &lt;li&gt;Robot XML and Motion Config preparation&lt;/li&gt; 
 &lt;li&gt;Humanoid-SMPL shape fitting&lt;/li&gt; 
 &lt;li&gt;Humanoid-SMPL motion retargeting&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;1. SMPL Shape preparation&lt;/h2&gt; 
&lt;p&gt;Download &lt;a href="https://download.is.tue.mpg.de/download.php?domain=smpl&amp;amp;sfile=SMPL_python_v.1.1.0.zip"&gt;v1.1.0 SMPL files with pkl format&lt;/a&gt; and put it under &lt;code&gt;humanoidverse/data/smpl/&lt;/code&gt;, and you should have:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;|-- ASAP
    |-- humanoidverse
        |-- data
            |-- smpl
                |-- SMPL_python_v.1.1.0.zip
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then &lt;code&gt;cd ASAP/humanoidverse/data/smpl/&lt;/code&gt; and &lt;code&gt;unzip SMPL_python_v.1.1.0.zip&lt;/code&gt;, after some copying and moving, you should have:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;|-- ASAP
    |-- humanoidverse
        |-- data
            |-- smpl
                |-- SMPL_python_v.1.1.0
                |-- models
                    |-- basicmodel_f_lbs_10_207_0_v1.1.0.pkl
                    |-- basicmodel_m_lbs_10_207_0_v1.1.0.pkl
                    |-- basicmodel_neutral_lbs_10_207_0_v1.1.0.pkl
                |-- smpl_webuser
                |-- ...

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Rename these three pkl files and move it under smpl like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;|-- ASAP
    |-- humanoidverse
        |-- data
            |-- smpl
                |-- SMPL_FEMALE.pkl
                |-- SMPL_MALE.pkl
                |-- SMPL_NEUTRAL.pkl
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;2. SMPL Motion preparation (AMASS)&lt;/h2&gt; 
&lt;p&gt;Download &lt;a href="https://amass.is.tue.mpg.de/index.html"&gt;AMASS Dataset&lt;/a&gt; with &lt;code&gt;SMPL + H G format&lt;/code&gt; and put it under &lt;code&gt;humanoidverse/data/motions/AMASS/AMASS_Complete/&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;|-- ASAP
    |-- humanoidverse
        |-- data
            |-- AMASS
                |-- AMASS_Complete
                    |-- ACCAD.tar.bz2
                    |-- BMLhandball.tar.bz2
                    |-- BMLmovi.tar.bz2
                    |-- BMLrub.tar
                    |-- CMU.tar.bz2
                    |-- ...
                    |-- Transitions.tar.bz2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then cd ASAP/humanoidverse/data/motions/AMASS/AMASS_Complete/ and extract all the motion files by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;for file in *.tar.bz2; do
    tar -xvjf "$file"
done
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you should have:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;|-- ASAP
    |-- humanoidverse
        |-- data
            |-- AMASS
                |-- AMASS_Complete
                    |-- ACCAD
                    |-- BioMotionLab_NTroje
                    |-- BMLhandball
                    |-- BMLmovi
                    |-- CMU
                    |-- ...
                    |-- Transitions
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Robot XML and Motion Config preparation&lt;/h2&gt; 
&lt;p&gt;Make sure you have robot xml and meshes ready at (G1 as example) &lt;code&gt;humanoidverse/data/robots/g1/g1_29dof_anneal_23dof_fitmotionONLY.xml&lt;/code&gt; And add your config for the robot motion in &lt;code&gt;humanoidverse/config/robot/g1_29dof_anneal_23dof.yaml&lt;/code&gt; with like the following. Remember to link the xml path in the config.&lt;/p&gt; 
&lt;h2&gt;4. Humanoid-SMPL shape fitting&lt;/h2&gt; 
&lt;p&gt;Run the following command to fit the SMPL shape to the humanoid.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python scripts/data_process/fit_smpl_shape.py +robot=g1/g1_29dof_anneal_23dof
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And you should have you shape file located at &lt;code&gt;humanoidverse/data/shape/g1_29dof_anneal_23dof/shape_optimized_v1.pkl&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to visualize the shape, you can run with flag &lt;code&gt;+vis=True&lt;/code&gt;, then you can have visualization of the fitted SMPL body shape and the humanoid body keypoints like this shape. The blue is the humanoid body keypoints and the orange is the fitted SMPL body keypoint. You can tune the &lt;code&gt;robot motion&lt;/code&gt; in &lt;code&gt;humanoidverse/config/robot/g1_29dof_anneal_23dof.yaml&lt;/code&gt; to adjust the correspondence, extend links lengths to get better fitted SMPL shape.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/imgs/g1_29dof_anneal_23dof_shape.png" width="400px" /&gt; 
&lt;h2&gt;5. Humanoid-SMPL motion retargeting&lt;/h2&gt; 
&lt;p&gt;Run the following command to retarget the motion to the humanoid.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python scripts/data_process/fit_smpl_motion.py +robot=g1/g1_29dof_anneal_23dof
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Visualize motion&lt;/h3&gt; 
&lt;p&gt;Run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python scripts/vis/vis_q_mj.py +robot=g1/g1_29dof_anneal_23dof +visualize_motion_file="humanoidverse/data/motions/g1_29dof_anneal_23dof/TairanTestbed/singles/0-motions_raw_tairantestbed_smpl_video_side_jump_level4_filter_amass.pkl"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To test, and you should have you one single motion file located at &lt;code&gt;humanoidverse/data/motions/g1_29dof_anneal_23dof/TairanTestbed/singles/0-motions_raw_tairantestbed_smpl_video_side_jump_level4_filter_amass.pkl&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you want to visualize the motion, you can run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python scripts/vis/vis_q_mj.py +robot=g1/g1_29dof_anneal_23dof +visualize_motion_file="humanoidverse/data/motions/g1_29dof_anneal_23dof/TairanTestbed/singles/0-motions_raw_tairantestbed_smpl_video_side_jump_level4_filter_amass.pkl"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should have&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/imgs/g1_29dof_anneal_23dof_motion.gif" width="400px" /&gt; 
&lt;h1&gt;Sim2Sim/Sim2Real&lt;/h1&gt; 
&lt;h2&gt;Environment Setup&lt;/h2&gt; 
&lt;p&gt;Env Installation:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mamba create -n asap_deploy python=3.10
mamba activate asap_deploy
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install ros2-python&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# this adds the conda-forge channel to the new created environment configuration 
conda config --env --add channels conda-forge
# and the robostack channel
conda config --env --add channels robostack-staging
# remove the defaults channel just in case, this might return an error if it is not in the list which is ok
conda config --env --remove channels defaults
# install the ros2-python package
conda install ros-humble-desktop
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Test Ros2Installation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;rviz2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should see the UI like this:&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/imgs/rviz.png" width="400px" /&gt; 
&lt;p&gt;Install Unitree SDK&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone git@github.com:unitreerobotics/unitree_sdk2_python.git
cd unitree_sdk2_python
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;minor issue to fix:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install --upgrade numpy scipy
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Sim2Sim&lt;/h2&gt; 
&lt;p&gt;start the simulation in the sim2real folder:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python sim_env/base_sim.py --config=config/g1_29dof_hist.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;in another terminal, start the policy:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python rl_policy/deepmimic_dec_loco_height.py --config=config/g1_29dof_hist.yaml --loco_model_path=./models/dec_loco/20250109_231507-noDR_rand_history_loco_stand_height_noise-decoupled_locomotion-g1_29dof/model_6600.onnx --mimic_model_paths=./models/mimic
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;click to the policy terminal and press &lt;code&gt;]&lt;/code&gt; to activate the locomotion policy&lt;/li&gt; 
 &lt;li&gt;click to the policy terminal and press &lt;code&gt;[&lt;/code&gt; to activate the asap policy (phase-based motion tracking policy)&lt;/li&gt; 
 &lt;li&gt;click to the policy terminal and press &lt;code&gt;;&lt;/code&gt; to switch to the asap policy&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;i&lt;/code&gt; to make the robot the initial position&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;o&lt;/code&gt; to emergence stop the robot&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;9&lt;/code&gt; in mujoco viewer to release the robostack&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;=&lt;/code&gt; to switch between tapping and walking for the locomotion policy&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;w/a/s/d&lt;/code&gt; to control the linear velocity&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;q/e&lt;/code&gt; to control the angular velocity&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;z&lt;/code&gt; to set all commands to zero&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And you should be able to play around with some checkpoints from the ASAP paper. Have fun!&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/imgs/asap-sim2sim-clip0-ezgif.com-video-to-gif-converter.gif" width="300px" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/imgs/asap-sim2sim-clip1-ezgif.com-video-to-gif-converter.gif" width="300px" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/imgs/asap-sim2sim-clip3-ezgif.com-video-to-gif-converter.gif" width="300px" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/imgs/asap-sim2sim-clip4-ezgif.com-video-to-gif-converter.gif" width="300px" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/imgs/asap-sim2sim-clip5-ezgif.com-video-to-gif-converter.gif" width="300px" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/imgs/asap-sim2sim-clip6-ezgif.com-video-to-gif-converter.gif" width="300px" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;!-- Replace gif1.gif ... gif6.gif with your actual gif filenames and optionally add captions below each if desired --&gt; 
&lt;h2&gt;Sim2Real&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Note from Tairan&lt;/code&gt;: make sure to make the G1 robot to 29dof following this &lt;a href="https://support.unitree.com/home/en/G1_developer/waist_fastener"&gt;doc&lt;/a&gt; and restart the robot after waist unlocking. If you don't know how to log into the Unitree Explore APP, contact unitree support.&lt;/p&gt; 
&lt;p&gt;Enter Low-Level for g1&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open humanoid and wait until the head blue light is constantly on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;L2+R2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;L2+A&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;L2+B&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Connect PC to the G1 by ethernet cable and configure the network following &lt;a href="https://support.unitree.com/home/en/G1_developer/quick_development"&gt;this document&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Before starting the policy, modify the &lt;code&gt;config/g1_29dof_hist.yaml&lt;/code&gt; to set &lt;code&gt;INTERFACE&lt;/code&gt; to &lt;code&gt;eth0&lt;/code&gt; (if you are using linux), basically the network interface that you are using to connect to the robot with your PC's IP shown as &lt;code&gt;192.168.123.xxx&lt;/code&gt; in &lt;code&gt;ifconfig&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;start the policy:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python rl_policy/deepmimic_dec_loco_height.py --config=config/g1_29dof_hist.yaml --loco_model_path=./models/dec_loco/20250109_231507-noDR_rand_history_loco_stand_height_noise-decoupled_locomotion-g1_29dof/model_6600.onnx --mimic_model_paths=./models/mimic
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;click to the policy terminal and press &lt;code&gt;]&lt;/code&gt; to activate the locomotion policy&lt;/li&gt; 
 &lt;li&gt;click to the policy terminal and press &lt;code&gt;[&lt;/code&gt; to activate the asap policy (phase-based motion tracking policy)&lt;/li&gt; 
 &lt;li&gt;click to the policy terminal and press &lt;code&gt;;&lt;/code&gt; to switch to the asap policy&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;i&lt;/code&gt; to make the robot the initial position&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;o&lt;/code&gt; to emergence stop the robot&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;9&lt;/code&gt; in mujoco viewer to release the robostack&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;=&lt;/code&gt; to switch between tapping and walking for the locomotion policy&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;w/a/s/d&lt;/code&gt; to control the linear velocity&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;q/e&lt;/code&gt; to control the angular velocity&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;z&lt;/code&gt; to set all commands to zero&lt;/li&gt; 
 &lt;li&gt;press &lt;code&gt;o&lt;/code&gt; to emergence stop the robot&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‚ÄºÔ∏èAlert &amp;amp; Disclaimer&lt;/h3&gt; 
&lt;p&gt;Deploying these models on physical hardware can be hazardous. Unless you have deep sim‚Äëto‚Äëreal expertise and robust safety protocols, we strongly advise against running the model on real robots. These models are supplied for research use only, and we disclaim all responsibility for any harm, loss, or malfunction arising from their deployment.&lt;/p&gt; 
&lt;h3&gt;Demo code to collect real-world data&lt;/h3&gt; 
&lt;p&gt;We provide a demo code to collect real-world data in the &lt;code&gt;sim2real/rl_policy/listener_deltaa.py&lt;/code&gt; file. Since MoCap setup is hard to transfer across different robots/labs, we hope this code can help you to collect data for your own experiments. Contact us (&lt;a href="mailto:tairanh@andrew.cmu.edu"&gt;tairanh@andrew.cmu.edu&lt;/a&gt;) if you have any questions.&lt;/p&gt; 
&lt;h1&gt;Citation&lt;/h1&gt; 
&lt;p&gt;If you find our work useful, please consider citing us!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{he2025asap,
  title={ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills},
  author={He, Tairan and Gao, Jiawei and Xiao, Wenli and Zhang, Yuanhang and Wang, Zi and Wang, Jiashun and Luo, Zhengyi and He, Guanqi and Sobanbabu, Nikhil and Pan, Chaoyi and Yi, Zeji and Qu, Guannan and Kitani, Kris and Hodgins, Jessica and Fan, Linxi "Jim" and Zhu, Yuke and Liu, Changliu and Shi, Guanya},
  journal={arXiv preprint arXiv:2502.01143},
  year={2025}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/LeCAR-Lab/ASAP/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>budtmo/docker-android</title>
      <link>https://github.com/budtmo/docker-android</link>
      <description>&lt;p&gt;Android in docker solution with noVNC supported and video recording&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img id="header" src="https://raw.githubusercontent.com/budtmo/docker-android/master/images/logo_docker-android.png" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="http://paypal.me/budtmo"&gt;&lt;img src="https://img.shields.io/badge/paypal-donate-blue.svg?sanitize=true" alt="Paypal Donate" /&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/budtmo/docker-android"&gt;&lt;img src="https://codecov.io/gh/budtmo/docker-android/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://gitter.im/budtmo/docker-android?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge"&gt;&lt;img src="https://badges.gitter.im/budtmo/docker-android.svg?sanitize=true" alt="Join the chat at https://gitter.im/budtmo/docker-android" /&gt;&lt;/a&gt; &lt;a href="https://github.com/budtmo/docker-android/releases"&gt;&lt;img src="https://img.shields.io/github/release/budtmo/docker-android.svg?sanitize=true" alt="GitHub release" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Docker-Android is a docker image built to be used for everything related to Android. It can be used for Application development and testing (native, web and hybrid-app).&lt;/p&gt; 
&lt;h2&gt;Advantages of using this project&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Emulator with different device profile and skins, such as Samsung Galaxy S6, LG Nexus 4, HTC Nexus One and more.&lt;/li&gt; 
 &lt;li&gt;Support vnc to be able to see what happen inside docker container&lt;/li&gt; 
 &lt;li&gt;Support log sharing feature where all logs can be accessed from web-UI&lt;/li&gt; 
 &lt;li&gt;Ability to control emulator from outside container by using adb connect&lt;/li&gt; 
 &lt;li&gt;Integrated with other cloud solutions, e.g. &lt;a href="https://www.genymotion.com/cloud/"&gt;Genymotion Cloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;It can be used to build Android project&lt;/li&gt; 
 &lt;li&gt;It can be used to run unit and UI-Test with different test-frameworks, e.g. Appium, Espresso, etc.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;List of Docker-Images&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Android&lt;/th&gt; 
   &lt;th align="left"&gt;API&lt;/th&gt; 
   &lt;th align="left"&gt;Image with latest release version&lt;/th&gt; 
   &lt;th align="left"&gt;Image with specific release version&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;9.0&lt;/td&gt; 
   &lt;td align="left"&gt;28&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_9.0&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_9.0_&amp;lt;release_version&amp;gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;10.0&lt;/td&gt; 
   &lt;td align="left"&gt;29&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_10.0&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_10.0_&amp;lt;release_version&amp;gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;11.0&lt;/td&gt; 
   &lt;td align="left"&gt;30&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_11.0&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_11.0_&amp;lt;release_version&amp;gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;12.0&lt;/td&gt; 
   &lt;td align="left"&gt;32&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_12.0&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_12.0_&amp;lt;release_version&amp;gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;13.0&lt;/td&gt; 
   &lt;td align="left"&gt;33&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_13.0&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_13.0_&amp;lt;release_version&amp;gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;14.0&lt;/td&gt; 
   &lt;td align="left"&gt;34&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_14.0&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:emulator_14.0_&amp;lt;release_version&amp;gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:genymotion&lt;/td&gt; 
   &lt;td align="left"&gt;budtmo/docker-android:genymotion_&amp;lt;release_version&amp;gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;List of Devices&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Device Name&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phone&lt;/td&gt; 
   &lt;td&gt;Samsung Galaxy S10&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phone&lt;/td&gt; 
   &lt;td&gt;Samsung Galaxy S9&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phone&lt;/td&gt; 
   &lt;td&gt;Samsung Galaxy S8&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phone&lt;/td&gt; 
   &lt;td&gt;Samsung Galaxy S7 Edge&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phone&lt;/td&gt; 
   &lt;td&gt;Samsung Galaxy S7&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phone&lt;/td&gt; 
   &lt;td&gt;Samsung Galaxy S6&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phone&lt;/td&gt; 
   &lt;td&gt;Nexus 4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phone&lt;/td&gt; 
   &lt;td&gt;Nexus 5&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phone&lt;/td&gt; 
   &lt;td&gt;Nexus One&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phone&lt;/td&gt; 
   &lt;td&gt;Nexus S&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tablet&lt;/td&gt; 
   &lt;td&gt;Nexus 7&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tablet&lt;/td&gt; 
   &lt;td&gt;Pixel C&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Docker is installed on your system.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;If you use &lt;em&gt;&lt;strong&gt;Ubuntu OS&lt;/strong&gt;&lt;/em&gt; on your host machine, you can skip this step. For &lt;em&gt;&lt;strong&gt;OSX&lt;/strong&gt;&lt;/em&gt; and &lt;em&gt;&lt;strong&gt;Windows OS&lt;/strong&gt;&lt;/em&gt; user, you need to use Virtual Machine that support Virtualization with Ubuntu OS because the image can be run under &lt;em&gt;&lt;strong&gt;Ubuntu OS only&lt;/strong&gt;&lt;/em&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Your machine should support virtualization. To check if the virtualization is enabled is:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo apt install cpu-checker
kvm-ok
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run Docker-Android container&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docker run -d -p 6080:6080 -e EMULATOR_DEVICE="Samsung Galaxy S10" -e WEB_VNC=true --device /dev/kvm --name android-container budtmo/docker-android:emulator_11.0
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Open &lt;em&gt;&lt;strong&gt;&lt;a href="http://localhost:6080"&gt;http://localhost:6080&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt; to see inside running container.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To check the status of the emulator&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docker exec -it android-container cat device_status
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Persisting data&lt;/h2&gt; 
&lt;p&gt;The default behaviour is to destroy the emulated device on container restart. To persist data, you need to mount a volume at &lt;code&gt;/home/androidusr&lt;/code&gt;: &lt;code&gt;docker run -v data:/home/androidusr budtmo/docker-android:emulator_11.0&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;WSL2 Hardware acceleration (Windows 11 only)&lt;/h2&gt; 
&lt;p&gt;Credit goes to &lt;a href="https://www.paralint.com/2022/11/find-new-modified-and-unversioned-subversion-files-on-windows"&gt;Guillaume - The Parallel Interface blog&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://learn.microsoft.com/en-us/windows/wsl/wsl-config"&gt;Microsoft - Advanced settings configuration in WSL&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Add yourself to the &lt;code&gt;kvm&lt;/code&gt; usergroup.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;sudo usermod -a -G kvm ${USER}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Add necessary flags to &lt;code&gt;/etc/wsl2.conf&lt;/code&gt; to their respective sections.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;[boot]
command = /bin/bash -c 'chown -v root:kvm /dev/kvm &amp;amp;&amp;amp; chmod 660 /dev/kvm'

[wsl2]
nestedVirtualization=true
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Restart WSL2 via CMD prompt or Powershell&lt;/p&gt; &lt;pre&gt;&lt;code&gt;wsl --shutdown
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;command = /bin/bash -c 'chown -v root:kvm /dev/kvm &amp;amp;&amp;amp; chmod 660 /dev/kvm'&lt;/code&gt; sets &lt;code&gt;/dev/kvm&lt;/code&gt; to &lt;code&gt;kvm&lt;/code&gt; usergroup rather than the default &lt;code&gt;root&lt;/code&gt; usergroup on WSL2 startup.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;nestedVirtualization&lt;/code&gt; flag is only available to Windows 11.&lt;/p&gt; 
&lt;h2&gt;Use-Cases&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/budtmo/docker-android/master/documentations/USE_CASE_BUILD_ANDROID_PROJECT.md"&gt;Build Android project&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/budtmo/docker-android/master/documentations/USE_CASE_APPIUM.md"&gt;UI-Test with Appium&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/budtmo/docker-android/master/documentations/USE_CASE_CONTROL_EMULATOR.md"&gt;Control Android emulator on host machine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/budtmo/docker-android/master/documentations/USE_CASE_SMS.md"&gt;SMS Simulation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/budtmo/docker-android/master/documentations/USE_CASE_JENKINS.md"&gt;Jenkins&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/budtmo/docker-android/master/documentations/USE_CASE_CLOUD.md"&gt;Deploying on cloud (Azure, AWS, GCP)&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Custom-Configurations&lt;/h2&gt; 
&lt;p&gt;This &lt;a href="https://raw.githubusercontent.com/budtmo/docker-android/master/documentations/CUSTOM_CONFIGURATIONS.md"&gt;document&lt;/a&gt; contains information about configurations that can be used to enable some features, e.g. log-sharing, etc.&lt;/p&gt; 
&lt;h2&gt;Genymotion&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img id="geny" src="https://raw.githubusercontent.com/budtmo/docker-android/master/images/logo_genymotion_and_dockerandroid.png" /&gt; &lt;/p&gt; 
&lt;p&gt;For you who do not have ressources to maintain the simulator or to buy machines or need different device profiles, you can give a try by using &lt;a href="https://cloud.geny.io/"&gt;Genymotion SAAS&lt;/a&gt;. Docker-Android is &lt;a href="https://www.genymotion.com/blog/partner_tag/docker/"&gt;integrated with Genymotion&lt;/a&gt; on different cloud services, e.g. Genymotion SAAS, AWS, GCP, Alibaba Cloud. Please follow &lt;a href="https://raw.githubusercontent.com/budtmo/docker-android/master/documentations/THIRD_PARTY_GENYMOTION.md"&gt;this document&lt;/a&gt; for more detail.&lt;/p&gt; 
&lt;h2&gt;Emulator Skins&lt;/h2&gt; 
&lt;p&gt;The Emulator skins are taken from &lt;a href="https://developer.android.com/studio"&gt;Android Studio IDE&lt;/a&gt; and &lt;a href="https://developer.samsung.com/"&gt;Samsung Developer Website&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;USERS&lt;/h2&gt; 
&lt;a href="https://lookerstudio.google.com/s/iGaemHJqQvg"&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/budtmo/docker-android/master/images/docker-android_users.png" alt="docker-android-users" width="800" height="600" /&gt; &lt;/p&gt; &lt;/a&gt; 
&lt;h2&gt;PRO VERSION&lt;/h2&gt; 
&lt;p&gt;Due to high requests for help and to be able to actively maintain the projects, the creator has decided to create docker-android-pro. Docker-Android-Pro is a sponsor based project which mean that the docker image of pro-version can be pulled only by &lt;a href="https://github.com/sponsors/budtmo"&gt;active sponsor&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The differences between normal version and pro version are:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Feature&lt;/th&gt; 
   &lt;th align="left"&gt;Normal&lt;/th&gt; 
   &lt;th align="left"&gt;Pro&lt;/th&gt; 
   &lt;th align="left"&gt;Comment&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;user-behavior-analytics&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;proxy&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Set up company proxy on Android emulator on fly&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;language&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Set up language on Android emulator on fly&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Newer Android version&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Support other newer Android version e.g. Android 15, Android 16, etc&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;root-privileged&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Able to run command with security privileged&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;headless-mode&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Save resources by using headless mode&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Selenium 4.x integration&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Running Appium UI-Tests againt one (Selenium Hub) endpoint for Android- and iOS emulator(s) / device(s)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;multiple Android-Simulators&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes (soon)&lt;/td&gt; 
   &lt;td align="left"&gt;Save resources by having multiple Android-Simulators on one docker-container&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Google Play Store&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes (soon)&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Video Recording&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes (soon)&lt;/td&gt; 
   &lt;td align="left"&gt;Helpful for debugging&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;This &lt;a href="https://raw.githubusercontent.com/budtmo/docker-android/master/documentations/DOCKER-ANDROID-PRO.md"&gt;document&lt;/a&gt; contains detail information about how to use docker-android-pro.&lt;/p&gt; 
&lt;h2&gt;LICENSE&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/budtmo/docker-android/master/LICENSE.md"&gt;License&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>denizsafak/abogen</title>
      <link>https://github.com/denizsafak/abogen</link>
      <description>&lt;p&gt;Generate audiobooks from EPUBs, PDFs and text with synchronized captions.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;abogen &lt;img width="40px" title="abogen icon" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/abogen/assets/icon.ico" align="right" style="padding-left: 10px; padding-top:5px;" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/denizsafak/abogen/actions"&gt;&lt;img src="https://github.com/denizsafak/abogen/actions/workflows/test_pip.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/denizsafak/abogen/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/denizsafak/abogen" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/abogen/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/abogen" alt="Abogen PyPi Python Versions" /&gt;&lt;/a&gt; &lt;a href="https://github.com/denizsafak/abogen/releases/latest"&gt;&lt;img src="https://img.shields.io/badge/os-windows%20%7C%20linux%20%7C%20macos%20-blue" alt="Operating Systems" /&gt;&lt;/a&gt; &lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" alt="Code style: black" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-maroon.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Abogen is a powerful text-to-speech conversion tool that makes it easy to turn ePub, PDF, or text files into high-quality audio with matching subtitles in seconds. Use it for audiobooks, voiceovers for Instagram, YouTube, TikTok, or any project that needs natural-sounding text-to-speech, using &lt;a href="https://huggingface.co/hexgrad/Kokoro-82M"&gt;Kokoro-82M&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img title="Abogen Main" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen.png" width="380" /&gt; &lt;img title="Abogen Processing" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen2.png" width="380" /&gt;&lt;/p&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/cb66512d-0a52-48c3-bda4-f1e6a03fb8d6"&gt;https://github.com/user-attachments/assets/cb66512d-0a52-48c3-bda4-f1e6a03fb8d6&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This demo was generated in just 5&amp;nbsp;seconds, producing ‚àº1&amp;nbsp;minute of audio with perfectly synced subtitles. To create a similar video, see &lt;a href="https://github.com/denizsafak/abogen/tree/main/demo"&gt;the demo guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;code&gt;How to install?&lt;/code&gt; &lt;a href="https://pypi.org/project/abogen/" target="_blank"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/abogen" alt="Abogen Compatible PyPi Python Versions" align="right" style="margin-top:6px;" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;Go to &lt;a href="https://github.com/espeak-ng/espeak-ng/releases/latest"&gt;espeak-ng latest release&lt;/a&gt; download and run the *.msi file.&lt;/p&gt; 
&lt;h4&gt;OPTION 1: Install using script&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/denizsafak/abogen/archive/refs/heads/main.zip"&gt;Download&lt;/a&gt; the repository&lt;/li&gt; 
 &lt;li&gt;Extract the ZIP file&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;WINDOWS_INSTALL.bat&lt;/code&gt; by double-clicking it&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This method handles everything automatically - installing all dependencies including CUDA in a self-contained environment without requiring a separate Python installation. (You still need to install &lt;a href="https://github.com/espeak-ng/espeak-ng/releases/latest"&gt;espeak-ng&lt;/a&gt;.)&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You don't need to install Python separately. The script will install Python automatically.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;OPTION 2: Install using pip&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a virtual environment (optional)
mkdir abogen &amp;amp;&amp;amp; cd abogen
python -m venv venv
venv\Scripts\activate

# For NVIDIA GPUs:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# For AMD GPUs:
# Not supported yet, because ROCm is not available on Windows. Use Linux if you have AMD GPU.

# Install abogen
pip install abogen
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Mac&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install espeak-ng
brew install espeak-ng

# Create a virtual environment (recommended)
mkdir abogen &amp;amp;&amp;amp; cd abogen
python3 -m venv venv
source venv/bin/activate

# Install abogen
pip3 install abogen
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install espeak-ng
sudo apt install espeak-ng # Ubuntu/Debian
sudo pacman -S espeak-ng # Arch Linux
sudo dnf install espeak-ng # Fedora

# Create a virtual environment (recommended)
mkdir abogen &amp;amp;&amp;amp; cd abogen
python3 -m venv venv
source venv/bin/activate

# Install abogen
pip3 install abogen

# For NVIDIA GPUs:
# Already supported, no need to install CUDA separately.

# For AMD GPUs:
# After installing abogen, we need to uninstall the existing torch package
pip3 uninstall torch 
pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.4
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you get &lt;code&gt;WARNING: The script abogen-cli is installed in '/home/username/.local/bin' which is not on PATH.&lt;/code&gt; error, run the following command to add it to your PATH:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;echo "export PATH=\"/home/$USER/.local/bin:\$PATH\"" &amp;gt;&amp;gt; ~/.bashrc &amp;amp;&amp;amp; source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you get "No matching distribution found" error, try installing it on supported Python (3.10 to 3.12). You can use &lt;a href="https://github.com/pyenv/pyenv"&gt;pyenv&lt;/a&gt; to manage multiple Python versions easily in Linux. Watch this &lt;a href="https://www.youtube.com/watch?v=MVyb-nI4KyI"&gt;video&lt;/a&gt; by NetworkChuck for a quick guide.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Special thanks to &lt;a href="https://github.com/hg000125"&gt;@hg000125&lt;/a&gt; for his contribution in &lt;a href="https://github.com/denizsafak/abogen/issues/23"&gt;#23&lt;/a&gt;. AMD GPU support is possible thanks to his work.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;code&gt;How to run?&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;If you installed using pip, you can simply run the following command to start Abogen:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;abogen
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you installed using the Windows installer &lt;code&gt;(WINDOWS_INSTALL.bat)&lt;/code&gt;, It should have created a shortcut in the same folder, or your desktop. You can run it from there. If you lost the shortcut, Abogen is located in &lt;code&gt;python_embedded/Scripts/abogen.exe&lt;/code&gt;. You can run it from there directly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;code&gt;How to use?&lt;/code&gt;&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Drag and drop any ePub, PDF, or text file (or use the built-in text editor)&lt;/li&gt; 
 &lt;li&gt;Configure the settings: 
  &lt;ul&gt; 
   &lt;li&gt;Set speech speed&lt;/li&gt; 
   &lt;li&gt;Select a voice (or create a custom voice using voice mixer)&lt;/li&gt; 
   &lt;li&gt;Select subtitle generation style (by sentence, word, etc.)&lt;/li&gt; 
   &lt;li&gt;Select output format&lt;/li&gt; 
   &lt;li&gt;Select where to save the output&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Hit Start&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;&lt;code&gt;In action&lt;/code&gt;&lt;/h2&gt; 
&lt;img title="Abogen in action" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/abogen.gif" /&gt; 
&lt;p&gt;Here‚Äôs Abogen in action: in this demo, it processes ‚àº3,000 characters of text in just 11 seconds and turns it into 3 minutes and 28 seconds of audio, and I have a low-end &lt;strong&gt;RTX&amp;nbsp;2060&amp;nbsp;Mobile laptop GPU&lt;/strong&gt;. Your results may vary depending on your hardware.&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;Configuration&lt;/code&gt;&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Input Box&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Drag and drop &lt;code&gt;ePub&lt;/code&gt;, &lt;code&gt;PDF&lt;/code&gt;, or &lt;code&gt;.TXT&lt;/code&gt; files (or use built-in text editor)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Queue options&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Add multiple files to a queue and process them in batch, with individual settings for each file. See &lt;a href="https://raw.githubusercontent.com/denizsafak/abogen/main/#queue-mode"&gt;Queue mode&lt;/a&gt; for more details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Speed&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Adjust speech rate from &lt;code&gt;0.1x&lt;/code&gt; to &lt;code&gt;2.0x&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Select Voice&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;First letter of the language code (e.g., &lt;code&gt;a&lt;/code&gt; for American English, &lt;code&gt;b&lt;/code&gt; for British English, etc.), second letter is for &lt;code&gt;m&lt;/code&gt; for male and &lt;code&gt;f&lt;/code&gt; for female.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Voice mixer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Create custom voices by mixing different voice models with a profile system. See &lt;a href="https://raw.githubusercontent.com/denizsafak/abogen/main/#voice-mixer"&gt;Voice Mixer&lt;/a&gt; for more details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Voice preview&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Listen to the selected voice before processing.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Generate subtitles&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Disabled&lt;/code&gt;, &lt;code&gt;Sentence&lt;/code&gt;, &lt;code&gt;Sentence + Comma&lt;/code&gt;, &lt;code&gt;1 word&lt;/code&gt;, &lt;code&gt;2 words&lt;/code&gt;, &lt;code&gt;3 words&lt;/code&gt;, etc. (Represents the number of words in each subtitle entry)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Output voice format&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.WAV&lt;/code&gt;, &lt;code&gt;.FLAC&lt;/code&gt;, &lt;code&gt;.MP3&lt;/code&gt;, &lt;code&gt;.OPUS (best compression)&lt;/code&gt; and &lt;code&gt;M4B (with chapters)&lt;/code&gt; (Special thanks to &lt;a href="https://github.com/jborza"&gt;@jborza&lt;/a&gt; for chapter support in PR &lt;a href="https://github.com/denizsafak/abogen/pull/10"&gt;#10&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Output subtitle format&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Configures the subtitle format as &lt;code&gt;SRT (standard)&lt;/code&gt;, &lt;code&gt;ASS (wide)&lt;/code&gt;, &lt;code&gt;ASS (narrow)&lt;/code&gt;, &lt;code&gt;ASS (centered wide)&lt;/code&gt;, or &lt;code&gt;ASS (centered narrow)&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Replace single newlines with spaces&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Replaces single newlines with spaces in the text. This is useful for texts that have imaginary line breaks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Save location&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;Save next to input file&lt;/code&gt;, &lt;code&gt;Save to desktop&lt;/code&gt;, or &lt;code&gt;Choose output folder&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Book handler options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Chapter Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Select specific &lt;code&gt;chapters&lt;/code&gt; from ePUBs or &lt;code&gt;chapters + pages&lt;/code&gt; from PDFs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Save each chapter separately&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Save each chapter in e-books as a separate audio file.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Create a merged version&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Create a single audio file that combines all chapters. (If &lt;code&gt;Save each chapter separately&lt;/code&gt; is disabled, this option will be the default behavior.)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Save in a project folder with metadata&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Save the converted items in a project folder with available metadata files.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Menu options&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Theme&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Change the application's theme using &lt;code&gt;System&lt;/code&gt;, &lt;code&gt;Light&lt;/code&gt;, or &lt;code&gt;Dark&lt;/code&gt; options.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Configure max words per subtitle&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Configures the maximum number of words per subtitle entry.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Configure max lines in log window&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Configures the maximum number of lines to display in the log window.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Separate chapters audio format&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Configures the audio format for separate chapters as &lt;code&gt;wav&lt;/code&gt;, &lt;code&gt;flac&lt;/code&gt;, &lt;code&gt;mp3&lt;/code&gt;, or &lt;code&gt;opus&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Create desktop shortcut&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Creates a shortcut on your desktop for easy access.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Open config directory&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Opens the directory where the configuration file is stored.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Open cache directory&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Opens the cache directory where converted text files are stored.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Clear cache files&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Deletes cache files created during the conversion or preview.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Check for updates at startup&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Automatically checks for updates when the program starts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Disable Kokoro's internet access&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Prevents Kokoro from downloading models or voices from HuggingFace Hub, useful for offline use.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Reset to default settings&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Resets all settings to their default values.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;&lt;code&gt;Voice Mixer&lt;/code&gt;&lt;/h2&gt; 
&lt;img title="Abogen Voice Mixer" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/voice_mixer.png" /&gt; 
&lt;p&gt;With voice mixer, you can create custom voices by mixing different voice models. You can adjust the weight of each voice and save your custom voice as a profile for future use. The voice mixer allows you to create unique and personalized voices. (Huge thanks to &lt;a href="https://github.com/jborza"&gt;@jborza&lt;/a&gt; for making this possible through his contributions in &lt;a href="https://github.com/denizsafak/abogen/pull/5"&gt;#5&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;Queue Mode&lt;/code&gt;&lt;/h2&gt; 
&lt;img title="Abogen queue mode" src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/queue.png" /&gt; 
&lt;p&gt;Abogen supports &lt;strong&gt;queue mode&lt;/strong&gt;, allowing you to add multiple files to a processing queue. This is useful if you want to convert several files in one batch.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can add text files (&lt;code&gt;.txt&lt;/code&gt;) directly using the &lt;strong&gt;Add files&lt;/strong&gt; button in the Queue Manager. To add PDF or EPUB files, use the input box in the main window and click the &lt;strong&gt;Add to Queue&lt;/strong&gt; button.&lt;/li&gt; 
 &lt;li&gt;Each file in the queue keeps the configuration settings that were active when it was added. Changing the main window configuration afterward does &lt;strong&gt;not&lt;/strong&gt; affect files already in the queue.&lt;/li&gt; 
 &lt;li&gt;You can view each file's configuration by hovering over them.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Abogen will process each item in the queue automatically, saving outputs as configured.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Special thanks to &lt;a href="https://github.com/jborza"&gt;@jborza&lt;/a&gt; for adding queue mode in PR &lt;a href="https://github.com/denizsafak/abogen/pull/35"&gt;#35&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;code&gt;About Chapter Markers&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;When you process ePUB or PDF files, Abogen converts them into text files stored in your cache directory. When you click "Edit," you're actually modifying these converted text files. In these text files, you'll notice tags that look like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;&amp;lt;CHAPTER_MARKER:Chapter Title&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;These are chapter markers. They are automatically added when you process ePUB or PDF files, based on the chapters you select. They serve an important purpose:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Allow you to split the text into separate audio files for each chapter&lt;/li&gt; 
 &lt;li&gt;Save time by letting you reprocess only specific chapters if errors occur, rather than the entire file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can manually add these markers to plain text files for the same benefits. Simply include them in your text like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;&amp;lt;CHAPTER_MARKER:Introduction&amp;gt;&amp;gt;
This is the beginning of my text...  

&amp;lt;&amp;lt;CHAPTER_MARKER:Main Content&amp;gt;&amp;gt; 
Here's another part...  
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When you process the text file, Abogen will detect these markers automatically and ask if you want to save each chapter separately and create a merged version.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/denizsafak/abogen/refs/heads/main/demo/chapter_marker.png" alt="Abogen Chapter Marker" /&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;About Metadata Tags&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;Similar to chapter markers, it is possible to add metadata tags for &lt;code&gt;M4B&lt;/code&gt; files. This is useful for audiobook players that support metadata, allowing you to add information like title, author, year, etc. Abogen automatically adds these tags when you process ePUB or PDF files, but you can also add them manually to your text files. Add metadata tags &lt;strong&gt;at the beginning of your text file&lt;/strong&gt; like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;lt;&amp;lt;METADATA_TITLE:Title&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_ARTIST:Author&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_ALBUM:Album Title&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_YEAR:Year&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_ALBUM_ARTIST:Album Artist&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_COMPOSER:Narrator&amp;gt;&amp;gt;
&amp;lt;&amp;lt;METADATA_GENRE:Audiobook&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;code&gt;Supported Languages&lt;/code&gt;&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;# üá∫üá∏ 'a' =&amp;gt; American English, üá¨üáß 'b' =&amp;gt; British English
# üá™üá∏ 'e' =&amp;gt; Spanish es
# üá´üá∑ 'f' =&amp;gt; French fr-fr
# üáÆüá≥ 'h' =&amp;gt; Hindi hi
# üáÆüáπ 'i' =&amp;gt; Italian it
# üáØüáµ 'j' =&amp;gt; Japanese: pip install misaki[ja]
# üáßüá∑ 'p' =&amp;gt; Brazilian Portuguese pt-br
# üá®üá≥ 'z' =&amp;gt; Mandarin Chinese: pip install misaki[zh]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a complete list of supported languages and voices, refer to Kokoro's &lt;a href="https://huggingface.co/hexgrad/Kokoro-82M/blob/main/VOICES.md"&gt;VOICES.md&lt;/a&gt;. To listen to sample audio outputs, see &lt;a href="https://huggingface.co/hexgrad/Kokoro-82M/blob/main/SAMPLES.md"&gt;SAMPLES.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;MPV Config&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;I highly recommend using &lt;a href="https://mpv.io/installation/"&gt;MPV&lt;/a&gt; to play your audio files, as it supports displaying subtitles even without a video track. Here's my &lt;code&gt;mpv.conf&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# --- MPV Settings ---
save-position-on-quit
keep-open=yes
# --- Subtitle ---
sub-ass-override=no
sub-margin-y=50
sub-margin-x=50
# --- Audio Quality ---
audio-spdif=ac3,dts,eac3,truehd,dts-hd
audio-channels=auto
audio-samplerate=48000
volume-max=200
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;code&gt;Docker Guide&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;If you want to run Abogen in a Docker container:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/denizsafak/abogen/archive/refs/heads/main.zip"&gt;Download the repository&lt;/a&gt; and extract, or clone it using git.&lt;/li&gt; 
 &lt;li&gt;Go to &lt;code&gt;abogen&lt;/code&gt; folder. You should see &lt;code&gt;Dockerfile&lt;/code&gt; there.&lt;/li&gt; 
 &lt;li&gt;Open your termminal in that directory and run the following commands:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build the Docker image:
docker build --progress plain -t abogen .

# Note that building the image may take a while.
# After building is complete, run the Docker container:

# Windows
docker run --name abogen -v %cd%:/shared -p 5800:5800 -p 5900:5900 --gpus all abogen

# Linux
docker run --name abogen -v $(pwd):/shared -p 5800:5800 -p 5900:5900 --gpus all abogen

# MacOS
docker run --name abogen -v $(pwd):/shared -p 5800:5800 -p 5900:5900 abogen

# We expose port 5800 for use by a web browser, 5900 if you want to connect with a VNC client.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Abogen launches automatically inside the container.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can access it via a web browser at &lt;a href="http://localhost:5800"&gt;http://localhost:5800&lt;/a&gt; or connect to it using a VNC client at &lt;code&gt;localhost:5900&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;You can use &lt;code&gt;/shared&lt;/code&gt; directory to share files between your host and the container.&lt;/li&gt; 
 &lt;li&gt;For later use, start it with &lt;code&gt;docker start abogen&lt;/code&gt; and stop it with &lt;code&gt;docker stop abogen&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Known issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Audio preview is not working inside container (ALSA error).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Open cache directory&lt;/code&gt; and &lt;code&gt;Open configuration directory&lt;/code&gt; options in settings not working. (Tried pcmanfm, did not work with Abogen).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;(Special thanks to &lt;a href="https://www.reddit.com/user/geo38/"&gt;@geo38&lt;/a&gt; from Reddit, who provided the Dockerfile and instructions in &lt;a href="https://www.reddit.com/r/selfhosted/comments/1k8x1yo/comment/mpe0bz8/"&gt;this comment&lt;/a&gt;.)&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;Similar Projects&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;Abogen is a standalone project, but it is inspired by and shares some similarities with other projects. Here are a few:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/santinic/audiblez"&gt;audiblez&lt;/a&gt;: Generate audiobooks from e-books. &lt;strong&gt;(Has CLI and GUI support)&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/plusuncold/autiobooks"&gt;autiobooks&lt;/a&gt;: Automatically convert epubs to audiobooks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mateogon/pdf-narrator"&gt;pdf-narrator&lt;/a&gt;: Convert your PDFs and EPUBs into audiobooks effortlessly.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/p0n1/epub_to_audiobook"&gt;epub_to_audiobook&lt;/a&gt;: EPUB to audiobook converter, optimized for Audiobookshelf&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DrewThomasson/ebook2audiobook"&gt;ebook2audiobook&lt;/a&gt;: Convert ebooks to audiobooks with chapters and metadata using dynamic AI models and voice cloning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;code&gt;Roadmap&lt;/code&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Add OCR scan feature for PDF files using docling/teserract.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Add chapter metadata for .m4a files. (Issue &lt;a href="https://github.com/denizsafak/abogen/issues/9"&gt;#9&lt;/a&gt;, PR &lt;a href="https://github.com/denizsafak/abogen/pull/10"&gt;#10&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Add support for different languages in GUI.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Add voice formula feature that enables mixing different voice models. (Issue &lt;a href="https://github.com/denizsafak/abogen/issues/1"&gt;#1&lt;/a&gt;, PR &lt;a href="https://github.com/denizsafak/abogen/pull/5"&gt;#5&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Add support for kokoro-onnx (If it's necessary).&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Add dark mode.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;code&gt;Troubleshooting&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;If you encounter any issues while running Abogen, try launching it from the command line with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;abogen-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will start Abogen in command-line mode and display detailed error messages. Please open a new issue on the &lt;a href="https://github.com/denizsafak/abogen/issues"&gt;Issues&lt;/a&gt; page with the error message and a description of your problem.&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;Contributing&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;I welcome contributions! If you have ideas for new features, improvements, or bug fixes, please fork the repository and submit a pull request.&lt;/p&gt; 
&lt;h3&gt;For developers and contributors&lt;/h3&gt; 
&lt;p&gt;If you'd like to modify the code and contribute to development, you can &lt;a href="https://github.com/denizsafak/abogen/archive/refs/heads/main.zip"&gt;download the repository&lt;/a&gt;, extract it and run the following commands to build &lt;strong&gt;or&lt;/strong&gt; install the package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Go to the directory where you extracted the repository and run:
pip install -e .      # Installs the package in editable mode
pip install build     # Install the build package
python -m build       # Builds the package in dist folder (optional)
abogen                # Opens the GUI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Feel free to explore the code and make any changes you like.&lt;/p&gt; 
&lt;h2&gt;&lt;code&gt;Credits&lt;/code&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Abogen uses &lt;a href="https://github.com/hexgrad/kokoro"&gt;Kokoro&lt;/a&gt; for its high-quality, natural-sounding text-to-speech synthesis. Huge thanks to the Kokoro team for making this possible.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://github.com/wojiushixiaobai"&gt;@wojiushixiaobai&lt;/a&gt; for &lt;a href="https://github.com/wojiushixiaobai/Python-Embed-Win64"&gt;Embedded Python&lt;/a&gt; packages. These modified packages include pip pre-installed, enabling Abogen to function as a standalone application without requiring users to separately install Python in Windows.&lt;/li&gt; 
 &lt;li&gt;Thanks to creators of &lt;a href="https://github.com/aerkalov/ebooklib"&gt;EbookLib&lt;/a&gt;, a Python library for reading and writing ePub files, which is used for extracting text from ePub files.&lt;/li&gt; 
 &lt;li&gt;Special thanks to the &lt;a href="https://www.riverbankcomputing.com/software/pyqt/"&gt;PyQt&lt;/a&gt; team for providing the cross-platform GUI toolkit that powers Abogen's interface.&lt;/li&gt; 
 &lt;li&gt;Icons: &lt;a href="https://icons8.com/icon/aRiu1GGi6Aoe/usa"&gt;US&lt;/a&gt;, &lt;a href="https://icons8.com/icon/t3NE3BsOAQwq/great-britain"&gt;Great Britain&lt;/a&gt;, &lt;a href="https://icons8.com/icon/ly7tzANRt33n/spain"&gt;Spain&lt;/a&gt;, &lt;a href="https://icons8.com/icon/3muzEmi4dpD5/france"&gt;France&lt;/a&gt;, &lt;a href="https://icons8.com/icon/esGVrxg9VCJ1/india"&gt;India&lt;/a&gt;, &lt;a href="https://icons8.com/icon/PW8KZnP7qXzO/italy"&gt;Italy&lt;/a&gt;, &lt;a href="https://icons8.com/icon/McQbrq9qaQye/japan"&gt;Japan&lt;/a&gt;, &lt;a href="https://icons8.com/icon/zHmH8HpOmM90/brazil"&gt;Brazil&lt;/a&gt;, &lt;a href="https://icons8.com/icon/Ej50Oe3crXwF/china"&gt;China&lt;/a&gt;, &lt;a href="https://icons8.com/icon/uI49hxbpxTkp/female"&gt;Female&lt;/a&gt;, &lt;a href="https://icons8.com/icon/12351/male"&gt;Male&lt;/a&gt;, &lt;a href="https://icons8.com/icon/21698/adjust"&gt;Adjust&lt;/a&gt; and &lt;a href="https://icons8.com/icon/GskSeVoroQ7u/voice-id"&gt;Voice Id&lt;/a&gt; icons by &lt;a href="https://icons8.com/"&gt;Icons8&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;code&gt;License&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;This project is available under the MIT License - see the &lt;a href="https://github.com/denizsafak/abogen/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details. &lt;a href="https://github.com/hexgrad/kokoro"&gt;Kokoro&lt;/a&gt; is licensed under &lt;a href="https://github.com/hexgrad/kokoro/raw/main/LICENSE"&gt;Apache-2.0&lt;/a&gt; which allows commercial use, modification, distribution, and private use.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Subtitle generation currently works only for English. This is because Kokoro provides timestamp tokens only for English text. If you want subtitles in other languages, please request this feature in the &lt;a href="https://github.com/hexgrad/kokoro"&gt;Kokoro project&lt;/a&gt;. For more technical details, see &lt;a href="https://github.com/hexgrad/kokoro/raw/6d87f4ae7abc2d14dbc4b3ef2e5f19852e861ac2/kokoro/pipeline.py#L383"&gt;this line&lt;/a&gt; in the Kokoro's code.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Tags: audiobook, kokoro, text-to-speech, TTS, audiobook generator, audiobooks, text to speech, audiobook maker, audiobook creator, audiobook generator, voice-synthesis, text to audio, text to audio converter, text to speech converter, text to speech generator, text to speech software, text to speech app, epub to audio, pdf to audio, content-creation, media-generation&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>paperless-ngx/paperless-ngx</title>
      <link>https://github.com/paperless-ngx/paperless-ngx</link>
      <description>&lt;p&gt;A community-supported supercharged document management system: scan, index and archive all your documents&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/paperless-ngx/paperless-ngx/actions"&gt;&lt;img src="https://github.com/paperless-ngx/paperless-ngx/workflows/ci/badge.svg?sanitize=true" alt="ci" /&gt;&lt;/a&gt; &lt;a href="https://crowdin.com/project/paperless-ngx"&gt;&lt;img src="https://badges.crowdin.net/paperless-ngx/localized.svg?sanitize=true" alt="Crowdin" /&gt;&lt;/a&gt; &lt;a href="https://docs.paperless-ngx.com"&gt;&lt;img src="https://img.shields.io/github/deployments/paperless-ngx/paperless-ngx/github-pages?label=docs" alt="Documentation Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/paperless-ngx/paperless-ngx"&gt;&lt;img src="https://codecov.io/gh/paperless-ngx/paperless-ngx/branch/main/graph/badge.svg?token=VK6OUPJ3TY" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/%23paperlessngx%3Amatrix.org"&gt;&lt;img src="https://matrix.to/img/matrix-badge.svg?sanitize=true" alt="Chat on Matrix" /&gt;&lt;/a&gt; &lt;a href="https://demo.paperless-ngx.com"&gt;&lt;img src="https://cronitor.io/badges/ve7ItY/production/W5E_B9jkelG9ZbDiNHUPQEVH3MY.svg?sanitize=true" alt="demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/paperless-ngx/paperless-ngx/blob/main/resources/logo/web/png/White%20logo%20-%20no%20background.png" width="50%" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/paperless-ngx/paperless-ngx/raw/main/resources/logo/web/png/Black%20logo%20-%20no%20background.png" width="50%" /&gt; 
  &lt;img src="https://github.com/paperless-ngx/paperless-ngx/raw/main/resources/logo/web/png/Black%20logo%20-%20no%20background.png" width="50%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;!-- omit in toc --&gt; 
&lt;h1&gt;Paperless-ngx&lt;/h1&gt; 
&lt;p&gt;Paperless-ngx is a document management system that transforms your physical documents into a searchable online archive so you can keep, well, &lt;em&gt;less paper&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;Paperless-ngx is the official successor to the original &lt;a href="https://github.com/the-paperless-project/paperless"&gt;Paperless&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/jonaswinkler/paperless-ng"&gt;Paperless-ng&lt;/a&gt; projects and is designed to distribute the responsibility of advancing and supporting the project among a team of people. &lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#community-support"&gt;Consider joining us!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Thanks to the generous folks at &lt;a href="https://m.do.co/c/8d70b916d462"&gt;DigitalOcean&lt;/a&gt;, a demo is available at &lt;a href="https://demo.paperless-ngx.com"&gt;demo.paperless-ngx.com&lt;/a&gt; using login &lt;code&gt;demo&lt;/code&gt; / &lt;code&gt;demo&lt;/code&gt;. &lt;em&gt;Note: demo content is reset frequently and confidential information should not be uploaded.&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#getting-started"&gt;Getting started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#contributing"&gt;Contributing&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#community-support"&gt;Community Support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#translation"&gt;Translation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#feature-requests"&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#bugs"&gt;Bugs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#related-projects"&gt;Related Projects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/dev/#important-note"&gt;Important Note&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;This project is supported by:&lt;br /&gt; &lt;a href="https://m.do.co/c/8d70b916d462" style="padding-top: 4px; display: block;"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_white.svg" width="140px" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg" width="140px" /&gt; 
   &lt;img src="https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_black_.svg?sanitize=true" width="140px" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards-dark.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/docs/assets/screenshots/documents-smallcards.png" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;A full list of &lt;a href="https://docs.paperless-ngx.com/#features"&gt;features&lt;/a&gt; and &lt;a href="https://docs.paperless-ngx.com/#screenshots"&gt;screenshots&lt;/a&gt; are available in the &lt;a href="https://docs.paperless-ngx.com/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Getting started&lt;/h1&gt; 
&lt;p&gt;The easiest way to deploy paperless is &lt;code&gt;docker compose&lt;/code&gt;. The files in the &lt;a href="https://github.com/paperless-ngx/paperless-ngx/tree/main/docker/compose"&gt;&lt;code&gt;/docker/compose&lt;/code&gt; directory&lt;/a&gt; are configured to pull the image from the GitHub container registry.&lt;/p&gt; 
&lt;p&gt;If you'd like to jump right in, you can configure a &lt;code&gt;docker compose&lt;/code&gt; environment with our install script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash -c "$(curl -L https://raw.githubusercontent.com/paperless-ngx/paperless-ngx/main/install-paperless-ngx.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details and step-by-step guides for alternative installation methods can be found in &lt;a href="https://docs.paperless-ngx.com/setup/#installation"&gt;the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Migrating from Paperless-ng is easy, just drop in the new docker image! See the &lt;a href="https://docs.paperless-ngx.com/setup/#migrating-to-paperless-ngx"&gt;documentation on migrating&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;!-- omit in toc --&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;The documentation for Paperless-ngx is available at &lt;a href="https://docs.paperless-ngx.com/"&gt;https://docs.paperless-ngx.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;If you feel like contributing to the project, please do! Bug fixes, enhancements, visual fixes etc. are always welcome. If you want to implement something big: Please start a discussion about that! The &lt;a href="https://docs.paperless-ngx.com/development/"&gt;documentation&lt;/a&gt; has some basic information on how to get started.&lt;/p&gt; 
&lt;h2&gt;Community Support&lt;/h2&gt; 
&lt;p&gt;People interested in continuing the work on paperless-ngx are encouraged to reach out here on github and in the &lt;a href="https://matrix.to/#/#paperless:matrix.org"&gt;Matrix Room&lt;/a&gt;. If you would like to contribute to the project on an ongoing basis there are multiple &lt;a href="https://github.com/orgs/paperless-ngx/people"&gt;teams&lt;/a&gt; (frontend, ci/cd, etc) that could use your help so please reach out!&lt;/p&gt; 
&lt;h2&gt;Translation&lt;/h2&gt; 
&lt;p&gt;Paperless-ngx is available in many languages that are coordinated on Crowdin. If you want to help out by translating paperless-ngx into your language, please head over to &lt;a href="https://crowdin.com/project/paperless-ngx"&gt;https://crowdin.com/project/paperless-ngx&lt;/a&gt;, and thank you! More details can be found in &lt;a href="https://github.com/paperless-ngx/paperless-ngx/raw/main/CONTRIBUTING.md#translating-paperless-ngx"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feature Requests&lt;/h2&gt; 
&lt;p&gt;Feature requests can be submitted via &lt;a href="https://github.com/paperless-ngx/paperless-ngx/discussions/categories/feature-requests"&gt;GitHub Discussions&lt;/a&gt;, you can search for existing ideas, add your own and vote for the ones you care about.&lt;/p&gt; 
&lt;h2&gt;Bugs&lt;/h2&gt; 
&lt;p&gt;For bugs please &lt;a href="https://github.com/paperless-ngx/paperless-ngx/issues"&gt;open an issue&lt;/a&gt; or &lt;a href="https://github.com/paperless-ngx/paperless-ngx/discussions"&gt;start a discussion&lt;/a&gt; if you have questions.&lt;/p&gt; 
&lt;h1&gt;Related Projects&lt;/h1&gt; 
&lt;p&gt;Please see &lt;a href="https://github.com/paperless-ngx/paperless-ngx/wiki/Related-Projects"&gt;the wiki&lt;/a&gt; for a user-maintained list of related projects and software that is compatible with Paperless-ngx.&lt;/p&gt; 
&lt;h1&gt;Important Note&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Document scanners are typically used to scan sensitive documents like your social insurance number, tax records, invoices, etc. &lt;strong&gt;Paperless-ngx should never be run on an untrusted host&lt;/strong&gt; because information is stored in clear text without encryption. No guarantees are made regarding security (but we do try!) and you use the app at your own risk. &lt;strong&gt;The safest way to run Paperless-ngx is on a local server in your own home with backups in place&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>microsoft/mcp-for-beginners</title>
      <link>https://github.com/microsoft/mcp-for-beginners</link>
      <description>&lt;p&gt;This open-source curriculum introduces the fundamentals of Model Context Protocol (MCP) through real-world, cross-language examples in .NET, Java, TypeScript, JavaScript, Rust and Python. Designed for developers, it focuses on practical techniques for building modular, scalable, and secure AI workflows from session setup to service orchestration.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/images/mcp-beginners.png" alt="MCP-for-beginners" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/issues"&gt;&lt;img src="https://img.shields.io/github/issues/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/microsoft/mcp-for-beginners.svg?sanitize=true" alt="GitHub pull-requests" /&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Watch" alt="GitHub watchers" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/fork"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/mcp-for-beginners?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.com/invite/ByRwuEEgH4"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/ByRwuEEgH4" alt="Microsoft Azure AI Foundry Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Follow these steps to get started using these resources:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the Repository&lt;/strong&gt;: Click &lt;a href="https://GitHub.com/microsoft/mcp-for-beginners/fork"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/mcp-for-beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Clone the Repository&lt;/strong&gt;: &lt;code&gt;git clone https://github.com/microsoft/mcp-for-beginners.git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.com/invite/ByRwuEEgH4"&gt;&lt;strong&gt;Join The Azure AI Foundry Discord and meet experts and fellow developers&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üåê Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ar/README.md"&gt;Arabic&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/bn/README.md"&gt;Bengali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/bg/README.md"&gt;Bulgarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/my/README.md"&gt;Burmese (Myanmar)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/zh/README.md"&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hk/README.md"&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/mo/README.md"&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tw/README.md"&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hr/README.md"&gt;Croatian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/cs/README.md"&gt;Czech&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/da/README.md"&gt;Danish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/nl/README.md"&gt;Dutch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fi/README.md"&gt;Finnish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fr/README.md"&gt;French&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/de/README.md"&gt;German&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/el/README.md"&gt;Greek&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/he/README.md"&gt;Hebrew&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hi/README.md"&gt;Hindi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/hu/README.md"&gt;Hungarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/id/README.md"&gt;Indonesian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/it/README.md"&gt;Italian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ja/README.md"&gt;Japanese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ko/README.md"&gt;Korean&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ms/README.md"&gt;Malay&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/mr/README.md"&gt;Marathi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ne/README.md"&gt;Nepali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/no/README.md"&gt;Norwegian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/fa/README.md"&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pl/README.md"&gt;Polish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/br/README.md"&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pt/README.md"&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/pa/README.md"&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ro/README.md"&gt;Romanian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ru/README.md"&gt;Russian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sr/README.md"&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sk/README.md"&gt;Slovak&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sl/README.md"&gt;Slovenian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/es/README.md"&gt;Spanish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sw/README.md"&gt;Swahili&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/sv/README.md"&gt;Swedish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tl/README.md"&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/th/README.md"&gt;Thai&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/tr/README.md"&gt;Turkish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/uk/README.md"&gt;Ukrainian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/ur/README.md"&gt;Urdu&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/translations/vi/README.md"&gt;Vietnamese&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;üöÄ Model Context Protocol (MCP) Curriculum for Beginners&lt;/h1&gt; 
&lt;h2&gt;&lt;strong&gt;Learn MCP with Hands-on Code Examples in C#, Java, JavaScript, Rust, Python, and TypeScript&lt;/strong&gt;&lt;/h2&gt; 
&lt;h2&gt;üß† Overview of the Model Context Protocol Curriculum&lt;/h2&gt; 
&lt;p&gt;The &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; is a cutting-edge framework designed to standardize interactions between AI models and client applications. This open-source curriculum offers a structured learning path, complete with practical coding examples and real-world use cases, across popular programming languages including C#, Java, JavaScript, TypeScript, and Python.&lt;/p&gt; 
&lt;p&gt;Whether you're an AI developer, system architect, or software engineer, this guide is your comprehensive resource for mastering MCP fundamentals and implementation strategies.&lt;/p&gt; 
&lt;h2&gt;üîó Official MCP Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìò &lt;a href="https://modelcontextprotocol.io/"&gt;MCP Documentation&lt;/a&gt; ‚Äì Detailed tutorials and user guides&lt;/li&gt; 
 &lt;li&gt;üìú &lt;a href="https://modelcontextprotocol.io/docs/"&gt;MCP Specification&lt;/a&gt; ‚Äì Protocol architecture and technical references&lt;/li&gt; 
 &lt;li&gt;üìú &lt;a href="https://spec.modelcontextprotocol.io/"&gt;Original MCP Specification&lt;/a&gt; ‚Äì Legacy technical references (may contain additional details)&lt;/li&gt; 
 &lt;li&gt;üßë‚Äçüíª &lt;a href="https://github.com/modelcontextprotocol"&gt;MCP GitHub Repository&lt;/a&gt; ‚Äì Open-source SDKs, tools, and code samples&lt;/li&gt; 
 &lt;li&gt;üåê &lt;a href="https://github.com/orgs/modelcontextprotocol/discussions"&gt;MCP Community&lt;/a&gt; ‚Äì Join discussions and contribute to the community&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‚û°Ô∏èWatch on Demand - MCP Dev Days&lt;/h3&gt; 
&lt;p&gt;Get ready for two days of deep technical insight, community connection, and hands-on learning at MCP Dev Days, a virtual event dedicated to the Model Context Protocol (MCP) ‚Äî the emerging standard that bridges AI models and the tools they rely on. You can watch MCP Dev Days by registering on our event page: &lt;a href="https://aka.ms/mcpdevdays"&gt;https://aka.ms/mcpdevdays&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Day 1: MCP Productivity, DevTools, &amp;amp; Community:&lt;/h4&gt; 
&lt;p&gt;Is all about empowering developers to use MCP in their developer workflow and celebrating the amazing MCP community. We‚Äôll be joined with community members and partners such as Arcade, Block, Okta, and Neon to see how they are collaborating with Microsoft to shape an open, extensible MCP ecosystem. Real-world demos across VS Code, Visual Studio, GitHub Copilot, and popular community tools Practical, context-driven dev workflows Community-led sessions and insights Whether you‚Äôre just getting started with MCP or already building with it, Day 1 will set the stage with inspiration and actionable takeaways.&lt;/p&gt; 
&lt;h4&gt;Day 2: Build MCP Servers with Confidence&lt;/h4&gt; 
&lt;p&gt;Is for MCP builders. We‚Äôll go deep into implementation strategies and best practices for creating MCP servers and integrating MCP into your AI workflows.&lt;/p&gt; 
&lt;h3&gt;Topics include:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Building MCP Servers and integrating them into agent experiences&lt;/li&gt; 
 &lt;li&gt;Prompt-driven development&lt;/li&gt; 
 &lt;li&gt;Security best practices&lt;/li&gt; 
 &lt;li&gt;Using building blocks like Functions, ACA, and API Management&lt;/li&gt; 
 &lt;li&gt;Registry alignment and tooling (1P + 3P)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you‚Äôre a developer, tool builder, or AI product strategist, this day is packed with the insights you need to build scalable, secure, and future-ready MCP solutions.&lt;/p&gt; 
&lt;h2&gt;üß≠ MCP Curriculum Overview&lt;/h2&gt; 
&lt;h3&gt;üìö Complete Curriculum Structure&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 1-3: Fundamentals&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;00&lt;/td&gt; 
   &lt;td&gt;Introduction to MCP&lt;/td&gt; 
   &lt;td&gt;Overview of the Model Context Protocol and its significance in AI pipelines&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/00-Introduction/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;01&lt;/td&gt; 
   &lt;td&gt;Core Concepts Explained&lt;/td&gt; 
   &lt;td&gt;In-depth exploration of core MCP concepts&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/01-CoreConcepts/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;02&lt;/td&gt; 
   &lt;td&gt;Security in MCP&lt;/td&gt; 
   &lt;td&gt;Security threats and best practices&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/02-Security/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;03&lt;/td&gt; 
   &lt;td&gt;Getting Started with MCP&lt;/td&gt; 
   &lt;td&gt;Environment setup, basic servers/clients, integration&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 3: Building Your First Server &amp;amp; Client&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.1&lt;/td&gt; 
   &lt;td&gt;First Server&lt;/td&gt; 
   &lt;td&gt;Create your first MCP server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/01-first-server/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.2&lt;/td&gt; 
   &lt;td&gt;First Client&lt;/td&gt; 
   &lt;td&gt;Develop a basic MCP client&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/02-client/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.3&lt;/td&gt; 
   &lt;td&gt;Client with LLM&lt;/td&gt; 
   &lt;td&gt;Integrate large language models&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/03-llm-client/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.4&lt;/td&gt; 
   &lt;td&gt;VS Code Integration&lt;/td&gt; 
   &lt;td&gt;Consume MCP servers in VS Code&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/04-vscode/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.5&lt;/td&gt; 
   &lt;td&gt;SSE Server&lt;/td&gt; 
   &lt;td&gt;Create servers using Server-Sent Events&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/05-sse-server/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.6&lt;/td&gt; 
   &lt;td&gt;HTTP Streaming&lt;/td&gt; 
   &lt;td&gt;Implement HTTP streaming in MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/06-http-streaming/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.7&lt;/td&gt; 
   &lt;td&gt;AI Toolkit&lt;/td&gt; 
   &lt;td&gt;Use AI Toolkit with MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/07-aitk/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.8&lt;/td&gt; 
   &lt;td&gt;Testing&lt;/td&gt; 
   &lt;td&gt;Test your MCP server implementation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/08-testing/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.9&lt;/td&gt; 
   &lt;td&gt;Deployment&lt;/td&gt; 
   &lt;td&gt;Deploy MCP servers to production&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/09-deployment/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 4-5: Practical &amp;amp; Advanced&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;04&lt;/td&gt; 
   &lt;td&gt;Practical Implementation&lt;/td&gt; 
   &lt;td&gt;SDKs, debugging, testing, reusable prompt templates&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;05&lt;/td&gt; 
   &lt;td&gt;Advanced Topics in MCP&lt;/td&gt; 
   &lt;td&gt;Multi-modal AI, scaling, enterprise use&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/README.md"&gt;Read more&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.1&lt;/td&gt; 
   &lt;td&gt;Azure Integration&lt;/td&gt; 
   &lt;td&gt;MCP Integration with Azure&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-integration/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.2&lt;/td&gt; 
   &lt;td&gt;Multi-modality&lt;/td&gt; 
   &lt;td&gt;Working with multiple modalities&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-multi-modality/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.3&lt;/td&gt; 
   &lt;td&gt;OAuth2 Demo&lt;/td&gt; 
   &lt;td&gt;Implement OAuth2 authentication&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-oauth2-demo/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.4&lt;/td&gt; 
   &lt;td&gt;Root Contexts&lt;/td&gt; 
   &lt;td&gt;Understand and implement root contexts&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-root-contexts/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.5&lt;/td&gt; 
   &lt;td&gt;Routing&lt;/td&gt; 
   &lt;td&gt;MCP routing strategies&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-routing/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.6&lt;/td&gt; 
   &lt;td&gt;Sampling&lt;/td&gt; 
   &lt;td&gt;Sampling techniques in MCP&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-sampling/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.7&lt;/td&gt; 
   &lt;td&gt;Scaling&lt;/td&gt; 
   &lt;td&gt;Scale MCP implementations&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-scaling/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.8&lt;/td&gt; 
   &lt;td&gt;Security&lt;/td&gt; 
   &lt;td&gt;Advanced security considerations&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-security/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.9&lt;/td&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;Implement web search capabilities&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/web-search-mcp/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.10&lt;/td&gt; 
   &lt;td&gt;Realtime Streaming&lt;/td&gt; 
   &lt;td&gt;Build realtime streaming functionality&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-realtimestreaming/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.11&lt;/td&gt; 
   &lt;td&gt;Realtime Search&lt;/td&gt; 
   &lt;td&gt;Implement realtime search&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-realtimesearch/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.12&lt;/td&gt; 
   &lt;td&gt;Entra ID Auth&lt;/td&gt; 
   &lt;td&gt;Authentication with Microsoft Entra ID&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-security-entra/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.13&lt;/td&gt; 
   &lt;td&gt;Foundry Integration&lt;/td&gt; 
   &lt;td&gt;Integrate with Azure AI Foundry&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-foundry-agent-integration/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.14&lt;/td&gt; 
   &lt;td&gt;Context Engineering&lt;/td&gt; 
   &lt;td&gt;Techniques for effective context engineering&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/05-AdvancedTopics/mcp-contextengineering/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Module 6-10: Community &amp;amp; Best Practices&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;06&lt;/td&gt; 
   &lt;td&gt;Community Contributions&lt;/td&gt; 
   &lt;td&gt;How to contribute to the MCP ecosystem&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/06-CommunityContributions/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;07&lt;/td&gt; 
   &lt;td&gt;Insights from Early Adoption&lt;/td&gt; 
   &lt;td&gt;Real-world implementation stories&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/07-LessonsFromEarlyAdoption/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;08&lt;/td&gt; 
   &lt;td&gt;Best Practices for MCP&lt;/td&gt; 
   &lt;td&gt;Performance, fault-tolerance, resilience&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/08-BestPractices/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;09&lt;/td&gt; 
   &lt;td&gt;MCP Case Studies&lt;/td&gt; 
   &lt;td&gt;Practical implementation examples&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/09-CaseStudy/README.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;Hands-on Workshop&lt;/td&gt; 
   &lt;td&gt;Building an MCP Server with AI Toolkit&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/10-StreamliningAIWorkflowsBuildingAnMCPServerWithAIToolkit/README.md"&gt;Lab&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üíª Sample Code Projects&lt;/h3&gt; 
&lt;h4&gt;Basic MCP Calculator Samples&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;C#&lt;/td&gt; 
   &lt;td&gt;MCP Server Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/csharp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Java&lt;/td&gt; 
   &lt;td&gt;MCP Calculator&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/java/calculator/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript&lt;/td&gt; 
   &lt;td&gt;MCP Demo&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/javascript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;MCP Server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/python/mcp_calculator_server.py"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TypeScript&lt;/td&gt; 
   &lt;td&gt;MCP Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/03-GettingStarted/samples/typescript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Advanced MCP Implementations&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;C#&lt;/td&gt; 
   &lt;td&gt;Advanced Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/csharp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Java with Spring&lt;/td&gt; 
   &lt;td&gt;Container App Example&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/java/containerapp/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript&lt;/td&gt; 
   &lt;td&gt;Advanced Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/javascript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
   &lt;td&gt;Complex Implementation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/python/mcp_sample.py"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TypeScript&lt;/td&gt; 
   &lt;td&gt;Container Sample&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/04-PracticalImplementation/samples/typescript/README.md"&gt;View Code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üéØ Prerequisites for Learning MCP&lt;/h2&gt; 
&lt;p&gt;To get the most out of this curriculum, you should have:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Basic knowledge of programming in at least one of the following languages: C#, Java, JavaScript, Python, or TypeScript&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Understanding of client-server model and APIs&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Familiarity with REST and HTTP concepts&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optional) Background in AI/ML concepts&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Joining our community discussions for support&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìö Study Guide &amp;amp; Resources&lt;/h2&gt; 
&lt;p&gt;This repository includes several resources to help you navigate and learn effectively:&lt;/p&gt; 
&lt;h3&gt;Study Guide&lt;/h3&gt; 
&lt;p&gt;A comprehensive &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/study_guide.md"&gt;Study Guide&lt;/a&gt; is available to help you navigate this repository effectively. The guide includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A visual curriculum map showing all topics covered&lt;/li&gt; 
 &lt;li&gt;Detailed breakdown of each repository section&lt;/li&gt; 
 &lt;li&gt;Guidance on how to use sample projects&lt;/li&gt; 
 &lt;li&gt;Recommended learning paths for different skill levels&lt;/li&gt; 
 &lt;li&gt;Additional resources to complement your learning journey&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Changelog&lt;/h3&gt; 
&lt;p&gt;We maintain a detailed &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/changelog.md"&gt;Changelog&lt;/a&gt; that tracks all significant updates to the curriculum materials, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;New content additions&lt;/li&gt; 
 &lt;li&gt;Structural changes&lt;/li&gt; 
 &lt;li&gt;Feature improvements&lt;/li&gt; 
 &lt;li&gt;Documentation updates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõ†Ô∏è How to Use This Curriculum Effectively&lt;/h2&gt; 
&lt;p&gt;Each lesson in this guide includes:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clear explanations of MCP concepts&lt;/li&gt; 
 &lt;li&gt;Live code examples in multiple languages&lt;/li&gt; 
 &lt;li&gt;Exercises to build real MCP applications&lt;/li&gt; 
 &lt;li&gt;Extra resources for advanced learners&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üåü Community Thanks&lt;/h2&gt; 
&lt;p&gt;Thanks to Microsoft Valued Professional &lt;a href="https://www.linkedin.com/in/shivam2003/"&gt;Shivam Goyal&lt;/a&gt; for contributing important code samples.&lt;/p&gt; 
&lt;h2&gt;üìú License Information&lt;/h2&gt; 
&lt;p&gt;This content is licensed under the &lt;strong&gt;MIT License&lt;/strong&gt;. For terms and conditions, see the &lt;a href="https://raw.githubusercontent.com/microsoft/mcp-for-beginners/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ù Contribution Guidelines&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;üìÇ Repository Structure&lt;/h2&gt; 
&lt;p&gt;The repository is organized as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Core Curriculum (00-10)&lt;/strong&gt;: The main content organized in ten sequential modules&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;images/&lt;/strong&gt;: Diagrams and illustrations used throughout the curriculum&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;translations/&lt;/strong&gt;: Multi-language support with automated translations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;translated_images/&lt;/strong&gt;: Localized versions of diagrams and illustrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;study_guide.md&lt;/strong&gt;: Comprehensive guide to navigating the repository&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;changelog.md&lt;/strong&gt;: Record of all significant changes to the curriculum materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;mcp.json&lt;/strong&gt;: Configuration file for MCP specification&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CODE_OF_CONDUCT.md, LICENSE, SECURITY.md, SUPPORT.md&lt;/strong&gt;: Project governance documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üéí Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/ai-agents-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI Agents For Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-with-javascript?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using JavaScript&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-for-beginners-java?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst"&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst"&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Security-101?WT.mc_id=academic-96948-sayoung"&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst"&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst"&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst"&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚Ñ¢Ô∏è Trademark Notice&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos is subject to those third-parties' policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>manycore-research/SpatialLM</title>
      <link>https://github.com/manycore-research/SpatialLM</link>
      <description>&lt;p&gt;SpatialLM: Training Large Language Models for Structured Indoor Modeling&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SpatialLM&lt;/h1&gt; 
&lt;!-- markdownlint-disable first-line-h1 --&gt; 
&lt;!-- markdownlint-disable html --&gt; 
&lt;!-- markdownlint-disable no-duplicate-header --&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/manycore-research/SpatialLM/main/figures/logo_light.png#gh-light-mode-only" width="60%" alt="SpatialLM" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/manycore-research/SpatialLM/main/figures/logo_dark.png#gh-dark-mode-only" width="60%" alt="SpatialLM" /&gt; 
&lt;/div&gt; 
&lt;hr style="margin-top: 0; margin-bottom: 8px;" /&gt; 
&lt;div align="center" style="margin-top: 0; padding-top: 0; line-height: 1;"&gt; 
 &lt;a href="https://manycore-research.github.io/SpatialLM" target="_blank" style="margin: 2px;"&gt;&lt;img alt="Project" src="https://img.shields.io/badge/üåê%20Website-SpatialLM-ffc107?color=42a5f5&amp;amp;logoColor=white" style="display: inline-block; vertical-align: middle;" /&gt;&lt;/a&gt; 
 &lt;a href="https://arxiv.org/abs/2506.07491" target="_blank" style="margin: 2px;"&gt;&lt;img alt="arXiv" src="https://img.shields.io/badge/arXiv-Techreport-b31b1b?logo=arxiv&amp;amp;logoColor=white" style="display: inline-block; vertical-align: middle;" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/manycore-research/SpatialLM" target="_blank" style="margin: 2px;"&gt;&lt;img alt="GitHub" src="https://img.shields.io/badge/GitHub-SpatialLM-24292e?logo=github&amp;amp;logoColor=white" style="display: inline-block; vertical-align: middle;" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center" style="line-height: 1;"&gt; 
 &lt;a href="https://huggingface.co/manycore-research/SpatialLM1.1-Qwen-0.5B" target="_blank" style="margin: 2px;"&gt;&lt;img alt="Hugging Face" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-SpatialLM-ffc107?color=ffc107&amp;amp;logoColor=white" style="display: inline-block; vertical-align: middle;" /&gt;&lt;/a&gt; 
 &lt;a href="https://huggingface.co/datasets/manycore-research/SpatialLM-Testset" target="_blank" style="margin: 2px;"&gt;&lt;img alt="Dataset" src="https://img.shields.io/badge/%F0%9F%A4%97%20Dataset-Testset-ffc107?color=ffc107&amp;amp;logoColor=white" style="display: inline-block; vertical-align: middle;" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ú® News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[Jun, 2025] Check out our new models: &lt;a href="https://huggingface.co/manycore-research/SpatialLM1.1-Llama-1B"&gt;SpatialLM1.1-Llama-1B&lt;/a&gt; and &lt;a href="https://huggingface.co/manycore-research/SpatialLM1.1-Qwen-0.5B"&gt;SpatialLM1.1-Qwen-0.5B&lt;/a&gt;, now available on Hugging Face. SpatialLM1.1 doubles the point cloud resolution, incorporates a more powerful point cloud encoder &lt;a href="https://xywu.me/sonata/"&gt;Sonata&lt;/a&gt; and supports detection with user-specified categories.&lt;/li&gt; 
 &lt;li&gt;[Jun, 2025] SpatialLM &lt;a href="https://arxiv.org/abs/2506.07491"&gt;Technical Report&lt;/a&gt; is now on arXiv.&lt;/li&gt; 
 &lt;li&gt;[Mar, 2025] We're excited to release the &lt;a href="https://huggingface.co/manycore-research/SpatialLM-Llama-1B"&gt;SpatialLM-Llama-1B&lt;/a&gt; and &lt;a href="https://huggingface.co/manycore-research/SpatialLM-Qwen-0.5B"&gt;SpatialLM-Qwen-0.5B&lt;/a&gt; on Hugging Face.&lt;/li&gt; 
 &lt;li&gt;[Mar, 2025] Initial release of SpatialLM!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;SpatialLM is a 3D large language model designed to process 3D point cloud data and generate structured 3D scene understanding outputs. These outputs include architectural elements like walls, doors, windows, and oriented object bounding boxes with their semantic categories. Unlike previous methods that require specialized equipment for data collection, SpatialLM can handle point clouds from diverse sources such as monocular video sequences, RGBD images, and LiDAR sensors. This multimodal architecture effectively bridges the gap between unstructured 3D geometric data and structured 3D representations, offering high-level semantic understanding. It enhances spatial reasoning capabilities for applications in embodied robotics, autonomous navigation, and other complex 3D scene analysis tasks.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;video src="https://github.com/user-attachments/assets/c0218d6a-f676-41f8-ae76-bba228866306" poster="figures/cover.png"&gt; 
 &lt;/video&gt; 
 &lt;p&gt;&lt;i&gt;SpatialLM reconstructs 3D layout from a monocular RGB video with MASt3R-SLAM. Results aligned to video with GT cameras for visualization.&lt;/i&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;SpatialLM Models&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Download&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;SpatialLM1.1-Llama-1B&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://huggingface.co/manycore-research/SpatialLM1.1-Llama-1B"&gt;ü§ó HuggingFace&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;SpatialLM1.1-Qwen-0.5B&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://huggingface.co/manycore-research/SpatialLM1.1-Qwen-0.5B"&gt;ü§ó HuggingFace&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;SpatialLM1.0-Llama-1B&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://huggingface.co/manycore-research/SpatialLM-Llama-1B"&gt;ü§ó HuggingFace&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;SpatialLM1.0-Qwen-0.5B&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://huggingface.co/manycore-research/SpatialLM-Qwen-0.5B"&gt;ü§ó HuggingFace&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;Tested with the following environment:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.11&lt;/li&gt; 
 &lt;li&gt;Pytorch 2.4.1&lt;/li&gt; 
 &lt;li&gt;CUDA Version 12.4&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# clone the repository
git clone https://github.com/manycore-research/SpatialLM.git
cd SpatialLM

# create a conda environment with cuda 12.4
conda create -n spatiallm python=3.11
conda activate spatiallm
conda install -y -c nvidia/label/cuda-12.4.0 cuda-toolkit conda-forge::sparsehash

# Install dependencies with poetry
pip install poetry &amp;amp;&amp;amp; poetry config virtualenvs.create false --local
poetry install
# SpatialLM1.0 dependency
poe install-torchsparse # Building wheel for torchsparse will take a while
# SpatialLM1.1 dependency
poe install-sonata # Building wheel for flash-attn will take a while
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Inference&lt;/h3&gt; 
&lt;p&gt;In the current version of SpatialLM, input point clouds are considered axis-aligned where the z-axis is the up axis. This orientation is crucial for maintaining consistency in spatial understanding and scene interpretation across different datasets and applications. Example preprocessed point clouds, reconstructed from RGB videos using &lt;a href="https://github.com/rmurai0610/MASt3R-SLAM"&gt;MASt3R-SLAM&lt;/a&gt;, are available in &lt;a href="https://raw.githubusercontent.com/manycore-research/SpatialLM/main/#spatiallm-testset"&gt;SpatialLM-Testset&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Download an example point cloud:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;huggingface-cli download manycore-research/SpatialLM-Testset pcd/scene0000_00.ply --repo-type dataset --local-dir .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run inference:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python inference.py --point_cloud pcd/scene0000_00.ply --output scene0000_00.txt --model_path manycore-research/SpatialLM1.1-Qwen-0.5B
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Detection with user-specified categories&lt;/h3&gt; 
&lt;p&gt;SpatialLM1.1 supports object detection conditioned on user-specified categories by leveraging the flexibility of LLMs.&lt;/p&gt; 
&lt;p&gt;SpatialLM1.1 offers three variants of structured indoor modeling tasks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Structured Reconstruction&lt;/strong&gt;: Detect walls, doors, windows, boxes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Layout Estimation&lt;/strong&gt;: Detect walls, doors, windows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;3D Object Detection&lt;/strong&gt;: Detect boxes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For tasks that include object box estimation, you can specify a subset of the 59 furniture categories, and the model will only predict objects within those specified categories. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python inference.py --point_cloud pcd/scene0000_00.ply --output scene0000_00.txt --model_path manycore-research/SpatialLM1.1-Qwen-0.5B --detect_type object --category bed nightstand
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Visualization&lt;/h3&gt; 
&lt;p&gt;Use &lt;code&gt;rerun&lt;/code&gt; to visualize the point cloud and the predicted structured 3D layout output:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Convert the predicted layout to Rerun format
python visualize.py --point_cloud pcd/scene0000_00.ply --layout scene0000_00.txt --save scene0000_00.rrd

# Visualize the point cloud and the predicted layout
rerun scene0000_00.rrd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Evaluation&lt;/h3&gt; 
&lt;p&gt;To evaluate the performance of SpatialLM, we provide &lt;code&gt;eval.py&lt;/code&gt; script that reports the benchmark results on the SpatialLM-Testset in the table below in section &lt;a href="https://raw.githubusercontent.com/manycore-research/SpatialLM/main/#benchmark-results"&gt;Benchmark Results&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Download the testset:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;huggingface-cli download manycore-research/SpatialLM-Testset --repo-type dataset --local-dir SpatialLM-Testset
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run evaluation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run inference on the PLY point clouds in folder SpatialLM-Testset/pcd with SpatialLM1.1-Qwen-0.5B model
python inference.py --point_cloud SpatialLM-Testset/pcd --output SpatialLM-Testset/pred --model_path manycore-research/SpatialLM1.1-Qwen-0.5B

# Evaluate the predicted layouts
python eval.py --metadata SpatialLM-Testset/test.csv --gt_dir SpatialLM-Testset/layout --pred_dir SpatialLM-Testset/pred --label_mapping SpatialLM-Testset/benchmark_categories.tsv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example using a custom video&lt;/h3&gt; 
&lt;p&gt;We provide an example of how to use our model to estimate scene layout starting from a RGB video with the newly released &lt;a href="https://github.com/PKU-VCL-3DV/SLAM3R"&gt;SLAM3R&lt;/a&gt; in &lt;a href="https://raw.githubusercontent.com/manycore-research/SpatialLM/main/EXAMPLE.md"&gt;EXAMPLE.md&lt;/a&gt;. These steps work for MASt3R-SLAM, and other reconstruction methods as well.&lt;/p&gt; 
&lt;h2&gt;SpatialLM Testset&lt;/h2&gt; 
&lt;p&gt;We provide a test set of 107 preprocessed point clouds, reconstructed from RGB videos using &lt;a href="https://github.com/rmurai0610/MASt3R-SLAM"&gt;MASt3R-SLAM&lt;/a&gt;. SpatialLM-Testset is quite challenging compared to prior clean RGBD scans datasets due to the noises and occlusions in the point clouds reconstructed from monocular RGB videos.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Dataset&lt;/strong&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;strong&gt;Download&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;SpatialLM-Testset&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://huggingface.co/datasets/manycore-research/SpatialLM-TestSet"&gt;ü§ó Datasets&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Benchmark Results&lt;/h2&gt; 
&lt;h3&gt;Layout Estimation&lt;/h3&gt; 
&lt;p&gt;Layout estimation focuses on predicting architectural elements, i.e., walls, doors, and windows, within an indoor scene. We evaluated this task on the &lt;a href="https://structured3d-dataset.org"&gt;Structured3D&lt;/a&gt; dataset. For &lt;a href="https://github.com/ywyue/RoomFormer"&gt;RoomFormer&lt;/a&gt;, we directly downloaded the model checkpoint. SceneScript and SpatialLM were first trained on our dataset, and further fine-tuned on Structured3D.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Method&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;RoomFormer&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;SceneScript (finetuned)&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;SpatialLM1.1-Qwen-0.5B (finetuned)&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;strong&gt;F1 @.25 IoU&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;70.4&lt;/td&gt; 
    &lt;td align="center"&gt;83.1&lt;/td&gt; 
    &lt;td align="center"&gt;86.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;strong&gt;F1 @.5 IoU&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;67.2&lt;/td&gt; 
    &lt;td align="center"&gt;80.8&lt;/td&gt; 
    &lt;td align="center"&gt;84.6&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h3&gt;3D Object Detection&lt;/h3&gt; 
&lt;p&gt;We evaluate 3D object detection on &lt;a href="http://www.scan-net.org"&gt;ScanNet&lt;/a&gt; with annotations of 18 object categories. For &lt;a href="https://github.com/V-DETR/V-DETR"&gt;V-DETR&lt;/a&gt;, we directly download the model checkpoint. SceneScript and SpatialLM were first trained on our dataset, and further fine-tuned on ScanNet.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Method&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;V-DETR&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;SceneScript (finetuned)&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;SpatialLM1.1-Qwen-0.5B (finetuned)&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;strong&gt;F1 @.25 IoU&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;65.1&lt;/td&gt; 
    &lt;td align="center"&gt;49.1&lt;/td&gt; 
    &lt;td align="center"&gt;65.6&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;strong&gt;F1 @.5 IoU&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;56.8&lt;/td&gt; 
    &lt;td align="center"&gt;36.8&lt;/td&gt; 
    &lt;td align="center"&gt;52.6&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h3&gt;Zero-shot Detection on Videos&lt;/h3&gt; 
&lt;p&gt;Zero-shot detection results on the challenging SpatialLM-Testset are reported in the following table:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;Method&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;SpatialLM1.1-Llama-1B&lt;/strong&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;&lt;strong&gt;SpatialLM1.1-Qwen-0.5B&lt;/strong&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;strong&gt;Layout&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;strong&gt;F1 @.25 IoU (2D)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;strong&gt;F1 @.25 IoU (2D)&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;wall&lt;/td&gt; 
    &lt;td align="center"&gt;68.9&lt;/td&gt; 
    &lt;td align="center"&gt;68.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;door&lt;/td&gt; 
    &lt;td align="center"&gt;46.3&lt;/td&gt; 
    &lt;td align="center"&gt;43.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;window&lt;/td&gt; 
    &lt;td align="center"&gt;43.8&lt;/td&gt; 
    &lt;td align="center"&gt;47.4&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;strong&gt;Objects&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;strong&gt;F1 @.25 IoU (3D)&lt;/strong&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;strong&gt;F1 @.25 IoU (2D)&lt;/strong&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;curtain&lt;/td&gt; 
    &lt;td align="center"&gt;34.9&lt;/td&gt; 
    &lt;td align="center"&gt;37.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;nightstand&lt;/td&gt; 
    &lt;td align="center"&gt;62.8&lt;/td&gt; 
    &lt;td align="center"&gt;67.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;chandelier&lt;/td&gt; 
    &lt;td align="center"&gt;53.5&lt;/td&gt; 
    &lt;td align="center"&gt;36.8&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;wardrobe&lt;/td&gt; 
    &lt;td align="center"&gt;29.4&lt;/td&gt; 
    &lt;td align="center"&gt;39.6&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;bed&lt;/td&gt; 
    &lt;td align="center"&gt;96.8&lt;/td&gt; 
    &lt;td align="center"&gt;95.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;sofa&lt;/td&gt; 
    &lt;td align="center"&gt;66.9&lt;/td&gt; 
    &lt;td align="center"&gt;69.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;chair&lt;/td&gt; 
    &lt;td align="center"&gt;20.8&lt;/td&gt; 
    &lt;td align="center"&gt;32.3&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;cabinet&lt;/td&gt; 
    &lt;td align="center"&gt;15.2&lt;/td&gt; 
    &lt;td align="center"&gt;11.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;dining table&lt;/td&gt; 
    &lt;td align="center"&gt;40.7&lt;/td&gt; 
    &lt;td align="center"&gt;24.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;plants&lt;/td&gt; 
    &lt;td align="center"&gt;29.5&lt;/td&gt; 
    &lt;td align="center"&gt;26.3&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;tv cabinet&lt;/td&gt; 
    &lt;td align="center"&gt;34.4&lt;/td&gt; 
    &lt;td align="center"&gt;27.3&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;coffee table&lt;/td&gt; 
    &lt;td align="center"&gt;56.4&lt;/td&gt; 
    &lt;td align="center"&gt;64.9&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;side table&lt;/td&gt; 
    &lt;td align="center"&gt;14.6&lt;/td&gt; 
    &lt;td align="center"&gt;9.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;air conditioner&lt;/td&gt; 
    &lt;td align="center"&gt;16.7&lt;/td&gt; 
    &lt;td align="center"&gt;24.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;dresser&lt;/td&gt; 
    &lt;td align="center"&gt;46.7&lt;/td&gt; 
    &lt;td align="center"&gt;46.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;stool&lt;/td&gt; 
    &lt;td align="center"&gt;17.6&lt;/td&gt; 
    &lt;td align="center"&gt;30.8&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;refrigerator&lt;/td&gt; 
    &lt;td align="center"&gt;0.0&lt;/td&gt; 
    &lt;td align="center"&gt;16.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;painting&lt;/td&gt; 
    &lt;td align="center"&gt;34.9&lt;/td&gt; 
    &lt;td align="center"&gt;38.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;carpet&lt;/td&gt; 
    &lt;td align="center"&gt;40.3&lt;/td&gt; 
    &lt;td align="center"&gt;24.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;tv&lt;/td&gt; 
    &lt;td align="center"&gt;16.0&lt;/td&gt; 
    &lt;td align="center"&gt;18.0&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h3&gt;Result Visualizations&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;Layout Estimation&lt;/th&gt; 
    &lt;th align="center"&gt;Object Detection&lt;/th&gt; 
    &lt;th align="center"&gt;Zero-shot Reconstruction&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/manycore-research/SpatialLM/main/figures/stru3d.jpg" alt="Structured3D" /&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/manycore-research/SpatialLM/main/figures/scannet.jpg" alt="ScanNet" /&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/manycore-research/SpatialLM/main/figures/zeroshot.jpg" alt="Zero-shot" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://manycore-research-azure.kujiale.com/manycore-research/SpatialLM/supplementary/visualization_layout.html"&gt;Structured3D Results&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://manycore-research-azure.kujiale.com/manycore-research/SpatialLM/supplementary/visualization_object.html"&gt;ScanNet Results&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://manycore-research-azure.kujiale.com/manycore-research/SpatialLM/supplementary/visualization_zeroshot.html"&gt;Zeroshot Results&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;SpatialLM-Llama-1B is derived from Llama3.2-1B-Instruct, which is licensed under the Llama3.2 license. SpatialLM-Qwen-0.5B is derived from the Qwen-2.5 series, originally licensed under the Apache 2.0 License.&lt;/p&gt; 
&lt;p&gt;SpatialLM1.0 are built upon the SceneScript point cloud encoder, licensed under the CC-BY-NC-4.0 License. TorchSparse, utilized in this project, is licensed under the MIT License.&lt;/p&gt; 
&lt;p&gt;SpatialLM1.1 are built upon Sonata point cloud encoder, model weight is licensed under the CC-BY-NC-4.0 License. Code built on Pointcept is licensed under the Apache 2.0 License.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find this work useful, please consider citing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{SpatialLM,
    title         = {SpatialLM: Training Large Language Models for Structured Indoor Modeling},
    author        = {Mao, Yongsen and Zhong, Junhao and Fang, Chuan and Zheng, Jia and Tang, Rui and Zhu, Hao and Tan, Ping and Zhou, Zihan},
    journal       = {arXiv preprint},
    year          = {2025},
    eprint        = {2506.07491},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We would like to thank the following projects that made this work possible:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/meta-llama"&gt;Llama3.2&lt;/a&gt; | &lt;a href="https://github.com/QwenLM/Qwen2.5"&gt;Qwen2.5&lt;/a&gt; | &lt;a href="https://github.com/huggingface/transformers"&gt;Transformers&lt;/a&gt; | &lt;a href="https://github.com/facebookresearch/scenescript"&gt;SceneScript&lt;/a&gt; | &lt;a href="https://github.com/mit-han-lab/torchsparse"&gt;TorchSparse&lt;/a&gt; | &lt;a href="https://xywu.me/sonata/"&gt;Sonata&lt;/a&gt; | &lt;a href="https://github.com/Pointcept/Pointcept"&gt;Pointcept&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vaastav/Fantasy-Premier-League</title>
      <link>https://github.com/vaastav/Fantasy-Premier-League</link>
      <description>&lt;p&gt;Creates a .csv file of all players in the English Player League with their respective team and total fantasy points&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://gitspo.com/mentions/vaastav/Fantasy-Premier-League"&gt;&lt;img src="https://gitspo.com/badges/mentions/vaastav/Fantasy-Premier-League?style=flat-square" alt="GitSpo Mentions" /&gt;&lt;/a&gt; &lt;a href="https://www.paypal.com/donate?hosted_button_id=RQ2V64LXSKPV4"&gt;&lt;img src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif" alt="paypal" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Fantasy-Premier-League&lt;/h1&gt; 
&lt;h1&gt;NOTICE&lt;/h1&gt; 
&lt;p&gt;This weekly updates for the repository have been stopped at the end of the 2024-25 season. NO weekly updates will be posted to this repository after the 2024-25 season.&lt;/p&gt; 
&lt;p&gt;Instead, there will be 3 major updates posted to this repository:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;One at the start of the season&lt;/li&gt; 
 &lt;li&gt;One at the end of the January transfer window&lt;/li&gt; 
 &lt;li&gt;One at the end of the season&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Description&lt;/h2&gt; 
&lt;p&gt;A FPL library that gets all the basic stats for each player, gw-specific data for each player and season history of each player&lt;/p&gt; 
&lt;h3&gt;How to CIte this dataset?&lt;/h3&gt; 
&lt;p&gt;BibTeX:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{anand2016fantasypremierleague,
  title = {{FPL Historical Dataset}},
  author = {Anand, Vaastav},
  year = {2022},
  howpublished = {Retrieved August 2022 from \url{https://github.com/vaastav/Fantasy-Premier-League/}}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Acknowledgement&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;rin-hairie for adding master team lists and merge scripts&lt;/li&gt; 
 &lt;li&gt;ergest for adding merged_gw.csv files for 2016-17 and 2017-18 seasons&lt;/li&gt; 
 &lt;li&gt;BDooley11 for providing top managers script&lt;/li&gt; 
 &lt;li&gt;speeder1987 for providing 2018/19 fixtures.csv file&lt;/li&gt; 
 &lt;li&gt;ravgeetdhillon for github actions automation for data update&lt;/li&gt; 
 &lt;li&gt;kz4killua for fixing GW37 data for the 21-22 season&lt;/li&gt; 
 &lt;li&gt;SaintJuniper for id-dictionary update for the 21-22 season&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Data Structure&lt;/h3&gt; 
&lt;p&gt;The data folder contains the data from past seasons as well as the current season. It is structured as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;season/cleaned_players.csv : The overview stats for the season&lt;/li&gt; 
 &lt;li&gt;season/gws/gw_number.csv : GW-specific stats for the particular season&lt;/li&gt; 
 &lt;li&gt;season/gws/merged_gws.csv : GW-by-GW stats for each player in a single file&lt;/li&gt; 
 &lt;li&gt;season/players/player_name/gws.csv : GW-by-GW stats for that specific player&lt;/li&gt; 
 &lt;li&gt;season/players/player_name/history.csv : Prior seasons history stats for that specific player.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Accessing the Data Directly in Python&lt;/h3&gt; 
&lt;p&gt;You can access data files within this repository programmatically using Python and the &lt;code&gt;pandas&lt;/code&gt; library. Below is an example using the &lt;code&gt;data/2023-24/gws/merged_gw.csv&lt;/code&gt; file. Similar methods can be applied to other data files in the repository. Note this is using the raw URL for direct file access, bypassing the GitHub UI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pandas as pd

# URL of the CSV file (example)
url = "https://raw.githubusercontent.com/vaastav/Fantasy-Premier-League/master/data/2023-24/gws/merged_gw.csv"

# Read the CSV file into a pandas DataFrame
df = pd.read_csv(url)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Player Position Data&lt;/h3&gt; 
&lt;p&gt;In players_raw.csv, element_type is the field that corresponds to the position. 1 = GK 2 = DEF 3 = MID 4 = FWD&lt;/p&gt; 
&lt;h3&gt;Errata&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;GW35 expected points data is wrong (all values are 0).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you feel like there is some data that is missing which you would like to see, then please feel free to create a PR or create an issue highlighting what is missing and what you would like to be added&lt;/li&gt; 
 &lt;li&gt;If you have access to old data (pre-2016) then please feel free to create Pull Requests adding the data to the repo or create an issue with links to old data and I will add them myself.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Using&lt;/h3&gt; 
&lt;p&gt;If you use data from here for your website or blog posts, then I would humbly request that you please add a link back to this repo as the data source (and I would in turn add a link to your post/site as a notable usage of this repo).&lt;/p&gt; 
&lt;h2&gt;Downloading Your Team Data&lt;/h2&gt; 
&lt;p&gt;You can download the data for your team by executing the following steps:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python teams_scraper.py &amp;lt;team_id&amp;gt;
#Eg: python teams_scraper.py 4582
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will create a new folder called "team_&amp;lt;team_id&amp;gt;_data18-19" with individual files of all the important data&lt;/p&gt; 
&lt;h1&gt;Notable Usages of this Repository&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/arcticdb/picking-the-ultimate-fantasy-premier-league-team-with-arcticdb-4ae31ff5d817"&gt;Picking the Ultimate Fantasy Premier League Team with ArcticDB by Matthew Simpson&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/arifpras/BelutListrik"&gt;Analysing Fantasy Premier League data in R Course by Arif P. Sulistiono&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/francescobarbara/FPL-point-predictor-via-random-forests"&gt;Point Predictor via Random Forests by Francesco Barbara&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.dtsquared.co.uk/money-football-how-will-our-virtual-football-team-selected-entirely-by-machine-learning-compete-in-the-big-leagues/"&gt;Money (Foot)Ball ‚Äì how will our virtual football team selected entirely by Machine Learning compete in the big leagues?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://towardsdatascience.com/an-introduction-to-sql-using-fpl-data-8314ec982308"&gt;An introduction to SQL using FPL data by Liam Connors&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://alpscode.com/blog/hindsight-optimization/"&gt;Hindsight Optimization for FPL by Sertalp B. Cay&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/the-sports-scientist/how-i-used-data-science-to-get-into-the-top-1-on-the-return-to-fantasy-premier-league-98829d4f65e5"&gt;Data Science to get top 1% on return to FPL by James Asher&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://www.fpldash.com"&gt;FPLDASH: A customizable Fantasy Premier League Dashboard by Jin Hyun Cheong&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.splunk.com/en_us/blog/machine-learning/how-to-win-at-fantasy-football-with-splunk-and-machine-learning-part-1.html"&gt;How to win at Fantasy Football with Splunk and Machine Learning by Rupert Truman&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=LzEuweGrHvc"&gt;2019-20 Winner Joshua Bull's Oxford Maths Public Lecture&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://twitter.com/theFPLkiwi/status/1297619700206239746?s=20"&gt;2019-20 Lottery Analysis by @theFPLKiwi&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.fantasynutmeg.com/history"&gt;Fantasy Nutmeg Website by code247&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/@2017csb1079/fantasy-premier-league-19-20-a-review-part-1-basics-167e610e229"&gt;Fantasy Premier League 19/20, a review by Hersh Dhillon&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/@erwindrarusli/visualisasi-data-fantasy-premier-league-19-20-a80aaf097a21"&gt;Visualisasi Data: Fantasy Premier League 19/20 by Erwindra Rusli&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://keytodatascience.com/fpl-machine-learning/"&gt;Machine Learning Model by pratz&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.reddit.com/r/FantasyPL/comments/erfdy1/a_plot_of_xg_vs_xa_for_for_attacking_midsforwards/"&gt;xA vs xG for Attacking Midfielders/Forwards by u/JLane1996&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.reddit.com/r/reddevils/comments/ecbn9j/corrected_plot_of_goals_vs_expected_goals_this/fba8vs3/"&gt;Expected Goals vs Actual Goals for Manchester United by u/JLane1996&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.reddit.com/r/tableau/comments/e2j0uq/my_first_tableu_viz_fpl/"&gt;Tableau Viz by u/richkelana&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.reddit.com/r/FantasyPL/comments/dz04hf/top_players_against_gw13_rival/"&gt;Top Players against GW13 rival by u/LiuSiuMing&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://mbarnfield.github.io/fpl.html"&gt;Captaincy Choice GW4 2019-20 post by Matthew Barnfield&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://www.didjfin.no/blog/fpl/fantasy-premier-league-data/"&gt;Building a dataset for Fantasy Premier League analysis by djfinnoy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://whogottheassist.com/value-in-fpl-2019-20-report/"&gt;Value in FPL 2019-20 Report by Who Got The Assist?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://whogottheassist.com/talisman-theory-part-one-2018-19-report/"&gt;Talisman Theory 2018-19 Report by Who Got The Assist?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://twitter.com/fplscrapR"&gt;Historical Analyses in fplscrapR by Rasmus Chrisentsen&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/@joseph.m.oconnor.88/linearly-optimising-fantasy-premier-league-teams-3b76e9694877"&gt;Linearly Optimising Fantasy Premier League Teams by Joseph O'Connor&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/@sol.paul/how-to-win-at-fantasy-premier-league-using-data-part-1-forecasting-with-deep-learning-bf121f38643a"&gt;How to Win at Fantasy Premier league using Deep learning by Paul Solomon&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://api.better-fpl.com/graphql"&gt;graphql API by u/jeppews&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/alsgregory/Fantasy-Football"&gt;FPL modeling and prediction by @alsgregory&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://fpl.co.id/tools/talismans/"&gt;FPL.co.id Talismans by @FPL_COID&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://twitter.com/neilswmurrayFPL/status/1147407501736009728"&gt;Leicester City Brendan Rodgers Impact Analysis on twitter by @neilswmurrayFPL&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://twitter.com/StatOnScout"&gt;Stat Analysis on twitter by @StatOnScout&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.linkedin.com/pulse/whoever-wins-2019-uefa-europe-league-final-still-ends-velko-kamenov/"&gt;Arsenal-Chelsea LinkedIn article by Velko Kamenov&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://towardsdatascience.com/mythbusting-fantasy-premier-league-form-over-fixtures-eecf9022e834"&gt;Form vs Fixture Medium article by JinHyunCheong&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.reddit.com/r/dataisbeautiful/comments/9zlx14/points_per_game_vs_predictability_after_12_weeks/"&gt;Visualization by u/dkattir&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.reddit.com/r/FantasyPL/comments/9bjwra/created_a_very_crude_and_basic_comparison_chart/"&gt;Visualization by u/Dray11&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://fantasy.elek.hr/"&gt;Visualization website by @antoniaelek&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/datacomics/building-an-fpl-captain-classifier-cf4ee343ebcc"&gt;FPL Captain Classifier by Raghunandh GS&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="http://vaastavanand.com/blog/"&gt;My Personal Blog&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://fpl.zoid.dev"&gt;FPL.zoid.dev - Query FPL data with SQL in your browser&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://fpl-pl-table.streamlit.app/"&gt;Premier League Table by FPL Points by Edward F&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://fpl-manager-medals.streamlit.app/"&gt;FPL Manager Medals by Edward F&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://fpl.infinitetrooper.com/"&gt;SiegFPL by @infinitetrooper&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>