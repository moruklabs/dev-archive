<rss version="2.0">
  <channel>
    <title>GitHub Rust Weekly Trending</title>
    <description>Weekly Trending of Rust in GitHub</description>
    <pubDate>Thu, 24 Jul 2025 01:43:18 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>Xerxes-2/clewdr</title>
      <link>https://github.com/Xerxes-2/clewdr</link>
      <description>&lt;p&gt;High Performance LLM Reverse Proxy&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/Xerxes-2/clewdr/master/assets/clewdr-logo.svg?sanitize=true" alt="ClewdR" height="60"&gt; 
 &lt;p&gt;&lt;em&gt;High-Performance LLM Proxy for the Modern Era&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://deepwiki.com/Xerxes-2/clewdr"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki"&gt;&lt;/a&gt; &lt;a href="https://github.com/Xerxes-2/clewdr/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/Xerxes-2/clewdr?style=for-the-badge&amp;amp;logo=github&amp;amp;color=blue" alt="GitHub Release"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Xerxes-2/clewdr/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/Xerxes-2/clewdr?style=for-the-badge&amp;amp;color=green" alt="License"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Xerxes-2/clewdr/master/#performance-metrics"&gt;&lt;img src="https://img.shields.io/badge/Performance-10x%20Faster-orange?style=for-the-badge" alt="Performance"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Xerxes-2/clewdr/master/#technical-architecture"&gt;&lt;img src="https://img.shields.io/badge/Memory-Single%20Digit%20MB-purple?style=for-the-badge" alt="Memory"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;üåç Language Support&lt;/h3&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/Xerxes-2/clewdr/master/README.md"&gt;&lt;strong&gt;üá∫üá∏ English&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Xerxes-2/clewdr/master/README_zh.md"&gt;&lt;strong&gt;üá®üá≥ ÁÆÄ‰Ωì‰∏≠Êñá&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;üéØ &lt;strong&gt;What is ClewdR?&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ClewdR&lt;/strong&gt; is a production-grade, high-performance proxy server engineered specifically for &lt;strong&gt;Claude&lt;/strong&gt; (Claude.ai, Claude Code) and &lt;strong&gt;Google Gemini&lt;/strong&gt; (AI Studio, Vertex AI). Built with &lt;strong&gt;Rust&lt;/strong&gt; for maximum performance and minimal resource usage, it provides enterprise-level reliability with consumer-friendly simplicity.&lt;/p&gt; 
&lt;h3&gt;üèÜ &lt;strong&gt;Why ClewdR?&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üöÑ 10x Performance&lt;/strong&gt;: Outperforms script-language implementations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíæ 1/10th Memory&lt;/strong&gt;: Uses only single-digit MB in production&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Production Ready&lt;/strong&gt;: Handles thousands of requests per second&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Multi-Platform&lt;/strong&gt;: Native support for Windows, macOS, Linux, Android&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ú® &lt;strong&gt;Core Features&lt;/strong&gt;&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;üé® &lt;strong&gt;Full-Featured Web Interface&lt;/strong&gt;&lt;/h3&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;React-powered dashboard&lt;/strong&gt; with real-time monitoring&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Multi-language support&lt;/strong&gt; (English/Chinese)&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Secure authentication&lt;/strong&gt; with auto-generated passwords&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Hot configuration reload&lt;/strong&gt; without service interruption&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Visual cookie &amp;amp; key management&lt;/strong&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;h3&gt;üèóÔ∏è &lt;strong&gt;Enterprise Architecture&lt;/strong&gt;&lt;/h3&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;Tokio + Axum&lt;/strong&gt; async runtime for maximum throughput&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Event-driven design&lt;/strong&gt; with decoupled components&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Moka-powered caching&lt;/strong&gt; with intelligent invalidation&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Chrome-level fingerprinting&lt;/strong&gt; for seamless API access&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Multi-threaded processing&lt;/strong&gt; with optimal resource usage&lt;/li&gt; 
    &lt;/ul&gt; &lt;h3&gt;üß† &lt;strong&gt;Intelligent Resource Management&lt;/strong&gt;&lt;/h3&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;Smart cookie rotation&lt;/strong&gt; with status classification&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;API key health monitoring&lt;/strong&gt; and automatic failover&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;Rate limiting protection&lt;/strong&gt; with exponential backoff&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;Connection pooling&lt;/strong&gt; with keep-alive optimization&lt;/p&gt; &lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
   &lt;td width="50%"&gt;   &lt;h3&gt;üåç &lt;strong&gt;Universal Compatibility&lt;/strong&gt;&lt;/h3&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;Static compilation&lt;/strong&gt; - single binary, zero dependencies&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Cross-platform native&lt;/strong&gt; - Windows, macOS, Linux, Android&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Docker ready&lt;/strong&gt; with optimized images&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Reverse proxy friendly&lt;/strong&gt; with custom endpoint support&lt;/li&gt; 
    &lt;/ul&gt; &lt;h3&gt;üöÄ &lt;strong&gt;Protocol Support&lt;/strong&gt;&lt;/h3&gt; &lt;h4&gt;&lt;strong&gt;Claude Integration&lt;/strong&gt;&lt;/h4&gt; 
    &lt;ul&gt; 
     &lt;li&gt;‚úÖ &lt;strong&gt;Claude.ai&lt;/strong&gt; web interface&lt;/li&gt; 
     &lt;li&gt;‚úÖ &lt;strong&gt;Claude Code&lt;/strong&gt; specialized support&lt;/li&gt; 
     &lt;li&gt;‚úÖ &lt;strong&gt;System prompt caching&lt;/strong&gt; for efficiency&lt;/li&gt; 
     &lt;li&gt;‚úÖ &lt;strong&gt;Extended Thinking&lt;/strong&gt; mode&lt;/li&gt; 
     &lt;li&gt;‚úÖ &lt;strong&gt;Image attachments&lt;/strong&gt; &amp;amp; web search&lt;/li&gt; 
     &lt;li&gt;‚úÖ &lt;strong&gt;Custom stop sequences&lt;/strong&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;h4&gt;&lt;strong&gt;Google Gemini Integration&lt;/strong&gt;&lt;/h4&gt; 
    &lt;ul&gt; 
     &lt;li&gt;‚úÖ &lt;strong&gt;AI Studio&lt;/strong&gt; &amp;amp; &lt;strong&gt;Vertex AI&lt;/strong&gt;&lt;/li&gt; 
     &lt;li&gt;‚úÖ &lt;strong&gt;OAuth2 authentication&lt;/strong&gt; for Vertex&lt;/li&gt; 
     &lt;li&gt;‚úÖ &lt;strong&gt;HTTP Keep-Alive&lt;/strong&gt; optimization&lt;/li&gt; 
     &lt;li&gt;‚úÖ &lt;strong&gt;Model switching&lt;/strong&gt; with automatic detection&lt;/li&gt; 
    &lt;/ul&gt; &lt;h4&gt;&lt;strong&gt;API Compatibility&lt;/strong&gt;&lt;/h4&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;‚úÖ &lt;strong&gt;OpenAI format&lt;/strong&gt; - drop-in replacement&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;‚úÖ &lt;strong&gt;Native formats&lt;/strong&gt; - Claude &amp;amp; Gemini&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;‚úÖ &lt;strong&gt;Streaming responses&lt;/strong&gt; with real-time processing&lt;/p&gt; &lt;/li&gt;
    &lt;/ul&gt;&lt;/td&gt; 
  &lt;/tr&gt;   
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;üìä &lt;strong&gt;Performance Metrics&lt;/strong&gt;&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Metric&lt;/th&gt; 
    &lt;th&gt;ClewdR&lt;/th&gt; 
    &lt;th&gt;Traditional Proxies&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Memory Usage&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;&amp;lt;10 MB&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;100-500 MB&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Requests/sec&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1000+&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;100-200&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Startup Time&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;&amp;lt;1 second&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;5-15 seconds&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Binary Size&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;~15 MB&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;50-200 MB&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Dependencies&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;Zero&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;Node.js/Python + libs&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;üöÄ &lt;strong&gt;Quick Start Guide&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;Step 1: Download &amp;amp; Run&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download the latest release for your platform
wget https://github.com/Xerxes-2/clewdr/releases/latest/download/clewdr-[platform]

# Extract the binary (if necessary)
tar -xzf clewdr-[platform].tar.gz

# Navigate to the directory
cd clewdr-[platform]

# Make executable (Linux/macOS)
chmod +x clewdr

# Run ClewdR
./clewdr
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;üì¶ &lt;strong&gt;Platform Downloads&lt;/strong&gt;&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Platform&lt;/th&gt; 
    &lt;th&gt;Architecture&lt;/th&gt; 
    &lt;th&gt;Download Link&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;ü™ü Windows&lt;/td&gt; 
    &lt;td&gt;x64&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/Xerxes-2/clewdr/releases/latest"&gt;clewdr-windows-x64.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üêß Linux&lt;/td&gt; 
    &lt;td&gt;x64&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/Xerxes-2/clewdr/releases/latest"&gt;clewdr-linux-x64&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üêß Linux&lt;/td&gt; 
    &lt;td&gt;ARM64&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/Xerxes-2/clewdr/releases/latest"&gt;clewdr-linux-arm64&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üçé macOS&lt;/td&gt; 
    &lt;td&gt;x64&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/Xerxes-2/clewdr/releases/latest"&gt;clewdr-macos-x64&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;üçé macOS&lt;/td&gt; 
    &lt;td&gt;ARM64 (M1/M2)&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/Xerxes-2/clewdr/releases/latest"&gt;clewdr-macos-arm64&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;ü§ñ Android&lt;/td&gt; 
    &lt;td&gt;ARM64&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/Xerxes-2/clewdr/releases/latest"&gt;clewdr-android-arm64&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;Step 2: Access Web Interface&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;üåê Open your browser to &lt;strong&gt;&lt;code&gt;http://127.0.0.1:8484&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;üîê Use the &lt;strong&gt;Web Admin Password&lt;/strong&gt; displayed in the console&lt;/li&gt; 
 &lt;li&gt;üéâ Welcome to ClewdR's management interface!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Pro Tips:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Forgot password?&lt;/strong&gt; Delete &lt;code&gt;clewdr.toml&lt;/code&gt; and restart&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Docker users:&lt;/strong&gt; Password appears in container logs&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Change password:&lt;/strong&gt; Use the web interface settings&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;Step 3: Configure Your Services&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h4&gt;üçÉ &lt;strong&gt;Claude Setup&lt;/strong&gt;&lt;/h4&gt; 
    &lt;ol&gt; 
     &lt;li&gt;&lt;strong&gt;Add Cookies&lt;/strong&gt;: Paste your Claude.ai session cookies&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Configure Proxy&lt;/strong&gt;: Set upstream proxy if needed&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Test Connection&lt;/strong&gt;: Verify cookie status in dashboard&lt;/li&gt; 
    &lt;/ol&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h4&gt;üîπ &lt;strong&gt;Gemini Setup&lt;/strong&gt;&lt;/h4&gt; 
    &lt;ol&gt; 
     &lt;li&gt;&lt;strong&gt;Add API Keys&lt;/strong&gt;: Input your Google AI Studio keys&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Vertex AI&lt;/strong&gt; (Optional): Configure OAuth2 for enterprise&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Model Selection&lt;/strong&gt;: Choose your preferred models&lt;/li&gt; 
    &lt;/ol&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;&lt;strong&gt;Step 4: Connect Your Applications&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;ClewdR provides multiple API endpoints. Check the console output for available endpoints:&lt;/p&gt; 
&lt;h4&gt;üîó &lt;strong&gt;API Endpoints&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Claude Endpoints
Claude Web:    http://127.0.0.1:8484/v1/messages          # Native format
Claude OpenAI: http://127.0.0.1:8484/v1/chat/completions  # OpenAI compatible
Claude Code:   http://127.0.0.1:8484/code/v1/messages     # Claude Code

# Gemini Endpoints  
Gemini Native: http://127.0.0.1:8484/v1/v1beta/generateContent    # Native format
Gemini OpenAI: http://127.0.0.1:8484/gemini/chat/completions      # OpenAI compatible
Vertex AI:     http://127.0.0.1:8484/v1/vertex/v1beta/            # Vertex AI
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚öôÔ∏è &lt;strong&gt;Application Configuration Examples&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;SillyTavern Configuration&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "api_url": "http://127.0.0.1:8484/v1/chat/completions",
  "api_key": "your-api-password-from-console",
  "model": "claude-3-sonnet-20240229"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Continue VSCode Extension&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "models": [
    {
      "title": "Claude via ClewdR",
      "provider": "openai",
      "model": "claude-3-sonnet-20240229",
      "apiBase": "http://127.0.0.1:8484/v1/",
      "apiKey": "your-api-password-from-console"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Cursor IDE Configuration&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "openaiApiBase": "http://127.0.0.1:8484/v1/",
  "openaiApiKey": "your-api-password-from-console"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;Step 5: Verify &amp;amp; Monitor&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Check cookie/key status in the web dashboard&lt;/li&gt; 
 &lt;li&gt;‚úÖ Monitor request logs for successful connections&lt;/li&gt; 
 &lt;li&gt;‚úÖ Test with a simple chat request&lt;/li&gt; 
 &lt;li&gt;‚úÖ Enjoy blazing-fast LLM proxy performance!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community Resources&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Github Aggregated Wiki&lt;/strong&gt;: &lt;a href="https://github.com/Xerxes-2/clewdr/wiki"&gt;https://github.com/Xerxes-2/clewdr/wiki&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/teralomaniac/clewd"&gt;Clewd Modified Version&lt;/a&gt; - A modified version of the original Clewd, providing many inspirations and foundational features.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mirrorange/clove"&gt;Clove&lt;/a&gt; - Provides the support logic for Claude Code.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>paradedb/paradedb</title>
      <link>https://github.com/paradedb/paradedb</link>
      <description>&lt;p&gt;ParadeDB is a modern Elasticsearch alternative built on Postgres. Built for real-time, update-heavy workloads.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://paradedb.com"&gt;&lt;img src="https://raw.githubusercontent.com/paradedb/paradedb/main/docs/logo/readme.svg?sanitize=true" alt="ParadeDB"&gt;&lt;/a&gt; &lt;br&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;b&gt;Postgres for Search and Analytics&lt;/b&gt;&lt;br&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; &lt;a href="https://paradedb.com"&gt;Website&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.paradedb.com"&gt;Docs&lt;/a&gt; ‚Ä¢ &lt;a href="https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw"&gt;Community&lt;/a&gt; ‚Ä¢ &lt;a href="https://paradedb.com/blog/"&gt;Blog&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.paradedb.com/changelog/"&gt;Changelog&lt;/a&gt; &lt;/h3&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;a href="https://artifacthub.io/packages/search?repo=paradedb"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/paradedb" alt="Artifact Hub"&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/paradedb/paradedb"&gt;&lt;img src="https://img.shields.io/docker/pulls/paradedb/paradedb" alt="Docker Pulls"&gt;&lt;/a&gt; &lt;a href="https://github.com/paradedb/paradedb?tab=AGPL-3.0-1-ov-file#readme"&gt;&lt;img src="https://img.shields.io/github/license/paradedb/paradedb?color=blue" alt="License"&gt;&lt;/a&gt; &lt;a href="https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw"&gt;&lt;img src="https://img.shields.io/badge/Join%20Slack-purple?logo=slack&amp;amp;link=https%3A%2F%2Fjoin.slack.com%2Ft%2Fparadedbcommunity%2Fshared_invite%2Fzt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw" alt="Slack URL"&gt;&lt;/a&gt; &lt;a href="https://x.com/paradedb"&gt;&lt;img src="https://img.shields.io/twitter/url?url=https%3A%2F%2Ftwitter.com%2Fparadedb&amp;amp;label=Follow%20%40paradedb" alt="X URL"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://paradedb.com"&gt;ParadeDB&lt;/a&gt; is a modern Elasticsearch alternative built on Postgres. Built for real-time, update-heavy workloads.&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;Please see our &lt;a href="https://docs.paradedb.com"&gt;documentation&lt;/a&gt; to get started. You'll also find our &lt;a href="https://docs.paradedb.com/welcome/architecture"&gt;architecture&lt;/a&gt; docs and &lt;a href="https://docs.paradedb.com/welcome/roadmap"&gt;public roadmap&lt;/a&gt; there.&lt;/p&gt; 
&lt;h2&gt;Deploying ParadeDB&lt;/h2&gt; 
&lt;p&gt;ParadeDB and its extensions can be deployed in one of two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker image based on &lt;a href="https://hub.docker.com/_/postgres"&gt;Postgres&lt;/a&gt; (&lt;a href="https://docs.paradedb.com/deploy/aws"&gt;see deployment instructions&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Kubernetes Helm chart based on &lt;a href="https://artifacthub.io/packages/helm/cloudnative-pg/cloudnative-pg"&gt;CloudNativePG&lt;/a&gt; (&lt;a href="https://docs.paradedb.com/deploy/helm"&gt;see deployment instructions&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information, including enterprise features and support, please &lt;a href="mailto:sales@paradedb.com"&gt;contact us by email&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Extensions&lt;/h3&gt; 
&lt;p&gt;You can find prebuilt binaries for the ParadeDB Postgres extensions on Debian 11, 12, Ubuntu 22.04 and 24.04, Red Hat Enterprise Linux 8 and 9, and macOS 14 (Sonoma) and 15 (Sequoia) for Postgres 14+ in the &lt;a href="https://github.com/paradedb/paradedb/releases/latest"&gt;GitHub Releases&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;ParadeDB supports all versions supported by the PostgreSQL Global Development Group, which includes PostgreSQL 14+, and you can compile the extensions for other versions of Postgres by following the instructions in the respective extension's README.&lt;/p&gt; 
&lt;h3&gt;Docker Image&lt;/h3&gt; 
&lt;p&gt;To quickly get a ParadeDB instance up and running, simply pull and run the latest Docker image:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --name paradedb -e POSTGRES_PASSWORD=password paradedb/paradedb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will start a ParadeDB instance with default user &lt;code&gt;postgres&lt;/code&gt; and password &lt;code&gt;password&lt;/code&gt;. You can then connect to the database using &lt;code&gt;psql&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec -it paradedb psql -U postgres
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install ParadeDB locally or on-premise, we recommend using our &lt;code&gt;docker-compose.yml&lt;/code&gt; file. Alternatively, you can pass the appropriate environment variables to the &lt;code&gt;docker run&lt;/code&gt; command, replacing the &amp;lt;&amp;gt; with your desired values:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run \
  --name paradedb \
  -e POSTGRES_USER=&amp;lt;user&amp;gt; \
  -e POSTGRES_PASSWORD=&amp;lt;password&amp;gt; \
  -e POSTGRES_DB=&amp;lt;dbname&amp;gt; \
  -v paradedb_data:/var/lib/postgresql/data/ \
  -p 5432:5432 \
  -d \
  paradedb/paradedb:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will start a ParadeDB instance with non-root user &lt;code&gt;&amp;lt;user&amp;gt;&lt;/code&gt; and password &lt;code&gt;&amp;lt;password&amp;gt;&lt;/code&gt;. The &lt;code&gt;-v&lt;/code&gt; flag enables your ParadeDB data to persist across restarts in a Docker volume named &lt;code&gt;paradedb_data&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can then connect to the database using &lt;code&gt;psql&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec -it paradedb psql -U &amp;lt;user&amp;gt; -d &amp;lt;dbname&amp;gt; -p 5432 -W
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Helm Chart&lt;/h3&gt; 
&lt;p&gt;ParadeDB is also available for Kubernetes via our Helm chart. You can find our Helm chart in the &lt;a href="https://github.com/paradedb/charts"&gt;ParadeDB Helm Chart GitHub repository&lt;/a&gt; or download it directly from &lt;a href="https://artifacthub.io/packages/helm/paradedb/paradedb"&gt;Artifact Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;ParadeDB Cloud&lt;/h3&gt; 
&lt;p&gt;At the moment, ParadeDB is not available as a managed cloud service. If you are interested in a ParadeDB Cloud service, please let us know by joining our &lt;a href="https://form.typeform.com/to/jHkLmIzx"&gt;waitlist&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;If you're missing a feature or have found a bug, please open a &lt;a href="https://github.com/paradedb/paradedb/issues/new/choose"&gt;GitHub Issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To get community support, you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Post a question in the &lt;a href="https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw"&gt;ParadeDB Slack Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ask for help on our &lt;a href="https://github.com/paradedb/paradedb/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you need commercial support, please &lt;a href="mailto:sales@paradedb.com"&gt;contact the ParadeDB team&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions, big or small, and are here to guide you along the way. To get started contributing, check our &lt;a href="https://github.com/paradedb/paradedb/labels/good%20first%20issue"&gt;first timer issues&lt;/a&gt; or message us in the &lt;a href="https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw"&gt;ParadeDB Community Slack&lt;/a&gt;. Once you contribute, ping us in Slack and we'll send you some ParadeDB swag!&lt;/p&gt; 
&lt;p&gt;For more information on how to contribute, please see our &lt;a href="https://raw.githubusercontent.com/paradedb/paradedb/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project is released with a &lt;a href="https://raw.githubusercontent.com/paradedb/paradedb/main/CODE_OF_CONDUCT.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project, you agree to follow its terms.&lt;/p&gt; 
&lt;p&gt;Thank you for helping us make ParadeDB better for everyone &lt;span&gt;‚ù§Ô∏è&lt;/span&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;ParadeDB is licensed under the &lt;a href="https://raw.githubusercontent.com/paradedb/paradedb/main/LICENSE"&gt;GNU Affero General Public License v3.0&lt;/a&gt; and as commercial software. For commercial licensing, please contact us at &lt;a href="mailto:sales@paradedb.com"&gt;sales@paradedb.com&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>antinomyhq/forge</title>
      <link>https://github.com/antinomyhq/forge</link>
      <description>&lt;p&gt;AI enabled pair programmer for Claude, GPT, O Series, Grok, Deepseek, Gemini and 300+ models&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;‚öíÔ∏è Forge: AI-Enhanced Terminal Development Environment&lt;/h1&gt; 
&lt;p align="center"&gt;A comprehensive coding agent that integrates AI capabilities with your development environment&lt;/p&gt; 
&lt;p align="center"&gt;&lt;code&gt;npx forgecode@latest&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/antinomyhq/forge/actions"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/antinomyhq/forge/ci.yml?style=for-the-badge" alt="CI Status"&gt;&lt;/a&gt; &lt;a href="https://github.com/antinomyhq/forge/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/antinomyhq/forge?style=for-the-badge" alt="GitHub Release"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/kRZBPpkgwq"&gt;&lt;img src="https://img.shields.io/discord/1044859667798568962?style=for-the-badge&amp;amp;cacheSeconds=120&amp;amp;logo=discord" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://cla-assistant.io/antinomyhq/forge"&gt;&lt;img src="https://cla-assistant.io/readme/badge/antinomyhq/forge?style=for-the-badge" alt="CLA assistant"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://assets.antinomy.ai/images/forge_demo_2x.gif" alt="Code-Forge Demo"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Table&amp;nbsp;of&amp;nbsp;Contents&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#quickstart"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#usage-examples"&gt;Usage Examples&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#why-forge"&gt;Why Forge?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#command-line-options"&gt;Command-Line Options&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#advanced-configuration"&gt;Advanced Configuration&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#provider-configuration"&gt;Provider Configuration&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#forgeyaml-configuration-options"&gt;forge.yaml Configuration Options&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#mcp-configuration"&gt;MCP Configuration&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#example-use-cases"&gt;Example Use Cases&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#usage-in-multi-agent-workflows"&gt;Usage in Multi-Agent Workflows&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#community"&gt;Community&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antinomyhq/forge/main/#support-us"&gt;Support Us&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Run Forge in interactive mode via npx&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx forgecode@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Connect through the Forge app and complete the OAuth process. This will open your browser to app.forgecode.dev where you can sign up or sign in with Google/GitHub.&lt;/p&gt; 
&lt;p&gt;That's it! Forge is now ready to assist you with your development tasks.&lt;/p&gt; 
&lt;h2&gt;Usage Examples&lt;/h2&gt; 
&lt;p&gt;Forge can be used in different ways depending on your needs. Here are some common usage patterns:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Code Understanding&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;&amp;gt; Can you explain how the authentication system works in this codebase?
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Forge will analyze your project's structure, identify authentication-related files, and provide a detailed explanation of the authentication flow, including the relationships between different components.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Implementing New Features&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;&amp;gt; I need to add a dark mode toggle to our React application. How should I approach this?
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Forge will suggest the best approach based on your current codebase, explain the steps needed, and even scaffold the necessary components and styles for you.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Debugging Assistance&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;&amp;gt; I'm getting this error: "TypeError: Cannot read property 'map' of undefined". What might be causing it?
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Forge will analyze the error, suggest potential causes based on your code, and propose different solutions to fix the issue.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Code Reviews&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;&amp;gt; Please review the code in src/components/UserProfile.js and suggest improvements
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Forge will analyze the code, identify potential issues, and suggest improvements for readability, performance, security, and maintainability.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Learning New Technologies&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;&amp;gt; I want to integrate GraphQL into this Express application. Can you explain how to get started?
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Forge will provide a tailored tutorial on integrating GraphQL with Express, using your specific project structure as context.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Database Schema Design&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;&amp;gt; I need to design a database schema for a blog with users, posts, comments, and categories
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Forge will suggest an appropriate schema design, including tables/collections, relationships, indexes, and constraints based on your project's existing database technology.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Refactoring Legacy Code&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;&amp;gt; Help me refactor this class-based component to use React Hooks
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Forge can help modernize your codebase by walking you through refactoring steps and implementing them with your approval.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Git Operations&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;&amp;gt; I need to merge branch 'feature/user-profile' into main but there are conflicts
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Forge can guide you through resolving git conflicts, explaining the differences and suggesting the best way to reconcile them.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Why Forge?&lt;/h2&gt; 
&lt;p&gt;Forge is designed for developers who want to enhance their workflow with AI assistance while maintaining full control over their development environment.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero configuration&lt;/strong&gt; - Just add your API key and you're ready to go&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless integration&lt;/strong&gt; - Works right in your terminal, where you already work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-provider support&lt;/strong&gt; - Use OpenAI, Anthropic, or other LLM providers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Secure by design&lt;/strong&gt; - Your code stays on your machine&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open-source&lt;/strong&gt; - Transparent, extensible, and community-driven&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Forge helps you code faster, solve complex problems, and learn new technologies without leaving your terminal.&lt;/p&gt; 
&lt;h2&gt;Command-Line Options&lt;/h2&gt; 
&lt;p&gt;Here's a quick reference of Forge's command-line options:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Option&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-p, --prompt &amp;lt;PROMPT&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Direct prompt to process without entering interactive mode&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-c, --command &amp;lt;COMMAND&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to a file containing initial commands to execute&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-w, --workflow &amp;lt;WORKFLOW&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to a file containing the workflow to execute&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-e, --event &amp;lt;EVENT&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dispatch an event to the workflow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--conversation &amp;lt;CONVERSATION&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Path to a file containing the conversation to execute&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-r, --restricted&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable restricted shell mode for enhanced security&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--verbose&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Enable verbose output mode&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-h, --help&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Print help information&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-V, --version&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Print version&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Advanced Configuration&lt;/h2&gt; 
&lt;h3&gt;Provider Configuration&lt;/h3&gt; 
&lt;p&gt;Forge supports multiple AI providers. Below are setup instructions for each supported provider:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;forgecode.dev (Recommended)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# .env
FORGE_KEY=ForgeKey
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To use Forgecode's provider with Forge:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Visit &lt;a href="https://app.forgecode.dev/"&gt;https://app.forgecode.dev/&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Login with your existing credentials or create a new account&lt;/li&gt; 
  &lt;li&gt;Once logged in, your account will automatically enable the Forge Provider&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;em&gt;No changes in &lt;code&gt;forge.yaml&lt;/code&gt; required&lt;/em&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;OpenRouter&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# .env
OPENROUTER_API_KEY=&amp;lt;your_openrouter_api_key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;em&gt;No changes in &lt;code&gt;forge.yaml&lt;/code&gt; required&lt;/em&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Requesty&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# .env
REQUESTY_API_KEY=&amp;lt;your_requesty_api_key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;em&gt;No changes in &lt;code&gt;forge.yaml&lt;/code&gt; required&lt;/em&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;x-ai&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# .env
XAI_API_KEY=&amp;lt;your_xai_api_key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;switch the model using &lt;code&gt;/model&lt;/code&gt; command in the Forge CLI.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# .env
OPENAI_API_KEY=&amp;lt;your_openai_api_key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
model: o3-mini-high
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# .env
ANTHROPIC_API_KEY=&amp;lt;your_anthropic_api_key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
model: claude-3.7-sonnet
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Google Vertex AI&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# .env
PROJECT_ID=&amp;lt;your_project_id&amp;gt;
LOCATION=&amp;lt;your_location&amp;gt;
OPENAI_API_KEY=&amp;lt;vertex_ai_key&amp;gt;
OPENAI_URL=https://${LOCATION}-aiplatform.googleapis.com/v1beta1/projects/${PROJECT_ID}/locations/${LOCATION}/endpoints/openapi
&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
model: publishers/anthropic/models/claude-3-7-sonnet
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;OpenAI-Compatible Providers&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# .env
OPENAI_API_KEY=&amp;lt;your_provider_api_key&amp;gt;
OPENAI_URL=&amp;lt;your_provider_url&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
model: &amp;lt;provider-specific-model&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Groq&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# .env
OPENAI_API_KEY=&amp;lt;your_groq_api_key&amp;gt;
OPENAI_URL=https://api.groq.com/openai/v1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
model: deepseek-r1-distill-llama-70b
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Amazon Bedrock&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;To use Amazon Bedrock models with Forge, you'll need to first set up the &lt;a href="https://github.com/aws-samples/bedrock-access-gateway"&gt;Bedrock Access Gateway&lt;/a&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Set up Bedrock Access Gateway&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Follow the deployment steps in the &lt;a href="https://github.com/aws-samples/bedrock-access-gateway"&gt;Bedrock Access Gateway repo&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Create your own API key in Secrets Manager&lt;/li&gt; 
    &lt;li&gt;Deploy the CloudFormation stack&lt;/li&gt; 
    &lt;li&gt;Note your API Base URL from the CloudFormation outputs&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Create these files in your project directory&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# .env
OPENAI_API_KEY=&amp;lt;your_bedrock_gateway_api_key&amp;gt;
OPENAI_URL=&amp;lt;your_bedrock_gateway_base_url&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
model: anthropic.claude-3-opus
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt;
 &lt;/ol&gt;
&lt;/details&gt;   
&lt;h3&gt;forge.yaml Configuration Options&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;forge.yaml&lt;/code&gt; file supports several advanced configuration options that let you customize Forge's behavior.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Custom Rules&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Add your own guidelines that all agents should follow when generating responses.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
custom_rules: |
  1. Always add comprehensive error handling to any code you write.
  2. Include unit tests for all new functions.
  3. Follow our team's naming convention: camelCase for variables, PascalCase for classes.
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Commands&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Define custom commands as shortcuts for repetitive prompts:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
commands:
  - name: 'refactor'
    description: 'Refactor selected code'
    prompt: 'Please refactor this code to improve readability and performance'
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Specify the default AI model to use for all agents in the workflow.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
model: 'claude-3.7-sonnet'
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Max Walker Depth&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Control how deeply Forge traverses your project directory structure when gathering context.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
max_walker_depth: 3 # Limit directory traversal to 3 levels deep
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Temperature&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Adjust the creativity and randomness in AI responses. Lower values (0.0-0.3) produce more focused, deterministic outputs, while higher values (0.7-2.0) generate more diverse and creative results.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
temperature: 0.7 # Balanced creativity and focus
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Tool Max Failure Limit&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Control how many times a tool can fail before Forge forces completion to prevent infinite retry loops. This helps avoid situations where an agent gets stuck repeatedly trying the same failing operation.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
max_tool_failure_per_turn: 3 # Allow up to 3 failures per tool before forcing completion
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Set to a higher value if you want more retry attempts, or lower if you want faster failure detection.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Max Requests Per Turn&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Limit the maximum number of requests an agent can make in a single conversation turn. This prevents runaway conversations and helps control API usage and costs.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-yaml"&gt;# forge.yaml
max_requests_per_turn: 50 # Allow up to 50 requests per turn
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;When this limit is reached, Forge will:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Ask you if you wish to continue&lt;/li&gt; 
  &lt;li&gt;If you respond with 'Yes', it will continue the conversation&lt;/li&gt; 
  &lt;li&gt;If you respond with 'No', it will end the conversation&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;The MCP feature allows AI agents to communicate with external tools and services. This implementation follows Anthropic's &lt;a href="https://docs.anthropic.com/en/docs/claude-code/tutorials#set-up-model-context-protocol-mcp"&gt;Model Context Protocol&lt;/a&gt; design.&lt;/p&gt; 
 &lt;h3&gt;MCP Configuration&lt;/h3&gt; 
 &lt;p&gt;Configure MCP servers using the CLI:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# List all MCP servers
forge mcp list

# Add a new server
forge mcp add

# Add a server using JSON format
forge mcp add-json

# Get server details
forge mcp get

# Remove a server
forge mcp remove
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Or manually create a &lt;code&gt;.mcp.json&lt;/code&gt; file with the following structure:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
	"mcpServers": {
		"server_name": {
			"command": "command_to_execute",
			"args": ["arg1", "arg2"],
			"env": { "ENV_VAR": "value" }
		},
		"another_server": {
			"url": "http://localhost:3000/events"
		}
	}
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;MCP configurations are read from two locations (in order of precedence):&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Local configuration (project-specific)&lt;/li&gt; 
  &lt;li&gt;User configuration (user-specific)&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;Example Use Cases&lt;/h3&gt; 
 &lt;p&gt;MCP can be used for various integrations:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Web browser automation&lt;/li&gt; 
  &lt;li&gt;External API interactions&lt;/li&gt; 
  &lt;li&gt;Tool integration&lt;/li&gt; 
  &lt;li&gt;Custom service connections&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Usage in Multi-Agent Workflows&lt;/h3&gt; 
 &lt;p&gt;MCP tools can be used as part of multi-agent workflows, allowing specialized agents to interact with external systems as part of a collaborative problem-solving approach.&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For comprehensive documentation on all features and capabilities, please visit the &lt;a href="https://github.com/antinomyhq/forge/tree/main/docs"&gt;documentation site&lt;/a&gt;.&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our vibrant Discord community to connect with other Forge users and contributors, get help with your projects, share ideas, and provide feedback!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/kRZBPpkgwq"&gt;&lt;img src="https://img.shields.io/discord/1044859667798568962?style=for-the-badge&amp;amp;cacheSeconds=120&amp;amp;logo=discord" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;Support Us&lt;/h2&gt; 
&lt;p&gt;Your support drives Forge's continued evolution! By starring our GitHub repository, you:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Help others discover this powerful tool üîç&lt;/li&gt; 
 &lt;li&gt;Motivate our development team üí™&lt;/li&gt; 
 &lt;li&gt;Enable us to prioritize new features üõ†Ô∏è&lt;/li&gt; 
 &lt;li&gt;Strengthen our open-source community üå±&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ankitects/anki</title>
      <link>https://github.com/ankitects/anki</link>
      <description>&lt;p&gt;Anki is a smart spaced repetition flashcard program&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Anki¬Æ&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://buildkite.com/ankitects/anki-ci"&gt;&lt;img src="https://badge.buildkite.com/c9edf020a4aec976f9835e54751cc5409d843adbb66d043bd3.svg?branch=main" alt="Build status"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repo contains the source code for the computer version of &lt;a href="https://apps.ankiweb.net"&gt;Anki&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;About&lt;/h1&gt; 
&lt;p&gt;Anki is a spaced repetition program. Please see the &lt;a href="https://apps.ankiweb.net"&gt;website&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h1&gt;Getting Started&lt;/h1&gt; 
&lt;h3&gt;Anki Betas&lt;/h3&gt; 
&lt;p&gt;If you'd like to try development builds of Anki but don't feel comfortable building the code, please see &lt;a href="https://betas.ankiweb.net/"&gt;Anki betas&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Developing&lt;/h3&gt; 
&lt;p&gt;For more information on building and developing, please see &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/docs/development.md"&gt;Development&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Want to contribute to Anki? Check out the &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/docs/contributing.md"&gt;Contribution Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Anki Contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/CONTRIBUTORS"&gt;CONTRIBUTORS&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Anki's license: &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>raphamorim/rio</title>
      <link>https://github.com/raphamorim/rio</link>
      <description>&lt;p&gt;A hardware-accelerated GPU terminal emulator focusing to run in desktops and browsers.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt; &lt;p align="center"&gt; &lt;img src="https://rioterm.com/assets/rio-logo.png" alt="Rio terminal logo" width="128"&gt; &lt;br&gt;Rio Terminal &lt;/p&gt;&lt;/h1&gt; 
&lt;p align="center"&gt; Rio is a modern terminal built to run everywhere. &lt;br&gt; &lt;a href="https://raw.githubusercontent.com/raphamorim/rio/main/#about"&gt;About&lt;/a&gt; ¬∑ &lt;a href="https://rioterm.com/docs/install"&gt;Install&lt;/a&gt; ¬∑ &lt;a href="https://rioterm.com/docs/config"&gt;Config&lt;/a&gt; ¬∑ &lt;a href="https://rioterm.com/docs/releases"&gt;Changelog&lt;/a&gt; ¬∑ &lt;a href="https://github.com/sponsors/raphamorim"&gt;Sponsor&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Development Notice&lt;/strong&gt;: We are currently in the process of releasing Rio 0.3.0, which includes major performance improvements and architectural changes. The main branch is under active development and may be unstable. For stable usage, please use the &lt;a href="https://github.com/raphamorim/rio/releases"&gt;latest release&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;Documentation: &lt;a href="https://rioterm.com"&gt;https://rioterm.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you are using or want to help in any way please consider to donate via &lt;a href="https://github.com/sponsors/raphamorim"&gt;Github Sponsors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Rio would not be possible without &lt;a href="https://github.com/alacritty/alacritty/"&gt;Alacritty&lt;/a&gt;, since a lot of Rio functionalities (e.g: ANSI parser, events, processor) was originally written (and still uses a good amount) of Alacritty code.&lt;/p&gt; 
&lt;h2&gt;Supporting the Project&lt;/h2&gt; 
&lt;p&gt;If you use and like Rio, please consider sponsoring it: your support helps to cover the fees required to maintain the project and to validate the time spent working on it!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/raphamorim"&gt;&lt;img src="https://img.shields.io/github/sponsors/raphamorim?label=Sponsor%20Rio&amp;amp;logo=github&amp;amp;style=for-the-badge" alt="Sponsor Rio terminal"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Packaging&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/rio-terminal/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/rio-terminal.svg?columns=3" alt="Packaging status"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Platforms&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Details&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MacOs &lt;em&gt;as desktop application&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rioterm.com/docs/install/macos"&gt;Installation guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux &lt;em&gt;as desktop application&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rioterm.com/docs/install/linux"&gt;Installation guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows &lt;em&gt;as desktop application&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://rioterm.com/docs/install/windows"&gt;Installation guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web Browser &lt;em&gt;(WebAssembly)&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;(Sugarloaf is ready but Rio still need to be ported)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Demo with split and CRT on MacOS&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/raphamorim/rio/main/docs/static/assets/posts/0.2.0/demo-rio.png" alt="Demo Rio 0.2.0 on MacOS"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Demo with blurred background on Linux&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/raphamorim/rio/main/docs/static/assets/demos/demos-nixos-blur.png" alt="Demo blurred background"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Demo of Rio running on a Steam Deck&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/raphamorim/rio/main/docs/static/assets/demos/demo-flatpak-steamdeck.jpg" alt="Demo of Rio running on a Steam Deck"&gt;&lt;/p&gt; 
&lt;h2&gt;Minimal stable rust version&lt;/h2&gt; 
&lt;p&gt;Rio's MSRV is 1.87.0.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>astral-sh/ruff</title>
      <link>https://github.com/astral-sh/ruff</link>
      <description>&lt;p&gt;An extremely fast Python linter and code formatter, written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ruff&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/astral-sh/ruff"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json" alt="Ruff"&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/ruff"&gt;&lt;img src="https://img.shields.io/pypi/v/ruff.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/ruff/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/pypi/l/ruff.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/ruff"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/ruff.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/ruff/actions"&gt;&lt;img src="https://github.com/astral-sh/ruff/workflows/CI/badge.svg?sanitize=true" alt="Actions status"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/astral-sh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.astral.sh/ruff/"&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://play.ruff.rs/"&gt;&lt;strong&gt;Playground&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An extremely fast Python linter and code formatter, written in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://user-images.githubusercontent.com/1309177/232603514-c95e9b0f-6b31-43de-9a80-9e844173fd6a.svg"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://user-images.githubusercontent.com/1309177/232603516-4fb4892d-585c-4b20-b810-3db9161831e4.svg"&gt; 
  &lt;img alt="Shows a bar chart with benchmark results." src="https://user-images.githubusercontent.com/1309177/232603516-4fb4892d-585c-4b20-b810-3db9161831e4.svg?sanitize=true"&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Linting the CPython codebase from scratch.&lt;/i&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ö°Ô∏è 10-100x faster than existing linters (like Flake8) and formatters (like Black)&lt;/li&gt; 
 &lt;li&gt;üêç Installable via &lt;code&gt;pip&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;code&gt;pyproject.toml&lt;/code&gt; support&lt;/li&gt; 
 &lt;li&gt;ü§ù Python 3.13 compatibility&lt;/li&gt; 
 &lt;li&gt;‚öñÔ∏è Drop-in parity with &lt;a href="https://docs.astral.sh/ruff/faq/#how-does-ruffs-linter-compare-to-flake8"&gt;Flake8&lt;/a&gt;, isort, and &lt;a href="https://docs.astral.sh/ruff/faq/#how-does-ruffs-formatter-compare-to-black"&gt;Black&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üì¶ Built-in caching, to avoid re-analyzing unchanged files&lt;/li&gt; 
 &lt;li&gt;üîß Fix support, for automatic error correction (e.g., automatically remove unused imports)&lt;/li&gt; 
 &lt;li&gt;üìè Over &lt;a href="https://docs.astral.sh/ruff/rules/"&gt;800 built-in rules&lt;/a&gt;, with native re-implementations of popular Flake8 plugins, like flake8-bugbear&lt;/li&gt; 
 &lt;li&gt;‚å®Ô∏è First-party &lt;a href="https://docs.astral.sh/ruff/editors"&gt;editor integrations&lt;/a&gt; for &lt;a href="https://github.com/astral-sh/ruff-vscode"&gt;VS Code&lt;/a&gt; and &lt;a href="https://docs.astral.sh/ruff/editors/setup"&gt;more&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üåé Monorepo-friendly, with &lt;a href="https://docs.astral.sh/ruff/configuration/#config-file-discovery"&gt;hierarchical and cascading configuration&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Ruff aims to be orders of magnitude faster than alternative tools while integrating more functionality behind a single, common interface.&lt;/p&gt; 
&lt;p&gt;Ruff can be used to replace &lt;a href="https://pypi.org/project/flake8/"&gt;Flake8&lt;/a&gt; (plus dozens of plugins), &lt;a href="https://github.com/psf/black"&gt;Black&lt;/a&gt;, &lt;a href="https://pypi.org/project/isort/"&gt;isort&lt;/a&gt;, &lt;a href="https://pypi.org/project/pydocstyle/"&gt;pydocstyle&lt;/a&gt;, &lt;a href="https://pypi.org/project/pyupgrade/"&gt;pyupgrade&lt;/a&gt;, &lt;a href="https://pypi.org/project/autoflake/"&gt;autoflake&lt;/a&gt;, and more, all while executing tens or hundreds of times faster than any individual tool.&lt;/p&gt; 
&lt;p&gt;Ruff is extremely actively developed and used in major open-source projects like:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apache/airflow"&gt;Apache Airflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apache/superset"&gt;Apache Superset&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tiangolo/fastapi"&gt;FastAPI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/transformers"&gt;Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pandas-dev/pandas"&gt;Pandas&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/scipy/scipy"&gt;SciPy&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;...and &lt;a href="https://raw.githubusercontent.com/astral-sh/ruff/main/#whos-using-ruff"&gt;many more&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Ruff is backed by &lt;a href="https://astral.sh"&gt;Astral&lt;/a&gt;. Read the &lt;a href="https://astral.sh/blog/announcing-astral-the-company-behind-ruff"&gt;launch post&lt;/a&gt;, or the original &lt;a href="https://notes.crmarsh.com/python-tooling-could-be-much-much-faster"&gt;project announcement&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Testimonials&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/tiangolo/status/1591912354882764802"&gt;&lt;strong&gt;Sebasti√°n Ram√≠rez&lt;/strong&gt;&lt;/a&gt;, creator of &lt;a href="https://github.com/tiangolo/fastapi"&gt;FastAPI&lt;/a&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ruff is so fast that sometimes I add an intentional bug in the code just to confirm it's actually running and checking the code.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/schrockn/status/1612615862904827904"&gt;&lt;strong&gt;Nick Schrock&lt;/strong&gt;&lt;/a&gt;, founder of &lt;a href="https://www.elementl.com/"&gt;Elementl&lt;/a&gt;, co-creator of &lt;a href="https://graphql.org/"&gt;GraphQL&lt;/a&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Why is Ruff a gamechanger? Primarily because it is nearly 1000x faster. Literally. Not a typo. On our largest module (dagster itself, 250k LOC) pylint takes about 2.5 minutes, parallelized across 4 cores on my M1. Running ruff against our &lt;em&gt;entire&lt;/em&gt; codebase takes .4 seconds.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/bokeh/bokeh/pull/12605"&gt;&lt;strong&gt;Bryan Van de Ven&lt;/strong&gt;&lt;/a&gt;, co-creator of &lt;a href="https://github.com/bokeh/bokeh/"&gt;Bokeh&lt;/a&gt;, original author of &lt;a href="https://docs.conda.io/en/latest/"&gt;Conda&lt;/a&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ruff is ~150-200x faster than flake8 on my machine, scanning the whole repo takes ~0.2s instead of ~20s. This is an enormous quality of life improvement for local dev. It's fast enough that I added it as an actual commit hook, which is terrific.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/timothycrosley/status/1606420868514877440"&gt;&lt;strong&gt;Timothy Crosley&lt;/strong&gt;&lt;/a&gt;, creator of &lt;a href="https://github.com/PyCQA/isort"&gt;isort&lt;/a&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Just switched my first project to Ruff. Only one downside so far: it's so fast I couldn't believe it was working till I intentionally introduced some errors.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/astral-sh/ruff/issues/465#issuecomment-1317400028"&gt;&lt;strong&gt;Tim Abbott&lt;/strong&gt;&lt;/a&gt;, lead developer of &lt;a href="https://github.com/zulip/zulip"&gt;Zulip&lt;/a&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;This is just ridiculously fast... &lt;code&gt;ruff&lt;/code&gt; is amazing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- End section: Overview --&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;p&gt;For more, see the &lt;a href="https://docs.astral.sh/ruff/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/astral-sh/ruff/main/#getting-started"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/astral-sh/ruff/main/#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/astral-sh/ruff/main/#rules"&gt;Rules&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/astral-sh/ruff/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/astral-sh/ruff/main/#support"&gt;Support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/astral-sh/ruff/main/#acknowledgements"&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/astral-sh/ruff/main/#whos-using-ruff"&gt;Who's Using Ruff?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/astral-sh/ruff/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Getting Started&lt;a id="getting-started"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;For more, see the &lt;a href="https://docs.astral.sh/ruff/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;Ruff is available as &lt;a href="https://pypi.org/project/ruff/"&gt;&lt;code&gt;ruff&lt;/code&gt;&lt;/a&gt; on PyPI.&lt;/p&gt; 
&lt;p&gt;Invoke Ruff directly with &lt;a href="https://docs.astral.sh/uv/"&gt;&lt;code&gt;uvx&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;uvx ruff check   # Lint all files in the current directory.
uvx ruff format  # Format all files in the current directory.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or install Ruff with &lt;code&gt;uv&lt;/code&gt; (recommended), &lt;code&gt;pip&lt;/code&gt;, or &lt;code&gt;pipx&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# With uv.
uv tool install ruff@latest  # Install Ruff globally.
uv add --dev ruff            # Or add Ruff to your project.

# With pip.
pip install ruff

# With pipx.
pipx install ruff
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Starting with version &lt;code&gt;0.5.0&lt;/code&gt;, Ruff can be installed with our standalone installers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# On macOS and Linux.
curl -LsSf https://astral.sh/ruff/install.sh | sh

# On Windows.
powershell -c "irm https://astral.sh/ruff/install.ps1 | iex"

# For a specific version.
curl -LsSf https://astral.sh/ruff/0.12.4/install.sh | sh
powershell -c "irm https://astral.sh/ruff/0.12.4/install.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also install Ruff via &lt;a href="https://formulae.brew.sh/formula/ruff"&gt;Homebrew&lt;/a&gt;, &lt;a href="https://anaconda.org/conda-forge/ruff"&gt;Conda&lt;/a&gt;, and with &lt;a href="https://docs.astral.sh/ruff/installation/"&gt;a variety of other package managers&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;To run Ruff as a linter, try any of the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ruff check                          # Lint all files in the current directory (and any subdirectories).
ruff check path/to/code/            # Lint all files in `/path/to/code` (and any subdirectories).
ruff check path/to/code/*.py        # Lint all `.py` files in `/path/to/code`.
ruff check path/to/code/to/file.py  # Lint `file.py`.
ruff check @arguments.txt           # Lint using an input file, treating its contents as newline-delimited command-line arguments.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, to run Ruff as a formatter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ruff format                          # Format all files in the current directory (and any subdirectories).
ruff format path/to/code/            # Format all files in `/path/to/code` (and any subdirectories).
ruff format path/to/code/*.py        # Format all `.py` files in `/path/to/code`.
ruff format path/to/code/to/file.py  # Format `file.py`.
ruff format @arguments.txt           # Format using an input file, treating its contents as newline-delimited command-line arguments.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ruff can also be used as a &lt;a href="https://pre-commit.com/"&gt;pre-commit&lt;/a&gt; hook via &lt;a href="https://github.com/astral-sh/ruff-pre-commit"&gt;&lt;code&gt;ruff-pre-commit&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;- repo: https://github.com/astral-sh/ruff-pre-commit
  # Ruff version.
  rev: v0.12.4
  hooks:
    # Run the linter.
    - id: ruff-check
      args: [ --fix ]
    # Run the formatter.
    - id: ruff-format
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ruff can also be used as a &lt;a href="https://github.com/astral-sh/ruff-vscode"&gt;VS Code extension&lt;/a&gt; or with &lt;a href="https://docs.astral.sh/ruff/editors/setup"&gt;various other editors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Ruff can also be used as a &lt;a href="https://github.com/features/actions"&gt;GitHub Action&lt;/a&gt; via &lt;a href="https://github.com/astral-sh/ruff-action"&gt;&lt;code&gt;ruff-action&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;name: Ruff
on: [ push, pull_request ]
jobs:
  ruff:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/ruff-action@v3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;a id="configuration"&gt;&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Ruff can be configured through a &lt;code&gt;pyproject.toml&lt;/code&gt;, &lt;code&gt;ruff.toml&lt;/code&gt;, or &lt;code&gt;.ruff.toml&lt;/code&gt; file (see: &lt;a href="https://docs.astral.sh/ruff/configuration/"&gt;&lt;em&gt;Configuration&lt;/em&gt;&lt;/a&gt;, or &lt;a href="https://docs.astral.sh/ruff/settings/"&gt;&lt;em&gt;Settings&lt;/em&gt;&lt;/a&gt; for a complete list of all configuration options).&lt;/p&gt; 
&lt;p&gt;If left unspecified, Ruff's default configuration is equivalent to the following &lt;code&gt;ruff.toml&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# Exclude a variety of commonly ignored directories.
exclude = [
    ".bzr",
    ".direnv",
    ".eggs",
    ".git",
    ".git-rewrite",
    ".hg",
    ".ipynb_checkpoints",
    ".mypy_cache",
    ".nox",
    ".pants.d",
    ".pyenv",
    ".pytest_cache",
    ".pytype",
    ".ruff_cache",
    ".svn",
    ".tox",
    ".venv",
    ".vscode",
    "__pypackages__",
    "_build",
    "buck-out",
    "build",
    "dist",
    "node_modules",
    "site-packages",
    "venv",
]

# Same as Black.
line-length = 88
indent-width = 4

# Assume Python 3.9
target-version = "py39"

[lint]
# Enable Pyflakes (`F`) and a subset of the pycodestyle (`E`) codes by default.
select = ["E4", "E7", "E9", "F"]
ignore = []

# Allow fix for all enabled rules (when `--fix`) is provided.
fixable = ["ALL"]
unfixable = []

# Allow unused variables when underscore-prefixed.
dummy-variable-rgx = "^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$"

[format]
# Like Black, use double quotes for strings.
quote-style = "double"

# Like Black, indent with spaces, rather than tabs.
indent-style = "space"

# Like Black, respect magic trailing commas.
skip-magic-trailing-comma = false

# Like Black, automatically detect the appropriate line ending.
line-ending = "auto"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that, in a &lt;code&gt;pyproject.toml&lt;/code&gt;, each section header should be prefixed with &lt;code&gt;tool.ruff&lt;/code&gt;. For example, &lt;code&gt;[lint]&lt;/code&gt; should be replaced with &lt;code&gt;[tool.ruff.lint]&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Some configuration options can be provided via dedicated command-line arguments, such as those related to rule enablement and disablement, file discovery, and logging level:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ruff check --select F401 --select F403 --quiet
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The remaining configuration options can be provided through a catch-all &lt;code&gt;--config&lt;/code&gt; argument:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ruff check --config "lint.per-file-ignores = {'some_file.py' = ['F841']}"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To opt in to the latest lint rules, formatter style changes, interface updates, and more, enable &lt;a href="https://docs.astral.sh/ruff/rules/"&gt;preview mode&lt;/a&gt; by setting &lt;code&gt;preview = true&lt;/code&gt; in your configuration file or passing &lt;code&gt;--preview&lt;/code&gt; on the command line. Preview mode enables a collection of unstable features that may change prior to stabilization.&lt;/p&gt; 
&lt;p&gt;See &lt;code&gt;ruff help&lt;/code&gt; for more on Ruff's top-level commands, or &lt;code&gt;ruff help check&lt;/code&gt; and &lt;code&gt;ruff help format&lt;/code&gt; for more on the linting and formatting commands, respectively.&lt;/p&gt; 
&lt;h2&gt;Rules&lt;a id="rules"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;!-- Begin section: Rules --&gt; 
&lt;p&gt;&lt;strong&gt;Ruff supports over 800 lint rules&lt;/strong&gt;, many of which are inspired by popular tools like Flake8, isort, pyupgrade, and others. Regardless of the rule's origin, Ruff re-implements every rule in Rust as a first-party feature.&lt;/p&gt; 
&lt;p&gt;By default, Ruff enables Flake8's &lt;code&gt;F&lt;/code&gt; rules, along with a subset of the &lt;code&gt;E&lt;/code&gt; rules, omitting any stylistic rules that overlap with the use of a formatter, like &lt;code&gt;ruff format&lt;/code&gt; or &lt;a href="https://github.com/psf/black"&gt;Black&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you're just getting started with Ruff, &lt;strong&gt;the default rule set is a great place to start&lt;/strong&gt;: it catches a wide variety of common errors (like unused imports) with zero configuration.&lt;/p&gt; 
&lt;!-- End section: Rules --&gt; 
&lt;p&gt;Beyond the defaults, Ruff re-implements some of the most popular Flake8 plugins and related code quality tools, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/autoflake/"&gt;autoflake&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/eradicate/"&gt;eradicate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-2020/"&gt;flake8-2020&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-annotations/"&gt;flake8-annotations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-async"&gt;flake8-async&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-bandit/"&gt;flake8-bandit&lt;/a&gt; (&lt;a href="https://github.com/astral-sh/ruff/issues/1646"&gt;#1646&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-blind-except/"&gt;flake8-blind-except&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-boolean-trap/"&gt;flake8-boolean-trap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-bugbear/"&gt;flake8-bugbear&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-builtins/"&gt;flake8-builtins&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-commas/"&gt;flake8-commas&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-comprehensions/"&gt;flake8-comprehensions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-copyright/"&gt;flake8-copyright&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-datetimez/"&gt;flake8-datetimez&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-debugger/"&gt;flake8-debugger&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-django/"&gt;flake8-django&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-docstrings/"&gt;flake8-docstrings&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-eradicate/"&gt;flake8-eradicate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-errmsg/"&gt;flake8-errmsg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-executable/"&gt;flake8-executable&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-future-annotations/"&gt;flake8-future-annotations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-gettext/"&gt;flake8-gettext&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-implicit-str-concat/"&gt;flake8-implicit-str-concat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/joaopalmeiro/flake8-import-conventions"&gt;flake8-import-conventions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-logging/"&gt;flake8-logging&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-logging-format/"&gt;flake8-logging-format&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-no-pep420"&gt;flake8-no-pep420&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-pie/"&gt;flake8-pie&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-print/"&gt;flake8-print&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-pyi/"&gt;flake8-pyi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-pytest-style/"&gt;flake8-pytest-style&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-quotes/"&gt;flake8-quotes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-raise/"&gt;flake8-raise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-return/"&gt;flake8-return&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-self/"&gt;flake8-self&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-simplify/"&gt;flake8-simplify&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-slots/"&gt;flake8-slots&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-super/"&gt;flake8-super&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-tidy-imports/"&gt;flake8-tidy-imports&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-todos/"&gt;flake8-todos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-type-checking/"&gt;flake8-type-checking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flake8-use-pathlib/"&gt;flake8-use-pathlib&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/flynt/"&gt;flynt&lt;/a&gt; (&lt;a href="https://github.com/astral-sh/ruff/issues/2102"&gt;#2102&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/isort/"&gt;isort&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/mccabe/"&gt;mccabe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/pandas-vet/"&gt;pandas-vet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/pep8-naming/"&gt;pep8-naming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/pydocstyle/"&gt;pydocstyle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pre-commit/pygrep-hooks"&gt;pygrep-hooks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/pylint-airflow/"&gt;pylint-airflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/pyupgrade/"&gt;pyupgrade&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/tryceratops/"&gt;tryceratops&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/yesqa/"&gt;yesqa&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a complete enumeration of the supported rules, see &lt;a href="https://docs.astral.sh/ruff/rules/"&gt;&lt;em&gt;Rules&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;a id="contributing"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome and highly appreciated. To get started, check out the &lt;a href="https://docs.astral.sh/ruff/contributing/"&gt;&lt;strong&gt;contributing guidelines&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also join us on &lt;a href="https://discord.com/invite/astral-sh"&gt;&lt;strong&gt;Discord&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;a id="support"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Having trouble? Check out the existing issues on &lt;a href="https://github.com/astral-sh/ruff/issues"&gt;&lt;strong&gt;GitHub&lt;/strong&gt;&lt;/a&gt;, or feel free to &lt;a href="https://github.com/astral-sh/ruff/issues/new"&gt;&lt;strong&gt;open a new one&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also ask for help on &lt;a href="https://discord.com/invite/astral-sh"&gt;&lt;strong&gt;Discord&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;a id="acknowledgements"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Ruff's linter draws on both the APIs and implementation details of many other tools in the Python ecosystem, especially &lt;a href="https://github.com/PyCQA/flake8"&gt;Flake8&lt;/a&gt;, &lt;a href="https://github.com/PyCQA/pyflakes"&gt;Pyflakes&lt;/a&gt;, &lt;a href="https://github.com/PyCQA/pycodestyle"&gt;pycodestyle&lt;/a&gt;, &lt;a href="https://github.com/PyCQA/pydocstyle"&gt;pydocstyle&lt;/a&gt;, &lt;a href="https://github.com/asottile/pyupgrade"&gt;pyupgrade&lt;/a&gt;, and &lt;a href="https://github.com/PyCQA/isort"&gt;isort&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In some cases, Ruff includes a "direct" Rust port of the corresponding tool. We're grateful to the maintainers of these tools for their work, and for all the value they've provided to the Python community.&lt;/p&gt; 
&lt;p&gt;Ruff's formatter is built on a fork of Rome's &lt;a href="https://github.com/rome/tools/tree/main/crates/rome_formatter"&gt;&lt;code&gt;rome_formatter&lt;/code&gt;&lt;/a&gt;, and again draws on both API and implementation details from &lt;a href="https://github.com/rome/tools"&gt;Rome&lt;/a&gt;, &lt;a href="https://github.com/prettier/prettier"&gt;Prettier&lt;/a&gt;, and &lt;a href="https://github.com/psf/black"&gt;Black&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Ruff's import resolver is based on the import resolution algorithm from &lt;a href="https://github.com/microsoft/pyright"&gt;Pyright&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Ruff is also influenced by a number of tools outside the Python ecosystem, like &lt;a href="https://github.com/rust-lang/rust-clippy"&gt;Clippy&lt;/a&gt; and &lt;a href="https://github.com/eslint/eslint"&gt;ESLint&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Ruff is the beneficiary of a large number of &lt;a href="https://github.com/astral-sh/ruff/graphs/contributors"&gt;contributors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Ruff is released under the MIT license.&lt;/p&gt; 
&lt;h2&gt;Who's Using Ruff?&lt;a id="whos-using-ruff"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Ruff is used by a number of major open-source projects and companies, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/albumentations-team/albumentations"&gt;Albumentations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Amazon (&lt;a href="https://github.com/aws/serverless-application-model"&gt;AWS SAM&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://apps.ankiweb.net/"&gt;Anki&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Anthropic (&lt;a href="https://github.com/anthropics/anthropic-sdk-python"&gt;Python SDK&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/apache/airflow"&gt;Apache Airflow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;AstraZeneca (&lt;a href="https://github.com/AstraZeneca/magnus-core"&gt;Magnus&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-babel/babel"&gt;Babel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Benchling (&lt;a href="https://github.com/benchling/refac"&gt;Refac&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bokeh/bokeh"&gt;Bokeh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Capital One (&lt;a href="https://github.com/capitalone/datacompy"&gt;datacompy&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;CrowdCent (&lt;a href="https://github.com/crowdcent/numerblox"&gt;NumerBlox&lt;/a&gt;) 
  &lt;!-- typos: ignore --&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyca/cryptography"&gt;Cryptography (PyCA)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;CERN (&lt;a href="https://getindico.io/"&gt;Indico&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/iterative/dvc"&gt;DVC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dagger/dagger"&gt;Dagger&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dagster-io/dagster"&gt;Dagster&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Databricks (&lt;a href="https://github.com/mlflow/mlflow"&gt;MLflow&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langgenius/dify"&gt;Dify&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tiangolo/fastapi"&gt;FastAPI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/godotengine/godot"&gt;Godot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gradio-app/gradio"&gt;Gradio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/great-expectations/great_expectations"&gt;Great Expectations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/encode/httpx"&gt;HTTPX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pypa/hatch"&gt;Hatch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/home-assistant/core"&gt;Home Assistant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hugging Face (&lt;a href="https://github.com/huggingface/transformers"&gt;Transformers&lt;/a&gt;, &lt;a href="https://github.com/huggingface/datasets"&gt;Datasets&lt;/a&gt;, &lt;a href="https://github.com/huggingface/diffusers"&gt;Diffusers&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;IBM (&lt;a href="https://github.com/Qiskit/qiskit"&gt;Qiskit&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;ING Bank (&lt;a href="https://github.com/ing-bank/popmon"&gt;popmon&lt;/a&gt;, &lt;a href="https://github.com/ing-bank/probatus"&gt;probatus&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ibis-project/ibis"&gt;Ibis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/unifyai/ivy"&gt;ivy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jax-ml/jax"&gt;JAX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jupyter-server/jupyter_server"&gt;Jupyter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kraken.tech/"&gt;Kraken Tech&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hwchase17/langchain"&gt;LangChain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://litestar.dev/"&gt;Litestar&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jerryjliu/llama_index"&gt;LlamaIndex&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Matrix (&lt;a href="https://github.com/matrix-org/synapse"&gt;Synapse&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oxsecurity/megalinter"&gt;MegaLinter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Meltano (&lt;a href="https://github.com/meltano/meltano"&gt;Meltano CLI&lt;/a&gt;, &lt;a href="https://github.com/meltano/sdk"&gt;Singer SDK&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Microsoft (&lt;a href="https://github.com/microsoft/semantic-kernel"&gt;Semantic Kernel&lt;/a&gt;, &lt;a href="https://github.com/microsoft/onnxruntime"&gt;ONNX Runtime&lt;/a&gt;, &lt;a href="https://github.com/microsoft/LightGBM"&gt;LightGBM&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Modern Treasury (&lt;a href="https://github.com/Modern-Treasury/modern-treasury-python"&gt;Python SDK&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Mozilla (&lt;a href="https://github.com/mozilla/gecko-dev"&gt;Firefox&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python/mypy"&gt;Mypy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nautobot/nautobot"&gt;Nautobot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Netflix (&lt;a href="https://github.com/Netflix/dispatch"&gt;Dispatch&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/neondatabase/neon"&gt;Neon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nokia.com/"&gt;Nokia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nonebot/nonebot2"&gt;NoneBot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyro-ppl/numpyro"&gt;NumPyro&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/onnx/onnx"&gt;ONNX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBBTerminal"&gt;OpenBB&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Open-Wine-Components/umu-launcher"&gt;Open Wine Components&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pdm-project/pdm"&gt;PDM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PaddlePaddle/Paddle"&gt;PaddlePaddle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pandas-dev/pandas"&gt;Pandas&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-pillow/Pillow"&gt;Pillow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/python-poetry/poetry"&gt;Poetry&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pola-rs/polars"&gt;Polars&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PostHog/posthog"&gt;PostHog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Prefect (&lt;a href="https://github.com/PrefectHQ/prefect"&gt;Python SDK&lt;/a&gt;, &lt;a href="https://github.com/PrefectHQ/marvin"&gt;Marvin&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyinstaller/pyinstaller"&gt;PyInstaller&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pymc-devs/pymc/"&gt;PyMC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pymc-labs/pymc-marketing"&gt;PyMC-Marketing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytest-dev/pytest"&gt;pytest&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pytorch/pytorch"&gt;PyTorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pydantic/pydantic"&gt;Pydantic&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/PyCQA/pylint"&gt;Pylint&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pyvista/pyvista"&gt;PyVista&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/reflex-dev/reflex"&gt;Reflex&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/online-ml/river"&gt;River&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://rippling.com"&gt;Rippling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sansyrox/robyn"&gt;Robyn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/saleor/saleor"&gt;Saleor&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Scale AI (&lt;a href="https://github.com/scaleapi/launch-python-client"&gt;Launch SDK&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/scipy/scipy"&gt;SciPy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Snowflake (&lt;a href="https://github.com/Snowflake-Labs/snowcli"&gt;SnowCLI&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sphinx-doc/sphinx"&gt;Sphinx&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DLR-RM/stable-baselines3"&gt;Stable Baselines3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/encode/starlette"&gt;Starlette&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/streamlit/streamlit"&gt;Streamlit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TheAlgorithms/Python"&gt;The Algorithms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/altair-viz/altair"&gt;Vega-Altair&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://weblate.org/"&gt;Weblate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WordPress (&lt;a href="https://github.com/WordPress/openverse"&gt;Openverse&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zenml-io/zenml"&gt;ZenML&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zulip/zulip"&gt;Zulip&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pypa/build"&gt;build (PyPA)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pypa/cibuildwheel"&gt;cibuildwheel (PyPA)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/delta-io/delta-rs"&gt;delta-rs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alteryx/featuretools"&gt;featuretools&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mesonbuild/meson-python"&gt;meson-python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wntrblm/nox"&gt;nox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pypa/pip"&gt;pip&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Show Your Support&lt;/h3&gt; 
&lt;p&gt;If you're using Ruff, consider adding the Ruff badge to your project's &lt;code&gt;README.md&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-md"&gt;[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...or &lt;code&gt;README.rst&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rst"&gt;.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json
    :target: https://github.com/astral-sh/ruff
    :alt: Ruff
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...or, as HTML:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-html"&gt;&amp;lt;a href="https://github.com/astral-sh/ruff"&amp;gt;&amp;lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json" alt="Ruff" style="max-width:100%;"&amp;gt;&amp;lt;/a&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;a id="license"&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://github.com/astral-sh/ruff/raw/main/LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://astral.sh" style="background:none"&gt; &lt;img src="https://raw.githubusercontent.com/astral-sh/ruff/main/assets/svg/Astral.svg?sanitize=true" alt="Made by Astral"&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>szabodanika/microbin</title>
      <link>https://github.com/szabodanika/microbin</link>
      <description>&lt;p&gt;A secure, configurable file-sharing and URL shortening web app written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/szabodanika/microbin/master/.github/index.png" alt="Screenshot"&gt;&lt;/p&gt; 
&lt;h1&gt;MicroBin&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/szabodanika/microbin/actions/workflows/rust.yml/badge.svg?sanitize=true" alt="Build"&gt; &lt;a href="https://crates.io/crates/microbin"&gt;&lt;img src="https://img.shields.io/crates/v/microbin.svg?sanitize=true" alt="crates.io"&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/danielszabo99/microbin"&gt;&lt;img src="https://github.com/szabodanika/microbin/actions/workflows/release.yml/badge.svg?sanitize=true" alt="Docker Image"&gt;&lt;/a&gt; &lt;a href="https://img.shields.io/docker/pulls/danielszabo99/microbin?label=Docker%20pulls"&gt;&lt;img src="https://img.shields.io/docker/pulls/danielszabo99/microbin?label=Docker%20pulls" alt="Docker Pulls"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MicroBin is a super tiny, feature-rich, configurable, self-contained and self-hosted paste bin web application. It is very easy to set up and use, and will only require a few megabytes of memory and disk storage. It takes only a couple minutes to set it up, why not give it a try now?&lt;/p&gt; 
&lt;h3&gt;Check out the Public Test Server at &lt;a href="https://pub.microbin.eu"&gt;pub.microbin.eu&lt;/a&gt;!&lt;/h3&gt; 
&lt;h3&gt;Or host MicroBin yourself&lt;/h3&gt; 
&lt;p&gt;Run our quick docker setup script (&lt;a href="https://hub.docker.com/r/danielszabo99/microbin"&gt;DockerHub&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash &amp;lt;(curl -s https://microbin.eu/docker.sh)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or install it manually from &lt;a href="https://crates.io/crates/microbin"&gt;Cargo&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install microbin;
curl -L -O https://raw.githubusercontent.com/szabodanika/microbin/master/.env;
source .env;
microbin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On our website &lt;a href="https://microbin.eu"&gt;microbin.eu&lt;/a&gt;, you will find the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://microbin.eu/screenshots/"&gt;Screenshots&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://microbin.eu/docs/intro"&gt;Guide and Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://microbin.eu/sponsorship"&gt;Donations and Sponsorships&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://microbin.eu/roadmap"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Entirely self-contained executable, MicroBin is a single file!&lt;/li&gt; 
 &lt;li&gt;Server-side and client-side encryption&lt;/li&gt; 
 &lt;li&gt;File uploads (e.g. &lt;code&gt;server.com/file/pig-dog-cat&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Raw text serving (e.g. &lt;code&gt;server.com/raw/pig-dog-cat&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;QR code support&lt;/li&gt; 
 &lt;li&gt;URL shortening and redirection&lt;/li&gt; 
 &lt;li&gt;Animal names instead of random numbers for upload identifiers (64 animals)&lt;/li&gt; 
 &lt;li&gt;SQLite and JSON database support&lt;/li&gt; 
 &lt;li&gt;Private and public, editable and uneditable, automatically and never expiring uploads&lt;/li&gt; 
 &lt;li&gt;Automatic dark mode and custom styling support with very little CSS and only vanilla JS (see &lt;a href="https://github.com/kognise/water.css"&gt;&lt;code&gt;water.css&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;And much more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is an upload?&lt;/h2&gt; 
&lt;p&gt;In MicroBin, an upload can be:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A text that you want to paste from one machine to another, e.g. some code,&lt;/li&gt; 
 &lt;li&gt;A file that you want to share, e.g. a video that is too large for Discord, a zip with a code project in it or an image,&lt;/li&gt; 
 &lt;li&gt;A URL redirection.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;When is MicroBin useful?&lt;/h2&gt; 
&lt;p&gt;You can use MicroBin:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;To send long texts to other people,&lt;/li&gt; 
 &lt;li&gt;To send large files to other people,&lt;/li&gt; 
 &lt;li&gt;To share secrets or sensitive documents securely,&lt;/li&gt; 
 &lt;li&gt;As a URL shortener/redirect service,&lt;/li&gt; 
 &lt;li&gt;To serve content on the web, eg . configuration files for testing, images, or any other file content using the Raw functionality,&lt;/li&gt; 
 &lt;li&gt;To move files between your desktop and a server you access from the console,&lt;/li&gt; 
 &lt;li&gt;As a "postbox" service where people can upload their files or texts, but they cannot see or remove what others sent you,&lt;/li&gt; 
 &lt;li&gt;Or even to take quick notes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;...and many other things, why not get creative?&lt;/p&gt; 
&lt;p&gt;MicroBin and MicroBin.eu are available under the &lt;a href="https://raw.githubusercontent.com/szabodanika/microbin/master/LICENSE"&gt;BSD 3-Clause License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;¬© D√°niel Szab√≥ 2022-2024&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>solana-foundation/anchor</title>
      <link>https://github.com/solana-foundation/anchor</link>
      <description>&lt;p&gt;‚öì Solana Sealevel Framework&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img height="170x" src="https://pbs.twimg.com/media/FVUVaO9XEAAulvK?format=png&amp;amp;name=small"&gt; 
 &lt;h1&gt;Anchor&lt;/h1&gt; 
 &lt;p&gt; &lt;strong&gt;Solana Program Framework&lt;/strong&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://github.com/coral-xyz/anchor/actions"&gt;&lt;img alt="Build Status" src="https://github.com/coral-xyz/anchor/actions/workflows/tests.yaml/badge.svg?sanitize=true"&gt;&lt;/a&gt; &lt;a href="https://anchor-lang.com"&gt;&lt;img alt="Tutorials" src="https://img.shields.io/badge/docs-tutorials-blueviolet"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/NHHGSXAnXk"&gt;&lt;img alt="Discord Chat" src="https://img.shields.io/discord/889577356681945098?color=blueviolet"&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img alt="License" src="https://img.shields.io/github/license/coral-xyz/anchor?color=blueviolet"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://www.anchor-lang.com/"&gt;Anchor&lt;/a&gt; is a framework providing several convenient developer tools for writing Solana programs (sometimes called 'smart contracts').&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rust eDSL for writing Solana programs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Interface_description_language"&gt;IDL&lt;/a&gt; specification&lt;/li&gt; 
 &lt;li&gt;TypeScript package for generating clients from IDL&lt;/li&gt; 
 &lt;li&gt;CLI and workspace management for developing complete applications&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Anchor is the most popular framework for Solana programs.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you're familiar with developing in Ethereum's &lt;a href="https://docs.soliditylang.org/en/"&gt;Solidity&lt;/a&gt;, &lt;a href="https://www.trufflesuite.com/"&gt;Truffle&lt;/a&gt;, &lt;a href="https://github.com/ethereum/web3.js"&gt;web3.js&lt;/a&gt;, then using Anchor be familiar. Although the DSL syntax and semantics are targeted at Solana, the high level flow of writing RPC request handlers, emitting an IDL, and generating clients from IDL is the same.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;For a quickstart guide and in depth tutorials, see the &lt;a href="https://book.anchor-lang.com"&gt;Anchor book&lt;/a&gt; and the &lt;a href="https://anchor-lang.com"&gt;Anchor documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To jump straight to examples, go &lt;a href="https://github.com/coral-xyz/anchor/tree/master/examples"&gt;here&lt;/a&gt;. For the latest Rust and TypeScript API documentation, see &lt;a href="https://docs.rs/anchor-lang"&gt;docs.rs&lt;/a&gt; and the &lt;a href="https://www.anchor-lang.com/docs/clients/typescript"&gt;typedoc&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Packages&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Package&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Version&lt;/th&gt; 
   &lt;th align="left"&gt;Docs&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;anchor-lang&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Rust primitives for writing programs on Solana&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://crates.io/crates/anchor-lang"&gt;&lt;img src="https://img.shields.io/crates/v/anchor-lang?color=blue" alt="Crates.io"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.rs/anchor-lang"&gt;&lt;img src="https://docs.rs/anchor-lang/badge.svg?sanitize=true" alt="Docs.rs"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;anchor-spl&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;CPI clients for SPL programs on Solana&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://crates.io/crates/anchor-spl"&gt;&lt;img src="https://img.shields.io/crates/v/anchor-spl?color=blue" alt="crates"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.rs/anchor-spl"&gt;&lt;img src="https://docs.rs/anchor-spl/badge.svg?sanitize=true" alt="Docs.rs"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;anchor-client&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Rust client for Anchor programs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://crates.io/crates/anchor-client"&gt;&lt;img src="https://img.shields.io/crates/v/anchor-client?color=blue" alt="crates"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.rs/anchor-client"&gt;&lt;img src="https://docs.rs/anchor-client/badge.svg?sanitize=true" alt="Docs.rs"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;@coral-xyz/anchor&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;TypeScript client for Anchor programs&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.npmjs.com/package/@coral-xyz/anchor"&gt;&lt;img src="https://img.shields.io/npm/v/@coral-xyz/anchor.svg?color=blue" alt="npm"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://coral-xyz.github.io/anchor/ts/index.html"&gt;&lt;img src="https://img.shields.io/badge/docs-typedoc-blue" alt="Docs"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;@coral-xyz/anchor-cli&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;CLI to support building and managing an Anchor workspace&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.npmjs.com/package/@coral-xyz/anchor-cli"&gt;&lt;img src="https://img.shields.io/npm/v/@coral-xyz/anchor-cli.svg?color=blue" alt="npm"&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://coral-xyz.github.io/anchor/cli/commands.html"&gt;&lt;img src="https://img.shields.io/badge/docs-typedoc-blue" alt="Docs"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Note&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Anchor is in active development, so all APIs are subject to change.&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;This code is unaudited. Use at your own risk.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Here's a counter program, where only the designated &lt;code&gt;authority&lt;/code&gt; can increment the count.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use anchor_lang::prelude::*;

declare_id!("Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS");

#[program]
mod counter {
    use super::*;

    pub fn initialize(ctx: Context&amp;lt;Initialize&amp;gt;, start: u64) -&amp;gt; Result&amp;lt;()&amp;gt; {
        let counter = &amp;amp;mut ctx.accounts.counter;
        counter.authority = *ctx.accounts.authority.key;
        counter.count = start;
        Ok(())
    }

    pub fn increment(ctx: Context&amp;lt;Increment&amp;gt;) -&amp;gt; Result&amp;lt;()&amp;gt; {
        let counter = &amp;amp;mut ctx.accounts.counter;
        counter.count += 1;
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Initialize&amp;lt;'info&amp;gt; {
    #[account(init, payer = authority, space = 48)]
    pub counter: Account&amp;lt;'info, Counter&amp;gt;,
    pub authority: Signer&amp;lt;'info&amp;gt;,
    pub system_program: Program&amp;lt;'info, System&amp;gt;,
}

#[derive(Accounts)]
pub struct Increment&amp;lt;'info&amp;gt; {
    #[account(mut, has_one = authority)]
    pub counter: Account&amp;lt;'info, Counter&amp;gt;,
    pub authority: Signer&amp;lt;'info&amp;gt;,
}

#[account]
pub struct Counter {
    pub authority: Pubkey,
    pub count: u64,
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more, see the &lt;a href="https://github.com/coral-xyz/anchor/tree/master/examples"&gt;examples&lt;/a&gt; and &lt;a href="https://github.com/coral-xyz/anchor/tree/master/tests"&gt;tests&lt;/a&gt; directories.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Anchor is licensed under &lt;a href="https://raw.githubusercontent.com/solana-foundation/anchor/master/LICENSE"&gt;Apache 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in Anchor by you, as defined in the Apache-2.0 license, shall be licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Thank you for your interest in contributing to Anchor! Please see the &lt;a href="https://raw.githubusercontent.com/solana-foundation/anchor/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; to learn how.&lt;/p&gt; 
&lt;h3&gt;Thanks ‚ù§Ô∏è&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/coral-xyz/anchor/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=coral-xyz/anchor" width="100%"&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>gfx-rs/wgpu</title>
      <link>https://github.com/gfx-rs/wgpu</link>
      <description>&lt;p&gt;A cross-platform, safe, pure-Rust graphics API.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;wgpu&lt;/h1&gt; 
&lt;img align="right" width="20%" src="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/logo.png"&gt; 
&lt;p&gt;&lt;a href="https://matrix.to/#/%23Wgpu:matrix.org"&gt;&lt;img src="https://img.shields.io/static/v1?label=Space&amp;amp;message=%23Wgpu&amp;amp;color=blue&amp;amp;logo=matrix" alt="Matrix Space"&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/%23wgpu:matrix.org"&gt;&lt;img src="https://img.shields.io/static/v1?label=devs&amp;amp;message=%23wgpu&amp;amp;color=blueviolet&amp;amp;logo=matrix" alt="Dev Matrix"&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/%23wgpu-users:matrix.org"&gt;&lt;img src="https://img.shields.io/static/v1?label=users&amp;amp;message=%23wgpu-users&amp;amp;color=blueviolet&amp;amp;logo=matrix" alt="User Matrix"&gt;&lt;/a&gt; &lt;a href="https://github.com/gfx-rs/wgpu/actions"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/gfx-rs/wgpu/ci.yml?branch=trunk&amp;amp;logo=github&amp;amp;label=CI" alt="Build Status"&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/gfx-rs/wgpu"&gt;&lt;img src="https://img.shields.io/codecov/c/github/gfx-rs/wgpu?logo=codecov&amp;amp;logoColor=fff&amp;amp;label=codecov&amp;amp;token=84qJTesmeS" alt="codecov.io"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;wgpu&lt;/code&gt; is a cross-platform, safe, pure-rust graphics API. It runs natively on Vulkan, Metal, D3D12, and OpenGL; and on top of WebGL2 and WebGPU on wasm.&lt;/p&gt; 
&lt;p&gt;The API is based on the &lt;a href="https://gpuweb.github.io/gpuweb/"&gt;WebGPU standard&lt;/a&gt;. It serves as the core of the WebGPU integration in Firefox, Servo, and Deno.&lt;/p&gt; 
&lt;h2&gt;Quick Links&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Docs&lt;/th&gt; 
   &lt;th align="center"&gt;Examples&lt;/th&gt; 
   &lt;th align="center"&gt;Changelog&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://docs.rs/wgpu/"&gt;v26&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/gfx-rs/wgpu/tree/v26/examples#readme"&gt;v26&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/gfx-rs/wgpu/releases"&gt;v26&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://wgpu.rs/doc/wgpu/"&gt;&lt;code&gt;trunk&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/gfx-rs/wgpu/tree/trunk/examples#readme"&gt;&lt;code&gt;trunk&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://github.com/gfx-rs/wgpu/raw/trunk/CHANGELOG.md#unreleased"&gt;&lt;code&gt;trunk&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Contributors are welcome! See &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Repo Overview&lt;/h2&gt; 
&lt;p&gt;The repository hosts the following libraries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://crates.io/crates/wgpu"&gt;&lt;img src="https://img.shields.io/crates/v/wgpu.svg?label=wgpu" alt="Crates.io"&gt;&lt;/a&gt; &lt;a href="https://docs.rs/wgpu/"&gt;&lt;img src="https://docs.rs/wgpu/badge.svg?sanitize=true" alt="docs.rs"&gt;&lt;/a&gt; - User facing Rust API.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://crates.io/crates/wgpu-core"&gt;&lt;img src="https://img.shields.io/crates/v/wgpu-core.svg?label=wgpu-core" alt="Crates.io"&gt;&lt;/a&gt; &lt;a href="https://docs.rs/wgpu-core/"&gt;&lt;img src="https://docs.rs/wgpu-core/badge.svg?sanitize=true" alt="docs.rs"&gt;&lt;/a&gt; - Internal safe implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://crates.io/crates/wgpu-hal"&gt;&lt;img src="https://img.shields.io/crates/v/wgpu-hal.svg?label=wgpu-hal" alt="Crates.io"&gt;&lt;/a&gt; &lt;a href="https://docs.rs/wgpu-hal/"&gt;&lt;img src="https://docs.rs/wgpu-hal/badge.svg?sanitize=true" alt="docs.rs"&gt;&lt;/a&gt; - Internal unsafe GPU API abstraction layer.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://crates.io/crates/wgpu-types"&gt;&lt;img src="https://img.shields.io/crates/v/wgpu-types.svg?label=wgpu-types" alt="Crates.io"&gt;&lt;/a&gt; &lt;a href="https://docs.rs/wgpu-types/"&gt;&lt;img src="https://docs.rs/wgpu-types/badge.svg?sanitize=true" alt="docs.rs"&gt;&lt;/a&gt; - Rust types shared between all crates.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://crates.io/crates/naga"&gt;&lt;img src="https://img.shields.io/crates/v/naga.svg?label=naga" alt="Crates.io"&gt;&lt;/a&gt; &lt;a href="https://docs.rs/naga/"&gt;&lt;img src="https://docs.rs/naga/badge.svg?sanitize=true" alt="docs.rs"&gt;&lt;/a&gt; - Stand-alone shader translation library.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://crates.io/crates/deno_webgpu"&gt;&lt;img src="https://img.shields.io/crates/v/deno_webgpu.svg?label=deno_webgpu" alt="Crates.io"&gt;&lt;/a&gt; - WebGPU implementation for the Deno JavaScript/TypeScript runtime&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following binaries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://crates.io/crates/naga-cli"&gt;&lt;img src="https://img.shields.io/crates/v/naga-cli.svg?label=naga-cli" alt="Crates.io"&gt;&lt;/a&gt; - Tool for translating shaders between different languages using &lt;code&gt;naga&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://crates.io/crates/wgpu-info"&gt;&lt;img src="https://img.shields.io/crates/v/wgpu-info.svg?label=wgpu-info" alt="Crates.io"&gt;&lt;/a&gt; - Tool for getting information on GPUs in the system.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cts_runner&lt;/code&gt; - WebGPU Conformance Test Suite runner using &lt;code&gt;deno_webgpu&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player&lt;/code&gt; - standalone application for replaying the API traces.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For an overview of all the components in the gfx-rs ecosystem, see &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/docs/big-picture.png"&gt;the big picture&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Play with our Examples&lt;/h3&gt; 
&lt;p&gt;Go to &lt;a href="https://wgpu.rs/examples/"&gt;https://wgpu.rs/examples/&lt;/a&gt; to play with our examples in your browser. Requires a browser supporting WebGPU for the WebGPU examples.&lt;/p&gt; 
&lt;h3&gt;Rust&lt;/h3&gt; 
&lt;p&gt;Rust examples can be found at &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/examples"&gt;examples&lt;/a&gt;. You can run the examples natively with &lt;code&gt;cargo run --bin wgpu-examples &amp;lt;example&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you are new to wgpu and graphics programming, we recommend starting with &lt;a href="https://sotrh.github.io/learn-wgpu/"&gt;https://sotrh.github.io/learn-wgpu/&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To run the examples in a browser, run &lt;code&gt;cargo xtask run-wasm&lt;/code&gt;. Then open &lt;code&gt;http://localhost:8000&lt;/code&gt; in your browser, and you can choose an example to run. Naturally, in order to display any of the WebGPU based examples, you need to make sure your browser supports it.&lt;/p&gt; 
&lt;h3&gt;C/C++&lt;/h3&gt; 
&lt;p&gt;To use wgpu in C/C++, you need &lt;a href="https://github.com/gfx-rs/wgpu-native"&gt;wgpu-native&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are looking for a wgpu C++ tutorial, look at the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://eliemichel.github.io/LearnWebGPU/"&gt;https://eliemichel.github.io/LearnWebGPU/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Others&lt;/h3&gt; 
&lt;p&gt;If you want to use wgpu in other languages, there are many bindings to wgpu-native from languages such as Python, D, Julia, Kotlin, and more. See &lt;a href="https://github.com/gfx-rs/wgpu-native#bindings"&gt;the list&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;We have the Matrix space &lt;a href="https://matrix.to/#/%23Wgpu:matrix.org"&gt;&lt;img src="https://img.shields.io/static/v1?label=Space&amp;amp;message=%23Wgpu&amp;amp;color=blue&amp;amp;logo=matrix" alt="Matrix Space"&gt;&lt;/a&gt; with a few different rooms that form the wgpu community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://matrix.to/#/%23wgpu:matrix.org"&gt;&lt;img src="https://img.shields.io/static/v1?label=wgpu-devs&amp;amp;message=%23wgpu&amp;amp;color=blueviolet&amp;amp;logo=matrix" alt="Wgpu Matrix"&gt;&lt;/a&gt; - discussion of the wgpu's development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://matrix.to/#/%23naga:matrix.org"&gt;&lt;img src="https://img.shields.io/static/v1?label=naga-devs&amp;amp;message=%23naga&amp;amp;color=blueviolet&amp;amp;logo=matrix" alt="Naga Matrix"&gt;&lt;/a&gt; - discussion of the naga's development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://matrix.to/#/%23wgpu-users:matrix.org"&gt;&lt;img src="https://img.shields.io/static/v1?label=wgpu-users&amp;amp;message=%23wgpu-users&amp;amp;color=blueviolet&amp;amp;logo=matrix" alt="User Matrix"&gt;&lt;/a&gt; - discussion of using the library and the surrounding ecosystem.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://matrix.to/#/%23wgpu-random:matrix.org"&gt;&lt;img src="https://img.shields.io/static/v1?label=random&amp;amp;message=%23wgpu-random&amp;amp;color=blueviolet&amp;amp;logo=matrix" alt="Random Matrix"&gt;&lt;/a&gt; - discussion of everything else.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Wiki&lt;/h2&gt; 
&lt;p&gt;We have a &lt;a href="https://github.com/gfx-rs/wgpu/wiki"&gt;wiki&lt;/a&gt; that serves as a knowledge base.&lt;/p&gt; 
&lt;h2&gt;Extension Specifications&lt;/h2&gt; 
&lt;p&gt;While the core of wgpu is based on the WebGPU standard, we also support extensions that allow for features that the standard does not have yet. For high-level documentation on how to use these extensions, see the individual specifications:&lt;/p&gt; 
&lt;p&gt;üß™EXPERIMENTALüß™ APIs are subject to change and may allow undefined behavior if used incorrectly.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß™EXPERIMENTALüß™ &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/docs/api-specs/ray_tracing.md"&gt;Ray Tracing&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üß™EXPERIMENTALüß™ &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/docs/api-specs/mesh_shading.md"&gt;Mesh Shading&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Platforms&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;API&lt;/th&gt; 
   &lt;th&gt;Windows&lt;/th&gt; 
   &lt;th&gt;Linux/Android&lt;/th&gt; 
   &lt;th&gt;macOS/iOS&lt;/th&gt; 
   &lt;th&gt;Web (wasm)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vulkan&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;üåã&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Metal&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DX12&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenGL&lt;/td&gt; 
   &lt;td&gt;üÜó (GL 3.3+)&lt;/td&gt; 
   &lt;td&gt;üÜó (GL ES 3.0+)&lt;/td&gt; 
   &lt;td&gt;üìê&lt;/td&gt; 
   &lt;td&gt;üÜó (WebGL2)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;WebGPU&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;‚úÖ = First Class Support&lt;br&gt; üÜó = Downlevel/Best Effort Support&lt;br&gt; üìê = Requires the &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/#angle"&gt;ANGLE&lt;/a&gt; translation layer (GL ES 3.0 only)&lt;br&gt; üåã = Requires the &lt;a href="https://vulkan.lunarg.com/sdk/home#mac"&gt;MoltenVK&lt;/a&gt; translation layer&lt;br&gt; üõ†Ô∏è = Unsupported, though open to contributions&lt;/p&gt; 
&lt;h3&gt;Shader Support&lt;/h3&gt; 
&lt;p&gt;wgpu supports shaders in &lt;a href="https://gpuweb.github.io/gpuweb/wgsl/"&gt;WGSL&lt;/a&gt;, SPIR-V, and GLSL. Both &lt;a href="https://github.com/Microsoft/DirectXShaderCompiler"&gt;HLSL&lt;/a&gt; and &lt;a href="https://github.com/KhronosGroup/glslang"&gt;GLSL&lt;/a&gt; have compilers to target SPIR-V. All of these shader languages can be used with any backend as we handle all of the conversions. Additionally, support for these shader inputs is not going away.&lt;/p&gt; 
&lt;p&gt;While WebGPU does not support any shading language other than WGSL, we will automatically convert your non-WGSL shaders if you're running on WebGPU.&lt;/p&gt; 
&lt;p&gt;WGSL is always supported by default, but GLSL and SPIR-V need features enabled to compile in support.&lt;/p&gt; 
&lt;p&gt;Note that the WGSL specification is still under development, so the &lt;a href="https://gpuweb.github.io/gpuweb/wgsl/"&gt;draft specification&lt;/a&gt; does not exactly describe what &lt;code&gt;wgpu&lt;/code&gt; supports. See &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/#tracking-the-webgpu-and-wgsl-draft-specifications"&gt;below&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;To enable SPIR-V shaders, enable the &lt;code&gt;spirv&lt;/code&gt; feature of wgpu. To enable GLSL shaders, enable the &lt;code&gt;glsl&lt;/code&gt; feature of wgpu.&lt;/p&gt; 
&lt;h3&gt;Angle&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://angleproject.org"&gt;Angle&lt;/a&gt; is a translation layer from GLES to other backends developed by Google. We support running our GLES3 backend over it in order to reach platforms DX11 support, which aren't accessible otherwise. In order to run with Angle, the "angle" feature has to be enabled, and Angle libraries placed in a location visible to the application. These binaries can be downloaded from &lt;a href="https://github.com/DileSoft/gfbuild-angle"&gt;gfbuild-angle&lt;/a&gt; artifacts, &lt;a href="https://github.com/google/angle/raw/main/doc/DevSetup.md"&gt;manual compilation&lt;/a&gt; may be required on Macs with Apple silicon.&lt;/p&gt; 
&lt;p&gt;On Windows, you generally need to copy them into the working directory, in the same directory as the executable, or somewhere in your path. On Linux, you can point to them using &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; environment.&lt;/p&gt; 
&lt;h3&gt;MSRV policy&lt;/h3&gt; 
&lt;p&gt;Due to complex dependants, we have two MSRV policies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;naga&lt;/code&gt;, &lt;code&gt;wgpu-core&lt;/code&gt;, &lt;code&gt;wgpu-hal&lt;/code&gt;, and &lt;code&gt;wgpu-types&lt;/code&gt;'s MSRV is &lt;strong&gt;1.82&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;The rest of the workspace has an MSRV of &lt;strong&gt;1.88&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;It is enforced on CI (in "/.github/workflows/ci.yml") with the &lt;code&gt;CORE_MSRV&lt;/code&gt; and &lt;code&gt;REPO_MSRV&lt;/code&gt; variables. This version can only be upgraded in breaking releases, though we release a breaking version every three months.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;naga&lt;/code&gt;, &lt;code&gt;wgpu-core&lt;/code&gt;, &lt;code&gt;wgpu-hal&lt;/code&gt;, and &lt;code&gt;wgpu-types&lt;/code&gt; crates should never require an MSRV ahead of Firefox's MSRV for nightly builds, as determined by the value of &lt;code&gt;MINIMUM_RUST_VERSION&lt;/code&gt; in &lt;a href="https://searchfox.org/mozilla-central/source/python/mozboot/mozboot/util.py"&gt;&lt;code&gt;python/mozboot/mozboot/util.py&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Environment Variables&lt;/h2&gt; 
&lt;p&gt;All testing and example infrastructure share the same set of environment variables that determine which Backend/GPU it will run on.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;WGPU_ADAPTER_NAME&lt;/code&gt; with a substring of the name of the adapter you want to use (ex. &lt;code&gt;1080&lt;/code&gt; will match &lt;code&gt;NVIDIA GeForce 1080ti&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;WGPU_BACKEND&lt;/code&gt; with a comma-separated list of the backends you want to use (&lt;code&gt;vulkan&lt;/code&gt;, &lt;code&gt;metal&lt;/code&gt;, &lt;code&gt;dx12&lt;/code&gt;, or &lt;code&gt;gl&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;WGPU_POWER_PREF&lt;/code&gt; with the power preference to choose when a specific adapter name isn't specified (&lt;code&gt;high&lt;/code&gt;, &lt;code&gt;low&lt;/code&gt; or &lt;code&gt;none&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;WGPU_DX12_COMPILER&lt;/code&gt; with the DX12 shader compiler you wish to use (&lt;code&gt;dxc&lt;/code&gt;, &lt;code&gt;static-dxc&lt;/code&gt;, or &lt;code&gt;fxc&lt;/code&gt;). Note that &lt;code&gt;dxc&lt;/code&gt; requires &lt;code&gt;dxcompiler.dll&lt;/code&gt; (min v1.8.2502) to be in the working directory, and &lt;code&gt;static-dxc&lt;/code&gt; requires the &lt;code&gt;static-dxc&lt;/code&gt; crate feature to be enabled. Otherwise, it will fall back to &lt;code&gt;fxc&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;WGPU_GLES_MINOR_VERSION&lt;/code&gt; with the minor OpenGL ES 3 version number to request (&lt;code&gt;0&lt;/code&gt;, &lt;code&gt;1&lt;/code&gt;, &lt;code&gt;2&lt;/code&gt; or &lt;code&gt;automatic&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;WGPU_ALLOW_UNDERLYING_NONCOMPLIANT_ADAPTER&lt;/code&gt; with a boolean whether non-compliant drivers are enumerated (&lt;code&gt;0&lt;/code&gt; for false, &lt;code&gt;1&lt;/code&gt; for true).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When running the CTS, use the variables &lt;code&gt;DENO_WEBGPU_ADAPTER_NAME&lt;/code&gt;, &lt;code&gt;DENO_WEBGPU_BACKEND&lt;/code&gt;, &lt;code&gt;DENO_WEBGPU_POWER_PREFERENCE&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Testing&lt;/h2&gt; 
&lt;p&gt;We have multiple methods of testing, each of which tests different qualities about wgpu. We automatically run our tests on CI. The current state of CI testing:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform/Backend&lt;/th&gt; 
   &lt;th&gt;Tests&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/DX12&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úî&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;using WARP&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows/OpenGL&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úî&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;using llvmpipe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MacOS/Metal&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úî&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;using hardware runner&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux/Vulkan&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úî&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;using lavapipe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux/OpenGL ES&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úî&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;using llvmpipe&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chrome/WebGL&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚úî&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;using swiftshader&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chrome/WebGPU&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;‚ùå&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;not set up&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Core Test Infrastructure&lt;/h3&gt; 
&lt;p&gt;We use a tool called &lt;a href="https://github.com/nextest-rs/nextest"&gt;&lt;code&gt;cargo nextest&lt;/code&gt;&lt;/a&gt; to run our tests. To install it, run &lt;code&gt;cargo install cargo-nextest&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To run the test suite:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo xtask test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run the test suite on WebGL (currently incomplete):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cd wgpu
wasm-pack test --headless --chrome --no-default-features --features webgl --workspace
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will automatically run the tests using a packaged browser. Remove &lt;code&gt;--headless&lt;/code&gt; to run the tests with whatever browser you wish at &lt;code&gt;http://localhost:8000&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you are a user and want a way to help contribute to wgpu, we always need more help writing test cases.&lt;/p&gt; 
&lt;h3&gt;WebGPU Conformance Test Suite&lt;/h3&gt; 
&lt;p&gt;WebGPU includes a Conformance Test Suite to validate that implementations are working correctly. We run cases from the CTS against wgpu using &lt;a href="https://deno.com/"&gt;Deno&lt;/a&gt;. A &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/cts_runner/test.lst"&gt;default list of enabled tests&lt;/a&gt; is automatically run on pull requests in CI.&lt;/p&gt; 
&lt;p&gt;To run the default set of CTS tests locally, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo xtask cts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also specify a test selector on the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo xtask cts 'webgpu:api,operation,command_buffer,basic:*'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or supply your own test list in a file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo xtask cts -f your_tests.lst
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To find the full list of tests, go to the &lt;a href="https://gpuweb.github.io/cts/standalone/?runnow=0&amp;amp;worker=0&amp;amp;debug=0&amp;amp;q=webgpu:*"&gt;web version of the CTS&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The version of the CTS used by &lt;code&gt;cargo xtask cts&lt;/code&gt; is specified in &lt;a href="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/cts_runner/revision.txt"&gt;&lt;code&gt;cts_runner/revision.txt&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Tracking the WebGPU and WGSL draft specifications&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;wgpu&lt;/code&gt; crate is meant to be an idiomatic Rust translation of the &lt;a href="https://www.w3.org/TR/webgpu/"&gt;WebGPU API&lt;/a&gt;. That specification, along with its shading language, &lt;a href="https://gpuweb.github.io/gpuweb/wgsl/"&gt;WGSL&lt;/a&gt;, are both still in the "Working Draft" phase, and while the general outlines are stable, details change frequently. Until the specification is stabilized, the &lt;code&gt;wgpu&lt;/code&gt; crate and the version of WGSL it implements will likely differ from what is specified, as the implementation catches up.&lt;/p&gt; 
&lt;p&gt;Exactly which WGSL features &lt;code&gt;wgpu&lt;/code&gt; supports depends on how you are using it:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;When running as native code, &lt;code&gt;wgpu&lt;/code&gt; uses the &lt;a href="https://github.com/gfx-rs/naga/"&gt;Naga&lt;/a&gt; crate to translate WGSL code into the shading language of your platform's native GPU API. Naga has &lt;a href="https://github.com/gfx-rs/naga/milestone/4"&gt;a milestone&lt;/a&gt; for catching up to the WGSL specification, but in general, there is no up-to-date summary of the differences between Naga and the WGSL spec.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;When running in a web browser (by compilation to WebAssembly) without the &lt;code&gt;"webgl"&lt;/code&gt; feature enabled, &lt;code&gt;wgpu&lt;/code&gt; relies on the browser's own WebGPU implementation. WGSL shaders are simply passed through to the browser, so that determines which WGSL features you can use.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;When running in a web browser with &lt;code&gt;wgpu&lt;/code&gt;'s &lt;code&gt;"webgl"&lt;/code&gt; feature enabled, &lt;code&gt;wgpu&lt;/code&gt; uses Naga to translate WGSL programs into GLSL. This uses the same version of Naga as if you were running &lt;code&gt;wgpu&lt;/code&gt; as native code.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Coordinate Systems&lt;/h2&gt; 
&lt;p&gt;wgpu uses the coordinate systems of D3D and Metal:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Render&lt;/th&gt; 
   &lt;th&gt;Texture&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/docs/render_coordinates.png" alt="render_coordinates"&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/gfx-rs/wgpu/trunk/docs/texture_coordinates.png" alt="texture_coordinates"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>get-convex/convex-backend</title>
      <link>https://github.com/get-convex/convex-backend</link>
      <description>&lt;p&gt;The open-source reactive database for app developers&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://static.convex.dev/logo/convex-logo-light.svg" width="600"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://static.convex.dev/logo/convex-logo.svg" width="600"&gt; 
  &lt;img alt="Convex logo" src="https://static.convex.dev/logo/convex-logo.svg?sanitize=true" width="600"&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://convex.dev"&gt;Convex&lt;/a&gt; is the open-source reactive database designed to make life easy for web app developers, whether human or LLM. Fetch data and perform business logic with strong consistency by writing pure TypeScript.&lt;/p&gt; 
&lt;p&gt;Convex provides a database, a place to write your server functions, and client libraries. It makes it easy to build and scale dynamic live-updating apps. &lt;a href="https://docs.convex.dev/understanding/"&gt;Read the docs to learn more&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Development of the Convex backend is led by the Convex team. We &lt;a href="https://raw.githubusercontent.com/get-convex/convex-backend/main/CONTRIBUTING.md"&gt;welcome bug fixes&lt;/a&gt; and &lt;a href="https://discord.gg/convex"&gt;love receiving feedback&lt;/a&gt;. We keep this repository synced with any internal development work within a handful of days.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://docs.convex.dev/"&gt;documentation&lt;/a&gt; to learn more about Convex and follow our getting started guides.&lt;/p&gt; 
&lt;p&gt;The easiest way to build with Convex is through our &lt;a href="https://www.convex.dev/plans"&gt;cloud platform&lt;/a&gt;, which includes a generous free tier and lets you focus on building your application without worrying about infrastructure. Many small applications and side-projects can operate entirely on the free tier with zero cost and zero maintenance.&lt;/p&gt; 
&lt;h2&gt;Self Hosting&lt;/h2&gt; 
&lt;p&gt;The self-hosted product includes most features of the cloud product, including the dashboard and CLI. Self-hosted Convex works well with a variety of tools including Neon, Fly.io, Vercel, Netlify, RDS, Sqlite, Postgres, and more.&lt;/p&gt; 
&lt;p&gt;You can either use Docker (recommended) or a prebuilt binary to self host Convex. Check out our &lt;a href="https://raw.githubusercontent.com/get-convex/convex-backend/main/self-hosted/README.md"&gt;self-hosting guide&lt;/a&gt; for detailed instructions. Community support for self-hosting is available in the &lt;code&gt;#self-hosted&lt;/code&gt; channel on &lt;a href="https://discord.gg/convex"&gt;Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join our &lt;a href="https://discord.gg/convex"&gt;Discord community&lt;/a&gt; for help and discussions.&lt;/li&gt; 
 &lt;li&gt;Report issues when building and using the open source Convex backend through &lt;a href="https://github.com/get-convex/convex-backend/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Building from source&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/get-convex/convex-backend/main/BUILD.md"&gt;BUILD.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Disclaimers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you choose to self-host, we recommend following the self-hosting guide. If you are instead building from source, make sure to change your instance secret and admin key from the defaults in the repo.&lt;/li&gt; 
 &lt;li&gt;Convex is battle tested most thoroughly on Linux and Mac. On Windows, it has less experience. If you run into issues, please message us on &lt;a href="https://convex.dev/community"&gt;Discord&lt;/a&gt; in the &lt;code&gt;#self-hosted&lt;/code&gt; channel.&lt;/li&gt; 
 &lt;li&gt;Convex self-hosted builds contain a beacon to help Convex improve the product. The information is minimal and anonymous and helpful to Convex, but if you really want to disable it, you can set the &lt;code&gt;--disable-beacon&lt;/code&gt; flag on the backend binary. The beacon's messages print in the log and only include 
  &lt;ul&gt; 
   &lt;li&gt;A random identifier for your deployment (not used elsewhere)&lt;/li&gt; 
   &lt;li&gt;Migration version of your database&lt;/li&gt; 
   &lt;li&gt;Git rev of the backend&lt;/li&gt; 
   &lt;li&gt;Uptime of the backend&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Repository layout&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;crates/&lt;/code&gt; contains Rust code&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Main binary 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;local_backend/&lt;/code&gt; is an application server on top of the &lt;code&gt;Runtime&lt;/code&gt;. This is the serving edge for the Convex cloud.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;npm-packages/&lt;/code&gt; contains both our public and internal TypeScript packages.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Internal packages 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;udf-runtime/&lt;/code&gt; sets up the user-defined functions JS environment for queries and mutations&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;udf-tests/&lt;/code&gt; is a collection of functions used in testing the isolate layer&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;system-udfs/&lt;/code&gt; contains functions used by the Convex system e.g. the CLI&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>tree-sitter/tree-sitter</title>
      <link>https://github.com/tree-sitter/tree-sitter</link>
      <description>&lt;p&gt;An incremental parsing system for programming tools&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;tree-sitter&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://zenodo.org/badge/latestdoi/14164618"&gt;&lt;img src="https://zenodo.org/badge/14164618.svg?sanitize=true" alt="DOI"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/w7nTvsVJhm"&gt;&lt;img src="https://img.shields.io/discord/1063097320771698699?logo=discord&amp;amp;label=discord" alt="discord"&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/%23tree-sitter-chat:matrix.org"&gt;&lt;img src="https://img.shields.io/matrix/tree-sitter-chat%3Amatrix.org?logo=matrix&amp;amp;label=matrix" alt="matrix"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source file and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;General&lt;/strong&gt; enough to parse any programming language&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt; enough to parse on every keystroke in a text editor&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Robust&lt;/strong&gt; enough to provide useful results even in the presence of syntax errors&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dependency-free&lt;/strong&gt; so that the runtime library (which is written in pure C) can be embedded in any application&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://tree-sitter.github.io"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tree-sitter/tree-sitter/master/lib/binding_rust/README.md"&gt;Rust binding&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tree-sitter/tree-sitter/master/lib/binding_web/README.md"&gt;WASM binding&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tree-sitter/tree-sitter/master/crates/cli/README.md"&gt;Command-line interface&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>tracel-ai/burn</title>
      <link>https://github.com/tracel-ai/burn</link>
      <description>&lt;p&gt;Burn is a next generation Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/logo-burn-neutral.webp" width="350px"&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/uPEBbYYDB6"&gt;&lt;img src="https://img.shields.io/discord/1038839012602941528.svg?color=7289da&amp;amp;&amp;amp;logo=discord" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/v/burn.svg?sanitize=true" alt="Current Crates.io Version"&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/msrv/burn" alt="Minimum Supported Rust Version"&gt;&lt;/a&gt; &lt;a href="https://burn.dev/docs/burn"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-blue" alt="Documentation"&gt;&lt;/a&gt; &lt;a href="https://github.com/tracel-ai/burn/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/tracel-ai/burn/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Test Status"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/#license"&gt;&lt;img src="https://shields.io/badge/license-MIT%2FApache--2.0-blue" alt="license"&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/tracel-ai/burn"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.runblaze.dev"&gt;&lt;img src="https://www.runblaze.dev/ci-blaze-powered.png" width="125px"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;p&gt;&lt;strong&gt;Burn is a next generation Deep Learning Framework that doesn't compromise on &lt;br&gt; flexibility, efficiency and portability.&lt;/strong&gt;&lt;/p&gt; 
 &lt;br&gt; 
&lt;/div&gt; 
&lt;div align="left"&gt; 
 &lt;h2&gt;Performance&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-blazingly-fast.png" height="96px"&gt; 
  &lt;p&gt;Because we believe the goal of a deep learning framework is to convert computation into useful intelligence, we have made performance a core pillar of Burn. We strive to achieve top efficiency by leveraging multiple optimization techniques described below.&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;Click on each section for more details&lt;/strong&gt; üëá&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;br&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Automatic kernel fusion üí• &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Using Burn means having your models optimized on any backend. When possible, we provide a way to automatically and dynamically create custom kernels that minimize data relocation between different memory spaces, extremely useful when moving memory is the bottleneck.&lt;/p&gt; 
  &lt;p&gt;As an example, you could write your own GELU activation function with the high level tensor api (see Rust code snippet below).&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;fn gelu_custom&amp;lt;B: Backend, const D: usize&amp;gt;(x: Tensor&amp;lt;B, D&amp;gt;) -&amp;gt; Tensor&amp;lt;B, D&amp;gt; {
    let x = x.clone() * ((x / SQRT_2).erf() + 1);
    x / 2
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Then, at runtime, a custom low-level kernel will be automatically created for your specific implementation and will rival a handcrafted GPU implementation. The kernel consists of about 60 lines of WGSL &lt;a href="%22https://www.w3.org/TR/WGSL/https://www.w3.org/TR/WGSL/%22"&gt;WebGPU Shading Language&lt;/a&gt;, an extremely verbose lower level shader language you probably don't want to program your deep learning models in!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Asynchronous execution ‚ù§Ô∏è‚Äçüî• &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;For &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/#backends"&gt;first-party backends&lt;/a&gt;, an asynchronous execution style is used, which allows to perform various optimizations, such as the previously mentioned automatic kernel fusion.&lt;/p&gt; 
  &lt;p&gt;Asynchronous execution also ensures that the normal execution of the framework does not block the model computations, which implies that the framework overhead won't impact the speed of execution significantly. Conversely, the intense computations in the model do not interfere with the responsiveness of the framework. For more information about our asynchronous backends, see &lt;a href="https://burn.dev/blog/creating-high-performance-asynchronous-backends-with-burn-compute"&gt;this blog post&lt;/a&gt;.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Thread-safe building blocks ü¶û &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Burn emphasizes thread safety by leveraging the &lt;a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html"&gt;ownership system of Rust&lt;/a&gt;. With Burn, each module is the owner of its weights. It is therefore possible to send a module to another thread for computing the gradients, then send the gradients to the main thread that can aggregate them, and &lt;em&gt;voil√†&lt;/em&gt;, you get multi-device training.&lt;/p&gt; 
  &lt;p&gt;This is a very different approach from what PyTorch does, where backpropagation actually mutates the &lt;em&gt;grad&lt;/em&gt; attribute of each tensor parameter. This is not a thread-safe operation and therefore requires lower level synchronization primitives, see &lt;a href="https://pytorch.org/docs/stable/distributed.html"&gt;distributed training&lt;/a&gt; for reference. Note that this is still very fast, but not compatible across different backends and quite hard to implement.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Intelligent memory management ü¶Ä &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;One of the main roles of a deep learning framework is to reduce the amount of memory necessary to run models. The naive way of handling memory is that each tensor has its own memory space, which is allocated when the tensor is created then deallocated as the tensor gets out of scope. However, allocating and deallocating data is very costly, so a memory pool is often required to achieve good throughput. Burn offers an infrastructure that allows for easily creating and selecting memory management strategies for backends. For more details on memory management in Burn, see &lt;a href="https://burn.dev/blog/creating-high-performance-asynchronous-backends-with-burn-compute"&gt;this blog post&lt;/a&gt;.&lt;/p&gt; 
  &lt;p&gt;Another very important memory optimization of Burn is that we keep track of when a tensor can be mutated in-place just by using the ownership system well. Even though it is a rather small memory optimization on its own, it adds up considerably when training or running inference with larger models and contributes to reduce the memory usage even more. For more information, see &lt;a href="https://burn.dev/blog/burn-rusty-approach-to-tensor-handling"&gt;this blog post about tensor handling&lt;/a&gt;.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Automatic kernel selection üéØ &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;A good deep learning framework should ensure that models run smoothly on all hardware. However, not all hardware share the same behavior in terms of execution speed. For instance, a matrix multiplication kernel can be launched with many different parameters, which are highly sensitive to the size of the matrices and the hardware. Using the wrong configuration could reduce the speed of execution by a large factor (10 times or even more in extreme cases), so choosing the right kernels becomes a priority.&lt;/p&gt; 
  &lt;p&gt;With our home-made backends, we run benchmarks automatically and choose the best configuration for the current hardware and matrix sizes with a reasonable caching strategy.&lt;/p&gt; 
  &lt;p&gt;This adds a small overhead by increasing the warmup execution time, but stabilizes quickly after a few forward and backward passes, saving lots of time in the long run. Note that this feature isn't mandatory, and can be disabled when cold starts are a priority over optimized throughput.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Hardware specific features üî• &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;It is no secret that deep learning is mostly relying on matrix multiplication as its core operation, since this is how fully-connected neural networks are modeled.&lt;/p&gt; 
  &lt;p&gt;More and more, hardware manufacturers optimize their chips specifically for matrix multiplication workloads. For instance, Nvidia has its &lt;em&gt;Tensor Cores&lt;/em&gt; and today most cellphones have AI specialized chips. As of this moment, we support Tensor Cores with our LibTorch, Candle, CUDA, Metal and WGPU/SPIR-V backends, but not other accelerators yet. We hope &lt;a href="https://github.com/gpuweb/gpuweb/issues/4195"&gt;this issue&lt;/a&gt; gets resolved at some point to bring support to our WGPU backend.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Custom Backend Extension üéí &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Burn aims to be the most flexible deep learning framework. While it's crucial to maintain compatibility with a wide variety of backends, Burn also provides the ability to extend the functionalities of a backend implementation to suit your personal modeling requirements.&lt;/p&gt; 
  &lt;p&gt;This versatility is advantageous in numerous ways, such as supporting custom operations like flash attention or manually writing your own kernel for a specific backend to enhance performance. See &lt;a href="https://burn.dev/books/burn/advanced/backend-extension/index.html"&gt;this section&lt;/a&gt; in the Burn Book üî• for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;br&gt; 
 &lt;h2&gt;Backend&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/backend-chip.png" height="96px"&gt; 
  &lt;p&gt;Burn strives to be as fast as possible on as many hardwares as possible, with robust implementations. We believe this flexibility is crucial for modern needs where you may train your models in the cloud, then deploy on customer hardwares, which vary from user to user.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;strong&gt;Supported Backends&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Backend&lt;/th&gt; 
    &lt;th&gt;Devices&lt;/th&gt; 
    &lt;th&gt;Class&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CUDA&lt;/td&gt; 
    &lt;td&gt;NVIDIA GPUs&lt;/td&gt; 
    &lt;td&gt;First-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;ROCm&lt;/td&gt; 
    &lt;td&gt;AMD GPUs&lt;/td&gt; 
    &lt;td&gt;First-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Metal&lt;/td&gt; 
    &lt;td&gt;Apple GPUs&lt;/td&gt; 
    &lt;td&gt;First-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Vulkan&lt;/td&gt; 
    &lt;td&gt;Most GPUs on Linux &amp;amp; Windows&lt;/td&gt; 
    &lt;td&gt;First-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wgpu&lt;/td&gt; 
    &lt;td&gt;Most GPUs&lt;/td&gt; 
    &lt;td&gt;First-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;NdArray&lt;/td&gt; 
    &lt;td&gt;Most CPUs&lt;/td&gt; 
    &lt;td&gt;Third-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;LibTorch&lt;/td&gt; 
    &lt;td&gt;Most GPUs &amp;amp; CPUs&lt;/td&gt; 
    &lt;td&gt;Third-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Candle&lt;/td&gt; 
    &lt;td&gt;Nvidia, Apple GPUs &amp;amp; CPUs&lt;/td&gt; 
    &lt;td&gt;Third-Party&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;br&gt; 
 &lt;p&gt;Compared to other frameworks, Burn has a very different approach to supporting many backends. By design, most code is generic over the Backend trait, which allows us to build Burn with swappable backends. This makes composing backend possible, augmenting them with additional functionalities such as autodifferentiation and automatic kernel fusion.&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Autodiff: Backend decorator that brings backpropagation to any backend üîÑ &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Contrary to the aforementioned backends, Autodiff is actually a backend &lt;em&gt;decorator&lt;/em&gt;. This means that it cannot exist by itself; it must encapsulate another backend.&lt;/p&gt; 
  &lt;p&gt;The simple act of wrapping a base backend with Autodiff transparently equips it with autodifferentiation support, making it possible to call backward on your model.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::backend::{Autodiff, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&amp;lt;Wgpu&amp;gt;;

    let x: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default);
    let y: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;amp;grads).unwrap();
    println!("{y_grad}");
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, it is impossible to make the mistake of calling backward on a model that runs on a backend that does not support autodiff (for inference), as this method is only offered by an Autodiff backend.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-autodiff/README.md"&gt;Autodiff Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Fusion: Backend decorator that brings kernel fusion to all first-party backends &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;This backend decorator enhances a backend with kernel fusion, provided that the inner backend supports it. Note that you can compose this backend with other backend decorators such as Autodiff. For now, only the WGPU and CUDA backends have support for fused kernels.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::backend::{Autodiff, Fusion, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&amp;lt;Fusion&amp;lt;Wgpu&amp;gt;&amp;gt;;

    let x: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default);
    let y: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;amp;grads).unwrap();
    println!("{y_grad}");
}

&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, we plan to implement automatic gradient checkpointing based on compute bound and memory bound operations, which will work gracefully with the fusion backend to make your code run even faster during training, see &lt;a href="https://github.com/tracel-ai/burn/issues/936"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-fusion/README.md"&gt;Fusion Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Router (Beta): Backend decorator that composes multiple backends into a single one &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;That backend simplifies hardware operability, if for instance you want to execute some operations on the CPU and other operations on the GPU.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::tensor::{Distribution, Tensor};
use burn::backend::{
    NdArray, Router, Wgpu, ndarray::NdArrayDevice, router::duo::MultiDevice, wgpu::WgpuDevice,
};

fn main() {
    type Backend = Router&amp;lt;(Wgpu, NdArray)&amp;gt;;

    let device_0 = MultiDevice::B1(WgpuDevice::DiscreteGpu(0));
    let device_1 = MultiDevice::B2(NdArrayDevice::Cpu);

    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_0);
    let tensor_cpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_1);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Remote (Beta): Backend decorator for remote backend execution, useful for distributed computations &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;That backend has two parts, one client and one server. The client sends tensor operations over the network to a remote compute backend. You can use any first-party backend as server in a single line of code:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;fn main_server() {
    // Start a server on port 3000.
    burn::server::start::&amp;lt;burn::backend::Cuda&amp;gt;(Default::default(), 3000);
}

fn main_client() {
    // Create a client that communicate with the server on port 3000.
    use burn::backend::{Autodiff, RemoteBackend};

    type Backend = Autodiff&amp;lt;RemoteDevice&amp;gt;;

    let device = RemoteDevice::new("ws://localhost:3000");
    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], Distribution::Default, &amp;amp;device);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;br&gt; 
 &lt;h2&gt;Training &amp;amp; Inference&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-wall.png" height="96px"&gt; 
  &lt;p&gt;The whole deep learning workflow is made easy with Burn, as you can monitor your training progress with an ergonomic dashboard, and run inference everywhere from embedded devices to large GPU clusters.&lt;/p&gt; 
  &lt;p&gt;Burn was built from the ground up with training and inference in mind. It's also worth noting how Burn, in comparison to frameworks like PyTorch, simplifies the transition from training to deployment, eliminating the need for code changes.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;br&gt; 
  &lt;a href="https://www.youtube.com/watch?v=N9RM5CQbNQc" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/burn-train-tui.png" alt="Burn Train TUI" width="75%"&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;strong&gt;Click on the following sections to expand üëá&lt;/strong&gt;&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Training Dashboard üìà &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;As you can see in the previous video (click on the picture!), a new terminal UI dashboard based on the &lt;a href="https://github.com/ratatui-org/ratatui"&gt;Ratatui&lt;/a&gt; crate allows users to follow their training with ease without having to connect to any external application.&lt;/p&gt; 
  &lt;p&gt;You can visualize your training and validation metrics updating in real-time and analyze the lifelong progression or recent history of any registered metrics using only the arrow keys. Break from the training loop without crashing, allowing potential checkpoints to be fully written or important pieces of code to complete without interruption üõ°&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; ONNX Support üê´ &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;ONNX (Open Neural Network Exchange) is an open-standard format that exports both the architecture and the weights of a deep learning model.&lt;/p&gt; 
  &lt;p&gt;Burn supports the importation of models that follow the ONNX standard so you can easily port a model you have written in another framework like TensorFlow or PyTorch to Burn to benefit from all the advantages our framework offers.&lt;/p&gt; 
  &lt;p&gt;Our ONNX support is further described in &lt;a href="https://burn.dev/books/burn/import/onnx-model.html"&gt;this section of the Burn Book üî•&lt;/a&gt;.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This crate is in active development and currently supports a &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-import/SUPPORTED-ONNX-OPS.md"&gt;limited set of ONNX operators&lt;/a&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Importing PyTorch or Safetensors Models üöö &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;You can load weights from PyTorch or Safetensors formats directly into your Burn-defined models. This makes it easy to reuse existing models while benefiting from Burn's performance and deployment features.&lt;/p&gt; 
  &lt;p&gt;Learn more:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/pytorch-model.html"&gt;Import pre-trained PyTorch models into Burn&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/safetensors-model.html"&gt;Load models from Safetensors format&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Inference in the Browser üåê &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Several of our backends can compile to Web Assembly: Candle and NdArray for CPU, and WGPU for GPU. This means that you can run inference directly within a browser. We provide several examples of this:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST&lt;/a&gt; where you can draw digits and a small convnet tries to find which one it is! 2Ô∏è‚É£ 7Ô∏è‚É£ üò∞&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification&lt;/a&gt; where you can upload images and classify them! üåÑ&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Embedded: &lt;i&gt;no_std&lt;/i&gt; support ‚öôÔ∏è &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Burn's core components support &lt;a href="https://docs.rust-embedded.org/book/intro/no-std.html"&gt;no_std&lt;/a&gt;. This means it can run in bare metal environment such as embedded devices without an operating system.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;As of now, only the NdArray backend can be used in a &lt;em&gt;no_std&lt;/em&gt; environment.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;br&gt; 
 &lt;h3&gt;Benchmarks&lt;/h3&gt; 
 &lt;p&gt;To evaluate performance across different backends and track improvements over time, we provide a dedicated benchmarking suite.&lt;/p&gt; 
 &lt;p&gt;Run and compare benchmarks using &lt;a href="https://github.com/tracel-ai/burn-bench"&gt;burn-bench&lt;/a&gt;.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Warning&lt;/strong&gt; When using one of the &lt;code&gt;wgpu&lt;/code&gt; backends, you may encounter compilation errors related to recursive type evaluation. This is due to complex type nesting within the &lt;code&gt;wgpu&lt;/code&gt; dependency chain. To resolve this issue, add the following line at the top of your &lt;code&gt;main.rs&lt;/code&gt; or &lt;code&gt;lib.rs&lt;/code&gt; file:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#![recursion_limit = "256"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;The default recursion limit (128) is often just below the required depth (typically 130-150) due to deeply nested associated types and trait bounds.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h2&gt;Getting Started&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-walking.png" height="96px"&gt; 
  &lt;p&gt;Just heard of Burn? You are at the right place! Just continue reading this section and we hope you can get on board really quickly.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;details&gt; 
  &lt;summary&gt; The Burn Book üî• &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;To begin working effectively with Burn, it is crucial to understand its key components and philosophy. This is why we highly recommend new users to read the first sections of &lt;a href="https://burn.dev/books/burn/"&gt;The Burn Book üî•&lt;/a&gt;. It provides detailed examples and explanations covering every facet of the framework, including building blocks like tensors, modules, and optimizers, all the way to advanced usage, like coding your own GPU kernels.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;The project is constantly evolving, and we try as much as possible to keep the book up to date with new additions. However, we might miss some details sometimes, so if you see something weird, let us know! We also gladly accept Pull Requests üòÑ&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Examples üôè &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Let's start with a code snippet that shows how intuitive the framework is to use! In the following, we declare a neural network module with some parameters along with its forward pass.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::nn;
use burn::module::Module;
use burn::tensor::backend::Backend;

#[derive(Module, Debug)]
pub struct PositionWiseFeedForward&amp;lt;B: Backend&amp;gt; {
    linear_inner: nn::Linear&amp;lt;B&amp;gt;,
    linear_outer: nn::Linear&amp;lt;B&amp;gt;,
    dropout: nn::Dropout,
    gelu: nn::Gelu,
}

impl&amp;lt;B: Backend&amp;gt; PositionWiseFeedForward&amp;lt;B&amp;gt; {
    pub fn forward&amp;lt;const D: usize&amp;gt;(&amp;amp;self, input: Tensor&amp;lt;B, D&amp;gt;) -&amp;gt; Tensor&amp;lt;B, D&amp;gt; {
        let x = self.linear_inner.forward(input);
        let x = self.gelu.forward(x);
        let x = self.dropout.forward(x);

        self.linear_outer.forward(x)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;We have a somewhat large amount of &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples"&gt;examples&lt;/a&gt; in the repository that shows how to use the framework in different scenarios.&lt;/p&gt; 
  &lt;p&gt;Following &lt;a href="https://burn.dev/books/burn/"&gt;the book&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/guide"&gt;Basic Workflow&lt;/a&gt; : Creates a custom CNN &lt;code&gt;Module&lt;/code&gt; to train on the MNIST dataset and use for inference.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-training-loop"&gt;Custom Training Loop&lt;/a&gt; : Implements a basic training loop instead of using the &lt;code&gt;Learner&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-wgpu-kernel"&gt;Custom WGPU Kernel&lt;/a&gt; : Learn how to create your own custom operation with the WGPU backend.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;Additional examples:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-csv-dataset"&gt;Custom CSV Dataset&lt;/a&gt; : Implements a dataset to parse CSV data for a regression task.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/simple-regression"&gt;Regression&lt;/a&gt; : Trains a simple MLP on the California Housing dataset to predict the median house value for a district.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-image-dataset"&gt;Custom Image Dataset&lt;/a&gt; : Trains a simple CNN on custom image dataset following a simple folder structure.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-renderer"&gt;Custom Renderer&lt;/a&gt; : Implements a custom renderer to display the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/building-blocks/learner.md"&gt;&lt;code&gt;Learner&lt;/code&gt;&lt;/a&gt; progress.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification Web&lt;/a&gt; : Image classification web browser demo using Burn, WGPU and WebAssembly.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST Inference on Web&lt;/a&gt; : An interactive MNIST inference demo in the browser. The demo is available &lt;a href="https://burn.dev/demo/"&gt;online&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist"&gt;MNIST Training&lt;/a&gt; : Demonstrates how to train a custom &lt;code&gt;Module&lt;/code&gt; (MLP) with the &lt;code&gt;Learner&lt;/code&gt; configured to log metrics and keep training checkpoints.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/named-tensor"&gt;Named Tensor&lt;/a&gt; : Performs operations with the experimental &lt;code&gt;NamedTensor&lt;/code&gt; feature.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/onnx-inference"&gt;ONNX Import Inference&lt;/a&gt; : Imports an ONNX model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/pytorch-import"&gt;PyTorch Import Inference&lt;/a&gt; : Imports a PyTorch model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-classification"&gt;Text Classification&lt;/a&gt; : Trains a text classification transformer model on the AG News or DbPedia dataset. The trained model can then be used to classify a text sample.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-generation"&gt;Text Generation&lt;/a&gt; : Trains a text generation transformer model on the DbPedia dataset.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/wgan"&gt;Wasserstein GAN MNIST&lt;/a&gt; : Trains a WGAN model to generate new handwritten digits based on MNIST.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;For more practical insights, you can clone the repository and run any of them directly on your computer!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Pre-trained Models ü§ñ &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;We keep an updated and curated list of models and examples built with Burn, see the &lt;a href="https://github.com/tracel-ai/models"&gt;tracel-ai/models repository&lt;/a&gt; for more details.&lt;/p&gt; 
  &lt;p&gt;Don't see the model you want? Don't hesitate to open an issue, and we may prioritize it. Built a model using Burn and want to share it? You can also open a Pull Request and add your model under the community section!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Why use Rust for Deep Learning? ü¶Ä &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Deep Learning is a special form of software where you need very high level abstractions as well as extremely fast execution time. Rust is the perfect candidate for that use case since it provides zero-cost abstractions to easily create neural network modules, and fine-grained control over memory to optimize every detail.&lt;/p&gt; 
  &lt;p&gt;It's important that a framework be easy to use at a high level so that its users can focus on innovating in the AI field. However, since running models relies so heavily on computations, performance can't be neglected.&lt;/p&gt; 
  &lt;p&gt;To this day, the mainstream solution to this problem has been to offer APIs in Python, but rely on bindings to low-level languages such as C/C++. This reduces portability, increases complexity and creates frictions between researchers and engineers. We feel like Rust's approach to abstractions makes it versatile enough to tackle this two languages dichotomy.&lt;/p&gt; 
  &lt;p&gt;Rust also comes with the Cargo package manager, which makes it incredibly easy to build, test, and deploy from any environment, which is usually a pain in Python.&lt;/p&gt; 
  &lt;p&gt;Although Rust has the reputation of being a difficult language at first, we strongly believe it leads to more reliable, bug-free solutions built faster (after some practice üòÖ)!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;br&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;Deprecation Note&lt;/strong&gt;&lt;br&gt;Since &lt;code&gt;0.14.0&lt;/code&gt;, the internal structure for tensor data has changed. The previous &lt;code&gt;Data&lt;/code&gt; struct was deprecated and officially removed since &lt;code&gt;0.17.0&lt;/code&gt; in favor of the new &lt;code&gt;TensorData&lt;/code&gt; struct, which allows for more flexibility by storing the underlying data as bytes and keeping the data type as a field. If you are using &lt;code&gt;Data&lt;/code&gt; in your code, make sure to switch to &lt;code&gt;TensorData&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;!-- &gt;
&gt; In the event that you are trying to load a model record saved in a previous version, make sure to
&gt; enable the `record-backward-compat` feature using a previous version of burn (&lt;=0.16.0). Otherwise,
&gt; the record won't be deserialized correctly and you will get an error message (which will also point
&gt; you to the backward compatible feature flag). The backward compatibility was maintained for
&gt; deserialization (loading), so as soon as you have saved the record again it will be saved according
&gt; to the new structure and you will be able to upgrade to this version. Please note that binary formats
&gt; are not backward compatible. Thus, you will need to load your record in a previous version and save it
&gt; to another of the self-describing record formats before using a compatible version (as described) with the
&gt; `record-backward-compat` feature flag. --&gt; 
 &lt;details id="deprecation"&gt; 
  &lt;summary&gt; Loading Model Records From Previous Versions ‚ö†Ô∏è &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;In the event that you are trying to load a model record saved in a version older than &lt;code&gt;0.14.0&lt;/code&gt;, make sure to use a compatible version (&lt;code&gt;0.14&lt;/code&gt;, &lt;code&gt;0.15&lt;/code&gt; or &lt;code&gt;0.16&lt;/code&gt;) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
  &lt;pre&gt;&lt;code&gt;features = [..., "record-backward-compat"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Otherwise, the record won't be deserialized correctly and you will get an error message. This error will also point you to the backward compatible feature flag.&lt;/p&gt; 
  &lt;p&gt;The backward compatibility was maintained for deserialization when loading records. Therefore, as soon as you have saved the record again it will be saved according to the new structure and you can upgrade back to the current version&lt;/p&gt; 
  &lt;p&gt;Please note that binary formats are not backward compatible. Thus, you will need to load your record in a previous version and save it in any of the other self-describing record format (e.g., using the &lt;code&gt;NamedMpkFileRecorder&lt;/code&gt;) before using a compatible version (as described) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;h2&gt;Community&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-community.png" height="96px"&gt; 
  &lt;p&gt;If you are excited about the project, don't hesitate to join our &lt;a href="https://discord.gg/uPEBbYYDB6"&gt;Discord&lt;/a&gt;! We try to be as welcoming as possible to everybody from any background. You can ask your questions and share what you built with the community!&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Before contributing, please take a moment to review our &lt;a href="https://github.com/tracel-ai/burn/tree/main/CODE-OF-CONDUCT.md"&gt;code of conduct&lt;/a&gt;. It's also highly recommended to read the &lt;a href="https://github.com/tracel-ai/burn/tree/main/contributor-book/src/project-architecture"&gt;architecture overview&lt;/a&gt;, which explains some of our architectural decisions. Refer to our &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;h2&gt;Status&lt;/h2&gt; 
 &lt;p&gt;Burn is currently in active development, and there will be breaking changes. While any resulting issues are likely to be easy to fix, there are no guarantees at this stage.&lt;/p&gt; 
 &lt;h2&gt;License&lt;/h2&gt; 
 &lt;p&gt;Burn is distributed under the terms of both the MIT license and the Apache License (Version 2.0). See &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; for details. Opening a pull request is assumed to signal agreement with these licensing terms.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>rustdesk/rustdesk</title>
      <link>https://github.com/rustdesk/rustdesk</link>
      <description>&lt;p&gt;An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/rustdesk/rustdesk/master/res/logo-header.svg?sanitize=true" alt="RustDesk - Your remote desktop"&gt;&lt;br&gt; &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#raw-steps-to-build"&gt;Build&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#how-to-build-with-docker"&gt;Docker&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#file-structure"&gt;Structure&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#snapshot"&gt;Snapshot&lt;/a&gt;&lt;br&gt; [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-UA.md"&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-CS.md"&gt;ƒçesky&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ZH.md"&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-HU.md"&gt;Magyar&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ES.md"&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FA.md"&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FR.md"&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DE.md"&gt;Deutsch&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PL.md"&gt;Polski&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ID.md"&gt;Indonesian&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FI.md"&gt;Suomi&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ML.md"&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-NL.md"&gt;Nederlands&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-IT.md"&gt;Italiano&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-RU.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PTBR.md"&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-EO.md"&gt;Esperanto&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-KR.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-AR.md"&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-VN.md"&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DA.md"&gt;Dansk&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-GR.md"&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-TR.md"&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-NO.md"&gt;Norsk&lt;/a&gt;]&lt;br&gt; &lt;b&gt;We need your help to translate this README, &lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/lang"&gt;RustDesk UI&lt;/a&gt; and &lt;a href="https://github.com/rustdesk/doc.rustdesk.com"&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Caution] &lt;strong&gt;Misuse Disclaimer:&lt;/strong&gt; &lt;br&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Chat with us: &lt;a href="https://discord.gg/nDceKgxnkV"&gt;Discord&lt;/a&gt; | &lt;a href="https://twitter.com/rustdesk"&gt;Twitter&lt;/a&gt; | &lt;a href="https://www.reddit.com/r/rustdesk"&gt;Reddit&lt;/a&gt; | &lt;a href="https://www.youtube.com/@rustdesk"&gt;YouTube&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ko-fi.com/I2I04VU09"&gt;&lt;img src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" alt="ko-fi"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, &lt;a href="https://rustdesk.com/server"&gt;set up your own&lt;/a&gt;, or &lt;a href="https://github.com/rustdesk/rustdesk-server-demo"&gt;write your own rendezvous/relay server&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png" alt="image"&gt;&lt;/p&gt; 
&lt;p&gt;RustDesk welcomes contribution from everyone. See &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for help getting started.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/wiki/FAQ"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/releases"&gt;&lt;strong&gt;BINARY DOWNLOAD&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/releases/tag/nightly"&gt;&lt;strong&gt;NIGHTLY BUILD&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://f-droid.org/en/packages/com.carriez.flutter_hbb"&gt;&lt;img src="https://f-droid.org/badge/get-it-on.png" alt="Get it on F-Droid" height="80"&gt;&lt;/a&gt; &lt;a href="https://flathub.org/apps/com.rustdesk.RustDesk"&gt;&lt;img src="https://flathub.org/api/badge?svg&amp;amp;locale=en" alt="Get it on Flathub" height="80"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;p&gt;Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our &lt;a href="https://github.com/rustdesk/rustdesk/raw/master/.github/workflows/flutter-build.yml"&gt;CI&lt;/a&gt; for building Flutter version.&lt;/p&gt; 
&lt;p&gt;Please download Sciter dynamic library yourself.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll"&gt;Windows&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so"&gt;Linux&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib"&gt;macOS&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Raw Steps to build&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Prepare your Rust development env and C++ build env&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://github.com/microsoft/vcpkg"&gt;vcpkg&lt;/a&gt;, and set &lt;code&gt;VCPKG_ROOT&lt;/code&gt; env variable correctly&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static&lt;/li&gt; 
   &lt;li&gt;Linux/macOS: vcpkg install libvpx libyuv opus aom&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;run &lt;code&gt;cargo run&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://rustdesk.com/docs/en/dev/build/"&gt;Build&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;How to Build on Linux&lt;/h2&gt; 
&lt;h3&gt;Ubuntu 18 (Debian 10)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;openSUSE Tumbleweed&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fedora 28 (CentOS 8)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Arch (Manjaro)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install vcpkg&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fix libvpx (For Fedora)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i 's/CFLAGS+=-I/CFLAGS+=-fPIC -I/g' Makefile
sed -i 's/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g' Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How to build with Docker&lt;/h2&gt; 
&lt;p&gt;Begin by cloning the repository and building the Docker container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t "rustdesk-builder" .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, each time you need to build the application, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID="$(id -u)" -e PGID="$(id -g)" rustdesk-builder
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the &lt;code&gt;&amp;lt;OPTIONAL-ARGS&amp;gt;&lt;/code&gt; position. For instance, if you wanted to build an optimized release version, you would run the command above followed by &lt;code&gt;--release&lt;/code&gt;. The resulting executable will be available in the target folder on your system, and can be run with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;target/debug/rustdesk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you're running a release executable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;target/release/rustdesk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as &lt;code&gt;install&lt;/code&gt; or &lt;code&gt;run&lt;/code&gt; are not currently supported via this method as they would install or run the program inside the container instead of the host.&lt;/p&gt; 
&lt;h2&gt;File Structure&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common"&gt;libs/hbb_common&lt;/a&gt;&lt;/strong&gt;: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/scrap"&gt;libs/scrap&lt;/a&gt;&lt;/strong&gt;: screen capture&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/enigo"&gt;libs/enigo&lt;/a&gt;&lt;/strong&gt;: platform specific keyboard/mouse control&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard"&gt;libs/clipboard&lt;/a&gt;&lt;/strong&gt;: file copy and paste implementation for Windows, Linux, macOS.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/ui"&gt;src/ui&lt;/a&gt;&lt;/strong&gt;: obsolete Sciter UI (deprecated)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/server"&gt;src/server&lt;/a&gt;&lt;/strong&gt;: audio/clipboard/input/video services, and network connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/client.rs"&gt;src/client.rs&lt;/a&gt;&lt;/strong&gt;: start a peer connection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs"&gt;src/rendezvous_mediator.rs&lt;/a&gt;&lt;/strong&gt;: Communicate with &lt;a href="https://github.com/rustdesk/rustdesk-server"&gt;rustdesk-server&lt;/a&gt;, wait for remote direct (TCP hole punching) or relayed connection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/platform"&gt;src/platform&lt;/a&gt;&lt;/strong&gt;: platform specific code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/flutter"&gt;flutter&lt;/a&gt;&lt;/strong&gt;: Flutter code for desktop and mobile&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js"&gt;flutter/web/js&lt;/a&gt;&lt;/strong&gt;: JavaScript for Flutter web client&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651" alt="Connection Manager"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea" alt="Connected to a Windows PC"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad" alt="File Transfer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5" alt="TCP Tunneling"&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vercel/turborepo</title>
      <link>https://github.com/vercel/turborepo</link>
      <description>&lt;p&gt;Build system optimized for JavaScript¬†and TypeScript, written in Rust&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://turborepo.com"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://user-images.githubusercontent.com/4060187/196936123-f6e1db90-784d-4174-b774-92502b718836.png"&gt; 
   &lt;img src="https://user-images.githubusercontent.com/4060187/196936104-5797972c-ab10-4834-bd61-0d1e5f442c9c.png" height="128"&gt; 
  &lt;/picture&gt; &lt;/a&gt;&lt;/p&gt;
&lt;h1 align="center"&gt;&lt;a href="https://turborepo.com"&gt;Turborepo&lt;/a&gt;&lt;/h1&gt;
&lt;a href="https://turborepo.com"&gt; &lt;/a&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a aria-label="Vercel logo" href="https://vercel.com/"&gt;&lt;img src="https://img.shields.io/badge/MADE%20BY%20Vercel-000000.svg?style=for-the-badge&amp;amp;logo=Vercel&amp;amp;labelColor=000"&gt;&lt;/a&gt; &lt;a aria-label="NPM version" href="https://www.npmjs.com/package/turbo"&gt;&lt;img alt="" src="https://img.shields.io/npm/v/turbo.svg?style=for-the-badge&amp;amp;labelColor=000000"&gt;&lt;/a&gt; &lt;a aria-label="License" href="https://github.com/vercel/turborepo/raw/main/LICENSE"&gt;&lt;img alt="" src="https://img.shields.io/npm/l/turbo.svg?style=for-the-badge&amp;amp;labelColor=000000&amp;amp;color="&gt;&lt;/a&gt; &lt;a aria-label="Join the community on GitHub" href="https://github.com/vercel/turborepo/discussions"&gt;&lt;img alt="" src="https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&amp;amp;logo=turborepo&amp;amp;labelColor=000000&amp;amp;logoWidth=20&amp;amp;logoColor=white"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Turborepo is a high-performance build system for JavaScript and TypeScript codebases, written in Rust.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Visit &lt;a href="https://turborepo.com"&gt;https://turborepo.com&lt;/a&gt; to get started with Turborepo.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/vercel/turborepo/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The Turborepo community can be found on &lt;a href="https://github.com/vercel/turborepo/discussions"&gt;GitHub Discussions&lt;/a&gt;, where you can ask questions, voice ideas, and share your projects.&lt;/p&gt; 
&lt;p&gt;To chat with other community members, you can join &lt;a href="https://vercel.community/tag/turborepo"&gt;Vercel Community's &lt;code&gt;#turborepo&lt;/code&gt; tag&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Our &lt;a href="https://github.com/vercel/turborepo/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; applies to all Turborepo community channels.&lt;/p&gt; 
&lt;h2&gt;Who is using Turborepo?&lt;/h2&gt; 
&lt;p&gt;Turborepo is used by the world's leading companies. Check out the &lt;a href="https://turborepo.com/showcase"&gt;Turborepo Showcase&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;p&gt;Follow &lt;a href="https://x.com/turborepo"&gt;@turborepo&lt;/a&gt; on X for project updates.&lt;/p&gt; 
&lt;h2&gt;Authors&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Turborepo&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jared Palmer (&lt;a href="https://x.com/jaredpalmer"&gt;@jaredpalmer&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you believe you have found a security vulnerability in Turborepo, we encourage you to responsibly disclose this and not open a public issue. We will investigate all legitimate reports. Email &lt;code&gt;security@vercel.com&lt;/code&gt; to disclose any security vulnerabilities.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://vercel.com/security"&gt;https://vercel.com/security&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>fujiapple852/trippy</title>
      <link>https://github.com/fujiapple852/trippy</link>
      <description>&lt;p&gt;A network diagnostic tool&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/fujiapple852/trippy/master/docs/src/assets/Trippy-Vertical-DarkMode.svg#gh-dark-mode-only" width="300"&gt; &lt;img src="https://raw.githubusercontent.com/fujiapple852/trippy/master/docs/src/assets/Trippy-Vertical.svg#gh-light-mode-only" width="300"&gt;&lt;br&gt; &lt;br&gt; &lt;a href="https://github.com/fujiapple852/trippy/actions/workflows/ci.yml"&gt; &lt;img src="https://github.com/fujiapple852/trippy/actions/workflows/ci.yml/badge.svg?branch=master"&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/trippy/0.13.0"&gt; &lt;img src="https://img.shields.io/crates/v/trippy.svg?sanitize=true"&gt;&lt;/a&gt; &lt;a href="https://repology.org/project/trippy/versions"&gt; &lt;img src="https://repology.org/badge/tiny-repos/trippy.svg?sanitize=true"&gt;&lt;/a&gt; &lt;a href="https://trippy.zulipchat.com"&gt; &lt;img src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg?sanitize=true"&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/%23trippy-dev:matrix.org"&gt; &lt;img src="https://img.shields.io/badge/matrix/trippy-dev:matrix.org-blue"&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt; Trippy combines the functionality of traceroute and ping and is designed to assist with the analysis of networking issues. &lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/fujiapple852/trippy/master/assets/0.12.0/demo.gif" alt="trippy"&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://trippy.rs/start/getting-started"&gt;getting started&lt;/a&gt; guide.&lt;/p&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;p&gt;Trippy runs on Linux, BSD, macOS, and Windows. It can be installed from most package managers, precompiled binaries, or source.&lt;/p&gt; 
&lt;p&gt;For example, to install Trippy from &lt;code&gt;cargo&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install trippy --locked
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;All package managers&lt;/summary&gt; 
 &lt;h3&gt;Cargo&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://crates.io/crates/trippy/0.13.0"&gt;&lt;img src="https://img.shields.io/crates/v/trippy" alt="Crates.io"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo install trippy --locked
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;APT (Debian)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://tracker.debian.org/pkg/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/debian_13/trippy.svg?sanitize=true" alt="Debian 13 package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;apt install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note:&lt;/p&gt; 
  &lt;p&gt;Only available for Debian 13 (&lt;code&gt;trixie&lt;/code&gt;) and later.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;PPA (Ubuntu)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://launchpad.net/~fujiapple/+archive/ubuntu/trippy/+packages"&gt;&lt;img src="https://img.shields.io/badge/Ubuntu%20PPA-0.13.0-brightgreen" alt="Ubuntu PPA"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;add-apt-repository ppa:fujiapple/trippy
apt update &amp;amp;&amp;amp; apt install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note:&lt;/p&gt; 
  &lt;p&gt;Only available for Ubuntu 24.04 (&lt;code&gt;Noble&lt;/code&gt;) and 22.04 (&lt;code&gt;Jammy&lt;/code&gt;).&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;Snap (Linux)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://snapcraft.io/trippy"&gt;&lt;img src="https://snapcraft.io/trippy/badge.svg?sanitize=true" alt="trippy"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;snap install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Homebrew (macOS)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://formulae.brew.sh/formula/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/homebrew/trippy.svg?sanitize=true" alt="Homebrew package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;brew install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;WinGet (Windows)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/microsoft/winget-pkgs/tree/master/manifests/f/FujiApple/Trippy/0.13.0"&gt;&lt;img src="https://img.shields.io/badge/WinGet-0.13.0-brightgreen" alt="winget package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;winget install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Scoop (Windows)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/ScoopInstaller/Main/raw/master/bucket/trippy.json"&gt;&lt;img src="https://img.shields.io/scoop/v/trippy?style=flat&amp;amp;labelColor=5c5c5c&amp;amp;color=%234dc71f" alt="Scoop package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;scoop install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Chocolatey (Windows)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://community.chocolatey.org/packages/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/chocolatey/trippy.svg?sanitize=true" alt="Chocolatey package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;choco install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;NetBSD&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://pkgsrc.se/net/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/pkgsrc_current/trippy.svg?sanitize=true" alt="pkgsrc current package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pkgin install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;FreeBSD&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://www.freshports.org/net/trippy/"&gt;&lt;img src="https://repology.org/badge/version-for-repo/freebsd/trippy.svg?sanitize=true" alt="FreeBSD port"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pkg install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;OpenBSD&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://openports.pl/path/net/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/openbsd/trippy.svg?sanitize=true" alt="OpenBSD port"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pkg_add trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Arch Linux&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://archlinux.org/packages/extra/x86_64/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/arch/trippy.svg?sanitize=true" alt="Arch package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pacman -S trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Gentoo Linux&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://packages.gentoo.org/packages/net-analyzer/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/gentoo/trippy.svg?sanitize=true" alt="Gentoo package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;emerge -av net-analyzer/trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Void Linux&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/void-linux/void-packages/tree/master/srcpkgs/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/void_x86_64/trippy.svg?sanitize=true" alt="Void Linux x86_64 package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;xbps-install -S trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;ALT Sisyphus&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://packages.altlinux.org/en/sisyphus/srpms/trippy/"&gt;&lt;img src="https://repology.org/badge/version-for-repo/altsisyphus/trippy.svg?sanitize=true" alt="ALT Sisyphus package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;apt-get install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Chimera Linux&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/chimera-linux/cports/tree/master/user/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/chimera/trippy.svg?sanitize=true" alt="Chimera Linux package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;apk add trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Nix&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/NixOS/nixpkgs/raw/master/pkgs/by-name/tr/trippy/package.nix"&gt;&lt;img src="https://repology.org/badge/version-for-repo/nix_unstable/trippy.svg?sanitize=true" alt="nixpkgs unstable package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;nix-env -iA trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Docker&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://hub.docker.com/r/fujiapple/trippy/"&gt;&lt;img src="https://img.shields.io/docker/v/fujiapple/trippy" alt="Docker Image Version (latest by date)"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;docker run -it fujiapple/trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;All Repositories&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://repology.org/project/trippy/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/trippy.svg?sanitize=true" alt="Packaging status"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;See the &lt;a href="https://trippy.rs/start/installation"&gt;installation&lt;/a&gt; guide for details of how to install Trippy on your system.&lt;/p&gt; 
&lt;h3&gt;Run&lt;/h3&gt; 
&lt;p&gt;To run a basic trace to &lt;code&gt;example.com&lt;/code&gt; with default settings, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sudo trip example.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://trippy.rs/guides/usage"&gt;usage examples&lt;/a&gt; and &lt;a href="https://trippy.rs/reference/cli"&gt;CLI reference&lt;/a&gt; for details of how to use Trippy. To use Trippy without elevated privileges, see the &lt;a href="https://trippy.rs/guides/privileges"&gt;privileges&lt;/a&gt; guide.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Full documentation is available at &lt;a href="https://trippy.rs"&gt;trippy.rs&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;documentation links&lt;/summary&gt; 
 &lt;h2&gt;Getting Started&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/start/getting-started/"&gt;Getting Started&lt;/a&gt; guide.&lt;/p&gt; 
 &lt;h2&gt;Features&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/start/features/"&gt;Features&lt;/a&gt; list.&lt;/p&gt; 
 &lt;h2&gt;Distributions&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/start/installation/"&gt;Distributions&lt;/a&gt; list.&lt;/p&gt; 
 &lt;h2&gt;Privileges&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/guides/privileges/"&gt;Privileges&lt;/a&gt; guide.&lt;/p&gt; 
 &lt;h2&gt;Usage Examples&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/guides/usage/"&gt;Usage Examples&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Command Reference&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/cli/"&gt;Command Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Theme Reference&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/theme/"&gt;Theme Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Column Reference&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/column/"&gt;Column Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Configuration Reference&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/configuration/"&gt;Configuration Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Locale Reference&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/locale/"&gt;Locale Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Versions&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/version/"&gt;Version Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; 
 &lt;h3&gt;Why does Trippy show "Awaiting data..."?&lt;/h3&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/guides/faq/"&gt;Awaiting Data&lt;/a&gt; guide.&lt;/p&gt; 
 &lt;p&gt;&lt;a name="windows-defender"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;How do I allow incoming ICMP traffic in the Windows Defender firewall?&lt;/h3&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/guides/windows_firewall/"&gt;Windows Defender Firewall&lt;/a&gt; guide.&lt;/p&gt; 
 &lt;h3&gt;What are the recommended settings for Trippy?&lt;/h3&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/guides/recommendation/"&gt;Recommended Tracing Settings&lt;/a&gt; guide.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;Trippy is made possible by &lt;a href="https://github.com/ratatui-org/ratatui"&gt;ratatui&lt;/a&gt; ( formerly &lt;a href="https://github.com/fdehau/tui-rs"&gt;tui-rs&lt;/a&gt;), &lt;a href="https://github.com/crossterm-rs/crossterm"&gt;crossterm&lt;/a&gt; as well as &lt;a href="https://github.com/fujiapple852/trippy/raw/master/Cargo.toml"&gt;several&lt;/a&gt; foundational Rust libraries.&lt;/p&gt; 
&lt;p&gt;Trippy draws heavily from &lt;a href="https://github.com/traviscross/mtr"&gt;mtr&lt;/a&gt; and also incorporates ideas from both &lt;a href="https://github.com/libparistraceroute/libparistraceroute"&gt;libparistraceroute&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/insomniacslk/dublin-traceroute"&gt;Dublin Traceroute&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The Trippy networking code is inspired by &lt;a href="https://github.com/libpnet/libpnet"&gt;pnet&lt;/a&gt; and some elements of that codebase are incorporated in Trippy.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://en.wikipedia.org/wiki/Autonomous_system_(Internet)"&gt;AS&lt;/a&gt; data is retrieved from the &lt;a href="https://team-cymru.com/community-services/ip-asn-mapping/#dns"&gt;IP to ASN Mapping Service&lt;/a&gt; provided by &lt;a href="https://team-cymru.com"&gt;Team Cymru&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://trippy.cli.rs"&gt;trippy.cli.rs&lt;/a&gt; CNAME hosting is provided by &lt;a href="https://cli.rs"&gt;cli.rs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The Trippy chat room is sponsored by &lt;a href="https://zulip.com"&gt;Zulip&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Trippy logo designed by &lt;a href="https://www.instagram.com/harunocaksiz"&gt;Harun Ocaksiz Design&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is distributed under the terms of the Apache License (Version 2.0).&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in time by you, as defined in the Apache-2.0 license, shall be licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/fujiapple852/trippy/master/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;Copyright 2022 &lt;a href="https://github.com/fujiapple852/trippy/graphs/contributors"&gt;Trippy Contributors&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>linera-io/linera-protocol</title>
      <link>https://github.com/linera-io/linera-protocol</link>
      <description>&lt;p&gt;Main repository for the Linera protocol&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://github.com/linera-io/linera-protocol/assets/1105398/fe08c941-93af-4114-bb83-bcc0eaec95f9" width="250" height="85"&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/linera-io/linera-protocol/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/linera-io/linera-protocol" alt="License"&gt;&lt;/a&gt; &lt;a href="https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml"&gt;&lt;img src="https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml/badge.svg?sanitize=true" alt="Build Status for Docker"&gt;&lt;/a&gt; &lt;a href="https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml"&gt;&lt;img src="https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml/badge.svg?sanitize=true" alt="Build Status for Rust"&gt;&lt;/a&gt; &lt;a href="https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml"&gt;&lt;img src="https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml/badge.svg?sanitize=true" alt="Build Status for Documentation"&gt;&lt;/a&gt; &lt;a href="https://x.com/linera_io"&gt;&lt;img src="https://img.shields.io/twitter/follow/linera_io" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/linera"&gt;&lt;img src="https://img.shields.io/discord/984941796272521226" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![Build Status for Kubernetes](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml) --&gt; 
&lt;p&gt;&lt;a href="https://linera.io"&gt;Linera&lt;/a&gt; is a decentralized blockchain infrastructure designed for highly scalable, secure, low-latency Web3 applications.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://linera.dev"&gt;developer page&lt;/a&gt; and read our &lt;a href="https://linera.io/whitepaper"&gt;whitepaper&lt;/a&gt; to learn more about the Linera protocol.&lt;/p&gt; 
&lt;h2&gt;Repository Structure&lt;/h2&gt; 
&lt;p&gt;The main crates and directories of this repository can be summarized as follows: (listed from low to high levels in the dependency graph)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_base/index.html"&gt;&lt;code&gt;linera-base&lt;/code&gt;&lt;/a&gt; Base definitions, including cryptography.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_version/index.html"&gt;&lt;code&gt;linera-version&lt;/code&gt;&lt;/a&gt; A library to manage version info in binaries and services.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_views/index.html"&gt;&lt;code&gt;linera-views&lt;/code&gt;&lt;/a&gt; A library mapping complex data structures onto a key-value store. The corresponding procedural macros are implemented in &lt;code&gt;linera-views-derive&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_execution/index.html"&gt;&lt;code&gt;linera-execution&lt;/code&gt;&lt;/a&gt; Persistent data and the corresponding logic for runtime and execution of Linera applications.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_chain/index.html"&gt;&lt;code&gt;linera-chain&lt;/code&gt;&lt;/a&gt; Persistent data and the corresponding logic for chains of blocks, certificates, and cross-chain messaging.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_storage/index.html"&gt;&lt;code&gt;linera-storage&lt;/code&gt;&lt;/a&gt; Defines the storage abstractions for the protocol on top of &lt;code&gt;linera-chain&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_core/index.html"&gt;&lt;code&gt;linera-core&lt;/code&gt;&lt;/a&gt; The core Linera protocol, including client and server logic, node synchronization, etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_rpc/index.html"&gt;&lt;code&gt;linera-rpc&lt;/code&gt;&lt;/a&gt; Defines the data-type for RPC messages (currently all client ‚Üî proxy ‚Üî chain ‚Üî chain interactions), and track the corresponding data schemas.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_client/index.html"&gt;&lt;code&gt;linera-client&lt;/code&gt;&lt;/a&gt; Library for writing Linera clients. Used for the command-line client and the node service in &lt;code&gt;linera-service&lt;/code&gt;, as well as the Web client in &lt;a href="https://github.com/linera-io/linera-web/"&gt;&lt;code&gt;linera-web&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_service/index.html"&gt;&lt;code&gt;linera-service&lt;/code&gt;&lt;/a&gt; Executable for clients (aka CLI wallets), proxy (aka validator frontend) and servers.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://linera-io.github.io/linera-protocol/linera_sdk/index.html"&gt;&lt;code&gt;linera-sdk&lt;/code&gt;&lt;/a&gt; The library to develop Linera applications written in Rust for the Wasm virtual machine. The corresponding procedural macros are implemented in &lt;code&gt;linera-sdk-derive&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/linera-io/linera-protocol/main/examples"&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt; Examples of Linera applications written in Rust.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/linera-io/linera-protocol/main/INSTALL.md"&gt;&lt;code&gt;INSTALL.md&lt;/code&gt;&lt;/a&gt; for software requirements to develop in this repo.&lt;/p&gt; 
&lt;h2&gt;Quickstart with the Linera CLI tool&lt;/h2&gt; 
&lt;p&gt;The following commands set up a local test network and run some transfers between the microchains owned by a single wallet.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Make sure to compile the Linera binaries and add them in the $PATH.
# cargo build -p linera-storage-service -p linera-service --bins
export PATH="$PWD/target/debug:$PATH"

# Import the optional helper function `linera_spawn`.
source /dev/stdin &amp;lt;&amp;lt;&amp;lt;"$(linera net helper 2&amp;gt;/dev/null)"

# Run a local test network with the default parameters and a number of microchains
# owned by the default wallet. This also defines `LINERA_TMP_DIR`.
linera_spawn \
linera net up --with-faucet --faucet-port 8080

# Remember the URL of the faucet.
FAUCET_URL=http://localhost:8080

# If you're using a testnet, start here and run this instead:
#   LINERA_TMP_DIR=$(mktemp -d)
#   FAUCET_URL=https://faucet.testnet-XXX.linera.net  # for some value XXX

# Set the path of the future wallet.
export LINERA_WALLET="$LINERA_TMP_DIR/wallet.json"
export LINERA_KEYSTORE="$LINERA_TMP_DIR/keystore.json"
export LINERA_STORAGE="rocksdb:$LINERA_TMP_DIR/client.db"

# Initialize a new user wallet.
linera wallet init --faucet $FAUCET_URL

# Request chains.
INFO1=($(linera wallet request-chain --faucet $FAUCET_URL))
INFO2=($(linera wallet request-chain --faucet $FAUCET_URL))
CHAIN1="${INFO1[0]}"
ACCOUNT1="${INFO1[1]}"
CHAIN2="${INFO2[0]}"
ACCOUNT2="${INFO2[1]}"

# Show the different chains tracked by the wallet.
linera wallet show

# Query the chain balance of some of the chains.
linera query-balance "$CHAIN1"
linera query-balance "$CHAIN2"

# Transfer 10 units then 5 back.
linera transfer 10 --from "$CHAIN1" --to "$CHAIN2"
linera transfer 5 --from "$CHAIN2" --to "$CHAIN1"

# Query balances again.
linera query-balance "$CHAIN1"
linera query-balance "$CHAIN2"

# Now let's fund the user balances.
linera transfer 5 --from "$CHAIN1" --to "$CHAIN1:$ACCOUNT1"
linera transfer 2 --from "$CHAIN1:$ACCOUNT1" --to "$CHAIN2:$ACCOUNT2"

# Query user balances again.
linera query-balance "$CHAIN1:$ACCOUNT1"
linera query-balance "$CHAIN2:$ACCOUNT2"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More complex examples may be found in our &lt;a href="https://linera.dev"&gt;developer manual&lt;/a&gt; as well as the &lt;a href="https://raw.githubusercontent.com/linera-io/linera-protocol/main/examples"&gt;example applications&lt;/a&gt; in this repository.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! If you'd like to contribute to the Linera protocol:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch (&lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Commit your changes (&lt;code&gt;git commit -m 'Add some amazing feature'&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Push to the branch (&lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Open a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For detailed guidelines, see our &lt;a href="https://raw.githubusercontent.com/linera-io/linera-protocol/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>helix-editor/helix</title>
      <link>https://github.com/helix-editor/helix</link>
      <description>&lt;p&gt;A post-modern modal text editor.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="logo_dark.svg"&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="logo_light.svg"&gt; 
   &lt;img alt="Helix" height="128" src="https://raw.githubusercontent.com/helix-editor/helix/master/logo_light.svg?sanitize=true"&gt; 
  &lt;/picture&gt; &lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/helix-editor/helix/actions"&gt;&lt;img src="https://github.com/helix-editor/helix/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build status"&gt;&lt;/a&gt; &lt;a href="https://github.com/helix-editor/helix/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/helix-editor/helix" alt="GitHub Release"&gt;&lt;/a&gt; &lt;a href="https://docs.helix-editor.com/"&gt;&lt;img src="https://shields.io/badge/-documentation-452859" alt="Documentation"&gt;&lt;/a&gt; &lt;a href="https://github.com/helix-editor/helix/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/helix-editor/helix" alt="GitHub contributors"&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/%23helix-community:matrix.org"&gt;&lt;img src="https://img.shields.io/matrix/helix-community:matrix.org" alt="Matrix Space"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/helix-editor/helix/master/screenshot.png" alt="Screenshot"&gt;&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://github.com/mawww/kakoune"&gt;Kakoune&lt;/a&gt; / &lt;a href="https://github.com/neovim/neovim"&gt;Neovim&lt;/a&gt; inspired editor, written in Rust.&lt;/p&gt; 
&lt;p&gt;The editing model is very heavily based on Kakoune; during development I found myself agreeing with most of Kakoune's design decisions.&lt;/p&gt; 
&lt;p&gt;For more information, see the &lt;a href="https://helix-editor.com"&gt;website&lt;/a&gt; or &lt;a href="https://docs.helix-editor.com/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;All shortcuts/keymaps can be found &lt;a href="https://docs.helix-editor.com/keymap.html"&gt;in the documentation on the website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/helix-editor/helix/wiki/Troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vim-like modal editing&lt;/li&gt; 
 &lt;li&gt;Multiple selections&lt;/li&gt; 
 &lt;li&gt;Built-in language server support&lt;/li&gt; 
 &lt;li&gt;Smart, incremental syntax highlighting and code editing via tree-sitter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Although it's primarily a terminal-based editor, I am interested in exploring a custom renderer (similar to Emacs) using wgpu or skulpin.&lt;/p&gt; 
&lt;p&gt;Note: Only certain languages have indentation definitions at the moment. Check &lt;code&gt;runtime/queries/&amp;lt;lang&amp;gt;/&lt;/code&gt; for &lt;code&gt;indents.scm&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://docs.helix-editor.com/install.html"&gt;Installation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/helix-editor/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/helix-editor.svg?exclude_unsupported=1" alt="Packaging status"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;Contributing guidelines can be found &lt;a href="https://raw.githubusercontent.com/helix-editor/helix/master/docs/CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Getting help&lt;/h1&gt; 
&lt;p&gt;Your question might already be answered on the &lt;a href="https://github.com/helix-editor/helix/wiki/FAQ"&gt;FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Discuss the project on the community &lt;a href="https://matrix.to/#/%23helix-community:matrix.org"&gt;Matrix Space&lt;/a&gt; (make sure to join &lt;code&gt;#helix-editor:matrix.org&lt;/code&gt; if you're on a client that doesn't support Matrix Spaces yet).&lt;/p&gt; 
&lt;h1&gt;Credits&lt;/h1&gt; 
&lt;p&gt;Thanks to &lt;a href="https://github.com/jakenvac"&gt;@jakenvac&lt;/a&gt; for designing the logo!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>espanso/espanso</title>
      <link>https://github.com/espanso/espanso</link>
      <description>&lt;p&gt;Cross-platform Text Expander written in Rust&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/espanso/espanso/dev/images/logo_extended.png" alt="espanso"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A cross-platform Text Expander written in Rust&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/v/release/espanso/espanso" alt="GitHub release (latest by date)"&gt; &lt;img src="https://img.shields.io/badge/language-rust-orange" alt="Language"&gt; &lt;img src="https://img.shields.io/badge/platforms-Windows%2C%20macOS%20and%20Linux-blue" alt="Platforms"&gt; &lt;img src="https://img.shields.io/github/license/espanso/espanso" alt="License"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/espanso/espanso/dev/images/example.gif" alt="example"&gt;&lt;/p&gt; 
&lt;p&gt;Visit the &lt;a href="https://espanso.org"&gt;espanso website&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;What is a Text Expander?&lt;/h4&gt; 
&lt;p&gt;A &lt;em&gt;text expander&lt;/em&gt; is a program that detects when you type a specific &lt;strong&gt;keyword&lt;/strong&gt; and replaces it with &lt;strong&gt;something else&lt;/strong&gt;. This is useful in many ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Save a lot of typing&lt;/strong&gt;, expanding common sentences.&lt;/li&gt; 
 &lt;li&gt;Create &lt;strong&gt;system-wide&lt;/strong&gt; code snippets.&lt;/li&gt; 
 &lt;li&gt;Execute &lt;strong&gt;custom scripts&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Use &lt;strong&gt;emojis&lt;/strong&gt; like a pro.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Works on &lt;strong&gt;Windows&lt;/strong&gt;, &lt;strong&gt;macOS&lt;/strong&gt; and &lt;strong&gt;Linux&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Works with almost &lt;strong&gt;any program&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Works with &lt;strong&gt;Emojis&lt;/strong&gt; üòÑ&lt;/li&gt; 
 &lt;li&gt;Works with &lt;strong&gt;Images&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Includes a powerful &lt;strong&gt;Search Bar&lt;/strong&gt; üîé&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Date&lt;/strong&gt; expansion support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom scripts&lt;/strong&gt; support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Shell commands&lt;/strong&gt; support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;App-specific&lt;/strong&gt; configurations&lt;/li&gt; 
 &lt;li&gt;Support &lt;a href="https://espanso.org/docs/matches/forms/"&gt;Forms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Expandable with &lt;strong&gt;packages&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Built-in &lt;strong&gt;package manager&lt;/strong&gt; for &lt;a href="https://hub.espanso.org/"&gt;espanso hub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;File based configuration&lt;/li&gt; 
 &lt;li&gt;Support Regex triggers&lt;/li&gt; 
 &lt;li&gt;Experimental Wayland support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;Visit the &lt;a href="https://espanso.org/docs/"&gt;official documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you need some help to setup espanso, want to ask a question or simply get involved in the community, you can &lt;a href="https://www.reddit.com/r/espanso/"&gt;join the official Subreddit&lt;/a&gt; or &lt;a href="https://discord.gg/DFcCNDg7bB"&gt;join the official Discord&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Donations&lt;/h2&gt; 
&lt;p&gt;espanso is a free, open source software developed in my (little) spare time. If you liked the project and would like to support further development, please consider making a small donation, it really helps :)&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;amp;hosted_button_id=FHNLR5DRS267E&amp;amp;source=url"&gt;&lt;img src="https://raw.githubusercontent.com/espanso/espanso/dev/images/donate.gif" alt="Donate with PayPal"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Many people helped the project along the way, thank you to all of you!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/espanso/espanso/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=espanso/espanso" alt="Image"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Remarks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://github.com/jordansissel/xdotool"&gt;libxdo&lt;/a&gt; and &lt;a href="https://github.com/astrand/xclip"&gt;xclip&lt;/a&gt;, used to implement the Linux port.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://xkbcommon.org/"&gt;libxkbcommon&lt;/a&gt; and &lt;a href="https://github.com/bugaevc/wl-clipboard"&gt;wl-clipboard&lt;/a&gt;, used to implement the Wayland port.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://www.wxwidgets.org/"&gt;wxWidgets&lt;/a&gt; for providing a powerful cross-platform GUI library.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;espanso was created by &lt;a href="http://federicoterzi.com"&gt;Federico Terzi&lt;/a&gt; and is licensed under the &lt;a href="https://raw.githubusercontent.com/espanso/espanso/dev/LICENSE"&gt;GPL-3.0 license&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>astral-sh/uv</title>
      <link>https://github.com/astral-sh/uv</link>
      <description>&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;uv&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json" alt="uv"&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/v/uv.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/l/uv.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/uv.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv/actions"&gt;&lt;img src="https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Actions status"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/astral-sh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d"&gt; 
  &lt;img alt="Shows a bar chart with benchmark results." src="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d"&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Installing &lt;a href="https://trio.readthedocs.io/"&gt;Trio&lt;/a&gt;'s dependencies with a warm cache.&lt;/i&gt; &lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ A single tool to replace &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, &lt;code&gt;pipx&lt;/code&gt;, &lt;code&gt;poetry&lt;/code&gt;, &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;twine&lt;/code&gt;, &lt;code&gt;virtualenv&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;‚ö°Ô∏è &lt;a href="https://github.com/astral-sh/uv/raw/main/BENCHMARKS.md"&gt;10-100x faster&lt;/a&gt; than &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;üóÇÔ∏è Provides &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#projects"&gt;comprehensive project management&lt;/a&gt;, with a &lt;a href="https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile"&gt;universal lockfile&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;‚ùáÔ∏è &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#scripts"&gt;Runs scripts&lt;/a&gt;, with support for &lt;a href="https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies"&gt;inline dependency metadata&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üêç &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#python-versions"&gt;Installs and manages&lt;/a&gt; Python versions.&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#tools"&gt;Runs and installs&lt;/a&gt; tools published as Python packages.&lt;/li&gt; 
 &lt;li&gt;üî© Includes a &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#the-pip-interface"&gt;pip-compatible interface&lt;/a&gt; for a performance boost with a familiar CLI.&lt;/li&gt; 
 &lt;li&gt;üè¢ Supports Cargo-style &lt;a href="https://docs.astral.sh/uv/concepts/projects/workspaces"&gt;workspaces&lt;/a&gt; for scalable projects.&lt;/li&gt; 
 &lt;li&gt;üíæ Disk-space efficient, with a &lt;a href="https://docs.astral.sh/uv/concepts/cache"&gt;global cache&lt;/a&gt; for dependency deduplication.&lt;/li&gt; 
 &lt;li&gt;‚è¨ Installable without Rust or Python via &lt;code&gt;curl&lt;/code&gt; or &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è Supports macOS, Linux, and Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;uv is backed by &lt;a href="https://astral.sh"&gt;Astral&lt;/a&gt;, the creators of &lt;a href="https://github.com/astral-sh/ruff"&gt;Ruff&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install uv with our standalone installers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On Windows.
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, from &lt;a href="https://pypi.org/project/uv/"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# With pip.
pip install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Or pipx.
pipx install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If installed via the standalone installer, uv can update itself to the latest version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv self update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;installation documentation&lt;/a&gt; for details and alternative installation methods.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;uv's documentation is available at &lt;a href="https://docs.astral.sh/uv"&gt;docs.astral.sh/uv&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, the command line reference documentation can be viewed with &lt;code&gt;uv help&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Projects&lt;/h3&gt; 
&lt;p&gt;uv manages project dependencies and environments, with support for lockfiles, workspaces, and more, similar to &lt;code&gt;rye&lt;/code&gt; or &lt;code&gt;poetry&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/projects/"&gt;project documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;uv also supports building and publishing projects, even if they're not managed with uv. See the &lt;a href="https://docs.astral.sh/uv/guides/publish/"&gt;publish guide&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h3&gt;Scripts&lt;/h3&gt; 
&lt;p&gt;uv manages dependencies and environments for single-file scripts.&lt;/p&gt; 
&lt;p&gt;Create a new script and add inline metadata declaring its dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ echo 'import requests; print(requests.get("https://astral.sh"))' &amp;gt; example.py

$ uv add --script example.py requests
Updated `example.py`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, run the script in an isolated virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&amp;lt;Response [200]&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/scripts/"&gt;scripts documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;uv executes and installs command-line tools provided by Python packages, similar to &lt;code&gt;pipx&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Run a tool in an ephemeral environment using &lt;code&gt;uvx&lt;/code&gt; (an alias for &lt;code&gt;uv tool run&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uvx pycowsay 'hello world!'
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  """

  ------------
&amp;lt; hello world! &amp;gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install a tool with &lt;code&gt;uv tool install&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/tools/"&gt;tools documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Python versions&lt;/h3&gt; 
&lt;p&gt;uv installs Python and allows quickly switching between versions.&lt;/p&gt; 
&lt;p&gt;Install multiple Python versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download Python versions as needed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&amp;gt;&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use a specific Python version in the current directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python pin 3.11
Pinned `.python-version` to `3.11`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/install-python/"&gt;Python installation documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;The pip interface&lt;/h3&gt; 
&lt;p&gt;uv provides a drop-in replacement for common &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, and &lt;code&gt;virtualenv&lt;/code&gt; commands.&lt;/p&gt; 
&lt;p&gt;uv extends their interfaces with advanced features, such as dependency version overrides, platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and more.&lt;/p&gt; 
&lt;p&gt;Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the &lt;code&gt;uv pip&lt;/code&gt; interface.&lt;/p&gt; 
&lt;p&gt;Compile requirements into a platform-independent requirements file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the locked requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/pip/index/"&gt;pip interface documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/platforms/"&gt;platform support&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Versioning policy&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/versioning/"&gt;versioning policy&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We are passionate about supporting contributors of all levels of experience and would love to see you get involved in the project. See the &lt;a href="https://github.com/astral-sh/uv/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h4&gt;How do you pronounce uv?&lt;/h4&gt; 
&lt;p&gt;It's pronounced as "you - vee" (&lt;a href="https://en.wikipedia.org/wiki/Help:IPA/English#Key"&gt;&lt;code&gt;/juÀê viÀê/&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; 
&lt;h4&gt;How should I stylize uv?&lt;/h4&gt; 
&lt;p&gt;Just "uv", please. See the &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/STYLE.md#styling-uv"&gt;style guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;uv's dependency resolver uses &lt;a href="https://github.com/pubgrub-rs/pubgrub"&gt;PubGrub&lt;/a&gt; under the hood. We're grateful to the PubGrub maintainers, especially &lt;a href="https://github.com/Eh2406"&gt;Jacob Finkelman&lt;/a&gt;, for their support.&lt;/p&gt; 
&lt;p&gt;uv's Git implementation is based on &lt;a href="https://github.com/rust-lang/cargo"&gt;Cargo&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some of uv's optimizations are inspired by the great work we've seen in &lt;a href="https://pnpm.io/"&gt;pnpm&lt;/a&gt;, &lt;a href="https://github.com/orogene/orogene"&gt;Orogene&lt;/a&gt;, and &lt;a href="https://github.com/oven-sh/bun"&gt;Bun&lt;/a&gt;. We've also learned a lot from Nathaniel J. Smith's &lt;a href="https://github.com/njsmith/posy"&gt;Posy&lt;/a&gt; and adapted its &lt;a href="https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline"&gt;trampoline&lt;/a&gt; for Windows support.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;uv is licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0, (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="https://opensource.org/licenses/MIT"&gt;https://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://astral.sh" style="background:none"&gt; &lt;img src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg?sanitize=true" alt="Made by Astral"&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>katanemo/archgw</title>
      <link>https://github.com/katanemo/archgw</link>
      <description>&lt;p&gt;The smart edge and AI gateway for agents. Arch is a proxy server that handles the low-level work in building agents like applying guardrails, routing prompts to the right agent, and unifying access to LLMs. It is framework-agnostic, natively understands prompts, and helps you build agents faster.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/arch-logo.png" alt="Arch Logo" width="75%" heigh="auto"&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Arch is a proxy server designed as a modular edge and AI gateway for agentic apps&lt;/em&gt;&lt;br&gt;&lt;br&gt; Arch handles the &lt;em&gt;pesky low-level work&lt;/em&gt; in building agentic apps ‚Äî like applying guardrails, clarifying vague user input, routing prompts to the right agent, and unifying access to any LLM. It‚Äôs a language and framework friendly infrastructure layer designed to help you build and ship agentic apps faster.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Quickstart"&gt;Quickstart&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Demos"&gt;Demos&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Build-AI-Agent-with-Arch-Gateway"&gt;Build agentic apps with Arch&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Use-Arch-as-a-LLM-Router"&gt;Route LLMs&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.archgw.com"&gt;Documentation&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Contact"&gt;Contact&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/katanemo/arch/actions/workflows/pre-commit.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/pre-commit.yml/badge.svg?sanitize=true" alt="pre-commit"&gt;&lt;/a&gt; &lt;a href="https://github.com/katanemo/arch/actions/workflows/rust_tests.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/rust_tests.yml/badge.svg?sanitize=true" alt="rust tests (prompt and llm gateway)"&gt;&lt;/a&gt; &lt;a href="https://github.com/katanemo/arch/actions/workflows/e2e_tests.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/e2e_tests.yml/badge.svg?sanitize=true" alt="e2e tests"&gt;&lt;/a&gt; &lt;a href="https://github.com/katanemo/arch/actions/workflows/static.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/static.yml/badge.svg?sanitize=true" alt="Build and Deploy Documentation"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;Overview&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.producthunt.com/posts/arch-3?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-arch-3" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=565761&amp;amp;theme=dark&amp;amp;period=daily&amp;amp;t=1742359429995" alt="Arch - Build fast, hyper-personalized agents with intelligent infra | Product Hunt" style="width: 188px; height: 41px;" width="188" height="41"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;AI demos are easy to build. But past the thrill of a quick hack, you are left building, maintaining and scaling low-level plumbing code for agents that slows down AI innovation. For example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You want to build specialized agents, but get stuck building &lt;strong&gt;routing and handoff&lt;/strong&gt; code.&lt;/li&gt; 
 &lt;li&gt;You want use new LLMs, but struggle to &lt;strong&gt;quickly and safely add LLMs&lt;/strong&gt; without writing integration code.&lt;/li&gt; 
 &lt;li&gt;You're bogged down with prompt engineering work to &lt;strong&gt;clarify user intent and validate inputs&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;You're wasting cycles choosing and integrating code for &lt;strong&gt;observability&lt;/strong&gt; instead of it happening transparently.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;With Arch, you can move faster by focusing on higher-level objectives in a language and framework agnostic way. &lt;strong&gt;Arch&lt;/strong&gt; was built by the contributors of &lt;a href="https://www.envoyproxy.io/"&gt;Envoy Proxy&lt;/a&gt; with the belief that:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Prompts are nuanced and opaque user requests, which require the same capabilities as traditional HTTP requests including secure handling, intelligent routing, robust observability, and integration with backend (API) systems to improve speed and accuracy for common agentic scenarios ‚Äì all outside core application logic.*&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Core Features&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;üö¶ Routing to Agents&lt;/code&gt;. Engineered with purpose-built &lt;a href="https://huggingface.co/collections/katanemo/arch-function-66f209a693ea8df14317ad68"&gt;LLMs&lt;/a&gt; for fast (&amp;lt;100ms) agent routing and hand-off scenarios&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;üîó Routing to LLMs&lt;/code&gt;: Unify access and routing to any LLM, including dynamic routing via &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Preference-based-Routing"&gt;preference policies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;‚õ® Guardrails&lt;/code&gt;: Centrally configure and prevent harmful outcomes and ensure safe user interactions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;‚ö° Tools Use&lt;/code&gt;: For common agentic scenarios let Arch instantly clarify and convert prompts to tools/API calls&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;üïµ Observability&lt;/code&gt;: W3C compatible request tracing and LLM metrics that instantly plugin with popular tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;üß± Built on Envoy&lt;/code&gt;: Arch runs alongside app servers as a containerized process, and builds on top of &lt;a href="https://envoyproxy.io"&gt;Envoy's&lt;/a&gt; proven HTTP management and scalability features to handle ingress and egress traffic related to prompts and LLMs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;High-Level Sequence Diagram&lt;/strong&gt;: &lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/arch_network_diagram_high_level.png" alt="alt text"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Jump to our &lt;a href="https://docs.archgw.com"&gt;docs&lt;/a&gt;&lt;/strong&gt; to learn how you can use Arch to improve the speed, security and personalization of your GenAI apps.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Today, the function calling LLM (Arch-Function) designed for the agentic and RAG scenarios is hosted free of charge in the US-central region. To offer consistent latencies and throughput, and to manage our expenses, we will enable access to the hosted version via developers keys soon, and give you the option to run that LLM locally. For more details see this issue &lt;a href="https://github.com/katanemo/archgw/issues/258"&gt;#258&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;To get in touch with us, please join our &lt;a href="https://discord.gg/pGZf2gcwEc"&gt;discord server&lt;/a&gt;. We will be monitoring that actively and offering support there.&lt;/p&gt; 
&lt;h2&gt;Demos&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/samples_python/weather_forecast/README.md"&gt;Sample App: Weather Forecast Agent&lt;/a&gt; - A sample agentic weather forecasting app that highlights core function calling capabilities of Arch.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/samples_python/network_switch_operator_agent/README.md"&gt;Sample App: Network Operator Agent&lt;/a&gt; - A simple network device switch operator agent that can retrive device statistics and reboot them.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/use_cases/spotify_bearer_auth"&gt;User Case: Connecting to SaaS APIs&lt;/a&gt; - Connect 3rd party SaaS APIs to your agentic chat experience.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Follow this quickstart guide to use arch gateway to build a simple AI agent. Laster in the section we will see how you can Arch Gateway to manage access keys, provide unified access to upstream LLMs and to provide e2e observability.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;p&gt;Before you begin, ensure you have the following:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/get-started/get-docker/"&gt;Docker System&lt;/a&gt; (v24)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/install/"&gt;Docker compose&lt;/a&gt; (v2.29)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python&lt;/a&gt; (v3.12)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Arch's CLI allows you to manage and interact with the Arch gateway efficiently. To install the CLI, simply run the following command:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] We recommend that developers create a new Python virtual environment to isolate dependencies before installing Arch. This ensures that archgw and its dependencies do not interfere with other packages on your system.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ python3.12 -m venv venv
$ source venv/bin/activate   # On Windows, use: venv\Scripts\activate
$ pip install archgw==0.3.6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build Agentic Apps with Arch Gateway&lt;/h3&gt; 
&lt;p&gt;In following quickstart we will show you how easy it is to build AI agent with Arch gateway. We will build a currency exchange agent using following simple steps. For this demo we will use &lt;code&gt;https://api.frankfurter.dev/&lt;/code&gt; to fetch latest price for currencies and assume USD as base currency.&lt;/p&gt; 
&lt;h4&gt;Step 1. Create arch config file&lt;/h4&gt; 
&lt;p&gt;Create &lt;code&gt;arch_config.yaml&lt;/code&gt; file with following content,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v0.1.0

listeners:
  ingress_traffic:
    address: 0.0.0.0
    port: 10000
    message_format: openai
    timeout: 30s

llm_providers:
  - access_key: $OPENAI_API_KEY
    model: openai/gpt-4o

system_prompt: |
  You are a helpful assistant.

prompt_guards:
  input_guards:
    jailbreak:
      on_exception:
        message: Looks like you're curious about my abilities, but I can only provide assistance for currency exchange.

prompt_targets:
  - name: currency_exchange
    description: Get currency exchange rate from USD to other currencies
    parameters:
      - name: currency_symbol
        description: the currency that needs conversion
        required: true
        type: str
        in_path: true
    endpoint:
      name: frankfurther_api
      path: /v1/latest?base=USD&amp;amp;symbols={currency_symbol}
    system_prompt: |
      You are a helpful assistant. Show me the currency symbol you want to convert from USD.

  - name: get_supported_currencies
    description: Get list of supported currencies for conversion
    endpoint:
      name: frankfurther_api
      path: /v1/currencies

endpoints:
  frankfurther_api:
    endpoint: api.frankfurter.dev:443
    protocol: https
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 2. Start arch gateway with currency conversion config&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;
$ archgw up arch_config.yaml
2024-12-05 16:56:27,979 - cli.main - INFO - Starting archgw cli version: 0.3.6
2024-12-05 16:56:28,485 - cli.utils - INFO - Schema validation successful!
2024-12-05 16:56:28,485 - cli.main - INFO - Starting arch model server and arch gateway
2024-12-05 16:56:51,647 - cli.core - INFO - Container is healthy!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once the gateway is up you can start interacting with at port 10000 using openai chat completion API.&lt;/p&gt; 
&lt;p&gt;Some of the sample queries you can ask could be &lt;code&gt;what is currency rate for gbp?&lt;/code&gt; or &lt;code&gt;show me list of currencies for conversion&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Step 3. Interacting with gateway using curl command&lt;/h4&gt; 
&lt;p&gt;Here is a sample curl command you can use to interact,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ curl --header 'Content-Type: application/json' \
  --data '{"messages": [{"role": "user","content": "what is exchange rate for gbp"}], "model": "none"}' \
  http://localhost:10000/v1/chat/completions | jq ".choices[0].message.content"

"As of the date provided in your context, December 5, 2024, the exchange rate for GBP (British Pound) from USD (United States Dollar) is 0.78558. This means that 1 USD is equivalent to 0.78558 GBP."

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And to get list of supported currencies,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ curl --header 'Content-Type: application/json' \
  --data '{"messages": [{"role": "user","content": "show me list of currencies that are supported for conversion"}], "model": "none"}' \
  http://localhost:10000/v1/chat/completions | jq ".choices[0].message.content"

"Here is a list of the currencies that are supported for conversion from USD, along with their symbols:\n\n1. AUD - Australian Dollar\n2. BGN - Bulgarian Lev\n3. BRL - Brazilian Real\n4. CAD - Canadian Dollar\n5. CHF - Swiss Franc\n6. CNY - Chinese Renminbi Yuan\n7. CZK - Czech Koruna\n8. DKK - Danish Krone\n9. EUR - Euro\n10. GBP - British Pound\n11. HKD - Hong Kong Dollar\n12. HUF - Hungarian Forint\n13. IDR - Indonesian Rupiah\n14. ILS - Israeli New Sheqel\n15. INR - Indian Rupee\n16. ISK - Icelandic Kr√≥na\n17. JPY - Japanese Yen\n18. KRW - South Korean Won\n19. MXN - Mexican Peso\n20. MYR - Malaysian Ringgit\n21. NOK - Norwegian Krone\n22. NZD - New Zealand Dollar\n23. PHP - Philippine Peso\n24. PLN - Polish Z≈Çoty\n25. RON - Romanian Leu\n26. SEK - Swedish Krona\n27. SGD - Singapore Dollar\n28. THB - Thai Baht\n29. TRY - Turkish Lira\n30. USD - United States Dollar\n31. ZAR - South African Rand\n\nIf you want to convert USD to any of these currencies, you can select the one you are interested in."

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use Arch as a LLM Router&lt;/h3&gt; 
&lt;p&gt;Arch supports two primary routing strategies for LLMs: model-based routing and preference-based routing.&lt;/p&gt; 
&lt;h4&gt;Model-based Routing&lt;/h4&gt; 
&lt;p&gt;Model-based routing allows you to configure static model names for routing. This is useful when you always want to use a specific model for certain tasks, or manually swap between models. Below an example configuration for model-based routing, and you can follow our &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/use_cases/README.md"&gt;usage guide&lt;/a&gt; on how to get working.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - access_key: $OPENAI_API_KEY
    model: openai/gpt-4o
    default: true

  - access_key: $MISTRAL_API_KEY
    model: mistral/mistral-3b-latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Preference-based Routing&lt;/h4&gt; 
&lt;p&gt;Preference-based routing is designed for more dynamic and intelligent selection of models. Instead of static model names, you write plain-language routing policies that describe the type of task or preference ‚Äî for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - model: openai/gpt-4.1
    access_key: $OPENAI_API_KEY
    default: true
    routing_preferences:
      - name: code generation
        description: generating new code snippets, functions, or boilerplate based on user prompts or requirements

  - model: openai/gpt-4o-mini
    access_key: $OPENAI_API_KEY
    routing_preferences:
      - name: code understanding
        description: understand and explain existing code snippets, functions, or libraries
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Arch uses a lightweight 1.5B autoregressive model to map prompts (and conversation context) to these policies. This approach adapts to intent drift, supports multi-turn conversations, and avoids the brittleness of embedding-based classifiers or manual if/else chains. No retraining is required when adding new models or updating policies ‚Äî routing is governed entirely by human-readable rules. You can learn more about the design, benchmarks, and methodology behind preference-based routing in our paper:&lt;/p&gt; 
&lt;div align="left"&gt; 
 &lt;a href="https://arxiv.org/abs/2506.16655" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/arch_router_paper_preview.png" alt="Arch Router Paper Preview"&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;a href="https://docs.archgw.com/guides/observability/observability.html"&gt;Observability&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Arch is designed to support best-in class observability by supporting open standards. Please read our &lt;a href="https://docs.archgw.com/guides/observability/observability.html"&gt;docs&lt;/a&gt; on observability for more details on tracing, metrics, and logs. The screenshot below is from our integration with Signoz (among others)&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/tracing.png" alt="alt text"&gt;&lt;/p&gt; 
&lt;h2&gt;Debugging&lt;/h2&gt; 
&lt;p&gt;When debugging issues / errors application logs and access logs provide key information to give you more context on whats going on with the system. Arch gateway runs in info log level and following is a typical output you could see in a typical interaction between developer and arch gateway,&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ archgw up --service archgw --foreground
...
[2025-03-26 18:32:01.350][26][info] prompt_gateway: on_http_request_body: sending request to model server
[2025-03-26 18:32:01.851][26][info] prompt_gateway: on_http_call_response: model server response received
[2025-03-26 18:32:01.852][26][info] prompt_gateway: on_http_call_response: dispatching api call to developer endpoint: weather_forecast_service, path: /weather, method: POST
[2025-03-26 18:32:01.882][26][info] prompt_gateway: on_http_call_response: developer api call response received: status code: 200
[2025-03-26 18:32:01.882][26][info] prompt_gateway: on_http_call_response: sending request to upstream llm
[2025-03-26 18:32:01.883][26][info] llm_gateway: on_http_request_body: provider: gpt-4o-mini, model requested: None, model selected: gpt-4o-mini
[2025-03-26 18:32:02.818][26][info] llm_gateway: on_http_response_body: time to first token: 1468ms
[2025-03-26 18:32:04.532][26][info] llm_gateway: on_http_response_body: request latency: 3183ms
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Log level can be changed to debug to get more details. To enable debug logs edit (supervisord.conf)[arch/supervisord.conf], change the log level &lt;code&gt;--component-log-level wasm:info&lt;/code&gt; to &lt;code&gt;--component-log-level wasm:debug&lt;/code&gt;. And after that you need to rebuild docker image and restart the arch gateway using following set of commands,&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# make sure you are at the root of the repo
$ archgw build
# go to your service that has arch_config.yaml file and issue following command,
$ archgw up --service archgw --foreground
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;We would love feedback on our &lt;a href="https://github.com/orgs/katanemo/projects/1"&gt;Roadmap&lt;/a&gt; and we welcome contributions to &lt;strong&gt;Arch&lt;/strong&gt;! Whether you're fixing bugs, adding new features, improving documentation, or creating tutorials, your help is much appreciated. Please visit our &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; for more details&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>firecracker-microvm/firecracker</title>
      <link>https://github.com/firecracker-microvm/firecracker</link>
      <description>&lt;p&gt;Secure and fast microVMs for serverless computing.&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="docs/images/fc_logo_full_transparent-bg_white-fg.png"&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="docs/images/fc_logo_full_transparent-bg.png"&gt; 
 &lt;img alt="Firecracker Logo Title" width="750" src="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/images/fc_logo_full_transparent-bg.png"&gt; 
&lt;/picture&gt; 
&lt;p&gt;Our mission is to enable secure, multi-tenant, minimal-overhead execution of container and function workloads.&lt;/p&gt; 
&lt;p&gt;Read more about the Firecracker Charter &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/CHARTER.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;What is Firecracker?&lt;/h2&gt; 
&lt;p&gt;Firecracker is an open source virtualization technology that is purpose-built for creating and managing secure, multi-tenant container and function-based services that provide serverless operational models. Firecracker runs workloads in lightweight virtual machines, called microVMs, which combine the security and isolation properties provided by hardware virtualization technology with the speed and flexibility of containers.&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;The main component of Firecracker is a virtual machine monitor (VMM) that uses the Linux Kernel Virtual Machine (KVM) to create and run microVMs. Firecracker has a minimalist design. It excludes unnecessary devices and guest-facing functionality to reduce the memory footprint and attack surface area of each microVM. This improves security, decreases the startup time, and increases hardware utilization. Firecracker has also been integrated in container runtimes, for example &lt;a href="https://github.com/kata-containers/kata-containers"&gt;Kata Containers&lt;/a&gt; and &lt;a href="https://github.com/liquidmetal-dev/flintlock"&gt;Flintlock&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Firecracker was developed at Amazon Web Services to accelerate the speed and efficiency of services like &lt;a href="https://aws.amazon.com/lambda/"&gt;AWS Lambda&lt;/a&gt; and &lt;a href="https://aws.amazon.com/fargate/"&gt;AWS Fargate&lt;/a&gt;. Firecracker is open sourced under &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/LICENSE"&gt;Apache version 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To read more about Firecracker, check out &lt;a href="https://firecracker-microvm.github.io"&gt;firecracker-microvm.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To get started with Firecracker, download the latest &lt;a href="https://github.com/firecracker-microvm/firecracker/releases"&gt;release&lt;/a&gt; binaries or build it from source.&lt;/p&gt; 
&lt;p&gt;You can build Firecracker on any Unix/Linux system that has Docker running (we use a development container) and &lt;code&gt;bash&lt;/code&gt; installed, as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/firecracker-microvm/firecracker
cd firecracker
tools/devtool build
toolchain="$(uname -m)-unknown-linux-musl"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Firecracker binary will be placed at &lt;code&gt;build/cargo_target/${toolchain}/debug/firecracker&lt;/code&gt;. For more information on building, testing, and running Firecracker, go to the &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/getting-started.md"&gt;quickstart guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The overall security of Firecracker microVMs, including the ability to meet the criteria for safe multi-tenant computing, depends on a well configured Linux host operating system. A configuration that we believe meets this bar is included in &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/prod-host-setup.md"&gt;the production host setup document&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Firecracker is already running production workloads within AWS, but it's still Day 1 on the journey guided by our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/CHARTER.md"&gt;mission&lt;/a&gt;. There's a lot more to build and we welcome all contributions.&lt;/p&gt; 
&lt;p&gt;To contribute to Firecracker, check out the development setup section in the &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/getting-started.md"&gt;getting started guide&lt;/a&gt; and then the Firecracker &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;p&gt;New Firecracker versions are released via the GitHub repository &lt;a href="https://github.com/firecracker-microvm/firecracker/releases"&gt;releases&lt;/a&gt; page, typically every two or three months. A history of changes is recorded in our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/CHANGELOG.md"&gt;changelog&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The Firecracker release policy is detailed &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/RELEASE_POLICY.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Design&lt;/h2&gt; 
&lt;p&gt;Firecracker's overall architecture is described in &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/design.md"&gt;the design document&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features &amp;amp; Capabilities&lt;/h2&gt; 
&lt;p&gt;Firecracker consists of a single micro Virtual Machine Manager process that exposes an API endpoint to the host once started. The API is &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/src/firecracker/swagger/firecracker.yaml"&gt;specified in OpenAPI format&lt;/a&gt;. Read more about it in the &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/api_requests"&gt;API docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;API endpoint&lt;/strong&gt; can be used to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Configure the microvm by: 
  &lt;ul&gt; 
   &lt;li&gt;Setting the number of vCPUs (the default is 1).&lt;/li&gt; 
   &lt;li&gt;Setting the memory size (the default is 128 MiB).&lt;/li&gt; 
   &lt;li&gt;Configuring a &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/cpu_templates/cpu-templates.md"&gt;CPU template&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Add one or more network interfaces to the microVM.&lt;/li&gt; 
 &lt;li&gt;Add one or more read-write or read-only disks to the microVM, each represented by a file-backed block device.&lt;/li&gt; 
 &lt;li&gt;Trigger a block device re-scan while the guest is running. This enables the guest OS to pick up size changes to the block device's backing file.&lt;/li&gt; 
 &lt;li&gt;Change the backing file for a block device, before or after the guest boots.&lt;/li&gt; 
 &lt;li&gt;Configure rate limiters for virtio devices which can limit the bandwidth, operations per second, or both.&lt;/li&gt; 
 &lt;li&gt;Configure the logging and metric system.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[BETA]&lt;/code&gt; Configure the data tree of the guest-facing metadata service. The service is only available to the guest if this resource is configured.&lt;/li&gt; 
 &lt;li&gt;Add a &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/vsock.md"&gt;vsock socket&lt;/a&gt; to the microVM.&lt;/li&gt; 
 &lt;li&gt;Add a &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/entropy.md"&gt;entropy device&lt;/a&gt; to the microVM.&lt;/li&gt; 
 &lt;li&gt;Start the microVM using a given kernel image, root file system, and boot arguments.&lt;/li&gt; 
 &lt;li&gt;[x86_64 only] Stop the microVM.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Built-in Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Demand fault paging and CPU oversubscription enabled by default.&lt;/li&gt; 
 &lt;li&gt;Advanced, thread-specific seccomp filters for enhanced security.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/jailer.md"&gt;Jailer&lt;/a&gt; process for starting Firecracker in production scenarios; applies a cgroup/namespace isolation barrier and then drops privileges.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Tested platforms&lt;/h2&gt; 
&lt;p&gt;We test all combinations of:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Instance&lt;/th&gt; 
   &lt;th align="left"&gt;Host OS &amp;amp; Kernel&lt;/th&gt; 
   &lt;th align="left"&gt;Guest Rootfs&lt;/th&gt; 
   &lt;th align="left"&gt;Guest Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;c5n.metal&lt;/td&gt; 
   &lt;td align="left"&gt;al2 linux_5.10&lt;/td&gt; 
   &lt;td align="left"&gt;ubuntu 24.04&lt;/td&gt; 
   &lt;td align="left"&gt;linux_5.10&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m5n.metal&lt;/td&gt; 
   &lt;td align="left"&gt;al2023 linux_6.1&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;linux_6.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m6i.metal&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m7i.metal-24xl&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m7i.metal-48xl&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m6a.metal&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m7a.metal-48xl&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m6g.metal&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m7g.metal&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m8g.metal-24xl&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m8g.metal-48xl&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Known issues and Limitations&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;pl031&lt;/code&gt; RTC device on aarch64 does not support interrupts, so guest programs which use an RTC alarm (e.g. &lt;code&gt;hwclock&lt;/code&gt;) will not work.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;Firecracker's performance characteristics are listed as part of the &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/SPECIFICATION.md"&gt;specification documentation&lt;/a&gt;. All specifications are a part of our commitment to supporting container and function workloads in serverless operational models, and are therefore enforced via continuous integration testing.&lt;/p&gt; 
&lt;h2&gt;Policy for Security Disclosures&lt;/h2&gt; 
&lt;p&gt;The security of Firecracker is our top priority. If you suspect you have uncovered a vulnerability, contact us privately, as outlined in our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/SECURITY.md"&gt;security policy document&lt;/a&gt;; we will immediately prioritize your disclosure.&lt;/p&gt; 
&lt;h2&gt;FAQ &amp;amp; Contact&lt;/h2&gt; 
&lt;p&gt;Frequently asked questions are collected in our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/FAQ.md"&gt;FAQ doc&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can get in touch with the Firecracker community in the following ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Security-related issues, see our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/SECURITY.md"&gt;security policy document&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Chat with us on our &lt;a href="https://join.slack.com/t/firecracker-microvm/shared_invite/zt-2tc0mfxpc-tU~HYAYSzLDl5XGGJU3YIg"&gt;Slack workspace&lt;/a&gt; &lt;em&gt;Note: most of the maintainers are on a European time zone.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Open a GitHub issue in this repository.&lt;/li&gt; 
 &lt;li&gt;Email the maintainers at &lt;a href="mailto:firecracker-maintainers@amazon.com"&gt;firecracker-maintainers@amazon.com&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When communicating within the Firecracker community, please mind our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/CODE_OF_CONDUCT.md"&gt;code of conduct&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>