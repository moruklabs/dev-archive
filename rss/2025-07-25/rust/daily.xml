<rss version="2.0">
  <channel>
    <title>GitHub Rust Daily Trending</title>
    <description>Daily Trending of Rust in GitHub</description>
    <pubDate>Thu, 24 Jul 2025 01:35:31 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>tracel-ai/burn</title>
      <link>https://github.com/tracel-ai/burn</link>
      <description>&lt;p&gt;Burn is a next generation Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/logo-burn-neutral.webp" width="350px"&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/uPEBbYYDB6"&gt;&lt;img src="https://img.shields.io/discord/1038839012602941528.svg?color=7289da&amp;amp;&amp;amp;logo=discord" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/v/burn.svg?sanitize=true" alt="Current Crates.io Version"&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/msrv/burn" alt="Minimum Supported Rust Version"&gt;&lt;/a&gt; &lt;a href="https://burn.dev/docs/burn"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-blue" alt="Documentation"&gt;&lt;/a&gt; &lt;a href="https://github.com/tracel-ai/burn/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/tracel-ai/burn/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Test Status"&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/#license"&gt;&lt;img src="https://shields.io/badge/license-MIT%2FApache--2.0-blue" alt="license"&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/tracel-ai/burn"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.runblaze.dev"&gt;&lt;img src="https://www.runblaze.dev/ci-blaze-powered.png" width="125px"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;p&gt;&lt;strong&gt;Burn is a next generation Deep Learning Framework that doesn't compromise on &lt;br&gt; flexibility, efficiency and portability.&lt;/strong&gt;&lt;/p&gt; 
 &lt;br&gt; 
&lt;/div&gt; 
&lt;div align="left"&gt; 
 &lt;h2&gt;Performance&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-blazingly-fast.png" height="96px"&gt; 
  &lt;p&gt;Because we believe the goal of a deep learning framework is to convert computation into useful intelligence, we have made performance a core pillar of Burn. We strive to achieve top efficiency by leveraging multiple optimization techniques described below.&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;Click on each section for more details&lt;/strong&gt; üëá&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;br&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Automatic kernel fusion üí• &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Using Burn means having your models optimized on any backend. When possible, we provide a way to automatically and dynamically create custom kernels that minimize data relocation between different memory spaces, extremely useful when moving memory is the bottleneck.&lt;/p&gt; 
  &lt;p&gt;As an example, you could write your own GELU activation function with the high level tensor api (see Rust code snippet below).&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;fn gelu_custom&amp;lt;B: Backend, const D: usize&amp;gt;(x: Tensor&amp;lt;B, D&amp;gt;) -&amp;gt; Tensor&amp;lt;B, D&amp;gt; {
    let x = x.clone() * ((x / SQRT_2).erf() + 1);
    x / 2
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Then, at runtime, a custom low-level kernel will be automatically created for your specific implementation and will rival a handcrafted GPU implementation. The kernel consists of about 60 lines of WGSL &lt;a href="%22https://www.w3.org/TR/WGSL/https://www.w3.org/TR/WGSL/%22"&gt;WebGPU Shading Language&lt;/a&gt;, an extremely verbose lower level shader language you probably don't want to program your deep learning models in!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Asynchronous execution ‚ù§Ô∏è‚Äçüî• &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;For &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/#backends"&gt;first-party backends&lt;/a&gt;, an asynchronous execution style is used, which allows to perform various optimizations, such as the previously mentioned automatic kernel fusion.&lt;/p&gt; 
  &lt;p&gt;Asynchronous execution also ensures that the normal execution of the framework does not block the model computations, which implies that the framework overhead won't impact the speed of execution significantly. Conversely, the intense computations in the model do not interfere with the responsiveness of the framework. For more information about our asynchronous backends, see &lt;a href="https://burn.dev/blog/creating-high-performance-asynchronous-backends-with-burn-compute"&gt;this blog post&lt;/a&gt;.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Thread-safe building blocks ü¶û &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Burn emphasizes thread safety by leveraging the &lt;a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html"&gt;ownership system of Rust&lt;/a&gt;. With Burn, each module is the owner of its weights. It is therefore possible to send a module to another thread for computing the gradients, then send the gradients to the main thread that can aggregate them, and &lt;em&gt;voil√†&lt;/em&gt;, you get multi-device training.&lt;/p&gt; 
  &lt;p&gt;This is a very different approach from what PyTorch does, where backpropagation actually mutates the &lt;em&gt;grad&lt;/em&gt; attribute of each tensor parameter. This is not a thread-safe operation and therefore requires lower level synchronization primitives, see &lt;a href="https://pytorch.org/docs/stable/distributed.html"&gt;distributed training&lt;/a&gt; for reference. Note that this is still very fast, but not compatible across different backends and quite hard to implement.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Intelligent memory management ü¶Ä &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;One of the main roles of a deep learning framework is to reduce the amount of memory necessary to run models. The naive way of handling memory is that each tensor has its own memory space, which is allocated when the tensor is created then deallocated as the tensor gets out of scope. However, allocating and deallocating data is very costly, so a memory pool is often required to achieve good throughput. Burn offers an infrastructure that allows for easily creating and selecting memory management strategies for backends. For more details on memory management in Burn, see &lt;a href="https://burn.dev/blog/creating-high-performance-asynchronous-backends-with-burn-compute"&gt;this blog post&lt;/a&gt;.&lt;/p&gt; 
  &lt;p&gt;Another very important memory optimization of Burn is that we keep track of when a tensor can be mutated in-place just by using the ownership system well. Even though it is a rather small memory optimization on its own, it adds up considerably when training or running inference with larger models and contributes to reduce the memory usage even more. For more information, see &lt;a href="https://burn.dev/blog/burn-rusty-approach-to-tensor-handling"&gt;this blog post about tensor handling&lt;/a&gt;.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Automatic kernel selection üéØ &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;A good deep learning framework should ensure that models run smoothly on all hardware. However, not all hardware share the same behavior in terms of execution speed. For instance, a matrix multiplication kernel can be launched with many different parameters, which are highly sensitive to the size of the matrices and the hardware. Using the wrong configuration could reduce the speed of execution by a large factor (10 times or even more in extreme cases), so choosing the right kernels becomes a priority.&lt;/p&gt; 
  &lt;p&gt;With our home-made backends, we run benchmarks automatically and choose the best configuration for the current hardware and matrix sizes with a reasonable caching strategy.&lt;/p&gt; 
  &lt;p&gt;This adds a small overhead by increasing the warmup execution time, but stabilizes quickly after a few forward and backward passes, saving lots of time in the long run. Note that this feature isn't mandatory, and can be disabled when cold starts are a priority over optimized throughput.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Hardware specific features üî• &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;It is no secret that deep learning is mostly relying on matrix multiplication as its core operation, since this is how fully-connected neural networks are modeled.&lt;/p&gt; 
  &lt;p&gt;More and more, hardware manufacturers optimize their chips specifically for matrix multiplication workloads. For instance, Nvidia has its &lt;em&gt;Tensor Cores&lt;/em&gt; and today most cellphones have AI specialized chips. As of this moment, we support Tensor Cores with our LibTorch, Candle, CUDA, Metal and WGPU/SPIR-V backends, but not other accelerators yet. We hope &lt;a href="https://github.com/gpuweb/gpuweb/issues/4195"&gt;this issue&lt;/a&gt; gets resolved at some point to bring support to our WGPU backend.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Custom Backend Extension üéí &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Burn aims to be the most flexible deep learning framework. While it's crucial to maintain compatibility with a wide variety of backends, Burn also provides the ability to extend the functionalities of a backend implementation to suit your personal modeling requirements.&lt;/p&gt; 
  &lt;p&gt;This versatility is advantageous in numerous ways, such as supporting custom operations like flash attention or manually writing your own kernel for a specific backend to enhance performance. See &lt;a href="https://burn.dev/books/burn/advanced/backend-extension/index.html"&gt;this section&lt;/a&gt; in the Burn Book üî• for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;br&gt; 
 &lt;h2&gt;Backend&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/backend-chip.png" height="96px"&gt; 
  &lt;p&gt;Burn strives to be as fast as possible on as many hardwares as possible, with robust implementations. We believe this flexibility is crucial for modern needs where you may train your models in the cloud, then deploy on customer hardwares, which vary from user to user.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;strong&gt;Supported Backends&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Backend&lt;/th&gt; 
    &lt;th&gt;Devices&lt;/th&gt; 
    &lt;th&gt;Class&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;CUDA&lt;/td&gt; 
    &lt;td&gt;NVIDIA GPUs&lt;/td&gt; 
    &lt;td&gt;First-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;ROCm&lt;/td&gt; 
    &lt;td&gt;AMD GPUs&lt;/td&gt; 
    &lt;td&gt;First-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Metal&lt;/td&gt; 
    &lt;td&gt;Apple GPUs&lt;/td&gt; 
    &lt;td&gt;First-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Vulkan&lt;/td&gt; 
    &lt;td&gt;Most GPUs on Linux &amp;amp; Windows&lt;/td&gt; 
    &lt;td&gt;First-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wgpu&lt;/td&gt; 
    &lt;td&gt;Most GPUs&lt;/td&gt; 
    &lt;td&gt;First-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;NdArray&lt;/td&gt; 
    &lt;td&gt;Most CPUs&lt;/td&gt; 
    &lt;td&gt;Third-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;LibTorch&lt;/td&gt; 
    &lt;td&gt;Most GPUs &amp;amp; CPUs&lt;/td&gt; 
    &lt;td&gt;Third-Party&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Candle&lt;/td&gt; 
    &lt;td&gt;Nvidia, Apple GPUs &amp;amp; CPUs&lt;/td&gt; 
    &lt;td&gt;Third-Party&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;br&gt; 
 &lt;p&gt;Compared to other frameworks, Burn has a very different approach to supporting many backends. By design, most code is generic over the Backend trait, which allows us to build Burn with swappable backends. This makes composing backend possible, augmenting them with additional functionalities such as autodifferentiation and automatic kernel fusion.&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Autodiff: Backend decorator that brings backpropagation to any backend üîÑ &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Contrary to the aforementioned backends, Autodiff is actually a backend &lt;em&gt;decorator&lt;/em&gt;. This means that it cannot exist by itself; it must encapsulate another backend.&lt;/p&gt; 
  &lt;p&gt;The simple act of wrapping a base backend with Autodiff transparently equips it with autodifferentiation support, making it possible to call backward on your model.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::backend::{Autodiff, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&amp;lt;Wgpu&amp;gt;;

    let x: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default);
    let y: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;amp;grads).unwrap();
    println!("{y_grad}");
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, it is impossible to make the mistake of calling backward on a model that runs on a backend that does not support autodiff (for inference), as this method is only offered by an Autodiff backend.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-autodiff/README.md"&gt;Autodiff Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Fusion: Backend decorator that brings kernel fusion to all first-party backends &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;This backend decorator enhances a backend with kernel fusion, provided that the inner backend supports it. Note that you can compose this backend with other backend decorators such as Autodiff. For now, only the WGPU and CUDA backends have support for fused kernels.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::backend::{Autodiff, Fusion, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&amp;lt;Fusion&amp;lt;Wgpu&amp;gt;&amp;gt;;

    let x: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default);
    let y: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;amp;grads).unwrap();
    println!("{y_grad}");
}

&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, we plan to implement automatic gradient checkpointing based on compute bound and memory bound operations, which will work gracefully with the fusion backend to make your code run even faster during training, see &lt;a href="https://github.com/tracel-ai/burn/issues/936"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-fusion/README.md"&gt;Fusion Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Router (Beta): Backend decorator that composes multiple backends into a single one &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;That backend simplifies hardware operability, if for instance you want to execute some operations on the CPU and other operations on the GPU.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::tensor::{Distribution, Tensor};
use burn::backend::{
    NdArray, Router, Wgpu, ndarray::NdArrayDevice, router::duo::MultiDevice, wgpu::WgpuDevice,
};

fn main() {
    type Backend = Router&amp;lt;(Wgpu, NdArray)&amp;gt;;

    let device_0 = MultiDevice::B1(WgpuDevice::DiscreteGpu(0));
    let device_1 = MultiDevice::B2(NdArrayDevice::Cpu);

    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_0);
    let tensor_cpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_1);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Remote (Beta): Backend decorator for remote backend execution, useful for distributed computations &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;That backend has two parts, one client and one server. The client sends tensor operations over the network to a remote compute backend. You can use any first-party backend as server in a single line of code:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;fn main_server() {
    // Start a server on port 3000.
    burn::server::start::&amp;lt;burn::backend::Cuda&amp;gt;(Default::default(), 3000);
}

fn main_client() {
    // Create a client that communicate with the server on port 3000.
    use burn::backend::{Autodiff, RemoteBackend};

    type Backend = Autodiff&amp;lt;RemoteDevice&amp;gt;;

    let device = RemoteDevice::new("ws://localhost:3000");
    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], Distribution::Default, &amp;amp;device);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;br&gt; 
 &lt;h2&gt;Training &amp;amp; Inference&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-wall.png" height="96px"&gt; 
  &lt;p&gt;The whole deep learning workflow is made easy with Burn, as you can monitor your training progress with an ergonomic dashboard, and run inference everywhere from embedded devices to large GPU clusters.&lt;/p&gt; 
  &lt;p&gt;Burn was built from the ground up with training and inference in mind. It's also worth noting how Burn, in comparison to frameworks like PyTorch, simplifies the transition from training to deployment, eliminating the need for code changes.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;br&gt; 
  &lt;a href="https://www.youtube.com/watch?v=N9RM5CQbNQc" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/burn-train-tui.png" alt="Burn Train TUI" width="75%"&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;strong&gt;Click on the following sections to expand üëá&lt;/strong&gt;&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Training Dashboard üìà &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;As you can see in the previous video (click on the picture!), a new terminal UI dashboard based on the &lt;a href="https://github.com/ratatui-org/ratatui"&gt;Ratatui&lt;/a&gt; crate allows users to follow their training with ease without having to connect to any external application.&lt;/p&gt; 
  &lt;p&gt;You can visualize your training and validation metrics updating in real-time and analyze the lifelong progression or recent history of any registered metrics using only the arrow keys. Break from the training loop without crashing, allowing potential checkpoints to be fully written or important pieces of code to complete without interruption üõ°&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; ONNX Support üê´ &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;ONNX (Open Neural Network Exchange) is an open-standard format that exports both the architecture and the weights of a deep learning model.&lt;/p&gt; 
  &lt;p&gt;Burn supports the importation of models that follow the ONNX standard so you can easily port a model you have written in another framework like TensorFlow or PyTorch to Burn to benefit from all the advantages our framework offers.&lt;/p&gt; 
  &lt;p&gt;Our ONNX support is further described in &lt;a href="https://burn.dev/books/burn/import/onnx-model.html"&gt;this section of the Burn Book üî•&lt;/a&gt;.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This crate is in active development and currently supports a &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-import/SUPPORTED-ONNX-OPS.md"&gt;limited set of ONNX operators&lt;/a&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Importing PyTorch or Safetensors Models üöö &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;You can load weights from PyTorch or Safetensors formats directly into your Burn-defined models. This makes it easy to reuse existing models while benefiting from Burn's performance and deployment features.&lt;/p&gt; 
  &lt;p&gt;Learn more:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/pytorch-model.html"&gt;Import pre-trained PyTorch models into Burn&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/safetensors-model.html"&gt;Load models from Safetensors format&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Inference in the Browser üåê &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Several of our backends can compile to Web Assembly: Candle and NdArray for CPU, and WGPU for GPU. This means that you can run inference directly within a browser. We provide several examples of this:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST&lt;/a&gt; where you can draw digits and a small convnet tries to find which one it is! 2Ô∏è‚É£ 7Ô∏è‚É£ üò∞&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification&lt;/a&gt; where you can upload images and classify them! üåÑ&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Embedded: &lt;i&gt;no_std&lt;/i&gt; support ‚öôÔ∏è &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Burn's core components support &lt;a href="https://docs.rust-embedded.org/book/intro/no-std.html"&gt;no_std&lt;/a&gt;. This means it can run in bare metal environment such as embedded devices without an operating system.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;As of now, only the NdArray backend can be used in a &lt;em&gt;no_std&lt;/em&gt; environment.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;br&gt; 
 &lt;h3&gt;Benchmarks&lt;/h3&gt; 
 &lt;p&gt;To evaluate performance across different backends and track improvements over time, we provide a dedicated benchmarking suite.&lt;/p&gt; 
 &lt;p&gt;Run and compare benchmarks using &lt;a href="https://github.com/tracel-ai/burn-bench"&gt;burn-bench&lt;/a&gt;.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Warning&lt;/strong&gt; When using one of the &lt;code&gt;wgpu&lt;/code&gt; backends, you may encounter compilation errors related to recursive type evaluation. This is due to complex type nesting within the &lt;code&gt;wgpu&lt;/code&gt; dependency chain. To resolve this issue, add the following line at the top of your &lt;code&gt;main.rs&lt;/code&gt; or &lt;code&gt;lib.rs&lt;/code&gt; file:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#![recursion_limit = "256"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;The default recursion limit (128) is often just below the required depth (typically 130-150) due to deeply nested associated types and trait bounds.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h2&gt;Getting Started&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-walking.png" height="96px"&gt; 
  &lt;p&gt;Just heard of Burn? You are at the right place! Just continue reading this section and we hope you can get on board really quickly.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;details&gt; 
  &lt;summary&gt; The Burn Book üî• &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;To begin working effectively with Burn, it is crucial to understand its key components and philosophy. This is why we highly recommend new users to read the first sections of &lt;a href="https://burn.dev/books/burn/"&gt;The Burn Book üî•&lt;/a&gt;. It provides detailed examples and explanations covering every facet of the framework, including building blocks like tensors, modules, and optimizers, all the way to advanced usage, like coding your own GPU kernels.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;The project is constantly evolving, and we try as much as possible to keep the book up to date with new additions. However, we might miss some details sometimes, so if you see something weird, let us know! We also gladly accept Pull Requests üòÑ&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Examples üôè &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Let's start with a code snippet that shows how intuitive the framework is to use! In the following, we declare a neural network module with some parameters along with its forward pass.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::nn;
use burn::module::Module;
use burn::tensor::backend::Backend;

#[derive(Module, Debug)]
pub struct PositionWiseFeedForward&amp;lt;B: Backend&amp;gt; {
    linear_inner: nn::Linear&amp;lt;B&amp;gt;,
    linear_outer: nn::Linear&amp;lt;B&amp;gt;,
    dropout: nn::Dropout,
    gelu: nn::Gelu,
}

impl&amp;lt;B: Backend&amp;gt; PositionWiseFeedForward&amp;lt;B&amp;gt; {
    pub fn forward&amp;lt;const D: usize&amp;gt;(&amp;amp;self, input: Tensor&amp;lt;B, D&amp;gt;) -&amp;gt; Tensor&amp;lt;B, D&amp;gt; {
        let x = self.linear_inner.forward(input);
        let x = self.gelu.forward(x);
        let x = self.dropout.forward(x);

        self.linear_outer.forward(x)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;We have a somewhat large amount of &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples"&gt;examples&lt;/a&gt; in the repository that shows how to use the framework in different scenarios.&lt;/p&gt; 
  &lt;p&gt;Following &lt;a href="https://burn.dev/books/burn/"&gt;the book&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/guide"&gt;Basic Workflow&lt;/a&gt; : Creates a custom CNN &lt;code&gt;Module&lt;/code&gt; to train on the MNIST dataset and use for inference.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-training-loop"&gt;Custom Training Loop&lt;/a&gt; : Implements a basic training loop instead of using the &lt;code&gt;Learner&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-wgpu-kernel"&gt;Custom WGPU Kernel&lt;/a&gt; : Learn how to create your own custom operation with the WGPU backend.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;Additional examples:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-csv-dataset"&gt;Custom CSV Dataset&lt;/a&gt; : Implements a dataset to parse CSV data for a regression task.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/simple-regression"&gt;Regression&lt;/a&gt; : Trains a simple MLP on the California Housing dataset to predict the median house value for a district.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-image-dataset"&gt;Custom Image Dataset&lt;/a&gt; : Trains a simple CNN on custom image dataset following a simple folder structure.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-renderer"&gt;Custom Renderer&lt;/a&gt; : Implements a custom renderer to display the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/building-blocks/learner.md"&gt;&lt;code&gt;Learner&lt;/code&gt;&lt;/a&gt; progress.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification Web&lt;/a&gt; : Image classification web browser demo using Burn, WGPU and WebAssembly.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST Inference on Web&lt;/a&gt; : An interactive MNIST inference demo in the browser. The demo is available &lt;a href="https://burn.dev/demo/"&gt;online&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist"&gt;MNIST Training&lt;/a&gt; : Demonstrates how to train a custom &lt;code&gt;Module&lt;/code&gt; (MLP) with the &lt;code&gt;Learner&lt;/code&gt; configured to log metrics and keep training checkpoints.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/named-tensor"&gt;Named Tensor&lt;/a&gt; : Performs operations with the experimental &lt;code&gt;NamedTensor&lt;/code&gt; feature.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/onnx-inference"&gt;ONNX Import Inference&lt;/a&gt; : Imports an ONNX model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/pytorch-import"&gt;PyTorch Import Inference&lt;/a&gt; : Imports a PyTorch model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-classification"&gt;Text Classification&lt;/a&gt; : Trains a text classification transformer model on the AG News or DbPedia dataset. The trained model can then be used to classify a text sample.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-generation"&gt;Text Generation&lt;/a&gt; : Trains a text generation transformer model on the DbPedia dataset.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/wgan"&gt;Wasserstein GAN MNIST&lt;/a&gt; : Trains a WGAN model to generate new handwritten digits based on MNIST.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;For more practical insights, you can clone the repository and run any of them directly on your computer!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Pre-trained Models ü§ñ &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;We keep an updated and curated list of models and examples built with Burn, see the &lt;a href="https://github.com/tracel-ai/models"&gt;tracel-ai/models repository&lt;/a&gt; for more details.&lt;/p&gt; 
  &lt;p&gt;Don't see the model you want? Don't hesitate to open an issue, and we may prioritize it. Built a model using Burn and want to share it? You can also open a Pull Request and add your model under the community section!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Why use Rust for Deep Learning? ü¶Ä &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;Deep Learning is a special form of software where you need very high level abstractions as well as extremely fast execution time. Rust is the perfect candidate for that use case since it provides zero-cost abstractions to easily create neural network modules, and fine-grained control over memory to optimize every detail.&lt;/p&gt; 
  &lt;p&gt;It's important that a framework be easy to use at a high level so that its users can focus on innovating in the AI field. However, since running models relies so heavily on computations, performance can't be neglected.&lt;/p&gt; 
  &lt;p&gt;To this day, the mainstream solution to this problem has been to offer APIs in Python, but rely on bindings to low-level languages such as C/C++. This reduces portability, increases complexity and creates frictions between researchers and engineers. We feel like Rust's approach to abstractions makes it versatile enough to tackle this two languages dichotomy.&lt;/p&gt; 
  &lt;p&gt;Rust also comes with the Cargo package manager, which makes it incredibly easy to build, test, and deploy from any environment, which is usually a pain in Python.&lt;/p&gt; 
  &lt;p&gt;Although Rust has the reputation of being a difficult language at first, we strongly believe it leads to more reliable, bug-free solutions built faster (after some practice üòÖ)!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;br&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;Deprecation Note&lt;/strong&gt;&lt;br&gt;Since &lt;code&gt;0.14.0&lt;/code&gt;, the internal structure for tensor data has changed. The previous &lt;code&gt;Data&lt;/code&gt; struct was deprecated and officially removed since &lt;code&gt;0.17.0&lt;/code&gt; in favor of the new &lt;code&gt;TensorData&lt;/code&gt; struct, which allows for more flexibility by storing the underlying data as bytes and keeping the data type as a field. If you are using &lt;code&gt;Data&lt;/code&gt; in your code, make sure to switch to &lt;code&gt;TensorData&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;!-- &gt;
&gt; In the event that you are trying to load a model record saved in a previous version, make sure to
&gt; enable the `record-backward-compat` feature using a previous version of burn (&lt;=0.16.0). Otherwise,
&gt; the record won't be deserialized correctly and you will get an error message (which will also point
&gt; you to the backward compatible feature flag). The backward compatibility was maintained for
&gt; deserialization (loading), so as soon as you have saved the record again it will be saved according
&gt; to the new structure and you will be able to upgrade to this version. Please note that binary formats
&gt; are not backward compatible. Thus, you will need to load your record in a previous version and save it
&gt; to another of the self-describing record formats before using a compatible version (as described) with the
&gt; `record-backward-compat` feature flag. --&gt; 
 &lt;details id="deprecation"&gt; 
  &lt;summary&gt; Loading Model Records From Previous Versions ‚ö†Ô∏è &lt;/summary&gt; 
  &lt;br&gt; 
  &lt;p&gt;In the event that you are trying to load a model record saved in a version older than &lt;code&gt;0.14.0&lt;/code&gt;, make sure to use a compatible version (&lt;code&gt;0.14&lt;/code&gt;, &lt;code&gt;0.15&lt;/code&gt; or &lt;code&gt;0.16&lt;/code&gt;) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
  &lt;pre&gt;&lt;code&gt;features = [..., "record-backward-compat"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Otherwise, the record won't be deserialized correctly and you will get an error message. This error will also point you to the backward compatible feature flag.&lt;/p&gt; 
  &lt;p&gt;The backward compatibility was maintained for deserialization when loading records. Therefore, as soon as you have saved the record again it will be saved according to the new structure and you can upgrade back to the current version&lt;/p&gt; 
  &lt;p&gt;Please note that binary formats are not backward compatible. Thus, you will need to load your record in a previous version and save it in any of the other self-describing record format (e.g., using the &lt;code&gt;NamedMpkFileRecorder&lt;/code&gt;) before using a compatible version (as described) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;h2&gt;Community&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-community.png" height="96px"&gt; 
  &lt;p&gt;If you are excited about the project, don't hesitate to join our &lt;a href="https://discord.gg/uPEBbYYDB6"&gt;Discord&lt;/a&gt;! We try to be as welcoming as possible to everybody from any background. You can ask your questions and share what you built with the community!&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Before contributing, please take a moment to review our &lt;a href="https://github.com/tracel-ai/burn/tree/main/CODE-OF-CONDUCT.md"&gt;code of conduct&lt;/a&gt;. It's also highly recommended to read the &lt;a href="https://github.com/tracel-ai/burn/tree/main/contributor-book/src/project-architecture"&gt;architecture overview&lt;/a&gt;, which explains some of our architectural decisions. Refer to our &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;h2&gt;Status&lt;/h2&gt; 
 &lt;p&gt;Burn is currently in active development, and there will be breaking changes. While any resulting issues are likely to be easy to fix, there are no guarantees at this stage.&lt;/p&gt; 
 &lt;h2&gt;License&lt;/h2&gt; 
 &lt;p&gt;Burn is distributed under the terms of both the MIT license and the Apache License (Version 2.0). See &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; for details. Opening a pull request is assumed to signal agreement with these licensing terms.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>biomejs/biome</title>
      <link>https://github.com/biomejs/biome</link>
      <description>&lt;p&gt;A toolchain for web projects, aimed to provide functionalities to maintain them. Biome offers formatter and linter, usable via CLI and LSP.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-dark-transparent.svg"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-light-transparent.svg"&gt; 
  &lt;img alt="Shows the banner of Biome, with its logo and the phrase 'Biome - Toolchain of the web'." src="https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-light-transparent.svg?sanitize=true" width="700"&gt; 
 &lt;/picture&gt; 
 &lt;br&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://github.com/biomejs/biome/actions/workflows/main.yml"&gt;&lt;img src="https://github.com/biomejs/biome/actions/workflows/main.yml/badge.svg?sanitize=true" alt="CI on main"&gt;&lt;/a&gt; &lt;a href="https://biomejs.dev/chat"&gt;&lt;img src="https://badgen.net/discord/online-members/BypW39g6Yc?icon=discord&amp;amp;label=discord&amp;amp;color=60a5fa" alt="Discord chat"&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@biomejs/biome/v/latest"&gt;&lt;img src="https://badgen.net/npm/v/@biomejs/biome?icon=npm&amp;amp;color=60a5fa&amp;amp;label=%40biomejs%2Fbiome" alt="npm version"&gt;&lt;/a&gt; &lt;a href="https://marketplace.visualstudio.com/items?itemName=biomejs.biome"&gt;&lt;img src="https://img.shields.io/visual-studio-marketplace/v/biomejs.biome?label=Visual%20Studio%20Marketplace&amp;amp;labelColor=374151&amp;amp;color=60a5fa" alt="VSCode version"&gt;&lt;/a&gt; &lt;a href="https://open-vsx.org/extension/biomejs/biome"&gt;&lt;img src="https://img.shields.io/visual-studio-marketplace/v/biomejs.biome?label=Open%20VSX%20Registry&amp;amp;logo=data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPHN2ZyB2aWV3Qm94PSI0LjYgNSA5Ni4yIDEyMi43IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogIDxwYXRoIGQ9Ik0zMCA0NC4yTDUyLjYgNUg3LjN6TTQuNiA4OC41aDQ1LjNMMjcuMiA0OS40em01MSAwbDIyLjYgMzkuMiAyMi42LTM5LjJ6IiBmaWxsPSIjYzE2MGVmIi8+CiAgPHBhdGggZD0iTTUyLjYgNUwzMCA0NC4yaDQ1LjJ6TTI3LjIgNDkuNGwyMi43IDM5LjEgMjIuNi0zOS4xem01MSAwTDU1LjYgODguNWg0NS4yeiIgZmlsbD0iI2E2MGVlNSIvPgo8L3N2Zz4=&amp;amp;labelColor=374151&amp;amp;color=60a5fa" alt="Open VSX version"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- Insert new entries lexicographically by language code.
     For example given below is the same order as these files appear on page:
     https://github.com/biomejs/biome/tree/main/packages/@biomejs/biome --&gt; 
 &lt;p&gt;&lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.hi.md"&gt;‡§π‡§ø‡§®‡•ç‡§¶‡•Ä&lt;/a&gt; | English | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.fr.md"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.zh-TW.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.zh-CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.pt-BR.md"&gt;Portugu√™s do Brasil&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.kr.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.ru.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.uk.md"&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; is a performant toolchain for web projects, it aims to provide developer tools to maintain the health of said projects.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome is a &lt;a href="https://raw.githubusercontent.com/biomejs/biome/main/benchmark#formatting"&gt;fast formatter&lt;/a&gt;&lt;/strong&gt; for &lt;em&gt;JavaScript&lt;/em&gt;, &lt;em&gt;TypeScript&lt;/em&gt;, &lt;em&gt;JSX&lt;/em&gt;, &lt;em&gt;JSON&lt;/em&gt;, &lt;em&gt;CSS&lt;/em&gt; and &lt;em&gt;GraphQL&lt;/em&gt; that scores &lt;strong&gt;&lt;a href="https://console.algora.io/challenges/prettier"&gt;97% compatibility with &lt;em&gt;Prettier&lt;/em&gt;&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome is a &lt;a href="https://github.com/biomejs/biome/tree/main/benchmark#linting"&gt;performant linter&lt;/a&gt;&lt;/strong&gt; for &lt;em&gt;JavaScript&lt;/em&gt;, &lt;em&gt;TypeScript&lt;/em&gt;, &lt;em&gt;JSX&lt;/em&gt;, &lt;em&gt;JSON&lt;/em&gt;, &lt;em&gt;CSS&lt;/em&gt;, and &lt;em&gt;GraphQL&lt;/em&gt; that features &lt;strong&gt;&lt;a href="https://biomejs.dev/linter/rules/"&gt;more than 300 rules&lt;/a&gt;&lt;/strong&gt; from ESLint, typescript-eslint, and &lt;a href="https://github.com/biomejs/biome/discussions/3"&gt;other sources&lt;/a&gt;. It &lt;strong&gt;outputs detailed and contextualized diagnostics&lt;/strong&gt; that help you to improve your code and become a better programmer!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; is designed from the start to be used &lt;a href="https://biomejs.dev/guides/editors/first-party-extensions/"&gt;interactively within an editor&lt;/a&gt;. It can format and lint malformed code as you are writing it.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install --save-dev --save-exact @biomejs/biome
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# format files
npx @biomejs/biome format --write

# lint files and apply the safe fixes
npx @biomejs/biome lint --write

# run format, lint, etc. and apply the safe fixes
npx @biomejs/biome check --write

# check all files against format, lint, etc. in CI environments
npx @biomejs/biome ci
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to give Biome a run without installing it, use the &lt;a href="https://biomejs.dev/playground/"&gt;online playground&lt;/a&gt;, compiled to WebAssembly.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Check out our &lt;a href="https://biomejs.dev/"&gt;homepage&lt;/a&gt; to learn more about Biome, or directly head to the &lt;a href="https://biomejs.dev/guides/getting-started/"&gt;Getting Started guide&lt;/a&gt; to start using Biome.&lt;/p&gt; 
&lt;h2&gt;More about Biome&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; has sane defaults and it doesn't require configuration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; aims to support &lt;a href="https://biomejs.dev/internals/language-support/"&gt;all main languages&lt;/a&gt; of modern web development.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; &lt;a href="https://biomejs.dev/guides/manual-installation/"&gt;doesn't require Node.js&lt;/a&gt; to function.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; has first-class LSP support, with a sophisticated parser that represents the source text in full fidelity and top-notch error recovery.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; wants to offer a high-quality &lt;em&gt;Developer Experience&lt;/em&gt;, with descriptive diagnostics and great performance.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; unifies functionalities that have previously been separate tools. Building upon a shared base allows us to provide a cohesive experience for processing code, displaying errors, parallelize work, caching, and configuration.&lt;/p&gt; 
&lt;p&gt;Read more about our &lt;a href="https://biomejs.dev/internals/philosophy/"&gt;project philosophy&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; is &lt;a href="https://github.com/biomejs/biome/tree/main/LICENSE-MIT"&gt;MIT licensed&lt;/a&gt; or &lt;a href="https://github.com/biomejs/biome/tree/main/LICENSE-APACHE"&gt;Apache 2.0 licensed&lt;/a&gt; and moderated under the &lt;a href="https://github.com/biomejs/biome/tree/main/CODE_OF_CONDUCT.md"&gt;Contributor Covenant Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Funding&lt;/h2&gt; 
&lt;p&gt;You can fund the project in different ways&lt;/p&gt; 
&lt;h3&gt;Project sponsorship and funding&lt;/h3&gt; 
&lt;p&gt;You can sponsor or fund the project via &lt;a href="https://opencollective.com/biome"&gt;Open collective&lt;/a&gt; or &lt;a href="https://github.com/sponsors/biomejs"&gt;GitHub sponsors&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Biome offers a simple sponsorship program that allows companies to get visibility and recognition among various developers.&lt;/p&gt; 
&lt;p&gt;Biome offers &lt;a href="https://biomejs.dev/enterprise"&gt;enterprise support&lt;/a&gt;, where Core Contributors can be employed to work on company-focused projects.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://depot.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-light@3x.png"&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-dark@3x.png"&gt; 
      &lt;img src="https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-light@3x.png" width="400" alt="Depot logo"&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Silver Sponsors&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://l2beat.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://images.opencollective.com/l2beat/c2b2a27/logo/256.png" height="100" alt="L2BEAT logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://www.phoenixlabs.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://images.opencollective.com/phoenix-labs/2824ed4/logo/100.png?height=100" height="100" alt="Phoenix Labs logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://lokalise.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/14294501?s=200&amp;amp;v=4" height="100" alt="Lokalise logo"&gt;&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Bronze Sponsors&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://nanabit.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://images.opencollective.com/nanabit/d15fd98/logo/256.png?height=80" width="80" alt="Nanabit logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://vital.io/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/25357309?s=200" width="80" alt="Vital logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://coderabbit.ai/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/132028505?s=200&amp;amp;v=4" width="80" alt="CodeRabbit logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://forge42.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/161314831?s=200&amp;amp;v=4" width="80" alt="Forge42 logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="http://rstudio.org/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/513560?s=200&amp;amp;v=4" width="80" alt="RStudio logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://pennylane.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/57875210?s=200&amp;amp;v=4" width="80" alt="Pennylane logo"&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://jetbrains.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.png" width="100" alt="JetBrains logo"&gt;&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>juspay/hyperswitch</title>
      <link>https://github.com/juspay/hyperswitch</link>
      <description>&lt;p&gt;An open source payments switch written in Rust to make payments fast, reliable and affordable&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-logo-dark.svg#gh-dark-mode-only" alt="Hyperswitch-Logo" width="40%"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-logo-light.svg#gh-light-mode-only" alt="Hyperswitch-Logo" width="40%"&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Composable Open-Source Payments Infrastructure&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/gifs/quickstart.gif" alt="Quickstart demo"&gt; &lt;/p&gt; 
&lt;!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} --&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/juspay/hyperswitch/actions?query=workflow%3ACI+branch%3Amain"&gt; &lt;img src="https://github.com/juspay/hyperswitch/workflows/CI-push/badge.svg?sanitize=true"&gt; &lt;/a&gt; &lt;a href="https://github.com/juspay/hyperswitch/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/juspay/hyperswitch"&gt; &lt;/a&gt; &lt;a href="https://github.com/juspay/hyperswitch/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/Made_in-Rust-orange"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.linkedin.com/company/hyperswitch/"&gt; &lt;img src="https://img.shields.io/badge/follow-hyperswitch-blue?logo=linkedin&amp;amp;labelColor=grey"&gt; &lt;/a&gt; &lt;a href="https://x.com/hyperswitchio"&gt; &lt;img src="https://img.shields.io/badge/follow-%40hyperswitchio-white?logo=x&amp;amp;labelColor=grey"&gt; &lt;/a&gt; &lt;a href="https://inviter.co/hyperswitch-slack"&gt; &lt;img src="https://img.shields.io/badge/chat-on_slack-blue?logo=slack&amp;amp;labelColor=grey&amp;amp;color=%233f0e40"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;üìÅ Table of Contents&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-what-can-i-do-with-hyperswitch"&gt;What Can I Do with Hyperswitch?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-quickstart-local-setup"&gt;Quickstart (Local Setup)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#cloud-deployment"&gt;Cloud Deployment&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#hosted-sandbox-no-setup-required"&gt;Hosted Sandbox (No Setup Required)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-why-hyperswitch"&gt;Why Hyperswitch?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#architectural-overview"&gt;Architectural Overview&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#our-vision"&gt;Our Vision&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#community--contributions"&gt;Community &amp;amp; Contributions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#feature-requests--bugs"&gt;Feature Requests &amp;amp; Bugs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#versioning"&gt;Versioning&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#copyright-and-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#team-behind-hyperswitch"&gt;Team Behind Hyperswitch&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;summary&gt;&lt;h2&gt; What Can I Do with Hyperswitch?&lt;/h2&gt;&lt;/summary&gt; 
&lt;p&gt;Hyperswitch offers a modular, open-source payments infrastructure designed for flexibility and control. Apart from our Payment Suite offering, this solution allows businesses to pick and integrate only the modules they need on top of their existing payment stack ‚Äî without unnecessary complexity or vendor lock-in.&lt;/p&gt; 
&lt;p&gt;Each module is independent and purpose-built to optimize different aspects of payment processing.&lt;/p&gt; 
&lt;h3&gt; Learn More About The Payment Modules &lt;/h3&gt; 
&lt;details&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cost Observability&lt;/strong&gt;&lt;br&gt; Advanced observability tools to audit, monitor, and optimize your payment costs. Detect hidden fees, downgrades, and penalties with self-serve dashboards and actionable insights.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/ai-powered-cost-observability"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revenue Recovery&lt;/strong&gt;&lt;br&gt; Combat passive churn with intelligent retry strategies tuned by card bin, region, method, and more. Offers fine-grained control over retry algorithms, penalty budgets, and recovery transparency.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/revenue-recovery"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vault&lt;/strong&gt;&lt;br&gt; A PCI-compliant vault service to store cards, tokens, wallets, and bank credentials. Provides a unified, secure, and reusable store of customer-linked payment methods.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/vault"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Intelligent Routing&lt;/strong&gt;&lt;br&gt; Route each transaction to the PSP with the highest predicted auth rate. Reduce retries, avoid downtime, and minimize latency while maximizing first attempt success.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/intelligent-routing"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reconciliation&lt;/strong&gt;&lt;br&gt; Automate 2-way and 3-way reconciliation with backdated support, staggered scheduling, and customizable outputs. Reduces manual ops effort and increases audit confidence.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/reconciliation"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternate Payment Methods&lt;/strong&gt;&lt;br&gt; Drop-in widgets for PayPal, Apple Pay, Google Pay, Samsung Pay, Pay by Bank, and BNPL providers like Klarna. Maximizes conversions with seamless one-click checkout.&lt;br&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/enable-alternate-payment-method-widgets"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt; Local Setup via Docker &lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# One-click local setup

git clone --depth 1 --branch latest https://github.com/juspay/hyperswitch

cd hyperswitch

scripts/setup.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;This script: &lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Detects Docker/Podman&lt;/li&gt; 
  &lt;li&gt;Offers multiple deployment profiles: 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Standard&lt;/strong&gt;: App server + Control Center&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Full&lt;/strong&gt;: Includes monitoring + schedulers&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Minimal&lt;/strong&gt;: Standalone App server&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Provides access links when done&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you need further help, check out our &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/overview/unified-local-setup-using-docker"&gt;video tutorial&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;üëâ After setup, &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/using-hyperswitch-control-center#add-a-payment-processor"&gt;configure a connector&lt;/a&gt; and &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/test-a-payment"&gt;test a payment&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Hosted Sandbox (No Setup Required)&lt;/h3&gt; 
&lt;p&gt;Hyperswitch offers a fully hosted sandbox environment that requires no setup. You can explore the Control Center, configure payment connectors, and test payments directly from the UI.&lt;/p&gt; 
&lt;a href="https://app.hyperswitch.io"&gt; &lt;img src="https://github.com/juspay/hyperswitch/raw/main/docs/imgs/try-the-sandbox.png?raw=true" height="35"&gt; &lt;/a&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt; What you can do in the Hosted Sandbox&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Access the full Control Center&lt;/li&gt; 
  &lt;li&gt;Configure payment connectors&lt;/li&gt; 
  &lt;li&gt;View logs, routing rules, and retry strategies&lt;/li&gt; 
  &lt;li&gt;Try payments directly from the UI&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;Cloud Deployment&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;You can deploy to AWS, GCP, or Azure using Helm or CDK scripts. Fastest path:&lt;/p&gt; 
&lt;p&gt;Click to deploy via AWS:&lt;/p&gt; 
&lt;a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=HyperswitchBootstarp&amp;amp;templateURL=https://hyperswitch-synth.s3.eu-central-1.amazonaws.com/hs-starter-config.yaml"&gt; &lt;img src="https://github.com/juspay/hyperswitch/raw/main/docs/imgs/aws_button.png?raw=true" height="35"&gt; &lt;/a&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Cloud Deployment Instructions&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Click the AWS deployment button above to launch the stack.&lt;/li&gt; 
  &lt;li&gt;Follow the guided steps in the AWS Console (approx. 30‚Äì45 mins).&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;‚úÖ This setup provisions Hyperswitch on your cloud account using CloudFormation.&lt;/p&gt; 
 &lt;p&gt;üìò For full instructions and Helm-based deployments, check out the&lt;br&gt; &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/deploy-on-kubernetes-using-helm"&gt;Cloud Install Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#architectural-overview"&gt; &lt;h2 id="architectural-overview"&gt;Architectural Overview&lt;/h2&gt; &lt;/a&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/features.png"&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/non-functional-features.png"&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-architecture-v1.png"&gt; 
&lt;h2&gt;Why Hyperswitch?&lt;/h2&gt; 
&lt;p&gt;Hyperswitch is a commercial open-source payments stack purpose-built for scale, flexibility, and developer experience. Designed with a modular architecture, Hyperswitch lets you pick only the components you need‚Äîwhether it‚Äôs routing, retries, vaulting, or observability‚Äîwithout vendor lock-in or bloated integrations.&lt;/p&gt; 
&lt;p&gt;Built in Rust for performance and reliability, Hyperswitch supports global payment methods (cards, wallets, BNPL, UPI, Pay by Bank), exposes smart routing and retry logic, and provides a visual workflow builder in the Control Center. Whether you're integrating a full payment suite or augmenting an existing stack with a single module, Hyperswitch meets you where you are.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;‚ÄúLinux for Payments‚Äù&lt;/strong&gt; ‚Äî Hyperswitch is a well-architected reference for teams who want to own their payments stack.&lt;/p&gt; 
&lt;p&gt;We believe in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Embracing Payment Diversity:&lt;/strong&gt; Innovation comes from enabling choice‚Äîacross payment methods, processors, and flows.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Open Source by Default:&lt;/strong&gt; Transparency drives trust and builds better, reusable software.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Community-Driven Development:&lt;/strong&gt; Our roadmap is shaped by real-world use cases and contributors.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Systems-Level Engineering:&lt;/strong&gt; We hold ourselves to a high bar for reliability, security, and performance.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Maximizing Value Creation:&lt;/strong&gt; For developers, customers, and partners alike.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Community-Driven, Enterprise-Tested:&lt;/strong&gt; Hyperswitch is built in the open with real-world feedback from developers and contributors, and maintained by Juspay, the team powering payment infrastructure for 400+ leading enterprises worldwide.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributors from around the world to help build Hyperswitch. Whether you're fixing bugs, improving documentation, or adding new features, your help is appreciated.&lt;/p&gt; 
&lt;p&gt;Please read our &lt;a href="https://github.com/juspay/hyperswitch/raw/main/docs/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;Join the conversation on &lt;a href="https://inviter.co/hyperswitch-slack"&gt;Slack&lt;/a&gt; or explore open issues on &lt;a href="https://github.com/juspay/hyperswitch/issues"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#feature-requests"&gt; &lt;h2 id="feature-requests"&gt;Feature requests &amp;amp; Bugs&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;For new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our &lt;a href="https://github.com/juspay/hyperswitch/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For reporting a bug, please read the issue guidelines and search for &lt;a href="https://github.com/juspay/hyperswitch/issues"&gt;existing and closed issues&lt;/a&gt;. If your problem or idea is not addressed yet, please &lt;a href="https://github.com/juspay/hyperswitch/issues/new/choose"&gt;open a new issue&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#versioning"&gt; &lt;h2 id="versioning"&gt;Versioning&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;Check the &lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#copyright-and-license"&gt; &lt;h2 id="copyright-and-license"&gt;Copyright and License&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;This product is licensed under the &lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/LICENSE"&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#team-behind-hyperswitch"&gt; &lt;h2 id="team-behind-hyperswitch"&gt;Team behind Hyperswitch&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;The core team of 150+ engineers building Hyperswitch. Keep up the great work! ü•Ç&lt;/p&gt; 
&lt;a href="https://github.com/juspay/hyperswitch/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=juspay/hyperswitch" alt="Contributors"&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>bevyengine/bevy</title>
      <link>https://github.com/bevyengine/bevy</link>
      <description>&lt;p&gt;A refreshingly simple data-driven game engine built in Rust&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://bevy.org"&gt;&lt;img src="https://raw.githubusercontent.com/bevyengine/bevy/main/assets/branding/bevy_logo_light_dark_and_dimmed.svg?sanitize=true" alt="Bevy"&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/bevyengine/bevy#license"&gt;&lt;img src="https://img.shields.io/badge/license-MIT%2FApache-blue.svg?sanitize=true" alt="License"&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/bevy"&gt;&lt;img src="https://img.shields.io/crates/v/bevy.svg?sanitize=true" alt="Crates.io"&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/bevy"&gt;&lt;img src="https://img.shields.io/crates/d/bevy.svg?sanitize=true" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://docs.rs/bevy/latest/bevy/"&gt;&lt;img src="https://docs.rs/bevy/badge.svg?sanitize=true" alt="Docs"&gt;&lt;/a&gt; &lt;a href="https://github.com/bevyengine/bevy/actions"&gt;&lt;img src="https://github.com/bevyengine/bevy/workflows/CI/badge.svg?sanitize=true" alt="CI"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/bevy"&gt;&lt;img src="https://img.shields.io/discord/691052431525675048.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What is Bevy?&lt;/h2&gt; 
&lt;p&gt;Bevy is a refreshingly simple data-driven game engine built in Rust. It is free and open-source forever!&lt;/p&gt; 
&lt;h2&gt;WARNING&lt;/h2&gt; 
&lt;p&gt;Bevy is still in the early stages of development. Important features are missing. Documentation is sparse. A new version of Bevy containing breaking changes to the API is released &lt;a href="https://bevy.org/news/bevy-0-6/#the-train-release-schedule"&gt;approximately once every 3 months&lt;/a&gt;. We provide &lt;a href="https://bevy.org/learn/migration-guides/"&gt;migration guides&lt;/a&gt;, but we can't guarantee migrations will always be easy. Use only if you are willing to work in this environment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;MSRV:&lt;/strong&gt; Bevy relies heavily on improvements in the Rust language and compiler. As a result, the Minimum Supported Rust Version (MSRV) is generally close to "the latest stable release" of Rust.&lt;/p&gt; 
&lt;h2&gt;Design Goals&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Capable&lt;/strong&gt;: Offer a complete 2D and 3D feature set&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple&lt;/strong&gt;: Easy for newbies to pick up, but infinitely flexible for power users&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Focused&lt;/strong&gt;: Data-oriented architecture using the Entity Component System paradigm&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modular&lt;/strong&gt;: Use only what you need. Replace what you don't like&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt;: App logic should run quickly, and when possible, in parallel&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Productive&lt;/strong&gt;: Changes should compile quickly ... waiting isn't fun&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://bevy.org"&gt;Features&lt;/a&gt;:&lt;/strong&gt; A quick overview of Bevy's features.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://bevy.org/news/"&gt;News&lt;/a&gt;&lt;/strong&gt;: A development blog that covers our progress, plans and shiny new features.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Docs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://bevy.org/learn/quick-start/introduction"&gt;Quick Start Guide&lt;/a&gt;:&lt;/strong&gt; Bevy's official Quick Start Guide. The best place to start learning Bevy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.rs/bevy"&gt;Bevy Rust API Docs&lt;/a&gt;:&lt;/strong&gt; Bevy's Rust API docs, which are automatically generated from the doc comments in this repo.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/bevyengine/bevy/tree/latest/examples"&gt;Official Examples&lt;/a&gt;:&lt;/strong&gt; Bevy's dedicated, runnable examples, which are great for digging into specific concepts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://bevy.org/assets/#learning"&gt;Community-Made Learning Resources&lt;/a&gt;&lt;/strong&gt;: More tutorials, documentation, and examples made by the Bevy community.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Before contributing or participating in discussions with the community, you should familiarize yourself with our &lt;a href="https://raw.githubusercontent.com/bevyengine/bevy/main/CODE_OF_CONDUCT.md"&gt;&lt;strong&gt;Code of Conduct&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://discord.gg/bevy"&gt;Discord&lt;/a&gt;:&lt;/strong&gt; Bevy's official discord server.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://reddit.com/r/bevy"&gt;Reddit&lt;/a&gt;:&lt;/strong&gt; Bevy's official subreddit.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/bevyengine/bevy/discussions"&gt;GitHub Discussions&lt;/a&gt;:&lt;/strong&gt; The best place for questions about Bevy, answered right here!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://bevy.org/assets/"&gt;Bevy Assets&lt;/a&gt;:&lt;/strong&gt; A collection of awesome Bevy projects, tools, plugins and learning materials.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;If you'd like to help build Bevy, check out the &lt;strong&gt;&lt;a href="https://bevy.org/learn/contribute/introduction"&gt;Contributor's Guide&lt;/a&gt;&lt;/strong&gt;. For simple problems, feel free to &lt;a href="https://github.com/bevyengine/bevy/issues"&gt;open an issue&lt;/a&gt; or &lt;a href="https://github.com/bevyengine/bevy/pulls"&gt;PR&lt;/a&gt; and tackle it yourself!&lt;/p&gt; 
&lt;p&gt;For more complex architecture decisions and experimental mad science, please open an &lt;a href="https://github.com/bevyengine/rfcs"&gt;RFC&lt;/a&gt; (Request For Comments) so we can brainstorm together effectively!&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;We recommend checking out the &lt;a href="https://bevy.org/learn/quick-start/introduction"&gt;Quick Start Guide&lt;/a&gt; for a brief introduction.&lt;/p&gt; 
&lt;p&gt;Follow the &lt;a href="https://bevy.org/learn/quick-start/getting-started/setup"&gt;Setup guide&lt;/a&gt; to ensure your development environment is set up correctly. Once set up, you can quickly try out the &lt;a href="https://github.com/bevyengine/bevy/tree/latest/examples"&gt;examples&lt;/a&gt; by cloning this repo and running the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Switch to the correct version (latest release, default is main development branch)
git checkout latest
# Runs the "breakout" example
cargo run --example breakout
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To draw a window with standard functionality enabled, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use bevy::prelude::*;

fn main() {
  App::new()
    .add_plugins(DefaultPlugins)
    .run();
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fast Compiles&lt;/h3&gt; 
&lt;p&gt;Bevy can be built just fine using default configuration on stable Rust. However for really fast iterative compiles, you should enable the "fast compiles" setup by &lt;a href="https://bevy.org/learn/quick-start/getting-started/setup"&gt;following the instructions here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/bevyengine/bevy/main/docs/cargo_features.md"&gt;Bevy Cargo Features&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;This &lt;a href="https://raw.githubusercontent.com/bevyengine/bevy/main/docs/cargo_features.md"&gt;list&lt;/a&gt; outlines the different cargo features supported by Bevy. These allow you to customize the Bevy feature set for your use-case.&lt;/p&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;p&gt;Bevy is the result of the hard work of many people. A huge thanks to all Bevy contributors, the many open source projects that have come before us, the &lt;a href="https://arewegameyet.rs/"&gt;Rust gamedev ecosystem&lt;/a&gt;, and the many libraries we build on.&lt;/p&gt; 
&lt;p&gt;A huge thanks to Bevy's &lt;a href="https://bevy.org"&gt;generous sponsors&lt;/a&gt;. Bevy will always be free and open source, but it isn't free to make. Please consider &lt;a href="https://bevy.org/donate/"&gt;sponsoring our work&lt;/a&gt; if you like what we're building.&lt;/p&gt; 
&lt;!-- This next line need to stay exactly as is. It is required for BrowserStack sponsorship. --&gt; 
&lt;p&gt;This project is tested with BrowserStack.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Bevy is free, open source and permissively licensed! Except where noted (below and/or in individual files), all code in this repository is dual-licensed under either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MIT License (&lt;a href="https://raw.githubusercontent.com/bevyengine/bevy/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="http://opensource.org/licenses/MIT"&gt;http://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Apache License, Version 2.0 (&lt;a href="https://raw.githubusercontent.com/bevyengine/bevy/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option. This means you can select the license you prefer! This dual-licensing approach is the de-facto standard in the Rust ecosystem and there are &lt;a href="https://github.com/bevyengine/bevy/issues/2373"&gt;very good reasons&lt;/a&gt; to include both.&lt;/p&gt; 
&lt;p&gt;Some of the engine's code carries additional copyright notices and license terms due to their external origins. These are generally BSD-like, but exact details vary by crate: If the README of a crate contains a 'License' header (or similar), the additional copyright notices and license terms applicable to that crate will be listed. The above licensing requirement still applies to contributions to those crates, and sections of those crates will carry those license terms. The &lt;a href="https://doc.rust-lang.org/cargo/reference/manifest.html#the-license-and-license-file-fields"&gt;license&lt;/a&gt; field of each crate will also reflect this. For example, &lt;a href="https://raw.githubusercontent.com/bevyengine/bevy/main/crates/bevy_mikktspace/README.md#license-agreement"&gt;&lt;code&gt;bevy_mikktspace&lt;/code&gt;&lt;/a&gt; has code under the Zlib license (as well as a copyright notice when choosing the MIT license).&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/bevyengine/bevy/main/assets"&gt;assets&lt;/a&gt; included in this repository (for our &lt;a href="https://raw.githubusercontent.com/bevyengine/bevy/main/examples/README.md"&gt;examples&lt;/a&gt;) typically fall under different open licenses. These will not be included in your game (unless copied in by you), and they are not distributed in the published bevy crates. See &lt;a href="https://raw.githubusercontent.com/bevyengine/bevy/main/CREDITS.md"&gt;CREDITS.md&lt;/a&gt; for the details of the licenses of those files.&lt;/p&gt; 
&lt;h3&gt;Your contributions&lt;/h3&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>bytecodealliance/wasmtime</title>
      <link>https://github.com/bytecodealliance/wasmtime</link>
      <description>&lt;p&gt;A lightweight WebAssembly runtime that is fast, secure, and standards-compliant&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;&lt;code&gt;wasmtime&lt;/code&gt;&lt;/h1&gt; 
 &lt;p&gt; &lt;strong&gt;A standalone runtime for &lt;a href="https://webassembly.org/"&gt;WebAssembly&lt;/a&gt;&lt;/strong&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;A &lt;a href="https://bytecodealliance.org/"&gt;Bytecode Alliance&lt;/a&gt; project&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://github.com/bytecodealliance/wasmtime/actions?query=workflow%3ACI"&gt;&lt;img src="https://github.com/bytecodealliance/wasmtime/workflows/CI/badge.svg?sanitize=true" alt="build status"&gt;&lt;/a&gt; &lt;a href="https://bytecodealliance.zulipchat.com/#narrow/stream/217126-wasmtime"&gt;&lt;img src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg?sanitize=true" alt="zulip chat"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/rustc-stable+-green.svg?sanitize=true" alt="supported rustc stable"&gt; &lt;a href="https://docs.rs/wasmtime"&gt;&lt;img src="https://docs.rs/wasmtime/badge.svg?sanitize=true" alt="Documentation Status"&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;h3&gt; &lt;a href="https://bytecodealliance.github.io/wasmtime/"&gt;Guide&lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://bytecodealliance.github.io/wasmtime/contributing.html"&gt;Contributing&lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://wasmtime.dev/"&gt;Website&lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://bytecodealliance.zulipchat.com/#narrow/stream/217126-wasmtime"&gt;Chat&lt;/a&gt; &lt;/h3&gt; 
&lt;/div&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The Wasmtime CLI can be installed on Linux and macOS (locally) with a small install script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;curl https://wasmtime.dev/install.sh -sSf | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This script installs into &lt;code&gt;$WASMTIME_HOME&lt;/code&gt; (defaults to &lt;code&gt;$HOME/.wasmtime&lt;/code&gt;), and executable is placed in &lt;code&gt;$WASMTIME_HOME/bin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Windows or otherwise interested users can download installers and binaries directly from the &lt;a href="https://github.com/bytecodealliance/wasmtime/releases"&gt;GitHub Releases&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;Documentation on Wasmtime's currently supported versions can be found &lt;a href="https://docs.wasmtime.dev/stability-release.html#current-versions"&gt;in the online book documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;If you've got the &lt;a href="https://www.rust-lang.org/tools/install"&gt;Rust compiler installed&lt;/a&gt; then you can take some Rust source code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;fn main() {
    println!("Hello, world!");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and compile it into a WebAssembly component with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;rustup target add wasm32-wasip2
rustc hello.rs --target wasm32-wasip2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once compiled, you can can run your component:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;wasmtime hello.wasm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should see the following output:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;Hello, world!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(Note: make sure you installed Rust using the &lt;a href="https://rustup.rs"&gt;&lt;code&gt;rustup&lt;/code&gt;&lt;/a&gt; method in the official instructions above, and do not have a copy of the Rust toolchain installed on your system in some other way as well (e.g. the system package manager). Otherwise, the &lt;code&gt;rustup target add...&lt;/code&gt; command may not install the target for the correct copy of Rust.)&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Fast&lt;/strong&gt;. Wasmtime is built on the optimizing &lt;a href="https://cranelift.dev/"&gt;Cranelift&lt;/a&gt; code generator to quickly generate high-quality machine code either at runtime or ahead-of-time. Wasmtime is optimized for efficient instantiation, low-overhead calls between the embedder and wasm, and scalability of concurrent instances.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.wasmtime.dev/security.html"&gt;Secure&lt;/a&gt;&lt;/strong&gt;. Wasmtime's development is strongly focused on correctness and security. Building on top of Rust's runtime safety guarantees, each Wasmtime feature goes through careful review and consideration via an &lt;a href="https://github.com/bytecodealliance/rfcs"&gt;RFC process&lt;/a&gt;. Once features are designed and implemented, they undergo 24/7 fuzzing donated by &lt;a href="https://google.github.io/oss-fuzz/"&gt;Google's OSS Fuzz&lt;/a&gt;. As features stabilize they become part of a &lt;a href="https://docs.wasmtime.dev/stability-release.html"&gt;release&lt;/a&gt;, and when things go wrong we have a well-defined &lt;a href="https://bytecodealliance.org/security"&gt;security policy&lt;/a&gt; in place to quickly mitigate and patch any issues. We follow best practices for defense-in-depth and integrate protections and mitigations for issues like Spectre. Finally, we're working to push the state-of-the-art by collaborating with academic researchers to formally verify critical parts of Wasmtime and Cranelift.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.rs/wasmtime/latest/wasmtime/struct.Config.html"&gt;Configurable&lt;/a&gt;&lt;/strong&gt;. Wasmtime uses sensible defaults, but can also be configured to provide more fine-grained control over things like CPU and memory consumption. Whether you want to run Wasmtime in a tiny environment or on massive servers with many concurrent instances, we've got you covered.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.rs/wasmtime-wasi/latest/wasmtime_wasi/"&gt;WASI&lt;/a&gt;&lt;/strong&gt;. Wasmtime supports a rich set of APIs for interacting with the host environment through the &lt;a href="https://wasi.dev"&gt;WASI standard&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.wasmtime.dev/stability-tiers.html"&gt;Standards Compliant&lt;/a&gt;&lt;/strong&gt;. Wasmtime passes the &lt;a href="https://github.com/WebAssembly/testsuite"&gt;official WebAssembly test suite&lt;/a&gt;, implements the &lt;a href="https://github.com/WebAssembly/wasm-c-api"&gt;official C API of wasm&lt;/a&gt;, and implements &lt;a href="https://github.com/WebAssembly/proposals"&gt;future proposals to WebAssembly&lt;/a&gt; as well. Wasmtime developers are intimately engaged with the WebAssembly standards process all along the way too.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Language Support&lt;/h2&gt; 
&lt;p&gt;You can use Wasmtime from a variety of different languages through embeddings of the implementation.&lt;/p&gt; 
&lt;p&gt;Languages supported by the Bytecode Alliance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://bytecodealliance.github.io/wasmtime/lang-rust.html"&gt;Rust&lt;/a&gt;&lt;/strong&gt; - the &lt;a href="https://crates.io/crates/wasmtime"&gt;&lt;code&gt;wasmtime&lt;/code&gt; crate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://bytecodealliance.github.io/wasmtime/lang-c.html"&gt;C&lt;/a&gt;&lt;/strong&gt; - the &lt;a href="https://bytecodealliance.github.io/wasmtime/c-api/"&gt;&lt;code&gt;wasm.h&lt;/code&gt;, &lt;code&gt;wasi.h&lt;/code&gt;, and &lt;code&gt;wasmtime.h&lt;/code&gt; headers&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/bytecodealliance/wasmtime/main/crates/c-api/CMakeLists.txt"&gt;CMake&lt;/a&gt; or &lt;a href="https://conan.io/center/wasmtime"&gt;&lt;code&gt;wasmtime&lt;/code&gt; Conan package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;C++&lt;/strong&gt; - the &lt;a href="https://bytecodealliance.github.io/wasmtime/c-api/"&gt;&lt;code&gt;wasmtime.hh&lt;/code&gt; header&lt;/a&gt; or the &lt;a href="https://conan.io/center/wasmtime-cpp"&gt;&lt;code&gt;wasmtime-cpp&lt;/code&gt; Conan package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://bytecodealliance.github.io/wasmtime/lang-python.html"&gt;Python&lt;/a&gt;&lt;/strong&gt; - the &lt;a href="https://pypi.org/project/wasmtime/"&gt;&lt;code&gt;wasmtime&lt;/code&gt; PyPI package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://bytecodealliance.github.io/wasmtime/lang-dotnet.html"&gt;.NET&lt;/a&gt;&lt;/strong&gt; - the &lt;a href="https://www.nuget.org/packages/Wasmtime"&gt;&lt;code&gt;Wasmtime&lt;/code&gt; NuGet package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://bytecodealliance.github.io/wasmtime/lang-go.html"&gt;Go&lt;/a&gt;&lt;/strong&gt; - the &lt;a href="https://pkg.go.dev/github.com/bytecodealliance/wasmtime-go"&gt;&lt;code&gt;wasmtime-go&lt;/code&gt; repository&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://bytecodealliance.github.io/wasmtime/lang-ruby.html"&gt;Ruby&lt;/a&gt;&lt;/strong&gt; - the &lt;a href="https://rubygems.org/gems/wasmtime"&gt;&lt;code&gt;wasmtime&lt;/code&gt; gem&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Languages supported by the community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.wasmtime.dev/lang-elixir.html"&gt;Elixir&lt;/a&gt;&lt;/strong&gt; - the &lt;a href="https://hex.pm/packages/wasmex"&gt;&lt;code&gt;wasmex&lt;/code&gt; hex package&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Perl&lt;/strong&gt; - the &lt;a href="https://metacpan.org/pod/Wasm::Wasmtime"&gt;&lt;code&gt;Wasm&lt;/code&gt; Perl package's &lt;code&gt;Wasm::Wasmtime&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://bytecodealliance.github.io/wasmtime"&gt;üìö Read the Wasmtime guide here! üìö&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://bytecodealliance.github.io/wasmtime"&gt;wasmtime guide&lt;/a&gt; is the best starting point to learn about what Wasmtime can do for you or help answer your questions about Wasmtime. If you're curious in contributing to Wasmtime, &lt;a href="https://bytecodealliance.github.io/wasmtime/contributing.html"&gt;it can also help you do that&lt;/a&gt;!&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;It's Wasmtime.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>fujiapple852/trippy</title>
      <link>https://github.com/fujiapple852/trippy</link>
      <description>&lt;p&gt;A network diagnostic tool&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/fujiapple852/trippy/master/docs/src/assets/Trippy-Vertical-DarkMode.svg#gh-dark-mode-only" width="300"&gt; &lt;img src="https://raw.githubusercontent.com/fujiapple852/trippy/master/docs/src/assets/Trippy-Vertical.svg#gh-light-mode-only" width="300"&gt;&lt;br&gt; &lt;br&gt; &lt;a href="https://github.com/fujiapple852/trippy/actions/workflows/ci.yml"&gt; &lt;img src="https://github.com/fujiapple852/trippy/actions/workflows/ci.yml/badge.svg?branch=master"&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/trippy/0.13.0"&gt; &lt;img src="https://img.shields.io/crates/v/trippy.svg?sanitize=true"&gt;&lt;/a&gt; &lt;a href="https://repology.org/project/trippy/versions"&gt; &lt;img src="https://repology.org/badge/tiny-repos/trippy.svg?sanitize=true"&gt;&lt;/a&gt; &lt;a href="https://trippy.zulipchat.com"&gt; &lt;img src="https://img.shields.io/badge/zulip-join_chat-brightgreen.svg?sanitize=true"&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/%23trippy-dev:matrix.org"&gt; &lt;img src="https://img.shields.io/badge/matrix/trippy-dev:matrix.org-blue"&gt;&lt;/a&gt; &lt;br&gt; &lt;br&gt; Trippy combines the functionality of traceroute and ping and is designed to assist with the analysis of networking issues. &lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/fujiapple852/trippy/master/assets/0.12.0/demo.gif" alt="trippy"&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://trippy.rs/start/getting-started"&gt;getting started&lt;/a&gt; guide.&lt;/p&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;p&gt;Trippy runs on Linux, BSD, macOS, and Windows. It can be installed from most package managers, precompiled binaries, or source.&lt;/p&gt; 
&lt;p&gt;For example, to install Trippy from &lt;code&gt;cargo&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo install trippy --locked
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;All package managers&lt;/summary&gt; 
 &lt;h3&gt;Cargo&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://crates.io/crates/trippy/0.13.0"&gt;&lt;img src="https://img.shields.io/crates/v/trippy" alt="Crates.io"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;cargo install trippy --locked
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;APT (Debian)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://tracker.debian.org/pkg/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/debian_13/trippy.svg?sanitize=true" alt="Debian 13 package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;apt install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note:&lt;/p&gt; 
  &lt;p&gt;Only available for Debian 13 (&lt;code&gt;trixie&lt;/code&gt;) and later.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;PPA (Ubuntu)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://launchpad.net/~fujiapple/+archive/ubuntu/trippy/+packages"&gt;&lt;img src="https://img.shields.io/badge/Ubuntu%20PPA-0.13.0-brightgreen" alt="Ubuntu PPA"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;add-apt-repository ppa:fujiapple/trippy
apt update &amp;amp;&amp;amp; apt install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ìò Note:&lt;/p&gt; 
  &lt;p&gt;Only available for Ubuntu 24.04 (&lt;code&gt;Noble&lt;/code&gt;) and 22.04 (&lt;code&gt;Jammy&lt;/code&gt;).&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;Snap (Linux)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://snapcraft.io/trippy"&gt;&lt;img src="https://snapcraft.io/trippy/badge.svg?sanitize=true" alt="trippy"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;snap install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Homebrew (macOS)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://formulae.brew.sh/formula/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/homebrew/trippy.svg?sanitize=true" alt="Homebrew package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;brew install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;WinGet (Windows)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/microsoft/winget-pkgs/tree/master/manifests/f/FujiApple/Trippy/0.13.0"&gt;&lt;img src="https://img.shields.io/badge/WinGet-0.13.0-brightgreen" alt="winget package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;winget install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Scoop (Windows)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/ScoopInstaller/Main/raw/master/bucket/trippy.json"&gt;&lt;img src="https://img.shields.io/scoop/v/trippy?style=flat&amp;amp;labelColor=5c5c5c&amp;amp;color=%234dc71f" alt="Scoop package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;scoop install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Chocolatey (Windows)&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://community.chocolatey.org/packages/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/chocolatey/trippy.svg?sanitize=true" alt="Chocolatey package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;choco install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;NetBSD&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://pkgsrc.se/net/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/pkgsrc_current/trippy.svg?sanitize=true" alt="pkgsrc current package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pkgin install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;FreeBSD&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://www.freshports.org/net/trippy/"&gt;&lt;img src="https://repology.org/badge/version-for-repo/freebsd/trippy.svg?sanitize=true" alt="FreeBSD port"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pkg install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;OpenBSD&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://openports.pl/path/net/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/openbsd/trippy.svg?sanitize=true" alt="OpenBSD port"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pkg_add trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Arch Linux&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://archlinux.org/packages/extra/x86_64/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/arch/trippy.svg?sanitize=true" alt="Arch package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;pacman -S trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Gentoo Linux&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://packages.gentoo.org/packages/net-analyzer/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/gentoo/trippy.svg?sanitize=true" alt="Gentoo package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;emerge -av net-analyzer/trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Void Linux&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/void-linux/void-packages/tree/master/srcpkgs/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/void_x86_64/trippy.svg?sanitize=true" alt="Void Linux x86_64 package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;xbps-install -S trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;ALT Sisyphus&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://packages.altlinux.org/en/sisyphus/srpms/trippy/"&gt;&lt;img src="https://repology.org/badge/version-for-repo/altsisyphus/trippy.svg?sanitize=true" alt="ALT Sisyphus package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;apt-get install trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Chimera Linux&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/chimera-linux/cports/tree/master/user/trippy"&gt;&lt;img src="https://repology.org/badge/version-for-repo/chimera/trippy.svg?sanitize=true" alt="Chimera Linux package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;apk add trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Nix&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://github.com/NixOS/nixpkgs/raw/master/pkgs/by-name/tr/trippy/package.nix"&gt;&lt;img src="https://repology.org/badge/version-for-repo/nix_unstable/trippy.svg?sanitize=true" alt="nixpkgs unstable package"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;nix-env -iA trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Docker&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://hub.docker.com/r/fujiapple/trippy/"&gt;&lt;img src="https://img.shields.io/docker/v/fujiapple/trippy" alt="Docker Image Version (latest by date)"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;docker run -it fujiapple/trippy
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;All Repositories&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://repology.org/project/trippy/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/trippy.svg?sanitize=true" alt="Packaging status"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;See the &lt;a href="https://trippy.rs/start/installation"&gt;installation&lt;/a&gt; guide for details of how to install Trippy on your system.&lt;/p&gt; 
&lt;h3&gt;Run&lt;/h3&gt; 
&lt;p&gt;To run a basic trace to &lt;code&gt;example.com&lt;/code&gt; with default settings, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sudo trip example.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://trippy.rs/guides/usage"&gt;usage examples&lt;/a&gt; and &lt;a href="https://trippy.rs/reference/cli"&gt;CLI reference&lt;/a&gt; for details of how to use Trippy. To use Trippy without elevated privileges, see the &lt;a href="https://trippy.rs/guides/privileges"&gt;privileges&lt;/a&gt; guide.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Full documentation is available at &lt;a href="https://trippy.rs"&gt;trippy.rs&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;documentation links&lt;/summary&gt; 
 &lt;h2&gt;Getting Started&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/start/getting-started/"&gt;Getting Started&lt;/a&gt; guide.&lt;/p&gt; 
 &lt;h2&gt;Features&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/start/features/"&gt;Features&lt;/a&gt; list.&lt;/p&gt; 
 &lt;h2&gt;Distributions&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/start/installation/"&gt;Distributions&lt;/a&gt; list.&lt;/p&gt; 
 &lt;h2&gt;Privileges&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/guides/privileges/"&gt;Privileges&lt;/a&gt; guide.&lt;/p&gt; 
 &lt;h2&gt;Usage Examples&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/guides/usage/"&gt;Usage Examples&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Command Reference&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/cli/"&gt;Command Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Theme Reference&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/theme/"&gt;Theme Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Column Reference&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/column/"&gt;Column Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Configuration Reference&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/configuration/"&gt;Configuration Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Locale Reference&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/locale/"&gt;Locale Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Versions&lt;/h2&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/reference/version/"&gt;Version Reference&lt;/a&gt;.&lt;/p&gt; 
 &lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; 
 &lt;h3&gt;Why does Trippy show "Awaiting data..."?&lt;/h3&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/guides/faq/"&gt;Awaiting Data&lt;/a&gt; guide.&lt;/p&gt; 
 &lt;p&gt;&lt;a name="windows-defender"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;How do I allow incoming ICMP traffic in the Windows Defender firewall?&lt;/h3&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/guides/windows_firewall/"&gt;Windows Defender Firewall&lt;/a&gt; guide.&lt;/p&gt; 
 &lt;h3&gt;What are the recommended settings for Trippy?&lt;/h3&gt; 
 &lt;p&gt;See the &lt;a href="https://trippy.rs/guides/recommendation/"&gt;Recommended Tracing Settings&lt;/a&gt; guide.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;Trippy is made possible by &lt;a href="https://github.com/ratatui-org/ratatui"&gt;ratatui&lt;/a&gt; ( formerly &lt;a href="https://github.com/fdehau/tui-rs"&gt;tui-rs&lt;/a&gt;), &lt;a href="https://github.com/crossterm-rs/crossterm"&gt;crossterm&lt;/a&gt; as well as &lt;a href="https://github.com/fujiapple852/trippy/raw/master/Cargo.toml"&gt;several&lt;/a&gt; foundational Rust libraries.&lt;/p&gt; 
&lt;p&gt;Trippy draws heavily from &lt;a href="https://github.com/traviscross/mtr"&gt;mtr&lt;/a&gt; and also incorporates ideas from both &lt;a href="https://github.com/libparistraceroute/libparistraceroute"&gt;libparistraceroute&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/insomniacslk/dublin-traceroute"&gt;Dublin Traceroute&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The Trippy networking code is inspired by &lt;a href="https://github.com/libpnet/libpnet"&gt;pnet&lt;/a&gt; and some elements of that codebase are incorporated in Trippy.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://en.wikipedia.org/wiki/Autonomous_system_(Internet)"&gt;AS&lt;/a&gt; data is retrieved from the &lt;a href="https://team-cymru.com/community-services/ip-asn-mapping/#dns"&gt;IP to ASN Mapping Service&lt;/a&gt; provided by &lt;a href="https://team-cymru.com"&gt;Team Cymru&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://trippy.cli.rs"&gt;trippy.cli.rs&lt;/a&gt; CNAME hosting is provided by &lt;a href="https://cli.rs"&gt;cli.rs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The Trippy chat room is sponsored by &lt;a href="https://zulip.com"&gt;Zulip&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Trippy logo designed by &lt;a href="https://www.instagram.com/harunocaksiz"&gt;Harun Ocaksiz Design&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is distributed under the terms of the Apache License (Version 2.0).&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in time by you, as defined in the Apache-2.0 license, shall be licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/fujiapple852/trippy/master/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;Copyright 2022 &lt;a href="https://github.com/fujiapple852/trippy/graphs/contributors"&gt;Trippy Contributors&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ankitects/anki</title>
      <link>https://github.com/ankitects/anki</link>
      <description>&lt;p&gt;Anki is a smart spaced repetition flashcard program&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Anki¬Æ&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://buildkite.com/ankitects/anki-ci"&gt;&lt;img src="https://badge.buildkite.com/c9edf020a4aec976f9835e54751cc5409d843adbb66d043bd3.svg?branch=main" alt="Build status"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repo contains the source code for the computer version of &lt;a href="https://apps.ankiweb.net"&gt;Anki&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;About&lt;/h1&gt; 
&lt;p&gt;Anki is a spaced repetition program. Please see the &lt;a href="https://apps.ankiweb.net"&gt;website&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h1&gt;Getting Started&lt;/h1&gt; 
&lt;h3&gt;Anki Betas&lt;/h3&gt; 
&lt;p&gt;If you'd like to try development builds of Anki but don't feel comfortable building the code, please see &lt;a href="https://betas.ankiweb.net/"&gt;Anki betas&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Developing&lt;/h3&gt; 
&lt;p&gt;For more information on building and developing, please see &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/docs/development.md"&gt;Development&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Want to contribute to Anki? Check out the &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/docs/contributing.md"&gt;Contribution Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Anki Contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/CONTRIBUTORS"&gt;CONTRIBUTORS&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Anki's license: &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rustdesk/rustdesk</title>
      <link>https://github.com/rustdesk/rustdesk</link>
      <description>&lt;p&gt;An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/rustdesk/rustdesk/master/res/logo-header.svg?sanitize=true" alt="RustDesk - Your remote desktop"&gt;&lt;br&gt; &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#raw-steps-to-build"&gt;Build&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#how-to-build-with-docker"&gt;Docker&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#file-structure"&gt;Structure&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#snapshot"&gt;Snapshot&lt;/a&gt;&lt;br&gt; [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-UA.md"&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-CS.md"&gt;ƒçesky&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ZH.md"&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-HU.md"&gt;Magyar&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ES.md"&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FA.md"&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FR.md"&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DE.md"&gt;Deutsch&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PL.md"&gt;Polski&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ID.md"&gt;Indonesian&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FI.md"&gt;Suomi&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ML.md"&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-NL.md"&gt;Nederlands&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-IT.md"&gt;Italiano&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-RU.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PTBR.md"&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-EO.md"&gt;Esperanto&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-KR.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-AR.md"&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-VN.md"&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DA.md"&gt;Dansk&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-GR.md"&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-TR.md"&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-NO.md"&gt;Norsk&lt;/a&gt;]&lt;br&gt; &lt;b&gt;We need your help to translate this README, &lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/lang"&gt;RustDesk UI&lt;/a&gt; and &lt;a href="https://github.com/rustdesk/doc.rustdesk.com"&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Caution] &lt;strong&gt;Misuse Disclaimer:&lt;/strong&gt; &lt;br&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Chat with us: &lt;a href="https://discord.gg/nDceKgxnkV"&gt;Discord&lt;/a&gt; | &lt;a href="https://twitter.com/rustdesk"&gt;Twitter&lt;/a&gt; | &lt;a href="https://www.reddit.com/r/rustdesk"&gt;Reddit&lt;/a&gt; | &lt;a href="https://www.youtube.com/@rustdesk"&gt;YouTube&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ko-fi.com/I2I04VU09"&gt;&lt;img src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" alt="ko-fi"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, &lt;a href="https://rustdesk.com/server"&gt;set up your own&lt;/a&gt;, or &lt;a href="https://github.com/rustdesk/rustdesk-server-demo"&gt;write your own rendezvous/relay server&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png" alt="image"&gt;&lt;/p&gt; 
&lt;p&gt;RustDesk welcomes contribution from everyone. See &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for help getting started.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/wiki/FAQ"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/releases"&gt;&lt;strong&gt;BINARY DOWNLOAD&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/releases/tag/nightly"&gt;&lt;strong&gt;NIGHTLY BUILD&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://f-droid.org/en/packages/com.carriez.flutter_hbb"&gt;&lt;img src="https://f-droid.org/badge/get-it-on.png" alt="Get it on F-Droid" height="80"&gt;&lt;/a&gt; &lt;a href="https://flathub.org/apps/com.rustdesk.RustDesk"&gt;&lt;img src="https://flathub.org/api/badge?svg&amp;amp;locale=en" alt="Get it on Flathub" height="80"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;p&gt;Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our &lt;a href="https://github.com/rustdesk/rustdesk/raw/master/.github/workflows/flutter-build.yml"&gt;CI&lt;/a&gt; for building Flutter version.&lt;/p&gt; 
&lt;p&gt;Please download Sciter dynamic library yourself.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll"&gt;Windows&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so"&gt;Linux&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib"&gt;macOS&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Raw Steps to build&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Prepare your Rust development env and C++ build env&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://github.com/microsoft/vcpkg"&gt;vcpkg&lt;/a&gt;, and set &lt;code&gt;VCPKG_ROOT&lt;/code&gt; env variable correctly&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static&lt;/li&gt; 
   &lt;li&gt;Linux/macOS: vcpkg install libvpx libyuv opus aom&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;run &lt;code&gt;cargo run&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://rustdesk.com/docs/en/dev/build/"&gt;Build&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;How to Build on Linux&lt;/h2&gt; 
&lt;h3&gt;Ubuntu 18 (Debian 10)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;openSUSE Tumbleweed&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fedora 28 (CentOS 8)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Arch (Manjaro)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install vcpkg&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fix libvpx (For Fedora)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i 's/CFLAGS+=-I/CFLAGS+=-fPIC -I/g' Makefile
sed -i 's/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g' Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How to build with Docker&lt;/h2&gt; 
&lt;p&gt;Begin by cloning the repository and building the Docker container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t "rustdesk-builder" .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, each time you need to build the application, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID="$(id -u)" -e PGID="$(id -g)" rustdesk-builder
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the &lt;code&gt;&amp;lt;OPTIONAL-ARGS&amp;gt;&lt;/code&gt; position. For instance, if you wanted to build an optimized release version, you would run the command above followed by &lt;code&gt;--release&lt;/code&gt;. The resulting executable will be available in the target folder on your system, and can be run with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;target/debug/rustdesk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you're running a release executable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;target/release/rustdesk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as &lt;code&gt;install&lt;/code&gt; or &lt;code&gt;run&lt;/code&gt; are not currently supported via this method as they would install or run the program inside the container instead of the host.&lt;/p&gt; 
&lt;h2&gt;File Structure&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common"&gt;libs/hbb_common&lt;/a&gt;&lt;/strong&gt;: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/scrap"&gt;libs/scrap&lt;/a&gt;&lt;/strong&gt;: screen capture&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/enigo"&gt;libs/enigo&lt;/a&gt;&lt;/strong&gt;: platform specific keyboard/mouse control&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard"&gt;libs/clipboard&lt;/a&gt;&lt;/strong&gt;: file copy and paste implementation for Windows, Linux, macOS.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/ui"&gt;src/ui&lt;/a&gt;&lt;/strong&gt;: obsolete Sciter UI (deprecated)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/server"&gt;src/server&lt;/a&gt;&lt;/strong&gt;: audio/clipboard/input/video services, and network connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/client.rs"&gt;src/client.rs&lt;/a&gt;&lt;/strong&gt;: start a peer connection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs"&gt;src/rendezvous_mediator.rs&lt;/a&gt;&lt;/strong&gt;: Communicate with &lt;a href="https://github.com/rustdesk/rustdesk-server"&gt;rustdesk-server&lt;/a&gt;, wait for remote direct (TCP hole punching) or relayed connection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/platform"&gt;src/platform&lt;/a&gt;&lt;/strong&gt;: platform specific code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/flutter"&gt;flutter&lt;/a&gt;&lt;/strong&gt;: Flutter code for desktop and mobile&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js"&gt;flutter/web/js&lt;/a&gt;&lt;/strong&gt;: JavaScript for Flutter web client&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651" alt="Connection Manager"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea" alt="Connected to a Windows PC"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad" alt="File Transfer"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5" alt="TCP Tunneling"&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>neovide/neovide</title>
      <link>https://github.com/neovide/neovide</link>
      <description>&lt;p&gt;No Nonsense Neovim Client in Rust&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Neovide&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/SjFpZdQys6"&gt;&lt;img src="https://badgen.net/badge/icon/discord?icon=discord&amp;amp;label" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/%23neovide:matrix.org"&gt;&lt;img src="https://matrix.to/img/matrix-badge.svg?sanitize=true" alt="Chat on Matrix"&gt;&lt;/a&gt; &lt;a href="https://github.com/neovide/neovide/discussions"&gt;&lt;img src="https://img.shields.io/badge/GitHub-Discussions-green?logo=github" alt="Discussions"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img align="left" src="https://raw.githubusercontent.com/neovide/neovide/main/website/docs/assets/neovide-128x128.png"&gt; 
&lt;p&gt;This is a simple graphical user interface for &lt;a href="https://github.com/neovim/neovim"&gt;Neovim&lt;/a&gt; (an aggressively refactored and updated Vim editor). Where possible there are some graphical improvements, but functionally it should act like the terminal UI.&lt;/p&gt; 
&lt;p&gt;To checkout all the &lt;strong&gt;cool features&lt;/strong&gt;, &lt;strong&gt;installation instructions&lt;/strong&gt;, &lt;strong&gt;configuration settings&lt;/strong&gt; and much more, head on over to &lt;a href="https://neovide.dev"&gt;neovide.dev&lt;/a&gt;.&lt;/p&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/neovide/neovide/main/website/docs/assets/BasicScreenCap.png" alt="Screenshot of Neovide"&gt; 
 &lt;em&gt;Screenshot of Neovide running on Windows&lt;/em&gt; 
&lt;/div&gt; 
&lt;h2&gt;Author Notes&lt;/h2&gt; 
&lt;p&gt;I've been using this as my daily driver since November 2019. It should be relatively stable, but I'm still working out some kinks and ironing out some cross platform issues. In general it should be usable at this point, and if it isn't I consider that a bug and appreciate a report in the issues! Any help and ideas are also greatly appreciated.&lt;/p&gt; 
&lt;p&gt;I'm also very interested in suggestions code quality/style wise when it comes to Rust. I'm pretty new to the language and appreciate any critiques that you might have to offer. I won't take all of them, but I promise to consider anything you might have to offer.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under &lt;a href="https://raw.githubusercontent.com/neovide/neovide/main/LICENSE"&gt;MIT&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>typst/typst</title>
      <link>https://github.com/typst/typst</link>
      <description>&lt;p&gt;A new markup-based typesetting system that is powerful and easy to learn.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img alt="Typst" src="https://user-images.githubusercontent.com/17899797/226108480-722b770e-6313-40d7-84f2-26bebb55a281.png"&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://typst.app/docs/"&gt; &lt;img alt="Documentation" src="https://img.shields.io/website?down_message=offline&amp;amp;label=docs&amp;amp;up_color=007aff&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Ftypst.app%2Fdocs"&gt;&lt;/a&gt; &lt;a href="https://typst.app/"&gt; &lt;img alt="Typst App" src="https://img.shields.io/website?down_message=offline&amp;amp;label=typst.app&amp;amp;up_color=239dad&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Ftypst.app"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/2uDybryKPe"&gt; &lt;img alt="Discord Server" src="https://img.shields.io/discord/1054443721975922748?color=5865F2&amp;amp;label=discord&amp;amp;labelColor=555"&gt;&lt;/a&gt; &lt;a href="https://github.com/typst/typst/raw/main/LICENSE"&gt; &lt;img alt="Apache-2 License" src="https://img.shields.io/badge/license-Apache%202-brightgreen"&gt;&lt;/a&gt; &lt;a href="https://typst.app/jobs/"&gt; &lt;img alt="Jobs at Typst" src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Ftypst.app%2Fassets%2Fdata%2Fshields.json&amp;amp;query=%24.jobs.text&amp;amp;label=jobs&amp;amp;color=%23A561FF&amp;amp;cacheSeconds=1800"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Typst is a new markup-based typesetting system that is designed to be as powerful as LaTeX while being much easier to learn and use. Typst has:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Built-in markup for the most common formatting tasks&lt;/li&gt; 
 &lt;li&gt;Flexible functions for everything else&lt;/li&gt; 
 &lt;li&gt;A tightly integrated scripting system&lt;/li&gt; 
 &lt;li&gt;Math typesetting, bibliography management, and more&lt;/li&gt; 
 &lt;li&gt;Fast compile times thanks to incremental compilation&lt;/li&gt; 
 &lt;li&gt;Friendly error messages in case something goes wrong&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This repository contains the Typst compiler and its CLI, which is everything you need to compile Typst documents locally. For the best writing experience, consider signing up to our &lt;a href="https://typst.app/"&gt;collaborative online editor&lt;/a&gt; for free.&lt;/p&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;A &lt;a href="https://typst.app/docs/tutorial/"&gt;gentle introduction&lt;/a&gt; to Typst is available in our documentation. However, if you want to see the power of Typst encapsulated in one image, here it is:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img alt="Example" width="900" src="https://user-images.githubusercontent.com/17899797/228031796-ced0e452-fcee-4ae9-92da-b9287764ff25.png"&gt; &lt;/p&gt; 
&lt;p&gt;Let's dissect what's going on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;We use &lt;em&gt;set rules&lt;/em&gt; to configure element properties like the size of pages or the numbering of headings. By setting the page height to &lt;code&gt;auto&lt;/code&gt;, it scales to fit the content. Set rules accommodate the most common configurations. If you need full control, you can also use &lt;a href="https://typst.app/docs/reference/styling/#show-rules"&gt;show rules&lt;/a&gt; to completely redefine the appearance of an element.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;We insert a heading with the &lt;code&gt;= Heading&lt;/code&gt; syntax. One equals sign creates a top level heading, two create a subheading and so on. Typst has more lightweight markup like this, see the &lt;a href="https://typst.app/docs/reference/syntax/"&gt;syntax&lt;/a&gt; reference for a full list.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://typst.app/docs/reference/math/"&gt;Mathematical equations&lt;/a&gt; are enclosed in dollar signs. By adding extra spaces around the contents of an equation, we can put it into a separate block. Multi-letter identifiers are interpreted as Typst definitions and functions unless put into quotes. This way, we don't need backslashes for things like &lt;code&gt;floor&lt;/code&gt; and &lt;code&gt;sqrt&lt;/code&gt;. And &lt;code&gt;phi.alt&lt;/code&gt; applies the &lt;code&gt;alt&lt;/code&gt; modifier to the &lt;code&gt;phi&lt;/code&gt; to select a particular symbol variant.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Now, we get to some &lt;a href="https://typst.app/docs/reference/scripting/"&gt;scripting&lt;/a&gt;. To input code into a Typst document, we can write a hash followed by an expression. We define two variables and a recursive function to compute the n-th fibonacci number. Then, we display the results in a center-aligned table. The table function takes its cells row-by-row. Therefore, we first pass the formulas &lt;code&gt;$F_1$&lt;/code&gt; to &lt;code&gt;$F_8$&lt;/code&gt; and then the computed fibonacci numbers. We apply the spreading operator (&lt;code&gt;..&lt;/code&gt;) to both because they are arrays and we want to pass the arrays' items as individual arguments.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Text version of the code example.&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-typst"&gt;#set page(width: 10cm, height: auto)
#set heading(numbering: "1.")

= Fibonacci sequence
The Fibonacci sequence is defined through the
recurrence relation $F_n = F_(n-1) + F_(n-2)$.
It can also be expressed in _closed form:_

$ F_n = round(1 / sqrt(5) phi.alt^n), quad
  phi.alt = (1 + sqrt(5)) / 2 $

#let count = 8
#let nums = range(1, count + 1)
#let fib(n) = (
  if n &amp;lt;= 2 { 1 }
  else { fib(n - 1) + fib(n - 2) }
)

The first #count numbers of the sequence are:

#align(center, table(
  columns: count,
  ..nums.map(n =&amp;gt; $F_#n$),
  ..nums.map(n =&amp;gt; str(fib(n))),
))
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Typst's CLI is available from different sources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can get sources and pre-built binaries for the latest release of Typst from the &lt;a href="https://github.com/typst/typst/releases/"&gt;releases page&lt;/a&gt;. Download the archive for your platform and place it in a directory that is in your &lt;code&gt;PATH&lt;/code&gt;. To stay up to date with future releases, you can simply run &lt;code&gt;typst update&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can install Typst through different package managers. Note that the versions in the package managers might lag behind the latest release.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Linux: 
    &lt;ul&gt; 
     &lt;li&gt;View &lt;a href="https://repology.org/project/typst/versions"&gt;Typst on Repology&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;View &lt;a href="https://snapcraft.io/typst"&gt;Typst's Snap&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;macOS: &lt;code&gt;brew install typst&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Windows: &lt;code&gt;winget install --id Typst.Typst&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If you have a &lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt; toolchain installed, you can install&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;the latest released Typst version with &lt;code&gt;cargo install --locked typst-cli&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;a development version with &lt;code&gt;cargo install --git https://github.com/typst/typst --locked typst-cli&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Nix users can&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;use the &lt;code&gt;typst&lt;/code&gt; package with &lt;code&gt;nix-shell -p typst&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;build and run a development version with &lt;code&gt;nix run github:typst/typst -- --version&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Docker users can run a prebuilt image with &lt;code&gt;docker run ghcr.io/typst/typst:latest --help&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Once you have installed Typst, you can use it like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Creates `file.pdf` in working directory.
typst compile file.typ

# Creates PDF file at the desired path.
typst compile path/to/source.typ path/to/output.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also watch source files and automatically recompile on changes. This is faster than compiling from scratch each time because Typst has incremental compilation.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Watches source files and recompiles on changes.
typst watch file.typ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Typst further allows you to add custom font paths for your project and list all of the fonts it discovered:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Adds additional directories to search for fonts.
typst compile --font-path path/to/fonts file.typ

# Lists all of the discovered fonts in the system and the given directory.
typst fonts --font-path path/to/fonts

# Or via environment variable (Linux syntax).
TYPST_FONT_PATHS=path/to/fonts typst fonts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For other CLI subcommands and options, see below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Prints available subcommands and options.
typst help

# Prints detailed usage of a subcommand.
typst help watch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you prefer an integrated IDE-like experience with autocompletion and instant preview, you can also check out our &lt;a href="https://typst.app/"&gt;free web app&lt;/a&gt;. Alternatively, there is a community-created language server called &lt;a href="https://myriad-dreamin.github.io/tinymist/"&gt;Tinymist&lt;/a&gt; which is integrated into various editor extensions.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The main places where the community gathers are our &lt;a href="https://forum.typst.app/"&gt;Forum&lt;/a&gt; and our &lt;a href="https://discord.gg/2uDybryKPe"&gt;Discord server&lt;/a&gt;. The Forum is a great place to ask questions, help others, and share cool things you created with Typst. The Discord server is more suitable for quicker questions, discussions about contributing, or just to chat. We'd be happy to see you there!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://typst.app/universe/"&gt;Typst Universe&lt;/a&gt; is where the community shares templates and packages. If you want to share your own creations, you can submit them to our &lt;a href="https://github.com/typst/packages/"&gt;package repository&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you had a bad experience in our community, please &lt;a href="https://typst.app/contact"&gt;reach out to us&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We love to see contributions from the community. If you experience bugs, feel free to open an issue. If you would like to implement a new feature or bug fix, please follow the steps outlined in the &lt;a href="https://github.com/typst/typst/raw/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To build Typst yourself, first ensure that you have the &lt;a href="https://rustup.rs/"&gt;latest stable Rust&lt;/a&gt; installed. Then, clone this repository and build the CLI with the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/typst/typst
cd typst
cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The optimized binary will be stored in &lt;code&gt;target/release/&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Another good way to contribute is by &lt;a href="https://github.com/typst/packages/"&gt;sharing packages&lt;/a&gt; with the community.&lt;/p&gt; 
&lt;h2&gt;Pronunciation and Spelling&lt;/h2&gt; 
&lt;p&gt;IPA: /ta…™pst/. "Ty" like in &lt;strong&gt;Ty&lt;/strong&gt;pesetting and "pst" like in Hi&lt;strong&gt;pst&lt;/strong&gt;er. When writing about Typst, capitalize its name as a proper noun, with a capital "T".&lt;/p&gt; 
&lt;h2&gt;Design Principles&lt;/h2&gt; 
&lt;p&gt;All of Typst has been designed with three key goals in mind: Power, simplicity, and performance. We think it's time for a system that matches the power of LaTeX, is easy to learn and use, all while being fast enough to realize instant preview. To achieve these goals, we follow three core design principles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simplicity through Consistency:&lt;/strong&gt; If you know how to do one thing in Typst, you should be able to transfer that knowledge to other things. If there are multiple ways to do the same thing, one of them should be at a different level of abstraction than the other. E.g. it's okay that &lt;code&gt;= Introduction&lt;/code&gt; and &lt;code&gt;#heading[Introduction]&lt;/code&gt; do the same thing because the former is just syntax sugar for the latter.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Power through Composability:&lt;/strong&gt; There are two ways to make something flexible: Have a knob for everything or have a few knobs that you can combine in many ways. Typst is designed with the second way in mind. We provide systems that you can compose in ways we've never even thought of. TeX is also in the second category, but it's a bit low-level and therefore people use LaTeX instead. But there, we don't really have that much composability. Instead, there's a package for everything (&lt;code&gt;\usepackage{knob}&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Performance through Incrementality:&lt;/strong&gt; All Typst language features must accommodate for incremental compilation. Luckily we have &lt;a href="https://github.com/typst/comemo/"&gt;&lt;code&gt;comemo&lt;/code&gt;&lt;/a&gt;, a system for incremental compilation which does most of the hard work in the background.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We'd like to thank everyone who is supporting Typst's development, be it via &lt;a href="https://github.com/sponsors/typst/"&gt;GitHub sponsors&lt;/a&gt; or elsewhere. In particular, special thanks[^1] go to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://posit.co/blog/posit-and-typst/"&gt;Posit&lt;/a&gt; for financing a full-time compiler engineer&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nlnet.nl/"&gt;NLnet&lt;/a&gt; for supporting work on Typst via multiple grants through the &lt;a href="https://nlnet.nl/core"&gt;NGI Zero Core&lt;/a&gt; fund: 
  &lt;ul&gt; 
   &lt;li&gt;Work on &lt;a href="https://nlnet.nl/project/Typst-HTML/"&gt;HTML export&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Work on &lt;a href="https://nlnet.nl/project/Typst-Accessibility/"&gt;PDF accessibility&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.science-startups.berlin/"&gt;Science &amp;amp; Startups&lt;/a&gt; for having financed Typst development from January through June 2023 via the Berlin Startup Scholarship&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zerodha.tech/blog/1-5-million-pdfs-in-25-minutes/"&gt;Zerodha&lt;/a&gt; for their generous one-time sponsorship&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;[^1]: This list only includes contributions for our open-source work that exceed or are expected to exceed ‚Ç¨10K.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tensorzero/tensorzero</title>
      <link>https://github.com/tensorzero/tensorzero</link>
      <description>&lt;p&gt;TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;
 &lt;picture&gt;
  &lt;img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" alt="TensorZero Logo" width="128" height="128"&gt;
 &lt;/picture&gt;&lt;/p&gt; 
&lt;h1&gt;TensorZero&lt;/h1&gt; 
&lt;p&gt;
 &lt;picture&gt;
  &lt;img src="https://www.tensorzero.com/github-trending-badge.svg?sanitize=true" alt="#1 Repository Of The Day"&gt;
 &lt;/picture&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TensorZero is an open-source stack for &lt;em&gt;industrial-grade LLM applications&lt;/em&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gateway:&lt;/strong&gt; access every LLM provider through a unified API, built for performance (&amp;lt;1ms p99 latency)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability:&lt;/strong&gt; store inferences and feedback in your database, available programmatically or in the UI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimization:&lt;/strong&gt; collect metrics and human feedback to optimize prompts, models, and inference strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evaluation:&lt;/strong&gt; benchmark individual inferences or end-to-end workflows using heuristics, LLM judges, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Experimentation:&lt;/strong&gt; ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Take what you need, adopt incrementally, and complement with other tools.&lt;/p&gt; 
&lt;hr&gt; 
&lt;p align="center"&gt; &lt;b&gt;&lt;a href="https://www.tensorzero.com/" target="_blank"&gt;Website&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs" target="_blank"&gt;Docs&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.x.com/tensorzero" target="_blank"&gt;Twitter&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/slack" target="_blank"&gt;Slack&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/discord" target="_blank"&gt;Discord&lt;/a&gt;&lt;/b&gt; &lt;br&gt; &lt;br&gt; &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart" target="_blank"&gt;Quick Start (5min)&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank"&gt;Deployment Guide&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank"&gt;API Reference&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank"&gt;Configuration Reference&lt;/a&gt;&lt;/b&gt; &lt;/p&gt; 
&lt;hr&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;What is TensorZero?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How is TensorZero different from other LLM frameworks?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt; 1. TensorZero enables you to optimize complex LLM applications based on production metrics and human feedback.&lt;br&gt; 2. TensorZero supports the needs of industrial-grade LLM applications: low latency, high throughput, type safety, self-hosted, GitOps, customizability, etc.&lt;br&gt; 3. TensorZero unifies the entire LLMOps stack, creating compounding benefits. For example, LLM evaluations can be used for fine-tuning models alongside AI judges. &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Can I use TensorZero with ___?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Yes. Every major programming language is supported. You can use TensorZero with our Python client, any OpenAI SDK or OpenAI-compatible client, or our HTTP API.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Is TensorZero production-ready?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Yes. Here's a case study: &lt;b&gt;&lt;a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms"&gt;Automating Code Changelogs at a Large Bank with LLMs&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How much does TensorZero cost?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Nothing. TensorZero is 100% self-hosted and open-source. There are no paid features.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;Who is building TensorZero?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;Our technical team includes a former Rust compiler maintainer, machine learning researchers (Stanford, CMU, Oxford, Columbia) with thousands of citations, and the chief product officer of a decacorn startup. We're backed by the same investors as leading open-source projects (e.g. ClickHouse, CockroachDB) and AI labs (e.g. OpenAI, Anthropic).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="30%" valign="top"&gt;&lt;b&gt;How do I get started?&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="70%" valign="top"&gt;You can adopt TensorZero incrementally. Our &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/b&gt; goes from a vanilla OpenAI wrapper to a production-ready LLM application with observability and fine-tuning in just 5 minutes.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;hr&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;üåê LLM Gateway&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Integrate with TensorZero once and access every major LLM provider.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Access every major LLM provider (API or self-hosted) through a single unified API&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Infer with streaming, tool use, structured generation (JSON mode), batch, multimodal (VLMs), file inputs, caching, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Define prompt templates and schemas to enforce a consistent, typed interface between your application and the LLMs&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Satisfy extreme throughput and latency needs, thanks to ü¶Ä Rust: &amp;lt;1ms p99 latency overhead at 10k+ QPS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Integrate using our Python client, any OpenAI SDK or OpenAI-compatible client, or our HTTP API (use any programming language)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Ensure high availability with routing, retries, fallbacks, load balancing, granular timeouts, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: embeddings; real-time voice&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Model Providers&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="left" valign="top"&gt; &lt;p&gt; The TensorZero Gateway natively supports: &lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic"&gt;Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock"&gt;AWS Bedrock&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker"&gt;AWS SageMaker&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure"&gt;Azure OpenAI Service&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek"&gt;DeepSeek&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks"&gt;Fireworks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic"&gt;GCP Vertex AI Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini"&gt;GCP Vertex AI Gemini&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini"&gt;Google AI Studio (Gemini API)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/groq"&gt;Groq&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic"&gt;Hyperbolic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral"&gt;Mistral&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai"&gt;OpenAI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openrouter"&gt;OpenRouter&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/sglang"&gt;SGLang&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/tgi"&gt;TGI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/together"&gt;Together AI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm"&gt;vLLM&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai"&gt;xAI (Grok)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt; &lt;em&gt; Need something else? Your provider is most likely supported because TensorZero integrates with &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible"&gt;any OpenAI-compatible API (e.g. Ollama)&lt;/a&gt;&lt;/b&gt;. &lt;/em&gt; &lt;/p&gt; &lt;/td&gt; 
   &lt;td width="50%" align="left" valign="top"&gt; &lt;p&gt; The TensorZero Gateway supports advanced features like: &lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks"&gt;Retries &amp;amp; Fallbacks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations"&gt;Inference-Time Optimizations&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas"&gt;Prompt Templates &amp;amp; Schemas&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/experimentation/"&gt;Experimentation (A/B Testing)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/configuration-reference"&gt;Configuration-as-Code (GitOps)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference"&gt;Batch Inference&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference"&gt;Multimodal Inference (VLMs)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching"&gt;Inference Caching&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback"&gt;Metrics &amp;amp; Feedback&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/episodes"&gt;Multi-Step LLM Workflows (Episodes)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;em&gt;&amp;amp; a lot more...&lt;/em&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt; The TensorZero Gateway is written in Rust ü¶Ä with &lt;b&gt;performance&lt;/b&gt; in mind (&amp;lt;1ms p99 latency overhead @ 10k QPS). See &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/benchmarks"&gt;Benchmarks&lt;/a&gt;&lt;/b&gt;.&lt;br&gt; &lt;/p&gt; &lt;p&gt; You can run inference using the &lt;b&gt;TensorZero client&lt;/b&gt; (recommended), the &lt;b&gt;OpenAI client&lt;/b&gt;, or the &lt;b&gt;HTTP API&lt;/b&gt;. &lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Python ‚Äî TensorZero Client (Recommended)&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the TensorZero Python client.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from tensorzero import TensorZeroGateway  # or AsyncTensorZeroGateway


with TensorZeroGateway.build_embedded(clickhouse_url="...", config_file="...") as client:
    response = client.inference(
        model_name="openai::gpt-4o-mini",
        # Try other providers easily: "anthropic::claude-3-7-sonnet-20250219"
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "Write a haiku about artificial intelligence.",
                }
            ]
        },
    )
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Python ‚Äî OpenAI Client&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the OpenAI Python client with TensorZero.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI  # or AsyncOpenAI
from tensorzero import patch_openai_client

client = OpenAI()

patch_openai_client(
    client,
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
    async_setup=False,
)

response = client.chat.completions.create(
    model="tensorzero::model_name::openai::gpt-4o-mini",
    # Try other providers easily: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
    messages=[
        {
            "role": "user",
            "content": "Write a haiku about artificial intelligence.",
        }
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: JavaScript / TypeScript (Node) ‚Äî OpenAI Client&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the OpenAI Node client with TensorZero.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment"&gt;Detailed instructions ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-ts"&gt;import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "http://localhost:3000/openai/v1",
});

const response = await client.chat.completions.create({
  model: "tensorzero::model_name::openai::gpt-4o-mini",
  // Try other providers easily: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
  messages: [
    {
      role: "user",
      content: "Write a haiku about artificial intelligence.",
    },
  ],
});
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Other Languages &amp;amp; Platforms ‚Äî HTTP API&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;TensorZero supports virtually any programming language or platform via its HTTP API.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment"&gt;Detailed instructions ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST "http://localhost:3000/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "openai::gpt-4o-mini",
    "input": {
      "messages": [
        {
          "role": "user",
          "content": "Write a haiku about artificial intelligence."
        }
      ]
    }
  }'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;br&gt; 
&lt;h3&gt;üîç LLM Observability&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Zoom in to debug individual API calls, or zoom out to monitor metrics across models and prompts over time ‚Äî all using the open-source TensorZero UI.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Store inferences and feedback (metrics, human edits, etc.) in your own database&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Dive into individual inferences or high-level aggregate patterns using the TensorZero UI or programmatically&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Build datasets for optimization, evaluation, and other workflows&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Replay historical inferences with new prompts, models, inference strategies, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Export OpenTelemetry (OTLP) traces to your favorite general-purpose observability tool&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: AI-assisted debugging and root cause analysis; AI-assisted data labeling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Observability ¬ª Inference&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Observability ¬ª Function&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/2cc3cc9a-f33f-4e94-b8de-07522326f80a"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/00ae6605-8fa0-4efd-8238-ae8ea589860f"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br&gt; 
&lt;h3&gt;üìà LLM Optimization&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Send production metrics and human feedback to easily optimize your prompts, models, and inference strategies ‚Äî using the UI or programmatically.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Optimize your models with supervised fine-tuning, RLHF, and other techniques&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Optimize your prompts with automated prompt engineering algorithms like MIPROv2&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Optimize your inference strategy with dynamic in-context learning, chain of thought, best/mixture-of-N sampling, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Enable a feedback loop for your LLMs: a data &amp;amp; learning flywheel turning production data into smarter, faster, and cheaper models&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: programmatic optimization; synthetic data generation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Model Optimization&lt;/h4&gt; 
&lt;p&gt;Optimize closed-source and open-source models using supervised fine-tuning (SFT) and preference fine-tuning (DPO).&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Supervised Fine-tuning ‚Äî UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Preference Fine-tuning (DPO) ‚Äî Jupyter Notebook&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/cf7acf66-732b-43b3-af2a-5eba1ce40f6f"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h4&gt;Inference-Time Optimization&lt;/h4&gt; 
&lt;p&gt;Boost performance by dynamically updating your prompts with relevant examples, combining responses from multiple inferences, and more.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling"&gt;Best-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling"&gt;Mixture-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl"&gt;Dynamic In-Context Learning (DICL)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot"&gt;Chain-of-Thought (CoT)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;h4&gt;Prompt Optimization&lt;/h4&gt; 
&lt;p&gt;Optimize your prompts programmatically using research-driven optimization techniques.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling"&gt;MIPROv2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy"&gt;DSPy Integration&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="MIPROv2 diagram"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt; TensorZero comes with several optimization recipes, but you can also easily create your own. This example shows how to optimize a TensorZero function using an arbitrary tool ‚Äî here, DSPy, a popular library for automated prompt engineering. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;h3&gt;üìä LLM Evaluation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Compare prompts, models, and inference strategies using evaluations powered by heuristics and LLM judges.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Evaluate individual inferences with &lt;em&gt;static evaluations&lt;/em&gt; powered by heuristics or LLM judges (‚âà unit tests for LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Evaluate end-to-end workflows with &lt;em&gt;dynamic evaluations&lt;/em&gt; with complete flexibility (‚âà integration tests for LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Optimize LLM judges just like any other TensorZero function to align them to human preferences&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: more built-in evaluators; headless evaluations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Evaluation ¬ª UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Evaluation ¬ª CLI&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699"&gt;&lt;/td&gt; 
   &lt;td width="50%" align="left" valign="middle"&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100
exact_match: 0.83 ¬± 0.03
semantic_match: 0.98 ¬± 0.01
item_count: 7.15 ¬± 0.39&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;üß™ LLM Experimentation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Ship with confidence with built-in A/B testing for models, prompts, providers, hyperparameters, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Enforce principled experiments (RCTs) in complex workflows, including multi-turn and compound LLM systems&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: multi-armed bandits; AI-managed experiments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&amp;amp; more!&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Build with an open-source stack well-suited for prototypes but designed from the ground up to support the most complex LLM applications and deployments.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Build simple applications or massive deployments with GitOps-friendly orchestration&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Extend TensorZero with built-in escape hatches, programmatic-first usage, direct database access, and more&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Integrate with third-party tools: specialized observability and evaluations, model providers, agent orchestration frameworks, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Soon: UI playground&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Watch LLMs get better at data extraction in real-time with TensorZero!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl"&gt;Dynamic in-context learning (DICL)&lt;/a&gt;&lt;/strong&gt; is a powerful inference-time optimization available out of the box with TensorZero. It enhances LLM performance by automatically incorporating relevant historical examples into the prompt, without the need for model fine-tuning.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb"&gt;https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Start building today.&lt;/strong&gt; The &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; shows it's easy to set up an LLM application with TensorZero.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Questions?&lt;/strong&gt; Ask us on &lt;strong&gt;&lt;a href="https://www.tensorzero.com/slack"&gt;Slack&lt;/a&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;a href="https://www.tensorzero.com/discord"&gt;Discord&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Using TensorZero at work?&lt;/strong&gt; Email us at &lt;strong&gt;&lt;a href="mailto:hello@tensorzero.com"&gt;hello@tensorzero.com&lt;/a&gt;&lt;/strong&gt; to set up a Slack or Teams channel with your team (free).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Work with us.&lt;/strong&gt; We're &lt;strong&gt;&lt;a href="https://www.tensorzero.com/jobs"&gt;hiring in NYC&lt;/a&gt;&lt;/strong&gt;. We'd also welcome &lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/raw/main/CONTRIBUTING.md"&gt;open-source contributions&lt;/a&gt;&lt;/strong&gt;!&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;We are working on a series of &lt;strong&gt;complete runnable examples&lt;/strong&gt; illustrating TensorZero's data &amp;amp; learning flywheel.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner"&gt;Optimizing Data Extraction (NER) with TensorZero&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to use TensorZero to optimize a data extraction pipeline. We demonstrate techniques like fine-tuning and dynamic in-context learning (DICL). In the end, an optimized GPT-4o Mini model outperforms GPT-4o on this task ‚Äî at a fraction of the cost and latency ‚Äî using a small amount of training data.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/"&gt;Agentic RAG ‚Äî Multi-Hop Question Answering with LLMs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to build a multi-hop retrieval agent using TensorZero. The agent iteratively searches Wikipedia to gather information, and decides when it has enough context to answer a complex question.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences"&gt;Writing Haikus to Satisfy a Judge with Hidden Preferences&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example fine-tunes GPT-4o Mini to generate haikus tailored to a specific taste. You'll see TensorZero's "data flywheel in a box" in action: better variants leads to better data, and better data leads to better variants. You'll see progress by fine-tuning the LLM multiple times.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/"&gt;Improving LLM Chess Ability with Best-of-N Sampling&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example showcases how best-of-N sampling can significantly enhance an LLM's chess-playing abilities by selecting the most promising moves from multiple generated options.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy"&gt;Improving Math Reasoning with a Custom Recipe for Automated Prompt Engineering (DSPy)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;TensorZero provides a number of pre-built optimization recipes covering common LLM engineering workflows. But you can also easily create your own recipes and workflows! This example shows how to optimize a TensorZero function using an arbitrary tool ‚Äî here, DSPy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;&amp;amp; many more on the way!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>wssheldon/osintui</title>
      <link>https://github.com/wssheldon/osintui</link>
      <description>&lt;p&gt;OSINT from your favorite services in a friendly terminal user interface - integrations for Virustotal, Shodan, and Censys&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;osintui&lt;/h1&gt; 
 &lt;p&gt; Open Source Intelligence Terminal User Interface &lt;/p&gt; 
 &lt;!-- Badges --&gt; 
 &lt;p&gt; &lt;a href="https://github.com/wssheldon/osintui/graphs/contributors"&gt; &lt;img src="https://img.shields.io/github/contributors/wssheldon/osintui" alt="contributors"&gt; &lt;/a&gt; &lt;a href=""&gt; &lt;img src="https://img.shields.io/github/last-commit/wssheldon/osintui" alt="last update"&gt; &lt;/a&gt; &lt;a href="https://github.com/wssheldon/osintui/stargazers"&gt; &lt;img src="https://img.shields.io/github/stars/wssheldon/osintui" alt="stars"&gt; &lt;/a&gt; &lt;a href="https://github.com/wssheldon/osintui/issues/"&gt; &lt;img src="https://img.shields.io/github/issues/wssheldon/osintui" alt="open issues"&gt; &lt;/a&gt; &lt;a href="https://github.com/wssheldon/osintui/raw/master/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/wssheldon/osintui.svg?sanitize=true" alt="license"&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;h4&gt; &lt;a href="https://github.com/wssheldon/osintui/issues/"&gt;Report Bug&lt;/a&gt; &lt;span&gt; ¬∑ &lt;/span&gt; &lt;a href="https://github.com/wssheldon/osintui/issues/"&gt;Request Feature&lt;/a&gt; &lt;/h4&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/wssheldon/osintui/main/assets/demo.gif" alt="screenshot"&gt; 
&lt;/div&gt; 
&lt;hr&gt; 
&lt;h2&gt;Integrations&lt;/h2&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://shodan.io/"&gt; &lt;img src="https://raw.githubusercontent.com/wssheldon/osintui/main/assets/logos/shodan_logo.png" alt="shodan"&gt; &lt;/a&gt; &lt;a href="https://censys.io/"&gt; &lt;img src="https://raw.githubusercontent.com/wssheldon/osintui/main/assets/logos/censys_logo.png" alt="censys"&gt; &lt;/a&gt; &lt;a href="https://virustotal.com/"&gt; &lt;img src="https://raw.githubusercontent.com/wssheldon/osintui/main/assets/logos/virustotal_logo.png" alt="virustotal"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;First, install &lt;a href="https://www.rust-lang.org/tools/install"&gt;Rust&lt;/a&gt; (using the recommended rustup installation method) and then&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;cargo install osintui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;osintui expects a TOML configuration file stored at &lt;code&gt;~/.osintui/config/config.toml&lt;/code&gt; that sets the necessary API tokens for each service. The configuration file will be created for you on first run if one was not found.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[keys]
virustotal = "api_key"
shodan = "api_key"
censys_id = "api_id"
censys_secret = "api_key"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Hotkeys&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Key&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;h&lt;/td&gt; 
   &lt;td&gt;Home&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;/&lt;/td&gt; 
   &lt;td&gt;Input&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;q&lt;/td&gt; 
   &lt;td&gt;Back&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;c&lt;/td&gt; 
   &lt;td&gt;Censys&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;s&lt;/td&gt; 
   &lt;td&gt;Shodan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;v&lt;/td&gt; 
   &lt;td&gt;Virustotal&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚Üí&lt;/td&gt; 
   &lt;td&gt;Move Right&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚Üê&lt;/td&gt; 
   &lt;td&gt;Move Left&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚Üë&lt;/td&gt; 
   &lt;td&gt;Move Up&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚Üì&lt;/td&gt; 
   &lt;td&gt;Move Down&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;‚≠ê &lt;strong&gt;&lt;a href="https://github.com/Rigellute/spotify-tui"&gt;spotify-tui&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The software architecture is almost entirely modeled after spotify-tui. The codebase was invaluable in learning how to cleanly manage complex TUI state and implement generic handling of TUI components.&lt;/p&gt; 
&lt;p&gt;‚≠ê &lt;strong&gt;&lt;a href="https://github.com/pirxthepilot/wtfis"&gt;wtfis&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;I needed a good first project to learn rust and wtfis was the primary source of inspiration for osintui.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>garyttierney/me3</title>
      <link>https://github.com/garyttierney/me3</link>
      <description>&lt;p&gt;A framework for modding and instrumenting games.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/garyttierney/me3/main/distribution/assets/me3.png" alt="me3 icon"&gt; &lt;/p&gt; 
 &lt;h2 align="center"&gt;me&lt;sup&gt;3&lt;/sup&gt;&lt;/h2&gt; 
 &lt;p align="center"&gt; &lt;strong&gt; A framework for modifying and instrumenting games. &lt;br&gt; &lt;/strong&gt;&lt;/p&gt;
 &lt;p align="center"&gt;&lt;strong&gt; &lt;a href="https://me3.help/en"&gt;&lt;img src="https://img.shields.io/badge/Documentation-%F0%9F%87%AC%F0%9F%87%A7-darkgrey?style=for-the-badge" alt="English"&gt;&lt;/a&gt; &lt;a href="https://me3.help/zh"&gt;&lt;img src="https://img.shields.io/badge/%E6%96%87%E6%A1%A3-%F0%9F%87%A8%F0%9F%87%B3-darkgrey?style=for-the-badge" alt="ÊñáÊ°£"&gt;&lt;/a&gt; &lt;a href="https://me3.help/pl"&gt;&lt;img src="https://img.shields.io/badge/Dokumentacja-%F0%9F%87%B5%F0%9F%87%B1-darkgrey?style=for-the-badge" alt="Dokumentacja"&gt;&lt;/a&gt; &lt;/strong&gt;&lt;/p&gt;
 &lt;strong&gt; &lt;a href="https://github.com/garyttierney/me3/discussions/categories/bug-reports"&gt;Report Bug&lt;/a&gt; ¬∑ &lt;a href="https://github.com/garyttierney/me3/discussions/categories/ideas"&gt;Request Feature&lt;/a&gt; &lt;/strong&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/garyttierney/me3/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/garyttierney/me3" alt="Discussions"&gt;&lt;/a&gt; &lt;a href="https://github.com/garyttierney/me3/raw/main/LICENSE-APACHE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT%2FApache--2.0-green?style=flat" alt="MIT + Apache-2.0 License"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/garyttierney/me3/total" alt="GitHub Downloads (all assets, all releases)"&gt; &lt;img src="https://img.shields.io/github/commits-since/garyttierney/me3/latest" alt="GitHub commits since latest release"&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#about-the-project"&gt;About The Project&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#supported-platforms"&gt;Supported platforms&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#supported-games"&gt;Supported games&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#developer-quickstart"&gt;Developer Quickstart&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#usage"&gt;Usage&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#contact"&gt;Contact&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#acknowledgments"&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#sponsors"&gt;Sponsors&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#sentry"&gt;Sentry&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#crowdin"&gt;Crowdin&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- ABOUT THE PROJECT --&gt; 
&lt;h2&gt;About The Project&lt;/h2&gt; 
&lt;p&gt;me3 is a tool that extends the functionality of FROMSOFTWARE games.&lt;/p&gt; 
&lt;h3&gt;Supported platforms&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Windows&lt;/li&gt; 
 &lt;li&gt;Linux via Proton&lt;/li&gt; 
 &lt;li&gt;macOS via &lt;a href="https://www.codeweavers.com/crossover"&gt;CrossOver¬Æ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Supported games&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ELDEN RING&lt;/li&gt; 
 &lt;li&gt;ELDEN RING NIGHTREIGN&lt;/li&gt; 
 &lt;li&gt;Armored Core VI: Fires of Rubicon&lt;/li&gt; 
 &lt;li&gt;Sekiro: Shadows Die Twice&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Follow the &lt;a href="https://me3.readthedocs.io/en/latest/#quickstart"&gt;user guide&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- GETTING STARTED --&gt; 
&lt;h2&gt;Developer Quickstart&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Cargo&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Windows: download and run &lt;a href="https://static.rust-lang.org/dist/rust-1.87.0-x86_64-pc-windows-msvc.msi"&gt;rustup‚Äëinit.exe&lt;/a&gt; then follow the onscreen instructions.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Linux:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Visual Studio C++ Build Tools&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Windows: download and run &lt;a href="https://aka.ms/vs/17/release/vs_BuildTools.exe"&gt;vs_BuildTools.exe&lt;/a&gt; then follow the onscreen instructions.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Linux: Acquire the Windows SDK using &lt;code&gt;xwin&lt;/code&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cargo install xwin &amp;amp;&amp;amp; xwin --accept-license splat --output ~/.xwin
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;And configure Cargo to link with lld-link and use the binaries from xwin in &lt;code&gt;~/.cargo/config.toml&lt;/code&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-toml"&gt;[target.x86_64-pc-windows-msvc]
linker = "lld-link"
runner = "wine"
rustflags = [
  "-Lnative=/home/gtierney/.xwin/crt/lib/x86_64",
  "-Lnative=/home/gtierney/.xwin/sdk/lib/um/x86_64",
  "-Lnative=/home/gtierney/.xwin/sdk/lib/ucrt/x86_64"
]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Clone the repo&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/garyttierney/me3.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build the binaries&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;cargo build [--release]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Attach the sample host DLL to your game&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;cargo run -p me3-cli -- launch -g elden-ring
&lt;/code&gt;&lt;/pre&gt; &lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;!-- CONTRIBUTING --&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;!-- LICENSE --&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;With the exception of the &lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/distribution/assets/me3.ico"&gt;me3 logo&lt;/a&gt;, this project is distributed under the terms of both the Apache Software License 2.0 and MIT License. See &lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;The me3 logo is not available under any license - all rights are reserved.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- CONTACT --&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;Project Link: &lt;a href="https://github.com/garyttierney/me3"&gt;https://github.com/garyttierney/me3&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Discussions Board: &lt;a href="https://github.com/garyttierney/me3/discussions"&gt;https://github.com/garyttierney/me3/discussions&lt;/a&gt;&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- ACKNOWLEDGMENTS --&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;!-- markdown-link-check-disable --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/katalash/ModEngine/tree/master/DS3ModEngine"&gt;Mod Engine&lt;/a&gt; - prior art for runtime modification of FROMSOFTWARE games.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ModOrganizer2/modorganizer/"&gt;Mod Organizer 2&lt;/a&gt; - inspiration for the VFS framework.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nexusmods.com/eldenring/mods/541"&gt;Elden Ring Reforged&lt;/a&gt; - provided invaluable feedback on the end-user perspective&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dasaav-dsv"&gt;Dasaav&lt;/a&gt; - work on compatibility across a variety of FROMSOFTWARE titles.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/Skadi_sbw"&gt;Skadi&lt;/a&gt; - &lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/distribution/assets/me3.png"&gt;me3 icon&lt;/a&gt; artwork&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- markdown-link-check-enable --&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;We are grateful for the generous support of our sponsors.&lt;/p&gt; 
&lt;h3&gt;Sentry&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://sentry.io/" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/garyttierney/me3/main/assets/sponsors/sentry-wordmark-dark-200x60.png" alt="Sentry"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Crowdin&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://crowdin.com/" target="_blank"&gt;&lt;img src="https://support.crowdin.com/assets/logos/plate/png/crowdin-logo-with-plate.png" alt="Crowdin" width="200"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/garyttierney/me3/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>MystenLabs/sui</title>
      <link>https://github.com/MystenLabs/sui</link>
      <description>&lt;p&gt;Sui, a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the Move programming language&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/MystenLabs/sui/refs/heads/main/docs/site/static/img/logo.svg?sanitize=true" alt="Logo" width="100" height="100"&gt; &lt;/p&gt; 
&lt;h1&gt;Welcome to Sui&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/MystenLabs/sui/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/tag/MystenLabs/sui.svg?sort=semver" alt="Github release"&gt;&lt;/a&gt; &lt;a href="https://github.com/MystenLabs/sui/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/MystenLabs/sui" alt="License"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://sui.io"&gt;Sui&lt;/a&gt; is a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the &lt;a href="https://github.com/MystenLabs/awesome-move"&gt;Move programming language&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Sui Highlights&lt;/h2&gt; 
&lt;p&gt;Sui offers the following benefits and capabilities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Unmatched scalability, instant settlement&lt;/li&gt; 
 &lt;li&gt;A safe smart contract language accessible to mainstream developers&lt;/li&gt; 
 &lt;li&gt;Ability to define rich and composable on-chain assets&lt;/li&gt; 
 &lt;li&gt;Better user experience for web3 apps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sui is the only blockchain today that can scale with the growth of web3 while achieving industry-leading performance, cost, programmability, and usability. As Sui approaches Mainnet launch, it will demonstrate capacity beyond the transaction processing capabilities of established systems ‚Äì traditional and blockchain alike. Sui is the first internet-scale programmable blockchain platform, a foundational layer for web3.&lt;/p&gt; 
&lt;h2&gt;Sui Architecture&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart LR
    CC(CLI Client) --&amp;gt; ClientService
    RC(Rest Client) --&amp;gt; ClientService
    RPCC(RPC Client) --&amp;gt; ClientService
    ClientService --&amp;gt; AuthorityAggregator
    AuthorityAggregator --&amp;gt; AC1[AuthorityClient] &amp;amp; AC2[AuthorityClient]
    subgraph Authority1
      AS[AuthorityState]
    end
    subgraph Authority2
      AS2[AuthorityState]
    end
    AC1 &amp;lt;==&amp;gt;|Network TCP| Authority1
    AC2 &amp;lt;==&amp;gt;|Network TCP| Authority2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Sui Overview&lt;/h2&gt; 
&lt;p&gt;Sui is a smart contract platform maintained by a permissionless set of authorities that play a role similar to validators or miners in other blockchain systems.&lt;/p&gt; 
&lt;p&gt;Sui offers scalability and unprecedented low-latency for common use cases. Sui makes the vast majority of transactions processable in parallel, which makes better use of processing resources, and offers the option to increase throughput with more resources. Sui forgoes consensus to instead use simpler and lower-latency primitives for common use cases, such as payment transactions and asset transfers. This is unprecedented in the blockchain world and enables a number of new latency-sensitive distributed applications, ranging from gaming to retail payment at physical points of sale.&lt;/p&gt; 
&lt;p&gt;Sui is written in &lt;a href="https://www.rust-lang.org"&gt;Rust&lt;/a&gt; and supports smart contracts written in the &lt;a href="https://github.com/move-language/move"&gt;Move programming language&lt;/a&gt; to define assets that may have an owner. Move programs define operations on these assets including custom rules for their creation, the transfer of these assets to new owners, and operations that mutate assets.&lt;/p&gt; 
&lt;p&gt;Sui has a native token called SUI, with a fixed supply. The SUI token is used to pay for gas, and is also used as &lt;a href="https://learn.bybit.com/blockchain/delegated-proof-of-stake-dpos/"&gt;delegated stake on authorities&lt;/a&gt; within an epoch. The voting power of authorities within this epoch is a function of this delegated stake. Authorities are periodically reconfigured according to the stake delegated to them. In any epoch, the set of authorities is &lt;a href="https://pmg.csail.mit.edu/papers/osdi99.pdf"&gt;Byzantine fault tolerant&lt;/a&gt;. At the end of the epoch, fees collected through all transactions processed are distributed to authorities according to their contribution to the operation of the system. Authorities can in turn share some of the fees as rewards to users that delegated stakes to them.&lt;/p&gt; 
&lt;p&gt;Sui is supported by several cutting-edge &lt;a href="https://github.com/MystenLabs/sui/raw/main/docs/content/concepts/research-papers.mdx"&gt;peer-reviewed studies&lt;/a&gt; and extensive years of open-source development.&lt;/p&gt; 
&lt;h2&gt;More About Sui&lt;/h2&gt; 
&lt;p&gt;Use the following links to learn more about Sui and the Sui ecosystem:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Learn more about working with Sui in the &lt;a href="https://docs.sui.io/"&gt;Sui Documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join the Sui community on &lt;a href="https://discord.gg/sui"&gt;Sui Discord&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Find out more about the Sui ecosystem on the &lt;a href="https://sui.io/resources/"&gt;Sui Resources&lt;/a&gt; page.&lt;/li&gt; 
 &lt;li&gt;Review information about Sui governance, &lt;a href="https://suifoundation.org/decentralization"&gt;decentralization&lt;/a&gt;, and &lt;a href="https://sui.io/grants-hub"&gt;Developer Grants Program&lt;/a&gt; on the &lt;a href="https://sui.io/about"&gt;Sui Foundation&lt;/a&gt; site.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Contribute&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/MystenLabs/sui/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details on how to contribute to Sui.&lt;/p&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/MystenLabs/sui/main/CODE_OF_CONDUCT.MD"&gt;Code of Conduct&lt;/a&gt; for details on our code of conduct.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/MystenLabs/sui/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>astral-sh/uv</title>
      <link>https://github.com/astral-sh/uv</link>
      <description>&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;uv&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json" alt="uv"&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/v/uv.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/l/uv.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/uv.svg?sanitize=true" alt="image"&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv/actions"&gt;&lt;img src="https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Actions status"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/astral-sh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310"&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d"&gt; 
  &lt;img alt="Shows a bar chart with benchmark results." src="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d"&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Installing &lt;a href="https://trio.readthedocs.io/"&gt;Trio&lt;/a&gt;'s dependencies with a warm cache.&lt;/i&gt; &lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ A single tool to replace &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, &lt;code&gt;pipx&lt;/code&gt;, &lt;code&gt;poetry&lt;/code&gt;, &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;twine&lt;/code&gt;, &lt;code&gt;virtualenv&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;‚ö°Ô∏è &lt;a href="https://github.com/astral-sh/uv/raw/main/BENCHMARKS.md"&gt;10-100x faster&lt;/a&gt; than &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;üóÇÔ∏è Provides &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#projects"&gt;comprehensive project management&lt;/a&gt;, with a &lt;a href="https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile"&gt;universal lockfile&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;‚ùáÔ∏è &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#scripts"&gt;Runs scripts&lt;/a&gt;, with support for &lt;a href="https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies"&gt;inline dependency metadata&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üêç &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#python-versions"&gt;Installs and manages&lt;/a&gt; Python versions.&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#tools"&gt;Runs and installs&lt;/a&gt; tools published as Python packages.&lt;/li&gt; 
 &lt;li&gt;üî© Includes a &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#the-pip-interface"&gt;pip-compatible interface&lt;/a&gt; for a performance boost with a familiar CLI.&lt;/li&gt; 
 &lt;li&gt;üè¢ Supports Cargo-style &lt;a href="https://docs.astral.sh/uv/concepts/projects/workspaces"&gt;workspaces&lt;/a&gt; for scalable projects.&lt;/li&gt; 
 &lt;li&gt;üíæ Disk-space efficient, with a &lt;a href="https://docs.astral.sh/uv/concepts/cache"&gt;global cache&lt;/a&gt; for dependency deduplication.&lt;/li&gt; 
 &lt;li&gt;‚è¨ Installable without Rust or Python via &lt;code&gt;curl&lt;/code&gt; or &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è Supports macOS, Linux, and Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;uv is backed by &lt;a href="https://astral.sh"&gt;Astral&lt;/a&gt;, the creators of &lt;a href="https://github.com/astral-sh/ruff"&gt;Ruff&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install uv with our standalone installers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On Windows.
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, from &lt;a href="https://pypi.org/project/uv/"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# With pip.
pip install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Or pipx.
pipx install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If installed via the standalone installer, uv can update itself to the latest version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv self update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;installation documentation&lt;/a&gt; for details and alternative installation methods.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;uv's documentation is available at &lt;a href="https://docs.astral.sh/uv"&gt;docs.astral.sh/uv&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, the command line reference documentation can be viewed with &lt;code&gt;uv help&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Projects&lt;/h3&gt; 
&lt;p&gt;uv manages project dependencies and environments, with support for lockfiles, workspaces, and more, similar to &lt;code&gt;rye&lt;/code&gt; or &lt;code&gt;poetry&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/projects/"&gt;project documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;uv also supports building and publishing projects, even if they're not managed with uv. See the &lt;a href="https://docs.astral.sh/uv/guides/publish/"&gt;publish guide&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h3&gt;Scripts&lt;/h3&gt; 
&lt;p&gt;uv manages dependencies and environments for single-file scripts.&lt;/p&gt; 
&lt;p&gt;Create a new script and add inline metadata declaring its dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ echo 'import requests; print(requests.get("https://astral.sh"))' &amp;gt; example.py

$ uv add --script example.py requests
Updated `example.py`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, run the script in an isolated virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&amp;lt;Response [200]&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/scripts/"&gt;scripts documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;uv executes and installs command-line tools provided by Python packages, similar to &lt;code&gt;pipx&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Run a tool in an ephemeral environment using &lt;code&gt;uvx&lt;/code&gt; (an alias for &lt;code&gt;uv tool run&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uvx pycowsay 'hello world!'
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  """

  ------------
&amp;lt; hello world! &amp;gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install a tool with &lt;code&gt;uv tool install&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/tools/"&gt;tools documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Python versions&lt;/h3&gt; 
&lt;p&gt;uv installs Python and allows quickly switching between versions.&lt;/p&gt; 
&lt;p&gt;Install multiple Python versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download Python versions as needed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&amp;gt;&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use a specific Python version in the current directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python pin 3.11
Pinned `.python-version` to `3.11`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/install-python/"&gt;Python installation documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;The pip interface&lt;/h3&gt; 
&lt;p&gt;uv provides a drop-in replacement for common &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, and &lt;code&gt;virtualenv&lt;/code&gt; commands.&lt;/p&gt; 
&lt;p&gt;uv extends their interfaces with advanced features, such as dependency version overrides, platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and more.&lt;/p&gt; 
&lt;p&gt;Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the &lt;code&gt;uv pip&lt;/code&gt; interface.&lt;/p&gt; 
&lt;p&gt;Compile requirements into a platform-independent requirements file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the locked requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/pip/index/"&gt;pip interface documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/platforms/"&gt;platform support&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Versioning policy&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/versioning/"&gt;versioning policy&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We are passionate about supporting contributors of all levels of experience and would love to see you get involved in the project. See the &lt;a href="https://github.com/astral-sh/uv/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h4&gt;How do you pronounce uv?&lt;/h4&gt; 
&lt;p&gt;It's pronounced as "you - vee" (&lt;a href="https://en.wikipedia.org/wiki/Help:IPA/English#Key"&gt;&lt;code&gt;/juÀê viÀê/&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; 
&lt;h4&gt;How should I stylize uv?&lt;/h4&gt; 
&lt;p&gt;Just "uv", please. See the &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/STYLE.md#styling-uv"&gt;style guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;uv's dependency resolver uses &lt;a href="https://github.com/pubgrub-rs/pubgrub"&gt;PubGrub&lt;/a&gt; under the hood. We're grateful to the PubGrub maintainers, especially &lt;a href="https://github.com/Eh2406"&gt;Jacob Finkelman&lt;/a&gt;, for their support.&lt;/p&gt; 
&lt;p&gt;uv's Git implementation is based on &lt;a href="https://github.com/rust-lang/cargo"&gt;Cargo&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some of uv's optimizations are inspired by the great work we've seen in &lt;a href="https://pnpm.io/"&gt;pnpm&lt;/a&gt;, &lt;a href="https://github.com/orogene/orogene"&gt;Orogene&lt;/a&gt;, and &lt;a href="https://github.com/oven-sh/bun"&gt;Bun&lt;/a&gt;. We've also learned a lot from Nathaniel J. Smith's &lt;a href="https://github.com/njsmith/posy"&gt;Posy&lt;/a&gt; and adapted its &lt;a href="https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline"&gt;trampoline&lt;/a&gt; for Windows support.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;uv is licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0, (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="https://opensource.org/licenses/MIT"&gt;https://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://astral.sh" style="background:none"&gt; &lt;img src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg?sanitize=true" alt="Made by Astral"&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>ast-grep/ast-grep</title>
      <link>https://github.com/ast-grep/ast-grep</link>
      <description>&lt;p&gt;‚ö°A CLI tool for code structural search, lint and rewriting. Written in Rust&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://ast-grep.github.io/logo.svg?sanitize=true" alt="ast-grep"&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/ast-grep/ast-grep/actions/workflows/coverage.yaml/badge.svg?sanitize=true" alt="coverage badge"&gt; &lt;a href="https://app.codecov.io/gh/ast-grep/ast-grep"&gt;&lt;img src="https://codecov.io/gh/ast-grep/ast-grep/branch/main/graph/badge.svg?token=37VX8H2EWV"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/4YZjf6htSQ" target="_blank"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1107749847722889217?label=Discord"&gt;&lt;/a&gt; &lt;a href="https://repology.org/project/ast-grep/versions" target="_blank"&gt;&lt;img alt="Repology" src="https://repology.org/badge/tiny-repos/ast-grep.svg?sanitize=true"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/stars/ast-grep/ast-grep?style=social" alt="Badge"&gt; &lt;img src="https://img.shields.io/github/forks/ast-grep/ast-grep?style=social" alt="Badge"&gt; &lt;img alt="GitHub Sponsors" src="https://img.shields.io/github/sponsors/HerringtonDarkholme?style=social"&gt; &lt;a href="https://gurubase.io/g/ast-grep"&gt;&lt;img alt="Gurubase" src="https://img.shields.io/badge/Gurubase-Ask%20ast--grep%20Guru-006BFF"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;ast-grep(sg)&lt;/h2&gt; 
&lt;p&gt;ast-grep(sg) is a CLI tool for code structural search, lint, and rewriting.&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;ast-grep is an &lt;a href="https://dev.to/balapriya/abstract-syntax-tree-ast-explained-in-plain-english-1h38"&gt;abstract syntax tree&lt;/a&gt; based tool to search code by pattern code. Think of it as your old-friend &lt;a href="https://en.wikipedia.org/wiki/Grep#:~:text=grep%20is%20a%20command%2Dline,which%20has%20the%20same%20effect."&gt;&lt;code&gt;grep&lt;/code&gt;&lt;/a&gt;, but matching AST nodes instead of text. You can write patterns as if you are writing ordinary code. It will match all code that has the same syntactical structure. You can use &lt;code&gt;$&lt;/code&gt; sign + upper case letters as a &lt;a href="https://en.wikipedia.org/wiki/Wildcard_character"&gt;wildcard&lt;/a&gt;, e.g. &lt;code&gt;$MATCH&lt;/code&gt;, to match any single AST node. Think of it as &lt;a href="https://regexone.com/lesson/wildcards_dot"&gt;regular expression dot&lt;/a&gt; &lt;code&gt;.&lt;/code&gt;, except it is not textual.&lt;/p&gt; 
&lt;p&gt;Try the &lt;a href="https://ast-grep.github.io/playground.html"&gt;online playground&lt;/a&gt; for a taste!&lt;/p&gt; 
&lt;h2&gt;Screenshot&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://ast-grep.github.io/image/search-replace.png" alt="demo"&gt;&lt;/p&gt; 
&lt;p&gt;See more screenshots on the &lt;a href="https://ast-grep.github.io/"&gt;website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;You can install it from &lt;a href="https://docs.npmjs.com/downloading-and-installing-node-js-and-npm"&gt;npm&lt;/a&gt;, &lt;a href="https://pypi.org/"&gt;pip&lt;/a&gt;, &lt;a href="https://doc.rust-lang.org/cargo/getting-started/installation.html"&gt;cargo&lt;/a&gt;, &lt;a href="https://github.com/cargo-bins/cargo-binstall"&gt;cargo-binstall&lt;/a&gt;, &lt;a href="https://brew.sh/"&gt;homebrew&lt;/a&gt;, &lt;a href="https://scoop.sh/"&gt;scoop&lt;/a&gt; or &lt;a href="https://www.macports.org"&gt;MacPorts&lt;/a&gt;!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install --global @ast-grep/cli
pip install ast-grep-cli
brew install ast-grep
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click for more installation methods&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cargo install ast-grep --locked
cargo binstall ast-grep

# install via scoop, thank @brian6932
scoop install main/ast-grep

# install via MacPorts
sudo port install ast-grep

# try ast-grep in nix-shell
nix-shell -p ast-grep
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;Or you can build ast-grep from source. You need to install rustup, clone the repository and then&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install --path ./crates/cli --locked
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/ast-grep/versions"&gt;Packages&lt;/a&gt; are available on other platforms too.&lt;/p&gt; 
&lt;h2&gt;Command line usage example&lt;/h2&gt; 
&lt;p&gt;ast-grep has following form.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sg --pattern 'var code = $PATTERN' --rewrite 'let code = new $PATTERN' --lang ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/Hchan_mgn/status/1547061516993699841?s=20&amp;amp;t=ldDoj4U2nq-FRKQkU5GWXA"&gt;Rewrite code in null coalescing operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sg -p '$A &amp;amp;&amp;amp; $A()' -l ts -r '$A?.()'
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/Hchan_mgn/status/1561802312846278657"&gt;Rewrite&lt;/a&gt; &lt;a href="https://github.com/ecyrbe/zodios#migrate-to-v8"&gt;Zodios&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sg -p 'new Zodios($URL,  $CONF as const,)' -l ts -r 'new Zodios($URL, $CONF)' -i
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/Hchan_mgn/status/1560108625460355073"&gt;Implement eslint rule using YAML.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsor&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HerringtonDarkholme/sponsors/main/sponsorkit/sponsors.svg?sanitize=true" alt="Sponsors"&gt;&lt;/p&gt; 
&lt;p&gt;If you find ast-grep interesting and useful for your work, please &lt;a href="https://github.com/sponsors/HerringtonDarkholme"&gt;buy me a coffee&lt;/a&gt; so I can spend more time on the project!&lt;/p&gt; 
&lt;h2&gt;Feature Highlight&lt;/h2&gt; 
&lt;p&gt;ast-grep's core is an algorithm to search and replace code based on abstract syntax tree produced by tree-sitter. It can help you to do lightweight static analysis and massive scale code manipulation in an intuitive way.&lt;/p&gt; 
&lt;p&gt;Key highlights:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;An intuitive pattern to find and replace AST. ast-grep's pattern looks like ordinary code you would write every day (you could say the pattern is isomorphic to code).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;jQuery like API for AST traversal and manipulation.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;YAML configuration to write new linting rules or code modification.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Written in compiled language, with tree-sitter based parsing and utilizing multiple cores.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Beautiful command line interface :)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ast-grep's vision is to democratize abstract syntax tree magic and to liberate one from cumbersome AST programming!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you are an open-source library author, ast-grep can help your library users adopt breaking changes more easily.&lt;/li&gt; 
 &lt;li&gt;if you are a tech lead in your team, ast-grep can help you enforce code best practice tailored to your business need.&lt;/li&gt; 
 &lt;li&gt;If you are a security researcher, ast-grep can help you write rules much faster.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>cachix/devenv</title>
      <link>https://github.com/cachix/devenv</link>
      <description>&lt;p&gt;Fast, Declarative, Reproducible, and Composable Developer Environments using Nix&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://devenv.sh"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="logos/devenv-horizontal-light-bg.svg"&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="logos/devenv-horizontal-dark-bg.svg"&gt; 
   &lt;img src="https://raw.githubusercontent.com/cachix/devenv/main/logos/devenv-horizontal-light-bg.svg?sanitize=true" width="500px" alt="devenv logo"&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;&lt;a href="https://devenv.sh"&gt;devenv.sh&lt;/a&gt; - Fast, Declarative, Reproducible, and Composable Developer Environments&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://builtwithnix.org"&gt;&lt;img src="https://img.shields.io/static/v1?logo=nixos&amp;amp;logoColor=white&amp;amp;label=&amp;amp;message=Built%20with%20Nix&amp;amp;color=41439a" alt="Built with Nix"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/naMgvexb6q"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2FnaMgvexb6q%3Fwith_counts%3Dtrue&amp;amp;query=%24.approximate_member_count&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;label=Discord%20users&amp;amp;color=green&amp;amp;style=flat" alt="Discord channel"&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/license/cachix/devenv" alt="License: Apache 2.0"&gt; &lt;a href="https://github.com/cachix/devenv/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/cachix/devenv?color=green&amp;amp;label=version&amp;amp;sort=semver" alt="Version"&gt;&lt;/a&gt; &lt;a href="https://github.com/cachix/devenv/actions/workflows/buildtest.yml?branch=main"&gt;&lt;img src="https://github.com/cachix/devenv/actions/workflows/buildtest.yml/badge.svg?sanitize=true" alt="CI"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Running &lt;code&gt;devenv init&lt;/code&gt; generates &lt;code&gt;devenv.nix&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-nix"&gt;{ pkgs, ... }:

{
  # https://devenv.sh/basics/
  env.GREET = "devenv";

  # https://devenv.sh/packages/
  packages = [ pkgs.git ];

  enterShell = ''
    hello
  '';

  # https://devenv.sh/tests/
  enterTest = ''
    echo "Running tests"
    git --version | grep --color=auto "${pkgs.git.version}"
  '';

  # https://devenv.sh/languages/
  languages.nix.enable = true;

  # https://devenv.sh/scripts/
  scripts.hello.exec = "echo hello from $GREET";

  # https://devenv.sh/services/
  services.postgres.enable = true;

  # https://devenv.sh/git-hooks/
  git-hooks.hooks.shellcheck.enable = true;

  # https://devenv.sh/processes/
  processes.ping.exec = "ping localhost";
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And &lt;code&gt;devenv shell&lt;/code&gt; activates the environment.&lt;/p&gt; 
&lt;h2&gt;Commands&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;$ devenv
https://devenv.sh 1.6.0: Fast, Declarative, Reproducible, and Composable Developer Environments

Usage: devenv [OPTIONS] [COMMAND]

Commands:
  init       Scaffold devenv.yaml, devenv.nix, .gitignore and .envrc.
  generate   Generate devenv.yaml and devenv.nix using AI
  shell      Activate the developer environment. https://devenv.sh/basics/
  update     Update devenv.lock from devenv.yaml inputs. http://devenv.sh/inputs/
  search     Search for packages and options in nixpkgs. https://devenv.sh/packages/#searching-for-a-file
  info       Print information about this developer environment.
  up         Start processes in the foreground. https://devenv.sh/processes/
  processes  Start or stop processes. https://devenv.sh/processes/
  tasks      Run tasks. https://devenv.sh/tasks/
  test       Run tests. http://devenv.sh/tests/
  container  Build, copy, or run a container. https://devenv.sh/containers/
  inputs     Add an input to devenv.yaml. https://devenv.sh/inputs/
  repl       Launch an interactive environment for inspecting the devenv configuration.
  gc         Delete previous shell generations. See https://devenv.sh/garbage-collection
  build      Build any attribute in devenv.nix.
  direnvrc   Print a direnvrc that adds devenv support to direnv. See https://devenv.sh/automatic-shell-activation.
  version    Print the version of devenv.
  help       Print this message or the help of the given subcommand(s)

Options:
  -V, --version
          Print version information and exit

  -v, --verbose
          Enable additional debug logs.

  -q, --quiet
          Silence all logs

      --log-format &amp;lt;LOG_FORMAT&amp;gt;
          Configure the output format of the logs.

          [default: cli]

          Possible values:
          - cli:            The default human-readable log format used in the CLI
          - tracing-full:   A verbose structured log format used for debugging
          - tracing-pretty: A pretty human-readable log format used for debugging

  -j, --max-jobs &amp;lt;MAX_JOBS&amp;gt;
          Maximum number of Nix builds at any time.

          [default: 8]

  -u, --cores &amp;lt;CORES&amp;gt;
          Maximum number CPU cores being used by a single build.

          [default: 2]

  -s, --system &amp;lt;SYSTEM&amp;gt;
          [default: x86_64-linux]

  -i, --impure
          Relax the hermeticity of the environment.

      --no-eval-cache
          Disable caching of Nix evaluation results.

      --refresh-eval-cache
          Force a refresh of the Nix evaluation cache.

      --offline
          Disable substituters and consider all previously downloaded files up-to-date.

  -c, --clean [&amp;lt;CLEAN&amp;gt;...]
          Ignore existing environment variables when entering the shell. Pass a list of comma-separated environment variables to let through.

      --nix-debugger
          Enter the Nix debugger on failure.

  -n, --nix-option &amp;lt;NAME&amp;gt; &amp;lt;VALUE&amp;gt;
          Pass additional options to nix commands.

          These options are passed directly to Nix using the --option flag.
          See `man nix.conf` for the full list of available options.

          Examples:
            --nix-option sandbox false
            --nix-option keep-outputs true
            --nix-option system x86_64-darwin

  -o, --override-input &amp;lt;NAME&amp;gt; &amp;lt;URI&amp;gt;
          Override inputs in devenv.yaml.

          Examples:
            --override-input nixpkgs github:NixOS/nixpkgs/nixos-unstable
            --override-input nixpkgs path:/path/to/local/nixpkgs

  -O, --option &amp;lt;OPTION&amp;gt; &amp;lt;VALUE&amp;gt;
          Override configuration options with typed values.

          OPTION must include a type: &amp;lt;attribute&amp;gt;:&amp;lt;type&amp;gt;
          Supported types: string, int, float, bool, path

          Examples:
            --option languages.rust.channel:string beta
            --option services.postgres.enable:bool true
            --option languages.python.version:string 3.10

  -h, --help
          Print help (see a summary with '-h')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://devenv.sh/getting-started/"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://devenv.sh/basics/"&gt;Basics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://devenv.sh/roadmap/"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://devenv.sh/blog/"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://devenv.sh/reference/yaml-options/"&gt;&lt;code&gt;devenv.yaml&lt;/code&gt; reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://devenv.sh/reference/options/"&gt;&lt;code&gt;devenv.nix&lt;/code&gt; reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://devenv.sh/community/contributing/"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>blockworks-foundation/autobahn</title>
      <link>https://github.com/blockworks-foundation/autobahn</link>
      <description>&lt;p&gt;Dex aggregator on Solana&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Fill.city Autobahn&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/blockworks-foundation/autobahn/main/brand/autobahn-logo-mark.svg?sanitize=true" alt="logo"&gt;&lt;/p&gt; 
&lt;p&gt;Autobahn is the open source aggregator for swaps on Solana. This public good protocol enables developers to contribute their own DEX adapters. Take back control: access to orderflow from routers on Solana should not be centralized.&lt;/p&gt; 
&lt;p&gt;The graph search is optimized for reliability of trade execution. Reliability is preferred over marginal price to improve user experience. Full test coverage through daily verification of all routed pools ensures correctness.&lt;/p&gt; 
&lt;p&gt;A hosted version is available. Reach out to &lt;a href="mailto:partnerships@mango.markets"&gt;partnerships@mango.markets&lt;/a&gt; to get an access token. Self-hosting requires custom validator patches to enable low-latency account subscriptions.&lt;/p&gt; 
&lt;h2&gt;Using the router (as a client)&lt;/h2&gt; 
&lt;p&gt;Basically it is the same API as Jupiter: &lt;code&gt;https://autobahn.mngo.cloud/&amp;lt;TOKEN&amp;gt;/&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;quote (GET)&lt;/h3&gt; 
&lt;p&gt;Supported parameters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;inputMint&lt;/li&gt; 
 &lt;li&gt;outputMint&lt;/li&gt; 
 &lt;li&gt;amount&lt;/li&gt; 
 &lt;li&gt;slippageBps&lt;/li&gt; 
 &lt;li&gt;maxAccounts&lt;/li&gt; 
 &lt;li&gt;onlyDirectRoutes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;swap &amp;amp; swap-instructions (POST)&lt;/h3&gt; 
&lt;p&gt;Supported parameters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;userPublicKey&lt;/li&gt; 
 &lt;li&gt;wrapAndUnwrapSol&lt;/li&gt; 
 &lt;li&gt;autoCreateOutAta&lt;/li&gt; 
 &lt;li&gt;quoteResponse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Running the router&lt;/h2&gt; 
&lt;p&gt;See example configuration file &lt;a href="https://raw.githubusercontent.com/blockworks-foundation/autobahn/main/bin/autobahn-router/example-config.toml"&gt;example-config.toml&lt;/a&gt; to create your own setup&lt;/p&gt; 
&lt;p&gt;Run like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;RUST_LOG=info router my_config.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Creating a new DEX Adapter&lt;/h2&gt; 
&lt;p&gt;Adding new DEX adapter is welcome, you can do a pull-request, it will be appreciated !&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/blockworks-foundation/autobahn/main/CreatingAnAdapter.MD"&gt;CreatingAnAdapter.MD&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Integration testing&lt;/h2&gt; 
&lt;p&gt;It's possible to dump data from mainnet, and then use that in tests:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;To assert quoting is correct (same result as simulated swap)&lt;/li&gt; 
 &lt;li&gt;To check router path finding perfomance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/blockworks-foundation/autobahn/main/Testing.MD"&gt;Testing.MD&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p&gt;There's a script for daily smoke tests:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;RPC_HTTP_URL=... ./scripts/smoke-test.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Tokio-Console&lt;/h2&gt; 
&lt;p&gt;Build router with feature &lt;code&gt;tokio-console&lt;/code&gt; and &lt;code&gt;RUSTFLAGS="--cfg tokio_unstable"&lt;/code&gt; like this:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;RUSTFLAGS="--cfg tokio_unstable" cargo build --bin router --release --features tokio-console&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;And use the &lt;code&gt;tokio-console&lt;/code&gt; crate to display running tasks&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Autobahn is published under GNU Affero General Public License v3.0. In case you are interested in an alternative license please reach out to &lt;a href="mailto:partnerships@mango.markets"&gt;partnerships@mango.markets&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>huggingface/tokenizers</title>
      <link>https://github.com/huggingface/tokenizers</link>
      <description>&lt;p&gt;üí• Fast State-of-the-Art Tokenizers optimized for Research and Production&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;br&gt; &lt;img src="https://huggingface.co/landing/assets/tokenizers/tokenizers-logo.png" width="600"&gt; &lt;br&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;img alt="Build" src="https://github.com/huggingface/tokenizers/workflows/Rust/badge.svg?sanitize=true"&gt; &lt;a href="https://github.com/huggingface/tokenizers/raw/main/LICENSE"&gt; &lt;img alt="GitHub" src="https://img.shields.io/github/license/huggingface/tokenizers.svg?color=blue&amp;amp;cachedrop"&gt; &lt;/a&gt; &lt;a href="https://pepy.tech/project/tokenizers"&gt; &lt;img src="https://pepy.tech/badge/tokenizers/week"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Provides an implementation of today's most used tokenizers, with a focus on performance and versatility.&lt;/p&gt; 
&lt;h2&gt;Main features:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Train new vocabularies and tokenize, using today's most used tokenizers.&lt;/li&gt; 
 &lt;li&gt;Extremely fast (both training and tokenization), thanks to the Rust implementation. Takes less than 20 seconds to tokenize a GB of text on a server's CPU.&lt;/li&gt; 
 &lt;li&gt;Easy to use, but also extremely versatile.&lt;/li&gt; 
 &lt;li&gt;Designed for research and production.&lt;/li&gt; 
 &lt;li&gt;Normalization comes with alignments tracking. It's always possible to get the part of the original sentence that corresponds to a given token.&lt;/li&gt; 
 &lt;li&gt;Does all the pre-processing: Truncate, Pad, add the special tokens your model needs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performances&lt;/h2&gt; 
&lt;p&gt;Performances can vary depending on hardware, but running the &lt;a href="https://raw.githubusercontent.com/huggingface/tokenizers/main/bindings/python/benches/test_tiktoken.py"&gt;~/bindings/python/benches/test_tiktoken.py&lt;/a&gt; should give the following on a g6 aws instance: &lt;img src="https://github.com/user-attachments/assets/2b913d4b-e488-4cbc-b542-f90a6c40643d" alt="image"&gt;&lt;/p&gt; 
&lt;h2&gt;Bindings&lt;/h2&gt; 
&lt;p&gt;We provide bindings to the following languages (more to come!):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/tokenizers/tree/main/tokenizers"&gt;Rust&lt;/a&gt; (Original implementation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/tokenizers/tree/main/bindings/python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/tokenizers/tree/main/bindings/node"&gt;Node.js&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ankane/tokenizers-ruby"&gt;Ruby&lt;/a&gt; (Contributed by @ankane, external repo)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;You can install from source using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/huggingface/tokenizers.git#subdirectory=bindings/python
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;our install the released versions with&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install tokenizers
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick example using Python:&lt;/h2&gt; 
&lt;p&gt;Choose your model between Byte-Pair Encoding, WordPiece or Unigram and instantiate a tokenizer:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tokenizers import Tokenizer
from tokenizers.models import BPE

tokenizer = Tokenizer(BPE())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can customize how pre-tokenization (e.g., splitting into words) is done:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tokenizers.pre_tokenizers import Whitespace

tokenizer.pre_tokenizer = Whitespace()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then training your tokenizer on a set of files just takes two lines of codes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tokenizers.trainers import BpeTrainer

trainer = BpeTrainer(special_tokens=["[UNK]", "[CLS]", "[SEP]", "[PAD]", "[MASK]"])
tokenizer.train(files=["wiki.train.raw", "wiki.valid.raw", "wiki.test.raw"], trainer=trainer)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once your tokenizer is trained, encode any text with just one line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;output = tokenizer.encode("Hello, y'all! How are you üòÅ ?")
print(output.tokens)
# ["Hello", ",", "y", "'", "all", "!", "How", "are", "you", "[UNK]", "?"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check the &lt;a href="https://huggingface.co/docs/tokenizers/index"&gt;documentation&lt;/a&gt; or the &lt;a href="https://huggingface.co/docs/tokenizers/quicktour"&gt;quicktour&lt;/a&gt; to learn more!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ai-dynamo/dynamo</title>
      <link>https://github.com/ai-dynamo/dynamo</link>
      <description>&lt;p&gt;A Datacenter Scale Distributed Inference Serving Framework&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-banner.png" alt="Dynamo banner"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License"&gt;&lt;/a&gt; &lt;a href="https://github.com/ai-dynamo/dynamo/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/ai-dynamo/dynamo" alt="GitHub Release"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/D92uqZRjCZ"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/ai-dynamo/dynamo"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/issues/762"&gt;Roadmap&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://docs.nvidia.com/dynamo/latest/index.html"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/examples"&gt;Examples&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/enhancements"&gt;Design Proposals&lt;/a&gt;&lt;/strong&gt; |&lt;/p&gt; 
&lt;h3&gt;The Era of Multi-Node, Multi-GPU&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-gpu-evolution.png" alt="GPU Evolution"&gt;&lt;/p&gt; 
&lt;p&gt;Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs‚Äîand sometimes many servers‚Äîbut it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-gpu-vertical.png" alt="Multi Node Multi-GPU topology"&gt;&lt;/p&gt; 
&lt;h3&gt;Introducing NVIDIA Dynamo&lt;/h3&gt; 
&lt;p&gt;NVIDIA Dynamo is a high-throughput low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments. Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-architecture.png" alt="Dynamo architecture"&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Disaggregated prefill &amp;amp; decode inference&lt;/strong&gt; ‚Äì Maximizes GPU throughput and facilitates trade off between throughput and latency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic GPU scheduling&lt;/strong&gt; ‚Äì Optimizes performance based on fluctuating demand&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-aware request routing&lt;/strong&gt; ‚Äì Eliminates unnecessary KV cache re-computation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accelerated data transfer&lt;/strong&gt; ‚Äì Reduces inference response time using NIXL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;KV cache offloading&lt;/strong&gt; ‚Äì Leverages multiple memory hierarchies for higher system throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;The following examples require a few system level packages. Recommended to use Ubuntu 24.04 with a x86_64 CPU. See &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/support_matrix.md"&gt;docs/support_matrix.md&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install etcd and nats&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To co-ordinate across the data center Dynamo relies on an etcd and nats cluster. To run locally these need to be available.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://etcd.io/"&gt;etcd&lt;/a&gt; can be run directly as &lt;code&gt;./etcd&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nats.io/"&gt;nats&lt;/a&gt; needs jetstream enabled: &lt;code&gt;nats-server -js&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The Dynamo team recommend the &lt;code&gt;uv&lt;/code&gt; Python package manager, although anyway works. Install uv:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Select an engine&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;We publish Python wheels specialized for each of our supported engines: vllm, sglang, llama.cpp and trtllm. The examples that follow use sglang, read on for other engines.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install "ai-dynamo[sglang]"
uv pip install "ai-dynamo[vllm]"
uv pip install "ai-dynamo[llama_cpp]" # CPU, see later for GPU
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running and Interacting with an LLM Locally&lt;/h3&gt; 
&lt;p&gt;You can run a model and interact with it locally using commands below.&lt;/p&gt; 
&lt;h4&gt;Example Commands&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.frontend --interactive
python -m dynamo.sglang.worker Qwen/Qwen3-4B
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;‚úî User ¬∑ Hello, how are you?
Okay, so I'm trying to figure out how to respond to the user's greeting. They said, "Hello, how are you?" and then followed it with "Hello! I'm just a program, but thanks for asking." Hmm, I need to come up with a suitable reply. ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the model is not available locally it will be downloaded from HuggingFace and cached.&lt;/p&gt; 
&lt;p&gt;You can also pass a local path: &lt;code&gt;python -m dynamo.sglang.worker --model-path ~/llms/Qwen3-0.6B&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Running an LLM API server&lt;/h3&gt; 
&lt;p&gt;Dynamo provides a simple way to spin up a local set of inference components including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI Compatible Frontend&lt;/strong&gt; ‚Äì High performance OpenAI compatible http api server written in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic and Kv Aware Router&lt;/strong&gt; ‚Äì Route and load balance traffic to a set of workers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workers&lt;/strong&gt; ‚Äì Set of pre-configured LLM serving engines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router:
python -m dynamo.frontend [--http-port 8080]

# Start the vllm engine, connecting to nats and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
python -m dynamo.sglang.worker deepseek-ai/DeepSeek-R1-Distill-Llama-8B
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Send a Request&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl localhost:8000/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "messages": [
    {
        "role": "user",
        "content": "Hello, how are you?"
    }
    ],
    "stream":false,
    "max_tokens": 300
  }' | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Rerun with &lt;code&gt;curl -N&lt;/code&gt; and change &lt;code&gt;stream&lt;/code&gt; in the request to &lt;code&gt;true&lt;/code&gt; to get the responses as soon as the engine issues them.&lt;/p&gt; 
&lt;h3&gt;Engines&lt;/h3&gt; 
&lt;p&gt;In the introduction we installed the &lt;code&gt;sglang&lt;/code&gt; engine. There are other options.&lt;/p&gt; 
&lt;p&gt;All of these requires nats and etcd, as well as a frontend (&lt;code&gt;python -m dynamo.frontend [--interactive]&lt;/code&gt;).&lt;/p&gt; 
&lt;h1&gt;vllm&lt;/h1&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[vllm]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.vllm --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;vllm attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass &lt;code&gt;--context-length &amp;lt;value&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To specify which GPUs to use set environment variable &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;sglang&lt;/h1&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[sglang]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.sglang.worker --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can pass any sglang flags directly to this worker, see &lt;a href="https://docs.sglang.ai/backend/server_arguments.html"&gt;https://docs.sglang.ai/backend/server_arguments.html&lt;/a&gt; . See there to use multiple GPUs.&lt;/p&gt; 
&lt;h1&gt;TRT-LLM&lt;/h1&gt; 
&lt;p&gt;This currently requires a container TODO ADD THE DOCS PLZ THANK YOU&lt;/p&gt; 
&lt;h1&gt;llama.cpp&lt;/h1&gt; 
&lt;p&gt;To install llama.cpp for CPU inference:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[llama_cpp]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build llama.cpp for CUDA:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install llama-cpp-python -C cmake.args="-DGGML_CUDA=on"
uv pip install uvloop ai-dynamo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;At time of writing the &lt;code&gt;uv pip&lt;/code&gt; version does not support that syntax, so use &lt;code&gt;pip&lt;/code&gt; directly inside the venv.&lt;/p&gt; 
&lt;p&gt;To build llama.cpp for other accelerators see &lt;a href="https://pypi.org/project/llama-cpp-python/"&gt;https://pypi.org/project/llama-cpp-python/&lt;/a&gt; .&lt;/p&gt; 
&lt;p&gt;Download a GGUF and run the engine like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.llama_cpp --model-path ~/llms/Qwen3-0.6B-Q8_0.gguf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you have multiple GPUs, llama.cpp does automatic tensor parallelism. You do not need to pass any extra flags to dynamo-run to enable it.&lt;/p&gt; 
&lt;h3&gt;Local Development&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install libraries&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Ubuntu:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# if brew is not installed on your system, install it
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If Metal is accessible, you should see an error like &lt;code&gt;metal: error: no input files&lt;/code&gt;, which confirms it is installed correctly.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install Rust&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Create a Python virtual env:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;uv venv dynamo
source dynamo/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Install build tools&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install pip maturin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/PyO3/maturin"&gt;Maturin&lt;/a&gt; is the Rust&amp;lt;-&amp;gt;Python bindings build tool.&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Build the Rust bindings&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;cd lib/bindings/python
maturin develop --uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt;Install the wheel&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;cd $PROJECT_ROOT
uv pip install .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note editable (&lt;code&gt;-e&lt;/code&gt;) does not work because the &lt;code&gt;dynamo&lt;/code&gt; package is split over multiple directories, one per backend.&lt;/p&gt; 
&lt;p&gt;You should now be able to run &lt;code&gt;python -m dynamo.frontend&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Remember that nats and etcd must be running (see earlier).&lt;/p&gt; 
&lt;p&gt;Set the environment variable &lt;code&gt;DYN_LOG&lt;/code&gt; to adjust the logging level; for example, &lt;code&gt;export DYN_LOG=debug&lt;/code&gt;. It has the same syntax as &lt;code&gt;RUST_LOG&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you use vscode or cursor, we have a .devcontainer folder built on &lt;a href="https://code.visualstudio.com/docs/devcontainers/containers"&gt;Microsofts Extension&lt;/a&gt;. For instructions see the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/.devcontainer/README.md"&gt;ReadMe&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Deployment to Kubernetes&lt;/h3&gt; 
&lt;p&gt;Follow the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/guides/dynamo_deploy/quickstart.md"&gt;Quickstart Guide&lt;/a&gt; to deploy to Kubernetes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>topgrade-rs/topgrade</title>
      <link>https://github.com/topgrade-rs/topgrade</link>
      <description>&lt;p&gt;Upgrade all the things&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt; &lt;img alt="Topgrade" src="https://raw.githubusercontent.com/topgrade-rs/topgrade/main/doc/topgrade_transparent.png" width="850px"&gt; &lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/topgrade-rs/topgrade/releases"&gt;&lt;img alt="GitHub Release" src="https://img.shields.io/github/release/topgrade-rs/topgrade.svg?sanitize=true"&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/topgrade"&gt;&lt;img alt="crates.io" src="https://img.shields.io/crates/v/topgrade.svg?sanitize=true"&gt;&lt;/a&gt; &lt;a href="https://aur.archlinux.org/packages/topgrade"&gt;&lt;img alt="AUR" src="https://img.shields.io/aur/version/topgrade.svg?sanitize=true"&gt;&lt;/a&gt; &lt;a href="https://formulae.brew.sh/formula/topgrade"&gt;&lt;img alt="Homebrew" src="https://img.shields.io/homebrew/v/topgrade.svg?sanitize=true"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;img alt="Demo" src="https://raw.githubusercontent.com/topgrade-rs/topgrade/main/doc/topgrade_demo.gif"&gt; 
&lt;/div&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; This is a fork of &lt;a href="https://github.com/r-darwish/topgrade"&gt;topgrade by r-darwish&lt;/a&gt; to keep it maintained.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Keeping your system up to date usually involves invoking multiple package managers. This results in big, non-portable shell one-liners saved in your shell. To remedy this, &lt;strong&gt;Topgrade&lt;/strong&gt; detects which tools you use and runs the appropriate commands to update them.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/topgrade/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/topgrade.svg?sanitize=true" alt="Packaging status"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Arch Linux: &lt;a href="https://aur.archlinux.org/packages/topgrade"&gt;AUR&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;NixOS: &lt;a href="https://search.nixos.org/packages?show=topgrade"&gt;Nixpkgs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Void Linux: &lt;a href="https://voidlinux.org/packages/?arch=x86_64&amp;amp;q=topgrade"&gt;XBPS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;macOS: &lt;a href="https://formulae.brew.sh/formula/topgrade"&gt;Homebrew&lt;/a&gt; or &lt;a href="https://ports.macports.org/port/topgrade/"&gt;MacPorts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Windows: &lt;a href="https://community.chocolatey.org/packages/topgrade"&gt;Chocolatey&lt;/a&gt;, &lt;a href="https://scoop.sh/#/apps?q=topgrade"&gt;Scoop&lt;/a&gt; or &lt;a href="https://winstall.app/apps/topgrade-rs.topgrade"&gt;Winget&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;PyPi: &lt;a href="https://pypi.org/project/topgrade/"&gt;pip&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Fedora: &lt;a href="https://copr.fedorainfracloud.org/coprs/lilay/topgrade/"&gt;Copr&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other systems users can either use &lt;code&gt;cargo install&lt;/code&gt; or the compiled binaries from the release page. The compiled binaries contain a self-upgrading feature.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Just run &lt;code&gt;topgrade&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;config.example.toml&lt;/code&gt; for an example configuration file.&lt;/p&gt; 
&lt;h2&gt;Migration and Breaking Changes&lt;/h2&gt; 
&lt;p&gt;Whenever there is a &lt;strong&gt;breaking change&lt;/strong&gt;, the major version number will be bumped, and we will document these changes in the release note, please take a look at it when updated to a major release.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Got a question? Feel free to open an issue or discussion!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Configuration Path&lt;/h3&gt; 
&lt;h4&gt;&lt;code&gt;CONFIG_DIR&lt;/code&gt; on each platform&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: &lt;code&gt;%APPDATA%&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt; and &lt;strong&gt;other Unix systems&lt;/strong&gt;: &lt;code&gt;${XDG_CONFIG_HOME:-~/.config}&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;code&gt;topgrade&lt;/code&gt; will look for the configuration file in the following places, in order of priority:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;CONFIG_DIR/topgrade.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;CONFIG_DIR/topgrade/topgrade.toml&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If the file with higher priority is present, no matter it is valid or not, the other configuration files will be ignored.&lt;/p&gt; 
&lt;p&gt;On the first run(no configuration file exists), &lt;code&gt;topgrade&lt;/code&gt; will create a configuration file at &lt;code&gt;CONFIG_DIR/topgrade.toml&lt;/code&gt; for you.&lt;/p&gt; 
&lt;h3&gt;Custom Commands&lt;/h3&gt; 
&lt;p&gt;Custom commands can be defined in the config file which can be run before, during, or after the inbuilt commands, as required. By default, the custom commands are run using a new shell according to the &lt;code&gt;$SHELL&lt;/code&gt; environment variable on unix (falls back to &lt;code&gt;sh&lt;/code&gt;) or &lt;code&gt;pwsh&lt;/code&gt; on windows (falls back to &lt;code&gt;powershell&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;On unix, if you want to run your command using an interactive shell, for example to source your shell's rc files, you can add &lt;code&gt;-i&lt;/code&gt; at the start of your custom command. But note that this requires the command to exit the shell correctly or else the shell will hang indefinitely.&lt;/p&gt; 
&lt;h2&gt;Remote Execution&lt;/h2&gt; 
&lt;p&gt;You can specify a key called &lt;code&gt;remote_topgrades&lt;/code&gt; in the configuration file. This key should contain a list of hostnames that have Topgrade installed on them. Topgrade will use &lt;code&gt;ssh&lt;/code&gt; to run &lt;code&gt;topgrade&lt;/code&gt; on remote hosts before acting locally. To limit the execution only to specific hosts use the &lt;code&gt;--remote-host-limit&lt;/code&gt; parameter.&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;h3&gt;Problems or missing features?&lt;/h3&gt; 
&lt;p&gt;Open a new issue describing your problem and if possible provide a solution.&lt;/p&gt; 
&lt;h3&gt;Missing a feature or found an unsupported tool/distro?&lt;/h3&gt; 
&lt;p&gt;Just let us now what you are missing by opening an issue. For tools, please open an issue describing the tool, which platforms it supports and if possible, give us an example of its usage.&lt;/p&gt; 
&lt;h3&gt;Want to contribute to the code?&lt;/h3&gt; 
&lt;p&gt;Just fork the repository and start coding.&lt;/p&gt; 
&lt;h3&gt;Contribution Guidelines&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://github.com/topgrade-rs/topgrade/raw/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Add a proper testing framework to the code base.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Add unit tests for package managers.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Split up code into more maintainable parts, eg. putting every linux package manager in a own submodule of linux.rs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Discord server&lt;/h2&gt; 
&lt;p&gt;Welcome to &lt;a href="https://discord.gg/Q8HGGWundY"&gt;join&lt;/a&gt; our Discord server if you want to discuss Topgrade!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jj-vcs/jj</title>
      <link>https://github.com/jj-vcs/jj</link>
      <description>&lt;p&gt;A Git-compatible VCS that is both simple and powerful&lt;/p&gt;&lt;hr&gt;&lt;div class="title-block" style="text-align: center;" align="center"&gt; 
 &lt;h1&gt;Jujutsu‚Äîa version control system&lt;/h1&gt; 
 &lt;p&gt;&lt;img title="jj logo" src="https://raw.githubusercontent.com/jj-vcs/jj/main/docs/images/jj-logo.svg?sanitize=true" width="320" height="320"&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/jj-vcs/jj/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/martinvonz/jj" alt="Release"&gt;&lt;/a&gt; &lt;a href="https://github.com/jj-vcs/jj/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/martinvonz/jj" alt="Release date"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/jj-vcs/jj/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/martinvonz/jj" alt="License"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/dkmfj3aGQN"&gt;&lt;img src="https://img.shields.io/discord/968932220549103686.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://web.libera.chat/?channel=#jujutsu"&gt;&lt;img src="https://img.shields.io/badge/irc-%23jujutsu-blue.svg?sanitize=true" alt="IRC"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj"&gt;Homepage&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj/latest/install-and-setup"&gt;Installation&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj/latest/tutorial"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://jj-vcs.github.io/jj/latest/roadmap"&gt;Development Roadmap&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Jujutsu is a powerful &lt;a href="https://en.wikipedia.org/wiki/Version_control"&gt;version control system&lt;/a&gt; for software projects. You use it to get a copy of your code, track changes to the code, and finally publish those changes for others to see and use. It is designed from the ground up to be easy to use‚Äîwhether you're new or experienced, working on brand new projects alone, or large scale software projects with large histories and teams.&lt;/p&gt; 
&lt;p&gt;Jujutsu is unlike most other systems, because internally it abstracts the user interface and version control algorithms from the &lt;em&gt;storage systems&lt;/em&gt; used to serve your content. This allows it to serve as a VCS with many possible physical backends, that may have their own data or networking models‚Äîlike &lt;a href="https://www.mercurial-scm.org/"&gt;Mercurial&lt;/a&gt; or &lt;a href="https://www.breezy-vcs.org/"&gt;Breezy&lt;/a&gt;, or hybrid systems like Google's cloud-based design, &lt;a href="https://youtu.be/W71BTkUbdqE?t=645"&gt;Piper/CitC&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Today, we use Git repositories as a storage layer to serve and track content, making it &lt;strong&gt;compatible with many of your favorite Git-based tools, right now!&lt;/strong&gt; All core developers use Jujutsu to develop Jujutsu, right here on GitHub. But it should hopefully work with your favorite Git forges, too.&lt;/p&gt; 
&lt;p&gt;We combine many distinct design choices and concepts from other version control systems into a single tool. Some of those sources of inspiration include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Git&lt;/strong&gt;: We make an effort to &lt;a href="https://github.com/jj-vcs/jj/discussions/49"&gt;be fast&lt;/a&gt;‚Äîwith a snappy UX, efficient algorithms, correct data structures, and good-old-fashioned attention to detail. The default storage backend uses Git repositories for "physical storage", for wide interoperability and ease of onboarding.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Mercurial &amp;amp; Sapling&lt;/strong&gt;: There are many Mercurial-inspired features, such as the &lt;a href="https://jj-vcs.github.io/jj/latest/revsets/"&gt;revset&lt;/a&gt; language to select commits. There is &lt;a href="https://jj-vcs.github.io/jj/latest/git-comparison/#the-index"&gt;no explicit index&lt;/a&gt; or staging area. Branches are "anonymous" like Mercurial, so you don't need to make up a name for each small change. Primitives for rewriting history are powerful and simple. Formatting output is done with a robust template language that can be configured by the user.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Darcs&lt;/strong&gt;: Jujutsu keeps track of conflicts as &lt;a href="https://jj-vcs.github.io/jj/latest/conflicts/"&gt;first-class objects&lt;/a&gt; in its model; they are first-class in the same way commits are, while alternatives like Git simply think of conflicts as textual diffs. While not as rigorous as systems like Darcs (which is based on a formalized theory of patches, as opposed to snapshots), the effect is that many forms of conflict resolution can be performed and propagated automatically.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And it adds several innovative, useful features of its own:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Working-copy-as-a-commit&lt;/strong&gt;: Changes to files are &lt;a href="https://jj-vcs.github.io/jj/latest/working-copy/"&gt;recorded automatically&lt;/a&gt; as normal commits, and amended on every subsequent change. This "snapshot" design simplifies the user-facing data model (commits are the only visible object), simplifies internal algorithms, and completely subsumes features like Git's stashes or the index/staging-area.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Operation log &amp;amp; undo&lt;/strong&gt;: Jujutsu records every operation that is performed on the repository, from commits, to pulls, to pushes. This makes debugging problems like "what just happened?" or "how did I end up here?" easier, &lt;em&gt;especially&lt;/em&gt; when you're helping your coworker answer those questions about their repository! And because everything is recorded, you can undo that mistake you just made with ease. Version control has finally entered &lt;a href="https://en.wikipedia.org/wiki/Undo#History"&gt;the 1960s&lt;/a&gt;!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic rebase and conflict resolution&lt;/strong&gt;: When you modify a commit, every descendent is automatically rebased on top of the freshly-modified one. This makes "patch-based" workflows a breeze. If you resolve a conflict in a commit, the &lt;em&gt;resolution&lt;/em&gt; of that conflict is also propagated through descendants as well. In effect, this is a completely transparent version of &lt;code&gt;git rebase --update-refs&lt;/code&gt; combined with &lt;code&gt;git rerere&lt;/code&gt;, supported by design.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] The following features are available for use, but experimental; they may have bugs, backwards incompatible storage changes, and user-interface changes!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Safe, concurrent replication&lt;/strong&gt;: Have you ever wanted to store your version controlled repositories inside a Dropbox folder? Or continuously backup repositories to S3? No? Well, now you can!&lt;/p&gt; &lt;p&gt;The fundamental problem with using filesystems like Dropbox and backup tools like &lt;code&gt;rsync&lt;/code&gt; on your typical Git/Mercurial repositories is that they rely on &lt;em&gt;local filesystem operations&lt;/em&gt; being atomic, serialized, and non-concurrent with respect to other reads and writes‚Äîwhich is &lt;em&gt;not&lt;/em&gt; true when operating on distributed file systems, or when operations like concurrent file copies (for backup) happen while lock files are being held.&lt;/p&gt; &lt;p&gt;Jujutsu is instead designed to be &lt;a href="https://jj-vcs.github.io/jj/latest/technical/concurrency/"&gt;safe under concurrent scenarios&lt;/a&gt;; simply using rsync or Dropbox and then using that resulting repository should never result in a repository in a &lt;em&gt;corrupt state&lt;/em&gt;. The worst that &lt;em&gt;should&lt;/em&gt; happen is that it will expose conflicts between the local and remote state, leaving you to resolve them.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The command-line tool is called &lt;code&gt;jj&lt;/code&gt; for now because it's easy to type and easy to replace (rare in English). The project is called "Jujutsu" because it matches "jj".&lt;/p&gt; 
&lt;p&gt;Jujutsu is relatively young, with lots of work to still be done. If you have any questions, or want to talk about future plans, please join us on Discord &lt;a href="https://discord.gg/dkmfj3aGQN"&gt;&lt;img src="https://img.shields.io/discord/968932220549103686.svg?label=&amp;amp;logo=discord&amp;amp;logoColor=ffffff&amp;amp;color=7389D8&amp;amp;labelColor=6A7EC2" alt="Discord"&gt;&lt;/a&gt;, start a &lt;a href="https://github.com/jj-vcs/jj/discussions"&gt;GitHub Discussion&lt;/a&gt;, or send an IRC message to &lt;a href="https://web.libera.chat/?channel=#jujutsu"&gt;&lt;code&gt;#jujutsu&lt;/code&gt; on Libera Chat&lt;/a&gt;. The developers monitor all of these channels[^bridge].&lt;/p&gt; 
&lt;p&gt;[^bridge]: To be more precise, the &lt;code&gt;#jujutsu&lt;/code&gt; Libera IRC channel is bridged to one of the channels on jj's Discord. Some of the developers stay on Discord and use the bridge to follow IRC.&lt;/p&gt; 
&lt;h3&gt;News and Updates üì£&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;December 2024&lt;/strong&gt;: The &lt;code&gt;jj&lt;/code&gt; Repository has moved to the &lt;code&gt;jj-vcs&lt;/code&gt; GitHub organisation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;November 2024&lt;/strong&gt;: Version 0.24 is released which adds &lt;code&gt;jj file annotate&lt;/code&gt;, which is equivalent to &lt;code&gt;git blame&lt;/code&gt; or &lt;code&gt;hg annotate&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;September 2024&lt;/strong&gt;: Martin gave a &lt;a href="https://www.youtube.com/watch?v=LV0JzI8IcCY"&gt;presentation about Jujutsu&lt;/a&gt; at Git Merge 2024.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 2024&lt;/strong&gt;: Version 0.14 is released, which deprecates &lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/CHANGELOG.md#0140---2024-02-07"&gt;"jj checkout" and "jj merge"&lt;/a&gt;, as well as &lt;code&gt;jj init --git&lt;/code&gt;, which is now just called &lt;code&gt;jj git init&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Oct 2023&lt;/strong&gt;: Version 0.10.0 is released! Now includes a bundled merge and diff editor for all platforms, "immutable revsets" to avoid accidentally &lt;code&gt;edit&lt;/code&gt;-ing the wrong revisions, and lots of polish.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jan 2023&lt;/strong&gt;: Martin gave a presentation about Google's plans for Jujutsu at Git Merge 2022! See the &lt;a href="https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view"&gt;slides&lt;/a&gt; or the &lt;a href="https://www.youtube.com/watch?v=bx_LGilOuE4"&gt;recording&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Related Media&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Mar 2024&lt;/strong&gt;: Chris Krycho started &lt;a href="https://www.youtube.com/playlist?list=PLelyiwKWHHAq01Pvmpf6x7J0y-yQpmtxp"&gt;a YouTube series about Jujutsu&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feb 2024&lt;/strong&gt;: Chris Krycho published an article about Jujutsu called &lt;a href="https://v5.chriskrycho.com/essays/jj-init/"&gt;jj init&lt;/a&gt; and Steve Klabnik followed up with the &lt;a href="https://steveklabnik.github.io/jujutsu-tutorial/"&gt;Jujutsu Tutorial&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jan 2024&lt;/strong&gt;: Jujutsu was featured in an LWN.net article called &lt;a href="https://lwn.net/Articles/958468/"&gt;Jujutsu: a new, Git-compatible version control system&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jan 2023&lt;/strong&gt;: Martin's Talk about Jujutsu at Git Merge 2022, &lt;a href="https://www.youtube.com/watch?v=bx_LGilOuE4"&gt;video&lt;/a&gt; and the associated &lt;a href="https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view"&gt;slides&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The wiki also contains a more extensive list of &lt;a href="https://github.com/jj-vcs/jj/wiki/Media"&gt;media references&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Jujutsu is an &lt;strong&gt;experimental version control system&lt;/strong&gt;. While Git compatibility is stable, and most developers use it daily for all their needs, there may still be work-in-progress features, suboptimal UX, and workflow gaps that make it unusable for your particular use.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Follow the &lt;a href="https://jj-vcs.github.io/jj/latest/install-and-setup"&gt;installation instructions&lt;/a&gt; to obtain and configure &lt;code&gt;jj&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The best way to get started is probably to go through &lt;a href="https://jj-vcs.github.io/jj/latest/tutorial"&gt;the tutorial&lt;/a&gt;. Also see the &lt;a href="https://jj-vcs.github.io/jj/latest/git-comparison"&gt;Git comparison&lt;/a&gt;, which includes a table of &lt;code&gt;jj&lt;/code&gt; vs. &lt;code&gt;git&lt;/code&gt; commands.&lt;/p&gt; 
&lt;p&gt;As you become more familiar with Jujutsu, the following resources may be helpful:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://jj-vcs.github.io/jj/latest/FAQ"&gt;FAQ&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://jj-vcs.github.io/jj/latest/glossary"&gt;Glossary&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;jj help&lt;/code&gt; command (e.g. &lt;code&gt;jj help rebase&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;jj help -k &amp;lt;keyword&amp;gt;&lt;/code&gt; command (e.g. &lt;code&gt;jj help -k config&lt;/code&gt;). Use &lt;code&gt;jj help --help&lt;/code&gt; to see what keywords are available.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you are using a &lt;strong&gt;prerelease&lt;/strong&gt; version of &lt;code&gt;jj&lt;/code&gt;, you would want to consult &lt;a href="https://jj-vcs.github.io/jj/prerelease/"&gt;the docs for the prerelease (main branch) version&lt;/a&gt;. You can also get there from the docs for the latest release by using the website's version switcher. The version switcher is visible in the header of the website when you scroll to the top of any page.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Compatible with Git&lt;/h3&gt; 
&lt;p&gt;Jujutsu is designed so that the underlying data and storage model is abstract. Today, only the Git backend is production-ready. The Git backend uses the &lt;a href="https://github.com/Byron/gitoxide"&gt;gitoxide&lt;/a&gt; Rust library.&lt;/p&gt; 
&lt;p&gt;The Git backend is fully featured and maintained, and allows you to use Jujutsu with any Git remote. The commits you create will look like regular Git commits. You can fetch branches from a regular Git remote and push branches to the remote. You can always switch back to Git.&lt;/p&gt; 
&lt;p&gt;Here is how you can explore a GitHub repository with &lt;code&gt;jj&lt;/code&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/git_compat.png"&gt; 
&lt;p&gt;You can even have a &lt;a href="https://jj-vcs.github.io/jj/latest/git-compatibility#co-located-jujutsugit-repos"&gt;"co-located" local repository&lt;/a&gt; where you can use both &lt;code&gt;jj&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt; commands interchangeably.&lt;/p&gt; 
&lt;h3&gt;The working copy is automatically committed&lt;/h3&gt; 
&lt;p&gt;Jujutsu uses a real commit to represent the working copy. Checking out a commit results a new working-copy commit on top of the target commit. Almost all commands automatically amend the working-copy commit.&lt;/p&gt; 
&lt;p&gt;The working-copy being a commit means that commands never fail because the working copy is dirty (no "error: Your local changes to the following files..."), and there is no need for &lt;code&gt;git stash&lt;/code&gt;. Also, because the working copy is a commit, commands work the same way on the working-copy commit as on any other commit, so you can set the commit message before you're done with the changes.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/working_copy.png"&gt; 
&lt;h3&gt;The repo is the source of truth&lt;/h3&gt; 
&lt;p&gt;With Jujutsu, the working copy plays a smaller role than with Git. Commands snapshot the working copy before they start, then they update the repo, and then the working copy is updated (if the working-copy commit was modified). Almost all commands (even checkout!) operate on the commits in the repo, leaving the common functionality of snapshotting and updating of the working copy to centralized code. For example, &lt;code&gt;jj restore&lt;/code&gt; (similar to &lt;code&gt;git restore&lt;/code&gt;) can restore from any commit and into any commit, and &lt;code&gt;jj describe&lt;/code&gt; can set the commit message of any commit (defaults to the working-copy commit).&lt;/p&gt; 
&lt;h3&gt;Entire repo is under version control&lt;/h3&gt; 
&lt;p&gt;All operations you perform in the repo are recorded, along with a snapshot of the repo state after the operation. This means that you can easily revert to an earlier repo state, or to simply undo a particular operation (which does not necessarily have to be the most recent operation).&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/operation_log.png"&gt; 
&lt;h3&gt;Conflicts can be recorded in commits&lt;/h3&gt; 
&lt;p&gt;If an operation results in &lt;a href="https://jj-vcs.github.io/jj/latest/glossary#conflict"&gt;conflicts&lt;/a&gt;, information about those conflicts will be recorded in the commit(s). The operation will succeed. You can then resolve the conflicts later. One consequence of this design is that there's no need to continue interrupted operations. Instead, you get a single workflow for resolving conflicts, regardless of which command caused them. This design also lets Jujutsu rebase merge commits correctly (unlike both Git and Mercurial).&lt;/p&gt; 
&lt;p&gt;Basic conflict resolution:&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/resolve_conflicts.png"&gt; 
&lt;p&gt;Juggling conflicts:&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/jj-vcs/jj/main/demos/juggle_conflicts.png"&gt; 
&lt;h3&gt;Automatic rebase&lt;/h3&gt; 
&lt;p&gt;Whenever you modify a commit, any descendants of the old commit will be rebased onto the new commit. Thanks to the conflict design described above, that can be done even if there are conflicts. Bookmarks pointing to rebased commits will be updated. So will the working copy if it points to a rebased commit.&lt;/p&gt; 
&lt;h3&gt;Comprehensive support for rewriting history&lt;/h3&gt; 
&lt;p&gt;Besides the usual rebase command, there's &lt;code&gt;jj describe&lt;/code&gt; for editing the description (commit message) of an arbitrary commit. There's also &lt;code&gt;jj diffedit&lt;/code&gt;, which lets you edit the changes in a commit without checking it out. To split a commit into two, use &lt;code&gt;jj split&lt;/code&gt;. You can even move part of the changes in a commit to any other commit using &lt;code&gt;jj squash -i --from X --into Y&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Status&lt;/h2&gt; 
&lt;p&gt;The tool is fairly feature-complete, but some important features like support for Git submodules are not yet completed. There are also several performance bugs. It's likely that workflows and setups different from what the core developers use are not well supported, e.g. there is no native support for email-based workflows.&lt;/p&gt; 
&lt;p&gt;Today, all core developers use &lt;code&gt;jj&lt;/code&gt; to work on &lt;code&gt;jj&lt;/code&gt;. I (Martin von Zweigbergk) have almost exclusively used &lt;code&gt;jj&lt;/code&gt; to develop the project itself since early January 2021. I haven't had to re-clone from source (I don't think I've even had to restore from backup).&lt;/p&gt; 
&lt;p&gt;There &lt;em&gt;will&lt;/em&gt; be changes to workflows and backward-incompatible changes to the on-disk formats before version 1.0.0. For any format changes, we'll try to implement transparent upgrades (as we've done with recent changes), or provide upgrade commands or scripts if requested.&lt;/p&gt; 
&lt;h2&gt;Related work&lt;/h2&gt; 
&lt;p&gt;There are several tools trying to solve similar problems as Jujutsu. See &lt;a href="https://jj-vcs.github.io/jj/latest/related-work"&gt;related work&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome outside contributions, and there's plenty of things to do, so don't be shy. Please ask if you want a pointer on something you can help with, and hopefully we can all figure something out.&lt;/p&gt; 
&lt;p&gt;We do have &lt;a href="https://jj-vcs.github.io/jj/prerelease/contributing/"&gt;a few policies and suggestions&lt;/a&gt; for contributors. The broad TL;DR:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bug reports are very welcome!&lt;/li&gt; 
 &lt;li&gt;Every commit that lands in the &lt;code&gt;main&lt;/code&gt; branch is code reviewed.&lt;/li&gt; 
 &lt;li&gt;Please behave yourself, and obey the Community Guidelines.&lt;/li&gt; 
 &lt;li&gt;There &lt;strong&gt;is&lt;/strong&gt; a mandatory CLA you must agree to. Importantly, it &lt;strong&gt;does not&lt;/strong&gt; transfer copyright ownership to Google or anyone else; it simply gives us the right to safely redistribute and use your changes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Mandatory Google Disclaimer&lt;/h3&gt; 
&lt;p&gt;I (Martin von Zweigbergk, &lt;a href="mailto:martinvonz@google.com"&gt;martinvonz@google.com&lt;/a&gt;) started Jujutsu as a hobby project in late 2019, and it has evolved into my full-time project at Google, with several other Googlers (now) assisting development in various capacities. That said, &lt;strong&gt;this is not a Google product&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Jujutsu is available as Open Source Software, under the Apache 2.0 license. See &lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; for details about copyright and redistribution.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;jj&lt;/code&gt; logo was contributed by J. Jennings and is licensed under a Creative Commons License, see &lt;a href="https://raw.githubusercontent.com/jj-vcs/jj/main/docs/images/LICENSE"&gt;&lt;code&gt;docs/images/LICENSE&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cocoindex-io/cocoindex</title>
      <link>https://github.com/cocoindex-io/cocoindex</link>
      <description>&lt;p&gt;Data transformation framework for AI. Ultra performant, with incremental processing.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/github.svg?sanitize=true" alt="CocoIndex"&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Data transformation for AI&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;&lt;img src="https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6" alt="GitHub"&gt;&lt;/a&gt; &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;&lt;img src="https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;amp;logoColor=00B9FF" alt="Documentation"&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white" alt="License"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/cocoindex/"&gt;&lt;img src="https://img.shields.io/pypi/v/cocoindex?color=5B5BD6" alt="PyPI version"&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/cocoindex"&gt;&lt;img src="https://img.shields.io/pypi/dm/cocoindex" alt="PyPI - Downloads"&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;amp;color=5B5BD6" alt="CI"&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;amp;color=5B5BD6" alt="release"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/zpA9S2DR7s"&gt;&lt;img src="https://img.shields.io/discord/1314801574169673738?logo=discord&amp;amp;color=5B5BD6&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13939" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13939" alt="cocoindex-io%2Fcocoindex | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Ultra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box. Exceptional developer velocity. Production-ready at day 0.&lt;/p&gt; 
&lt;p&gt;‚≠ê Drop a star to help us grow!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
 &lt;p&gt;&lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=en"&gt;English&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/transformation.svg?sanitize=true" alt="CocoIndex Transformation"&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;p&gt;CocoIndex makes it super easy to transform data with AI workloads, and keep source data and target in sync effortlessly.&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/venn-features.png" alt="CocoIndex Features" width="400"&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;p&gt;Either creating embedding, building knowledge graphs, or any data transformations - beyond traditional SQL.&lt;/p&gt; 
&lt;h2&gt;Exceptional velocity&lt;/h2&gt; 
&lt;p&gt;Just declare transformation in dataflow with ~100 lines of python&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# import
data['content'] = flow_builder.add_source(...)

# transform
data['out'] = data['content']
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CocoIndex follows the idea of &lt;a href="https://en.wikipedia.org/wiki/Dataflow_programming"&gt;Dataflow&lt;/a&gt; programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Particularly&lt;/strong&gt;, developers don't explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.&lt;/p&gt; 
&lt;h2&gt;Build like LEGO&lt;/h2&gt; 
&lt;p&gt;Native builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/components.svg?sanitize=true" alt="CocoIndex Features"&gt; &lt;/p&gt; 
&lt;h2&gt;Data Freshness&lt;/h2&gt; 
&lt;p&gt;CocoIndex keep source data and target in sync effortlessly.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6" alt="Incremental Processing" width="700"&gt; &lt;/p&gt; 
&lt;p&gt;It has out-of-box support for incremental indexing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;minimal recomputation on source or logic change.&lt;/li&gt; 
 &lt;li&gt;(re-)processing necessary portions; reuse cache when possible&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start:&lt;/h2&gt; 
&lt;p&gt;If you're new to CocoIndex, we recommend checking out&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;a href="https://cocoindex.io/docs"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üé¨ &lt;a href="https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT"&gt;Quick Start Video Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install CocoIndex Python library&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U cocoindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;a href="https://cocoindex.io/docs/getting_started/installation#-install-postgres"&gt;Install Postgres&lt;/a&gt; if you don't have one. CocoIndex uses it for incremental processing.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Define data flow&lt;/h2&gt; 
&lt;p&gt;Follow &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quick Start Guide&lt;/a&gt; to define your first indexing flow. An example flow looks like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@cocoindex.flow_def(name="TextEmbedding")
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope["documents"] = flow_builder.add_source(cocoindex.sources.LocalFile(path="markdown_files"))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope["documents"].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc["chunks"] = doc["content"].transform(
            cocoindex.functions.SplitRecursively(),
            language="markdown", chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc["chunks"].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk["embedding"] = chunk["text"].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model="sentence-transformers/all-MiniLM-L6-v2"))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc["filename"], location=chunk["location"],
                                   text=chunk["text"], embedding=chunk["embedding"])

    # Export collected data to a vector index.
    doc_embeddings.export(
        "doc_embeddings",
        cocoindex.targets.Postgres(),
        primary_key_fields=["filename", "location"],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name="embedding",
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It defines an index flow like this:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="400" alt="Data Flow" src="https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463"&gt; &lt;/p&gt; 
&lt;h2&gt;üöÄ Examples and demo&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding"&gt;Text Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents with embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/code_embedding"&gt;Code Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index code embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/pdf_embedding"&gt;PDF Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Parse PDF and index text embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/manuals_llm_extraction"&gt;Manuals LLM Extraction&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured information from a manual using LLM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/amazon_s3_embedding"&gt;Amazon S3 Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Amazon S3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/azure_blob_embedding"&gt;Azure Blob Storage Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Azure Blob Storage&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/gdrive_text_embedding"&gt;Google Drive Text Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Google Drive&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/docs_to_knowledge_graph"&gt;Docs to Knowledge Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract relationships from Markdown documents and build a knowledge graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding_qdrant"&gt;Embeddings to Qdrant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index documents in a Qdrant collection for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/fastapi_server_docker"&gt;FastAPI Server with Docker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Run the semantic search server in a Dockerized FastAPI setup&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/product_recommendation"&gt;Product Recommendation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Build real-time product recommendations with LLM and graph database&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/image_search"&gt;Image Search with Vision API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/face_recognition"&gt;Face Recognition&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Recognize faces in images and build embedding index&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/paper_metadata"&gt;Paper Metadata&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index papers in PDF files, and build metadata tables for each paper&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More coming and stay tuned üëÄ!&lt;/p&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, visit &lt;a href="https://cocoindex.io/docs"&gt;CocoIndex Documentation&lt;/a&gt;, including a &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quickstart guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We love contributions from our community ‚ù§Ô∏è. For details on contributing or running the project for development, check out our &lt;a href="https://cocoindex.io/docs/about/contributing"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üë• Community&lt;/h2&gt; 
&lt;p&gt;Welcome with a huge coconut hug ü••‚ãÜÔΩ°Àöü§ó. We are super excited for community contributions of all kinds - whether it's code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.&lt;/p&gt; 
&lt;p&gt;Join our community here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üåü &lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;Star us on GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üëã &lt;a href="https://discord.com/invite/zpA9S2DR7s"&gt;Join our Discord community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ñ∂Ô∏è &lt;a href="https://www.youtube.com/@cocoindex-io"&gt;Subscribe to our YouTube channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìú &lt;a href="https://cocoindex.io/blogs/"&gt;Read our blog posts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support us:&lt;/h2&gt; 
&lt;p&gt;We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ‚≠ê at GitHub repo &lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;&lt;img src="https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6" alt="GitHub"&gt;&lt;/a&gt; to stay tuned and help us grow.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;CocoIndex is Apache 2.0 licensed.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>