<rss version="2.0">
  <channel>
    <title>GitHub Go Daily Trending</title>
    <description>Daily Trending of Go in GitHub</description>
    <pubDate>Sun, 07 Dec 2025 01:34:23 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>hashicorp/terraform-provider-aws</title>
      <link>https://github.com/hashicorp/terraform-provider-aws</link>
      <description>&lt;p&gt;The AWS Provider enables Terraform to manage AWS resources.&lt;/p&gt;&lt;hr&gt;&lt;a href="https://terraform.io"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset=".github/terraform_logo_dark.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset=".github/terraform_logo_light.svg" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/hashicorp/terraform-provider-aws/main/.github/terraform_logo_light.svg?sanitize=true" alt="Terraform logo" title="Terraform" align="right" height="50" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h1&gt;Terraform AWS Provider&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://discuss.hashicorp.com/c/terraform-providers/tf-aws/"&gt;&lt;img src="https://img.shields.io/badge/discuss-terraform--aws-623CE4.svg?style=flat" alt="Forums" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://registry.terraform.io/providers/hashicorp/aws/latest/docs"&gt;AWS Provider&lt;/a&gt; enables &lt;a href="https://terraform.io"&gt;Terraform&lt;/a&gt; to manage &lt;a href="https://aws.amazon.com"&gt;AWS&lt;/a&gt; resources.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hashicorp.github.io/terraform-provider-aws/"&gt;Contributing guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/hashicorp/terraform-provider-aws/main/ROADMAP.md"&gt;Quarterly development roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hashicorp.github.io/terraform-provider-aws/faq/"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.hashicorp.com/collections/terraform/aws-get-started"&gt;Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discuss.hashicorp.com/c/terraform-providers/tf-aws/"&gt;discuss.hashicorp.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Please note:&lt;/strong&gt; We take Terraform's security and our users' trust very seriously. If you believe you have found a security issue in the Terraform AWS Provider, please responsibly disclose it by contacting us at &lt;a href="mailto:security@hashicorp.com"&gt;security@hashicorp.com&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>aquasecurity/trivy</title>
      <link>https://github.com/aquasecurity/trivy</link>
      <description>&lt;p&gt;Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/aquasecurity/trivy/main/docs/imgs/logo.png" width="200" /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/aquasecurity/trivy/releases"&gt;&lt;img src="https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/actions/workflows/test.yaml"&gt;&lt;img src="https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg?sanitize=true" alt="Test" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/aquasecurity/trivy"&gt;&lt;img src="https://goreportcard.com/badge/github.com/aquasecurity/trivy" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github" alt="GitHub Downloads" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;amp;label=docker%20pulls%20%2F%20trivy" alt="Docker Pulls" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trivy.dev/docs/latest/"&gt;üìñ Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Trivy (&lt;a href="https://raw.githubusercontent.com/aquasecurity/trivy/main/#how-to-pronounce-the-name-trivy"&gt;pronunciation&lt;/a&gt;) is a comprehensive and versatile security scanner. Trivy has &lt;em&gt;scanners&lt;/em&gt; that look for security issues, and &lt;em&gt;targets&lt;/em&gt; where it can find those issues.&lt;/p&gt; 
&lt;p&gt;Targets (what Trivy can scan):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Container Image&lt;/li&gt; 
 &lt;li&gt;Filesystem&lt;/li&gt; 
 &lt;li&gt;Git Repository (remote)&lt;/li&gt; 
 &lt;li&gt;Virtual Machine Image&lt;/li&gt; 
 &lt;li&gt;Kubernetes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Scanners (what Trivy can find there):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OS packages and software dependencies in use (SBOM)&lt;/li&gt; 
 &lt;li&gt;Known vulnerabilities (CVEs)&lt;/li&gt; 
 &lt;li&gt;IaC issues and misconfigurations&lt;/li&gt; 
 &lt;li&gt;Sensitive information and secrets&lt;/li&gt; 
 &lt;li&gt;Software licenses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the &lt;a href="https://trivy.dev/docs/latest/coverage/"&gt;Scanning Coverage&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;To learn more, go to the &lt;a href="https://trivy.dev"&gt;Trivy homepage&lt;/a&gt; for feature highlights, or to the &lt;a href="https://trivy.dev/docs/latest/"&gt;Documentation site&lt;/a&gt; for detailed information.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Get Trivy&lt;/h3&gt; 
&lt;p&gt;Trivy is available in most common distribution channels. The full list of installation options is available in the &lt;a href="https://trivy.dev/docs/latest/getting-started/installation/"&gt;Installation&lt;/a&gt; page. Here are a few popular examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;brew install trivy&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;docker run aquasec/trivy&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Download binary from &lt;a href="https://github.com/aquasecurity/trivy/releases/latest/"&gt;https://github.com/aquasecurity/trivy/releases/latest/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://trivy.dev/docs/latest/getting-started/installation/"&gt;Installation&lt;/a&gt; for more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the &lt;a href="https://trivy.dev/docs/latest/ecosystem/"&gt;Ecosystem&lt;/a&gt; page. Here are a few popular examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-action"&gt;GitHub Actions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-operator"&gt;Kubernetes operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-vscode-extension"&gt;VS Code plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://trivy.dev/docs/latest/ecosystem/"&gt;Ecosystem&lt;/a&gt; for more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Canary builds&lt;/h3&gt; 
&lt;p&gt;There are canary builds (&lt;a href="https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;amp;name=canary"&gt;Docker Hub&lt;/a&gt;, &lt;a href="https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary"&gt;GitHub&lt;/a&gt;, &lt;a href="https://gallery.ecr.aws/aquasecurity/trivy#canary"&gt;ECR&lt;/a&gt; images and &lt;a href="https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml"&gt;binaries&lt;/a&gt;) generated with every push to the main branch.&lt;/p&gt; 
&lt;p&gt;Please be aware: canary builds might have critical bugs, so they are not recommended for use in production.&lt;/p&gt; 
&lt;h3&gt;General usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy &amp;lt;target&amp;gt; [--scanners &amp;lt;scanner1,scanner2&amp;gt;] &amp;lt;subject&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy image python:3.4-alpine
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov"&gt;https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy fs --scanners vuln,secret,misconfig myproject/
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov"&gt;https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy k8s --report summary cluster
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aquasecurity/trivy/main/docs/imgs/trivy-k8s.png" alt="k8s summary" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;How to pronounce the name "Trivy"?&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;tri&lt;/code&gt; is pronounced like &lt;strong&gt;tri&lt;/strong&gt;gger, &lt;code&gt;vy&lt;/code&gt; is pronounced like en&lt;strong&gt;vy&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Want more? Check out Aqua&lt;/h2&gt; 
&lt;p&gt;If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.&lt;br /&gt; You can find a high level comparison table specific to Trivy users &lt;a href="https://trivy.dev/docs/latest/commercial/compare/"&gt;here&lt;/a&gt;. In addition check out the &lt;a href="https://aquasec.com"&gt;https://aquasec.com&lt;/a&gt; website for more information about our products and services. If you'd like to contact Aqua or request a demo, please use this form: &lt;a href="https://www.aquasec.com/demo"&gt;https://www.aquasec.com/demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Trivy is an &lt;a href="https://aquasec.com"&gt;Aqua Security&lt;/a&gt; open source project.&lt;br /&gt; Learn about our open source work and portfolio &lt;a href="https://www.aquasec.com/products/open-source-projects/"&gt;here&lt;/a&gt;.&lt;br /&gt; Contact us about any matter by opening a GitHub Discussion &lt;a href="https://github.com/aquasecurity/trivy/discussions"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Please ensure to abide by our &lt;a href="https://github.com/aquasecurity/community/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; during all interactions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>golang/go</title>
      <link>https://github.com/golang/go</link>
      <description>&lt;p&gt;The Go programming language&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Go Programming Language&lt;/h1&gt; 
&lt;p&gt;Go is an open source programming language that makes it easy to build simple, reliable, and efficient software.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://golang.org/doc/gopher/fiveyears.jpg" alt="Gopher image" /&gt; &lt;em&gt;Gopher image by &lt;a href="https://reneefrench.blogspot.com/"&gt;Renee French&lt;/a&gt;, licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;Creative Commons 4.0 Attribution license&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Our canonical Git repository is located at &lt;a href="https://go.googlesource.com/go"&gt;https://go.googlesource.com/go&lt;/a&gt;. There is a mirror of the repository at &lt;a href="https://github.com/golang/go"&gt;https://github.com/golang/go&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unless otherwise noted, the Go source files are distributed under the BSD-style license found in the LICENSE file.&lt;/p&gt; 
&lt;h3&gt;Download and Install&lt;/h3&gt; 
&lt;h4&gt;Binary Distributions&lt;/h4&gt; 
&lt;p&gt;Official binary distributions are available at &lt;a href="https://go.dev/dl/"&gt;https://go.dev/dl/&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After downloading a binary release, visit &lt;a href="https://go.dev/doc/install"&gt;https://go.dev/doc/install&lt;/a&gt; for installation instructions.&lt;/p&gt; 
&lt;h4&gt;Install From Source&lt;/h4&gt; 
&lt;p&gt;If a binary distribution is not available for your combination of operating system and architecture, visit &lt;a href="https://go.dev/doc/install/source"&gt;https://go.dev/doc/install/source&lt;/a&gt; for source installation instructions.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Go is the work of thousands of contributors. We appreciate your help!&lt;/p&gt; 
&lt;p&gt;To contribute, please read the contribution guidelines at &lt;a href="https://go.dev/doc/contribute"&gt;https://go.dev/doc/contribute&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Note that the Go project uses the issue tracker for bug reports and proposals only. See &lt;a href="https://go.dev/wiki/Questions"&gt;https://go.dev/wiki/Questions&lt;/a&gt; for a list of places to ask questions about the Go language.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>metallb/metallb</title>
      <link>https://github.com/metallb/metallb</link>
      <description>&lt;p&gt;A network load-balancer implementation for Kubernetes using standard routing protocols&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MetalLB&lt;/h1&gt; 
&lt;p&gt;MetalLB is a load-balancer implementation for bare metal &lt;a href="https://kubernetes.io"&gt;Kubernetes&lt;/a&gt; clusters, using standard routing protocols.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://metallb.io/concepts/maturity/"&gt;&lt;img src="https://img.shields.io/badge/maturity-beta-orange.svg?sanitize=true" alt="Project maturity: beta" /&gt;&lt;/a&gt; &lt;a href="https://github.com/metallb/metallb/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/metallb/metallb.svg?maxAge=2592000" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://github.com/metallb/metallb/actions/workflows/ci.yaml"&gt;&lt;img src="https://github.com/metallb/metallb/actions/workflows/ci.yaml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/u/metallb"&gt;&lt;img src="https://img.shields.io/badge/containers-ready-green.svg?sanitize=true" alt="Containers" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/metallb/metallb"&gt;&lt;img src="https://goreportcard.com/badge/github.com/metallb/metallb" alt="Go report card" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/5391"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/5391/badge" alt="CII Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://metallb.io"&gt;MetalLB's website&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h1&gt;WARNING&lt;/h1&gt; 
&lt;p&gt;Although the main branch has been relatively stable in the past, please be aware that it is the development branch.&lt;/p&gt; 
&lt;p&gt;Consuming manifests from main may result in unstable / non backward compatible deployments. We strongly suggest consuming a stable branch, as described in the &lt;a href="https://metallb.io/installation/"&gt;official docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome contributions in all forms. Please check out the &lt;a href="https://metallb.io/community/#contributing"&gt;hacking and contributing guide&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;Participation in this project is subject to a &lt;a href="https://metallb.io/community/code-of-conduct/"&gt;code of conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;One lightweight way you can contribute is to &lt;a href="https://github.com/metallb/metallb/issues/5"&gt;tell us that you're using MetalLB&lt;/a&gt;, which will give us warm fuzzy feelings :).&lt;/p&gt; 
&lt;h1&gt;Reporting security issues&lt;/h1&gt; 
&lt;p&gt;You can report security issues in the github issue tracker. If you prefer private disclosure, please email to all of the maintainers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="mailto:fpaoline@redhat.com"&gt;fpaoline@redhat.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="mailto:obraunsh@redhat.com"&gt;obraunsh@redhat.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We aim for initial response to vulnerability reports within 48 hours. The timeline for fixes depends on the complexity of the issue.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nats-io/nats-server</title>
      <link>https://github.com/nats-io/nats-server</link>
      <description>&lt;p&gt;High-Performance server for NATS.io, the cloud and edge native messaging system.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/nats-io/nats-server/main/logos/nats-horizontal-color.png" width="300" alt="NATS Logo" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://nats.io"&gt;NATS&lt;/a&gt; is a simple, secure and performant communications system for digital systems, services and devices. NATS is part of the Cloud Native Computing Foundation (&lt;a href="https://cncf.io"&gt;CNCF&lt;/a&gt;). NATS has over &lt;a href="https://nats.io/download/"&gt;40 client language implementations&lt;/a&gt;, and its server can run on-premise, in the cloud, at the edge, and even on a Raspberry Pi. NATS can secure and simplify design and operation of modern distributed systems.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache2-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/nats-io/nats-server/actions/workflows/tests.yaml"&gt;&lt;img src="https://github.com/nats-io/nats-server/actions/workflows/tests.yaml/badge.svg?branch=main" alt="Build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/nats-io/nats-server/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/nats-io/nats-server" alt="Release" /&gt;&lt;/a&gt; &lt;a href="https://slack.nats.io"&gt;&lt;img src="https://img.shields.io/badge/chat-on%20slack-green" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/r/nats-io/nats-server?branch=main"&gt;&lt;img src="https://coveralls.io/repos/github/nats-io/nats-server/badge.svg?branch=main" alt="Coverage" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/_/nats"&gt;&lt;img src="https://img.shields.io/docker/pulls/_/nats.svg?sanitize=true" alt="Docker Downloads" /&gt;&lt;/a&gt; &lt;a href="https://somsubhra.github.io/github-release-stats/?username=nats-io&amp;amp;repository=nats-server"&gt;&lt;img src="https://img.shields.io/github/downloads/nats-io/nats-server/total.svg?logo=github" alt="GitHub Downloads" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/1895"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/1895/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/helm/nats/nats"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/nats" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://nats.io"&gt;Official Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.nats.io"&gt;Official Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.nats.io/reference/faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Watch &lt;a href="https://rethink.synadia.com/episodes/1/"&gt;a video overview&lt;/a&gt; of NATS.&lt;/li&gt; 
 &lt;li&gt;Watch &lt;a href="https://www.youtube.com/watch?v=sm63oAVPqAM"&gt;this video from SCALE 13x&lt;/a&gt; to learn more about its origin story and design philosophy.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/nats_io"&gt;Twitter&lt;/a&gt;: Follow us on Twitter!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/forum/#!forum/natsio"&gt;Google Groups&lt;/a&gt;: Where you can ask questions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://natsio.slack.com"&gt;Slack&lt;/a&gt;: Click &lt;a href="https://slack.nats.io"&gt;here&lt;/a&gt; to join. You can ask questions to our maintainers and to the rich and active community.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you are interested in contributing to NATS, read about our...&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nats-io/nats-server/main/CONTRIBUTING.md"&gt;Contributing guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nats-io"&gt;Report issues or propose Pull Requests&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;The NATS product roadmap can be found &lt;a href="https://nats.io/about/#roadmap"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;Who uses NATS? See our &lt;a href="https://nats.io/#who-uses-nats"&gt;list of users&lt;/a&gt; on &lt;a href="https://nats.io"&gt;https://nats.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;h3&gt;Security Audit&lt;/h3&gt; 
&lt;p&gt;A third party security audit was performed by Trail of Bits following engagement by the Open Source Technology Improvement Fund (OSTIF). You can see the &lt;a href="https://github.com/trailofbits/publications/raw/master/reviews/2025-04-ostif-nats-securityreview.pdf"&gt;full report from April 2025 here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Reporting Security Vulnerabilities&lt;/h3&gt; 
&lt;p&gt;If you've found a vulnerability or a potential vulnerability in the NATS server, please let us know at &lt;a href="mailto:security@nats.io"&gt;nats-security&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Unless otherwise noted, the NATS source files are distributed under the Apache Version 2.0 license found in the LICENSE file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/typescript-go</title>
      <link>https://github.com/microsoft/typescript-go</link>
      <description>&lt;p&gt;Staging repo for development of native port of TypeScript&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;TypeScript 7&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://devblogs.microsoft.com/typescript/typescript-native-port/"&gt;Not sure what this is? Read the announcement post!&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Preview&lt;/h2&gt; 
&lt;p&gt;A preview build is available on npm as &lt;a href="https://www.npmjs.com/package/@typescript/native-preview"&gt;&lt;code&gt;@typescript/native-preview&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm install @typescript/native-preview
npx tsgo # Use this as you would tsc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A preview VS Code extension is &lt;a href="https://marketplace.visualstudio.com/items?itemName=TypeScriptTeam.native-preview"&gt;available on the VS Code marketplace&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To use this, set this in your VS Code settings:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "typescript.experimental.useTsgo": true
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What Works So Far?&lt;/h2&gt; 
&lt;p&gt;This is still a work in progress and is not yet at full feature parity with TypeScript. Bugs may exist. Please check this list carefully before logging a new issue or assuming an intentional change.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Program creation&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Same files and module resolution as TS 5.9. Not all resolution modes supported yet.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Parsing/scanning&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Exact same syntax errors as TS 5.9&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Commandline and &lt;code&gt;tsconfig.json&lt;/code&gt; parsing&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Done, though &lt;code&gt;tsconfig&lt;/code&gt; errors may not be as helpful.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Type resolution&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Same types as TS 5.9.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Type checking&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;Same errors, locations, and messages as TS 5.9. Types printback in errors may display differently.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript-specific inference and JSDoc&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;Mostly complete, but intentionally lacking some features. Declaration emit not complete.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JSX&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Declaration emit&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;Most common features are in place, but some edge cases and feature flags are still unhandled.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Emit (JS output)&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;target: esnext&lt;/code&gt; well-supported, other targets may have gaps.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Watch mode&lt;/td&gt; 
   &lt;td&gt;prototype&lt;/td&gt; 
   &lt;td&gt;Watches files and rebuilds, but no incremental rechecking. Not optimized.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Build mode / project references&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Incremental build&lt;/td&gt; 
   &lt;td&gt;done&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Language service (LSP)&lt;/td&gt; 
   &lt;td&gt;in progress&lt;/td&gt; 
   &lt;td&gt;Most functionality. More features coming soon.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;API&lt;/td&gt; 
   &lt;td&gt;not ready&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Definitions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;done&lt;/strong&gt; aka "believed done": We're not currently aware of any deficits or major left work to do. OK to log bugs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;in progress&lt;/strong&gt;: currently being worked on; some features may work and some might not. OK to log panics, but nothing else please&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;prototype&lt;/strong&gt;: proof-of-concept only; do not log bugs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;not ready&lt;/strong&gt;: either haven't even started yet, or far enough from ready that you shouldn't bother messing with it yet&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Other Notes&lt;/h2&gt; 
&lt;p&gt;Long-term, we expect that this repo and its contents will be merged into &lt;code&gt;microsoft/TypeScript&lt;/code&gt;. As a result, the repo and issue tracker for typescript-go will eventually be closed, so treat discussions/issues accordingly.&lt;/p&gt; 
&lt;p&gt;For a list of intentional changes with respect to TypeScript 5.9, see CHANGES.md.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;Contributor License Agreements&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>psviderski/uncloud</title>
      <link>https://github.com/psviderski/uncloud</link>
      <description>&lt;p&gt;A lightweight tool for deploying and managing containerised applications across a network of Docker hosts. Bridging the gap between Docker and Kubernetes ‚ú®&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/psviderski/uncloud/main/website/landing/images/logo-title.svg#gh-light-mode-only" alt="Uncloud logo" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/psviderski/uncloud/main/website/landing/images/logo-title-dark.svg#gh-dark-mode-only" alt="Uncloud logo" /&gt; 
 &lt;p&gt;&lt;strong&gt;‚ñ∏ Docker simplicity. Multi-machine power ‚óÇ&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://uncloud.run/docs"&gt;&lt;img src="https://img.shields.io/badge/Docs-blue.svg?style=for-the-badge&amp;amp;logo=gitbook&amp;amp;logoColor=white" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/eR35KQJhPu"&gt;&lt;img src="https://img.shields.io/badge/discord-5865F2.svg?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Join Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/psviderski"&gt;&lt;img src="https://img.shields.io/badge/follow-black?style=for-the-badge&amp;amp;logo=X&amp;amp;logoColor=while" alt="Follow on X" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/psviderski"&gt;&lt;img src="https://img.shields.io/badge/Donate-EA4AAA.svg?style=for-the-badge&amp;amp;logo=githubsponsors&amp;amp;logoColor=white" alt="Donate" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Uncloud is a lightweight clustering and container orchestration tool that lets you deploy and manage web apps across cloud VMs and bare metal with minimised cluster management overhead. It creates a secure WireGuard mesh network between your Docker hosts and provides automatic service discovery, load balancing, ingress with HTTPS, and simple CLI commands to manage your apps.&lt;/p&gt; 
&lt;p&gt;Unlike traditional orchestrators, there's no central control plane and quorum to maintain. Each machine maintains a synchronised copy of the cluster state through peer-to-peer communication, keeping cluster operations functional even if some machines go offline.&lt;/p&gt; 
&lt;p&gt;Uncloud is the solution for developers who want the flexibility of self-hosted infrastructure without the operational complexity of Kubernetes.&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Deploy anywhere&lt;/strong&gt;: Combine cloud VMs, dedicated servers, and bare metal into a unified computing environment, regardless of location or provider.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt;: Familiar &lt;a href="https://compose-spec.io/"&gt;Docker Compose&lt;/a&gt; format for defining services and volumes. No need to learn a new bespoke DSL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-downtime deployments&lt;/strong&gt;: Rolling updates without service interruption. Automatic rollback on failure is coming soon.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/psviderski/unregistry"&gt;Unregistry&lt;/a&gt; integration&lt;/strong&gt;: Build and push your Docker images directly to your machines without an external registry. It will transfer only the missing layers, making it fast and efficient.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Service discovery&lt;/strong&gt;: Built-in DNS server resolves service names to container IPs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistent storage&lt;/strong&gt;: Run stateful services with Docker volumes managed across machines.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-config private network&lt;/strong&gt;: Automatic WireGuard mesh with peer discovery and NAT traversal. Containers get unique IPs for direct cross-machine communication.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No control plane&lt;/strong&gt;: Fully decentralised design eliminates single points of failure and reduces operational overhead.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Imperative over declarative&lt;/strong&gt;: Favoring imperative operations over state reconciliation simplifies both the mental model and troubleshooting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Managed DNS&lt;/strong&gt;: Automatic DNS records &lt;code&gt;*.&amp;lt;id&amp;gt;.cluster.uncloud.run&lt;/code&gt; for services with public access via managed &lt;a href="https://github.com/psviderski/uncloud-dns"&gt;Uncloud DNS&lt;/a&gt; service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic HTTPS&lt;/strong&gt;: Built-in Caddy reverse proxy handles TLS certificate provisioning and renewal using Let's Encrypt.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker-like CLI&lt;/strong&gt;: Familiar commands for managing both infrastructure and applications.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remote management&lt;/strong&gt;: Control your entire infrastructure through SSH access to any single machine in the cluster.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üé¨ Quick demo&lt;/h2&gt; 
&lt;p&gt;The screenshot below demonstrates how I use Uncloud to deploy &lt;a href="https://uncloud.run"&gt;https://uncloud.run&lt;/a&gt; website to 2 remote machines from the &lt;a href="https://raw.githubusercontent.com/psviderski/uncloud/main/website/compose.yaml"&gt;&lt;code&gt;compose.yaml&lt;/code&gt;&lt;/a&gt; file on my local machine.&lt;/p&gt; 
&lt;p&gt;It exposes the container port &lt;code&gt;8000/tcp&lt;/code&gt; as HTTPS on the domain &lt;code&gt;uncloud.run&lt;/code&gt;, served by the Caddy reverse proxy on the remote machines. All managed by Uncloud.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/psviderski/uncloud/main/.github/images/compose-deploy.jpg" alt="Uncloud compose deployment demo" /&gt;&lt;/p&gt; 
&lt;p&gt;Here is a more advanced use case. Deploy a highly available web app with automatic HTTPS across multiple regions and on-premises in just a couple minutes.&lt;/p&gt; 
&lt;a href="https://uncloud.wistia.com/medias/k47uwt9uau?wvideo=k47uwt9uau"&gt; &lt;img src="https://embed-ssl.wistia.com/deliveries/3cf7014a48b93afc556444bed3e39a8c.jpg?image_crop_resized=900x526&amp;amp;image_play_button_rounded=true&amp;amp;image_play_button_size=2x&amp;amp;image_play_button_color=18181Be0" alt="Uncloud demo" width="450" height="263" /&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìö Want more examples?&lt;/strong&gt; Check out the &lt;a href="https://github.com/psviderski/uncloud-recipes"&gt;&lt;strong&gt;uncloud-recipes&lt;/strong&gt;&lt;/a&gt; repository for community recipes and templates for deploying popular services on Uncloud.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üí´ Why Uncloud?&lt;/h2&gt; 
&lt;p&gt;Modern cloud platforms like Heroku and Render offer amazing developer experiences but at a premium price. Traditional container orchestrators like Kubernetes provide power and flexibility but require significant operational expertise. I believe there's a sweet spot in between ‚Äî a pragmatic solution for the majority of us who aren't running at Google scale. You should be able to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Own your infrastructure and data&lt;/strong&gt;: Whether driven by costs, compliance, or flexibility, run applications on any combination of cloud VMs and personal hardware while controlling your data and maintaining the cloud-like experience you love.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stay simple as you grow&lt;/strong&gt;: Start with a single machine and add more whenever you need without changing your workflow. No worrying about highly-available control planes or complex YAML configurations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build with proven primitives&lt;/strong&gt;: Get production-grade networking, deployment primitives, service discovery, load balancing, and ingress with HTTPS out of the box without becoming a distributed systems expert.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support sustainable computing&lt;/strong&gt; üåø: Minimise system overhead to maximise resources available for your applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Uncloud's goal is to make deployment and management of containerised applications feel as seamless as using a cloud platform, whether you're running on a $5 VPS, a spare Mac mini, or a rack of bare metal servers.&lt;/p&gt; 
&lt;h2&gt;üöÄ Quick start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install Uncloud CLI:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;brew install psviderski/tap/uncloud

# or using curl (macOS/Linux)
curl -fsS https://get.uncloud.run/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;See &lt;a href="https://uncloud.run/docs/getting-started/install-cli"&gt;Installation&lt;/a&gt; for more options.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Initialise your first machine:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uc machine init root@your-server-ip
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Deploy your app from a Docker image and publish its container port 8000 as HTTPS using &lt;code&gt;app.example.com&lt;/code&gt; domain:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uc run -p app.example.com:8000/https image/my-app
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create a DNS A record in your DNS provider (Cloudflare, Namecheap, etc.) that points &lt;code&gt;app.example.com&lt;/code&gt; to your server's IP address. Allow a few minutes for DNS propagation.&lt;/p&gt; &lt;p&gt;That's it! Your app is now running and accessible at &lt;a href="https://app.example.com"&gt;https://app.example.com&lt;/a&gt; ‚ú®&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clean up when you're done:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uc ls
# Copy the service name from the output and run the rm command:
uc rm my-app-name
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If you want to fully uninstall Uncloud on a machine, run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uncloud-uninstall
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;View the &lt;a href="https://uncloud.run/docs"&gt;Documentation&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;‚öôÔ∏è How it works&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;a href="https://raw.githubusercontent.com/psviderski/uncloud/main/misc/design.md"&gt;design document&lt;/a&gt; to understand Uncloud's design philosophy and goals.&lt;/p&gt; 
&lt;p&gt;Here is a diagram of an Uncloud multi-provider cluster of 3 machines:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/psviderski/uncloud/main/website/landing/images/diagram.webp" alt="Diagram: multi-provider cluster of 3 machines" /&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Peek under the hood to see what happens when you run certain commands.&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;When you initialise a new cluster on a machine:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;$ uc machine init --name oracle-vm ubuntu@152.67.101.197

Downloading Uncloud install script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/install.sh
‚è≥ Running Uncloud install script...
‚úì Docker is already installed.
‚è≥ Installing Docker...
...
‚úì Docker installed successfully.
‚úì Linux user and group 'uncloud' created.
‚úì Linux user 'ubuntu' added to group 'uncloud'.
‚è≥ Installing Uncloud binaries...
‚è≥ Downloading uncloudd binary: https://github.com/psviderski/uncloud/releases/latest/download/uncloudd_linux_arm64.tar.gz
‚úì uncloudd binary installed: /usr/local/bin/uncloudd
‚è≥ Downloading uninstall script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/uninstall.sh
‚úì uncloud-uninstall script installed: /usr/local/bin/uncloud-uninstall
‚úì Systemd unit file created: /etc/systemd/system/uncloud.service
Created symlink /etc/systemd/system/multi-user.target.wants/uncloud.service ‚Üí /etc/systemd/system/uncloud.service.
‚è≥ Downloading uncloud-corrosion binary: https://github.com/psviderski/corrosion/releases/latest/download/corrosion-aarch64-unknown-linux-gnu.tar.gz
‚úì uncloud-corrosion binary installed: /usr/local/bin/uncloud-corrosion
‚úì Systemd unit file created: /etc/systemd/system/uncloud-corrosion.service
‚è≥ Starting Uncloud machine daemon (uncloud.service)...
‚úì Uncloud machine daemon started.
‚úì Uncloud installed on the machine successfully! üéâ
Cluster "default" initialised with machine "oracle-vm"
Waiting for the machine to be ready...

Reserved cluster domain: xuw3xd.cluster.uncloud.run
[+] Deploying service caddy 1/1
 ‚úî Container caddy-c47x on oracle-vm  Started                                                                                                                                          0.9s

Updating cluster domain records in Uncloud DNS to point to machines running caddy service...
[+] Verifying internet access to caddy service 1/1
 ‚úî Machine oracle-vm (152.67.101.197)  Reachable                                                                                                                                       0.1s

DNS records updated to use only the internet-reachable machines running caddy service:
  *.xuw3xd.cluster.uncloud.run  A ‚Üí 152.67.101.197
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol&gt; 
  &lt;li&gt;The CLI SSHs into the machine and installs Docker, the &lt;code&gt;uncloudd&lt;/code&gt; machine daemon and &lt;a href="https://github.com/superfly/corrosion"&gt;corrosion&lt;/a&gt; service, managed by systemd.&lt;/li&gt; 
  &lt;li&gt;Generates a unique WireGuard key pair, allocates a dedicated subnet &lt;code&gt;10.210.0.0/24&lt;/code&gt; for the machine and its containers, and configures &lt;code&gt;uncloudd&lt;/code&gt; accordingly. All subsequent communication happens with &lt;code&gt;uncloudd&lt;/code&gt; through its gRPC API over SSH.&lt;/li&gt; 
  &lt;li&gt;Configures and starts &lt;code&gt;corrosion&lt;/code&gt;, a CRDT-based distributed SQLite database to share cluster state between machines.&lt;/li&gt; 
  &lt;li&gt;Creates a Docker bridge network connected to the WireGuard interface.&lt;/li&gt; 
  &lt;li&gt;This machine becomes an entry point for the newly created cluster which is stored in the cluster config under &lt;code&gt;~/.config/uncloud&lt;/code&gt; on your local machine.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;&lt;strong&gt;When you add another machine:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;$ uc machine add --name hetzner-server root@5.223.45.199
Downloading Uncloud install script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/install.sh
‚è≥ Running Uncloud install script...
‚úì Docker is already installed.
‚úì Linux user and group 'uncloud' created.
‚è≥ Installing Uncloud binaries...
‚è≥ Downloading uncloudd binary: https://github.com/psviderski/uncloud/releases/latest/download/uncloudd_linux_amd64.tar.gz
‚úì uncloudd binary installed: /usr/local/bin/uncloudd
‚è≥ Downloading uninstall script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/uninstall.sh
‚úì uncloud-uninstall script installed: /usr/local/bin/uncloud-uninstall
‚úì Systemd unit file created: /etc/systemd/system/uncloud.service
Created symlink /etc/systemd/system/multi-user.target.wants/uncloud.service ‚Üí /etc/systemd/system/uncloud.service.
‚è≥ Downloading uncloud-corrosion binary: https://github.com/psviderski/corrosion/releases/latest/download/corrosion-x86_64-unknown-linux-gnu.tar.gz
‚úì uncloud-corrosion binary installed: /usr/local/bin/uncloud-corrosion
‚úì Systemd unit file created: /etc/systemd/system/uncloud-corrosion.service
‚è≥ Starting Uncloud machine daemon (uncloud.service)...
‚úì Uncloud machine daemon started.
‚úì Uncloud installed on the machine successfully! üéâ
Machine "hetzner-server" added to cluster
Waiting for the machine to be ready...

[+] Deploying service caddy 1/1
 ‚úî Container caddy-d36c on hetzner-server  Started                                                                                                                                     1.0s

Updating cluster domain records in Uncloud DNS to point to machines running caddy service...
[+] Verifying internet access to caddy service 2/2
 ‚úî Machine hetzner-server (5.223.45.199)  Reachable                                                                                                                                    0.2s
 ‚úî Machine oracle-vm (152.67.101.197)     Reachable                                                                                                                                    0.1s

DNS records updated to use only the internet-reachable machines running caddy service:
  *.xuw3xd.cluster.uncloud.run  A ‚Üí 152.67.101.197, 5.223.45.199

$ uc machine ls
NAME             STATE   ADDRESS         PUBLIC IP        WIREGUARD ENDPOINTS
oracle-vm        Up      10.210.0.1/24   152.67.101.197   10.0.0.95:51820, 152.67.101.197:51820
hetzner-server   Up      10.210.1.1/24   5.223.45.199     5.223.45.199:51820, [2a01:4ff:2f0:128b::1]:51820
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol&gt; 
  &lt;li&gt;The second machine gets provisioned just like the first. A non-root SSH user will need &lt;code&gt;sudo&lt;/code&gt; access.&lt;/li&gt; 
  &lt;li&gt;Allocates a new subnet &lt;code&gt;10.210.1.0/24&lt;/code&gt; for the second machine and its containers.&lt;/li&gt; 
  &lt;li&gt;Registers the second machine in the cluster state and exchanges WireGuard keys with the first machine.&lt;/li&gt; 
  &lt;li&gt;Both machines establish a WireGuard tunnel between each other, allowing Docker containers connected to the bridge network to communicate directly across machines.&lt;/li&gt; 
  &lt;li&gt;Configures and starts &lt;code&gt;corrosion&lt;/code&gt; on the second machine to sync the cluster state.&lt;/li&gt; 
  &lt;li&gt;The second machine is added as an alternative entry point in the cluster config.&lt;/li&gt; 
  &lt;li&gt;If one of the machines goes offline, the other machine can still serve cluster operations.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;If one more machine is added, the process repeats with a new subnet. The new machine needs to establish a WireGuard connection with only one of the existing machines. Other machines will learn about it through the shared cluster state and automatically establish a WireGuard tunnel with it.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;When you run a service:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;$ uc run -p app.example.com:8000/https image/my-app

[+] Running service my-app-1b3b (replicated mode) 1/1
 ‚úî Container my-app-1b3b-tcex on oracle-vm  Started

my-app-1b3b endpoints:
 ‚Ä¢ https://app.example.com ‚Üí :8000
 ‚Ä¢ https://my-app-1b3b.xuw3xd.cluster.uncloud.run ‚Üí :8000
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol&gt; 
  &lt;li&gt;CLI picks a machine to run your container.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;uncloudd&lt;/code&gt; that the CLI communicates with uses &lt;a href="https://github.com/siderolabs/grpc-proxy"&gt;&lt;code&gt;grpc-proxy&lt;/code&gt;&lt;/a&gt; to forward the request to the target machine to launch a container there.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;uncloudd&lt;/code&gt; on the target machine starts the Docker container in the bridge network and stores its info in the cluster's distributed state.&lt;/li&gt; 
  &lt;li&gt;The container gets a cluster-unique IP address from the bridge network (in the &lt;code&gt;10.210.X.2-254&lt;/code&gt; range) and becomes accessible from other machines in the cluster.&lt;/li&gt; 
  &lt;li&gt;Caddy reverse proxy which runs in &lt;a href="https://github.com/compose-spec/compose-spec/raw/main/deploy.md#mode"&gt;&lt;code&gt;global&lt;/code&gt;&lt;/a&gt; mode on each machine watches the cluster state for new services and updates its configuration to route traffic to the new container.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Look ma, no control plane or master nodes to maintain! Just a simple overlay network and eventually consistent state sync that lets machines work together. Want to check on things or make changes? Connect to any machine either implicitly using the CLI or directly over SSH. They all have the complete cluster state and can control everything. It's like each machine is a full backup of your control plane.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;üèó Project status&lt;/h2&gt; 
&lt;p&gt;Uncloud is currently in active development and is &lt;strong&gt;not ready for production use&lt;/strong&gt;. Features may change significantly and there may be breaking changes between releases.&lt;/p&gt; 
&lt;p&gt;We'd love your input! Here's how you can contribute:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ Found a bug? &lt;a href="https://github.com/psviderski/uncloud/issues"&gt;Open an issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° Have questions, ideas, or need help? 
  &lt;ul&gt; 
   &lt;li&gt;Start a discussion or join an existing one in the &lt;a href="https://github.com/psviderski/uncloud/discussions"&gt;Discussions&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Join our &lt;a href="https://discord.gg/eR35KQJhPu"&gt;Discord community&lt;/a&gt; where we discuss features, roadmap, implementation details, and help each other out.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôè Inspiration &amp;amp; Acknowledgements&lt;/h2&gt; 
&lt;p&gt;I'm grateful to the following projects that inspired Uncloud's design and implementation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kamal-deploy.org/"&gt;Kamal&lt;/a&gt; ‚Äî for proving that even in the declarative era of Kubernetes there is a place for simple deployment tools that use imperative commands without complex orchestration. Kamal powers the multi-billion dollar company &lt;a href="https://37signals.com/"&gt;37signals&lt;/a&gt; where it was created, and that's truly inspiring!&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fly.io/"&gt;Fly.io&lt;/a&gt; ‚Äî for inspiring my vision for what self-hosted infrastructure should feel like, proving that developer experience and powerful infrastructure can coexist beautifully.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tailscale.com/"&gt;Tailscale&lt;/a&gt; ‚Äî for pioneering the vision of decentralised flat mesh networking with an amazing user experience that feels like magic.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/siderolabs/talos"&gt;Talos Linux&lt;/a&gt; and &lt;a href="https://www.talos.dev/v1.10/talos-guides/network/kubespan/"&gt;KubeSpan&lt;/a&gt; ‚Äî for the machine API design using &lt;a href="https://github.com/siderolabs/grpc-proxy"&gt;grpc-proxy&lt;/a&gt; and for its elegant approach to secure WireGuard-based overlay networking with zero configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/docker-archive/classicswarm"&gt;Docker Swarm Classic&lt;/a&gt; and &lt;a href="http://rancher-com-website-main-elb-elb-1798790864.us-west-2.elb.amazonaws.com/docs/rancher/v1.6/en/"&gt;Rancher 1.x&lt;/a&gt; ‚Äî for showing the power of simplicity and pragmatism in container orchestration and that not every problem needs the complexity of Kubernetes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Special thanks to the &lt;a href="https://github.com/superfly/corrosion"&gt;Corrosion&lt;/a&gt; project by Fly.io for providing the distributed SQLite database used to share Uncloud's cluster state.&lt;/p&gt; 
&lt;h2&gt;üì´ Stay updated&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join our &lt;a href="https://discord.gg/eR35KQJhPu"&gt;Discord server&lt;/a&gt; for real-time discussions, support, and updates.&lt;/li&gt; 
 &lt;li&gt;Follow &lt;a href="https://x.com/psviderski"&gt;@psviderski&lt;/a&gt; on X/Twitter.&lt;/li&gt; 
 &lt;li&gt;Subscribe to &lt;a href="https://uncloud.run/#subscribe"&gt;my newsletter&lt;/a&gt; to follow the progress, get early insights into new features, and be the first to know when it's ready for production use.&lt;/li&gt; 
 &lt;li&gt;Watch this repository for releases.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíñ Sponsors&lt;/h2&gt; 
&lt;p&gt;These companies and projects are helping Uncloud with their generous sponsorship and/or services:&lt;/p&gt; 
&lt;!-- Sentry --&gt; 
&lt;a href="https://sentry.io/welcome/"&gt; &lt;img height="100" alt="Sentry" src="https://github.com/user-attachments/assets/6c1439c0-d20d-40dc-a669-c9aa94651dfa" /&gt; &lt;/a&gt; 
&lt;h2&gt;‚ù§Ô∏è Contributors&lt;/h2&gt; 
&lt;p&gt;Thank you &lt;a href="https://github.com/cedws"&gt;@cedws&lt;/a&gt; for being the first contributor to Uncloud! üéâ&lt;/p&gt; 
&lt;a href="https://github.com/psviderski/uncloud/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=psviderski/uncloud" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>m1k1o/neko</title>
      <link>https://github.com/m1k1o/neko</link>
      <description>&lt;p&gt;A self hosted virtual browser that runs in docker and uses WebRTC.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://github.com/m1k1o/neko" title="Neko's Github repository."&gt; &lt;img src="https://neko.m1k1o.net/img/logo.png" width="400" height="auto" /&gt; &lt;/a&gt; 
 &lt;p align="center"&gt; &lt;a href="https://github.com/m1k1o/neko/releases"&gt; &lt;img src="https://img.shields.io/github/v/release/m1k1o/neko" alt="release" /&gt; &lt;/a&gt; &lt;a href="https://github.com/m1k1o/neko/raw/master/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/m1k1o/neko" alt="license" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/m1k1o/neko"&gt; &lt;img src="https://img.shields.io/docker/pulls/m1k1o/neko" alt="pulls" /&gt; &lt;/a&gt; &lt;a href="https://github.com/m1k1o/neko/issues"&gt; &lt;img src="https://img.shields.io/github/issues/m1k1o/neko" alt="issues" /&gt; &lt;/a&gt; &lt;a href="https://github.com/sponsors/m1k1o"&gt; &lt;img src="https://img.shields.io/badge/-sponsor-red" alt="issues" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/3U6hWpC"&gt; &lt;img src="https://discordapp.com/api/guilds/665851821906067466/widget.png" alt="Chat on discord" /&gt; &lt;/a&gt; &lt;a href="https://hellogithub.com/repository/4536d4546af24196af3f08a023dfa007" target="_blank"&gt; &lt;img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=4536d4546af24196af3f08a023dfa007&amp;amp;claim_uid=0x19e4dJwD83aW2&amp;amp;theme=small" alt="FeaturedÔΩúHelloGitHub" /&gt; &lt;/a&gt; &lt;a href="https://github.com/m1k1o/neko/actions"&gt; &lt;img src="https://github.com/m1k1o/neko/actions/workflows/ghcr.yml/badge.svg?sanitize=true" alt="build" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;img src="https://neko.m1k1o.net/img/intro.gif" width="650" height="auto" /&gt; 
&lt;/div&gt; 
&lt;h1&gt;n.eko&lt;/h1&gt; 
&lt;p&gt;Welcome to Neko, a self-hosted virtual browser that runs in Docker and uses WebRTC technology. Neko is a powerful tool that allows you to &lt;strong&gt;run a fully-functional browser in a virtual environment&lt;/strong&gt;, giving you the ability to &lt;strong&gt;access the internet securely and privately from anywhere&lt;/strong&gt;. With Neko, you can browse the web, &lt;strong&gt;run applications&lt;/strong&gt;, and perform other tasks just as you would on a regular browser, all within a &lt;strong&gt;secure and isolated environment&lt;/strong&gt;. Whether you are a developer looking to test web applications, a &lt;strong&gt;privacy-conscious user seeking a secure browsing experience&lt;/strong&gt;, or simply someone who wants to take advantage of the &lt;strong&gt;convenience and flexibility of a virtual browser&lt;/strong&gt;, Neko is the perfect solution.&lt;/p&gt; 
&lt;p&gt;In addition to its security and privacy features, Neko offers the &lt;strong&gt;ability for multiple users to access it simultaneously&lt;/strong&gt;. This makes it an ideal solution for teams or organizations that need to share access to a browser, as well as for individuals who want to use &lt;strong&gt;multiple devices to access the same virtual environment&lt;/strong&gt;. With Neko, you can &lt;strong&gt;easily and securely share access to a browser with others&lt;/strong&gt;, without having to worry about maintaining separate configurations or settings. Whether you need to &lt;strong&gt;collaborate on a project&lt;/strong&gt;, access shared resources, or simply want to &lt;strong&gt;share access to a browser with friends or family&lt;/strong&gt;, Neko makes it easy to do so.&lt;/p&gt; 
&lt;p&gt;Neko is also a great tool for &lt;strong&gt;hosting watch parties&lt;/strong&gt; and interactive presentations. With its virtual browser capabilities, Neko allows you to host watch parties and presentations that are &lt;strong&gt;accessible from anywhere&lt;/strong&gt;, without the need for in-person gatherings. This makes it easy to &lt;strong&gt;stay connected with friends and colleagues&lt;/strong&gt;, even when you are unable to meet in person. With Neko, you can easily host a watch party or give an &lt;strong&gt;interactive presentation&lt;/strong&gt;, whether it's for leisure or work. Simply invite your guests to join the virtual environment, and you can share the screen and &lt;strong&gt;interact with them in real-time&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;This app uses WebRTC to stream a desktop inside of a docker container, original author made this because &lt;a href="https://en.wikipedia.org/wiki/Rabb.it"&gt;rabb.it&lt;/a&gt; went under and his internet could not handle streaming and discord kept crashing when his friend attempted to. He just wanted to watch anime with his friends ·Éö(‡≤†Áõä‡≤†·Éö) so he started digging throughout the internet and found a few &lt;em&gt;kinda&lt;/em&gt; clones, but none of them had the virtual browser, then he found &lt;a href="https://github.com/Khauri/Turtus"&gt;Turtus&lt;/a&gt; and he was able to figure out the rest.&lt;/p&gt; 
&lt;p&gt;Then I found &lt;a href="https://github.com/nurdism/neko"&gt;this&lt;/a&gt; project and started to dig into it. I really liked the idea of having collaborative browser browsing together with multiple people, so I created a fork. Initially, I wanted to merge my changes to the upstream repository, but the original author did not have time for this project anymore and it got eventually archived.&lt;/p&gt; 
&lt;h2&gt;Use-cases and comparison&lt;/h2&gt; 
&lt;p&gt;Neko started as a virtual browser that is streamed using WebRTC to multiple users.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;It is &lt;strong&gt;not only limited to a browser&lt;/strong&gt;; it can run anything that runs on linux (e.g. VLC). Browser only happens to be the most popular and widely used use-case.&lt;/li&gt; 
 &lt;li&gt;In fact, it is not limited to a single program either; you can install a full desktop environment (e.g. XFCE, KDE).&lt;/li&gt; 
 &lt;li&gt;Speaking of limits, it does not need to run in a container; you could install neko on your host, connect to your X server and control your whole VM.&lt;/li&gt; 
 &lt;li&gt;Theoretically it is not limited to only X server, anything that can be controlled and scraped periodically for images could be used instead. 
  &lt;ul&gt; 
   &lt;li&gt;Like implementing RDP or VNC protocol, where neko would only act as WebRTC relay server. This is currently only future.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Primary use case is connecting with multiple people, leveraging real time synchronization and interactivity:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Watch party&lt;/strong&gt; - watching video content together with multiple people and reacting to it (chat, emotes) - open source alternative to &lt;a href="https://giggl.app/"&gt;giggl.app&lt;/a&gt; or &lt;a href="https://watch.hyperbeam.com"&gt;hyperbeam&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive presentation&lt;/strong&gt; - not only screen sharing, but others can control the screen.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Collaborative tool&lt;/strong&gt; - brainstorming ideas, cobrowsing, code debugging together.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support/Teaching&lt;/strong&gt; - interactively guiding people in controlled environment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Embed anything&lt;/strong&gt; - embed virtual browser in your web app - open source alternative to &lt;a href="https://hyperbeam.com/"&gt;hyperbeam API&lt;/a&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;open any third-party website or application, synchronize audio and video flawlessly among multiple participants.&lt;/li&gt; 
   &lt;li&gt;request rooms using API with &lt;a href="https://github.com/m1k1o/neko-rooms"&gt;neko-rooms&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other use cases that benefit from single-user:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Personal workspace&lt;/strong&gt; - streaming containerized apps and desktops to end-users - similar to &lt;a href="https://www.kasmweb.com/"&gt;kasm&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Persistent browser&lt;/strong&gt; - own browser with persistent cookies available anywhere - similar to &lt;a href="https://www.mightyapp.com/"&gt;mightyapp&lt;/a&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;no state is left on the host browser after terminating the connection.&lt;/li&gt; 
   &lt;li&gt;sensitive data like cookies are not transferred - only video is shared.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Throwaway browser&lt;/strong&gt; - a better solution for planning secret parties and buying birthday gifts off the internet. 
  &lt;ul&gt; 
   &lt;li&gt;use Tor Browser and &lt;a href="https://github.com/m1k1o/neko-vpn"&gt;VPN&lt;/a&gt; for additional anonymity.&lt;/li&gt; 
   &lt;li&gt;mitigates risk of OS fingerprinting and browser vulnerabilities by running in container.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session broadcasting&lt;/strong&gt; - broadcast room content using RTMP (to e.g. twitch or youtube...).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session recording&lt;/strong&gt; - broadcast RTMP can be saved to a file using e.g. &lt;a href="https://www.nginx.com/products/nginx/modules/rtmp-media-streaming/"&gt;nginx-rtmp&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;have clean environment when recording tutorials.&lt;/li&gt; 
   &lt;li&gt;no need to hide bookmarks or use incognito mode.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jump host&lt;/strong&gt; - access your internal applications securely without the need for VPN.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automated browser&lt;/strong&gt; - you can install &lt;a href="https://playwright.dev/"&gt;playwright&lt;/a&gt; or &lt;a href="https://pptr.dev/"&gt;puppeteer&lt;/a&gt; and automate tasks while being able to actively intercept them.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Compared to clientless remote desktop gateway (e.g. &lt;a href="https://guacamole.apache.org/"&gt;Apache Guacamole&lt;/a&gt; or &lt;a href="https://github.com/novnc/websockify"&gt;websockify&lt;/a&gt; with &lt;a href="https://novnc.com/"&gt;noVNC&lt;/a&gt;), installed with remote desktop server along with desired program (e.g. &lt;a href="https://docs.linuxserver.io/images/docker-firefox"&gt;linuxserver/firefox&lt;/a&gt;) provides neko additionally:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Smooth video&lt;/strong&gt; because it uses WebRTC and not images sent over WebSockets.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built in audio&lt;/strong&gt; support, what is not part of Apache Guacamole or noVNC.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-participant control&lt;/strong&gt;, what is not natively supported by Apache Guacamole or noVNC.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Supported browsers&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#firefox"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/firefox.svg?sanitize=true" title="ghcr.io/m1k1o/neko/firefox" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#tor-browser"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/tor-browser.svg?sanitize=true" title="ghcr.io/m1k1o/neko/tor-browser" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#waterfox"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/waterfox.svg?sanitize=true" title="ghcr.io/m1k1o/neko/waterfox" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#chromium"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/chromium.svg?sanitize=true" title="ghcr.io/m1k1o/neko/chromium" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#google-chrome"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/google-chrome.svg?sanitize=true" title="ghcr.io/m1k1o/neko/google-chrome" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#ungoogled-chromium"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/ungoogled-chromium.svg?sanitize=true" title="ghcr.io/m1k1o/neko/google-chrome" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#microsoft-edge"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/microsoft-edge.svg?sanitize=true" title="ghcr.io/m1k1o/neko/microsoft-edge" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#brave"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/brave.svg?sanitize=true" title="ghcr.io/m1k1o/neko/brave" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#vivaldi"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/vivaldi.svg?sanitize=true" title="ghcr.io/m1k1o/neko/vivaldi" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#opera"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/opera.svg?sanitize=true" title="ghcr.io/m1k1o/neko/opera" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;p&gt;... see &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images"&gt;all available images&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;Other applications&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#xfce"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/xfce.svg?sanitize=true" title="ghcr.io/m1k1o/neko/xfce" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#kde"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/kde.svg?sanitize=true" title="ghcr.io/m1k1o/neko/kde" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#remmina"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/remmina.svg?sanitize=true" title="ghcr.io/m1k1o/neko/remmina" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;a href="https://neko.m1k1o.net/docs/v3/installation/docker-images#vlc"&gt; &lt;img src="https://neko.m1k1o.net/img/icons/vlc.svg?sanitize=true" title="ghcr.io/m1k1o/neko/vlc" width="60" height="auto" /&gt; &lt;/a&gt; 
 &lt;p&gt;... others in &lt;a href="https://github.com/m1k1o/neko-apps"&gt;m1k1o/neko-apps&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;Why neko?&lt;/h3&gt; 
&lt;p&gt;I like cats üê± (&lt;code&gt;Neko&lt;/code&gt; is the Japanese word for cat), I'm a weeb/nerd.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;But why the cat butt?&lt;/strong&gt;&lt;/em&gt; Because cats are &lt;em&gt;assholes&lt;/em&gt;, but you love them anyways.&lt;/p&gt; 
&lt;h2&gt;Multiple rooms&lt;/h2&gt; 
&lt;p&gt;For neko room management software, visit &lt;a href="https://github.com/m1k1o/neko-rooms"&gt;neko-rooms&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;It also offers &lt;a href="https://github.com/m1k1o/neko-rooms/?tab=readme-ov-file#zero-knowledge-installation-with-https"&gt;Zero-knowledge installation (with HTTPS)&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Full documentation is available at &lt;a href="https://neko.m1k1o.net/"&gt;neko.m1k1o.net&lt;/a&gt;. Key sections include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/migration-from-v2"&gt;Migration from V2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/quick-start"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/installation/examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/faq"&gt;Frequently Asked Questions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neko.m1k1o.net/docs/v3/troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Contribute&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Check the &lt;a href="https://neko.m1k1o.net/contributing"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;If you find Neko useful, consider supporting the project via &lt;a href="https://github.com/sponsors/m1k1o"&gt;GitHub Sponsors&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kubernetes/kubernetes</title>
      <link>https://github.com/kubernetes/kubernetes</link>
      <description>&lt;p&gt;Production-Grade Container Scheduling and Management&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kubernetes (K8s)&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://bestpractices.coreinfrastructure.org/projects/569"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/569/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/kubernetes/kubernetes"&gt;&lt;img src="https://goreportcard.com/badge/github.com/kubernetes/kubernetes" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/v/release/kubernetes/kubernetes?sort=semver" alt="GitHub release (latest SemVer)" /&gt;&lt;/p&gt; 
&lt;img src="https://github.com/kubernetes/kubernetes/raw/master/logo/logo.png" width="100" /&gt; 
&lt;hr /&gt; 
&lt;p&gt;Kubernetes, also known as K8s, is an open source system for managing &lt;a href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/"&gt;containerized applications&lt;/a&gt; across multiple hosts. It provides basic mechanisms for the deployment, maintenance, and scaling of applications.&lt;/p&gt; 
&lt;p&gt;Kubernetes builds upon a decade and a half of experience at Google running production workloads at scale using a system called &lt;a href="https://research.google.com/pubs/pub43438.html?authuser=1"&gt;Borg&lt;/a&gt;, combined with best-of-breed ideas and practices from the community.&lt;/p&gt; 
&lt;p&gt;Kubernetes is hosted by the Cloud Native Computing Foundation (&lt;a href="https://www.cncf.io/about"&gt;CNCF&lt;/a&gt;). If your company wants to help shape the evolution of technologies that are container-packaged, dynamically scheduled, and microservices-oriented, consider joining the CNCF. For details about who's involved and how Kubernetes plays a role, read the CNCF &lt;a href="https://cncf.io/news/announcement/2015/07/new-cloud-native-computing-foundation-drive-alignment-among-container"&gt;announcement&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;To start using K8s&lt;/h2&gt; 
&lt;p&gt;See our documentation on &lt;a href="https://kubernetes.io"&gt;kubernetes.io&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Take a free course on &lt;a href="https://www.udacity.com/course/scalable-microservices-with-kubernetes--ud615"&gt;Scalable Microservices with Kubernetes&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To use Kubernetes code as a library in other applications, see the &lt;a href="https://git.k8s.io/kubernetes/staging/README.md"&gt;list of published components&lt;/a&gt;. Use of the &lt;code&gt;k8s.io/kubernetes&lt;/code&gt; module or &lt;code&gt;k8s.io/kubernetes/...&lt;/code&gt; packages as libraries is not supported.&lt;/p&gt; 
&lt;h2&gt;To start developing K8s&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://git.k8s.io/community"&gt;community repository&lt;/a&gt; hosts all information about building Kubernetes from source, how to contribute code and documentation, who to contact about what, etc.&lt;/p&gt; 
&lt;p&gt;If you want to build Kubernetes right away there are two options:&lt;/p&gt; 
&lt;h5&gt;You have a working &lt;a href="https://go.dev/doc/install"&gt;Go environment&lt;/a&gt;.&lt;/h5&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/kubernetes/kubernetes
cd kubernetes
make
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;You have a working &lt;a href="https://docs.docker.com/engine"&gt;Docker environment&lt;/a&gt;.&lt;/h5&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/kubernetes/kubernetes
cd kubernetes
make quick-release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the full story, head over to the &lt;a href="https://git.k8s.io/community/contributors/devel#readme"&gt;developer's documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;If you need support, start with the &lt;a href="https://kubernetes.io/docs/tasks/debug/"&gt;troubleshooting guide&lt;/a&gt;, and work your way through the process that we've outlined.&lt;/p&gt; 
&lt;p&gt;That said, if you have questions, reach out to us &lt;a href="https://git.k8s.io/community/communication"&gt;one way or another&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community Meetings&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://www.kubernetes.dev/resources/calendar/"&gt;Calendar&lt;/a&gt; has the list of all the meetings in the Kubernetes community in a single location.&lt;/p&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://kubernetes.io/case-studies/"&gt;User Case Studies&lt;/a&gt; website has real-world use cases of organizations across industries that are deploying/migrating to Kubernetes.&lt;/p&gt; 
&lt;h2&gt;Governance&lt;/h2&gt; 
&lt;p&gt;Kubernetes project is governed by a framework of principles, values, policies and processes to help our community and constituents towards our shared goals.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://github.com/kubernetes/community/raw/master/governance.md"&gt;Kubernetes Community&lt;/a&gt; is the launching point for learning about how we organize ourselves.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://github.com/kubernetes/steering"&gt;Kubernetes Steering community repo&lt;/a&gt; is used by the Kubernetes Steering Committee, which oversees governance of the Kubernetes project.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://github.com/kubernetes/enhancements"&gt;Kubernetes Enhancements repo&lt;/a&gt; provides information about Kubernetes releases, as well as feature tracking and backlogs.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>open-telemetry/opentelemetry-collector-contrib</title>
      <link>https://github.com/open-telemetry/opentelemetry-collector-contrib</link>
      <description>&lt;p&gt;Contrib repository for the OpenTelemetry Collector&lt;/p&gt;&lt;hr&gt;&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://opentelemetry.io/docs/collector/getting-started/"&gt;Getting Started&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/raw/main/CONTRIBUTING.md"&gt;Getting Involved&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://cloud-native.slack.com/archives/C01N6P7KR6W"&gt;Getting In Touch&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector-contrib/actions/workflows/build-and-test.yml?query=branch%3Amain"&gt; &lt;img alt="Build Status" src="https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector-contrib/build-and-test.yml?branch=main&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector-contrib"&gt; &lt;img alt="Go Report Card" src="https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/branch/main/"&gt; &lt;img alt="Codecov Status" src="https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge" /&gt; &lt;/a&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector-contrib/releases"&gt; &lt;img alt="GitHub release (latest by date including pre-releases)" src="https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector-contrib?include_prereleases&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;img alt="Beta" src="https://img.shields.io/badge/status-beta-informational?style=for-the-badge&amp;amp;logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABgAAAAYCAYAAADgdz34AAAAAXNSR0IArs4c6QAAAIRlWElmTU0AKgAAAAgABQESAAMAAAABAAEAAAEaAAUAAAABAAAASgEbAAUAAAABAAAAUgEoAAMAAAABAAIAAIdpAAQAAAABAAAAWgAAAAAAAACQAAAAAQAAAJAAAAABAAOgAQADAAAAAQABAACgAgAEAAAAAQAAABigAwAEAAAAAQAAABgAAAAA8A2UOAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAAVlpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IlhNUCBDb3JlIDUuNC4wIj4KICAgPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4KICAgICAgPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIKICAgICAgICAgICAgeG1sbnM6dGlmZj0iaHR0cDovL25zLmFkb2JlLmNvbS90aWZmLzEuMC8iPgogICAgICAgICA8dGlmZjpPcmllbnRhdGlvbj4xPC90aWZmOk9yaWVudGF0aW9uPgogICAgICA8L3JkZjpEZXNjcmlwdGlvbj4KICAgPC9yZGY6UkRGPgo8L3g6eG1wbWV0YT4KTMInWQAABK5JREFUSA2dVm1sFEUYfmd2b/f2Pkqghn5eEQWKrRgjpkYgpoRCLC0oxV5apAiGUDEpJvwxEQ2raWPU+Kf8INU/RtEedwTCR9tYPloxGNJYTTQUwYqJ1aNpaLH3sXu3t7vjvFevpSqt7eSyM+/czvM8877PzB3APBoLgoDLsNePF56LBwqa07EKlDGg84CcWsI4CEbhNnDpAd951lXE2NkiNknCCTLv4HtzZuvPm1C/IKv4oDNXqNDHragety2XVzjECZsJARuBMyRzJrh1O0gQwLXuxofxsPSj4hG8fMLQo7bl9JJD8XZfC1E5yWFOMtd07dvX5kDwg6+2++Chq8txHGtfPoAp0gOFmhYoNFkHjn2TNUmrwRdna7W1QSkU8hvbGk4uThLrapaiLA2E6QY4u/lS9ItHfvJkxYsTMVtnAJLipYIWtVrcdX+8+b8IVnPl/R81prbuPZ1jpYw+0aEUGSkdFsgyBIaFTXCm6nyaxMtJ4n+TeDhJzGqZtQZcuYDgqDwDbqb0JF9oRpIG1Oea3bC1Y6N3x/WV8Zh83emhCs++hlaghDw+8w5UlYKq2lU7Pl8IkvS9KDqXmKmEwdMppVPKwGSEilmyAwJhRwWcq7wYC6z4wZ1rrEoMWxecdOjZWXeAQClBcYDN3NwVwD9pGwqUSyQgclcmxpNJqCuwLmDh3WtvPqXdlt+6Oz70HPGDNSNBee/EOen+rGbEFqDENBPDbtdCp0ukPANmzO0QQJYUpyS5IJJI3Hqt4maS+EB3199ozm8EDU/6fVNU2dQpdx3ZnKzeFXyaUTiasEV/gZMzJMjr3Z+WvAdQ+hs/zw9savimxUntDSaBdZ2f+Idbm1rlNY8esFffBit9HtK5/MejsrJVxikOXlb1Ukir2X+Rbdkd1KG2Ixfn2Ql4JRmELnYK9mEM8G36fAA3xEQ89fxXihC8q+sAKi9jhHxNqagY2hiaYgRCm0f0QP7H4Fp11LSXiuBY2aYFlh0DeDIVVFUJQn5rCnpiNI2gvLxHnASn9DIVHJJlm5rXvQAGEo4zvKq2w5G1NxENN7jrft1oxMdekETjxdH2Z3x+VTVYsPb+O0C/9/auN6v2hNZw5b2UOmSbG5/rkC3LBA+1PdxFxORjxpQ81GcxKc+ybVjEBvUJvaGJ7p7n5A5KSwe4AzkasA+crmzFtowoIVTiLjANm8GDsrWW35ScI3JY8Urv83tnkF8JR0yLvEt2hO/0qNyy3Jb3YKeHeHeLeOuVLRpNF+pkf85OW7/zJxWdXsbsKBUk2TC0BCPwMq5Q/CPvaJFkNS/1l1qUPe+uH3oD59erYGI/Y4sce6KaXYElAIOLt+0O3t2+/xJDF1XvOlWGC1W1B8VMszbGfOvT5qaRRAIFK3BCO164nZ0uYLH2YjNN8thXS2v2BK9gTfD7jHVxzHr4roOlEvYYz9QIz+Vl/sLDXInsctFsXjqIRnO2ZO387lxmIboLDZCJ59KLFliNIgh9ipt6tLg9SihpRPDO1ia5byw7de1aCQmF5geOQtK509rzfdwxaKOIq+73AvwCC5/5fcV4vo3+3LpMdtWHh0ywsJC/ZGoCb8/9D8F/ifgLLl8S8QWfU8cAAAAASUVORK5CYII=" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/raw/main/docs/vision.md"&gt;Vision&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/raw/main/docs/observability.md"&gt;Observability&lt;/a&gt; &amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp; &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/raw/main/docs/security-best-practices.md"&gt;Security&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;OpenTelemetry Collector Contrib&lt;/h1&gt; 
&lt;p&gt;This is a repository for OpenTelemetry Collector components that are not suitable for the &lt;a href="https://github.com/open-telemetry/opentelemetry-collector"&gt;core repository&lt;/a&gt; of the collector.&lt;/p&gt; 
&lt;p&gt;The official distributions, core and contrib, are available as part of the &lt;a href="https://github.com/open-telemetry/opentelemetry-collector-releases"&gt;opentelemetry-collector-releases&lt;/a&gt; repository. Some of the components in this repository are part of the "core" distribution, such as the Jaeger and Prometheus components, but most of the components here are only available as part of the "contrib" distribution. Users of the OpenTelemetry Collector are also encouraged to build their own custom distributions with the &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder"&gt;OpenTelemetry Collector Builder&lt;/a&gt;, using the components they need from the core repository, the contrib repository, and possibly third-party or internal repositories.&lt;/p&gt; 
&lt;p&gt;Each component has its own support levels, as defined in the following sections. For each signal that a component supports, there's a stability level, setting the right expectations. It is possible then that a component will be &lt;strong&gt;Stable&lt;/strong&gt; for traces but &lt;strong&gt;Alpha&lt;/strong&gt; for metrics and &lt;strong&gt;Development&lt;/strong&gt; for logs.&lt;/p&gt; 
&lt;h2&gt;Stability levels&lt;/h2&gt; 
&lt;p&gt;Stability level for components in this repository follow the &lt;a href="https://github.com/open-telemetry/opentelemetry-collector#stability-levels"&gt;definitions&lt;/a&gt; from the OpenTelemetry Collector repository.&lt;/p&gt; 
&lt;h2&gt;Gated features&lt;/h2&gt; 
&lt;p&gt;Some features are hidden behind feature gates before they are part of the main code path for the component. Note that the feature gates themselves might be at different &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/tree/main/featuregate#feature-lifecycle"&gt;lifecycle stages&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Each component is supported either by the community of OpenTelemetry Collector Contrib maintainers, as defined by the GitHub group &lt;a href="https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer"&gt;@open-telemetry/collector-contrib-maintainer&lt;/a&gt;, or by specific vendors. See the individual README files for information about the specific components.&lt;/p&gt; 
&lt;p&gt;The OpenTelemetry Collector Contrib maintainers may at any time downgrade specific components if they are deemed unmaintained or if they pose a risk to the repository and/or binary distribution.&lt;/p&gt; 
&lt;p&gt;Even though the OpenTelemetry Collector Contrib maintainers are ultimately responsible for the components hosted here, actual support will likely be provided by individual contributors, typically a code owner for the specific component.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector-contrib/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/codeboten"&gt;Alex Boten&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/andrzej-stencel"&gt;Andrzej Stencel&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/atoulme"&gt;Antoine Toulme&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bogdandrutu"&gt;Bogdan Drutu&lt;/a&gt;, Snowflake&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ChrsMark"&gt;Christos Markou&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dmitryax"&gt;Dmitrii Anoshin&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/edmocosta"&gt;Edmo Vamerlatti Costa&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/evan-bradley"&gt;Evan Bradley&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mx-psi"&gt;Pablo Baeyens&lt;/a&gt;, DataDog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MovieStoreGuy"&gt;Sean Marciniak&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/TylerHelmuth"&gt;Tyler Helmuth&lt;/a&gt;, Honeycomb&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/songy23"&gt;Yang Song&lt;/a&gt;, DataDog&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the maintainer role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#maintainer"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/axw"&gt;Andrew Wilkins&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArthurSens"&gt;Arthur Silva Sens&lt;/a&gt;, Grafana Labs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/braydonk"&gt;Braydon Kains&lt;/a&gt;, Google&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crobert-1"&gt;Curtis Robert&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dashpole"&gt;David Ashpole&lt;/a&gt;, Google&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mwear"&gt;Matt Wear&lt;/a&gt;, Lightstep&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pjanotti"&gt;Paulo Janotti&lt;/a&gt;, Splunk&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dehaansa"&gt;Sam DeHaan&lt;/a&gt;, Grafana Labs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/VihasMakwana"&gt;Vihas Makwana&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fatsheep9146"&gt;Ziqi Zhao&lt;/a&gt;, Alibaba&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the approver role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#approver"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frzifus"&gt;Benedikt Bongartz&lt;/a&gt;, Red Hat&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bogdan-st"&gt;Bogdan Stancu&lt;/a&gt;, Adobe&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/constanca-m"&gt;Constan√ßa Manteigas&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/douglascamata"&gt;Douglas Camata&lt;/a&gt;, Coralogix&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bacherfl"&gt;Florian Bacher&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/iblancasa"&gt;Israel Blancas&lt;/a&gt;, Coralogix&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jamesmoessis"&gt;James Moessis&lt;/a&gt;, Atlassian&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/JaredTan95"&gt;Jared Tan&lt;/a&gt;, DaoCloud&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Frapschen"&gt;Murphy Chen&lt;/a&gt;, DaoCloud&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/odubajDT"&gt;Ondrej Dubaj&lt;/a&gt;, Dynatrace&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paulojmdias"&gt;Paulo Dias&lt;/a&gt;, Five9&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rogercoll"&gt;Roger Coll&lt;/a&gt;, Elastic&lt;/li&gt; 
 &lt;li&gt;Actively seeking contributors to triage issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the triager role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#triager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Maintainers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/djaglowski"&gt;Daniel Jaglowski&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jpkrohling"&gt;Juraci Paix√£o Kr√∂hling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tigrannajaryan"&gt;Tigran Najaryan&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Approvers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Aneurysm9"&gt;Anthony Mirabella&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bryan-aguilar"&gt;Bryan Aguilar&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pmm-sumo"&gt;Przemek Maciolek&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kovrus"&gt;Ruslan Kovalov&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Emeritus Triagers&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alolita"&gt;Alolita Sharma&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gbbr"&gt;Gabriel Aszalos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gouthamve"&gt;Goutham Veeramachaneni&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/punya"&gt;Punya Biswal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/flands"&gt;Steve Flanders&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information about the emeritus role, see the &lt;a href="https://github.com/open-telemetry/community/raw/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager"&gt;community repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;No Over-Representation&lt;/h3&gt; 
&lt;p&gt;A community member cannot be promoted to be a Collector contrib maintainer if, after their promotion, the resulting maintainers group has more than one-fourth (25%) of the members affiliated with the same employer. Job changes and similar events might result in over-representation, and no new maintainers from the same company can be promoted until representation is balanced again. In the event of confusion or concern, the OpenTelemetry Collector SIG will defer to the CNCF definition of "same employer".&lt;/p&gt; 
&lt;h2&gt;PRs and Reviews&lt;/h2&gt; 
&lt;p&gt;When creating a PR please follow the process &lt;a href="https://github.com/open-telemetry/opentelemetry-collector/raw/main/CONTRIBUTING.md#how-to-structure-prs-to-get-expedient-reviews"&gt;described here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;New PRs will be automatically associated with the reviewers based on &lt;a href="https://raw.githubusercontent.com/open-telemetry/opentelemetry-collector-contrib/main/.github/CODEOWNERS"&gt;CODEOWNERS&lt;/a&gt;. PRs will be also automatically assigned to one of the maintainers or approvers for facilitation.&lt;/p&gt; 
&lt;p&gt;The facilitator is responsible for helping the PR author and reviewers to make progress or if progress cannot be made for closing the PR.&lt;/p&gt; 
&lt;p&gt;If the reviewers do not have approval rights the facilitator is also responsible for the official approval that is required for the PR to be merged and if the facilitator is a maintainer they are responsible for merging the PR as well.&lt;/p&gt; 
&lt;p&gt;The facilitator is not required to perform a thorough review, but they are encouraged to enforce Collector best practices and consistency across the codebase and component behavior. The facilitators will typically rely on codeowner's detailed review of the code when making the final approval decision.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>putyy/res-downloader</title>
      <link>https://github.com/putyy/res-downloader</link>
      <description>&lt;p&gt;ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÁõ¥Êí≠ÊµÅ„ÄÅm3u8„ÄÅÈÖ∑Áãó„ÄÅQQÈü≥‰πêÁ≠âÂ∏∏ËßÅÁΩëÁªúËµÑÊ∫ê‰∏ãËΩΩ!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/putyy/res-downloader"&gt;&lt;img src="https://raw.githubusercontent.com/putyy/res-downloader/master/build/appicon.png" width="120" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h1&gt;res-downloader&lt;/h1&gt; 
 &lt;h4&gt;üìñ ‰∏≠Êñá | &lt;a href="https://github.com/putyy/res-downloader/raw/master/README-EN.md"&gt;English&lt;/a&gt;&lt;/h4&gt; 
 &lt;p&gt;&lt;a href="https://github.com/putyy/res-downloader/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/putyy/res-downloader" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/putyy/res-downloader/fork"&gt;&lt;img src="https://img.shields.io/github/forks/putyy/res-downloader" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/putyy/res-downloader/releases"&gt;&lt;img src="https://img.shields.io/github/release/putyy/res-downloader" alt="GitHub release" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/putyy/res-downloader/total" alt="GitHub All Releases" /&gt; &lt;a href="https://github.com/putyy/res-downloader/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/putyy/res-downloader" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;üéâ Áà±‰∫´Á¥†Êùê‰∏ãËΩΩÂô®&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏ÄÊ¨æÂü∫‰∫é Go + &lt;a href="https://github.com/wailsapp/wails"&gt;Wails&lt;/a&gt; ÁöÑË∑®Âπ≥Âè∞ËµÑÊ∫ê‰∏ãËΩΩÂ∑•ÂÖ∑ÔºåÁÆÄÊ¥ÅÊòìÁî®ÔºåÊîØÊåÅÂ§öÁßçËµÑÊ∫êÂóÖÊé¢‰∏é‰∏ãËΩΩ„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;‚ú® ÂäüËÉΩÁâπËâ≤&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;ÁÆÄÂçïÊòìÁî®&lt;/strong&gt;ÔºöÊìç‰ΩúÁÆÄÂçïÔºåÁïåÈù¢Ê∏ÖÊô∞ÁæéËßÇ&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è &lt;strong&gt;Â§öÂπ≥Âè∞ÊîØÊåÅ&lt;/strong&gt;ÔºöWindows / macOS / Linux&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Â§öËµÑÊ∫êÁ±ªÂûãÊîØÊåÅ&lt;/strong&gt;ÔºöËßÜÈ¢ë / Èü≥È¢ë / ÂõæÁâá / m3u8 / Áõ¥Êí≠ÊµÅÁ≠â&lt;/li&gt; 
 &lt;li&gt;üì± &lt;strong&gt;Âπ≥Âè∞ÂÖºÂÆπÂπøÊ≥õ&lt;/strong&gt;ÔºöÊîØÊåÅÂæÆ‰ø°ËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅÂ∞èÁ∫¢‰π¶„ÄÅÈÖ∑ÁãóÈü≥‰πê„ÄÅQQÈü≥‰πêÁ≠â&lt;/li&gt; 
 &lt;li&gt;üåç &lt;strong&gt;‰ª£ÁêÜÊäìÂåÖ&lt;/strong&gt;ÔºöÊîØÊåÅËÆæÁΩÆ‰ª£ÁêÜËé∑ÂèñÂèóÈôêÁΩëÁªú‰∏ãÁöÑËµÑÊ∫ê&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìö ÊñáÊ°£ &amp;amp; ÁâàÊú¨&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìò &lt;a href="https://res.putyy.com/"&gt;Âú®Á∫øÊñáÊ°£&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://www.putyy.com/app/admin/upload/img/20250418/6801d9554dc7.webp"&gt;Âä†ÂÖ•‰∫§ÊµÅÁæ§&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß© &lt;a href="https://github.com/putyy/res-downloader/releases"&gt;ÊúÄÊñ∞Áâà&lt;/a&gt; ÔΩú &lt;a href="https://github.com/putyy/resd-mini"&gt;MiniÁâà ‰ΩøÁî®ÈªòËÆ§ÊµèËßàÂô®Â±ïÁ§∫UI&lt;/a&gt; ÔΩú &lt;a href="https://github.com/putyy/res-downloader/tree/old"&gt;ElectronÊóßÁâà ÊîØÊåÅWin7&lt;/a&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;em&gt;Áæ§Êª°Êó∂ÂèØÂä†ÂæÆ‰ø° &lt;code&gt;AmorousWorld&lt;/code&gt;ÔºåËØ∑Â§áÊ≥®‚Äúgithub‚Äù&lt;/em&gt;&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© ‰∏ãËΩΩÂú∞ÂùÄ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üÜï &lt;a href="https://github.com/putyy/res-downloader/releases"&gt;GitHub ‰∏ãËΩΩ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜï &lt;a href="https://wwjv.lanzoum.com/b04wgtfyb"&gt;ËìùÂ•è‰∫ë‰∏ãËΩΩÔºàÂØÜÁ†ÅÔºö9vs5Ôºâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ö†Ô∏è &lt;em&gt;Win7 Áî®Êà∑ËØ∑‰∏ãËΩΩ &lt;code&gt;2.3.0&lt;/code&gt; ÁâàÊú¨&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üñºÔ∏è È¢ÑËßà&lt;/h2&gt; 
&lt;h2&gt;&lt;img src="https://raw.githubusercontent.com/putyy/res-downloader/master/docs/images/show.webp" alt="È¢ÑËßà" /&gt;&lt;/h2&gt; 
&lt;h2&gt;üöÄ ‰ΩøÁî®ÊñπÊ≥ï&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËØ∑Êåâ‰ª•‰∏ãÊ≠•È™§Êìç‰Ωú‰ª•Ê≠£Á°Æ‰ΩøÁî®ËΩØ‰ª∂Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;ÂÆâË£ÖÊó∂Âä°ÂøÖ &lt;strong&gt;ÂÖÅËÆ∏ÂÆâË£ÖËØÅ‰π¶Êñá‰ª∂&lt;/strong&gt; Âπ∂ &lt;strong&gt;ÂÖÅËÆ∏ÁΩëÁªúËÆøÈóÆ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;ÊâìÂºÄËΩØ‰ª∂ ‚Üí È¶ñÈ°µÂ∑¶‰∏äËßíÁÇπÂáª &lt;strong&gt;‚ÄúÂêØÂä®‰ª£ÁêÜ‚Äù&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;ÈÄâÊã©Ë¶ÅËé∑ÂèñÁöÑËµÑÊ∫êÁ±ªÂûãÔºàÈªòËÆ§ÂÖ®ÈÉ®Ôºâ&lt;/li&gt; 
 &lt;li&gt;Âú®Â§ñÈÉ®ÊâìÂºÄËµÑÊ∫êÈ°µÈù¢ÔºàÂ¶ÇËßÜÈ¢ëÂè∑„ÄÅÂ∞èÁ®ãÂ∫è„ÄÅÁΩëÈ°µÁ≠âÔºâ&lt;/li&gt; 
 &lt;li&gt;ËøîÂõûËΩØ‰ª∂È¶ñÈ°µÔºåÂç≥ÂèØÁúãÂà∞ËµÑÊ∫êÂàóË°®&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;‚ùì Â∏∏ËßÅÈóÆÈ¢ò&lt;/h2&gt; 
&lt;h3&gt;üì∫ m3u8 ËßÜÈ¢ëËµÑÊ∫ê&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âú®Á∫øÈ¢ÑËßàÔºö&lt;a href="https://m3u8play.com/"&gt;m3u8play&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ËßÜÈ¢ë‰∏ãËΩΩÔºö&lt;a href="https://m3u8-down.gowas.cn/"&gt;m3u8-down&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì° Áõ¥Êí≠ÊµÅËµÑÊ∫ê&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êé®Ëçê‰ΩøÁî® &lt;a href="https://obsproject.com/"&gt;OBS&lt;/a&gt; ËøõË°åÂΩïÂà∂ÔºàÊïôÁ®ãËØ∑ÁôæÂ∫¶Ôºâ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üê¢ ‰∏ãËΩΩÊÖ¢„ÄÅÂ§ßÊñá‰ª∂Â§±Ë¥•Ôºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êé®ËçêÂ∑•ÂÖ∑Ôºö 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://www.neatdownloadmanager.com/index.php/en/"&gt;Neat Download Manager&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://motrix.app/download"&gt;Motrix&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ËßÜÈ¢ëÂè∑ËµÑÊ∫ê‰∏ãËΩΩÂêéÂèØÂú®Êìç‰ΩúÈ°πÁÇπÂáª &lt;code&gt;ËßÜÈ¢ëËß£ÂØÜÔºàËßÜÈ¢ëÂè∑Ôºâ&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß© ËΩØ‰ª∂Êó†Ê≥ïÊã¶Êà™ËµÑÊ∫êÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°ÆËÆæÁΩÆÁ≥ªÁªü‰ª£ÁêÜÔºö&lt;br /&gt; Âú∞ÂùÄÔºö127.0.0.1 Á´ØÂè£Ôºö8899&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üåê ÂÖ≥Èó≠ËΩØ‰ª∂ÂêéÊó†Ê≥ï‰∏äÁΩëÔºü&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÊâãÂä®ÂÖ≥Èó≠Á≥ªÁªü‰ª£ÁêÜËÆæÁΩÆ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß† Êõ¥Â§öÈóÆÈ¢ò&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/putyy/res-downloader/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://s.gowas.cn/d/4089"&gt;Áà±‰∫´ËÆ∫ÂùõËÆ®ËÆ∫Â∏ñ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üí° ÂÆûÁé∞ÂéüÁêÜ &amp;amp; ÂàùË°∑&lt;/h2&gt; 
&lt;p&gt;Êú¨Â∑•ÂÖ∑ÈÄöËøá‰ª£ÁêÜÊñπÂºèÂÆûÁé∞ÁΩëÁªúÊäìÂåÖÔºåÂπ∂Á≠õÈÄâÂèØÁî®ËµÑÊ∫ê„ÄÇ‰∏é Fiddler„ÄÅCharles„ÄÅÊµèËßàÂô® DevTools ÂéüÁêÜÁ±ª‰ººÔºå‰ΩÜÂØπËµÑÊ∫êËøõË°å‰∫ÜÊõ¥ÂèãÂ•ΩÁöÑÁ≠õÈÄâ„ÄÅÂ±ïÁ§∫ÂíåÂ§ÑÁêÜÔºåÂ§ßÂπÖÂ∫¶Èôç‰Ωé‰∫Ü‰ΩøÁî®Èó®ÊßõÔºåÊõ¥ÈÄÇÂêàÂ§ß‰ºóÁî®Êà∑‰ΩøÁî®„ÄÇ&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êú¨ËΩØ‰ª∂‰ªÖ‰æõÂ≠¶‰π†‰∏éÁ†îÁ©∂Áî®ÈÄîÔºåÁ¶ÅÊ≠¢Áî®‰∫é‰ªª‰ΩïÂïÜ‰∏öÊàñËøùÊ≥ïÁî®ÈÄî„ÄÇ&lt;br /&gt; Â¶ÇÂõ†Ê≠§‰∫ßÁîüÁöÑ‰ªª‰ΩïÊ≥ïÂæãË¥£‰ªªÔºåÊ¶Ç‰∏é‰ΩúËÄÖÊó†ÂÖ≥ÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>opencontainers/image-spec</title>
      <link>https://github.com/opencontainers/image-spec</link>
      <description>&lt;p&gt;OCI Image Format&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OCI Image Format Specification&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/license/opencontainers/image-spec" alt="License" /&gt; &lt;a href="https://pkg.go.dev/github.com/opencontainers/image-spec"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/opencontainers/image-spec.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The OCI Image Format project creates and maintains the software shipping container image format spec (OCI Image Format).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/opencontainers/image-spec/main/spec.md"&gt;The specification can be found here&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This repository also provides &lt;a href="https://raw.githubusercontent.com/opencontainers/image-spec/main/specs-go"&gt;Go types&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/opencontainers/image-spec/main/schema"&gt;intra-blob validation tooling, and JSON Schema&lt;/a&gt;. The Go types and validation should be compatible with the current Go release; earlier Go releases are not supported.&lt;/p&gt; 
&lt;p&gt;Additional documentation about how this group operates:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opencontainers/org/raw/master/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/opencontainers/image-spec/main/#roadmap"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/opencontainers/image-spec/main/RELEASES.md"&gt;Releases&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Running an OCI Image&lt;/h2&gt; 
&lt;p&gt;The OCI Image Format partner project is the &lt;a href="https://github.com/opencontainers/runtime-spec"&gt;OCI Runtime Spec project&lt;/a&gt;. The Runtime Specification outlines how to run a "&lt;a href="https://github.com/opencontainers/runtime-spec/raw/main/bundle.md"&gt;filesystem bundle&lt;/a&gt;" that is unpacked on disk. At a high-level an OCI implementation would download an OCI Image then unpack that image into an OCI Runtime filesystem bundle. At this point the OCI Runtime Bundle would be run by an OCI Runtime.&lt;/p&gt; 
&lt;p&gt;This entire workflow supports the UX that users have come to expect from container engines like Docker and rkt: primarily, the ability to run an image with no additional arguments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;docker run example.com/org/app:v1.0.0&lt;/li&gt; 
 &lt;li&gt;rkt run example.com/org/app,version=v1.0.0&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To support this UX the OCI Image Format contains sufficient information to launch the application on the target platform (e.g. command, arguments, environment variables, etc).&lt;/p&gt; 
&lt;h2&gt;Distributing an OCI Image&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://github.com/opencontainers/distribution-spec/"&gt;OCI Distribution Spec Project&lt;/a&gt; defines an API protocol to facilitate and standardize the distribution of content. This API includes support for pushing and pulling OCI images to an OCI conformant registry.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Q: What happens to AppC or Docker Image Formats?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;A: Existing formats can continue to be a proving ground for technologies, as needed. The OCI Image Format project strives to provide a dependable open specification that can be shared between different tools and be evolved for years or decades of compatibility; as the deb and rpm format have.&lt;/p&gt; 
&lt;p&gt;Find more &lt;a href="https://www.opencontainers.org/faq"&gt;FAQ on the OCI site&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://github.com/opencontainers/image-spec/milestones"&gt;GitHub milestones&lt;/a&gt; lay out the path to the future improvements.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Development happens on GitHub for the spec. Issues are used for bugs and actionable items and longer discussions can happen on the &lt;a href="https://raw.githubusercontent.com/opencontainers/image-spec/main/#mailing-list"&gt;mailing list&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The specification and code is licensed under the Apache 2.0 license found in the &lt;code&gt;LICENSE&lt;/code&gt; file of this repository.&lt;/p&gt; 
&lt;h3&gt;Discuss your design&lt;/h3&gt; 
&lt;p&gt;The project welcomes submissions, but please let everyone know what you are working on.&lt;/p&gt; 
&lt;p&gt;Before undertaking a nontrivial change to this specification, send mail to the &lt;a href="https://raw.githubusercontent.com/opencontainers/image-spec/main/#mailing-list"&gt;mailing list&lt;/a&gt; to discuss what you plan to do. This gives everyone a chance to validate the design, helps prevent duplication of effort, and ensures that the idea fits. It also guarantees that the design is sound before code is written; a GitHub pull-request is not the place for high-level discussions.&lt;/p&gt; 
&lt;p&gt;Typos and grammatical errors can go straight to a pull-request. When in doubt, start on the &lt;a href="https://raw.githubusercontent.com/opencontainers/image-spec/main/#mailing-list"&gt;mailing-list&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Meetings&lt;/h3&gt; 
&lt;p&gt;Please see the &lt;a href="https://github.com/opencontainers/org#meetings"&gt;OCI org repository README&lt;/a&gt; for the most up-to-date information on OCI contributor and maintainer meeting schedules. You can also find links to meeting agendas and minutes for all prior meetings.&lt;/p&gt; 
&lt;h3&gt;Mailing List&lt;/h3&gt; 
&lt;p&gt;You can subscribe and join the mailing list on &lt;a href="https://groups.google.com/a/opencontainers.org/forum/#!forum/dev"&gt;Google Groups&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Markdown style&lt;/h3&gt; 
&lt;p&gt;To keep consistency throughout the Markdown files in the Open Container spec all files should be formatted one sentence per line. This fixes two things: it makes diffing easier with git and it resolves fights about line wrapping length. For example, this paragraph will span three lines in the Markdown source.&lt;/p&gt; 
&lt;h3&gt;Git commit&lt;/h3&gt; 
&lt;h4&gt;Sign your work&lt;/h4&gt; 
&lt;p&gt;The sign-off is a simple line at the end of the explanation for the patch, which certifies that you wrote it or otherwise have the right to pass it on as an open-source patch. The rules are pretty simple: if you can certify the below (from &lt;a href="https://developercertificate.org/"&gt;developercertificate.org&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;Developer Certificate of Origin
Version 1.1

Copyright (C) 2004, 2006 The Linux Foundation and its contributors.
660 York Street, Suite 102,
San Francisco, CA 94110 USA

Everyone is permitted to copy and distribute verbatim copies of this
license document, but changing it is not allowed.


Developer's Certificate of Origin 1.1

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I
    have the right to submit it under the open source license
    indicated in the file; or

(b) The contribution is based upon previous work that, to the best
    of my knowledge, is covered under an appropriate open source
    license and I have the right under that license to submit that
    work with modifications, whether created in whole or in part
    by me, under the same open source license (unless I am
    permitted to submit under a different license), as indicated
    in the file; or

(c) The contribution was provided directly to me by some other
    person who certified (a), (b) or (c) and I have not modified
    it.

(d) I understand and agree that this project and the contribution
    are public and that a record of the contribution (including all
    personal information I submit with it, including my sign-off) is
    maintained indefinitely and may be redistributed consistent with
    this project or the open source license(s) involved.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;then you just add a line to every git commit message:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;Signed-off-by: Joe Smith &amp;lt;joe@gmail.com&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;using your real name (sorry, no pseudonyms or anonymous contributions.)&lt;/p&gt; 
&lt;p&gt;You can add the sign off when creating the git commit via &lt;code&gt;git commit -s&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Commit Style&lt;/h3&gt; 
&lt;p&gt;Simple house-keeping for clean git history. Read more on &lt;a href="https://chris.beams.io/posts/git-commit/"&gt;How to Write a Git Commit Message&lt;/a&gt; or the Discussion section of &lt;a href="https://git-scm.com/docs/git-commit"&gt;&lt;code&gt;git-commit(1)&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Separate the subject from body with a blank line&lt;/li&gt; 
 &lt;li&gt;Limit the subject line to 50 characters&lt;/li&gt; 
 &lt;li&gt;Capitalize the subject line&lt;/li&gt; 
 &lt;li&gt;Do not end the subject line with a period&lt;/li&gt; 
 &lt;li&gt;Use the imperative mood in the subject line&lt;/li&gt; 
 &lt;li&gt;Wrap the body at 72 characters&lt;/li&gt; 
 &lt;li&gt;Use the body to explain what and why vs. how 
  &lt;ul&gt; 
   &lt;li&gt;If there was important/useful/essential conversation or information, copy or include a reference&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;When possible, one keyword to scope the change in the subject (i.e. "README: ...", "runtime: ...")&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>docker/cagent</title>
      <link>https://github.com/docker/cagent</link>
      <description>&lt;p&gt;Agent Builder and Runtime by Docker Engineering&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ü§ñ &lt;code&gt;cagent&lt;/code&gt; ü§ñ&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A powerful, easy-to-use, customizable multi-agent runtime that orchestrates AI agents with specialized capabilities and tools, and the interactions between agents.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/docker/cagent/main/docs/demo.gif" alt="cagent in action" /&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® What is &lt;code&gt;cagent&lt;/code&gt;? ‚ú®&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;cagent&lt;/code&gt; lets you create and run intelligent AI agents, where each agent has specialized knowledge, tools and capabilities.&lt;/p&gt; 
&lt;p&gt;Think of it as allowing you to quickly build, share and run a team of virtual experts that collaborate to solve complex problems for you.&lt;/p&gt; 
&lt;p&gt;And it's dead easy to use!&lt;/p&gt; 
&lt;p&gt;‚ö†Ô∏è Note: &lt;code&gt;cagent&lt;/code&gt; is in active development, &lt;strong&gt;breaking changes are to be expected&lt;/strong&gt; ‚ö†Ô∏è&lt;/p&gt; 
&lt;h3&gt;Your First Agent&lt;/h3&gt; 
&lt;p&gt;Example &lt;a href="https://raw.githubusercontent.com/docker/cagent/main/examples/basic_agent.yaml"&gt;basic_agent.yaml&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;Creating agents with cagent is straightforward. They are described in a short .yaml file, like this one:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run it in a terminal with &lt;code&gt;cagent run basic_agent.yaml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Many more examples can be found &lt;a href="https://raw.githubusercontent.com/docker/cagent/main/examples/README.md"&gt;here&lt;/a&gt;!&lt;/p&gt; 
&lt;h3&gt;Improving an agent with MCP tools&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;cagent&lt;/code&gt; supports MCP servers, enabling agents to use a wide variety of external tools and services.&lt;/p&gt; 
&lt;p&gt;It supports three transport types: &lt;code&gt;stdio&lt;/code&gt;, &lt;code&gt;http&lt;/code&gt; and &lt;code&gt;sse&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Giving an agent access to tools via MCP is a quick way to greatly improve its capabilities, the quality of its results and its general usefulness.&lt;/p&gt; 
&lt;p&gt;Get started quickly with the &lt;a href="https://docs.docker.com/ai/mcp-catalog-and-toolkit/toolkit/"&gt;Docker MCP Toolkit&lt;/a&gt; and &lt;a href="https://docs.docker.com/ai/mcp-catalog-and-toolkit/catalog/"&gt;catalog&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Here, we're giving the same basic agent from the example above access to a &lt;strong&gt;containerized&lt;/strong&gt; &lt;code&gt;duckduckgo&lt;/code&gt; mcp server and its tools by using Docker's MCP Gateway:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses.
    toolsets:
      - type: mcp
        ref: docker:duckduckgo # stdio transport
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When using a containerized server via the Docker MCP gateway, you can configure any required settings/secrets/authentication using the &lt;a href="https://docs.docker.com/ai/mcp-catalog-and-toolkit/toolkit/#example-use-the-github-official-mcp-server"&gt;Docker MCP Toolkit&lt;/a&gt; in Docker Desktop.&lt;/p&gt; 
&lt;p&gt;Aside from the containerized MCP servers the Docker MCP Gateway provides, any standard MCP server can be used with cagent!&lt;/p&gt; 
&lt;p&gt;Here's an example similar to the above but adding &lt;code&gt;read_file&lt;/code&gt; and &lt;code&gt;write_file&lt;/code&gt; tools from the &lt;code&gt;rust-mcp-filesystem&lt;/code&gt; MCP server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses. Write your search results to disk.
    toolsets:
      - type: mcp
        ref: docker:duckduckgo
      - type: mcp
        command: rust-mcp-filesystem # installed with `cargo install rust-mcp-filesystem`
        args: ["--allow-write", "."]
        tools: ["read_file", "write_file"] # Optional: specific tools only
        env:
          - "RUST_LOG=debug"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/docker/cagent/main/docs/USAGE.md#tool-configuration"&gt;the USAGE docs&lt;/a&gt; for more detailed information and examples&lt;/p&gt; 
&lt;h3&gt;Exposing agents as MCP tools&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;cagent&lt;/code&gt; can expose agents as MCP tools via the &lt;code&gt;cagent mcp&lt;/code&gt; command, allowing other MCP clients to use your agents.&lt;/p&gt; 
&lt;p&gt;Each agent in your configuration becomes an MCP tool with its description.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start MCP server with local file
cagent mcp ./examples/dev-team.yaml

# Or use an OCI artifact
cagent mcp agentcatalog/pirate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This exposes each agent as a tool (e.g., &lt;code&gt;root&lt;/code&gt;, &lt;code&gt;designer&lt;/code&gt;, &lt;code&gt;awesome_engineer&lt;/code&gt;) that MCP clients can call:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "method": "tools/call",
  "params": {
    "name": "designer",
    "arguments": {
      "message": "Design a login page"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/docker/cagent/main/docs/MCP-MODE.md"&gt;MCP Mode documentation&lt;/a&gt; for detailed instructions on exposing your agents through MCP with Claude Desktop, Claude Code, and other MCP clients.&lt;/p&gt; 
&lt;h3&gt;üéØ Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üèóÔ∏è Multi-agent architecture&lt;/strong&gt; - Create specialized agents for different domains.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Rich tool ecosystem&lt;/strong&gt; - Agents can use external tools and APIs via the MCP protocol.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ Smart delegation&lt;/strong&gt; - Agents can automatically route tasks to the most suitable specialist.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìù YAML configuration&lt;/strong&gt; - Declarative model and agent configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üí≠ Advanced reasoning&lt;/strong&gt; - Built-in "think", "todo" and "memory" tools for complex problem-solving.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç RAG (Retrieval-Augmented Generation)&lt;/strong&gt; - Pluggable retrieval strategies (BM25, chunked-embeddings, semantic-embeddings) with hybrid retrieval, result fusion and reranking support.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Multiple AI providers&lt;/strong&gt; - Support for OpenAI, Anthropic, Gemini, xAI, Mistral, Nebius and &lt;a href="https://docs.docker.com/ai/model-runner/"&gt;Docker Model Runner&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Quick Start üöÄ&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Using Homebrew&lt;/h4&gt; 
&lt;p&gt;Install &lt;code&gt;cagent&lt;/code&gt; with a single command using &lt;a href="https://brew.sh/"&gt;homebrew&lt;/a&gt;!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ brew install cagent
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using binary releases&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://github.com/docker/cagent/releases"&gt;Prebuilt binaries&lt;/a&gt; for Windows, macOS and Linux can be found on the release page of the &lt;a href="https://github.com/docker/cagent/releases"&gt;project's GitHub repository&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Once you've downloaded the appropriate binary for your platform, you may need to give it executable permissions. On macOS and Linux, this is done with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# linux amd64 build example
chmod +x /path/to/downloads/cagent-linux-amd64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then rename the binary to &lt;code&gt;cagent&lt;/code&gt; and configure your &lt;code&gt;PATH&lt;/code&gt; to be able to find it (configuration varies by platform).&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Set your API keys&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Based on the models you configure your agents to use, you will need to set the corresponding provider API key accordingly, all these keys are optional, you will likely need at least one of these, though:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For OpenAI models
export OPENAI_API_KEY=your_api_key_here

# For Anthropic models
export ANTHROPIC_API_KEY=your_api_key_here

# For Gemini models
export GOOGLE_API_KEY=your_api_key_here

# For xAI models
export XAI_API_KEY=your_api_key_here

# For Nebius models
export NEBIUS_API_KEY=your_api_key_here

# For Mistral models
export MISTRAL_API_KEY=your_api_key_here
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run Agents!&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run an agent!
cagent run ./examples/pirate.yaml

# or specify a different starting agent from the config, useful for agent teams
cagent run ./examples/pirate.yaml -a root

# or run directly from an image reference here I'm pulling the pirate agent from the creek repository
cagent run creek/pirate
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multi-agent team example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;agents:
  root:
    model: claude
    description: "Main coordinator agent that delegates tasks and manages workflow"
    instruction: |
      You are the root coordinator agent. Your job is to:
      1. Understand user requests and break them down into manageable tasks
      2. Delegate appropriate tasks to your helper agent
      3. Coordinate responses and ensure tasks are completed properly
      4. Provide final responses to the user
      When you receive a request, analyze what needs to be done and decide whether to:
      - Handle it yourself if it's simple
      - Delegate to the helper agent if it requires specific assistance
      - Break complex requests into multiple sub-tasks
    sub_agents: ["helper"]

  helper:
    model: claude
    description: "Assistant agent that helps with various tasks as directed by the root agent"
    instruction: |
      You are a helpful assistant agent. Your role is to:
      1. Complete specific tasks assigned by the root agent
      2. Provide detailed and accurate responses
      3. Ask for clarification if tasks are unclear
      4. Report back to the root agent with your results

      Focus on being thorough and helpful in whatever task you're given.

models:
  claude:
    provider: anthropic
    model: claude-sonnet-4-0
    max_tokens: 64000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You'll find a curated list of agents examples, spread into 3 categories, &lt;a href="https://github.com/docker/cagent/tree/main/examples#basic-configurations"&gt;Basic&lt;/a&gt;, &lt;a href="https://github.com/docker/cagent/tree/main/examples#advanced-configurations"&gt;Advanced&lt;/a&gt; and &lt;a href="https://github.com/docker/cagent/tree/main/examples#multi-agent-configurations"&gt;multi-agents&lt;/a&gt; in the &lt;code&gt;/examples/&lt;/code&gt; directory.&lt;/p&gt; 
&lt;h3&gt;DMR (Docker Model Runner) provider options&lt;/h3&gt; 
&lt;p&gt;When using the &lt;code&gt;dmr&lt;/code&gt; provider, you can use the &lt;code&gt;provider_opts&lt;/code&gt; key for DMR runtime-specific (e.g. llama.cpp/vllm) options and speculative decoding:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;models:
  local-qwen:
    provider: dmr
    model: ai/qwen3
    max_tokens: 8192
    provider_opts:
      # general flags passed to the underlying model runtime
      runtime_flags: ["--ngl=33", "--repeat-penalty=1.2", ...] # or comma/space-separated string
      # speculative decoding for faster inference
      speculative_draft_model: ai/qwen3:1B
      speculative_num_tokens: 5
      speculative_acceptance_rate: 0.8
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The default base_url &lt;code&gt;cagent&lt;/code&gt; will use for DMR providers is &lt;code&gt;http://localhost:12434/engines/llama.cpp/v1&lt;/code&gt;. DMR itself might need to be enabled via &lt;a href="https://docs.docker.com/ai/model-runner/get-started/#enable-dmr-in-docker-desktop"&gt;Docker Desktop's settings&lt;/a&gt; on macOS and Windows, and via the command-line on &lt;a href="https://docs.docker.com/ai/model-runner/get-started/#enable-dmr-in-docker-engine"&gt;Docker CE on Linux&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/docker/cagent/main/docs/USAGE.md#dmr-docker-model-runner-provider-usage"&gt;DMR Provider documentation&lt;/a&gt; for more details on runtime flags and speculative decoding options.&lt;/p&gt; 
&lt;h2&gt;RAG (Retrieval-Augmented Generation)&lt;/h2&gt; 
&lt;p&gt;Give your agents access to your documents with cagent's modular RAG system. It supports multiple retrieval strategies that can be used individually or combined for hybrid search.&lt;/p&gt; 
&lt;h3&gt;Quick RAG Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;models:
  embedder:
    provider: openai
    model: text-embedding-3-small

rag:
  my_knowledge_base:
    docs: [./documents, ./pdfs]
    strategies:
      - type: chunked-embeddings
        model: embedder
        threshold: 0.5
        chunking:
          size: 1000
          overlap: 100
    results:
      limit: 5

agents:
  root:
    model: openai/gpt-4o
    instruction: |
      You are an assistant with access to an internal knowledge base.
      Use the knowledge base to gather context before answering user questions
    rag: [my_knowledge_base]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hybrid Retrieval (Chunked-Embeddings + BM25)&lt;/h3&gt; 
&lt;p&gt;Combine semantic search (chunked-embeddings) with keyword search (BM25) for best results:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;rag:
  hybrid_search:
    docs: [./shared_docs]
    
    strategies:
      - type: chunked-embeddings
        model: embedder
        threshold: 0.5
        limit: 20
        chunking:
          size: 1000
          overlap: 100
      
      - type: bm25
        k1: 1.5
        b: 0.75
        threshold: 0.3
        limit: 15
        chunking:
          size: 1000
          overlap: 100
    
    results:
      fusion:
        strategy: rrf  # Reciprocal Rank Fusion
        k: 60
      deduplicate: true
      limit: 5

agents:
  root:
    model: openai/gpt-4o
    rag: [hybrid_search]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple strategies&lt;/strong&gt;: Vector embeddings, semantic embeddings, BM25 (keyword), or combinations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel execution&lt;/strong&gt;: Strategies run concurrently for fast results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pluggable fusion&lt;/strong&gt;: RRF, weighted, or max score combining&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Result reranking&lt;/strong&gt;: Re-score results with specialized models for improved relevance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Per-strategy configuration&lt;/strong&gt;: Different thresholds, limits, and documents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Auto file watching&lt;/strong&gt;: Reindex automatically on file changes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Result Reranking&lt;/h3&gt; 
&lt;p&gt;Improve search quality by re-scoring retrieved results with a reranking model:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;rag:
  knowledge_base:
    docs: [./documents]
    strategies:
      - type: chunked-embeddings
        model: openai/text-embedding-3-small
        limit: 20  # Retrieve more candidates for reranking
    
    results:
      reranking:
        model: openai/gpt-4.1-mini   # Any chat model or DMR reranker
        top_k: 10                   # Only rerank top 10 (optional)
        threshold: 0.3              # Filter low-scoring results (optional)
        criteria: |                 # Domain-specific relevance guidance (optional, not used with DMR reranking specific models)
          Prioritize recent documentation and practical examples.
          Documents from official sources are more relevant.
      limit: 5  # Final top results after reranking
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Supported providers:&lt;/strong&gt; DMR (native &lt;code&gt;/rerank&lt;/code&gt; endpoint), OpenAI, Anthropic, Gemini (via structured outputs)&lt;br /&gt; &lt;strong&gt;Note:&lt;/strong&gt; Temperature defaults to 0.0 for more deterministic scoring when not explicitly set.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/docker/cagent/main/docs/USAGE.md#rag-configuration"&gt;RAG documentation in USAGE.md&lt;/a&gt; for complete details, examples, and debugging guides.&lt;/p&gt; 
&lt;h2&gt;Quickly generate agents and agent teams with &lt;code&gt;cagent new&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;Using the command &lt;code&gt;cagent new&lt;/code&gt; you can quickly generate agents or multi-agent teams using a single prompt!&lt;br /&gt; &lt;code&gt;cagent&lt;/code&gt; has a built-in agent dedicated to this task.&lt;/p&gt; 
&lt;p&gt;To use the feature, you must have an Anthropic, OpenAI or Google API key available in your environment or specify a local model to run with DMR (Docker Model Runner).&lt;/p&gt; 
&lt;p&gt;You can choose what provider and model gets used by passing the &lt;code&gt;--model provider/modelname&lt;/code&gt; flag to &lt;code&gt;cagent new&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If &lt;code&gt;--model&lt;/code&gt; is unspecified, &lt;code&gt;cagent new&lt;/code&gt; will automatically choose between these three providers in order based on the first api key it finds in your environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export ANTHROPIC_API_KEY=your_api_key_here  # first choice. default model claude-sonnet-4-0
export OPENAI_API_KEY=your_api_key_here     # if anthropic key not set. default model gpt-5-mini
export GOOGLE_API_KEY=your_api_key_here     # if anthropic and openai keys are not set. default model gemini-2.5-flash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;--max-tokens&lt;/code&gt; can be specified to override the context limit used.&lt;br /&gt; When using DMR, the default is 16k to limit memory usage. With all other providers the default is 64k&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--max-iterations&lt;/code&gt; can be specified to override how many times the agent is allowed to loop when doing tool calling etc. When using DMR, the default is set to 20 (small local models have the highest chance of getting confused and looping endlessly). For all other providers, the default is 0 (unlimited).&lt;/p&gt; 
&lt;p&gt;Example of provider, model, context size and max iterations overriding:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Use GPT-5 via OpenAI
cagent new --model openai/gpt-5

# Use a local model (ai/gemma3-qat:12B) via DMR
cagent new --model dmr/ai/gemma3-qat:12B

# Override the max_tokens used during generation, default is 64k, 16k when using the dmr provider
cagent new --model openai/gpt-5-mini --max-tokens 32000

# Override max_iterations to limit how much the model can loop autonomously when tool calling
cagent new --model dmr/ai/gemma3n:2B-F16 --max-iterations 15
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;pre&gt;&lt;code&gt;$ cagent new

------- Welcome to cagent! -------
(Ctrl+C to stop the agent and exit)

What should your agent/agent team do? (describe its purpose):

&amp;gt; I need an agent team that connects to &amp;lt;some-service&amp;gt; and does...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Pushing and pulling agents from Docker Hub&lt;/h2&gt; 
&lt;h3&gt;&lt;code&gt;cagent push&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Agent configurations can be packaged and shared to Docker Hub using the &lt;code&gt;cagent push&lt;/code&gt; command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cagent push ./&amp;lt;agent-file&amp;gt;.yaml namespace/reponame
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;cagent&lt;/code&gt; will automatically build an OCI image and push it to the desired repository using your Docker credentials&lt;/p&gt; 
&lt;h3&gt;&lt;code&gt;cagent pull&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Pulling agents from Docker Hub is also just one &lt;code&gt;cagent pull&lt;/code&gt; command away.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cagent pull creek/pirate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;cagent&lt;/code&gt; will pull the image, extract the .yaml file and place it in your working directory for ease of use.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cagent run creek.yaml&lt;/code&gt; will run your newly pulled agent&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;More details on the usage and configuration of &lt;code&gt;cagent&lt;/code&gt; can be found in &lt;a href="https://raw.githubusercontent.com/docker/cagent/main/docs/USAGE.md"&gt;USAGE.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;We track anonymous usage data to improve the tool. See &lt;a href="https://raw.githubusercontent.com/docker/cagent/main/docs/TELEMETRY.md"&gt;TELEMETRY.md&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Want to hack on &lt;code&gt;cagent&lt;/code&gt;, or help us fix bugs and build out some features? üîß&lt;/p&gt; 
&lt;p&gt;Read the information on how to build from source and contribute to the project in &lt;a href="https://raw.githubusercontent.com/docker/cagent/main/docs/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;DogFooding: using &lt;code&gt;cagent&lt;/code&gt; to code on &lt;code&gt;cagent&lt;/code&gt;&lt;/h2&gt; 
&lt;p&gt;A smart way to improve &lt;code&gt;cagent&lt;/code&gt;'s codebase and feature set is to do it with the help of a &lt;code&gt;cagent&lt;/code&gt; agent!&lt;/p&gt; 
&lt;p&gt;We have one that we use and that you should use too:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd cagent
cagent run ./golang_developer.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This agent is an &lt;em&gt;expert Golang developer specializing in the cagent multi-agent AI system architecture&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;Ask it anything about &lt;code&gt;cagent&lt;/code&gt;. It can be questions about the current code or about improvements to the code. It can also fix issues and implement new features!&lt;/p&gt; 
&lt;h2&gt;Share your feedback&lt;/h2&gt; 
&lt;p&gt;We‚Äôd love to hear your thoughts on this project. You can find us on &lt;a href="https://dockercommunity.slack.com/archives/C09DASHHRU4"&gt;Slack&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>google/osv-scanner</title>
      <link>https://github.com/google/osv-scanner</link>
      <description>&lt;p&gt;Vulnerability scanner written in Go which uses the data provided by https://osv.dev&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;source srcset="/docs/images/osv-scanner-full-logo-darkmode.svg" media="(prefers-color-scheme: dark)" /&gt; 
 &lt;!-- markdown-link-check-disable-next-line --&gt; 
 &lt;img src="https://raw.githubusercontent.com/google/osv-scanner/main/docs/images/osv-scanner-full-logo-lightmode.svg?sanitize=true" /&gt; 
&lt;/picture&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://scorecard.dev/viewer/?uri=github.com/google/osv-scanner"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/google/osv-scanner/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/google/osv-scanner"&gt;&lt;img src="https://goreportcard.com/badge/github.com/google/osv-scanner" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/google/osv-scanner"&gt;&lt;img src="https://codecov.io/gh/google/osv-scanner/graph/badge.svg?token=C8IDVX9LP5" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://slsa.dev"&gt;&lt;img src="https://slsa.dev/images/gh-badge-level3.svg?sanitize=true" alt="SLSA 3" /&gt;&lt;/a&gt; &lt;a href="https://github.com/google/osv-scanner/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/google/osv-scanner" alt="GitHub Release" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Use OSV-Scanner to find existing vulnerabilities affecting your project's dependencies. OSV-Scanner provides an officially supported frontend to the &lt;a href="https://osv.dev/"&gt;OSV database&lt;/a&gt; and CLI interface to &lt;a href="https://github.com/google/osv-scalibr"&gt;OSV-Scalibr&lt;/a&gt; that connects a project‚Äôs list of dependencies with the vulnerabilities that affect them.&lt;/p&gt; 
&lt;p&gt;OSV-Scanner supports a wide range of project types, package managers and features, including but not limited to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Languages:&lt;/strong&gt; C/C++, Dart, Elixir, Go, Java, Javascript, PHP, Python, R, Ruby, Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Package Managers:&lt;/strong&gt; npm, pip, yarn, maven, go modules, cargo, gem, composer, nuget and others.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Operating Systems:&lt;/strong&gt; Detects vulnerabilities in OS packages on Linux systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Containers:&lt;/strong&gt; Scans container images for vulnerabilities in their base images and included packages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Guided Remediation:&lt;/strong&gt; Provides recommendations for package version upgrades based on criteria such as dependency depth, minimum severity, fix strategy, and return on investment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;OSV-Scanner uses the extensible &lt;a href="https://github.com/google/osv-scalibr"&gt;OSV-Scalibr&lt;/a&gt; library under the hood to provide this functionality. If a language or package manager is not supported currently, please file a &lt;a href="https://github.com/google/osv-scanner/issues"&gt;feature request.&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Underlying database&lt;/h4&gt; 
&lt;p&gt;The underlying database, &lt;a href="https://osv.dev/"&gt;OSV.dev&lt;/a&gt; has several benefits in comparison with closed source advisory databases and scanners:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Covering most open source language and OS ecosystems (including &lt;a href="https://osv.dev/list?q=&amp;amp;ecosystem=GIT"&gt;Git&lt;/a&gt;), it‚Äôs comprehensive.&lt;/li&gt; 
 &lt;li&gt;Each advisory comes from an open and authoritative source (e.g. &lt;a href="https://github.com/github/advisory-database"&gt;GitHub Security Advisories&lt;/a&gt;, &lt;a href="https://github.com/rustsec/advisory-db"&gt;RustSec Advisory Database&lt;/a&gt;, &lt;a href="https://github.com/canonical/ubuntu-security-notices/tree/main/osv"&gt;Ubuntu security notices&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Anyone can suggest improvements to advisories, resulting in a very high quality database.&lt;/li&gt; 
 &lt;li&gt;The OSV format unambiguously stores information about affected versions in a machine-readable format that precisely maps onto a developer‚Äôs list of packages&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The above all results in accurate and actionable vulnerability notifications, which reduces the time needed to resolve them. Check out &lt;a href="https://osv.dev/"&gt;OSV.dev&lt;/a&gt; for more details!&lt;/p&gt; 
&lt;h2&gt;Basic installation&lt;/h2&gt; 
&lt;p&gt;To install OSV-Scanner, please refer to the &lt;a href="https://google.github.io/osv-scanner/installation"&gt;installation section&lt;/a&gt; of our documentation. OSV-Scanner releases can be found on the &lt;a href="https://github.com/google/osv-scanner/releases"&gt;releases page&lt;/a&gt; of the GitHub repository. The recommended method is to download a prebuilt binary for your platform. Alternatively, you can use &lt;code&gt;go install github.com/google/osv-scanner/v2/cmd/osv-scanner@latest&lt;/code&gt; to build it from source.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;p&gt;For more information, please read our &lt;a href="https://google.github.io/osv-scanner"&gt;detailed documentation&lt;/a&gt; to learn how to use OSV-Scanner. For detailed information about each feature, click their titles in this README.&lt;/p&gt; 
&lt;p&gt;Please note: These are the instructions for the latest OSV-Scanner V2 beta. If you are using V1, checkout the V1 &lt;a href="https://github.com/google/osv-scanner-v1"&gt;README&lt;/a&gt; and &lt;a href="https://google.github.io/osv-scanner-v1/"&gt;documentation&lt;/a&gt; instead.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://google.github.io/osv-scanner/usage"&gt;Scanning a source directory&lt;/a&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ osv-scanner scan source -r /path/to/your/dir
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command will recursively scan the specified directory for any supported package files, such as &lt;code&gt;package.json&lt;/code&gt;, &lt;code&gt;go.mod&lt;/code&gt;, &lt;code&gt;pom.xml&lt;/code&gt;, etc. and output any discovered vulnerabilities.&lt;/p&gt; 
&lt;p&gt;OSV-Scanner has the option of using call analysis to determine if a vulnerable function is actually being used in the project, resulting in fewer false positives, and actionable alerts.&lt;/p&gt; 
&lt;p&gt;OSV-Scanner can also detect vendored C/C++ code for vulnerability scanning. See &lt;a href="https://google.github.io/osv-scanner/usage/#cc-scanning"&gt;here&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h4&gt;Supported Lockfiles&lt;/h4&gt; 
&lt;p&gt;OSV-Scanner supports 11+ language ecosystems and 19+ lockfile types. To check if your ecosystem is covered, please check out our &lt;a href="https://google.github.io/osv-scanner/supported-languages-and-lockfiles/#supported-lockfiles"&gt;detailed documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://google.github.io/osv-scanner/usage/scan-image"&gt;Container Scanning&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;OSV-Scanner also supports comprehensive, layer-aware scanning for container images to detect vulnerabilities the following operating system packages and language-specific dependencies.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Distro Support&lt;/th&gt; 
   &lt;th&gt;Language Artifacts Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Alpine OS&lt;/td&gt; 
   &lt;td&gt;Go&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Debian&lt;/td&gt; 
   &lt;td&gt;Java&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ubuntu&lt;/td&gt; 
   &lt;td&gt;Node&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Python&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;See the &lt;a href="https://google.github.io/osv-scanner/supported-languages-and-lockfiles/#supported-artifacts"&gt;full documentation&lt;/a&gt; for details on support.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Usage&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ osv-scanner scan image my-image-name:tag
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/8bb95366-27ec-45d1-86ed-e42890f2fb46" alt="screencast of html output of container scanning" /&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://google.github.io/osv-scanner/usage/license-scanning/"&gt;License Scanning&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Check your dependencies' licenses using deps.dev data. For a summary:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;osv-scanner --licenses path/to/repository
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To check against an allowed license list (SPDX format):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;osv-scanner --licenses="MIT,Apache-2.0" path/to/directory
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;a href="https://google.github.io/osv-scanner/usage/offline-mode/"&gt;Offline Scanning&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Scan your project against a local OSV database. No network connection is required after the initial database download. The database can also be manually downloaded.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;osv-scanner --offline --download-offline-databases ./path/to/your/dir
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;a href="https://google.github.io/osv-scanner/experimental/guided-remediation/"&gt;Guided Remediation&lt;/a&gt; (Experimental)&lt;/h3&gt; 
&lt;p&gt;OSV-Scanner provides guided remediation, a feature that suggests package version upgrades based on criteria such as dependency depth, minimum severity, fix strategy, and return on investment. We currently support remediating vulnerabilities in the following files:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Ecosystem&lt;/th&gt; 
   &lt;th align="left"&gt;File Format (Type)&lt;/th&gt; 
   &lt;th align="left"&gt;Supported Remediation Strategies&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;npm&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;package-lock.json&lt;/code&gt; (lockfile)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://google.github.io/osv-scanner/experimental/guided-remediation/#in-place-lockfile-remediation"&gt;&lt;code&gt;in-place&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;npm&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;package.json&lt;/code&gt; (manifest)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://google.github.io/osv-scanner/experimental/guided-remediation/#in-place-lockfile-remediation"&gt;&lt;code&gt;relock&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Maven&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;pom.xml&lt;/code&gt; (manifest)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://google.github.io/osv-scanner/experimental/guided-remediation/#override-dependency-versions"&gt;&lt;code&gt;override&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;This is available as a headless CLI command, as well as an interactive mode.&lt;/p&gt; 
&lt;h4&gt;Example (for npm)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ osv-scanner fix \
    --max-depth=3 \
    --min-severity=5 \
    --ignore-dev  \
    --strategy=in-place \
    -L path/to/package-lock.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Interactive mode (for npm)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ osv-scanner fix \
    -M path/to/package.json \
    -L path/to/package-lock.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;img src="https://google.github.io/osv-scanner/images/guided-remediation-relock-patches.png" alt="Screenshot of the interactive relock results screen with some relaxation patches selected" /&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;h3&gt;Report Problems&lt;/h3&gt; 
&lt;p&gt;If you have what looks like a bug, please use the &lt;a href="https://github.com/google/osv-scanner/issues"&gt;GitHub issue tracking system&lt;/a&gt;. Before you file an issue, please search existing issues to see if your issue is already covered.&lt;/p&gt; 
&lt;h3&gt;Contributing code to &lt;code&gt;osv-scanner&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/google/osv-scanner/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for documentation on how to contribute code.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#google/osv-scanner&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=google/osv-scanner&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tesserato/CodeWeaver</title>
      <link>https://github.com/tesserato/CodeWeaver</link>
      <description>&lt;p&gt;Weave your codebase into a single, navigable Markdown document&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;CodeWeaver: Generate Markdown Documentation from Your Codebase&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://go.dev/"&gt;&lt;img src="https://img.shields.io/badge/Go-00ADD8?style=for-the-badge&amp;amp;logo=go&amp;amp;logoColor=white" alt="Go" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;CodeWeaver is a command-line tool that transforms your codebase into a single, navigable Markdown document. It recursively scans a directory, creating a tree-like representation of your project's file structure and embedding the content of each file within markdown code blocks. This simplifies codebase sharing, documentation, and integration with AI/ML tools by providing a consolidated, readable Markdown output.&lt;/p&gt; 
&lt;p&gt;The output for the current repository can be found &lt;a href="https://github.com/tesserato/CodeWeaver/raw/main/codebase.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Codebase Documentation:&lt;/strong&gt; Generates a Markdown file outlining your project's directory and file structure in a clear, tree-like format.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Content Inclusion:&lt;/strong&gt; Embeds the &lt;em&gt;complete&lt;/em&gt; content of each file within the Markdown document, using code blocks based on file extensions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Path Filtering:&lt;/strong&gt; Uses regular expressions to define &lt;code&gt;include&lt;/code&gt; and / or &lt;code&gt;ignore&lt;/code&gt; patterns, giving you precise control over which files are included.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optional Path Logging:&lt;/strong&gt; Saves lists of included and excluded file paths to separate files for detailed tracking.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Clipboard Integration:&lt;/strong&gt; Optionally copies the generated Markdown to the clipboard for easy pasting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple CLI:&lt;/strong&gt; A straightforward command-line interface with intuitive options.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Using &lt;code&gt;go install&lt;/code&gt; (Recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Requires Go 1.18 or later.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/tesserato/CodeWeaver@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install a specific version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/tesserato/CodeWeaver@vX.Y.Z  # Replace X.Y.Z with the desired version
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;From Pre-built Executables:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Download the appropriate executable for your operating system from the &lt;a href="https://github.com/tesserato/CodeWeaver/releases"&gt;releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After downloading, make the executable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;chmod +x codeweaver  # On Linux/macOS
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codeweaver [options]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For help:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codeweaver -h
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Option&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
   &lt;th align="left"&gt;Default Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;-input &amp;lt;directory&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The root directory to scan.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;.&lt;/code&gt; (current directory)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;-output &amp;lt;filename&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;The name of the output Markdown file.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;codebase.md&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;-ignore "&amp;lt;regex patterns&amp;gt;"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Comma-separated list of regular expressions for paths to &lt;em&gt;exclude&lt;/em&gt;. Example: &lt;code&gt;\.git.*,node_modules,*.log&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;\.git.*&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;-include "&amp;lt;regex patterns&amp;gt;"&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Comma-separated list of regular expressions. &lt;em&gt;Only&lt;/em&gt; paths matching these are &lt;em&gt;included&lt;/em&gt;. Example: &lt;code&gt;\.go$,\.md$&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;None&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;-included-paths-file &amp;lt;filename&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Saves the list of &lt;em&gt;included&lt;/em&gt; paths to this file.&lt;/td&gt; 
   &lt;td align="left"&gt;None&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;-excluded-paths-file &amp;lt;filename&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Saves the list of &lt;em&gt;excluded&lt;/em&gt; paths to this file.&lt;/td&gt; 
   &lt;td align="left"&gt;None&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;-clipboard&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Copies the generated Markdown to the clipboard.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;-version&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Displays the version and exits.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;-help&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Displays this help message and exits.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Understanding &lt;code&gt;-include&lt;/code&gt; and &lt;code&gt;-ignore&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;These flags control which files and directories are included in the generated documentation.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;-ignore&lt;/code&gt; (Blacklist):&lt;/strong&gt; Excludes files/directories matching &lt;em&gt;any&lt;/em&gt; of the provided regular expressions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;-include&lt;/code&gt; (Whitelist):&lt;/strong&gt; &lt;em&gt;Only&lt;/em&gt; includes files/directories matching &lt;em&gt;at least one&lt;/em&gt; of the provided regular expressions. If &lt;code&gt;-include&lt;/code&gt; is used, everything else is &lt;em&gt;excluded&lt;/em&gt; by default.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Behavior Table:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;&lt;code&gt;-ignore&lt;/code&gt;&lt;/th&gt; 
   &lt;th align="left"&gt;&lt;code&gt;-include&lt;/code&gt;&lt;/th&gt; 
   &lt;th align="left"&gt;Behavior&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Includes all files/directories except the input directory itself (&lt;code&gt;.&lt;/code&gt;).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Excludes files/directories matching &lt;code&gt;-ignore&lt;/code&gt;; includes everything else.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;No&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;em&gt;Only&lt;/em&gt; includes files/directories matching &lt;code&gt;-include&lt;/code&gt;. Everything else is excluded.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Yes&lt;/td&gt; 
   &lt;td align="left"&gt;Includes files/directories that match &lt;em&gt;at least one&lt;/em&gt; &lt;code&gt;-include&lt;/code&gt; pattern AND do &lt;em&gt;not&lt;/em&gt; match &lt;em&gt;any&lt;/em&gt; &lt;code&gt;-ignore&lt;/code&gt; pattern. &lt;code&gt;-include&lt;/code&gt; creates a whitelist, and &lt;code&gt;-ignore&lt;/code&gt; filters it.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Basic Usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codeweaver
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Creates &lt;code&gt;codebase.md&lt;/code&gt; in the current directory, documenting the structure and content (excluding paths matching the default ignore pattern &lt;code&gt;\.git.*&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Different Input/Output:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codeweaver -input=my_project -output=project_docs.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Processes &lt;code&gt;my_project&lt;/code&gt; and saves the output to &lt;code&gt;project_docs.md&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. Ignoring Files/Directories:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codeweaver -ignore="\.log,temp,build"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Excludes files/directories named &lt;code&gt;.log&lt;/code&gt;, &lt;code&gt;temp&lt;/code&gt;, or &lt;code&gt;build&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;4. Including Only Specific Files:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codeweaver -include="\.go$,\.md$"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Includes &lt;em&gt;only&lt;/em&gt; Go (&lt;code&gt;.go&lt;/code&gt;) and Markdown (&lt;code&gt;.md&lt;/code&gt;) files.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;5. Combining &lt;code&gt;include&lt;/code&gt; and &lt;code&gt;ignore&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codeweaver -include="\.go$,\.md$" -ignore="vendor,test"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Includes Go and Markdown files, &lt;em&gt;except&lt;/em&gt; those with "vendor" or "test" in their paths.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;6. Saving Included/Excluded Paths:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codeweaver -ignore="node_modules" -included-paths-file=included.txt -excluded-paths-file=excluded.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Creates &lt;code&gt;codebase.md&lt;/code&gt;, saves included paths to &lt;code&gt;included.txt&lt;/code&gt;, and excluded paths to &lt;code&gt;excluded.txt&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;7. Copying to Clipboard:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codeweaver -clipboard
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Creates &lt;code&gt;codebase.md&lt;/code&gt; and copies its content to the clipboard.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;8. Regex Examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;.&lt;/code&gt;: Matches any single character.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;*&lt;/code&gt;: Matches zero or more of the preceding character.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;+&lt;/code&gt;: Matches one or more of the preceding character.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;?&lt;/code&gt;: Matches zero or one of the preceding character.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[abc]&lt;/code&gt;: Matches any one of the characters inside the brackets.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[^abc]&lt;/code&gt;: Matches any character &lt;em&gt;not&lt;/em&gt; inside the brackets.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[a-z]&lt;/code&gt;: Matches any character in the range a-z.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;^&lt;/code&gt;: Matches the beginning of the string.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$&lt;/code&gt;: Matches the end of the string.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;\.&lt;/code&gt;: Matches a literal dot (.). You need to escape it because &lt;code&gt;.&lt;/code&gt; has special meaning in regex.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;\|&lt;/code&gt;: Used for alternation (OR). e.g., &lt;code&gt;a\|b&lt;/code&gt; matches either "a" or "b".&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.*\.py[cod]$&lt;/code&gt;: matches python files that end with pyc, pyd or pyo.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.*\.pdf&lt;/code&gt;: matches PDF files.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;(dir1\|dir2)&lt;/code&gt;: matches &lt;code&gt;dir1&lt;/code&gt; or &lt;code&gt;dir2&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;9. Complete example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;codeweaver -input=. -output=codebase.md -ignore="\.git.*,.+\.exe,codebase.md,excluded_paths.txt" -include="\.go$,\.md$,\.ps1$,\.yaml$,\.txt$,\.csv$" -excluded-paths-file="excluded_paths.txt" -clipboard
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Process the current directory (&lt;code&gt;.&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;Generate documentation and save it in &lt;code&gt;codebase.md&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Exclude files matching &lt;code&gt;.git.*&lt;/code&gt;, &lt;code&gt;.+\.exe&lt;/code&gt;, the output file (&lt;code&gt;codebase.md&lt;/code&gt;), and the file where the excluded paths will be saved.&lt;/li&gt; 
 &lt;li&gt;Include &lt;em&gt;only&lt;/em&gt; files with the extensions .go, .md, .ps1, .yaml, .txt, and .csv.&lt;/li&gt; 
 &lt;li&gt;Save the list of excluded files in a file named &lt;code&gt;excluded_paths.txt&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Copy the generated Markdown to the system clipboard.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please open an issue or submit a pull request on the project's GitHub repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;CodeWeaver is released under the &lt;a href="https://raw.githubusercontent.com/tesserato/CodeWeaver/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#tesserato/CodeWeaver&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=tesserato/CodeWeaver&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Alternatives&lt;/h2&gt; 
&lt;p&gt;This section lists tools with similar or overlapping functionality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GitHub Repositories&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Project&lt;/th&gt; 
   &lt;th align="left"&gt;Stars&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/tanq16/ai-context"&gt;ai-context&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/tanq16/ai-context"&gt;&lt;img src="https://img.shields.io/github/stars/tanq16/ai-context?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/manfrin/bundle-codebases"&gt;bundle-codebases&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/manfrin/bundle-codebases"&gt;&lt;img src="https://img.shields.io/github/stars/manfrin/bundle-codebases?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/mufeedvh/code2prompt"&gt;code2prompt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/mufeedvh/code2prompt"&gt;&lt;img src="https://img.shields.io/github/stars/mufeedvh/code2prompt?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/forrest321/code2text"&gt;code2text&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/forrest321/code2text"&gt;&lt;img src="https://img.shields.io/github/stars/forrest321/code2text?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/regenrek/codefetch"&gt;codefetch&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/regenrek/codefetch"&gt;&lt;img src="https://img.shields.io/github/stars/regenrek/codefetch?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/kasperjunge/copcon"&gt;copcon&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/kasperjunge/copcon"&gt;&lt;img src="https://img.shields.io/github/stars/kasperjunge/copcon?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/rodlaf/describe"&gt;describe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/rodlaf/describe"&gt;&lt;img src="https://img.shields.io/github/stars/rodlaf/describe?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nahco314/feed-llm"&gt;feed-llm&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nahco314/feed-llm"&gt;&lt;img src="https://img.shields.io/github/stars/nahco314/feed-llm?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/simonw/files-to-prompt"&gt;files-to-prompt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/simonw/files-to-prompt"&gt;&lt;img src="https://img.shields.io/github/stars/simonw/files-to-prompt?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/keizo/ggrab"&gt;ggrab&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/keizo/ggrab"&gt;&lt;img src="https://img.shields.io/github/stars/keizo/ggrab?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gitingest.com/"&gt;gitingest&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/cyclotruc/gitingest"&gt;&lt;img src="https://img.shields.io/github/stars/cyclotruc/gitingest?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gitpodcast.com"&gt;gitpodcast&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/BandarLabs/gitpodcast"&gt;&lt;img src="https://img.shields.io/github/stars/BandarLabs/gitpodcast?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/jzombie/globcat.sh"&gt;globcat.sh&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/jzombie/globcat.sh"&gt;&lt;img src="https://img.shields.io/github/stars/jzombie/globcat.sh?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/foresturquhart/grimoire"&gt;grimoire&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/foresturquhart/grimoire"&gt;&lt;img src="https://img.shields.io/github/stars/foresturquhart/grimoire?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/azer/llmcat"&gt;llmcat&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/azer/llmcat"&gt;&lt;img src="https://img.shields.io/github/stars/azer/llmcat?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yamadashy/repomix"&gt;RepoMix&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yamadashy/repomix"&gt;&lt;img src="https://img.shields.io/github/stars/yamadashy/repomix?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/glebkudr/shotgun_code/"&gt;RepoMix&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/glebkudr/shotgun_code/"&gt;&lt;img src="https://img.shields.io/github/stars/glebkudr/shotgun_code?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/thesurlydev/techdocs"&gt;techdocs&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/thesurlydev/techdocs"&gt;&lt;img src="https://img.shields.io/github/stars/thesurlydev/techdocs?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/franzenzenhofer/thisismy"&gt;thisismy&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/franzenzenhofer/thisismy"&gt;&lt;img src="https://img.shields.io/github/stars/franzenzenhofer/thisismy?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/bodo-run/yek"&gt;yek&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/bodo-run/yek"&gt;&lt;img src="https://img.shields.io/github/stars/bodo-run/yek?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/Dicklesworthstone/your-source-to-prompt.html"&gt;your-source-to-prompt&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/Dicklesworthstone/your-source-to-prompt"&gt;&lt;img src="https://img.shields.io/github/stars/Dicklesworthstone/your-source-to-prompt.html?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/sammcj/ingest"&gt;ingest&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/sammcj/ingest"&gt;&lt;img src="https://img.shields.io/github/stars/sammcj/ingest?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/jimmc414/onefilellm"&gt;onefilellm&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/jimmc414/onefilellm"&gt;&lt;img src="https://img.shields.io/github/stars/jimmc414/onefilellm?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/artkulak/repo2file"&gt;repo2file&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/artkulak/repo2file"&gt;&lt;img src="https://img.shields.io/github/stars/artkulak/repo2file?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/strizzo/clipsource"&gt;clipsource&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/strizzo/clipsource"&gt;&lt;img src="https://img.shields.io/github/stars/strizzo/clipsource?style=social" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Other Tools&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;r2md:&lt;/strong&gt; A Rust crate (&lt;a href="https://crates.io/crates/r2md"&gt;https://crates.io/crates/r2md&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;repo2txt:&lt;/strong&gt; A web-based tool (&lt;a href="https://chathub.gg/repo2txt"&gt;https://chathub.gg/repo2txt&lt;/a&gt; and &lt;a href="https://repo2txt.simplebasedomain.com/local.html"&gt;https://repo2txt.simplebasedomain.com/local.html&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;repoprompt:&lt;/strong&gt; A web service (&lt;a href="https://www.repoprompt.com"&gt;https://www.repoprompt.com&lt;/a&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;VSCode Extensions&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Codebase to Markdown:&lt;/strong&gt; (&lt;a href="https://marketplace.visualstudio.com/items?itemName=DVYIO.combine-open-files"&gt;https://marketplace.visualstudio.com/items?itemName=DVYIO.combine-open-files&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>minio/minio</title>
      <link>https://github.com/minio/minio</link>
      <description>&lt;p&gt;MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Maintenance Mode&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;This project is currently under maintenance and is not accepting new changes.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The codebase is in a maintenance-only state&lt;/li&gt; 
 &lt;li&gt;No new features, enhancements, or pull requests will be accepted&lt;/li&gt; 
 &lt;li&gt;Critical security fixes may be evaluated on a case-by-case basis&lt;/li&gt; 
 &lt;li&gt;Existing issues and pull requests will not be actively reviewed&lt;/li&gt; 
 &lt;li&gt;Community support continues on a best-effort basis through &lt;a href="https://slack.min.io"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For enterprise support and actively maintained versions, please see &lt;a href="https://www.min.io/product/aistor"&gt;MinIO AIStor&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;MinIO Quickstart Guide&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://slack.min.io"&gt;&lt;img src="https://slack.min.io/slack?type=svg" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/minio/minio/"&gt;&lt;img src="https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL%20V3-blue" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://min.io"&gt;&lt;img src="https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true" alt="MinIO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license. Designed for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;S3 API Compatible ‚Äì Seamless integration with existing S3 tools&lt;/li&gt; 
 &lt;li&gt;Built for AI &amp;amp; Analytics ‚Äì Optimized for large-scale data pipelines&lt;/li&gt; 
 &lt;li&gt;High Performance ‚Äì Ideal for demanding storage workloads.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This README provides instructions for building MinIO from source and deploying onto baremetal hardware. Use the &lt;a href="https://github.com/minio/docs"&gt;MinIO Documentation&lt;/a&gt; project to build and host a local copy of the documentation.&lt;/p&gt; 
&lt;h2&gt;MinIO is Open Source Software&lt;/h2&gt; 
&lt;p&gt;We designed MinIO as Open Source software for the Open Source software community. We encourage the community to remix, redesign, and reshare MinIO under the terms of the AGPLv3 license.&lt;/p&gt; 
&lt;p&gt;All usage of MinIO in your application stack requires validation against AGPLv3 obligations, which include but are not limited to the release of modified code to the community from which you have benefited. Any commercial/proprietary usage of the AGPLv3 software, including repackaging or reselling services/features, is done at your own risk.&lt;/p&gt; 
&lt;p&gt;The AGPLv3 provides no obligation by any party to support, maintain, or warranty the original or any modified work. All support is provided on a best-effort basis through Github and our &lt;a href="https://raw.githubusercontent.com/minio/minio/master/https//slack.min.io"&gt;Slack&lt;/a&gt; channel, and any member of the community is welcome to contribute and assist others in their usage of the software.&lt;/p&gt; 
&lt;p&gt;MinIO &lt;a href="https://www.min.io/product/aistor"&gt;AIStor&lt;/a&gt; includes enterprise-grade support and licensing for workloads which require commercial or proprietary usage and production-level SLA/SLO-backed support. For more information, &lt;a href="https://min.io/pricing"&gt;reach out for a quote&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Source-Only Distribution&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The MinIO community edition is now distributed as source code only. We will no longer provide pre-compiled binary releases for the community version.&lt;/p&gt; 
&lt;h3&gt;Installing Latest MinIO Community Edition&lt;/h3&gt; 
&lt;p&gt;To use MinIO community edition, you have two options:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install from source&lt;/strong&gt; using &lt;code&gt;go install github.com/minio/minio@latest&lt;/code&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build a Docker image&lt;/strong&gt; from the provided Dockerfile&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the sections below for detailed instructions on each method.&lt;/p&gt; 
&lt;h3&gt;Legacy Binary Releases&lt;/h3&gt; 
&lt;p&gt;Historical pre-compiled binary releases remain available for reference but are no longer maintained:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub Releases: &lt;a href="https://github.com/minio/minio/releases"&gt;https://github.com/minio/minio/releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Direct downloads: &lt;a href="https://dl.min.io/server/minio/release/"&gt;https://dl.min.io/server/minio/release/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;These legacy binaries will not receive updates.&lt;/strong&gt; We strongly recommend using source builds for access to the latest features, bug fixes, and security updates.&lt;/p&gt; 
&lt;h2&gt;Install from Source&lt;/h2&gt; 
&lt;p&gt;Use the following commands to compile and run a standalone MinIO server from source. If you do not have a working Golang environment, please follow &lt;a href="https://golang.org/doc/install"&gt;How to install Golang&lt;/a&gt;. Minimum version required is &lt;a href="https://golang.org/dl/#stable"&gt;go1.24&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/minio/minio@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can alternatively run &lt;code&gt;go build&lt;/code&gt; and use the &lt;code&gt;GOOS&lt;/code&gt; and &lt;code&gt;GOARCH&lt;/code&gt; environment variables to control the OS and architecture target. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env GOOS=linux GOARCh=arm64 go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start MinIO by running &lt;code&gt;minio server PATH&lt;/code&gt; where &lt;code&gt;PATH&lt;/code&gt; is any empty folder on your local filesystem.&lt;/p&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://docs.min.io/enterprise/aistor-object-store/developers/sdk/"&gt;https://docs.min.io/enterprise/aistor-object-store/developers/sdk/&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Production environments using compiled-from-source MinIO binaries do so at their own risk. The AGPLv3 license provides no warranties nor liabilites for any such usage.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Build Docker Image&lt;/h2&gt; 
&lt;p&gt;You can use the &lt;code&gt;docker build .&lt;/code&gt; command to build a Docker image on your local host machine. You must first &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#install-from-source"&gt;build MinIO&lt;/a&gt; and ensure the &lt;code&gt;minio&lt;/code&gt; binary exists in the project root.&lt;/p&gt; 
&lt;p&gt;The following command builds the Docker image using the default &lt;code&gt;Dockerfile&lt;/code&gt; in the root project directory with the repository and image tag &lt;code&gt;myminio:minio&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t myminio:minio .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;docker image ls&lt;/code&gt; to confirm the image exists in your local repository. You can run the server using standard Docker invocation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run -p 9000:9000 -p 9001:9001 myminio:minio server /tmp/minio --console-address :9001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Complete documentation for building Docker containers, managing custom images, or loading images into orchestration platforms is out of scope for this documentation. You can modify the &lt;code&gt;Dockerfile&lt;/code&gt; and &lt;code&gt;dockerscripts/docker-entrypoint.sh&lt;/code&gt; as-needed to reflect your specific image requirements.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/baremetal-deploy-minio-as-a-container.html#deploy-minio-container"&gt;MinIO Container&lt;/a&gt; documentation for more guidance on running MinIO within a Container image.&lt;/p&gt; 
&lt;h2&gt;Install using Helm Charts&lt;/h2&gt; 
&lt;p&gt;There are two paths for installing MinIO onto Kubernetes infrastructure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;a href="https://github.com/minio/operator"&gt;MinIO Operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use the community-maintained &lt;a href="https://github.com/minio/minio/tree/master/helm/minio"&gt;Helm charts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/kubernetes.html"&gt;MinIO Documentation&lt;/a&gt; for guidance on deploying using the Operator. The Community Helm chart has instructions in the folder-level README.&lt;/p&gt; 
&lt;h2&gt;Test MinIO Connectivity&lt;/h2&gt; 
&lt;h3&gt;Test using MinIO Console&lt;/h3&gt; 
&lt;p&gt;MinIO Server comes with an embedded web based object browser. Point your web browser to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; to ensure your server has started successfully.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MinIO runs console on random port by default, if you wish to choose a specific port use &lt;code&gt;--console-address&lt;/code&gt; to pick a specific interface and port.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;mc&lt;/code&gt; provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services.&lt;/p&gt; 
&lt;p&gt;The following commands set a local alias, validate the server information, create a bucket, copy data to that bucket, and list the contents of the bucket.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info
mc mb data
mc cp ~/Downloads/mydata data/
mc ls data/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the MinIO Client &lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html#quickstart"&gt;Quickstart Guide&lt;/a&gt; for further instructions.&lt;/p&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/index.html"&gt;The MinIO documentation website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html"&gt;Use &lt;code&gt;mc&lt;/code&gt; with MinIO Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/enterprise/aistor-object-store/developers/sdk/go/"&gt;Use &lt;code&gt;minio-go&lt;/code&gt; SDK with MinIO Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute to MinIO Project&lt;/h2&gt; 
&lt;p&gt;Please follow MinIO &lt;a href="https://github.com/minio/minio/raw/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt; for guidance on making new contributions to the repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MinIO source is licensed under the &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;GNU AGPLv3&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;MinIO &lt;a href="https://github.com/minio/minio/tree/master/docs"&gt;documentation&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;CC BY 4.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/minio/minio/raw/master/COMPLIANCE.md"&gt;License Compliance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>cloudreve/cloudreve</title>
      <link>https://github.com/cloudreve/cloudreve</link>
      <description>&lt;p&gt;üå© Self-hosted file management and sharing system, supports multiple storage providers&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/cloudreve/Cloudreve/raw/master/README_zh-CN.md"&gt;‰∏≠ÊñáÁâàÊú¨&lt;/a&gt;&lt;/p&gt; 
&lt;h1 align="center"&gt; &lt;br /&gt; &lt;a href="https://cloudreve.org/" alt="logo"&gt;&lt;img src="https://raw.githubusercontent.com/cloudreve/frontend/master/public/static/img/logo192.png" width="150" /&gt;&lt;/a&gt; &lt;br /&gt; Cloudreve &lt;br /&gt; &lt;/h1&gt; 
&lt;h4 align="center"&gt;Self-hosted file management system with multi-cloud support.&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a href="https://dev.azure.com/abslantliu/Cloudreve/_build?definitionId=6"&gt; &lt;img src="https://dev.azure.com/abslantliu/Cloudreve/_apis/build/status%2Fcloudreve.Cloudreve?branchName=refs%2Fpull%2F2481%2Fmerge" alt="Azure pipelines" /&gt; &lt;/a&gt; &lt;a href="https://github.com/cloudreve/Cloudreve/releases"&gt; &lt;img src="https://img.shields.io/github/v/release/cloudreve/Cloudreve?include_prereleases" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/cloudreve/cloudreve"&gt; &lt;img src="https://img.shields.io/docker/image-size/cloudreve/cloudreve" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/cloudreve/cloudreve"&gt; &lt;img alt="Docker Pulls" src="https://img.shields.io/docker/pulls/cloudreve/cloudreve" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://cloudreve.org"&gt;Homepage&lt;/a&gt; ‚Ä¢ &lt;a href="https://demo.cloudreve.org"&gt;Try it&lt;/a&gt; ‚Ä¢ &lt;a href="https://github.com/cloudreve/cloudreve/discussions"&gt;Discussion&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.cloudreve.org"&gt;Documents&lt;/a&gt; ‚Ä¢ &lt;a href="https://github.com/cloudreve/Cloudreve/releases"&gt;Download&lt;/a&gt; ‚Ä¢ &lt;a href="https://t.me/cloudreve_official"&gt;Telegram&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.com/invite/WTpMFpZT76"&gt;Discord&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudreve/docs/master/images/homepage.png" alt="Screenshot" /&gt;&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;‚ú®&lt;/span&gt; Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;span&gt;‚òÅ&lt;/span&gt; Support storing files into Local, Remote node, OneDrive, S3 compatible API, Qiniu Kodo, Aliyun OSS, Tencent COS, Huawei Cloud OBS, Kingsoft Cloud KS3, Upyun.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üì§&lt;/span&gt; Upload/Download in directly transmission from client to storage providers.&lt;/li&gt; 
 &lt;li&gt;üíæ Integrate with Aria2/qBittorrent to download files in background, use multiple download nodes to share the load.&lt;/li&gt; 
 &lt;li&gt;üìö Compress/Extract/Preview archived files, download files in batch.&lt;/li&gt; 
 &lt;li&gt;üíª WebDAV support covering all storage providers.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;‚ö°&lt;/span&gt;Drag&amp;amp;Drop to upload files or folders, with parallel resumable upload support.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üóÉ&lt;/span&gt; Extract media metadata from files, search files by metadata or tags.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üë©üëßüë¶&lt;/span&gt; Multi-users with multi-groups.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üîó&lt;/span&gt; Create share links for files and folders with expiration date.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üëÅüó®&lt;/span&gt; Preview videos, images, audios, ePub files online; edit texts, diagrams, Markdown, images, Office documents online.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üé®&lt;/span&gt; Customize theme colors, dark mode, PWA application, SPA, i18n.&lt;/li&gt; 
 &lt;li&gt;&lt;span&gt;üöÄ&lt;/span&gt; All-in-one packaging, with all features out of the box.&lt;/li&gt; 
 &lt;li&gt;üåà ... ...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;üõ†&lt;/span&gt; Deploy&lt;/h2&gt; 
&lt;p&gt;To deploy Cloudreve, you can refer to &lt;a href="https://docs.cloudreve.org/overview/quickstart"&gt;Getting started&lt;/a&gt; for a quick local deployment to test.&lt;/p&gt; 
&lt;p&gt;When you're ready to deploy Cloudreve to a production environment, you can refer to &lt;a href="https://docs.cloudreve.org/overview/deploy/"&gt;Deploy&lt;/a&gt; for a complete deployment.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;‚öô&lt;/span&gt; Build&lt;/h2&gt; 
&lt;p&gt;Please refer to &lt;a href="https://docs.cloudreve.org/overview/build/"&gt;Build&lt;/a&gt; for how to build Cloudreve from source code.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;üöÄ&lt;/span&gt; Contributing&lt;/h2&gt; 
&lt;p&gt;If you're interested in contributing to Cloudreve, please refer to &lt;a href="https://docs.cloudreve.org/api/contributing/"&gt;Contributing&lt;/a&gt; for how to contribute to Cloudreve.&lt;/p&gt; 
&lt;h2&gt;&lt;span&gt;‚öó&lt;/span&gt; Stacks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://golang.org/"&gt;Go&lt;/a&gt; + &lt;a href="https://github.com/gin-gonic/gin"&gt;Gin&lt;/a&gt; + &lt;a href="https://github.com/ent/ent"&gt;ent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/facebook/react"&gt;React&lt;/a&gt; + &lt;a href="https://github.com/reduxjs/redux"&gt;Redux&lt;/a&gt; + &lt;a href="https://github.com/mui-org/material-ui"&gt;Material-UI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;üìú&lt;/span&gt; License&lt;/h2&gt; 
&lt;p&gt;GPL V3&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>livekit/livekit</title>
      <link>https://github.com/livekit/livekit</link>
      <description>&lt;p&gt;End-to-end realtime stack for connecting humans and AI&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="/.github/banner_dark.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="/.github/banner_light.png" /&gt; 
 &lt;img style="width:100%;" alt="The LiveKit icon, the name of the repository and some sample code in the background." src="https://raw.githubusercontent.com/livekit/livekit/main/.github/banner_light.png" /&gt; 
&lt;/picture&gt; 
&lt;!--END_BANNER_IMAGE--&gt; 
&lt;h1&gt;LiveKit: Real-time video, audio and data for developers&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://livekit.io"&gt;LiveKit&lt;/a&gt; is an open source project that provides scalable, multi-user conferencing based on WebRTC. It's designed to provide everything you need to build real-time video audio data capabilities in your applications.&lt;/p&gt; 
&lt;p&gt;LiveKit's server is written in Go, using the awesome &lt;a href="https://github.com/pion/webrtc"&gt;Pion WebRTC&lt;/a&gt; implementation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/livekit/livekit/stargazers/"&gt;&lt;img src="https://img.shields.io/github/stars/livekit/livekit?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://livekit.io/join-slack"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Flivekit.io%2Fbadges%2Fslack" alt="Slack community" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/livekit"&gt;&lt;img src="https://img.shields.io/twitter/follow/livekit" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/livekit/livekit"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://github.com/livekit/livekit/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/livekit/livekit" alt="GitHub release (latest SemVer)" /&gt;&lt;/a&gt; &lt;a href="https://github.com/livekit/livekit/actions/workflows/buildtest.yaml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/livekit/livekit/buildtest.yaml?branch=master" alt="GitHub Workflow Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/livekit/livekit/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/livekit/livekit" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Scalable, distributed WebRTC SFU (Selective Forwarding Unit)&lt;/li&gt; 
 &lt;li&gt;Modern, full-featured client SDKs&lt;/li&gt; 
 &lt;li&gt;Built for production, supports JWT authentication&lt;/li&gt; 
 &lt;li&gt;Robust networking and connectivity, UDP/TCP/TURN&lt;/li&gt; 
 &lt;li&gt;Easy to deploy: single binary, Docker or Kubernetes&lt;/li&gt; 
 &lt;li&gt;Advanced features including: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.livekit.io/home/client/tracks/subscribe/#speaker-detection"&gt;speaker detection&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.livekit.io/home/client/tracks/publish/#video-simulcast"&gt;simulcast&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://blog.livekit.io/livekit-one-dot-zero/"&gt;end-to-end optimizations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.livekit.io/home/client/tracks/subscribe/#selective-subscription"&gt;selective subscription&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.livekit.io/home/server/managing-participants/"&gt;moderation APIs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;end-to-end encryption&lt;/li&gt; 
   &lt;li&gt;SVC codecs (VP9, AV1)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.livekit.io/home/server/webhooks/"&gt;webhooks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.livekit.io/home/self-hosting/distributed/"&gt;distributed and multi-region&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation &amp;amp; Guides&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://docs.livekit.io"&gt;https://docs.livekit.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Live Demos&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://meet.livekit.io"&gt;LiveKit Meet&lt;/a&gt; (&lt;a href="https://github.com/livekit-examples/meet"&gt;source&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://spatial-audio-demo.livekit.io/"&gt;Spatial Audio&lt;/a&gt; (&lt;a href="https://github.com/livekit-examples/spatial-audio"&gt;source&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Livestreaming from OBS Studio (&lt;a href="https://github.com/livekit-examples/livestream"&gt;source&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://livekit.io/kitt"&gt;AI voice assistant using ChatGPT&lt;/a&gt; (&lt;a href="https://github.com/livekit-examples/kitt"&gt;source&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/livekit/agents"&gt;Agents&lt;/a&gt;: build real-time multimodal AI applications with programmable backend participants&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/livekit/egress"&gt;Egress&lt;/a&gt;: record or multi-stream rooms and export individual tracks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/livekit/ingress"&gt;Ingress&lt;/a&gt;: ingest streams from external sources like RTMP, WHIP, HLS, or OBS Studio&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;SDKs &amp;amp; Tools&lt;/h2&gt; 
&lt;h3&gt;Client SDKs&lt;/h3&gt; 
&lt;p&gt;Client SDKs enable your frontend to include interactive, multi-user experiences.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th&gt;Language&lt;/th&gt; 
   &lt;th&gt;Repo&lt;/th&gt; 
   &lt;th&gt; &lt;a href="https://docs.livekit.io/home/client/events/#declarative-ui" target="_blank" rel="noopener noreferrer"&gt;Declarative UI&lt;/a&gt; &lt;/th&gt; 
   &lt;th&gt;Links&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;!-- BEGIN Template
  &lt;tr&gt;
    &lt;td&gt;Language&lt;/td&gt;
    &lt;td&gt;
      &lt;a href="" target="_blank" rel="noopener noreferrer"&gt;&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  END --&gt; 
  &lt;!-- JavaScript --&gt; 
  &lt;tr&gt; 
   &lt;td&gt;JavaScript (TypeScript)&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/livekit/client-sdk-js" target="_blank" rel="noopener noreferrer"&gt;client-sdk-js&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/livekit/livekit-react" target="_blank" rel="noopener noreferrer"&gt;React&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://docs.livekit.io/client-sdk-js/" target="_blank" rel="noopener noreferrer"&gt;docs&lt;/a&gt; | &lt;a href="https://github.com/livekit/client-sdk-js/tree/main/example" target="_blank" rel="noopener noreferrer"&gt;JS example&lt;/a&gt; | &lt;a href="https://github.com/livekit/client-sdk-js/tree/main/example" target="_blank" rel="noopener noreferrer"&gt;React example&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;!-- Swift --&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Swift (iOS / MacOS)&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/livekit/client-sdk-swift" target="_blank" rel="noopener noreferrer"&gt;client-sdk-swift&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Swift UI&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://docs.livekit.io/client-sdk-swift/" target="_blank" rel="noopener noreferrer"&gt;docs&lt;/a&gt; | &lt;a href="https://github.com/livekit/client-example-swift" target="_blank" rel="noopener noreferrer"&gt;example&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;!-- Kotlin --&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Kotlin (Android)&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/livekit/client-sdk-android" target="_blank" rel="noopener noreferrer"&gt;client-sdk-android&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;Compose&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://docs.livekit.io/client-sdk-android/index.html" target="_blank" rel="noopener noreferrer"&gt;docs&lt;/a&gt; | &lt;a href="https://github.com/livekit/client-sdk-android/tree/main/sample-app/src/main/java/io/livekit/android/sample" target="_blank" rel="noopener noreferrer"&gt;example&lt;/a&gt; | &lt;a href="https://github.com/livekit/client-sdk-android/tree/main/sample-app-compose/src/main/java/io/livekit/android/composesample" target="_blank" rel="noopener noreferrer"&gt;Compose example&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;!-- Flutter --&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Flutter (all platforms)&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/livekit/client-sdk-flutter" target="_blank" rel="noopener noreferrer"&gt;client-sdk-flutter&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;native&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://docs.livekit.io/client-sdk-flutter/" target="_blank" rel="noopener noreferrer"&gt;docs&lt;/a&gt; | &lt;a href="https://github.com/livekit/client-sdk-flutter/tree/main/example" target="_blank" rel="noopener noreferrer"&gt;example&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;!-- Unity --&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Unity WebGL&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/livekit/client-sdk-unity-web" target="_blank" rel="noopener noreferrer"&gt;client-sdk-unity-web&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://livekit.github.io/client-sdk-unity-web/" target="_blank" rel="noopener noreferrer"&gt;docs&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;!-- React Native --&gt; 
  &lt;tr&gt; 
   &lt;td&gt;React Native (beta)&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/livekit/client-sdk-react-native" target="_blank" rel="noopener noreferrer"&gt;client-sdk-react-native&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;native&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;!-- Rust --&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Rust&lt;/td&gt; 
   &lt;td&gt; &lt;a href="https://github.com/livekit/client-sdk-rust" target="_blank" rel="noopener noreferrer"&gt;client-sdk-rust&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;Server SDKs&lt;/h3&gt; 
&lt;p&gt;Server SDKs enable your backend to generate &lt;a href="https://docs.livekit.io/home/get-started/authentication/"&gt;access tokens&lt;/a&gt;, call &lt;a href="https://docs.livekit.io/reference/server/server-apis/"&gt;server APIs&lt;/a&gt;, and receive &lt;a href="https://docs.livekit.io/home/server/webhooks/"&gt;webhooks&lt;/a&gt;. In addition, the Go SDK includes client capabilities, enabling you to build automations that behave like end-users.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Language&lt;/th&gt; 
   &lt;th align="left"&gt;Repo&lt;/th&gt; 
   &lt;th align="left"&gt;Docs&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Go&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/livekit/server-sdk-go"&gt;server-sdk-go&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/livekit/server-sdk-go"&gt;docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;JavaScript (TypeScript)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/livekit/server-sdk-js"&gt;server-sdk-js&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://docs.livekit.io/server-sdk-js/"&gt;docs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Ruby&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/livekit/server-sdk-ruby"&gt;server-sdk-ruby&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Java (Kotlin)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/livekit/server-sdk-kotlin"&gt;server-sdk-kotlin&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Python (community)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/livekit/python-sdks"&gt;python-sdks&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;PHP (community)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/agence104/livekit-server-sdk-php"&gt;agence104/livekit-server-sdk-php&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/livekit/livekit-cli"&gt;CLI&lt;/a&gt; - command line interface &amp;amp; load tester&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/r/livekit/livekit-server"&gt;Docker image&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/livekit/livekit-helm"&gt;Helm charts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] We recommend installing &lt;a href="https://github.com/livekit/livekit-cli"&gt;LiveKit CLI&lt;/a&gt; along with the server. It lets you access server APIs, create tokens, and generate test traffic.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The following will install LiveKit's media server:&lt;/p&gt; 
&lt;h3&gt;MacOS&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install livekit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl -sSL https://get.livekit.io | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;p&gt;Download the &lt;a href="https://github.com/livekit/livekit/releases/latest"&gt;latest release here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Starting LiveKit&lt;/h3&gt; 
&lt;p&gt;Start LiveKit in development mode by running &lt;code&gt;livekit-server --dev&lt;/code&gt;. It'll use a placeholder API key/secret pair.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;API Key: devkey
API Secret: secret
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To customize your setup for production, refer to our &lt;a href="https://docs.livekit.io/deploy/"&gt;deployment docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Creating access token&lt;/h3&gt; 
&lt;p&gt;A user connecting to a LiveKit room requires an &lt;a href="https://docs.livekit.io/home/get-started/authentication/#creating-a-token"&gt;access token&lt;/a&gt;. Access tokens (JWT) encode the user's identity and the room permissions they've been granted. You can generate a token with our CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;lk token create \
    --api-key devkey --api-secret secret \
    --join --room my-first-room --identity user1 \
    --valid-for 24h
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Test with example app&lt;/h3&gt; 
&lt;p&gt;Head over to our &lt;a href="https://example.livekit.io"&gt;example app&lt;/a&gt; and enter a generated token to connect to your LiveKit server. This app is built with our &lt;a href="https://github.com/livekit/livekit-react"&gt;React SDK&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Once connected, your video and audio are now being published to your new LiveKit instance!&lt;/p&gt; 
&lt;h3&gt;Simulating a test publisher&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;lk room join \
    --url ws://localhost:7880 \
    --api-key devkey --api-secret secret \
    --identity bot-user1 \
    --publish-demo \
    my-first-room
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command publishes a looped demo video to a room. Due to how the video clip was encoded (keyframes every 3s), there's a slight delay before the browser has sufficient data to begin rendering frames. This is an artifact of the simulation.&lt;/p&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;h3&gt;Use LiveKit Cloud&lt;/h3&gt; 
&lt;p&gt;LiveKit Cloud is the fastest and most reliable way to run LiveKit. Every project gets free monthly bandwidth and transcoding credits.&lt;/p&gt; 
&lt;p&gt;Sign up for &lt;a href="https://cloud.livekit.io/"&gt;LiveKit Cloud&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Self-host&lt;/h3&gt; 
&lt;p&gt;Read our &lt;a href="https://docs.livekit.io/deploy/"&gt;deployment docs&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Building from source&lt;/h2&gt; 
&lt;p&gt;Pre-requisites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go 1.23+ is installed&lt;/li&gt; 
 &lt;li&gt;GOPATH/bin is in your PATH&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/livekit/livekit
cd livekit
./bootstrap.sh
mage
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome your contributions toward improving LiveKit! Please join us &lt;a href="http://livekit.io/join-slack"&gt;on Slack&lt;/a&gt; to discuss your ideas and/or PRs.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;LiveKit server is licensed under Apache License v2.0.&lt;/p&gt; 
&lt;!--BEGIN_REPO_NAV--&gt; 
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;table&gt; 
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th colspan="2"&gt;LiveKit Ecosystem&lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt;
   &lt;td&gt;LiveKit SDKs&lt;/td&gt;
   &lt;td&gt;&lt;a href="https://github.com/livekit/client-sdk-js"&gt;Browser&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/client-sdk-swift"&gt;iOS/macOS/visionOS&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/client-sdk-android"&gt;Android&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/client-sdk-flutter"&gt;Flutter&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/client-sdk-react-native"&gt;React Native&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/rust-sdks"&gt;Rust&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/node-sdks"&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/python-sdks"&gt;Python&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/client-sdk-unity"&gt;Unity&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/client-sdk-unity-web"&gt;Unity (WebGL)&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/client-sdk-esp32"&gt;ESP32&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Server APIs&lt;/td&gt;
   &lt;td&gt;&lt;a href="https://github.com/livekit/node-sdks"&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/server-sdk-go"&gt;Golang&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/server-sdk-ruby"&gt;Ruby&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/server-sdk-kotlin"&gt;Java/Kotlin&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/python-sdks"&gt;Python&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/rust-sdks"&gt;Rust&lt;/a&gt; ¬∑ &lt;a href="https://github.com/agence104/livekit-server-sdk-php"&gt;PHP (community)&lt;/a&gt; ¬∑ &lt;a href="https://github.com/pabloFuente/livekit-server-sdk-dotnet"&gt;.NET (community)&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;UI Components&lt;/td&gt;
   &lt;td&gt;&lt;a href="https://github.com/livekit/components-js"&gt;React&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/components-android"&gt;Android Compose&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/components-swift"&gt;SwiftUI&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/components-flutter"&gt;Flutter&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Agents Frameworks&lt;/td&gt;
   &lt;td&gt;&lt;a href="https://github.com/livekit/agents"&gt;Python&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/agents-js"&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/agent-playground"&gt;Playground&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Services&lt;/td&gt;
   &lt;td&gt;&lt;b&gt;LiveKit server&lt;/b&gt; ¬∑ &lt;a href="https://github.com/livekit/egress"&gt;Egress&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/ingress"&gt;Ingress&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/sip"&gt;SIP&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;tr&gt;
   &lt;td&gt;Resources&lt;/td&gt;
   &lt;td&gt;&lt;a href="https://docs.livekit.io"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit-examples"&gt;Example apps&lt;/a&gt; ¬∑ &lt;a href="https://livekit.io/cloud"&gt;Cloud&lt;/a&gt; ¬∑ &lt;a href="https://docs.livekit.io/home/self-hosting/deployment"&gt;Self-hosting&lt;/a&gt; ¬∑ &lt;a href="https://github.com/livekit/livekit-cli"&gt;CLI&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;!--END_REPO_NAV--&gt;</description>
    </item>
    
    <item>
      <title>Adembc/lazyssh</title>
      <link>https://github.com/Adembc/lazyssh</link>
      <description>&lt;p&gt;A terminal-based SSH manager inspired by lazydocker and k9s - Written in go&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/Adembc/lazyssh/main/docs/logo.png" alt="lazyssh logo" width="600" height="600" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;Lazyssh is a terminal-based, interactive SSH manager inspired by tools like lazydocker and k9s ‚Äî but built for managing your fleet of servers directly from your terminal. &lt;br /&gt; With lazyssh, you can quickly navigate, connect, manage, and transfer files between your local machine and any server defined in your &lt;code&gt;~/.ssh/config&lt;/code&gt;. No more remembering IP addresses or running long scp commands ‚Äî just a clean, keyboard-driven UI.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;h3&gt;Server Management&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìú Read &amp;amp; display servers from your &lt;code&gt;~/.ssh/config&lt;/code&gt; in a scrollable list.&lt;/li&gt; 
 &lt;li&gt;‚ûï Add a new server from the UI with comprehensive SSH configuration options.&lt;/li&gt; 
 &lt;li&gt;‚úè Edit existing server entries directly from the UI with a tabbed interface.&lt;/li&gt; 
 &lt;li&gt;üóë Delete server entries safely.&lt;/li&gt; 
 &lt;li&gt;üìå Pin / unpin servers to keep favorites at the top.&lt;/li&gt; 
 &lt;li&gt;üèì Ping server to check status.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Server Navigation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîç Fuzzy search by alias, IP, or tags.&lt;/li&gt; 
 &lt;li&gt;üñ• One‚Äëkeypress SSH into the selected server (Enter).&lt;/li&gt; 
 &lt;li&gt;üè∑ Tag servers (e.g., prod, dev, test) for quick filtering.&lt;/li&gt; 
 &lt;li&gt;‚ÜïÔ∏è Sort by alias or last SSH (toggle + reverse).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced SSH Configuration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîó Port forwarding (LocalForward, RemoteForward, DynamicForward).&lt;/li&gt; 
 &lt;li&gt;üöÄ Connection multiplexing for faster subsequent connections.&lt;/li&gt; 
 &lt;li&gt;üîê Advanced authentication options (public key, password, agent forwarding).&lt;/li&gt; 
 &lt;li&gt;üîí Security settings (ciphers, MACs, key exchange algorithms).&lt;/li&gt; 
 &lt;li&gt;üåê Proxy settings (ProxyJump, ProxyCommand).&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è Extensive SSH config options organized in tabbed interface.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Management&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîë SSH key autocomplete with automatic detection of available keys.&lt;/li&gt; 
 &lt;li&gt;üìù Smart key selection with support for multiple keys.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Upcoming&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìÅ Copy files between local and servers with an easy picker UI.&lt;/li&gt; 
 &lt;li&gt;üîë SSH Key Deployment Features: 
  &lt;ul&gt; 
   &lt;li&gt;Use default local public key (&lt;code&gt;~/.ssh/id_ed25519.pub&lt;/code&gt; or &lt;code&gt;~/.ssh/id_rsa.pub&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Paste custom public keys manually&lt;/li&gt; 
   &lt;li&gt;Generate new keypairs and deploy them&lt;/li&gt; 
   &lt;li&gt;Automatically append keys to &lt;code&gt;~/.ssh/authorized_keys&lt;/code&gt; with correct permissions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîê Security Notice&lt;/h2&gt; 
&lt;p&gt;lazyssh does not introduce any new security risks. It is simply a UI/TUI wrapper around your existing &lt;code&gt;~/.ssh/config&lt;/code&gt; file.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;All SSH connections are executed through your system‚Äôs native ssh binary (OpenSSH).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Private keys, passwords, and credentials are never stored, transmitted, or modified by lazyssh.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Your existing IdentityFile paths and ssh-agent integrations work exactly as before.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;lazyssh only reads and updates your &lt;code&gt;~/.ssh/config&lt;/code&gt;. A backup of the file is created automatically before any changes.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;File permissions on your SSH config are preserved to ensure security.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõ°Ô∏è Config Safety: Non‚Äëdestructive writes and backups&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Non‚Äëdestructive edits: lazyssh only writes the minimal required changes to your ~/.ssh/config. It uses a parser that preserves existing comments, spacing, order, and any settings it didn‚Äôt touch. Your handcrafted comments and formatting remain intact.&lt;/li&gt; 
 &lt;li&gt;Atomic writes: updates are written to a temporary file and then atomically renamed over the original, minimizing the risk of partial writes.&lt;/li&gt; 
 &lt;li&gt;Backups: 
  &lt;ul&gt; 
   &lt;li&gt;One‚Äëtime original backup: before lazyssh makes its first change, it creates a single snapshot named config.original.backup beside your SSH config. If this file is present, it will never be recreated or overwritten.&lt;/li&gt; 
   &lt;li&gt;Rolling backups: on every subsequent save, lazyssh also creates a timestamped backup named like: ~/.ssh/config-
    &lt;timestamp&gt;
     -lazyssh.backup. The app keeps at most 10 of these backups, automatically removing the oldest ones.
    &lt;/timestamp&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì∑ Screenshots&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;üöÄ Startup&lt;/h3&gt; 
 &lt;img src="https://raw.githubusercontent.com/Adembc/lazyssh/main/docs/loader.png" alt="App starting splash/loader" width="800" /&gt; 
 &lt;p&gt;Clean loading screen when launching the app&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;üìã Server Management Dashboard&lt;/h3&gt; 
 &lt;img src="./docs/list server.png" alt="Server list view" width="900" /&gt; 
 &lt;p&gt;Main dashboard displaying all configured servers with status indicators, pinned favorites at the top, and easy navigation&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;üîé Search&lt;/h3&gt; 
 &lt;img src="https://raw.githubusercontent.com/Adembc/lazyssh/main/docs/search.png" alt="Fuzzy search servers" width="900" /&gt; 
 &lt;p&gt;Fuzzy search functionality to quickly find servers by name, IP address, or tags&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;‚ûï Add/Edit Server&lt;/h3&gt; 
 &lt;img src="./docs/add server.png" alt="Add a new server" width="900" /&gt; 
 &lt;p&gt;Tabbed interface for managing SSH connections with extensive configuration options organized into:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Basic&lt;/strong&gt; - Host, user, port, keys, tags&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Connection&lt;/strong&gt; - Proxy, timeouts, multiplexing, canonicalization&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Forwarding&lt;/strong&gt; - Port forwarding, X11, agent&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt; - Keys, passwords, methods, algorithm settings&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Advanced&lt;/strong&gt; - Security, cryptography, environment, debugging&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;üîê Connect to server&lt;/h3&gt; 
 &lt;img src="https://raw.githubusercontent.com/Adembc/lazyssh/main/docs/ssh.png" alt="SSH connection details" width="900" /&gt; 
 &lt;p&gt;SSH into the selected server&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üì¶ Installation&lt;/h2&gt; 
&lt;h3&gt;Option 1: Homebrew (macOS)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install Adembc/homebrew-tap/lazyssh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Option 2: Download Binary from Releases&lt;/h3&gt; 
&lt;p&gt;Download from &lt;a href="https://github.com/Adembc/lazyssh/releases"&gt;GitHub Releases&lt;/a&gt;. You can use the snippet below to automatically fetch the latest version for your OS/ARCH (Darwin/Linux and amd64/arm64 supported):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Detect latest version
LATEST_TAG=$(curl -fsSL https://api.github.com/repos/Adembc/lazyssh/releases/latest | jq -r .tag_name)
# Download the correct binary for your system
curl -LJO "https://github.com/Adembc/lazyssh/releases/download/${LATEST_TAG}/lazyssh_$(uname)_$(uname -m).tar.gz"
# Extract the binary
tar -xzf lazyssh_$(uname)_$(uname -m).tar.gz
# Move to /usr/local/bin or another directory in your PATH
sudo mv lazyssh /usr/local/bin/
# enjoy!
lazyssh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Option 3: Build from Source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/Adembc/lazyssh.git
cd lazyssh

# Build for macOS
make build
./bin/lazyssh

# Or Run it directly
make run
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚å®Ô∏è Key Bindings&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Key&lt;/th&gt; 
   &lt;th&gt;Action&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;/&lt;/td&gt; 
   &lt;td&gt;Toggle search bar&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‚Üë‚Üì/jk&lt;/td&gt; 
   &lt;td&gt;Navigate servers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Enter&lt;/td&gt; 
   &lt;td&gt;SSH into selected server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;c&lt;/td&gt; 
   &lt;td&gt;Copy SSH command to clipboard&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;g&lt;/td&gt; 
   &lt;td&gt;Ping selected server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;r&lt;/td&gt; 
   &lt;td&gt;Refresh background data&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;a&lt;/td&gt; 
   &lt;td&gt;Add server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;e&lt;/td&gt; 
   &lt;td&gt;Edit server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;t&lt;/td&gt; 
   &lt;td&gt;Edit tags&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;d&lt;/td&gt; 
   &lt;td&gt;Delete server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;p&lt;/td&gt; 
   &lt;td&gt;Pin/Unpin server&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;s&lt;/td&gt; 
   &lt;td&gt;Toggle sort field&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;S&lt;/td&gt; 
   &lt;td&gt;Reverse sort order&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;q&lt;/td&gt; 
   &lt;td&gt;Quit&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;In Server Form:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Key&lt;/th&gt; 
   &lt;th&gt;Action&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ctrl+H&lt;/td&gt; 
   &lt;td&gt;Previous tab&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ctrl+L&lt;/td&gt; 
   &lt;td&gt;Next tab&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ctrl+S&lt;/td&gt; 
   &lt;td&gt;Save&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Esc&lt;/td&gt; 
   &lt;td&gt;Cancel&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Tip: The hint bar at the top of the list shows the most useful shortcuts.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you spot a bug or have a feature request, please &lt;a href="https://github.com/adembc/lazyssh/issues"&gt;open an issue&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you'd like to contribute, fork the repo and submit a pull request ‚ù§Ô∏è.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We love seeing the community make Lazyssh better üöÄ&lt;/p&gt; 
&lt;h3&gt;Semantic Pull Requests&lt;/h3&gt; 
&lt;p&gt;This repository enforces semantic PR titles via an automated GitHub Action. Please format your PR title as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;type(scope): short descriptive subject Notes:&lt;/li&gt; 
 &lt;li&gt;Scope is optional and should be one of: ui, cli, config, parser.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Allowed types in this repo:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;feat: a new feature&lt;/li&gt; 
 &lt;li&gt;fix: a bug fix&lt;/li&gt; 
 &lt;li&gt;improve: quality or UX improvements that are not a refactor or perf&lt;/li&gt; 
 &lt;li&gt;refactor: code change that neither fixes a bug nor adds a feature&lt;/li&gt; 
 &lt;li&gt;docs: documentation only changes&lt;/li&gt; 
 &lt;li&gt;test: adding or refactoring tests&lt;/li&gt; 
 &lt;li&gt;ci: CI/CD or automation changes&lt;/li&gt; 
 &lt;li&gt;chore: maintenance tasks, dependency bumps, non-code infra&lt;/li&gt; 
 &lt;li&gt;revert: reverts a previous commit&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;feat(ui): add server pinning and sorting options&lt;/li&gt; 
 &lt;li&gt;fix(parser): handle comments at end of Host blocks&lt;/li&gt; 
 &lt;li&gt;improve(cli): show friendly error when ssh binary missing&lt;/li&gt; 
 &lt;li&gt;refactor(config): simplify backup rotation logic&lt;/li&gt; 
 &lt;li&gt;docs: add installation instructions for Homebrew&lt;/li&gt; 
 &lt;li&gt;ci: cache Go toolchain and dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Tip: If your PR touches multiple areas, pick the most relevant scope or omit the scope.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠ê Support&lt;/h2&gt; 
&lt;p&gt;If you find Lazyssh useful, please consider giving the repo a &lt;strong&gt;star&lt;/strong&gt; ‚≠êÔ∏è and join &lt;a href="https://github.com/adembc/lazyssh/stargazers"&gt;stargazers&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;‚òï You can also support me by &lt;a href="https://www.buymeacoffee.com/adembc"&gt;buying me a coffee&lt;/a&gt; ‚ù§Ô∏è &lt;br /&gt; &lt;a href="https://buymeacoffee.com/adembc" target="_blank"&gt;&lt;img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" width="200" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Built with &lt;a href="https://github.com/rivo/tview"&gt;tview&lt;/a&gt; and &lt;a href="https://github.com/gdamore/tcell"&gt;tcell&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Inspired by &lt;a href="https://github.com/derailed/k9s"&gt;k9s&lt;/a&gt; and &lt;a href="https://github.com/jesseduffield/lazydocker"&gt;lazydocker&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>seaweedfs/seaweedfs</title>
      <link>https://github.com/seaweedfs/seaweedfs</link>
      <description>&lt;p&gt;SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeaweedFS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;&lt;img src="https://img.shields.io/badge/slack-purple" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=seaweedfs"&gt;&lt;img src="https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;amp;label=Follow" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/seaweedfs/seaweedfs/weed"&gt;&lt;img src="https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;&lt;img src="https://img.shields.io/badge/docs-wiki-blue.svg?sanitize=true" alt="Wiki" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/search?q=g:com.github.chrislusf"&gt;&lt;img src="https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client" alt="SeaweedFS on Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=seaweedfs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png" alt="SeaweedFS Logo" /&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt;&lt;a href="https://www.patreon.com/seaweedfs"&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;SeaweedFS is an independent Apache-licensed open source project with its ongoing development made possible entirely thanks to the support of these awesome &lt;a href="https://github.com/seaweedfs/seaweedfs/raw/master/backers.md"&gt;backers&lt;/a&gt;. If you'd like to grow SeaweedFS even stronger, please consider joining our &lt;a href="https://www.patreon.com/seaweedfs"&gt;sponsors on Patreon&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your support will be really appreciated by me and other supporters!&lt;/p&gt; 
&lt;!--
&lt;h4 align="center"&gt;Platinum&lt;/h4&gt;

&lt;p align="center"&gt;
  &lt;a href="" target="_blank"&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.nodion.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png" alt="nodion" /&gt;&lt;/a&gt; &lt;a href="https://www.piknik.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png" alt="piknik" /&gt;&lt;/a&gt; &lt;a href="https://www.keepsec.ca"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png" alt="keepsec" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/releases/latest"&gt;Download Binaries for different platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;SeaweedFS on Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/SeaweedFS"&gt;SeaweedFS on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/Seaweedfs"&gt;SeaweedFS on Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/SeaweedFS/"&gt;SeaweedFS on Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/d/forum/seaweedfs"&gt;SeaweedFS Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;Wiki Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf"&gt;SeaweedFS White Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2025.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2021.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/chrislusf/seaweedfs-introduction"&gt;SeaweedFS Introduction Slides 2019.3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-for-s3-api-on-docker"&gt;Quick Start for S3 API on Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-single-binary"&gt;Quick Start with Single Binary&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-seaweedfs-s3-on-aws"&gt;Quick Start SeaweedFS S3 on AWS&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#additional-features"&gt;Additional Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#filer-features"&gt;Filer Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#example-using-seaweed-object-store"&gt;Example: Using Seaweed Object Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#object-store-architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-other-file-systems"&gt;Compared to Other File Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-hdfs"&gt;Compared to HDFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs-ceph"&gt;Compared to GlusterFS, Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs"&gt;Compared to GlusterFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-ceph"&gt;Compared to Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-minio"&gt;Compared to Minio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#dev-plan"&gt;Dev Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#installation-guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#disk-related-topics"&gt;Disk Related Topics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#benchmark"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#enterprise"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;h2&gt;Quick Start for S3 API on Docker&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker run -p 8333:8333 chrislusf/seaweedfs server -s3&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start with Single Binary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;. Or run &lt;code&gt;go install github.com/seaweedfs/seaweedfs/weed@latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key&lt;/code&gt; as the admin credentials to access the object store.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;weed server -dir=/some/data/dir -s3&lt;/code&gt; to start one master, one volume server, one filer, and one S3 gateway.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, to increase capacity, just add more volume servers by running &lt;code&gt;weed volume -dir="/some/data/dir2" -mserver="&amp;lt;master_host&amp;gt;:9333" -port=8081&lt;/code&gt; locally, or on a different machine, or on thousands of machines. That is it!&lt;/p&gt; 
&lt;h2&gt;Quick Start SeaweedFS S3 on AWS&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setup fast production-ready &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc"&gt;SeaweedFS S3 on AWS with cloudformation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;to store billions of files!&lt;/li&gt; 
 &lt;li&gt;to serve the files fast!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;SeaweedFS started as an Object Store to handle small files efficiently. Instead of managing all file metadata in a central master, the central master only manages volumes on volume servers, and these volume servers manage files and their metadata. This relieves concurrency pressure from the central master and spreads file metadata into volume servers, allowing faster file access (O(1), usually just one disk read operation).&lt;/p&gt; 
&lt;p&gt;There is only 40 bytes of disk storage overhead for each file's metadata. It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.&lt;/p&gt; 
&lt;p&gt;SeaweedFS started by implementing &lt;a href="http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook's Haystack design paper&lt;/a&gt;. Also, SeaweedFS implements erasure coding with ideas from &lt;a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf"&gt;f4: Facebook‚Äôs Warm BLOB Storage System&lt;/a&gt;, and has a lot of similarities with &lt;a href="https://www.usenix.org/system/files/fast21-pan.pdf"&gt;Facebook‚Äôs Tectonic Filesystem&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On top of the object store, optional &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer&lt;/a&gt; can support directories and POSIX attributes. Filer is a separate linearly-scalable stateless server with customizable metadata stores, e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.&lt;/p&gt; 
&lt;p&gt;For any distributed key value stores, the large values can be offloaded to SeaweedFS. With the fast access speed and linearly scalable capacity, SeaweedFS can work as a distributed &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store"&gt;Key-Large-Value store&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can transparently integrate with the cloud. With hot data on local cluster, and warm data on the cloud with O(1) access time, SeaweedFS can achieve both fast local access time and elastic cloud storage capacity. What's more, the cloud storage access API cost is minimized. Faster and cheaper than direct cloud storage!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Can choose no replication or different replication levels, rack and data center aware.&lt;/li&gt; 
 &lt;li&gt;Automatic master servers failover - no single point of failure (SPOF).&lt;/li&gt; 
 &lt;li&gt;Automatic Gzip compression depending on file MIME type.&lt;/li&gt; 
 &lt;li&gt;Automatic compaction to reclaim disk space after deletion or update.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live"&gt;Automatic entry TTL expiration&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Any server with some disk space can add to the total storage space.&lt;/li&gt; 
 &lt;li&gt;Adding/Removing servers does &lt;strong&gt;not&lt;/strong&gt; cause any data re-balancing unless triggered by admin commands.&lt;/li&gt; 
 &lt;li&gt;Optional picture resizing.&lt;/li&gt; 
 &lt;li&gt;Support ETag, Accept-Range, Last-Modified, etc.&lt;/li&gt; 
 &lt;li&gt;Support in-memory/leveldb/readonly mode tuning for memory/performance balance.&lt;/li&gt; 
 &lt;li&gt;Support rebalancing the writable and readonly volumes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage"&gt;Customizable Multiple Storage Tiers&lt;/a&gt;: Customizable storage disk types to balance performance and cost.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier"&gt;Transparent cloud integration&lt;/a&gt;: unlimited capacity via tiered cloud storage for warm data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage"&gt;Erasure Coding for warm storage&lt;/a&gt; Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filer Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer server&lt;/a&gt; provides "normal" directories and files via HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores"&gt;File TTL&lt;/a&gt; automatically expires file metadata and actual file data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount"&gt;Mount filer&lt;/a&gt; reads and writes files directly as a local directory via FUSE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication"&gt;Filer Store Replication&lt;/a&gt; enables HA for filer meta data stores.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization"&gt;Active-Active Replication&lt;/a&gt; enables asynchronous one-way or two-way cross cluster continuous replication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API"&gt;Amazon S3 compatible API&lt;/a&gt; accesses files with S3 tooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System"&gt;Hadoop Compatible File System&lt;/a&gt; accesses files from Hadoop/Spark/Flink/etc or even runs HBase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud"&gt;Async Replication To Cloud&lt;/a&gt; has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/WebDAV"&gt;WebDAV&lt;/a&gt; accesses as a mapped drive on Mac and Windows, or from mobile devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption"&gt;AES256-GCM Encrypted Storage&lt;/a&gt; safely stores the encrypted data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files"&gt;Super Large Files&lt;/a&gt; stores large or super large files in tens of TB.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt; mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage"&gt;Gateway to Remote Object Store&lt;/a&gt; mirrors bucket operations to remote object storage, in addition to &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Kubernetes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-csi-driver"&gt;Kubernetes CSI Driver&lt;/a&gt; A Container Storage Interface (CSI) Driver. &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-operator"&gt;SeaweedFS Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example: Using Seaweed Object Store&lt;/h2&gt; 
&lt;p&gt;By default, the master node runs on port 9333, and the volume nodes run on port 8080. Let's start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We'll use localhost as an example.&lt;/p&gt; 
&lt;p&gt;SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.&lt;/p&gt; 
&lt;h3&gt;Start Master Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; ./weed master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Volume Servers&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; weed volume -dir="/tmp/data1" -max=5  -mserver="localhost:9333" -port=8080 &amp;amp;
&amp;gt; weed volume -dir="/tmp/data2" -max=10 -mserver="localhost:9333" -port=8081 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write File&lt;/h3&gt; 
&lt;p&gt;To upload a file: first, send a HTTP POST, PUT, or GET request to &lt;code&gt;/dir/assign&lt;/code&gt; to get an &lt;code&gt;fid&lt;/code&gt; and a volume server URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/assign
{"count":1,"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Second, to store the file content, send a HTTP multi-part POST request to &lt;code&gt;url + '/' + fid&lt;/code&gt; from the response:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{"name":"myphoto.jpg","size":43234,"eTag":"1cc0118e"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update, send another POST request with updated file content.&lt;/p&gt; 
&lt;p&gt;For deletion, send an HTTP DELETE request to the same &lt;code&gt;url + '/' + fid&lt;/code&gt; URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Save File Id&lt;/h3&gt; 
&lt;p&gt;Now, you can save the &lt;code&gt;fid&lt;/code&gt;, 3,01637037d6 in this case, to a database field.&lt;/p&gt; 
&lt;p&gt;The number 3 at the start represents a volume id. After the comma, it's one file key, 01, and a file cookie, 637037d6.&lt;/p&gt; 
&lt;p&gt;The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.&lt;/p&gt; 
&lt;p&gt;The file key and file cookie are both coded in hex. You can store the &amp;lt;volume id, file key, file cookie&amp;gt; tuple in your own format, or simply store the &lt;code&gt;fid&lt;/code&gt; as a string.&lt;/p&gt; 
&lt;p&gt;If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.&lt;/p&gt; 
&lt;p&gt;If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.&lt;/p&gt; 
&lt;h3&gt;Read File&lt;/h3&gt; 
&lt;p&gt;Here is an example of how to render the URL.&lt;/p&gt; 
&lt;p&gt;First look up the volume server's URLs by the file's volumeId:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/lookup?volumeId=3
{"volumeId":"3","locations":[{"publicUrl":"localhost:8080","url":"localhost:8080"}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since (usually) there are not too many volume servers, and volumes don't move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.&lt;/p&gt; 
&lt;p&gt;Now you can take the public URL, render the URL or directly read from the volume server via URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3,01637037d6.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notice we add a file extension ".jpg" here. It's optional and just one way for the client to specify the file content type.&lt;/p&gt; 
&lt;p&gt;If you want a nicer URL, you can use one of these alternative URL formats:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to get a scaled version of an image, you can add some params:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fill
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rack-Aware and Data Center-Aware Replication&lt;/h3&gt; 
&lt;p&gt;SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:9333/dir/assign?replication=001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication parameter options are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about replication can be found &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Replication"&gt;on the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also set the default replication strategy when starting the master server.&lt;/p&gt; 
&lt;h3&gt;Allocate File Key on Specific Data Center&lt;/h3&gt; 
&lt;p&gt;Volume servers can be started with a specific data center name:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When requesting a file key, an optional "dataCenter" parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to 'dc1':&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:9333/dir/assign?dataCenter=dc1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server"&gt;No Single Point of Failure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys"&gt;Insert with your own keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files"&gt;Chunking large files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space"&gt;Collection as a Simple Name Space&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Object Store Architecture&lt;/h2&gt; 
&lt;p&gt;Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.&lt;/p&gt; 
&lt;p&gt;The main drawback is that the central master can't handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.&lt;/p&gt; 
&lt;p&gt;Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.&lt;/p&gt; 
&lt;p&gt;The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.&lt;/p&gt; 
&lt;p&gt;For comparison, consider that an xfs inode structure in Linux is 536 bytes.&lt;/p&gt; 
&lt;h3&gt;Master Server and Volume Server&lt;/h3&gt; 
&lt;p&gt;The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.&lt;/p&gt; 
&lt;p&gt;All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.&lt;/p&gt; 
&lt;p&gt;On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.&lt;/p&gt; 
&lt;h3&gt;Write and Read files&lt;/h3&gt; 
&lt;p&gt;When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.&lt;/p&gt; 
&lt;p&gt;When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages and let browsers fetch the content.&lt;/p&gt; 
&lt;p&gt;Please see the example for details on the write-read process.&lt;/p&gt; 
&lt;h3&gt;Storage Size&lt;/h3&gt; 
&lt;p&gt;In the current implementation, each volume can hold 32 gibibytes (32GiB or 8x2^32 bytes). This is because we align content to 8 bytes. We can easily increase this to 64GiB, or 128GiB, or more, by changing 2 lines of code, at the cost of some wasted padding space due to alignment.&lt;/p&gt; 
&lt;p&gt;There can be 4 gibibytes (4GiB or 2^32 bytes) of volumes. So the total system size is 8 x 4GiB x 4GiB which is 128 exbibytes (128EiB or 2^67 bytes).&lt;/p&gt; 
&lt;p&gt;Each individual file size is limited to the volume size.&lt;/p&gt; 
&lt;h3&gt;Saving memory&lt;/h3&gt; 
&lt;p&gt;All file meta information stored on a volume server is readable from memory without disk access. Each file takes just a 16-byte map entry of &amp;lt;64bit key, 32bit offset, 32bit size&amp;gt;. Of course, each map entry has its own space cost for the map. But usually the disk space runs out before the memory does.&lt;/p&gt; 
&lt;h3&gt;Tiered Storage to the cloud&lt;/h3&gt; 
&lt;p&gt;The local volume servers are much faster, while cloud storages have elastic capacity and are actually more cost-efficient if not accessed often (usually free to upload, but relatively costly to access). With the append-only structure and O(1) access time, SeaweedFS can take advantage of both local and cloud storage by offloading the warm data to the cloud.&lt;/p&gt; 
&lt;p&gt;Usually hot data are fresh and warm data are old. SeaweedFS puts the newly created volumes on local servers, and optionally upload the older volumes on the cloud. If the older data are accessed less often, this literally gives you unlimited capacity with limited local servers, and still fast for new data.&lt;/p&gt; 
&lt;p&gt;With the O(1) access time, the network latency cost is kept at minimum.&lt;/p&gt; 
&lt;p&gt;If the hot/warm data is split as 20/80, with 20 servers, you can achieve storage capacity of 100 servers. That's a cost saving of 80%! Or you can repurpose the 80 servers to store new data also, and get 5X storage throughput.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compared to Other File Systems&lt;/h2&gt; 
&lt;p&gt;Most other distributed file systems seem more complicated than necessary.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is meant to be fast and simple, in both setup and operation. If you do not understand how it works when you reach here, we've failed! Please raise an issue with any questions or update this file with clarifications.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is constantly moving forward. Same with other systems. These comparisons can be outdated quickly. Please help to keep them updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to HDFS&lt;/h3&gt; 
&lt;p&gt;HDFS uses the chunk approach for each file, and is ideal for storing large files.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is ideal for serving relatively smaller files quickly and concurrently.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can also store extra large files by splitting them into manageable data chunks, and store the file ids of the data chunks into a meta chunk. This is managed by "weed upload/download" tool, and the weed master or volume servers are agnostic about it.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS, Ceph&lt;/h3&gt; 
&lt;p&gt;The architectures are mostly the same. SeaweedFS aims to store and read files fast, with a simple and flat architecture. The main differences are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SeaweedFS optimizes for small files, ensuring O(1) disk seek operation, and can also handle large files.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS statically assigns a volume id for a file. Locating file content becomes just a lookup of the volume id, which can be easily cached.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Filer metadata store can be any well-known and proven data store, e.g., Redis, Cassandra, HBase, Mongodb, Elastic Search, MySql, Postgres, Sqlite, MemSql, TiDB, CockroachDB, Etcd, YDB etc, and is easy to customize.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Volume server also communicates directly with clients via HTTP, supporting range queries, direct uploads, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;File Metadata&lt;/th&gt; 
   &lt;th&gt;File Content Read&lt;/th&gt; 
   &lt;th&gt;POSIX&lt;/th&gt; 
   &lt;th&gt;REST API&lt;/th&gt; 
   &lt;th&gt;Optimized for large number of small files&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS&lt;/td&gt; 
   &lt;td&gt;lookup volume id, cacheable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS Filer&lt;/td&gt; 
   &lt;td&gt;Linearly Scalable, Customizable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GlusterFS&lt;/td&gt; 
   &lt;td&gt;hashing&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE, NFS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ceph&lt;/td&gt; 
   &lt;td&gt;hashing + rules&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MooseFS&lt;/td&gt; 
   &lt;td&gt;in memory&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinIO&lt;/td&gt; 
   &lt;td&gt;separate meta file for each file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS&lt;/h3&gt; 
&lt;p&gt;GlusterFS stores files, both directories and content, in configurable volumes called "bricks".&lt;/p&gt; 
&lt;p&gt;GlusterFS hashes the path and filename into ids, and assigned to virtual volumes, and then mapped to "bricks".&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MooseFS&lt;/h3&gt; 
&lt;p&gt;MooseFS chooses to neglect small file issue. From moosefs 3.0 manual, "even a small file will occupy 64KiB plus additionally 4KiB of checksums and 1KiB for the header", because it "was initially designed for keeping large amounts (like several thousands) of very big files"&lt;/p&gt; 
&lt;p&gt;MooseFS Master Server keeps all meta data in memory. Same issue as HDFS namenode.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to Ceph&lt;/h3&gt; 
&lt;p&gt;Ceph can be setup similar to SeaweedFS as a key-&amp;gt;blob store. It is much more complicated, with the need to support layers on top of it. &lt;a href="https://github.com/seaweedfs/seaweedfs/issues/120"&gt;Here is a more detailed comparison&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;SeaweedFS has a centralized master group to look up free volumes, while Ceph uses hashing and metadata servers to locate its objects. Having a centralized master makes it easy to code and manage.&lt;/p&gt; 
&lt;p&gt;Ceph, like SeaweedFS, is based on the object store RADOS. Ceph is rather complicated with mixed reviews.&lt;/p&gt; 
&lt;p&gt;Ceph uses CRUSH hashing to automatically manage data placement, which is efficient to locate the data. But the data has to be placed according to the CRUSH algorithm. Any wrong configuration would cause data loss. Topology changes, such as adding new servers to increase capacity, will cause data migration with high IO cost to fit the CRUSH algorithm. SeaweedFS places data by assigning them to any writable volumes. If writes to one volume failed, just pick another volume to write. Adding more volumes is also as simple as it can be.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is optimized for small files. Small files are stored as one continuous block of content, with at most 8 unused bytes between files. Small file access is O(1) disk read.&lt;/p&gt; 
&lt;p&gt;SeaweedFS Filer uses off-the-shelf stores, such as MySql, Postgres, Sqlite, Mongodb, Redis, Elastic Search, Cassandra, HBase, MemSql, TiDB, CockroachCB, Etcd, YDB, to manage file directories. These stores are proven, scalable, and easier to manage.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SeaweedFS&lt;/th&gt; 
   &lt;th&gt;comparable to Ceph&lt;/th&gt; 
   &lt;th&gt;advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Master&lt;/td&gt; 
   &lt;td&gt;MDS&lt;/td&gt; 
   &lt;td&gt;simpler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volume&lt;/td&gt; 
   &lt;td&gt;OSD&lt;/td&gt; 
   &lt;td&gt;optimized for small files&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filer&lt;/td&gt; 
   &lt;td&gt;Ceph FS&lt;/td&gt; 
   &lt;td&gt;linearly scalable, Customizable, O(1) or O(logN)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MinIO&lt;/h3&gt; 
&lt;p&gt;MinIO follows AWS S3 closely and is ideal for testing for S3 API. It has good UI, policies, versionings, etc. SeaweedFS is trying to catch up here. It is also possible to put MinIO as a gateway in front of SeaweedFS later.&lt;/p&gt; 
&lt;p&gt;MinIO metadata are in simple files. Each file write will incur extra writes to corresponding meta file.&lt;/p&gt; 
&lt;p&gt;MinIO does not have optimization for lots of small files. The files are simply stored as is to local disks. Plus the extra meta file and shards for erasure coding, it only amplifies the LOSF problem.&lt;/p&gt; 
&lt;p&gt;MinIO has multiple disk IO to read one file. SeaweedFS has O(1) disk reads, even for erasure coded files.&lt;/p&gt; 
&lt;p&gt;MinIO has full-time erasure coding. SeaweedFS uses replication on hot data for faster speed and optionally applies erasure coding on warm data.&lt;/p&gt; 
&lt;p&gt;MinIO does not have POSIX-like API support.&lt;/p&gt; 
&lt;p&gt;MinIO has specific requirements on storage layout. It is not flexible to adjust capacity. In SeaweedFS, just start one volume server pointing to the master. That's all.&lt;/p&gt; 
&lt;h2&gt;Dev Plan&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More tools and documentation, on how to manage and scale the system.&lt;/li&gt; 
 &lt;li&gt;Read and write stream data.&lt;/li&gt; 
 &lt;li&gt;Support structured data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is a super exciting project! And we need helpers and &lt;a href="https://www.patreon.com/seaweedfs"&gt;support&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Installation guide for users who are not familiar with golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Step 1: install go on your machine and setup the environment by following the instructions at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://golang.org/doc/install"&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;make sure to define your $GOPATH&lt;/p&gt; 
&lt;p&gt;Step 2: checkout this repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/seaweedfs/seaweedfs.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step 3: download, compile, and install the project by executing the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd seaweedfs/weed &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this is done, you will find the executable "weed" in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory&lt;/p&gt; 
&lt;p&gt;For more installation options, including how to run with Docker, see the &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Getting-Started"&gt;Getting Started guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disk Related Topics&lt;/h2&gt; 
&lt;h3&gt;Hard Drive Performance&lt;/h3&gt; 
&lt;p&gt;When testing read performance on SeaweedFS, it basically becomes a performance test of your hard drive's random read speed. Hard drives usually get 100MB/s~200MB/s.&lt;/p&gt; 
&lt;h3&gt;Solid State Disk&lt;/h3&gt; 
&lt;p&gt;To modify or delete small files, SSD must delete a whole block at a time, and move content in existing blocks to a new block. SSD is fast when brand new, but will get fragmented over time and you have to garbage collect, compacting blocks. SeaweedFS is friendly to SSD since it is append-only. Deletion and compaction are done on volume level in the background, not slowing reading and not causing fragmentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;My Own Unscientific Single Machine Results on Mac Book with Solid State Disk, CPU: 1 Intel Core i7 2.6GHz.&lt;/p&gt; 
&lt;p&gt;Write 1 million 1KB file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   66.753 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106789009 bytes
Requests per second:    15708.23 [#/sec]
Transfer rate:          16191.69 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.3      1.0       84.3      0.9

Percentage of the requests served within a certain time (ms)
   50%      0.8 ms
   66%      1.0 ms
   75%      1.1 ms
   80%      1.2 ms
   90%      1.4 ms
   95%      1.7 ms
   98%      2.1 ms
   99%      2.6 ms
  100%     84.3 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Randomly read 1 million files:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   22.301 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106812873 bytes
Requests per second:    47019.38 [#/sec]
Transfer rate:          48467.57 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.0      0.3       54.1      0.2

Percentage of the requests served within a certain time (ms)
   50%      0.3 ms
   90%      0.4 ms
   98%      0.6 ms
   99%      0.7 ms
  100%     54.1 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run WARP and launch a mixed benchmark.&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make benchmark
warp: Benchmark data written to "warp-mixed-2025-12-05[194844]-kBpU.csv.zst"

Mixed operations.
Operation: DELETE, 10%, Concurrency: 20, Ran 42s.
 * Throughput: 55.13 obj/s

Operation: GET, 45%, Concurrency: 20, Ran 42s.
 * Throughput: 2477.45 MiB/s, 247.75 obj/s

Operation: PUT, 15%, Concurrency: 20, Ran 42s.
 * Throughput: 825.85 MiB/s, 82.59 obj/s

Operation: STAT, 30%, Concurrency: 20, Ran 42s.
 * Throughput: 165.27 obj/s

Cluster Total: 3302.88 MiB/s, 550.51 obj/s over 43s.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;For enterprise users, please visit &lt;a href="https://seaweedfs.com"&gt;seaweedfs.com&lt;/a&gt; for the SeaweedFS Enterprise Edition, which has a self-healing storage format with better data protection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;p&gt;The text of this page is available for modification and reuse under the terms of the Creative Commons Attribution-Sharealike 3.0 Unported License and the GNU Free Documentation License (unversioned, with no invariant sections, front-cover texts, or back-cover texts).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/chrislusf/seaweedfs"&gt;&lt;img src="https://starchart.cc/chrislusf/seaweedfs.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anchore/grype</title>
      <link>https://github.com/anchore/grype</link>
      <description>&lt;p&gt;A vulnerability scanner for container images and filesystems&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img alt="Grype logo" src="https://user-images.githubusercontent.com/5199289/136855393-d0a9eef9-ccf1-4e2b-9d7c-7aad16a567e5.png" width="234" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &amp;nbsp;&lt;a href="https://github.com/anchore/grype/actions?query=workflow%3A%22Static+Analysis+%2B+Unit+%2B+Integration%22"&gt;&lt;img src="https://github.com/anchore/grype/workflows/Static%20Analysis%20+%20Unit%20+%20Integration/badge.svg?sanitize=true" alt="Static Analysis + Unit + Integration" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://github.com/anchore/grype/actions/workflows/validations.yaml"&gt;&lt;img src="https://github.com/anchore/grype/workflows/Validations/badge.svg?sanitize=true" alt="Validations" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://goreportcard.com/report/github.com/anchore/grype"&gt;&lt;img src="https://goreportcard.com/badge/github.com/anchore/grype" alt="Go Report Card" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://github.com/anchore/grype/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release/anchore/grype.svg?sanitize=true" alt="GitHub release" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://github.com/anchore/grype"&gt;&lt;img src="https://img.shields.io/github/go-mod/go-version/anchore/grype.svg?sanitize=true" alt="GitHub go.mod Go version" /&gt;&lt;/a&gt;&amp;nbsp; &lt;br /&gt; &amp;nbsp;&lt;a href="https://github.com/anchore/grype/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://anchore.com/discourse"&gt;&lt;img src="https://img.shields.io/badge/Discourse-Join-blue?logo=discourse" alt="Join our Discourse" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a rel="me" href="https://fosstodon.org/@grype"&gt;&lt;img src="https://img.shields.io/badge/Mastodon-Follow-blue?logoColor=white&amp;amp;logo=mastodon" alt="Follow on Mastodon" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://scorecard.dev/viewer/?uri=github.com/anchore/grype"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/anchore/grype/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://www.bestpractices.dev/projects/6708"&gt;&lt;img src="https://www.bestpractices.dev/projects/6708/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt;&amp;nbsp; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;A vulnerability scanner for container images and filesystems. Easily &lt;a href="https://raw.githubusercontent.com/anchore/grype/main/#installation"&gt;install the binary&lt;/a&gt; to try it out. Works with &lt;a href="https://github.com/anchore/syft"&gt;Syft&lt;/a&gt;, the powerful SBOM (software bill of materials) tool for container images and filesystems.&lt;/p&gt; 
&lt;h3&gt;Join our community meetings!&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Calendar: &lt;a href="https://calendar.google.com/calendar/u/0/r?cid=Y182OTM4dGt0MjRtajI0NnNzOThiaGtnM29qNEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t"&gt;https://calendar.google.com/calendar/u/0/r?cid=Y182OTM4dGt0MjRtajI0NnNzOThiaGtnM29qNEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Agenda: &lt;a href="https://docs.google.com/document/d/1ZtSAa6fj2a6KRWviTn3WoJm09edvrNUp4Iz_dOjjyY8/edit?usp=sharing"&gt;https://docs.google.com/document/d/1ZtSAa6fj2a6KRWviTn3WoJm09edvrNUp4Iz_dOjjyY8/edit?usp=sharing&lt;/a&gt; (join &lt;a href="https://groups.google.com/g/anchore-oss-community"&gt;this group&lt;/a&gt; for write access)&lt;/li&gt; 
 &lt;li&gt;All are welcome!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For commercial support options with Syft or Grype, please &lt;a href="https://get.anchore.com/contact/"&gt;contact Anchore&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/590471/90276236-9868f300-de31-11ea-8068-4268b6b68529.gif" alt="grype-demo" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Scan the contents of a container image or filesystem to find known vulnerabilities.&lt;/li&gt; 
 &lt;li&gt;Find vulnerabilities for major operating system packages: 
  &lt;ul&gt; 
   &lt;li&gt;Alpine&lt;/li&gt; 
   &lt;li&gt;Amazon Linux&lt;/li&gt; 
   &lt;li&gt;Azure Linux (previously CBL-Mariner)&lt;/li&gt; 
   &lt;li&gt;BusyBox&lt;/li&gt; 
   &lt;li&gt;CentOS&lt;/li&gt; 
   &lt;li&gt;Debian&lt;/li&gt; 
   &lt;li&gt;Echo&lt;/li&gt; 
   &lt;li&gt;Distroless&lt;/li&gt; 
   &lt;li&gt;MinimOS&lt;/li&gt; 
   &lt;li&gt;Oracle Linux&lt;/li&gt; 
   &lt;li&gt;Red Hat (RHEL)&lt;/li&gt; 
   &lt;li&gt;Ubuntu&lt;/li&gt; 
   &lt;li&gt;Wolfi&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Find vulnerabilities for language-specific packages: 
  &lt;ul&gt; 
   &lt;li&gt;Ruby (Gems)&lt;/li&gt; 
   &lt;li&gt;Java (JAR, WAR, EAR, JPI, HPI)&lt;/li&gt; 
   &lt;li&gt;JavaScript (NPM, Yarn)&lt;/li&gt; 
   &lt;li&gt;Python (Egg, Wheel, Poetry, requirements.txt/setup.py files)&lt;/li&gt; 
   &lt;li&gt;Dotnet (deps.json)&lt;/li&gt; 
   &lt;li&gt;Golang (go.mod)&lt;/li&gt; 
   &lt;li&gt;PHP (Composer)&lt;/li&gt; 
   &lt;li&gt;Rust (Cargo)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Supports Docker, OCI and &lt;a href="https://github.com/sylabs/singularity"&gt;Singularity&lt;/a&gt; image formats.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openvex"&gt;OpenVEX&lt;/a&gt; support for filtering and augmenting scanning results.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you encounter an issue, please &lt;a href="https://github.com/anchore/grype/issues"&gt;let us know using the issue tracker&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Recommended&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSfL https://get.anchore.io/grype | sudo sh -s -- -b /usr/local/bin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install script options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-b&lt;/code&gt;: Specify a custom installation directory (defaults to &lt;code&gt;./bin&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-d&lt;/code&gt;: More verbose logging levels (&lt;code&gt;-d&lt;/code&gt; for debug, &lt;code&gt;-dd&lt;/code&gt; for trace)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v&lt;/code&gt;: Verify the signature of the downloaded artifact before installation (requires &lt;a href="https://github.com/sigstore/cosign"&gt;&lt;code&gt;cosign&lt;/code&gt;&lt;/a&gt; to be installed)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Chocolatey&lt;/h3&gt; 
&lt;p&gt;The chocolatey distribution of grype is community-maintained and not distributed by the anchore team.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;choco install grype -y
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Homebrew&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew tap anchore/grype
brew install grype
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MacPorts&lt;/h3&gt; 
&lt;p&gt;On macOS, Grype can additionally be installed from the &lt;a href="https://ports.macports.org/port/grype/"&gt;community-maintained port&lt;/a&gt; via MacPorts:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo port install grype
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Currently, Grype is built only for macOS and Linux.&lt;/p&gt; 
&lt;h3&gt;From source&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/anchore/grype/main/DEVELOPING.md#native-development"&gt;DEVELOPING.md&lt;/a&gt; for instructions to build and run from source.&lt;/p&gt; 
&lt;h3&gt;GitHub Actions&lt;/h3&gt; 
&lt;p&gt;If you're using GitHub Actions, you can use our &lt;a href="https://github.com/marketplace/actions/anchore-container-scan"&gt;Grype-based action&lt;/a&gt; to run vulnerability scans on your code or container images during your CI workflows.&lt;/p&gt; 
&lt;h2&gt;Verifying the artifacts&lt;/h2&gt; 
&lt;p&gt;Checksums are applied to all artifacts, and the resulting checksum file is signed using cosign.&lt;/p&gt; 
&lt;p&gt;You need the following tool to verify signature:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.sigstore.dev/cosign/system_config/installation/"&gt;Cosign&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Verification steps are as follow:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Download the files you want, and the checksums.txt, checksums.txt.pem and checksums.txt.sig files from the &lt;a href="https://github.com/anchore/grype/releases"&gt;releases&lt;/a&gt; page:&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Verify the signature:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cosign verify-blob &amp;lt;path to checksum.txt&amp;gt; \
--certificate &amp;lt;path to checksums.txt.pem&amp;gt; \
--signature &amp;lt;path to checksums.txt.sig&amp;gt; \
--certificate-identity-regexp 'https://github\.com/anchore/grype/\.github/workflows/.+' \
--certificate-oidc-issuer "https://token.actions.githubusercontent.com"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Once the signature is confirmed as valid, you can proceed to validate that the SHA256 sums align with the downloaded artifact:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sha256sum --ignore-missing -c checksums.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/anchore/grype/main/#installation"&gt;Install the binary&lt;/a&gt;, and make sure that &lt;code&gt;grype&lt;/code&gt; is available in your path. To scan for vulnerabilities in an image:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;grype &amp;lt;image&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above command scans for vulnerabilities visible in the container (i.e., the squashed representation of the image). To include software from all image layers in the vulnerability scan, regardless of its presence in the final image, provide &lt;code&gt;--scope all-layers&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;grype &amp;lt;image&amp;gt; --scope all-layers
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run grype from a Docker container so it can scan a running container, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yml"&gt;docker run --rm \
--volume /var/run/docker.sock:/var/run/docker.sock \
--name Grype anchore/grype:latest \
$(ImageName):$(ImageTag)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported sources&lt;/h2&gt; 
&lt;p&gt;Grype can scan a variety of sources beyond those found in Docker.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# scan a container image archive (from the result of `docker image save ...`, `podman save ...`, or `skopeo copy` commands)
grype path/to/image.tar

# scan a Singularity Image Format (SIF) container
grype path/to/image.sif

# scan a directory
grype dir:path/to/dir
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sources can be explicitly provided with a scheme:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;podman:yourrepo/yourimage:tag          use images from the Podman daemon
docker:yourrepo/yourimage:tag          use images from the Docker daemon
docker-archive:path/to/yourimage.tar   use a tarball from disk for archives created from "docker save"
oci-archive:path/to/yourimage.tar      use a tarball from disk for OCI archives (from Skopeo or otherwise)
oci-dir:path/to/yourimage              read directly from a path on disk for OCI layout directories (from Skopeo or otherwise)
singularity:path/to/yourimage.sif      read directly from a Singularity Image Format (SIF) container on disk
dir:path/to/yourproject                read directly from a path on disk (any directory)
file:path/to/yourfile                  read directly from a file on disk
sbom:path/to/syft.json                 read Syft JSON from path on disk
registry:yourrepo/yourimage:tag        pull image directly from a registry (no container runtime required)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If an image source is not provided and cannot be detected from the given reference it is assumed the image should be pulled from the Docker daemon. If docker is not present, then the Podman daemon is attempted next, followed by reaching out directly to the image registry last.&lt;/p&gt; 
&lt;p&gt;This default behavior can be overridden with the &lt;code&gt;default-image-pull-source&lt;/code&gt; configuration option (See &lt;a href="https://github.com/anchore/grype#configuration"&gt;Configuration&lt;/a&gt; for more details).&lt;/p&gt; 
&lt;p&gt;Use SBOMs for even faster vulnerability scanning in Grype:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Then scan for new vulnerabilities as frequently as needed
grype sbom:./sbom.json

# (You can also pipe the SBOM into Grype)
cat ./sbom.json | grype
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Grype supports input of &lt;a href="https://github.com/anchore/syft"&gt;Syft&lt;/a&gt;, &lt;a href="https://spdx.dev/"&gt;SPDX&lt;/a&gt;, and &lt;a href="https://cyclonedx.org/"&gt;CycloneDX&lt;/a&gt; SBOM formats. If Syft has generated any of these file types, they should have the appropriate information to work properly with Grype. It is also possible to use SBOMs generated by other tools with varying degrees of success. Two things that make Grype matching more successful are the inclusion of CPE and Linux distribution information. If an SBOM does not include any CPE information, it is possible to generate these based on package information using the &lt;code&gt;--add-cpes-if-none&lt;/code&gt; flag. To specify a distribution, use the &lt;code&gt;--distro &amp;lt;distro&amp;gt;:&amp;lt;version&amp;gt;&lt;/code&gt; flag. A full example is:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;grype --add-cpes-if-none --distro alpine:3.10 sbom:some-alpine-3.10.spdx.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Threat &amp;amp; Risk Prioritization&lt;/h2&gt; 
&lt;p&gt;This section explains the columns and UI cues that help prioritize remediation efforts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Severity&lt;/strong&gt;: String-based severity derived from CVSS scores that indicates the significance of a vulnerability in levels. This balances concerns such as ease of exploitability, and the potential to affect confidentiality, integrity, and availability of software and services.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;EPSS&lt;/strong&gt;: &lt;a href="https://www.first.org/epss/model"&gt;Exploit Prediction Scoring System&lt;/a&gt; is a metric expressing the likelihood that a vulnerability will be exploited in the wild over the next 30 days (on a 0‚Äì1 scale); higher values signal a greater likelihood of exploitation. The table output shows the EPSS percentile, a one-way transform of the EPSS score showing the proportion of all scored vulnerabilities with an equal or lower probability. Percentiles linearize a heavily skewed distribution, making threshold choice (e.g. ‚Äúonly CVEs above the 90th percentile‚Äù) straightforward.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;KEV Indicator&lt;/strong&gt;: Flags entries from CISA‚Äôs &lt;a href="https://www.cisa.gov/known-exploited-vulnerabilities-catalog"&gt;Known Exploited Vulnerabilities Catalog&lt;/a&gt; --an authoritative list of flaws observed being exploited in the wild.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Risk Score&lt;/strong&gt;: A composite 0‚Äì100 metric calculated as:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-markdown"&gt;risk = min(1, threat * average(severity)) * 100
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Where:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;severity&lt;/code&gt; is the average of all CVSS scores and string severity for a vulnerability (scaled between 0‚Äì1).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;threat&lt;/code&gt; is the EPSS score (between 0‚Äì1). If the vulnerability is on the KEV list then &lt;code&gt;threat&lt;/code&gt; is &lt;code&gt;1.05&lt;/code&gt;, or &lt;code&gt;1.1&lt;/code&gt; if the vulnerability is associated with a ransomware campaign. This metric is one way to combine EPSS and CVSS suggested in the &lt;a href="https://www.first.org/epss/user-guide"&gt;EPSS user guide&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Suggested Fixes&lt;/strong&gt;: All possible fixes for a package are listed, however, when multiple fixes are available, we de-emphasize all upgrade paths except for the minimal upgrade path (which highlights the smallest, safest version bump).&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Results default to sorting by Risk Score and can be overridden with &lt;code&gt;--sort-by &amp;lt;value&amp;gt;&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;severity&lt;/code&gt;: sort by severity&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;epss&lt;/code&gt;: sort by EPSS percentile (aka, "threat")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;risk&lt;/code&gt;: sort by risk score&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;kev&lt;/code&gt;: just like risk, except that KEV entries are always above non-KEV entries&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;package&lt;/code&gt;: sort by package name, version, type&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vulnerability&lt;/code&gt;: sort by vulnerability ID&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Supported versions&lt;/h3&gt; 
&lt;p&gt;Software updates are always applied to the latest version of Grype; fixes are not backported to any previous versions of Grype.&lt;/p&gt; 
&lt;p&gt;In terms of database updates, any version of Grype before v0.51.0 (Oct 2022, before schema v5) will not receive vulnerability database updates. You can still build vulnerability databases for unsupported Grype releases by using previous releases of &lt;a href="https://github.com/anchore/vunnel"&gt;vunnel&lt;/a&gt; to gather the upstream data and &lt;a href="https://github.com/anchore/grype-db"&gt;grype-db&lt;/a&gt; to build databases for unsupported schemas.&lt;/p&gt; 
&lt;p&gt;Only the latest database schema is considered to be supported. When a new database schema is introduced then the one it replaces is marked as deprecated. Deprecated schemas will continue to receive updates for at least one year after they are marked as deprecated at which point they will no longer be supported.&lt;/p&gt; 
&lt;h3&gt;Working with attestations&lt;/h3&gt; 
&lt;p&gt;Grype supports scanning SBOMs as input via stdin. Users can use &lt;a href="https://github.com/sigstore/cosign"&gt;cosign&lt;/a&gt; to verify attestations with an SBOM as its content to scan an image for vulnerabilities:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;COSIGN_EXPERIMENTAL=1 cosign verify-attestation caphill4/java-spdx-tools:latest \
| jq -r .payload \
| base64 --decode \
| jq -r .predicate.Data \
| grype
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Vulnerability Summary&lt;/h3&gt; 
&lt;h4&gt;Basic Grype Vulnerability Data Shape&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt; {
  "vulnerability": {
    ...
  },
  "relatedVulnerabilities": [
    ...
  ],
  "matchDetails": [
    ...
  ],
  "artifact": {
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Vulnerability&lt;/strong&gt;: All information on the specific vulnerability that was directly matched on (e.g. ID, severity, CVSS score, fix information, links for more information)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RelatedVulnerabilities&lt;/strong&gt;: Information pertaining to vulnerabilities found to be related to the main reported vulnerability. Perhaps the vulnerability we matched on was a GitHub Security Advisory, which has an upstream CVE (in the authoritative national vulnerability database). In these cases we list the upstream vulnerabilities here.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MatchDetails&lt;/strong&gt;: This section tries to explain what we searched for while looking for a match and exactly what details on the package and vulnerability that led to a match.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Artifact&lt;/strong&gt;: This is a subset of the information that we know about the package (when compared to the &lt;a href="https://github.com/anchore/syft"&gt;Syft&lt;/a&gt; json output, we summarize the metadata section). This has information about where within the container image or directory we found the package, what kind of package it is, licensing info, pURLs, CPEs, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Excluding file paths&lt;/h3&gt; 
&lt;p&gt;Grype can exclude files and paths from being scanned within a source by using glob expressions with one or more &lt;code&gt;--exclude&lt;/code&gt; parameters:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;grype &amp;lt;source&amp;gt; --exclude './out/**/*.json' --exclude /etc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; in the case of &lt;em&gt;image scanning&lt;/em&gt;, since the entire filesystem is scanned it is possible to use absolute paths like &lt;code&gt;/etc&lt;/code&gt; or &lt;code&gt;/usr/**/*.txt&lt;/code&gt; whereas &lt;em&gt;directory scans&lt;/em&gt; exclude files &lt;em&gt;relative to the specified directory&lt;/em&gt;. For example: scanning &lt;code&gt;/usr/foo&lt;/code&gt; with &lt;code&gt;--exclude ./package.json&lt;/code&gt; would exclude &lt;code&gt;/usr/foo/package.json&lt;/code&gt; and &lt;code&gt;--exclude '**/package.json'&lt;/code&gt; would exclude all &lt;code&gt;package.json&lt;/code&gt; files under &lt;code&gt;/usr/foo&lt;/code&gt;. For &lt;em&gt;directory scans&lt;/em&gt;, it is required to begin path expressions with &lt;code&gt;./&lt;/code&gt;, &lt;code&gt;*/&lt;/code&gt;, or &lt;code&gt;**/&lt;/code&gt;, all of which will be resolved &lt;em&gt;relative to the specified scan directory&lt;/em&gt;. Keep in mind, your shell may attempt to expand wildcards, so put those parameters in single quotes, like: &lt;code&gt;'**/*.json'&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;External Sources&lt;/h3&gt; 
&lt;p&gt;Grype can be configured to incorporate external data sources for added fidelity in vulnerability matching. This feature is currently disabled by default. To enable this feature add the following to the grype config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;external-sources:
  enable: true
  maven:
    search-upstream-by-sha1: true
    base-url: https://search.maven.org/solrsearch/select
    rate-limit: 300ms # Time between Maven API requests
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also configure the base-url if you're using another registry as your maven endpoint.&lt;/p&gt; 
&lt;p&gt;The rate at which Maven API requests are made can be configured to match your environment's requirements. The default is 300ms between requests.&lt;/p&gt; 
&lt;h3&gt;Output formats&lt;/h3&gt; 
&lt;p&gt;The output format for Grype is configurable as well:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;grype &amp;lt;image&amp;gt; -o &amp;lt;format&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Where the formats available are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;table&lt;/code&gt;: A columnar summary (default).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cyclonedx&lt;/code&gt;: An XML report conforming to the &lt;a href="https://cyclonedx.org/specification/overview/"&gt;CycloneDX 1.6 specification&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cyclonedx-json&lt;/code&gt;: A JSON report conforming to the &lt;a href="https://cyclonedx.org/specification/overview/"&gt;CycloneDX 1.6 specification&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;json&lt;/code&gt;: Use this to get as much information out of Grype as possible!&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;sarif&lt;/code&gt;: Use this option to get a &lt;a href="https://docs.oasis-open.org/sarif/sarif/v2.1.0/sarif-v2.1.0.html"&gt;SARIF&lt;/a&gt; report (Static Analysis Results Interchange Format)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;template&lt;/code&gt;: Lets the user specify the output format. See &lt;a href="https://raw.githubusercontent.com/anchore/grype/main/#using-templates"&gt;"Using templates"&lt;/a&gt; below.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Using templates&lt;/h3&gt; 
&lt;p&gt;Grype lets you define custom output formats, using &lt;a href="https://golang.org/pkg/text/template/"&gt;Go templates&lt;/a&gt;. Here's how it works:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Define your format as a Go template, and save this template as a file.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Set the output format to "template" (&lt;code&gt;-o template&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Specify the path to the template file (&lt;code&gt;-t ./path/to/custom.template&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Grype's template processing uses the same data models as the &lt;code&gt;json&lt;/code&gt; output format ‚Äî so if you're wondering what data is available as you author a template, you can use the output from &lt;code&gt;grype &amp;lt;image&amp;gt; -o json&lt;/code&gt; as a reference.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Please note:&lt;/strong&gt; Templates can access information about the system they are running on, such as environment variables. You should never run untrusted templates.&lt;/p&gt; 
&lt;p&gt;There are several example templates in the &lt;a href="https://github.com/anchore/grype/tree/main/templates"&gt;templates&lt;/a&gt; directory in the Grype source which can serve as a starting point for a custom output format. For example, &lt;a href="https://github.com/anchore/grype/raw/main/templates/csv.tmpl"&gt;csv.tmpl&lt;/a&gt; produces a vulnerability report in CSV (comma separated value) format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;"Package","Version Installed","Vulnerability ID","Severity"
"coreutils","8.30-3ubuntu2","CVE-2016-2781","Low"
"libc-bin","2.31-0ubuntu9","CVE-2016-10228","Negligible"
"libc-bin","2.31-0ubuntu9","CVE-2020-6096","Low"
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also find the template for the default "table" output format in the same place.&lt;/p&gt; 
&lt;p&gt;Grype also includes a vast array of utility templating functions from &lt;a href="http://masterminds.github.io/sprig/"&gt;sprig&lt;/a&gt; apart from the default golang &lt;a href="https://pkg.go.dev/text/template#hdr-Functions"&gt;text/template&lt;/a&gt; to allow users to customize the output from Grype.&lt;/p&gt; 
&lt;h3&gt;Gating on severity of vulnerabilities&lt;/h3&gt; 
&lt;p&gt;You can have Grype exit with an error if any vulnerabilities are reported at or above the specified severity level. This comes in handy when using Grype within a script or CI pipeline. To do this, use the &lt;code&gt;--fail-on &amp;lt;severity&amp;gt;&lt;/code&gt; CLI flag.&lt;/p&gt; 
&lt;p&gt;For example, here's how you could trigger a CI pipeline failure if any vulnerabilities are found in the &lt;code&gt;ubuntu:latest&lt;/code&gt; image with a severity of "medium" or higher:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;grype ubuntu:latest --fail-on medium
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Grype returns exit code &lt;code&gt;2&lt;/code&gt; on vulnerability errors.&lt;/p&gt; 
&lt;h3&gt;Specifying matches to ignore&lt;/h3&gt; 
&lt;p&gt;If you're seeing Grype report &lt;strong&gt;false positives&lt;/strong&gt; or any other vulnerability matches that you just don't want to see, you can tell Grype to &lt;strong&gt;ignore&lt;/strong&gt; matches by specifying one or more &lt;em&gt;"ignore rules"&lt;/em&gt; in your Grype configuration file (e.g. &lt;code&gt;~/.grype.yaml&lt;/code&gt;). This causes Grype not to report any vulnerability matches that meet the criteria specified by any of your ignore rules.&lt;/p&gt; 
&lt;p&gt;Each rule can specify any combination of the following criteria:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;vulnerability ID (e.g. &lt;code&gt;"CVE-2008-4318"&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;include vulnerability aliases when matching on a vulnerability ID (set &lt;code&gt;"include-aliases"&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;namespace (e.g. &lt;code&gt;"nvd"&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;fix state (allowed values: &lt;code&gt;"fixed"&lt;/code&gt;, &lt;code&gt;"not-fixed"&lt;/code&gt;, &lt;code&gt;"wont-fix"&lt;/code&gt;, or &lt;code&gt;"unknown"&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;match type (allowed values: &lt;code&gt;"exact-direct-match"&lt;/code&gt;, &lt;code&gt;"exact-indirect-match"&lt;/code&gt;, or &lt;code&gt;"cpe-match"&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;package name (e.g. &lt;code&gt;"libcurl"&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;package version (e.g. &lt;code&gt;"1.5.1"&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;package language (e.g. &lt;code&gt;"python"&lt;/code&gt;; these values are defined &lt;a href="https://github.com/anchore/syft/raw/main/syft/pkg/language.go#L14-L23"&gt;here&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;package type (e.g. &lt;code&gt;"npm"&lt;/code&gt;; these values are defined &lt;a href="https://github.com/anchore/syft/raw/main/syft/pkg/type.go#L10-L24"&gt;here&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;package location (e.g. &lt;code&gt;"/usr/local/lib/node_modules/**"&lt;/code&gt;; supports glob patterns)&lt;/li&gt; 
 &lt;li&gt;package upstream name (e.g. &lt;code&gt;"curl"&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can also document a rule with a free-form &lt;code&gt;reason&lt;/code&gt;, and use VEX-specific fields (&lt;code&gt;vex-status&lt;/code&gt; and &lt;code&gt;vex-justification&lt;/code&gt;) when providing VEX data.&lt;/p&gt; 
&lt;p&gt;Here's an example &lt;code&gt;~/.grype.yaml&lt;/code&gt; that demonstrates the expected format for ignore rules:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;ignore:
  # This is the full set of supported rule fields:
  - vulnerability: CVE-2008-4318
    include-aliases: true
    reason: "False positive due to bundled curl version"
    fix-state: unknown
    namespace: nvd
    # VEX fields apply when Grype reads vex data:
    vex-status: not_affected
    vex-justification: vulnerable_code_not_present
    match-type: exact-direct-match
    package:
      name: libcurl
      version: 1.5.1
      language: python
      type: npm
      location: "/usr/local/lib/node_modules/**"
      upstream-name: curl

  # We can make rules to match just by vulnerability ID:
  - vulnerability: CVE-2014-54321

  # ...or just by a single package field:
  - package:
      type: gem
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Vulnerability matches will be ignored if &lt;strong&gt;any&lt;/strong&gt; rules apply to the match. A rule is considered to apply to a given vulnerability match only if &lt;strong&gt;all&lt;/strong&gt; fields specified in the rule apply to the vulnerability match.&lt;/p&gt; 
&lt;p&gt;When you run Grype while specifying ignore rules, the following happens to the vulnerability matches that are "ignored":&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ignored matches are &lt;strong&gt;completely hidden&lt;/strong&gt; from Grype's output, except for when using the &lt;code&gt;json&lt;/code&gt; or &lt;code&gt;template&lt;/code&gt; output formats; however, in these two formats, the ignored matches are &lt;strong&gt;removed&lt;/strong&gt; from the existing &lt;code&gt;matches&lt;/code&gt; array field, and they are placed in a new &lt;code&gt;ignoredMatches&lt;/code&gt; array field. Each listed ignored match also has an additional field, &lt;code&gt;appliedIgnoreRules&lt;/code&gt;, which is an array of any rules that caused Grype to ignore this vulnerability match.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ignored matches &lt;strong&gt;do not&lt;/strong&gt; factor into Grype's exit status decision when using &lt;code&gt;--fail-on &amp;lt;severity&amp;gt;&lt;/code&gt;. For instance, if a user specifies &lt;code&gt;--fail-on critical&lt;/code&gt;, and all of the vulnerability matches found with a "critical" severity have been &lt;em&gt;ignored&lt;/em&gt;, Grype will exit zero.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Please continue to &lt;strong&gt;&lt;a href="https://github.com/anchore/grype/issues/new/choose"&gt;report&lt;/a&gt;&lt;/strong&gt; any false positives you see! Even if you can reliably filter out false positives using ignore rules, it's very helpful to the Grype community if we have as much knowledge about Grype's false positives as possible. This helps us continuously improve Grype!&lt;/p&gt; 
&lt;h3&gt;Showing only "fixed" vulnerabilities&lt;/h3&gt; 
&lt;p&gt;If you only want Grype to report vulnerabilities &lt;strong&gt;that have a confirmed fix&lt;/strong&gt;, you can use the &lt;code&gt;--only-fixed&lt;/code&gt; flag. (This automatically adds &lt;a href="https://raw.githubusercontent.com/anchore/grype/main/#specifying-matches-to-ignore"&gt;ignore rules&lt;/a&gt; into Grype's configuration, such that vulnerabilities that aren't fixed will be ignored.)&lt;/p&gt; 
&lt;p&gt;For example, here's a scan of Alpine 3.10:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;NAME          INSTALLED  FIXED-IN   VULNERABILITY   SEVERITY
apk-tools     2.10.6-r0  2.10.7-r0  CVE-2021-36159  Critical
libcrypto1.1  1.1.1k-r0             CVE-2021-3711   Critical
libcrypto1.1  1.1.1k-r0             CVE-2021-3712   High
libssl1.1     1.1.1k-r0             CVE-2021-3712   High
libssl1.1     1.1.1k-r0             CVE-2021-3711   Critical
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;...and here's the same scan, but adding the flag &lt;code&gt;--only-fixed&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;NAME       INSTALLED  FIXED-IN   VULNERABILITY   SEVERITY
apk-tools  2.10.6-r0  2.10.7-r0  CVE-2021-36159  Critical
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want Grype to only report vulnerabilities &lt;strong&gt;that do not have a confirmed fix&lt;/strong&gt;, you can use the &lt;code&gt;--only-notfixed&lt;/code&gt; flag. Alternatively, you can use the &lt;code&gt;--ignore-states&lt;/code&gt; flag to filter results for vulnerabilities with specific states such as &lt;code&gt;wont-fix&lt;/code&gt; (see &lt;code&gt;--help&lt;/code&gt; for a list of valid fix states). These flags automatically add &lt;a href="https://raw.githubusercontent.com/anchore/grype/main/#specifying-matches-to-ignore"&gt;ignore rules&lt;/a&gt; into Grype's configuration, such that vulnerabilities which are fixed, or will not be fixed, will be ignored.&lt;/p&gt; 
&lt;h2&gt;VEX Support&lt;/h2&gt; 
&lt;p&gt;Grype can use VEX (Vulnerability Exploitability Exchange) data to filter false positives or provide additional context, augmenting matches. When scanning a container image, you can use the &lt;code&gt;--vex&lt;/code&gt; flag to point to one or more &lt;a href="https://github.com/openvex"&gt;OpenVEX&lt;/a&gt; documents.&lt;/p&gt; 
&lt;p&gt;VEX statements relate a product (a container image), a vulnerability, and a VEX status to express an assertion of the vulnerability's impact. There are four &lt;a href="https://github.com/openvex/spec/raw/main/OPENVEX-SPEC.md#status-labels"&gt;VEX statuses&lt;/a&gt;: &lt;code&gt;not_affected&lt;/code&gt;, &lt;code&gt;affected&lt;/code&gt;, &lt;code&gt;fixed&lt;/code&gt; and &lt;code&gt;under_investigation&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Here is an example of a simple OpenVEX document. (tip: use &lt;a href="https://github.com/openvex/vexctl"&gt;&lt;code&gt;vexctl&lt;/code&gt;&lt;/a&gt; to generate your own documents).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "@context": "https://openvex.dev/ns/v0.2.0",
  "@id": "https://openvex.dev/docs/public/vex-d4e9020b6d0d26f131d535e055902dd6ccf3e2088bce3079a8cd3588a4b14c78",
  "author": "A Grype User &amp;lt;jdoe@example.com&amp;gt;",
  "timestamp": "2023-07-17T18:28:47.696004345-06:00",
  "version": 1,
  "statements": [
    {
      "vulnerability": {
        "name": "CVE-2023-1255"
      },
      "products": [
        {
          "@id": "pkg:oci/alpine@sha256%3A124c7d2707904eea7431fffe91522a01e5a861a624ee31d03372cc1d138a3126",
          "subcomponents": [
            { "@id": "pkg:apk/alpine/libssl3@3.0.8-r3" },
            { "@id": "pkg:apk/alpine/libcrypto3@3.0.8-r3" }
          ]
        }
      ],
      "status": "fixed"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, Grype will use any statements in specified VEX documents with a status of &lt;code&gt;not_affected&lt;/code&gt; or &lt;code&gt;fixed&lt;/code&gt; to move matches to the ignore set.&lt;/p&gt; 
&lt;p&gt;Any matches ignored as a result of VEX statements are flagged when using &lt;code&gt;--show-suppressed&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;libcrypto3  3.0.8-r3   3.0.8-r4   apk   CVE-2023-1255  Medium (suppressed by VEX)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Statements with an &lt;code&gt;affected&lt;/code&gt; or &lt;code&gt;under_investigation&lt;/code&gt; status will only be considered to augment the result set when specifically requested using the &lt;code&gt;GRYPE_VEX_ADD&lt;/code&gt; environment variable or in a configuration file.&lt;/p&gt; 
&lt;h3&gt;VEX Ignore Rules&lt;/h3&gt; 
&lt;p&gt;Ignore rules can be written to control how Grype honors VEX statements. For example, to configure Grype to only act on VEX statements when the justification is &lt;code&gt;vulnerable_code_not_present&lt;/code&gt;, you can write a rule like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;---
ignore:
  - vex-status: not_affected
    vex-justification: vulnerable_code_not_present
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/openvex/spec/raw/main/OPENVEX-SPEC.md#status-justifications"&gt;list of justifications&lt;/a&gt; for details. You can mix &lt;code&gt;vex-status&lt;/code&gt; and &lt;code&gt;vex-justification&lt;/code&gt; with other ignore rule parameters.&lt;/p&gt; 
&lt;h2&gt;Grype's database&lt;/h2&gt; 
&lt;p&gt;When Grype performs a scan for vulnerabilities, it does so using a vulnerability database that's stored on your local filesystem, which is constructed by pulling data from a variety of publicly available vulnerability data sources. These sources include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Alpine Linux SecDB: &lt;a href="https://secdb.alpinelinux.org/"&gt;https://secdb.alpinelinux.org/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Amazon Linux ALAS: &lt;a href="https://alas.aws.amazon.com/AL2/alas.rss"&gt;https://alas.aws.amazon.com/AL2/alas.rss&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Chainguard SecDB: &lt;a href="https://packages.cgr.dev/chainguard/security.json"&gt;https://packages.cgr.dev/chainguard/security.json&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Debian Linux CVE Tracker: &lt;a href="https://security-tracker.debian.org/tracker/data/json"&gt;https://security-tracker.debian.org/tracker/data/json&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Echo Security Advisories: &lt;a href="https://advisory.echohq.com/data.json"&gt;https://advisory.echohq.com/data.json&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub Security Advisories (GHSAs): &lt;a href="https://github.com/advisories"&gt;https://github.com/advisories&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;MinimOS SecDB: &lt;a href="https://packages.mini.dev/advisories/secdb/security.json"&gt;https://packages.mini.dev/advisories/secdb/security.json&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;National Vulnerability Database (NVD): &lt;a href="https://nvd.nist.gov/vuln/data-feeds"&gt;https://nvd.nist.gov/vuln/data-feeds&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Oracle Linux OVAL: &lt;a href="https://linux.oracle.com/security/oval/"&gt;https://linux.oracle.com/security/oval/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RedHat Linux Security Data: &lt;a href="https://access.redhat.com/hydra/rest/securitydata/"&gt;https://access.redhat.com/hydra/rest/securitydata/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RedHat RHSAs: &lt;a href="https://www.redhat.com/security/data/oval/"&gt;https://www.redhat.com/security/data/oval/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;SUSE Linux OVAL: &lt;a href="https://ftp.suse.com/pub/projects/security/oval/"&gt;https://ftp.suse.com/pub/projects/security/oval/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ubuntu Linux Security: &lt;a href="https://people.canonical.com/~ubuntu-security/"&gt;https://people.canonical.com/~ubuntu-security/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Wolfi SecDB: &lt;a href="https://packages.wolfi.dev/os/security.json"&gt;https://packages.wolfi.dev/os/security.json&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By default, Grype automatically manages this database for you. Grype checks for new updates to the vulnerability database to make sure that every scan uses up-to-date vulnerability information. This behavior is configurable. For more information, see the &lt;a href="https://raw.githubusercontent.com/anchore/grype/main/#managing-grypes-database"&gt;Managing Grype's database&lt;/a&gt; section.&lt;/p&gt; 
&lt;h3&gt;How database updates work&lt;/h3&gt; 
&lt;p&gt;Grype's vulnerability database is a SQLite file, named &lt;code&gt;vulnerability.db&lt;/code&gt;. Updates to the database are atomic: the entire database is replaced and then treated as "readonly" by Grype.&lt;/p&gt; 
&lt;p&gt;Grype's first step in a database update is discovering databases that are available for retrieval. Grype does this by requesting a "latest database file" from a public endpoint:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://grype.anchore.io/databases/v6/latest.json"&gt;https://grype.anchore.io/databases/v6/latest.json&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The latest database file contains an entry for the most recent database available for download.&lt;/p&gt; 
&lt;p&gt;Here's an example of an entry in the latest database file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "status": "active",
  "schemaVersion": "6.0.0",
  "built": "2025-02-11T04:06:41Z",
  "path": "vulnerability-db_v6.0.0_2025-02-11T01:30:51Z_1739246801.tar.zst",
  "checksum": "sha256:79bfa04265c5a32d21773ad0da1bda13c31e932fa1e1422db635c8d714038868"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With this information, Grype can find the most recently built database with the current schema version, download the database, and verify the database's integrity using the &lt;code&gt;checksum&lt;/code&gt; value.&lt;/p&gt; 
&lt;h3&gt;Managing Grype's database&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; During normal usage, &lt;em&gt;there is no need for users to manage Grype's database!&lt;/em&gt; Grype manages its database behind the scenes. However, for users that need more control, Grype provides options to manage the database more explicitly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Local database cache directory&lt;/h4&gt; 
&lt;p&gt;By default, the database is cached on the local filesystem in the directory &lt;code&gt;$XDG_CACHE_HOME/grype/db/&amp;lt;SCHEMA-VERSION&amp;gt;/&lt;/code&gt;. For example, on macOS, the database would be stored in &lt;code&gt;~/Library/Caches/grype/db/6/&lt;/code&gt;. (For more information on XDG paths, refer to the &lt;a href="https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html"&gt;XDG Base Directory Specification&lt;/a&gt;.)&lt;/p&gt; 
&lt;p&gt;You can set the cache directory path using the environment variable &lt;code&gt;GRYPE_DB_CACHE_DIR&lt;/code&gt;. If setting that variable alone does not work, then the &lt;code&gt;TMPDIR&lt;/code&gt; environment variable might also need to be set.&lt;/p&gt; 
&lt;h4&gt;Data staleness&lt;/h4&gt; 
&lt;p&gt;Grype needs up-to-date vulnerability information to provide accurate matches. By default, it will fail execution if the local database was not built in the last 5 days. The data staleness check is configurable via the environment variable &lt;code&gt;GRYPE_DB_MAX_ALLOWED_BUILT_AGE&lt;/code&gt; and &lt;code&gt;GRYPE_DB_VALIDATE_AGE&lt;/code&gt; or the field &lt;code&gt;max-allowed-built-age&lt;/code&gt; and &lt;code&gt;validate-age&lt;/code&gt;, under &lt;code&gt;db&lt;/code&gt;. It uses &lt;a href="https://pkg.go.dev/time#ParseDuration"&gt;golang's time duration syntax&lt;/a&gt;. Set &lt;code&gt;GRYPE_DB_VALIDATE_AGE&lt;/code&gt; or &lt;code&gt;validate-age&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt; to disable staleness check.&lt;/p&gt; 
&lt;h4&gt;Offline and air-gapped environments&lt;/h4&gt; 
&lt;p&gt;By default, Grype checks for a new database on every run, by making a network request over the internet. You can tell Grype not to perform this check by setting the environment variable &lt;code&gt;GRYPE_DB_AUTO_UPDATE&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;As long as you place Grype's &lt;code&gt;vulnerability.db&lt;/code&gt; and &lt;code&gt;import.json&lt;/code&gt; files in the cache directory for the expected schema version, Grype has no need to access the network. Additionally, you can get a reference to the latest database archive for download from the &lt;code&gt;grype db list&lt;/code&gt; command in an online environment, download the database archive, transfer it to your offline environment, and use &lt;code&gt;grype db import &amp;lt;db-archive-path&amp;gt;&lt;/code&gt; to use the given database in an offline capacity.&lt;/p&gt; 
&lt;p&gt;If you would like to distribute your own Grype databases internally without needing to use &lt;code&gt;db import&lt;/code&gt; manually you can leverage Grype's DB update mechanism. To do this you can craft your own &lt;code&gt;latest.json&lt;/code&gt; file similar to the public "latest database file" and change the download URL to point to an internal endpoint (e.g. a private S3 bucket, an internal file server, etc.). Any internal installation of Grype can receive database updates automatically by configuring the &lt;code&gt;db.update-url&lt;/code&gt; (same as the &lt;code&gt;GRYPE_DB_UPDATE_URL&lt;/code&gt; environment variable) to point to the hosted &lt;code&gt;latest.json&lt;/code&gt; file you've crafted.&lt;/p&gt; 
&lt;h4&gt;CLI commands for database management&lt;/h4&gt; 
&lt;p&gt;Grype provides database-specific CLI commands for users that want to control the database from the command line. Here are some of the useful commands provided:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;grype db status&lt;/code&gt; ‚Äî report the current status of Grype's database (such as its location, build date, and checksum)&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;grype db check&lt;/code&gt; ‚Äî see if updates are available for the database&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;grype db update&lt;/code&gt; ‚Äî ensure the latest database has been downloaded to the cache directory (Grype performs this operation at the beginning of every scan by default)&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;grype db list&lt;/code&gt; ‚Äî download the latest database file configured at &lt;code&gt;db.update-url&lt;/code&gt; and show the database available for download&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;grype db import&lt;/code&gt; ‚Äî provide grype with a database archive to explicitly use (useful for offline DB updates)&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;grype db providers&lt;/code&gt; - provides a detailed list of database providers&lt;/p&gt; 
&lt;p&gt;Find complete information on Grype's database commands by running &lt;code&gt;grype db --help&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Shell completion&lt;/h2&gt; 
&lt;p&gt;Grype supplies shell completion through its CLI implementation (&lt;a href="https://github.com/spf13/cobra/raw/master/shell_completions.md"&gt;cobra&lt;/a&gt;). Generate the completion code for your shell by running one of the following commands:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;grype completion &amp;lt;bash|zsh|fish&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;go run ./cmd/grype completion &amp;lt;bash|zsh|fish&amp;gt;&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This will output a shell script to STDOUT, which can then be used as a completion script for Grype. Running one of the above commands with the &lt;code&gt;-h&lt;/code&gt; or &lt;code&gt;--help&lt;/code&gt; flags will provide instructions on how to do that for your chosen shell.&lt;/p&gt; 
&lt;h2&gt;Private Registry Authentication&lt;/h2&gt; 
&lt;h3&gt;Local Docker Credentials&lt;/h3&gt; 
&lt;p&gt;When a container runtime is not present, grype can still utilize credentials configured in common credential sources (such as &lt;code&gt;~/.docker/config.json&lt;/code&gt;). It will pull images from private registries using these credentials. The config file is where your credentials are stored when authenticating with private registries via some command like &lt;code&gt;docker login&lt;/code&gt;. For more information see the &lt;code&gt;go-containerregistry&lt;/code&gt; &lt;a href="https://github.com/google/go-containerregistry/tree/main/pkg/authn"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;An example &lt;code&gt;config.json&lt;/code&gt; looks something like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;// config.json
{
  "auths": {
    "registry.example.com": {
      "username": "AzureDiamond",
      "password": "hunter2"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can run the following command as an example. It details the mount/environment configuration a container needs to access a private registry:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;docker run -v ./config.json:/config/config.json -e "DOCKER_CONFIG=/config" anchore/grype:latest &amp;lt;private_image&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Docker Credentials in Kubernetes&lt;/h3&gt; 
&lt;p&gt;The below section shows a simple workflow on how to mount this config file as a secret into a container on kubernetes.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a secret. The value of &lt;code&gt;config.json&lt;/code&gt; is important. It refers to the specification detailed &lt;a href="https://github.com/google/go-containerregistry/tree/main/pkg/authn#the-config-file"&gt;here&lt;/a&gt;. Below this section is the &lt;code&gt;secret.yaml&lt;/code&gt; file that the pod configuration will consume as a volume. The key &lt;code&gt;config.json&lt;/code&gt; is important. It will end up being the name of the file when mounted into the pod. &lt;pre&gt;&lt;code class="language-#"&gt;
    apiVersion: v1
    kind: Secret
    metadata:
      name: registry-config
      namespace: grype
    data:
      config.json: &amp;lt;base64 encoded config.json&amp;gt;
    ```

    `kubectl apply -f secret.yaml`

&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Create your pod running grype. The env &lt;code&gt;DOCKER_CONFIG&lt;/code&gt; is important because it advertises where to look for the credential file. In the below example, setting &lt;code&gt;DOCKER_CONFIG=/config&lt;/code&gt; informs grype that credentials can be found at &lt;code&gt;/config/config.json&lt;/code&gt;. This is why we used &lt;code&gt;config.json&lt;/code&gt; as the key for our secret. When mounted into containers the secrets' key is used as the filename. The &lt;code&gt;volumeMounts&lt;/code&gt; section mounts our secret to &lt;code&gt;/config&lt;/code&gt;. The &lt;code&gt;volumes&lt;/code&gt; section names our volume and leverages the secret we created in step one. &lt;pre&gt;&lt;code class="language-#"&gt;
    apiVersion: v1
    kind: Pod
    spec:
      containers:
        - image: anchore/grype:latest
          name: grype-private-registry-demo
          env:
            - name: DOCKER_CONFIG
              value: /config
          volumeMounts:
          - mountPath: /config
            name: registry-config
            readOnly: true
          args:
            - &amp;lt;private_image&amp;gt;
      volumes:
      - name: registry-config
        secret:
          secretName: registry-config
    ```

    `kubectl apply -f pod.yaml`

&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;The user can now run &lt;code&gt;kubectl logs grype-private-registry-demo&lt;/code&gt;. The logs should show the grype analysis for the &lt;code&gt;&amp;lt;private_image&amp;gt;&lt;/code&gt; provided in the pod configuration.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Using the above information, users should be able to configure private registry access without having to do so in the &lt;code&gt;grype&lt;/code&gt; or &lt;code&gt;syft&lt;/code&gt; configuration files. They will also not be dependent on a docker daemon, (or some other runtime software) for registry configuration and access.&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Default configuration search paths (see all with &lt;code&gt;grype config locations&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;.grype.yaml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;.grype/config.yaml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;~/.grype.yaml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;&amp;lt;XDG_CONFIG_HOME&amp;gt;/grype/config.yaml&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Use &lt;code&gt;grype config&lt;/code&gt; to print a sample config file to stdout. Use &lt;code&gt;grype config --load&lt;/code&gt; to print the current config after loading all values to stdout.&lt;/p&gt; 
&lt;p&gt;You can specify files directly using the &lt;code&gt;--config&lt;/code&gt; / &lt;code&gt;-c&lt;/code&gt; flags (or environment variable &lt;code&gt;GRYPE_CONFIG&lt;/code&gt;) to provide your own configuration files/paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Using the flag
grype &amp;lt;image&amp;gt; -c /path/to/config.yaml
# Or using the environment variable
GRYPE_CONFIG=/path/to/config.yaml grype &amp;lt;image&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Configuration options (example values are the default):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# the output format of the vulnerability report (options: table, template, json, cyclonedx)
# when using template as the output type, you must also provide a value for 'output-template-file' (env: GRYPE_OUTPUT)
output: 'table'

# if using template output, you must provide a path to a Go template file
# see https://github.com/anchore/grype#using-templates for more information on template output
# the default path to the template file is the current working directory
# output-template-file: .grype/html.tmpl
#
# write output report to a file (default is to write to stdout) (env: GRYPE_FILE)
file: ''

# pretty-print JSON output (env: GRYPE_PRETTY)
pretty: false

# distro to match against in the format: &amp;lt;distro&amp;gt;:&amp;lt;version&amp;gt; (env: GRYPE_DISTRO)
distro: ''

# generate CPEs for packages with no CPE data (env: GRYPE_ADD_CPES_IF_NONE)
add-cpes-if-none: false

# specify the path to a Go template file (requires 'template' output to be selected) (env: GRYPE_OUTPUT_TEMPLATE_FILE)
output-template-file: ''

# enable/disable checking for application updates on startup (env: GRYPE_CHECK_FOR_APP_UPDATE)
check-for-app-update: true

# ignore matches for vulnerabilities that are not fixed (env: GRYPE_ONLY_FIXED)
only-fixed: false

# ignore matches for vulnerabilities that are fixed (env: GRYPE_ONLY_NOTFIXED)
only-notfixed: false

# ignore matches for vulnerabilities with specified comma separated fix states, options=[fixed not-fixed unknown wont-fix] (env: GRYPE_IGNORE_WONTFIX)
ignore-wontfix: ''

# an optional platform specifier for container image sources (e.g. 'linux/arm64', 'linux/arm64/v8', 'arm64', 'linux') (env: GRYPE_PLATFORM)
platform: ''

# upon scanning, if a severity is found at or above the given severity then the return code will be 1
# default is unset which will skip this validation (options: negligible, low, medium, high, critical) (env: GRYPE_FAIL_ON_SEVERITY)
fail-on-severity: ''

# show suppressed/ignored vulnerabilities in the output (only supported with table output format) (env: GRYPE_SHOW_SUPPRESSED)
show-suppressed: false

# orient results by CVE instead of the original vulnerability ID when possible (env: GRYPE_BY_CVE)
by-cve: false

# sort the match results with the given strategy, options=[package severity epss risk kev vulnerability] (env: GRYPE_SORT_BY)
sort-by: 'risk'

# same as --name; set the name of the target being analyzed (env: GRYPE_NAME)
name: ''

# allows users to specify which image source should be used to generate the sbom
# valid values are: registry, docker, podman (env: GRYPE_DEFAULT_IMAGE_PULL_SOURCE)
default-image-pull-source: ''

search:
  # selection of layers to analyze, options=[squashed all-layers] (env: GRYPE_SEARCH_SCOPE)
  scope: 'squashed'

  # search within archives that do not contain a file index to search against (tar, tar.gz, tar.bz2, etc)
  # note: enabling this may result in a performance impact since all discovered compressed tars will be decompressed
  # note: for now this only applies to the java package cataloger (env: GRYPE_SEARCH_UNINDEXED_ARCHIVES)
  unindexed-archives: false

  # search within archives that do contain a file index to search against (zip)
  # note: for now this only applies to the java package cataloger (env: GRYPE_SEARCH_INDEXED_ARCHIVES)
  indexed-archives: true

# A list of vulnerability ignore rules, one or more property may be specified and all matching vulnerabilities will be ignored.
# This is the full set of supported rule fields:
#   - vulnerability: CVE-2008-4318
#     fix-state: unknown
#     package:
#       name: libcurl
#       version: 1.5.1
#       type: npm
#       location: "/usr/local/lib/node_modules/**"
#
# VEX fields apply when Grype reads vex data:
#   - vex-status: not_affected
#     vex-justification: vulnerable_code_not_present
ignore: []

# a list of globs to exclude from scanning, for example:
#   - '/etc/**'
#   - './out/**/*.json'
# same as --exclude (env: GRYPE_EXCLUDE)
exclude: []

external-sources:
  # enable Grype searching network source for additional information (env: GRYPE_EXTERNAL_SOURCES_ENABLE)
  enable: false

  maven:
    # search for Maven artifacts by SHA1 (env: GRYPE_EXTERNAL_SOURCES_MAVEN_SEARCH_MAVEN_UPSTREAM)
    search-maven-upstream: true

    # base URL of the Maven repository to search (env: GRYPE_EXTERNAL_SOURCES_MAVEN_BASE_URL)
    base-url: 'https://search.maven.org/solrsearch/select'

    # (env: GRYPE_EXTERNAL_SOURCES_MAVEN_RATE_LIMIT)
    rate-limit: 300ms

match:
  java:
    # use CPE matching to find vulnerabilities (env: GRYPE_MATCH_JAVA_USING_CPES)
    using-cpes: false

  jvm:
    # (env: GRYPE_MATCH_JVM_USING_CPES)
    using-cpes: true

  dotnet:
    # use CPE matching to find vulnerabilities (env: GRYPE_MATCH_DOTNET_USING_CPES)
    using-cpes: false

  golang:
    # use CPE matching to find vulnerabilities (env: GRYPE_MATCH_GOLANG_USING_CPES)
    using-cpes: false

    # use CPE matching to find vulnerabilities for the Go standard library (env: GRYPE_MATCH_GOLANG_ALWAYS_USE_CPE_FOR_STDLIB)
    always-use-cpe-for-stdlib: true

    # allow comparison between main module pseudo-versions (e.g. v0.0.0-20240413-2b432cf643...) (env: GRYPE_MATCH_GOLANG_ALLOW_MAIN_MODULE_PSEUDO_VERSION_COMPARISON)
    allow-main-module-pseudo-version-comparison: false

  javascript:
    # use CPE matching to find vulnerabilities (env: GRYPE_MATCH_JAVASCRIPT_USING_CPES)
    using-cpes: false

  python:
    # use CPE matching to find vulnerabilities (env: GRYPE_MATCH_PYTHON_USING_CPES)
    using-cpes: false

  ruby:
    # use CPE matching to find vulnerabilities (env: GRYPE_MATCH_RUBY_USING_CPES)
    using-cpes: false

  rust:
    # use CPE matching to find vulnerabilities (env: GRYPE_MATCH_RUST_USING_CPES)
    using-cpes: false

  stock:
    # use CPE matching to find vulnerabilities (env: GRYPE_MATCH_STOCK_USING_CPES)
    using-cpes: true


registry:
  # skip TLS verification when communicating with the registry (env: GRYPE_REGISTRY_INSECURE_SKIP_TLS_VERIFY)
  insecure-skip-tls-verify: false

  # use http instead of https when connecting to the registry (env: GRYPE_REGISTRY_INSECURE_USE_HTTP)
  insecure-use-http: false

  # Authentication credentials for specific registries. Each entry describes authentication for a specific authority:
  # -   authority: the registry authority URL the URL to the registry (e.g. "docker.io", "localhost:5000", etc.) (env: SYFT_REGISTRY_AUTH_AUTHORITY)
  #     username: a username if using basic credentials (env: SYFT_REGISTRY_AUTH_USERNAME)
  #     password: a corresponding password (env: SYFT_REGISTRY_AUTH_PASSWORD)
  #     token: a token if using token-based authentication, mutually exclusive with username/password (env: SYFT_REGISTRY_AUTH_TOKEN)
  #     tls-cert: filepath to the client certificate used for TLS authentication to the registry (env: SYFT_REGISTRY_AUTH_TLS_CERT)
  #     tls-key: filepath to the client key used for TLS authentication to the registry (env: SYFT_REGISTRY_AUTH_TLS_KEY)
  auth: []

  # filepath to a CA certificate (or directory containing *.crt, *.cert, *.pem) used to generate the client certificate (env: GRYPE_REGISTRY_CA_CERT)
  ca-cert: ''

# a list of VEX documents to consider when producing scanning results (env: GRYPE_VEX_DOCUMENTS)
vex-documents: []

# VEX statuses to consider as ignored rules (env: GRYPE_VEX_ADD)
vex-add: []

# match kernel-header packages with upstream kernel as kernel vulnerabilities (env: GRYPE_MATCH_UPSTREAM_KERNEL_HEADERS)
match-upstream-kernel-headers: false

db:
  # location to write the vulnerability database cache (env: GRYPE_DB_CACHE_DIR)
  cache-dir: '~/Library/Caches/grype/db'

  # URL of the vulnerability database (env: GRYPE_DB_UPDATE_URL)
  update-url: 'https://grype.anchore.io/databases'

  # certificate to trust download the database and listing file (env: GRYPE_DB_CA_CERT)
  ca-cert: ''

  # check for database updates on execution (env: GRYPE_DB_AUTO_UPDATE)
  auto-update: true

  # validate the database matches the known hash each execution (env: GRYPE_DB_VALIDATE_BY_HASH_ON_START)
  validate-by-hash-on-start: true

  # ensure db build is no older than the max-allowed-built-age (env: GRYPE_DB_VALIDATE_AGE)
  validate-age: true

  # Max allowed age for vulnerability database,
  # age being the time since it was built
  # Default max age is 120h (or five days) (env: GRYPE_DB_MAX_ALLOWED_BUILT_AGE)
  max-allowed-built-age: 120h0m0s

  # fail the scan if unable to check for database updates (env: GRYPE_DB_REQUIRE_UPDATE_CHECK)
  require-update-check: false

  # Timeout for downloading GRYPE_DB_UPDATE_URL to see if the database needs to be downloaded
  # This file is ~156KiB as of 2024-04-17 so the download should be quick; adjust as needed (env: GRYPE_DB_UPDATE_AVAILABLE_TIMEOUT)
  update-available-timeout: 30s

  # Timeout for downloading actual vulnerability DB
  # The DB is ~156MB as of 2024-04-17 so slower connections may exceed the default timeout; adjust as needed (env: GRYPE_DB_UPDATE_DOWNLOAD_TIMEOUT)
  update-download-timeout: 5m0s

  # Maximum frequency to check for vulnerability database updates (env: GRYPE_DB_MAX_UPDATE_CHECK_FREQUENCY)
  max-update-check-frequency: 2h0m0s

log:
  # suppress all logging output (env: GRYPE_LOG_QUIET)
  quiet: false

  # explicitly set the logging level (available: [error warn info debug trace]) (env: GRYPE_LOG_LEVEL)
  level: 'warn'

  # file path to write logs to (env: GRYPE_LOG_FILE)
  file: ''

dev:
  # capture resource profiling data (available: [cpu, mem]) (env: GRYPE_DEV_PROFILE)
  profile: ''

  db:
    # show sql queries in trace logging (requires -vv) (env: GRYPE_DEV_DB_DEBUG)
    debug: false

# include a timestamp (env: GRYPE_TIMESTAMP)
timestamp: true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Future plans&lt;/h2&gt; 
&lt;p&gt;The following areas of potential development are currently being investigated:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support for allowlist, package mapping&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Grype Logo&lt;/h2&gt; 
&lt;p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"&gt;&lt;a property="dct:title" rel="cc:attributionURL" href="https://anchore.com/wp-content/uploads/2024/11/grype-logo.svg"&gt;Grype Logo&lt;/a&gt; by &lt;a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://anchore.com/"&gt;Anchore&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"&gt;CC BY 4.0&lt;img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?sanitize=true" alt="" /&gt;&lt;img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>charmbracelet/crush</title>
      <link>https://github.com/charmbracelet/crush</link>
      <description>&lt;p&gt;The glamourous AI coding agent for your favourite terminal üíò&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Crush&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://stuff.charm.sh/crush/charm-crush.png"&gt;&lt;img width="450" alt="Charm Crush Logo" src="https://github.com/user-attachments/assets/adc1a6f4-b284-4603-836c-59038caa2e8b" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/charmbracelet/crush/releases"&gt;&lt;img src="https://img.shields.io/github/release/charmbracelet/crush" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/charmbracelet/crush/actions"&gt;&lt;img src="https://github.com/charmbracelet/crush/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Your new coding bestie, now available in your favourite terminal.&lt;br /&gt;Your tools, your code, and your workflows, wired into your LLM of choice.&lt;/p&gt; 
&lt;p align="center"&gt;‰Ω†ÁöÑÊñ∞ÁºñÁ®ã‰ºô‰º¥ÔºåÁé∞Âú®Â∞±Âú®‰Ω†ÊúÄÁà±ÁöÑÁªàÁ´Ø‰∏≠„ÄÇ&lt;br /&gt;‰Ω†ÁöÑÂ∑•ÂÖ∑„ÄÅ‰ª£Á†ÅÂíåÂ∑•‰ΩúÊµÅÔºåÈÉΩ‰∏éÊÇ®ÈÄâÊã©ÁöÑ LLM Ê®°ÂûãÁ¥ßÂØÜÁõ∏Ëøû„ÄÇ&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img width="800" alt="Crush Demo" src="https://github.com/user-attachments/assets/58280caf-851b-470a-b6f7-d5c4ea8a1968" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Model:&lt;/strong&gt; choose from a wide range of LLMs or add your own via OpenAI- or Anthropic-compatible APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible:&lt;/strong&gt; switch LLMs mid-session while preserving context&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session-Based:&lt;/strong&gt; maintain multiple work sessions and contexts per project&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LSP-Enhanced:&lt;/strong&gt; Crush uses LSPs for additional context, just like you do&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible:&lt;/strong&gt; add capabilities via MCPs (&lt;code&gt;http&lt;/code&gt;, &lt;code&gt;stdio&lt;/code&gt;, and &lt;code&gt;sse&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Works Everywhere:&lt;/strong&gt; first-class support in every terminal on macOS, Linux, Windows (PowerShell and WSL), FreeBSD, OpenBSD, and NetBSD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Use a package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Homebrew
brew install charmbracelet/tap/crush

# NPM
npm install -g @charmland/crush

# Arch Linux (btw)
yay -S crush-bin

# Nix
nix run github:numtide/nix-ai-tools#crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Windows users:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Winget
winget install charmbracelet.crush

# Scoop
scoop bucket add charm https://github.com/charmbracelet/scoop-bucket.git
scoop install crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Nix (NUR)&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Crush is available via &lt;a href="https://github.com/nix-community/NUR"&gt;NUR&lt;/a&gt; in &lt;code&gt;nur.repos.charmbracelet.crush&lt;/code&gt;.&lt;/p&gt; 
 &lt;p&gt;You can also try out Crush via &lt;code&gt;nix-shell&lt;/code&gt;:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Add the NUR channel.
nix-channel --add https://github.com/nix-community/NUR/archive/main.tar.gz nur
nix-channel --update

# Get Crush in a Nix shell.
nix-shell -p '(import &amp;lt;nur&amp;gt; { pkgs = import &amp;lt;nixpkgs&amp;gt; {}; }).repos.charmbracelet.crush'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;NixOS &amp;amp; Home Manager Module Usage via NUR&lt;/h3&gt; 
 &lt;p&gt;Crush provides NixOS and Home Manager modules via NUR. You can use these modules directly in your flake by importing them from NUR. Since it auto detects whether its a home manager or nixos context you can use the import the exact same way :)&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-nix"&gt;{
  inputs = {
    nixpkgs.url = "github:NixOS/nixpkgs/nixos-unstable";
    nur.url = "github:nix-community/NUR";
  };

  outputs = { self, nixpkgs, nur, ... }: {
    nixosConfigurations.your-hostname = nixpkgs.lib.nixosSystem {
      system = "x86_64-linux";
      modules = [
        nur.modules.nixos.default
        nur.repos.charmbracelet.modules.crush
        {
          programs.crush = {
            enable = true;
            settings = {
              providers = {
                openai = {
                  id = "openai";
                  name = "OpenAI";
                  base_url = "https://api.openai.com/v1";
                  type = "openai";
                  api_key = "sk-fake123456789abcdef...";
                  models = [
                    {
                      id = "gpt-4";
                      name = "GPT-4";
                    }
                  ];
                };
              };
              lsp = {
                go = { command = "gopls"; enabled = true; };
                nix = { command = "nil"; enabled = true; };
              };
              options = {
                context_paths = [ "/etc/nixos/configuration.nix" ];
                tui = { compact_mode = true; };
                debug = false;
              };
            };
          };
        }
      ];
    };
  };
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Debian/Ubuntu&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo "deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *" | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;amp;&amp;amp; sudo apt install crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Fedora/RHEL&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;echo '[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key' | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install crush
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;Or, download it:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/crush/releases"&gt;Packages&lt;/a&gt; are available in Debian and RPM formats&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/crush/releases"&gt;Binaries&lt;/a&gt; are available for Linux, macOS, Windows, FreeBSD, OpenBSD, and NetBSD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Or just install it with Go:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install github.com/charmbracelet/crush@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Productivity may increase when using Crush and you may find yourself nerd sniped when first using the application. If the symptoms persist, join the &lt;a href="https://charm.land/discord"&gt;Discord&lt;/a&gt; and nerd snipe the rest of us.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;The quickest way to get started is to grab an API key for your preferred provider such as Anthropic, OpenAI, Groq, or OpenRouter and just start Crush. You'll be prompted to enter your API key.&lt;/p&gt; 
&lt;p&gt;That said, you can also set environment variables for preferred providers.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Environment Variable&lt;/th&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google Gemini&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;CEREBRAS_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Cerebras&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;HF_TOKEN&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Huggingface Inference&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;VERTEXAI_PROJECT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google Cloud VertexAI (Gemini)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;VERTEXAI_LOCATION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Google Cloud VertexAI (Gemini)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GROQ_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Groq&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Claude)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Claude)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_REGION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Claude)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_PROFILE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock (Custom Profile)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AWS_BEARER_TOKEN_BEDROCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Amazon Bedrock&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI models (optional when using Entra ID)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_OPENAI_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI models&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;By the Way&lt;/h3&gt; 
&lt;p&gt;Is there a provider you‚Äôd like to see in Crush? Is there an existing model that needs an update?&lt;/p&gt; 
&lt;p&gt;Crush‚Äôs default model listing is managed in &lt;a href="https://github.com/charmbracelet/catwalk"&gt;Catwalk&lt;/a&gt;, a community-supported, open source repository of Crush-compatible models, and you‚Äôre welcome to contribute.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/catwalk"&gt;&lt;img width="174" height="174" alt="Catwalk Badge" src="https://github.com/user-attachments/assets/95b49515-fe82-4409-b10d-5beb0873787d" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Crush runs great with no configuration. That said, if you do need or want to customize Crush, configuration can be added either local to the project itself, or globally, with the following priority:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;.crush.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;crush.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/.config/crush/crush.json&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Configuration itself is stored as a JSON object:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "this-setting": { "this": "that" },
  "that-setting": ["ceci", "cela"]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As an additional note, Crush also stores ephemeral data, such as application state, in one additional location:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Unix
$HOME/.local/share/crush/crush.json

# Windows
%LOCALAPPDATA%\crush\crush.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;LSPs&lt;/h3&gt; 
&lt;p&gt;Crush can use LSPs for additional context to help inform its decisions, just like you would. LSPs can be added manually like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "lsp": {
    "go": {
      "command": "gopls",
      "env": {
        "GOTOOLCHAIN": "go1.24.5"
      }
    },
    "typescript": {
      "command": "typescript-language-server",
      "args": ["--stdio"]
    },
    "nix": {
      "command": "nil"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MCPs&lt;/h3&gt; 
&lt;p&gt;Crush also supports Model Context Protocol (MCP) servers through three transport types: &lt;code&gt;stdio&lt;/code&gt; for command-line servers, &lt;code&gt;http&lt;/code&gt; for HTTP endpoints, and &lt;code&gt;sse&lt;/code&gt; for Server-Sent Events. Environment variable expansion is supported using &lt;code&gt;$(echo $VAR)&lt;/code&gt; syntax.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "mcp": {
    "filesystem": {
      "type": "stdio",
      "command": "node",
      "args": ["/path/to/mcp-server.js"],
      "timeout": 120,
      "disabled": false,
      "env": {
        "NODE_ENV": "production"
      }
    },
    "github": {
      "type": "http",
      "url": "https://api.githubcopilot.com/mcp/",
      "timeout": 120,
      "disabled": false,
      "headers": {
        "Authorization": "Bearer $GH_PAT"
      }
    },
    "streaming-service": {
      "type": "sse",
      "url": "https://example.com/mcp/sse",
      "timeout": 120,
      "disabled": false,
      "headers": {
        "API-Key": "$(echo $API_KEY)"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Ignoring Files&lt;/h3&gt; 
&lt;p&gt;Crush respects &lt;code&gt;.gitignore&lt;/code&gt; files by default, but you can also create a &lt;code&gt;.crushignore&lt;/code&gt; file to specify additional files and directories that Crush should ignore. This is useful for excluding files that you want in version control but don't want Crush to consider when providing context.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;.crushignore&lt;/code&gt; file uses the same syntax as &lt;code&gt;.gitignore&lt;/code&gt; and can be placed in the root of your project or in subdirectories.&lt;/p&gt; 
&lt;h3&gt;Allowing Tools&lt;/h3&gt; 
&lt;p&gt;By default, Crush will ask you for permission before running tool calls. If you'd like, you can allow tools to be executed without prompting you for permissions. Use this with care.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "permissions": {
    "allowed_tools": [
      "view",
      "ls",
      "grep",
      "edit",
      "mcp_context7_get-library-doc"
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also skip all permission prompts entirely by running Crush with the &lt;code&gt;--yolo&lt;/code&gt; flag. Be very, very careful with this feature.&lt;/p&gt; 
&lt;h3&gt;Initialization&lt;/h3&gt; 
&lt;p&gt;When you initialize a project, Crush analyzes your codebase and creates a context file that helps it work more effectively in future sessions. By default, this file is named &lt;code&gt;AGENTS.md&lt;/code&gt;, but you can customize the name and location with the &lt;code&gt;initialize_as&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "initialize_as": "AGENTS.md"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is useful if you prefer a different naming convention or want to place the file in a specific directory (e.g., &lt;code&gt;CRUSH.md&lt;/code&gt; or &lt;code&gt;docs/LLMs.md&lt;/code&gt;). Crush will fill the file with project-specific context like build commands, code patterns, and conventions it discovered during initialization.&lt;/p&gt; 
&lt;h3&gt;Attribution Settings&lt;/h3&gt; 
&lt;p&gt;By default, Crush adds attribution information to Git commits and pull requests it creates. You can customize this behavior with the &lt;code&gt;attribution&lt;/code&gt; option:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "attribution": {
      "trailer_style": "co-authored-by",
      "generated_with": true
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;trailer_style&lt;/code&gt;: Controls the attribution trailer added to commit messages (default: &lt;code&gt;assisted-by&lt;/code&gt;) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;assisted-by&lt;/code&gt;: Adds &lt;code&gt;Assisted-by: [Model Name] via Crush &amp;lt;crush@charm.land&amp;gt;&lt;/code&gt; (includes the model name)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;co-authored-by&lt;/code&gt;: Adds &lt;code&gt;Co-Authored-By: Crush &amp;lt;crush@charm.land&amp;gt;&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;none&lt;/code&gt;: No attribution trailer&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;generated_with&lt;/code&gt;: When true (default), adds &lt;code&gt;üíò Generated with Crush&lt;/code&gt; line to commit messages and PR descriptions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Custom Providers&lt;/h3&gt; 
&lt;p&gt;Crush supports custom provider configurations for both OpenAI-compatible and Anthropic-compatible APIs.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Note that we support two "types" for OpenAI. Make sure to choose the right one to ensure the best experience!&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;openai&lt;/code&gt; should be used when proxying or routing requests through OpenAI.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;openai-compat&lt;/code&gt; should be used when using non-OpenAI providers that have OpenAI-compatible APIs.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;OpenAI-Compatible APIs&lt;/h4&gt; 
&lt;p&gt;Here‚Äôs an example configuration for Deepseek, which uses an OpenAI-compatible API. Don't forget to set &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt; in your environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "providers": {
    "deepseek": {
      "type": "openai-compat",
      "base_url": "https://api.deepseek.com/v1",
      "api_key": "$DEEPSEEK_API_KEY",
      "models": [
        {
          "id": "deepseek-chat",
          "name": "Deepseek V3",
          "cost_per_1m_in": 0.27,
          "cost_per_1m_out": 1.1,
          "cost_per_1m_in_cached": 0.07,
          "cost_per_1m_out_cached": 1.1,
          "context_window": 64000,
          "default_max_tokens": 5000
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Anthropic-Compatible APIs&lt;/h4&gt; 
&lt;p&gt;Custom Anthropic-compatible providers follow this format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "providers": {
    "custom-anthropic": {
      "type": "anthropic",
      "base_url": "https://api.anthropic.com/v1",
      "api_key": "$ANTHROPIC_API_KEY",
      "extra_headers": {
        "anthropic-version": "2023-06-01"
      },
      "models": [
        {
          "id": "claude-sonnet-4-20250514",
          "name": "Claude Sonnet 4",
          "cost_per_1m_in": 3,
          "cost_per_1m_out": 15,
          "cost_per_1m_in_cached": 3.75,
          "cost_per_1m_out_cached": 0.3,
          "context_window": 200000,
          "default_max_tokens": 50000,
          "can_reason": true,
          "supports_attachments": true
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Amazon Bedrock&lt;/h3&gt; 
&lt;p&gt;Crush currently supports running Anthropic models through Bedrock, with caching disabled.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A Bedrock provider will appear once you have AWS configured, i.e. &lt;code&gt;aws configure&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Crush also expects the &lt;code&gt;AWS_REGION&lt;/code&gt; or &lt;code&gt;AWS_DEFAULT_REGION&lt;/code&gt; to be set&lt;/li&gt; 
 &lt;li&gt;To use a specific AWS profile set &lt;code&gt;AWS_PROFILE&lt;/code&gt; in your environment, i.e. &lt;code&gt;AWS_PROFILE=myprofile crush&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Alternatively to &lt;code&gt;aws configure&lt;/code&gt;, you can also just set &lt;code&gt;AWS_BEARER_TOKEN_BEDROCK&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Vertex AI Platform&lt;/h3&gt; 
&lt;p&gt;Vertex AI will appear in the list of available providers when &lt;code&gt;VERTEXAI_PROJECT&lt;/code&gt; and &lt;code&gt;VERTEXAI_LOCATION&lt;/code&gt; are set. You will also need to be authenticated:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;gcloud auth application-default login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To add specific models to the configuration, configure as such:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "providers": {
    "vertexai": {
      "models": [
        {
          "id": "claude-sonnet-4@20250514",
          "name": "VertexAI Sonnet 4",
          "cost_per_1m_in": 3,
          "cost_per_1m_out": 15,
          "cost_per_1m_in_cached": 3.75,
          "cost_per_1m_out_cached": 0.3,
          "context_window": 200000,
          "default_max_tokens": 50000,
          "can_reason": true,
          "supports_attachments": true
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Local Models&lt;/h3&gt; 
&lt;p&gt;Local models can also be configured via OpenAI-compatible API. Here are two common examples:&lt;/p&gt; 
&lt;h4&gt;Ollama&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "providers": {
    "ollama": {
      "name": "Ollama",
      "base_url": "http://localhost:11434/v1/",
      "type": "openai-compat",
      "models": [
        {
          "name": "Qwen 3 30B",
          "id": "qwen3:30b",
          "context_window": 256000,
          "default_max_tokens": 20000
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;LM Studio&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "providers": {
    "lmstudio": {
      "name": "LM Studio",
      "base_url": "http://localhost:1234/v1/",
      "type": "openai-compat",
      "models": [
        {
          "name": "Qwen 3 30B",
          "id": "qwen/qwen3-30b-a3b-2507",
          "context_window": 256000,
          "default_max_tokens": 20000
        }
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Logging&lt;/h2&gt; 
&lt;p&gt;Sometimes you need to look at logs. Luckily, Crush logs all sorts of stuff. Logs are stored in &lt;code&gt;./.crush/logs/crush.log&lt;/code&gt; relative to the project.&lt;/p&gt; 
&lt;p&gt;The CLI also contains some helper commands to make perusing recent logs easier:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Print the last 1000 lines
crush logs

# Print the last 500 lines
crush logs --tail 500

# Follow logs in real time
crush logs --follow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Want more logging? Run &lt;code&gt;crush&lt;/code&gt; with the &lt;code&gt;--debug&lt;/code&gt; flag, or enable it in the config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "debug": true,
    "debug_lsp": true
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Provider Auto-Updates&lt;/h2&gt; 
&lt;p&gt;By default, Crush automatically checks for the latest and greatest list of providers and models from &lt;a href="https://github.com/charmbracelet/catwalk"&gt;Catwalk&lt;/a&gt;, the open source Crush provider database. This means that when new providers and models are available, or when model metadata changes, Crush automatically updates your local configuration.&lt;/p&gt; 
&lt;h3&gt;Disabling automatic provider updates&lt;/h3&gt; 
&lt;p&gt;For those with restricted internet access, or those who prefer to work in air-gapped environments, this might not be want you want, and this feature can be disabled.&lt;/p&gt; 
&lt;p&gt;To disable automatic provider updates, set &lt;code&gt;disable_provider_auto_update&lt;/code&gt; into your &lt;code&gt;crush.json&lt;/code&gt; config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "$schema": "https://charm.land/crush.json",
  "options": {
    "disable_provider_auto_update": true
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or set the &lt;code&gt;CRUSH_DISABLE_PROVIDER_AUTO_UPDATE&lt;/code&gt; environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export CRUSH_DISABLE_PROVIDER_AUTO_UPDATE=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manually updating providers&lt;/h3&gt; 
&lt;p&gt;Manually updating providers is possible with the &lt;code&gt;crush update-providers&lt;/code&gt; command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Update providers remotely from Catwalk.
crush update-providers

# Update providers from a custom Catwalk base URL.
crush update-providers https://example.com/

# Update providers from a local file.
crush update-providers /path/to/local-providers.json

# Reset providers to the embedded version, embedded at crush at build time.
crush update-providers embedded

# For more info:
crush update-providers --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Metrics&lt;/h2&gt; 
&lt;p&gt;Crush records pseudonymous usage metrics (tied to a device-specific hash), which maintainers rely on to inform development and support priorities. The metrics include solely usage metadata; prompts and responses are NEVER collected.&lt;/p&gt; 
&lt;p&gt;Details on exactly what‚Äôs collected are in the source code (&lt;a href="https://github.com/charmbracelet/crush/tree/main/internal/event"&gt;here&lt;/a&gt; and &lt;a href="https://github.com/charmbracelet/crush/raw/main/internal/llm/agent/event.go"&gt;here&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;You can opt out of metrics collection at any time by setting the environment variable by setting the following in your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export CRUSH_DISABLE_METRICS=1
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or by setting the following in your config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "options": {
    "disable_metrics": true
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Crush also respects the &lt;a href="https://consoledonottrack.com"&gt;&lt;code&gt;DO_NOT_TRACK&lt;/code&gt;&lt;/a&gt; convention which can be enabled via &lt;code&gt;export DO_NOT_TRACK=1&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/charmbracelet/crush?tab=contributing-ov-file#contributing"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Whatcha think?&lt;/h2&gt; 
&lt;p&gt;We‚Äôd love to hear your thoughts on this project. Need help? We gotchu. You can find us on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/charmcli"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.land/slack"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.land/discord"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@charmcli"&gt;The Fediverse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bsky.app/profile/charm.land"&gt;Bluesky&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/crush/raw/main/LICENSE.md"&gt;FSL-1.1-MIT&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Part of &lt;a href="https://charm.land"&gt;Charm&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://charm.land/"&gt;&lt;img alt="The Charm logo" width="400" src="https://stuff.charm.sh/charm-banner-next.jpg" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!--prettier-ignore--&gt; 
&lt;p&gt;CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>etcd-io/etcd</title>
      <link>https://github.com/etcd-io/etcd</link>
      <description>&lt;p&gt;Distributed reliable key-value store for the most critical data of a distributed system&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;etcd&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/etcd-io/etcd"&gt;&lt;img src="https://goreportcard.com/badge/github.com/etcd-io/etcd?style=flat-square" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://app.codecov.io/gh/etcd-io/etcd/tree/main"&gt;&lt;img src="https://codecov.io/gh/etcd-io/etcd/branch/main/graph/badge.svg?sanitize=true" alt="Coverage" /&gt;&lt;/a&gt; &lt;a href="https://github.com/etcd-io/etcd/actions/workflows/tests.yaml"&gt;&lt;img src="https://github.com/etcd-io/etcd/actions/workflows/tests.yaml/badge.svg?sanitize=true" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/etcd-io/etcd/actions/workflows/codeql-analysis.yml"&gt;&lt;img src="https://github.com/etcd-io/etcd/actions/workflows/codeql-analysis.yml/badge.svg?sanitize=true" alt="codeql-analysis" /&gt;&lt;/a&gt; &lt;a href="https://etcd.io/docs"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-green.svg?sanitize=true" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://godocs.io/go.etcd.io/etcd/v3"&gt;&lt;img src="http://img.shields.io/badge/go-documentation-blue.svg?style=flat-square" alt="Godoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/etcd-io/etcd/releases"&gt;&lt;img src="https://img.shields.io/github/release/etcd-io/etcd/all.svg?style=flat-square" alt="Releases" /&gt;&lt;/a&gt; &lt;a href="https://github.com/etcd-io/etcd/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/etcd-io/etcd.svg?style=flat-square" alt="LICENSE" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/etcd-io/etcd"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/etcd-io/etcd/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;code&gt;main&lt;/code&gt; branch may be in an &lt;em&gt;unstable or even broken state&lt;/em&gt; during development. For stable versions, see &lt;a href="https://github.com/etcd-io/etcd/releases"&gt;releases&lt;/a&gt;.&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/cncf/artwork/9870640f123303a355611065195c43ac3f27aa19/projects/etcd/horizontal/white/etcd-horizontal-white.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="logos/etcd-horizontal-color.svg" /&gt; 
 &lt;img alt="etcd logo" src="https://raw.githubusercontent.com/etcd-io/etcd/main/logos/etcd-horizontal-color.svg?sanitize=true" width="269" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;etcd is a distributed reliable key-value store for the most critical data of a distributed system, with a focus on being:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;em&gt;Simple&lt;/em&gt;: well-defined, user-facing API (gRPC)&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Secure&lt;/em&gt;: automatic TLS with optional client cert authentication&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Fast&lt;/em&gt;: benchmarked 10,000 writes/sec&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Reliable&lt;/em&gt;: properly distributed using Raft&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;etcd is written in Go and uses the &lt;a href="https://raft.github.io/"&gt;Raft&lt;/a&gt; consensus algorithm to manage a highly-available replicated log.&lt;/p&gt; 
&lt;p&gt;etcd is used &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/ADOPTERS.md"&gt;in production by many companies&lt;/a&gt;, and the development team stands behind it in critical deployment scenarios, where etcd is frequently teamed with applications such as &lt;a href="http://kubernetes.io/"&gt;Kubernetes&lt;/a&gt;, &lt;a href="https://github.com/coreos/locksmith"&gt;locksmith&lt;/a&gt;, &lt;a href="https://github.com/vulcand/vulcand"&gt;vulcand&lt;/a&gt;, &lt;a href="https://github.com/youtube/doorman"&gt;Doorman&lt;/a&gt;, and many others. Reliability is further ensured by rigorous &lt;a href="https://github.com/etcd-io/etcd/tree/main/tests/robustness"&gt;&lt;strong&gt;robustness testing&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/etcd-io/etcd/tree/main/etcdctl"&gt;etcdctl&lt;/a&gt; for a simple command line client.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/etcd-io/etcd/main/logos/etcd-xkcd-2347.png" alt="etcd reliability is important" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;sub&gt;Original image credited to xkcd.com/2347, alterations by Josh Berkus.&lt;/sub&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The most common API documentation you'll need can be found here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/api/v3"&gt;go.etcd.io/etcd/api/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/client/pkg/v3"&gt;go.etcd.io/etcd/client/pkg/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/client/v3"&gt;go.etcd.io/etcd/client/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/etcdctl/v3"&gt;go.etcd.io/etcd/etcdctl/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/pkg/v3"&gt;go.etcd.io/etcd/pkg/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/raft/v3"&gt;go.etcd.io/etcd/raft/v3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://godocs.io/go.etcd.io/etcd/server/v3"&gt;go.etcd.io/etcd/server/v3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Maintainers&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/OWNERS"&gt;Maintainers&lt;/a&gt; strive to shape an inclusive open source project culture where users are heard and contributors feel respected and empowered. Maintainers aim to build productive relationships across different companies and disciplines. Read more about &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/Documentation/contributor-guide/community-membership.md#maintainers"&gt;Maintainers role and responsibilities&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;h3&gt;Getting etcd&lt;/h3&gt; 
&lt;p&gt;The easiest way to get etcd is to use one of the pre-built release binaries which are available for OSX, Linux, Windows, and Docker on the &lt;a href="https://github.com/etcd-io/etcd/releases"&gt;release page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more installation guides, please check out &lt;a href="http://play.etcd.io"&gt;play.etcd.io&lt;/a&gt; and &lt;a href="https://etcd.io/docs/latest/op-guide"&gt;operating etcd&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Running etcd&lt;/h3&gt; 
&lt;p&gt;First start a single-member cluster of etcd.&lt;/p&gt; 
&lt;p&gt;If etcd is installed using the &lt;a href="https://github.com/etcd-io/etcd/releases"&gt;pre-built release binaries&lt;/a&gt;, run it from the installation location as below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/tmp/etcd-download-test/etcd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The etcd command can be simply run as such if it is moved to the system path as below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mv /tmp/etcd-download-test/etcd /usr/local/bin/
etcd
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will bring up etcd listening on port 2379 for client communication and on port 2380 for server-to-server communication.&lt;/p&gt; 
&lt;p&gt;Next, let's set a single key, and then retrieve it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;etcdctl put mykey "this is awesome"
etcdctl get mykey
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;etcd is now running and serving client requests. For more, please check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://play.etcd.io"&gt;Interactive etcd playground&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://etcd.io/docs/latest/demo"&gt;Animated quick demo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;etcd TCP ports&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt"&gt;official etcd ports&lt;/a&gt; are 2379 for client requests, and 2380 for peer communication.&lt;/p&gt; 
&lt;h3&gt;Running a local etcd cluster&lt;/h3&gt; 
&lt;p&gt;First install &lt;a href="https://github.com/mattn/goreman"&gt;goreman&lt;/a&gt;, which manages Procfile-based applications.&lt;/p&gt; 
&lt;p&gt;Our &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/Procfile"&gt;Procfile script&lt;/a&gt; will set up a local example cluster. Start it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;goreman start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will bring up 3 etcd members &lt;code&gt;infra1&lt;/code&gt;, &lt;code&gt;infra2&lt;/code&gt; and &lt;code&gt;infra3&lt;/code&gt; and optionally etcd &lt;code&gt;grpc-proxy&lt;/code&gt;, which runs locally and composes a cluster.&lt;/p&gt; 
&lt;p&gt;Every cluster member and proxy accepts key value reads and key value writes.&lt;/p&gt; 
&lt;p&gt;Follow the comments in &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/Procfile"&gt;Procfile script&lt;/a&gt; to add a learner node to the cluster.&lt;/p&gt; 
&lt;h3&gt;Install etcd client v3&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go get go.etcd.io/etcd/client/v3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Next steps&lt;/h3&gt; 
&lt;p&gt;Now it's time to dig into the full etcd API and other guides.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read the full &lt;a href="https://etcd.io/docs/latest"&gt;documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Review etcd &lt;a href="https://etcd.io/docs/latest/faq"&gt;frequently asked questions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Explore the full gRPC &lt;a href="https://etcd.io/docs/latest/learning/api"&gt;API&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Set up a &lt;a href="https://etcd.io/docs/latest/op-guide/clustering"&gt;multi-machine cluster&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Learn the &lt;a href="https://etcd.io/docs/latest/op-guide/configuration"&gt;config format, env variables and flags&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Find &lt;a href="https://etcd.io/docs/latest/integrations"&gt;language bindings and tools&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Use TLS to &lt;a href="https://etcd.io/docs/latest/op-guide/security"&gt;secure an etcd cluster&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://etcd.io/docs/latest/tuning"&gt;Tune etcd&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Email: &lt;a href="https://groups.google.com/g/etcd-dev"&gt;etcd-dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Slack: &lt;a href="https://kubernetes.slack.com/archives/C3HD8ARJ5"&gt;#sig-etcd&lt;/a&gt; channel on Kubernetes (&lt;a href="http://slack.kubernetes.io/"&gt;get an invite&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/#community-meetings"&gt;Community meetings&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community meetings&lt;/h3&gt; 
&lt;p&gt;etcd contributors and maintainers meet every week at &lt;code&gt;11:00&lt;/code&gt; AM (USA Pacific) on Thursday and meetings alternate between community meetings and issue triage meetings. Meeting agendas are recorded in a &lt;a href="https://docs.google.com/document/d/16XEGyPBisZvmmoIHSZzv__LoyOeluC5a4x353CX0SIM/edit"&gt;shared Google doc&lt;/a&gt; and everyone is welcome to suggest additional topics or other agendas.&lt;/p&gt; 
&lt;p&gt;Issue triage meetings are aimed at getting through our backlog of PRs and Issues. Triage meetings are open to any contributor; you don't have to be a reviewer or approver to help out! They can also be a good way to get started contributing.&lt;/p&gt; 
&lt;p&gt;The meeting lead role is rotated for each meeting between etcd maintainers or sig-etcd leads and is recorded in a &lt;a href="https://docs.google.com/spreadsheets/d/1jodHIO7Dk2VWTs1IRnfMFaRktS9IH8XRyifOnPdSY8I/edit"&gt;shared Google sheet&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Meeting recordings are uploaded to the official etcd &lt;a href="https://www.youtube.com/@etcdio"&gt;YouTube channel&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Get calendar invitations by joining &lt;a href="https://groups.google.com/g/etcd-dev"&gt;etcd-dev&lt;/a&gt; mailing group.&lt;/p&gt; 
&lt;p&gt;Join the CNCF-funded Zoom channel: &lt;a href="https://zoom.us/my/cncfetcdproject"&gt;zoom.us/my/cncfetcdproject&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; for details on setting up your development environment, submitting patches and the contribution workflow.&lt;/p&gt; 
&lt;p&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/Documentation/contributor-guide/community-membership.md#member"&gt;community-membership.md&lt;/a&gt; for information on becoming an etcd project member. We welcome and look forward to your contributions to the project!&lt;/p&gt; 
&lt;p&gt;Please also refer to &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/Documentation/contributor-guide/roadmap.md"&gt;roadmap&lt;/a&gt; to get more details on the priorities for the next few major or minor releases.&lt;/p&gt; 
&lt;h2&gt;Reporting bugs&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/etcd-io/etcd/raw/main/Documentation/contributor-guide/reporting_bugs.md"&gt;reporting bugs&lt;/a&gt; for details about reporting any issues. Before opening an issue please check it is not covered in our &lt;a href="https://etcd.io/docs/latest/faq"&gt;frequently asked questions&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Reporting a security vulnerability&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/security/README.md"&gt;security disclosure and release process&lt;/a&gt; for details on how to report a security vulnerability and how the etcd team manages it.&lt;/p&gt; 
&lt;h2&gt;Issue and PR management&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/etcd-io/etcd/raw/main/Documentation/contributor-guide/triage_issues.md"&gt;issue triage guidelines&lt;/a&gt; for details on how issues are managed.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/etcd-io/etcd/raw/main/Documentation/contributor-guide/triage_prs.md"&gt;PR management&lt;/a&gt; for guidelines on how pull requests are managed.&lt;/p&gt; 
&lt;h2&gt;etcd Emeritus Maintainers&lt;/h2&gt; 
&lt;p&gt;etcd &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/OWNERS"&gt;emeritus maintainers&lt;/a&gt; dedicated a part of their career to etcd and reviewed code, triaged bugs and pushed the project forward over a substantial period of time. Their contribution is greatly appreciated.&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;etcd is under the Apache 2.0 license. See the &lt;a href="https://raw.githubusercontent.com/etcd-io/etcd/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂÆòÊñπÁΩëÁ´ô" src="https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞" src="https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.2.0-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;üí° WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;üìå Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Latest Updates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;v0.2.0 Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Agent Mode&lt;/strong&gt;: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;üîå &lt;strong&gt;MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;New UI&lt;/strong&gt;: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Infrastructure Upgrade&lt;/strong&gt;: Introduced MQ async task management, support for automatic database migration, and fast development mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîí Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/architecture.png" alt="weknora-architecture.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;üéØ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Agent Mode&lt;/strong&gt;: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîå MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öôÔ∏è Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìä Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent Mode&lt;/td&gt; 
   &lt;td&gt;‚úÖ ReACT Agent Mode&lt;/td&gt; 
   &lt;td&gt;Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Knowledge Base Types&lt;/td&gt; 
   &lt;td&gt;‚úÖ FAQ / Document&lt;/td&gt; 
   &lt;td&gt;Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ Centralized configuration, built-in model sharing&lt;/td&gt; 
   &lt;td&gt;Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;‚úÖ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;‚úÖ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Conversation Strategy&lt;/td&gt; 
   &lt;td&gt;‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration&lt;/td&gt; 
   &lt;td&gt;Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;‚úÖ Extensible search engines, DuckDuckGo&lt;/td&gt; 
   &lt;td&gt;Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MCP Tools&lt;/td&gt; 
   &lt;td&gt;‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE&lt;/td&gt; 
   &lt;td&gt;Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;‚úÖ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;‚úÖ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements, with fast development mode support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;‚úÖ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ MQ async tasks, automatic database migration&lt;/td&gt; 
   &lt;td&gt;MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;üõ† Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;h4&gt;‚ë† Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services (include Ollama)&lt;/h4&gt; 
&lt;p&gt;Check the images that need to be started in the .env file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.0 Start ollama services (Optional)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.1 Activate different combinations of features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimum core services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;All features enabled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile full up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tracing logs required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile jaeger up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neo4j knowledge graph required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minio file storage service required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple options combination&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë£ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîå Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1Ô∏è‚É£ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2Ô∏è‚É£ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîß Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.&lt;/p&gt; 
&lt;h3&gt;‚ë† Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë° Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë¢ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë£ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.&lt;/p&gt; 
&lt;h2&gt;üì± Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledgebases.png" alt="Knowledge Base Management" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/settings.png" alt="Conversation Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/agent-qa.png" alt="Agent Mode Tool Call Process" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Mode:&lt;/strong&gt; Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Conversation Strategy:&lt;/strong&gt; Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;p&gt;For detailed configuration, please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/KnowledgeGraph.md"&gt;Knowledge Graph Configuration Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Server&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for the necessary setup.&lt;/p&gt; 
&lt;h2&gt;üìò API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/API.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üß≠ Developer Guide&lt;/h2&gt; 
&lt;h3&gt;‚ö° Fast Development Mode (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you need to frequently modify code, &lt;strong&gt;you don't need to rebuild Docker images every time&lt;/strong&gt;! Use fast development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Development Advantages:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Frontend modifications auto hot-reload (no restart needed)&lt;/li&gt; 
 &lt;li&gt;‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)&lt;/li&gt; 
 &lt;li&gt;‚úÖ No need to rebuild Docker images&lt;/li&gt; 
 &lt;li&gt;‚úÖ Support IDE breakpoint debugging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Detailed Documentation:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md"&gt;Development Environment Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üìÅ Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
‚îú‚îÄ‚îÄ client/      # go client
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ docker/      # docker images files
‚îú‚îÄ‚îÄ docreader/   # Document parsing app
‚îú‚îÄ‚îÄ docs/        # Project documentation
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ mcp-server/  # MCP server
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îî‚îÄ‚îÄ scripts/     # Shell scripts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;üéØ How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üé® Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìù Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üë• Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;üìà Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
  </channel>
</rss>