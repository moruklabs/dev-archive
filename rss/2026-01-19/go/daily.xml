<rss version="2.0">
  <channel>
    <title>GitHub Go Daily Trending</title>
    <description>Daily Trending of Go in GitHub</description>
    <pubDate>Sun, 18 Jan 2026 01:35:30 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>cilium/cilium</title>
      <link>https://github.com/cilium/cilium</link>
      <description>&lt;p&gt;eBPF-based Networking, Security, and Observability&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. raw:: html&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://cdn.jsdelivr.net/gh/cilium/cilium@main/Documentation/images/logo.png" width="350" alt="Cilium Logo" /&gt; 
 &lt;img src="https://cdn.jsdelivr.net/gh/cilium/cilium@main/Documentation/images/logo-dark.png" width="350" alt="Cilium Logo" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;|cii| |go-report| |clomonitor| |artifacthub| |slack| |go-doc| |rtd| |apache| |bsd| |gpl| |fossa| |gateway-api| |codespaces|&lt;/p&gt; 
&lt;p&gt;Cilium is a networking, observability, and security solution with an eBPF-based dataplane. It provides a simple flat Layer 3 network with the ability to span multiple clusters in either a native routing or overlay mode. It is L7-protocol aware and can enforce network policies on L3-L7 using an identity based security model that is decoupled from network addressing.&lt;/p&gt; 
&lt;p&gt;Cilium implements distributed load balancing for traffic between pods and to external services, and is able to fully replace kube-proxy, using efficient hash tables in eBPF allowing for almost unlimited scale. It also supports advanced functionality like integrated ingress and egress gateway, bandwidth management and service mesh, and provides deep network and security visibility and monitoring.&lt;/p&gt; 
&lt;p&gt;A new Linux kernel technology called eBPF_ is at the foundation of Cilium. It supports dynamic insertion of eBPF bytecode into the Linux kernel at various integration points such as: network IO, application sockets, and tracepoints to implement security, networking and visibility logic. eBPF is highly efficient and flexible. To learn more about eBPF, visit &lt;code&gt;eBPF.io&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;.. image:: Documentation/images/cilium-overview.png :alt: Overview of Cilium features for networking, observability, service mesh, and runtime security&lt;/p&gt; 
&lt;p&gt;.. raw:: html&lt;/p&gt; 
&lt;a href="https://cncf.io/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/cncf/artwork/blob/main/other/cncf-member/graduated/color/cncf-graduated-color.svg" /&gt; 
  &lt;img src="https://github.com/cncf/artwork/raw/main/other/cncf-member/graduated/white/cncf-graduated-white.svg?sanitize=true" alt="CNCF Graduated Project" height="80" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;a href="https://ebpf.io/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset=".github/assets/ebpf-horizontal.svg" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/cilium/cilium/main/.github/assets/ebpf-horizontal-dark-back.svg?sanitize=true" alt="eBPF Logo" height="80" align="right" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h1&gt;Stable Releases&lt;/h1&gt; 
&lt;p&gt;The Cilium community maintains minor stable releases for the last three minor Cilium versions. Older Cilium stable versions from minor releases prior to that are considered EOL.&lt;/p&gt; 
&lt;p&gt;For upgrades to new minor releases please consult the &lt;code&gt;Cilium Upgrade Guide&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;Listed below are the actively maintained release branches along with their latest patch release, corresponding image pull tags and their release notes:&lt;/p&gt; 
&lt;p&gt;+---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+ | &lt;code&gt;v1.18 &amp;lt;https://github.com/cilium/cilium/tree/v1.18&amp;gt;&lt;/code&gt;__ | 2026-01-13 | &lt;code&gt;quay.io/cilium/cilium:v1.18.6&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.18.6&amp;gt;&lt;/code&gt;__ | +---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+ | &lt;code&gt;v1.17 &amp;lt;https://github.com/cilium/cilium/tree/v1.17&amp;gt;&lt;/code&gt;__ | 2026-01-13 | &lt;code&gt;quay.io/cilium/cilium:v1.17.12&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.17.12&amp;gt;&lt;/code&gt;__ | +---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+ | &lt;code&gt;v1.16 &amp;lt;https://github.com/cilium/cilium/tree/v1.16&amp;gt;&lt;/code&gt;__ | 2026-01-13 | &lt;code&gt;quay.io/cilium/cilium:v1.16.19&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.16.19&amp;gt;&lt;/code&gt;__ | +---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+&lt;/p&gt; 
&lt;h2&gt;Architectures&lt;/h2&gt; 
&lt;p&gt;Cilium images are distributed for AMD64 and AArch64 architectures.&lt;/p&gt; 
&lt;h2&gt;Software Bill of Materials&lt;/h2&gt; 
&lt;p&gt;Starting with Cilium version 1.13.0, all images include a Software Bill of Materials (SBOM). The SBOM is generated in &lt;code&gt;SPDX&lt;/code&gt;_ format. More information on this is available on &lt;code&gt;Cilium SBOM&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;.. _&lt;code&gt;SPDX&lt;/code&gt;: &lt;a href="https://spdx.dev/"&gt;https://spdx.dev/&lt;/a&gt; .. _&lt;code&gt;Cilium SBOM&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/latest/configuration/sbom/"&gt;https://docs.cilium.io/en/latest/configuration/sbom/&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Development&lt;/h1&gt; 
&lt;p&gt;For development and testing purpose, the Cilium community publishes snapshots, early release candidates (RC) and CI container images build from the &lt;code&gt;main branch &amp;lt;https://github.com/cilium/cilium/commits/main&amp;gt;&lt;/code&gt;_. These images are not for use in production.&lt;/p&gt; 
&lt;p&gt;For testing upgrades to new development releases please consult the latest development build of the &lt;code&gt;Cilium Upgrade Guide&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;Listed below are branches for testing along with their snapshots or RC releases, corresponding image pull tags and their release notes where applicable:&lt;/p&gt; 
&lt;p&gt;+----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+ | &lt;code&gt;main &amp;lt;https://github.com/cilium/cilium/commits/main&amp;gt;&lt;/code&gt;__ | daily | &lt;code&gt;quay.io/cilium/cilium-ci:latest&lt;/code&gt; | N/A | +----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+ | &lt;code&gt;v1.19.0-rc.0 &amp;lt;https://github.com/cilium/cilium/commits/v1.19.0-rc.0&amp;gt;&lt;/code&gt;__ | 2026-01-15 | &lt;code&gt;quay.io/cilium/cilium:v1.19.0-rc.0&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.19.0-rc.0&amp;gt;&lt;/code&gt;__ | +----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+&lt;/p&gt; 
&lt;h1&gt;Functionality Overview&lt;/h1&gt; 
&lt;p&gt;.. begin-functionality-overview&lt;/p&gt; 
&lt;h2&gt;CNI (Container Network Interface)&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Cilium as a CNI plugin &amp;lt;https://cilium.io/use-cases/cni/&amp;gt;&lt;/code&gt;_ provides a fast, scalable, and secure networking layer for Kubernetes clusters. Built on eBPF, it offers several deployment options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Overlay networking:&lt;/strong&gt; encapsulation-based virtual network spanning all hosts with support for VXLAN and Geneve. It works on almost any network infrastructure as the only requirement is IP connectivity between hosts which is typically already given.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Native routing mode:&lt;/strong&gt; Use of the regular routing table of the Linux host. The network is required to be capable of routing the IP addresses of the application containers. It integrates with cloud routers, routing daemons, and IPv6-native infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flexible routing options:&lt;/strong&gt; Cilium can automate route learning and advertisement in common topologies such as using L2 neighbor discovery when nodes share a layer 2 domain, or BGP when routing across layer 3 boundaries.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each mode is designed for maximum interoperability with existing infrastructure while minimizing operational burden.&lt;/p&gt; 
&lt;h2&gt;Load Balancing&lt;/h2&gt; 
&lt;p&gt;Cilium implements distributed load balancing for traffic between application containers and to/from external services. The load balancing is implemented in eBPF using efficient hashtables enabling high service density and low latency at scale.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;East-west load balancing&lt;/strong&gt; rewrites service connections at the socket level (&lt;code&gt;connect()&lt;/code&gt;), avoiding the overhead of per-packet NAT and fully &lt;code&gt;replacing kube-proxy &amp;lt;https://cilium.io/use-cases/kube-proxy/&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;North-south load balancing&lt;/strong&gt; supports XDP for high-throughput scenarios and &lt;code&gt;layer 4 load balancing &amp;lt;https://cilium.io/use-cases/load-balancer/&amp;gt;&lt;/code&gt;_ including Direct Server Return (DSR), and Maglev consistent hashing.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cluster Mesh&lt;/h2&gt; 
&lt;p&gt;Cilium &lt;code&gt;Cluster Mesh &amp;lt;https://cilium.io/use-cases/cluster-mesh/&amp;gt;&lt;/code&gt;_ enables secure, seamless connectivity across multiple Kubernetes clusters. For operators running hybrid or multi-cloud environments, Cluster Mesh ensures a consistent security and connectivity experience.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Global service discovery&lt;/strong&gt;: Workloads across clusters can discover and connect to services as if they were local. This enables fault tolerance, like automatically failing over to backends in another cluster, and exposes shared services like logging, auth, or databases across environments.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unified identity model:&lt;/strong&gt; Security policies are enforced based on identity, not IP address, across all clusters.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Network Policy&lt;/h2&gt; 
&lt;p&gt;Cilium &lt;code&gt;Network Policy &amp;lt;https://cilium.io/use-cases/network-policy/&amp;gt;&lt;/code&gt;_ provides identity-aware enforcement across L3-L7. Typical container firewalls secure workloads by filtering on source IP addresses and destination ports. This concept requires the firewalls on all servers to be manipulated whenever a container is started anywhere in the cluster.&lt;/p&gt; 
&lt;p&gt;In order to avoid this situation which limits scale, Cilium assigns a security identity to groups of application containers which share identical security policies. The identity is then associated with all network packets emitted by the application containers, allowing to validate the identity at the receiving node.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Identity-based security&lt;/strong&gt; removes reliance on brittle IP addresses.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L3/L4 policies&lt;/strong&gt; restrict traffic based on labels, protocols, and ports.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;DNS-based policies:&lt;/strong&gt; Allow or deny traffic to FQDNs or wildcard domains (e.g., &lt;code&gt;api.example.com&lt;/code&gt;, &lt;code&gt;*.trusted.com&lt;/code&gt;). This is especially useful for securing egress traffic to third-party services.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L7-aware policies&lt;/strong&gt; allow filtering by HTTP method, URL path, gRPC call, and more:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Example: Allow only GET requests to &lt;code&gt;/public/.*&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Enforce the presence of headers like &lt;code&gt;X-Token: [0-9]+&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CIDR-based egress and ingress policies are also supported for controlling access to external IPs, ideal for integrating with legacy systems or regulatory boundaries.&lt;/p&gt; 
&lt;h2&gt;Service Mesh&lt;/h2&gt; 
&lt;p&gt;With Cilium &lt;code&gt;Service Mesh &amp;lt;https://cilium.io/use-cases/service-mesh/&amp;gt;&lt;/code&gt;_, operators gain the benefits of fine-grained traffic control, encryption, observability, access control, without the cost and complexity of traditional proxy-based designs. Key features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Mutual authentication&lt;/strong&gt; with automatic identity-based encryption between workloads using IPSec or WireGuard.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L7-aware policy enforcement&lt;/strong&gt; for security and compliance.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deep integration with the Kubernetes Gateway API :&lt;/strong&gt; Acts as a &lt;code&gt;Gateway API &amp;lt;https://cilium.io/use-cases/gateway-api/&amp;gt;&lt;/code&gt;_ compliant data plane, allowing you to declaratively manage ingress, traffic splitting, and routing behavior using Kubernetes-native CRDs.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Observability and Troubleshooting&lt;/h2&gt; 
&lt;p&gt;Observability is built into Cilium from the ground up, providing rich visibility that helps operators diagnose and understand system behavior including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hubble&lt;/strong&gt;: A fully integrated observability platform that offers real-time service maps, flow visibility with identity and label metadata, and DNS-aware filtering and protocol-specific insights&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Metrics and alerting&lt;/strong&gt;: Integration with Prometheus, Grafana, and other monitoring systems.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Drop reasons and audit trails&lt;/strong&gt;: Get actionable insights into why traffic was dropped, including policy or port violations and issues like failed DNS lookups.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;.. end-functionality-overview&lt;/p&gt; 
&lt;h1&gt;Getting Started&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Why Cilium?&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Getting Started&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Architecture and Concepts&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Installing Cilium&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Frequently Asked Questions&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;Contributing_&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Community&lt;/h1&gt; 
&lt;h2&gt;Slack&lt;/h2&gt; 
&lt;p&gt;Join the Cilium &lt;code&gt;Slack channel &amp;lt;https://slack.cilium.io&amp;gt;&lt;/code&gt;_ to chat with Cilium developers and other Cilium users. This is a good place to learn about Cilium, ask questions, and share your experiences.&lt;/p&gt; 
&lt;h2&gt;Special Interest Groups (SIG)&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;Special Interest groups &amp;lt;https://github.com/cilium/community/blob/main/sigs.yaml&amp;gt;&lt;/code&gt;_ for a list of all SIGs and their meeting times.&lt;/p&gt; 
&lt;h2&gt;Developer meetings&lt;/h2&gt; 
&lt;p&gt;The Cilium developer community hangs out on Zoom to chat. Everybody is welcome.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Weekly, Wednesday, 5:00 pm &lt;code&gt;Europe/Zurich time &amp;lt;https://time.is/Canton_of_Zurich&amp;gt;&lt;/code&gt;__ (CET/CEST), usually equivalent to 8:00 am PT, or 11:00 am ET. &lt;code&gt;Meeting Notes and Zoom Info&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;Third Wednesday of each month, 9:00 am &lt;code&gt;Japan time &amp;lt;https://time.is/Tokyo&amp;gt;&lt;/code&gt;__ (JST). &lt;code&gt;APAC Meeting Notes and Zoom Info&lt;/code&gt;_&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;eBPF &amp;amp; Cilium Office Hours livestream&lt;/h2&gt; 
&lt;p&gt;We host a weekly community &lt;code&gt;YouTube livestream called eCHO &amp;lt;https://www.youtube.com/channel/UCJFUxkVQTBJh3LD1wYBWvuQ&amp;gt;&lt;/code&gt;_ which (very loosely!) stands for eBPF &amp;amp; Cilium Office Hours. Join us live, catch up with past episodes, or head over to the &lt;code&gt;eCHO repo &amp;lt;https://github.com/isovalent/eCHO&amp;gt;&lt;/code&gt;_ and let us know your ideas for topics we should cover.&lt;/p&gt; 
&lt;h2&gt;Governance&lt;/h2&gt; 
&lt;p&gt;The Cilium project is governed by a group of &lt;code&gt;Maintainers and Committers &amp;lt;https://raw.githubusercontent.com/cilium/cilium/main/MAINTAINERS.md&amp;gt;&lt;/code&gt;&lt;strong&gt;. How they are selected and govern is outlined in our &lt;code&gt;governance document &amp;lt;https://github.com/cilium/community/blob/main/GOVERNANCE.md&amp;gt;&lt;/code&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;A list of adopters of the Cilium project who are deploying it in production, and of their use cases, can be found in file &lt;code&gt;USERS.md &amp;lt;https://github.com/cilium/cilium/blob/main/USERS.md&amp;gt;&lt;/code&gt;__.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;.. _apache-license: LICENSE .. _bsd-license: bpf/LICENSE.BSD-2-Clause .. _gpl-license: bpf/LICENSE.GPL-2.0&lt;/p&gt; 
&lt;p&gt;The Cilium user space components are licensed under the &lt;code&gt;Apache License, Version 2.0 &amp;lt;apache-license_&amp;gt;&lt;/code&gt;&lt;strong&gt;. The BPF code templates are dual-licensed under the &lt;code&gt;General Public License, Version 2.0 (only) &amp;lt;gpl-license_&amp;gt;&lt;/code&gt;&lt;/strong&gt; and the &lt;code&gt;2-Clause BSD License &amp;lt;bsd-license_&amp;gt;&lt;/code&gt;__ (you can use the terms of either license, at your option).&lt;/p&gt; 
&lt;p&gt;.. _&lt;code&gt;Cilium Upgrade Guide&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/operations/upgrade/"&gt;https://docs.cilium.io/en/stable/operations/upgrade/&lt;/a&gt; .. _&lt;code&gt;Why Cilium?&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/overview/intro"&gt;https://docs.cilium.io/en/stable/overview/intro&lt;/a&gt; .. _&lt;code&gt;Getting Started&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/#getting-started"&gt;https://docs.cilium.io/en/stable/#getting-started&lt;/a&gt; .. _&lt;code&gt;Architecture and Concepts&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/overview/component-overview/"&gt;https://docs.cilium.io/en/stable/overview/component-overview/&lt;/a&gt; .. _&lt;code&gt;Installing Cilium&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/"&gt;https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/&lt;/a&gt; .. _&lt;code&gt;Frequently Asked Questions&lt;/code&gt;: &lt;a href="https://github.com/cilium/cilium/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue+label%3Akind%2Fquestion+"&gt;https://github.com/cilium/cilium/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue+label%3Akind%2Fquestion+&lt;/a&gt; .. _Contributing: &lt;a href="https://docs.cilium.io/en/stable/contributing/development/"&gt;https://docs.cilium.io/en/stable/contributing/development/&lt;/a&gt; .. _Prerequisites: &lt;a href="https://docs.cilium.io/en/stable/operations/system_requirements/"&gt;https://docs.cilium.io/en/stable/operations/system_requirements/&lt;/a&gt; .. _&lt;code&gt;eBPF&lt;/code&gt;: &lt;a href="https://ebpf.io"&gt;https://ebpf.io&lt;/a&gt; .. _&lt;code&gt;eBPF.io&lt;/code&gt;: &lt;a href="https://ebpf.io"&gt;https://ebpf.io&lt;/a&gt; .. _&lt;code&gt;Meeting Notes and Zoom Info&lt;/code&gt;: &lt;a href="https://docs.google.com/document/d/1Y_4chDk4rznD6UgXPlPvn3Dc7l-ZutGajUv1eF0VDwQ/edit#"&gt;https://docs.google.com/document/d/1Y_4chDk4rznD6UgXPlPvn3Dc7l-ZutGajUv1eF0VDwQ/edit#&lt;/a&gt; .. _&lt;code&gt;APAC Meeting Notes and Zoom Info&lt;/code&gt;: &lt;a href="https://docs.google.com/document/d/1egv4qLydr0geP-GjQexYKm4tz3_tHy-LCBjVQcXcT5M/edit#"&gt;https://docs.google.com/document/d/1egv4qLydr0geP-GjQexYKm4tz3_tHy-LCBjVQcXcT5M/edit#&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |go-report| image:: &lt;a href="https://goreportcard.com/badge/github.com/cilium/cilium"&gt;https://goreportcard.com/badge/github.com/cilium/cilium&lt;/a&gt; :alt: Go Report Card :target: &lt;a href="https://goreportcard.com/report/github.com/cilium/cilium"&gt;https://goreportcard.com/report/github.com/cilium/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |go-doc| image:: &lt;a href="https://godoc.org/github.com/cilium/cilium?status.svg"&gt;https://godoc.org/github.com/cilium/cilium?status.svg&lt;/a&gt; :alt: GoDoc :target: &lt;a href="https://godoc.org/github.com/cilium/cilium"&gt;https://godoc.org/github.com/cilium/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |rtd| image:: &lt;a href="https://readthedocs.org/projects/docs/badge/?version=latest"&gt;https://readthedocs.org/projects/docs/badge/?version=latest&lt;/a&gt; :alt: Read the Docs :target: &lt;a href="https://docs.cilium.io/"&gt;https://docs.cilium.io/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |apache| image:: &lt;a href="https://img.shields.io/badge/license-Apache-blue.svg"&gt;https://img.shields.io/badge/license-Apache-blue.svg&lt;/a&gt; :alt: Apache licensed :target: apache-license_&lt;/p&gt; 
&lt;p&gt;.. |bsd| image:: &lt;a href="https://img.shields.io/badge/license-BSD-blue.svg"&gt;https://img.shields.io/badge/license-BSD-blue.svg&lt;/a&gt; :alt: BSD licensed :target: bsd-license_&lt;/p&gt; 
&lt;p&gt;.. |gpl| image:: &lt;a href="https://img.shields.io/badge/license-GPL-blue.svg"&gt;https://img.shields.io/badge/license-GPL-blue.svg&lt;/a&gt; :alt: GPL licensed :target: gpl-license_&lt;/p&gt; 
&lt;p&gt;.. |slack| image:: &lt;a href="https://img.shields.io/badge/slack-cilium-brightgreen.svg?logo=slack"&gt;https://img.shields.io/badge/slack-cilium-brightgreen.svg?logo=slack&lt;/a&gt; :alt: Join the Cilium slack channel :target: &lt;a href="https://slack.cilium.io"&gt;https://slack.cilium.io&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |cii| image:: &lt;a href="https://bestpractices.coreinfrastructure.org/projects/1269/badge"&gt;https://bestpractices.coreinfrastructure.org/projects/1269/badge&lt;/a&gt; :alt: CII Best Practices :target: &lt;a href="https://bestpractices.coreinfrastructure.org/projects/1269"&gt;https://bestpractices.coreinfrastructure.org/projects/1269&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |clomonitor| image:: &lt;a href="https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/cilium/badge"&gt;https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/cilium/badge&lt;/a&gt; :alt: CLOMonitor :target: &lt;a href="https://clomonitor.io/projects/cncf/cilium"&gt;https://clomonitor.io/projects/cncf/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |artifacthub| image:: &lt;a href="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/cilium"&gt;https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/cilium&lt;/a&gt; :alt: Artifact Hub :target: &lt;a href="https://artifacthub.io/packages/helm/cilium/cilium"&gt;https://artifacthub.io/packages/helm/cilium/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |fossa| image:: &lt;a href="https://app.fossa.com/api/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git.svg?type=shield"&gt;https://app.fossa.com/api/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git.svg?type=shield&lt;/a&gt; :alt: FOSSA Status :target: &lt;a href="https://app.fossa.com/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git?ref=badge_shield"&gt;https://app.fossa.com/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git?ref=badge_shield&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |gateway-api| image:: &lt;a href="https://img.shields.io/badge/Gateway%20API%20Conformance%20v1.2.0-Cilium-green"&gt;https://img.shields.io/badge/Gateway%20API%20Conformance%20v1.2.0-Cilium-green&lt;/a&gt; :alt: Gateway API Status :target: &lt;a href="https://github.com/kubernetes-sigs/gateway-api/tree/main/conformance/reports/v1.2.0/cilium-cilium"&gt;https://github.com/kubernetes-sigs/gateway-api/tree/main/conformance/reports/v1.2.0/cilium-cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |codespaces| image:: &lt;a href="https://img.shields.io/badge/Open_in_GitHub_Codespaces-gray?logo=github"&gt;https://img.shields.io/badge/Open_in_GitHub_Codespaces-gray?logo=github&lt;/a&gt; :alt: Github Codespaces :target: &lt;a href="https://github.com/codespaces/new?hide_repo_select=true&amp;amp;ref=master&amp;amp;repo=48109239&amp;amp;machine=standardLinux32gb&amp;amp;location=WestEurope"&gt;https://github.com/codespaces/new?hide_repo_select=true&amp;amp;ref=master&amp;amp;repo=48109239&amp;amp;machine=standardLinux32gb&amp;amp;location=WestEurope&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>helm/helm</title>
      <link>https://github.com/helm/helm</link>
      <description>&lt;p&gt;The Kubernetes Package Manager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Helm&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/helm/helm/actions?workflow=release"&gt;&lt;img src="https://github.com/helm/helm/workflows/release/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/helm.sh/helm/v4"&gt;&lt;img src="https://goreportcard.com/badge/helm.sh/helm/v4" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/helm.sh/helm/v4"&gt;&lt;img src="https://img.shields.io/static/v1?label=godoc&amp;amp;message=reference&amp;amp;color=blue" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/3131"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/3131/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/helm/helm"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/helm/helm/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://insights.linuxfoundation.org/project/helm"&gt;&lt;img src="https://insights.linuxfoundation.org/api/badge/health-score?project=helm" alt="LFX Health Score" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Helm is a tool for managing Charts. Charts are packages of pre-configured Kubernetes resources.&lt;/p&gt; 
&lt;p&gt;Use Helm to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Find and use &lt;a href="https://artifacthub.io/packages/search?kind=0"&gt;popular software packaged as Helm Charts&lt;/a&gt; to run in Kubernetes&lt;/li&gt; 
 &lt;li&gt;Share your own applications as Helm Charts&lt;/li&gt; 
 &lt;li&gt;Create reproducible builds of your Kubernetes applications&lt;/li&gt; 
 &lt;li&gt;Intelligently manage your Kubernetes manifest files&lt;/li&gt; 
 &lt;li&gt;Manage releases of Helm packages&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Helm in a Handbasket&lt;/h2&gt; 
&lt;p&gt;Helm is a tool that streamlines installing and managing Kubernetes applications. Think of it like apt/yum/homebrew for Kubernetes.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Helm renders your templates and communicates with the Kubernetes API&lt;/li&gt; 
 &lt;li&gt;Helm runs on your laptop, CI/CD, or wherever you want it to run.&lt;/li&gt; 
 &lt;li&gt;Charts are Helm packages that contain at least two things: 
  &lt;ul&gt; 
   &lt;li&gt;A description of the package (&lt;code&gt;Chart.yaml&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;One or more templates, which contain Kubernetes manifest files&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Charts can be stored on disk, or fetched from remote chart repositories (like Debian or RedHat packages)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Helm Development and Stable Versions&lt;/h2&gt; 
&lt;p&gt;Helm v4 is currently under development on the &lt;code&gt;main&lt;/code&gt; branch. This is unstable and the APIs within the Go SDK and at the command line are changing. Helm v3 (current stable) is maintained on the &lt;code&gt;dev-v3&lt;/code&gt; branch. APIs there follow semantic versioning.&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;Binary downloads of the Helm client can be found on &lt;a href="https://github.com/helm/helm/releases/latest"&gt;the Releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unpack the &lt;code&gt;helm&lt;/code&gt; binary and add it to your PATH and you are good to go!&lt;/p&gt; 
&lt;p&gt;If you want to use a package manager:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt; users can use &lt;code&gt;brew install helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://chocolatey.org/"&gt;Chocolatey&lt;/a&gt; users can use &lt;code&gt;choco install kubernetes-helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/windows/package-manager/"&gt;Winget&lt;/a&gt; users can use &lt;code&gt;winget install Helm.Helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://scoop.sh/"&gt;Scoop&lt;/a&gt; users can use &lt;code&gt;scoop install helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://snapcraft.io/"&gt;Snapcraft&lt;/a&gt; users can use &lt;code&gt;snap install helm --classic&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://flox.dev"&gt;Flox&lt;/a&gt; users can use &lt;code&gt;flox install kubernetes-helm&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mise.jdx.dev/"&gt;Mise-en-place&lt;/a&gt; users can use &lt;code&gt;mise use -g helm@latest&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To rapidly get Helm up and running, start with the &lt;a href="https://helm.sh/docs/intro/quickstart/"&gt;Quick Start Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://helm.sh/docs/intro/install/"&gt;installation guide&lt;/a&gt; for more options, including installing pre-releases.&lt;/p&gt; 
&lt;h2&gt;Docs&lt;/h2&gt; 
&lt;p&gt;Get started with the &lt;a href="https://helm.sh/docs/intro/quickstart/"&gt;Quick Start guide&lt;/a&gt; or plunge into the &lt;a href="https://helm.sh/docs"&gt;complete documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://github.com/helm/helm/milestones"&gt;Helm roadmap uses GitHub milestones&lt;/a&gt; to track the progress of the project.&lt;/p&gt; 
&lt;p&gt;The development of Helm v4 is currently happening on the &lt;code&gt;main&lt;/code&gt; branch while the development of Helm v3, the stable branch, is happening on the &lt;code&gt;dev-v3&lt;/code&gt; branch. Changes should be made to the &lt;code&gt;main&lt;/code&gt; branch prior to being added to the &lt;code&gt;dev-v3&lt;/code&gt; branch so that all changes are carried along to Helm v4.&lt;/p&gt; 
&lt;h2&gt;Community, discussion, contribution, and support&lt;/h2&gt; 
&lt;p&gt;You can reach the Helm community and developers via the following channels:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kubernetes.slack.com"&gt;Kubernetes Slack&lt;/a&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://kubernetes.slack.com/messages/helm-users"&gt;#helm-users&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://kubernetes.slack.com/messages/helm-dev"&gt;#helm-dev&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://kubernetes.slack.com/messages/charts"&gt;#charts&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Mailing List: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://lists.cncf.io/g/cncf-helm"&gt;Helm Mailing List&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Developer Call: Thursdays at 9:30-10:00 Pacific (&lt;a href="https://github.com/helm/community/raw/master/communication.md#meetings"&gt;meeting details&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contribution&lt;/h3&gt; 
&lt;p&gt;If you're interested in contributing, please refer to the &lt;a href="https://raw.githubusercontent.com/helm/helm/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; &lt;strong&gt;before submitting a pull request&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Code of conduct&lt;/h3&gt; 
&lt;p&gt;Participation in the Helm community is governed by the &lt;a href="https://raw.githubusercontent.com/helm/helm/main/code-of-conduct.md"&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>wavetermdev/waveterm</title>
      <link>https://github.com/wavetermdev/waveterm</link>
      <description>&lt;p&gt;An open-source, cross-platform terminal for seamless workflows&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.waveterm.dev"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="./assets/wave-dark.png" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="./assets/wave-light.png" /&gt; 
   &lt;img alt="Wave Terminal Logo" src="https://raw.githubusercontent.com/wavetermdev/waveterm/main/assets/wave-light.png" width="240" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;h1&gt;Wave Terminal&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Wave is an open-source terminal that combines traditional terminal features with graphical capabilities like file previews, web browsing, and AI assistance. It runs on MacOS, Linux, and Windows.&lt;/p&gt; 
&lt;p&gt;Modern development involves constantly switching between terminals and browsers - checking documentation, previewing files, monitoring systems, and using AI tools. Wave brings these graphical tools directly into the terminal, letting you control them from the command line. This means you can stay in your terminal workflow while still having access to the visual interfaces you need.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/wavetermdev/waveterm/main/assets/wave-screenshot.webp" alt="WaveTerm Screenshot" /&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Flexible drag &amp;amp; drop interface to organize terminal blocks, editors, web browsers, and AI assistants&lt;/li&gt; 
 &lt;li&gt;Built-in editor for seamlessly editing remote files with syntax highlighting and modern editor features&lt;/li&gt; 
 &lt;li&gt;Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)&lt;/li&gt; 
 &lt;li&gt;Quick full-screen toggle for any block - expand terminals, editors, and previews for better visibility, then instantly return to multi-block view&lt;/li&gt; 
 &lt;li&gt;Wave AI - Context-aware terminal assistant that reads your terminal output, analyzes widgets, and performs file operations&lt;/li&gt; 
 &lt;li&gt;AI chat widget with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)&lt;/li&gt; 
 &lt;li&gt;Command Blocks for isolating and monitoring individual commands with auto-close options&lt;/li&gt; 
 &lt;li&gt;One-click remote connections with full terminal and file system access&lt;/li&gt; 
 &lt;li&gt;Secure secret storage using native system backends - store API keys and credentials locally, access them across SSH sessions&lt;/li&gt; 
 &lt;li&gt;Rich customization including tab themes, terminal styles, and background images&lt;/li&gt; 
 &lt;li&gt;Powerful &lt;code&gt;wsh&lt;/code&gt; command system for managing your workspace from the CLI and sharing data between terminal sessions&lt;/li&gt; 
 &lt;li&gt;Connected file management with &lt;code&gt;wsh file&lt;/code&gt; - seamlessly copy and sync files between local, remote SSH hosts, Wave filesystem, and S3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Wave AI&lt;/h2&gt; 
&lt;p&gt;Wave AI is your context-aware terminal assistant with access to your workspace:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Terminal Context&lt;/strong&gt;: Reads terminal output and scrollback for debugging and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;File Operations&lt;/strong&gt;: Read, write, and edit files with automatic backups and user approval&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CLI Integration&lt;/strong&gt;: Use &lt;code&gt;wsh ai&lt;/code&gt; to pipe output or attach files directly from the command line&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Free Beta&lt;/strong&gt;: Included AI credits while we refine the experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Coming Soon&lt;/strong&gt;: Command execution (with approval), local model support, and alternate AI providers (BYOK)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Learn more in our &lt;a href="https://docs.waveterm.dev/waveai"&gt;Wave AI documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Wave Terminal works on macOS, Linux, and Windows.&lt;/p&gt; 
&lt;p&gt;Platform-specific installation instructions can be found &lt;a href="https://docs.waveterm.dev/gettingstarted"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also install Wave Terminal directly from: &lt;a href="https://www.waveterm.dev/download"&gt;www.waveterm.dev/download&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Minimum requirements&lt;/h3&gt; 
&lt;p&gt;Wave Terminal runs on the following platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;macOS 11 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Windows 10 1809 or later (x64)&lt;/li&gt; 
 &lt;li&gt;Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The WSH helper runs on the following platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;macOS 11 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Windows 10 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Wave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/ROADMAP.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Want to provide input to our future releases? Connect with us on &lt;a href="https://discord.gg/XfvZ334gwU"&gt;Discord&lt;/a&gt; or open a &lt;a href="https://github.com/wavetermdev/waveterm/issues/new/choose"&gt;Feature Request&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Homepage ‚Äî &lt;a href="https://www.waveterm.dev"&gt;https://www.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Download Page ‚Äî &lt;a href="https://www.waveterm.dev/download"&gt;https://www.waveterm.dev/download&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation ‚Äî &lt;a href="https://docs.waveterm.dev"&gt;https://docs.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Legacy Documentation ‚Äî &lt;a href="https://legacydocs.waveterm.dev"&gt;https://legacydocs.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Blog ‚Äî &lt;a href="https://blog.waveterm.dev"&gt;https://blog.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;X ‚Äî &lt;a href="https://x.com/wavetermdev"&gt;https://x.com/wavetermdev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord Community ‚Äî &lt;a href="https://discord.gg/XfvZ334gwU"&gt;https://discord.gg/XfvZ334gwU&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Building from Source&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/BUILD.md"&gt;Building Wave Terminal&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Wave uses GitHub Issues for issue tracking.&lt;/p&gt; 
&lt;p&gt;Find more information in our &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md"&gt;Contributions Guide&lt;/a&gt;, which includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md#contributing-to-wave-terminal"&gt;Ways to contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md#before-you-start"&gt;Contribution guidelines&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Wave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/ACKNOWLEDGEMENTS.md"&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;a href="https://trendshift.io/repositories/15289" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15289" alt="Tencent%2FWeKnora | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂÆòÊñπÁΩëÁ´ô" src="https://img.shields.io/badge/ÂÆòÊñπÁΩëÁ´ô-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞" src="https://img.shields.io/badge/ÂæÆ‰ø°ÂØπËØùÂºÄÊîæÂπ≥Âè∞-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.2.10-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;Êó•Êú¨Ë™û&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;üí° WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;üìå Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚ú® Latest Updates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;v0.2.0 Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Agent Mode&lt;/strong&gt;: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry&lt;/li&gt; 
 &lt;li&gt;‚öôÔ∏è &lt;strong&gt;Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;üîå &lt;strong&gt;MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;New UI&lt;/strong&gt;: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;strong&gt;Infrastructure Upgrade&lt;/strong&gt;: Introduced MQ async task management, support for automatic database migration, and fast development mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîí Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/architecture.png" alt="weknora-architecture.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;üéØ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Agent Mode&lt;/strong&gt;: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üß† Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîå MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚öôÔ∏è Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìä Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent Mode&lt;/td&gt; 
   &lt;td&gt;‚úÖ ReACT Agent Mode&lt;/td&gt; 
   &lt;td&gt;Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Knowledge Base Types&lt;/td&gt; 
   &lt;td&gt;‚úÖ FAQ / Document&lt;/td&gt; 
   &lt;td&gt;Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;‚úÖ PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ Centralized configuration, built-in model sharing&lt;/td&gt; 
   &lt;td&gt;Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;‚úÖ Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;‚úÖ BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Conversation Strategy&lt;/td&gt; 
   &lt;td&gt;‚úÖ Agent models, normal mode models, retrieval thresholds, Prompt configuration&lt;/td&gt; 
   &lt;td&gt;Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;‚úÖ Extensible search engines, DuckDuckGo / Google&lt;/td&gt; 
   &lt;td&gt;Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MCP Tools&lt;/td&gt; 
   &lt;td&gt;‚úÖ uvx, npx launchers, Stdio/HTTP Streamable/SSE&lt;/td&gt; 
   &lt;td&gt;Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;‚úÖ Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;‚úÖ Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;‚úÖ Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements, with fast development mode support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;‚úÖ Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task Management&lt;/td&gt; 
   &lt;td&gt;‚úÖ MQ async tasks, automatic database migration&lt;/td&gt; 
   &lt;td&gt;MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;üõ† Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Installation&lt;/h3&gt; 
&lt;h4&gt;‚ë† Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢ Start the services (include Ollama)&lt;/h4&gt; 
&lt;p&gt;Check the images that need to be started in the .env file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.0 Start ollama services (Optional)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë¢.1 Activate different combinations of features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimum core services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;All features enabled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile full up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tracing logs required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile jaeger up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neo4j knowledge graph required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minio file storage service required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple options combination&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë£ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîå Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1Ô∏è‚É£ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2Ô∏è‚É£ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîß Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps ‚ë†‚ë° and go directly to steps ‚ë¢‚ë£.&lt;/p&gt; 
&lt;h3&gt;‚ë† Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë° Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë¢ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ë£ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.&lt;/p&gt; 
&lt;h2&gt;üì± Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledgebases.png" alt="Knowledge Base Management" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/settings.png" alt="Conversation Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/agent-qa.png" alt="Agent Mode Tool Call Process" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Mode:&lt;/strong&gt; Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Conversation Strategy:&lt;/strong&gt; Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;p&gt;For detailed configuration, please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/KnowledgeGraph.md"&gt;Knowledge Graph Configuration Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Server&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for the necessary setup.&lt;/p&gt; 
&lt;h2&gt;üìò API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/api/README.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üß≠ Developer Guide&lt;/h2&gt; 
&lt;h3&gt;‚ö° Fast Development Mode (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you need to frequently modify code, &lt;strong&gt;you don't need to rebuild Docker images every time&lt;/strong&gt;! Use fast development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Development Advantages:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Frontend modifications auto hot-reload (no restart needed)&lt;/li&gt; 
 &lt;li&gt;‚úÖ Backend modifications quick restart (5-10 seconds, supports Air hot-reload)&lt;/li&gt; 
 &lt;li&gt;‚úÖ No need to rebuild Docker images&lt;/li&gt; 
 &lt;li&gt;‚úÖ Support IDE breakpoint debugging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Detailed Documentation:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md"&gt;Development Environment Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üìÅ Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
‚îú‚îÄ‚îÄ client/      # go client
‚îú‚îÄ‚îÄ cmd/         # Main entry point
‚îú‚îÄ‚îÄ config/      # Configuration files
‚îú‚îÄ‚îÄ docker/      # docker images files
‚îú‚îÄ‚îÄ docreader/   # Document parsing app
‚îú‚îÄ‚îÄ docs/        # Project documentation
‚îú‚îÄ‚îÄ frontend/    # Frontend app
‚îú‚îÄ‚îÄ internal/    # Core business logic
‚îú‚îÄ‚îÄ mcp-server/  # MCP server
‚îú‚îÄ‚îÄ migrations/  # DB migration scripts
‚îî‚îÄ‚îÄ scripts/     # Shell scripts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;üéØ How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;‚ú® &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üé® Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìù Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üë• Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;üìà Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>harvester/harvester</title>
      <link>https://github.com/harvester/harvester</link>
      <description>&lt;p&gt;Open source hyperconverged infrastructure (HCI) software&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Harvester&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/harvester/harvester/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/harvester/harvester/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/harvester/harvester"&gt;&lt;img src="https://goreportcard.com/badge/github.com/harvester/harvester" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harvester/harvester/releases"&gt;&lt;img src="https://img.shields.io/github/release/harvester/harvester.svg?sanitize=true" alt="Releases" /&gt;&lt;/a&gt; &lt;a href="https://slack.rancher.io/"&gt;&lt;img src="https://img.shields.io/badge/slack-join-brightgreen" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://harvesterhci.io/"&gt;Harvester&lt;/a&gt; is a modern, open, interoperable, &lt;a href="https://en.wikipedia.org/wiki/Hyper-converged_infrastructure"&gt;hyperconverged infrastructure (HCI)&lt;/a&gt; solution built on Kubernetes. It is an open-source alternative designed for operators seeking a &lt;a href="https://about.gitlab.com/topics/cloud-native/"&gt;cloud-native&lt;/a&gt; HCI solution. Harvester runs on bare metal servers and provides integrated virtualization and distributed storage capabilities. In addition to traditional virtual machines (VMs), Harvester supports containerized environments automatically through integration with &lt;a href="https://ranchermanager.docs.rancher.com/integrations-in-rancher/harvester"&gt;Rancher&lt;/a&gt;. It offers a solution that unifies legacy virtualized infrastructure while enabling the adoption of containers from core to edge locations.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harvester/harvester/master/docs/assets/dashboard.png" alt="harvester-ui" /&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Harvester is an enterprise-ready, easy-to-use infrastructure platform that leverages local, direct attached storage instead of complex external SANs. It utilizes Kubernetes API as a unified automation language across container and VM workloads. Some key features of Harvester include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Easy to install:&lt;/strong&gt; Since Harvester ships as a bootable appliance image, you can install it directly on a bare metal server with the &lt;a href="https://github.com/harvester/harvester/releases"&gt;ISO&lt;/a&gt; image or automatically install it using &lt;a href="https://docs.harvesterhci.io/latest/install/pxe-boot-install"&gt;iPXE scripts&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;VM lifecycle management:&lt;/strong&gt; Easily create, edit, clone, and delete VMs, including SSH-Key injection, cloud-init, and graphic and serial port console.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;VM live migration support:&lt;/strong&gt; Move a VM to a different host or node with zero downtime.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;VM backup, snapshot, and restore:&lt;/strong&gt; Back up your VMs from NFS, S3 servers, or NAS devices. Use your backup to restore a failed VM or create a new VM on a different cluster.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage management:&lt;/strong&gt; Harvester supports distributed block storage and tiering. Volumes represent storage; you can easily create, edit, clone, or export a volume.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network management:&lt;/strong&gt; Supports using a virtual IP (VIP) and multiple Network Interface Cards (NICs). If your VMs need to connect to the external network, create a VLAN or untagged network.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Integration with &lt;a href="https://ranchermanager.docs.rancher.com/integrations-in-rancher/harvester"&gt;Rancher&lt;/a&gt;:&lt;/strong&gt; Access Harvester directly within Rancher through Rancher‚Äôs Virtualization Management page and manage your VM workloads alongside your Kubernetes clusters.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The following diagram outlines a high-level architecture of Harvester:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harvester/harvester/master/docs/assets/architecture.svg?sanitize=true" alt="architecture.svg" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://longhorn.io/"&gt;Longhorn&lt;/a&gt; is a lightweight, reliable, and easy-to-use distributed block storage system for Kubernetes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kubevirt.io/"&gt;KubeVirt&lt;/a&gt; is a virtual machine management add-on for Kubernetes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rancher/elemental-toolkit"&gt;Elemental for SLE-Micro 5.3&lt;/a&gt; is an immutable Linux distribution designed to remove as much OS maintenance as possible in a Kubernetes cluster.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hardware Requirements&lt;/h2&gt; 
&lt;p&gt;To get the Harvester server up and running the following minimum hardware is required:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Type&lt;/th&gt; 
   &lt;th align="left"&gt;Requirements&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;CPU&lt;/td&gt; 
   &lt;td align="left"&gt;x86_64 only. Hardware-assisted virtualization is required. 8-core processor minimum for testing; 16-core or above required for production&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Memory&lt;/td&gt; 
   &lt;td align="left"&gt;32 GB minimum; 64 GB or above required for production&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Disk Capacity&lt;/td&gt; 
   &lt;td align="left"&gt;250 GB minimum for testing (180 GB minimum when using multiple disks); 500 GB or above required for production&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Disk Performance&lt;/td&gt; 
   &lt;td align="left"&gt;5,000+ random IOPS per disk (SSD/NVMe). Management nodes (first three nodes) must be &lt;a href="https://www.suse.com/support/kb/doc/?id=000020100"&gt;fast enough for etcd&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Network Card&lt;/td&gt; 
   &lt;td align="left"&gt;1 Gbps Ethernet minimum for testing; 10Gbps Ethernet required for production&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Network Switch&lt;/td&gt; 
   &lt;td align="left"&gt;Trunking of ports required for VLAN support&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;We recommend server-class hardware for best results. Laptops and nested virtualization are not officially supported.&lt;/p&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;You can use the ISO to install Harvester directly on the bare-metal server to form a Harvester cluster. Users can add one or many compute nodes to join the existing cluster.&lt;/p&gt; 
&lt;p&gt;To get the Harvester ISO, download it from the &lt;a href="https://github.com/harvester/harvester/releases"&gt;Github releases.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;During the installation, you can either choose to &lt;strong&gt;create a new Harvester cluster&lt;/strong&gt; or &lt;strong&gt;join the node to an existing Harvester cluster&lt;/strong&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Mount the Harvester ISO file and boot the server by selecting the &lt;code&gt;Harvester Installer&lt;/code&gt; option. &lt;img src="https://raw.githubusercontent.com/harvester/harvester/master/docs/assets/iso-install.png" alt="iso-install.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;The Harvester installer checks if the hardware meets the minimum requirements for production use. If any of the checks fail, installation is stopped and warnings are printed to the system console. Choose whether to proceed with the installation or exit the installer.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harvester/harvester/master/docs/assets/hardware-check.png" alt="hardware-check.png" /&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: You can disable the hardware check during iPXE installation (for testing purposes) by adding the kernel parameter &lt;code&gt;harvester.install.skipchecks=true&lt;/code&gt; when you boot the system.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Change the password for the default user &lt;code&gt;rancher&lt;/code&gt;. This password will be used to access the node via SSH. &lt;img src="https://raw.githubusercontent.com/harvester/harvester/master/docs/assets/password-change.png" alt="password-change.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;Use the arrow keys to choose an installation mode. By default, the first node will be the management node of the cluster. &lt;img src="https://raw.githubusercontent.com/harvester/harvester/master/docs/assets/iso-installation-mode.png" alt="iso-install-mode.png" /&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;Create a new Harvester cluster&lt;/code&gt;: Select this option to create an entirely new Harvester cluster.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Join an existing Harvester cluster&lt;/code&gt;: Select this option to join an existing Harvester cluster. You need the VIP and cluster token of the cluster you want to join.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Install Harvester binaries only&lt;/code&gt;: If you choose this option, additional setup is required after the first bootup.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Choose the installation disk you want to install the Harvester cluster on and the data disk you want to store VM data on. By default, Harvester uses &lt;a href="https://en.wikipedia.org/wiki/GUID_Partition_Table"&gt;GUID Partition Table (GPT)&lt;/a&gt; partitioning schema for both UEFI and BIOS. If you use the BIOS boot, then you will have the option to select &lt;a href="https://en.wikipedia.org/wiki/Master_boot_record"&gt;Master boot record (MBR)&lt;/a&gt;. &lt;img src="https://raw.githubusercontent.com/harvester/harvester/master/docs/assets/iso-choose-disks.png" alt="iso-choose-disks.png" /&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;Installation disk&lt;/code&gt;: The disk to install the Harvester cluster on.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Data disk&lt;/code&gt;: The disk to store VM data on. Choosing a separate disk to store VM data is recommended.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;Persistent size&lt;/code&gt;: If you only have one disk or use the same disk for both OS and VM data, you need to configure persistent partition size to store system packages and container images. The default and minimum persistent partition size is 150 GiB. You can specify a size like 200Gi or 153600Mi.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Configure network interface(s) for the management network. By default, Harvester will create a bonded NIC named &lt;code&gt;mgmt-bo&lt;/code&gt;, and the IP address can either be configured via DHCP or statically assigned. &lt;img src="https://raw.githubusercontent.com/harvester/harvester/master/docs/assets/iso-config-network.png" alt="iso-config-network.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;(Optional) Configure cluster network. Leave blank to use the defaults.&lt;/li&gt; 
 &lt;li&gt;Configure the &lt;code&gt;HostName&lt;/code&gt; of the node.&lt;/li&gt; 
 &lt;li&gt;(Optional) Configure the &lt;code&gt;DNS Servers&lt;/code&gt;. Use commas as a delimiter to add more DNS servers. Leave blank to use the default DNS server.&lt;/li&gt; 
 &lt;li&gt;Configure the virtual IP (VIP) by selecting a &lt;code&gt;VIP Mode&lt;/code&gt;. This VIP is used to access the cluster or for other nodes to join the cluster. &lt;img src="https://raw.githubusercontent.com/harvester/harvester/master/docs/assets/iso-config-vip.png" alt="iso-config-vip.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;Configure the &lt;code&gt;cluster token&lt;/code&gt;. This token will be used for adding other nodes to the cluster.&lt;/li&gt; 
 &lt;li&gt;Configure and confirm a &lt;code&gt;Password&lt;/code&gt; to access the node. The default SSH user is &lt;code&gt;rancher&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Configure &lt;code&gt;NTP servers&lt;/code&gt; to make sure all nodes' times are synchronized. This defaults to &lt;code&gt;0.suse.pool.ntp.org&lt;/code&gt;. Use commas as a delimiter to add more NTP servers.&lt;/li&gt; 
 &lt;li&gt;(Optional) If you need to use an HTTP proxy to access the outside world, enter the proxy URL address here. Otherwise, leave this blank.&lt;/li&gt; 
 &lt;li&gt;(Optional) You can choose to import SSH keys by providing &lt;code&gt;HTTP URL&lt;/code&gt;. For example, your GitHub public keys &lt;code&gt;https://github.com/&amp;lt;username&amp;gt;.keys&lt;/code&gt; can be used.&lt;/li&gt; 
 &lt;li&gt;(Optional) If you need to customize the host with a &lt;a href="https://docs.harvesterhci.io/latest/install/harvester-configuration"&gt;Harvester configuration&lt;/a&gt;. file, enter the &lt;code&gt;HTTP URL&lt;/code&gt; here.&lt;/li&gt; 
 &lt;li&gt;Review and confirm your installation options. After confirming the installation options, Harvester will be installed on your host. The installation may take a few minutes to complete.&lt;/li&gt; 
 &lt;li&gt;Once the installation is complete, your node restarts. After the restart, the Harvester console displays the management URL and status. The default URL of the web interface is &lt;code&gt;https://your-virtual-ip&lt;/code&gt;. You can use &lt;code&gt;F12&lt;/code&gt; to switch from the Harvester console to the Shell and type &lt;code&gt;exit&lt;/code&gt; to go back to the Harvester console. &lt;img src="https://raw.githubusercontent.com/harvester/harvester/master/docs/assets/iso-installed.png" alt="iso-installed.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;You will be prompted to set the password for the default &lt;code&gt;admin&lt;/code&gt; user when logging in for the first time. &lt;img src="https://raw.githubusercontent.com/harvester/harvester/master/docs/assets/first-time-login.png" alt="first-login.png" /&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;&amp;lt;version&amp;gt;*&lt;/strong&gt; means the release branch is under active support and will have periodic follow-up patch releases.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Latest&lt;/strong&gt; release means the version is the latest release of the newest release branch.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt; release means the version is stable and has been widely adopted by users.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;EOL&lt;/strong&gt; means that the software has reached the end of its useful life and no further code-level maintenance will be provided. You may continue to use the software within the terms of the licensing agreement.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/harvester/harvester/releases"&gt;https://github.com/harvester/harvester/releases&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Release&lt;/th&gt; 
   &lt;th&gt;Version&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Release Note (Changelog)&lt;/th&gt; 
   &lt;th&gt;Upgrade Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;1.7&lt;/strong&gt;*&lt;/td&gt; 
   &lt;td&gt;1.7.0&lt;/td&gt; 
   &lt;td&gt;Latest&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/harvester/harvester/releases/tag/v1.7.0"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.harvesterhci.io/v1.7/upgrade/v1-6-x-to-v1-7-x"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;1.6&lt;/strong&gt;*&lt;/td&gt; 
   &lt;td&gt;1.6.1&lt;/td&gt; 
   &lt;td&gt;Stable&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/harvester/harvester/releases/tag/v1.6.1"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.harvesterhci.io/v1.6/upgrade/v1-5-x-to-v1-6-x"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;1.5&lt;/strong&gt;*&lt;/td&gt; 
   &lt;td&gt;1.5.2&lt;/td&gt; 
   &lt;td&gt;Stable&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/harvester/harvester/releases/tag/v1.5.2"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.harvesterhci.io/v1.5/upgrade/v1-4-2-to-v1-5-2"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;1.4&lt;/strong&gt;*&lt;/td&gt; 
   &lt;td&gt;1.4.3&lt;/td&gt; 
   &lt;td&gt;EOL&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/harvester/harvester/releases/tag/v1.4.3"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.harvesterhci.io/v1.4/upgrade/v1-4-1-to-v1-4-3"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;1.3&lt;/strong&gt;*&lt;/td&gt; 
   &lt;td&gt;1.3.2&lt;/td&gt; 
   &lt;td&gt;EOL&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/harvester/harvester/releases/tag/v1.3.2"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.harvesterhci.io/v1.3/upgrade/v1-3-1-to-v1-3-2"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;1.2&lt;/strong&gt;*&lt;/td&gt; 
   &lt;td&gt;1.2.2&lt;/td&gt; 
   &lt;td&gt;EOL&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/harvester/harvester/releases/tag/v1.2.2"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.harvesterhci.io/v1.2/upgrade/v1-2-1-to-v1-2-2"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;1.1&lt;/strong&gt;*&lt;/td&gt; 
   &lt;td&gt;1.1.3&lt;/td&gt; 
   &lt;td&gt;EOL&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/harvester/harvester/releases/tag/v1.1.3"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.harvesterhci.io/v1.2/upgrade/v1-1-to-v1-1-2"&gt;üîó&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Find more documentation &lt;a href="https://docs.harvesterhci.io/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;Check out this &lt;a href="https://youtu.be/Ngsk7m6NYf4"&gt;demo&lt;/a&gt; to get a quick overview of the Harvester UI.&lt;/p&gt; 
&lt;h2&gt;Source code&lt;/h2&gt; 
&lt;p&gt;Harvester is 100% open-source software. The project source code is spread across a number of repos:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Name&lt;/th&gt; 
   &lt;th align="left"&gt;Repo Address&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Harvester&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/harvester/harvester"&gt;https://github.com/harvester/harvester&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Harvester Dashboard&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/harvester/dashboard"&gt;https://github.com/harvester/dashboard&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Harvester Installer&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/harvester/harvester-installer"&gt;https://github.com/harvester/harvester-installer&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Harvester Network Controller&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/harvester/harvester-network-controller"&gt;https://github.com/harvester/harvester-network-controller&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Harvester Cloud Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/harvester/cloud-provider-harvester"&gt;https://github.com/harvester/cloud-provider-harvester&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Harvester Load Balancer&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/harvester/load-balancer-harvester"&gt;https://github.com/harvester/load-balancer-harvester&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Harvester CSI Driver&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/harvester/harvester-csi-driver"&gt;https://github.com/harvester/harvester-csi-driver&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Harvester Terraform Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/harvester/terraform-provider-harvester"&gt;https://github.com/harvester/terraform-provider-harvester&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;If you need any help with Harvester, please join us at either our &lt;a href="https://slack.rancher.io/"&gt;Slack&lt;/a&gt; #harvester channel or &lt;a href="https://forums.rancher.com/"&gt;forums&lt;/a&gt; where most of our team hangs out at.&lt;/p&gt; 
&lt;p&gt;If you have any feedback or questions, feel free to &lt;a href="https://github.com/harvester/harvester/issues/new/choose"&gt;file an issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also &lt;a href="https://gurubase.io/g/harvester"&gt;ask Harvester Guru&lt;/a&gt; your questions.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright (c) 2025 &lt;a href="https://www.suse.com/"&gt;SUSE, LLC.&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;p&gt;&lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>alibaba/higress</title>
      <link>https://github.com/alibaba/higress</link>
      <description>&lt;p&gt;ü§ñ AI Gateway | AI Native API Gateway&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1 align="center"&gt; &lt;img src="https://img.alicdn.com/imgextra/i2/O1CN01NwxLDd20nxfGBjxmZ_!!6000000006895-2-tps-960-290.png" alt="Higress" width="240" height="72.5" /&gt; &lt;br /&gt; AI Gateway &lt;/h1&gt; 
&lt;h4 align="center"&gt; AI Native API Gateway &lt;/h4&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/alibaba/higress/actions"&gt;&lt;img src="https://github.com/alibaba/higress/actions/workflows/build-and-test.yaml/badge.svg?branch=main" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://www.apache.org/licenses/LICENSE-2.0.html"&gt;&lt;img src="https://img.shields.io/github/license/alibaba/higress.svg?sanitize=true" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/tSbww9VDaM"&gt;&lt;img src="https://img.shields.io/discord/1364956090566971515?color=5865F2&amp;amp;label=discord&amp;amp;labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/10918" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10918" alt="alibaba%2Fhigress | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;a href="https://www.producthunt.com/posts/higress?embed=true&amp;amp;utm_source=badge-featured&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-higress" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=951287&amp;amp;theme=light&amp;amp;t=1745492822283" alt="Higress - Global APIs as MCP powered by AI Gateway | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://higress.ai/en/"&gt;&lt;strong&gt;Official Site&lt;/strong&gt;&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a href="https://higress.cn/en/docs/latest/overview/what-is-higress/"&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a href="https://higress.cn/en/blog/"&gt;&lt;strong&gt;Blog&lt;/strong&gt;&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a href="https://higress.cn/en/ai/mcp-quick-start/"&gt;&lt;strong&gt;MCP Server QuickStart&lt;/strong&gt;&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a href="https://higress.cn/en/docs/latest/dev/architecture/"&gt;&lt;strong&gt;Developer Guide&lt;/strong&gt;&lt;/a&gt; &amp;nbsp; | &amp;nbsp; &lt;a href="https://higress.cn/en/plugin/"&gt;&lt;strong&gt;Wasm Plugin Hub&lt;/strong&gt;&lt;/a&gt; &amp;nbsp; |&lt;/p&gt; 
&lt;p&gt; English | &lt;a href="https://raw.githubusercontent.com/alibaba/higress/main/README_ZH.md"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/alibaba/higress/main/README_JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;What is Higress?&lt;/h2&gt; 
&lt;p&gt;Higress is a cloud-native API gateway based on Istio and Envoy, which can be extended with Wasm plugins written in Go/Rust/JS. It provides dozens of ready-to-use general-purpose plugins and an out-of-the-box console (try the &lt;a href="http://demo.higress.io/"&gt;demo here&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Core Use Cases&lt;/h3&gt; 
&lt;p&gt;Higress's AI gateway capabilities support all &lt;a href="https://github.com/alibaba/higress/tree/main/plugins/wasm-go/extensions/ai-proxy/provider"&gt;mainstream model providers&lt;/a&gt; both domestic and international. It also supports hosting MCP (Model Context Protocol) Servers through its plugin mechanism, enabling AI Agents to easily call various tools and services. With the &lt;a href="https://github.com/higress-group/openapi-to-mcpserver"&gt;openapi-to-mcp tool&lt;/a&gt;, you can quickly convert OpenAPI specifications into remote MCP servers for hosting. Higress provides unified management for both LLM API and MCP API.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üåü Try it now at &lt;a href="https://mcp.higress.ai/"&gt;https://mcp.higress.ai/&lt;/a&gt;&lt;/strong&gt; to experience Higress-hosted Remote MCP Servers firsthand:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://img.alicdn.com/imgextra/i2/O1CN01nmVa0a1aChgpyyWOX_!!6000000003294-0-tps-3430-1742.jpg" alt="Higress MCP Server Platform" /&gt;&lt;/p&gt; 
&lt;h3&gt;Enterprise Adoption&lt;/h3&gt; 
&lt;p&gt;Higress was born within Alibaba to solve the issues of Tengine reload affecting long-connection services and insufficient load balancing capabilities for gRPC/Dubbo. Within Alibaba Cloud, Higress's AI gateway capabilities support core AI applications such as Tongyi Bailian model studio, machine learning PAI platform, and other critical AI services. Alibaba Cloud has built its cloud-native API gateway product based on Higress, providing 99.99% gateway high availability guarantee service capabilities for a large number of enterprise customers.&lt;/p&gt; 
&lt;p&gt;You can click the button below to install the enterprise version of Higress:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.aliyun.com/product/api-gateway?spm=higress-github.topbar.0.0.0"&gt;&lt;img src="https://img.alicdn.com/imgextra/i1/O1CN01e6vwe71EWTHoZEcpK_!!6000000000359-55-tps-170-40.svg?sanitize=true" alt="Deploy on AlibabaCloud" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you use open-source Higress and wish to obtain enterprise-level support, you can contact the project maintainer johnlanni's email: &lt;strong&gt;&lt;a href="mailto:zty98751@alibaba-inc.com"&gt;zty98751@alibaba-inc.com&lt;/a&gt;&lt;/strong&gt; or social media accounts (WeChat ID: &lt;strong&gt;nomadao&lt;/strong&gt;, DingTalk ID: &lt;strong&gt;chengtanzty&lt;/strong&gt;). Please note &lt;strong&gt;Higress&lt;/strong&gt; when adding as a friend :)&lt;/p&gt; 
&lt;h2&gt;Summary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/alibaba/higress/main/#quick-start"&gt;&lt;strong&gt;Quick Start&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/alibaba/higress/main/#feature-showcase"&gt;&lt;strong&gt;Feature Showcase&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/alibaba/higress/main/#use-cases"&gt;&lt;strong&gt;Use Cases&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/alibaba/higress/main/#core-advantages"&gt;&lt;strong&gt;Core Advantages&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/alibaba/higress/main/#community"&gt;&lt;strong&gt;Community&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Higress can be started with just Docker, making it convenient for individual developers to set up locally for learning or for building simple sites:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a working directory
mkdir higress; cd higress
# Start higress, configuration files will be written to the working directory
docker run -d --rm --name higress-ai -v ${PWD}:/data \
        -p 8001:8001 -p 8080:8080 -p 8443:8443  \
        higress-registry.cn-hangzhou.cr.aliyuncs.com/higress/all-in-one:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Port descriptions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Port 8001: Higress UI console entry&lt;/li&gt; 
 &lt;li&gt;Port 8080: Gateway HTTP protocol entry&lt;/li&gt; 
 &lt;li&gt;Port 8443: Gateway HTTPS protocol entry&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;All Higress Docker images use Higress's own image repository and are not affected by Docker Hub rate limits. In addition, the submission and updates of the images are protected by a security scanning mechanism (powered by Alibaba Cloud ACR), making them very secure for use in production environments.&lt;/p&gt; 
 &lt;p&gt;If you experience a timeout when pulling image from &lt;code&gt;higress-registry.cn-hangzhou.cr.aliyuncs.com&lt;/code&gt;, you can try replacing it with the following docker registry mirror source:&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;North America&lt;/strong&gt;: &lt;code&gt;higress-registry.us-west-1.cr.aliyuncs.com&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Southeast Asia&lt;/strong&gt;: &lt;code&gt;higress-registry.ap-southeast-7.cr.aliyuncs.com&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For other installation methods such as Helm deployment under K8s, please refer to the official &lt;a href="https://higress.io/en-us/docs/user/quickstart"&gt;Quick Start documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are deploying on the cloud, it is recommended to use the &lt;a href="https://www.aliyun.com/product/apigateway?spm=higress-github.topbar.0.0.0"&gt;Enterprise Edition&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Use Cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP Server Hosting&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;Higress hosts MCP Servers through its plugin mechanism, enabling AI Agents to easily call various tools and services. With the &lt;a href="https://github.com/higress-group/openapi-to-mcpserver"&gt;openapi-to-mcp tool&lt;/a&gt;, you can quickly convert OpenAPI specifications into remote MCP servers.&lt;/p&gt; &lt;p&gt;&lt;img src="https://img.alicdn.com/imgextra/i1/O1CN01wv8H4g1mS4MUzC1QC_!!6000000004952-2-tps-1764-597.png" alt="" /&gt;&lt;/p&gt; &lt;p&gt;Key benefits of hosting MCP Servers with Higress:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Unified authentication and authorization mechanisms&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Fine-grained rate limiting to prevent abuse&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Comprehensive audit logs for all tool calls&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Rich observability for monitoring performance&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Simplified deployment through Higress's plugin mechanism&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Dynamic updates without disruption or connection drops&lt;/p&gt; &lt;p&gt;&lt;a href="https://higress.cn/en/ai/mcp-quick-start/?spm=36971b57.7beea2de.0.0.d85f20a94jsWGm"&gt;Learn more...&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI Gateway&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;Higress connects to all LLM model providers using a unified protocol, with AI observability, multi-model load balancing, token rate limiting, and caching capabilities:&lt;/p&gt; &lt;p&gt;&lt;img src="https://img.alicdn.com/imgextra/i2/O1CN01izmBNX1jbHT7lP3Yr_!!6000000004566-0-tps-1920-1080.jpg" alt="" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Kubernetes ingress controller&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;Higress can function as a feature-rich ingress controller, which is compatible with many annotations of K8s' nginx ingress controller.&lt;/p&gt; &lt;p&gt;&lt;a href="https://gateway-api.sigs.k8s.io/"&gt;Gateway API&lt;/a&gt; is already supported, and it supports a smooth migration from Ingress API to Gateway API.&lt;/p&gt; &lt;p&gt;Compared to ingress-nginx, the resource overhead has significantly decreased, and the speed at which route changes take effect has improved by ten times.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;The following resource overhead comparison comes from &lt;a href="https://github.com/labring"&gt;sealos&lt;/a&gt;.&lt;/p&gt; 
   &lt;p&gt;For details, you can read this &lt;a href="https://sealos.io/blog/sealos-envoy-vs-nginx-2000-tenants"&gt;article&lt;/a&gt; to understand how sealos migrates the monitoring of &lt;strong&gt;tens of thousands of ingress&lt;/strong&gt; resources from nginx ingress to higress.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;p&gt;&lt;img src="https://img.alicdn.com/imgextra/i1/O1CN01bhEtb229eeMNBWmdP_!!6000000008093-2-tps-750-547.png" alt="" /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Microservice gateway&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;Higress can function as a microservice gateway, which can discovery microservices from various service registries, such as Nacos, ZooKeeper, Consul, Eureka, etc.&lt;/p&gt; &lt;p&gt;It deeply integrates with &lt;a href="https://github.com/apache/dubbo"&gt;Dubbo&lt;/a&gt;, &lt;a href="https://github.com/alibaba/nacos"&gt;Nacos&lt;/a&gt;, &lt;a href="https://github.com/alibaba/Sentinel"&gt;Sentinel&lt;/a&gt; and other microservice technology stacks.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Security gateway&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;Higress can be used as a security gateway, supporting WAF and various authentication strategies, such as key-auth, hmac-auth, jwt-auth, basic-auth, oidc, etc.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Core Advantages&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Production Grade&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Born from Alibaba's internal product with over 2 years of production validation, supporting large-scale scenarios with hundreds of thousands of requests per second.&lt;/p&gt; &lt;p&gt;Completely eliminates traffic jitter caused by Nginx reload, configuration changes take effect in milliseconds and are transparent to business. Especially friendly to long-connection scenarios such as AI businesses.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Streaming Processing&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Supports true complete streaming processing of request/response bodies, Wasm plugins can easily customize the handling of streaming protocols such as SSE (Server-Sent Events).&lt;/p&gt; &lt;p&gt;In high-bandwidth scenarios such as AI businesses, it can significantly reduce memory overhead.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Easy to Extend&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Provides a rich official plugin library covering AI, traffic management, security protection and other common functions, meeting more than 90% of business scenario requirements.&lt;/p&gt; &lt;p&gt;Focuses on Wasm plugin extensions, ensuring memory safety through sandbox isolation, supporting multiple programming languages, allowing plugin versions to be upgraded independently, and achieving traffic-lossless hot updates of gateway logic.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secure and Easy to Use&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Based on Ingress API and Gateway API standards, provides out-of-the-box UI console, WAF protection plugin, IP/Cookie CC protection plugin ready to use.&lt;/p&gt; &lt;p&gt;Supports connecting to Let's Encrypt for automatic issuance and renewal of free certificates, and can be deployed outside of K8s, started with a single Docker command, convenient for individual developers to use.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our Discord community! This is where you can connect with developers and other enthusiastic users of Higress.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/tSbww9VDaM"&gt;&lt;img src="https://img.shields.io/discord/1364956090566971515?color=5865F2&amp;amp;label=discord&amp;amp;labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Thanks&lt;/h3&gt; 
&lt;p&gt;Higress would not be possible without the valuable open-source work of projects in the community. We would like to extend a special thank you to Envoy and Istio.&lt;/p&gt; 
&lt;h3&gt;Related Repositories&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Higress Console: &lt;a href="https://github.com/higress-group/higress-console"&gt;https://github.com/higress-group/higress-console&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Higress Standalone: &lt;a href="https://github.com/higress-group/higress-standalone"&gt;https://github.com/higress-group/higress-standalone&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;a href="https://github.com/alibaba/higress/graphs/contributors"&gt; &lt;img alt="contributors" src="https://contrib.rocks/image?repo=alibaba/higress" /&gt; &lt;/a&gt; 
&lt;h3&gt;Star History&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#alibaba/higress&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=alibaba/higress&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="right" style="font-size: 14px; color: #555; margin-top: 20px;"&gt; &lt;a href="https://raw.githubusercontent.com/alibaba/higress/main/#readme-top" style="text-decoration: none; color: #007bff; font-weight: bold;"&gt; ‚Üë Back to Top ‚Üë &lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>juicedata/juicefs</title>
      <link>https://github.com/juicedata/juicefs</link>
      <description>&lt;p&gt;JuiceFS is a distributed POSIX file system built on top of Redis and S3.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;a href="https://github.com/juicedata/juicefs"&gt;&lt;img alt="JuiceFS Logo" src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-logo-new.svg?sanitize=true" width="50%" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/juicedata/juicefs/releases/latest"&gt;&lt;img alt="Latest Stable Release" src="https://img.shields.io/github/v/release/juicedata/juicefs" /&gt;&lt;/a&gt; &lt;a href="https://github.com/juicedata/juicefs/actions/workflows/unittests.yml"&gt;&lt;img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/unittests.yml?branch=main&amp;amp;label=Unit%20Testing" /&gt;&lt;/a&gt; &lt;a href="https://github.com/juicedata/juicefs/actions/workflows/integrationtests.yml"&gt;&lt;img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/integrationtests.yml?branch=main&amp;amp;label=Integration%20Testing" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/juicedata/juicefs"&gt;&lt;img alt="Go Report" src="https://goreportcard.com/badge/github.com/juicedata/juicefs" /&gt;&lt;/a&gt; &lt;a href="https://juicefs.com/docs/community/introduction"&gt;&lt;img alt="English doc" src="https://img.shields.io/badge/docs-Doc%20Center-brightgreen" /&gt;&lt;/a&gt; &lt;a href="https://go.juicefs.com/slack"&gt;&lt;img alt="Join Slack" src="https://badgen.net/badge/Slack/Join%20JuiceFS/0abd59?icon=slack" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;JuiceFS&lt;/strong&gt; is a high-performance &lt;a href="https://en.wikipedia.org/wiki/POSIX"&gt;POSIX&lt;/a&gt; file system released under Apache License 2.0, particularly designed for the cloud-native environment. The data, stored via JuiceFS, will be persisted in Object Storage &lt;em&gt;(e.g. Amazon S3)&lt;/em&gt;, and the corresponding metadata can be persisted in various compatible database engines such as Redis, MySQL, and TiKV based on the scenarios and requirements.&lt;/p&gt; 
&lt;p&gt;With JuiceFS, massive cloud storage can be directly connected to big data, machine learning, artificial intelligence, and various application platforms in production environments. Without modifying code, the massive cloud storage can be used as efficiently as local storage.&lt;/p&gt; 
&lt;p&gt;üìñ &lt;strong&gt;Document&lt;/strong&gt;: &lt;a href="https://juicefs.com/docs/community/quick_start_guide"&gt;Quick Start Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Highlighted Features&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fully POSIX-compatible&lt;/strong&gt;: Use as a local file system, seamlessly docking with existing applications without breaking business workflow.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fully Hadoop-compatible&lt;/strong&gt;: JuiceFS' &lt;a href="https://juicefs.com/docs/community/hadoop_java_sdk"&gt;Hadoop Java SDK&lt;/a&gt; is compatible with Hadoop 2.x and Hadoop 3.x as well as a variety of components in the Hadoop ecosystems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3-compatible&lt;/strong&gt;: JuiceFS' &lt;a href="https://juicefs.com/docs/community/s3_gateway"&gt;S3 Gateway&lt;/a&gt; provides an S3-compatible interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Native&lt;/strong&gt;: A &lt;a href="https://juicefs.com/docs/community/how_to_use_on_kubernetes"&gt;Kubernetes CSI Driver&lt;/a&gt; is provided for easily using JuiceFS in Kubernetes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Shareable&lt;/strong&gt;: JuiceFS is a shared file storage that can be read and written by thousands of clients.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Strong Consistency&lt;/strong&gt;: The confirmed modification will be immediately visible on all the servers mounted with the same file system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Outstanding Performance&lt;/strong&gt;: The latency can be as low as a few milliseconds, and the throughput can be expanded nearly unlimitedly &lt;em&gt;(depending on the size of the Object Storage)&lt;/em&gt;. &lt;a href="https://juicefs.com/docs/community/benchmark"&gt;Test results&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: Supports data encryption in transit and at rest (please refer to &lt;a href="https://juicefs.com/docs/community/security/encrypt"&gt;the guide&lt;/a&gt; for more information).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Global File Locks&lt;/strong&gt;: JuiceFS supports both BSD locks (flock) and POSIX record locks (fcntl).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Compression&lt;/strong&gt;: JuiceFS supports &lt;a href="https://lz4.github.io/lz4"&gt;LZ4&lt;/a&gt; or &lt;a href="https://facebook.github.io/zstd"&gt;Zstandard&lt;/a&gt; to compress all your data.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#architecture"&gt;Architecture&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#getting-started"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#advanced-topics"&gt;Advanced Topics&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#posix-compatibility"&gt;POSIX Compatibility&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#performance-benchmark"&gt;Performance Benchmark&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#supported-object-storage"&gt;Supported Object Storage&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#who-is-using"&gt;Who is using&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#roadmap"&gt;Roadmap&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#reporting-issues"&gt;Reporting Issues&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#contributing"&gt;Contributing&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#community"&gt;Community&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#usage-tracking"&gt;Usage Tracking&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#license"&gt;License&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#credits"&gt;Credits&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#faq"&gt;FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;JuiceFS consists of three parts:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;JuiceFS Client&lt;/strong&gt;: Coordinates Object Storage and metadata storage engine as well as implementation of file system interfaces such as POSIX, Hadoop, Kubernetes, and S3 gateway.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Storage&lt;/strong&gt;: Stores data, with supports of a variety of data storage media, e.g., local disk, public or private cloud Object Storage, and HDFS.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Metadata Engine&lt;/strong&gt;: Stores the corresponding metadata that contains information of file name, file size, permission group, creation and modification time and directory structure, etc., with supports of different metadata engines, e.g., Redis, MySQL, SQLite and TiKV.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-arch-new.png" alt="JuiceFS Architecture" /&gt;&lt;/p&gt; 
&lt;p&gt;JuiceFS can store the metadata of file system on different metadata engines, like Redis, which is a fast, open-source, in-memory key-value data storage, particularly suitable for storing metadata; meanwhile, all the data will be stored in Object Storage through JuiceFS client. &lt;a href="https://juicefs.com/docs/community/architecture"&gt;Learn more&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/data-structure-diagram.svg?sanitize=true" alt="data-structure-diagram" /&gt;&lt;/p&gt; 
&lt;p&gt;Each file stored in JuiceFS is split into &lt;strong&gt;"Chunk"&lt;/strong&gt; s at a fixed size with the default upper limit of 64 MiB. Each Chunk is composed of one or more &lt;strong&gt;"Slice"&lt;/strong&gt;(s), and the length of the slice varies depending on how the file is written. Each slice is composed of size-fixed &lt;strong&gt;"Block"&lt;/strong&gt; s, which are 4 MiB by default. These blocks will be stored in Object Storage in the end; at the same time, the metadata information of the file and its Chunks, Slices, and Blocks will be stored in metadata engines via JuiceFS. &lt;a href="https://juicefs.com/docs/community/architecture/#how-juicefs-store-files"&gt;Learn more&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/how-juicefs-stores-files.svg?sanitize=true" alt="How JuiceFS stores your files" /&gt;&lt;/p&gt; 
&lt;p&gt;When using JuiceFS, files will eventually be split into Chunks, Slices and Blocks and stored in Object Storage. Therefore, the source files stored in JuiceFS cannot be found in the file browser of the Object Storage platform; instead, there are only a chunks directory and a bunch of digitally numbered directories and files in the bucket. Don't panic! This is just the secret of the high-performance operation of JuiceFS!&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Before you begin, make sure you have:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;One supported metadata engine, see &lt;a href="https://juicefs.com/docs/community/databases_for_metadata"&gt;How to Set Up Metadata Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;One supported Object Storage for storing data blocks, see &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage"&gt;Supported Object Storage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/installation"&gt;JuiceFS Client&lt;/a&gt; downloaded and installed&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please refer to &lt;a href="https://juicefs.com/docs/community/quick_start_guide"&gt;Quick Start Guide&lt;/a&gt; to start using JuiceFS right away!&lt;/p&gt; 
&lt;h3&gt;Command Reference&lt;/h3&gt; 
&lt;p&gt;Check out all the command line options in &lt;a href="https://juicefs.com/docs/community/command_reference"&gt;command reference&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Containers&lt;/h3&gt; 
&lt;p&gt;JuiceFS can be used as a persistent volume for Docker and Podman, please check &lt;a href="https://juicefs.com/docs/community/juicefs_on_docker"&gt;here&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Kubernetes&lt;/h3&gt; 
&lt;p&gt;It is also very easy to use JuiceFS on Kubernetes. Please find more information &lt;a href="https://juicefs.com/docs/community/how_to_use_on_kubernetes"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Hadoop Java SDK&lt;/h3&gt; 
&lt;p&gt;If you wanna use JuiceFS in Hadoop, check &lt;a href="https://juicefs.com/docs/community/hadoop_java_sdk"&gt;Hadoop Java SDK&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Advanced Topics&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/redis_best_practices"&gt;Redis Best Practices&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage"&gt;How to Setup Object Storage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/cache"&gt;Cache&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/fault_diagnosis_and_analysis"&gt;Fault Diagnosis and Analysis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/fuse_mount_options"&gt;FUSE Mount Options&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/installation#windows"&gt;Using JuiceFS on Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://juicefs.com/docs/community/s3_gateway"&gt;S3 Gateway&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please refer to &lt;a href="https://juicefs.com/docs/community/introduction"&gt;JuiceFS Document Center&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;POSIX Compatibility&lt;/h2&gt; 
&lt;p&gt;JuiceFS has passed all of the compatibility tests (8813 in total) in the latest &lt;a href="https://github.com/pjd/pjdfstest"&gt;pjdfstest&lt;/a&gt; .&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;All tests successful.

Test Summary Report
-------------------
/root/soft/pjdfstest/tests/chown/00.t          (Wstat: 0 Tests: 1323 Failed: 0)
  TODO passed:   693, 697, 708-709, 714-715, 729, 733
Files=235, Tests=8813, 233 wallclock secs ( 2.77 usr  0.38 sys +  2.57 cusr  3.93 csys =  9.65 CPU)
Result: PASS
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Aside from the POSIX features covered by pjdfstest, JuiceFS also provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Close-to-open consistency&lt;/strong&gt;. Once a file is written &lt;em&gt;and&lt;/em&gt; closed, it is guaranteed to view the written data in the following opens and reads from any client. Within the same mount point, all the written data can be read immediately.&lt;/li&gt; 
 &lt;li&gt;Rename and all other metadata operations are atomic, which are guaranteed by supported metadata engine transaction.&lt;/li&gt; 
 &lt;li&gt;Opened files remain accessible after unlink from same mount point.&lt;/li&gt; 
 &lt;li&gt;Mmap (tested with FSx).&lt;/li&gt; 
 &lt;li&gt;Fallocate with punch hole support.&lt;/li&gt; 
 &lt;li&gt;Extended attributes (xattr).&lt;/li&gt; 
 &lt;li&gt;BSD locks (flock).&lt;/li&gt; 
 &lt;li&gt;POSIX record locks (fcntl).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performance Benchmark&lt;/h2&gt; 
&lt;h3&gt;Basic benchmark&lt;/h3&gt; 
&lt;p&gt;JuiceFS provides a subcommand that can run a few basic benchmarks to help you understand how it works in your environment:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/juicefs-bench.png" alt="JuiceFS Bench" /&gt;&lt;/p&gt; 
&lt;h3&gt;Throughput&lt;/h3&gt; 
&lt;p&gt;A sequential read/write benchmark has also been performed on JuiceFS, &lt;a href="https://aws.amazon.com/efs"&gt;EFS&lt;/a&gt; and &lt;a href="https://github.com/s3fs-fuse/s3fs-fuse"&gt;S3FS&lt;/a&gt; by &lt;a href="https://github.com/axboe/fio"&gt;fio&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/sequential-read-write-benchmark.svg?sanitize=true" alt="Sequential Read Write Benchmark" /&gt;&lt;/p&gt; 
&lt;p&gt;Above result figure shows that JuiceFS can provide 10X more throughput than the other two (see &lt;a href="https://juicefs.com/docs/community/fio"&gt;more details&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Metadata IOPS&lt;/h3&gt; 
&lt;p&gt;A simple mdtest benchmark has been performed on JuiceFS, &lt;a href="https://aws.amazon.com/efs"&gt;EFS&lt;/a&gt; and &lt;a href="https://github.com/s3fs-fuse/s3fs-fuse"&gt;S3FS&lt;/a&gt; by &lt;a href="https://github.com/hpc/ior"&gt;mdtest&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/juicedata/juicefs/main/docs/en/images/metadata-benchmark.svg?sanitize=true" alt="Metadata Benchmark" /&gt;&lt;/p&gt; 
&lt;p&gt;The result shows that JuiceFS can provide significantly more metadata IOPS than the other two (see &lt;a href="https://juicefs.com/docs/community/mdtest"&gt;more details&lt;/a&gt;).&lt;/p&gt; 
&lt;h3&gt;Analyze performance&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/fault_diagnosis_and_analysis#performance-monitor"&gt;Real-Time Performance Monitoring&lt;/a&gt; if you encountered performance issues.&lt;/p&gt; 
&lt;h2&gt;Supported Object Storage&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Amazon S3 &lt;em&gt;(and other S3 compatible Object Storage services)&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Google Cloud Storage&lt;/li&gt; 
 &lt;li&gt;Azure Blob Storage&lt;/li&gt; 
 &lt;li&gt;Alibaba Cloud Object Storage Service (OSS)&lt;/li&gt; 
 &lt;li&gt;Tencent Cloud Object Storage (COS)&lt;/li&gt; 
 &lt;li&gt;Qiniu Cloud Object Storage (Kodo)&lt;/li&gt; 
 &lt;li&gt;QingStor Object Storage&lt;/li&gt; 
 &lt;li&gt;Ceph RGW&lt;/li&gt; 
 &lt;li&gt;MinIO&lt;/li&gt; 
 &lt;li&gt;Local disk&lt;/li&gt; 
 &lt;li&gt;Redis&lt;/li&gt; 
 &lt;li&gt;...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;JuiceFS supports numerous Object Storage services. &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage"&gt;Learn more&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Who is using&lt;/h2&gt; 
&lt;p&gt;JuiceFS is production ready and used by thousands of machines in production. A list of users has been assembled and documented &lt;a href="https://juicefs.com/docs/community/adopters"&gt;here&lt;/a&gt;. In addition JuiceFS has several collaborative projects that integrate with other open source projects, which we have documented &lt;a href="https://juicefs.com/docs/community/integrations"&gt;here&lt;/a&gt;. If you are also using JuiceFS, please feel free to let us know, and you are welcome to share your specific experience with everyone.&lt;/p&gt; 
&lt;p&gt;The storage format is stable, and will be supported by all future releases.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Gateway Optimization&lt;/li&gt; 
 &lt;li&gt;Resumable Sync&lt;/li&gt; 
 &lt;li&gt;Read-ahead Optimization&lt;/li&gt; 
 &lt;li&gt;Optimization for Large-scale Scenarios&lt;/li&gt; 
 &lt;li&gt;Snapshots&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reporting Issues&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/juicedata/juicefs/issues"&gt;GitHub Issues&lt;/a&gt; to track community reported issues. You can also &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/#community"&gt;contact&lt;/a&gt; the community for any questions.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for your contribution! Please refer to the &lt;a href="https://juicefs.com/docs/community/development/contributing_guide"&gt;JuiceFS Contributing Guide&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Welcome to join the &lt;a href="https://github.com/juicedata/juicefs/discussions"&gt;Discussions&lt;/a&gt; and the &lt;a href="https://go.juicefs.com/slack"&gt;Slack channel&lt;/a&gt; to connect with JuiceFS team members and other users.&lt;/p&gt; 
&lt;h2&gt;Usage Tracking&lt;/h2&gt; 
&lt;p&gt;JuiceFS collects &lt;strong&gt;anonymous&lt;/strong&gt; usage data by default to help us better understand how the community is using JuiceFS. Only core metrics (e.g. version number) will be reported, and user data and any other sensitive data will not be included. The related code can be viewed &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/pkg/usage/usage.go"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You could also disable reporting easily by command line option &lt;code&gt;--no-usage-report&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;juicefs mount --no-usage-report
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;JuiceFS is open-sourced under Apache License 2.0, see &lt;a href="https://raw.githubusercontent.com/juicedata/juicefs/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;The design of JuiceFS was inspired by &lt;a href="https://research.google/pubs/pub51"&gt;Google File System&lt;/a&gt;, &lt;a href="https://hadoop.apache.org"&gt;HDFS&lt;/a&gt; and &lt;a href="https://moosefs.com"&gt;MooseFS&lt;/a&gt;. Thanks for their great work!&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Why doesn't JuiceFS support XXX Object Storage?&lt;/h3&gt; 
&lt;p&gt;JuiceFS supports many Object Storage services. Please check out &lt;a href="https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage"&gt;this list&lt;/a&gt; first. If the Object Storage you want to use is compatible with S3, you could treat it as S3. Otherwise, try reporting any issue.&lt;/p&gt; 
&lt;h3&gt;Can I use Redis Cluster as metadata engine?&lt;/h3&gt; 
&lt;p&gt;Yes. Since &lt;a href="https://github.com/juicedata/juicefs/releases/tag/v1.0.0-beta3"&gt;v1.0.0 Beta3&lt;/a&gt; JuiceFS supports the use of &lt;a href="https://redis.io/docs/manual/scaling"&gt;Redis Cluster&lt;/a&gt; as the metadata engine, but it should be noted that Redis Cluster requires that the keys of all operations in a transaction must be in the same hash slot, so a JuiceFS file system can only use one hash slot.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/redis_best_practices"&gt;"Redis Best Practices"&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;What's the difference between JuiceFS and XXX?&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://juicefs.com/docs/community/comparison/juicefs_vs_alluxio"&gt;"Comparison with Others"&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;For more FAQs, please see the &lt;a href="https://juicefs.com/docs/community/faq"&gt;full list&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#juicedata/juicefs&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=juicedata/juicefs&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>grafana/loki</title>
      <link>https://github.com/grafana/loki</link>
      <description>&lt;p&gt;Like Prometheus, but for logs.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/grafana/loki/main/docs/sources/logo_and_name.png" alt="Loki Logo" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/grafana/loki/actions/workflows/check.yml"&gt;&lt;img src="https://github.com/grafana/loki/actions/workflows/check.yml/badge.svg?sanitize=true" alt="Check" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/grafana/loki"&gt;&lt;img src="https://goreportcard.com/badge/github.com/grafana/loki" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://slack.grafana.com/"&gt;&lt;img src="https://img.shields.io/badge/join%20slack-%23loki-brightgreen.svg?sanitize=true" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;amp;can=1&amp;amp;q=proj:loki"&gt;&lt;img src="https://oss-fuzz-build-logs.storage.googleapis.com/badges/loki.svg?sanitize=true" alt="Fuzzing Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Loki: like Prometheus, but for logs.&lt;/h1&gt; 
&lt;p&gt;Loki is a horizontally-scalable, highly-available, multi-tenant log aggregation system inspired by &lt;a href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt;. It is designed to be very cost effective and easy to operate. It does not index the contents of the logs, but rather a set of labels for each log stream.&lt;/p&gt; 
&lt;p&gt;Compared to other log aggregation systems, Loki:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;does not do full text indexing on logs. By storing compressed, unstructured logs and only indexing metadata, Loki is simpler to operate and cheaper to run.&lt;/li&gt; 
 &lt;li&gt;indexes and groups log streams using the same labels you‚Äôre already using with Prometheus, enabling you to seamlessly switch between metrics and logs using the same labels that you‚Äôre already using with Prometheus.&lt;/li&gt; 
 &lt;li&gt;is an especially good fit for storing &lt;a href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt; Pod logs. Metadata such as Pod labels is automatically scraped and indexed.&lt;/li&gt; 
 &lt;li&gt;has native support in Grafana (needs Grafana v6.0).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;A Loki-based logging stack consists of 3 components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grafana/alloy"&gt;Alloy&lt;/a&gt; is agent, responsible for gathering logs and sending them to Loki.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grafana/loki"&gt;Loki&lt;/a&gt; is the main service, responsible for storing logs and processing queries.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grafana/grafana"&gt;Grafana&lt;/a&gt; for querying and displaying the logs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note that Alloy replaced Promtail in the stack, because Promtail is considered to be feature complete, and future development for logs collection will be in &lt;a href="https://github.com/grafana/alloy"&gt;Grafana Alloy&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Loki is like Prometheus, but for logs: we prefer a multidimensional label-based approach to indexing, and want a single-binary, easy to operate system with no dependencies. Loki differs from Prometheus by focusing on logs instead of metrics, and delivering logs via push, instead of pull.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/installation/"&gt;Installing Loki&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/send-data/alloy/"&gt;Installing Alloy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/get-started/"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Upgrading&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/upgrading/"&gt;Upgrading Loki&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/"&gt;Latest release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/next/"&gt;Upcoming release&lt;/a&gt;, at the tip of the main branch&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Commonly used sections:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/api/"&gt;API documentation&lt;/a&gt; for getting logs into Loki.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/getting-started/labels/"&gt;Labels&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/operations/"&gt;Operations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/clients/promtail/"&gt;Promtail&lt;/a&gt; is an agent which tails log files and pushes them to Loki.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/clients/promtail/pipelines/"&gt;Pipelines&lt;/a&gt; details the log processing pipeline.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/clients/docker-driver/"&gt;Docker Driver Client&lt;/a&gt; is a Docker plugin to send logs directly to Loki from Docker containers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/query/logcli/"&gt;LogCLI&lt;/a&gt; provides a command-line interface for querying logs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/operations/loki-canary/"&gt;Loki Canary&lt;/a&gt; monitors your Loki installation for missing logs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/operations/troubleshooting/"&gt;Troubleshooting&lt;/a&gt; presents help dealing with error messages.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/loki/latest/operations/grafana/"&gt;Loki in Grafana&lt;/a&gt; describes how to set up a Loki datasource in Grafana.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;p&gt;If you have any questions or feedback regarding Loki:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Search existing thread in the Grafana Labs community forum for Loki: &lt;a href="https://community.grafana.com/c/grafana-loki/"&gt;https://community.grafana.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ask a question on the Loki Slack channel. To invite yourself to the Grafana Slack, visit &lt;a href="https://slack.grafana.com/"&gt;https://slack.grafana.com/&lt;/a&gt; and join the #loki channel.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grafana/loki/issues/new"&gt;File an issue&lt;/a&gt; for bugs, issues and feature suggestions.&lt;/li&gt; 
 &lt;li&gt;Send an email to &lt;a href="mailto:lokiproject@googlegroups.com"&gt;lokiproject@googlegroups.com&lt;/a&gt;, or use the &lt;a href="https://groups.google.com/forum/#!forum/lokiproject"&gt;web interface&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;UI issues should be filed directly in &lt;a href="https://github.com/grafana/grafana/issues/new"&gt;Grafana&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your feedback is always welcome.&lt;/p&gt; 
&lt;h2&gt;Further Reading&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The original &lt;a href="https://docs.google.com/document/d/11tjK_lvp1-SVsFZjgOTr1vV3-q6vBAsZYIQ5ZeYBkyM/view"&gt;design doc&lt;/a&gt; for Loki is a good source for discussion of the motivation and design decisions.&lt;/li&gt; 
 &lt;li&gt;Callum Styan's March 2019 DevOpsDays Vancouver talk "&lt;a href="https://grafana.com/blog/2019/05/06/how-loki-correlates-metrics-and-logs-and-saves-you-money/"&gt;Grafana Loki: Log Aggregation for Incident Investigations&lt;/a&gt;".&lt;/li&gt; 
 &lt;li&gt;Grafana Labs blog post "&lt;a href="https://grafana.com/blog/2019/04/15/how-we-designed-loki-to-work-easily-both-as-microservices-and-as-monoliths/"&gt;How We Designed Loki to Work Easily Both as Microservices and as Monoliths&lt;/a&gt;".&lt;/li&gt; 
 &lt;li&gt;Tom Wilkie's early-2019 CNCF Paris/FOSDEM talk "&lt;a href="https://fosdem.org/2019/schedule/event/loki_prometheus_for_logs/"&gt;Grafana Loki: like Prometheus, but for logs&lt;/a&gt;" (&lt;a href="https://speakerdeck.com/grafana/grafana-loki-like-prometheus-but-for-logs"&gt;slides&lt;/a&gt;, &lt;a href="https://mirror.as35701.net/video.fosdem.org/2019/UB2.252A/loki_prometheus_for_logs.mp4"&gt;video&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;David Kaltschmidt's KubeCon 2018 talk "&lt;a href="https://kccna18.sched.com/event/GrXC/on-the-oss-path-to-full-observability-with-grafana-david-kaltschmidt-grafana-labs"&gt;On the OSS Path to Full Observability with Grafana&lt;/a&gt;" (&lt;a href="https://speakerdeck.com/davkal/on-the-path-to-full-observability-with-oss-and-launch-of-loki"&gt;slides&lt;/a&gt;, &lt;a href="https://www.youtube.com/watch?v=U7C5SpRtK74&amp;amp;list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU&amp;amp;index=346"&gt;video&lt;/a&gt;) on how Loki fits into a cloud-native environment.&lt;/li&gt; 
 &lt;li&gt;Goutham Veeramachaneni's blog post "&lt;a href="https://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/"&gt;Loki: Prometheus-inspired, open source logging for cloud natives&lt;/a&gt;" on details of the Loki architecture.&lt;/li&gt; 
 &lt;li&gt;David Kaltschmidt's blog post "&lt;a href="https://grafana.com/blog/2019/01/02/closer-look-at-grafanas-user-interface-for-loki/"&gt;Closer look at Grafana's user interface for Loki&lt;/a&gt;" on the ideas that went into the logging user interface.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Refer to &lt;a href="https://raw.githubusercontent.com/grafana/loki/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Building from source&lt;/h3&gt; 
&lt;p&gt;Loki can be run in a single host, no-dependencies mode using the following commands.&lt;/p&gt; 
&lt;p&gt;You need an up-to-date version of &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt;, we recommend using the version found in our &lt;a href="https://github.com/grafana/loki/raw/main/Makefile"&gt;Makefile&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Checkout source code
$ git clone https://github.com/grafana/loki
$ cd loki

# Build binary
$ go build ./cmd/loki

# Run executable
$ ./loki -config.file=./cmd/loki/loki-local-config.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, on Unix systems you can use &lt;code&gt;make&lt;/code&gt; to build the binary, which adds additional arguments to the &lt;code&gt;go build&lt;/code&gt; command.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build binary
$ make loki

# Run executable
$ ./cmd/loki/loki -config.file=./cmd/loki/loki-local-config.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build Promtail on non-Linux platforms, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ go build ./clients/cmd/promtail
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On Linux, Promtail requires the systemd headers to be installed if Journal support is enabled. To enable Journal support the go build tag flag &lt;code&gt;promtail_journal_enabled&lt;/code&gt; should be passed&lt;/p&gt; 
&lt;p&gt;With Journal support on Ubuntu, run with the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ sudo apt install -y libsystemd-dev
$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With Journal support on CentOS, run with the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ sudo yum install -y systemd-devel
$ go build --tags=promtail_journal_enabled ./clients/cmd/promtail
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Otherwise, to build Promtail without Journal support, run &lt;code&gt;go build&lt;/code&gt; with CGO disabled:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ CGO_ENABLED=0 go build ./clients/cmd/promtail
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://raw.githubusercontent.com/grafana/loki/main/ADOPTERS.md"&gt;ADOPTERS.md&lt;/a&gt; for some of the organizations using Loki today. If you would like to add your organization to the list, please open a PR to add it to the list.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Grafana Loki is distributed under &lt;a href="https://raw.githubusercontent.com/grafana/loki/main/LICENSE"&gt;AGPL-3.0-only&lt;/a&gt;. For Apache-2.0 exceptions, see &lt;a href="https://raw.githubusercontent.com/grafana/loki/main/LICENSING.md"&gt;LICENSING.md&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>memodb-io/Acontext</title>
      <link>https://github.com/memodb-io/Acontext</link>
      <description>&lt;p&gt;Data platform for context engineering. Context data platform that stores, observes and learns. Join the community‚ù§Ô∏è: https://discord.acontext.io&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://discord.acontext.io"&gt; &lt;img alt="Show Acontext header banner" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/Acontext-header-banner.png" /&gt; &lt;/a&gt; 
 &lt;p&gt; &lt;/p&gt;
 &lt;h4&gt;Context Data Platform for Building Cloud-native AI Agents&lt;/h4&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://pypi.org/project/acontext/"&gt;&lt;img src="https://img.shields.io/pypi/v/acontext.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@acontext/acontext"&gt;&lt;img src="https://img.shields.io/npm/v/@acontext/acontext.svg?logo=npm&amp;amp;logoColor=fff&amp;amp;style=flat&amp;amp;labelColor=2C2C2C&amp;amp;color=28CF8D" /&gt;&lt;/a&gt; &lt;a href="https://github.com/memodb-io/acontext/actions/workflows/core-test.yaml"&gt;&lt;img src="https://github.com/memodb-io/acontext/actions/workflows/core-test.yaml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/memodb-io/acontext/actions/workflows/api-test.yaml"&gt;&lt;img src="https://github.com/memodb-io/acontext/actions/workflows/api-test.yaml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/memodb-io/acontext/actions/workflows/cli-test.yaml"&gt;&lt;img src="https://github.com/memodb-io/acontext/actions/workflows/cli-test.yaml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://x.com/acontext_io"&gt;&lt;img src="https://img.shields.io/twitter/follow/acontext_io?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://discord.acontext.io"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?label=Acontext&amp;amp;style=flat&amp;amp;query=approximate_member_count&amp;amp;url=https%3A%2F%2Fdiscord.com%2Fapi%2Fv10%2Finvites%2FSG9xJcqVBu%3Fwith_counts%3Dtrue&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;suffix=+members&amp;amp;color=36393f&amp;amp;labelColor=5765F2" alt="Acontext Discord" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/de/README.md"&gt;Deutsch&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/es/README.md"&gt;Espa√±ol&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/fr/README.md"&gt;Fran√ßais&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/ja/README.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/ko/README.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/pt/README.md"&gt;Portugu√™s&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/ru/README.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | 
  &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/readme/zh/README.md"&gt;‰∏≠Êñá&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;em&gt;Everyone is telling you how to use their agents. But what if YOU need to build an agent for 100,000 users, how would you start?&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üì¶ Problem 1: 99% of your DB is just LLM messages.&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Poor schema design makes your most valuable data expensive and slow. Acontext handles context storage and retrieval via PG, Redis, and S3.&lt;/p&gt; 
 &lt;p&gt;ChatGPT, Gemini, Anthropic, images, audio, files... we've got you covered.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;‚è∞ Problem 2: Long-running agents are a nightmare.&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You know context engineering, but you're always writing it from scratch. Acontext comes with built-in context editing methods and a todo agent out of the box.&lt;/p&gt; 
 &lt;p&gt;Managing agent state? Piece of cake.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;üëÄ Problem 3: You can't see how your agent is doing.&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;How satisfied are your users, really? Acontext tracks tasks per session and shows you your agent's actual success rate.&lt;/p&gt; 
 &lt;p&gt;Stop obsessing over token costs, improve the agent first.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;üß† Problem 4: Your agent is hit or miss.&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Can it learn from its wins? Acontext's experience agent remembers successful runs and turns them into reusable tool-use SOPs.&lt;/p&gt; 
 &lt;p&gt;Consistency is everything.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To solve those problems at once, Acontext becomes the &lt;strong&gt;Context Data Platform&lt;/strong&gt;:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="Acontext Learning" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/acontext-components.jpg" width="100%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;Context Data Platform that Store, Observe and Learn&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;üí° Core Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Context Engineering&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.acontext.io/store/messages/multi-provider"&gt;Session&lt;/a&gt;: unified message storage for any llm, any modal.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.acontext.io/store/disk"&gt;Disk&lt;/a&gt;: save/download artifacts with file path.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://docs.acontext.io/store/editing"&gt;Context Editing&lt;/a&gt; - manage your context window in one api.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="Acontext Learning" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/acontext-context-engineering.png" width="80%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;Context Engineering in Acontext&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Observe agent tasks and user feedback&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.acontext.io/observe/agent_tasks"&gt;Task&lt;/a&gt;: collect agent's working status, progress and preferences in near real-time.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agent self-learning&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.acontext.io/learn/advance/experience-agent"&gt;Experience&lt;/a&gt;: let agent learn SOPs for each user.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;View everything in one &lt;a href="https://docs.acontext.io/observe/dashboard"&gt;dashboard&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="Dashboard" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/docs/images/dashboard/BI.png" width="80%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;Dashboard of Agent Success Rate and Other Metrics&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;üèóÔ∏è How it works?&lt;/h1&gt; 
&lt;details&gt; 
 &lt;summary&gt;click to open&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;graph TB
    subgraph "Client Layer"
        PY["pip install acontext"]
        TS["npm i @acontext/acontext"]
    end
    
    subgraph "Acontext Backend"
      subgraph " "
          API["API&amp;lt;br/&amp;gt;localhost:8029"]
          CORE["Core"]
          API --&amp;gt;|FastAPI &amp;amp; MQ| CORE
      end
      
      subgraph " "
          Infrastructure["Infrastructures"]
          PG["PostgreSQL"]
          S3["S3"]
          REDIS["Redis"]
          MQ["RabbitMQ"]
      end
    end
    
    subgraph "Dashboard"
        UI["Web Dashboard&amp;lt;br/&amp;gt;localhost:3000"]
    end
    
    PY --&amp;gt;|RESTFUL API| API
    TS --&amp;gt;|RESTFUL API| API
    UI --&amp;gt;|RESTFUL API| API
    API --&amp;gt; Infrastructure
    CORE --&amp;gt; Infrastructure

    Infrastructure --&amp;gt; PG
    Infrastructure --&amp;gt; S3
    Infrastructure --&amp;gt; REDIS
    Infrastructure --&amp;gt; MQ
    
    
    style PY fill:#3776ab,stroke:#fff,stroke-width:2px,color:#fff
    style TS fill:#3178c6,stroke:#fff,stroke-width:2px,color:#fff
    style API fill:#00add8,stroke:#fff,stroke-width:2px,color:#fff
    style CORE fill:#ffd43b,stroke:#333,stroke-width:2px,color:#333
    style UI fill:#000,stroke:#fff,stroke-width:2px,color:#fff
    style PG fill:#336791,stroke:#fff,stroke-width:2px,color:#fff
    style S3 fill:#ff9900,stroke:#fff,stroke-width:2px,color:#fff
    style REDIS fill:#dc382d,stroke:#fff,stroke-width:2px,color:#fff
    style MQ fill:#ff6600,stroke:#fff,stroke-width:2px,color:#fff
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;How They Work Together&lt;/h2&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ User ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ Your Agent ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   Session    ‚îÇ    ‚îÇ Artifact Disk ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                  ‚îÇ # if enable
                  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ         ‚îÇ Observed Tasks  ‚îÇ
                  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                  ‚îÇ # if enable
                  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ         ‚îÇ   Learn Skills  ‚îÇ
                  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      Search skills
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;Data Structures&lt;/h2&gt; 
 &lt;details&gt; 
  &lt;summary&gt;üìñ Task Structure&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-json"&gt;{
  "task_description": "Star https://github.com/memodb-io/Acontext",
  "progresses": [
    "I have navigated to Acontext repo",
    "Tried to Star but a pop-up required me to login",
    ...
  ],
  "user_preferences": [
    "user wants to use outlook email to login"
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;üìñ Skill Structure&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-json"&gt;{
    "use_when": "star a repo on github.com",
    "preferences": "use user's outlook account",
    "tool_sops": [
        {"tool_name": "goto", "action": "goto github.com"},
        {"tool_name": "click", "action": "find login button if any. login first"},
        ...
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt;üìñ Space Structure&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-txt"&gt;/
‚îî‚îÄ‚îÄ github/ (folder)
    ‚îî‚îÄ‚îÄ GTM (page)
        ‚îú‚îÄ‚îÄ find_trending_repos (sop)
        ‚îî‚îÄ‚îÄ find_contributor_emails (sop)
    ‚îî‚îÄ‚îÄ basic_ops (page)
        ‚îú‚îÄ‚îÄ create_repo (sop)
        ‚îî‚îÄ‚îÄ delete_repo (sop)
    ...
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
&lt;/details&gt; 
&lt;h1&gt;üöÄ Connect to Acontext&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to &lt;a href="https://acontext.io"&gt;Acontext.io&lt;/a&gt;, claim your free credits.&lt;/li&gt; 
 &lt;li&gt;Go through a one-click onboarding to get your API Key: &lt;code&gt;sk-ac-xxx&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="Dashboard" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/onboard.png" width="80%" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;details&gt; 
 &lt;summary&gt;üíª Self-host Acontext&lt;/summary&gt; 
 &lt;p&gt;We have an &lt;code&gt;acontext-cli&lt;/code&gt; to help you do quick proof-of-concept. Download it first in your terminal:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://install.acontext.io | sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You should have &lt;a href="https://www.docker.com/get-started/"&gt;docker&lt;/a&gt; installed and an OpenAI API Key to start an Acontext backend on your computer:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;mkdir acontext_server &amp;amp;&amp;amp; cd acontext_server
acontext docker up
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
  &lt;p&gt;Make sure your LLM has the ability to &lt;a href="https://platform.openai.com/docs/guides/function-calling"&gt;call tools&lt;/a&gt;. By default, Acontext will use &lt;code&gt;gpt-4.1&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;code&gt;acontext docker up&lt;/code&gt; will create/use &lt;code&gt;.env&lt;/code&gt; and &lt;code&gt;config.yaml&lt;/code&gt; for Acontext, and create a &lt;code&gt;db&lt;/code&gt; folder to persist data.&lt;/p&gt; 
 &lt;p&gt;Once it's done, you can access the following endpoints:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Acontext API Base URL: &lt;a href="http://localhost:8029/api/v1"&gt;http://localhost:8029/api/v1&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Acontext Dashboard: &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;üßê Use Acontext to build Agent&lt;/h1&gt; 
&lt;p&gt;Download end-to-end scripts with &lt;code&gt;acontext&lt;/code&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;acontext create my-proj --template-path "python/openai-basic"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;More examples on Python:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;python/openai-agent-basic&lt;/code&gt;: self-learning agent in openai agent sdk.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;python/agno-basic&lt;/code&gt;: self-learning agent in agno framework.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;python/openai-agent-artifacts&lt;/code&gt;: agent that can edit and download artifacts.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Typescript&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;acontext create my-proj --template-path "typescript/openai-basic"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;More examples on Typescript:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;typescript/vercel-ai-basic&lt;/code&gt;: self-learning agent in @vercel/ai-sdk&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Check our example repo for more templates: &lt;a href="https://github.com/memodb-io/Acontext-Examples"&gt;Acontext-Examples&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;We're cooking more full-stack Agent Applications! &lt;a href="https://discord.acontext.io"&gt;Tell us what you want!&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Step-by-step Quickstart&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;click to open&lt;/summary&gt; 
 &lt;p&gt;We're maintaining Python &lt;a href="https://pypi.org/project/acontext/"&gt;&lt;img src="https://img.shields.io/pypi/v/acontext.svg?sanitize=true" alt="pypi" /&gt;&lt;/a&gt; and Typescript &lt;a href="https://www.npmjs.com/package/@acontext/acontext"&gt;&lt;img src="https://img.shields.io/npm/v/@acontext/acontext.svg?logo=npm&amp;amp;logoColor=fff&amp;amp;style=flat&amp;amp;labelColor=2C2C2C&amp;amp;color=28CF8D" alt="npm" /&gt;&lt;/a&gt; SDKs. The snippets below are using Python.&lt;/p&gt; 
 &lt;h2&gt;Install SDKs&lt;/h2&gt; 
 &lt;pre&gt;&lt;code&gt;pip install acontext # for Python
npm i @acontext/acontext # for Typescript
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h2&gt;Initialize Client&lt;/h2&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import os
from acontext import AcontextClient

client = AcontextClient(
    api_key=os.getenv("ACONTEXT_API_KEY"),
)

# If you're using self-hosted Acontext:
# client = AcontextClient(
#     base_url="http://localhost:8029/api/v1",
#     api_key="sk-ac-your-root-api-bearer-token",
# )
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;a href="https://docs.acontext.io/settings/core"&gt;üìñ async client doc&lt;/a&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h2&gt;Store&lt;/h2&gt; 
 &lt;p&gt;Acontext can manage agent sessions and artifacts.&lt;/p&gt; 
 &lt;h3&gt;Save Messages &lt;a href="https://docs.acontext.io/api-reference/session/store-message-to-session"&gt;üìñ&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;Acontext offers persistent storage for message data. When you call &lt;code&gt;session.store_message&lt;/code&gt;, Acontext will persist the message and start to monitor this session:&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Code Snippet&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-python"&gt;session = client.sessions.create()

messages = [
    {"role": "user", "content": "I need to write a landing page of iPhone 15 pro max"},
    {
        "role": "assistant",
        "content": "Sure, my plan is below:\n1. Search for the latest news about iPhone 15 pro max\n2. Init Next.js project for the landing page\n3. Deploy the landing page to the website",
    }
]

# Save messages
for msg in messages:
    client.sessions.store_message(session_id=session.id, blob=msg, format="openai")
&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;a href="https://docs.acontext.io/store/messages/multi-modal"&gt;üìñ&lt;/a&gt; We also support multi-modal message storage and anthropic SDK.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;h3&gt;Load Messages &lt;a href="https://docs.acontext.io/api-reference/session/get-messages-from-session"&gt;üìñ&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;Obtain your session messages using &lt;code&gt;sessions.get_messages&lt;/code&gt;&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Code Snippet&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-python"&gt;r = client.sessions.get_messages(session.id)
new_msg = r.items

new_msg.append({"role": "user", "content": "How are you doing?"})
r = openai_client.chat.completions.create(model="gpt-4.1", messages=new_msg)
print(r.choices[0].message.content)
client.sessions.store_message(session_id=session.id, blob=r.choices[0].message)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;div align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="Session" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/docs/images/dashboard/message_viewer.png" width="100%" /&gt; 
  &lt;/picture&gt; 
  &lt;p&gt;You can view sessions in your local Dashboard&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;Artifacts &lt;a href="https://docs.acontext.io/store/disk"&gt;üìñ&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;Create a disk for your agent to store and read artifacts using file paths:&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Code Snippet&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-python"&gt;from acontext import FileUpload

disk = client.disks.create()

file = FileUpload(
    filename="todo.md",
    content=b"# Sprint Plan\n\n## Goals\n- Complete user authentication\n- Fix critical bugs"
)
artifact = client.disks.artifacts.upsert(
    disk.id,
    file=file,
    file_path="/todo/"
)


print(client.disks.artifacts.list(
    disk.id,
    path="/todo/"
))

result = client.disks.artifacts.get(
    disk.id,
    file_path="/todo/",
    filename="todo.md",
    with_public_url=True,
    with_content=True
)
print(f"‚úì File content: {result.content.raw}")
print(f"‚úì Download URL: {result.public_url}")        
&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;div align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="Artifacts" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/docs/images/dashboard/artifact_viewer.png" width="100%" /&gt; 
  &lt;/picture&gt; 
  &lt;p&gt;You can view artifacts in your local Dashboard&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h2&gt;Observe &lt;a href="https://docs.acontext.io/observe"&gt;üìñ&lt;/a&gt;&lt;/h2&gt; 
 &lt;p&gt;For every session, Acontext will &lt;strong&gt;automatically&lt;/strong&gt; launch a background agent to track the task progress and user feedback. &lt;strong&gt;It's like a background TODO agent&lt;/strong&gt;. Acontext will use it to observe your daily agent success rate.&lt;/p&gt; 
 &lt;p&gt;You can use the SDK to retrieve the current state of the agent session, for Context Engineering like Reduction and Compression.&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt;Full Script&lt;/summary&gt; 
  &lt;pre&gt;&lt;code class="language-python"&gt;from acontext import AcontextClient

# Initialize client
client = AcontextClient(
    base_url="http://localhost:8029/api/v1", api_key="sk-ac-your-root-api-bearer-token"
)

# Create a project and session
session = client.sessions.create()

# Conversation messages
messages = [
    {"role": "user", "content": "I need to write a landing page of iPhone 15 pro max"},
    {
        "role": "assistant",
        "content": "Sure, my plan is below:\n1. Search for the latest news about iPhone 15 pro max\n2. Init Next.js project for the landing page\n3. Deploy the landing page to the website",
    },
    {
        "role": "user",
        "content": "That sounds good. Let's first collect the message and report to me before any landing page coding.",
    },
    {
        "role": "assistant",
        "content": "Sure, I will first collect the message then report to you before any landing page coding.",
      	"tool_calls": [
            {
                "id": "call_001",
                "type": "function",
                "function": {
                    "name": "search_news",
                    "arguments": "{\"query\": \"iPhone news\"}"
                }
            }
        ]
    },
]

# Store messages in a loop
for msg in messages:
    client.sessions.store_message(session_id=session.id, blob=msg, format="openai")

# Wait for task extraction to complete
client.sessions.flush(session.id)

# Display extracted tasks
tasks_response = client.sessions.get_tasks(session.id)
print(tasks_response)
for task in tasks_response.items:
    print(f"\nTask #{task.order}:")
    print(f"  ID: {task.id}")
    print(f"  Title: {task.data.task_description}")
    print(f"  Status: {task.status}")

    # Show progress updates if available
    if task.data.progresses:
        print(f"  Progress updates: {len(task.data.progresses)}")
        for progress in task.data.progresses:
            print(f"    - {progress}")

    # Show user preferences if available
    if task.data.user_preferences:
        print("  User preferences:")
        for pref in task.data.user_preferences:
            print(f"    - {pref}")

&lt;/code&gt;&lt;/pre&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;flush&lt;/code&gt; is a blocking call, it will wait for the task extraction to complete. You don't need to call it in production, Acontext has a &lt;a href="https://docs.acontext.io/observe/buffer"&gt;buffer mechanism&lt;/a&gt; to ensure the task extraction is completed right on time.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;p&gt;Example Task Return:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-txt"&gt;Task #1:
  Title: Search for the latest news about iPhone 15 Pro Max and report findings to the user before any landing page coding.
  Status: success
  Progress updates: 2
    - I confirmed that the first step will be reporting before moving on to landing page development.
    - I have already collected all the iPhone 15 pro max info and reported to the user, waiting for approval for next step.
  User preferences:
    - user expects a report on latest news about iPhone 15 pro max before any coding work on the landing page.

Task #2:
  Title: Initialize a Next.js project for the iPhone 15 Pro Max landing page.
  Status: pending

Task #3:
  Title: Deploy the completed landing page to the website.
  Status: pending
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;You can view the session tasks' statuses in the Dashboard:&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="Acontext Learning" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/docs/images/dashboard/session_task_viewer.png" width="100%" /&gt; 
  &lt;/picture&gt; 
  &lt;p&gt;A Task Demo&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h2&gt;Self-learning&lt;/h2&gt; 
 &lt;p&gt;Acontext can gather a bunch of sessions and learn skills (SOPs) on how to call tools for certain tasks.&lt;/p&gt; 
 &lt;h3&gt;Learn Skills to a &lt;code&gt;Space&lt;/code&gt; &lt;a href="https://docs.acontext.io/learn/skill-space"&gt;üìñ&lt;/a&gt;&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="A Space Demo" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/acontext_dataflow.png" width="100%" /&gt; 
  &lt;/picture&gt; 
  &lt;p&gt;How self-learning works?&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;A &lt;code&gt;Space&lt;/code&gt; can store skills, and memories in a Notion-like system. You first need to connect a session to &lt;code&gt;Space&lt;/code&gt; to enable the learning process:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;# Step 1: Create a Space for skill learning
space = client.spaces.create()
print(f"Created Space: {space.id}")

# Step 2: Create a session attached to the space
session = client.sessions.create(space_id=space.id)

# ... push the agent working context
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The learning happens in the background and is not real-time (delay around 10-30s).&lt;/p&gt; 
 &lt;p&gt;What Acontext will do in the background:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;graph LR
    A[Task Completed] --&amp;gt; B[Task Extraction]
    B --&amp;gt; C{Space Connected?}
    C --&amp;gt;|Yes| D[Queue for Learning]
    C --&amp;gt;|No| E[Skip Learning]
    D --&amp;gt; F[Extract SOP]
    F --&amp;gt; G{Hard Enough?}
    G --&amp;gt;|No - Too Simple| H[Skip Learning]
    G --&amp;gt;|Yes - Complex| I[Store as Skill Block]
    I --&amp;gt; J[Available for Future Sessions]
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Eventually, SOP blocks with tool-call pattern will be saved to &lt;code&gt;Space&lt;/code&gt;. You can view every &lt;code&gt;Space&lt;/code&gt; in the Dashboard:&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;picture&gt; 
   &lt;img alt="A Space Demo" src="https://raw.githubusercontent.com/memodb-io/Acontext/main/docs/images/dashboard/skill_viewer.png" width="100%" /&gt; 
  &lt;/picture&gt; 
  &lt;p&gt;A Space Demo&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;Search Skills from a &lt;code&gt;Space&lt;/code&gt; &lt;a href="https://docs.acontext.io/learn/search-skills"&gt;üìñ&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;To search skills from a &lt;code&gt;Space&lt;/code&gt; and use them in the next session:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;result = client.spaces.experience_search(
    space_id=space.id,
    query="I need to implement authentication",
  	mode="fast"
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Acontext supports &lt;code&gt;fast&lt;/code&gt; and &lt;code&gt;agentic&lt;/code&gt; modes for search. The former uses embeddings to match skills. The latter uses an Experience Agent to explore the entire &lt;code&gt;Space&lt;/code&gt; and tries to cover every skill needed.&lt;/p&gt; 
 &lt;p&gt;The return is a list of sop blocks, which look like below:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
    "use_when": "star a github repo",
    "preferences": "use personal account. star but not fork",
    "tool_sops": [
        {"tool_name": "goto", "action": "goto the user given github repo url"},
        {"tool_name": "click", "action": "find login button if any, and start to login first"},
        ...
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h1&gt;üîç Document&lt;/h1&gt; 
&lt;p&gt;To understand what Acontext can do better, please view &lt;a href="https://docs.acontext.io/"&gt;our docs&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;‚ù§Ô∏è Stay Updated&lt;/h1&gt; 
&lt;p&gt;Star Acontext on Github to support and receive instant notifications&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/star_acontext.gif" alt="click_star" /&gt;&lt;/p&gt; 
&lt;h1&gt;ü§ù Stay Together&lt;/h1&gt; 
&lt;p&gt;Join the community for support and discussions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.acontext.io"&gt;Discuss with Builders on Acontext Discord&lt;/a&gt; üëª&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/acontext_io"&gt;Follow Acontext on X&lt;/a&gt; ùïè&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;üåü Contributing&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check our &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/ROADMAP.md"&gt;roadmap.md&lt;/a&gt; first.&lt;/li&gt; 
 &lt;li&gt;Read &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/CONTRIBUTING.md"&gt;contributing.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;üìë LICENSE&lt;/h1&gt; 
&lt;p&gt;This project is currently licensed under &lt;a href="https://raw.githubusercontent.com/memodb-io/Acontext/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;ü•á Badges&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/badge-made-with-acontext.svg?sanitize=true" alt="Made with Acontext" /&gt; &lt;img src="https://raw.githubusercontent.com/memodb-io/Acontext/main/assets/badge-made-with-acontext-dark.svg?sanitize=true" alt="Made with Acontext (dark)" /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-md"&gt;[![Made with Acontext](https://assets.memodb.io/Acontext/badge-made-with-acontext.svg)](https://acontext.io)

[![Made with Acontext](https://assets.memodb.io/Acontext/badge-made-with-acontext-dark.svg)](https://acontext.io)
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>ccfos/nightingale</title>
      <link>https://github.com/ccfos/nightingale</link>
      <description>&lt;p&gt;Nightingale is to monitoring and alerting what Grafana is to visualization.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://github.com/ccfos/nightingale"&gt; &lt;img src="https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/Nightingale_L_V.png" alt="nightingale - cloud native monitoring" width="100" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;b&gt;Open-Source Alerting Expert&lt;/b&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://flashcat.cloud/docs/"&gt; &lt;img alt="Docs" src="https://img.shields.io/badge/docs-get%20started-brightgreen" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/u/flashcatcloud"&gt; &lt;img alt="Docker pulls" src="https://img.shields.io/docker/pulls/flashcatcloud/nightingale" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ccfos/nightingale/graphs/contributors"&gt; &lt;img alt="GitHub contributors" src="https://img.shields.io/github/contributors-anon/ccfos/nightingale" /&gt;&lt;/a&gt; &lt;img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/ccfos/nightingale" /&gt; &lt;img alt="GitHub forks" src="https://img.shields.io/github/forks/ccfos/nightingale" /&gt; &lt;br /&gt;&lt;img alt="GitHub Repo issues" src="https://img.shields.io/github/issues/ccfos/nightingale" /&gt; &lt;img alt="GitHub Repo issues closed" src="https://img.shields.io/github/issues-closed/ccfos/nightingale" /&gt; &lt;img alt="GitHub latest release" src="https://img.shields.io/github/v/release/ccfos/nightingale" /&gt; &lt;img alt="License" src="https://img.shields.io/badge/license-Apache--2.0-blue" /&gt; &lt;a href="https://n9e-talk.slack.com/"&gt; &lt;img alt="GitHub contributors" src="https://img.shields.io/badge/join%20slack-%23n9e-brightgreen.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ccfos/nightingale/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/ccfos/nightingale/main/README_zh.md"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üéØ What is Nightingale&lt;/h2&gt; 
&lt;p&gt;Nightingale is an open-source monitoring project that focuses on alerting. Similar to Grafana, Nightingale also connects with various existing data sources. However, while Grafana emphasizes visualization, Nightingale places greater emphasis on the alerting engine, as well as the processing and distribution of alarms.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The Nightingale project was initially developed and open-sourced by DiDi.inc. On May 11, 2022, it was donated to the Open Source Development Committee of the China Computer Federation (CCF ODC).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://n9e.github.io/img/global/arch-bg.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;üí° How Nightingale Works&lt;/h2&gt; 
&lt;p&gt;Many users have already collected metrics and log data. In this case, you can connect your storage repositories (such as VictoriaMetrics, ElasticSearch, etc.) as data sources in Nightingale. This allows you to configure alerting rules and notification rules within Nightingale, enabling the generation and distribution of alarms.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/readme/20240221152601.png" alt="Nightingale Product Architecture" /&gt;&lt;/p&gt; 
&lt;p&gt;Nightingale itself does not provide monitoring data collection capabilities. We recommend using &lt;a href="https://github.com/flashcatcloud/categraf"&gt;Categraf&lt;/a&gt; as the collector, which integrates seamlessly with Nightingale.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/flashcatcloud/categraf"&gt;Categraf&lt;/a&gt; can collect monitoring data from operating systems, network devices, various middleware, and databases. It pushes this data to Nightingale via the &lt;code&gt;Prometheus Remote Write&lt;/code&gt; protocol. Nightingale then stores the monitoring data in a time-series database (such as Prometheus, VictoriaMetrics, etc.) and provides alerting and visualization capabilities.&lt;/p&gt; 
&lt;p&gt;For certain edge data centers with poor network connectivity to the central Nightingale server, we offer a distributed deployment mode for the alerting engine. In this mode, even if the network is disconnected, the alerting functionality remains unaffected.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/readme/multi-region-arch.png" alt="Edge Deployment Mode" /&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;In the above diagram, Data Center A has a good network with the central data center, so it uses the Nightingale process in the central data center as the alerting engine. Data Center B has a poor network with the central data center, so it deploys &lt;code&gt;n9e-edge&lt;/code&gt; as the alerting engine to handle alerting for its own data sources.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üîï Alert Noise Reduction, Escalation, and Collaboration&lt;/h2&gt; 
&lt;p&gt;Nightingale focuses on being an alerting engine, responsible for generating alarms and flexibly distributing them based on rules. It supports 20 built-in notification medias (such as phone calls, SMS, email, DingTalk, Slack, etc.).&lt;/p&gt; 
&lt;p&gt;If you have more advanced requirements, such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Want to consolidate events from multiple monitoring systems into one platform for unified noise reduction, response handling, and data analysis.&lt;/li&gt; 
 &lt;li&gt;Want to support personnel scheduling, practice on-call culture, and support alert escalation (to avoid missing alerts) and collaborative handling.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Then Nightingale is not suitable. It is recommended that you choose on-call products such as PagerDuty and FlashDuty. These products are simple and easy to use.&lt;/p&gt; 
&lt;h2&gt;üó®Ô∏è Communication Channels&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Report Bugs:&lt;/strong&gt; It is highly recommended to submit issues via the &lt;a href="https://github.com/ccfos/nightingale/issues/new?assignees=&amp;amp;labels=kind%2Fbug&amp;amp;projects=&amp;amp;template=bug_report.yml"&gt;Nightingale GitHub Issue tracker&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation:&lt;/strong&gt; For more information, we recommend thoroughly browsing the &lt;a href="https://n9e.github.io/"&gt;Nightingale Documentation Site&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîë Key Features&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/readme/alerting-rules-en.png" alt="Nightingale Alerting rules" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nightingale supports alerting rules, mute rules, subscription rules, and notification rules. It natively supports 20 types of notification media and allows customization of message templates.&lt;/li&gt; 
 &lt;li&gt;It supports event pipelines for Pipeline processing of alarms, facilitating automated integration with in-house systems. For example, it can append metadata to alarms or perform relabeling on events.&lt;/li&gt; 
 &lt;li&gt;It introduces the concept of business groups and a permission system to manage various rules in a categorized manner.&lt;/li&gt; 
 &lt;li&gt;Many databases and middleware come with built-in alert rules that can be directly imported and used. It also supports direct import of Prometheus alerting rules.&lt;/li&gt; 
 &lt;li&gt;It supports alerting self-healing, which automatically triggers a script to execute predefined logic after an alarm is generated‚Äîsuch as cleaning up disk space or capturing the current system state.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/readme/active-events-en.png" alt="Nightingale Alarm Dashboard" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nightingale archives historical alarms and supports multi-dimensional query and statistics.&lt;/li&gt; 
 &lt;li&gt;It supports flexible aggregation grouping, allowing a clear view of the distribution of alarms across the company.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/readme/integration-components-en.png" alt="Nightingale Integration Center" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nightingale has built-in metric descriptions, dashboards, and alerting rules for common operating systems, middleware, and databases, which are contributed by the community with varying quality.&lt;/li&gt; 
 &lt;li&gt;It directly receives data via multiple protocols such as Remote Write, OpenTSDB, Datadog, and Falcon, integrates with various Agents.&lt;/li&gt; 
 &lt;li&gt;It supports data sources like Prometheus, ElasticSearch, Loki, ClickHouse, MySQL, Postgres, allowing alerting based on data from these sources.&lt;/li&gt; 
 &lt;li&gt;Nightingale can be easily embedded into internal enterprise systems (e.g. Grafana, CMDB), and even supports configuring menu visibility for these embedded systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/readme/dashboard-en.png" alt="Nightingale dashboards" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Nightingale supports dashboard functionality, including common chart types, and comes with pre-built dashboards. The image above is a screenshot of one of these dashboards.&lt;/li&gt; 
 &lt;li&gt;If you are already accustomed to Grafana, it is recommended to continue using Grafana for visualization, as Grafana has deeper expertise in this area.&lt;/li&gt; 
 &lt;li&gt;For machine-related monitoring data collected by Categraf, it is advisable to use Nightingale's built-in dashboards for viewing. This is because Categraf's metric naming follows Telegraf's convention, which differs from that of Node Exporter.&lt;/li&gt; 
 &lt;li&gt;Due to Nightingale's concept of business groups (where machines can belong to different groups), there may be scenarios where you only want to view machines within the current business group on the dashboard. Thus, Nightingale's dashboards can be linked with business groups for interactive filtering.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåü Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#ccfos/nightingale&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=ccfos/nightingale&amp;amp;type=Date" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üî• Users&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ccfos/nightingale/main/doc/img/readme/logos.png" alt="User Logos" /&gt;&lt;/p&gt; 
&lt;h2&gt;ü§ù Community Co-Building&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚ùáÔ∏è Please read the &lt;a href="https://raw.githubusercontent.com/ccfos/nightingale/main/doc/community-governance.md"&gt;Nightingale Open Source Project and Community Governance Draft&lt;/a&gt;. We sincerely welcome every user, developer, company, and organization to use Nightingale, actively report bugs, submit feature requests, share best practices, and help build a professional and active open-source community.&lt;/li&gt; 
 &lt;li&gt;‚ù§Ô∏è Nightingale Contributors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;a href="https://github.com/ccfos/nightingale/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=ccfos/nightingale" /&gt; &lt;/a&gt; 
&lt;h2&gt;üìú License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ccfos/nightingale/raw/main/LICENSE"&gt;Apache License V2.0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>fatedier/frp</title>
      <link>https://github.com/fatedier/frp</link>
      <description>&lt;p&gt;A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;frp&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://circleci.com/gh/fatedier/frp"&gt;&lt;img src="https://circleci.com/gh/fatedier/frp.svg?style=shield" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/fatedier/frp/releases"&gt;&lt;img src="https://img.shields.io/github/tag/fatedier/frp.svg?label=release" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/fatedier/frp"&gt;&lt;img src="https://goreportcard.com/badge/github.com/fatedier/frp" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://somsubhra.github.io/github-release-stats/?username=fatedier&amp;amp;repository=frp"&gt;&lt;img src="https://img.shields.io/github/downloads/fatedier/frp/total.svg?logo=github" alt="GitHub Releases Stats" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/README.md"&gt;README&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/README_zh.md"&gt;‰∏≠ÊñáÊñáÊ°£&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;frp is an open source project with its ongoing development made possible entirely by the support of our awesome sponsors. If you'd like to join them, please consider &lt;a href="https://github.com/sponsors/fatedier"&gt;sponsoring frp's development&lt;/a&gt;.&lt;/p&gt; 
&lt;h3 align="center"&gt;Gold Sponsors&lt;/h3&gt; 
&lt;!--gold sponsors start--&gt; 
&lt;p align="center"&gt; &lt;a href="https://go.warp.dev/frp" target="_blank"&gt; &lt;img width="360px" src="https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-01.png" /&gt; &lt;br /&gt; &lt;b&gt;Warp, built for collaborating with AI Agents&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;Available for macOS, Linux and Windows&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://jb.gg/frp" target="_blank"&gt; &lt;img width="420px" src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_jetbrains.jpg" /&gt; &lt;br /&gt; &lt;b&gt;The complete IDE crafted for professional Go developers&lt;/b&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/beclab/Olares" target="_blank"&gt; &lt;img width="420px" src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_olares.jpeg" /&gt; &lt;br /&gt; &lt;b&gt;The sovereign cloud that puts you in control&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;An open source, self-hosted alternative to public clouds, built for data ownership and privacy&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h2&gt;Recall.ai - API for meeting recordings&lt;/h2&gt; 
 &lt;p&gt;If you're looking for a meeting recording API, consider checking out &lt;a href="https://www.recall.ai/?utm_source=github&amp;amp;utm_medium=sponsorship&amp;amp;utm_campaign=fatedier-frp"&gt;Recall.ai&lt;/a&gt;,&lt;/p&gt; 
 &lt;p&gt;an API that records Zoom, Google Meet, Microsoft Teams, in-person meetings, and more.&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://requestly.com/?utm_source=github&amp;amp;utm_medium=partnered&amp;amp;utm_campaign=frp" target="_blank"&gt; &lt;img width="480px" src="https://github.com/user-attachments/assets/24670320-997d-4d62-9bca-955c59fe883d" /&gt; &lt;br /&gt; &lt;b&gt;Requestly - Free &amp;amp; Open-Source alternative to Postman&lt;/b&gt; &lt;br /&gt; &lt;sub&gt;All-in-one platform to Test, Mock and Intercept APIs.&lt;/sub&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;!--gold sponsors end--&gt; 
&lt;h2&gt;What is frp?&lt;/h2&gt; 
&lt;p&gt;frp is a fast reverse proxy that allows you to expose a local server located behind a NAT or firewall to the Internet. It currently supports &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;, as well as &lt;strong&gt;HTTP&lt;/strong&gt; and &lt;strong&gt;HTTPS&lt;/strong&gt; protocols, enabling requests to be forwarded to internal services via domain name.&lt;/p&gt; 
&lt;p&gt;frp also offers a P2P connect mode.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;!-- vim-markdown-toc GFM --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#development-status"&gt;Development Status&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#about-v2"&gt;About V2&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#example-usage"&gt;Example Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#access-your-computer-in-a-lan-network-via-ssh"&gt;Access your computer in a LAN network via SSH&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#multiple-ssh-services-sharing-the-same-port"&gt;Multiple SSH services sharing the same port&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#accessing-internal-web-services-with-custom-domains-in-lan"&gt;Accessing Internal Web Services with Custom Domains in LAN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#forward-dns-query-requests"&gt;Forward DNS query requests&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#forward-unix-domain-socket"&gt;Forward Unix Domain Socket&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#expose-a-simple-http-file-server"&gt;Expose a simple HTTP file server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#enable-https-for-a-local-https-service"&gt;Enable HTTPS for a local HTTP(S) service&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#expose-your-service-privately"&gt;Expose your service privately&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#p2p-mode"&gt;P2P Mode&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#configuration-files"&gt;Configuration Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#using-environment-variables"&gt;Using Environment Variables&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#split-configures-into-different-files"&gt;Split Configures Into Different Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#server-dashboard"&gt;Server Dashboard&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#client-admin-ui"&gt;Client Admin UI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#monitor"&gt;Monitor&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#prometheus"&gt;Prometheus&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#authenticating-the-client"&gt;Authenticating the Client&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#token-authentication"&gt;Token Authentication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#oidc-authentication"&gt;OIDC Authentication&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#encryption-and-compression"&gt;Encryption and Compression&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tls"&gt;TLS&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#hot-reloading-frpc-configuration"&gt;Hot-Reloading frpc configuration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#get-proxy-status-from-client"&gt;Get proxy status from client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#only-allowing-certain-ports-on-the-server"&gt;Only allowing certain ports on the server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#port-reuse"&gt;Port Reuse&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#bandwidth-limit"&gt;Bandwidth Limit&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#for-each-proxy"&gt;For Each Proxy&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tcp-stream-multiplexing"&gt;TCP Stream Multiplexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#support-kcp-protocol"&gt;Support KCP Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#support-quic-protocol"&gt;Support QUIC Protocol&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#connection-pooling"&gt;Connection Pooling&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#load-balancing"&gt;Load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#service-health-check"&gt;Service Health Check&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#rewriting-the-http-host-header"&gt;Rewriting the HTTP Host Header&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#setting-other-http-headers"&gt;Setting other HTTP Headers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#get-real-ip"&gt;Get Real IP&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#http-x-forwarded-for"&gt;HTTP X-Forwarded-For&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#proxy-protocol"&gt;Proxy Protocol&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#require-http-basic-auth-password-for-web-services"&gt;Require HTTP Basic Auth (Password) for Web Services&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#custom-subdomain-names"&gt;Custom Subdomain Names&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#url-routing"&gt;URL Routing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#tcp-port-multiplexing"&gt;TCP Port Multiplexing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#connecting-to-frps-via-proxy"&gt;Connecting to frps via PROXY&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#port-range-mapping"&gt;Port range mapping&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#client-plugins"&gt;Client Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#server-manage-plugins"&gt;Server Manage Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#ssh-tunnel-gateway"&gt;SSH Tunnel Gateway&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#virtual-network-virtualnet"&gt;Virtual Network (VirtualNet)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#feature-gates"&gt;Feature Gates&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#available-feature-gates"&gt;Available Feature Gates&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#enabling-feature-gates"&gt;Enabling Feature Gates&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#feature-lifecycle"&gt;Feature Lifecycle&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#related-projects"&gt;Related Projects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#donation"&gt;Donation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#github-sponsors"&gt;GitHub Sponsors&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#paypal"&gt;PayPal&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- vim-markdown-toc --&gt; 
&lt;h2&gt;Development Status&lt;/h2&gt; 
&lt;p&gt;frp is currently under development. You can try the latest release version in the &lt;code&gt;master&lt;/code&gt; branch, or use the &lt;code&gt;dev&lt;/code&gt; branch to access the version currently in development.&lt;/p&gt; 
&lt;p&gt;We are currently working on version 2 and attempting to perform some code refactoring and improvements. However, please note that it will not be compatible with version 1.&lt;/p&gt; 
&lt;p&gt;We will transition from version 0 to version 1 at the appropriate time and will only accept bug fixes and improvements, rather than big feature requests.&lt;/p&gt; 
&lt;h3&gt;About V2&lt;/h3&gt; 
&lt;p&gt;The complexity and difficulty of the v2 version are much higher than anticipated. I can only work on its development during fragmented time periods, and the constant interruptions disrupt productivity significantly. Given this situation, we will continue to optimize and iterate on the current version until we have more free time to proceed with the major version overhaul.&lt;/p&gt; 
&lt;p&gt;The concept behind v2 is based on my years of experience and reflection in the cloud-native domain, particularly in K8s and ServiceMesh. Its core is a modernized four-layer and seven-layer proxy, similar to envoy. This proxy itself is highly scalable, not only capable of implementing the functionality of intranet penetration but also applicable to various other domains. Building upon this highly scalable core, we aim to implement all the capabilities of frp v1 while also addressing the functionalities that were previously unachievable or difficult to implement in an elegant manner. Furthermore, we will maintain efficient development and iteration capabilities.&lt;/p&gt; 
&lt;p&gt;In addition, I envision frp itself becoming a highly extensible system and platform, similar to how we can provide a range of extension capabilities based on K8s. In K8s, we can customize development according to enterprise needs, utilizing features such as CRD, controller mode, webhook, CSI, and CNI. In frp v1, we introduced the concept of server plugins, which implemented some basic extensibility. However, it relies on a simple HTTP protocol and requires users to start independent processes and manage them on their own. This approach is far from flexible and convenient, and real-world demands vary greatly. It is unrealistic to expect a non-profit open-source project maintained by a few individuals to meet everyone's needs.&lt;/p&gt; 
&lt;p&gt;Finally, we acknowledge that the current design of modules such as configuration management, permission verification, certificate management, and API management is not modern enough. While we may carry out some optimizations in the v1 version, ensuring compatibility remains a challenging issue that requires a considerable amount of effort to address.&lt;/p&gt; 
&lt;p&gt;We sincerely appreciate your support for frp.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/architecture.png" alt="architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Example Usage&lt;/h2&gt; 
&lt;p&gt;To begin, download the latest program for your operating system and architecture from the &lt;a href="https://github.com/fatedier/frp/releases"&gt;Release&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;Next, place the &lt;code&gt;frps&lt;/code&gt; binary and server configuration file on Server A, which has a public IP address.&lt;/p&gt; 
&lt;p&gt;Finally, place the &lt;code&gt;frpc&lt;/code&gt; binary and client configuration file on Server B, which is located on a LAN that cannot be directly accessed from the public internet.&lt;/p&gt; 
&lt;p&gt;Some antiviruses improperly mark frpc as malware and delete it. This is due to frp being a networking tool capable of creating reverse proxies. Antiviruses sometimes flag reverse proxies due to their ability to bypass firewall port restrictions. If you are using antivirus, then you may need to whitelist/exclude frpc in your antivirus settings to avoid accidental quarantine/deletion. See &lt;a href="https://github.com/fatedier/frp/issues/3637"&gt;issue 3637&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Access your computer in a LAN network via SSH&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt; on server A by setting the &lt;code&gt;bindPort&lt;/code&gt; for frp clients to connect to:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt; on server A:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; on server B and set the &lt;code&gt;serverAddr&lt;/code&gt; field to the public IP address of your frps server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the &lt;code&gt;localPort&lt;/code&gt; (listened on the client) and &lt;code&gt;remotePort&lt;/code&gt; (exposed on the server) are used for traffic going in and out of the frp system, while the &lt;code&gt;serverPort&lt;/code&gt; is used for communication between frps and frpc.&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on server B:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;To access server B from another machine through server A via SSH (assuming the username is &lt;code&gt;test&lt;/code&gt;), use the following command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 test@x.x.x.x&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Multiple SSH services sharing the same port&lt;/h3&gt; 
&lt;p&gt;This example implements multiple SSH services exposed through the same port using a proxy of type tcpmux. Similarly, as long as the client supports the HTTP Connect proxy connection method, port reuse can be achieved in this way.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Deploy frps on a machine with a public IP and modify the frps.toml file. Here is a simplified configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;bindPort = 7000
tcpmuxHTTPConnectPort = 5002
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Deploy frpc on the internal machine A with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh1"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["machine-a.example.com"]
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Deploy another frpc on the internal machine B with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "ssh2"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["machine-b.example.com"]
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;To access internal machine A using SSH ProxyCommand, assuming the username is "test":&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -o 'proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002' test@machine-a.example.com&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;To access internal machine B, the only difference is the domain name, assuming the username is "test":&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -o 'proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002' test@machine-b.example.com&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Accessing Internal Web Services with Custom Domains in LAN&lt;/h3&gt; 
&lt;p&gt;Sometimes we need to expose a local web service behind a NAT network to others for testing purposes with our own domain name.&lt;/p&gt; 
&lt;p&gt;Unfortunately, we cannot resolve a domain name to a local IP. However, we can use frp to expose an HTTP(S) service.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt; and set the HTTP port for vhost to 8080:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
vhostHTTPPort = 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to configure an https proxy, you need to set up the &lt;code&gt;vhostHTTPSPort&lt;/code&gt;.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; and set &lt;code&gt;serverAddr&lt;/code&gt; to the IP address of the remote frps server. Specify the &lt;code&gt;localPort&lt;/code&gt; of your web service:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["www.example.com"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt; &lt;p&gt;Map the A record of &lt;code&gt;www.example.com&lt;/code&gt; to either the public IP of the remote frps server or a CNAME record pointing to your original domain.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Visit your local web service using url &lt;code&gt;http://www.example.com:8080&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Forward DNS query requests&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Modify &lt;code&gt;frps.toml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start &lt;code&gt;frps&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frps -c ./frps.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Modify &lt;code&gt;frpc.toml&lt;/code&gt; and set &lt;code&gt;serverAddr&lt;/code&gt; to the IP address of the remote frps server. Forward DNS query requests to the Google Public DNS server &lt;code&gt;8.8.8.8:53&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "dns"
type = "udp"
localIP = "8.8.8.8"
localPort = 53
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Start frpc:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;./frpc -c ./frpc.toml&lt;/code&gt;&lt;/p&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Test DNS resolution using the &lt;code&gt;dig&lt;/code&gt; command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;dig @x.x.x.x -p 6000 www.google.com&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Forward Unix Domain Socket&lt;/h3&gt; 
&lt;p&gt;Expose a Unix domain socket (e.g. the Docker daemon socket) as TCP.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; as above.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "unix_domain_socket"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "unix_domain_socket"
unixPath = "/var/run/docker.sock"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Test the configuration by getting the docker version using &lt;code&gt;curl&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;curl http://x.x.x.x:6000/version&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Expose a simple HTTP file server&lt;/h3&gt; 
&lt;p&gt;Expose a simple HTTP file server to access files stored in the LAN from the public Internet.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; as described above, then:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "test_static_file"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "static_file"
localPath = "/tmp/files"
stripPrefix = "static"
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Visit &lt;code&gt;http://x.x.x.x:6000/static/&lt;/code&gt; from your browser and specify correct username and password to view files in &lt;code&gt;/tmp/files&lt;/code&gt; on the &lt;code&gt;frpc&lt;/code&gt; machine.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Enable HTTPS for a local HTTP(S) service&lt;/h3&gt; 
&lt;p&gt;You may substitute &lt;code&gt;https2https&lt;/code&gt; for the plugin, and point the &lt;code&gt;localAddr&lt;/code&gt; to a HTTPS endpoint.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; with the following configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "test_https2http"
type = "https"
customDomains = ["test.example.com"]

[proxies.plugin]
type = "https2http"
localAddr = "127.0.0.1:80"
crtPath = "./server.crt"
keyPath = "./server.key"
hostHeaderRewrite = "127.0.0.1"
requestHeaders.set.x-from-where = "frp"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Visit &lt;code&gt;https://test.example.com&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Expose your service privately&lt;/h3&gt; 
&lt;p&gt;To mitigate risks associated with exposing certain services directly to the public network, STCP (Secret TCP) mode requires a preshared key to be used for access to the service from other clients.&lt;/p&gt; 
&lt;p&gt;Configure &lt;code&gt;frps&lt;/code&gt; same as above.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on machine B with the following config. This example is for exposing the SSH service (port 22), and note the &lt;code&gt;secretKey&lt;/code&gt; field for the preshared key, and that the &lt;code&gt;remotePort&lt;/code&gt; field is removed here:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "secret_ssh"
type = "stcp"
secretKey = "abcdefg"
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start another &lt;code&gt;frpc&lt;/code&gt; (typically on another machine C) with the following config to access the SSH service with a security key (&lt;code&gt;secretKey&lt;/code&gt; field):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[visitors]]
name = "secret_ssh_visitor"
type = "stcp"
serverName = "secret_ssh"
secretKey = "abcdefg"
bindAddr = "127.0.0.1"
bindPort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;On machine C, connect to SSH on machine B, using this command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 127.0.0.1&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;P2P Mode&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;xtcp&lt;/strong&gt; is designed to transmit large amounts of data directly between clients. A frps server is still needed, as P2P here only refers to the actual data transmission.&lt;/p&gt; 
&lt;p&gt;Note that it may not work with all types of NAT devices. You might want to fallback to stcp if xtcp doesn't work.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Start &lt;code&gt;frpc&lt;/code&gt; on machine B, and expose the SSH port. Note that the &lt;code&gt;remotePort&lt;/code&gt; field is removed:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
# set up a new stun server if the default one is not available.
# natHoleStunServer = "xxx"

[[proxies]]
name = "p2p_ssh"
type = "xtcp"
secretKey = "abcdefg"
localIP = "127.0.0.1"
localPort = 22
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Start another &lt;code&gt;frpc&lt;/code&gt; (typically on another machine C) with the configuration to connect to SSH using P2P mode:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
# set up a new stun server if the default one is not available.
# natHoleStunServer = "xxx"

[[visitors]]
name = "p2p_ssh_visitor"
type = "xtcp"
serverName = "p2p_ssh"
secretKey = "abcdefg"
bindAddr = "127.0.0.1"
bindPort = 6000
# when automatic tunnel persistence is required, set it to true
keepTunnelOpen = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;On machine C, connect to SSH on machine B, using this command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;ssh -oPort=6000 127.0.0.1&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;Since v0.52.0, we support TOML, YAML, and JSON for configuration. Please note that INI is deprecated and will be removed in future releases. New features will only be available in TOML, YAML, or JSON. Users wanting these new features should switch their configuration format accordingly.&lt;/p&gt; 
&lt;p&gt;Read the full example configuration files to find out even more features not described here.&lt;/p&gt; 
&lt;p&gt;Examples use TOML format, but you can still use YAML or JSON.&lt;/p&gt; 
&lt;p&gt;These configuration files is for reference only. Please do not use this configuration directly to run the program as it may have various issues.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/conf/frps_full_example.toml"&gt;Full configuration file for frps (Server)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/conf/frpc_full_example.toml"&gt;Full configuration file for frpc (Client)&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Using Environment Variables&lt;/h3&gt; 
&lt;p&gt;Environment variables can be referenced in the configuration file, using Go's standard format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "{{ .Envs.FRP_SERVER_ADDR }}"
serverPort = 7000

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = {{ .Envs.FRP_SSH_REMOTE_PORT }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With the config above, variables can be passed into &lt;code&gt;frpc&lt;/code&gt; program like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export FRP_SERVER_ADDR=x.x.x.x
export FRP_SSH_REMOTE_PORT=6000
./frpc -c ./frpc.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;frpc&lt;/code&gt; will render configuration file template using OS environment variables. Remember to prefix your reference with &lt;code&gt;.Envs&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Split Configures Into Different Files&lt;/h3&gt; 
&lt;p&gt;You can split multiple proxy configs into different files and include them in the main file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
includes = ["./confd/*.toml"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# ./confd/test.toml

[[proxies]]
name = "ssh"
type = "tcp"
localIP = "127.0.0.1"
localPort = 22
remotePort = 6000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Server Dashboard&lt;/h3&gt; 
&lt;p&gt;Check frp's status and proxies' statistics information by Dashboard.&lt;/p&gt; 
&lt;p&gt;Configure a port for dashboard to enable this feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# The default value is 127.0.0.1. Change it to 0.0.0.0 when you want to access it from a public network.
webServer.addr = "0.0.0.0"
webServer.port = 7500
# dashboard's username and password are both optional
webServer.user = "admin"
webServer.password = "admin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://[serverAddr]:7500&lt;/code&gt; to see the dashboard, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, you can use HTTPS port by using your domains wildcard or normal SSL certificate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;webServer.port = 7500
# dashboard's username and password are both optional
webServer.user = "admin"
webServer.password = "admin"
webServer.tls.certFile = "server.crt"
webServer.tls.keyFile = "server.key"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;https://[serverAddr]:7500&lt;/code&gt; to see the dashboard in secure HTTPS connection, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/dashboard.png" alt="dashboard" /&gt;&lt;/p&gt; 
&lt;h3&gt;Client Admin UI&lt;/h3&gt; 
&lt;p&gt;The Client Admin UI helps you check and manage frpc's configuration.&lt;/p&gt; 
&lt;p&gt;Configure an address for admin UI to enable this feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;webServer.addr = "127.0.0.1"
webServer.port = 7400
webServer.user = "admin"
webServer.password = "admin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then visit &lt;code&gt;http://127.0.0.1:7400&lt;/code&gt; to see admin UI, with username and password both being &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Monitor&lt;/h3&gt; 
&lt;p&gt;When web server is enabled, frps will save monitor data in cache for 7 days. It will be cleared after process restart.&lt;/p&gt; 
&lt;p&gt;Prometheus is also supported.&lt;/p&gt; 
&lt;h4&gt;Prometheus&lt;/h4&gt; 
&lt;p&gt;Enable dashboard first, then configure &lt;code&gt;enablePrometheus = true&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;http://{dashboard_addr}/metrics&lt;/code&gt; will provide prometheus monitor data.&lt;/p&gt; 
&lt;h3&gt;Authenticating the Client&lt;/h3&gt; 
&lt;p&gt;There are 2 authentication methods to authenticate frpc with frps.&lt;/p&gt; 
&lt;p&gt;You can decide which one to use by configuring &lt;code&gt;auth.method&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt;, the default one is token.&lt;/p&gt; 
&lt;p&gt;Configuring &lt;code&gt;auth.additionalScopes = ["HeartBeats"]&lt;/code&gt; will use the configured authentication method to add and validate authentication on every heartbeat between frpc and frps.&lt;/p&gt; 
&lt;p&gt;Configuring &lt;code&gt;auth.additionalScopes = ["NewWorkConns"]&lt;/code&gt; will do the same for every new work connection between frpc and frps.&lt;/p&gt; 
&lt;h4&gt;Token Authentication&lt;/h4&gt; 
&lt;p&gt;When specifying &lt;code&gt;auth.method = "token"&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; - token based authentication will be used.&lt;/p&gt; 
&lt;p&gt;Make sure to specify the same &lt;code&gt;auth.token&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt; and &lt;code&gt;frpc.toml&lt;/code&gt; for frpc to pass frps validation&lt;/p&gt; 
&lt;h5&gt;Token Source&lt;/h5&gt; 
&lt;p&gt;frp supports reading authentication tokens from external sources using the &lt;code&gt;tokenSource&lt;/code&gt; configuration. Currently, file-based token source is supported.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;File-based token source:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
auth.method = "token"
auth.tokenSource.type = "file"
auth.tokenSource.file.path = "/path/to/token/file"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The token will be read from the specified file at startup. This is useful for scenarios where tokens are managed by external systems or need to be kept separate from configuration files for security reasons.&lt;/p&gt; 
&lt;h4&gt;OIDC Authentication&lt;/h4&gt; 
&lt;p&gt;When specifying &lt;code&gt;auth.method = "oidc"&lt;/code&gt; in &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; - OIDC based authentication will be used.&lt;/p&gt; 
&lt;p&gt;OIDC stands for OpenID Connect, and the flow used is called &lt;a href="https://tools.ietf.org/html/rfc6749#section-4.4"&gt;Client Credentials Grant&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To use this authentication type - configure &lt;code&gt;frpc.toml&lt;/code&gt; and &lt;code&gt;frps.toml&lt;/code&gt; as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
auth.method = "oidc"
auth.oidc.issuer = "https://example-oidc-issuer.com/"
auth.oidc.audience = "https://oidc-audience.com/.default"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
auth.method = "oidc"
auth.oidc.clientID = "98692467-37de-409a-9fac-bb2585826f18" # Replace with OIDC client ID
auth.oidc.clientSecret = "oidc_secret"
auth.oidc.audience = "https://oidc-audience.com/.default"
auth.oidc.tokenEndpointURL = "https://example-oidc-endpoint.com/oauth2/v2.0/token"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Encryption and Compression&lt;/h3&gt; 
&lt;p&gt;The features are off by default. You can turn on encryption and/or compression:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "ssh"
type = "tcp"
localPort = 22
remotePort = 6000
transport.useEncryption = true
transport.useCompression = true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;TLS&lt;/h4&gt; 
&lt;p&gt;Since v0.50.0, the default value of &lt;code&gt;transport.tls.enable&lt;/code&gt; and &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; has been changed to true, and tls is enabled by default.&lt;/p&gt; 
&lt;p&gt;For port multiplexing, frp sends a first byte &lt;code&gt;0x17&lt;/code&gt; to dial a TLS connection. This only takes effect when you set &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; to false.&lt;/p&gt; 
&lt;p&gt;To &lt;strong&gt;enforce&lt;/strong&gt; &lt;code&gt;frps&lt;/code&gt; to only accept TLS connections - configure &lt;code&gt;transport.tls.force = true&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt;. &lt;strong&gt;This is optional.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;frpc&lt;/code&gt; TLS settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;transport.tls.enable = true
transport.tls.certFile = "certificate.crt"
transport.tls.keyFile = "certificate.key"
transport.tls.trustedCaFile = "ca.crt"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;frps&lt;/code&gt; TLS settings:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;transport.tls.force = true
transport.tls.certFile = "certificate.crt"
transport.tls.keyFile = "certificate.key"
transport.tls.trustedCaFile = "ca.crt"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You will need &lt;strong&gt;a root CA cert&lt;/strong&gt; and &lt;strong&gt;at least one SSL/TLS certificate&lt;/strong&gt;. It &lt;strong&gt;can&lt;/strong&gt; be self-signed or regular (such as Let's Encrypt or another SSL/TLS certificate provider).&lt;/p&gt; 
&lt;p&gt;If you using &lt;code&gt;frp&lt;/code&gt; via IP address and not hostname, make sure to set the appropriate IP address in the Subject Alternative Name (SAN) area when generating SSL/TLS Certificates.&lt;/p&gt; 
&lt;p&gt;Given an example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prepare openssl config file. It exists at &lt;code&gt;/etc/pki/tls/openssl.cnf&lt;/code&gt; in Linux System and &lt;code&gt;/System/Library/OpenSSL/openssl.cnf&lt;/code&gt; in MacOS, and you can copy it to current path, like &lt;code&gt;cp /etc/pki/tls/openssl.cnf ./my-openssl.cnf&lt;/code&gt;. If not, you can build it by yourself, like:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;cat &amp;gt; my-openssl.cnf &amp;lt;&amp;lt; EOF
[ ca ]
default_ca = CA_default
[ CA_default ]
x509_extensions = usr_cert
[ req ]
default_bits        = 2048
default_md          = sha256
default_keyfile     = privkey.pem
distinguished_name  = req_distinguished_name
attributes          = req_attributes
x509_extensions     = v3_ca
string_mask         = utf8only
[ req_distinguished_name ]
[ req_attributes ]
[ usr_cert ]
basicConstraints       = CA:FALSE
nsComment              = "OpenSSL Generated Certificate"
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid,issuer
[ v3_ca ]
subjectKeyIdentifier   = hash
authorityKeyIdentifier = keyid:always,issuer
basicConstraints       = CA:true
EOF
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build ca certificates:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out ca.key 2048
openssl req -x509 -new -nodes -key ca.key -subj "/CN=example.ca.com" -days 5000 -out ca.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build frps certificates:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out server.key 2048

openssl req -new -sha256 -key server.key \
    -subj "/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=server.com" \
    -reqexts SAN \
    -config &amp;lt;(cat my-openssl.cnf &amp;lt;(printf "\n[SAN]\nsubjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com")) \
    -out server.csr

openssl x509 -req -days 365 -sha256 \
	-in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial \
	-extfile &amp;lt;(printf "subjectAltName=DNS:localhost,IP:127.0.0.1,DNS:example.server.com") \
	-out server.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;build frpc certificatesÔºö&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;openssl genrsa -out client.key 2048
openssl req -new -sha256 -key client.key \
    -subj "/C=XX/ST=DEFAULT/L=DEFAULT/O=DEFAULT/CN=client.com" \
    -reqexts SAN \
    -config &amp;lt;(cat my-openssl.cnf &amp;lt;(printf "\n[SAN]\nsubjectAltName=DNS:client.com,DNS:example.client.com")) \
    -out client.csr

openssl x509 -req -days 365 -sha256 \
    -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial \
	-extfile &amp;lt;(printf "subjectAltName=DNS:client.com,DNS:example.client.com") \
	-out client.crt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hot-Reloading frpc configuration&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;webServer&lt;/code&gt; fields are required for enabling HTTP API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
webServer.addr = "127.0.0.1"
webServer.port = 7400
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run command &lt;code&gt;frpc reload -c ./frpc.toml&lt;/code&gt; and wait for about 10 seconds to let &lt;code&gt;frpc&lt;/code&gt; create or update or remove proxies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note that global client parameters won't be modified except 'start'.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can run command &lt;code&gt;frpc verify -c ./frpc.toml&lt;/code&gt; before reloading to check if there are config errors.&lt;/p&gt; 
&lt;h3&gt;Get proxy status from client&lt;/h3&gt; 
&lt;p&gt;Use &lt;code&gt;frpc status -c ./frpc.toml&lt;/code&gt; to get status of all proxies. The &lt;code&gt;webServer&lt;/code&gt; fields are required for enabling HTTP API.&lt;/p&gt; 
&lt;h3&gt;Only allowing certain ports on the server&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;allowPorts&lt;/code&gt; in &lt;code&gt;frps.toml&lt;/code&gt; is used to avoid abuse of ports:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
allowPorts = [
  { start = 2000, end = 3000 },
  { single = 3001 },
  { single = 3003 },
  { start = 4000, end = 50000 }
]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Port Reuse&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;vhostHTTPPort&lt;/code&gt; and &lt;code&gt;vhostHTTPSPort&lt;/code&gt; in frps can use same port with &lt;code&gt;bindPort&lt;/code&gt;. frps will detect the connection's protocol and handle it correspondingly.&lt;/p&gt; 
&lt;p&gt;What you need to pay attention to is that if you want to configure &lt;code&gt;vhostHTTPSPort&lt;/code&gt; and &lt;code&gt;bindPort&lt;/code&gt; to the same port, you need to first set &lt;code&gt;transport.tls.disableCustomTLSFirstByte&lt;/code&gt; to false.&lt;/p&gt; 
&lt;p&gt;We would like to try to allow multiple proxies bind a same remote port with different protocols in the future.&lt;/p&gt; 
&lt;h3&gt;Bandwidth Limit&lt;/h3&gt; 
&lt;h4&gt;For Each Proxy&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "ssh"
type = "tcp"
localPort = 22
remotePort = 6000
transport.bandwidthLimit = "1MB"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set &lt;code&gt;transport.bandwidthLimit&lt;/code&gt; in each proxy's configure to enable this feature. Supported units are &lt;code&gt;MB&lt;/code&gt; and &lt;code&gt;KB&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Set &lt;code&gt;transport.bandwidthLimitMode&lt;/code&gt; to &lt;code&gt;client&lt;/code&gt; or &lt;code&gt;server&lt;/code&gt; to limit bandwidth on the client or server side. Default is &lt;code&gt;client&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;TCP Stream Multiplexing&lt;/h3&gt; 
&lt;p&gt;frp supports tcp stream multiplexing since v0.10.0 like HTTP2 Multiplexing, in which case all logic connections to the same frpc are multiplexed into the same TCP connection.&lt;/p&gt; 
&lt;p&gt;You can disable this feature by modify &lt;code&gt;frps.toml&lt;/code&gt; and &lt;code&gt;frpc.toml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml and frpc.toml, must be same
transport.tcpMux = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Support KCP Protocol&lt;/h3&gt; 
&lt;p&gt;KCP is a fast and reliable protocol that can achieve the transmission effect of a reduction of the average latency by 30% to 40% and reduction of the maximum delay by a factor of three, at the cost of 10% to 20% more bandwidth wasted than TCP.&lt;/p&gt; 
&lt;p&gt;KCP mode uses UDP as the underlying transport. Using KCP in frp:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable KCP in frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
# Specify a UDP port for KCP.
kcpBindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;kcpBindPort&lt;/code&gt; number can be the same number as &lt;code&gt;bindPort&lt;/code&gt;, since &lt;code&gt;bindPort&lt;/code&gt; field specifies a TCP port.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Configure &lt;code&gt;frpc.toml&lt;/code&gt; to use KCP to connect to frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
# Same as the 'kcpBindPort' in frps.toml
serverPort = 7000
transport.protocol = "kcp"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Support QUIC Protocol&lt;/h3&gt; 
&lt;p&gt;QUIC is a new multiplexed transport built on top of UDP.&lt;/p&gt; 
&lt;p&gt;Using QUIC in frp:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable QUIC in frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
# Specify a UDP port for QUIC.
quicBindPort = 7000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;quicBindPort&lt;/code&gt; number can be the same number as &lt;code&gt;bindPort&lt;/code&gt;, since &lt;code&gt;bindPort&lt;/code&gt; field specifies a TCP port.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Configure &lt;code&gt;frpc.toml&lt;/code&gt; to use QUIC to connect to frps:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
# Same as the 'quicBindPort' in frps.toml
serverPort = 7000
transport.protocol = "quic"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connection Pooling&lt;/h3&gt; 
&lt;p&gt;By default, frps creates a new frpc connection to the backend service upon a user request. With connection pooling, frps keeps a certain number of pre-established connections, reducing the time needed to establish a connection.&lt;/p&gt; 
&lt;p&gt;This feature is suitable for a large number of short connections.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Configure the limit of pool count each proxy can use in &lt;code&gt;frps.toml&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
transport.maxPoolCount = 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Enable and specify the number of connection pool:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
transport.poolCount = 1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Load balancing&lt;/h3&gt; 
&lt;p&gt;Load balancing is supported by &lt;code&gt;group&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This feature is only available for types &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;tcpmux&lt;/code&gt; now.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "test1"
type = "tcp"
localPort = 8080
remotePort = 80
loadBalancer.group = "web"
loadBalancer.groupKey = "123"

[[proxies]]
name = "test2"
type = "tcp"
localPort = 8081
remotePort = 80
loadBalancer.group = "web"
loadBalancer.groupKey = "123"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;loadBalancer.groupKey&lt;/code&gt; is used for authentication.&lt;/p&gt; 
&lt;p&gt;Connections to port 80 will be dispatched to proxies in the same group randomly.&lt;/p&gt; 
&lt;p&gt;For type &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;remotePort&lt;/code&gt; in the same group should be the same.&lt;/p&gt; 
&lt;p&gt;For type &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;customDomains&lt;/code&gt;, &lt;code&gt;subdomain&lt;/code&gt;, &lt;code&gt;locations&lt;/code&gt; should be the same.&lt;/p&gt; 
&lt;h3&gt;Service Health Check&lt;/h3&gt; 
&lt;p&gt;Health check feature can help you achieve high availability with load balancing.&lt;/p&gt; 
&lt;p&gt;Add &lt;code&gt;healthCheck.type = "tcp"&lt;/code&gt; or &lt;code&gt;healthCheck.type = "http"&lt;/code&gt; to enable health check.&lt;/p&gt; 
&lt;p&gt;With health check type &lt;strong&gt;tcp&lt;/strong&gt;, the service port will be pinged (TCPing):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "test1"
type = "tcp"
localPort = 22
remotePort = 6000
# Enable TCP health check
healthCheck.type = "tcp"
# TCPing timeout seconds
healthCheck.timeoutSeconds = 3
# If health check failed 3 times in a row, the proxy will be removed from frps
healthCheck.maxFailed = 3
# A health check every 10 seconds
healthCheck.intervalSeconds = 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With health check type &lt;strong&gt;http&lt;/strong&gt;, an HTTP request will be sent to the service and an HTTP 2xx OK response is expected:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localIP = "127.0.0.1"
localPort = 80
customDomains = ["test.example.com"]
# Enable HTTP health check
healthCheck.type = "http"
# frpc will send a GET request to '/status'
# and expect an HTTP 2xx OK response
healthCheck.path = "/status"
healthCheck.timeoutSeconds = 3
healthCheck.maxFailed = 3
healthCheck.intervalSeconds = 10
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rewriting the HTTP Host Header&lt;/h3&gt; 
&lt;p&gt;By default frp does not modify the tunneled HTTP requests at all as it's a byte-for-byte copy.&lt;/p&gt; 
&lt;p&gt;However, speaking of web servers and HTTP requests, your web server might rely on the &lt;code&gt;Host&lt;/code&gt; HTTP header to determine the website to be accessed. frp can rewrite the &lt;code&gt;Host&lt;/code&gt; header when forwarding the HTTP requests, with the &lt;code&gt;hostHeaderRewrite&lt;/code&gt; field:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
hostHeaderRewrite = "dev.example.com"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The HTTP request will have the &lt;code&gt;Host&lt;/code&gt; header rewritten to &lt;code&gt;Host: dev.example.com&lt;/code&gt; when it reaches the actual web server, although the request from the browser probably has &lt;code&gt;Host: test.example.com&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Setting other HTTP Headers&lt;/h3&gt; 
&lt;p&gt;Similar to &lt;code&gt;Host&lt;/code&gt;, You can override other HTTP request and response headers with proxy type &lt;code&gt;http&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
hostHeaderRewrite = "dev.example.com"
requestHeaders.set.x-from-where = "frp"
responseHeaders.set.foo = "bar"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In this example, it will set header &lt;code&gt;x-from-where: frp&lt;/code&gt; in the HTTP request and &lt;code&gt;foo: bar&lt;/code&gt; in the HTTP response.&lt;/p&gt; 
&lt;h3&gt;Get Real IP&lt;/h3&gt; 
&lt;h4&gt;HTTP X-Forwarded-For&lt;/h4&gt; 
&lt;p&gt;This feature is for &lt;code&gt;http&lt;/code&gt; proxies or proxies with the &lt;code&gt;https2http&lt;/code&gt; and &lt;code&gt;https2https&lt;/code&gt; plugins enabled.&lt;/p&gt; 
&lt;p&gt;You can get user's real IP from HTTP request headers &lt;code&gt;X-Forwarded-For&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Proxy Protocol&lt;/h4&gt; 
&lt;p&gt;frp supports Proxy Protocol to send user's real IP to local services.&lt;/p&gt; 
&lt;p&gt;Here is an example for https service:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "https"
localPort = 443
customDomains = ["test.example.com"]

# now v1 and v2 are supported
transport.proxyProtocolVersion = "v2"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can enable Proxy Protocol support in nginx to expose user's real IP in HTTP header &lt;code&gt;X-Real-IP&lt;/code&gt;, and then read &lt;code&gt;X-Real-IP&lt;/code&gt; header in your web service for the real IP.&lt;/p&gt; 
&lt;h3&gt;Require HTTP Basic Auth (Password) for Web Services&lt;/h3&gt; 
&lt;p&gt;Anyone who can guess your tunnel URL can access your local web server unless you protect it with a password.&lt;/p&gt; 
&lt;p&gt;This enforces HTTP Basic Auth on all requests with the username and password specified in frpc's configure file.&lt;/p&gt; 
&lt;p&gt;It can only be enabled when proxy type is http.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
customDomains = ["test.example.com"]
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit &lt;code&gt;http://test.example.com&lt;/code&gt; in the browser and now you are prompted to enter the username and password.&lt;/p&gt; 
&lt;h3&gt;Custom Subdomain Names&lt;/h3&gt; 
&lt;p&gt;It is convenient to use &lt;code&gt;subdomain&lt;/code&gt; configure for http and https types when many people share one frps server.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
subDomainHost = "frps.com"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Resolve &lt;code&gt;*.frps.com&lt;/code&gt; to the frps server's IP. This is usually called a Wildcard DNS record.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web"
type = "http"
localPort = 80
subdomain = "test"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can visit your web service on &lt;code&gt;test.frps.com&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that if &lt;code&gt;subdomainHost&lt;/code&gt; is not empty, &lt;code&gt;customDomains&lt;/code&gt; should not be the subdomain of &lt;code&gt;subdomainHost&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;URL Routing&lt;/h3&gt; 
&lt;p&gt;frp supports forwarding HTTP requests to different backend web services by url routing.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;locations&lt;/code&gt; specifies the prefix of URL used for routing. frps first searches for the most specific prefix location given by literal strings regardless of the listed order.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "web01"
type = "http"
localPort = 80
customDomains = ["web.example.com"]
locations = ["/"]

[[proxies]]
name = "web02"
type = "http"
localPort = 81
customDomains = ["web.example.com"]
locations = ["/news", "/about"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;HTTP requests with URL prefix &lt;code&gt;/news&lt;/code&gt; or &lt;code&gt;/about&lt;/code&gt; will be forwarded to &lt;strong&gt;web02&lt;/strong&gt; and other requests to &lt;strong&gt;web01&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;TCP Port Multiplexing&lt;/h3&gt; 
&lt;p&gt;frp supports receiving TCP sockets directed to different proxies on a single port on frps, similar to &lt;code&gt;vhostHTTPPort&lt;/code&gt; and &lt;code&gt;vhostHTTPSPort&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The only supported TCP port multiplexing method available at the moment is &lt;code&gt;httpconnect&lt;/code&gt; - HTTP CONNECT tunnel.&lt;/p&gt; 
&lt;p&gt;When setting &lt;code&gt;tcpmuxHTTPConnectPort&lt;/code&gt; to anything other than 0 in frps, frps will listen on this port for HTTP CONNECT requests.&lt;/p&gt; 
&lt;p&gt;The host of the HTTP CONNECT request will be used to match the proxy in frps. Proxy hosts can be configured in frpc by configuring &lt;code&gt;customDomains&lt;/code&gt; and / or &lt;code&gt;subdomain&lt;/code&gt; under &lt;code&gt;tcpmux&lt;/code&gt; proxies, when &lt;code&gt;multiplexer = "httpconnect"&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
bindPort = 7000
tcpmuxHTTPConnectPort = 1337
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000

[[proxies]]
name = "proxy1"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["test1"]
localPort = 80

[[proxies]]
name = "proxy2"
type = "tcpmux"
multiplexer = "httpconnect"
customDomains = ["test2"]
localPort = 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In the above configuration - frps can be contacted on port 1337 with a HTTP CONNECT header such as:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;CONNECT test1 HTTP/1.1\r\n\r\n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and the connection will be routed to &lt;code&gt;proxy1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Connecting to frps via PROXY&lt;/h3&gt; 
&lt;p&gt;frpc can connect to frps through proxy if you set OS environment variable &lt;code&gt;HTTP_PROXY&lt;/code&gt;, or if &lt;code&gt;transport.proxyURL&lt;/code&gt; is set in frpc.toml file.&lt;/p&gt; 
&lt;p&gt;It only works when protocol is tcp.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml
serverAddr = "x.x.x.x"
serverPort = 7000
transport.proxyURL = "http://user:pwd@192.168.1.128:8080"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Port range mapping&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Added in v0.56.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;We can use the range syntax of Go template combined with the built-in &lt;code&gt;parseNumberRangePair&lt;/code&gt; function to achieve port range mapping.&lt;/p&gt; 
&lt;p&gt;The following example, when run, will create 8 proxies named &lt;code&gt;test-6000, test-6001 ... test-6007&lt;/code&gt;, each mapping the remote port to the local port.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{{- range $_, $v := parseNumberRangePair "6000-6006,6007" "6000-6006,6007" }}
[[proxies]]
name = "tcp-{{ $v.First }}"
type = "tcp"
localPort = {{ $v.First }}
remotePort = {{ $v.Second }}
{{- end }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Client Plugins&lt;/h3&gt; 
&lt;p&gt;frpc only forwards requests to local TCP or UDP ports by default.&lt;/p&gt; 
&lt;p&gt;Plugins are used for providing rich features. There are built-in plugins such as &lt;code&gt;unix_domain_socket&lt;/code&gt;, &lt;code&gt;http_proxy&lt;/code&gt;, &lt;code&gt;socks5&lt;/code&gt;, &lt;code&gt;static_file&lt;/code&gt;, &lt;code&gt;http2https&lt;/code&gt;, &lt;code&gt;https2http&lt;/code&gt;, &lt;code&gt;https2https&lt;/code&gt; and you can see &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/#example-usage"&gt;example usage&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Using plugin &lt;strong&gt;http_proxy&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frpc.toml

[[proxies]]
name = "http_proxy"
type = "tcp"
remotePort = 6000
[proxies.plugin]
type = "http_proxy"
httpUser = "abc"
httpPassword = "abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;httpUser&lt;/code&gt; and &lt;code&gt;httpPassword&lt;/code&gt; are configuration parameters used in &lt;code&gt;http_proxy&lt;/code&gt; plugin.&lt;/p&gt; 
&lt;h3&gt;Server Manage Plugins&lt;/h3&gt; 
&lt;p&gt;Read the &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/server_plugin.md"&gt;document&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Find more plugins in &lt;a href="https://github.com/gofrp/plugin"&gt;gofrp/plugin&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;SSH Tunnel Gateway&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;added in v0.53.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;frp supports listening to an SSH port on the frps side and achieves TCP protocol proxying through the SSH -R protocol, without relying on frpc.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# frps.toml
sshTunnelGateway.bindPort = 2200
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running &lt;code&gt;./frps -c frps.toml&lt;/code&gt;, a private key file named &lt;code&gt;.autogen_ssh_key&lt;/code&gt; will be automatically created in the current working directory. This generated private key file will be used by the SSH server in frps.&lt;/p&gt; 
&lt;p&gt;Executing the command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ssh -R :80:127.0.0.1:8080 v0@{frp address} -p 2200 tcp --proxy_name "test-tcp" --remote_port 9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;sets up a proxy on frps that forwards the local 8080 service to the port 9090.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;frp (via SSH) (Ctrl+C to quit)

User:
ProxyName: test-tcp
Type: tcp
RemoteAddress: :9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is equivalent to:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;frpc tcp --proxy_name "test-tcp" --local_ip 127.0.0.1 --local_port 8080 --remote_port 9090
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to this &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/ssh_tunnel_gateway.md"&gt;document&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Virtual Network (VirtualNet)&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Alpha feature added in v0.62.0&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;The VirtualNet feature enables frp to create and manage virtual network connections between clients and visitors through a TUN interface. This allows for IP-level routing between machines, extending frp beyond simple port forwarding to support full network connectivity.&lt;/p&gt; 
&lt;p&gt;For detailed information about configuration and usage, please refer to the &lt;a href="https://raw.githubusercontent.com/fatedier/frp/dev/doc/virtual_net.md"&gt;VirtualNet documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feature Gates&lt;/h2&gt; 
&lt;p&gt;frp supports feature gates to enable or disable experimental features. This allows users to try out new features before they're considered stable.&lt;/p&gt; 
&lt;h3&gt;Available Feature Gates&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Stage&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;VirtualNet&lt;/td&gt; 
   &lt;td&gt;ALPHA&lt;/td&gt; 
   &lt;td&gt;false&lt;/td&gt; 
   &lt;td&gt;Virtual network capabilities for frp&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Enabling Feature Gates&lt;/h3&gt; 
&lt;p&gt;To enable an experimental feature, add the feature gate to your configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;featureGates = { VirtualNet = true }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Feature Lifecycle&lt;/h3&gt; 
&lt;p&gt;Features typically go through three stages:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ALPHA&lt;/strong&gt;: Disabled by default, may be unstable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;BETA&lt;/strong&gt;: May be enabled by default, more stable but still evolving&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GA (Generally Available)&lt;/strong&gt;: Enabled by default, ready for production use&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gofrp/plugin"&gt;gofrp/plugin&lt;/a&gt; - A repository for frp plugins that contains a variety of plugins implemented based on the frp extension mechanism, meeting the customization needs of different scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gofrp/tiny-frpc"&gt;gofrp/tiny-frpc&lt;/a&gt; - A lightweight version of the frp client (around 3.5MB at minimum) implemented using the ssh protocol, supporting some of the most commonly used features, suitable for devices with limited resources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in getting involved? We would like to help you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Take a look at our &lt;a href="https://github.com/fatedier/frp/issues"&gt;issues list&lt;/a&gt; and consider sending a Pull Request to &lt;strong&gt;dev branch&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;If you want to add a new feature, please create an issue first to describe the new feature, as well as the implementation approach. Once a proposal is accepted, create an implementation of the new features and submit it as a pull request.&lt;/li&gt; 
 &lt;li&gt;Sorry for my poor English. Improvements for this document are welcome, even some typo fixes.&lt;/li&gt; 
 &lt;li&gt;If you have great ideas, send an email to &lt;a href="mailto:fatedier@gmail.com"&gt;fatedier@gmail.com&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note: We prefer you to give your advise in &lt;a href="https://github.com/fatedier/frp/issues"&gt;issues&lt;/a&gt;, so others with a same question can search it quickly and we don't need to answer them repeatedly.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Donation&lt;/h2&gt; 
&lt;p&gt;If frp helps you a lot, you can support us by:&lt;/p&gt; 
&lt;h3&gt;GitHub Sponsors&lt;/h3&gt; 
&lt;p&gt;Support us by &lt;a href="https://github.com/sponsors/fatedier"&gt;Github Sponsors&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can have your company's logo placed on README file of this project.&lt;/p&gt; 
&lt;h3&gt;PayPal&lt;/h3&gt; 
&lt;p&gt;Donate money by &lt;a href="https://www.paypal.me/fatedier"&gt;PayPal&lt;/a&gt; to my account &lt;strong&gt;&lt;a href="mailto:fatedier@gmail.com"&gt;fatedier@gmail.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>seaweedfs/seaweedfs</title>
      <link>https://github.com/seaweedfs/seaweedfs</link>
      <description>&lt;p&gt;SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeaweedFS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;&lt;img src="https://img.shields.io/badge/slack-purple" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=seaweedfs"&gt;&lt;img src="https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;amp;label=Follow" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/seaweedfs/seaweedfs/weed"&gt;&lt;img src="https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;&lt;img src="https://img.shields.io/badge/docs-wiki-blue.svg?sanitize=true" alt="Wiki" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/search?q=g:com.github.chrislusf"&gt;&lt;img src="https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client" alt="SeaweedFS on Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=seaweedfs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png" alt="SeaweedFS Logo" /&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt;&lt;a href="https://www.patreon.com/seaweedfs"&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;SeaweedFS is an independent Apache-licensed open source project with its ongoing development made possible entirely thanks to the support of these awesome &lt;a href="https://github.com/seaweedfs/seaweedfs/raw/master/backers.md"&gt;backers&lt;/a&gt;. If you'd like to grow SeaweedFS even stronger, please consider joining our &lt;a href="https://www.patreon.com/seaweedfs"&gt;sponsors on Patreon&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your support will be really appreciated by me and other supporters!&lt;/p&gt; 
&lt;!--
&lt;h4 align="center"&gt;Platinum&lt;/h4&gt;

&lt;p align="center"&gt;
  &lt;a href="" target="_blank"&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.nodion.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png" alt="nodion" /&gt;&lt;/a&gt; &lt;a href="https://www.piknik.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png" alt="piknik" /&gt;&lt;/a&gt; &lt;a href="https://www.keepsec.ca"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png" alt="keepsec" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/releases/latest"&gt;Download Binaries for different platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;SeaweedFS on Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/SeaweedFS"&gt;SeaweedFS on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/Seaweedfs"&gt;SeaweedFS on Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/SeaweedFS/"&gt;SeaweedFS on Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/d/forum/seaweedfs"&gt;SeaweedFS Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;Wiki Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf"&gt;SeaweedFS White Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2025.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2021.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/chrislusf/seaweedfs-introduction"&gt;SeaweedFS Introduction Slides 2019.3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-weed-mini"&gt;Quick Start with weed mini&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-for-s3-api-on-docker"&gt;Quick Start for S3 API on Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-single-binary"&gt;Quick Start with Single Binary&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#additional-features"&gt;Additional Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#filer-features"&gt;Filer Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#example-using-seaweed-object-store"&gt;Example: Using Seaweed Object Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#object-store-architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-other-file-systems"&gt;Compared to Other File Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-hdfs"&gt;Compared to HDFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs-ceph"&gt;Compared to GlusterFS, Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs"&gt;Compared to GlusterFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-ceph"&gt;Compared to Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-minio"&gt;Compared to Minio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#dev-plan"&gt;Dev Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#installation-guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#disk-related-topics"&gt;Disk Related Topics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#benchmark"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#enterprise"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;h2&gt;Quick Start with weed mini&lt;/h2&gt; 
&lt;p&gt;The easiest way to get started with SeaweedFS for development and testing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# remove quarantine on macOS
# xattr -d com.apple.quarantine  ./weed

./weed mini -dir=/data
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This single command starts a complete SeaweedFS setup with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Master UI&lt;/strong&gt;: &lt;a href="http://localhost:9333"&gt;http://localhost:9333&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Volume Server&lt;/strong&gt;: &lt;a href="http://localhost:9340"&gt;http://localhost:9340&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Filer UI&lt;/strong&gt;: &lt;a href="http://localhost:8888"&gt;http://localhost:8888&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3 Endpoint&lt;/strong&gt;: &lt;a href="http://localhost:8333"&gt;http://localhost:8333&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WebDAV&lt;/strong&gt;: &lt;a href="http://localhost:7333"&gt;http://localhost:7333&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Admin UI&lt;/strong&gt;: &lt;a href="http://localhost:23646"&gt;http://localhost:23646&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Perfect for development, testing, learning SeaweedFS, and single node deployments!&lt;/p&gt; 
&lt;h2&gt;Quick Start for S3 API on Docker&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker run -p 8333:8333 chrislusf/seaweedfs server -s3&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start with Single Binary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;. Or run &lt;code&gt;go install github.com/seaweedfs/seaweedfs/weed@latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key&lt;/code&gt; as the admin credentials to access the object store.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;weed server -dir=/some/data/dir -s3&lt;/code&gt; to start one master, one volume server, one filer, and one S3 gateway. The difference with &lt;code&gt;weed mini&lt;/code&gt; is that &lt;code&gt;weed mini&lt;/code&gt; can auto configure based on the single host environment, while &lt;code&gt;weed server&lt;/code&gt; requires manual configuration and are designed for production use.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, to increase capacity, just add more volume servers by running &lt;code&gt;weed volume -dir="/some/data/dir2" -master="&amp;lt;master_host&amp;gt;:9333" -port=8081&lt;/code&gt; locally, or on a different machine, or on thousands of machines. That is it!&lt;/p&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;to store billions of files!&lt;/li&gt; 
 &lt;li&gt;to serve the files fast!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;SeaweedFS started as a blob store to handle small files efficiently. Instead of managing all file metadata in a central master, the central master only manages volumes on volume servers, and these volume servers manage files and their metadata. This relieves concurrency pressure from the central master and spreads file metadata into volume servers, allowing faster file access (O(1), usually just one disk read operation).&lt;/p&gt; 
&lt;p&gt;There is only 40 bytes of disk storage overhead for each file's metadata. It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.&lt;/p&gt; 
&lt;p&gt;SeaweedFS started by implementing &lt;a href="http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook's Haystack design paper&lt;/a&gt;. Also, SeaweedFS implements erasure coding with ideas from &lt;a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf"&gt;f4: Facebook‚Äôs Warm BLOB Storage System&lt;/a&gt;, and has a lot of similarities with &lt;a href="https://www.usenix.org/system/files/fast21-pan.pdf"&gt;Facebook‚Äôs Tectonic Filesystem&lt;/a&gt; and &lt;a href="https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system"&gt;Google's Colossus File System&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On top of the blob store, optional &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer&lt;/a&gt; can support directories and POSIX attributes. Filer is a separate linearly-scalable stateless server with customizable metadata stores, e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can transparently integrate with the cloud. With hot data on local cluster, and warm data on the cloud with O(1) access time, SeaweedFS can achieve both fast local access time and elastic cloud storage capacity. What's more, the cloud storage access API cost is minimized. Faster and cheaper than direct cloud storage!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Additional Blob Store Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support different replication levels, with rack and data center aware.&lt;/li&gt; 
 &lt;li&gt;Automatic master servers failover - no single point of failure (SPOF).&lt;/li&gt; 
 &lt;li&gt;Automatic compression depending on file MIME type.&lt;/li&gt; 
 &lt;li&gt;Automatic compaction to reclaim disk space after deletion or update.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live"&gt;Automatic entry TTL expiration&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Flexible Capacity Expansion: Any server with some disk space can add to the total storage space.&lt;/li&gt; 
 &lt;li&gt;Adding/Removing servers does &lt;strong&gt;not&lt;/strong&gt; cause any data re-balancing unless triggered by admin commands.&lt;/li&gt; 
 &lt;li&gt;Optional picture resizing.&lt;/li&gt; 
 &lt;li&gt;Support ETag, Accept-Range, Last-Modified, etc.&lt;/li&gt; 
 &lt;li&gt;Support in-memory/leveldb/readonly mode tuning for memory/performance balance.&lt;/li&gt; 
 &lt;li&gt;Support rebalancing the writable and readonly volumes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage"&gt;Customizable Multiple Storage Tiers&lt;/a&gt;: Customizable storage disk types to balance performance and cost.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier"&gt;Transparent cloud integration&lt;/a&gt;: unlimited capacity via tiered cloud storage for warm data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage"&gt;Erasure Coding for warm storage&lt;/a&gt; Rack-Aware 10.4 erasure coding reduces storage cost and increases availability. Enterprise version can customize EC ratio.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filer Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer server&lt;/a&gt; provides "normal" directories and files via HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores"&gt;File TTL&lt;/a&gt; automatically expires file metadata and actual file data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount"&gt;Mount filer&lt;/a&gt; reads and writes files directly as a local directory via FUSE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication"&gt;Filer Store Replication&lt;/a&gt; enables HA for filer meta data stores.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization"&gt;Active-Active Replication&lt;/a&gt; enables asynchronous one-way or two-way cross cluster continuous replication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API"&gt;Amazon S3 compatible API&lt;/a&gt; accesses files with S3 tooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System"&gt;Hadoop Compatible File System&lt;/a&gt; accesses files from Hadoop/Spark/Flink/etc or even runs HBase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud"&gt;Async Replication To Cloud&lt;/a&gt; has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/WebDAV"&gt;WebDAV&lt;/a&gt; accesses as a mapped drive on Mac and Windows, or from mobile devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption"&gt;AES256-GCM Encrypted Storage&lt;/a&gt; safely stores the encrypted data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files"&gt;Super Large Files&lt;/a&gt; stores large or super large files in tens of TB.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt; mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage"&gt;Gateway to Remote Object Store&lt;/a&gt; mirrors bucket operations to remote object storage, in addition to &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Kubernetes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-csi-driver"&gt;Kubernetes CSI Driver&lt;/a&gt; A Container Storage Interface (CSI) Driver. &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-operator"&gt;SeaweedFS Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example: Using Seaweed Blob Store&lt;/h2&gt; 
&lt;p&gt;By default, the master node runs on port 9333, and the volume nodes run on port 8080. Let's start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We'll use localhost as an example.&lt;/p&gt; 
&lt;p&gt;SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.&lt;/p&gt; 
&lt;h3&gt;Start Master Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; ./weed master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Volume Servers&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; weed volume -dir="/tmp/data1" -max=5  -master="localhost:9333" -port=8080 &amp;amp;
&amp;gt; weed volume -dir="/tmp/data2" -max=10 -master="localhost:9333" -port=8081 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write A Blob&lt;/h3&gt; 
&lt;p&gt;A blob, also referred as a needle, a chunk, or mistakenly as a file, is just a byte array. It can have attributes, such as name, mime type, create or update time, etc. But basically it is just a byte array of a relatively small size, such as 2 MB ~ 64 MB. The size is not fixed.&lt;/p&gt; 
&lt;p&gt;To upload a blob: first, send a HTTP POST, PUT, or GET request to &lt;code&gt;/dir/assign&lt;/code&gt; to get an &lt;code&gt;fid&lt;/code&gt; and a volume server URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/assign
{"count":1,"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Second, to store the blob content, send a HTTP multi-part POST request to &lt;code&gt;url + '/' + fid&lt;/code&gt; from the response:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{"name":"myphoto.jpg","size":43234,"eTag":"1cc0118e"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update, send another POST request with updated blob content.&lt;/p&gt; 
&lt;p&gt;For deletion, send an HTTP DELETE request to the same &lt;code&gt;url + '/' + fid&lt;/code&gt; URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Save Blob Id&lt;/h3&gt; 
&lt;p&gt;Now, you can save the &lt;code&gt;fid&lt;/code&gt;, 3,01637037d6 in this case, to a database field.&lt;/p&gt; 
&lt;p&gt;The number 3 at the start represents a volume id. After the comma, it's one file key, 01, and a file cookie, 637037d6.&lt;/p&gt; 
&lt;p&gt;The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.&lt;/p&gt; 
&lt;p&gt;The file key and file cookie are both coded in hex. You can store the &amp;lt;volume id, file key, file cookie&amp;gt; tuple in your own format, or simply store the &lt;code&gt;fid&lt;/code&gt; as a string.&lt;/p&gt; 
&lt;p&gt;If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.&lt;/p&gt; 
&lt;p&gt;If space is really a concern, you can store the file id in the binary format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.&lt;/p&gt; 
&lt;h3&gt;Read a Blob&lt;/h3&gt; 
&lt;p&gt;Here is an example of how to render the URL.&lt;/p&gt; 
&lt;p&gt;First look up the volume server's URLs by the file's volumeId:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/lookup?volumeId=3
{"volumeId":"3","locations":[{"publicUrl":"localhost:8080","url":"localhost:8080"}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since (usually) there are not too many volume servers, and volumes don't move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.&lt;/p&gt; 
&lt;p&gt;Now you can take the public URL, render the URL or directly read from the volume server via URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3,01637037d6.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notice we add a file extension ".jpg" here. It's optional and just one way for the client to specify the file content type.&lt;/p&gt; 
&lt;p&gt;If you want a nicer URL, you can use one of these alternative URL formats:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to get a scaled version of an image, you can add some params:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fill
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rack-Aware and Data Center-Aware Replication&lt;/h3&gt; 
&lt;p&gt;SeaweedFS applies the replication strategy at a volume level. So, when you are getting a blob id, you can specify the replication strategy. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:9333/dir/assign?replication=001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication parameter options are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about replication can be found &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Replication"&gt;on the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also set the default replication strategy when starting the master server.&lt;/p&gt; 
&lt;h3&gt;Allocate Blob Key on Specific Data Center&lt;/h3&gt; 
&lt;p&gt;Volume servers can be started with a specific data center name:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When requesting a blob key, an optional "dataCenter" parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to 'dc1':&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:9333/dir/assign?dataCenter=dc1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server"&gt;No Single Point of Failure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys"&gt;Insert with your own keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files"&gt;Chunking large files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space"&gt;Collection as a Simple Name Space&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Blob Store Architecture&lt;/h2&gt; 
&lt;p&gt;Usually distributed file systems split each file into chunks. A central server keeps a mapping of filenames to chunks, and also which chunks each chunk server has.&lt;/p&gt; 
&lt;p&gt;The main drawback is that the central server can't handle many small files efficiently, and since all read requests need to go through the central master, so it might not scale well for many concurrent users.&lt;/p&gt; 
&lt;p&gt;Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of blobs. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.&lt;/p&gt; 
&lt;p&gt;The actual blob metadata, which are the blob volume, offset, and size, is stored in each volume on volume servers. Since each volume server only manages metadata of blobs on its own disk, with only 16 bytes for each blob, all access can read the metadata just from memory and only needs one disk operation to actually read file data.&lt;/p&gt; 
&lt;p&gt;For comparison, consider that an xfs inode structure in Linux is 536 bytes.&lt;/p&gt; 
&lt;h3&gt;Master Server and Volume Server&lt;/h3&gt; 
&lt;p&gt;The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.&lt;/p&gt; 
&lt;p&gt;All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.&lt;/p&gt; 
&lt;p&gt;On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.&lt;/p&gt; 
&lt;h3&gt;Write and Read files&lt;/h3&gt; 
&lt;p&gt;When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the blob. The client then contacts the volume node and POSTs the blob content.&lt;/p&gt; 
&lt;p&gt;When a client needs to read a blob based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages and let browsers fetch the content.&lt;/p&gt; 
&lt;h3&gt;Saving memory&lt;/h3&gt; 
&lt;p&gt;All blob metadata stored on a volume server is readable from memory without disk access. Each file takes just a 16-byte map entry of &amp;lt;64bit key, 32bit offset, 32bit size&amp;gt;. Of course, each map entry has its own space cost for the map. But usually the disk space runs out before the memory does.&lt;/p&gt; 
&lt;h3&gt;Tiered Storage to the cloud&lt;/h3&gt; 
&lt;p&gt;The local volume servers are much faster, while cloud storages have elastic capacity and are actually more cost-efficient if not accessed often (usually free to upload, but relatively costly to access). With the append-only structure and O(1) access time, SeaweedFS can take advantage of both local and cloud storage by offloading the warm data to the cloud.&lt;/p&gt; 
&lt;p&gt;Usually hot data are fresh and warm data are old. SeaweedFS puts the newly created volumes on local servers, and optionally upload the older volumes on the cloud. If the older data are accessed less often, this literally gives you unlimited capacity with limited local servers, and still fast for new data.&lt;/p&gt; 
&lt;p&gt;With the O(1) access time, the network latency cost is kept at minimum.&lt;/p&gt; 
&lt;p&gt;If the hot/warm data is split as 20/80, with 20 servers, you can achieve storage capacity of 100 servers. That's a cost saving of 80%! Or you can repurpose the 80 servers to store new data also, and get 5X storage throughput.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;SeaweedFS Filer&lt;/h2&gt; 
&lt;p&gt;Built on top of the blob store, SeaweedFS Filer adds directory structure to create a file system. The directory sturcture is an interface that is implemented in many key-value stores or databases.&lt;/p&gt; 
&lt;p&gt;The content of a file is mapped to one or many blobs, distributed to multiple volumes on multiple volume servers.&lt;/p&gt; 
&lt;h2&gt;Compared to Other File Systems&lt;/h2&gt; 
&lt;p&gt;Most other distributed file systems seem more complicated than necessary.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is meant to be fast and simple, in both setup and operation. If you do not understand how it works when you reach here, we've failed! Please raise an issue with any questions or update this file with clarifications.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is constantly moving forward. Same with other systems. These comparisons can be outdated quickly. Please help to keep them updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to HDFS&lt;/h3&gt; 
&lt;p&gt;HDFS uses the chunk approach for each file, and is ideal for storing large files.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is ideal for serving relatively smaller files quickly and concurrently.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can also store extra large files by splitting them into manageable data chunks, and store the file ids of the data chunks into a meta chunk. This is managed by "weed upload/download" tool, and the weed master or volume servers are agnostic about it.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS, Ceph&lt;/h3&gt; 
&lt;p&gt;The architectures are mostly the same. SeaweedFS aims to store and read files fast, with a simple and flat architecture. The main differences are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SeaweedFS optimizes for small files, ensuring O(1) disk seek operation, and can also handle large files.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS statically assigns a volume id for a file. Locating file content becomes just a lookup of the volume id, which can be easily cached.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Filer metadata store can be any well-known and proven data store, e.g., Redis, Cassandra, HBase, Mongodb, Elastic Search, MySql, Postgres, Sqlite, MemSql, TiDB, CockroachDB, Etcd, YDB etc, and is easy to customize.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Volume server also communicates directly with clients via HTTP, supporting range queries, direct uploads, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;File Metadata&lt;/th&gt; 
   &lt;th&gt;File Content Read&lt;/th&gt; 
   &lt;th&gt;POSIX&lt;/th&gt; 
   &lt;th&gt;REST API&lt;/th&gt; 
   &lt;th&gt;Optimized for large number of small files&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS&lt;/td&gt; 
   &lt;td&gt;lookup volume id, cacheable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS Filer&lt;/td&gt; 
   &lt;td&gt;Linearly Scalable, Customizable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GlusterFS&lt;/td&gt; 
   &lt;td&gt;hashing&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE, NFS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ceph&lt;/td&gt; 
   &lt;td&gt;hashing + rules&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MooseFS&lt;/td&gt; 
   &lt;td&gt;in memory&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinIO&lt;/td&gt; 
   &lt;td&gt;separate meta file for each file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS&lt;/h3&gt; 
&lt;p&gt;GlusterFS stores files, both directories and content, in configurable volumes called "bricks".&lt;/p&gt; 
&lt;p&gt;GlusterFS hashes the path and filename into ids, and assigned to virtual volumes, and then mapped to "bricks".&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MooseFS&lt;/h3&gt; 
&lt;p&gt;MooseFS chooses to neglect small file issue. From moosefs 3.0 manual, "even a small file will occupy 64KiB plus additionally 4KiB of checksums and 1KiB for the header", because it "was initially designed for keeping large amounts (like several thousands) of very big files"&lt;/p&gt; 
&lt;p&gt;MooseFS Master Server keeps all meta data in memory. Same issue as HDFS namenode.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to Ceph&lt;/h3&gt; 
&lt;p&gt;Ceph can be setup similar to SeaweedFS as a key-&amp;gt;blob store. It is much more complicated, with the need to support layers on top of it. &lt;a href="https://github.com/seaweedfs/seaweedfs/issues/120"&gt;Here is a more detailed comparison&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;SeaweedFS has a centralized master group to look up free volumes, while Ceph uses hashing and metadata servers to locate its objects. Having a centralized master makes it easy to code and manage.&lt;/p&gt; 
&lt;p&gt;Ceph, like SeaweedFS, is based on the object store RADOS. Ceph is rather complicated with mixed reviews.&lt;/p&gt; 
&lt;p&gt;Ceph uses CRUSH hashing to automatically manage data placement, which is efficient to locate the data. But the data has to be placed according to the CRUSH algorithm. Any wrong configuration would cause data loss. Topology changes, such as adding new servers to increase capacity, will cause data migration with high IO cost to fit the CRUSH algorithm. SeaweedFS places data by assigning them to any writable volumes. If writes to one volume failed, just pick another volume to write. Adding more volumes is also as simple as it can be.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is optimized for small files. Small files are stored as one continuous block of content, with at most 8 unused bytes between files. Small file access is O(1) disk read.&lt;/p&gt; 
&lt;p&gt;SeaweedFS Filer uses off-the-shelf stores, such as MySql, Postgres, Sqlite, Mongodb, Redis, Elastic Search, Cassandra, HBase, MemSql, TiDB, CockroachCB, Etcd, YDB, to manage file directories. These stores are proven, scalable, and easier to manage.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SeaweedFS&lt;/th&gt; 
   &lt;th&gt;comparable to Ceph&lt;/th&gt; 
   &lt;th&gt;advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Master&lt;/td&gt; 
   &lt;td&gt;MDS&lt;/td&gt; 
   &lt;td&gt;simpler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volume&lt;/td&gt; 
   &lt;td&gt;OSD&lt;/td&gt; 
   &lt;td&gt;optimized for small files&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filer&lt;/td&gt; 
   &lt;td&gt;Ceph FS&lt;/td&gt; 
   &lt;td&gt;linearly scalable, Customizable, O(1) or O(logN)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MinIO&lt;/h3&gt; 
&lt;p&gt;MinIO follows AWS S3 closely and is ideal for testing for S3 API. It has good UI, policies, versionings, etc. SeaweedFS is trying to catch up here. It is also possible to put MinIO as a gateway in front of SeaweedFS later.&lt;/p&gt; 
&lt;p&gt;MinIO metadata are in simple files. Each file write will incur extra writes to corresponding meta file.&lt;/p&gt; 
&lt;p&gt;MinIO does not have optimization for lots of small files. The files are simply stored as is to local disks. Plus the extra meta file and shards for erasure coding, it only amplifies the LOSF problem.&lt;/p&gt; 
&lt;p&gt;MinIO has multiple disk IO to read one file. SeaweedFS has O(1) disk reads, even for erasure coded files.&lt;/p&gt; 
&lt;p&gt;MinIO has full-time erasure coding. SeaweedFS uses replication on hot data for faster speed and optionally applies erasure coding on warm data.&lt;/p&gt; 
&lt;p&gt;MinIO does not have POSIX-like API support.&lt;/p&gt; 
&lt;p&gt;MinIO has specific requirements on storage layout. It is not flexible to adjust capacity. In SeaweedFS, just start one volume server pointing to the master. That's all.&lt;/p&gt; 
&lt;h2&gt;Dev Plan&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More tools and documentation, on how to manage and scale the system.&lt;/li&gt; 
 &lt;li&gt;Read and write stream data.&lt;/li&gt; 
 &lt;li&gt;Support structured data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is a super exciting project! And we need helpers and &lt;a href="https://www.patreon.com/seaweedfs"&gt;support&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Installation guide for users who are not familiar with golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Step 1: install go on your machine and setup the environment by following the instructions at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://golang.org/doc/install"&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;make sure to define your $GOPATH&lt;/p&gt; 
&lt;p&gt;Step 2: checkout this repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/seaweedfs/seaweedfs.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step 3: download, compile, and install the project by executing the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd seaweedfs/weed &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this is done, you will find the executable "weed" in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory&lt;/p&gt; 
&lt;p&gt;For more installation options, including how to run with Docker, see the &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Getting-Started"&gt;Getting Started guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disk Related Topics&lt;/h2&gt; 
&lt;h3&gt;Hard Drive Performance&lt;/h3&gt; 
&lt;p&gt;When testing read performance on SeaweedFS, it basically becomes a performance test of your hard drive's random read speed. Hard drives usually get 100MB/s~200MB/s.&lt;/p&gt; 
&lt;h3&gt;Solid State Disk&lt;/h3&gt; 
&lt;p&gt;To modify or delete small files, SSD must delete a whole block at a time, and move content in existing blocks to a new block. SSD is fast when brand new, but will get fragmented over time and you have to garbage collect, compacting blocks. SeaweedFS is friendly to SSD since it is append-only. Deletion and compaction are done on volume level in the background, not slowing reading and not causing fragmentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;My Own Unscientific Single Machine Results on Mac Book with Solid State Disk, CPU: 1 Intel Core i7 2.6GHz.&lt;/p&gt; 
&lt;p&gt;Write 1 million 1KB file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   66.753 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106789009 bytes
Requests per second:    15708.23 [#/sec]
Transfer rate:          16191.69 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.3      1.0       84.3      0.9

Percentage of the requests served within a certain time (ms)
   50%      0.8 ms
   66%      1.0 ms
   75%      1.1 ms
   80%      1.2 ms
   90%      1.4 ms
   95%      1.7 ms
   98%      2.1 ms
   99%      2.6 ms
  100%     84.3 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Randomly read 1 million files:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   22.301 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106812873 bytes
Requests per second:    47019.38 [#/sec]
Transfer rate:          48467.57 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.0      0.3       54.1      0.2

Percentage of the requests served within a certain time (ms)
   50%      0.3 ms
   90%      0.4 ms
   98%      0.6 ms
   99%      0.7 ms
  100%     54.1 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run WARP and launch a mixed benchmark.&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make benchmark
warp: Benchmark data written to "warp-mixed-2025-12-05[194844]-kBpU.csv.zst"

Mixed operations.
Operation: DELETE, 10%, Concurrency: 20, Ran 42s.
 * Throughput: 55.13 obj/s

Operation: GET, 45%, Concurrency: 20, Ran 42s.
 * Throughput: 2477.45 MiB/s, 247.75 obj/s

Operation: PUT, 15%, Concurrency: 20, Ran 42s.
 * Throughput: 825.85 MiB/s, 82.59 obj/s

Operation: STAT, 30%, Concurrency: 20, Ran 42s.
 * Throughput: 165.27 obj/s

Cluster Total: 3302.88 MiB/s, 550.51 obj/s over 43s.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;For enterprise users, please visit &lt;a href="https://seaweedfs.com"&gt;seaweedfs.com&lt;/a&gt; for the SeaweedFS Enterprise Edition, which has a self-healing storage format with better data protection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;p&gt;The text of this page is available for modification and reuse under the terms of the Creative Commons Attribution-Sharealike 3.0 Unported License and the GNU Free Documentation License (unversioned, with no invariant sections, front-cover texts, or back-cover texts).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/seaweedfs/seaweedfs"&gt;&lt;img src="https://starchart.cc/seaweedfs/seaweedfs.svg?variant=adaptive" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kubernetes-sigs/ingress2gateway</title>
      <link>https://github.com/kubernetes-sigs/ingress2gateway</link>
      <description>&lt;p&gt;Convert Ingress resources to Gateway API resources&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Ingress to Gateway&lt;/h1&gt; 
&lt;p&gt;Ingress2gateway helps translate Ingress and provider-specific resources (CRDs) to Gateway API resources. Ingress2gateway is managed by the &lt;a href="https://gateway-api.sigs.k8s.io/"&gt;Gateway API&lt;/a&gt; SIG-Network subproject.&lt;/p&gt; 
&lt;h2&gt;Scope&lt;/h2&gt; 
&lt;p&gt;Ingress2gateway is primarily focused on translating Ingress and provider-specific resources(CRDs) to Gateway API resources. Widely used provider-specific annotations and/or CRDs &lt;em&gt;may&lt;/em&gt; still not be supported. Please refer to &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/ingress2gateway/main/#supported-providers"&gt;supported providers&lt;/a&gt; for the current supported providers and their documentation. Contributions for provider-specific annotations and/or CRDs support are mostly welcomed as long as they can be translated to &lt;a href="https://gateway-api.sigs.k8s.io/"&gt;Gateway API&lt;/a&gt; directly.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Ingress2gateway is not intended to copy annotations from Ingress to Gateway API.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Supported providers&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/ingress2gateway/main/pkg/i2gw/providers/apisix/README.md"&gt;apisix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/ingress2gateway/main/pkg/i2gw/providers/cilium/README.md"&gt;cilium&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/ingress2gateway/main/pkg/i2gw/providers/ingressnginx/README.md"&gt;ingress-nginx&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/ingress2gateway/main/pkg/i2gw/providers/istio/README.md"&gt;istio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/ingress2gateway/main/pkg/i2gw/providers/gce/README.md"&gt;gce&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/ingress2gateway/main/pkg/i2gw/providers/kong/README.md"&gt;kong&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/ingress2gateway/main/pkg/i2gw/providers/nginx/README.md"&gt;nginx&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/ingress2gateway/main/pkg/i2gw/providers/openapi3/README.md"&gt;openapi&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If your provider, or a specific feature, is not currently supported, please open an issue and describe your use case.&lt;/p&gt; 
&lt;p&gt;To contribute a new provider support - please read &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/ingress2gateway/main/PROVIDER.md"&gt;PROVIDER.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Via go install&lt;/h3&gt; 
&lt;p&gt;If you have a Go development environment locally, you can install ingress2gateway with &lt;code&gt;go install github.com/kubernetes-sigs/ingress2gateway@v0.5.0&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;This will put &lt;code&gt;ingress2gateway&lt;/code&gt; binary in &lt;code&gt;$(go env GOPATH)/bin&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Alternatively, you can download the binary at the &lt;a href="https://github.com/kubernetes-sigs/ingress2gateway/releases"&gt;releases page&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;On macOS and linux via Homebrew&lt;/h3&gt; 
&lt;p&gt;Make sure Homebrew is installed on your system.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install ingress2gateway
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build from Source&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Ensure that your system meets the following requirements:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Install Git: Make sure Git is installed on your system to clone the project repository.&lt;/li&gt; 
   &lt;li&gt;Install Go: Make sure the go language is installed on your system. You can download it from the official website (&lt;a href="https://golang.org/dl/"&gt;https://golang.org/dl/&lt;/a&gt;) and follow the installation instructions.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the project repository&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/kubernetes-sigs/ingress2gateway.git &amp;amp;&amp;amp; cd ingress2gateway
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build the project&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;make build
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Ingress2gateway reads Ingress resources and/or provider-specifc CRDs from a Kubernetes cluster or a file. It will output the equivalent Gateway API resources in a YAML/JSON format to stdout. The simplest case is to convert all ingresses from one provider (in this example we use ingress-nginx):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./ingress2gateway print --providers=ingress-nginx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above command will:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Read your Kube config file to extract the cluster credentials and the current active namespace.&lt;/li&gt; 
 &lt;li&gt;Search for ingress-nginx resources in that namespace.&lt;/li&gt; 
 &lt;li&gt;Convert them to Gateway-API resources (Currently only Gateways and HTTPRoutes).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Options&lt;/h2&gt; 
&lt;h3&gt;&lt;code&gt;print&lt;/code&gt; command&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Flag&lt;/th&gt; 
   &lt;th&gt;Default Value&lt;/th&gt; 
   &lt;th&gt;Required&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;all-namespaces&lt;/td&gt; 
   &lt;td&gt;False&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;If present, list the requested object(s) across all namespaces. Namespace in the current context is ignored even if specified with --namespace.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;input-file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Path to the manifest file. When set, the tool will read ingresses from the file instead of reading from the cluster. Supported files are yaml and json.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;namespace&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;If present, the namespace scope for the invocation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;openapi3-backend&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Provider-specific: openapi3. The name of the backend service to use in the HTTPRoutes.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;openapi3-gateway-class-name&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Provider-specific: openapi3. The name of the gateway class to use in the Gateways.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;openapi3-gateway-tls-secret&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Provider-specific: openapi3. The name of the secret for the TLS certificate references in the Gateways.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;output&lt;/td&gt; 
   &lt;td&gt;yaml&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;The output format, either yaml or json.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;providers&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Comma-separated list of providers.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;kubeconfig&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;The kubeconfig file to use when talking to the cluster. If the flag is not set, a set of standard locations can be searched for an existing kubeconfig file.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Conversion of Ingress resources to Gateway API&lt;/h2&gt; 
&lt;h3&gt;Processing Order and Conflicts&lt;/h3&gt; 
&lt;p&gt;Ingress resources will be processed with a defined order to ensure deterministic generated Gateway API configuration. This should also determine precedence order of Ingress resources and routes in case of conflicts.&lt;/p&gt; 
&lt;p&gt;Ingress resources with the oldest creation timestamp will be sorted first and therefore given precedence. If creation timestamps are equal, then sorting will be done based on the namespace/name of the resources. If an Ingress rule conflicts with another (e.g. same path match but different backends) an error will be reported for the one that sorted later.&lt;/p&gt; 
&lt;p&gt;Since the Ingress v1 spec does not itself have a conflict resolution guide, we have adopted this one. These rules are similar to the &lt;a href="https://gateway-api.sigs.k8s.io/concepts/guidelines/#conflicts"&gt;Gateway API conflict resolution guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Ingress resource fields to Gateway API fields&lt;/h3&gt; 
&lt;p&gt;Given a set of Ingress resources, &lt;code&gt;ingress2gateway&lt;/code&gt; will generate a Gateway with various HTTP and HTTPS Listeners as well as HTTPRoutes that should represent equivalent routing rules.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ingress Field&lt;/th&gt; 
   &lt;th&gt;Gateway API configuration&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ingressClassName&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;If configured on an Ingress resource, this value will be used as the &lt;code&gt;gatewayClassName&lt;/code&gt; set on the corresponding generated Gateway. &lt;code&gt;kubernetes.io/ingress.class&lt;/code&gt; annotation has the same behavior.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;defaultBackend&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;If present, this configuration will generate a Gateway Listener with no &lt;code&gt;hostname&lt;/code&gt; specified as well as a catchall HTTPRoute that references this listener. The backend specified here will be translated to a HTTPRoute &lt;code&gt;rules[].backendRefs[]&lt;/code&gt; element.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tls[].hosts&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Each host in an IngressTLS will result in a HTTPS Listener on the generated Gateway with the following: &lt;code&gt;listeners[].hostname&lt;/code&gt; = host as described, &lt;code&gt;listeners[].port&lt;/code&gt; = &lt;code&gt;443&lt;/code&gt;, &lt;code&gt;listeners[].protocol&lt;/code&gt; = &lt;code&gt;HTTPS&lt;/code&gt;, &lt;code&gt;listeners[].tls.mode&lt;/code&gt; = &lt;code&gt;Terminate&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tls[].secretName&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The secret specified here will be referenced in the Gateway HTTPS Listeners mentioned above with the field &lt;code&gt;listeners[].tls.certificateRefs&lt;/code&gt;. Each Listener for each host in an IngressTLS will get this secret.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;rules[].host&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;If non-empty, each distinct value for this field in the provided Ingress resources will result in a separate Gateway HTTP Listener with matching &lt;code&gt;listeners[].hostname&lt;/code&gt;. &lt;code&gt;listeners[].port&lt;/code&gt; will be set to &lt;code&gt;80&lt;/code&gt; and &lt;code&gt;listeners[].protocol&lt;/code&gt; set to &lt;code&gt;HTTPS&lt;/code&gt;. In addition, Ingress rules with the same hostname will generate HTTPRoute rules in a HTTPRoute with &lt;code&gt;hostnames&lt;/code&gt; containing it as the single element. If empty, similar to the &lt;code&gt;defaultBackend&lt;/code&gt;, a Gateway Listener with no hostname configuration will be generated (if it doesn't exist) and routing rules will be generated in a catchall HTTPRoute.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;rules[].http.paths[].path&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;This field translates to a HTTPRoute &lt;code&gt;rules[].matches[].path.value&lt;/code&gt; configuration.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;rules[].http.paths[].pathType&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;This field translates to a HTTPRoute &lt;code&gt;rules[].matches[].path.type&lt;/code&gt; configuration. Ingress &lt;code&gt;Exact&lt;/code&gt; = HTTPRoute &lt;code&gt;Exact&lt;/code&gt; match. Ingress &lt;code&gt;Prefix&lt;/code&gt; = HTTPRoute &lt;code&gt;PathPrefix&lt;/code&gt; match.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;rules[].http.paths[].backend&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The backend specified here will be translated to a HTTPRoute &lt;code&gt;rules[].backendRefs[]&lt;/code&gt; element.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Get Involved&lt;/h2&gt; 
&lt;p&gt;This project will be discussed in the same Slack channel and community meetings as the rest of the Gateway API subproject. For more information, refer to the &lt;a href="https://gateway-api.sigs.k8s.io/contributing/"&gt;Gateway API Community&lt;/a&gt; page.&lt;/p&gt; 
&lt;h3&gt;Code of conduct&lt;/h3&gt; 
&lt;p&gt;Participation in the Kubernetes community is governed by the &lt;a href="https://raw.githubusercontent.com/kubernetes-sigs/ingress2gateway/main/code-of-conduct.md"&gt;Kubernetes Code of Conduct&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>github/github-mcp-server</title>
      <link>https://github.com/github/github-mcp-server</link>
      <description>&lt;p&gt;GitHub's official MCP Server&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/github/github-mcp-server"&gt;&lt;img src="https://goreportcard.com/badge/github.com/github/github-mcp-server" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;GitHub MCP Server&lt;/h1&gt; 
&lt;p&gt;The GitHub MCP Server connects AI tools directly to GitHub's platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code files, manage issues and PRs, analyze code, and automate workflows. All through natural language interactions.&lt;/p&gt; 
&lt;h3&gt;Use Cases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Repository Management: Browse and query code, search files, analyze commits, and understand project structure across any repository you have access to.&lt;/li&gt; 
 &lt;li&gt;Issue &amp;amp; PR Automation: Create, update, and manage issues and pull requests. Let AI help triage bugs, review code changes, and maintain project boards.&lt;/li&gt; 
 &lt;li&gt;CI/CD &amp;amp; Workflow Intelligence: Monitor GitHub Actions workflow runs, analyze build failures, manage releases, and get insights into your development pipeline.&lt;/li&gt; 
 &lt;li&gt;Code Analysis: Examine security findings, review Dependabot alerts, understand code patterns, and get comprehensive insights into your codebase.&lt;/li&gt; 
 &lt;li&gt;Team Collaboration: Access discussions, manage notifications, analyze team activity, and streamline processes for your team.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Built for developers who want to connect their AI tools to GitHub context and capabilities, from simple natural language queries to complex multi-step agent workflows.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Remote GitHub MCP Server&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D"&gt;&lt;img src="https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;amp;logo=visualstudiocode&amp;amp;logoColor=white" alt="Install in VS Code" /&gt;&lt;/a&gt; &lt;a href="https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D&amp;amp;quality=insiders"&gt;&lt;img src="https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;amp;logo=visualstudiocode&amp;amp;logoColor=white" alt="Install in VS Code Insiders" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The remote GitHub MCP Server is hosted by GitHub and provides the easiest method for getting up and running. If your MCP host does not support remote MCP servers, don't worry! You can use the &lt;a href="https://github.com/github/github-mcp-server?tab=readme-ov-file#local-github-mcp-server"&gt;local version of the GitHub MCP Server&lt;/a&gt; instead.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;A compatible MCP host with remote server support (VS Code 1.101+, Claude Desktop, Cursor, Windsurf, etc.)&lt;/li&gt; 
 &lt;li&gt;Any applicable &lt;a href="https://github.com/github/github-mcp-server/raw/main/docs/policies-and-governance.md"&gt;policies enabled&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Install in VS Code&lt;/h3&gt; 
&lt;p&gt;For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start. Make sure you're using &lt;a href="https://code.visualstudio.com/updates/v1_101"&gt;VS Code 1.101&lt;/a&gt; or &lt;a href="https://code.visualstudio.com/updates"&gt;later&lt;/a&gt; for remote MCP and OAuth support.&lt;/p&gt; 
&lt;p&gt;Alternatively, to manually configure VS Code, choose the appropriate JSON block from the examples below and add it to your host configuration:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;
   &lt;th&gt;Using OAuth&lt;/th&gt;
   &lt;th&gt;Using a GitHub PAT&lt;/th&gt;
  &lt;/tr&gt; 
  &lt;tr&gt;
   &lt;th align="left" colspan="2"&gt;VS Code (version 1.101 or greater)&lt;/th&gt;
  &lt;/tr&gt; 
  &lt;tr valign="top"&gt; 
   &lt;td&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "servers": {
    "github": {
      "type": "http",
      "url": "https://api.githubcopilot.com/mcp/"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "servers": {
    "github": {
      "type": "http",
      "url": "https://api.githubcopilot.com/mcp/",
      "headers": {
        "Authorization": "Bearer ${input:github_mcp_pat}"
      }
    }
  },
  "inputs": [
    {
      "type": "promptString",
      "id": "github_mcp_pat",
      "description": "GitHub Personal Access Token",
      "password": true
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;Install in other MCP hosts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides/install-other-copilot-ides.md"&gt;GitHub Copilot in other IDEs&lt;/a&gt;&lt;/strong&gt; - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides/install-claude.md"&gt;Claude Applications&lt;/a&gt;&lt;/strong&gt; - Installation guide for Claude Desktop and Claude Code CLI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides/install-codex.md"&gt;Codex&lt;/a&gt;&lt;/strong&gt; - Installation guide for Open AI Codex&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides/install-cursor.md"&gt;Cursor&lt;/a&gt;&lt;/strong&gt; - Installation guide for Cursor IDE&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides/install-windsurf.md"&gt;Windsurf&lt;/a&gt;&lt;/strong&gt; - Installation guide for Windsurf IDE&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides/install-rovo-dev-cli.md"&gt;Rovo Dev CLI&lt;/a&gt;&lt;/strong&gt; - Installation guide for Rovo Dev CLI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Each MCP host application needs to configure a GitHub App or OAuth App to support remote access via OAuth. Any host application that supports remote MCP servers should support the remote GitHub server with PAT authentication. Configuration details and support levels vary by host. Make sure to refer to the host application's documentation for more info.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;h4&gt;Toolset configuration&lt;/h4&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/remote-server.md"&gt;Remote Server Documentation&lt;/a&gt; for full details on remote server configuration, toolsets, headers, and advanced usage. This file provides comprehensive instructions and examples for connecting, customizing, and installing the remote GitHub MCP Server in VS Code and other MCP hosts.&lt;/p&gt; 
&lt;p&gt;When no toolsets are specified, &lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/#default-toolset"&gt;default toolsets&lt;/a&gt; are used.&lt;/p&gt; 
&lt;h4&gt;GitHub Enterprise&lt;/h4&gt; 
&lt;h5&gt;GitHub Enterprise Cloud with data residency (ghe.com)&lt;/h5&gt; 
&lt;p&gt;GitHub Enterprise Cloud can also make use of the remote server.&lt;/p&gt; 
&lt;p&gt;Example for &lt;code&gt;https://octocorp.ghe.com&lt;/code&gt; with GitHub PAT token:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;{
    ...
    "proxima-github": {
      "type": "http",
      "url": "https://copilot-api.octocorp.ghe.com/mcp",
      "headers": {
        "Authorization": "Bearer ${input:github_mcp_pat}"
      }
    },
    ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When using OAuth with GitHub Enterprise with VS Code and GitHub Copilot, you also need to configure your VS Code settings to point to your GitHub Enterprise instance - see &lt;a href="https://docs.github.com/en/enterprise-cloud@latest/copilot/how-tos/configure-personal-settings/authenticate-to-ghecom"&gt;Authenticate from VS Code&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h5&gt;GitHub Enterprise Server&lt;/h5&gt; 
&lt;p&gt;GitHub Enterprise Server does not support remote server hosting. Please refer to &lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/#github-enterprise-server-and-enterprise-cloud-with-data-residency-ghecom"&gt;GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)&lt;/a&gt; from the local server configuration.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Local GitHub MCP Server&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D"&gt;&lt;img src="https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;amp;logo=visualstudiocode&amp;amp;logoColor=white" alt="Install with Docker in VS Code" /&gt;&lt;/a&gt; &lt;a href="https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D&amp;amp;quality=insiders"&gt;&lt;img src="https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;amp;logo=visualstudiocode&amp;amp;logoColor=white" alt="Install with Docker in VS Code Insiders" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;To run the server in a container, you will need to have &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; installed.&lt;/li&gt; 
 &lt;li&gt;Once Docker is installed, you will also need to ensure Docker is running. The Docker image is available at &lt;code&gt;ghcr.io/github/github-mcp-server&lt;/code&gt;. The image is public; if you get errors on pull, you may have an expired token and need to &lt;code&gt;docker logout ghcr.io&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Lastly you will need to &lt;a href="https://github.com/settings/personal-access-tokens/new"&gt;Create a GitHub Personal Access Token&lt;/a&gt;. The MCP server can use many of the GitHub APIs, so enable the permissions that you feel comfortable granting your AI tools (to learn more about access tokens, please check out the &lt;a href="https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens"&gt;documentation&lt;/a&gt;).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;details&gt;
 &lt;summary&gt;&lt;b&gt;Handling PATs Securely&lt;/b&gt;&lt;/summary&gt; 
 &lt;h3&gt;Environment Variables (Recommended)&lt;/h3&gt; 
 &lt;p&gt;To keep your GitHub PAT secure and reusable across different MCP hosts:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Store your PAT in environment variables&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;export GITHUB_PAT=your_token_here
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or create a &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-env"&gt;GITHUB_PAT=your_token_here
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Protect your &lt;code&gt;.env&lt;/code&gt; file&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Add to .gitignore to prevent accidental commits
echo ".env" &amp;gt;&amp;gt; .gitignore
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reference the token in configurations&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# CLI usage
claude mcp update github -e GITHUB_PERSONAL_ACCESS_TOKEN=$GITHUB_PAT

# In config files (where supported)
"env": {
  "GITHUB_PERSONAL_ACCESS_TOKEN": "$GITHUB_PAT"
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Environment variable support varies by host app and IDE. Some applications (like Windsurf) require hardcoded tokens in config files.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;Token Security Best Practices&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Minimum scopes&lt;/strong&gt;: Only grant necessary permissions 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt; - Repository operations&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;read:packages&lt;/code&gt; - Docker image access&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;read:org&lt;/code&gt; - Organization team access&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Separate tokens&lt;/strong&gt;: Use different PATs for different projects/environments&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Regular rotation&lt;/strong&gt;: Update tokens periodically&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Never commit&lt;/strong&gt;: Keep tokens out of version control&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;File permissions&lt;/strong&gt;: Restrict access to config files containing tokens &lt;pre&gt;&lt;code class="language-bash"&gt;chmod 600 ~/.your-app/config.json
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)&lt;/h3&gt; 
&lt;p&gt;The flag &lt;code&gt;--gh-host&lt;/code&gt; and the environment variable &lt;code&gt;GITHUB_HOST&lt;/code&gt; can be used to set the hostname for GitHub Enterprise Server or GitHub Enterprise Cloud with data residency.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For GitHub Enterprise Server, prefix the hostname with the &lt;code&gt;https://&lt;/code&gt; URI scheme, as it otherwise defaults to &lt;code&gt;http://&lt;/code&gt;, which GitHub Enterprise Server does not support.&lt;/li&gt; 
 &lt;li&gt;For GitHub Enterprise Cloud with data residency, use &lt;code&gt;https://YOURSUBDOMAIN.ghe.com&lt;/code&gt; as the hostname.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"github": {
    "command": "docker",
    "args": [
    "run",
    "-i",
    "--rm",
    "-e",
    "GITHUB_PERSONAL_ACCESS_TOKEN",
    "-e",
    "GITHUB_HOST",
    "ghcr.io/github/github-mcp-server"
    ],
    "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "${input:github_token}",
        "GITHUB_HOST": "https://&amp;lt;your GHES or ghe.com domain name&amp;gt;"
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Install in GitHub Copilot on VS Code&lt;/h3&gt; 
&lt;p&gt;For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start.&lt;/p&gt; 
&lt;p&gt;More about using MCP server tools in VS Code's &lt;a href="https://code.visualstudio.com/docs/copilot/chat/mcp-servers"&gt;agent mode documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Install in GitHub Copilot on other IDEs (JetBrains, Visual Studio, Eclipse, etc.)&lt;/p&gt; 
&lt;p&gt;Add the following JSON block to your IDE's MCP settings.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcp": {
    "inputs": [
      {
        "type": "promptString",
        "id": "github_token",
        "description": "GitHub Personal Access Token",
        "password": true
      }
    ],
    "servers": {
      "github": {
        "command": "docker",
        "args": [
          "run",
          "-i",
          "--rm",
          "-e",
          "GITHUB_PERSONAL_ACCESS_TOKEN",
          "ghcr.io/github/github-mcp-server"
        ],
        "env": {
          "GITHUB_PERSONAL_ACCESS_TOKEN": "${input:github_token}"
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Optionally, you can add a similar example (i.e. without the mcp key) to a file called &lt;code&gt;.vscode/mcp.json&lt;/code&gt; in your workspace. This will allow you to share the configuration with other host applications that accept the same format.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Example JSON block without the MCP key included&lt;/b&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "inputs": [
    {
      "type": "promptString",
      "id": "github_token",
      "description": "GitHub Personal Access Token",
      "password": true
    }
  ],
  "servers": {
    "github": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "GITHUB_PERSONAL_ACCESS_TOKEN",
        "ghcr.io/github/github-mcp-server"
      ],
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "${input:github_token}"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Install in Other MCP Hosts&lt;/h3&gt; 
&lt;p&gt;For other MCP host applications, please refer to our installation guides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides/install-other-copilot-ides.md"&gt;GitHub Copilot in other IDEs&lt;/a&gt;&lt;/strong&gt; - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides/install-claude.md"&gt;Claude Code &amp;amp; Claude Desktop&lt;/a&gt;&lt;/strong&gt; - Installation guide for Claude Code and Claude Desktop&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides/install-cursor.md"&gt;Cursor&lt;/a&gt;&lt;/strong&gt; - Installation guide for Cursor IDE&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides/install-gemini-cli.md"&gt;Google Gemini CLI&lt;/a&gt;&lt;/strong&gt; - Installation guide for Google Gemini CLI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides/install-windsurf.md"&gt;Windsurf&lt;/a&gt;&lt;/strong&gt; - Installation guide for Windsurf IDE&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a complete overview of all installation options, see our &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/installation-guides"&gt;Installation Guides Index&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Any host application that supports local MCP servers should be able to access the local GitHub MCP server. However, the specific configuration process, syntax and stability of the integration will vary by host application. While many may follow a similar format to the examples above, this is not guaranteed. Please refer to your host application's documentation for the correct MCP configuration syntax and setup process.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;p&gt;If you don't have Docker, you can use &lt;code&gt;go build&lt;/code&gt; to build the binary in the &lt;code&gt;cmd/github-mcp-server&lt;/code&gt; directory, and use the &lt;code&gt;github-mcp-server stdio&lt;/code&gt; command with the &lt;code&gt;GITHUB_PERSONAL_ACCESS_TOKEN&lt;/code&gt; environment variable set to your token. To specify the output location of the build, use the &lt;code&gt;-o&lt;/code&gt; flag. You should configure your server to use the built executable as its &lt;code&gt;command&lt;/code&gt;. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-JSON"&gt;{
  "mcp": {
    "servers": {
      "github": {
        "command": "/path/to/github-mcp-server",
        "args": ["stdio"],
        "env": {
          "GITHUB_PERSONAL_ACCESS_TOKEN": "&amp;lt;YOUR_TOKEN&amp;gt;"
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Tool Configuration&lt;/h2&gt; 
&lt;p&gt;The GitHub MCP Server supports enabling or disabling specific groups of functionalities via the &lt;code&gt;--toolsets&lt;/code&gt; flag. This allows you to control which GitHub API capabilities are available to your AI tools. Enabling only the toolsets that you need can help the LLM with tool choice and reduce the context size.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Toolsets are not limited to Tools. Relevant MCP Resources and Prompts are also included where applicable.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;When no toolsets are specified, &lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/#default-toolset"&gt;default toolsets&lt;/a&gt; are used.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Looking for examples?&lt;/strong&gt; See the &lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/server-configuration.md"&gt;Server Configuration Guide&lt;/a&gt; for common recipes like minimal setups, read-only mode, and combining tools with toolsets.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Specifying Toolsets&lt;/h4&gt; 
&lt;p&gt;To specify toolsets you want available to the LLM, you can pass an allow-list in two ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Using Command Line Argument&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;github-mcp-server --toolsets repos,issues,pull_requests,actions,code_security
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Using Environment Variable&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;GITHUB_TOOLSETS="repos,issues,pull_requests,actions,code_security" ./github-mcp-server
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The environment variable &lt;code&gt;GITHUB_TOOLSETS&lt;/code&gt; takes precedence over the command line argument if both are provided.&lt;/p&gt; 
&lt;h4&gt;Specifying Individual Tools&lt;/h4&gt; 
&lt;p&gt;You can also configure specific tools using the &lt;code&gt;--tools&lt;/code&gt; flag. Tools can be used independently or combined with toolsets and dynamic toolsets discovery for fine-grained control.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Using Command Line Argument&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;github-mcp-server --tools get_file_contents,issue_read,create_pull_request
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Using Environment Variable&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;GITHUB_TOOLS="get_file_contents,issue_read,create_pull_request" ./github-mcp-server
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Combining with Toolsets&lt;/strong&gt; (additive):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;github-mcp-server --toolsets repos,issues --tools get_gist
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This registers all tools from &lt;code&gt;repos&lt;/code&gt; and &lt;code&gt;issues&lt;/code&gt; toolsets, plus &lt;code&gt;get_gist&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Combining with Dynamic Toolsets&lt;/strong&gt; (additive):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;github-mcp-server --tools get_file_contents --dynamic-toolsets
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This registers &lt;code&gt;get_file_contents&lt;/code&gt; plus the dynamic toolset tools (&lt;code&gt;enable_toolset&lt;/code&gt;, &lt;code&gt;list_available_toolsets&lt;/code&gt;, &lt;code&gt;get_toolset_tools&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Important Notes:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tools, toolsets, and dynamic toolsets can all be used together&lt;/li&gt; 
 &lt;li&gt;Read-only mode takes priority: write tools are skipped if &lt;code&gt;--read-only&lt;/code&gt; is set, even if explicitly requested via &lt;code&gt;--tools&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Tool names must match exactly (e.g., &lt;code&gt;get_file_contents&lt;/code&gt;, not &lt;code&gt;getFileContents&lt;/code&gt;). Invalid tool names will cause the server to fail at startup with an error message&lt;/li&gt; 
 &lt;li&gt;When tools are renamed, old names are preserved as aliases for backward compatibility. See &lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/docs/deprecated-tool-aliases.md"&gt;Deprecated Tool Aliases&lt;/a&gt; for details.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Using Toolsets With Docker&lt;/h3&gt; 
&lt;p&gt;When using Docker, you can pass the toolsets as environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&amp;lt;your-token&amp;gt; \
  -e GITHUB_TOOLSETS="repos,issues,pull_requests,actions,code_security" \
  ghcr.io/github/github-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Tools With Docker&lt;/h3&gt; 
&lt;p&gt;When using Docker, you can pass specific tools as environment variables. You can also combine tools with toolsets:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Tools only
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&amp;lt;your-token&amp;gt; \
  -e GITHUB_TOOLS="get_file_contents,issue_read,create_pull_request" \
  ghcr.io/github/github-mcp-server

# Tools combined with toolsets (additive)
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&amp;lt;your-token&amp;gt; \
  -e GITHUB_TOOLSETS="repos,issues" \
  -e GITHUB_TOOLS="get_gist" \
  ghcr.io/github/github-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Special toolsets&lt;/h3&gt; 
&lt;h4&gt;"all" toolset&lt;/h4&gt; 
&lt;p&gt;The special toolset &lt;code&gt;all&lt;/code&gt; can be provided to enable all available toolsets regardless of any other configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./github-mcp-server --toolsets all
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or using the environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;GITHUB_TOOLSETS="all" ./github-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;"default" toolset&lt;/h4&gt; 
&lt;p&gt;The default toolset &lt;code&gt;default&lt;/code&gt; is the configuration that gets passed to the server if no toolsets are specified.&lt;/p&gt; 
&lt;p&gt;The default configuration is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;context&lt;/li&gt; 
 &lt;li&gt;repos&lt;/li&gt; 
 &lt;li&gt;issues&lt;/li&gt; 
 &lt;li&gt;pull_requests&lt;/li&gt; 
 &lt;li&gt;users&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To keep the default configuration and add additional toolsets:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;GITHUB_TOOLSETS="default,stargazers" ./github-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Available Toolsets&lt;/h3&gt; 
&lt;p&gt;The following sets of tools are available:&lt;/p&gt; 
&lt;!-- START AUTOMATED TOOLSETS --&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Toolset&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/person-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/person-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/person-light.png" width="20" height="20" alt="person" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;context&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Strongly recommended&lt;/strong&gt;: Tools that provide context about the current user and GitHub context you are operating in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/workflow-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/workflow-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/workflow-light.png" width="20" height="20" alt="workflow" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;actions&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Actions workflows and CI/CD operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/codescan-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/codescan-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/codescan-light.png" width="20" height="20" alt="codescan" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;code_security&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Code security related tools, such as GitHub Code Scanning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/dependabot-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/dependabot-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/dependabot-light.png" width="20" height="20" alt="dependabot" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;dependabot&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dependabot tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/comment-discussion-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/comment-discussion-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/comment-discussion-light.png" width="20" height="20" alt="comment-discussion" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;discussions&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Discussions related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/logo-gist-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/logo-gist-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/logo-gist-light.png" width="20" height="20" alt="logo-gist" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;gists&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Gist related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/git-branch-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/git-branch-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/git-branch-light.png" width="20" height="20" alt="git-branch" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;git&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Git API related tools for low-level Git operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/issue-opened-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/issue-opened-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/issue-opened-light.png" width="20" height="20" alt="issue-opened" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;issues&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Issues related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/tag-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/tag-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/tag-light.png" width="20" height="20" alt="tag" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;labels&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Labels related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/bell-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/bell-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/bell-light.png" width="20" height="20" alt="bell" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;notifications&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Notifications related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/organization-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/organization-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/organization-light.png" width="20" height="20" alt="organization" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;orgs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Organization related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/project-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/project-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/project-light.png" width="20" height="20" alt="project" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;projects&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Projects related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/git-pull-request-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/git-pull-request-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/git-pull-request-light.png" width="20" height="20" alt="git-pull-request" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;pull_requests&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Pull Request related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/repo-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/repo-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/repo-light.png" width="20" height="20" alt="repo" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;repos&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Repository related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/shield-lock-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/shield-lock-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/shield-lock-light.png" width="20" height="20" alt="shield-lock" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;secret_protection&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Secret protection related tools, such as GitHub Secret Scanning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/shield-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/shield-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/shield-light.png" width="20" height="20" alt="shield" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;security_advisories&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Security advisories related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/star-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/star-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/star-light.png" width="20" height="20" alt="star" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;stargazers&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub Stargazers related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;
    &lt;picture&gt;
     &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/people-dark.png" /&gt;
     &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/people-light.png" /&gt;
     &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/people-light.png" width="20" height="20" alt="people" /&gt;
    &lt;/picture&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;users&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GitHub User related tools&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;!-- END AUTOMATED TOOLSETS --&gt; 
&lt;h3&gt;Additional Toolsets in Remote GitHub MCP Server&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Toolset&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;copilot&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Copilot related tools (e.g. Copilot Coding Agent)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;copilot_spaces&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Copilot Spaces related tools&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;github_support_docs_search&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Search docs to answer GitHub product and support questions&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Tools&lt;/h2&gt; 
&lt;!-- START AUTOMATED TOOLS --&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/workflow-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/workflow-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/workflow-light.png" width="20" height="20" alt="workflow" /&gt;
  &lt;/picture&gt; Actions&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;cancel_workflow_run&lt;/strong&gt; - Cancel workflow run&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;run_id&lt;/code&gt;: The unique identifier of the workflow run (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;delete_workflow_run_logs&lt;/strong&gt; - Delete workflow logs&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;run_id&lt;/code&gt;: The unique identifier of the workflow run (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;download_workflow_run_artifact&lt;/strong&gt; - Download workflow artifact&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;artifact_id&lt;/code&gt;: The unique identifier of the artifact (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_job_logs&lt;/strong&gt; - Get job logs&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;failed_only&lt;/code&gt;: When true, gets logs for all failed jobs in run_id (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;job_id&lt;/code&gt;: The unique identifier of the workflow job (required for single job logs) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;return_content&lt;/code&gt;: Returns actual log content instead of URLs (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;run_id&lt;/code&gt;: Workflow run ID (required when using failed_only) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;tail_lines&lt;/code&gt;: Number of lines to return from the end of the log (number, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_workflow_run&lt;/strong&gt; - Get workflow run&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;run_id&lt;/code&gt;: The unique identifier of the workflow run (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_workflow_run_logs&lt;/strong&gt; - Get workflow run logs&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;run_id&lt;/code&gt;: The unique identifier of the workflow run (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_workflow_run_usage&lt;/strong&gt; - Get workflow usage&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;run_id&lt;/code&gt;: The unique identifier of the workflow run (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_workflow_jobs&lt;/strong&gt; - List workflow jobs&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;filter&lt;/code&gt;: Filters jobs by their completed_at timestamp (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;run_id&lt;/code&gt;: The unique identifier of the workflow run (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_workflow_run_artifacts&lt;/strong&gt; - List workflow artifacts&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;run_id&lt;/code&gt;: The unique identifier of the workflow run (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_workflow_runs&lt;/strong&gt; - List workflow runs&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;actor&lt;/code&gt;: Returns someone's workflow runs. Use the login for the user who created the workflow run. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;branch&lt;/code&gt;: Returns workflow runs associated with a branch. Use the name of the branch. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;event&lt;/code&gt;: Returns workflow runs for a specific event type (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;status&lt;/code&gt;: Returns workflow runs with the check run status (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;workflow_id&lt;/code&gt;: The workflow ID or workflow file name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_workflows&lt;/strong&gt; - List workflows&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;rerun_failed_jobs&lt;/strong&gt; - Rerun failed jobs&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;run_id&lt;/code&gt;: The unique identifier of the workflow run (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;rerun_workflow_run&lt;/strong&gt; - Rerun workflow run&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;run_id&lt;/code&gt;: The unique identifier of the workflow run (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;run_workflow&lt;/strong&gt; - Run workflow&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;inputs&lt;/code&gt;: Inputs the workflow accepts (object, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;ref&lt;/code&gt;: The git reference for the workflow. The reference can be a branch or tag name. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;workflow_id&lt;/code&gt;: The workflow ID (numeric) or workflow file name (e.g., main.yml, ci.yaml) (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/codescan-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/codescan-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/codescan-light.png" width="20" height="20" alt="codescan" /&gt;
  &lt;/picture&gt; Code Security&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_code_scanning_alert&lt;/strong&gt; - Get code scanning alert&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;, &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;alertNumber&lt;/code&gt;: The number of the alert. (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: The owner of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: The name of the repository. (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_code_scanning_alerts&lt;/strong&gt; - List code scanning alerts&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;, &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: The owner of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;ref&lt;/code&gt;: The Git reference for the results you want to list. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: The name of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;severity&lt;/code&gt;: Filter code scanning alerts by severity (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: Filter code scanning alerts by state. Defaults to open (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;tool_name&lt;/code&gt;: The name of the tool used for code scanning. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/person-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/person-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/person-light.png" width="20" height="20" alt="person" /&gt;
  &lt;/picture&gt; Context&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_me&lt;/strong&gt; - Get my user profile&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;No parameters required&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_team_members&lt;/strong&gt; - Get team members&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;read:org&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;admin:org&lt;/code&gt;, &lt;code&gt;read:org&lt;/code&gt;, &lt;code&gt;write:org&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;org&lt;/code&gt;: Organization login (owner) that contains the team. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;team_slug&lt;/code&gt;: Team slug (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_teams&lt;/strong&gt; - Get teams&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;read:org&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;admin:org&lt;/code&gt;, &lt;code&gt;read:org&lt;/code&gt;, &lt;code&gt;write:org&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;user&lt;/code&gt;: Username to get teams for. If not provided, uses the authenticated user. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/dependabot-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/dependabot-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/dependabot-light.png" width="20" height="20" alt="dependabot" /&gt;
  &lt;/picture&gt; Dependabot&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_dependabot_alert&lt;/strong&gt; - Get dependabot alert&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;, &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;alertNumber&lt;/code&gt;: The number of the alert. (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: The owner of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: The name of the repository. (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_dependabot_alerts&lt;/strong&gt; - List dependabot alerts&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;, &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: The owner of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: The name of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;severity&lt;/code&gt;: Filter dependabot alerts by severity (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: Filter dependabot alerts by state. Defaults to open (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/comment-discussion-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/comment-discussion-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/comment-discussion-light.png" width="20" height="20" alt="comment-discussion" /&gt;
  &lt;/picture&gt; Discussions&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_discussion&lt;/strong&gt; - Get discussion&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;discussionNumber&lt;/code&gt;: Discussion Number (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_discussion_comments&lt;/strong&gt; - Get discussion comments&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;after&lt;/code&gt;: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;discussionNumber&lt;/code&gt;: Discussion Number (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_discussion_categories&lt;/strong&gt; - List discussion categories&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name. If not provided, discussion categories will be queried at the organisation level. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_discussions&lt;/strong&gt; - List discussions&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;after&lt;/code&gt;: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;category&lt;/code&gt;: Optional filter by discussion category ID. If provided, only discussions with this category are listed. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;direction&lt;/code&gt;: Order direction. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;orderBy&lt;/code&gt;: Order discussions by field. If provided, the 'direction' also needs to be provided. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name. If not provided, discussions will be queried at the organisation level. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/logo-gist-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/logo-gist-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/logo-gist-light.png" width="20" height="20" alt="logo-gist" /&gt;
  &lt;/picture&gt; Gists&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;create_gist&lt;/strong&gt; - Create Gist&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;gist&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;content&lt;/code&gt;: Content for simple single-file gist creation (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;description&lt;/code&gt;: Description of the gist (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;filename&lt;/code&gt;: Filename for simple single-file gist creation (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;public&lt;/code&gt;: Whether the gist is public (boolean, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_gist&lt;/strong&gt; - Get Gist Content&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;gist_id&lt;/code&gt;: The ID of the gist (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_gists&lt;/strong&gt; - List Gists&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;since&lt;/code&gt;: Only gists updated after this time (ISO 8601 timestamp) (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;username&lt;/code&gt;: GitHub username (omit for authenticated user's gists) (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;update_gist&lt;/strong&gt; - Update Gist&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;gist&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;content&lt;/code&gt;: Content for the file (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;description&lt;/code&gt;: Updated description of the gist (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;filename&lt;/code&gt;: Filename to update or create (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;gist_id&lt;/code&gt;: ID of the gist to update (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/git-branch-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/git-branch-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/git-branch-light.png" width="20" height="20" alt="git-branch" /&gt;
  &lt;/picture&gt; Git&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;get_repository_tree&lt;/strong&gt; - Get repository tree 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (username or organization) (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;path_filter&lt;/code&gt;: Optional path prefix to filter the tree results (e.g., 'src/' to only show files in the src directory) (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;recursive&lt;/code&gt;: Setting this parameter to true returns the objects or subtrees referenced by the tree. Default is false (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;tree_sha&lt;/code&gt;: The SHA1 value or ref (branch or tag) name of the tree. Defaults to the repository's default branch (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/issue-opened-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/issue-opened-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/issue-opened-light.png" width="20" height="20" alt="issue-opened" /&gt;
  &lt;/picture&gt; Issues&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;add_issue_comment&lt;/strong&gt; - Add comment to issue&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;body&lt;/code&gt;: Comment content (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;issue_number&lt;/code&gt;: Issue number to comment on (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;assign_copilot_to_issue&lt;/strong&gt; - Assign Copilot to issue&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;base_ref&lt;/code&gt;: Git reference (e.g., branch) that the agent will start its work from. If not specified, defaults to the repository's default branch (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;custom_instructions&lt;/code&gt;: Optional custom instructions to guide the agent beyond the issue body. Use this to provide additional context, constraints, or guidance that is not captured in the issue description (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;issue_number&lt;/code&gt;: Issue number (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_label&lt;/strong&gt; - Get a specific label from a repository.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;name&lt;/code&gt;: Label name. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (username or organization name) (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;issue_read&lt;/strong&gt; - Get issue details&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;issue_number&lt;/code&gt;: The number of the issue (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;method&lt;/code&gt;: The read operation to perform on a single issue. Options are: 
     &lt;ol&gt; 
      &lt;li&gt;get - Get details of a specific issue.&lt;/li&gt; 
      &lt;li&gt;get_comments - Get issue comments.&lt;/li&gt; 
      &lt;li&gt;get_sub_issues - Get sub-issues of the issue.&lt;/li&gt; 
      &lt;li&gt;get_labels - Get labels assigned to the issue. (string, required)&lt;/li&gt; 
     &lt;/ol&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: The owner of the repository (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: The name of the repository (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;issue_write&lt;/strong&gt; - Create or update issue.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;assignees&lt;/code&gt;: Usernames to assign to this issue (string[], optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;body&lt;/code&gt;: Issue body content (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;duplicate_of&lt;/code&gt;: Issue number that this issue is a duplicate of. Only used when state_reason is 'duplicate'. (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;issue_number&lt;/code&gt;: Issue number to update (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;labels&lt;/code&gt;: Labels to apply to this issue (string[], optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;method&lt;/code&gt;: Write operation to perform on a single issue. Options are: 
     &lt;ul&gt; 
      &lt;li&gt;'create' - creates a new issue.&lt;/li&gt; 
      &lt;li&gt;'update' - updates an existing issue. (string, required)&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;milestone&lt;/code&gt;: Milestone number (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: New state (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;state_reason&lt;/code&gt;: Reason for the state change. Ignored unless state is changed. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;title&lt;/code&gt;: Issue title (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: Type of this issue. Only use if the repository has issue types configured. Use list_issue_types tool to get valid type values for the organization. If the repository doesn't support issue types, omit this parameter. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_issue_types&lt;/strong&gt; - List available issue types&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;read:org&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;admin:org&lt;/code&gt;, &lt;code&gt;read:org&lt;/code&gt;, &lt;code&gt;write:org&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: The organization owner of the repository (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_issues&lt;/strong&gt; - List issues&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;after&lt;/code&gt;: Cursor for pagination. Use the endCursor from the previous page's PageInfo for GraphQL APIs. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;direction&lt;/code&gt;: Order direction. If provided, the 'orderBy' also needs to be provided. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;labels&lt;/code&gt;: Filter by labels (string[], optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;orderBy&lt;/code&gt;: Order issues by field. If provided, the 'direction' also needs to be provided. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;since&lt;/code&gt;: Filter by date (ISO 8601 timestamp) (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: Filter by state, by default both open and closed issues are returned when not provided (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;search_issues&lt;/strong&gt; - Search issues&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;order&lt;/code&gt;: Sort order (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Optional repository owner. If provided with repo, only issues for this repository are listed. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;query&lt;/code&gt;: Search query using GitHub issues search syntax (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Optional repository name. If provided with owner, only issues for this repository are listed. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sort&lt;/code&gt;: Sort field by number of matches of categories, defaults to best match (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;sub_issue_write&lt;/strong&gt; - Change sub-issue&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;after_id&lt;/code&gt;: The ID of the sub-issue to be prioritized after (either after_id OR before_id should be specified) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;before_id&lt;/code&gt;: The ID of the sub-issue to be prioritized before (either after_id OR before_id should be specified) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;issue_number&lt;/code&gt;: The number of the parent issue (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;method&lt;/code&gt;: The action to perform on a single sub-issue Options are: 
     &lt;ul&gt; 
      &lt;li&gt;'add' - add a sub-issue to a parent issue in a GitHub repository.&lt;/li&gt; 
      &lt;li&gt;'remove' - remove a sub-issue from a parent issue in a GitHub repository.&lt;/li&gt; 
      &lt;li&gt;'reprioritize' - change the order of sub-issues within a parent issue in a GitHub repository. Use either 'after_id' or 'before_id' to specify the new position. (string, required)&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;replace_parent&lt;/code&gt;: When true, replaces the sub-issue's current parent issue. Use with 'add' method only. (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sub_issue_id&lt;/code&gt;: The ID of the sub-issue to add. ID is not the same as issue number (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/tag-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/tag-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/tag-light.png" width="20" height="20" alt="tag" /&gt;
  &lt;/picture&gt; Labels&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_label&lt;/strong&gt; - Get a specific label from a repository.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;name&lt;/code&gt;: Label name. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (username or organization name) (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;label_write&lt;/strong&gt; - Write operations on repository labels.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;color&lt;/code&gt;: Label color as 6-character hex code without '#' prefix (e.g., 'f29513'). Required for 'create', optional for 'update'. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;description&lt;/code&gt;: Label description text. Optional for 'create' and 'update'. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;method&lt;/code&gt;: Operation to perform: 'create', 'update', or 'delete' (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;name&lt;/code&gt;: Label name - required for all operations (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;new_name&lt;/code&gt;: New name for the label (used only with 'update' method to rename) (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (username or organization name) (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_label&lt;/strong&gt; - List labels from a repository&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (username or organization name) - required for all operations (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name - required for all operations (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/bell-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/bell-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/bell-light.png" width="20" height="20" alt="bell" /&gt;
  &lt;/picture&gt; Notifications&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;dismiss_notification&lt;/strong&gt; - Dismiss notification&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;notifications&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: The new state of the notification (read/done) (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;threadID&lt;/code&gt;: The ID of the notification thread (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_notification_details&lt;/strong&gt; - Get notification details&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;notifications&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;notificationID&lt;/code&gt;: The ID of the notification (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_notifications&lt;/strong&gt; - List notifications&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;notifications&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;before&lt;/code&gt;: Only show notifications updated before the given time (ISO 8601 format) (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;filter&lt;/code&gt;: Filter notifications to, use default unless specified. Read notifications are ones that have already been acknowledged by the user. Participating notifications are those that the user is directly involved in, such as issues or pull requests they have commented on or created. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Optional repository owner. If provided with repo, only notifications for this repository are listed. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Optional repository name. If provided with owner, only notifications for this repository are listed. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;since&lt;/code&gt;: Only show notifications updated after the given time (ISO 8601 format) (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;manage_notification_subscription&lt;/strong&gt; - Manage notification subscription&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;notifications&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;action&lt;/code&gt;: Action to perform: ignore, watch, or delete the notification subscription. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;notificationID&lt;/code&gt;: The ID of the notification thread. (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;manage_repository_notification_subscription&lt;/strong&gt; - Manage repository notification subscription&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;notifications&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;action&lt;/code&gt;: Action to perform: ignore, watch, or delete the repository notification subscription. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: The account owner of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: The name of the repository. (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;mark_all_notifications_read&lt;/strong&gt; - Mark all notifications as read&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;notifications&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;lastReadAt&lt;/code&gt;: Describes the last point that notifications were checked (optional). Default: Now (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Optional repository owner. If provided with repo, only notifications for this repository are marked as read. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Optional repository name. If provided with owner, only notifications for this repository are marked as read. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/organization-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/organization-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/organization-light.png" width="20" height="20" alt="organization" /&gt;
  &lt;/picture&gt; Organizations&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;search_orgs&lt;/strong&gt; - Search organizations 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;read:org&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;admin:org&lt;/code&gt;, &lt;code&gt;read:org&lt;/code&gt;, &lt;code&gt;write:org&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;order&lt;/code&gt;: Sort order (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;query&lt;/code&gt;: Organization search query. Examples: 'microsoft', 'location:california', 'created:&amp;gt;=2025-01-01'. Search is automatically scoped to type:org. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sort&lt;/code&gt;: Sort field by category (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/project-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/project-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/project-light.png" width="20" height="20" alt="project" /&gt;
  &lt;/picture&gt; Projects&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;add_project_item&lt;/strong&gt; - Add project item&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;item_id&lt;/code&gt;: The numeric ID of the issue or pull request to add to the project. (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;item_type&lt;/code&gt;: The item's type, either issue or pull_request. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner_type&lt;/code&gt;: Owner type (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;project_number&lt;/code&gt;: The project's number. (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;delete_project_item&lt;/strong&gt; - Delete project item&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;item_id&lt;/code&gt;: The internal project item ID to delete from the project (not the issue or pull request ID). (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner_type&lt;/code&gt;: Owner type (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;project_number&lt;/code&gt;: The project's number. (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_project&lt;/strong&gt; - Get project&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;project&lt;/code&gt;, &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner_type&lt;/code&gt;: Owner type (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;project_number&lt;/code&gt;: The project's number (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_project_field&lt;/strong&gt; - Get project field&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;project&lt;/code&gt;, &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;field_id&lt;/code&gt;: The field's id. (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner_type&lt;/code&gt;: Owner type (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;project_number&lt;/code&gt;: The project's number. (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_project_item&lt;/strong&gt; - Get project item&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;project&lt;/code&gt;, &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;fields&lt;/code&gt;: Specific list of field IDs to include in the response (e.g. ["102589", "985201", "169875"]). If not provided, only the title field is included. (string[], optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;item_id&lt;/code&gt;: The item's ID. (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner_type&lt;/code&gt;: Owner type (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;project_number&lt;/code&gt;: The project's number. (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_project_fields&lt;/strong&gt; - List project fields&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;project&lt;/code&gt;, &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;after&lt;/code&gt;: Forward pagination cursor from previous pageInfo.nextCursor. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;before&lt;/code&gt;: Backward pagination cursor from previous pageInfo.prevCursor (rare). (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner_type&lt;/code&gt;: Owner type (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;per_page&lt;/code&gt;: Results per page (max 50) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;project_number&lt;/code&gt;: The project's number. (number, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_project_items&lt;/strong&gt; - List project items&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;project&lt;/code&gt;, &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;after&lt;/code&gt;: Forward pagination cursor from previous pageInfo.nextCursor. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;before&lt;/code&gt;: Backward pagination cursor from previous pageInfo.prevCursor (rare). (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;fields&lt;/code&gt;: Field IDs to include (e.g. ["102589", "985201"]). CRITICAL: Always provide to get field values. Without this, only titles returned. (string[], optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner_type&lt;/code&gt;: Owner type (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;per_page&lt;/code&gt;: Results per page (max 50) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;project_number&lt;/code&gt;: The project's number. (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;query&lt;/code&gt;: Query string for advanced filtering of project items using GitHub's project filtering syntax. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_projects&lt;/strong&gt; - List projects&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;project&lt;/code&gt;, &lt;code&gt;read:project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;after&lt;/code&gt;: Forward pagination cursor from previous pageInfo.nextCursor. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;before&lt;/code&gt;: Backward pagination cursor from previous pageInfo.prevCursor (rare). (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner_type&lt;/code&gt;: Owner type (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;per_page&lt;/code&gt;: Results per page (max 50) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;query&lt;/code&gt;: Filter projects by title text and open/closed state; permitted qualifiers: is:open, is:closed; examples: "roadmap is:open", "is:open feature planning". (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;update_project_item&lt;/strong&gt; - Update project item&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;project&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;item_id&lt;/code&gt;: The unique identifier of the project item. This is not the issue or pull request ID. (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: If owner_type == user it is the handle for the GitHub user account. If owner_type == org it is the name of the organization. The name is not case sensitive. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner_type&lt;/code&gt;: Owner type (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;project_number&lt;/code&gt;: The project's number. (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;updated_field&lt;/code&gt;: Object consisting of the ID of the project field to update and the new value for the field. To clear the field, set value to null. Example: {"id": 123456, "value": "New Value"} (object, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/git-pull-request-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/git-pull-request-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/git-pull-request-light.png" width="20" height="20" alt="git-pull-request" /&gt;
  &lt;/picture&gt; Pull Requests&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;add_comment_to_pending_review&lt;/strong&gt; - Add review comment to the requester's latest pending pull request review&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;body&lt;/code&gt;: The text of the review comment (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;line&lt;/code&gt;: The line of the blob in the pull request diff that the comment applies to. For multi-line comments, the last line of the range (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;path&lt;/code&gt;: The relative path to the file that necessitates a comment (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;pullNumber&lt;/code&gt;: Pull request number (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;side&lt;/code&gt;: The side of the diff to comment on. LEFT indicates the previous state, RIGHT indicates the new state (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;startLine&lt;/code&gt;: For multi-line comments, the first line of the range that the comment applies to (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;startSide&lt;/code&gt;: For multi-line comments, the starting side of the diff that the comment applies to. LEFT indicates the previous state, RIGHT indicates the new state (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;subjectType&lt;/code&gt;: The level at which the comment is targeted (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;create_pull_request&lt;/strong&gt; - Open new pull request&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;base&lt;/code&gt;: Branch to merge into (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;body&lt;/code&gt;: PR description (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;draft&lt;/code&gt;: Create as draft PR (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;head&lt;/code&gt;: Branch containing changes (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;maintainer_can_modify&lt;/code&gt;: Allow maintainer edits (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;title&lt;/code&gt;: PR title (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_pull_requests&lt;/strong&gt; - List pull requests&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;base&lt;/code&gt;: Filter by base branch (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;direction&lt;/code&gt;: Sort direction (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;head&lt;/code&gt;: Filter by head user/org and branch (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sort&lt;/code&gt;: Sort by (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: Filter by state (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;merge_pull_request&lt;/strong&gt; - Merge pull request&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;commit_message&lt;/code&gt;: Extra detail for merge commit (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;commit_title&lt;/code&gt;: Title for merge commit (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;merge_method&lt;/code&gt;: Merge method (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;pullNumber&lt;/code&gt;: Pull request number (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;pull_request_read&lt;/strong&gt; - Get details for a single pull request&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;method&lt;/code&gt;: Action to specify what pull request data needs to be retrieved from GitHub. Possible options: 
     &lt;ol&gt; 
      &lt;li&gt;get - Get details of a specific pull request.&lt;/li&gt; 
      &lt;li&gt;get_diff - Get the diff of a pull request.&lt;/li&gt; 
      &lt;li&gt;get_status - Get status of a head commit in a pull request. This reflects status of builds and checks.&lt;/li&gt; 
      &lt;li&gt;get_files - Get the list of files changed in a pull request. Use with pagination parameters to control the number of results returned.&lt;/li&gt; 
      &lt;li&gt;get_review_comments - Get review threads on a pull request. Each thread contains logically grouped review comments made on the same code location during pull request reviews. Returns threads with metadata (isResolved, isOutdated, isCollapsed) and their associated comments. Use cursor-based pagination (perPage, after) to control results.&lt;/li&gt; 
      &lt;li&gt;get_reviews - Get the reviews on a pull request. When asked for review comments, use get_review_comments method.&lt;/li&gt; 
      &lt;li&gt;get_comments - Get comments on a pull request. Use this if user doesn't specifically want review comments. Use with pagination parameters to control the number of results returned. (string, required)&lt;/li&gt; 
     &lt;/ol&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;pullNumber&lt;/code&gt;: Pull request number (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;pull_request_review_write&lt;/strong&gt; - Write operations (create, submit, delete) on pull request reviews.&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;body&lt;/code&gt;: Review comment text (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;commitID&lt;/code&gt;: SHA of commit to review (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;event&lt;/code&gt;: Review action to perform. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;method&lt;/code&gt;: The write operation to perform on pull request review. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;pullNumber&lt;/code&gt;: Pull request number (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;request_copilot_review&lt;/strong&gt; - Request Copilot review&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;pullNumber&lt;/code&gt;: Pull request number (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;search_pull_requests&lt;/strong&gt; - Search pull requests&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;order&lt;/code&gt;: Sort order (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Optional repository owner. If provided with repo, only pull requests for this repository are listed. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;query&lt;/code&gt;: Search query using GitHub pull request search syntax (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Optional repository name. If provided with owner, only pull requests for this repository are listed. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sort&lt;/code&gt;: Sort field by number of matches of categories, defaults to best match (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;update_pull_request&lt;/strong&gt; - Edit pull request&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;base&lt;/code&gt;: New base branch name (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;body&lt;/code&gt;: New description (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;draft&lt;/code&gt;: Mark pull request as draft (true) or ready for review (false) (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;maintainer_can_modify&lt;/code&gt;: Allow maintainer edits (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;pullNumber&lt;/code&gt;: Pull request number to update (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;reviewers&lt;/code&gt;: GitHub usernames to request reviews from (string[], optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: New state (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;title&lt;/code&gt;: New title (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;update_pull_request_branch&lt;/strong&gt; - Update pull request branch&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;expectedHeadSha&lt;/code&gt;: The expected SHA of the pull request's HEAD ref (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;pullNumber&lt;/code&gt;: Pull request number (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/repo-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/repo-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/repo-light.png" width="20" height="20" alt="repo" /&gt;
  &lt;/picture&gt; Repositories&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;create_branch&lt;/strong&gt; - Create branch&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;branch&lt;/code&gt;: Name for new branch (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;from_branch&lt;/code&gt;: Source branch (defaults to repo default) (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;create_or_update_file&lt;/strong&gt; - Create or update file&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;branch&lt;/code&gt;: Branch to create/update the file in (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;content&lt;/code&gt;: Content of the file (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;message&lt;/code&gt;: Commit message (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (username or organization) (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;path&lt;/code&gt;: Path where to create/update the file (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sha&lt;/code&gt;: The blob SHA of the file being replaced. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;create_repository&lt;/strong&gt; - Create repository&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;autoInit&lt;/code&gt;: Initialize with README (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;description&lt;/code&gt;: Repository description (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;name&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;organization&lt;/code&gt;: Organization to create the repository in (omit to create in your personal account) (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;private&lt;/code&gt;: Whether repo should be private (boolean, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;delete_file&lt;/strong&gt; - Delete file&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;branch&lt;/code&gt;: Branch to delete the file from (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;message&lt;/code&gt;: Commit message (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (username or organization) (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;path&lt;/code&gt;: Path to the file to delete (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;fork_repository&lt;/strong&gt; - Fork repository&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;organization&lt;/code&gt;: Organization to fork to (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_commit&lt;/strong&gt; - Get commit details&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;include_diff&lt;/code&gt;: Whether to include file diffs and stats in the response. Default is true. (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sha&lt;/code&gt;: Commit SHA, branch name, or tag name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_file_contents&lt;/strong&gt; - Get file or directory contents&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (username or organization) (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;path&lt;/code&gt;: Path to file/directory (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;ref&lt;/code&gt;: Accepts optional git refs such as &lt;code&gt;refs/tags/{tag}&lt;/code&gt;, &lt;code&gt;refs/heads/{branch}&lt;/code&gt; or &lt;code&gt;refs/pull/{pr_number}/head&lt;/code&gt; (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sha&lt;/code&gt;: Accepts optional commit SHA. If specified, it will be used instead of ref (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_latest_release&lt;/strong&gt; - Get latest release&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_release_by_tag&lt;/strong&gt; - Get a release by tag name&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;tag&lt;/code&gt;: Tag name (e.g., 'v1.0.0') (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_tag&lt;/strong&gt; - Get tag details&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;tag&lt;/code&gt;: Tag name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_branches&lt;/strong&gt; - List branches&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_commits&lt;/strong&gt; - List commits&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;author&lt;/code&gt;: Author username or email address to filter commits by (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sha&lt;/code&gt;: Commit SHA, branch or tag name to list commits of. If not provided, uses the default branch of the repository. If a commit SHA is provided, will list commits up to that SHA. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_releases&lt;/strong&gt; - List releases&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_tags&lt;/strong&gt; - List tags&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;push_files&lt;/strong&gt; - Push files to repository&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;branch&lt;/code&gt;: Branch to push to (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;files&lt;/code&gt;: Array of file objects to push, each object with path (string) and content (string) (object[], required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;message&lt;/code&gt;: Commit message (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;search_code&lt;/strong&gt; - Search code&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;order&lt;/code&gt;: Sort order for results (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;query&lt;/code&gt;: Search query using GitHub's powerful code search syntax. Examples: 'content:Skill language:Java org:github', 'NOT is:archived language:Python OR language:go', 'repo:github/github-mcp-server'. Supports exact matching, language filters, path filters, and more. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sort&lt;/code&gt;: Sort field ('indexed' only) (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;search_repositories&lt;/strong&gt; - Search repositories&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;minimal_output&lt;/code&gt;: Return minimal repository information (default: true). When false, returns full GitHub API repository objects. (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;order&lt;/code&gt;: Sort order (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;query&lt;/code&gt;: Repository search query. Examples: 'machine learning in:name stars:&amp;gt;1000 language:python', 'topic:react', 'user:facebook'. Supports advanced search syntax for precise filtering. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sort&lt;/code&gt;: Sort repositories by field, defaults to best match (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/shield-lock-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/shield-lock-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/shield-lock-light.png" width="20" height="20" alt="shield-lock" /&gt;
  &lt;/picture&gt; Secret Protection&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_secret_scanning_alert&lt;/strong&gt; - Get secret scanning alert&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;, &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;alertNumber&lt;/code&gt;: The number of the alert. (number, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: The owner of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: The name of the repository. (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_secret_scanning_alerts&lt;/strong&gt; - List secret scanning alerts&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;, &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: The owner of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: The name of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;resolution&lt;/code&gt;: Filter by resolution (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;secret_type&lt;/code&gt;: A comma-separated list of secret types to return. All default secret patterns are returned. To return generic patterns, pass the token name(s) in the parameter. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: Filter by state (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/shield-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/shield-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/shield-light.png" width="20" height="20" alt="shield" /&gt;
  &lt;/picture&gt; Security Advisories&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_global_security_advisory&lt;/strong&gt; - Get a global security advisory&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;, &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;ghsaId&lt;/code&gt;: GitHub Security Advisory ID (format: GHSA-xxxx-xxxx-xxxx). (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_global_security_advisories&lt;/strong&gt; - List global security advisories&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;, &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;affects&lt;/code&gt;: Filter advisories by affected package or version (e.g. "package1,package2@1.0.0"). (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;cveId&lt;/code&gt;: Filter by CVE ID. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;cwes&lt;/code&gt;: Filter by Common Weakness Enumeration IDs (e.g. ["79", "284", "22"]). (string[], optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;ecosystem&lt;/code&gt;: Filter by package ecosystem. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;ghsaId&lt;/code&gt;: Filter by GitHub Security Advisory ID (format: GHSA-xxxx-xxxx-xxxx). (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;isWithdrawn&lt;/code&gt;: Whether to only return withdrawn advisories. (boolean, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;modified&lt;/code&gt;: Filter by publish or update date or date range (ISO 8601 date or range). (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;published&lt;/code&gt;: Filter by publish date or date range (ISO 8601 date or range). (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;severity&lt;/code&gt;: Filter by severity. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: Advisory type. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;updated&lt;/code&gt;: Filter by update date or date range (ISO 8601 date or range). (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_org_repository_security_advisories&lt;/strong&gt; - List org repository security advisories&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;, &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;direction&lt;/code&gt;: Sort direction. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;org&lt;/code&gt;: The organization login. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sort&lt;/code&gt;: Sort field. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: Filter by advisory state. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_repository_security_advisories&lt;/strong&gt; - List repository security advisories&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Accepted OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;, &lt;code&gt;security_events&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;direction&lt;/code&gt;: Sort direction. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: The owner of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: The name of the repository. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sort&lt;/code&gt;: Sort field. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;state&lt;/code&gt;: Filter by advisory state. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/star-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/star-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/star-light.png" width="20" height="20" alt="star" /&gt;
  &lt;/picture&gt; Stargazers&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_starred_repositories&lt;/strong&gt; - List starred repositories&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;direction&lt;/code&gt;: The direction to sort the results by. (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sort&lt;/code&gt;: How to sort the results. Can be either 'created' (when the repository was starred) or 'updated' (when the repository was last pushed to). (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;username&lt;/code&gt;: Username to list starred repositories for. Defaults to the authenticated user. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;star_repository&lt;/strong&gt; - Star repository&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;unstar_repository&lt;/strong&gt; - Unstar repository&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;
  &lt;picture&gt;
   &lt;source media="(prefers-color-scheme: dark)" srcset="pkg/octicons/icons/people-dark.png" /&gt;
   &lt;source media="(prefers-color-scheme: light)" srcset="pkg/octicons/icons/people-light.png" /&gt;
   &lt;img src="https://raw.githubusercontent.com/github/github-mcp-server/main/pkg/octicons/icons/people-light.png" width="20" height="20" alt="people" /&gt;
  &lt;/picture&gt; Users&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;search_users&lt;/strong&gt; - Search users 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Required OAuth Scopes&lt;/strong&gt;: &lt;code&gt;repo&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;order&lt;/code&gt;: Sort order (string, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;page&lt;/code&gt;: Page number for pagination (min 1) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;perPage&lt;/code&gt;: Results per page for pagination (min 1, max 100) (number, optional)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;query&lt;/code&gt;: User search query. Examples: 'john smith', 'location:seattle', 'followers:&amp;gt;100'. Search is automatically scoped to type:user. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;sort&lt;/code&gt;: Sort users by number of followers or repositories, or when the person joined GitHub. (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;!-- END AUTOMATED TOOLS --&gt; 
&lt;h3&gt;Additional Tools in Remote GitHub MCP Server&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Copilot&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;create_pull_request_with_copilot&lt;/strong&gt; - Perform task with GitHub Copilot coding agent 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: Repository owner. You can guess the owner, but confirm it with the user before proceeding. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;repo&lt;/code&gt;: Repository name. You can guess the repository name, but confirm it with the user before proceeding. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;problem_statement&lt;/code&gt;: Detailed description of the task to be performed (e.g., 'Implement a feature that does X', 'Fix bug Y', etc.) (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;title&lt;/code&gt;: Title for the pull request that will be created (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;base_ref&lt;/code&gt;: Git reference (e.g., branch) that the agent will start its work from. If not specified, defaults to the repository's default branch (string, optional)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Copilot Spaces&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;get_copilot_space&lt;/strong&gt; - Get Copilot Space&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;owner&lt;/code&gt;: The owner of the space. (string, required)&lt;/li&gt; 
    &lt;li&gt;&lt;code&gt;name&lt;/code&gt;: The name of the space. (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;list_copilot_spaces&lt;/strong&gt; - List Copilot Spaces&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;GitHub Support Docs Search&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;github_support_docs_search&lt;/strong&gt; - Retrieve documentation relevant to answer GitHub product and support questions. Support topics include: GitHub Actions Workflows, Authentication, GitHub Support Inquiries, Pull Request Practices, Repository Maintenance, GitHub Pages, GitHub Packages, GitHub Discussions, Copilot Spaces 
   &lt;ul&gt; 
    &lt;li&gt;&lt;code&gt;query&lt;/code&gt;: Input from the user about the question they need answered. This is the latest raw unedited user message. You should ALWAYS leave the user message as it is, you should never modify it. (string, required)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Dynamic Tool Discovery&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This feature is currently in beta and is not available in the Remote GitHub MCP Server. Please test it out and let us know if you encounter any issues.&lt;/p&gt; 
&lt;p&gt;Instead of starting with all tools enabled, you can turn on dynamic toolset discovery. Dynamic toolsets allow the MCP host to list and enable toolsets in response to a user prompt. This should help to avoid situations where the model gets confused by the sheer number of tools available.&lt;/p&gt; 
&lt;h3&gt;Using Dynamic Tool Discovery&lt;/h3&gt; 
&lt;p&gt;When using the binary, you can pass the &lt;code&gt;--dynamic-toolsets&lt;/code&gt; flag.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./github-mcp-server --dynamic-toolsets
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When using Docker, you can pass the toolsets as environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&amp;lt;your-token&amp;gt; \
  -e GITHUB_DYNAMIC_TOOLSETS=1 \
  ghcr.io/github/github-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Read-Only Mode&lt;/h2&gt; 
&lt;p&gt;To run the server in read-only mode, you can use the &lt;code&gt;--read-only&lt;/code&gt; flag. This will only offer read-only tools, preventing any modifications to repositories, issues, pull requests, etc.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./github-mcp-server --read-only
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When using Docker, you can pass the read-only mode as an environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&amp;lt;your-token&amp;gt; \
  -e GITHUB_READ_ONLY=1 \
  ghcr.io/github/github-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Lockdown Mode&lt;/h2&gt; 
&lt;p&gt;Lockdown mode limits the content that the server will surface from public repositories. When enabled, the server checks whether the author of each item has push access to the repository. Private repositories are unaffected, and collaborators keep full access to their own content.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./github-mcp-server --lockdown-mode
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running with Docker, set the corresponding environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&amp;lt;your-token&amp;gt; \
  -e GITHUB_LOCKDOWN_MODE=1 \
  ghcr.io/github/github-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The behavior of lockdown mode depends on the tool invoked.&lt;/p&gt; 
&lt;p&gt;Following tools will return an error when the author lacks the push access:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;issue_read:get&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pull_request_read:get&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Following tools will filter out content from users lacking the push access:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;issue_read:get_comments&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;issue_read:get_sub_issues&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pull_request_read:get_comments&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pull_request_read:get_review_comments&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pull_request_read:get_reviews&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;i18n / Overriding Descriptions&lt;/h2&gt; 
&lt;p&gt;The descriptions of the tools can be overridden by creating a &lt;code&gt;github-mcp-server-config.json&lt;/code&gt; file in the same directory as the binary.&lt;/p&gt; 
&lt;p&gt;The file should contain a JSON object with the tool names as keys and the new descriptions as values. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "TOOL_ADD_ISSUE_COMMENT_DESCRIPTION": "an alternative description",
  "TOOL_CREATE_BRANCH_DESCRIPTION": "Create a new branch in a GitHub repository"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can create an export of the current translations by running the binary with the &lt;code&gt;--export-translations&lt;/code&gt; flag.&lt;/p&gt; 
&lt;p&gt;This flag will preserve any translations/overrides you have made, while adding any new translations that have been added to the binary since the last time you exported.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;./github-mcp-server --export-translations
cat github-mcp-server-config.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use ENV vars to override the descriptions. The environment variable names are the same as the keys in the JSON file, prefixed with &lt;code&gt;GITHUB_MCP_&lt;/code&gt; and all uppercase.&lt;/p&gt; 
&lt;p&gt;For example, to override the &lt;code&gt;TOOL_ADD_ISSUE_COMMENT_DESCRIPTION&lt;/code&gt; tool, you can set the following environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;export GITHUB_MCP_TOOL_ADD_ISSUE_COMMENT_DESCRIPTION="an alternative description"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Library Usage&lt;/h2&gt; 
&lt;p&gt;The exported Go API of this module should currently be considered unstable, and subject to breaking changes. In the future, we may offer stability; please file an issue if there is a use case where this would be valuable.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the terms of the MIT open source license. Please refer to &lt;a href="https://raw.githubusercontent.com/github/github-mcp-server/main/LICENSE"&gt;MIT&lt;/a&gt; for the full terms.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>containers/podman</title>
      <link>https://github.com/containers/podman</link>
      <description>&lt;p&gt;Podman: A tool for managing OCI containers and pods.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/containers/common/main/logos/podman-logo-full-vert.png" alt="PODMAN logo" /&gt;&lt;/p&gt; 
&lt;h1&gt;Podman: A tool for managing OCI containers and pods&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt; &lt;img src="https://img.shields.io/github/v/release/containers/podman" alt="GitHub release (latest SemVer)" /&gt; &lt;a href="https://goreportcard.com/report/github.com/containers/podman/v6"&gt;&lt;img src="https://goreportcard.com/badge/github.com/containers/podman/v6" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/10499"&gt;&lt;img src="https://www.bestpractices.dev/projects/10499/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://insights.linuxfoundation.org/project/podman-container-tools/repository/containers-podman"&gt;&lt;img src="https://insights.linuxfoundation.org/api/badge/health-score?project=podman-container-tools&amp;amp;repos=https://github.com/containers/podman" alt="LFX Health Score" /&gt;&lt;/a&gt; &lt;a href="https://insights.linuxfoundation.org/project/podman-container-tools/repository/containers-podman"&gt;&lt;img src="https://insights.linuxfoundation.org/api/badge/contributors?project=podman-container-tools&amp;amp;repos=https://github.com/containers/podman" alt="LFX Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;Podman (the POD MANager) is a tool for managing containers and images, volumes mounted into those containers, and pods made from groups of containers. Podman runs containers on Linux, but can also be used on Mac and Windows systems using a Podman-managed virtual machine. Podman is based on libpod, a library for container lifecycle management that is also contained in this repository. The libpod library provides APIs for managing containers, pods, container images, and volumes.&lt;/p&gt; 
&lt;p&gt;Podman releases a new major or minor release 4 times a year, during the second week of February, May, August, and November. Patch releases are more frequent and may occur at any time to get bugfixes out to users. All releases are PGP signed. Public keys of members of the team approved to make releases are located &lt;a href="https://github.com/containers/release-keys/tree/main/podman"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Continuous Integration: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://cirrus-ci.com/github/containers/podman/main"&gt;&lt;img src="https://api.cirrus-ci.com/github/containers/podman.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://godoc.org/github.com/containers/podman/libpod"&gt;GoDoc: &lt;img src="https://godoc.org/github.com/containers/podman/libpod?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/containers/podman/main/DOWNLOADS.md"&gt;Downloads&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Overview and scope&lt;/h2&gt; 
&lt;p&gt;At a high level, the scope of Podman and libpod is the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Support for multiple container image formats, including OCI and Docker images.&lt;/li&gt; 
 &lt;li&gt;Full management of those images, including pulling from various sources (including trust and verification), creating (built via Containerfile or Dockerfile or committed from a container), and pushing to registries and other storage backends.&lt;/li&gt; 
 &lt;li&gt;Full management of container lifecycle, including creation (both from an image and from an exploded root filesystem), running, checkpointing and restoring (via CRIU), and removal.&lt;/li&gt; 
 &lt;li&gt;Full management of container networking, using Netavark.&lt;/li&gt; 
 &lt;li&gt;Support for pods, groups of containers that share resources and are managed together.&lt;/li&gt; 
 &lt;li&gt;Support for running containers and pods without root or other elevated privileges.&lt;/li&gt; 
 &lt;li&gt;Resource isolation of containers and pods.&lt;/li&gt; 
 &lt;li&gt;Support for a Docker-compatible CLI interface, which can both run containers locally and on remote systems.&lt;/li&gt; 
 &lt;li&gt;No manager daemon, for improved security and lower resource utilization at idle.&lt;/li&gt; 
 &lt;li&gt;Support for a REST API providing both a Docker-compatible interface and an improved interface exposing advanced Podman functionality.&lt;/li&gt; 
 &lt;li&gt;Support for running on Windows and Mac via virtual machines run by &lt;code&gt;podman machine&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;The future of Podman feature development can be found in its &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/podman/main/ROADMAP.md"&gt;roadmap&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Communications&lt;/h2&gt; 
&lt;p&gt;If you think you've identified a security issue in the project, please &lt;em&gt;DO NOT&lt;/em&gt; report the issue publicly via the GitHub issue tracker, mailing list, or IRC. Instead, send an email with as many details as possible to &lt;code&gt;security@lists.podman.io&lt;/code&gt;. This is a private mailing list for the core maintainers.&lt;/p&gt; 
&lt;p&gt;For general questions and discussion, please use Podman's &lt;a href="https://podman.io/community/#slack-irc-matrix-and-discord"&gt;channels&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For discussions around issues/bugs and features, you can use the GitHub &lt;a href="https://github.com/containers/podman/issues"&gt;issues&lt;/a&gt; and &lt;a href="https://github.com/containers/podman/pulls"&gt;PRs&lt;/a&gt; tracking system.&lt;/p&gt; 
&lt;p&gt;There is also a &lt;a href="https://lists.podman.io/archives/"&gt;mailing list&lt;/a&gt; at &lt;code&gt;lists.podman.io&lt;/code&gt;. You can subscribe by sending a message to &lt;code&gt;podman-join@lists.podman.io&lt;/code&gt; with the subject &lt;code&gt;subscribe&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Rootless&lt;/h2&gt; 
&lt;p&gt;Podman can be easily run as a normal user, without requiring a setuid binary. When run without root, Podman containers use user namespaces to set root in the container to the user running Podman. Rootless Podman runs locked-down containers with no privileges that the user running the container does not have. Some of these restrictions can be lifted (via &lt;code&gt;--privileged&lt;/code&gt;, for example), but rootless containers will never have more privileges than the user that launched them. If you run Podman as your user and mount in &lt;code&gt;/etc/passwd&lt;/code&gt; from the host, you still won't be able to change it, since your user doesn't have permission to do so.&lt;/p&gt; 
&lt;p&gt;Almost all normal Podman functionality is available, though there are some &lt;a href="https://github.com/containers/podman/raw/main/rootless.md"&gt;shortcomings&lt;/a&gt;. Any recent Podman release should be able to run rootless without any additional configuration, though your operating system may require some additional configuration detailed in the &lt;a href="https://podman.io/getting-started/installation"&gt;install guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;A little configuration by an administrator is required before rootless Podman can be used, the necessary setup is documented &lt;a href="https://github.com/containers/podman/raw/main/docs/tutorials/rootless_tutorial.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Podman Desktop&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://podman-desktop.io/"&gt;Podman Desktop&lt;/a&gt; provides a local development environment for Podman and Kubernetes on Linux, Windows, and Mac machines. It is a full-featured desktop UI frontend for Podman which uses the &lt;code&gt;podman machine&lt;/code&gt; backend on non-Linux operating systems to run containers. It supports full container lifecycle management (building, pulling, and pushing images, creating and managing containers, creating and managing pods, and working with Kubernetes YAML). The project develops on &lt;a href="https://github.com/containers/podman-desktop"&gt;GitHub&lt;/a&gt; and contributions are welcome.&lt;/p&gt; 
&lt;h2&gt;Out of scope&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Specialized signing and pushing of images to various storage backends. See &lt;a href="https://github.com/containers/skopeo/"&gt;Skopeo&lt;/a&gt; for those tasks.&lt;/li&gt; 
 &lt;li&gt;Support for the Kubernetes CRI interface for container management. The &lt;a href="https://github.com/cri-o/cri-o"&gt;CRI-O&lt;/a&gt; daemon specializes in that.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;OCI Projects Plans&lt;/h2&gt; 
&lt;p&gt;Podman uses OCI projects and best of breed libraries for different aspects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Runtime: We use the &lt;a href="https://github.com/opencontainers/runtime-tools"&gt;OCI runtime tools&lt;/a&gt; to generate OCI runtime configurations that can be used with any OCI-compliant runtime, like &lt;a href="https://github.com/containers/crun/"&gt;crun&lt;/a&gt; and &lt;a href="https://github.com/opencontainers/runc/"&gt;runc&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Images: Image management uses the &lt;a href="https://github.com/containers/image"&gt;containers/image&lt;/a&gt; library.&lt;/li&gt; 
 &lt;li&gt;Storage: Container and image storage is managed by &lt;a href="https://github.com/containers/storage"&gt;containers/storage&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Networking: Networking support through use of &lt;a href="https://github.com/containers/netavark"&gt;Netavark&lt;/a&gt; and &lt;a href="https://github.com/containers/aardvark-dns"&gt;Aardvark&lt;/a&gt;. Rootless networking is handled via &lt;a href="https://passt.top/passt"&gt;pasta&lt;/a&gt; or &lt;a href="https://github.com/rootless-containers/slirp4netns"&gt;slirp4netns&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Builds: Builds are supported via &lt;a href="https://github.com/containers/buildah"&gt;Buildah&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Conmon: &lt;a href="https://github.com/containers/conmon"&gt;Conmon&lt;/a&gt; is a tool for monitoring OCI runtimes, used by both Podman and CRI-O.&lt;/li&gt; 
 &lt;li&gt;Seccomp: A unified &lt;a href="https://github.com/containers/common/raw/main/pkg/seccomp/seccomp.json"&gt;Seccomp&lt;/a&gt; policy for Podman, Buildah, and CRI-O.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Podman Information for Developers&lt;/h2&gt; 
&lt;p&gt;For blogs, release announcements and more, please checkout the &lt;a href="https://podman.io"&gt;podman.io&lt;/a&gt; website!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/podman/main/install.md"&gt;Installation notes&lt;/a&gt;&lt;/strong&gt; Information on how to install Podman in your environment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/containers/common/raw/main/pkg/hooks/README.md"&gt;OCI Hooks Support&lt;/a&gt;&lt;/strong&gt; Information on how Podman configures &lt;a href="https://github.com/opencontainers/runtime-spec/raw/v1.0.2/config.md#posix-platform-hooks"&gt;OCI Hooks&lt;/a&gt; to run when launching a container.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.podman.io/en/latest/_static/api.html"&gt;Podman API&lt;/a&gt;&lt;/strong&gt; Documentation on the Podman REST API.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://podman.readthedocs.io/en/latest/Commands.html"&gt;Podman Commands&lt;/a&gt;&lt;/strong&gt; A list of the Podman commands with links to their man pages and in many cases videos showing the commands in use.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/containers/image_build/raw/main/podman/README.md"&gt;Podman Container Images&lt;/a&gt;&lt;/strong&gt; Information on the Podman Container Images found on &lt;a href="https://quay.io/podman/stable"&gt;quay.io&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/podman/main/troubleshooting.md"&gt;Podman Troubleshooting Guide&lt;/a&gt;&lt;/strong&gt; A list of common issues and solutions for Podman.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/podman/main/transfer.md"&gt;Podman Usage Transfer&lt;/a&gt;&lt;/strong&gt; Useful information for ops and dev transfer as it relates to infrastructure that utilizes Podman. This page includes tables showing Docker commands and their Podman equivalent commands.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/podman/main/docs/tutorials"&gt;Tutorials&lt;/a&gt;&lt;/strong&gt; Tutorials on using Podman.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/containers/podman/raw/main/docs/tutorials/remote_client.md"&gt;Remote Client&lt;/a&gt;&lt;/strong&gt; A brief how-to on using the Podman remote client.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/containers/podman/raw/main/docs/tutorials/rootless_tutorial.md"&gt;Basic Setup and Use of Podman in a Rootless environment&lt;/a&gt;&lt;/strong&gt; A tutorial showing the setup and configuration necessary to run Rootless Podman.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/podman/main/RELEASE_NOTES.md"&gt;Release Notes&lt;/a&gt;&lt;/strong&gt; Release notes for recent Podman versions.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/containers/podman/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/strong&gt; Information about contributing to this project.&lt;/p&gt; 
&lt;h2&gt;Buildah and Podman relationship&lt;/h2&gt; 
&lt;p&gt;Buildah and Podman are two complementary open-source projects that are available on most Linux platforms and both projects reside at &lt;a href="https://github.com"&gt;GitHub.com&lt;/a&gt; with Buildah &lt;a href="https://github.com/containers/buildah"&gt;here&lt;/a&gt; and Podman &lt;a href="https://github.com/containers/podman"&gt;here&lt;/a&gt;. Both, Buildah and Podman are command line tools that work on Open Container Initiative (OCI) images and containers. The two projects differentiate in their specialization.&lt;/p&gt; 
&lt;p&gt;Buildah specializes in building OCI images. Buildah's commands replicate all of the commands that are found in a Dockerfile. This allows building images with and without Dockerfiles while not requiring any root privileges. Buildah‚Äôs ultimate goal is to provide a lower-level coreutils interface to build images. The flexibility of building images without Dockerfiles allows for the integration of other scripting languages into the build process. Buildah follows a simple fork-exec model and does not run as a daemon but it is based on a comprehensive API in golang, which can be vendored into other tools.&lt;/p&gt; 
&lt;p&gt;Podman specializes in all of the commands and functions that help you to maintain and modify OCI images, such as pulling and tagging. It also allows you to create, run, and maintain those containers created from those images. For building container images via Dockerfiles, Podman uses Buildah's golang API and can be installed independently from Buildah.&lt;/p&gt; 
&lt;p&gt;A major difference between Podman and Buildah is their concept of a container. Podman allows users to create "traditional containers" where the intent of these containers is to be long lived. While Buildah containers are really just created to allow content to be added back to the container image. An easy way to think of it is the &lt;code&gt;buildah run&lt;/code&gt; command emulates the RUN command in a Dockerfile while the &lt;code&gt;podman run&lt;/code&gt; command emulates the &lt;code&gt;docker run&lt;/code&gt; command in functionality. Because of this and their underlying storage differences, you can not see Podman containers from within Buildah or vice versa.&lt;/p&gt; 
&lt;p&gt;In short, Buildah is an efficient way to create OCI images while Podman allows you to manage and maintain those images and containers in a production environment using familiar container cli commands. For more details, see the &lt;a href="https://github.com/containers/buildah/tree/main/docs/containertools"&gt;Container Tools Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Podman Hello&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;$ podman run quay.io/podman/hello
Trying to pull quay.io/podman/hello:latest...
Getting image source signatures
Copying blob a6b3126f3807 done
Copying config 25c667d086 done
Writing manifest to image destination
Storing signatures
!... Hello Podman World ...!

         .--"--.
       / -     - \
      / (O)   (O) \
   ~~~| -=(,Y,)=- |
    .---. /`  \   |~~
 ~/  o  o \~~~~.----. ~~
  | =(X)= |~  / (O (O) \
   ~~~~~~~  ~| =(Y_)=-  |
  ~~~~    ~~~|   U      |~~

Project:   https://github.com/containers/podman
Website:   https://podman.io
Documents: https://docs.podman.io
Twitter:   @Podman_io
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>ArvinLovegood/go-stock</title>
      <link>https://github.com/ArvinLovegood/go-stock</link>
      <description>&lt;p&gt;ü¶Ñü¶Ñü¶ÑAIËµãËÉΩËÇ°Á•®ÂàÜÊûêÔºöAIÂä†ÊåÅÁöÑËÇ°Á•®ÂàÜÊûê/ÈÄâËÇ°Â∑•ÂÖ∑„ÄÇËÇ°Á•®Ë°åÊÉÖËé∑ÂèñÔºåAIÁÉ≠ÁÇπËµÑËÆØÂàÜÊûêÔºåAIËµÑÈáë/Ë¥¢Âä°ÂàÜÊûêÔºåÊ∂®Ë∑åÊä•Ë≠¶Êé®ÈÄÅ„ÄÇÊîØÊåÅAËÇ°ÔºåÊ∏ØËÇ°ÔºåÁæéËÇ°„ÄÇÊîØÊåÅÂ∏ÇÂú∫Êï¥‰Ωì/‰∏™ËÇ°ÊÉÖÁª™ÂàÜÊûêÔºåAIËæÖÂä©ÈÄâËÇ°Á≠â„ÄÇÊï∞ÊçÆÂÖ®ÈÉ®‰øùÁïôÂú®Êú¨Âú∞„ÄÇÊîØÊåÅDeepSeekÔºåOpenAIÔºå OllamaÔºåLMStudioÔºåAnythingLLMÔºåÁ°ÖÂü∫ÊµÅÂä®ÔºåÁÅ´Â±±ÊñπËàüÔºåÈòøÈáå‰∫ëÁôæÁÇºÁ≠âÂπ≥Âè∞ÊàñÊ®°Âûã„ÄÇ&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;go-stock : Âü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑAIËµãËÉΩËÇ°Á•®ÂàÜÊûêÂ∑•ÂÖ∑&lt;/h1&gt; 
&lt;h2&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/appicon.png" alt="go-stock" /&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/github/v/release/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases&amp;amp;link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock%2Freleases" alt="GitHub Release" /&gt; &lt;a href="https://github.com/ArvinLovegood/go-stock"&gt;&lt;img src="https://img.shields.io/github/stars/ArvinLovegood/go-stock?link=https%3A%2F%2Fgithub.com%2FArvinLovegood%2Fgo-stock" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://gitee.com/arvinlovegood_admin/go-stock"&gt;&lt;img src="https://gitee.com/arvinlovegood_admin/go-stock/badge/star.svg?theme=dark" alt="star" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üåüÂÖ¨‰ºóÂè∑&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/%E6%89%AB%E7%A0%81_%E6%90%9C%E7%B4%A2%E8%81%94%E5%90%88%E4%BC%A0%E6%92%AD%E6%A0%B7%E5%BC%8F-%E7%99%BD%E8%89%B2%E7%89%88.png" alt="Êâ´Á†Å_ÊêúÁ¥¢ËÅîÂêà‰º†Êí≠Ê†∑Âºè-ÁôΩËâ≤Áâà.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;üìà ‰∫§ÊµÅÁæ§&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;QQ‰∫§ÊµÅÁæ§Ôºö&lt;a href="http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&amp;amp;k=0YQ8qD3exahsD4YLNhzQTWe5ssstWC89&amp;amp;authKey=usOMMRFtIQDC%2FYcatHYapcxQbJ7PwXPHK9OypTXWzNjAq%2FRVvQu9bj2lRgb%2BSZ3p&amp;amp;noverify=0&amp;amp;group_code=491605333"&gt;ÁÇπÂáªÈìæÊé•Âä†ÂÖ•Áæ§ËÅä„Äêgo-stock‰∫§ÊµÅÁæ§„ÄëÔºö491605333(ÂÆöÊúüÊ∏ÖÁêÜÔºåÈöèÁºòÂÖ•Áæ§)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‚ú® ÁÆÄ‰ªã&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êú¨È°πÁõÆÂü∫‰∫éWailsÂíåNaiveUIÂºÄÂèëÔºåÁªìÂêàAIÂ§ßÊ®°ÂûãÊûÑÂª∫ÁöÑËÇ°Á•®ÂàÜÊûêÂ∑•ÂÖ∑„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÁõÆÂâçÂ∑≤ÊîØÊåÅAËÇ°ÔºåÊ∏ØËÇ°ÔºåÁæéËÇ°ÔºåÊú™Êù•ËÆ°ÂàíÂä†ÂÖ•Âü∫ÈáëÔºåETFÁ≠âÊîØÊåÅ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÊîØÊåÅÂ∏ÇÂú∫Êï¥‰Ωì/‰∏™ËÇ°ÊÉÖÁª™ÂàÜÊûêÔºåKÁ∫øÊäÄÊúØÊåáÊ†áÂàÜÊûêÁ≠âÂäüËÉΩ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Êú¨È°πÁõÆ‰ªÖ‰æõÂ®±‰πêÔºå‰∏çÂñúÂãøÂñ∑ÔºåAIÂàÜÊûêËÇ°Á•®ÁªìÊûú‰ªÖ‰æõÂ≠¶‰π†Á†îÁ©∂ÔºåÊäïËµÑÊúâÈ£éÈô©ÔºåËØ∑Ë∞®ÊÖé‰ΩøÁî®„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂºÄÂèëÁéØÂ¢É‰∏ªË¶ÅÂü∫‰∫éWindows10+ÔºåÂÖ∂‰ªñÂπ≥Âè∞Êú™ÊµãËØïÊàñÂäüËÉΩÂèóÈôê„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üì¶ Á´ãÂç≥‰ΩìÈ™å&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÁªøËâ≤ÁâàÔºö&lt;a href="https://github.com/ArvinLovegood/go-stock/releases"&gt;go-stock-windows-amd64.exe&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;MACOSÁªøËâ≤ÁâàÔºö&lt;a href="https://github.com/ArvinLovegood/go-stock/releases"&gt;go-stock-darwin-universal&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üí¨ ÊîØÊåÅÂ§ßÊ®°Âûã/Âπ≥Âè∞&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ê®°Âûã&lt;/th&gt; 
   &lt;th&gt;Áä∂ÊÄÅ&lt;/th&gt; 
   &lt;th&gt;Â§áÊ≥®&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://platform.openai.com/"&gt;OpenAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;ÂèØÊé•ÂÖ•‰ªª‰Ωï OpenAI Êé•Âè£Ê†ºÂºèÊ®°Âûã&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://ollama.com/"&gt;Ollama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;Êú¨Âú∞Â§ßÊ®°ÂûãËøêË°åÂπ≥Âè∞&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lmstudio.ai/"&gt;LMStudio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;Êú¨Âú∞Â§ßÊ®°ÂûãËøêË°åÂπ≥Âè∞&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://anythingllm.com/"&gt;AnythingLLM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;Êú¨Âú∞Áü•ËØÜÂ∫ì&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.deepseek.com/"&gt;DeepSeek&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;deepseek-reasoner,deepseek-chat&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://cloud.siliconflow.cn/i/foufCerk"&gt;Â§ßÊ®°ÂûãËÅöÂêàÂπ≥Âè∞&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;Â¶ÇÔºö&lt;a href="https://cloud.siliconflow.cn/i/foufCerk"&gt;Á°ÖÂü∫ÊµÅÂä®&lt;/a&gt;Ôºå&lt;a href="https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;amp;ac=DSASUQY5&amp;amp;rc=IJSE43PZ"&gt;ÁÅ´Â±±ÊñπËàü&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;span style="color: #568DF4;"&gt;ÂêÑ‰Ωç‰∫≤Áà±ÁöÑÊúãÂèã‰ª¨ÔºåÂ¶ÇÊûúÊÇ®ÂØπËøô‰∏™È°πÁõÆÊÑüÂÖ¥Ë∂£ÔºåËØ∑ÂÖàÁªôÊàë‰∏Ä‰∏™&lt;i style="color: #EA2626;"&gt;star&lt;/i&gt;ÂêßÔºåË∞¢Ë∞¢ÔºÅ&lt;/span&gt;üíï&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÁÅ´Â±±ÊñπËàüÔºöÊñ∞Áî®Êà∑ÊØè‰∏™Ê®°ÂûãÊ≥®ÂÜåÂç≥ÈÄÅ50‰∏átokensÔºå&lt;a href="https://www.volcengine.com/experience/ark?utm_term=202502dsinvite&amp;amp;ac=DSASUQY5&amp;amp;rc=IJSE43PZ"&gt;Ê≥®ÂÜåÈìæÊé•&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Á°ÖÂü∫ÊµÅÂä®(siliconflow)ÔºåÊ≥®ÂÜåÂç≥ÈÄÅ2000‰∏áTokensÔºå&lt;a href="https://cloud.siliconflow.cn/i/foufCerk"&gt;Ê≥®ÂÜåÈìæÊé•&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;TushareÂ§ßÊï∞ÊçÆÂºÄÊîæÁ§æÂå∫,ÂÖçË¥πÊèê‰æõÂêÑÁ±ªÈáëËûçÊï∞ÊçÆ,Âä©ÂäõË°å‰∏öÂíåÈáèÂåñÁ†îÁ©∂(Ê≥®ÊÑèÔºöTushareÂè™ÈúÄË¶Å120ÁßØÂàÜÂç≥ÂèØÔºåÊ≥®ÂÜåÂÆåÊàê‰∏™‰∫∫ËµÑÊñôË°•ÂÖÖÂç≥ÂèØÂæó120ÁßØÂàÜÔºÅÔºÅÔºÅ)Ôºå&lt;a href="https://tushare.pro/register?reg=701944"&gt;Ê≥®ÂÜåÈìæÊé•&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ËΩØ‰ª∂Âø´ÈÄüËø≠‰ª£ÂºÄÂèë‰∏≠,ËØ∑Â§ßÂÆ∂‰ºòÂÖàÊµãËØïÂíå‰ΩøÁî®ÊúÄÊñ∞ÂèëÂ∏ÉÁöÑÁâàÊú¨„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Ê¨¢ËøéÂ§ßÂÆ∂ÊèêÂá∫ÂÆùË¥µÁöÑÂª∫ËÆÆÔºåÊ¨¢ËøéÊèêissue,PR„ÄÇÂΩìÁÑ∂Êõ¥Ê¨¢Ëøé&lt;a href="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/#%E9%83%BD%E5%88%92%E5%88%B0%E8%BF%99%E4%BA%86%E5%A6%82%E6%9E%9C%E6%88%91%E7%9A%84%E9%A1%B9%E7%9B%AE%E5%AF%B9%E6%82%A8%E6%9C%89%E5%B8%AE%E5%8A%A9%E8%AF%B7%E8%B5%9E%E5%8A%A9%E6%88%91%E5%90%A7"&gt;ËµûÂä©Êàë&lt;/a&gt;„ÄÇüíï&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÊîØÊåÅÂºÄÊ∫êüíïËÆ°Âàí&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;ËµûÂä©ËÆ°Âàí&lt;/th&gt; 
   &lt;th&gt;ËµûÂä©Á≠âÁ∫ß&lt;/th&gt; 
   &lt;th align="left"&gt;ÊùÉÁõäËØ¥Êòé&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ÊØèÊúà 0 RMB&lt;/td&gt; 
   &lt;td&gt;vip0&lt;/td&gt; 
   &lt;td align="left"&gt;üåü ÂÖ®ÈÉ®ÂäüËÉΩ,ËΩØ‰ª∂Ëá™Âä®Êõ¥Êñ∞(‰ªéGitHub‰∏ãËΩΩ),Ëá™Ë°åËß£ÂÜ≥githubÂπ≥Âè∞ÁΩëÁªúÈóÆÈ¢ò„ÄÇ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ÊØèÊúàËµûÂä© 18.8 RMB&lt;br /&gt;ÊØèÂπ¥ËµûÂä© 120 RMB&lt;/td&gt; 
   &lt;td&gt;vip1&lt;/td&gt; 
   &lt;td align="left"&gt;üíï ÂÖ®ÈÉ®ÂäüËÉΩ,ËΩØ‰ª∂Ëá™Âä®Êõ¥Êñ∞(‰ªéCDN‰∏ãËΩΩ),Êõ¥Êñ∞Âø´ÈÄü‰æøÊç∑„ÄÇAIÈÖçÁΩÆÊåáÂØºÔºåÊèêÁ§∫ËØçÂèÇËÄÉÁ≠â&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ÊØèÊúàËµûÂä© 28.8 RMB&lt;br /&gt;ÊØèÂπ¥ËµûÂä© 240 RMB&lt;/td&gt; 
   &lt;td&gt;vip2&lt;/td&gt; 
   &lt;td align="left"&gt;üíï üíï vip1ÂÖ®ÈÉ®ÂäüËÉΩ,Ëµ†ÈÄÅÁ°ÖÂü∫ÊµÅÂä®AIÂàÜÊûêÊúçÂä°,ÂêØÂä®Êó∂Ëá™Âä®ÂêåÊ≠•ÊúÄËøë24Â∞èÊó∂Â∏ÇÂú∫ËµÑËÆØ(ÂåÖÊã¨Â§ñÂ™íÁÆÄËÆØ)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ÊØèÊúàËµûÂä© X RMB&lt;/td&gt; 
   &lt;td&gt;vipX&lt;/td&gt; 
   &lt;td align="left"&gt;üß© Êõ¥Â§öËÆ°ÂàíÔºåËßÜgo-stockÂºÄÊ∫êÈ°πÁõÆÂèëÂ±ïÊÉÖÂÜµËÄåÂÆö...(ÊâøÊé•GitHubÈ°πÁõÆREADMEÂπøÂëäÊé®Âπøüíñ)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üß© ÈáçÂ§ßÂäüËÉΩÂºÄÂèëËÆ°Âàí&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÂäüËÉΩËØ¥Êòé&lt;/th&gt; 
   &lt;th&gt;Áä∂ÊÄÅ&lt;/th&gt; 
   &lt;th&gt;Â§áÊ≥®&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ËÇ°Á•®ÂàÜÊûêÁü•ËØÜÂ∫ì&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;Êú™Êù•ËÆ°Âàí&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AiÊô∫ËÉΩÈÄâËÇ°&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;AiÊô∫ËÉΩÈÄâËÇ°ÂäüËÉΩ(Â∏ÇÂú∫Ë°åÊÉÖ-„ÄãAIÊÄªÁªì/AIÊô∫ËÉΩ‰ΩìÂäüËÉΩ)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ETFÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;üöß&lt;/td&gt; 
   &lt;td&gt;ETFÊï∞ÊçÆÊîØÊåÅ (ÁõÆÂâçÂèØ‰ª•Êü•ÁúãÂáÄÂÄºÂíå‰º∞ÂÄº)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ÁæéËÇ°ÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;ÁæéËÇ°Êï∞ÊçÆÊîØÊåÅ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ê∏ØËÇ°ÊîØÊåÅ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;Ê∏ØËÇ°Êï∞ÊçÆÊîØÊåÅ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Â§öËΩÆÂØπËØù&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;AIÂàÜÊûêÂêéÂèØÁªßÁª≠ÂØπËØùÊèêÈóÆ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ëá™ÂÆö‰πâAIÂàÜÊûêÊèêÈóÆÊ®°Êùø&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;ÂèØÈÖçÁΩÆÁöÑÊèêÈóÆÊ®°Êùø &lt;a href="https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha"&gt;v2025.2.12.7-alpha&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;‰∏çÂÜçÂº∫Âà∂‰æùËµñChromeÊµèËßàÂô®&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;ÈªòËÆ§‰ΩøÁî®edgeÊµèËßàÂô®ÊäìÂèñÊñ∞ÈóªËµÑËÆØ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üëÄ Êõ¥Êñ∞Êó•Âøó&lt;/h2&gt; 
&lt;h3&gt;2025.12.16 Êñ∞Â¢ûAIÊÄùËÄÉÊ®°Âºè‰∏éÁÉ≠Èó®ÈÄâËÇ°Á≠ñÁï•ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.11.21 Êñ∞Â¢ûÂ∏¶È¢ëÁéáÊùÉÈáçÁöÑÊÉÖÊÑüÂàÜÊûêÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.10.30 Ê∑ªÂä†AIÊô∫ËÉΩ‰ΩìÂäüËÉΩÂºÄÂÖ≥(ÈªòËÆ§ÂÖ≥Èó≠ÔºåÂõ†‰∏∫‰ΩøÁî®‰ΩìÈ™å‰∏çÁêÜÊÉ≥)ÔºåÁßªÈô§È°µÈù¢Ê∞¥Âç∞&lt;/h3&gt; 
&lt;h3&gt;2025.09.27 Ê∑ªÂä†Êú∫ÊûÑ/Âà∏ÂïÜÁöÑÁ†îÁ©∂Êä•ÂëäAIÂ∑•ÂÖ∑ÂáΩÊï∞&lt;/h3&gt; 
&lt;h3&gt;2025.08.09 Ê∑ªÂä†AIÊô∫ËÉΩ‰ΩìËÅäÂ§©ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.07.08 ÂÆûÁé∞ËΩØ‰ª∂Ëá™Âä®Êõ¥Êñ∞ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.07.07 Âç°ÁâáÊ∑ªÂä†Ëø∑‰Ω†ÂàÜÊó∂Âõæ&lt;/h3&gt; 
&lt;h3&gt;2025.07.05 MacOsÊîØÊåÅ&lt;/h3&gt; 
&lt;h3&gt;2025.07.01 AIÂàÜÊûêÈõÜÊàêÂ∑•ÂÖ∑ÂáΩÊï∞ÔºåAIÂàÜÊûêÂ∞ÜÊõ¥Âä†Êô∫ËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.30 Ê∑ªÂä†ÊåáÊ†áÈÄâËÇ°ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.27 Ê∑ªÂä†Ë¥¢ÁªèÊó•ÂéÜÂíåÈáçÂ§ß‰∫ã‰ª∂Êó∂Èó¥ËΩ¥ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.25 Ê∑ªÂä†ÁÉ≠Èó®ËÇ°Á•®„ÄÅ‰∫ã‰ª∂ÂíåËØùÈ¢òÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.18 Êõ¥Êñ∞ÂÜÖÁΩÆËÇ°Á•®Âü∫Á°ÄÊï∞ÊçÆ,ËΩØ‰ª∂ÂÜÖÂÆûÊó∂Â∏ÇÂú∫ËµÑËÆØ‰ø°ÊÅØÊèêÈÜíÔºåÊ∑ªÂä†Ë°å‰∏öÁ†îÁ©∂ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.15 Ê∑ªÂä†ÂÖ¨Âè∏ÂÖ¨Âëä‰ø°ÊÅØÊêúÁ¥¢/Êü•ÁúãÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.15 Ê∑ªÂä†‰∏™ËÇ°Á†îÊä•Âà∞ÂºπÂá∫ËèúÂçï&lt;/h3&gt; 
&lt;h3&gt;2025.06.13 Ê∑ªÂä†‰∏™ËÇ°Á†îÊä•ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.06.12 Ê∑ªÂä†ÈæôËôéÊ¶úÂäüËÉΩÔºåÊñ∞Â¢ûË°å‰∏öÊéíÂêçÂàÜÁ±ª&lt;/h3&gt; 
&lt;h3&gt;2025.05.30 ‰ºòÂåñËÇ°Á•®ÂàÜÊó∂ÂõæÊòæÁ§∫&lt;/h3&gt; 
&lt;h3&gt;2025.05.20 ‰øÆÂ§çË¥¢ËÅîÁ§æÁîµÊä•Ëé∑ÂèñÈóÆÈ¢ò&lt;/h3&gt; 
&lt;h3&gt;2025.05.16 ‰ºòÂåñËµÑÈáëË∂ãÂäøÂõæË°®ÁªÑ‰ª∂&lt;/h3&gt; 
&lt;h3&gt;2025.05.15 ÈáçÊûÑÂ∫îÁî®Âä†ËΩΩÂíåÊï∞ÊçÆÂàùÂßãÂåñÈÄªËæëÔºåÊ∑ªÂä†ËÇ°Á•®ËµÑÈáëË∂ãÂäøÂäüËÉΩÔºåËµÑÈáëË∂ãÂäøÂõæË°®Â¢ûÂä†‰∏ªÂäõÂΩìÊó•ÂáÄÊµÅÂÖ•Êï∞ÊçÆÂπ∂‰ºòÂåñÂ±ïÁ§∫ÊïàÊûú&lt;/h3&gt; 
&lt;h3&gt;2025.05.14 Ê∑ªÂä†‰∏™ËÇ°ËµÑÈáëÊµÅÂêëÂäüËÉΩÔºåÊéíË°åÊ¶úÂ¢ûÂä†ËÇ°Á•®Ë°åÊÉÖKÁ∫øÂõæÂºπÁ™ó&lt;/h3&gt; 
&lt;h3&gt;2025.05.13 Ê∑ªÂä†Ë°å‰∏öÊéíÂêçÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.05.09 Ê∑ªÂä†AËÇ°ÁõòÂè£Êï∞ÊçÆËß£ÊûêÂíåÂ±ïÁ§∫ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.05.07 ‰ºòÂåñÂàÜÊó∂ÂõæÁöÑÂ±ïÁ§∫&lt;/h3&gt; 
&lt;h3&gt;2025.04.29 Ë°•ÂÖ®Ê∏ØËÇ°/ÁæéËÇ°Âü∫Á°ÄÊï∞ÊçÆÔºå‰ºòÂåñÊ∏ØËÇ°ËÇ°‰ª∑Âª∂ËøüÈóÆÈ¢òÔºå‰ºòÂåñÂàùÂßãÂåñÈÄªËæë&lt;/h3&gt; 
&lt;h3&gt;2025.04.25 Â∏ÇÂú∫ËµÑËÆØÊîØÊåÅAIÂàÜÊûêÂíåÊÄªÁªìÔºöËÆ©AIÂ∏Æ‰Ω†ËØªÂ∏ÇÂú∫ÔºÅ&lt;/h3&gt; 
&lt;h3&gt;2025.04.24 Êñ∞Â¢ûÂ∏ÇÂú∫Ë°åÊÉÖÊ®°ÂùóÔºöÂç≥Êó∂ÊéåÊè°ÂÖ®ÁêÉÂ∏ÇÂú∫Ë°åÊÉÖËµÑËÆØ/Âä®ÊÄÅÔºå‰ªéÊ≠§ÂÜç‰πü‰∏çÁî®ÂÅ∑Êë∏ÂéªÂêÑÂ§ßË¥¢ÁªèÁΩëÁ´ôÂï¶„ÄÇgo-stock‰∏ÄÈîÆÂ∏Æ‰Ω†ÊêûÂÆöÔºÅ&lt;/h3&gt; 
&lt;h3&gt;2025.04.22 ‰ºòÂåñKÁ∫øÂõæÂ±ïÁ§∫ÔºåÊîØÊåÅÊãâ‰º∏ÊîæÂ§ßÔºåÁúãÂæóÊõ¥ËàíÊúçÂï¶ÔºÅ&lt;/h3&gt; 
&lt;h3&gt;2025.04.21 Ê∏ØËÇ°ÔºåÁæéËÇ°KÁ∫øÊï∞ÊçÆËé∑Âèñ‰ºòÂåñ&lt;/h3&gt; 
&lt;h3&gt;2025.04.01 ‰ºòÂåñÈÉ®ÂàÜËÆæÁΩÆÈÄâÈ°πÔºåÈÅøÂÖçÈáçÂêØËΩØ‰ª∂&lt;/h3&gt; 
&lt;h3&gt;2025.03.31 ‰ºòÂåñÊï∞ÊçÆÁà¨Âèñ&lt;/h3&gt; 
&lt;h3&gt;2025.03.30 AIËá™Âä®ÂÆöÊó∂ÂàÜÊûêÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.03.29 Â§öÊèêÁ§∫ËØçÊ®°ÊùøÁÆ°ÁêÜÔºåAIÂàÜÊûêÊó∂ÊîØÊåÅÈÄâÊã©‰∏çÂêåÊèêÁ§∫ËØçÊ®°Êùø&lt;/h3&gt; 
&lt;h3&gt;2025.03.28 AIÂàÜÊûêÁªìÊûú‰øùÂ≠ò‰∏∫markdownÊñá‰ª∂Êó∂ÔºåÊîØÊåÅ‰øùÂ≠ò‰ΩçÁΩÆÁõÆÂΩïÈÄâÊã©&lt;/h3&gt; 
&lt;h3&gt;2025.03.15 Ëá™ÂÆö‰πâÁà¨Ëô´‰ΩøÁî®ÁöÑÊµèËßàÂô®Ë∑ØÂæÑÈÖçÁΩÆ&lt;/h3&gt; 
&lt;h3&gt;2025.03.14 ‰ºòÂåñÁºñËØëÊûÑÂª∫ÔºåÂ§ßÂπÖÂáèÂ∞ëÁºñËØëÂêéÁöÑÁ®ãÂ∫èÊñá‰ª∂Â§ßÂ∞è&lt;/h3&gt; 
&lt;h3&gt;2025.03.09 Âü∫Èáë‰º∞ÂÄºÂíåÂáÄÂÄºÁõëÊéßÊü•Áúã&lt;/h3&gt; 
&lt;h3&gt;2025.03.06 È°πÁõÆÁ§æÂå∫ÂàÜ‰∫´ÂäüËÉΩ&lt;/h3&gt; 
&lt;h3&gt;2025.02.28 ÁæéËÇ°Êï∞ÊçÆÊîØÊåÅ&lt;/h3&gt; 
&lt;h3&gt;2025.02.23 ÂºπÂπïÂäüËÉΩÔºåÁõØÁõò‰∏çÂÜçÂ≠§ÂçïÔºåÊó†ËÅäÂàí‰∏™Ê∞¥ÔºÅüòé&lt;/h3&gt; 
&lt;h3&gt;2025.02.22 Ê∏ØËÇ°Êï∞ÊçÆÊîØÊåÅ(ÁõÆÂâçÊúâÂª∂Ëøü)&lt;/h3&gt; 
&lt;h3&gt;2025.02.16 AIÂàÜÊûêÂêéÂèØÁªßÁª≠ÂØπËØùÊèêÈóÆ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.16.1-alpha"&gt;v2025.2.16.1-alpha&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2025.02.12 ÂèØÈÖçÁΩÆÁöÑÊèêÈóÆÊ®°Êùø&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ArvinLovegood/go-stock/releases/tag/v2025.2.12.7-alpha"&gt;v2025.2.12.7-alpha&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü¶Ñ ÈáçÂ§ßÊõ¥Êñ∞&lt;/h2&gt; 
&lt;h3&gt;BIG NEWS !!! ÈáçÂ§ßÊõ¥Êñ∞ÔºÅÔºÅÔºÅ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025.11.21 Êñ∞Â¢ûÂ∏¶È¢ëÁéáÊùÉÈáçÁöÑÊÉÖÊÑüÂàÜÊûêÂäüËÉΩ &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img15.png" alt="img_1.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;2025.04.25 Â∏ÇÂú∫ËµÑËÆØÊîØÊåÅAIÂàÜÊûêÂíåÊÄªÁªìÔºöËÆ©AIÂ∏Æ‰Ω†ËØªÂ∏ÇÂú∫ÔºÅ &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/img.png" alt="img.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;2025.04.24 Êñ∞Â¢ûÂ∏ÇÂú∫Ë°åÊÉÖÊ®°ÂùóÔºöÂç≥Êó∂ÊéåÊè°ÂÖ®ÁêÉÂ∏ÇÂú∫Ë°åÊÉÖËµÑËÆØ/Âä®ÊÄÅÔºå‰ªéÊ≠§ÂÜç‰πü‰∏çÁî®ÂÅ∑Êë∏ÂéªÂêÑÂ§ßË¥¢ÁªèÁΩëÁ´ôÂï¶„ÄÇgo-stock‰∏ÄÈîÆÂ∏Æ‰Ω†ÊêûÂÆöÔºÅ &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img13.png" alt="img.png" /&gt; &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_13.png" alt="img_13.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_14.png" alt="img_14.png" /&gt;&lt;/li&gt; 
 &lt;li&gt;2025.01.17 Êñ∞Â¢ûAIÂ§ßÊ®°ÂûãÂàÜÊûêËÇ°Á•®ÂäüËÉΩ &lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img.png" alt="img_5.png" /&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì∏ ÂäüËÉΩÊà™Âõæ&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_6.png" alt="img_1.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;ËÆæÁΩÆ&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_4.png" alt="img_12.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;ÊàêÊú¨ËÆæÁΩÆ&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_7.png" alt="img.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;Êó•K&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_12.png" alt="img_12.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;ÂàÜÊó∂&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_9.png" alt="img_3.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;ÈíâÈíâÊä•Ë≠¶ÈÄöÁü•&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_5.png" alt="img_4.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;AIÂàÜÊûêËÇ°Á•®&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img.png" alt="img_5.png" /&gt;&lt;/p&gt; 
&lt;h3&gt;ÁâàÊú¨‰ø°ÊÅØÊèêÁ§∫&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/img_11.png" alt="img_11.png" /&gt;&lt;/p&gt; 
&lt;h2&gt;üíï ÊÑüË∞¢‰ª•‰∏ãÈ°πÁõÆ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.naiveui.com/"&gt;NaiveUI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wails.io/"&gt;Wails&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vuejs.org/"&gt;Vue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vitejs.dev/"&gt;Vite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tushare.pro/register?reg=701944"&gt;Tushare&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üòò ËµûÂä©Êàë&lt;/h2&gt; 
&lt;h3&gt;ÈÉΩÂàíÂà∞Ëøô‰∫ÜÔºåÂ¶ÇÊûúÊàëÁöÑÈ°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑ËµûÂä©ÊàëÂêßÔºÅüòäüòäüòä&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÊîØ‰ªòÂÆù&lt;/th&gt; 
   &lt;th&gt;ÂæÆ‰ø°&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/alipay.jpg" alt="alipay.jpg" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/build/screenshot/wxpay.jpg" alt="wxpay.jpg" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#ArvinLovegood/go-stock&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=ArvinLovegood/go-stock&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ü§ñ Áä∂ÊÄÅ&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/40b07d415a42c2264a18c4fe1b6f182ff1470687.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;üê≥ ÂÖ≥‰∫éÊäÄÊúØÊîØÊåÅÁî≥Êòé&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Êú¨ËΩØ‰ª∂Âü∫‰∫éÂºÄÊ∫êÊäÄÊúØÊûÑÂª∫Ôºå‰ΩøÁî®Wails„ÄÅNaiveUI„ÄÅVue„ÄÅAIÂ§ßÊ®°ÂûãÁ≠âÂºÄÊ∫êÈ°πÁõÆ„ÄÇ ÊäÄÊúØ‰∏äÂ¶ÇÊúâÈóÆÈ¢òÔºåÂèØ‰ª•ÂÖàÂêëÂØπÂ∫îÁöÑÂºÄÊ∫êÁ§æÂå∫ËØ∑Ê±ÇÂ∏ÆÂä©„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂºÄÊ∫ê‰∏çÊòìÔºåÊú¨‰∫∫Á≤æÂäõÂíåÊó∂Èó¥ÊúâÈôêÔºåÂ¶ÇÈúÄ‰∏ÄÂØπ‰∏ÄÊäÄÊúØÊîØÊåÅÔºåËØ∑ÂÖàËµûÂä©„ÄÇËÅîÁ≥ªQQ(Â§áÊ≥® ÊäÄÊúØÊîØÊåÅ)Ôºö506808970&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;ÊäÄÊúØÊîØÊåÅÊñπÂºè&lt;/th&gt; 
   &lt;th align="center"&gt;ËµûÂä©(ÂÖÉ)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Âä† QQÔºö506808970&lt;/td&gt; 
   &lt;td align="center"&gt;100/Ê¨°&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;ÈïøÊúüÊäÄÊúØÊîØÊåÅÔºà‰∏çÈôêÊ¨°Êï∞ÔºåÊñ∞ÂäüËÉΩ‰ºòÂÖà‰ΩìÈ™åÁ≠âÔºâ&lt;/td&gt; 
   &lt;td align="center"&gt;5000&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ArvinLovegood/go-stock/dev/LICENSE"&gt;Apache License 2.0&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>maximhq/bifrost</title>
      <link>https://github.com/maximhq/bifrost</link>
      <description>&lt;p&gt;Fastest LLM gateway (50x faster than LiteLLM) with adaptive load balancer, cluster mode, guardrails, 1000+ models support &amp; &lt;100 ¬µs overhead at 5k RPS.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Bifrost&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/maximhq/bifrost/core"&gt;&lt;img src="https://goreportcard.com/badge/github.com/maximhq/bifrost/core" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/exN5KAydbU"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/https://discord.gg/exN5KAydbU?style=flat" alt="Discord badge" /&gt;&lt;/a&gt; &lt;a href="https://snyk.io/test/github/maximhq/bifrost"&gt;&lt;img src="https://snyk.io/test/github/maximhq/bifrost/badge.svg?sanitize=true" alt="Known Vulnerabilities" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/maximhq/bifrost"&gt;&lt;img src="https://codecov.io/gh/maximhq/bifrost/branch/main/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/docker/pulls/maximhq/bifrost" alt="Docker Pulls" /&gt; &lt;a href="https://app.getpostman.com/run-collection/31642484-2ba0e658-4dcd-49f4-845a-0c7ed745b916?action=collection%2Ffork&amp;amp;source=rip_markdown&amp;amp;collection-url=entityId%3D31642484-2ba0e658-4dcd-49f4-845a-0c7ed745b916%26entityType%3Dcollection%26workspaceId%3D63e853c8-9aec-477f-909c-7f02f543150e"&gt;&lt;img src="https://run.pstmn.io/button.svg?sanitize=true" alt="Run In Postman" style="width: 95px; height: 21px;" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=bifrost"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/bifrost" alt="Artifact Hub" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/maximhq/bifrost/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/maximhq/bifrost" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;The fastest way to build AI applications that never go down&lt;/h2&gt; 
&lt;p&gt;Bifrost is a high-performance AI gateway that unifies access to 15+ providers (OpenAI, Anthropic, AWS Bedrock, Google Vertex, and more) through a single OpenAI-compatible API. Deploy in seconds with zero configuration and get automatic failover, load balancing, semantic caching, and enterprise-grade features.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/maximhq/bifrost/main/docs/media/getting-started.png" alt="Get started" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Go from zero to production-ready AI gateway in under a minute.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 1:&lt;/strong&gt; Start Bifrost Gateway&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install and run locally
npx -y @maximhq/bifrost

# Or use Docker
docker run -p 8080:8080 maximhq/bifrost
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 2:&lt;/strong&gt; Configure via Web UI&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Open the built-in web interface
open http://localhost:8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Step 3:&lt;/strong&gt; Make your first API call&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "openai/gpt-4o-mini",
    "messages": [{"role": "user", "content": "Hello, Bifrost!"}]
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;That's it!&lt;/strong&gt; Your AI gateway is running with a web interface for visual configuration, real-time monitoring, and analytics.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Complete Setup Guides:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Gateway Setup&lt;/a&gt; - HTTP API deployment&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/go-sdk/setting-up"&gt;Go SDK Setup&lt;/a&gt; - Direct integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Enterprise Deployments&lt;/h2&gt; 
&lt;p&gt;Bifrost supports enterprise-grade, private deployments for teams running production AI systems at scale. In addition to private networking, custom security controls, and governance, enterprise deployments unlock advanced capabilities including adaptive load balancing, clustering, guardrails, MCP gateway and and other features designed for enterprise-grade scale and reliability.&lt;/p&gt; 
&lt;p&gt;üëâ &lt;a href="https://www.getmaxim.ai/bifrost/enterprise" target="_blank"&gt;Explore enterprise capabilities&lt;/a&gt;&lt;/p&gt; 
&lt;div align="left"&gt; 
 &lt;a href="https://calendly.com/maximai/bifrost-demo"&gt; &lt;img src="https://raw.githubusercontent.com/maximhq/bifrost/main/.github/assets/book-demo-button.png" alt="Book a Demo" width="170" style="margin-top:5px;" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;h3&gt;Core Infrastructure&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/unified-interface"&gt;Unified Interface&lt;/a&gt;&lt;/strong&gt; - Single OpenAI-compatible API for all providers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/provider-configuration"&gt;Multi-Provider Support&lt;/a&gt;&lt;/strong&gt; - OpenAI, Anthropic, AWS Bedrock, Google Vertex, Azure, Cerebras, Cohere, Mistral, Ollama, Groq, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/fallbacks"&gt;Automatic Fallbacks&lt;/a&gt;&lt;/strong&gt; - Seamless failover between providers and models with zero downtime&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/fallbacks"&gt;Load Balancing&lt;/a&gt;&lt;/strong&gt; - Intelligent request distribution across multiple API keys and providers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/strong&gt; - Enable AI models to use external tools (filesystem, web search, databases)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/semantic-caching"&gt;Semantic Caching&lt;/a&gt;&lt;/strong&gt; - Intelligent response caching based on semantic similarity to reduce costs and latency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/streaming"&gt;Multimodal Support&lt;/a&gt;&lt;/strong&gt; - Support for text,images, audio, and streaming, all behind a common interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/custom-plugins"&gt;Custom Plugins&lt;/a&gt;&lt;/strong&gt; - Extensible middleware architecture for analytics, monitoring, and custom logic&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/governance"&gt;Governance&lt;/a&gt;&lt;/strong&gt; - Usage tracking, rate limiting, and fine-grained access control&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enterprise &amp;amp; Security&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/governance"&gt;Budget Management&lt;/a&gt;&lt;/strong&gt; - Hierarchical cost control with virtual keys, teams, and customer budgets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/sso-with-google-github"&gt;SSO Integration&lt;/a&gt;&lt;/strong&gt; - Google and GitHub authentication support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/observability"&gt;Observability&lt;/a&gt;&lt;/strong&gt; - Native Prometheus metrics, distributed tracing, and comprehensive logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/vault-support"&gt;Vault Support&lt;/a&gt;&lt;/strong&gt; - Secure API key management with HashiCorp Vault integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Developer Experience&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Zero-Config Startup&lt;/a&gt;&lt;/strong&gt; - Start immediately with dynamic provider configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/features/drop-in-replacement"&gt;Drop-in Replacement&lt;/a&gt;&lt;/strong&gt; - Replace OpenAI/Anthropic/GenAI APIs with one line of code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/integrations/what-is-an-integration"&gt;SDK Integrations&lt;/a&gt;&lt;/strong&gt; - Native support for popular AI SDKs with zero code changes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/provider-configuration"&gt;Configuration Flexibility&lt;/a&gt;&lt;/strong&gt; - Web UI, API-driven, or file-based configuration options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Repository Structure&lt;/h2&gt; 
&lt;p&gt;Bifrost uses a modular architecture for maximum flexibility:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;bifrost/
‚îú‚îÄ‚îÄ npx/                 # NPX script for easy installation
‚îú‚îÄ‚îÄ core/                # Core functionality and shared components
‚îÇ   ‚îú‚îÄ‚îÄ providers/       # Provider-specific implementations (OpenAI, Anthropic, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ schemas/         # Interfaces and structs used throughout Bifrost
‚îÇ   ‚îî‚îÄ‚îÄ bifrost.go       # Main Bifrost implementation
‚îú‚îÄ‚îÄ framework/           # Framework components for data persistence
‚îÇ   ‚îú‚îÄ‚îÄ configstore/     # Configuration storages
‚îÇ   ‚îú‚îÄ‚îÄ logstore/        # Request logging storages
‚îÇ   ‚îî‚îÄ‚îÄ vectorstore/     # Vector storages
‚îú‚îÄ‚îÄ transports/          # HTTP gateway and other interface layers
‚îÇ   ‚îî‚îÄ‚îÄ bifrost-http/    # HTTP transport implementation
‚îú‚îÄ‚îÄ ui/                  # Web interface for HTTP gateway
‚îú‚îÄ‚îÄ plugins/             # Extensible plugin system
‚îÇ   ‚îú‚îÄ‚îÄ governance/      # Budget management and access control
‚îÇ   ‚îú‚îÄ‚îÄ jsonparser/      # JSON parsing and manipulation utilities
‚îÇ   ‚îú‚îÄ‚îÄ logging/         # Request logging and analytics
‚îÇ   ‚îú‚îÄ‚îÄ maxim/           # Maxim's observability integration
‚îÇ   ‚îú‚îÄ‚îÄ mocker/          # Mock responses for testing and development
‚îÇ   ‚îú‚îÄ‚îÄ semanticcache/   # Intelligent response caching
‚îÇ   ‚îî‚îÄ‚îÄ telemetry/       # Monitoring and observability
‚îú‚îÄ‚îÄ docs/                # Documentation and guides
‚îî‚îÄ‚îÄ tests/               # Comprehensive test suites
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Getting Started Options&lt;/h2&gt; 
&lt;p&gt;Choose the deployment method that fits your needs:&lt;/p&gt; 
&lt;h3&gt;1. Gateway (HTTP API)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Language-agnostic integration, microservices, and production deployments&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# NPX - Get started in 30 seconds
npx -y @maximhq/bifrost

# Docker - Production ready
docker run -p 8080:8080 -v $(pwd)/data:/app/data maximhq/bifrost
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt; Web UI, real-time monitoring, multi-provider management, zero-config startup&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn More:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Gateway Setup Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Go SDK&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Direct Go integration with maximum performance and control&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/maximhq/bifrost/core
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt; Native Go APIs, embedded deployment, custom middleware integration&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn More:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/quickstart/go-sdk/setting-up"&gt;Go SDK Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;3. Drop-in Replacement&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Migrating existing applications with zero code changes&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-diff"&gt;# OpenAI SDK
- base_url = "https://api.openai.com"
+ base_url = "http://localhost:8080/openai"

# Anthropic SDK  
- base_url = "https://api.anthropic.com"
+ base_url = "http://localhost:8080/anthropic"

# Google GenAI SDK
- api_endpoint = "https://generativelanguage.googleapis.com"
+ api_endpoint = "http://localhost:8080/genai"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Learn More:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/integrations/what-is-an-integration"&gt;Integration Guides&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;Bifrost adds virtually zero overhead to your AI requests. In sustained 5,000 RPS benchmarks, the gateway added only &lt;strong&gt;11 ¬µs&lt;/strong&gt; of overhead per request.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;t3.medium&lt;/th&gt; 
   &lt;th&gt;t3.xlarge&lt;/th&gt; 
   &lt;th&gt;Improvement&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Added latency (Bifrost overhead)&lt;/td&gt; 
   &lt;td&gt;59 ¬µs&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;11 ¬µs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;-81%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Success rate @ 5k RPS&lt;/td&gt; 
   &lt;td&gt;100%&lt;/td&gt; 
   &lt;td&gt;100%&lt;/td&gt; 
   &lt;td&gt;No failed requests&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Avg. queue wait time&lt;/td&gt; 
   &lt;td&gt;47 ¬µs&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;1.67 ¬µs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;-96%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Avg. request latency (incl. provider)&lt;/td&gt; 
   &lt;td&gt;2.12 s&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;1.61 s&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;-24%&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Key Performance Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Perfect Success Rate&lt;/strong&gt; - 100% request success rate even at 5k RPS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Minimal Overhead&lt;/strong&gt; - Less than 15 ¬µs additional latency per request&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Queuing&lt;/strong&gt; - Sub-microsecond average wait times&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast Key Selection&lt;/strong&gt; - ~10 ns to pick weighted API keys&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Complete Benchmarks:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai/benchmarking/getting-started"&gt;Performance Analysis&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Complete Documentation:&lt;/strong&gt; &lt;a href="https://docs.getbifrost.ai"&gt;https://docs.getbifrost.ai&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/setting-up"&gt;Gateway Setup&lt;/a&gt; - HTTP API deployment in 30 seconds&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/go-sdk/setting-up"&gt;Go SDK Setup&lt;/a&gt; - Direct Go integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/quickstart/gateway/provider-configuration"&gt;Provider Configuration&lt;/a&gt; - Multi-provider setup&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/unified-interface"&gt;Multi-Provider Support&lt;/a&gt; - Single API for all providers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/mcp"&gt;MCP Integration&lt;/a&gt; - External tool calling&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/semantic-caching"&gt;Semantic Caching&lt;/a&gt; - Intelligent response caching&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/fallbacks"&gt;Fallbacks &amp;amp; Load Balancing&lt;/a&gt; - Reliability features&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/features/governance"&gt;Budget Management&lt;/a&gt; - Cost control and governance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/openai-sdk"&gt;OpenAI SDK&lt;/a&gt; - Drop-in OpenAI replacement&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/anthropic-sdk"&gt;Anthropic SDK&lt;/a&gt; - Drop-in Anthropic replacement&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/bedrock-sdk"&gt;AWS Bedrock SDK&lt;/a&gt; - AWS Bedrock integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/genai-sdk"&gt;Google GenAI SDK&lt;/a&gt; - Drop-in GenAI replacement&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/litellm-sdk"&gt;LiteLLM SDK&lt;/a&gt; - LiteLLM integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/integrations/langchain-sdk"&gt;Langchain SDK&lt;/a&gt; - Langchain integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enterprise&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/custom-plugins"&gt;Custom Plugins&lt;/a&gt; - Extend functionality&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/clustering"&gt;Clustering&lt;/a&gt; - Multi-node deployment&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/enterprise/vault-support"&gt;Vault Support&lt;/a&gt; - Secure key management&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.getbifrost.ai/deployment/docker-setup"&gt;Production Deployment&lt;/a&gt; - Scaling and monitoring&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Need Help?&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://discord.gg/exN5KAydbU"&gt;Join our Discord&lt;/a&gt;&lt;/strong&gt; for community support and discussions.&lt;/p&gt; 
&lt;p&gt;Get help with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Quick setup assistance and troubleshooting&lt;/li&gt; 
 &lt;li&gt;Best practices and configuration tips&lt;/li&gt; 
 &lt;li&gt;Community discussions and support&lt;/li&gt; 
 &lt;li&gt;Real-time help with integrations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of all kinds! See our &lt;a href="https://docs.getbifrost.ai/contributing/setting-up-repo"&gt;Contributing Guide&lt;/a&gt; for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setting up the development environment&lt;/li&gt; 
 &lt;li&gt;Code conventions and best practices&lt;/li&gt; 
 &lt;li&gt;How to submit pull requests&lt;/li&gt; 
 &lt;li&gt;Building and testing locally&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For development requirements and build instructions, see our &lt;a href="https://docs.getbifrost.ai/contributing/setting-up-repo#development-environment-setup"&gt;Development Setup Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="https://raw.githubusercontent.com/maximhq/bifrost/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p&gt;Built with ‚ù§Ô∏è by &lt;a href="https://github.com/maximhq"&gt;Maxim&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HavocFramework/Havoc</title>
      <link>https://github.com/HavocFramework/Havoc</link>
      <description>&lt;p&gt;The Havoc Framework&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img width="125px" src="https://raw.githubusercontent.com/HavocFramework/Havoc/main/assets/Havoc.png" /&gt; 
 &lt;h1&gt;Havoc&lt;/h1&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;i&gt;Havoc is a modern and malleable post-exploitation command and control framework, created by &lt;a href="https://twitter.com/C5pider"&gt;@C5pider&lt;/a&gt;.&lt;/i&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HavocFramework/Havoc/main/assets/Screenshots/FullSessionGraph.jpeg" width="90%" /&gt;&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/HavocFramework/Havoc/main/assets/Screenshots/MultiUserAgentControl.png" width="90%" /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Please see the &lt;a href="https://github.com/HavocFramework/Havoc/wiki"&gt;Wiki&lt;/a&gt; for complete documentation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Havoc works well on Debian 10/11, Ubuntu 20.04/22.04 and Kali Linux. It's recommended to use the latest versions possible to avoid issues. You'll need a modern version of Qt and Python 3.10.x to avoid build issues.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://havocframework.com/docs/installation"&gt;Installation&lt;/a&gt; docs for instructions. If you run into issues, check the &lt;a href="https://github.com/HavocFramework/Havoc/wiki#known-issues"&gt;Known Issues&lt;/a&gt; page as well as the open/closed &lt;a href="https://github.com/HavocFramework/Havoc/issues"&gt;Issues&lt;/a&gt; list.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;h4&gt;Client&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Cross-platform UI written in C++ and Qt&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Modern, dark theme based on &lt;a href="https://draculatheme.com/"&gt;Dracula&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Teamserver&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Written in Golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiplayer&lt;/li&gt; 
 &lt;li&gt;Payload generation (exe/shellcode/dll)&lt;/li&gt; 
 &lt;li&gt;HTTP/HTTPS listeners&lt;/li&gt; 
 &lt;li&gt;Customizable C2 profiles&lt;/li&gt; 
 &lt;li&gt;External C2&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Demon&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Havoc's flagship agent written in C and ASM&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sleep Obfuscation via &lt;a href="https://github.com/Cracked5pider/Ekko"&gt;Ekko&lt;/a&gt;, Ziliean or &lt;a href="https://github.com/SecIdiot/FOLIAGE"&gt;FOLIAGE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;x64 return address spoofing&lt;/li&gt; 
 &lt;li&gt;Indirect Syscalls for Nt* APIs&lt;/li&gt; 
 &lt;li&gt;SMB support&lt;/li&gt; 
 &lt;li&gt;Token vault&lt;/li&gt; 
 &lt;li&gt;Variety of built-in post-exploitation commands&lt;/li&gt; 
 &lt;li&gt;Patching Amsi/Etw via Hardware breakpoints&lt;/li&gt; 
 &lt;li&gt;Proxy library loading&lt;/li&gt; 
 &lt;li&gt;Stack duplication during sleep.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HavocFramework/Havoc/main/assets/Screenshots/SessionConsoleHelp.png" width="90%" /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h4&gt;Extensibility&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HavocFramework/Havoc/wiki#external-c2"&gt;External C2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Custom Agent Support 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/HavocFramework/Talon"&gt;Talon&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HavocFramework/havoc-py"&gt;Python API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/HavocFramework/Modules"&gt;Modules&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Community&lt;/h3&gt; 
&lt;p&gt;You can join the official &lt;a href="https://discord.gg/z3PF3NRDE5"&gt;Havoc Discord&lt;/a&gt; to chat with the community!&lt;/p&gt; 
&lt;h3&gt;Note&lt;/h3&gt; 
&lt;p&gt;Please do not open any issues regarding detection.&lt;/p&gt; 
&lt;p&gt;The Havoc Framework hasn't been developed to be evasive. Rather it has been designed to be as malleable &amp;amp; modular as possible. Giving the operator the capability to add custom features or modules that evades their targets detection system.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jesseduffield/lazydocker</title>
      <link>https://github.com/jesseduffield/lazydocker</link>
      <description>&lt;p&gt;The lazier way to manage everything docker&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;sup&gt;Special thanks to:&lt;/sup&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://www.warp.dev/?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=lazydocker_20231023"&gt; 
  &lt;div&gt; 
   &lt;img src="https://github.com/warpdotdev/brand-assets/raw/main/Github/Sponsor/Warp-Github-LG-02.png?raw=true" width="400" alt="Warp" /&gt; 
  &lt;/div&gt; &lt;b&gt;Warp, the intelligent terminal&lt;/b&gt; &lt;br /&gt; &lt;b&gt;Available for MacOS and Linux&lt;/b&gt; &lt;br /&gt; 
  &lt;div&gt; 
   &lt;sup&gt;Visit&amp;nbsp;warp.dev&amp;nbsp;to learn more.&lt;/sup&gt; 
  &lt;/div&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;hr /&gt; 
 &lt;a href="https://tuple.app/lazydocker"&gt; 
  &lt;div&gt; 
   &lt;img src="https://raw.githubusercontent.com/jesseduffield/lazydocker/master/assets/tuple.png" width="400" alt="Tuple" /&gt; 
  &lt;/div&gt; &lt;b&gt;Tuple, the premier screen sharing app for developers on macOS and Windows.&lt;/b&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;hr /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://www.subble.com/jobs/engineer"&gt; 
  &lt;div&gt; 
   &lt;img src="https://raw.githubusercontent.com/jesseduffield/lazydocker/master/assets/subble-job-ad.jpg" width="400" alt="Subble" /&gt; 
  &lt;/div&gt; &lt;b&gt;Click here to learn more&lt;/b&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;img src="https://user-images.githubusercontent.com/8456633/59972109-8e9c8480-95cc-11e9-8350-38f7f86ba76d.png" /&gt; &lt;/p&gt; 
&lt;p&gt;A simple terminal UI for both docker and docker-compose, written in Go with the &lt;a href="https://github.com/jroimartin/gocui" title="gocui"&gt;gocui&lt;/a&gt; library.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/jesseduffield/lazygit/workflows/Continuous%20Integration/badge.svg?sanitize=true" alt="CI" /&gt; &lt;a href="https://goreportcard.com/report/github.com/jesseduffield/lazydocker"&gt;&lt;img src="https://goreportcard.com/badge/github.com/jesseduffield/lazydocker" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://golangci.com"&gt;&lt;img src="https://golangci.com/badges/github.com/jesseduffield/lazydocker.svg?sanitize=true" alt="GolangCI" /&gt;&lt;/a&gt; &lt;a href="http://godoc.org/github.com/jesseduffield/lazydocker"&gt;&lt;img src="https://godoc.org/github.com/jesseduffield/lazydocker?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/repo-size/jesseduffield/lazydocker" alt="GitHub repo size" /&gt; &lt;a href="https://github.com/jesseduffield/lazydocker/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/jesseduffield/lazydocker/total" alt="GitHub Releases" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jesseduffield/lazydocker/releases/latest"&gt;&lt;img src="https://img.shields.io/github/tag/jesseduffield/lazydocker.svg?sanitize=true" alt="GitHub tag" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Homebrew/homebrew-core/raw/master/Formula/lazydocker.rb"&gt;&lt;img src="https://img.shields.io/homebrew/v/lazydocker" alt="homebrew" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazydocker/master/docs/resources/demo3.gif" alt="Gif" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/NICqQPxwJWw"&gt;Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p align="center"&gt; Maintenance of this project is made possible by all the &lt;a href="https://github.com/jesseduffield/lazydocker/graphs/contributors"&gt;contributors&lt;/a&gt; and &lt;a href="https://github.com/sponsors/jesseduffield"&gt;sponsors&lt;/a&gt;. If you'd like to sponsor this project and have your avatar or company logo appear below &lt;a href="https://github.com/sponsors/jesseduffield"&gt;click here&lt;/a&gt;. üíô &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- sponsors --&gt;&lt;a href="https://github.com/intabulas"&gt;&lt;img src="https://github.com/intabulas.png" width="60px" alt="Mark Lussier" /&gt;&lt;/a&gt;&lt;a href="https://github.com/peppy"&gt;&lt;img src="https://github.com/peppy.png" width="60px" alt="Dean Herbert" /&gt;&lt;/a&gt;&lt;a href="https://github.com/piot"&gt;&lt;img src="https://github.com/piot.png" width="60px" alt="Peter Bjorklund" /&gt;&lt;/a&gt;&lt;a href="https://github.com/rgwood"&gt;&lt;img src="https://github.com/rgwood.png" width="60px" alt="Reilly Wood" /&gt;&lt;/a&gt;&lt;a href="https://github.com/oliverguenther"&gt;&lt;img src="https://github.com/oliverguenther.png" width="60px" alt="Oliver G√ºnther" /&gt;&lt;/a&gt;&lt;a href="https://github.com/pawanjay176"&gt;&lt;img src="https://github.com/pawanjay176.png" width="60px" alt="Pawan Dhananjay" /&gt;&lt;/a&gt;&lt;a href="https://github.com/bdach"&gt;&lt;img src="https://github.com/bdach.png" width="60px" alt="Bart≈Çomiej Dach" /&gt;&lt;/a&gt;&lt;a href="https://github.com/davidklsn"&gt;&lt;img src="https://github.com/davidklsn.png" width="60px" alt="David Karlsson" /&gt;&lt;/a&gt;&lt;a href="https://github.com/carstengehling"&gt;&lt;img src="https://github.com/carstengehling.png" width="60px" alt="Carsten Gehling" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ceuk"&gt;&lt;img src="https://github.com/ceuk.png" width="60px" alt="CEUK" /&gt;&lt;/a&gt;&lt;a href="https://github.com/akospwc"&gt;&lt;img src="https://github.com/akospwc.png" width="60px" alt="Akos Putz" /&gt;&lt;/a&gt;&lt;a href="https://github.com/Xetera"&gt;&lt;img src="https://github.com/Xetera.png" width="60px" alt="Xetera" /&gt;&lt;/a&gt;&lt;a href="https://github.com/HoldenLucas"&gt;&lt;img src="https://github.com/HoldenLucas.png" width="60px" alt="Holden Lucas" /&gt;&lt;/a&gt;&lt;a href="https://github.com/nartc"&gt;&lt;img src="https://github.com/nartc.png" width="60px" alt="Chau Tran" /&gt;&lt;/a&gt;&lt;a href="https://github.com/matejcik"&gt;&lt;img src="https://github.com/matejcik.png" width="60px" alt="matejcik" /&gt;&lt;/a&gt;&lt;a href="https://github.com/lucatume"&gt;&lt;img src="https://github.com/lucatume.png" width="60px" alt="theAverageDev (Luca Tumedei)" /&gt;&lt;/a&gt;&lt;a href="https://github.com/IvanZuy"&gt;&lt;img src="https://github.com/IvanZuy.png" width="60px" alt="Ivan Zaitsev" /&gt;&lt;/a&gt;&lt;a href="https://github.com/nicholascloud"&gt;&lt;img src="https://github.com/nicholascloud.png" width="60px" alt="Nicholas Cloud" /&gt;&lt;/a&gt;&lt;a href="https://github.com/PhotonQuantum"&gt;&lt;img src="https://github.com/PhotonQuantum.png" width="60px" alt="LightQuantum" /&gt;&lt;/a&gt;&lt;a href="https://github.com/GitSquared"&gt;&lt;img src="https://github.com/GitSquared.png" width="60px" alt="Gabriel Saillard" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ava1ar"&gt;&lt;img src="https://github.com/ava1ar.png" width="60px" alt="Aliaksandr Stelmachonak" /&gt;&lt;/a&gt;&lt;a href="https://github.com/minidfx"&gt;&lt;img src="https://github.com/minidfx.png" width="60px" alt="Burgy Benjamin" /&gt;&lt;/a&gt;&lt;a href="https://github.com/JoeKlemmer"&gt;&lt;img src="https://github.com/JoeKlemmer.png" width="60px" alt="Joe Klemmer" /&gt;&lt;/a&gt;&lt;a href="https://github.com/tobi"&gt;&lt;img src="https://github.com/tobi.png" width="60px" alt="Tobias L√ºtke" /&gt;&lt;/a&gt;&lt;a href="https://github.com/benbfortis"&gt;&lt;img src="https://github.com/benbfortis.png" width="60px" alt="Ben Beaumont" /&gt;&lt;/a&gt;&lt;a href="https://github.com/jakewarren"&gt;&lt;img src="https://github.com/jakewarren.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/tgpholly"&gt;&lt;img src="https://github.com/tgpholly.png" width="60px" alt="Holly" /&gt;&lt;/a&gt;&lt;a href="https://github.com/jisantuc"&gt;&lt;img src="https://github.com/jisantuc.png" width="60px" alt="James Santucci" /&gt;&lt;/a&gt;&lt;a href="https://github.com/bitprophet"&gt;&lt;img src="https://github.com/bitprophet.png" width="60px" alt="Jeff Forcier" /&gt;&lt;/a&gt;&lt;a href="https://github.com/tayleighr"&gt;&lt;img src="https://github.com/tayleighr.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/Novakov"&gt;&lt;img src="https://github.com/Novakov.png" width="60px" alt="Maciej T. Nowak" /&gt;&lt;/a&gt;&lt;a href="https://github.com/farzadmf"&gt;&lt;img src="https://github.com/farzadmf.png" width="60px" alt="Farzad Majidfayyaz" /&gt;&lt;/a&gt;&lt;a href="https://github.com/nekhaevskiy"&gt;&lt;img src="https://github.com/nekhaevskiy.png" width="60px" alt="Yury" /&gt;&lt;/a&gt;&lt;a href="https://github.com/reivilibre"&gt;&lt;img src="https://github.com/reivilibre.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/andreaskurth"&gt;&lt;img src="https://github.com/andreaskurth.png" width="60px" alt="Andreas Kurth" /&gt;&lt;/a&gt;&lt;a href="https://github.com/BSteffaniak"&gt;&lt;img src="https://github.com/BSteffaniak.png" width="60px" alt="Braden Steffaniak" /&gt;&lt;/a&gt;&lt;a href="https://github.com/jordan-gillard"&gt;&lt;img src="https://github.com/jordan-gillard.png" width="60px" alt="Jordan Gillard" /&gt;&lt;/a&gt;&lt;a href="https://github.com/smangels"&gt;&lt;img src="https://github.com/smangels.png" width="60px" alt="Sebastian" /&gt;&lt;/a&gt;&lt;a href="https://github.com/George-Spanos"&gt;&lt;img src="https://github.com/George-Spanos.png" width="60px" alt="George Spanos" /&gt;&lt;/a&gt;&lt;a href="https://github.com/frantisekstanko"&gt;&lt;img src="https://github.com/frantisekstanko.png" width="60px" alt="Frantisek Stanko" /&gt;&lt;/a&gt;&lt;a href="https://github.com/amslezak"&gt;&lt;img src="https://github.com/amslezak.png" width="60px" alt="Andy Slezak" /&gt;&lt;/a&gt;&lt;a href="https://github.com/mkock"&gt;&lt;img src="https://github.com/mkock.png" width="60px" alt="Martin Kock" /&gt;&lt;/a&gt;&lt;a href="https://github.com/illarionvk"&gt;&lt;img src="https://github.com/illarionvk.png" width="60px" alt="Illarion Koperski" /&gt;&lt;/a&gt;&lt;a href="https://github.com/WhiteBlackGoose"&gt;&lt;img src="https://github.com/WhiteBlackGoose.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/jessealama"&gt;&lt;img src="https://github.com/jessealama.png" width="60px" alt="Jesse Alama" /&gt;&lt;/a&gt;&lt;a href="https://github.com/codacy"&gt;&lt;img src="https://github.com/codacy.png" width="60px" alt="Codacy" /&gt;&lt;/a&gt;&lt;a href="https://github.com/colbr"&gt;&lt;img src="https://github.com/colbr.png" width="60px" alt="Brett" /&gt;&lt;/a&gt;&lt;a href="https://github.com/heijmans"&gt;&lt;img src="https://github.com/heijmans.png" width="60px" alt="Jan Heijmans" /&gt;&lt;/a&gt;&lt;a href="https://github.com/Vesther"&gt;&lt;img src="https://github.com/Vesther.png" width="60px" alt="Kevin Nowald" /&gt;&lt;/a&gt;&lt;a href="https://github.com/sempruijs"&gt;&lt;img src="https://github.com/sempruijs.png" width="60px" alt="sem pruijs" /&gt;&lt;/a&gt;&lt;a href="https://github.com/omarluq"&gt;&lt;img src="https://github.com/omarluq.png" width="60px" alt="Omar Luq " /&gt;&lt;/a&gt;&lt;a href="https://github.com/ethanjli"&gt;&lt;img src="https://github.com/ethanjli.png" width="60px" alt="Ethan Li" /&gt;&lt;/a&gt;&lt;a href="https://github.com/phubaba"&gt;&lt;img src="https://github.com/phubaba.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/fomrat"&gt;&lt;img src="https://github.com/fomrat.png" width="60px" alt="Brian MacAskill" /&gt;&lt;/a&gt;&lt;a href="https://github.com/canhazcodez"&gt;&lt;img src="https://github.com/canhazcodez.png" width="60px" alt="Maxi" /&gt;&lt;/a&gt;&lt;a href="https://github.com/nikbrunner"&gt;&lt;img src="https://github.com/nikbrunner.png" width="60px" alt="nbr" /&gt;&lt;/a&gt;&lt;a href="https://github.com/neunkasulle"&gt;&lt;img src="https://github.com/neunkasulle.png" width="60px" alt="Jan Zenkner" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ahkohd"&gt;&lt;img src="https://github.com/ahkohd.png" width="60px" alt="Victor Aremu" /&gt;&lt;/a&gt;&lt;a href="https://github.com/RVxLab"&gt;&lt;img src="https://github.com/RVxLab.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/igor-ramazanov"&gt;&lt;img src="https://github.com/igor-ramazanov.png" width="60px" alt="Igor Ramazanov" /&gt;&lt;/a&gt;&lt;a href="https://github.com/glotchimo"&gt;&lt;img src="https://github.com/glotchimo.png" width="60px" alt="Elliott Maguire" /&gt;&lt;/a&gt;&lt;a href="https://github.com/n8nio"&gt;&lt;img src="https://github.com/n8nio.png" width="60px" alt="n8n - Workflow Automation" /&gt;&lt;/a&gt;&lt;a href="https://github.com/kaleballmon"&gt;&lt;img src="https://github.com/kaleballmon.png" width="60px" alt="kaleb allmon" /&gt;&lt;/a&gt;&lt;a href="https://github.com/joshuadavidthomas"&gt;&lt;img src="https://github.com/joshuadavidthomas.png" width="60px" alt="Josh Thomas" /&gt;&lt;/a&gt;&lt;a href="https://github.com/josephjacks"&gt;&lt;img src="https://github.com/josephjacks.png" width="60px" alt="JJ" /&gt;&lt;/a&gt;&lt;a href="https://github.com/FrederickGeek8"&gt;&lt;img src="https://github.com/FrederickGeek8.png" width="60px" alt="Frederick Morlock" /&gt;&lt;/a&gt;&lt;a href="https://github.com/agrippanux"&gt;&lt;img src="https://github.com/agrippanux.png" width="60px" alt="Darren Craine" /&gt;&lt;/a&gt;&lt;a href="https://github.com/ezdac"&gt;&lt;img src="https://github.com/ezdac.png" width="60px" alt="Maximilian Langenfeld" /&gt;&lt;/a&gt;&lt;a href="https://github.com/sarzhann"&gt;&lt;img src="https://github.com/sarzhann.png" width="60px" alt="Nurzhan" /&gt;&lt;/a&gt;&lt;a href="https://github.com/dbuls"&gt;&lt;img src="https://github.com/dbuls.png" width="60px" alt="Davis Buls" /&gt;&lt;/a&gt;&lt;a href="https://github.com/MGreek"&gt;&lt;img src="https://github.com/MGreek.png" width="60px" alt="Grec Marc" /&gt;&lt;/a&gt;&lt;a href="https://github.com/sainu"&gt;&lt;img src="https://github.com/sainu.png" width="60px" alt="sainu" /&gt;&lt;/a&gt;&lt;a href="https://github.com/mguellsegarra"&gt;&lt;img src="https://github.com/mguellsegarra.png" width="60px" alt="Marc G√ºell Segarra" /&gt;&lt;/a&gt;&lt;a href="https://github.com/lppassos"&gt;&lt;img src="https://github.com/lppassos.png" width="60px" alt="" /&gt;&lt;/a&gt;&lt;a href="https://github.com/chrisolsen"&gt;&lt;img src="https://github.com/chrisolsen.png" width="60px" alt="Chris Olsen" /&gt;&lt;/a&gt;&lt;a href="https://github.com/vladimir-popov"&gt;&lt;img src="https://github.com/vladimir-popov.png" width="60px" alt="Vladimir Popov" /&gt;&lt;/a&gt;&lt;a href="https://github.com/neilcode"&gt;&lt;img src="https://github.com/neilcode.png" width="60px" alt="Neil Lambert" /&gt;&lt;/a&gt;&lt;a href="https://github.com/shaungarwood"&gt;&lt;img src="https://github.com/shaungarwood.png" width="60px" alt="Shaun Garwood" /&gt;&lt;/a&gt;&lt;a href="https://github.com/dhh"&gt;&lt;img src="https://github.com/dhh.png" width="60px" alt="David Heinemeier Hansson" /&gt;&lt;/a&gt;&lt;a href="https://github.com/wayanjimmy"&gt;&lt;img src="https://github.com/wayanjimmy.png" width="60px" alt="Wayan jimmy" /&gt;&lt;/a&gt;
 &lt;!-- sponsors --&gt; &lt;/p&gt; 
&lt;h2&gt;Elevator Pitch&lt;/h2&gt; 
&lt;p&gt;Minor rant incoming: Something's not working? Maybe a service is down. &lt;code&gt;docker-compose ps&lt;/code&gt;. Yep, it's that microservice that's still buggy. No issue, I'll just restart it: &lt;code&gt;docker-compose restart&lt;/code&gt;. Okay now let's try again. Oh wait the issue is still there. Hmm. &lt;code&gt;docker-compose ps&lt;/code&gt;. Right so the service must have just stopped immediately after starting. I probably would have known that if I was reading the log stream, but there is a lot of clutter in there from other services. I could get the logs for just that one service with &lt;code&gt;docker compose logs --follow myservice&lt;/code&gt; but that dies everytime the service dies so I'd need to run that command every time I restart the service. I could alternatively run &lt;code&gt;docker-compose up myservice&lt;/code&gt; and in that terminal window if the service is down I could just &lt;code&gt;up&lt;/code&gt; it again, but now I've got one service hogging a terminal window even after I no longer care about its logs. I guess when I want to reclaim the terminal realestate I can do &lt;code&gt;ctrl+P,Q&lt;/code&gt;, but... wait, that's not working for some reason. Should I use ctrl+C instead? I can't remember if that closes the foreground process or kills the actual service.&lt;/p&gt; 
&lt;p&gt;What a headache!&lt;/p&gt; 
&lt;p&gt;Memorising docker commands is hard. Memorising aliases is slightly less hard. Keeping track of your containers across multiple terminal windows is near impossible. What if you had all the information you needed in one terminal window with every common command living one keypress away (and the ability to add custom commands as well). Lazydocker's goal is to make that dream a reality.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jesseduffield/lazydocker#requirements"&gt;Requirements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jesseduffield/lazydocker#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jesseduffield/lazydocker#usage"&gt;Usage&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazydocker/master/docs/keybindings"&gt;Keybindings&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jesseduffield/lazydocker#cool-features"&gt;Cool Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jesseduffield/lazydocker#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/NICqQPxwJWw"&gt;Video Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jesseduffield/lazydocker/master/docs/Config.md"&gt;Config Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.twitch.tv/jesseduffield"&gt;Twitch Stream&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jesseduffield/lazydocker#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docker &amp;gt;= &lt;strong&gt;29.0.0&lt;/strong&gt; (API &amp;gt;= &lt;strong&gt;1.24&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;Docker-Compose &amp;gt;= &lt;strong&gt;1.23.2&lt;/strong&gt; (optional)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Homebrew&lt;/h3&gt; 
&lt;p&gt;Normally &lt;code&gt;lazydocker&lt;/code&gt; formula can be found in the Homebrew core but we suggest you to tap our formula to get frequently updated one. It works with Linux, too.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tap&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install jesseduffield/lazydocker/lazydocker
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Core&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install lazydocker
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scoop (Windows)&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;lazydocker&lt;/code&gt; using &lt;a href="https://scoop.sh/"&gt;scoop&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;scoop install lazydocker
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Chocolatey (Windows)&lt;/h3&gt; 
&lt;p&gt;You can install &lt;code&gt;lazydocker&lt;/code&gt; using &lt;a href="https://chocolatey.org/"&gt;Chocolatey&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;choco install lazydocker
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;asdf-vm&lt;/h3&gt; 
&lt;p&gt;You can install &lt;a href="https://github.com/comdotlinux/asdf-lazydocker"&gt;asdf-lazydocker plugin&lt;/a&gt; using &lt;a href="https://asdf-vm.com/"&gt;asdf-vm&lt;/a&gt;:&lt;/p&gt; 
&lt;h4&gt;Setup (Once)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;asdf plugin add lazydocker https://github.com/comdotlinux/asdf-lazydocker.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;For Install / Upgrade&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;asdf list all lazydocker
asdf install lazydocker latest
asdf global lazydocker latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Binary Release (Linux/OSX/Windows)&lt;/h3&gt; 
&lt;p&gt;You can manually download a binary release from &lt;a href="https://github.com/jesseduffield/lazydocker/releases"&gt;the release page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Automated install/update, don't forget to always verify what you're piping into bash:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl https://raw.githubusercontent.com/jesseduffield/lazydocker/master/scripts/install_update_linux.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The script installs downloaded binary to &lt;code&gt;$HOME/.local/bin&lt;/code&gt; directory by default, but it can be changed by setting &lt;code&gt;DIR&lt;/code&gt; environment variable.&lt;/p&gt; 
&lt;h3&gt;Go&lt;/h3&gt; 
&lt;p&gt;Required Go Version &amp;gt;= &lt;strong&gt;1.19&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/jesseduffield/lazydocker@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Required Go version &amp;gt;= &lt;strong&gt;1.8&lt;/strong&gt;, &amp;lt;= &lt;strong&gt;1.17&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go get github.com/jesseduffield/lazydocker
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Arch Linux AUR&lt;/h3&gt; 
&lt;p&gt;You can install lazydocker using the &lt;a href="https://aur.archlinux.org/packages/lazydocker"&gt;AUR&lt;/a&gt; by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;yay -S lazydocker
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/lazyteam/lazydocker"&gt;&lt;img src="https://img.shields.io/docker/pulls/lazyteam/lazydocker.svg?sanitize=true" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/lazyteam/lazydocker"&gt;&lt;img src="https://img.shields.io/docker/stars/lazyteam/lazydocker.svg?sanitize=true" alt="Docker Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/lazyteam/lazydocker"&gt;&lt;img src="https://img.shields.io/docker/cloud/automated/lazyteam/lazydocker.svg?sanitize=true" alt="Docker Automated" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; 
  &lt;details&gt;
   &lt;summary&gt;Click if you have an ARM device&lt;/summary&gt;
   &lt;p&gt; &lt;/p&gt;
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;If you have a ARM 32 bit v6 architecture&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t lazyteam/lazydocker \
--build-arg BASE_IMAGE_BUILDER=arm32v6/golang \
--build-arg GOARCH=arm \
--build-arg GOARM=6 \
https://github.com/jesseduffield/lazydocker.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;If you have a ARM 32 bit v7 architecture&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t lazyteam/lazydocker \
--build-arg BASE_IMAGE_BUILDER=arm32v7/golang \
--build-arg GOARCH=arm \
--build-arg GOARM=7 \
https://github.com/jesseduffield/lazydocker.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;If you have a ARM 64 bit v8 architecture&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t lazyteam/lazydocker \
--build-arg BASE_IMAGE_BUILDER=arm64v8/golang \
--build-arg GOARCH=arm64 \
https://github.com/jesseduffield/lazydocker.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
   &lt;p&gt;&lt;/p&gt;
  &lt;/details&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the container&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;docker run --rm -it -v \
/var/run/docker.sock:/var/run/docker.sock \
-v /yourpath:/.config/jesseduffield/lazydocker \
lazyteam/lazydocker
&lt;/code&gt;&lt;/pre&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Don't forget to change &lt;code&gt;/yourpath&lt;/code&gt; to an actual path you created to store lazydocker's config&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;You can also use this &lt;a href="https://github.com/jesseduffield/lazydocker/raw/master/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;You might want to create an alias, for example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;echo "alias lzd='docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock -v /yourpath/config:/.config/jesseduffield/lazydocker lazyteam/lazydocker'" &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For development, you can build the image using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/jesseduffield/lazydocker.git
cd lazydocker
docker build -t lazyteam/lazydocker \
    --build-arg BUILD_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ"` \
    --build-arg VCS_REF=`git rev-parse --short HEAD` \
    --build-arg VERSION=`git describe --abbrev=0 --tag` \
    .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you encounter a compatibility issue with Docker bundled binary, try rebuilding the image with the build argument &lt;code&gt;--build-arg DOCKER_VERSION="v$(docker -v | cut -d" " -f3 | rev | cut -c 2- | rev)"&lt;/code&gt; so that the bundled docker binary matches your host docker binary version.&lt;/p&gt; 
&lt;h3&gt;Manual&lt;/h3&gt; 
&lt;p&gt;You'll need to &lt;a href="https://golang.org/doc/install"&gt;install Go&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/jesseduffield/lazydocker.git
cd lazydocker
go install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use &lt;code&gt;go run main.go&lt;/code&gt; to compile and run in one go (pun definitely intended)&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Call &lt;code&gt;lazydocker&lt;/code&gt; in your terminal. I personally use this a lot so I've made an alias for it like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;echo "alias lzd='lazydocker'" &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(you can substitute .zshrc for whatever rc file you're using)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Basic video tutorial &lt;a href="https://youtu.be/NICqQPxwJWw"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;List of keybindings &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazydocker/master/docs/keybindings"&gt;here&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cool features&lt;/h2&gt; 
&lt;p&gt;everything is one keypress away (or one click away! Mouse support FTW):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;viewing the state of your docker or docker-compose container environment at a glance&lt;/li&gt; 
 &lt;li&gt;viewing logs for a container/service&lt;/li&gt; 
 &lt;li&gt;viewing ascii graphs of your containers' metrics so that you can not only feel but also look like a developer&lt;/li&gt; 
 &lt;li&gt;customising those graphs to measure nearly any metric you want&lt;/li&gt; 
 &lt;li&gt;attaching to a container/service&lt;/li&gt; 
 &lt;li&gt;restarting/removing/rebuilding containers/services&lt;/li&gt; 
 &lt;li&gt;viewing the ancestor layers of a given image&lt;/li&gt; 
 &lt;li&gt;pruning containers, images, or volumes that are hogging up disk space&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;There is still a lot of work to go! Please check out the &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazydocker/master/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt;. For contributor discussion about things not better discussed here in the repo, join the discord channel&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/ehwFt2t4wt"&gt;&lt;img src="https://raw.githubusercontent.com/jesseduffield/lazydocker/master/docs/resources/discord.png" width="75" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Donate&lt;/h2&gt; 
&lt;p&gt;If you would like to support the development of lazydocker, consider &lt;a href="https://github.com/sponsors/jesseduffield"&gt;sponsoring me&lt;/a&gt; (github is matching all donations dollar-for-dollar for 12 months)&lt;/p&gt; 
&lt;h2&gt;Social&lt;/h2&gt; 
&lt;p&gt;If you want to see what I (Jesse) am up to in terms of development, follow me on &lt;a href="https://twitter.com/DuffieldJesse"&gt;twitter&lt;/a&gt; or watch me program on &lt;a href="https://www.twitch.tv/jesseduffield"&gt;twitch&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;How do I edit my config?&lt;/h3&gt; 
&lt;p&gt;By opening lazydocker, clicking on the 'project' panel in the top left, and pressing 'o' (or 'e' if your editor is vim). See &lt;a href="https://raw.githubusercontent.com/jesseduffield/lazydocker/master/docs/Config.md"&gt;Config Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;How do I get text to wrap in my main panel?&lt;/h3&gt; 
&lt;p&gt;In the future I want to make this the default, but for now there are some CPU issues that arise with wrapping. If you want to enable wrapping, use &lt;code&gt;gui.wrapMainPanel: true&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;How do you select text?&lt;/h3&gt; 
&lt;p&gt;Because we support mouse events, you will need to hold option while dragging the mouse to indicate you're trying to select text rather than click on something. Alternatively you can disable mouse events via the &lt;code&gt;gui.ignoreMouseEvents&lt;/code&gt; config value.&lt;/p&gt; 
&lt;p&gt;Mac Users: See &lt;a href="https://github.com/jesseduffield/lazydocker/issues/190"&gt;Issue #190&lt;/a&gt; for other options.&lt;/p&gt; 
&lt;h3&gt;Why can't I see my container's logs?&lt;/h3&gt; 
&lt;p&gt;By default we only show logs from the last hour, so that we're not putting too much strain on the machine. This may be why you can't see logs when you first start lazydocker. This can be overwritten in the config's &lt;code&gt;commandTemplates&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you are running lazydocker in Docker container, it is a know bug, that you can't see logs or CPU usage.&lt;/p&gt; 
&lt;h2&gt;Alternatives&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/skanehira/docui"&gt;docui&lt;/a&gt; - Skanehira beat me to the punch on making a docker terminal UI, so definitely check out that repo as well! I think the two repos can live in harmony though: lazydocker is more about managing existing containers/services, and docui is more about creating and configuring them.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/portainer/portainer"&gt;Portainer&lt;/a&gt; - Portainer tries to solve the same problem but it's accessed via your browser rather than your terminal. It also supports docker swarm.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/veggiemonk/awesome-docker/raw/master/README.md#terminal"&gt;Awesome Docker list&lt;/a&gt; for similar tools to work with Docker.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>mudler/LocalAI</title>
      <link>https://github.com/mudler/LocalAI</link>
      <description>&lt;p&gt;ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, MCP, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;img width="300" src="https://raw.githubusercontent.com/mudler/LocalAI/master/core/http/static/logo.png" /&gt; &lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/go-skynet/LocalAI/fork" target="blank"&gt; &lt;img src="https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI forks" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/stargazers" target="blank"&gt; &lt;img src="https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/pulls" target="blank"&gt; &lt;img src="https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI pull-requests" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/releases"&gt; &lt;img src="https://img.shields.io/github/release/go-skynet/LocalAI?&amp;amp;label=Latest&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://hub.docker.com/r/localai/localai" target="blank"&gt; &lt;img src="https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker" alt="LocalAI Docker hub" /&gt; &lt;/a&gt; &lt;a href="https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;amp;tag=latest" target="blank"&gt; &lt;img src="https://img.shields.io/badge/quay.io-images-important.svg?" alt="LocalAI Quay.io" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://twitter.com/LocalAI_API" target="blank"&gt; &lt;img src="https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;amp;logo=X&amp;amp;logoColor=white&amp;amp;label=LocalAI_API" alt="Follow LocalAI_API" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy" target="blank"&gt; &lt;img src="https://img.shields.io/badge/dynamic/json?color=blue&amp;amp;label=Discord&amp;amp;style=for-the-badge&amp;amp;query=approximate_member_count&amp;amp;url=https%3A%2F%2Fdiscordapp.com%2Fapi%2Finvites%2FuJAeKSAGDy%3Fwith_counts%3Dtrue&amp;amp;logo=discord" alt="Join LocalAI Discord Community" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/5539" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/5539" alt="mudler%2FLocalAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;üí°&lt;/span&gt; Get help - &lt;a href="https://localai.io/faq/"&gt;‚ùìFAQ&lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/discussions"&gt;üí≠Discussions&lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy"&gt;&lt;span&gt;üí¨&lt;/span&gt; Discord&lt;/a&gt; &lt;a href="https://localai.io/"&gt;&lt;span&gt;üìñ&lt;/span&gt; Documentation website&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://localai.io/basics/getting_started/"&gt;üíª Quickstart&lt;/a&gt; &lt;a href="https://models.localai.io/"&gt;üñºÔ∏è Models&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;üöÄ Roadmap&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;üõ´ Examples&lt;/a&gt; Try on &lt;a href="https://t.me/localaiofficial_bot"&gt;&lt;img src="https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;amp;logo=telegram&amp;amp;logoColor=white" alt="Telegram" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg?sanitize=true" alt="tests" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="Build and Release" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg?sanitize=true" alt="build container images" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg?sanitize=true" alt="Bump dependencies" /&gt;&lt;/a&gt;&lt;a href="https://artifacthub.io/packages/search?repo=localai"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;LocalAI&lt;/strong&gt; is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by &lt;a href="https://github.com/mudler"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìöüÜï Local Stack Family&lt;/h2&gt; 
&lt;p&gt;üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png" width="300" alt="LocalAGI Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI's Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalRecall"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png" width="300" alt="LocalRecall Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Screenshots / Video&lt;/h2&gt; 
&lt;h3&gt;Youtube video&lt;/h3&gt; 
&lt;h1 align="center"&gt; &lt;br /&gt; &lt;a href="https://www.youtube.com/watch?v=PDqYhB9nNHA" target="_blank"&gt; &lt;img width="300" src="https://img.youtube.com/vi/PDqYhB9nNHA/0.jpg" /&gt; &lt;/a&gt;&lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;h3&gt;Screenshots&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Talk Interface&lt;/th&gt; 
   &lt;th&gt;Generate Audio&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Models Overview&lt;/th&gt; 
   &lt;th&gt;Generate Images&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_gallery.png" alt="Screenshot 2025-03-31 at 12-01-20 LocalAI - Models" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_image.png" alt="Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chat Interface&lt;/th&gt; 
   &lt;th&gt;Home&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_chat.png" alt="Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_home.png" alt="Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Login&lt;/th&gt; 
   &lt;th&gt;Swarm&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_login.png" alt="Screenshot 2025-03-31 at 12-09-59 " /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_p2p.png" alt="Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üíª Quickstart&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Note:&lt;/strong&gt; The &lt;code&gt;install.sh&lt;/code&gt; script is currently experiencing issues due to the heavy changes currently undergoing in LocalAI and may produce broken or misconfigured installations. Please use Docker installation (see below) or manual binary installation until &lt;a href="https://github.com/mudler/LocalAI/issues/8032"&gt;issue #8032&lt;/a&gt; is resolved.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Run the installer script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
curl https://localai.io/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more installation options, see &lt;a href="https://localai.io/installation/"&gt;Installer Options&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;macOS Download:&lt;/h3&gt; 
&lt;a href="https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg"&gt; &lt;img src="https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="Download LocalAI for macOS" /&gt; &lt;/a&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: the DMGs are not signed by Apple as quarantined. See &lt;a href="https://github.com/mudler/LocalAI/issues/6268"&gt;https://github.com/mudler/LocalAI/issues/6268&lt;/a&gt; for a workaround, fix is tracked here: &lt;a href="https://github.com/mudler/LocalAI/issues/6244"&gt;https://github.com/mudler/LocalAI/issues/6244&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Containers (Docker, podman, ...)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Docker Run vs Docker Start&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;docker run&lt;/code&gt; creates and starts a new container. If a container with the same name already exists, this command will fail.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;docker start&lt;/code&gt; starts an existing container that was previously created with &lt;code&gt;docker run&lt;/code&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you've already run LocalAI before and want to start it again, use: &lt;code&gt;docker start -i local-ai&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;CPU only image:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;NVIDIA GPU Images:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CUDA 13.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-13

# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# NVIDIA Jetson (L4T) ARM64
# CUDA 12 (for Nvidia AGX Orin and similar platforms)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64

# CUDA 13 (for Nvidia DGX Spark)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64-cuda-13
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;AMD GPU Images (ROCm):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Intel GPU Images (oneAPI):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Vulkan GPU Images:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;AIO Images (pre-downloaded models):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 13 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-13

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information about the AIO images and pre-downloaded models, see &lt;a href="https://localai.io/basics/container/"&gt;Container Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To load models:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö° &lt;strong&gt;Automatic Backend Detection&lt;/strong&gt;: When you install models from the gallery or YAML files, LocalAI automatically detects your system's GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see &lt;a href="https://localai.io/features/gpu-acceleration/#automatic-backend-detection"&gt;GPU Acceleration&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more information, see &lt;a href="https://localai.io/basics/getting_started/index.html"&gt;üíª Getting started&lt;/a&gt;, if you are interested in our roadmap items and future enhancements, you can see the &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;Issues labeled as Roadmap here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∞ Latest project news&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;December 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/7583"&gt;Dynamic Memory Resource reclaimer&lt;/a&gt;, &lt;a href="https://github.com/mudler/LocalAI/pull/7584"&gt;Automatic fitting of models to multiple GPUS(llama.cpp)&lt;/a&gt;, &lt;a href="https://github.com/mudler/LocalAI/pull/7494"&gt;Added Vibevoice backend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;November 2025: Major improvements to the UX. Among these: &lt;a href="https://github.com/mudler/LocalAI/pull/7245"&gt;Import models via URL&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalAI/pull/7325"&gt;Multiple chats and history&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;October 2025: üîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; support added for agentic capabilities with external tools&lt;/li&gt; 
 &lt;li&gt;September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.&lt;/li&gt; 
 &lt;li&gt;August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with &lt;code&gt;development&lt;/code&gt; suffix in the gallery ): &lt;a href="https://github.com/mudler/LocalAI/pull/6049"&gt;https://github.com/mudler/LocalAI/pull/6049&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6119"&gt;https://github.com/mudler/LocalAI/pull/6119&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6121"&gt;https://github.com/mudler/LocalAI/pull/6121&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6060"&gt;https://github.com/mudler/LocalAI/pull/6060&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July/August 2025: üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt; added to the API featuring &lt;a href="https://github.com/roboflow/rf-detr"&gt;rf-detr&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v3.2.0"&gt;Read the release notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;Backend management&lt;/a&gt; has been added. Attention: extras images are going to be deprecated from the next release! Read &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;the backend management PR&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5466"&gt;Audio input&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalAI/pull/5396"&gt;Reranking&lt;/a&gt; in llama.cpp backend, &lt;a href="https://github.com/mudler/LocalAI/pull/5392"&gt;Realtime API&lt;/a&gt;, Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).&lt;/li&gt; 
 &lt;li&gt;May 2025: Important: image name changes &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v2.29.0"&gt;See release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Apr 2025: Rebrand, WebUI enhancements&lt;/li&gt; 
 &lt;li&gt;Apr 2025: &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt; join the LocalAI family stack.&lt;/li&gt; 
 &lt;li&gt;Apr 2025: WebUI overhaul, AIO images updates&lt;/li&gt; 
 &lt;li&gt;Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images&lt;/li&gt; 
 &lt;li&gt;Jan 2025: LocalAI model release: &lt;a href="https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3"&gt;https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3&lt;/a&gt;, SANA support in diffusers: &lt;a href="https://github.com/mudler/LocalAI/pull/4603"&gt;https://github.com/mudler/LocalAI/pull/4603&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dec 2024: stablediffusion.cpp backend (ggml) added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4289"&gt;https://github.com/mudler/LocalAI/pull/4289&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Bark.cpp backend added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4287"&gt;https://github.com/mudler/LocalAI/pull/4287&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Voice activity detection models (&lt;strong&gt;VAD&lt;/strong&gt;) added to the API: &lt;a href="https://github.com/mudler/LocalAI/pull/4204"&gt;https://github.com/mudler/LocalAI/pull/4204&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Oct 2024: examples moved to &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;LocalAI-examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Aug 2024: üÜï FLUX-1, &lt;a href="https://explorer.localai.io"&gt;P2P Explorer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: &lt;a href="https://github.com/mudler/LocalAI/pull/2723"&gt;https://github.com/mudler/LocalAI/pull/2723&lt;/a&gt;. P2P Global community pools: &lt;a href="https://github.com/mudler/LocalAI/issues/3113"&gt;https://github.com/mudler/LocalAI/issues/3113&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Decentralized P2P llama.cpp: &lt;a href="https://github.com/mudler/LocalAI/pull/2343"&gt;https://github.com/mudler/LocalAI/pull/2343&lt;/a&gt; (peer2peer llama.cpp!) üëâ Docs &lt;a href="https://localai.io/features/distribute/"&gt;https://localai.io/features/distribute/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Distributed inferencing: &lt;a href="https://github.com/mudler/LocalAI/pull/2324"&gt;https://github.com/mudler/LocalAI/pull/2324&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;April 2024: Reranker API: &lt;a href="https://github.com/mudler/LocalAI/pull/2121"&gt;https://github.com/mudler/LocalAI/pull/2121&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Roadmap items: &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;List of issues&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ &lt;a href="https://localai.io/features/"&gt;Features&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß© &lt;a href="https://localai.io/backends/"&gt;Backend Gallery&lt;/a&gt;: Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://localai.io/features/text-generation/"&gt;Text generation with GPTs&lt;/a&gt; (&lt;code&gt;llama.cpp&lt;/code&gt;, &lt;code&gt;transformers&lt;/code&gt;, &lt;code&gt;vllm&lt;/code&gt; ... &lt;a href="https://localai.io/model-compatibility/index.html#model-compatibility-table"&gt;&lt;span&gt;üìñ&lt;/span&gt; and more&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üó£ &lt;a href="https://localai.io/features/text-to-audio/"&gt;Text to Audio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîà &lt;a href="https://localai.io/features/audio-to-text/"&gt;Audio to Text&lt;/a&gt; (Audio transcription with &lt;code&gt;whisper.cpp&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;üé® &lt;a href="https://localai.io/features/image-generation"&gt;Image generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî• &lt;a href="https://localai.io/features/openai-functions/"&gt;OpenAI-alike tools API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß† &lt;a href="https://localai.io/features/embeddings/"&gt;Embeddings generation for vector databases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;a href="https://localai.io/features/constrained_grammars/"&gt;Constrained grammars&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üñºÔ∏è &lt;a href="https://localai.io/models/"&gt;Download Models directly from Huggingface &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ü•Ω &lt;a href="https://localai.io/features/gpt-vision/"&gt;Vision API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìà &lt;a href="https://localai.io/features/reranker/"&gt;Reranker API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüñß &lt;a href="https://localai.io/features/distribute/"&gt;P2P Inferencing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; - Agentic capabilities with external tools and &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI's Agentic capabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîä Voice activity detection (Silero-VAD support)&lt;/li&gt; 
 &lt;li&gt;üåç Integrated WebUI!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© Supported Backends &amp;amp; Acceleration&lt;/h2&gt; 
&lt;p&gt;LocalAI supports a comprehensive range of AI backends with multiple acceleration options:&lt;/p&gt; 
&lt;h3&gt;Text Generation &amp;amp; Language Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM inference in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel SYCL, Vulkan, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vLLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast LLM inference with PagedAttention&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;transformers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace transformers framework&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;exllama2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GPTQ inference library&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon LLM inference&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX-VLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon Vision-Language Models&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Audio &amp;amp; Speech Processing&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;whisper.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Whisper in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;faster-whisper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast Whisper with CTranslate2&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-audio generation&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark-cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;C++ implementation of Bark&lt;/td&gt; 
   &lt;td&gt;CUDA, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;coqui&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Advanced TTS with 1100+ languages&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kokoro&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Lightweight TTS model&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;chatterbox&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Production-grade TTS&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;piper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast neural TTS system&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kitten-tts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Kitten TTS models&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;silero-vad&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Voice Activity Detection&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;neutts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-speech with voice cloning&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vibevoice&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time TTS with voice cloning&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;pocket-tts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Lightweight CPU-based TTS&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Image &amp;amp; Video Generation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;stablediffusion.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Stable Diffusion in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;diffusers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace diffusion models&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Specialized AI Tasks&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rfdetr&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time object detection&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rerankers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document reranking API&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;local-store&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Vector database&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;huggingface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace API integration&lt;/td&gt; 
   &lt;td&gt;API-based&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware Acceleration Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Acceleration Type&lt;/th&gt; 
   &lt;th&gt;Supported Backends&lt;/th&gt; 
   &lt;th&gt;Hardware Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 12&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All CUDA-compatible backends&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 13&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All CUDA-compatible backends&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AMD ROCm&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts, vibevoice, pocket-tts&lt;/td&gt; 
   &lt;td&gt;AMD Graphics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Intel oneAPI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark, vibevoice, pocket-tts&lt;/td&gt; 
   &lt;td&gt;Intel Arc, Intel iGPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apple Metal&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp&lt;/td&gt; 
   &lt;td&gt;Apple M1/M2/M3+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Vulkan&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion&lt;/td&gt; 
   &lt;td&gt;Cross-platform GPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA Jetson (CUDA 12)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rfdetr&lt;/td&gt; 
   &lt;td&gt;ARM64 embedded AI (AGX Orin, etc.)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA Jetson (CUDA 13)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rfdetr&lt;/td&gt; 
   &lt;td&gt;ARM64 embedded AI (DGX Spark)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;CPU Optimized&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All backends&lt;/td&gt; 
   &lt;td&gt;AVX/AVX2/AVX512, quantization support&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üîó Community and integrations&lt;/h3&gt; 
&lt;p&gt;Build and deploy custom containers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sozercan/aikit"&gt;https://github.com/sozercan/aikit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;WebUIs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jirubizu/localai-admin"&gt;https://github.com/Jirubizu/localai-admin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/LocalAI-frontend"&gt;https://github.com/go-skynet/LocalAI-frontend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) &lt;a href="https://github.com/reid41/QA-Pilot"&gt;https://github.com/reid41/QA-Pilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Agentic Libraries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/cogito"&gt;https://github.com/mudler/cogito&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MCPs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/MCPs"&gt;https://github.com/mudler/MCPs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model galleries&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/model-gallery"&gt;https://github.com/go-skynet/model-gallery&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Voice:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richiejp/VoxInput"&gt;https://github.com/richiejp/VoxInput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Helm chart &lt;a href="https://github.com/go-skynet/helm-charts"&gt;https://github.com/go-skynet/helm-charts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VSCode extension &lt;a href="https://github.com/badgooooor/localai-vscode-plugin"&gt;https://github.com/badgooooor/localai-vscode-plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Langchain: &lt;a href="https://python.langchain.com/docs/integrations/providers/localai/"&gt;https://python.langchain.com/docs/integrations/providers/localai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Terminal utility &lt;a href="https://github.com/djcopley/ShellOracle"&gt;https://github.com/djcopley/ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Local Smart assistant &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Home Assistant &lt;a href="https://github.com/sammcj/homeassistant-localai"&gt;https://github.com/sammcj/homeassistant-localai&lt;/a&gt; / &lt;a href="https://github.com/drndos/hass-openai-custom-conversation"&gt;https://github.com/drndos/hass-openai-custom-conversation&lt;/a&gt; / &lt;a href="https://github.com/valentinfrlch/ha-gpt4vision"&gt;https://github.com/valentinfrlch/ha-gpt4vision&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/discord"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Slack bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/slack"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) &lt;a href="https://github.com/reid41/shell-pilot"&gt;https://github.com/reid41/shell-pilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Telegram bot &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot"&gt;https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Another Telegram Bot &lt;a href="https://github.com/JackBekket/Hellper"&gt;https://github.com/JackBekket/Hellper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Auto-documentation &lt;a href="https://github.com/JackBekket/Reflexia"&gt;https://github.com/JackBekket/Reflexia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github bot which answer on issues, with code and documentation as context &lt;a href="https://github.com/JackBekket/GitHelper"&gt;https://github.com/JackBekket/GitHelper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github Actions: &lt;a href="https://github.com/marketplace/actions/start-localai"&gt;https://github.com/marketplace/actions/start-localai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Examples: &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/"&gt;https://github.com/mudler/LocalAI/tree/master/examples/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/advanced/fine-tuning/"&gt;LLM finetuning guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/build/index.html"&gt;How to build locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes"&gt;How to install in Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/integrations/"&gt;Projects integrating LocalAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://io.midori-ai.xyz/howtos/"&gt;How tos section&lt;/a&gt; (curated by our community)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;üìñ&lt;/span&gt; üé• &lt;a href="https://localai.io/basics/news/#media-blogs-social"&gt;Media, Blogs, Social&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.suse.com/c/running-ai-locally/"&gt;Run Visual studio code with LocalAI (SUSE)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜï &lt;a href="https://mudler.pm/posts/local-ai-jetson-nano-devkit/"&gt;Run LocalAI on Jetson Nano Devkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/"&gt;Run LocalAI on AWS EKS with Pulumi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance"&gt;Run LocalAI on AWS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/smart-slackbot-for-teams/"&gt;Create a slackbot for teams and OSS projects that answer to documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=PKrDNuJ_dfE"&gt;LocalAI meets k8sgpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/localai-question-answering/"&gt;Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65"&gt;Tutorial to use k8sgpt with LocalAI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you utilize this repository, data in a downstream project, please consider citing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{localai,
  author = {Ettore Di Giacinto},
  title = {LocalAI: The free, Open source OpenAI alternative},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/go-skynet/LocalAI}},
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ù§Ô∏è Sponsors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Do you find LocalAI useful?&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Support the project by becoming &lt;a href="https://github.com/sponsors/mudler"&gt;a backer or sponsor&lt;/a&gt;. Your logo will show up here with a link to your website.&lt;/p&gt; 
&lt;p&gt;A huge thank you to our generous sponsors who support this project covering CI expenses, and our &lt;a href="https://github.com/sponsors/mudler"&gt;Sponsor list&lt;/a&gt;:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.spectrocloud.com/" target="blank"&gt; &lt;img height="200" src="https://github.com/user-attachments/assets/72eab1dd-8b93-4fc0-9ade-84db49f24962" /&gt; &lt;/a&gt; &lt;a href="https://www.premai.io/" target="blank"&gt; &lt;img height="200" src="https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6" /&gt; &lt;br /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3&gt;Individual sponsors&lt;/h3&gt; 
&lt;p&gt;A special thanks to individual sponsors that contributed to the project, a full list is in &lt;a href="https://github.com/sponsors/mudler"&gt;Github&lt;/a&gt; and &lt;a href="https://buymeacoffee.com/mudler"&gt;buymeacoffee&lt;/a&gt;, a special shout out goes to &lt;a href="https://github.com/drikster80"&gt;drikster80&lt;/a&gt; for being generous. Thank you everyone!&lt;/p&gt; 
&lt;h2&gt;üåü Star history&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#go-skynet/LocalAI&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=go-skynet/LocalAI&amp;amp;type=Date" alt="LocalAI Star history Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìñ License&lt;/h2&gt; 
&lt;p&gt;LocalAI is a community-driven project created by &lt;a href="https://github.com/mudler/"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;MIT - Author Ettore Di Giacinto &lt;a href="mailto:mudler@localai.io"&gt;mudler@localai.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üôá Acknowledgements&lt;/h2&gt; 
&lt;p&gt;LocalAI couldn't have been built without the help of great software already available from the community. Thank you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatsu-lab/stanford_alpaca"&gt;https://github.com/tatsu-lab/stanford_alpaca&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cornelk/llama-go"&gt;https://github.com/cornelk/llama-go&lt;/a&gt; for the initial ideas&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/antimatter15/alpaca.cpp"&gt;https://github.com/antimatter15/alpaca.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EdVince/Stable-Diffusion-NCNN"&gt;https://github.com/EdVince/Stable-Diffusion-NCNN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/whisper.cpp"&gt;https://github.com/ggerganov/whisper.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rhasspy/piper"&gt;https://github.com/rhasspy/piper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ó Contributors&lt;/h2&gt; 
&lt;p&gt;This is a community project, a special thanks to our contributors! ü§ó &lt;a href="https://github.com/go-skynet/LocalAI/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=go-skynet/LocalAI" /&gt; &lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>