<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Sat, 24 Jan 2026 01:40:37 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>microsoft/markitdown</title>
      <link>https://github.com/microsoft/markitdown</link>
      <description>&lt;p&gt;Python tool for converting files and office documents to Markdown.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MarkItDown&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/markitdown/"&gt;&lt;img src="https://img.shields.io/pypi/v/markitdown.svg?sanitize=true" alt="PyPI" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/dd/markitdown" alt="PyPI - Downloads" /&gt; &lt;a href="https://github.com/microsoft/autogen"&gt;&lt;img src="https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue" alt="Built by AutoGen Team" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See &lt;a href="https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp"&gt;markitdown-mcp&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Breaking changes between 0.0.1 to 0.1.0:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dependencies are now organized into optional feature-groups (further details below). Use &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt; to have backward-compatible behavior.&lt;/li&gt; 
  &lt;li&gt;convert_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.&lt;/li&gt; 
  &lt;li&gt;The DocumentConverter class interface has changed to read from file-like streams rather than file paths. &lt;em&gt;No temporary files are created anymore&lt;/em&gt;. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to &lt;a href="https://github.com/deanmalmgren/textract"&gt;textract&lt;/a&gt;, but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.&lt;/p&gt; 
&lt;p&gt;MarkItDown currently supports the conversion from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PDF&lt;/li&gt; 
 &lt;li&gt;PowerPoint&lt;/li&gt; 
 &lt;li&gt;Word&lt;/li&gt; 
 &lt;li&gt;Excel&lt;/li&gt; 
 &lt;li&gt;Images (EXIF metadata and OCR)&lt;/li&gt; 
 &lt;li&gt;Audio (EXIF metadata and speech transcription)&lt;/li&gt; 
 &lt;li&gt;HTML&lt;/li&gt; 
 &lt;li&gt;Text-based formats (CSV, JSON, XML)&lt;/li&gt; 
 &lt;li&gt;ZIP files (iterates over contents)&lt;/li&gt; 
 &lt;li&gt;Youtube URLs&lt;/li&gt; 
 &lt;li&gt;EPubs&lt;/li&gt; 
 &lt;li&gt;... and more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why Markdown?&lt;/h2&gt; 
&lt;p&gt;Markdown is extremely close to plain text, with minimal markup or formatting, but still provides a way to represent important document structure. Mainstream LLMs, such as OpenAI's GPT-4o, natively "&lt;em&gt;speak&lt;/em&gt;" Markdown, and often incorporate Markdown into their responses unprompted. This suggests that they have been trained on vast amounts of Markdown-formatted text, and understand it well. As a side benefit, Markdown conventions are also highly token-efficient.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;MarkItDown requires Python 3.10 or higher. It is recommended to use a virtual environment to avoid dependency conflicts.&lt;/p&gt; 
&lt;p&gt;With the standard Python installation, you can create and activate a virtual environment using the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If using &lt;code&gt;uv&lt;/code&gt;, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv --python=3.12 .venv
source .venv/bin/activate
# NOTE: Be sure to use 'uv pip install' rather than just 'pip install' to install packages in this virtual environment
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using Anaconda, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n markitdown python=3.12
conda activate markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install MarkItDown, use pip: &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt;. Alternatively, you can install it from the source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone git@github.com:microsoft/markitdown.git
cd markitdown
pip install -e 'packages/markitdown[all]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Command-Line&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf &amp;gt; document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use &lt;code&gt;-o&lt;/code&gt; to specify the output file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also pipe content:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cat path-to-file.pdf | markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Dependencies&lt;/h3&gt; 
&lt;p&gt;MarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the &lt;code&gt;[all]&lt;/code&gt; option. However, you can also install them individually for more control. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'markitdown[pdf, docx, pptx]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;will install only the dependencies for PDF, DOCX, and PPTX files.&lt;/p&gt; 
&lt;p&gt;At the moment, the following optional dependencies are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[all]&lt;/code&gt; Installs all optional dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pptx]&lt;/code&gt; Installs dependencies for PowerPoint files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[docx]&lt;/code&gt; Installs dependencies for Word files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xlsx]&lt;/code&gt; Installs dependencies for Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xls]&lt;/code&gt; Installs dependencies for older Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pdf]&lt;/code&gt; Installs dependencies for PDF files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[outlook]&lt;/code&gt; Installs dependencies for Outlook messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[az-doc-intel]&lt;/code&gt; Installs dependencies for Azure Document Intelligence&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[audio-transcription]&lt;/code&gt; Installs dependencies for audio transcription of wav and mp3 files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[youtube-transcription]&lt;/code&gt; Installs dependencies for fetching YouTube video transcription&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Plugins&lt;/h3&gt; 
&lt;p&gt;MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --list-plugins
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To enable plugins use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --use-plugins path-to-file.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To find available plugins, search GitHub for the hashtag &lt;code&gt;#markitdown-plugin&lt;/code&gt;. To develop a plugin, see &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Azure Document Intelligence&lt;/h3&gt; 
&lt;p&gt;To use Microsoft Document Intelligence for conversion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md -d -e "&amp;lt;document_intelligence_endpoint&amp;gt;"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More information about how to set up an Azure Document Intelligence Resource can be found &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Python API&lt;/h3&gt; 
&lt;p&gt;Basic usage in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
result = md.convert("test.xlsx")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Document Intelligence conversion in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(docintel_endpoint="&amp;lt;document_intelligence_endpoint&amp;gt;")
result = md.convert("test.pdf")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use Large Language Models for image descriptions (currently only for pptx and image files), provide &lt;code&gt;llm_client&lt;/code&gt; and &lt;code&gt;llm_model&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown
from openai import OpenAI

client = OpenAI()
md = MarkItDown(llm_client=client, llm_model="gpt-4o", llm_prompt="optional custom prompt")
result = md.convert("example.jpg")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t markitdown:latest .
docker run --rm -i markitdown:latest &amp;lt; ~/your-file.pdf &amp;gt; output.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;p&gt;You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as 'open for contribution' and 'open for reviewing' to help facilitate community contributions. These are of course just suggestions and you are welcome to contribute in any way you like.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;All&lt;/th&gt; 
    &lt;th&gt;Especially Needs Help from Community&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues"&gt;All Issues&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22"&gt;Issues open for contribution&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;PRs&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls"&gt;All PRs&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22"&gt;PRs open for reviewing&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h3&gt;Running Tests and Checks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to the MarkItDown package:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;cd packages/markitdown
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;code&gt;hatch&lt;/code&gt; in your environment and run tests:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
hatch shell
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(Alternative) Use the Devcontainer which has all the dependencies installed:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;# Reopen the project in Devcontainer and run:
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run pre-commit checks before submitting a PR: &lt;code&gt;pre-commit run --all-files&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing 3rd-party Plugins&lt;/h3&gt; 
&lt;p&gt;You can also contribute by creating and sharing 3rd party plugins. See &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NVIDIA/NeMo-Agent-Toolkit</title>
      <link>https://github.com/NVIDIA/NeMo-Agent-Toolkit</link>
      <description>&lt;p&gt;The NVIDIA NeMo Agent toolkit is an open-source library for efficiently connecting and optimizing teams of AI agents.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/_static/banner.png" alt="NVIDIA NeMo Agent Toolkit" title="NeMo Agent Toolkit banner image" /&gt;&lt;/p&gt; 
&lt;h1&gt;NVIDIA NeMo Agent Toolkit&lt;/h1&gt; 
&lt;!-- vale off (due to hyperlinks) --&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-green.svg?sanitize=true" alt="License: Apache 2.0" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NVIDIA/NeMo-Agent-Toolkit/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/NVIDIA/NeMo-Agent-Toolkit" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/nvidia-nat/"&gt;&lt;img src="https://img.shields.io/pypi/v/nvidia-nat" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NVIDIA/NeMo-Agent-Toolkit/issues"&gt;&lt;img src="https://img.shields.io/github/issues/NVIDIA/NeMo-Agent-Toolkit" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NVIDIA/NeMo-Agent-Toolkit/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/NVIDIA/NeMo-Agent-Toolkit" alt="GitHub pull requests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NVIDIA/NeMo-Agent-Toolkit"&gt;&lt;img src="https://img.shields.io/github/stars/NVIDIA/NeMo-Agent-Toolkit" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/NVIDIA/NeMo-Agent-Toolkit/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/NVIDIA/NeMo-Agent-Toolkit" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/NVIDIA/NeMo-Agent-Toolkit"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/NVIDIA/NeMo-Agent-Toolkit/"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open in Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- vale on --&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;NVIDIA NeMo Agent Toolkit is a flexible, lightweight, and unifying library that allows you to easily connect existing enterprise agents to data sources and tools across any framework.&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üî• New Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/components/integrations/a2a.md"&gt;&lt;strong&gt;A2A Support&lt;/strong&gt;&lt;/a&gt; NeMo Agent Toolkit now supports deploying and consuming agents using the A2A protocol.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/components/integrations/frameworks.md#strands"&gt;&lt;strong&gt;Amazon Bedrock AgentCore and Strands Agents Support:&lt;/strong&gt;&lt;/a&gt; NeMo Agent Toolkit now supports building agents using Strands Agents framework and deploying them securely on Amazon Bedrock AgentCore runtime.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/examples/frameworks/auto_wrapper/langchain_deep_research/README.md"&gt;&lt;strong&gt;LangChain Agent Automatic Wrapper:&lt;/strong&gt;&lt;/a&gt; NeMo Agent Toolkit now supports automatic wrapping of existing LangChain/LangGraph Agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/components/integrations/frameworks.md#autogen"&gt;&lt;strong&gt;Microsoft AutoGen Support&lt;/strong&gt;&lt;/a&gt; NeMo Agent Toolkit now supports building agents using AutoGen framework.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://docs.nvidia.com/dynamo/latest/"&gt;&lt;strong&gt;Initial NVIDIA Dynamo Integration:&lt;/strong&gt;&lt;/a&gt; NeMo Agent Toolkit now has initial Dynamo support for end-to-end deployment acceleration of agentic workflows.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ú® Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üß© &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/components/integrations/frameworks.md"&gt;&lt;strong&gt;Framework Agnostic:&lt;/strong&gt;&lt;/a&gt; NeMo Agent Toolkit works side-by-side and around existing agentic frameworks, such as &lt;a href="https://www.langchain.com/"&gt;LangChain&lt;/a&gt;, &lt;a href="https://www.llamaindex.ai/"&gt;LlamaIndex&lt;/a&gt;, &lt;a href="https://www.crewai.com/"&gt;CrewAI&lt;/a&gt;, &lt;a href="https://learn.microsoft.com/en-us/semantic-kernel/"&gt;Microsoft Semantic Kernel&lt;/a&gt;, and &lt;a href="https://google.github.io/adk-docs/"&gt;Google ADK&lt;/a&gt;, as well as custom enterprise agentic frameworks and simple Python agents. This allows you to use your current technology stack without replatforming. NeMo Agent Toolkit complements any existing agentic framework or memory tool you're using and isn't tied to any specific agentic framework, LLM provider, or data source.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üîÅ &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/components/sharing-components.md"&gt;&lt;strong&gt;Reusability:&lt;/strong&gt;&lt;/a&gt; Every agent, tool, and agentic workflow in this library exists as a function call that works together in complex software applications. The composability between these agents, tools, and workflows allows you to build once and reuse in different scenarios.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‚ö° &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/get-started/tutorials/customize-a-workflow.md"&gt;&lt;strong&gt;Rapid Development:&lt;/strong&gt;&lt;/a&gt; Start with a pre-built agent, tool, or workflow, and customize it to your needs. This allows you and your development teams to move quickly if you're already developing with agents.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üìà &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/improve-workflows/profiler.md"&gt;&lt;strong&gt;Profiling:&lt;/strong&gt;&lt;/a&gt; Use the profiler to profile entire workflows down to the tool and agent level, track input/output tokens and timings, and identify bottlenecks. While we encourage you to wrap (decorate) every tool and agent to get the most out of the profiler, you have the freedom to integrate your tools, agents, and workflows to whatever level you want. You start small and go to where you believe you'll see the most value and expand from there.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üîé &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/run-workflows/observe/observe.md"&gt;&lt;strong&gt;Observability:&lt;/strong&gt;&lt;/a&gt; Monitor and debug your workflows with dedicated integrations for popular observability platforms such as Phoenix, Weave, and Langfuse, plus compatibility with OpenTelemetry-based observability platforms. Track performance, trace execution flows, and gain insights into your agent behaviors.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üß™ &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/improve-workflows/evaluate.md"&gt;&lt;strong&gt;Evaluation System:&lt;/strong&gt;&lt;/a&gt; Validate and maintain accuracy of agentic workflows with built-in evaluation tools.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üí¨ &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/run-workflows/launching-ui.md"&gt;&lt;strong&gt;User Interface:&lt;/strong&gt;&lt;/a&gt; Use the NeMo Agent Toolkit UI chat interface to interact with your agents, visualize output, and debug workflows.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üîó &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/build-workflows/mcp-client.md"&gt;&lt;strong&gt;Full MCP Support:&lt;/strong&gt;&lt;/a&gt; Compatible with &lt;a href="https://modelcontextprotocol.io/"&gt;Model Context Protocol (MCP)&lt;/a&gt;. You can use NeMo Agent Toolkit as an &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/build-workflows/mcp-client.md"&gt;MCP client&lt;/a&gt; to connect to and use tools served by remote MCP servers. You can also use NeMo Agent Toolkit as an &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/run-workflows/mcp-server.md"&gt;MCP server&lt;/a&gt; to publish tools via MCP.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;With NeMo Agent Toolkit, you can move quickly, experiment freely, and ensure reliability across all your agent-driven projects.&lt;/p&gt; 
&lt;h2&gt;üöÄ Installation&lt;/h2&gt; 
&lt;p&gt;Before you begin using NeMo Agent Toolkit, ensure that you have Python 3.11, 3.12, or 3.13 installed on your system.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] For users who want to run the examples, it's required to clone the repository and install from source to get the necessary files required to run the examples. Please refer to the &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/examples/README.md"&gt;Examples&lt;/a&gt; documentation for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To install the latest stable version of NeMo Agent Toolkit from PyPI, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install nvidia-nat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;NeMo Agent Toolkit has many optional dependencies which can be installed with the core package. Optional dependencies are grouped by framework and can be installed with the core package. For example, to install the LangChain/LangGraph plugin, run the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "nvidia-nat[langchain]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or for &lt;strong&gt;almost all&lt;/strong&gt; optional dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "nvidia-nat[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Detailed installation instructions, including the full list of optional dependencies and their conflicts, can be found in the &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/get-started/installation.md"&gt;Installation Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üåü Hello World Example&lt;/h2&gt; 
&lt;p&gt;Before getting started, it's possible to run this simple workflow and many other examples in Google Colab with no setup. Click here to open the introduction notebook: &lt;a href="https://colab.research.google.com/github/NVIDIA/NeMo-Agent-Toolkit/"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open in Colab" /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Ensure you have set the &lt;code&gt;NVIDIA_API_KEY&lt;/code&gt; environment variable to allow the example to use NVIDIA NIMs. An API key can be obtained by visiting &lt;a href="https://build.nvidia.com/"&gt;&lt;code&gt;build.nvidia.com&lt;/code&gt;&lt;/a&gt; and creating an account.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;export NVIDIA_API_KEY=&amp;lt;your_api_key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create the NeMo Agent Toolkit workflow configuration file. This file will define the agents, tools, and workflows that will be used in the example. Save the following as &lt;code&gt;workflow.yml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-yaml"&gt;functions:
   # Add a tool to search wikipedia
   wikipedia_search:
      _type: wiki_search
      max_results: 2

llms:
   # Tell NeMo Agent Toolkit which LLM to use for the agent
   nim_llm:
      _type: nim
      model_name: meta/llama-3.1-70b-instruct
      temperature: 0.0

workflow:
   # Use an agent that 'reasons' and 'acts'
   _type: react_agent
   # Give it access to our wikipedia search tool
   tool_names: [wikipedia_search]
   # Tell it which LLM to use
   llm_name: nim_llm
   # Make it verbose
   verbose: true
   # Retry up to 3 times
   parse_agent_response_max_retries: 3
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the Hello World example using the &lt;code&gt;nat&lt;/code&gt; CLI and the &lt;code&gt;workflow.yml&lt;/code&gt; file.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;nat run --config_file workflow.yml --input "List five subspecies of Aardvarks"
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This will run the workflow and output the results to the console.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-console"&gt;Workflow Result:
['Here are five subspecies of Aardvarks:\n\n1. Orycteropus afer afer (Southern aardvark)\n2. O. a. adametzi  Grote, 1921 (Western aardvark)\n3. O. a. aethiopicus  Sundevall, 1843\n4. O. a. angolensis  Zukowsky &amp;amp; Haltenorth, 1957\n5. O. a. erikssoni  L√∂nnberg, 1906']
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìö Additional Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;a href="https://docs.nvidia.com/nemo/agent-toolkit/latest"&gt;Documentation&lt;/a&gt;: Explore the full documentation for NeMo Agent Toolkit.&lt;/li&gt; 
 &lt;li&gt;üß≠ &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/get-started/installation.md"&gt;Get Started Guide&lt;/a&gt;: Set up your environment and start building with NeMo Agent toolkit.&lt;/li&gt; 
 &lt;li&gt;ü§ù &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/resources/contributing/index.md"&gt;Contributing&lt;/a&gt;: Learn how to contribute to NeMo Agent Toolkit and set up your development environment.&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/examples/README.md"&gt;Examples&lt;/a&gt;: Explore examples of NeMo Agent Toolkit workflows located in the &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/examples"&gt;&lt;code&gt;examples&lt;/code&gt;&lt;/a&gt; directory of the source repository.&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/get-started/tutorials/customize-a-workflow.md"&gt;Create and Customize NeMo Agent Toolkit Workflows&lt;/a&gt;: Learn how to create and customize NeMo Agent Toolkit workflows.&lt;/li&gt; 
 &lt;li&gt;üéØ &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/improve-workflows/evaluate.md"&gt;Evaluate with NeMo Agent Toolkit&lt;/a&gt;: Learn how to evaluate your NeMo Agent Toolkit workflows.&lt;/li&gt; 
 &lt;li&gt;üÜò &lt;a href="https://raw.githubusercontent.com/NVIDIA/NeMo-Agent-Toolkit/develop/docs/source/resources/troubleshooting.md"&gt;Troubleshooting&lt;/a&gt;: Get help with common issues.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõ£Ô∏è Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Automatic Reinforcement Learning (RL) to fine-tune LLMs for a specific agent.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Integration with &lt;a href="https://github.com/NVIDIA/NeMo-Guardrails"&gt;NeMo Guardrails&lt;/a&gt; to secure any function in an agent workflow.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; End-to-end acceleration using intelligent integrations with &lt;a href="https://github.com/ai-dynamo/dynamo"&gt;NVIDIA Dynamo&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üí¨ Feedback&lt;/h2&gt; 
&lt;p&gt;We would love to hear from you! Please file an issue on &lt;a href="https://github.com/NVIDIA/NeMo-Agent-Toolkit/issues"&gt;GitHub&lt;/a&gt; if you have any feedback or feature requests.&lt;/p&gt; 
&lt;h2&gt;ü§ù Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We would like to thank the following groups for their contribution to the toolkit:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.synopsys.com/"&gt;Synopsys&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Google ADK framework support.&lt;/li&gt; 
   &lt;li&gt;Microsoft AutoGen framework support.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wandb.ai/site/weave/"&gt;W&amp;amp;B Weave Team&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Contributions to the evaluation and telemetry system.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition, we would like to thank the following open source projects that made NeMo Agent Toolkit possible:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/a2aproject/A2A"&gt;Agent2Agent (A2A) Protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI"&gt;CrewAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ai-dynamo/dynamo"&gt;Dynamo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tiangolo/fastapi"&gt;FastAPI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/adk-python"&gt;Google Agent Development Kit (ADK)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langchain-ai/langchain"&gt;LangChain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/run-llama/llama_index"&gt;Llama-Index&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mem0ai/mem0"&gt;Mem0ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/autogen"&gt;Microsoft AutoGen&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/minio/minio"&gt;MinIO&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/modelcontextprotocol/modelcontextprotocol"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/open-telemetry/opentelemetry-python"&gt;OpenTelemetry&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/arize-ai/phoenix"&gt;Phoenix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/explodinggradients/ragas"&gt;Ragas&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/redis/redis-py"&gt;Redis&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/semantic-kernel"&gt;Semantic Kernel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/strands-agents/sdk-python"&gt;Strands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wandb/weave"&gt;Weave&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Asabeneh/30-Days-Of-Python</title>
      <link>https://github.com/Asabeneh/30-Days-Of-Python</link>
      <description>&lt;p&gt;The 30 Days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than 100 days. Follow your own pace. These videos may help too: https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üêç 30 Days Of Python&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;# Day&lt;/th&gt; 
   &lt;th align="center"&gt;Topics&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;01&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/readme.md"&gt;Introduction&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;02&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md"&gt;Variables, Built-in Functions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;03&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/03_Day_Operators/03_operators.md"&gt;Operators&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;04&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/04_Day_Strings/04_strings.md"&gt;Strings&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;05&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/05_Day_Lists/05_lists.md"&gt;Lists&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;06&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/06_Day_Tuples/06_tuples.md"&gt;Tuples&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;07&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/07_Day_Sets/07_sets.md"&gt;Sets&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;08&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/08_Day_Dictionaries/08_dictionaries.md"&gt;Dictionaries&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;09&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/09_Day_Conditionals/09_conditionals.md"&gt;Conditionals&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/10_Day_Loops/10_loops.md"&gt;Loops&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/11_Day_Functions/11_functions.md"&gt;Functions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/12_Day_Modules/12_modules.md"&gt;Modules&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/13_Day_List_comprehension/13_list_comprehension.md"&gt;List Comprehension&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/14_Day_Higher_order_functions/14_higher_order_functions.md"&gt;Higher Order Functions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/15_Day_Python_type_errors/15_python_type_errors.md"&gt;Python Type Errors&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/16_Day_Python_date_time/16_python_datetime.md"&gt;Python Date time&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/17_Day_Exception_handling/17_exception_handling.md"&gt;Exception Handling&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/18_Day_Regular_expressions/18_regular_expressions.md"&gt;Regular Expressions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/19_Day_File_handling/19_file_handling.md"&gt;File Handling&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/20_Day_Python_package_manager/20_python_package_manager.md"&gt;Python Package Manager&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/21_Day_Classes_and_objects/21_classes_and_objects.md"&gt;Classes and Objects&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/22_Day_Web_scraping/22_web_scraping.md"&gt;Web Scraping&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/23_Day_Virtual_environment/23_virtual_environment.md"&gt;Virtual Environment&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/24_Day_Statistics/24_statistics.md"&gt;Statistics&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/25_Day_Pandas/25_pandas.md"&gt;Pandas&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/26_Day_Python_web/26_python_web.md"&gt;Python web&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/27_Day_Python_with_mongodb/27_python_with_mongodb.md"&gt;Python with MongoDB&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/28_Day_API/28_API.md"&gt;API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/29_Day_Building_API/29_building_API.md"&gt;Building API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;30&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/30_Day_Conclusions/30_conclusions.md"&gt;Conclusions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;small&gt;üß°üß°üß° HAPPY CODING üß°üß°üß°&lt;/small&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div&gt; 
 &lt;h2&gt;üíñ Sponsors&lt;/h2&gt; 
 &lt;p&gt;Our amazing sponsors for supporting my open-source contribution and the &lt;strong&gt;30 Days of Challenge&lt;/strong&gt; series!&lt;/p&gt; 
 &lt;h3&gt;Current Sponsors&lt;/h3&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://ref.wisprflow.ai/MPMzRGE" target="_blank" rel="noopener noreferrer"&gt; 
   &lt;picture&gt; 
    &lt;!-- Dark mode --&gt; 
    &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/Asabeneh/asabeneh/master/images/Wispr_Flow-Logo-white.png" /&gt; 
    &lt;!-- Light mode (fallback) --&gt; 
    &lt;img src="https://raw.githubusercontent.com/Asabeneh/asabeneh/master/images/Wispr_Flow-logo.png" width="400px" alt="Wispr Flow Logo" title="Wispr Flow" /&gt; 
   &lt;/picture&gt; &lt;/a&gt; 
  &lt;h1&gt; &lt;a href="https://ref.wisprflow.ai/MPMzRGE" target="_blank" rel="noopener noreferrer"&gt; Talk to code, stay in the Flow. &lt;/a&gt; &lt;/h1&gt; 
  &lt;h2&gt; &lt;a href="https://ref.wisprflow.ai/MPMzRGE" target="_blank" rel="noopener noreferrer"&gt; Flow is built for devs who live in their tools. Speak and give more context, get better results. &lt;/a&gt; &lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://client.petrosky.io/aff.php?aff=402" target="_blank" rel="noopener noreferrer"&gt; 
   &lt;picture&gt; 
    &lt;!-- Dark mode --&gt; 
    &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/Asabeneh/asabeneh/master/images/petrosky-logo-white.png" /&gt; 
    &lt;!-- Light mode (fallback) --&gt; 
    &lt;img src="https://raw.githubusercontent.com/Asabeneh/asabeneh/master/images/petrosky-logo-black.png" width="400px" alt="Petrosky Logo" title="Petrosky" /&gt; 
   &lt;/picture&gt; &lt;/a&gt; 
  &lt;h1&gt; &lt;a href="https://client.petrosky.io/aff.php?aff=402" target="_blank" rel="noopener noreferrer"&gt; A hosting for your entire journey! &lt;/a&gt; &lt;/h1&gt; 
  &lt;h2&gt; &lt;a href="https://client.petrosky.io/aff.php?aff=402" target="_blank" rel="noopener noreferrer"&gt; Affordable VPS Hosting Services For All Your Needs &lt;/a&gt; &lt;/h2&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;üôå Become a Sponsor&lt;/h3&gt; 
 &lt;p&gt;You can support this project by becoming a sponsor on &lt;strong&gt;&lt;a href="https://github.com/sponsors/asabeneh"&gt;GitHub Sponsors&lt;/a&gt;&lt;/strong&gt; or through &lt;a href="https://www.paypal.me/asabeneh"&gt;PayPal&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;Every contribution, big or small, makes a huge difference. Thank you for your support! üåü&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h1&gt; 30 Days Of Python: Day 1 - Introduction&lt;/h1&gt; 
  &lt;a class="header-badge" target="_blank" href="https://www.linkedin.com/in/asabeneh/"&gt; &lt;img src="https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&amp;amp;logo=linkedin&amp;amp;style=social" /&gt; &lt;/a&gt; 
  &lt;a class="header-badge" target="_blank" href="https://twitter.com/Asabeneh"&gt; &lt;img alt="Twitter Follow" src="https://img.shields.io/twitter/follow/asabeneh?style=social" /&gt; &lt;/a&gt; 
  &lt;p&gt;&lt;sub&gt;Author: &lt;a href="https://www.linkedin.com/in/asabeneh/" target="_blank"&gt;Asabeneh Yetayeh&lt;/a&gt;&lt;br /&gt; &lt;small&gt; Second Edition: July, 2021&lt;/small&gt; &lt;/sub&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;p&gt;üáßüá∑ &lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/Portuguese/README.md"&gt;Portuguese&lt;/a&gt; üá®üá≥ &lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/Chinese/README.md"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md"&gt;Day 2 &amp;gt;&amp;gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/30DaysOfPython_banner3@2x.png" alt="30DaysOfPython" /&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-30-days-of-python"&gt;üêç 30 Days Of Python&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-become-a-sponsor"&gt;üôå Become a Sponsor&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-day-1"&gt;üìò Day 1&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#welcome"&gt;Welcome&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#why-python-"&gt;Why Python ?&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#environment-setup"&gt;Environment Setup&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#installing-python"&gt;Installing Python&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-shell"&gt;Python Shell&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#installing-visual-studio-code"&gt;Installing Visual Studio Code&lt;/a&gt; 
       &lt;ul&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#how-to-use-visual-studio-code"&gt;How to use visual studio code&lt;/a&gt;&lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#basic-python"&gt;Basic Python&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-syntax"&gt;Python Syntax&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-indentation"&gt;Python Indentation&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#comments"&gt;Comments&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#data-types"&gt;Data types&lt;/a&gt; 
       &lt;ul&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#number"&gt;Number&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#string"&gt;String&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#booleans"&gt;Booleans&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#list"&gt;List&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#dictionary"&gt;Dictionary&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#tuple"&gt;Tuple&lt;/a&gt;&lt;/li&gt; 
        &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#set"&gt;Set&lt;/a&gt;&lt;/li&gt; 
       &lt;/ul&gt; &lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#checking-data-types"&gt;Checking Data types&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-file"&gt;Python File&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-exercises---day-1"&gt;üíª Exercises - Day 1&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-1"&gt;Exercise: Level 1&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-2"&gt;Exercise: Level 2&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-3"&gt;Exercise: Level 3&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h1&gt;üìò Day 1&lt;/h1&gt; 
 &lt;h2&gt;Welcome&lt;/h2&gt; 
 &lt;p&gt;&lt;strong&gt;Congratulations&lt;/strong&gt; for deciding to participate in a &lt;em&gt;30 days of Python&lt;/em&gt; programming challenge. In this challenge, you will learn everything you need to be a python programmer and the whole concept of programming. In the end of the challenge you will get a &lt;em&gt;30DaysOfPython&lt;/em&gt; programming challenge certificate.&lt;/p&gt; 
 &lt;p&gt;If you would like to actively engage in the challenge, you may join the &lt;a href="https://t.me/ThirtyDaysOfPython"&gt;30DaysOfPython challenge&lt;/a&gt; telegram group.&lt;/p&gt; 
 &lt;h2&gt;Introduction&lt;/h2&gt; 
 &lt;p&gt;Python is a high-level programming language for general-purpose programming. It is an open source, interpreted, object-oriented programming language. Python was created by a Dutch programmer, Guido van Rossum. The name of the Python programming language was derived from a British sketch comedy series, &lt;em&gt;Monty Python's Flying Circus&lt;/em&gt;. The first version was released on February 20, 1991. This 30 days of Python challenge will help you learn the latest version of Python, Python 3 step by step. The topics are broken down into 30 days, where each day contains several topics with easy-to-understand explanations, real-world examples, and many hands on exercises and projects.&lt;/p&gt; 
 &lt;p&gt;This challenge is designed for beginners and professionals who want to learn python programming language. It may take 30 to 100 days to complete the challenge. People who actively participate in the telegram group have a high probability of completing the challenge.&lt;/p&gt; 
 &lt;p&gt;This challenge is easy to read, written in conversational English, engaging, motivating and at the same time, it is very demanding. You need to allocate much time to finish this challenge. If you are a visual learner, you may get the video lesson on &lt;a href="https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw"&gt; Washera&lt;/a&gt; YouTube channel. You may start from &lt;a href="https://youtu.be/OCCWZheOesI"&gt;Python for Absolute Beginners video&lt;/a&gt;. Subscribe the channel, comment and ask questions on YouTube videos and be proactive, the author will eventually notice you.&lt;/p&gt; 
 &lt;p&gt;The author likes to hear your opinion about the challenge, share the author by expressing your thoughts about the 30DaysOfPython challenge. You can leave your testimonial on this &lt;a href="https://www.asabeneh.com/testimonials"&gt;link&lt;/a&gt;&lt;/p&gt; 
 &lt;h2&gt;Why Python ?&lt;/h2&gt; 
 &lt;p&gt;It is a programming language which is very close to human language and because of that, it is easy to learn and use. Python is used by various industries and companies (including Google). It has been used to develop web applications, desktop applications, system administration, and machine learning libraries. Python is a highly embraced language in the data science and machine learning community. I hope this is enough to convince you to start learning Python. Python is eating the world and you are killing it before it eats you.&lt;/p&gt; 
 &lt;h2&gt;Environment Setup&lt;/h2&gt; 
 &lt;h3&gt;Installing Python&lt;/h3&gt; 
 &lt;p&gt;To run a python script you need to install python. Let's &lt;a href="https://www.python.org/"&gt;download&lt;/a&gt; python. If your are a windows user, click the button encircled in red.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/installing_on_windows.png" alt="installing on Windows" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;If you are a macOS user, click the button encircled in red.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/installing_on_macOS.png" alt="installing on Windows" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;To check if python is installed write the following command on your device terminal.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;python3 --version
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/python_versio.png" alt="Python Version" /&gt;&lt;/p&gt; 
 &lt;p&gt;As you can see from the terminal, I am using &lt;em&gt;Python 3.7.5&lt;/em&gt; version at the moment. Your version of Python might be different from mine by but it should be 3.6 or above. If you manage to see the python version, well done. Python has been installed on your machine. Continue to the next section.&lt;/p&gt; 
 &lt;h3&gt;Python Shell&lt;/h3&gt; 
 &lt;p&gt;Python is an interpreted scripting language, so it does not need to be compiled. It means it executes the code line by line. Python comes with a &lt;em&gt;Python Shell (Python Interactive Shell)&lt;/em&gt;. It is used to execute a single python command and get the result.&lt;/p&gt; 
 &lt;p&gt;Python Shell waits for the Python code from the user. When you enter the code, it interprets the code and shows the result in the next line. Open your terminal or command prompt(cmd) and write:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;python
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_python_shell.png" alt="Python Scripting Shell" /&gt;&lt;/p&gt; 
 &lt;p&gt;The Python interactive shell is opened and it is waiting for you to write Python code(Python script). You will write your Python script next to this symbol &amp;gt;&amp;gt;&amp;gt; and then click Enter. Let us write our very first script on the Python scripting shell.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/adding_on_python_shell.png" alt="Python script on Python shell" /&gt;&lt;/p&gt; 
 &lt;p&gt;Well done, you wrote your first Python script on Python interactive shell. How do we close the Python interactive shell ? To close the shell, next to this symbol &amp;gt;&amp;gt;&amp;gt; write &lt;strong&gt;exit()&lt;/strong&gt; command and press Enter.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/exit_from_shell.png" alt="Exit from python shell" /&gt;&lt;/p&gt; 
 &lt;p&gt;Now, you know how to open the Python interactive shell and how to exit from it.&lt;/p&gt; 
 &lt;p&gt;Python will give you results if you write scripts that Python understands, if not it returns errors. Let's make a deliberate mistake and see what Python will return.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/invalid_syntax_error.png" alt="Invalid Syntax Error" /&gt;&lt;/p&gt; 
 &lt;p&gt;As you can see from the returned error, Python is so clever that it knows the mistake we made and which was &lt;em&gt;Syntax Error: invalid syntax&lt;/em&gt;. Using x as multiplication in Python is a syntax error because (x) is not a valid syntax in Python. Instead of (&lt;strong&gt;x&lt;/strong&gt;) we use asterisk (*) for multiplication. The returned error clearly shows what to fix.&lt;/p&gt; 
 &lt;p&gt;The process of identifying and removing errors from a program is called &lt;em&gt;debugging&lt;/em&gt;. Let us debug it by putting * in place of &lt;strong&gt;x&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/fixing_syntax_error.png" alt="Fixing Syntax Error" /&gt;&lt;/p&gt; 
 &lt;p&gt;Our bug was fixed, the code ran and we got a result we were expecting. As a programmer you will see such kind of errors on daily basis. It is good to know how to debug. To be good at debugging you should understand what kind of errors you are facing. Some of the Python errors you may encounter are &lt;em&gt;SyntaxError&lt;/em&gt;, &lt;em&gt;IndexError&lt;/em&gt;, &lt;em&gt;NameError&lt;/em&gt;, &lt;em&gt;ModuleNotFoundError&lt;/em&gt;, &lt;em&gt;KeyError&lt;/em&gt;, &lt;em&gt;ImportError&lt;/em&gt;, &lt;em&gt;AttributeError&lt;/em&gt;, &lt;em&gt;TypeError&lt;/em&gt;, &lt;em&gt;ValueError&lt;/em&gt;, &lt;em&gt;ZeroDivisionError&lt;/em&gt; etc. We will see more about different Python &lt;strong&gt;&lt;em&gt;error types&lt;/em&gt;&lt;/strong&gt; in later sections.&lt;/p&gt; 
 &lt;p&gt;Let us practice more how to use Python interactive shell. Go to your terminal or command prompt and write the word &lt;strong&gt;python&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_python_shell.png" alt="Python Scripting Shell" /&gt;&lt;/p&gt; 
 &lt;p&gt;The Python interactive shell is opened. Let us do some basic mathematical operations (addition, subtraction, multiplication, division, modulus, exponentiation).&lt;/p&gt; 
 &lt;p&gt;Let us do some maths first before we write any Python code:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;2 + 3 = 5&lt;/li&gt; 
  &lt;li&gt;3 - 2 = 1&lt;/li&gt; 
  &lt;li&gt;3 * 2 = 6&lt;/li&gt; 
  &lt;li&gt;3 / 2 = 1.5&lt;/li&gt; 
  &lt;li&gt;3 ** 2 = 3 x 3 = 9&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;In python, we have the following additional operations:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;3 % 2 = 1 =&amp;gt; which means finding the remainder&lt;/li&gt; 
  &lt;li&gt;3 // 2 = 1 =&amp;gt; which means removing the remainder&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Let us change the above mathematical expressions to Python code. The Python shell has been opened and let us write a comment at the very beginning of the shell.&lt;/p&gt; 
 &lt;p&gt;A &lt;em&gt;comment&lt;/em&gt; is a part of the code which is not executed by python. So we can leave some text in our code to make our code more readable. Python does not run the comment part. A comment in python starts with hash(#) symbol. This is how you write a comment in python&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt; # comment starts with hash
 # this is a python comment, because it starts with a (#) symbol
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/maths_on_python_shell.png" alt="Maths on python shell" /&gt;&lt;/p&gt; 
 &lt;p&gt;Before we move on to the next section, let us practice more on the Python interactive shell. Close the opened shell by writing &lt;em&gt;exit()&lt;/em&gt; on the shell and open it again and let us practice how to write text on the Python shell.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/writing_string_on_shell.png" alt="Writing String on python shell" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Installing Visual Studio Code&lt;/h3&gt; 
 &lt;p&gt;The Python interactive shell is good to try and test small script codes but it will not be for a big project. In real work environment, developers use different code editors to write codes. In this 30 days of Python programming challenge, we will use Visual Studio Code. Visual Studio Code is a very popular open source text editor. I am a fan of vscode and I would recommend to &lt;a href="https://code.visualstudio.com/"&gt;download&lt;/a&gt; visual studio code, but if you are in favor of other editors, feel free to follow with what you have.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://code.visualstudio.com/"&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/vscode.png" alt="Visual Studio Code" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;If you installed visual studio code, let us see how to use it. If you prefer a video, you can follow this Visual Studio Code for Python &lt;a href="https://www.youtube.com/watch?v=bn7Cx4z-vSo"&gt;Video tutorial&lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt;How to use visual studio code&lt;/h4&gt; 
 &lt;p&gt;Open the visual studio code by double clicking the visual studio icon. When you open it you will get this kind of interface. Try to interact with the labeled icons.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/vscode_ui.png" alt="Visual studio Code" /&gt;&lt;/p&gt; 
 &lt;p&gt;Create a folder named 30DaysOfPython on your desktop. Then open it using visual studio code.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/how_to_open_project_on_vscode.png" alt="Opening Project on Visual studio" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_project.png" alt="Opening a project" /&gt;&lt;/p&gt; 
 &lt;p&gt;After opening it, you will see shortcuts for creating files and folders inside of 30DaysOfPython project's directory. As you can see below, I have created the very first file, &lt;code&gt;helloworld.py&lt;/code&gt;. You can do the same.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/helloworld.png" alt="Creating a python file" /&gt;&lt;/p&gt; 
 &lt;p&gt;After a long day of coding, you want to close your code editor, right? This is how you will close the opened project.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/closing_opened_project.png" alt="Closing project" /&gt;&lt;/p&gt; 
 &lt;p&gt;Congratulations, you have finished setting up the development environment. Let us start coding.&lt;/p&gt; 
 &lt;h2&gt;Basic Python&lt;/h2&gt; 
 &lt;h3&gt;Python Syntax&lt;/h3&gt; 
 &lt;p&gt;A Python script can be written in Python interactive shell or in the code editor. A Python file has an extension .py.&lt;/p&gt; 
 &lt;h3&gt;Python Indentation&lt;/h3&gt; 
 &lt;p&gt;An indentation is a white space in a text. Indentation in many languages is used to increase code readability; however, Python uses indentation to create blocks of code. In other programming languages, curly brackets are used to create code blocks instead of indentation. One of the common bugs when writing Python code is incorrect indentation.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/indentation.png" alt="Indentation Error" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Comments&lt;/h3&gt; 
 &lt;p&gt;Comments play a crucial role in enhancing code readability and allowing developers to leave notes within their code. In Python, any text preceded by a hash (#) symbol is considered a comment and is not executed when the code runs.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example: Single Line Comment&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;    # This is the first comment
    # This is the second comment
    # Python is eating the world
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Example: Multiline Comment&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Triple quote can be used for multiline comment if it is not assigned to a variable&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;"""This is multiline comment
multiline comment takes multiple lines.
python is eating the world
"""
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Data types&lt;/h3&gt; 
 &lt;p&gt;In Python there are several types of data types. Let us get started with the most common ones. Different data types will be covered in detail in other sections. For the time being, let us just go through the different data types and get familiar with them. You do not have to have a clear understanding now.&lt;/p&gt; 
 &lt;h4&gt;Number&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Integer: Integer(negative, zero and positive) numbers Example: ... -3, -2, -1, 0, 1, 2, 3 ...&lt;/li&gt; 
  &lt;li&gt;Float: Decimal number Example ... -3.5, -2.25, -1.0, 0.0, 1.1, 2.2, 3.5 ...&lt;/li&gt; 
  &lt;li&gt;Complex Example 1 + j, 2 + 4j&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;String&lt;/h4&gt; 
 &lt;p&gt;A collection of one or more characters under a single or double quote. If a string is more than one sentence then we use a triple quote.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;'Asabeneh'
'Finland'
'Python'
'I love teaching'
'I hope you are enjoying the first day of 30DaysOfPython Challenge'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Booleans&lt;/h4&gt; 
 &lt;p&gt;A boolean data type is either a True or False value. T and F should be always uppercase.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;    True  #  Is the light on? If it is on, then the value is True
    False # Is the light on? If it is off, then the value is False
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;List&lt;/h4&gt; 
 &lt;p&gt;Python list is an ordered collection which allows to store different data type items. A list is similar to an array in JavaScript.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;[0, 1, 2, 3, 4, 5]  # all are the same data types - a list of numbers
['Banana', 'Orange', 'Mango', 'Avocado'] # all the same data types - a list of strings (fruits)
['Finland','Estonia', 'Sweden','Norway'] # all the same data types - a list of strings (countries)
['Banana', 10, False, 9.81] # different data types in the list - string, integer, boolean and float
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Dictionary&lt;/h4&gt; 
 &lt;p&gt;A Python dictionary object is an unordered collection of data in a key value pair format.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;{
'first_name':'Asabeneh',
'last_name':'Yetayeh',
'country':'Finland',
'age':250,
'is_married':True,
'skills':['JS', 'React', 'Node', 'Python']
}
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Tuple&lt;/h4&gt; 
 &lt;p&gt;A tuple is an ordered collection of different data types like list but tuples can not be modified once they are created. They are immutable.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;('Asabeneh', 'Pawel', 'Brook', 'Abraham', 'Lidiya') # Names
&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;('Earth', 'Jupiter', 'Neptune', 'Mars', 'Venus', 'Saturn', 'Uranus', 'Mercury') # planets
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;Set&lt;/h4&gt; 
 &lt;p&gt;A set is a collection of data types similar to list and tuple. Unlike list and tuple, set is not an ordered collection of items. Like in Mathematics, set in Python stores only unique items.&lt;/p&gt; 
 &lt;p&gt;In later sections, we will go in detail about each and every Python data type.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;{2, 4, 3, 5}
{3.14, 9.81, 2.7} # order is not important in set
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;Checking Data types&lt;/h3&gt; 
 &lt;p&gt;To check the data type of certain data/variable we use the &lt;strong&gt;type&lt;/strong&gt; function. In the following terminal you will see different python data types:&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/checking_data_types.png" alt="Checking Data types" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Python File&lt;/h3&gt; 
 &lt;p&gt;First open your project folder, 30DaysOfPython. If you don't have this folder, create a folder name called 30DaysOfPython. Inside this folder, create a file called helloworld.py. Now, let's do what we did on python interactive shell using visual studio code.&lt;/p&gt; 
 &lt;p&gt;The Python interactive shell was printing without using &lt;strong&gt;print&lt;/strong&gt; but on visual studio code to see our result we should use a built in function &lt;em&gt;print()&lt;/em&gt;. The &lt;em&gt;print()&lt;/em&gt; built-in function takes one or more arguments as follows &lt;em&gt;print('arument1', 'argument2', 'argument3')&lt;/em&gt;. See the examples below.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;The file name is &lt;code&gt;helloworld.py&lt;/code&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-py"&gt;# Day 1 - 30DaysOfPython Challenge

print(2 + 3)             # addition(+)
print(3 - 1)             # subtraction(-)
print(2 * 3)             # multiplication(*)
print(3 / 2)             # division(/)
print(3 ** 2)            # exponential(**)
print(3 % 2)             # modulus(%)
print(3 // 2)            # Floor division operator(//)

# Checking data types
print(type(10))          # Int
print(type(3.14))        # Float
print(type(1 + 3j))      # Complex number
print(type('Asabeneh'))  # String
print(type([1, 2, 3]))   # List
print(type({'name':'Asabeneh'})) # Dictionary
print(type({9.8, 3.14, 2.7}))    # Set
print(type((9.8, 3.14, 2.7)))    # Tuple
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;To run the python file check the image below. You can run the python file either by running the green button on Visual Studio Code or by typing &lt;em&gt;python helloworld.py&lt;/em&gt; in the terminal .&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/running_python_script.png" alt="Running python script" /&gt;&lt;/p&gt; 
 &lt;p&gt;üåï You are amazing. You have just completed day 1 challenge and you are on your way to greatness. Now do some exercises for your brain and muscles.&lt;/p&gt; 
 &lt;h2&gt;üíª Exercises - Day 1&lt;/h2&gt; 
 &lt;h3&gt;Exercise: Level 1&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Check the python version you are using&lt;/li&gt; 
  &lt;li&gt;Open the python interactive shell and do the following operations. The operands are 3 and 4. 
   &lt;ul&gt; 
    &lt;li&gt;addition(+)&lt;/li&gt; 
    &lt;li&gt;subtraction(-)&lt;/li&gt; 
    &lt;li&gt;multiplication(*)&lt;/li&gt; 
    &lt;li&gt;modulus(%)&lt;/li&gt; 
    &lt;li&gt;division(/)&lt;/li&gt; 
    &lt;li&gt;exponential(**)&lt;/li&gt; 
    &lt;li&gt;floor division operator(//)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Write strings on the python interactive shell. The strings are the following: 
   &lt;ul&gt; 
    &lt;li&gt;Your name&lt;/li&gt; 
    &lt;li&gt;Your family name&lt;/li&gt; 
    &lt;li&gt;Your country&lt;/li&gt; 
    &lt;li&gt;I am enjoying 30 days of python&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Check the data types of the following data: 
   &lt;ul&gt; 
    &lt;li&gt;10&lt;/li&gt; 
    &lt;li&gt;9.8&lt;/li&gt; 
    &lt;li&gt;3.14&lt;/li&gt; 
    &lt;li&gt;4 - 4j&lt;/li&gt; 
    &lt;li&gt;['Asabeneh', 'Python', 'Finland']&lt;/li&gt; 
    &lt;li&gt;Your name&lt;/li&gt; 
    &lt;li&gt;Your family name&lt;/li&gt; 
    &lt;li&gt;Your country&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;Exercise: Level 2&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Create a folder named day_1 inside 30DaysOfPython folder. Inside day_1 folder, create a python file helloworld.py and repeat questions 1, 2, 3 and 4. Remember to use &lt;em&gt;print()&lt;/em&gt; when you are working on a python file. Navigate to the directory where you have saved your file, and run it.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;Exercise: Level 3&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Write an example for different Python data types such as Number(Integer, Float, Complex), String, Boolean, List, Tuple, Set and Dictionary.&lt;/li&gt; 
  &lt;li&gt;Find an &lt;a href="https://en.wikipedia.org/wiki/Euclidean_distance#:~:text=In%20mathematics%2C%20the%20Euclidean%20distance,being%20called%20the%20Pythagorean%20distance."&gt;Euclidean distance&lt;/a&gt; between (2, 3) and (10, 8)&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;üéâ CONGRATULATIONS ! üéâ&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md"&gt;Day 2 &amp;gt;&amp;gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>microsoft/VibeVoice</title>
      <link>https://github.com/microsoft/VibeVoice</link>
      <description>&lt;p&gt;Open-Source Frontier Voice AI&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h2&gt;üéôÔ∏è VibeVoice: Open-Source Frontier Voice AI&lt;/h2&gt; 
 &lt;p&gt;&lt;a href="https://microsoft.github.io/VibeVoice"&gt;&lt;img src="https://img.shields.io/badge/Project-Page-blue?logo=githubpages" alt="Project Page" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/collections/microsoft/vibevoice-68a2ef24a875c44be47b034f"&gt;&lt;img src="https://img.shields.io/badge/HuggingFace-Collection-orange?logo=huggingface" alt="Hugging Face" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/pdf/2508.19205"&gt;&lt;img src="https://img.shields.io/badge/TTS-Report-red?logo=arxiv" alt="TTS Report" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/microsoft/VibeVoice/blob/main/demo/VibeVoice_colab.ipynb"&gt;&lt;img src="https://img.shields.io/badge/StreamingTTS-Colab-green?logo=googlecolab" alt="Colab" /&gt;&lt;/a&gt; &lt;a href="https://aka.ms/vibevoice-asr"&gt;&lt;img src="https://img.shields.io/badge/ASR-Playground-6F42C1?logo=gradio" alt="ASR Playground" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="Figures/VibeVoice_logo_white.png" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/microsoft/VibeVoice/main/Figures/VibeVoice_logo.png" alt="VibeVoice Logo" width="300" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;div align="left"&gt; 
 &lt;h3&gt;üì∞ News&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;2026-01-21: üì£ We open-sourced &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-asr.md"&gt;&lt;strong&gt;VibeVoice-ASR&lt;/strong&gt;&lt;/a&gt;, a unified speech-to-text model designed to handle 60-minute long-form audio in a single pass, generating structured transcriptions containing Who (Speaker), When (Timestamps), and What (Content), with support for User-Customized Context. Try it in &lt;a href="https://aka.ms/vibevoice-asr"&gt;Playground&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;2025-12-16: üì£ We added experimental speakers to &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md"&gt;&lt;strong&gt;VibeVoice‚ÄëRealtime‚Äë0.5B&lt;/strong&gt;&lt;/a&gt; for exploration, including multilingual voices in nine languages (DE, FR, IT, JP, KR, NL, PL, PT, ES) and 11 distinct English style voices. &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md#optional-more-experimental-voices"&gt;Try it&lt;/a&gt;. More speaker types will be added over time.&lt;/p&gt; 
 &lt;p&gt;2025-12-03: üì£ We open-sourced &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md"&gt;&lt;strong&gt;VibeVoice‚ÄëRealtime‚Äë0.5B&lt;/strong&gt;&lt;/a&gt;, a real‚Äëtime text‚Äëto‚Äëspeech model that supports streaming text input and robust long-form speech generation. Try it on &lt;a href="https://colab.research.google.com/github/microsoft/VibeVoice/blob/main/demo/vibevoice_realtime_colab.ipynb"&gt;Colab&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;2025-09-05: VibeVoice is an open-source research framework intended to advance collaboration in the speech synthesis community. After release, we discovered instances where the tool was used in ways inconsistent with the stated intent. Since responsible use of AI is one of Microsoft‚Äôs guiding principles, we have removed the VibeVoice-TTS code from this repository.&lt;/p&gt; 
 &lt;p&gt;2025-08-25: üì£ We open-sourced &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-tts.md"&gt;&lt;strong&gt;VibeVoice-TTS&lt;/strong&gt;&lt;/a&gt;, a long-form multi-speaker text-to-speech model that can synthesize speech up to 90 minutes long with up to 4 distinct speakers.&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;VibeVoice is a &lt;strong&gt;family of open-source frontier voice AI models&lt;/strong&gt; that includes both Text-to-Speech (TTS) and Automatic Speech Recognition (ASR) models.&lt;/p&gt; 
&lt;p&gt;A core innovation of VibeVoice is its use of continuous speech tokenizers (Acoustic and Semantic) operating at an ultra-low frame rate of &lt;strong&gt;7.5 Hz&lt;/strong&gt;. These tokenizers efficiently preserve audio fidelity while significantly boosting computational efficiency for processing long sequences. VibeVoice employs a &lt;a href="https://arxiv.org/abs/2412.08635"&gt;next-token diffusion&lt;/a&gt; framework, leveraging a Large Language Model (LLM) to understand textual context and dialogue flow, and a diffusion head to generate high-fidelity acoustic details.&lt;/p&gt; 
&lt;p&gt;For more information, demos, and examples, please visit our &lt;a href="https://microsoft.github.io/VibeVoice"&gt;Project Page&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;Weight&lt;/th&gt; 
    &lt;th&gt;Quick Try&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;VibeVoice-ASR-7B&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://huggingface.co/microsoft/VibeVoice-ASR"&gt;HF Link&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://aka.ms/vibevoice-asr"&gt;Playground&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;VibeVoice-TTS-1.5B&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://huggingface.co/microsoft/VibeVoice-1.5B"&gt;HF Link&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Disabled&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;VibeVoice-Realtime-0.5B&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://huggingface.co/microsoft/VibeVoice-Realtime-0.5B"&gt;HF Link&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://colab.research.google.com/github/microsoft/VibeVoice/blob/main/demo/vibevoice_realtime_colab.ipynb"&gt;Colab&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Models&lt;/h2&gt; 
&lt;h3&gt;1. üìñ &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-asr.md"&gt;VibeVoice-ASR&lt;/a&gt; - Long-form Speech Recognition&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;VibeVoice-ASR&lt;/strong&gt; is a unified speech-to-text model designed to handle &lt;strong&gt;60-minute long-form audio&lt;/strong&gt; in a single pass, generating structured transcriptions containing &lt;strong&gt;Who (Speaker), When (Timestamps), and What (Content)&lt;/strong&gt;, with support for &lt;strong&gt;Customized Hotwords&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üïí 60-minute Single-Pass Processing&lt;/strong&gt;: Unlike conventional ASR models that slice audio into short chunks (often losing global context), VibeVoice ASR accepts up to &lt;strong&gt;60 minutes&lt;/strong&gt; of continuous audio input within 64K token length. This ensures consistent speaker tracking and semantic coherence across the entire hour.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üë§ Customized Hotwords&lt;/strong&gt;: Users can provide customized hotwords (e.g., specific names, technical terms, or background info) to guide the recognition process, significantly improving accuracy on domain-specific content.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìù Rich Transcription (Who, When, What)&lt;/strong&gt;: The model jointly performs ASR, diarization, and timestamping, producing a structured output that indicates &lt;em&gt;who&lt;/em&gt; said &lt;em&gt;what&lt;/em&gt; and &lt;em&gt;when&lt;/em&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-asr.md"&gt;üìñ Documentation&lt;/a&gt; | &lt;a href="https://huggingface.co/microsoft/VibeVoice-ASR"&gt;ü§ó Hugging Face&lt;/a&gt; | &lt;a href="https://aka.ms/vibevoice-asr"&gt;üéÆ Playground&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/finetuning-asr/README.md"&gt;üõ†Ô∏è Finetuning&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/VibeVoice/main/Figures/DER.jpg" alt="DER" width="50%" /&gt;&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/VibeVoice/main/Figures/cpWER.jpg" alt="cpWER" width="50%" /&gt;&lt;br /&gt; &lt;img src="https://raw.githubusercontent.com/microsoft/VibeVoice/main/Figures/tcpWER.jpg" alt="tcpWER" width="50%" /&gt; &lt;/p&gt; 
&lt;div align="center" id="vibevoice-asr"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/acde5602-dc17-4314-9e3b-c630bc84aefa"&gt;https://github.com/user-attachments/assets/acde5602-dc17-4314-9e3b-c630bc84aefa&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h3&gt;2. üéôÔ∏è &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-tts.md"&gt;VibeVoice-TTS&lt;/a&gt; - Long-form Multi-speaker TTS&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Best for&lt;/strong&gt;: Long-form conversational audio, podcasts, multi-speaker dialogues&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚è±Ô∏è 90-minute Long-form Generation&lt;/strong&gt;: Synthesizes conversational/single-speaker speech up to &lt;strong&gt;90 minutes&lt;/strong&gt; in a single pass, maintaining speaker consistency and semantic coherence throughout.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üë• Multi-speaker Support&lt;/strong&gt;: Supports up to &lt;strong&gt;4 distinct speakers&lt;/strong&gt; in a single conversation, with natural turn-taking and speaker consistency across long dialogues.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üé≠ Expressive Speech&lt;/strong&gt;: Generates expressive, natural-sounding speech that captures conversational dynamics and emotional nuances.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üåê Multi-lingual Support&lt;/strong&gt;: Supports English, Chinese and other languages.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-tts.md"&gt;üìñ Documentation&lt;/a&gt; | &lt;a href="https://huggingface.co/microsoft/VibeVoice-1.5B"&gt;ü§ó Hugging Face&lt;/a&gt; | &lt;a href="https://arxiv.org/pdf/2508.19205"&gt;üìä Paper&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/microsoft/VibeVoice/main/Figures/VibeVoice-TTS-results.jpg" alt="VibeVoice Results" width="80%" /&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/0967027c-141e-4909-bec8-091558b1b784"&gt;https://github.com/user-attachments/assets/0967027c-141e-4909-bec8-091558b1b784&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Chinese&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/322280b7-3093-4c67-86e3-10be4746c88f"&gt;https://github.com/user-attachments/assets/322280b7-3093-4c67-86e3-10be4746c88f&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Cross-Lingual&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/838d8ad9-a201-4dde-bb45-8cd3f59ce722"&gt;https://github.com/user-attachments/assets/838d8ad9-a201-4dde-bb45-8cd3f59ce722&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Spontaneous Singing&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/6f27a8a5-0c60-4f57-87f3-7dea2e11c730"&gt;https://github.com/user-attachments/assets/6f27a8a5-0c60-4f57-87f3-7dea2e11c730&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Long Conversation with 4 people&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/a357c4b6-9768-495c-a576-1618f6275727"&gt;https://github.com/user-attachments/assets/a357c4b6-9768-495c-a576-1618f6275727&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h3&gt;3. ‚ö° &lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md"&gt;VibeVoice-Streaming&lt;/a&gt; - Real-time Streaming TTS&lt;/h3&gt; 
&lt;p&gt;VibeVoice-Realtime is a &lt;strong&gt;lightweight real‚Äëtime&lt;/strong&gt; text-to-speech model supporting &lt;strong&gt;streaming text input&lt;/strong&gt; and &lt;strong&gt;robust long-form speech generation&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Parameter size: 0.5B (deployment-friendly)&lt;/li&gt; 
 &lt;li&gt;Real-time TTS (~300 milliseconds first audible latency)&lt;/li&gt; 
 &lt;li&gt;Streaming text input&lt;/li&gt; 
 &lt;li&gt;Robust long-form speech generation (~10 minutes)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/VibeVoice/main/docs/vibevoice-realtime-0.5b.md"&gt;üìñ Documentation&lt;/a&gt; | &lt;a href="https://huggingface.co/microsoft/VibeVoice-Realtime-0.5B"&gt;ü§ó Hugging Face&lt;/a&gt; | &lt;a href="https://colab.research.google.com/github/microsoft/VibeVoice/blob/main/demo/vibevoice_realtime_colab.ipynb"&gt;üöÄ Colab&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center" id="generated-example-audio-vibevoice-realtime"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/0901d274-f6ae-46ef-a0fd-3c4fba4f76dc"&gt;https://github.com/user-attachments/assets/0901d274-f6ae-46ef-a0fd-3c4fba4f76dc&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;‚ö†Ô∏è Risks and Limitations&lt;/h2&gt; 
&lt;p&gt;While efforts have been made to optimize it through various techniques, it may still produce outputs that are unexpected, biased, or inaccurate. VibeVoice inherits any biases, errors, or omissions produced by its base model (specifically, Qwen2.5 1.5b in this release). Potential for Deepfakes and Disinformation: High-quality synthetic speech can be misused to create convincing fake audio content for impersonation, fraud, or spreading disinformation. Users must ensure transcripts are reliable, check content accuracy, and avoid using generated content in misleading ways. Users are expected to use the generated content and to deploy the models in a lawful manner, in full compliance with all applicable laws and regulations in the relevant jurisdictions. It is best practice to disclose the use of AI when sharing AI-generated content.&lt;/p&gt; 
&lt;p&gt;We do not recommend using VibeVoice in commercial or real-world applications without further testing and development. This model is intended for research and development purposes only. Please use responsibly.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://api.star-history.com/svg?repos=Microsoft/vibevoice&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>browser-use/browser-use</title>
      <link>https://github.com/browser-use/browser-use</link>
      <description>&lt;p&gt;üåê Make websites accessible for AI agents. Automate tasks online with ease.&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/2ccdb752-22fb-41c7-8948-857fc1ad7e24" " /&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/774a46d5-27a0-490c-b7d0-e65fcbbfa358" /&gt; 
 &lt;img alt="Shows a black Browser Use Logo in light color mode and a white one in dark color mode." src="https://github.com/user-attachments/assets/2ccdb752-22fb-41c7-8948-857fc1ad7e24" width="full" /&gt; 
&lt;/picture&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/9955dda9-ede3-4971-8ee0-91cbc3850125" " /&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/6797d09b-8ac3-4cb9-ba07-b289e080765a" /&gt; 
  &lt;img alt="The AI browser agent." src="https://github.com/user-attachments/assets/9955dda9-ede3-4971-8ee0-91cbc3850125" width="400" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://cloud.browser-use.com"&gt;&lt;img src="https://media.browser-use.tools/badges/package" height="48" alt="Browser-Use Package Download Statistics" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://raw.githubusercontent.com/browser-use/browser-use/main/#demos"&gt;&lt;img src="https://media.browser-use.tools/badges/demos" alt="Demos" /&gt;&lt;/a&gt; 
 &lt;img width="16" height="1" alt="" /&gt; 
 &lt;a href="https://docs.browser-use.com"&gt;&lt;img src="https://media.browser-use.tools/badges/docs" alt="Docs" /&gt;&lt;/a&gt; 
 &lt;img width="16" height="1" alt="" /&gt; 
 &lt;a href="https://browser-use.com/posts"&gt;&lt;img src="https://media.browser-use.tools/badges/blog" alt="Blog" /&gt;&lt;/a&gt; 
 &lt;img width="16" height="1" alt="" /&gt; 
 &lt;a href="https://browsermerch.com"&gt;&lt;img src="https://media.browser-use.tools/badges/merch" alt="Merch" /&gt;&lt;/a&gt; 
 &lt;img width="100" height="1" alt="" /&gt; 
 &lt;a href="https://github.com/browser-use/browser-use"&gt;&lt;img src="https://media.browser-use.tools/badges/github" alt="Github Stars" /&gt;&lt;/a&gt; 
 &lt;img width="4" height="1" alt="" /&gt; 
 &lt;a href="https://x.com/intent/user?screen_name=browser_use"&gt;&lt;img src="https://media.browser-use.tools/badges/twitter" alt="Twitter" /&gt;&lt;/a&gt; 
 &lt;img width="4 height=" 1" alt="" /&gt; 
 &lt;a href="https://link.browser-use.com/discord"&gt;&lt;img src="https://media.browser-use.tools/badges/discord" alt="Discord" /&gt;&lt;/a&gt; 
 &lt;img width="4" height="1" alt="" /&gt; 
 &lt;a href="https://cloud.browser-use.com"&gt;&lt;img src="https://media.browser-use.tools/badges/cloud" height="48" alt="Browser-Use Cloud" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;üå§Ô∏è Want to skip the setup? Use our &lt;b&gt;&lt;a href="https://cloud.browser-use.com"&gt;cloud&lt;/a&gt;&lt;/b&gt; for faster, scalable, stealth-enabled browser automation!&lt;/p&gt; 
&lt;h1&gt;ü§ñ LLM Quickstart&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;Direct your favorite coding agent (Cursor, Claude Code, etc) to &lt;a href="https://docs.browser-use.com/llms-full.txt"&gt;Agents.md&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Prompt away!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;br /&gt; 
&lt;h1&gt;üëã Human Quickstart&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;1. Create environment with &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt; (Python&amp;gt;=3.11):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv init
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;2. Install Browser-Use package:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;#  We ship every day - use the latest version!
uv add browser-use
uv sync
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;3. Get your API key from &lt;a href="https://cloud.browser-use.com/new-api-key"&gt;Browser Use Cloud&lt;/a&gt; and add it to your &lt;code&gt;.env&lt;/code&gt; file (new signups get $10 free credits):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# .env
BROWSER_USE_API_KEY=your-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;4. Install Chromium browser:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx browser-use install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;5. Run your first agent:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from browser_use import Agent, Browser, ChatBrowserUse
import asyncio

async def example():
    browser = Browser(
        # use_cloud=True,  # Uncomment to use a stealth browser on Browser Use Cloud
    )

    llm = ChatBrowserUse()

    agent = Agent(
        task="Find the number of stars of the browser-use repo",
        llm=llm,
        browser=browser,
    )

    history = await agent.run()
    return history

if __name__ == "__main__":
    history = asyncio.run(example())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check out the &lt;a href="https://docs.browser-use.com"&gt;library docs&lt;/a&gt; and the &lt;a href="https://docs.cloud.browser-use.com"&gt;cloud docs&lt;/a&gt; for more!&lt;/p&gt; 
&lt;br /&gt; 
&lt;h1&gt;üî• Deploy on Sandboxes&lt;/h1&gt; 
&lt;p&gt;We handle agents, browsers, persistence, auth, cookies, and LLMs. The agent runs right next to the browser for minimal latency.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from browser_use import Browser, sandbox, ChatBrowserUse
from browser_use.agent.service import Agent
import asyncio

@sandbox()
async def my_task(browser: Browser):
    agent = Agent(task="Find the top HN post", browser=browser, llm=ChatBrowserUse())
    await agent.run()

# Just call it like any async function
asyncio.run(my_task())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://docs.browser-use.com/production"&gt;Going to Production&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h1&gt;üöÄ Template Quickstart&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Want to get started even faster?&lt;/strong&gt; Generate a ready-to-run template:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx browser-use init --template default
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This creates a &lt;code&gt;browser_use_default.py&lt;/code&gt; file with a working example. Available templates:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;default&lt;/code&gt; - Minimal setup to get started quickly&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;advanced&lt;/code&gt; - All configuration options with detailed comments&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tools&lt;/code&gt; - Examples of custom tools and extending the agent&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can also specify a custom output path:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx browser-use init --template default --output my_agent.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;h1&gt;üíª CLI&lt;/h1&gt; 
&lt;p&gt;Fast, persistent browser automation from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;browser-use open https://example.com    # Navigate to URL
browser-use state                       # See clickable elements
browser-use click 5                     # Click element by index
browser-use type "Hello"                # Type text
browser-use screenshot page.png         # Take screenshot
browser-use close                       # Close browser
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The CLI keeps the browser running between commands for fast iteration. See &lt;a href="https://raw.githubusercontent.com/browser-use/browser-use/main/browser_use/skill_cli/README.md"&gt;CLI docs&lt;/a&gt; for all commands.&lt;/p&gt; 
&lt;h3&gt;Claude Code Skill&lt;/h3&gt; 
&lt;p&gt;For &lt;a href="https://claude.ai/code"&gt;Claude Code&lt;/a&gt;, install the skill to enable AI-assisted browser automation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir -p ~/.claude/skills/browser-use
curl -o ~/.claude/skills/browser-use/SKILL.md \
  https://raw.githubusercontent.com/browser-use/browser-use/main/skills/browser-use/SKILL.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;h1&gt;Demos&lt;/h1&gt; 
&lt;h3&gt;üìã Form-Filling&lt;/h3&gt; 
&lt;h4&gt;Task = "Fill in this job application with my resume and information."&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/57865ee6-6004-49d5-b2c2-6dff39ec2ba9" alt="Job Application Demo" /&gt; &lt;a href="https://github.com/browser-use/browser-use/raw/main/examples/use-cases/apply_to_job.py"&gt;Example code ‚Üó&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üçé Grocery-Shopping&lt;/h3&gt; 
&lt;h4&gt;Task = "Put this list of items into my instacart."&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/a6813fa7-4a7c-40a6-b4aa-382bf88b1850"&gt;https://github.com/user-attachments/assets/a6813fa7-4a7c-40a6-b4aa-382bf88b1850&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/browser-use/browser-use/raw/main/examples/use-cases/buy_groceries.py"&gt;Example code ‚Üó&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üíª Personal-Assistant.&lt;/h3&gt; 
&lt;h4&gt;Task = "Help me find parts for a custom PC."&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/ac34f75c-057a-43ef-ad06-5b2c9d42bf06"&gt;https://github.com/user-attachments/assets/ac34f75c-057a-43ef-ad06-5b2c9d42bf06&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/browser-use/browser-use/raw/main/examples/use-cases/pcpartpicker.py"&gt;Example code ‚Üó&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üí°See &lt;a href="https://docs.browser-use.com/examples"&gt;more examples here ‚Üó&lt;/a&gt; and give us a star!&lt;/h3&gt; 
&lt;br /&gt; 
&lt;h2&gt;Integrations, hosting, custom tools, MCP, and more on our &lt;a href="https://docs.browser-use.com"&gt;Docs ‚Üó&lt;/a&gt;&lt;/h2&gt; 
&lt;br /&gt; 
&lt;h1&gt;FAQ&lt;/h1&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;What's the best model to use?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;We optimized &lt;strong&gt;ChatBrowserUse()&lt;/strong&gt; specifically for browser automation tasks. On avg it completes tasks 3-5x faster than other models with SOTA accuracy.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Pricing (per 1M tokens):&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Input tokens: $0.20&lt;/li&gt; 
  &lt;li&gt;Cached input tokens: $0.02&lt;/li&gt; 
  &lt;li&gt;Output tokens: $2.00&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;For other LLM providers, see our &lt;a href="https://docs.browser-use.com/supported-models"&gt;supported models documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Can I use custom tools with the agent?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Yes! You can add custom tools to extend the agent's capabilities:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from browser_use import Tools

tools = Tools()

@tools.action(description='Description of what this tool does.')
def custom_tool(param: str) -&amp;gt; str:
    return f"Result: {param}"

agent = Agent(
    task="Your task",
    llm=llm,
    browser=browser,
    tools=tools,
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Can I use this for free?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Yes! Browser-Use is open source and free to use. You only need to choose an LLM provider (like OpenAI, Google, ChatBrowserUse, or run local models with Ollama).&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;How do I handle authentication?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Check out our authentication examples:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/browser-use/browser-use/raw/main/examples/browser/real_browser.py"&gt;Using real browser profiles&lt;/a&gt; - Reuse your existing Chrome profile with saved logins&lt;/li&gt; 
  &lt;li&gt;If you want to use temporary accounts with inbox, choose AgentMail&lt;/li&gt; 
  &lt;li&gt;To sync your auth profile with the remote browser, run &lt;code&gt;curl -fsSL https://browser-use.com/profile.sh | BROWSER_USE_API_KEY=XXXX sh&lt;/code&gt; (replace XXXX with your API key)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;These examples show how to maintain sessions and handle authentication seamlessly.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;How do I solve CAPTCHAs?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;For CAPTCHA handling, you need better browser fingerprinting and proxies. Use &lt;a href="https://cloud.browser-use.com"&gt;Browser Use Cloud&lt;/a&gt; which provides stealth browsers designed to avoid detection and CAPTCHA challenges.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;How do I go into production?&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;Chrome can consume a lot of memory, and running many agents in parallel can be tricky to manage.&lt;/p&gt; 
 &lt;p&gt;For production use cases, use our &lt;a href="https://cloud.browser-use.com"&gt;Browser Use Cloud API&lt;/a&gt; which handles:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Scalable browser infrastructure&lt;/li&gt; 
  &lt;li&gt;Memory management&lt;/li&gt; 
  &lt;li&gt;Proxy rotation&lt;/li&gt; 
  &lt;li&gt;Stealth browser fingerprinting&lt;/li&gt; 
  &lt;li&gt;High-performance parallel execution&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Tell your computer what to do, and it gets it done.&lt;/strong&gt;&lt;/p&gt; 
 &lt;img src="https://github.com/user-attachments/assets/06fa3078-8461-4560-b434-445510c1766f" width="400" /&gt; 
 &lt;p&gt;&lt;a href="https://x.com/intent/user?screen_name=mamagnus00"&gt;&lt;img src="https://img.shields.io/twitter/follow/Magnus?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; ‚ÄÉ‚ÄÉ‚ÄÉ &lt;a href="https://x.com/intent/user?screen_name=gregpr07"&gt;&lt;img src="https://img.shields.io/twitter/follow/Gregor?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt;
  Made with ‚ù§Ô∏è in Zurich and San Francisco 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>OpenBMB/UltraRAG</title>
      <link>https://github.com/OpenBMB/UltraRAG</link>
      <description>&lt;p&gt;UltraRAG v3: A Low-Code MCP Framework for Building Complex and Innovative RAG Pipelines&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="./docs/ultrarag_dark.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="./docs/ultrarag.svg" /&gt; 
  &lt;img alt="UltraRAG" src="https://raw.githubusercontent.com/OpenBMB/UltraRAG/main/docs/ultrarag.svg?sanitize=true" width="55%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; Less Code, Lower Barrier, Faster Deployment &lt;/h3&gt; 
&lt;p align="center"&gt; | &lt;a href="https://ultrarag.openbmb.cn/pages/en/getting_started/introduction"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://modelscope.cn/datasets/UltraRAG/UltraRAG_Benchmark"&gt;&lt;b&gt;Dataset&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://github.com/OpenBMB/UltraRAG/tree/rag-paper-daily/rag-paper-daily"&gt;&lt;b&gt;Paper Daily&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/OpenBMB/UltraRAG/main/docs/README_zh.md"&gt;&lt;b&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/b&gt;&lt;/a&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; üî•&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2026.01.23] üéâ UltraRAG 3.0 Released: Say no to "black box" development‚Äîmake every line of reasoning logic clearly visible üëâ|&lt;a href="https://github.com/OpenBMB/UltraRAG/raw/page/project/blog/en/ultrarag3_0.md"&gt;üìñ Blog&lt;/a&gt;|&lt;/li&gt; 
 &lt;li&gt;[2026.01.20] üéâ AgentCPM-Report Model Released! DeepResearch is finally localized: 8B on-device writing agent AgentCPM-Report is open-sourced üëâ |&lt;a href="https://huggingface.co/openbmb/AgentCPM-Report"&gt;ü§ó Model&lt;/a&gt;|&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Previous News&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;[2025.11.11] üéâ UltraRAG 2.1 Released: Enhanced knowledge ingestion &amp;amp; multimodal support, with a more complete unified evaluation system!&lt;/li&gt; 
  &lt;li&gt;[2025.09.23] New daily RAG paper digest, updated every day üëâ |&lt;a href="https://github.com/OpenBMB/UltraRAG/tree/rag-paper-daily/rag-paper-daily"&gt;üìñ Papers&lt;/a&gt;|&lt;/li&gt; 
  &lt;li&gt;[2025.09.09] Released a Lightweight DeepResearch Pipeline local setup tutorial üëâ |&lt;a href="https://www.bilibili.com/video/BV1p8JfziEwM"&gt;üì∫ bilibili&lt;/a&gt;|&lt;a href="https://github.com/OpenBMB/UltraRAG/raw/page/project/blog/en/01_build_light_deepresearch.md"&gt;üìñ Blog&lt;/a&gt;|&lt;/li&gt; 
  &lt;li&gt;[2025.09.01] Released a step-by-step UltraRAG installation and full RAG walkthrough video üëâ |&lt;a href="https://www.bilibili.com/video/BV1B9apz4E7K/?share_source=copy_web&amp;amp;vd_source=7035ae721e76c8149fb74ea7a2432710"&gt;üì∫ bilibili&lt;/a&gt;|&lt;a href="https://github.com/OpenBMB/UltraRAG/raw/page/project/blog/en/00_Installing_and_Running_RAG.md"&gt;üìñ Blog&lt;/a&gt;|&lt;/li&gt; 
  &lt;li&gt;[2025.08.28] üéâ UltraRAG 2.0 Released! UltraRAG 2.0 is fully upgraded: build a high-performance RAG with just a few dozen lines of code, empowering researchers to focus on ideas and innovation! We have preserved the UltraRAG v2 code, which can be viewed at &lt;a href="https://github.com/OpenBMB/UltraRAG/tree/v2"&gt;v2&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025.01.23] UltraRAG Released! Enabling large models to better comprehend and utilize knowledge bases. The UltraRAG 1.0 code is still available at &lt;a href="https://github.com/OpenBMB/UltraRAG/tree/v1"&gt;v1&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;About UltraRAG&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/18747" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/18747" alt="OpenBMB%2FUltraRAG | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;UltraRAG is the first lightweight RAG development framework based on the &lt;a href="https://modelcontextprotocol.io/docs/getting-started/intro"&gt;Model Context Protocol (MCP)&lt;/a&gt; architecture design, jointly launched by &lt;a href="https://nlp.csai.tsinghua.edu.cn/"&gt;THUNLP&lt;/a&gt; at Tsinghua University, &lt;a href="https://neuir.github.io"&gt;NEUIR&lt;/a&gt; at Northeastern University, &lt;a href="https://www.openbmb.cn/home"&gt;OpenBMB&lt;/a&gt;, and &lt;a href="https://github.com/AI9Stars"&gt;AI9stars&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Designed for research exploration and industrial prototyping, UltraRAG standardizes core RAG components (Retriever, Generation, etc.) as independent &lt;strong&gt;MCP Servers&lt;/strong&gt;, combined with the powerful workflow orchestration capabilities of the &lt;strong&gt;MCP Client&lt;/strong&gt;. Developers can achieve precise orchestration of complex control structures such as conditional branches and loops simply through YAML configuration.&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img alt="UltraRAG" src="https://raw.githubusercontent.com/OpenBMB/UltraRAG/main/docs/architecture.png" width="90%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h3&gt;UltraRAG UI&lt;/h3&gt; 
&lt;p&gt;UltraRAG UI transcends the boundaries of traditional chat interfaces, evolving into a visual RAG Integrated Development Environment (IDE) that combines orchestration, debugging, and demonstration.&lt;/p&gt; 
&lt;p&gt;The system features a powerful built-in Pipeline Builder that supports bidirectional real-time synchronization between "Canvas Construction" and "Code Editing," allowing for granular online adjustments of pipeline parameters and prompts. Furthermore, it introduces an Intelligent AI Assistant to empower the entire development lifecycle, from pipeline structural design to parameter tuning and prompt generation. Once constructed, logic flows can be converted into interactive dialogue systems with a single click. The system seamlessly integrates Knowledge Base Management components, enabling users to build custom knowledge bases for document Q&amp;amp;A. This truly realizes a one-stop closed loop, spanning from underlying logic construction and data governance to final application deployment.&lt;/p&gt; 
&lt;!-- &lt;p align="center"&gt;
  &lt;picture&gt;
    &lt;img alt="UltraRAG_UI" src="./docs/chat_menu.png" width=80%&gt;
  &lt;/picture&gt;
&lt;/p&gt; --&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/fcf437b7-8b79-42f2-bf4e-e3b7c2a896b9"&gt;https://github.com/user-attachments/assets/fcf437b7-8b79-42f2-bf4e-e3b7c2a896b9&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Key Highlights&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üöÄ &lt;strong&gt;Low-Code Orchestration of Complex Workflows&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Inference Orchestration&lt;/strong&gt;: Natively supports control structures such as sequential, loop, and conditional branches. Developers only need to write YAML configuration files to implement complex iterative RAG logic in dozens of lines of code.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‚ö° &lt;strong&gt;Modular Extension and Reproduction&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Atomic Servers&lt;/strong&gt;: Based on the MCP architecture, functions are decoupled into independent Servers. New features only need to be registered as function-level Tools to seamlessly integrate into workflows, achieving extremely high reusability.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üìä &lt;strong&gt;Unified Evaluation and Benchmark Comparison&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Research Efficiency&lt;/strong&gt;: Built-in standardized evaluation workflows, ready-to-use mainstream research benchmarks. Through unified metric management and baseline integration, significantly improves experiment reproducibility and comparison efficiency.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‚ú® &lt;strong&gt;Rapid Interactive Prototype Generation&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;One-Click Delivery&lt;/strong&gt;: Say goodbye to tedious UI development. With just one command, Pipeline logic can be instantly converted into an interactive conversational Web UI, shortening the distance from algorithm to demonstration.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;We provide two installation methods: local source code installation (recommended using &lt;code&gt;uv&lt;/code&gt; for package management) and Docker container deployment&lt;/p&gt; 
&lt;h3&gt;Method 1: Source Code Installation&lt;/h3&gt; 
&lt;p&gt;We strongly recommend using &lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; to manage Python environments and dependencies, as it can greatly improve installation speed.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Prepare Environment&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you haven't installed uv yet, please execute:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;## Direct installation
pip install uv
## Download
curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Download Source Code&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/OpenBMB/UltraRAG.git --depth 1
cd UltraRAG
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Install Dependencies&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Choose one of the following modes to install dependencies based on your use case:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A: Create a New Environment&lt;/strong&gt; Use &lt;code&gt;uv sync&lt;/code&gt; to automatically create a virtual environment and synchronize dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Core dependencies: If you only need to run basic core functions, such as only using UltraRAG UI:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uv sync
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Full installation: If you want to fully experience UltraRAG's retrieval, generation, corpus processing, and evaluation functions, please run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uv sync --all-extras
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;On-demand installation: If you only need to run specific modules, keep the corresponding &lt;code&gt;--extra&lt;/code&gt; as needed, for example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;uv sync --extra retriever   # Retrieval module only
uv sync --extra generation  # Generation module only
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Once installed, activate the virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Windows CMD
.venv\Scripts\activate.bat

# Windows Powershell
.venv\Scripts\Activate.ps1

# macOS / Linux
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;B: Install into an Existing Environment&lt;/strong&gt; To install UltraRAG into your currently active Python environment, use &lt;code&gt;uv pip&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Core dependencies
uv pip install -e .

# Full installation
uv pip install -e ".[all]"

# On-demand installation
uv pip install -e ".[retriever]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Method 2: Docker Container Deployment&lt;/h3&gt; 
&lt;p&gt;If you prefer not to configure a local Python environment, you can deploy using Docker.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Get Code and Images&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# 1. Clone the repository
git clone https://github.com/OpenBMB/UltraRAG.git --depth 1
cd UltraRAG

# 2. Prepare the image (choose one)
# Option A: Pull from Docker Hub
docker pull hdxin2002/ultrarag:v0.3.0-base-cpu # Base version (CPU)
docker pull hdxin2002/ultrarag:v0.3.0-base-gpu # Base version (GPU)
docker pull hdxin2002/ultrarag:v0.3.0          # Full version (GPU)

# Option B: Build locally
docker build -t ultrarag:v0.3.0 .

# 3. Start container (port 5050 is automatically mapped)
docker run -it --gpus all -p 5050:5050 &amp;lt;docker_image_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Start the Container&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Start the container (Port 5050 is mapped by default)
docker run -it --gpus all -p 5050:5050 &amp;lt;docker_image_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: After the container starts, UltraRAG UI will run automatically. You can directly access &lt;code&gt;http://localhost:5050&lt;/code&gt; in your browser to use it.&lt;/p&gt; 
&lt;h3&gt;Verify Installation&lt;/h3&gt; 
&lt;p&gt;After installation, run the following example command to check if the environment is normal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ultrarag run examples/sayhello.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you see the following output, the installation is successful:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Hello, UltraRAG v3!
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;We provide complete tutorial examples from beginner to advanced. Whether you are conducting academic research or building industrial applications, you can find guidance here. Welcome to visit the &lt;a href="https://ultrarag.openbmb.cn/pages/en/getting_started/introduction"&gt;Documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Research Experiments&lt;/h3&gt; 
&lt;p&gt;Designed for researchers, providing data, experimental workflows, and visualization analysis tools.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ultrarag.openbmb.cn/pages/en/getting_started/quick_start"&gt;Getting Started&lt;/a&gt;: Learn how to quickly run standard RAG experimental workflows based on UltraRAG.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ultrarag.openbmb.cn/pages/en/develop_guide/dataset"&gt;Evaluation Data&lt;/a&gt;: Download the most commonly used public evaluation datasets in the RAG field and large-scale retrieval corpora, directly for research benchmark testing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ultrarag.openbmb.cn/pages/en/develop_guide/case_study"&gt;Case Analysis&lt;/a&gt;: Provides a visual Case Study interface to deeply track each intermediate output of the workflow, assisting in analysis and error attribution.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ultrarag.openbmb.cn/pages/en/develop_guide/code_integration"&gt;Code Integration&lt;/a&gt;: Learn how to directly call UltraRAG components in Python code to achieve more flexible customized development.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Demo Systems&lt;/h3&gt; 
&lt;p&gt;Designed for developers and end users, providing complete UI interaction and complex application cases.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ultrarag.openbmb.cn/pages/en/ui/start"&gt;Quick Start&lt;/a&gt;: Learn how to start UltraRAG UI and familiarize yourself with various advanced configurations in administrator mode.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ultrarag.openbmb.cn/pages/en/ui/prepare"&gt;Deployment Guide&lt;/a&gt;: Detailed production environment deployment tutorials, covering the setup of Retriever, Generation models (LLM), and Milvus vector database.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ultrarag.openbmb.cn/pages/en/demo/deepresearch"&gt;Deep Research&lt;/a&gt;: Flagship case, deploy a Deep Research Pipeline. Combined with the AgentCPM-Report model, it can automatically perform multi-step retrieval and integration to generate tens of thousands of words of survey reports.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thanks to the following contributors for their code submissions and testing. We also welcome new members to join us in collectively building a comprehensive RAG ecosystem!&lt;/p&gt; 
&lt;p&gt;You can contribute by following the standard process: &lt;strong&gt;Fork this repository ‚Üí Submit Issues ‚Üí Create Pull Requests (PRs)&lt;/strong&gt;.&lt;/p&gt; 
&lt;a href="https://github.com/OpenBMB/UltraRAG/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=OpenBMB/UltraRAG&amp;amp;nocache=true" /&gt; &lt;/a&gt; 
&lt;h2&gt;Support Us&lt;/h2&gt; 
&lt;p&gt;If you find this repository helpful for your research, please consider giving us a ‚≠ê to show your support.&lt;/p&gt; 
&lt;a href="https://star-history.com/#OpenBMB/UltraRAG&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=OpenBMB/UltraRAG&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=OpenBMB/UltraRAG&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=OpenBMB/UltraRAG&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For technical issues and feature requests, please use &lt;a href="https://github.com/OpenBMB/UltraRAG/issues"&gt;GitHub Issues&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For questions about usage, feedback, or any discussions related to RAG technologies, you are welcome to join our &lt;a href="https://github.com/OpenBMB/UltraRAG/raw/main/docs/wechat_qr.png"&gt;WeChat group&lt;/a&gt;, &lt;a href="https://github.com/OpenBMB/UltraRAG/raw/main/docs/feishu_qr.png"&gt;Feishu group&lt;/a&gt;, and &lt;a href="https://discord.gg/yRFFjjJnnS"&gt;Discord&lt;/a&gt; to exchange ideas with us.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/UltraRAG/main/docs/wechat_qr.png" alt="WeChat Group QR Code" width="220" /&gt;&lt;br /&gt; &lt;b&gt;WeChat Group&lt;/b&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;img src="https://raw.githubusercontent.com/OpenBMB/UltraRAG/main/docs/feishu_qr.png" alt="Feishu Group QR Code" width="220" /&gt;&lt;br /&gt; &lt;b&gt;Feishu Group&lt;/b&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://discord.gg/yRFFjjJnnS"&gt; &lt;img src="https://img.shields.io/badge/Discord-5865F2?logo=discord&amp;amp;logoColor=white" alt="Join Discord" /&gt; &lt;/a&gt;&lt;br /&gt; &lt;b&gt;Discord&lt;/b&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>vllm-project/vllm</title>
      <link>https://github.com/vllm-project/vllm</link>
      <description>&lt;p&gt;A high-throughput and memory-efficient inference and serving engine for LLMs&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-dark.png" /&gt; 
  &lt;img alt="vLLM" src="https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-light.png" width="55%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; Easy, fast, and cheap LLM serving for everyone &lt;/h3&gt; 
&lt;p align="center"&gt; | &lt;a href="https://docs.vllm.ai"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://blog.vllm.ai/"&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2309.06180"&gt;&lt;b&gt;Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://x.com/vllm_project"&gt;&lt;b&gt;Twitter/X&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://discuss.vllm.ai"&gt;&lt;b&gt;User Forum&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://slack.vllm.ai"&gt;&lt;b&gt;Developer Slack&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p&gt;üî• We have built a vllm website to help you get started with vllm. Please visit &lt;a href="https://vllm.ai"&gt;vllm.ai&lt;/a&gt; to learn more. For events, please visit &lt;a href="https://vllm.ai/events"&gt;vllm.ai/events&lt;/a&gt; to join us.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;vLLM is a fast and easy-to-use library for LLM inference and serving.&lt;/p&gt; 
&lt;p&gt;Originally developed in the &lt;a href="https://sky.cs.berkeley.edu"&gt;Sky Computing Lab&lt;/a&gt; at UC Berkeley, vLLM has evolved into a community-driven project with contributions from both academia and industry.&lt;/p&gt; 
&lt;p&gt;vLLM is fast with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;State-of-the-art serving throughput&lt;/li&gt; 
 &lt;li&gt;Efficient management of attention key and value memory with &lt;a href="https://blog.vllm.ai/2023/06/20/vllm.html"&gt;&lt;strong&gt;PagedAttention&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Continuous batching of incoming requests&lt;/li&gt; 
 &lt;li&gt;Fast model execution with CUDA/HIP graph&lt;/li&gt; 
 &lt;li&gt;Quantizations: &lt;a href="https://arxiv.org/abs/2210.17323"&gt;GPTQ&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2306.00978"&gt;AWQ&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2309.05516"&gt;AutoRound&lt;/a&gt;, INT4, INT8, and FP8&lt;/li&gt; 
 &lt;li&gt;Optimized CUDA kernels, including integration with FlashAttention and FlashInfer&lt;/li&gt; 
 &lt;li&gt;Speculative decoding&lt;/li&gt; 
 &lt;li&gt;Chunked prefill&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM is flexible and easy to use with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Seamless integration with popular Hugging Face models&lt;/li&gt; 
 &lt;li&gt;High-throughput serving with various decoding algorithms, including &lt;em&gt;parallel sampling&lt;/em&gt;, &lt;em&gt;beam search&lt;/em&gt;, and more&lt;/li&gt; 
 &lt;li&gt;Tensor, pipeline, data and expert parallelism support for distributed inference&lt;/li&gt; 
 &lt;li&gt;Streaming outputs&lt;/li&gt; 
 &lt;li&gt;OpenAI-compatible API server&lt;/li&gt; 
 &lt;li&gt;Support for NVIDIA GPUs, AMD CPUs and GPUs, Intel CPUs and GPUs, PowerPC CPUs, Arm CPUs, and TPU. Additionally, support for diverse hardware plugins such as Intel Gaudi, IBM Spyre and Huawei Ascend.&lt;/li&gt; 
 &lt;li&gt;Prefix caching support&lt;/li&gt; 
 &lt;li&gt;Multi-LoRA support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM seamlessly supports most popular open-source models on HuggingFace, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Transformer-like LLMs (e.g., Llama)&lt;/li&gt; 
 &lt;li&gt;Mixture-of-Expert LLMs (e.g., Mixtral, Deepseek-V2 and V3)&lt;/li&gt; 
 &lt;li&gt;Embedding Models (e.g., E5-Mistral)&lt;/li&gt; 
 &lt;li&gt;Multi-modal LLMs (e.g., LLaVA)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Find the full list of supported models &lt;a href="https://docs.vllm.ai/en/latest/models/supported_models.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Install vLLM with &lt;code&gt;pip&lt;/code&gt; or &lt;a href="https://docs.vllm.ai/en/latest/getting_started/installation/gpu/index.html#build-wheel-from-source"&gt;from source&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install vllm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit our &lt;a href="https://docs.vllm.ai/en/latest/"&gt;documentation&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/installation.html"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/models/supported_models.html"&gt;List of Supported Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and value any contributions and collaborations. Please check out &lt;a href="https://docs.vllm.ai/en/latest/contributing/index.html"&gt;Contributing to vLLM&lt;/a&gt; for how to get involved.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use vLLM for your research, please cite our &lt;a href="https://arxiv.org/abs/2309.06180"&gt;paper&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;!-- --8&lt;-- [start:contact-us] --&gt; 
&lt;ul&gt; 
 &lt;li&gt;For technical questions and feature requests, please use GitHub &lt;a href="https://github.com/vllm-project/vllm/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For discussing with fellow users, please use the &lt;a href="https://discuss.vllm.ai"&gt;vLLM Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For coordinating contributions and development, please use &lt;a href="https://slack.vllm.ai"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For security disclosures, please use GitHub's &lt;a href="https://github.com/vllm-project/vllm/security/advisories"&gt;Security Advisories&lt;/a&gt; feature&lt;/li&gt; 
 &lt;li&gt;For collaborations and partnerships, please contact us at &lt;a href="mailto:collaboration@vllm.ai"&gt;collaboration@vllm.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- --8&lt;-- [end:contact-us] --&gt; 
&lt;h2&gt;Media Kit&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you wish to use vLLM's logo, please refer to &lt;a href="https://github.com/vllm-project/media-kit"&gt;our media kit repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>bytedance/deer-flow</title>
      <link>https://github.com/bytedance/deer-flow</link>
      <description>&lt;p&gt;DeerFlow is a community-driven Deep Research framework, combining language models with tools like web search, crawling, and Python execution, while contributing back to the open-source community.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ü¶å DeerFlow&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/badge/python-3.12+-blue.svg?sanitize=true" alt="Python 3.12+" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/bytedance/deer-flow"&gt;&lt;img src="https://img.shields.io/badge/DeepWiki-bytedance%2Fdeer--flow-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McCcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==" alt="DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- DeepWiki badge generated by https://deepwiki.ryoppippi.com/ --&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/README_zh.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/README_ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/README_de.md"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/README_es.md"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/README_ru.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/README_pt.md"&gt;Portuguese&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Originated from Open Source, give back to Open Source.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] As we're &lt;a href="https://github.com/bytedance/deer-flow/issues/824"&gt;moving to DeerFlow 2.0&lt;/a&gt; in February, it's time to wrap up DeerFlow 1.0 on the main branch.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;DeerFlow&lt;/strong&gt; (&lt;strong&gt;D&lt;/strong&gt;eep &lt;strong&gt;E&lt;/strong&gt;xploration and &lt;strong&gt;E&lt;/strong&gt;fficient &lt;strong&gt;R&lt;/strong&gt;esearch &lt;strong&gt;Flow&lt;/strong&gt;) is a community-driven Deep Research framework that builds upon the incredible work of the open source community. Our goal is to combine language models with specialized tools for tasks like web search, crawling, and Python code execution, while giving back to the community that made this possible.&lt;/p&gt; 
&lt;p&gt;Currently, DeerFlow has officially entered the &lt;a href="https://console.volcengine.com/vefaas/region:vefaas+cn-beijing/market"&gt;FaaS Application Center of Volcengine&lt;/a&gt;. Users can experience it online through the &lt;a href="https://console.volcengine.com/vefaas/region:vefaas+cn-beijing/market/deerflow/?channel=github&amp;amp;source=deerflow"&gt;experience link&lt;/a&gt; to intuitively feel its powerful functions and convenient operations. At the same time, to meet the deployment needs of different users, DeerFlow supports one-click deployment based on Volcengine. Click the &lt;a href="https://console.volcengine.com/vefaas/region:vefaas+cn-beijing/application/create?templateId=683adf9e372daa0008aaed5c&amp;amp;channel=github&amp;amp;source=deerflow"&gt;deployment link&lt;/a&gt; to quickly complete the deployment process and start an efficient research journey.&lt;/p&gt; 
&lt;p&gt;DeerFlow has newly integrated the intelligent search and crawling toolset independently developed by BytePlus--&lt;a href="https://docs.byteplus.com/en/docs/InfoQuest/What_is_Info_Quest"&gt;InfoQuest (supports free online experience)&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://docs.byteplus.com/en/docs/InfoQuest/What_is_Info_Quest" target="_blank"&gt; &lt;img src="https://sf16-sg.tiktokcdn.com/obj/eden-sg/hubseh7bsbps/20251208-160108.png" alt="infoquest_bannar" /&gt; &lt;/a&gt; 
&lt;p&gt;Please visit &lt;a href="https://deerflow.tech/"&gt;our official website&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;h3&gt;Video&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f3786598-1f2a-4d07-919e-8b99dfa1de3e"&gt;https://github.com/user-attachments/assets/f3786598-1f2a-4d07-919e-8b99dfa1de3e&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;In this demo, we showcase how to use DeerFlow to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Seamlessly integrate with MCP services&lt;/li&gt; 
 &lt;li&gt;Conduct the Deep Research process and produce a comprehensive report with images&lt;/li&gt; 
 &lt;li&gt;Create podcast audio based on the generated report&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Replays&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://deerflow.tech/chat?replay=eiffel-tower-vs-tallest-building"&gt;How tall is Eiffel Tower compared to tallest building?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://deerflow.tech/chat?replay=github-top-trending-repo"&gt;What are the top trending repositories on GitHub?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://deerflow.tech/chat?replay=nanjing-traditional-dishes"&gt;Write an article about Nanjing's traditional dishes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://deerflow.tech/chat?replay=rental-apartment-decoration"&gt;How to decorate a rental apartment?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://deerflow.tech/#case-studies"&gt;Visit our official website to explore more replays.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìë Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/#quick-start"&gt;üöÄ Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/#features"&gt;üåü Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/#architecture"&gt;üèóÔ∏è Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/#development"&gt;üõ†Ô∏è Development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/#docker"&gt;üê≥ Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/#text-to-speech-integration"&gt;üó£Ô∏è Text-to-Speech Integration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/#examples"&gt;üìö Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/#faq"&gt;‚ùì FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/#license"&gt;üìú License&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/#acknowledgments"&gt;üíñ Acknowledgments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/#star-history"&gt;‚≠ê Star History&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;DeerFlow is developed in Python, and comes with a web UI written in Node.js. To ensure a smooth setup process, we recommend using the following tools:&lt;/p&gt; 
&lt;h3&gt;Recommended Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt;:&lt;/strong&gt; Simplify Python environment and dependency management. &lt;code&gt;uv&lt;/code&gt; automatically creates a virtual environment in the root directory and installs all required packages for you‚Äîno need to manually install Python environments.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/nvm-sh/nvm"&gt;&lt;code&gt;nvm&lt;/code&gt;&lt;/a&gt;:&lt;/strong&gt; Manage multiple versions of the Node.js runtime effortlessly.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://pnpm.io/installation"&gt;&lt;code&gt;pnpm&lt;/code&gt;&lt;/a&gt;:&lt;/strong&gt; Install and manage dependencies of Node.js project.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Environment Requirements&lt;/h3&gt; 
&lt;p&gt;Make sure your system meets the following minimum requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python&lt;/a&gt;:&lt;/strong&gt; Version &lt;code&gt;3.12+&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://nodejs.org/en/download/"&gt;Node.js&lt;/a&gt;:&lt;/strong&gt; Version &lt;code&gt;22+&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/bytedance/deer-flow.git
cd deer-flow

# Install dependencies, uv will take care of the python interpreter and venv creation, and install the required packages
uv sync

# Configure .env with your API keys
# Tavily: https://app.tavily.com/home
# Brave_SEARCH: https://brave.com/search/api/
# volcengine TTS: Add your TTS credentials if you have them
cp .env.example .env

# See the 'Supported Search Engines' and 'Text-to-Speech Integration' sections below for all available options

# Configure conf.yaml for your LLM model and API keys
# Please refer to 'docs/configuration_guide.md' for more details
# For local development, you can use Ollama or other local models
cp conf.yaml.example conf.yaml

# Install marp for ppt generation
# https://github.com/marp-team/marp-cli?tab=readme-ov-file#use-package-manager
brew install marp-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Optionally, install web UI dependencies via &lt;a href="https://pnpm.io/installation"&gt;pnpm&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd deer-flow/web
pnpm install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configurations&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/docs/configuration_guide.md"&gt;Configuration Guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Before you start the project, read the guide carefully, and update the configurations to match your specific settings and requirements.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Console UI&lt;/h3&gt; 
&lt;p&gt;The quickest way to run the project is to use the console UI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run the project in a bash-like shell
uv run main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Web UI&lt;/h3&gt; 
&lt;p&gt;This project also includes a Web UI, offering a more dynamic and engaging interactive experience.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] You need to install the dependencies of web UI first.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run both the backend and frontend servers in development mode
# On macOS/Linux
./bootstrap.sh -d

# On Windows
bootstrap.bat -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] By default, the backend server binds to 127.0.0.1 (localhost) for security reasons. If you need to allow external connections (e.g., when deploying on Linux server), you can modify the server host to 0.0.0.0 in the bootstrap script(uv run server.py --host 0.0.0.0). Please ensure your environment is properly secured before exposing the service to external networks.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Open your browser and visit &lt;a href="http://localhost:3000"&gt;&lt;code&gt;http://localhost:3000&lt;/code&gt;&lt;/a&gt; to explore the web UI.&lt;/p&gt; 
&lt;p&gt;Explore more details in the &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/web/"&gt;&lt;code&gt;web&lt;/code&gt;&lt;/a&gt; directory.&lt;/p&gt; 
&lt;h2&gt;Supported Search Engines&lt;/h2&gt; 
&lt;h3&gt;Web Search&lt;/h3&gt; 
&lt;p&gt;DeerFlow supports multiple search engines that can be configured in your &lt;code&gt;.env&lt;/code&gt; file using the &lt;code&gt;SEARCH_API&lt;/code&gt; variable:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tavily&lt;/strong&gt; (default): A specialized search API for AI applications&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Requires &lt;code&gt;TAVILY_API_KEY&lt;/code&gt; in your &lt;code&gt;.env&lt;/code&gt; file&lt;/li&gt; 
   &lt;li&gt;Sign up at: &lt;a href="https://app.tavily.com/home"&gt;https://app.tavily.com/home&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;InfoQuest&lt;/strong&gt; (recommended): AI-optimized intelligent search and crawling toolset independently developed by BytePlus&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Requires &lt;code&gt;INFOQUEST_API_KEY&lt;/code&gt; in your &lt;code&gt;.env&lt;/code&gt; file&lt;/li&gt; 
   &lt;li&gt;Support for time range filtering and site filtering&lt;/li&gt; 
   &lt;li&gt;Provides high-quality search results and content extraction&lt;/li&gt; 
   &lt;li&gt;Sign up at: &lt;a href="https://console.byteplus.com/infoquest/infoquests"&gt;https://console.byteplus.com/infoquest/infoquests&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Visit &lt;a href="https://docs.byteplus.com/en/docs/InfoQuest/What_is_Info_Quest"&gt;https://docs.byteplus.com/en/docs/InfoQuest/What_is_Info_Quest&lt;/a&gt; to learn more&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;DuckDuckGo&lt;/strong&gt;: Privacy-focused search engine&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;No API key required&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Brave Search&lt;/strong&gt;: Privacy-focused search engine with advanced features&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Requires &lt;code&gt;BRAVE_SEARCH_API_KEY&lt;/code&gt; in your &lt;code&gt;.env&lt;/code&gt; file&lt;/li&gt; 
   &lt;li&gt;Sign up at: &lt;a href="https://brave.com/search/api/"&gt;https://brave.com/search/api/&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Arxiv&lt;/strong&gt;: Scientific paper search for academic research&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;No API key required&lt;/li&gt; 
   &lt;li&gt;Specialized for scientific and academic papers&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Searx/SearxNG&lt;/strong&gt;: Self-hosted metasearch engine&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Requires &lt;code&gt;SEARX_HOST&lt;/code&gt; to be set in the &lt;code&gt;.env&lt;/code&gt; file&lt;/li&gt; 
   &lt;li&gt;Supports connecting to either Searx or SearxNG&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To configure your preferred search engine, set the &lt;code&gt;SEARCH_API&lt;/code&gt; variable in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Choose one: tavily, infoquest, duckduckgo, brave_search, arxiv
SEARCH_API=tavily
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Crawling Tools&lt;/h3&gt; 
&lt;p&gt;DeerFlow supports multiple crawling tools that can be configured in your &lt;code&gt;conf.yaml&lt;/code&gt; file:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Jina&lt;/strong&gt; (default): Freely accessible web content crawling tool&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;InfoQuest&lt;/strong&gt; (recommended): AI-optimized intelligent search and crawling toolset developed by BytePlus&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Requires &lt;code&gt;INFOQUEST_API_KEY&lt;/code&gt; in your &lt;code&gt;.env&lt;/code&gt; file&lt;/li&gt; 
   &lt;li&gt;Provides configurable crawling parameters&lt;/li&gt; 
   &lt;li&gt;Supports custom timeout settings&lt;/li&gt; 
   &lt;li&gt;Offers more powerful content extraction capabilities&lt;/li&gt; 
   &lt;li&gt;Visit &lt;a href="https://docs.byteplus.com/en/docs/InfoQuest/What_is_Info_Quest"&gt;https://docs.byteplus.com/en/docs/InfoQuest/What_is_Info_Quest&lt;/a&gt; to learn more&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To configure your preferred crawling tool, set the following in your &lt;code&gt;conf.yaml&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;CRAWLER_ENGINE:
  # Engine type: "jina" (default) or "infoquest"
  engine: infoquest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Private Knowledgebase&lt;/h3&gt; 
&lt;p&gt;DeerFlow supports private knowledgebase such as RAGFlow, Qdrant, Milvus, and VikingDB, so that you can use your private documents to answer questions.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://ragflow.io/docs/dev/"&gt;RAGFlow&lt;/a&gt;&lt;/strong&gt;: open source RAG engine&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# examples in .env.example
RAG_PROVIDER=ragflow
RAGFLOW_API_URL="http://localhost:9388"
RAGFLOW_API_KEY="ragflow-xxx"
RAGFLOW_RETRIEVAL_SIZE=10
RAGFLOW_CROSS_LANGUAGES=English,Chinese,Spanish,French,German,Japanese,Korean
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://qdrant.tech/"&gt;Qdrant&lt;/a&gt;&lt;/strong&gt;: open source vector database&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Using Qdrant Cloud or self-hosted
RAG_PROVIDER=qdrant
QDRANT_LOCATION=https://xyz-example.eu-central.aws.cloud.qdrant.io:6333
QDRANT_API_KEY=your_qdrant_api_key
QDRANT_COLLECTION=documents
QDRANT_EMBEDDING_PROVIDER=openai
QDRANT_EMBEDDING_MODEL=text-embedding-ada-002
QDRANT_EMBEDDING_API_KEY=your_openai_api_key
QDRANT_AUTO_LOAD_EXAMPLES=true
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Core Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;LLM Integration&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;It supports the integration of most models through &lt;a href="https://docs.litellm.ai/docs/providers"&gt;litellm&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Support for open source models like Qwen, you need to read the &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/docs/configuration_guide.md"&gt;configuration&lt;/a&gt; for more details.&lt;/li&gt; 
   &lt;li&gt;OpenAI-compatible API interface&lt;/li&gt; 
   &lt;li&gt;Multi-tier LLM system for different task complexities&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Tools and MCP Integrations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üîç &lt;strong&gt;Search and Retrieval&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Web search via Tavily, InfoQuest, Brave Search and more&lt;/li&gt; 
   &lt;li&gt;Crawling with Jina and InfoQuest&lt;/li&gt; 
   &lt;li&gt;Advanced content extraction&lt;/li&gt; 
   &lt;li&gt;Support for private knowledgebase&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üìÉ &lt;strong&gt;RAG Integration&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Supports multiple vector databases: &lt;a href="https://qdrant.tech/"&gt;Qdrant&lt;/a&gt;, &lt;a href="https://milvus.io/"&gt;Milvus&lt;/a&gt;, &lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt;, VikingDB, MOI, and Dify&lt;/li&gt; 
   &lt;li&gt;Supports mentioning files from RAG providers within the input box&lt;/li&gt; 
   &lt;li&gt;Easy switching between different vector databases through configuration&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üîó &lt;strong&gt;MCP Seamless Integration&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Expand capabilities for private domain access, knowledge graph, web browsing and more&lt;/li&gt; 
   &lt;li&gt;Facilitates integration of diverse research tools and methodologies&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Human Collaboration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;üí¨ &lt;strong&gt;Intelligent Clarification Feature&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Multi-turn dialogue to clarify vague research topics&lt;/li&gt; 
   &lt;li&gt;Improve research precision and report quality&lt;/li&gt; 
   &lt;li&gt;Reduce ineffective searches and token usage&lt;/li&gt; 
   &lt;li&gt;Configurable switch for flexible enable/disable control&lt;/li&gt; 
   &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/docs/configuration_guide.md#multi-turn-clarification-feature"&gt;Configuration Guide - Clarification&lt;/a&gt; for details&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üß† &lt;strong&gt;Human-in-the-loop&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Supports interactive modification of research plans using natural language&lt;/li&gt; 
   &lt;li&gt;Supports auto-acceptance of research plans&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;üìù &lt;strong&gt;Report Post-Editing&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Supports Notion-like block editing&lt;/li&gt; 
   &lt;li&gt;Allows AI refinements, including AI-assisted polishing, sentence shortening, and expansion&lt;/li&gt; 
   &lt;li&gt;Powered by &lt;a href="https://tiptap.dev/"&gt;tiptap&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Content Creation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üéôÔ∏è &lt;strong&gt;Podcast and Presentation Generation&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;AI-powered podcast script generation and audio synthesis&lt;/li&gt; 
   &lt;li&gt;Automated creation of simple PowerPoint presentations&lt;/li&gt; 
   &lt;li&gt;Customizable templates for tailored content&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;DeerFlow implements a modular multi-agent system architecture designed for automated research and code analysis. The system is built on LangGraph, enabling a flexible state-based workflow where components communicate through a well-defined message passing system.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/bytedance/deer-flow/main/assets/architecture.png" alt="Architecture Diagram" /&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;See it live at &lt;a href="https://deerflow.tech/#multi-agent-architecture"&gt;deerflow.tech&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The system employs a streamlined workflow with the following components:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Coordinator&lt;/strong&gt;: The entry point that manages the workflow lifecycle&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Initiates the research process based on user input&lt;/li&gt; 
   &lt;li&gt;Delegates tasks to the planner when appropriate&lt;/li&gt; 
   &lt;li&gt;Acts as the primary interface between the user and the system&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Planner&lt;/strong&gt;: Strategic component for task decomposition and planning&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Analyzes research objectives and creates structured execution plans&lt;/li&gt; 
   &lt;li&gt;Determines if enough context is available or if more research is needed&lt;/li&gt; 
   &lt;li&gt;Manages the research flow and decides when to generate the final report&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Research Team&lt;/strong&gt;: A collection of specialized agents that execute the plan:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Researcher&lt;/strong&gt;: Conducts web searches and information gathering using tools like web search engines, crawling and even MCP services.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Coder&lt;/strong&gt;: Handles code analysis, execution, and technical tasks using Python REPL tool. Each agent has access to specific tools optimized for their role and operates within the LangGraph framework&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reporter&lt;/strong&gt;: Final stage processor for research outputs&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Aggregates findings from the research team&lt;/li&gt; 
   &lt;li&gt;Processes and structures the collected information&lt;/li&gt; 
   &lt;li&gt;Generates comprehensive research reports&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Text-to-Speech Integration&lt;/h2&gt; 
&lt;p&gt;DeerFlow now includes a Text-to-Speech (TTS) feature that allows you to convert research reports to speech. This feature uses the volcengine TTS API to generate high-quality audio from text. Features like speed, volume, and pitch are also customizable.&lt;/p&gt; 
&lt;h3&gt;Using the TTS API&lt;/h3&gt; 
&lt;p&gt;You can access the TTS functionality through the &lt;code&gt;/api/tts&lt;/code&gt; endpoint:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Example API call using curl
curl --location 'http://localhost:8000/api/tts' \
--header 'Content-Type: application/json' \
--data '{
    "text": "This is a test of the text-to-speech functionality.",
    "speed_ratio": 1.0,
    "volume_ratio": 1.0,
    "pitch_ratio": 1.0
}' \
--output speech.mp3
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Testing&lt;/h3&gt; 
&lt;p&gt;Install development dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install -e ".[test]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the test suite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run all tests
make test

# Run specific test file
pytest tests/integration/test_workflow.py

# Run with coverage
make coverage
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Code Quality&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run linting
make lint

# Format code
make format
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debugging with LangGraph Studio&lt;/h3&gt; 
&lt;p&gt;DeerFlow uses LangGraph for its workflow architecture. You can use LangGraph Studio to debug and visualize the workflow in real-time.&lt;/p&gt; 
&lt;h4&gt;Running LangGraph Studio Locally&lt;/h4&gt; 
&lt;p&gt;DeerFlow includes a &lt;code&gt;langgraph.json&lt;/code&gt; configuration file that defines the graph structure and dependencies for the LangGraph Studio. This file points to the workflow graphs defined in the project and automatically loads environment variables from the &lt;code&gt;.env&lt;/code&gt; file.&lt;/p&gt; 
&lt;h5&gt;Mac&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install uv package manager if you don't have it
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies and start the LangGraph server
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.12 langgraph dev --allow-blocking
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Windows / Linux&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies
pip install -e .
pip install -U "langgraph-cli[inmem]"

# Start the LangGraph server
langgraph dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After starting the LangGraph server, you'll see several URLs in the terminal:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;API: &lt;a href="http://127.0.0.1:2024"&gt;http://127.0.0.1:2024&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Studio UI: &lt;a href="https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024"&gt;https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;API Docs: &lt;a href="http://127.0.0.1:2024/docs"&gt;http://127.0.0.1:2024/docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Open the Studio UI link in your browser to access the debugging interface.&lt;/p&gt; 
&lt;h4&gt;Using LangGraph Studio&lt;/h4&gt; 
&lt;p&gt;In the Studio UI, you can:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Visualize the workflow graph and see how components connect&lt;/li&gt; 
 &lt;li&gt;Trace execution in real-time to see how data flows through the system&lt;/li&gt; 
 &lt;li&gt;Inspect the state at each step of the workflow&lt;/li&gt; 
 &lt;li&gt;Debug issues by examining inputs and outputs of each component&lt;/li&gt; 
 &lt;li&gt;Provide feedback during the planning phase to refine research plans&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;When you submit a research topic in the Studio UI, you'll be able to see the entire workflow execution, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The planning phase where the research plan is created&lt;/li&gt; 
 &lt;li&gt;The feedback loop where you can modify the plan&lt;/li&gt; 
 &lt;li&gt;The research and writing phases for each section&lt;/li&gt; 
 &lt;li&gt;The final report generation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enabling LangSmith Tracing&lt;/h3&gt; 
&lt;p&gt;DeerFlow supports LangSmith tracing to help you debug and monitor your workflows. To enable LangSmith tracing:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Make sure your &lt;code&gt;.env&lt;/code&gt; file has the following configurations (see &lt;code&gt;.env.example&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY="xxx"
LANGSMITH_PROJECT="xxx"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start tracing and visualize the graph locally with LangSmith by running:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;langgraph dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This will enable trace visualization in LangGraph Studio and send your traces to LangSmith for monitoring and analysis.&lt;/p&gt; 
&lt;h3&gt;Checkpointing&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Postgres and MonogDB implementation of LangGraph checkpoint saver.&lt;/li&gt; 
 &lt;li&gt;In-memory store is used to caching the streaming messages before persisting to database, If finish_reason is "stop" or "interrupt", it triggers persistence.&lt;/li&gt; 
 &lt;li&gt;Supports saving and loading checkpoints for workflow execution.&lt;/li&gt; 
 &lt;li&gt;Supports saving chat stream events for replaying conversations.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;em&gt;Note: About langgraph issue #5557&lt;/em&gt; The latest langgraph-checkpoint-postgres-2.0.23 have checkpointing issue, you can check the open issue:"TypeError: Object of type HumanMessage is not JSON serializable" [https://github.com/langchain-ai/langgraph/issues/5557].&lt;/p&gt; 
&lt;p&gt;To use postgres checkpoint you should install langgraph-checkpoint-postgres-2.0.21&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Note: About psycopg dependencies&lt;/em&gt; Please read the following document before using postgres: &lt;a href="https://www.psycopg.org/psycopg3/docs/basic/install.html"&gt;https://www.psycopg.org/psycopg3/docs/basic/install.html&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;BY default, psycopg needs libpq to be installed on your system. If you don't have libpq installed, you can install psycopg with the &lt;code&gt;binary&lt;/code&gt; extra to include a statically linked version of libpq mannually:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install psycopg[binary]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will install a self-contained package with all the libraries needed, but binary not supported for all platform, you check the supported platform : &lt;a href="https://pypi.org/project/psycopg-binary/#files"&gt;https://pypi.org/project/psycopg-binary/#files&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;if not supported, you can select local-installation: &lt;a href="https://www.psycopg.org/psycopg3/docs/basic/install.html#local-installation"&gt;https://www.psycopg.org/psycopg3/docs/basic/install.html#local-installation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The default database and collection will be automatically created if not exists. Default database: checkpoing_db Default collection: checkpoint_writes_aio (langgraph checkpoint writes) Default collection: checkpoints_aio (langgraph checkpoints) Default collection: chat_streams (chat stream events for replaying conversations)&lt;/p&gt; 
&lt;p&gt;You need to set the following environment variables in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Enable LangGraph checkpoint saver, supports MongoDB, Postgres
LANGGRAPH_CHECKPOINT_SAVER=true
# Set the database URL for saving checkpoints
LANGGRAPH_CHECKPOINT_DB_URL="mongodb://localhost:27017/"
#LANGGRAPH_CHECKPOINT_DB_URL=postgresql://localhost:5432/postgres
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;You can also run this project with Docker.&lt;/p&gt; 
&lt;p&gt;First, you need read the &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/docs/configuration_guide.md"&gt;configuration&lt;/a&gt; below. Make sure &lt;code&gt;.env&lt;/code&gt;, &lt;code&gt;.conf.yaml&lt;/code&gt; files are ready.&lt;/p&gt; 
&lt;p&gt;Second, to build a Docker image of your own web server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t deer-flow-api .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Final, start up a docker container running the web server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Replace deer-flow-api-app with your preferred container name
# Start the server then bind to localhost:8000
docker run -d -t -p 127.0.0.1:8000:8000 --env-file .env --name deer-flow-api-app deer-flow-api

# stop the server
docker stop deer-flow-api-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Compose (include both backend and frontend)&lt;/h3&gt; 
&lt;p&gt;DeerFlow provides a docker-compose setup to easily run both the backend and frontend together:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# building docker image
docker compose build

# start the server
docker compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] If you want to deploy the deer flow into production environments, please add authentication to the website and evaluate your security check of the MCPServer and Python Repl.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;The following examples demonstrate the capabilities of DeerFlow:&lt;/p&gt; 
&lt;h3&gt;Research Reports&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenAI Sora Report&lt;/strong&gt; - Analysis of OpenAI's Sora AI tool&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Discusses features, access, prompt engineering, limitations, and ethical considerations&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/examples/openai_sora_report.md"&gt;View full report&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Google's Agent to Agent Protocol Report&lt;/strong&gt; - Overview of Google's Agent to Agent (A2A) protocol&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Discusses its role in AI agent communication and its relationship with Anthropic's Model Context Protocol (MCP)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/examples/what_is_agent_to_agent_protocol.md"&gt;View full report&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;What is MCP?&lt;/strong&gt; - A comprehensive analysis of the term "MCP" across multiple contexts&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Explores Model Context Protocol in AI, Monocalcium Phosphate in chemistry, and Micro-channel Plate in electronics&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/examples/what_is_mcp.md"&gt;View full report&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bitcoin Price Fluctuations&lt;/strong&gt; - Analysis of recent Bitcoin price movements&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Examines market trends, regulatory influences, and technical indicators&lt;/li&gt; 
   &lt;li&gt;Provides recommendations based on historical data&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/examples/bitcoin_price_fluctuation.md"&gt;View full report&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;What is LLM?&lt;/strong&gt; - An in-depth exploration of Large Language Models&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Discusses architecture, training, applications, and ethical considerations&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/examples/what_is_llm.md"&gt;View full report&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;How to Use Claude for Deep Research?&lt;/strong&gt; - Best practices and workflows for using Claude in deep research&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Covers prompt engineering, data analysis, and integration with other tools&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/examples/how_to_use_claude_deep_research.md"&gt;View full report&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;AI Adoption in Healthcare: Influencing Factors&lt;/strong&gt; - Analysis of factors driving AI adoption in healthcare&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Discusses AI technologies, data quality, ethical considerations, economic evaluations, organizational readiness, and digital infrastructure&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/examples/AI_adoption_in_healthcare.md"&gt;View full report&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Quantum Computing Impact on Cryptography&lt;/strong&gt; - Analysis of quantum computing's impact on cryptography&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Discusses vulnerabilities of classical cryptography, post-quantum cryptography, and quantum-resistant cryptographic solutions&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/examples/Quantum_Computing_Impact_on_Cryptography.md"&gt;View full report&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cristiano Ronaldo's Performance Highlights&lt;/strong&gt; - Analysis of Cristiano Ronaldo's performance highlights&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Discusses his career achievements, international goals, and performance in various matches&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/examples/Cristiano_Ronaldo's_Performance_Highlights.md"&gt;View full report&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To run these examples or create your own research reports, you can use the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run with a specific query
uv run main.py "What factors are influencing AI adoption in healthcare?"

# Run with custom planning parameters
uv run main.py --max_plan_iterations 3 "How does quantum computing impact cryptography?"

# Run in interactive mode with built-in questions
uv run main.py --interactive

# Or run with basic interactive prompt
uv run main.py

# View all available options
uv run main.py --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Interactive Mode&lt;/h3&gt; 
&lt;p&gt;The application now supports an interactive mode with built-in questions in both English and Chinese:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Launch the interactive mode:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;uv run main.py --interactive
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Select your preferred language (English or ‰∏≠Êñá)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Choose from a list of built-in questions or select the option to ask your own question&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The system will process your question and generate a comprehensive research report&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Human in the Loop&lt;/h3&gt; 
&lt;p&gt;DeerFlow includes a human in the loop mechanism that allows you to review, edit, and approve research plans before they are executed:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Plan Review&lt;/strong&gt;: When human in the loop is enabled, the system will present the generated research plan for your review before execution&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Providing Feedback&lt;/strong&gt;: You can:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Accept the plan by responding with &lt;code&gt;[ACCEPTED]&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Edit the plan by providing feedback (e.g., &lt;code&gt;[EDIT PLAN] Add more steps about technical implementation&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;The system will incorporate your feedback and generate a revised plan&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Auto-acceptance&lt;/strong&gt;: You can enable auto-acceptance to skip the review process:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Via API: Set &lt;code&gt;auto_accepted_plan: true&lt;/code&gt; in your request&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;API Integration&lt;/strong&gt;: When using the API, you can provide feedback through the &lt;code&gt;feedback&lt;/code&gt; parameter:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json"&gt;{
  "messages": [{ "role": "user", "content": "What is quantum computing?" }],
  "thread_id": "my_thread_id",
  "auto_accepted_plan": false,
  "feedback": "[EDIT PLAN] Include more about quantum algorithms"
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Command Line Arguments&lt;/h3&gt; 
&lt;p&gt;The application supports several command-line arguments to customize its behavior:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;query&lt;/strong&gt;: The research query to process (can be multiple words)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;--interactive&lt;/strong&gt;: Run in interactive mode with built-in questions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;--max_plan_iterations&lt;/strong&gt;: Maximum number of planning cycles (default: 1)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;--max_step_num&lt;/strong&gt;: Maximum number of steps in a research plan (default: 3)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;--debug&lt;/strong&gt;: Enable detailed debug logging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/docs/FAQ.md"&gt;FAQ.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is open source and available under the &lt;a href="https://raw.githubusercontent.com/bytedance/deer-flow/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;p&gt;DeerFlow is built upon the incredible work of the open-source community. We are deeply grateful to all the projects and contributors whose efforts have made DeerFlow possible. Truly, we stand on the shoulders of giants.&lt;/p&gt; 
&lt;p&gt;We would like to extend our sincere appreciation to the following projects for their invaluable contributions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/langchain-ai/langchain"&gt;LangChain&lt;/a&gt;&lt;/strong&gt;: Their exceptional framework powers our LLM interactions and chains, enabling seamless integration and functionality.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/langchain-ai/langgraph"&gt;LangGraph&lt;/a&gt;&lt;/strong&gt;: Their innovative approach to multi-agent orchestration has been instrumental in enabling DeerFlow's sophisticated workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/steven-tey/novel"&gt;Novel&lt;/a&gt;&lt;/strong&gt;: Their Notion-style WYSIWYG editor supports our report editing and AI-assisted rewriting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt;&lt;/strong&gt;: We have achieved support for research on users' private knowledge bases through integration with RAGFlow.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;These projects exemplify the transformative power of open-source collaboration, and we are proud to build upon their foundations.&lt;/p&gt; 
&lt;h3&gt;Key Contributors&lt;/h3&gt; 
&lt;p&gt;A heartfelt thank you goes out to the core authors of &lt;code&gt;DeerFlow&lt;/code&gt;, whose vision, passion, and dedication have brought this project to life:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/hetaoBackend/"&gt;Daniel Walnut&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/magiccube/"&gt;Henry Li&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your unwavering commitment and expertise have been the driving force behind DeerFlow's success. We are honored to have you at the helm of this journey.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#bytedance/deer-flow&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=bytedance/deer-flow&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/skills</title>
      <link>https://github.com/anthropics/skills</link>
      <description>&lt;p&gt;Public repository for Agent Skills&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This repository contains Anthropic's implementation of skills for Claude. For information about the Agent Skills standard, see &lt;a href="http://agentskills.io"&gt;agentskills.io&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Skills&lt;/h1&gt; 
&lt;p&gt;Skills are folders of instructions, scripts, and resources that Claude loads dynamically to improve performance on specialized tasks. Skills teach Claude how to complete specific tasks in a repeatable way, whether that's creating documents with your company's brand guidelines, analyzing data using your organization's specific workflows, or automating personal tasks.&lt;/p&gt; 
&lt;p&gt;For more information, check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512176-what-are-skills"&gt;What are skills?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512180-using-skills-in-claude"&gt;Using skills in Claude&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512198-creating-custom-skills"&gt;How to create custom skills&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills"&gt;Equipping agents for the real world with Agent Skills&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;About This Repository&lt;/h1&gt; 
&lt;p&gt;This repository contains skills that demonstrate what's possible with Claude's skills system. These skills range from creative applications (art, music, design) to technical tasks (testing web apps, MCP server generation) to enterprise workflows (communications, branding, etc.).&lt;/p&gt; 
&lt;p&gt;Each skill is self-contained in its own folder with a &lt;code&gt;SKILL.md&lt;/code&gt; file containing the instructions and metadata that Claude uses. Browse through these skills to get inspiration for your own skills or to understand different patterns and approaches.&lt;/p&gt; 
&lt;p&gt;Many skills in this repo are open source (Apache 2.0). We've also included the document creation &amp;amp; editing skills that power &lt;a href="https://www.anthropic.com/news/create-files"&gt;Claude's document capabilities&lt;/a&gt; under the hood in the &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/docx"&gt;&lt;code&gt;skills/docx&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/pdf"&gt;&lt;code&gt;skills/pdf&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/pptx"&gt;&lt;code&gt;skills/pptx&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/xlsx"&gt;&lt;code&gt;skills/xlsx&lt;/code&gt;&lt;/a&gt; subfolders. These are source-available, not open source, but we wanted to share these with developers as a reference for more complex skills that are actively used in a production AI application.&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;These skills are provided for demonstration and educational purposes only.&lt;/strong&gt; While some of these capabilities may be available in Claude, the implementations and behaviors you receive from Claude may differ from what is shown in these skills. These skills are meant to illustrate patterns and possibilities. Always test skills thoroughly in your own environment before relying on them for critical tasks.&lt;/p&gt; 
&lt;h1&gt;Skill Sets&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills"&gt;./skills&lt;/a&gt;: Skill examples for Creative &amp;amp; Design, Development &amp;amp; Technical, Enterprise &amp;amp; Communication, and Document Skills&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/spec"&gt;./spec&lt;/a&gt;: The Agent Skills specification&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/template"&gt;./template&lt;/a&gt;: Skill template&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Try in Claude Code, Claude.ai, and the API&lt;/h1&gt; 
&lt;h2&gt;Claude Code&lt;/h2&gt; 
&lt;p&gt;You can register this repository as a Claude Code Plugin marketplace by running the following command in Claude Code:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/plugin marketplace add anthropics/skills
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, to install a specific set of skills:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Select &lt;code&gt;Browse and install plugins&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;anthropic-agent-skills&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;document-skills&lt;/code&gt; or &lt;code&gt;example-skills&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;Install now&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Alternatively, directly install either Plugin via:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/plugin install document-skills@anthropic-agent-skills
/plugin install example-skills@anthropic-agent-skills
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After installing the plugin, you can use the skill by just mentioning it. For instance, if you install the &lt;code&gt;document-skills&lt;/code&gt; plugin from the marketplace, you can ask Claude Code to do something like: "Use the PDF skill to extract the form fields from &lt;code&gt;path/to/some-file.pdf&lt;/code&gt;"&lt;/p&gt; 
&lt;h2&gt;Claude.ai&lt;/h2&gt; 
&lt;p&gt;These example skills are all already available to paid plans in Claude.ai.&lt;/p&gt; 
&lt;p&gt;To use any skill from this repository or upload custom skills, follow the instructions in &lt;a href="https://support.claude.com/en/articles/12512180-using-skills-in-claude#h_a4222fa77b"&gt;Using skills in Claude&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Claude API&lt;/h2&gt; 
&lt;p&gt;You can use Anthropic's pre-built skills, and upload custom skills, via the Claude API. See the &lt;a href="https://docs.claude.com/en/api/skills-guide#creating-a-skill"&gt;Skills API Quickstart&lt;/a&gt; for more.&lt;/p&gt; 
&lt;h1&gt;Creating a Basic Skill&lt;/h1&gt; 
&lt;p&gt;Skills are simple to create - just a folder with a &lt;code&gt;SKILL.md&lt;/code&gt; file containing YAML frontmatter and instructions. You can use the &lt;strong&gt;template-skill&lt;/strong&gt; in this repository as a starting point:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;---
name: my-skill-name
description: A clear description of what this skill does and when to use it
---

# My Skill Name

[Add your instructions here that Claude will follow when this skill is active]

## Examples
- Example usage 1
- Example usage 2

## Guidelines
- Guideline 1
- Guideline 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The frontmatter requires only two fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt; - A unique identifier for your skill (lowercase, hyphens for spaces)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;description&lt;/code&gt; - A complete description of what the skill does and when to use it&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The markdown content below contains the instructions, examples, and guidelines that Claude will follow. For more details, see &lt;a href="https://support.claude.com/en/articles/12512198-creating-custom-skills"&gt;How to create custom skills&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Partner Skills&lt;/h1&gt; 
&lt;p&gt;Skills are a great way to teach Claude how to get better at using specific pieces of software. As we see awesome example skills from partners, we may highlight some of them here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Notion&lt;/strong&gt; - &lt;a href="https://www.notion.so/notiondevs/Notion-Skills-for-Claude-28da4445d27180c7af1df7d8615723d0"&gt;Notion Skills for Claude&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>topoteretes/cognee</title>
      <link>https://github.com/topoteretes/cognee</link>
      <description>&lt;p&gt;Memory for AI Agents in 6 lines of code&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://github.com/topoteretes/cognee"&gt; &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/dev/assets/cognee-logo-transparent.png" alt="Cognee Logo" height="60" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Cognee - Accurate and Persistent AI Memory&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://www.youtube.com/watch?v=1bezuvLwJmw&amp;amp;t=2s"&gt;Demo&lt;/a&gt; . &lt;a href="https://docs.cognee.ai/"&gt;Docs&lt;/a&gt; . &lt;a href="https://cognee.ai"&gt;Learn More&lt;/a&gt; ¬∑ &lt;a href="https://discord.gg/NQPKmU5CCg"&gt;Join Discord&lt;/a&gt; ¬∑ &lt;a href="https://www.reddit.com/r/AIMemory/"&gt;Join r/AIMemory&lt;/a&gt; . &lt;a href="https://github.com/topoteretes/cognee-community"&gt;Community Plugins &amp;amp; Add-ons&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://GitHub.com/topoteretes/cognee/network/"&gt;&lt;img src="https://img.shields.io/github/forks/topoteretes/cognee.svg?style=social&amp;amp;label=Fork&amp;amp;maxAge=2592000" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/stargazers/"&gt;&lt;img src="https://img.shields.io/github/stars/topoteretes/cognee.svg?style=social&amp;amp;label=Star&amp;amp;maxAge=2592000" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/topoteretes/cognee/commit/"&gt;&lt;img src="https://badgen.net/github/commits/topoteretes/cognee" alt="GitHub commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/tags/"&gt;&lt;img src="https://badgen.net/github/tag/topoteretes/cognee" alt="GitHub tag" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/cognee"&gt;&lt;img src="https://static.pepy.tech/badge/cognee" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/topoteretes/cognee/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/topoteretes/cognee?colorA=00C586&amp;amp;colorB=000000" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/topoteretes"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-‚ù§Ô∏è-ff69b4.svg" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://www.producthunt.com/posts/cognee?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-cognee" target="_blank" style="display:inline-block; margin-right:10px;"&gt; &lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=946346&amp;amp;theme=light&amp;amp;period=daily&amp;amp;t=1744472480704" alt="cognee - Memory for AI Agents  in 5 lines of code | Product Hunt" width="250" height="54" /&gt; &lt;/a&gt; &lt;a href="https://trendshift.io/repositories/13955" target="_blank" style="display:inline-block;"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/13955" alt="topoteretes%2Fcognee | Trendshift" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;Use your data to build personalized and dynamic memory for AI Agents. Cognee lets you replace RAG with scalable and modular ECL (Extract, Cognify, Load) pipelines.&lt;/p&gt; 
 &lt;p align="center"&gt; üåê Available Languages : 
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=fr"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/topoteretes/cognee?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt; &lt;/p&gt; 
 &lt;div style="text-align: center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png" alt="Why cognee?" width="50%" /&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;About Cognee&lt;/h2&gt; 
&lt;p&gt;Cognee is an open-source tool and platform that transforms your raw data into persistent and dynamic AI memory for Agents. It combines vector search with graph databases to make your documents both searchable by meaning and connected by relationships. Cognee offers default memory creation and search which we describe bellow. But with Cognee you can build your own!&lt;/p&gt; 
&lt;p&gt;&lt;span&gt;‚≠ê&lt;/span&gt; &lt;em&gt;Help us reach more developers and grow the cognee community. Star this repo!&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Cognee Open Source:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Interconnects any type of data ‚Äî including past conversations, files, images, and audio transcriptions&lt;/li&gt; 
 &lt;li&gt;Replaces traditional RAG systems with a unified memory layer built on graphs and vectors&lt;/li&gt; 
 &lt;li&gt;Reduces developer effort and infrastructure cost while improving quality and precision&lt;/li&gt; 
 &lt;li&gt;Provides Pythonic data pipelines for ingestion from 30+ data sources&lt;/li&gt; 
 &lt;li&gt;Offers high customizability through user-defined tasks, modular pipelines, and built-in search endpoints&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Basic Usage &amp;amp; Feature Guide&lt;/h2&gt; 
&lt;p&gt;To learn more, &lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;check out this short, end-to-end Colab walkthrough&lt;/a&gt; of Cognee's core features.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Let‚Äôs try Cognee in just a few lines of code. For detailed setup and configuration, see the &lt;a href="https://docs.cognee.ai/getting-started/installation#environment-configuration"&gt;Cognee Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 to 3.13&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 1: Install Cognee&lt;/h3&gt; 
&lt;p&gt;You can install Cognee with &lt;strong&gt;pip&lt;/strong&gt;, &lt;strong&gt;poetry&lt;/strong&gt;, &lt;strong&gt;uv&lt;/strong&gt;, or your preferred Python package manager.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install cognee
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Configure the LLM&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
os.environ["LLM_API_KEY"] = "YOUR OPENAI_API_KEY"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, create a &lt;code&gt;.env&lt;/code&gt; file using our &lt;a href="https://github.com/topoteretes/cognee/raw/main/.env.template"&gt;template&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To integrate other LLM providers, see our &lt;a href="https://docs.cognee.ai/setup-configuration/llm-providers"&gt;LLM Provider Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Step 3: Run the Pipeline&lt;/h3&gt; 
&lt;p&gt;Cognee will take your documents, generate a knowledge graph from them and then query the graph based on combined relationships.&lt;/p&gt; 
&lt;p&gt;Now, run a minimal pipeline:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cognee
import asyncio
from pprint import pprint


async def main():
    # Add text to cognee
    await cognee.add("Cognee turns documents into AI memory.")

    # Generate the knowledge graph
    await cognee.cognify()

    # Add memory algorithms to the graph
    await cognee.memify()

    # Query the knowledge graph
    results = await cognee.search("What does Cognee do?")

    # Display the results
    for result in results:
        pprint(result)


if __name__ == '__main__':
    asyncio.run(main())

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As you can see, the output is generated from the document we previously stored in Cognee:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;  Cognee turns documents into AI memory.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use the Cognee CLI&lt;/h3&gt; 
&lt;p&gt;As an alternative, you can get started with these essential commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli add "Cognee turns documents into AI memory."

cognee-cli cognify

cognee-cli search "What does Cognee do?"
cognee-cli delete --all

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To open the local UI, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cognee-cli -ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Demos &amp;amp; Examples&lt;/h2&gt; 
&lt;p&gt;See Cognee in action:&lt;/p&gt; 
&lt;h3&gt;Persistent Agent Memory&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/e113b628-7212-4a2b-b288-0be39a93a1c3"&gt;Cognee Memory for LangGraph Agents&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Simple GraphRAG&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f2186b2e-305a-42b0-9c2d-9f4473f15df8"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Cognee with Ollama&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/39672858-f774-4136-b957-1e2de67b8981"&gt;Watch Demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community &amp;amp; Support&lt;/h2&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome contributions from the community! Your input helps make Cognee better for everyone. See &lt;a href="https://raw.githubusercontent.com/topoteretes/cognee/main/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Code of Conduct&lt;/h3&gt; 
&lt;p&gt;We're committed to fostering an inclusive and respectful community. Read our &lt;a href="https://github.com/topoteretes/cognee/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; for guidelines.&lt;/p&gt; 
&lt;h2&gt;Research &amp;amp; Citation&lt;/h2&gt; 
&lt;p&gt;We recently published a research paper on optimizing knowledge graphs for LLM reasoning:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{markovic2025optimizinginterfaceknowledgegraphs,
      title={Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning},
      author={Vasilije Markovic and Lazar Obradovic and Laszlo Hajdu and Jovan Pavlovic},
      year={2025},
      eprint={2505.24478},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.24478},
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>KellerJordan/modded-nanogpt</title>
      <link>https://github.com/KellerJordan/modded-nanogpt</link>
      <description>&lt;p&gt;NanoGPT (124M) in 2 minutes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Modded-NanoGPT&lt;/h1&gt; 
&lt;p&gt;This repository hosts the &lt;em&gt;NanoGPT speedrun&lt;/em&gt;, in which we (collaboratively|competitively) search for the fastest algorithm to use 8 NVIDIA H100 GPUs to train a language model that attains 3.28 cross-entropy loss on the &lt;a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb"&gt;FineWeb&lt;/a&gt; validation set.&lt;/p&gt; 
&lt;p&gt;The target (3.28 validation loss on FineWeb) follows Andrej Karpathy's &lt;a href="https://github.com/karpathy/llm.c/discussions/481#:~:text=By%20the%20end%20of%20the%20optimization%20we%27ll%20get%20to%20about%203.29"&gt;GPT-2 replication in llm.c, which attains that loss after running for 45 minutes&lt;/a&gt;. The speedrun code also descends from llm.c's &lt;a href="https://github.com/karpathy/llm.c/raw/master/train_gpt2.py"&gt;PyTorch trainer&lt;/a&gt;, which itself descends from NanoGPT, hence the name of the repo. Thanks to the efforts of many contributors, this repo now contains a training algorithm which attains the target performance in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Under 100 seconds on 8xH100 (the llm.c GPT-2 replication needed 45 minutes)&lt;/li&gt; 
 &lt;li&gt;under 500M tokens (the llm.c GPT-2 replication needed 10B)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This improvement in training speed has been brought about by the following techniques:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Modernized architecture: Rotary embeddings, QK-Norm, and ReLU¬≤&lt;/li&gt; 
 &lt;li&gt;The Muon optimizer [&lt;a href="https://kellerjordan.github.io/posts/muon/"&gt;writeup&lt;/a&gt;] [&lt;a href="https://github.com/KellerJordan/Muon"&gt;repo&lt;/a&gt;]&lt;/li&gt; 
 &lt;li&gt;Use FP8 matmul for head, and asymmetric rescale and softcap logits&lt;/li&gt; 
 &lt;li&gt;Initialization of projections to zero (muP-like)&lt;/li&gt; 
 &lt;li&gt;Skip connections from embedding to every block as well as from block 3 to 6&lt;/li&gt; 
 &lt;li&gt;Extra embeddings which are mixed into the values in attention layers (inspired by Zhou et al. 2024)&lt;/li&gt; 
 &lt;li&gt;Flash Attention 3 with long-short sliding window attention pattern (inspired by Gemma 2) and window size warmup with YaRN&lt;/li&gt; 
 &lt;li&gt;Align training batch starts with EoS and set a max document length&lt;/li&gt; 
 &lt;li&gt;Accumulate gradients for 2 steps for embedding and lm_head before updating parameters&lt;/li&gt; 
 &lt;li&gt;Enable model to back out contributions from first 2/3 layers before prediction&lt;/li&gt; 
 &lt;li&gt;Polar Express implementation in Muon&lt;/li&gt; 
 &lt;li&gt;Smear module to enable 1 token look back&lt;/li&gt; 
 &lt;li&gt;Sparse attention gate&lt;/li&gt; 
 &lt;li&gt;NorMuon&lt;/li&gt; 
 &lt;li&gt;Cautious Weight Decay w/ schedule tied to LR&lt;/li&gt; 
 &lt;li&gt;Exponential decay of residual stream&lt;/li&gt; 
 &lt;li&gt;Batch size schedule&lt;/li&gt; 
 &lt;li&gt;Partial Key Offset&lt;/li&gt; 
 &lt;li&gt;Multi token prediction&lt;/li&gt; 
 &lt;li&gt;Untie embed and lm_head at 2/3 of training&lt;/li&gt; 
 &lt;li&gt;Additional gating on value embeddings and skip connection&lt;/li&gt; 
 &lt;li&gt;Paired head attention&lt;/li&gt; 
 &lt;li&gt;Bigram hash embedding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As well as many systems optimizations.&lt;/p&gt; 
&lt;p&gt;Contributors list (growing with each new record): &lt;a href="https://x.com/bozavlado"&gt;@bozavlado&lt;/a&gt;; &lt;a href="https://x.com/brendanh0gan"&gt;@brendanh0gan&lt;/a&gt;; &lt;a href="https://bsky.app/profile/fernbear.bsky.social"&gt;@fernbear.bsky.social&lt;/a&gt;; &lt;a href="https://x.com/Grad62304977"&gt;@Grad62304977&lt;/a&gt;; &lt;a href="https://x.com/jxbz"&gt;@jxbz&lt;/a&gt;; &lt;a href="https://x.com/kellerjordan0"&gt;@kellerjordan0&lt;/a&gt;; &lt;a href="https://x.com/KoszarskyB"&gt;@KoszarskyB&lt;/a&gt;; &lt;a href="https://x.com/@leloykun"&gt;@leloykun&lt;/a&gt;; &lt;a href="https://x.com/YouJiacheng"&gt;@YouJiacheng&lt;/a&gt;; &lt;a href="https://x.com/jadenj3o"&gt;@jadenj3o&lt;/a&gt;; &lt;a href="https://github.com/KonstantinWilleke"&gt;@KonstantinWilleke&lt;/a&gt;, &lt;a href="https://github.com/alexrgilbert"&gt;@alexrgilbert&lt;/a&gt;, &lt;a href="https://github.com/adricarda"&gt;@adricarda&lt;/a&gt;, &lt;a href="https://github.com/tuttyfrutyee"&gt;@tuttyfrutyee&lt;/a&gt;, &lt;a href="https://github.com/vdlad"&gt;@vdlad&lt;/a&gt;; &lt;a href="https://x.com/ryanyang0"&gt;@ryanyang0&lt;/a&gt;, &lt;a href="https://github.com/vagrawal"&gt;@vagrawal&lt;/a&gt;, &lt;a href="https://x.com/classiclarryd"&gt;@classiclarryd&lt;/a&gt;, &lt;a href="https://github.com/byronxu99"&gt;@byronxu99&lt;/a&gt;, &lt;a href="https://x.com/varunneal"&gt;@varunneal&lt;/a&gt;, &lt;a href="https://github.com/EmelyanenkoK"&gt;@EmelyanenkoK&lt;/a&gt;, &lt;a href="https://github.com/bernard24"&gt;@bernard24&lt;/a&gt;/&lt;a href="https://www.hiverge.ai/"&gt;https://www.hiverge.ai/&lt;/a&gt;, &lt;a href="https://x.com/Gusarich"&gt;@Gusarich&lt;/a&gt;, &lt;a href="https://x.com/li_zichong"&gt;@li_zichong&lt;/a&gt;, &lt;a href="https://github.com/akash5474"&gt;@akash5474&lt;/a&gt;, &lt;a href="https://x.com/omouamoua"&gt;@snimu&lt;/a&gt;, &lt;a href="https://x.com/roeeshenberg"&gt;@roeeshenberg&lt;/a&gt;, &lt;a href="https://x.com/ChrisJMcCormick"&gt;@ChrisJMcCormick&lt;/a&gt;, &lt;a href="https://github.com/dominikkallusky"&gt;@dominikkallusky&lt;/a&gt;, &lt;a href="https://github.com/acutkosky"&gt;@acutkosky&lt;/a&gt;, &lt;a href="https://github.com/manikbhandari"&gt;@manikbhandari&lt;/a&gt;, &lt;a href="https://github.com/andrewbriand"&gt;@andrewbriand&lt;/a&gt;, &lt;a href="https://github.com/jrauvola"&gt;@jrauvola&lt;/a&gt;, &lt;a href="https://x.com/soren_dunn_"&gt;@soren_dunn_&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Running the current record&lt;/h2&gt; 
&lt;p&gt;To run the current record, run the following commands.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/KellerJordan/modded-nanogpt.git &amp;amp;&amp;amp; cd modded-nanogpt
pip install -r requirements.txt
pip install torch==2.10.0.dev20251210+cu126 --index-url https://download.pytorch.org/whl/nightly/cu126
# downloads only the first 900M training tokens to save time
python data/cached_fineweb10B.py 9
./run.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Add torchrun to path if ./run.sh gives error &lt;code&gt;torchrun: command not found&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note: torch.compile will add around 7 minutes of latency the first time you run the code.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Official records are timed on 8 NVIDIA H100 GPUs from &lt;a href="https://app.primeintellect.ai/"&gt;https://app.primeintellect.ai/&lt;/a&gt;. PrimeIntellect has generously sponsored recent validation runs.&lt;/p&gt; 
&lt;h2&gt;Alternative: Running with Docker (recommended for precise timing)&lt;/h2&gt; 
&lt;p&gt;For cases where CUDA or NCCL versions aren't compatible with your current system setup, Docker can be a helpful alternative. This approach standardizes versions for CUDA, NCCL, CUDNN, and Python, reducing dependency issues and simplifying setup. Note: an NVIDIA driver must already be installed on the system (useful if only the NVIDIA driver and Docker are available).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/KellerJordan/modded-nanogpt.git &amp;amp;&amp;amp; cd modded-nanogpt
sudo docker build -t modded-nanogpt .
sudo docker run -it --rm --gpus all -v $(pwd):/modded-nanogpt modded-nanogpt python data/cached_fineweb10B.py 8
sudo docker run -it --rm --gpus all -v $(pwd):/modded-nanogpt modded-nanogpt sh run.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To get an interactive docker, you can use&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo docker run -it --rm --gpus all -v $(pwd):/modded-nanogpt modded-nanogpt bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;World record history&lt;/h2&gt; 
&lt;p&gt;The following is the historical progression of world speed records for the following competitive task:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;Train a neural network to ‚â§3.28 validation loss on FineWeb using 8x NVIDIA H100s.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Note: The 3.28 target was selected to match &lt;a href="https://github.com/karpathy/llm.c/discussions/481"&gt;Andrej Karpathy's GPT-2 (small) reproduction&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;Record time&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Date&lt;/th&gt; 
   &lt;th&gt;Log&lt;/th&gt; 
   &lt;th&gt;Contributors&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;45 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/karpathy/llm.c/discussions/481"&gt;llm.c baseline&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;05/28/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-10-13_llmc/main.log"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@karpathy, llm.c contributors&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;31.4 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1798863559243513937"&gt;Tuned learning rate &amp;amp; rotary embeddings&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;06/06/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-06-06_AdamW/f66d43d7-e449-4029-8adf-e8537bab49ea.log"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;24.9 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1842300916864844014"&gt;Introduced the Muon optimizer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10/04/24&lt;/td&gt; 
   &lt;td&gt;none&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0, @jxbz&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;22.3 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1844820919061287009"&gt;Muon improvements&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10/11/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-10-10_Muon/eb5659d0-fb6a-49e5-a311-f1f89412f726.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0, @bozavlado&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;15.2 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1845865698532450646"&gt;Pad embeddings, ReLU¬≤, zero-init projections, QK-norm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10/14/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-10-14_ModernArch/dabaaddd-237c-4ec9-939d-6608a9ed5e27.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@Grad62304977, @kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;13.1 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1847291684016783746"&gt;Distributed the overhead of Muon&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10/18/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-10-17_DistributedMuon/22d24867-eb5a-4fcc-ae2c-263d0277dfd1.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;12.0 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1847358578686152764"&gt;Upgraded PyTorch 2.5.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10/18/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-10-18_PyTorch25/d4bfb25f-688d-4da5-8743-33926fad4842.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;10.8 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1853188916704387239"&gt;Untied embedding and head&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/03/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-11-03_UntieEmbed/d6b50d71-f419-4d26-bb39-a60d55ae7a04.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@Grad62304977, @kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9&lt;/td&gt; 
   &lt;td&gt;8.2 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1854296101303800108"&gt;Value and embedding skip connections, momentum warmup, logit softcap&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/06/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-11-06_ShortcutsTweaks/dd7304a6-cc43-4d5e-adb8-c070111464a1.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@Grad62304977, @kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;7.8 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1855267054774865980"&gt;Bfloat16 activations&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/08/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-11-08_CastBf16/a833bed8-2fa8-4cfe-af05-58c1cc48bc30.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td&gt;7.2 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1856053121103093922"&gt;U-net pattern skip connections &amp;amp; double lr&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/10/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-11-10_UNetDoubleLr/c87bb826-797b-4f37-98c7-d3a5dad2de74.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@brendanh0gan&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;5.03 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1859331370268623321"&gt;1024-ctx dense causal attention ‚Üí 64K-ctx FlexAttention&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/19/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-11-19_FlexAttention/8384493d-dba9-4991-b16b-8696953f5e6d.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@KoszarskyB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td&gt;4.66 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/hi_tysam/status/1860851011797053450"&gt;Attention window warmup&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/24/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-11-24_WindowWarmup/cf9e4571-c5fc-4323-abf3-a98d862ec6c8.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@fernbear.bsky.social&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;4.41 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/KoszarskyB/status/1864746625572257852"&gt;Value Embeddings&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/04/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-12-04_ValueEmbed"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@KoszarskyB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;3.95 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1865761473886347747"&gt;U-net pattern value embeddings, assorted code optimizations&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/08/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-12-08_UNetValueEmbedsTweaks"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@leloykun, @YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;3.80 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1866734331559071981"&gt;Split value embeddings, block sliding window, separate block mask&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/10/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-12-10_MFUTweaks"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;3.57 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1868938024731787640"&gt;Sparsify value embeddings, improve rotary embeddings, drop an attn layer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/17/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2024-12-17_SparsifyEmbeds"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;3.4 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1876048851158880624"&gt;Lower logit softcap from 30 to 15&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/04/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-01-04_SoftCap/31d6c427-f1f7-4d8a-91be-a67b5dcd13fd.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@KoszarskyB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;3.142 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1878827972519772241"&gt;FP8 head, offset logits, lr decay to 0.1 instead of 0.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/13/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-01-13_Fp8LmHead/c51969c2-d04c-40a7-bcea-c092c3c2d11a.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;2.992 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/leloykun/status/1880301753213809016"&gt;Merged QKV weights, long-short attention, attention scale, lower Adam epsilon, batched Muon&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/16/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-01-16_Sub3Min/1d3bd93b-a69e-4118-aeb8-8184239d7566.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@leloykun, @fernbear.bsky.social, @YouJiacheng, @brendanh0gan, @scottjmaddox, @Grad62304977&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;2.933 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/leloykun/status/1885640350368420160"&gt;Reduced batch size&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/26/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-01-26_BatchSize/c44090cc-1b99-4c95-8624-38fb4b5834f9.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@leloykun&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;2.997 minutes&lt;/td&gt; 
   &lt;td&gt;21st record with new timing&lt;/td&gt; 
   &lt;td&gt;02/01/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-02-01_RuleTweak/eff63a8c-2f7e-4fc5-97ce-7f600dae0bc7.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;not a new record, just re-timing #21 with the &lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/#timing-change-after-record-21"&gt;updated rules&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td&gt;3.014 minutes&lt;/td&gt; 
   &lt;td&gt;21st record with latest torch&lt;/td&gt; 
   &lt;td&gt;05/24/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-05-24_StableTorch/89d9f224-3b01-4581-966e-358d692335e0.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;not a new record, just re-timing #21 with latest torch&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;2.990 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/KonstantinWille/status/1927137223238909969"&gt;Faster gradient all-reduce&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;05/24/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-05-24_FasterReduce/23f40b75-06fb-4c3f-87a8-743524769a35.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@KonstantinWilleke, @alexrgilbert, @adricarda, @tuttyfrutyee, @vdlad; The Enigma project&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;2.979 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1927460573098262616"&gt;Overlap computation and gradient communication&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;05/25/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-05-25_EvenFasterReduce/6ae86d05-5cb2-4e40-a512-63246fd08e45.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@ryanyang0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;2.966 minutes&lt;/td&gt; 
   &lt;td&gt;Replace gradient all_reduce with reduce_scatter&lt;/td&gt; 
   &lt;td&gt;05/30/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-05-30_noallreduce/8054c239-3a18-499e-b0c8-dbd27cb4b3ab.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@vagrawal&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;2.896 minutes&lt;/td&gt; 
   &lt;td&gt;Upgrade PyTorch to 2.9.0.dev20250713+cu126&lt;/td&gt; 
   &lt;td&gt;07/13/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-07-13_UpgradeTorch190/692f80e0-5e64-4819-97d4-0dc83b7106b9.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;2.863 minutes&lt;/td&gt; 
   &lt;td&gt;Align training batch starts with EoS, increase cooldown frac to .45&lt;/td&gt; 
   &lt;td&gt;07/13/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-07-12_BosAlign/c1fd8a38-bb9f-45c4-8af0-d37f70c993f3.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;2.817 minutes&lt;/td&gt; 
   &lt;td&gt;Transpose one of the MLP matrices + add Triton kernel for symmetric matmul&lt;/td&gt; 
   &lt;td&gt;07/18/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-07-18_TritonMuon/record.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/109"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@byronxu99&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;2.812 minutes&lt;/td&gt; 
   &lt;td&gt;Sparse attention gate&lt;/td&gt; 
   &lt;td&gt;08/23/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-08-23_SparseAttnGate/020630eb-2191-4ba2-9ee4-4cdc94316943.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/117"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td&gt;2.731 minutes&lt;/td&gt; 
   &lt;td&gt;Flash Attention 3, 2048 max_doc_len, update ws schedule&lt;/td&gt; 
   &lt;td&gt;09/03/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-09-03_FA3/44fc1276-0510-4961-92c0-730c65e5feba.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/118"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@varunneal&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;30&lt;/td&gt; 
   &lt;td&gt;2.717 minutes&lt;/td&gt; 
   &lt;td&gt;Drop first MLP layer&lt;/td&gt; 
   &lt;td&gt;09/05/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-09-05_SkipMLPBlocks/07e7ae76-b7d0-4481-b149-01e7d81b5ad4.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/120"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@EmelyanenkoK&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;31&lt;/td&gt; 
   &lt;td&gt;2.656 minutes&lt;/td&gt; 
   &lt;td&gt;Dynamically incorporate YaRN during training and validation&lt;/td&gt; 
   &lt;td&gt;09/10/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-09-10_Yarn/0ecdb695-510b-4c3b-b030-09861a162ce8.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/122"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;32&lt;/td&gt; 
   &lt;td&gt;2.625 minutes&lt;/td&gt; 
   &lt;td&gt;Optimize distributed training, improve skip connection gating, and enhance bfloat16 usage&lt;/td&gt; 
   &lt;td&gt;09/11/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-09-11_VectSigmoidBFloat16/0d0d9882-c34f-4d82-b961-a17d5659c988.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/125"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@bernard24 &amp;amp; AI system &lt;a href="https://www.hiverge.ai/"&gt;hiverge.ai&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;33&lt;/td&gt; 
   &lt;td&gt;2.565 minutes&lt;/td&gt; 
   &lt;td&gt;Asynchronously fetch and index data batches, extend final layer attention window for validation&lt;/td&gt; 
   &lt;td&gt;09/15/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-09-15_AsyncDataLoadAttnFinalWindow/25db37c7-2bab-4ef4-ae63-d593590ef823.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/127"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;34&lt;/td&gt; 
   &lt;td&gt;2.547 minutes&lt;/td&gt; 
   &lt;td&gt;Smear token embeddings 1 position forward&lt;/td&gt; 
   &lt;td&gt;09/18/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-09-18_Smear/18a1e5c7-947e-479d-bc3a-a57a61a98fc9.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/130"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;35&lt;/td&gt; 
   &lt;td&gt;2.527 minutes&lt;/td&gt; 
   &lt;td&gt;Drop first attn layer, extend all long windows for validation, update schedule&lt;/td&gt; 
   &lt;td&gt;09/21/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-09-21_DropAttn/01fc4a96-f2a0-47a1-8a6a-c7d10bac99fe.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/131"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;36&lt;/td&gt; 
   &lt;td&gt;2.495 minutes&lt;/td&gt; 
   &lt;td&gt;MuonCustomSizing, perform mlp and attn reduce scatter in shared call&lt;/td&gt; 
   &lt;td&gt;09/23/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-09-23_MuonCustomSizing/b067b4ac-72a6-4436-a6f8-ea51c1efeef3.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/132"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;37&lt;/td&gt; 
   &lt;td&gt;2.483 minutes&lt;/td&gt; 
   &lt;td&gt;Compute cross entropy in BF16 during training&lt;/td&gt; 
   &lt;td&gt;09/27/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-09-27_BF16CE/08c0770f-17fc-44cd-971d-734a7a28a3e3.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/133"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@Gusarich&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;38&lt;/td&gt; 
   &lt;td&gt;2.476 minutes&lt;/td&gt; 
   &lt;td&gt;Polar Express, replacement for Newton-Schulz&lt;/td&gt; 
   &lt;td&gt;09/29/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-09-29_PolarExpress/0e3f0af5-ad08-47a6-813d-0c709b50d422.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/134"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@varunneal&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;39&lt;/td&gt; 
   &lt;td&gt;2.447 minutes&lt;/td&gt; 
   &lt;td&gt;Only update Adam params every other step, reduce batch size&lt;/td&gt; 
   &lt;td&gt;09/30/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-09-30_CustomBatching/40b101b1-77ea-45ea-a089-1d3a647daa22.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/136"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;40&lt;/td&gt; 
   &lt;td&gt;2.358 minutes&lt;/td&gt; 
   &lt;td&gt;Backout, misc hyperparameter tuning, optimize lambda padding&lt;/td&gt; 
   &lt;td&gt;10/04/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-10-04_Backout/514e7581-fbd4-4338-a3e4-e556f9c958ce.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/140"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;41&lt;/td&gt; 
   &lt;td&gt;2.345 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/2510.05491"&gt;NorMuon&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;10/24/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-10-24_NorMuon/088a77ee-9b67-475a-bbb9-3e92e4698799.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/144"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@li_zichong&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;42&lt;/td&gt; 
   &lt;td&gt;2.313 minutes&lt;/td&gt; 
   &lt;td&gt;Update NorMuon LR, Step Logic&lt;/td&gt; 
   &lt;td&gt;10/27/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-10-27_FixMuonLR/14afd380-d3d9-48d7-ad23-4c13cb96754b.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/146"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@varunneal&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;43&lt;/td&gt; 
   &lt;td&gt;2.284 minutes&lt;/td&gt; 
   &lt;td&gt;Cautious Weight Decay w/ schedule&lt;/td&gt; 
   &lt;td&gt;11/10/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-11-10_CautiousWD/1aac0132-a891-4ed9-b358-0fd2abd1b019.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/154"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@varunneal&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;44&lt;/td&gt; 
   &lt;td&gt;2.269 minutes&lt;/td&gt; 
   &lt;td&gt;Backward hooks on Adam, &lt;a href="https://blog.underfit.ai/profiling-101-nanogpt"&gt;Profiling 101&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/16/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-10-31_AdamSyncGradientHook/0c17cdfd-772c-4906-8d11-141b370599a0.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/149"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@akash5474&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;45&lt;/td&gt; 
   &lt;td&gt;2.248 minutes&lt;/td&gt; 
   &lt;td&gt;Refine skip arch, update exponential decay init&lt;/td&gt; 
   &lt;td&gt;11/18/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-11-18_RefineSkip/00f4e1e6-0044-4a08-b88a-3b7ec0624081.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/159"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;46&lt;/td&gt; 
   &lt;td&gt;2.203 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/1998212158770065844"&gt;Batch size schedule&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;11/29/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-11-29_BatchSizeSchedule/10e8f7c6-7175-4467-bdb0-a5de25d771a6.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/163"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@varunneal&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;47&lt;/td&gt; 
   &lt;td&gt;2.193 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/1999630732814348451"&gt;Multiply attn lambda with weight instead of data, fix warmup&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/10/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-12-10_SALambdaOnWeights/15ef5eaf-56e1-40e1-9ddf-af010027c9dd.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/166"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@roeeshenberg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;48&lt;/td&gt; 
   &lt;td&gt;2.170 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2000272495644152317"&gt;Speed up Muon, additional pre-multiply lambda, reshape matrices, update lr, update NorMuon axis&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/11/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-12-11_NorMuonOptimsAndFixes/82edf6be-f343-475d-b93a-47c32acf4de2.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/168"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@ChrisJMcCormick&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;49&lt;/td&gt; 
   &lt;td&gt;2.146 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2000841339299402142"&gt;Partial Key Offset&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/14/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-12-14_PartialKeyOffset/150d40bf-c20b-4568-aac9-26eb919e25fd.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/169"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;50&lt;/td&gt; 
   &lt;td&gt;2.128 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2002482925741486381"&gt;Extend Cautious Weight Decay to Adam parameters&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/18/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-12-18_CautiousWDAdam/1981d492-bc65-4ba9-a0fa-2b30fc5c3eba.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/172"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@roeeshenberg&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;51&lt;/td&gt; 
   &lt;td&gt;2.075 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2003167208483209668"&gt;Retie Embed to lm_head, retune fp8 scales&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/19/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-12-19_RetieLMHead/0828d309-ecfe-4442-9ee9-68fed3a4b599.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/175"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@varunneal&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;52&lt;/td&gt; 
   &lt;td&gt;2.037 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2003863282613190656"&gt;Smooth scalars via beta increase, decrease smear gate lr, freeze scalars during transitions, adam all reduce&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/21/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-12-21_SmoothedScalars/12-21-Smoothed-Scalars/0bc6e909-8ee8-4ae3-ac62-0070e151a808.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/177"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@ChrisJMcCormick&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;53&lt;/td&gt; 
   &lt;td&gt;1.988 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2004248941878296580"&gt;Multi-token prediction, untie embed/lm_head at 2/3 training, lr update, tweak CWD&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/22/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-12-22_MultiTokenPrediction/17aaf854-f338-4d0d-9767-a5db30fd7980.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/178"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@varunneal, feat. @classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;54&lt;/td&gt; 
   &lt;td&gt;1.940 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2004791008098480232"&gt;Asymmetric Logit Rescale&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/26/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-12-26_LogitRescale/03e41c2d-2951-4546-a599-24cd723247fc.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/181"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;55&lt;/td&gt; 
   &lt;td&gt;1.918 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2005659526960492638"&gt;Gates on value embeds and skip connection&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/29/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-12-29_VeSkipGates/2851d7dc-d6a5-4e74-8623-57031425db16.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/186"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;56&lt;/td&gt; 
   &lt;td&gt;1.894 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2007882371576873445"&gt;Optimize and compile Adam, increase Adam buffer precision, move gates from Muon to Adam parameter banks&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;12/31/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-12-31_GatesToCompiledAdam/12-31-gates-to-adam-20stps/219a5f2f-151e-4c56-ab91-3735ae4610b8.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/187"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@ChrisJMcCormick&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;57&lt;/td&gt; 
   &lt;td&gt;1.878 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2008261904566022590"&gt;Bfloat16 attn/mlp weights, mixed precision Muon, interweave Adam/Muon, finer-grain Adam beta&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/04/26&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2026-01-04_MixedPrecisionInterweavedOptimizer/41f606b6-1b9c-46a3-b46e-2beff1521d18.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/190"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd, feat. @YouJiacheng, @ChrisJMcCormick&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;58&lt;/td&gt; 
   &lt;td&gt;1.820 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2008963501688324228"&gt;Paired Head Attention&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/07/26&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2026-01-07_PairedHeadAttention/2a5d5cde-db5f-4aab-a4a8-cc8e183ea671.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/191"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;59&lt;/td&gt; 
   &lt;td&gt;1.781 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2010545452832407943"&gt;Fused triton kernel for linear relu square MLP step&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/10/26&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2026-01-10_FusedLinearReLUSquare/3c47e63b-075e-4b5b-9c76-9dbe7bad9ad4.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/197"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@andrewbriand, @jrauvola&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;60&lt;/td&gt; 
   &lt;td&gt;1.765 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2012927211448516796"&gt;Fused triton kernel for softcapped multi-token prediction cross entropy step&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/16/26&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2026-01-16_FusedSoftcappedEntropy/45beba56-93e2-4995-bc5b-caff3cb2c1b5.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/199"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@soren_dunn_ &amp;amp; AI System &lt;a href="https://www.intology.ai/blog/previewing-locus"&gt;Locus&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;61&lt;/td&gt; 
   &lt;td&gt;1.748 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2013399457841160702"&gt;Unified Optimizers and Transposed LM Head&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/18/26&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2026-01-18_UnifiedOptimizers/unified-optimizer/2fc79469-a527-4bde-8540-8426ed3352d1.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/200"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@ChrisJMcCormick&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;62&lt;/td&gt; 
   &lt;td&gt;1.655 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/classiclarryd/status/2013520088297558274"&gt;Bigram Hash Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/19/26&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2026-01-19_BigramHashEmbedding/40ec7bb6-14b3-46f8-90b7-bb5ed188faba.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/201"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@classiclarryd&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Rules&lt;/h2&gt; 
&lt;p&gt;New records must:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Not modify the train or validation data pipelines. (You can change the batch size, sequence length, attention structure etc.; just don't change the underlying streams of tokens.)&lt;/li&gt; 
 &lt;li&gt;Attain ‚â§3.28 mean val loss. (Due to inter-run variance, submissions must provide enough run logs to attain a statistical significance level of p&amp;lt;0.01 that their mean val loss is ‚â§3.28. Example code to compute p-value can be found &lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_1_short/2025-01-04_SoftCap#softer-softcap"&gt;here&lt;/a&gt;. For submissions which improve speed by optimizing the systems performance, without touching the ML, this requirement is waived.)&lt;/li&gt; 
 &lt;li&gt;Not use any extra &lt;code&gt;torch._inductor.config&lt;/code&gt; or &lt;code&gt;torch.compile&lt;/code&gt; flags. (These can save a few seconds, but they can also make compilation take &amp;gt;30min. This rule was introduced after the 21st record.)&lt;/li&gt; 
 &lt;li&gt;Run faster than the prior record when baselined on the same hardware.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Discretionary reasons why a PR may not be accepted:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Disproportionately degrades the readability of the codebase. A 200 line kernel to drop 300ms is considered worthwhile. 500 lines that convolute the optimizer layout for a 50ms gain will likely be rejected.&lt;/li&gt; 
 &lt;li&gt;The current record is intentionally kept roughly 0.001-0.002 loss below 3.28 to make validation simpler. If a PR substantially consumes this buffer, it should do so in a way that outperforms a simple step count decrease, when measured at equivalent loss.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: &lt;code&gt;torch._inductor.config.coordinate_descent_tuning&lt;/code&gt; is allowed for GPT-2 Medium track (a.k.a. 2.92 track).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Other than that, anything and everything is fair game!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/KellerJordan/modded-nanogpt/discussions/23?sort=new#discussioncomment-12109560"&gt;further clarifications&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Comment on the target metric&lt;/h3&gt; 
&lt;p&gt;The target metric is &lt;em&gt;cross-entropy loss on the FineWeb val set&lt;/em&gt;. To speak mathematically, the goal of the speedrun is *to obtain a probability model of language which assigns a probability of at least &lt;code&gt;math.exp(-3.28 * 10485760)&lt;/code&gt; to the first 10,485,760 tokens of the FineWeb valset. Hence, e.g., we allow evaluation at any sequence length, so long as we still have a valid probability model of language.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Timing change after record 21&lt;/h3&gt; 
&lt;p&gt;After the 21st record, we made two changes to the timing. First, there used to be an initial "grace period" of 10 untimed steps to allow kernel warmup. We replaced this with an explicit kernel-warmup section which is untimed and uses dummy data. This results in an extra runtime of 850ms from the 10 extra timed steps. Second, we banned the use of &lt;code&gt;torch._inductor.config.coordinate_descent_tuning&lt;/code&gt;. This saves ~25min of untimed pre-run compilation, but results in an extra runtime of ~3s.&lt;/p&gt; 
&lt;!--Note: The original llm.c baseline is intended to be closer to a replication of GPT-2 than to an optimized LLM training.
So it's no surprise that there is room to improve; as @karpathy has said, 'llm.c still has a lot of pending optimizations.'
In addition, many of the techniques used in these records are completely standard, such as rotary embeddings.
The goal of this benchmark/speedrun is simply to find out which techniques actually work, and maybe come up with some new ones.--&gt; 
&lt;!--The goal of this benchmark is simply to find out all the techniques which actually work, because I'm going crazy reading all these
LLM training papers
which claim a huge benefit but then use their own idiosyncratic non-competitive benchmark and therefore no one in the community has any idea if it's legit for months.--&gt; 
&lt;!--[LLM](https://arxiv.org/abs/2305.14342) [training](https://arxiv.org/abs/2402.17764) [papers](https://arxiv.org/abs/2410.01131)--&gt; 
&lt;!--I mean hello??? We're in a completely empirical field; it is insane to not have a benchmark. Ideally everyone uses the same LLM training benchmark,
and then reviewing LLM training papers becomes as simple as checking if they beat the benchmark. It's not like this would be unprecedented, that's how things
were in the ImageNet days.
The only possible 'benefit' I can think of for any empirical field to abandon benchmarks is that it would make it easier to publish false results. Oh, I guess that's why it happened.
Hilarious to think about how, in the often-commented-upon and ongoing collapse of the peer review system, people blame the *reviewers* --
yeah, those guys doing free labor who everyone constantly musters all of their intelligence to lie to, it's *their* fault! My bad, you caught me monologuing.--&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Notable attempts &amp;amp; forks&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Notable runs:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://x.com/alexjc/status/1881410039639863622"&gt;@alexjc's 01/20/2025 2.77-minute TokenMonster-based record&lt;/a&gt;. This record is technically outside the rules of the speedrun, since we specified that the train/val tokens must be kept fixed. However, it's very interesting, and worth including. The run is not more data-efficient; rather, the speedup comes from the improved tokenizer allowing the vocabulary size to be reduced (nearly halved!) while preserving the same bytes-per-token, which saves lots of parameters and FLOPs in the head and embeddings.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Notable forks:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/BlinkDL/modded-nanogpt-rwkv"&gt;https://github.com/BlinkDL/modded-nanogpt-rwkv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nikhilvyas/modded-nanogpt-SOAP"&gt;https://github.com/nikhilvyas/modded-nanogpt-SOAP&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Speedrun track 2: GPT-2 Medium&lt;/h2&gt; 
&lt;p&gt;The target loss for this track is lowered from 3.28 to 2.92, as per Andrej Karpathy's 350M-parameter llm.c baseline. This baseline generates a model with performance similar to the original GPT-2 Medium, whereas the first track's baseline generates a model on par with GPT-2 Small. All other rules remain the same.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: &lt;code&gt;torch._inductor.config.coordinate_descent_tuning&lt;/code&gt; is turned on after the record 6 (*).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;#&lt;/th&gt; 
   &lt;th&gt;Record time&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Date&lt;/th&gt; 
   &lt;th&gt;Log&lt;/th&gt; 
   &lt;th&gt;Contributors&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;5.8 hours&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/karpathy/llm.c/discussions/481"&gt;llm.c baseline (350M parameters)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;05/28/24&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-01-18/main.log"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@karpathy, llm.c contributors&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;29.3 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1881959719012847703"&gt;Initial record based on scaling up the GPT-2 small track speedrun&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;01/18/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-01-18/241dd7a7-3d76-4dce-85a4-7df60387f32a.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;28.1 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/kellerjordan0/status/1888320690543284449"&gt;Added standard weight decay&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;02/08/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-02-08_WeightDecay/b01743db-605c-4326-b5b1-d388ee5bebc5.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@kellerjordan0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;27.7 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/leloykun/status/1892793848163946799"&gt;Tuned Muon Newton-Schulz coefficients&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;02/14/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-02-14_OptCoeffs/1baa66b2-bff7-4850-aced-d63885ffb4b6.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@leloykun&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;27.2 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-03-06_LongerCooldown/779c041a-2a37-45d2-a18b-ec0f223c2bb7.txt"&gt;Increased learning rate cooldown phase duration&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;03/06/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-03-06_LongerCooldown/779c041a-2a37-45d2-a18b-ec0f223c2bb7.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;25.95 minutes*&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1905861218138804534"&gt;2x MLP wd, qkv norm, all_reduce/opt.step() overlap, optimized skip pattern&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;03/25/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-03-25_ArchOptTweaks/train_gpt-20250329.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;25.29 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/YouJiacheng/status/1912570883878842527"&gt;Remove FP8 head; ISRU logits softcap; New sharded mixed precision Muon; merge weights&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;04/16/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-04-16_Record7/223_3310d0b1-b24d-48ee-899f-d5c2a254a195.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@YouJiacheng&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;24.50 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://x.com/jadenj3o/status/1914893086276169754"&gt;Cubic sliding window size schedule, 2√ó max window size (24.84 minutes)&lt;/a&gt; &lt;a href="https://x.com/YouJiacheng/status/1915667616913645985"&gt;24.5min repro&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;04/22/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-04-22_Record8/075_640429f2-e726-4e83-aa27-684626239ffc.txt"&gt;log&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@jadenj3o&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;9&lt;/td&gt; 
   &lt;td&gt;24.12 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://snimu.github.io/2025/10/07/modded-nanogpt-value-embeddings.html"&gt;Add two value embeddings&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;08/28/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-08-28_NewValemb/036_61ef4351-7b68-4897-b440-a99221a1a629.txt"&gt;log&lt;/a&gt;, &lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/119"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@snimu&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;24.07 minutes&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://snimu.github.io/2025/10/10/modded-nanogpt-x0.html"&gt;Second input embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;09/11/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-09-11_SecondInputEmbed/000_592014ec-6781-4f59-b274-c4af68ccfe75.txt"&gt;log&lt;/a&gt;, &lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/124"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@snimu&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td&gt;23.45 minutes&lt;/td&gt; 
   &lt;td&gt;Upgrade from torch 2.7 to torch==2.10.0.dev20251210+cu126&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;23.28 minutes&lt;/td&gt; 
   &lt;td&gt;Snoo Optimizer (Outer optimizer around Adam and Muon)&lt;/td&gt; 
   &lt;td&gt;09/16/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-09-16_Snoo/000_01db7a67-f715-4114-a7b5-6bfe23bac1b1.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/128"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@dominikkallusky&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td&gt;23.14 minutes&lt;/td&gt; 
   &lt;td&gt;EMA Wrapper on Muon&lt;/td&gt; 
   &lt;td&gt;09/17/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-09-17_UpdateSmoothing/001_8379f695-6bc3-4f76-b58b-8fadd3b6ebb0.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/129"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@acutkosky&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;23.08 minutes&lt;/td&gt; 
   &lt;td&gt;Combine both records 12 &amp;amp; 13&lt;/td&gt; 
   &lt;td&gt;09/30/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-09-30_SmoothedSnooMedium/101_5bc91cd0-cb46-428c-a5da-9d8d228f1f97.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/137"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@acutkosky&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;23.03 minutes&lt;/td&gt; 
   &lt;td&gt;Backout (Skip from 2/3 point to pre-lm_head)&lt;/td&gt; 
   &lt;td&gt;10/04/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-10-04_GPT2MediumLayerReuse/000_cc3943e4-02b5-4ae3-9441-839d32dfd9b2.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/139"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@snimu&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;22.99 minutes&lt;/td&gt; 
   &lt;td&gt;Smear-MTP&lt;/td&gt; 
   &lt;td&gt;11/02/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-11-02-Smear-MTP/000_3b50518d-d542-44bc-8566-3abf633f83ad.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/151"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@snimu&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;22.98 minutes&lt;/td&gt; 
   &lt;td&gt;Remove Redundant Mask Op&lt;/td&gt; 
   &lt;td&gt;11/12/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-11-12_BlockMaskRedundantOp/000_3b22a9d4-b52e-4916-99bf-3d48b38747a7.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/157/"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;@manikbhandari&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;17.35 minutes&lt;/td&gt; 
   &lt;td&gt;Bulk transfer short track features&lt;/td&gt; 
   &lt;td&gt;12/31/25&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/records/track_2_medium/2025-12-31_BulkSmallTrackTransfer/354be270-7d41-44b7-8064-f040923f024f.txt"&gt;log&lt;/a&gt;,&lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/188"&gt;PR&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Q: What is the point of NanoGPT speedrunning?&lt;/h3&gt; 
&lt;p&gt;A: The officially stated goal of NanoGPT speedrunning is as follows: &lt;code&gt;gotta go fast&lt;/code&gt;. But for something a little more verbose involving an argument for good benchmarking, here's some kind of manifesto, adorned with a blessing from the master. &lt;a href="https://x.com/karpathy/status/1846790537262571739"&gt;https://x.com/karpathy/status/1846790537262571739&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Q: What makes "NanoGPT speedrunning" not just another idiosyncratic benchmark?&lt;/h3&gt; 
&lt;p&gt;A: Because it is a &lt;em&gt;competitive&lt;/em&gt; benchmark. In particular, if you attain a new speed record (using whatever method you want), there is an open invitation for you to post that record (on arXiv or X) and thereby vacuum up all the clout for yourself. I will even help you do it by reposting you as much as I can.&lt;/p&gt; 
&lt;!--On the contrary, for example, the benchmark used in the [Sophia](https://arxiv.org/abs/2305.14342) paper does *not* have this property.
There is no such open invitation for anyone to compete on the benchmark they used. In particular, if, for a random and definitely not weirdly specific example, you happen to find better AdamW hyperparameters for their training setup than
the ones they used which significantly close the gap between AdamW and their proposed optimizer,
then there is no clear path for you to publish that result in *any* form.
You could try posting it on X.com, but then you would be risking being perceived as aggressive/confrontational, which is *not a good look* in this racket.
So if you're rational, the result probably just dies with you and no one else learns anything
(unless you're in a frontier lab, in which case you can do a nice internal writeup. Boy I'd love to get my hands on those writeups).--&gt; 
&lt;p&gt;&lt;a href="https://www.argmin.net/p/too-much-information"&gt;"Artificial intelligence advances by inventing games and gloating to goad others to play" - Professor Ben Recht&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Q: NanoGPT speedrunning is cool and all, but meh it probably won't scale and is just overfitting to val loss&lt;/h3&gt; 
&lt;p&gt;A: This is hard to refute, since "at scale" is an infinite category (what if the methods stop working only for &amp;gt;100T models?), making it impossible to fully prove. Also, I would agree that some of the methods used in the speedrun are unlikely to scale, particularly those which &lt;em&gt;impose additional structure&lt;/em&gt; on the network, such as logit softcapping. But if the reader cares about 1.5B models, they might be convinced by this result:&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Straightforwardly scaling up the speedrun (10/18/24 version) to 1.5B parameters yields a model with GPT-2 (1.5B)-level HellaSwag performance 2.5x more cheaply than &lt;a href="https://github.com/karpathy/llm.c/discussions/677"&gt;@karpathy's baseline&lt;/a&gt; ($233 instead of $576):&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/img/nanogpt_speedrun51.png" alt="" /&gt; [&lt;a href="https://github.com/KellerJordan/modded-nanogpt/raw/master/records/track_1_short/2024-10-20_ScaleUp1B/ad8d7ae5-7b2d-4ee9-bc52-f912e9174d7a.txt"&gt;reproducible log&lt;/a&gt;] &lt;img src="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/img/nanogpt_speedrun52.png" alt="" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;&lt;a href="https://github.com/KellerJordan/Muon"&gt;Muon optimizer&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Muon is defined as follows:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/img/algo_optimizer.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;Where NewtonSchulz5 is the following Newton-Schulz iteration [2, 3], which approximately replaces &lt;code&gt;G&lt;/code&gt; with &lt;code&gt;U @ V.T&lt;/code&gt; where &lt;code&gt;U, S, V = G.svd()&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@torch.compile
def zeroth_power_via_newtonschulz5(G, steps=5, eps=1e-7):
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16() / (G.norm() + eps)
    if G.size(0) &amp;gt; G.size(1):
        X = X.T 
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A
        X = a * X + B @ X
    if G.size(0) &amp;gt; G.size(1):
        X = X.T 
    return X.to(G.dtype)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For this training scenario, Muon has the following favorable properties:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Lower memory usage than Adam&lt;/li&gt; 
 &lt;li&gt;~1.5x better sample-efficiency&lt;/li&gt; 
 &lt;li&gt;&amp;lt;2% wallclock overhead&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provenance&lt;/h3&gt; 
&lt;p&gt;Many of the choices made to generate this optimizer were obtained experimentally by our pursuit of &lt;a href="https://github.com/KellerJordan/cifar10-airbench"&gt;CIFAR-10 speedrunning&lt;/a&gt;. In particular, we experimentally obtained the following practices:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Using Nesterov momentum inside the update, with orthogonalization applied after momentum.&lt;/li&gt; 
 &lt;li&gt;Using a specifically quintic Newton-Schulz iteration as the method of orthogonalization.&lt;/li&gt; 
 &lt;li&gt;Using non-convergent coefficients for the quintic polynomial in order to maximize slope at zero, and thereby minimize the number of necessary Newton-Schulz iterations. It turns out that the variance doesn't actually matter that much, so we end up with a quintic that rapidly converges to the range 0.68, 1.13 upon repeated application, rather than converging more slowly to 1.&lt;/li&gt; 
 &lt;li&gt;Running the Newton-Schulz iteration in bfloat16 (whereas Shampoo implementations often depend on inverse-pth-roots run in fp32 or fp64).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Our use of a Newton-Schulz iteration for orthogonalization traces to &lt;a href="https://arxiv.org/abs/2409.20325"&gt;Bernstein &amp;amp; Newhouse (2024)&lt;/a&gt;, who suggested it as a way to compute Shampoo [5, 6] preconditioners, and theoretically explored Shampoo without preconditioner accumulation. In particular, Jeremy Bernstein @jxbz sent us the draft, which caused us to experiment with various Newton-Schulz iterations as the orthogonalization method for this optimizer. If we had used SVD instead of a Newton-Schulz iteration, this optimizer would have been too slow to be useful. Bernstein &amp;amp; Newhouse also pointed out that Shampoo without preconditioner accumulation is equivalent to steepest descent in the spectral norm, and therefore Shampoo can be thought of as a way to smooth out spectral steepest descent. The proposed optimizer can be thought of as a second way of smoothing spectral steepest descent, with a different set of memory and runtime tradeoffs compared to Shampoo.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Running on fewer GPUs&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;To run experiments on fewer GPUs, simply modify &lt;code&gt;run.sh&lt;/code&gt; to have a different &lt;code&gt;--nproc_per_node&lt;/code&gt;. This should not change the behavior of the training.&lt;/li&gt; 
 &lt;li&gt;If you're running out of memory, you may need to reduce the sequence length for FlexAttention (which does change the training. see &lt;a href="https://github.com/KellerJordan/modded-nanogpt/pull/38"&gt;here&lt;/a&gt; for a guide)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;References&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2406.17557"&gt;Guilherme Penedo et al. "The fineweb datasets: Decanting the web for the finest text data at scale." arXiv preprint arXiv:2406.17557 (2024).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Nicholas J. Higham. Functions of Matrices. Society for Industrial and Applied Mathematics (2008). Equation 5.22.&lt;/li&gt; 
 &lt;li&gt;G√É¬ºnther Schulz. Iterative Berechnung der reziproken Matrix. Z. Angew. Math. Mech., 13:57√¢¬Ä¬ì59 (1933).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2409.20325"&gt;Jeremy Bernstein and Laker Newhouse. "Old Optimizer, New Norm: An Anthology." arxiv preprint arXiv:2409.20325 (2024).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/1802.09568"&gt;Vineet Gupta, Tomer Koren, and Yoram Singer. "Shampoo: Preconditioned stochastic tensor optimization." International Conference on Machine Learning. PMLR, 2018.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2002.09018"&gt;Rohan Anil et al. "Scalable second order optimization for deep learning." arXiv preprint arXiv:2002.09018 (2020).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2405.18392"&gt;Alexander H√É¬§gele et al. "Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations." arXiv preprint arXiv:2405.18392 (2024).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2410.17897"&gt;Zhanchao Zhou et al. "Value Residual Learning For Alleviating Attention Concentration In Transformers." arXiv preprint arXiv:2410.17897 (2024).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2408.00118"&gt;Team, Gemma, et al. "Gemma 2: Improving open language models at a practical size." arXiv preprint arXiv:2408.00118 (2024).&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"&gt;Alec Radford et al. "Language models are unsupervised multitask learners." OpenAI blog 1.8 (2019).&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@misc{modded_nanogpt_2024,
  author       = {Keller Jordan and Jeremy Bernstein and Brendan Rappazzo and
                  @fernbear.bsky.social and Boza Vlado and You Jiacheng and
                  Franz Cesista and Braden Koszarsky and @Grad62304977},
  title        = {modded-nanogpt: Speedrunning the NanoGPT baseline},
  year         = {2024},
  url          = {https://github.com/KellerJordan/modded-nanogpt}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;img src="https://raw.githubusercontent.com/KellerJordan/modded-nanogpt/master/img/dofa.jpg" alt="itsover_wereback" style="width:100%;" /&gt;</description>
    </item>
    
    <item>
      <title>Shubhamsaboo/awesome-llm-apps</title>
      <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
      <description>&lt;p&gt;Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="http://www.theunwindai.com"&gt; &lt;img src="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/unwind_black.png" width="900px" alt="Unwind AI" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.linkedin.com/in/shubhamsaboo/"&gt; &lt;img src="https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;amp;style=flat-square" alt="LinkedIn" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/Saboo_Shubham_"&gt; &lt;img src="https://img.shields.io/twitter/follow/Shubham_Saboo" alt="Twitter" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üåü Awesome LLM Apps&lt;/h1&gt; 
&lt;p&gt;A curated collection of &lt;strong&gt;Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.&lt;/strong&gt; This repository features LLM apps that use models from &lt;img src="https://cdn.simpleicons.org/openai" alt="openai logo" width="25" height="15" /&gt;&lt;strong&gt;OpenAI&lt;/strong&gt; , &lt;img src="https://cdn.simpleicons.org/anthropic" alt="anthropic logo" width="25" height="15" /&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;, &lt;img src="https://cdn.simpleicons.org/googlegemini" alt="google logo" width="25" height="18" /&gt;&lt;strong&gt;Google&lt;/strong&gt;, &lt;img src="https://cdn.simpleicons.org/x" alt="X logo" width="25" height="15" /&gt;&lt;strong&gt;xAI&lt;/strong&gt; and open-source models like &lt;img src="https://cdn.simpleicons.org/alibabacloud" alt="alibaba logo" width="25" height="15" /&gt;&lt;strong&gt;Qwen&lt;/strong&gt; or &lt;img src="https://cdn.simpleicons.org/meta" alt="meta logo" width="25" height="15" /&gt;&lt;strong&gt;Llama&lt;/strong&gt; that you can run locally on your computer.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/9876" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/9876" alt="Shubhamsaboo%2Fawesome-llm-apps | Trendshift" style="width: 250px; height: 55px;" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;ü§î Why Awesome LLM Apps?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí° Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.&lt;/li&gt; 
 &lt;li&gt;üî• Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp;amp; RAG.&lt;/li&gt; 
 &lt;li&gt;üéì Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôè Thanks to our sponsors&lt;/h2&gt; 
&lt;table align="center" cellpadding="16" cellspacing="12"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://tsdb.co/shubham-gh" target="_blank" rel="noopener" title="Tiger Data"&gt; &lt;img src="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/sponsors/tigerdata.png" alt="Tiger Data" width="500" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://tsdb.co/shubham-gh" target="_blank" rel="noopener" style="text-decoration: none; color: #333; font-weight: bold; font-size: 18px;"&gt; Tiger Data MCP &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://github.com/speechmatics/speechmatics-academy" target="_blank" rel="noopener" title="Speechmatics"&gt; &lt;img src="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/sponsors/speechmatics.png" alt="Speechmatics" width="500" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/speechmatics/speechmatics-academy" target="_blank" rel="noopener" style="text-decoration: none; color: #333; font-weight: bold; font-size: 18px;"&gt; Speechmatics &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt; &lt;a href="https://okara.ai/?utm_source=oss&amp;amp;utm_medium=sponsorship&amp;amp;utm_campaign=awesome-llm-apps" title="Okara"&gt; &lt;img src="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/sponsors/okara.png" alt="Okara" width="500" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://okara.ai/?utm_source=oss&amp;amp;utm_medium=sponsorship&amp;amp;utm_campaign=awesome-llm-apps" style="text-decoration: none; color: #333; font-weight: bold; font-size: 18px;"&gt; Okara AI &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center"&gt; &lt;a href="https://sponsorunwindai.com/" title="Become a Sponsor"&gt; &lt;img src="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/docs/banner/sponsor_awesome_llm_apps.png" alt="Become a Sponsor" width="500" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://sponsorunwindai.com/" style="text-decoration: none; color: #333; font-weight: bold; font-size: 18px;"&gt; Become a Sponsor &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;üìÇ Featured AI Projects&lt;/h2&gt; 
&lt;h3&gt;AI Agents&lt;/h3&gt; 
&lt;h3&gt;üå± Starter AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_blog_to_podcast_agent/"&gt;üéôÔ∏è AI Blog to Podcast Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_breakup_recovery_agent/"&gt;‚ù§Ô∏è‚Äçü©π AI Breakup Recovery Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_data_analysis_agent/"&gt;üìä AI Data Analysis Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_medical_imaging_agent/"&gt;ü©ª AI Medical Imaging Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_meme_generator_agent_browseruse/"&gt;üòÇ AI Meme Generator Agent (Browser)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_music_generator_agent/"&gt;üéµ AI Music Generator Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/ai_travel_agent/"&gt;üõ´ AI Travel Agent (Local &amp;amp; Cloud)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/gemini_multimodal_agent_demo/"&gt;‚ú® Gemini Multimodal Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/mixture_of_agents/"&gt;üîÑ Mixture of Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/xai_finance_agent/"&gt;üìä xAI Finance Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/opeani_research_agent/"&gt;üîç OpenAI Research Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/starter_ai_agents/web_scrapping_ai_agent/"&gt;üï∏Ô∏è Web Scraping AI Agent (Local &amp;amp; Cloud SDK)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üöÄ Advanced AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_home_renovation_agent"&gt;üèöÔ∏è üçå AI Home Renovation Agent with Nano Banana Pro&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_deep_research_agent/"&gt;üîç AI Deep Research Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_vc_due_diligence_agent_team"&gt;üìä AI VC Due Diligence Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/research_agent_gemini_interaction_api"&gt;üî¨ AI Research Planner &amp;amp; Executor (Google Interactions API)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_consultant_agent"&gt;ü§ù AI Consultant Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_system_architect_r1/"&gt;üèóÔ∏è AI System Architect Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/"&gt;üí∞ AI Financial Coach Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_movie_production_agent/"&gt;üé¨ AI Movie Production Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_investment_agent/"&gt;üìà AI Investment Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/"&gt;üèãÔ∏è‚Äç‚ôÇÔ∏è AI Health &amp;amp; Fitness Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent"&gt;üöÄ AI Product Launch Intelligence Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_journalist_agent/"&gt;üóûÔ∏è AI Journalist Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/"&gt;üß† AI Mental Wellbeing Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/single_agent_apps/ai_meeting_agent/"&gt;üìë AI Meeting Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/"&gt;üß¨ AI Self-Evolving Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_sales_intelligence_agent_team"&gt;üë®üèª‚Äçüíº AI Sales Intelligence Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/"&gt;üéß AI Social Media News and Podcast Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/accomplish-ai/openwork"&gt;üåê Openwork - Open Browser Automation Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üéÆ Autonomous Game Playing Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/"&gt;üéÆ AI 3D Pygame Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/"&gt;‚ôú AI Chess Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/"&gt;üé≤ AI Tic-Tac-Toe Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ü§ù Multi-agent Teams&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/"&gt;üß≤ AI Competitor Intelligence Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/"&gt;üí≤ AI Finance Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/"&gt;üé® AI Game Design Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/"&gt;üë®‚Äç‚öñÔ∏è AI Legal Agent Team (Cloud &amp;amp; Local)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/"&gt;üíº AI Recruitment Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team"&gt;üè† AI Real Estate Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/"&gt;üë®‚Äçüíº AI Services Agency (CrewAI)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/"&gt;üë®‚Äçüè´ AI Teaching Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/"&gt;üíª Multimodal Coding Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/"&gt;‚ú® Multimodal Design Agent Team&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_uiux_feedback_agent_team/"&gt;üé® üçå Multimodal UI/UX Feedback Agent Team with Nano Banana&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/"&gt;üåè AI Travel Planner Agent Team&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üó£Ô∏è Voice AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/ai_audio_tour_agent/"&gt;üó£Ô∏è AI Audio Tour Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/customer_support_voice_agent/"&gt;üìû Customer Support Voice Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/voice_ai_agents/voice_rag_openaisdk/"&gt;üîä Voice RAG Agent (OpenAI SDK)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/akshayaggarwal99/jarvis-ai-assistant"&gt;üéôÔ∏è OpenSource Voice Dictation Agent (like Wispr Flow&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;img src="https://cdn.simpleicons.org/modelcontextprotocol" alt="mcp logo" width="25" height="20" /&gt; MCP AI Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/browser_mcp_agent/"&gt;‚ôæÔ∏è Browser MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/github_mcp_agent/"&gt;üêô GitHub MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/notion_mcp_agent"&gt;üìë Notion MCP Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/mcp_ai_agents/ai_travel_planner_mcp_agent_team"&gt;üåç AI Travel Planner MCP Agent&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìÄ RAG (Retrieval Augmented Generation)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/agentic_rag_embedding_gemma"&gt;üî• Agentic RAG with Embedding Gemma&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/agentic_rag_with_reasoning/"&gt;üßê Agentic RAG with Reasoning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/ai_blog_search/"&gt;üì∞ AI Blog Search (RAG)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/autonomous_rag/"&gt;üîç Autonomous RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/contextualai_rag_agent/"&gt;üîÑ Contextual AI RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/corrective_rag/"&gt;üîÑ Corrective RAG (CRAG)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/deepseek_local_rag_agent/"&gt;üêã Deepseek Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/gemini_agentic_rag/"&gt;ü§î Gemini Agentic RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/hybrid_search_rag/"&gt;üëÄ Hybrid Search RAG (Cloud)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/llama3.1_local_rag/"&gt;üîÑ Llama 3.1 Local RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/local_hybrid_search_rag/"&gt;üñ•Ô∏è Local Hybrid Search RAG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/local_rag_agent/"&gt;ü¶ô Local RAG Agent&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag-as-a-service/"&gt;üß© RAG-as-a-Service&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_agent_cohere/"&gt;‚ú® RAG Agent with Cohere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_chain/"&gt;‚õìÔ∏è Basic RAG Chain&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/rag_database_routing/"&gt;üì† RAG with Database Routing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/rag_tutorials/vision_rag/"&gt;üñºÔ∏è Vision RAG&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üíæ LLM Apps with Memory Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/"&gt;üíæ AI ArXiv Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/"&gt;üõ©Ô∏è AI Travel Agent with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/"&gt;üí¨ Llama3 Stateful Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/"&gt;üìù LLM App with Personalized Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/"&gt;üóÑÔ∏è Local ChatGPT Clone with Memory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/"&gt;üß† Multi-LLM Application with Shared Memory&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üí¨ Chat with X Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_github/"&gt;üí¨ Chat with GitHub (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/"&gt;üì® Chat with Gmail&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/"&gt;üìÑ Chat with PDF (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/"&gt;üìö Chat with Research Papers (ArXiv) (GPT &amp;amp; Llama3)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/"&gt;üìù Chat with Substack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/"&gt;üìΩÔ∏è Chat with YouTube Videos&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üéØ LLM Optimization Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_optimization_tools/toonify_token_optimization/"&gt;üéØ Toonify Token Optimization&lt;/a&gt; - Reduce LLM API costs by 30-60% using TOON format&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîß LLM Fine-tuning Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;img src="https://cdn.simpleicons.org/google" alt="google logo" width="20" height="15" /&gt; &lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_finetuning_tutorials/gemma3_finetuning/"&gt;Gemma 3 Fine-tuning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;img src="https://cdn.simpleicons.org/meta" alt="meta logo" width="25" height="15" /&gt; &lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/"&gt;Llama 3.2 Fine-tuning&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üßë‚Äçüè´ AI Agent Framework Crash Course&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://cdn.simpleicons.org/google" alt="google logo" width="25" height="15" /&gt; &lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/ai_agent_framework_crash_course/google_adk_crash_course/"&gt;Google ADK Crash Course&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Starter agent; model‚Äëagnostic (OpenAI, Claude)&lt;/li&gt; 
 &lt;li&gt;Structured outputs (Pydantic)&lt;/li&gt; 
 &lt;li&gt;Tools: built‚Äëin, function, third‚Äëparty, MCP tools&lt;/li&gt; 
 &lt;li&gt;Memory; callbacks; Plugins&lt;/li&gt; 
 &lt;li&gt;Simple multi‚Äëagent; Multi‚Äëagent patterns&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://cdn.simpleicons.org/openai" alt="openai logo" width="25" height="15" /&gt; &lt;a href="https://raw.githubusercontent.com/Shubhamsaboo/awesome-llm-apps/main/ai_agent_framework_crash_course/openai_sdk_crash_course/"&gt;OpenAI Agents SDK Crash Course&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Starter agent; function calling; structured outputs&lt;/li&gt; 
 &lt;li&gt;Tools: built‚Äëin, function, third‚Äëparty integrations&lt;/li&gt; 
 &lt;li&gt;Memory; callbacks; evaluation&lt;/li&gt; 
 &lt;li&gt;Multi‚Äëagent patterns; agent handoffs&lt;/li&gt; 
 &lt;li&gt;Swarm orchestration; routing logic&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Navigate to the desired project directory&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cd awesome-llm-apps/starter_ai_agents/ai_travel_agent
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install the required dependencies&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Follow the project-specific instructions&lt;/strong&gt; in each project's &lt;code&gt;README.md&lt;/code&gt; file to set up and run the app.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;img src="https://cdn.simpleicons.org/github" alt="github logo" width="25" height="20" /&gt; Thank You, Community, for the Support! üôè&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;üåü &lt;strong&gt;Don‚Äôt miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jamwithai/arxiv-paper-curator</title>
      <link>https://github.com/jamwithai/arxiv-paper-curator</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Mother of AI Project&lt;/h1&gt; 
&lt;h2&gt;Phase 1 RAG Systems: arXiv Paper Curator&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;A Learner-Focused Journey into Production RAG Systems&lt;/h3&gt; 
 &lt;p&gt;Learn to build modern AI systems from the ground up through hands-on implementation&lt;/p&gt; 
 &lt;p&gt;Master the most in-demand AI engineering skills: &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;img src="https://img.shields.io/badge/Python-3.12+-blue.svg?sanitize=true" alt="Python Version" /&gt; &lt;img src="https://img.shields.io/badge/FastAPI-0.115+-green.svg?sanitize=true" alt="FastAPI" /&gt; &lt;img src="https://img.shields.io/badge/OpenSearch-2.19-orange.svg?sanitize=true" alt="OpenSearch" /&gt; &lt;img src="https://img.shields.io/badge/Docker-Compose-blue.svg?sanitize=true" alt="Docker" /&gt; &lt;img src="https://img.shields.io/badge/Status-Week%207%20Advanced%20Features-brightgreen.svg?sanitize=true" alt="Status" /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/#-about-this-course"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/mother_of_ai_project_rag_architecture.gif" alt="RAG Architecture" width="700" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üìñ About This Course&lt;/h2&gt; 
&lt;p&gt;This is a &lt;strong&gt;learner-focused project&lt;/strong&gt; where you'll build a complete research assistant system that automatically fetches academic papers, understands their content, and answers your research questions using advanced RAG techniques.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The arXiv Paper Curator&lt;/strong&gt; will teach you to build a &lt;strong&gt;production-grade RAG system using industry best practices&lt;/strong&gt;. Unlike tutorials that jump straight to vector search, we follow the &lt;strong&gt;professional path&lt;/strong&gt;: master keyword search foundations first, then enhance with vectors for hybrid retrieval.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üéØ The Professional Difference:&lt;/strong&gt; We build RAG systems the way successful companies do - solid search foundations enhanced with AI, not AI-first approaches that ignore search fundamentals.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;By the end of this course, you'll have your own AI research assistant and the deep technical skills to build production RAG systems for any domain.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéì What You'll Build&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Week 1:&lt;/strong&gt; Complete infrastructure with Docker, FastAPI, PostgreSQL, OpenSearch, and Airflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 2:&lt;/strong&gt; Automated data pipeline fetching and parsing academic papers from arXiv&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 3:&lt;/strong&gt; Production BM25 keyword search with filtering and relevance scoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 4:&lt;/strong&gt; Intelligent chunking + hybrid search combining keywords with semantic understanding&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 5:&lt;/strong&gt; Complete RAG pipeline with local LLM, streaming responses, and Gradio interface&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 6:&lt;/strong&gt; Production monitoring with Langfuse tracing and Redis caching for optimized performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Week 7:&lt;/strong&gt; &lt;strong&gt;Agentic RAG with LangGraph and Telegram Bot for mobile access&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è System Architecture Evolution&lt;/h2&gt; 
&lt;h3&gt;Week 7: Agentic RAG &amp;amp; Telegram Bot Integration&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week7_telegram_and_agentic_ai.png" alt="Week 7 Telegram and Agentic AI Architecture" width="800" /&gt; 
 &lt;p&gt;&lt;em&gt;Complete Week 7 architecture showing Telegram bot integration with the agentic RAG system&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;LangGraph Agentic RAG Workflow&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/langgraph-mermaid.png" alt="LangGraph Agentic RAG Flow" width="800" /&gt; 
 &lt;p&gt;&lt;em&gt;Detailed LangGraph workflow showing decision nodes, document grading, and adaptive retrieval&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Week 7 Code walkthrough + blog:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/agentic-rag-with-langgraph-and-telegram"&gt;Agentic RAG with LangGraph and Telegram&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Innovations in Week 7:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Decision-Making&lt;/strong&gt;: Agents evaluate and adapt retrieval strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document Grading&lt;/strong&gt;: Automatic relevance assessment with semantic evaluation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Query Rewriting&lt;/strong&gt;: Adaptive query refinement when results are insufficient&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Guardrails&lt;/strong&gt;: Out-of-domain detection prevents hallucination&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mobile Access&lt;/strong&gt;: Telegram bot for conversational AI on any device&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Transparency&lt;/strong&gt;: Full reasoning step tracking for debugging and trust&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;üìã Prerequisites&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Desktop&lt;/strong&gt; (with Docker Compose)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.12+&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UV Package Manager&lt;/strong&gt; (&lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;Install Guide&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;8GB+ RAM&lt;/strong&gt; and &lt;strong&gt;20GB+ free disk space&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;‚ö° Get Started&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Clone and setup
git clone &amp;lt;repository-url&amp;gt;
cd arxiv-paper-curator

# 2. Configure environment (IMPORTANT!)
cp .env.example .env
# The .env file contains all necessary configuration for OpenSearch, 
# arXiv API, and service connections. Defaults work out of the box.
# You need to add Jina embeddings free api key and langfuse keys (check the blogs)

# 3. Install dependencies
uv sync

# 4. Start all services
docker compose up --build -d

# 5. Verify everything works
curl http://localhost:8000/health
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üìö Weekly Learning Path&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Week&lt;/th&gt; 
   &lt;th&gt;Topic&lt;/th&gt; 
   &lt;th&gt;Blog Post&lt;/th&gt; 
   &lt;th&gt;Code Release&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 0&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;The Mother of AI project - 6 phases&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-mother-of-ai-project"&gt;The Mother of AI project&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 1&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Infrastructure Foundation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-infrastructure-that-powers-rag"&gt;The Infrastructure That Powers RAG Systems&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week1.0"&gt;week1.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Data Ingestion Pipeline&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/bringing-your-rag-system-to-life"&gt;Building Data Ingestion Pipelines for RAG&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week2.0"&gt;week2.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 3&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenSearch ingestion &amp;amp; BM25 retrieval&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-search-foundation-every-rag-system"&gt;The Search Foundation Every RAG System Needs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week3.0"&gt;week3.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 4&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Chunking &amp;amp; Hybrid Search&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/chunking-strategies-and-hybrid-rag"&gt;The Chunking Strategy That Makes Hybrid Search Work&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week4.0"&gt;week4.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 5&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Complete RAG system&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/the-complete-rag-system"&gt;The Complete RAG System&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week5.0"&gt;week5.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 6&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Production monitoring &amp;amp; caching&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/production-ready-rag-monitoring-and"&gt;Production-ready RAG: Monitoring &amp;amp; Caching&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week6.0"&gt;week6.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Week 7&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Agentic RAG &amp;amp; Telegram Bot&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://jamwithai.substack.com/p/agentic-rag-with-langgraph-and-telegram"&gt;Agentic RAG with LangGraph and Telegram&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jamwithai/arxiv-paper-curator/releases/tag/week7.0"&gt;week7.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;üì• Clone a specific week's release:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone a specific week's code
git clone --branch &amp;lt;WEEK_TAG&amp;gt; https://github.com/jamwithai/arxiv-paper-curator
cd arxiv-paper-curator
uv sync
docker compose down -v
docker compose up --build -d

# Replace &amp;lt;WEEK_TAG&amp;gt; with: week1.0, week2.0, etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üìä Access Your Services&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;URL&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Documentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:8000/docs"&gt;http://localhost:8000/docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Interactive API testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Gradio RAG Interface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:7861"&gt;http://localhost:7861&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;User-friendly chat interface&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Langfuse Dashboard&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;RAG pipeline monitoring &amp;amp; tracing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Airflow Dashboard&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Workflow management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OpenSearch Dashboards&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://localhost:5601"&gt;http://localhost:5601&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Hybrid search engine UI&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Check airflow/simple_auth_manager_passwords.json.generated for Airflow username and password&lt;/h4&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 1: Infrastructure Foundation ‚úÖ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Start here!&lt;/strong&gt; Master the infrastructure that powers modern RAG systems.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Complete infrastructure setup with Docker Compose&lt;/li&gt; 
 &lt;li&gt;FastAPI development with automatic documentation and health checks&lt;/li&gt; 
 &lt;li&gt;PostgreSQL database configuration and management&lt;/li&gt; 
 &lt;li&gt;OpenSearch hybrid search engine setup&lt;/li&gt; 
 &lt;li&gt;Ollama local LLM service configuration&lt;/li&gt; 
 &lt;li&gt;Service orchestration and health monitoring&lt;/li&gt; 
 &lt;li&gt;Professional development environment with code quality tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week1_infra_setup.png" alt="Week 1 Infrastructure Setup" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;FastAPI&lt;/strong&gt;: REST endpoints with async support (Port 8000)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL 16&lt;/strong&gt;: Paper metadata storage (Port 5432)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenSearch 2.19&lt;/strong&gt;: Search engine with dashboards (Ports 9200, 5601)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Apache Airflow 3.0&lt;/strong&gt;: Workflow orchestration (Port 8080)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ollama&lt;/strong&gt;: Local LLM server (Port 11434)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 1 notebook
uv run jupyter notebook notebooks/week1/week1_setup.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week1/week1_setup.ipynb"&gt;Week 1 notebook&lt;/a&gt; for hands-on setup and verification steps.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/the-infrastructure-that-powers-rag"&gt;The Infrastructure That Powers RAG Systems&lt;/a&gt; - Detailed walkthrough and production insights&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 2: Data Ingestion Pipeline ‚úÖ&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 1 infrastructure:&lt;/strong&gt; Learn to fetch, process, and store academic papers automatically.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;arXiv API integration with rate limiting and retry logic&lt;/li&gt; 
 &lt;li&gt;Scientific PDF parsing using Docling&lt;/li&gt; 
 &lt;li&gt;Automated data ingestion pipelines with Apache Airflow&lt;/li&gt; 
 &lt;li&gt;Metadata extraction and storage workflows&lt;/li&gt; 
 &lt;li&gt;Complete paper processing from API to database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week2_data_ingestion_flow.png" alt="Week 2 Data Ingestion Architecture" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Data Pipeline Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MetadataFetcher&lt;/strong&gt;: üéØ Main orchestrator coordinating the entire pipeline&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ArxivClient&lt;/strong&gt;: Rate-limited paper fetching with retry logic&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PDFParserService&lt;/strong&gt;: Docling-powered scientific document processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Airflow DAGs&lt;/strong&gt;: Automated daily paper ingestion workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL Storage&lt;/strong&gt;: Structured paper metadata and content&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Implementation Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 2 notebook  
uv run jupyter notebook notebooks/week2/week2_arxiv_integration.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week2/week2_arxiv_integration.ipynb"&gt;Week 2 notebook&lt;/a&gt; for hands-on implementation and verification steps.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/bringing-your-rag-system-to-life"&gt;Building Data Ingestion Pipelines for RAG&lt;/a&gt; - arXiv API integration and PDF processing&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 3: Keyword Search First - The Critical Foundation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Weeks 1-2 foundation:&lt;/strong&gt; Implement the keyword search foundation that professional RAG systems rely on.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Why keyword search is essential for RAG systems (foundation first approach)&lt;/li&gt; 
 &lt;li&gt;OpenSearch index management, mappings, and search optimization&lt;/li&gt; 
 &lt;li&gt;BM25 algorithm and the math behind effective keyword search&lt;/li&gt; 
 &lt;li&gt;Query DSL for building complex search queries with filters and boosting&lt;/li&gt; 
 &lt;li&gt;Search analytics for measuring relevance and performance&lt;/li&gt; 
 &lt;li&gt;Production patterns used by real companies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week3_opensearch_flow.png" alt="Week 3 OpenSearch Flow Architecture" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Search Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenSearch Service&lt;/strong&gt;: &lt;code&gt;src/services/opensearch/&lt;/code&gt; - Professional search service implementation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search API&lt;/strong&gt;: &lt;code&gt;src/routers/search.py&lt;/code&gt; - Search API endpoints with BM25 scoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Learning Materials&lt;/strong&gt;: &lt;code&gt;notebooks/week3/&lt;/code&gt; - Complete OpenSearch integration guide&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality Metrics&lt;/strong&gt;: Precision, recall, and relevance scoring&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 3 notebook
uv run jupyter notebook notebooks/week3/week3_opensearch.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week3/week3_opensearch.ipynb"&gt;Week 3 notebook&lt;/a&gt; for hands-on OpenSearch setup and BM25 search implementation.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/the-search-foundation-every-rag-system"&gt;The Search Foundation Every RAG System Needs&lt;/a&gt; - Complete BM25 implementation with OpenSearch&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 4: Chunking &amp;amp; Hybrid Search - The Semantic Layer&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 3 foundation:&lt;/strong&gt; Add the semantic layer that makes search truly intelligent.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Section-based chunking with intelligent document segmentation&lt;/li&gt; 
 &lt;li&gt;Production embeddings with Jina AI integration and fallback strategies&lt;/li&gt; 
 &lt;li&gt;Hybrid search mastery using RRF fusion for keyword + semantic retrieval&lt;/li&gt; 
 &lt;li&gt;Unified API design with single endpoint supporting multiple search modes&lt;/li&gt; 
 &lt;li&gt;Performance analysis and trade-offs between search approaches&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week4_hybrid_opensearch.png" alt="Week 4 Hybrid Search Architecture" width="800" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Hybrid Search Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text Chunker&lt;/strong&gt;: &lt;code&gt;src/services/indexing/text_chunker.py&lt;/code&gt; - Section-aware chunking with overlap strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Embeddings Service&lt;/strong&gt;: &lt;code&gt;src/services/embeddings/&lt;/code&gt; - Production embedding pipeline with Jina AI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hybrid Search API&lt;/strong&gt;: &lt;code&gt;src/routers/hybrid_search.py&lt;/code&gt; - Unified search API supporting all modes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Learning Materials&lt;/strong&gt;: &lt;code&gt;notebooks/week4/&lt;/code&gt; - Complete hybrid search implementation guide&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 4 notebook
uv run jupyter notebook notebooks/week4/week4_hybrid_search.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week4/week4_hybrid_search.ipynb"&gt;Week 4 notebook&lt;/a&gt; for hands-on implementation and verification steps.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/chunking-strategies-and-hybrid-rag"&gt;The Chunking Strategy That Makes Hybrid Search Work&lt;/a&gt; - Production chunking and RRF fusion implementation&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 5: Complete RAG Pipeline with LLM Integration&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 4 hybrid search:&lt;/strong&gt; Add the LLM layer that turns search into intelligent conversation.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Local LLM integration with Ollama for complete data privacy&lt;/li&gt; 
 &lt;li&gt;Performance optimization with 80% prompt reduction (6x speed improvement)&lt;/li&gt; 
 &lt;li&gt;Streaming implementation using Server-Sent Events for real-time responses&lt;/li&gt; 
 &lt;li&gt;Dual API design with standard and streaming endpoints&lt;/li&gt; 
 &lt;li&gt;Interactive Gradio interface with advanced parameter controls&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week5_complete_rag.png" alt="Week 5 Complete RAG System Architecture" width="900" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Complete RAG Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;RAG Endpoints&lt;/strong&gt;: &lt;code&gt;src/routers/ask.py&lt;/code&gt; - Dual endpoints (&lt;code&gt;/api/v1/ask&lt;/code&gt; + &lt;code&gt;/api/v1/stream&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ollama Service&lt;/strong&gt;: &lt;code&gt;src/services/ollama/&lt;/code&gt; - LLM client with optimized prompts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;System Prompt&lt;/strong&gt;: &lt;code&gt;src/services/ollama/prompts/rag_system.txt&lt;/code&gt; - Optimized for academic papers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gradio Interface&lt;/strong&gt;: &lt;code&gt;src/gradio_app.py&lt;/code&gt; - Interactive web UI with streaming support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Launcher Script&lt;/strong&gt;: &lt;code&gt;gradio_launcher.py&lt;/code&gt; - Easy-launch script (runs on port 7861)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 5 notebook
uv run jupyter notebook notebooks/week5/week5_complete_rag_system.ipynb

# Launch Gradio interface
uv run python gradio_launcher.py
# Open http://localhost:7861
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week5/week5_complete_rag_system.ipynb"&gt;Week 5 notebook&lt;/a&gt; for hands-on LLM integration and RAG pipeline implementation.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/the-complete-rag-system"&gt;The Complete RAG System&lt;/a&gt; - Complete RAG system with local LLM integration and optimization techniques&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 6: Production Monitoring and Caching&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 5 complete RAG system:&lt;/strong&gt; Add observability, performance optimization, and production-grade monitoring.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Langfuse integration for end-to-end RAG pipeline tracing&lt;/li&gt; 
 &lt;li&gt;Redis caching strategy with intelligent cache keys and TTL management&lt;/li&gt; 
 &lt;li&gt;Performance monitoring with real-time dashboards for latency and costs&lt;/li&gt; 
 &lt;li&gt;Production patterns for observability and optimization&lt;/li&gt; 
 &lt;li&gt;Cost analysis and LLM usage optimization (150-400x speedup with caching)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week6_monitoring_and_caching.png" alt="Week 6 Monitoring &amp;amp; Caching Architecture" width="900" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Production Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Langfuse Service&lt;/strong&gt;: &lt;code&gt;src/services/langfuse/&lt;/code&gt; - Complete tracing integration with RAG-specific metrics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cache Service&lt;/strong&gt;: &lt;code&gt;src/services/cache/&lt;/code&gt; - Redis client with exact-match caching and graceful fallback&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Updated Endpoints&lt;/strong&gt;: &lt;code&gt;src/routers/ask.py&lt;/code&gt; - Integrated tracing and caching middleware&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Config&lt;/strong&gt;: &lt;code&gt;docker-compose.yml&lt;/code&gt; - Added Redis service and Langfuse local instance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Learning Materials&lt;/strong&gt;: &lt;code&gt;notebooks/week6/&lt;/code&gt; - Complete monitoring and caching implementation guide&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 6 notebook
uv run jupyter notebook notebooks/week6/week6_cache_testing.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week6/week6_cache_testing.ipynb"&gt;Week 6 notebook&lt;/a&gt; for hands-on Langfuse tracing and Redis caching implementation.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/production-ready-rag-monitoring-and"&gt;Production-ready RAG: Monitoring &amp;amp; Caching&lt;/a&gt; - Production-ready RAG with monitoring and caching&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Week 7: Agentic RAG with LangGraph and Telegram Bot&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Building on Week 6 production system:&lt;/strong&gt; Add intelligent reasoning, multi-step decision-making, and Telegram bot integration for mobile-first AI interactions.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üéØ Learning Objectives&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;LangGraph workflows for state-based agent orchestration with decision nodes&lt;/li&gt; 
 &lt;li&gt;Guardrail implementation for query validation and domain boundary detection&lt;/li&gt; 
 &lt;li&gt;Document grading with semantic relevance evaluation&lt;/li&gt; 
 &lt;li&gt;Query rewriting for automatic query refinement and better retrieval&lt;/li&gt; 
 &lt;li&gt;Adaptive retrieval with multi-attempt retrieval and intelligent fallback&lt;/li&gt; 
 &lt;li&gt;Telegram bot integration with async operations and error handling&lt;/li&gt; 
 &lt;li&gt;Reasoning transparency by exposing agent decision-making process&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Architecture Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/static/week7_telegram_and_agentic_ai.png" alt="Week 7 Agentic RAG &amp;amp; Telegram Architecture" width="900" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agentic RAG Infrastructure Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Agent Nodes&lt;/strong&gt;: &lt;code&gt;src/services/agents/nodes/&lt;/code&gt; - Guardrail, retrieve, grade, rewrite, and generate nodes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workflow Orchestration&lt;/strong&gt;: &lt;code&gt;src/services/agents/agentic_rag.py&lt;/code&gt; - LangGraph workflow coordination&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Telegram Bot&lt;/strong&gt;: &lt;code&gt;src/services/telegram/&lt;/code&gt; - Command handlers and message processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agentic Endpoint&lt;/strong&gt;: &lt;code&gt;src/routers/agentic_ask.py&lt;/code&gt; - Agentic RAG API endpoint&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Learning Materials&lt;/strong&gt;: &lt;code&gt;notebooks/week7/&lt;/code&gt; - Week 7 learning materials and examples&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;strong&gt;üìì Setup Guide&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Week 7 notebook
uv run jupyter notebook notebooks/week7/week7_agentic_rag.ipynb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Completion Guide:&lt;/strong&gt; Follow the &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/notebooks/week7/week7_agentic_rag.ipynb"&gt;Week 7 notebook&lt;/a&gt; for hands-on LangGraph agentic RAG and Telegram bot implementation.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üìñ Deep Dive&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Blog Post:&lt;/strong&gt; &lt;a href="https://jamwithai.substack.com/p/agentic-rag-with-langgraph-and-telegram"&gt;Agentic RAG with LangGraph and Telegram&lt;/a&gt; - Building intelligent agents with decision-making, adaptive retrieval, and mobile access&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚öôÔ∏è Configuration&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Setup:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env
# Edit .env for your environment
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Key Variables:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;JINA_API_KEY&lt;/code&gt; - Required for Week 4+ (hybrid search with embeddings)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;TELEGRAM__BOT_TOKEN&lt;/code&gt; - Required for Week 7 (Telegram bot integration)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;LANGFUSE__PUBLIC_KEY&lt;/code&gt; &amp;amp; &lt;code&gt;LANGFUSE__SECRET_KEY&lt;/code&gt; - Optional for Week 6 (monitoring)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Complete Configuration:&lt;/strong&gt; See &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/.env.example"&gt;.env.example&lt;/a&gt; for all available options and detailed documentation.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîß Reference &amp;amp; Development Guide&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;üõ†Ô∏è Technology Stack&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;FastAPI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;REST API with automatic docs&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PostgreSQL 16&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper metadata and content storage&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OpenSearch 2.19&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Hybrid search engine (BM25 + Vector)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apache Airflow 3.0&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Workflow automation&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Jina AI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Embedding generation (Week 4)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ollama&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Local LLM serving (Week 5)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;High-performance caching (Week 6)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Langfuse&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;RAG pipeline observability (Week 6)&lt;/td&gt; 
   &lt;td&gt;‚úÖ Ready&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Development Tools:&lt;/strong&gt; UV, Ruff, MyPy, Pytest, Docker Compose&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üèóÔ∏è Project Structure&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;arxiv-paper-curator/
‚îú‚îÄ‚îÄ src/                    # Main application code
‚îÇ   ‚îú‚îÄ‚îÄ routers/            # API endpoints (search, ask, papers)
‚îÇ   ‚îú‚îÄ‚îÄ services/           # Business logic (opensearch, ollama, agents, cache)
‚îÇ   ‚îú‚îÄ‚îÄ models/             # Database models (SQLAlchemy)
‚îÇ   ‚îú‚îÄ‚îÄ schemas/            # Pydantic validation schemas
‚îÇ   ‚îî‚îÄ‚îÄ config.py           # Environment configuration
‚îú‚îÄ‚îÄ notebooks/              # Weekly learning materials (week1-7)
‚îú‚îÄ‚îÄ airflow/                # Workflow orchestration (DAGs)
‚îú‚îÄ‚îÄ tests/                  # Test suite
‚îî‚îÄ‚îÄ compose.yml             # Docker service orchestration
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üì° API Endpoints Reference&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Endpoint&lt;/th&gt; 
   &lt;th&gt;Method&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Week&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/health&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Service health check&lt;/td&gt; 
   &lt;td&gt;Week 1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/papers&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;List stored papers&lt;/td&gt; 
   &lt;td&gt;Week 2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/papers/{id}&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Get specific paper&lt;/td&gt; 
   &lt;td&gt;Week 2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/search&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;BM25 keyword search&lt;/td&gt; 
   &lt;td&gt;Week 3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;/api/v1/hybrid-search/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;Hybrid search (BM25 + Vector)&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Week 4&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;API Documentation:&lt;/strong&gt; Visit &lt;a href="http://localhost:8000/docs"&gt;http://localhost:8000/docs&lt;/a&gt; for interactive API explorer&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;üîß Essential Commands&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;strong&gt;Using the Makefile&lt;/strong&gt; (Recommended)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# View all available commands
make help

# Quick workflow
make start         # Start all services
make health        # Check all services health
make test          # Run tests
make stop          # Stop services
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;All Available Commands&lt;/strong&gt;&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Command&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make start&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Start all services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make stop&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Stop all services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make restart&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Restart all services&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make status&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show service status&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make logs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Show service logs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make health&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Check all services health&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make setup&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Install Python dependencies&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make format&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Format code&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make lint&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Lint and type check&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make test&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Run tests&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make test-cov&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Run tests with coverage&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;make clean&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Clean up everything&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;&lt;strong&gt;Direct Commands&lt;/strong&gt; (Alternative)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If you prefer using commands directly
docker compose up --build -d    # Start services
docker compose ps               # Check status
docker compose logs            # View logs
uv run pytest                 # Run tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;üéì Target Audience&lt;/strong&gt;&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Who&lt;/th&gt; 
   &lt;th&gt;Why&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI/ML Engineers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Learn production RAG architecture beyond tutorials&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Software Engineers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Build end-to-end AI applications with best practices&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Data Scientists&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Implement production AI systems using modern tools&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üõ†Ô∏è Troubleshooting&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Common Issues:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Services not starting?&lt;/strong&gt; Wait 2-3 minutes, check &lt;code&gt;docker compose logs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Port conflicts?&lt;/strong&gt; Stop other services using ports 8000, 8080, 5432, 9200&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory issues?&lt;/strong&gt; Increase Docker Desktop memory allocation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Get Help:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check the comprehensive Week 1 notebook troubleshooting section&lt;/li&gt; 
 &lt;li&gt;Review service logs: &lt;code&gt;docker compose logs [service-name]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Complete reset: &lt;code&gt;docker compose down --volumes &amp;amp;&amp;amp; docker compose up --build -d&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí∞ Cost Structure&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;This course is completely free!&lt;/strong&gt; You'll only need minimal costs for optional services:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local Development:&lt;/strong&gt; $0 (everything runs locally)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optional Cloud APIs:&lt;/strong&gt; ~$2-5 for external LLM services (if chosen)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;üéâ Ready to Start Your AI Engineering Journey?&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;Begin with the Week 1 setup notebook and build your first production RAG system!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;For learners who want to master modern AI engineering&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Built with love by Jam With AI&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;MIT License - see &lt;a href="https://raw.githubusercontent.com/jamwithai/arxiv-paper-curator/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>donnemartin/system-design-primer</title>
      <link>https://github.com/donnemartin/system-design-primer</link>
      <description>&lt;p&gt;Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;em&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README.md"&gt;English&lt;/a&gt; ‚àô &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; ‚àô &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-Hans.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; ‚àô &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-TW.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/170"&gt;ÿßŸÑÿπŸéÿ±Ÿéÿ®ŸêŸäŸéŸëÿ©‚Äé&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/220"&gt;‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/40"&gt;Portugu√™s do Brasil&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/186"&gt;Deutsch&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/130"&gt;ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/272"&gt;◊¢◊ë◊®◊ô◊™&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/104"&gt;Italiano&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/102"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/110"&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/68"&gt;Polski&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/87"&gt;—Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/136"&gt;Espa√±ol&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/187"&gt;‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/39"&gt;T√ºrk√ße&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/127"&gt;ti·∫øng Vi·ªát&lt;/a&gt; ‚àô &lt;a href="https://github.com/donnemartin/system-design-primer/issues/250"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Add Translation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Help &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/TRANSLATIONS.md"&gt;translate&lt;/a&gt; this guide!&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;The System Design Primer&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn how to design large-scale systems.&lt;/p&gt; 
 &lt;p&gt;Prep for the system design interview.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Learn how to design large-scale systems&lt;/h3&gt; 
&lt;p&gt;Learning how to design scalable systems will help you become a better engineer.&lt;/p&gt; 
&lt;p&gt;System design is a broad topic. There is a &lt;strong&gt;vast amount of resources scattered throughout the web&lt;/strong&gt; on system design principles.&lt;/p&gt; 
&lt;p&gt;This repo is an &lt;strong&gt;organized collection&lt;/strong&gt; of resources to help you learn how to build systems at scale.&lt;/p&gt; 
&lt;h3&gt;Learn from the open source community&lt;/h3&gt; 
&lt;p&gt;This is a continually updated, open source project.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contributions&lt;/a&gt; are welcome!&lt;/p&gt; 
&lt;h3&gt;Prep for the system design interview&lt;/h3&gt; 
&lt;p&gt;In addition to coding interviews, system design is a &lt;strong&gt;required component&lt;/strong&gt; of the &lt;strong&gt;technical interview process&lt;/strong&gt; at many tech companies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Practice common system design interview questions&lt;/strong&gt; and &lt;strong&gt;compare&lt;/strong&gt; your results with &lt;strong&gt;sample solutions&lt;/strong&gt;: discussions, code, and diagrams.&lt;/p&gt; 
&lt;p&gt;Additional topics for interview prep:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#study-guide"&gt;Study guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Anki flashcards&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/zdCAkB3.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;The provided &lt;a href="https://apps.ankiweb.net/"&gt;Anki flashcard decks&lt;/a&gt; use spaced repetition to help you retain key system design concepts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg"&gt;System design deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg"&gt;System design exercises deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg"&gt;Object oriented design exercises deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Great for use while on-the-go.&lt;/p&gt; 
&lt;h3&gt;Coding Resource: Interactive Coding Challenges&lt;/h3&gt; 
&lt;p&gt;Looking for resources to help you prep for the &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Coding Interview&lt;/strong&gt;&lt;/a&gt;?&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/b4YtAEN.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;Check out the sister repo &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Interactive Coding Challenges&lt;/strong&gt;&lt;/a&gt;, which contains an additional Anki deck:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg"&gt;Coding deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn from the community.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Feel free to submit pull requests to help:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fix errors&lt;/li&gt; 
 &lt;li&gt;Improve sections&lt;/li&gt; 
 &lt;li&gt;Add new sections&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Translate&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Content that needs some polishing is placed &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development"&gt;under development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Review the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Index of system design topics&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Summaries of various system design topics, including pros and cons. &lt;strong&gt;Everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Each section contains links to more in-depth resources.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-topics-start-here"&gt;System design topics: start here&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-1-review-the-scalability-video-lecture"&gt;Step 1: Review the scalability video lecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-2-review-the-scalability-article"&gt;Step 2: Review the scalability article&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#next-steps"&gt;Next steps&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#performance-vs-scalability"&gt;Performance vs scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-vs-throughput"&gt;Latency vs throughput&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-vs-consistency"&gt;Availability vs consistency&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP theorem&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cp---consistency-and-partition-tolerance"&gt;CP - consistency and partition tolerance&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#ap---availability-and-partition-tolerance"&gt;AP - availability and partition tolerance&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#consistency-patterns"&gt;Consistency patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#weak-consistency"&gt;Weak consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;Eventual consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#strong-consistency"&gt;Strong consistency&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-patterns"&gt;Availability patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#fail-over"&gt;Fail-over&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#replication"&gt;Replication&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-in-numbers"&gt;Availability in numbers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#domain-name-system"&gt;Domain name system&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network"&gt;Content delivery network&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#push-cdns"&gt;Push CDNs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#pull-cdns"&gt;Pull CDNs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer"&gt;Load balancer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive"&gt;Active-passive&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active"&gt;Active-active&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#horizontal-scaling"&gt;Horizontal scaling&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;Reverse proxy (web server)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer-vs-reverse-proxy"&gt;Load balancer vs reverse proxy&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-layer"&gt;Application layer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#microservices"&gt;Microservices&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#service-discovery"&gt;Service discovery&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;Database&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#relational-database-management-system-rdbms"&gt;Relational database management system (RDBMS)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;Federation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding"&gt;Sharding&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization"&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-tuning"&gt;SQL tuning&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#nosql"&gt;NoSQL&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store"&gt;Key-value store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#document-store"&gt;Document store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#wide-column-store"&gt;Wide column store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#graph-database"&gt;Graph Database&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache"&gt;Cache&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#client-caching"&gt;Client caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cdn-caching"&gt;CDN caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#web-server-caching"&gt;Web server caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database-caching"&gt;Database caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-caching"&gt;Application caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-database-query-level"&gt;Caching at the database query level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-object-level"&gt;Caching at the object level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#when-to-update-the-cache"&gt;When to update the cache&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache-aside"&gt;Cache-aside&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-through"&gt;Write-through&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-behind-write-back"&gt;Write-behind (write-back)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#refresh-ahead"&gt;Refresh-ahead&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism"&gt;Asynchronism&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#message-queues"&gt;Message queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#task-queues"&gt;Task queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#back-pressure"&gt;Back pressure&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;Communication&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#transmission-control-protocol-tcp"&gt;Transmission control protocol (TCP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#user-datagram-protocol-udp"&gt;User datagram protocol (UDP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#remote-procedure-call-rpc"&gt;Remote procedure call (RPC)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest"&gt;Representational state transfer (REST)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#security"&gt;Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix"&gt;Appendix&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-architectures"&gt;Company architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development"&gt;Under development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#credits"&gt;Credits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contact-info"&gt;Contact info&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Study guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Suggested topics to review based on your interview timeline (short, medium, long).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/OfVllex.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: For interviews, do I need to know everything here?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A: No, you don't need to know everything here to prepare for the interview&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;What you are asked in an interview depends on variables such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;How much experience you have&lt;/li&gt; 
 &lt;li&gt;What your technical background is&lt;/li&gt; 
 &lt;li&gt;What positions you are interviewing for&lt;/li&gt; 
 &lt;li&gt;Which companies you are interviewing with&lt;/li&gt; 
 &lt;li&gt;Luck&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More experienced candidates are generally expected to know more about system design. Architects or team leads might be expected to know more than individual contributors. Top tech companies are likely to have one or more design interview rounds.&lt;/p&gt; 
&lt;p&gt;Start broad and go deeper in a few areas. It helps to know a little about various key system design topics. Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Short timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;some&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;some depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;many&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Long timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;more depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;most&lt;/strong&gt; interview questions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Short&lt;/th&gt; 
   &lt;th&gt;Medium&lt;/th&gt; 
   &lt;th&gt;Long&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics"&gt;System design topics&lt;/a&gt; to get a broad understanding of how systems work&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few articles in the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt; for the companies you are interviewing with&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;üëç&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;How to approach a system design interview question&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;How to tackle a system design interview question.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The system design interview is an &lt;strong&gt;open-ended conversation&lt;/strong&gt;. You are expected to lead it.&lt;/p&gt; 
&lt;p&gt;You can use the following steps to guide the discussion. To help solidify this process, work through the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt; section using the following steps.&lt;/p&gt; 
&lt;h3&gt;Step 1: Outline use cases, constraints, and assumptions&lt;/h3&gt; 
&lt;p&gt;Gather requirements and scope the problem. Ask questions to clarify use cases and constraints. Discuss assumptions.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Who is going to use it?&lt;/li&gt; 
 &lt;li&gt;How are they going to use it?&lt;/li&gt; 
 &lt;li&gt;How many users are there?&lt;/li&gt; 
 &lt;li&gt;What does the system do?&lt;/li&gt; 
 &lt;li&gt;What are the inputs and outputs of the system?&lt;/li&gt; 
 &lt;li&gt;How much data do we expect to handle?&lt;/li&gt; 
 &lt;li&gt;How many requests per second do we expect?&lt;/li&gt; 
 &lt;li&gt;What is the expected read to write ratio?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Create a high level design&lt;/h3&gt; 
&lt;p&gt;Outline a high level design with all important components.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sketch the main components and connections&lt;/li&gt; 
 &lt;li&gt;Justify your ideas&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 3: Design core components&lt;/h3&gt; 
&lt;p&gt;Dive into details for each core component. For example, if you were asked to &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;design a url shortening service&lt;/a&gt;, discuss:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generating and storing a hash of the full url 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;MD5&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;Base62&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Hash collisions&lt;/li&gt; 
   &lt;li&gt;SQL or NoSQL&lt;/li&gt; 
   &lt;li&gt;Database schema&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Translating a hashed url to the full url 
  &lt;ul&gt; 
   &lt;li&gt;Database lookup&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;API and object-oriented design&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 4: Scale the design&lt;/h3&gt; 
&lt;p&gt;Identify and address bottlenecks, given the constraints. For example, do you need the following to address scalability issues?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Load balancer&lt;/li&gt; 
 &lt;li&gt;Horizontal scaling&lt;/li&gt; 
 &lt;li&gt;Caching&lt;/li&gt; 
 &lt;li&gt;Database sharding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Discuss potential solutions and trade-offs. Everything is a trade-off. Address bottlenecks using &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics"&gt;principles of scalable system design&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Back-of-the-envelope calculations&lt;/h3&gt; 
&lt;p&gt;You might be asked to do some estimates by hand. Refer to the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix"&gt;Appendix&lt;/a&gt; for the following resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html"&gt;Use back of the envelope calculations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;p&gt;Check out the following links to get a better idea of what to expect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20210505130322/https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/"&gt;How to ace a systems design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design"&gt;The system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ZgdS0EUmn70"&gt;Intro to Architecture and Systems Design Interviews&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://leetcode.com/discuss/career/229177/My-System-Design-Template"&gt;System design template&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Pastebin.com (or Bit.ly)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a web crawler&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Mint.com&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the data structures for a social network&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store for a search engine&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Amazon's sales ranking by category feature&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that scales to millions of users on AWS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Design Pastebin.com (or Bit.ly)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4edXG0T.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a web crawler&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bWxPtQA.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design Mint.com&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/V5q57vU.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design the data structures for a social network&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/cdCv5g7.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a key-value store for a search engine&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4j99mhe.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design Amazon's sales ranking by category feature&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/MzExP06.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h3&gt;Design a system that scales to millions of users on AWS&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png" alt="Imgur" /&gt;&lt;/p&gt; 
&lt;h2&gt;Object-oriented design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common object-oriented design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note: This section is under development&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a hash map&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/hash_table/hash_map.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a least recently used cache&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/lru_cache/lru_cache.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a call center&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/call_center/call_center.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a deck of cards&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a parking lot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/parking_lot/parking_lot.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/online_chat/online_chat.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a circular array&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an object-oriented design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;System design topics: start here&lt;/h2&gt; 
&lt;p&gt;New to system design?&lt;/p&gt; 
&lt;p&gt;First, you'll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.&lt;/p&gt; 
&lt;h3&gt;Step 1: Review the scalability video lecture&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=-W9F__D3oY4"&gt;Scalability Lecture at Harvard&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;Vertical scaling&lt;/li&gt; 
   &lt;li&gt;Horizontal scaling&lt;/li&gt; 
   &lt;li&gt;Caching&lt;/li&gt; 
   &lt;li&gt;Load balancing&lt;/li&gt; 
   &lt;li&gt;Database replication&lt;/li&gt; 
   &lt;li&gt;Database partitioning&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Review the scalability article&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://web.archive.org/web/20221030091841/http://www.lecloud.net/tagged/scalability/chrono"&gt;Scalability&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones"&gt;Clones&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database"&gt;Databases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache"&gt;Caches&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220926171507/https://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism"&gt;Asynchronism&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next steps&lt;/h3&gt; 
&lt;p&gt;Next, we'll look at high-level trade-offs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; vs &lt;strong&gt;scalability&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Latency&lt;/strong&gt; vs &lt;strong&gt;throughput&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; vs &lt;strong&gt;consistency&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Keep in mind that &lt;strong&gt;everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Then we'll dive into more specific topics such as DNS, CDNs, and load balancers.&lt;/p&gt; 
&lt;h2&gt;Performance vs scalability&lt;/h2&gt; 
&lt;p&gt;A service is &lt;strong&gt;scalable&lt;/strong&gt; if it results in increased &lt;strong&gt;performance&lt;/strong&gt; in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Another way to look at performance vs scalability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;performance&lt;/strong&gt; problem, your system is slow for a single user.&lt;/li&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;scalability&lt;/strong&gt; problem, your system is fast for a single user but slow under heavy load.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html"&gt;A word on scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Latency vs throughput&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt; is the time to perform some action or to produce some result.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Throughput&lt;/strong&gt; is the number of such actions or results per unit of time.&lt;/p&gt; 
&lt;p&gt;Generally, you should aim for &lt;strong&gt;maximal throughput&lt;/strong&gt; with &lt;strong&gt;acceptable latency&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://community.cadence.com/cadence_blogs_8/b/fv/posts/understanding-latency-vs-throughput"&gt;Understanding latency vs throughput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability vs consistency&lt;/h2&gt; 
&lt;h3&gt;CAP theorem&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bgLMI2u.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://robertgreiner.com/cap-theorem-revisited"&gt;Source: CAP theorem revisited&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In a distributed computer system, you can only support two of the following guarantees:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Every read receives the most recent write or an error&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; - Every request receives a response, without guarantee that it contains the most recent version of the information&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Partition Tolerance&lt;/strong&gt; - The system continues to operate despite arbitrary partitioning due to network failures&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Networks aren't reliable, so you'll need to support partition tolerance. You'll need to make a software tradeoff between consistency and availability.&lt;/em&gt;&lt;/p&gt; 
&lt;h4&gt;CP - consistency and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Waiting for a response from the partitioned node might result in a timeout error. CP is a good choice if your business needs require atomic reads and writes.&lt;/p&gt; 
&lt;h4&gt;AP - availability and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Responses return the most readily available version of the data available on any node, which might not be the latest. Writes might take some time to propagate when the partition is resolved.&lt;/p&gt; 
&lt;p&gt;AP is a good choice if the business needs to allow for &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;eventual consistency&lt;/a&gt; or when the system needs to continue working despite external errors.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://robertgreiner.com/cap-theorem-revisited/"&gt;CAP theorem revisited&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://ksat.me/a-plain-english-introduction-to-cap-theorem"&gt;A plain english introduction to CAP theorem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/henryr/cap-faq"&gt;CAP FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=k-Yaq8AHlFA"&gt;The CAP theorem&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Consistency patterns&lt;/h2&gt; 
&lt;p&gt;With multiple copies of the same data, we are faced with options on how to synchronize them so clients have a consistent view of the data. Recall the definition of consistency from the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP theorem&lt;/a&gt; - Every read receives the most recent write or an error.&lt;/p&gt; 
&lt;h3&gt;Weak consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads may or may not see it. A best effort approach is taken.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as memcached. Weak consistency works well in real time use cases such as VoIP, video chat, and realtime multiplayer games. For example, if you are on a phone call and lose reception for a few seconds, when you regain connection you do not hear what was spoken during connection loss.&lt;/p&gt; 
&lt;h3&gt;Eventual consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will eventually see it (typically within milliseconds). Data is replicated asynchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as DNS and email. Eventual consistency works well in highly available systems.&lt;/p&gt; 
&lt;h3&gt;Strong consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will see it. Data is replicated synchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in file systems and RDBMSes. Strong consistency works well in systems that need transactions.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://snarfed.org/transactions_across_datacenters_io.html"&gt;Transactions across data centers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability patterns&lt;/h2&gt; 
&lt;p&gt;There are two complementary patterns to support high availability: &lt;strong&gt;fail-over&lt;/strong&gt; and &lt;strong&gt;replication&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Fail-over&lt;/h3&gt; 
&lt;h4&gt;Active-passive&lt;/h4&gt; 
&lt;p&gt;With active-passive fail-over, heartbeats are sent between the active and the passive server on standby. If the heartbeat is interrupted, the passive server takes over the active's IP address and resumes service.&lt;/p&gt; 
&lt;p&gt;The length of downtime is determined by whether the passive server is already running in 'hot' standby or whether it needs to start up from 'cold' standby. Only the active server handles traffic.&lt;/p&gt; 
&lt;p&gt;Active-passive failover can also be referred to as master-slave failover.&lt;/p&gt; 
&lt;h4&gt;Active-active&lt;/h4&gt; 
&lt;p&gt;In active-active, both servers are managing traffic, spreading the load between them.&lt;/p&gt; 
&lt;p&gt;If the servers are public-facing, the DNS would need to know about the public IPs of both servers. If the servers are internal-facing, application logic would need to know about both servers.&lt;/p&gt; 
&lt;p&gt;Active-active failover can also be referred to as master-master failover.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): failover&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fail-over adds more hardware and additional complexity.&lt;/li&gt; 
 &lt;li&gt;There is a potential for loss of data if the active system fails before any newly written data can be replicated to the passive.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Replication&lt;/h3&gt; 
&lt;h4&gt;Master-slave and master-master&lt;/h4&gt; 
&lt;p&gt;This topic is further discussed in the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;Database&lt;/a&gt; section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Availability in numbers&lt;/h3&gt; 
&lt;p&gt;Availability is often quantified by uptime (or downtime) as a percentage of time the service is available. Availability is generally measured in number of 9s--a service with 99.99% availability is described as having four 9s.&lt;/p&gt; 
&lt;h4&gt;99.9% availability - three 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;8h 45min 57s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;43m 49.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;10m 4.8s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;1m 26.4s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;99.99% availability - four 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;52min 35.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;4m 23s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;1m 5s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;8.6s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Availability in parallel vs in sequence&lt;/h4&gt; 
&lt;p&gt;If a service consists of multiple components prone to failure, the service's overall availability depends on whether the components are in sequence or in parallel.&lt;/p&gt; 
&lt;h6&gt;In sequence&lt;/h6&gt; 
&lt;p&gt;Overall availability decreases when two components with availability &amp;lt; 100% are in sequence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = Availability (Foo) * Availability (Bar)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in sequence would be 99.8%.&lt;/p&gt; 
&lt;h6&gt;In parallel&lt;/h6&gt; 
&lt;p&gt;Overall availability increases when two components with availability &amp;lt; 100% are in parallel:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = 1 - (1 - Availability (Foo)) * (1 - Availability (Bar))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in parallel would be 99.9999%.&lt;/p&gt; 
&lt;h2&gt;Domain name system&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/IOyLj4i.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/srikrupa5/dns-security-presentation-issa"&gt;Source: DNS security presentation&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A Domain Name System (DNS) translates a domain name such as &lt;a href="http://www.example.com"&gt;www.example.com&lt;/a&gt; to an IP address.&lt;/p&gt; 
&lt;p&gt;DNS is hierarchical, with a few authoritative servers at the top level. Your router or ISP provides information about which DNS server(s) to contact when doing a lookup. Lower level DNS servers cache mappings, which could become stale due to DNS propagation delays. DNS results can also be cached by your browser or OS for a certain period of time, determined by the &lt;a href="https://en.wikipedia.org/wiki/Time_to_live"&gt;time to live (TTL)&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;NS record (name server)&lt;/strong&gt; - Specifies the DNS servers for your domain/subdomain.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MX record (mail exchange)&lt;/strong&gt; - Specifies the mail servers for accepting messages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A record (address)&lt;/strong&gt; - Points a name to an IP address.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CNAME (canonical)&lt;/strong&gt; - Points a name to another name or &lt;code&gt;CNAME&lt;/code&gt; (example.com to &lt;a href="http://www.example.com"&gt;www.example.com&lt;/a&gt;) or to an &lt;code&gt;A&lt;/code&gt; record.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Services such as &lt;a href="https://www.cloudflare.com/dns/"&gt;CloudFlare&lt;/a&gt; and &lt;a href="https://aws.amazon.com/route53/"&gt;Route 53&lt;/a&gt; provide managed DNS services. Some DNS services can route traffic through various methods:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.jscape.com/blog/load-balancing-algorithms"&gt;Weighted round robin&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Prevent traffic from going to servers under maintenance&lt;/li&gt; 
   &lt;li&gt;Balance between varying cluster sizes&lt;/li&gt; 
   &lt;li&gt;A/B testing&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-latency.html"&gt;Latency-based&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html"&gt;Geolocation-based&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): DNS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Accessing a DNS server introduces a slight delay, although mitigated by caching described above.&lt;/li&gt; 
 &lt;li&gt;DNS server management could be complex and is generally managed by &lt;a href="http://superuser.com/questions/472695/who-controls-the-dns-servers/472729"&gt;governments, ISPs, and large companies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;DNS services have recently come under &lt;a href="http://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack/"&gt;DDoS attack&lt;/a&gt;, preventing users from accessing websites such as Twitter without knowing Twitter's IP address(es).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/dd197427(v=ws.10).aspx"&gt;DNS architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Domain_Name_System"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.dnsimple.com/categories/dns/"&gt;DNS articles&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Content delivery network&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h9TAuGI.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/"&gt;Source: Why use a CDN&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A content delivery network (CDN) is a globally distributed network of proxy servers, serving content from locations closer to the user. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN, although some CDNs such as Amazon's CloudFront support dynamic content. The site's DNS resolution will tell clients which server to contact.&lt;/p&gt; 
&lt;p&gt;Serving content from CDNs can significantly improve performance in two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Users receive content from data centers close to them&lt;/li&gt; 
 &lt;li&gt;Your servers do not have to serve requests that the CDN fulfills&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Push CDNs&lt;/h3&gt; 
&lt;p&gt;Push CDNs receive new content whenever changes occur on your server. You take full responsibility for providing content, uploading directly to the CDN and rewriting URLs to point to the CDN. You can configure when content expires and when it is updated. Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.&lt;/p&gt; 
&lt;p&gt;Sites with a small amount of traffic or sites with content that isn't often updated work well with push CDNs. Content is placed on the CDNs once, instead of being re-pulled at regular intervals.&lt;/p&gt; 
&lt;h3&gt;Pull CDNs&lt;/h3&gt; 
&lt;p&gt;Pull CDNs grab new content from your server when the first user requests the content. You leave the content on your server and rewrite URLs to point to the CDN. This results in a slower request until the content is cached on the CDN.&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://en.wikipedia.org/wiki/Time_to_live"&gt;time-to-live (TTL)&lt;/a&gt; determines how long content is cached. Pull CDNs minimize storage space on the CDN, but can create redundant traffic if files expire and are pulled before they have actually changed.&lt;/p&gt; 
&lt;p&gt;Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): CDN&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CDN costs could be significant depending on traffic, although this should be weighed with additional costs you would incur not using a CDN.&lt;/li&gt; 
 &lt;li&gt;Content might be stale if it is updated before the TTL expires it.&lt;/li&gt; 
 &lt;li&gt;CDNs require changing URLs for static content to point to the CDN.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972"&gt;Globally distributed content delivery&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.travelblogadvice.com/technical/the-differences-between-push-and-pull-cdns/"&gt;The differences between push and pull CDNs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Content_delivery_network"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Load balancer&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h81n9iK.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Load balancers distribute incoming client requests to computing resources such as application servers and databases. In each case, the load balancer returns the response from the computing resource to the appropriate client. Load balancers are effective at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Preventing requests from going to unhealthy servers&lt;/li&gt; 
 &lt;li&gt;Preventing overloading resources&lt;/li&gt; 
 &lt;li&gt;Helping to eliminate a single point of failure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Load balancers can be implemented with hardware (expensive) or with software such as HAProxy.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session persistence&lt;/strong&gt; - Issue cookies and route a specific client's requests to same instance if the web apps do not keep track of sessions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To protect against failures, it's common to set up multiple load balancers, either in &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive"&gt;active-passive&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active"&gt;active-active&lt;/a&gt; mode.&lt;/p&gt; 
&lt;p&gt;Load balancers can route traffic based on various metrics, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Random&lt;/li&gt; 
 &lt;li&gt;Least loaded&lt;/li&gt; 
 &lt;li&gt;Session/cookies&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.g33kinfo.com/info/round-robin-vs-weighted-round-robin-lb"&gt;Round robin or weighted round robin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing"&gt;Layer 4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing"&gt;Layer 7&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Layer 4 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 4 load balancers look at info at the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;transport layer&lt;/a&gt; to decide how to distribute requests. Generally, this involves the source, destination IP addresses, and ports in the header, but not the contents of the packet. Layer 4 load balancers forward network packets to and from the upstream server, performing &lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/"&gt;Network Address Translation (NAT)&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Layer 7 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 7 load balancers look at the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;application layer&lt;/a&gt; to decide how to distribute requests. This can involve contents of the header, message, and cookies. Layer 7 load balancers terminate network traffic, reads the message, makes a load-balancing decision, then opens a connection to the selected server. For example, a layer 7 load balancer can direct video traffic to servers that host videos while directing more sensitive user billing traffic to security-hardened servers.&lt;/p&gt; 
&lt;p&gt;At the cost of flexibility, layer 4 load balancing requires less time and computing resources than Layer 7, although the performance impact can be minimal on modern commodity hardware.&lt;/p&gt; 
&lt;h3&gt;Horizontal scaling&lt;/h3&gt; 
&lt;p&gt;Load balancers can also help with horizontal scaling, improving performance and availability. Scaling out using commodity machines is more cost efficient and results in higher availability than scaling up a single server on more expensive hardware, called &lt;strong&gt;Vertical Scaling&lt;/strong&gt;. It is also easier to hire for talent working on commodity hardware than it is for specialized enterprise systems.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): horizontal scaling&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Scaling horizontally introduces complexity and involves cloning servers 
  &lt;ul&gt; 
   &lt;li&gt;Servers should be stateless: they should not contain any user-related data like sessions or profile pictures&lt;/li&gt; 
   &lt;li&gt;Sessions can be stored in a centralized data store such as a &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;database&lt;/a&gt; (SQL, NoSQL) or a persistent &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache"&gt;cache&lt;/a&gt; (Redis, Memcached)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Downstream servers such as caches and databases need to handle more simultaneous connections as upstream servers scale out&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): load balancer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The load balancer can become a performance bottleneck if it does not have enough resources or if it is not configured properly.&lt;/li&gt; 
 &lt;li&gt;Introducing a load balancer to help eliminate a single point of failure results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single load balancer is a single point of failure, configuring multiple load balancers further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Load_balancing_(computing)"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-7-load-balancing/"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html"&gt;ELB listener config&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reverse proxy (web server)&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n41Azff.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg"&gt;Source: Wikipedia&lt;/a&gt;&lt;/i&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;A reverse proxy is a web server that centralizes internal services and provides unified interfaces to the public. Requests from clients are forwarded to a server that can fulfill it before the reverse proxy returns the server's response to the client.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Increased security&lt;/strong&gt; - Hide information about backend servers, blacklist IPs, limit number of connections per client&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Increased scalability and flexibility&lt;/strong&gt; - Clients only see the reverse proxy's IP, allowing you to scale servers or change their configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compression&lt;/strong&gt; - Compress server responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt; - Return the response for cached requests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Static content&lt;/strong&gt; - Serve static content directly 
  &lt;ul&gt; 
   &lt;li&gt;HTML/CSS/JS&lt;/li&gt; 
   &lt;li&gt;Photos&lt;/li&gt; 
   &lt;li&gt;Videos&lt;/li&gt; 
   &lt;li&gt;Etc&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Load balancer vs reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploying a load balancer is useful when you have multiple servers. Often, load balancers route traffic to a set of servers serving the same function.&lt;/li&gt; 
 &lt;li&gt;Reverse proxies can be useful even with just one web server or application server, opening up the benefits described in the previous section.&lt;/li&gt; 
 &lt;li&gt;Solutions such as NGINX and HAProxy can support both layer 7 reverse proxying and load balancing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Introducing a reverse proxy results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single reverse proxy is a single point of failure, configuring multiple reverse proxies (ie a &lt;a href="https://en.wikipedia.org/wiki/Failover"&gt;failover&lt;/a&gt;) further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/"&gt;Reverse proxy vs load balancer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Reverse_proxy"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Application layer&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yB5SYwm.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Separating out the web layer from the application layer (also known as platform layer) allows you to scale and configure both layers independently. Adding a new API results in adding application servers without necessarily adding additional web servers. The &lt;strong&gt;single responsibility principle&lt;/strong&gt; advocates for small and autonomous services that work together. Small teams with small services can plan more aggressively for rapid growth.&lt;/p&gt; 
&lt;p&gt;Workers in the application layer also help enable &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism"&gt;asynchronism&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Microservices&lt;/h3&gt; 
&lt;p&gt;Related to this discussion are &lt;a href="https://en.wikipedia.org/wiki/Microservices"&gt;microservices&lt;/a&gt;, which can be described as a suite of independently deployable, small, modular services. Each service runs a unique process and communicates through a well-defined, lightweight mechanism to serve a business goal. &lt;sup&gt;&lt;a href="https://smartbear.com/learn/api-design/what-are-microservices"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Pinterest, for example, could have the following microservices: user profile, follower, feed, search, photo upload, etc.&lt;/p&gt; 
&lt;h3&gt;Service Discovery&lt;/h3&gt; 
&lt;p&gt;Systems such as &lt;a href="https://www.consul.io/docs/index.html"&gt;Consul&lt;/a&gt;, &lt;a href="https://coreos.com/etcd/docs/latest"&gt;Etcd&lt;/a&gt;, and &lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;Zookeeper&lt;/a&gt; can help services find each other by keeping track of registered names, addresses, and ports. &lt;a href="https://www.consul.io/intro/getting-started/checks.html"&gt;Health checks&lt;/a&gt; help verify service integrity and are often done using an &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#hypertext-transfer-protocol-http"&gt;HTTP&lt;/a&gt; endpoint. Both Consul and Etcd have a built in &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store"&gt;key-value store&lt;/a&gt; that can be useful for storing config values and other shared data.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): application layer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adding an application layer with loosely coupled services requires a different approach from an architectural, operations, and process viewpoint (vs a monolithic system).&lt;/li&gt; 
 &lt;li&gt;Microservices can add complexity in terms of deployments and operations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale"&gt;Intro to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Service-oriented_architecture"&gt;Service oriented architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;Introduction to Zookeeper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudncode.wordpress.com/2016/07/22/msa-getting-started/"&gt;Here's what you need to know about building microservices&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Database&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Xkm5CXz.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Relational database management system (RDBMS)&lt;/h3&gt; 
&lt;p&gt;A relational database like SQL is a collection of data items organized in tables.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ACID&lt;/strong&gt; is a set of properties of relational database &lt;a href="https://en.wikipedia.org/wiki/Database_transaction"&gt;transactions&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Atomicity&lt;/strong&gt; - Each transaction is all or nothing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Any transaction will bring the database from one valid state to another&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt; - Executing transactions concurrently has the same results as if the transactions were executed serially&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Durability&lt;/strong&gt; - Once a transaction has been committed, it will remain so&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are many techniques to scale a relational database: &lt;strong&gt;master-slave replication&lt;/strong&gt;, &lt;strong&gt;master-master replication&lt;/strong&gt;, &lt;strong&gt;federation&lt;/strong&gt;, &lt;strong&gt;sharding&lt;/strong&gt;, &lt;strong&gt;denormalization&lt;/strong&gt;, and &lt;strong&gt;SQL tuning&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Master-slave replication&lt;/h4&gt; 
&lt;p&gt;The master serves reads and writes, replicating writes to one or more slaves, which serve only reads. Slaves can also replicate to additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/C9ioGtn.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-slave replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Additional logic is needed to promote a slave to a master.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Master-master replication&lt;/h4&gt; 
&lt;p&gt;Both masters serve reads and writes and coordinate with each other on writes. If either master goes down, the system can continue to operate with both reads and writes.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/krAHLGg.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-master replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You'll need a load balancer or you'll need to make changes to your application logic to determine where to write.&lt;/li&gt; 
 &lt;li&gt;Most master-master systems are either loosely consistent (violating ACID) or have increased write latency due to synchronization.&lt;/li&gt; 
 &lt;li&gt;Conflict resolution comes more into play as more write nodes are added and as latency increases.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There is a potential for loss of data if the master fails before any newly written data can be replicated to other nodes.&lt;/li&gt; 
 &lt;li&gt;Writes are replayed to the read replicas. If there are a lot of writes, the read replicas can get bogged down with replaying writes and can't do as many reads.&lt;/li&gt; 
 &lt;li&gt;The more read slaves, the more you have to replicate, which leads to greater replication lag.&lt;/li&gt; 
 &lt;li&gt;On some systems, writing to the master can spawn multiple threads to write in parallel, whereas read replicas only support writing sequentially with a single thread.&lt;/li&gt; 
 &lt;li&gt;Replication adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Multi-master_replication"&gt;Multi-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Federation&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/U3qV33e.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Federation (or functional partitioning) splits up databases by function. For example, instead of a single, monolithic database, you could have three databases: &lt;strong&gt;forums&lt;/strong&gt;, &lt;strong&gt;users&lt;/strong&gt;, and &lt;strong&gt;products&lt;/strong&gt;, resulting in less read and write traffic to each database and therefore less replication lag. Smaller databases result in more data that can fit in memory, which in turn results in more cache hits due to improved cache locality. With no single central master serializing writes you can write in parallel, increasing throughput.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Federation is not effective if your schema requires huge functions or tables.&lt;/li&gt; 
 &lt;li&gt;You'll need to update your application logic to determine which database to read and write.&lt;/li&gt; 
 &lt;li&gt;Joining data from two databases is more complex with a &lt;a href="http://stackoverflow.com/questions/5145637/querying-data-by-joining-two-tables-in-two-database-on-different-servers"&gt;server link&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Federation adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Sharding&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wU8x5Id.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Sharding distributes data across different databases such that each database can only manage a subset of the data. Taking a users database as an example, as the number of users increases, more shards are added to the cluster.&lt;/p&gt; 
&lt;p&gt;Similar to the advantages of &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;federation&lt;/a&gt;, sharding results in less read and write traffic, less replication, and more cache hits. Index size is also reduced, which generally improves performance with faster queries. If one shard goes down, the other shards are still operational, although you'll want to add some form of replication to avoid data loss. Like federation, there is no single central master serializing writes, allowing you to write in parallel with increased throughput.&lt;/p&gt; 
&lt;p&gt;Common ways to shard a table of users is either through the user's last name initial or the user's geographic location.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You'll need to update your application logic to work with shards, which could result in complex SQL queries.&lt;/li&gt; 
 &lt;li&gt;Data distribution can become lopsided in a shard. For example, a set of power users on a shard could result in increased load to that shard compared to others. 
  &lt;ul&gt; 
   &lt;li&gt;Rebalancing adds additional complexity. A sharding function based on &lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html"&gt;consistent hashing&lt;/a&gt; can reduce the amount of transferred data.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Joining data from multiple shards is more complex.&lt;/li&gt; 
 &lt;li&gt;Sharding adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html"&gt;The coming of the shard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Shard_(database_architecture)"&gt;Shard database architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html"&gt;Consistent hashing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Denormalization&lt;/h4&gt; 
&lt;p&gt;Denormalization attempts to improve read performance at the expense of some write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins. Some RDBMS such as &lt;a href="https://en.wikipedia.org/wiki/PostgreSQL"&gt;PostgreSQL&lt;/a&gt; and Oracle support &lt;a href="https://en.wikipedia.org/wiki/Materialized_view"&gt;materialized views&lt;/a&gt; which handle the work of storing redundant information and keeping redundant copies consistent.&lt;/p&gt; 
&lt;p&gt;Once data becomes distributed with techniques such as &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;federation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding"&gt;sharding&lt;/a&gt;, managing joins across data centers further increases complexity. Denormalization might circumvent the need for such complex joins.&lt;/p&gt; 
&lt;p&gt;In most systems, reads can heavily outnumber writes 100:1 or even 1000:1. A read resulting in a complex database join can be very expensive, spending a significant amount of time on disk operations.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): denormalization&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Data is duplicated.&lt;/li&gt; 
 &lt;li&gt;Constraints can help redundant copies of information stay in sync, which increases complexity of the database design.&lt;/li&gt; 
 &lt;li&gt;A denormalized database under heavy write load might perform worse than its normalized counterpart.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;Source(s) and further reading: denormalization&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Denormalization"&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;SQL tuning&lt;/h4&gt; 
&lt;p&gt;SQL tuning is a broad topic and many &lt;a href="https://www.amazon.com/s/ref=nb_sb_noss_2?url=search-alias%3Daps&amp;amp;field-keywords=sql+tuning"&gt;books&lt;/a&gt; have been written as reference.&lt;/p&gt; 
&lt;p&gt;It's important to &lt;strong&gt;benchmark&lt;/strong&gt; and &lt;strong&gt;profile&lt;/strong&gt; to simulate and uncover bottlenecks.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark&lt;/strong&gt; - Simulate high-load situations with tools such as &lt;a href="http://httpd.apache.org/docs/2.2/programs/ab.html"&gt;ab&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Profile&lt;/strong&gt; - Enable tools such as the &lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html"&gt;slow query log&lt;/a&gt; to help track performance issues.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Benchmarking and profiling might point you to the following optimizations.&lt;/p&gt; 
&lt;h5&gt;Tighten up the schema&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;MySQL dumps to disk in contiguous blocks for fast access.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;CHAR&lt;/code&gt; instead of &lt;code&gt;VARCHAR&lt;/code&gt; for fixed-length fields. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;CHAR&lt;/code&gt; effectively allows for fast, random access, whereas with &lt;code&gt;VARCHAR&lt;/code&gt;, you must find the end of a string before moving onto the next one.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;TEXT&lt;/code&gt; for large blocks of text such as blog posts. &lt;code&gt;TEXT&lt;/code&gt; also allows for boolean searches. Using a &lt;code&gt;TEXT&lt;/code&gt; field results in storing a pointer on disk that is used to locate the text block.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;INT&lt;/code&gt; for larger numbers up to 2^32 or 4 billion.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;DECIMAL&lt;/code&gt; for currency to avoid floating point representation errors.&lt;/li&gt; 
 &lt;li&gt;Avoid storing large &lt;code&gt;BLOBS&lt;/code&gt;, store the location of where to get the object instead.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;VARCHAR(255)&lt;/code&gt; is the largest number of characters that can be counted in an 8 bit number, often maximizing the use of a byte in some RDBMS.&lt;/li&gt; 
 &lt;li&gt;Set the &lt;code&gt;NOT NULL&lt;/code&gt; constraint where applicable to &lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search"&gt;improve search performance&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Use good indices&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Columns that you are querying (&lt;code&gt;SELECT&lt;/code&gt;, &lt;code&gt;GROUP BY&lt;/code&gt;, &lt;code&gt;ORDER BY&lt;/code&gt;, &lt;code&gt;JOIN&lt;/code&gt;) could be faster with indices.&lt;/li&gt; 
 &lt;li&gt;Indices are usually represented as self-balancing &lt;a href="https://en.wikipedia.org/wiki/B-tree"&gt;B-tree&lt;/a&gt; that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time.&lt;/li&gt; 
 &lt;li&gt;Placing an index can keep the data in memory, requiring more space.&lt;/li&gt; 
 &lt;li&gt;Writes could also be slower since the index also needs to be updated.&lt;/li&gt; 
 &lt;li&gt;When loading large amounts of data, it might be faster to disable indices, load the data, then rebuild the indices.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Avoid expensive joins&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization"&gt;Denormalize&lt;/a&gt; where performance demands it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Partition tables&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Break up a table by putting hot spots in a separate table to help keep it in memory.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Tune the query cache&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;In some cases, the &lt;a href="https://dev.mysql.com/doc/refman/5.7/en/query-cache.html"&gt;query cache&lt;/a&gt; could lead to &lt;a href="https://www.percona.com/blog/2016/10/12/mysql-5-7-performance-tuning-immediately-after-installation/"&gt;performance issues&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL tuning&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://aiddroid.com/10-tips-optimizing-mysql-queries-dont-suck/"&gt;Tips for optimizing MySQL queries&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1217466/is-there-a-good-reason-i-see-varchar255-used-so-often-as-opposed-to-another-l"&gt;Is there a good reason i see VARCHAR(255) used so often?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search"&gt;How do null values affect performance?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html"&gt;Slow query log&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;NoSQL&lt;/h3&gt; 
&lt;p&gt;NoSQL is a collection of data items represented in a &lt;strong&gt;key-value store&lt;/strong&gt;, &lt;strong&gt;document store&lt;/strong&gt;, &lt;strong&gt;wide column store&lt;/strong&gt;, or a &lt;strong&gt;graph database&lt;/strong&gt;. Data is denormalized, and joins are generally done in the application code. Most NoSQL stores lack true ACID transactions and favor &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;eventual consistency&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;BASE&lt;/strong&gt; is often used to describe the properties of NoSQL databases. In comparison with the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP Theorem&lt;/a&gt;, BASE chooses availability over consistency.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Basically available&lt;/strong&gt; - the system guarantees availability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Soft state&lt;/strong&gt; - the state of the system may change over time, even without input.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Eventual consistency&lt;/strong&gt; - the system will become consistent over a period of time, given that the system doesn't receive input during that period.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to choosing between &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;, it is helpful to understand which type of NoSQL database best fits your use case(s). We'll review &lt;strong&gt;key-value stores&lt;/strong&gt;, &lt;strong&gt;document stores&lt;/strong&gt;, &lt;strong&gt;wide column stores&lt;/strong&gt;, and &lt;strong&gt;graph databases&lt;/strong&gt; in the next section.&lt;/p&gt; 
&lt;h4&gt;Key-value store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: hash table&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A key-value store generally allows for O(1) reads and writes and is often backed by memory or SSD. Data stores can maintain keys in &lt;a href="https://en.wikipedia.org/wiki/Lexicographical_order"&gt;lexicographic order&lt;/a&gt;, allowing efficient retrieval of key ranges. Key-value stores can allow for storing of metadata with a value.&lt;/p&gt; 
&lt;p&gt;Key-value stores provide high performance and are often used for simple data models or for rapidly-changing data, such as an in-memory cache layer. Since they offer only a limited set of operations, complexity is shifted to the application layer if additional operations are needed.&lt;/p&gt; 
&lt;p&gt;A key-value store is the basis for more complex systems such as a document store, and in some cases, a graph database.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: key-value store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Key-value_database"&gt;Key-value database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/4056093/what-are-the-disadvantages-of-using-a-key-value-table-over-nullable-columns-or"&gt;Disadvantages of key-value stores&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://qnimate.com/overview-of-redis-architecture/"&gt;Redis architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://adayinthelifeof.nl/2011/02/06/memcache-internals/"&gt;Memcached architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Document store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: key-value store with documents stored as values&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A document store is centered around documents (XML, JSON, binary, etc), where a document stores all information for a given object. Document stores provide APIs or a query language to query based on the internal structure of the document itself. &lt;em&gt;Note, many key-value stores include features for working with a value's metadata, blurring the lines between these two storage types.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Based on the underlying implementation, documents are organized by collections, tags, metadata, or directories. Although documents can be organized or grouped together, documents may have fields that are completely different from each other.&lt;/p&gt; 
&lt;p&gt;Some document stores like &lt;a href="https://www.mongodb.com/mongodb-architecture"&gt;MongoDB&lt;/a&gt; and &lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/"&gt;CouchDB&lt;/a&gt; also provide a SQL-like language to perform complex queries. &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf"&gt;DynamoDB&lt;/a&gt; supports both key-values and documents.&lt;/p&gt; 
&lt;p&gt;Document stores provide high flexibility and are often used for working with occasionally changing data.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: document store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Document-oriented_database"&gt;Document-oriented database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.mongodb.com/mongodb-architecture"&gt;MongoDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/"&gt;CouchDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up"&gt;Elasticsearch architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Wide column store&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n16iOGk.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html"&gt;Source: SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: nested map &lt;code&gt;ColumnFamily&amp;lt;RowKey, Columns&amp;lt;ColKey, Value, Timestamp&amp;gt;&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A wide column store's basic unit of data is a column (name/value pair). A column can be grouped in column families (analogous to a SQL table). Super column families further group column families. You can access each column independently with a row key, and columns with the same row key form a row. Each value contains a timestamp for versioning and for conflict resolution.&lt;/p&gt; 
&lt;p&gt;Google introduced &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;Bigtable&lt;/a&gt; as the first wide column store, which influenced the open-source &lt;a href="https://www.edureka.co/blog/hbase-architecture/"&gt;HBase&lt;/a&gt; often-used in the Hadoop ecosystem, and &lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html"&gt;Cassandra&lt;/a&gt; from Facebook. Stores such as BigTable, HBase, and Cassandra maintain keys in lexicographic order, allowing efficient retrieval of selective key ranges.&lt;/p&gt; 
&lt;p&gt;Wide column stores offer high availability and high scalability. They are often used for very large data sets.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: wide column store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html"&gt;SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;Bigtable architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.edureka.co/blog/hbase-architecture/"&gt;HBase architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html"&gt;Cassandra architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Graph database&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/fNcl65g.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://en.wikipedia.org/wiki/File:GraphDatabase_PropertyGraph.png"&gt;Source: Graph database&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: graph&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;In a graph database, each node is a record and each arc is a relationship between two nodes. Graph databases are optimized to represent complex relationships with many foreign keys or many-to-many relationships.&lt;/p&gt; 
&lt;p&gt;Graphs databases offer high performance for data models with complex relationships, such as a social network. They are relatively new and are not yet widely-used; it might be more difficult to find development tools and resources. Many graphs can only be accessed with &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest"&gt;REST APIs&lt;/a&gt;.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: graph&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Graph_database"&gt;Graph database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neo4j.com/"&gt;Neo4j&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.twitter.com/2010/introducing-flockdb"&gt;FlockDB&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: NoSQL&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/3342497/explanation-of-base-terminology"&gt;Explanation of base terminology&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.wskogqenq"&gt;NoSQL databases a survey and decision guidance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qI_g07C_Q5I"&gt;Introduction to NoSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://horicky.blogspot.com/2009/11/nosql-patterns.html"&gt;NoSQL patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;SQL or NoSQL&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wXGqG5f.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.infoq.com/articles/Transition-RDBMS-NoSQL/"&gt;Source: Transitioning from RDBMS to NoSQL&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;SQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Structured data&lt;/li&gt; 
 &lt;li&gt;Strict schema&lt;/li&gt; 
 &lt;li&gt;Relational data&lt;/li&gt; 
 &lt;li&gt;Need for complex joins&lt;/li&gt; 
 &lt;li&gt;Transactions&lt;/li&gt; 
 &lt;li&gt;Clear patterns for scaling&lt;/li&gt; 
 &lt;li&gt;More established: developers, community, code, tools, etc&lt;/li&gt; 
 &lt;li&gt;Lookups by index are very fast&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;NoSQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Semi-structured data&lt;/li&gt; 
 &lt;li&gt;Dynamic or flexible schema&lt;/li&gt; 
 &lt;li&gt;Non-relational data&lt;/li&gt; 
 &lt;li&gt;No need for complex joins&lt;/li&gt; 
 &lt;li&gt;Store many TB (or PB) of data&lt;/li&gt; 
 &lt;li&gt;Very data intensive workload&lt;/li&gt; 
 &lt;li&gt;Very high throughput for IOPS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample data well-suited for NoSQL:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rapid ingest of clickstream and log data&lt;/li&gt; 
 &lt;li&gt;Leaderboard or scoring data&lt;/li&gt; 
 &lt;li&gt;Temporary data, such as a shopping cart&lt;/li&gt; 
 &lt;li&gt;Frequently accessed ('hot') tables&lt;/li&gt; 
 &lt;li&gt;Metadata/lookup tables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL or NoSQL&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sitepoint.com/sql-vs-nosql-differences/"&gt;SQL vs NoSQL differences&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cache&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Q6z24La.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Caching improves page load times and can reduce the load on your servers and databases. In this model, the dispatcher will first lookup if the request has been made before and try to find the previous result to return, in order to save the actual execution.&lt;/p&gt; 
&lt;p&gt;Databases often benefit from a uniform distribution of reads and writes across its partitions. Popular items can skew the distribution, causing bottlenecks. Putting a cache in front of a database can help absorb uneven loads and spikes in traffic.&lt;/p&gt; 
&lt;h3&gt;Client caching&lt;/h3&gt; 
&lt;p&gt;Caches can be located on the client side (OS or browser), &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;server side&lt;/a&gt;, or in a distinct cache layer.&lt;/p&gt; 
&lt;h3&gt;CDN caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network"&gt;CDNs&lt;/a&gt; are considered a type of cache.&lt;/p&gt; 
&lt;h3&gt;Web server caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;Reverse proxies&lt;/a&gt; and caches such as &lt;a href="https://www.varnish-cache.org/"&gt;Varnish&lt;/a&gt; can serve static and dynamic content directly. Web servers can also cache requests, returning responses without having to contact application servers.&lt;/p&gt; 
&lt;h3&gt;Database caching&lt;/h3&gt; 
&lt;p&gt;Your database usually includes some level of caching in a default configuration, optimized for a generic use case. Tweaking these settings for specific usage patterns can further boost performance.&lt;/p&gt; 
&lt;h3&gt;Application caching&lt;/h3&gt; 
&lt;p&gt;In-memory caches such as Memcached and Redis are key-value stores between your application and your data storage. Since the data is held in RAM, it is much faster than typical databases where data is stored on disk. RAM is more limited than disk, so &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms"&gt;cache invalidation&lt;/a&gt; algorithms such as &lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)"&gt;least recently used (LRU)&lt;/a&gt; can help invalidate 'cold' entries and keep 'hot' data in RAM.&lt;/p&gt; 
&lt;p&gt;Redis has the following additional features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Persistence option&lt;/li&gt; 
 &lt;li&gt;Built-in data structures such as sorted sets and lists&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are multiple levels you can cache that fall into two general categories: &lt;strong&gt;database queries&lt;/strong&gt; and &lt;strong&gt;objects&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Row level&lt;/li&gt; 
 &lt;li&gt;Query-level&lt;/li&gt; 
 &lt;li&gt;Fully-formed serializable objects&lt;/li&gt; 
 &lt;li&gt;Fully-rendered HTML&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Generally, you should try to avoid file-based caching, as it makes cloning and auto-scaling more difficult.&lt;/p&gt; 
&lt;h3&gt;Caching at the database query level&lt;/h3&gt; 
&lt;p&gt;Whenever you query the database, hash the query as a key and store the result to the cache. This approach suffers from expiration issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hard to delete a cached result with complex queries&lt;/li&gt; 
 &lt;li&gt;If one piece of data changes such as a table cell, you need to delete all cached queries that might include the changed cell&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Caching at the object level&lt;/h3&gt; 
&lt;p&gt;See your data as an object, similar to what you do with your application code. Have your application assemble the dataset from the database into a class instance or a data structure(s):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Remove the object from cache if its underlying data has changed&lt;/li&gt; 
 &lt;li&gt;Allows for asynchronous processing: workers assemble objects by consuming the latest cached object&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Suggestions of what to cache:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;User sessions&lt;/li&gt; 
 &lt;li&gt;Fully rendered web pages&lt;/li&gt; 
 &lt;li&gt;Activity streams&lt;/li&gt; 
 &lt;li&gt;User graph data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;When to update the cache&lt;/h3&gt; 
&lt;p&gt;Since you can only store a limited amount of data in cache, you'll need to determine which cache update strategy works best for your use case.&lt;/p&gt; 
&lt;h4&gt;Cache-aside&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/ONjORqk.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application is responsible for reading and writing from storage. The cache does not interact with storage directly. The application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Look for entry in cache, resulting in a cache miss&lt;/li&gt; 
 &lt;li&gt;Load entry from the database&lt;/li&gt; 
 &lt;li&gt;Add entry to cache&lt;/li&gt; 
 &lt;li&gt;Return entry&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def get_user(self, user_id):
    user = cache.get("user.{0}", user_id)
    if user is None:
        user = db.query("SELECT * FROM users WHERE user_id = {0}", user_id)
        if user is not None:
            key = "user.{0}".format(user_id)
            cache.set(key, json.dumps(user))
    return user
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://memcached.org/"&gt;Memcached&lt;/a&gt; is generally used in this manner.&lt;/p&gt; 
&lt;p&gt;Subsequent reads of data added to cache are fast. Cache-aside is also referred to as lazy loading. Only requested data is cached, which avoids filling up the cache with data that isn't requested.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): cache-aside&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Each cache miss results in three trips, which can cause a noticeable delay.&lt;/li&gt; 
 &lt;li&gt;Data can become stale if it is updated in the database. This issue is mitigated by setting a time-to-live (TTL) which forces an update of the cache entry, or by using write-through.&lt;/li&gt; 
 &lt;li&gt;When a node fails, it is replaced by a new, empty node, increasing latency.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-through&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/0vBc0hN.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application uses the cache as the main data store, reading and writing data to it, while the cache is responsible for reading and writing to the database:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Application adds/updates entry in cache&lt;/li&gt; 
 &lt;li&gt;Cache synchronously writes entry to data store&lt;/li&gt; 
 &lt;li&gt;Return&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Application code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;set_user(12345, {"foo":"bar"})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Cache code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def set_user(user_id, values):
    user = db.query("UPDATE Users WHERE id = {0}", user_id, values)
    cache.set(user_id, user)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Write-through is a slow overall operation due to the write operation, but subsequent reads of just written data are fast. Users are generally more tolerant of latency when updating data than reading data. Data in the cache is not stale.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): write through&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;When a new node is created due to failure or scaling, the new node will not cache entries until the entry is updated in the database. Cache-aside in conjunction with write through can mitigate this issue.&lt;/li&gt; 
 &lt;li&gt;Most data written might never be read, which can be minimized with a TTL.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-behind (write-back)&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/rgSrvjG.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In write-behind, the application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add/update entry in cache&lt;/li&gt; 
 &lt;li&gt;Asynchronously write entry to the data store, improving write performance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): write-behind&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There could be data loss if the cache goes down prior to its contents hitting the data store.&lt;/li&gt; 
 &lt;li&gt;It is more complex to implement write-behind than it is to implement cache-aside or write-through.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Refresh-ahead&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/kxtjqgE.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;You can configure the cache to automatically refresh any recently accessed cache entry prior to its expiration.&lt;/p&gt; 
&lt;p&gt;Refresh-ahead can result in reduced latency vs read-through if the cache can accurately predict which items are likely to be needed in the future.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): refresh-ahead&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not accurately predicting which items are likely to be needed in the future can result in reduced performance than without refresh-ahead.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): cache&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Need to maintain consistency between caches and the source of truth such as the database through &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms"&gt;cache invalidation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Cache invalidation is a difficult problem, there is additional complexity associated with when to update the cache.&lt;/li&gt; 
 &lt;li&gt;Need to make application changes such as adding Redis or memcached.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;From cache to in-memory data grid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Scalable system design patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/"&gt;Introduction to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Strategies.html"&gt;AWS ElastiCache strategies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Cache_(computing)"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Asynchronism&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/54GYsSx.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Asynchronous workflows help reduce request times for expensive operations that would otherwise be performed in-line. They can also help by doing time-consuming work in advance, such as periodic aggregation of data.&lt;/p&gt; 
&lt;h3&gt;Message queues&lt;/h3&gt; 
&lt;p&gt;Message queues receive, hold, and deliver messages. If an operation is too slow to perform inline, you can use a message queue with the following workflow:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;An application publishes a job to the queue, then notifies the user of job status&lt;/li&gt; 
 &lt;li&gt;A worker picks up the job from the queue, processes it, then signals the job is complete&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The user is not blocked and the job is processed in the background. During this time, the client might optionally do a small amount of processing to make it seem like the task has completed. For example, if posting a tweet, the tweet could be instantly posted to your timeline, but it could take some time before your tweet is actually delivered to all of your followers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://redis.io/"&gt;Redis&lt;/a&gt;&lt;/strong&gt; is useful as a simple message broker but messages can be lost.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt;&lt;/strong&gt; is popular but requires you to adapt to the 'AMQP' protocol and manage your own nodes.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/sqs/"&gt;Amazon SQS&lt;/a&gt;&lt;/strong&gt; is hosted but can have high latency and has the possibility of messages being delivered twice.&lt;/p&gt; 
&lt;h3&gt;Task queues&lt;/h3&gt; 
&lt;p&gt;Tasks queues receive tasks and their related data, runs them, then delivers their results. They can support scheduling and can be used to run computationally-intensive jobs in the background.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.celeryproject.org/en/stable/"&gt;Celery&lt;/a&gt;&lt;/strong&gt; has support for scheduling and primarily has python support.&lt;/p&gt; 
&lt;h3&gt;Back pressure&lt;/h3&gt; 
&lt;p&gt;If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance. &lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html"&gt;Back pressure&lt;/a&gt; can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue. Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later. Clients can retry the request at a later time, perhaps with &lt;a href="https://en.wikipedia.org/wiki/Exponential_backoff"&gt;exponential backoff&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): asynchronism&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use cases such as inexpensive calculations and realtime workflows might be better suited for synchronous operations, as introducing queues can add delays and complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1KRYH75wgy4"&gt;It's all a numbers game&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html"&gt;Applying back pressure when overloaded&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Little%27s_law"&gt;Little's law&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-a-message-queue-and-a-task-queue-Why-would-a-task-queue-require-a-message-broker-like-RabbitMQ-Redis-Celery-or-IronMQ-to-function"&gt;What is the difference between a message queue and a task queue?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/5KeocQs.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.escotal.com/osilayer.html"&gt;Source: OSI 7 layer model&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Hypertext transfer protocol (HTTP)&lt;/h3&gt; 
&lt;p&gt;HTTP is a method for encoding and transporting data between a client and a server. It is a request/response protocol: clients issue requests and servers issue responses with relevant content and completion status info about the request. HTTP is self-contained, allowing requests and responses to flow through many intermediate routers and servers that perform load balancing, caching, encryption, and compression.&lt;/p&gt; 
&lt;p&gt;A basic HTTP request consists of a verb (method) and a resource (endpoint). Below are common HTTP verbs:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Verb&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Idempotent*&lt;/th&gt; 
   &lt;th&gt;Safe&lt;/th&gt; 
   &lt;th&gt;Cacheable&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Reads a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;Creates a resource or trigger a process that handles data&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PUT&lt;/td&gt; 
   &lt;td&gt;Creates or replace a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PATCH&lt;/td&gt; 
   &lt;td&gt;Partially updates a resource&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DELETE&lt;/td&gt; 
   &lt;td&gt;Deletes a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Can be called many times without different outcomes.&lt;/p&gt; 
&lt;p&gt;HTTP is an application layer protocol relying on lower-level protocols such as &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: HTTP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/http/"&gt;What is HTTP?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-HTTP-protocol-and-TCP-protocol"&gt;Difference between HTTP and TCP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://laracasts.com/discuss/channels/general-discussion/whats-the-differences-between-put-and-patch?page=1"&gt;Difference between PUT and PATCH&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Transmission control protocol (TCP)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/JdAsdvG.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;TCP is a connection-oriented protocol over an &lt;a href="https://en.wikipedia.org/wiki/Internet_Protocol"&gt;IP network&lt;/a&gt;. Connection is established and terminated using a &lt;a href="https://en.wikipedia.org/wiki/Handshaking"&gt;handshake&lt;/a&gt;. All packets sent are guaranteed to reach the destination in the original order and without corruption through:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sequence numbers and &lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Checksum_computation"&gt;checksum fields&lt;/a&gt; for each packet&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)"&gt;Acknowledgement&lt;/a&gt; packets and automatic retransmission&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If the sender does not receive a correct response, it will resend the packets. If there are multiple timeouts, the connection is dropped. TCP also implements &lt;a href="https://en.wikipedia.org/wiki/Flow_control_(data)"&gt;flow control&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Network_congestion#Congestion_control"&gt;congestion control&lt;/a&gt;. These guarantees cause delays and generally result in less efficient transmission than UDP.&lt;/p&gt; 
&lt;p&gt;To ensure high throughput, web servers can keep a large number of TCP connections open, resulting in high memory usage. It can be expensive to have a large number of open connections between web server threads and say, a &lt;a href="https://memcached.org/"&gt;memcached&lt;/a&gt; server. &lt;a href="https://en.wikipedia.org/wiki/Connection_pool"&gt;Connection pooling&lt;/a&gt; can help in addition to switching to UDP where applicable.&lt;/p&gt; 
&lt;p&gt;TCP is useful for applications that require high reliability but are less time critical. Some examples include web servers, database info, SMTP, FTP, and SSH.&lt;/p&gt; 
&lt;p&gt;Use TCP over UDP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need all of the data to arrive intact&lt;/li&gt; 
 &lt;li&gt;You want to automatically make a best estimate use of the network throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User datagram protocol (UDP)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yzDrJtA.jpg" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;UDP is connectionless. Datagrams (analogous to packets) are guaranteed only at the datagram level. Datagrams might reach their destination out of order or not at all. UDP does not support congestion control. Without the guarantees that TCP support, UDP is generally more efficient.&lt;/p&gt; 
&lt;p&gt;UDP can broadcast, sending datagrams to all devices on the subnet. This is useful with &lt;a href="https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol"&gt;DHCP&lt;/a&gt; because the client has not yet received an IP address, thus preventing a way for TCP to stream without the IP address.&lt;/p&gt; 
&lt;p&gt;UDP is less reliable but works well in real time use cases such as VoIP, video chat, streaming, and realtime multiplayer games.&lt;/p&gt; 
&lt;p&gt;Use UDP over TCP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need the lowest latency&lt;/li&gt; 
 &lt;li&gt;Late data is worse than loss of data&lt;/li&gt; 
 &lt;li&gt;You want to implement your own error correction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: TCP and UDP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://gafferongames.com/networking-for-game-programmers/udp-vs-tcp/"&gt;Networking for game programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cyberciti.biz/faq/key-differences-between-tcp-and-udp-protocols/"&gt;Key differences between TCP and UDP protocols&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/5970383/difference-between-tcp-and-udp"&gt;Difference between TCP and UDP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol"&gt;Transmission control protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol"&gt;User datagram protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cs.bu.edu/~jappavoo/jappavoo.github.com/451/papers/memcache-fb.pdf"&gt;Scaling memcache at Facebook&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Remote procedure call (RPC)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/iF4Mkb5.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Source: Crack the system design interview&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In an RPC, a client causes a procedure to execute on a different address space, usually a remote server. The procedure is coded as if it were a local procedure call, abstracting away the details of how to communicate with the server from the client program. Remote calls are usually slower and less reliable than local calls so it is helpful to distinguish RPC calls from local calls. Popular RPC frameworks include &lt;a href="https://developers.google.com/protocol-buffers/"&gt;Protobuf&lt;/a&gt;, &lt;a href="https://thrift.apache.org/"&gt;Thrift&lt;/a&gt;, and &lt;a href="https://avro.apache.org/docs/current/"&gt;Avro&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;RPC is a request-response protocol:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Client program&lt;/strong&gt; - Calls the client stub procedure. The parameters are pushed onto the stack like a local procedure call.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client stub procedure&lt;/strong&gt; - Marshals (packs) procedure id and arguments into a request message.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client communication module&lt;/strong&gt; - OS sends the message from the client to the server.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server communication module&lt;/strong&gt; - OS passes the incoming packets to the server stub procedure.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server stub procedure&lt;/strong&gt; - Unmarshalls the results, calls the server procedure matching the procedure id and passes the given arguments.&lt;/li&gt; 
 &lt;li&gt;The server response repeats the steps above in reverse order.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample RPC calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someoperation?data=anId

POST /anotheroperation
{
  "data":"anId";
  "anotherdata": "another value"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RPC is focused on exposing behaviors. RPCs are often used for performance reasons with internal communications, as you can hand-craft native calls to better fit your use cases.&lt;/p&gt; 
&lt;p&gt;Choose a native library (aka SDK) when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You know your target platform.&lt;/li&gt; 
 &lt;li&gt;You want to control how your "logic" is accessed.&lt;/li&gt; 
 &lt;li&gt;You want to control how error control happens off your library.&lt;/li&gt; 
 &lt;li&gt;Performance and end user experience is your primary concern.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;HTTP APIs following &lt;strong&gt;REST&lt;/strong&gt; tend to be used more often for public APIs.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;RPC clients become tightly coupled to the service implementation.&lt;/li&gt; 
 &lt;li&gt;A new API must be defined for every new operation or use case.&lt;/li&gt; 
 &lt;li&gt;It can be difficult to debug RPC.&lt;/li&gt; 
 &lt;li&gt;You might not be able to leverage existing technologies out of the box. For example, it might require additional effort to ensure &lt;a href="https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/"&gt;RPC calls are properly cached&lt;/a&gt; on caching servers such as &lt;a href="http://www.squid-cache.org/"&gt;Squid&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Representational state transfer (REST)&lt;/h3&gt; 
&lt;p&gt;REST is an architectural style enforcing a client/server model where the client acts on a set of resources managed by the server. The server provides a representation of resources and actions that can either manipulate or get a new representation of resources. All communication must be stateless and cacheable.&lt;/p&gt; 
&lt;p&gt;There are four qualities of a RESTful interface:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Identify resources (URI in HTTP)&lt;/strong&gt; - use the same URI regardless of any operation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change with representations (Verbs in HTTP)&lt;/strong&gt; - use verbs, headers, and body.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-descriptive error message (status response in HTTP)&lt;/strong&gt; - Use status codes, don't reinvent the wheel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="http://restcookbook.com/Basics/hateoas/"&gt;HATEOAS&lt;/a&gt; (HTML interface for HTTP)&lt;/strong&gt; - your web service should be fully accessible in a browser.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample REST calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someresources/anId

PUT /someresources/anId
{"anotherdata": "another value"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;REST is focused on exposing data. It minimizes the coupling between client/server and is often used for public HTTP APIs. REST uses a more generic and uniform method of exposing resources through URIs, &lt;a href="https://github.com/for-GET/know-your-http-well/raw/master/headers.md"&gt;representation through headers&lt;/a&gt;, and actions through verbs such as GET, POST, PUT, DELETE, and PATCH. Being stateless, REST is great for horizontal scaling and partitioning.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): REST&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;With REST being focused on exposing data, it might not be a good fit if resources are not naturally organized or accessed in a simple hierarchy. For example, returning all updated records from the past hour matching a particular set of events is not easily expressed as a path. With REST, it is likely to be implemented with a combination of URI path, query parameters, and possibly the request body.&lt;/li&gt; 
 &lt;li&gt;REST typically relies on a few verbs (GET, POST, PUT, DELETE, and PATCH) which sometimes doesn't fit your use case. For example, moving expired documents to the archive folder might not cleanly fit within these verbs.&lt;/li&gt; 
 &lt;li&gt;Fetching complicated resources with nested hierarchies requires multiple round trips between the client and server to render single views, e.g. fetching content of a blog entry and the comments on that entry. For mobile applications operating in variable network conditions, these multiple roundtrips are highly undesirable.&lt;/li&gt; 
 &lt;li&gt;Over time, more fields might be added to an API response and older clients will receive all new data fields, even those that they do not need, as a result, it bloats the payload size and leads to larger latencies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RPC and REST calls comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operation&lt;/th&gt; 
   &lt;th&gt;RPC&lt;/th&gt; 
   &lt;th&gt;REST&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Resign&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /resign&lt;br /&gt;{&lt;br /&gt;"personid": "1234"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a person&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readPerson?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a person‚Äôs items list&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readUsersItemsList?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234/items&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an item to a person‚Äôs items&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /addItemToUsersItemsList&lt;br /&gt;{&lt;br /&gt;"personid": "1234";&lt;br /&gt;"itemid": "456"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons/1234/items&lt;br /&gt;{&lt;br /&gt;"itemid": "456"&lt;br /&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Update an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /modifyItem&lt;br /&gt;{&lt;br /&gt;"itemid": "456";&lt;br /&gt;"key": "value"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;PUT&lt;/strong&gt; /items/456&lt;br /&gt;{&lt;br /&gt;"key": "value"&lt;br /&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Delete an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /removeItem&lt;br /&gt;{&lt;br /&gt;"itemid": "456"&lt;br /&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /items/456&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p align="center"&gt; &lt;i&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/"&gt;Source: Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: REST and RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/"&gt;Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://programmers.stackexchange.com/a/181186"&gt;When are RPC-ish approaches more appropriate than REST?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/15056878/rest-vs-json-rpc"&gt;REST vs JSON-RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/"&gt;Debunking the myths of RPC and REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-are-the-drawbacks-of-using-RESTful-APIs"&gt;What are the drawbacks of using REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.facebook.com/posts/1468950976659943/"&gt;Thrift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://arstechnica.com/civis/viewtopic.php?t=1190508"&gt;Why REST for internal use and not RPC&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;This section could use some updates. Consider &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;contributing&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Security is a broad topic. Unless you have considerable experience, a security background, or are applying for a position that requires knowledge of security, you probably won't need to know more than the basics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Encrypt in transit and at rest.&lt;/li&gt; 
 &lt;li&gt;Sanitize all user inputs or any input parameters exposed to user to prevent &lt;a href="https://en.wikipedia.org/wiki/Cross-site_scripting"&gt;XSS&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/SQL_injection"&gt;SQL injection&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Use parameterized queries to prevent SQL injection.&lt;/li&gt; 
 &lt;li&gt;Use the principle of &lt;a href="https://en.wikipedia.org/wiki/Principle_of_least_privilege"&gt;least privilege&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shieldfy/API-Security-Checklist"&gt;API security checklist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FallibleInc/security-guide-for-developers"&gt;Security guide for developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.owasp.org/index.php/OWASP_Top_Ten_Cheat_Sheet"&gt;OWASP top ten&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Appendix&lt;/h2&gt; 
&lt;p&gt;You'll sometimes be asked to do 'back-of-the-envelope' estimates. For example, you might need to determine how long it will take to generate 100 image thumbnails from disk or how much memory a data structure will take. The &lt;strong&gt;Powers of two table&lt;/strong&gt; and &lt;strong&gt;Latency numbers every programmer should know&lt;/strong&gt; are handy references.&lt;/p&gt; 
&lt;h3&gt;Powers of two table&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Power           Exact Value         Approx Value        Bytes
---------------------------------------------------------------
7                             128
8                             256
10                           1024   1 thousand           1 KB
16                         65,536                       64 KB
20                      1,048,576   1 million            1 MB
30                  1,073,741,824   1 billion            1 GB
32                  4,294,967,296                        4 GB
40              1,099,511,627,776   1 trillion           1 TB
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Power_of_two"&gt;Powers of two&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Latency numbers every programmer should know&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Latency Comparison Numbers
--------------------------
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns                      14x L1 cache
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache
Compress 1K bytes with Zippy            10,000   ns       10 us
Send 1 KB bytes over 1 Gbps network     10,000   ns       10 us
Read 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD
Read 1 MB sequentially from memory     250,000   ns      250 us
Round trip within same datacenter      500,000   ns      500 us
Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory
HDD seek                            10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip
Read 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD
Read 1 MB sequentially from HDD     30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD
Send packet CA-&amp;gt;Netherlands-&amp;gt;CA    150,000,000   ns  150,000 us  150 ms

Notes
-----
1 ns = 10^-9 seconds
1 us = 10^-6 seconds = 1,000 ns
1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Handy metrics based on numbers above:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read sequentially from HDD at 30 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from 1 Gbps Ethernet at 100 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from SSD at 1 GB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from main memory at 4 GB/s&lt;/li&gt; 
 &lt;li&gt;6-7 world-wide round trips per second&lt;/li&gt; 
 &lt;li&gt;2,000 round trips per second within a data center&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Latency numbers visualized&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67" alt="" /&gt;&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/jboner/2841832"&gt;Latency numbers every programmer should know - 1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/hellerbarde/2843375"&gt;Latency numbers every programmer should know - 2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf"&gt;Designs, lessons, and advice from building large distributed systems&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf"&gt;Software Engineering Advice from Building Large-Scale Distributed Systems&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Additional system design interview questions&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions, with links to resources on how to solve each.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a file sync service like Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc"&gt;youtube.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a search engine like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://queue.acm.org/detail.cfm?id=988407"&gt;queue.acm.org&lt;/a&gt;&lt;br /&gt;&lt;a href="http://programmers.stackexchange.com/questions/38324/interview-question-how-would-you-implement-google-search"&gt;stackexchange.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://www.ardendertat.com/2012/01/11/implementing-search-engines/"&gt;ardendertat.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://infolab.stanford.edu/~backrub/google.html"&gt;stanford.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a scalable web crawler like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.quora.com/How-can-I-build-a-web-crawler-from-scratch"&gt;quora.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Google docs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://code.google.com/p/google-mobwrite/"&gt;code.google.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://neil.fraser.name/writing/sync/"&gt;neil.fraser.name&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store like Redis&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a cache system like Memcached&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a recommendation system like Amazon's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://web.archive.org/web/20170406065247/http://tech.hulu.com/blog/2011/09/19/recommendation-system.html"&gt;hulu.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://ijcai13.org/files/tutorial_slides/td3.pdf"&gt;ijcai13.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a tinyurl system like Bitly&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://n00tc0d3r.blogspot.com/"&gt;n00tc0d3r.blogspot.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat app like WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a picture sharing system like Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture"&gt;highscalability.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook news feed function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.quora.com/What-are-best-practices-for-building-something-like-a-News-Feed"&gt;quora.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://www.quora.com/Activity-Streams/What-are-the-scaling-issues-to-keep-in-mind-while-developing-a-social-network-feed"&gt;quora.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://www.slideshare.net/danmckinley/etsy-activity-feeds-architecture"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook timeline function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.facebook.com/note.php?note_id=10150468255628920"&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2012/1/23/facebook-timeline-brought-to-you-by-the-power-of-denormaliza.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook chat function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf"&gt;erlang-factory.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.facebook.com/note.php?note_id=14218138919&amp;amp;id=9445547199&amp;amp;index=0"&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a graph search function like Facebook's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-building-out-the-infrastructure-for-graph-search/10151347573598920"&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-indexing-and-ranking-in-graph-search/10151361720763920"&gt;facebook.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-the-natural-language-interface-of-graph-search/10151432733048920"&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a content delivery network like CloudFlare&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972"&gt;figshare.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a trending topic system like Twitter's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/"&gt;michael-noll.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/"&gt;snikolov .wordpress.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a random ID generation system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://blog.twitter.com/2010/announcing-snowflake"&gt;blog.twitter.com&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/twitter/snowflake/"&gt;github.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Return the top k requests during a time interval&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.cs.ucsb.edu/sites/default/files/documents/2005-23.pdf"&gt;cs.ucsb.edu&lt;/a&gt;&lt;br /&gt;&lt;a href="http://davis.wpi.edu/xmdv/docs/EDBT11-diyang.pdf"&gt;wpi.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that serves data from multiple data centers&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/24/how-google-serves-data-from-multiple-datacenters.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an online multiplayer card game&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://web.archive.org/web/20180929181117/http://www.indieflashblog.com/how-to-create-an-asynchronous-multiplayer-game.html"&gt;indieflashblog.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://buildnewgames.com/real-time-multiplayer/"&gt;buildnewgames.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a garbage collection system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/"&gt;stuffwithstuff.com&lt;/a&gt;&lt;br /&gt;&lt;a href="http://courses.cs.washington.edu/courses/csep521/07wi/prj/rick.pdf"&gt;washington.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an API rate limiter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://stripe.com/blog/rate-limiters"&gt;https://stripe.com/blog/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a Stock Exchange (like NASDAQ or Binance)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/b1e4t2k2KJY"&gt;Jane Street&lt;/a&gt;&lt;br /&gt;&lt;a href="https://around25.com/blog/building-a-trading-engine-for-a-crypto-exchange/"&gt;Golang Implementation&lt;/a&gt;&lt;br /&gt;&lt;a href="http://bhomnick.net/building-a-simple-limit-order-in-go/"&gt;Go Implementation&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Real world architectures&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Articles on how real world systems are designed.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/TcUo2fw.png" /&gt; &lt;br /&gt; &lt;i&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability"&gt;Source: Twitter timelines at scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Don't focus on nitty gritty details for the following articles, instead:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Identify shared principles, common technologies, and patterns within these articles&lt;/li&gt; 
 &lt;li&gt;Study what problems are solved by each component, where it works, where it doesn't&lt;/li&gt; 
 &lt;li&gt;Review the lessons learned&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MapReduce&lt;/strong&gt; - Distributed data processing from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/mapreduce-osdi04.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spark&lt;/strong&gt; - Distributed data processing from Databricks&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/AGrishchenko/apache-spark-architecture"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Storm&lt;/strong&gt; - Distributed data processing from Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/previa/storm-16094009"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Bigtable&lt;/strong&gt; - Distributed column-oriented database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;HBase&lt;/strong&gt; - Open source implementation of Bigtable&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/alexbaranau/intro-to-hbase"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Cassandra&lt;/strong&gt; - Distributed column-oriented database from Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/planetcassandra/cassandra-introduction-features-30103666"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DynamoDB&lt;/strong&gt; - Document-oriented database from Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MongoDB&lt;/strong&gt; - Document-oriented database&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/mdirolf/introduction-to-mongodb"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spanner&lt;/strong&gt; - Globally-distributed database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://research.google.com/archive/spanner-osdi2012.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Memcached&lt;/strong&gt; - Distributed memory caching system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt; - Distributed memory caching system with persistence and value types&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Google File System (GFS)&lt;/strong&gt; - Distributed file system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/gfs-sosp2003.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Hadoop File System (HDFS)&lt;/strong&gt; - Open source implementation of GFS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html"&gt;apache.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Chubby&lt;/strong&gt; - Lock service for loosely-coupled distributed systems from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/chubby-osdi06.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Dapper&lt;/strong&gt; - Distributed systems tracing infrastructure&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Kafka&lt;/strong&gt; - Pub/sub message queue from LinkedIn&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/mumrah/kafka-talk-tri-hug"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt; - Centralized infrastructure and services enabling synchronization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Add an architecture&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company architectures&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Company&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/amazon-architecture"&gt;Amazon architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cinchcast&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/7/16/cinchcast-architecture-producing-1500-hours-of-audio-every-d.html"&gt;Producing 1,500 hours of audio every day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DataSift&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/11/29/datasift-architecture-realtime-datamining-at-120000-tweets-p.html"&gt;Realtime datamining At 120,000 tweets per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc"&gt;How we've scaled Dropbox&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ESPN&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html"&gt;Operating At 100,000 duh nuh nuhs per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/google-architecture"&gt;Google architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html"&gt;14 million users, terabytes of photos&lt;/a&gt;&lt;br /&gt;&lt;a href="http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances"&gt;What powers Instagram&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Justin.tv&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/3/16/justintvs-live-video-broadcasting-architecture.html"&gt;Justin.Tv's live video broadcasting architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/key-value/fb-memcached-nsdi-2013.pdf"&gt;Scaling memcached at Facebook&lt;/a&gt;&lt;br /&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/data-store/tao-facebook-distributed-datastore-atc-2013.pdf"&gt;TAO: Facebook‚Äôs distributed data store for the social graph&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook‚Äôs photo storage&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2016/6/27/how-facebook-live-streams-to-800000-simultaneous-viewers.html"&gt;How Facebook Live Streams To 800,000 Simultaneous Viewers&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Flickr&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture"&gt;Flickr architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mailbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/6/18/scaling-mailbox-from-0-to-one-million-users-in-6-weeks-and-1.html"&gt;From 0 to one million users in 6 weeks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Netflix&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/11/9/a-360-degree-view-of-the-entire-netflix-stack.html"&gt;A 360 Degree View Of The Entire Netflix Stack&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2017/12/11/netflix-what-happens-when-you-press-play.html"&gt;Netflix: What Happens When You Press Play?&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pinterest&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html"&gt;From 0 To 10s of billions of page views a month&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html"&gt;18 million visitors, 10x growth, 12 employees&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Playfish&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/9/21/playfishs-social-gaming-architecture-50-million-monthly-user.html"&gt;50 million monthly users and growing&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PlentyOfFish&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/plentyoffish-architecture"&gt;PlentyOfFish architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Salesforce&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html"&gt;How they handle 1.3 billion transactions a day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Stack Overflow&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/5/stack-overflow-architecture.html"&gt;Stack Overflow architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TripAdvisor&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/6/27/tripadvisor-architecture-40m-visitors-200m-dynamic-page-view.html"&gt;40M visitors, 200M dynamic page views, 30TB data&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tumblr&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html"&gt;15 billion page views a month&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster"&gt;Making Twitter 10000 percent faster&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2011/12/19/how-twitter-stores-250-million-tweets-a-day-using-mysql.html"&gt;Storing 250 million tweets a day using MySQL&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html"&gt;150M active users, 300K QPS, a 22 MB/S firehose&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability"&gt;Timelines at scale&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.youtube.com/watch?v=5cKTP36HVgI"&gt;Big and small data at Twitter&lt;/a&gt;&lt;br /&gt;&lt;a href="https://www.youtube.com/watch?v=z8LU0Cj6BOU"&gt;Operations at Twitter: scaling beyond 100 million users&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2016/4/20/how-twitter-handles-3000-images-per-second.html"&gt;How Twitter Handles 3,000 Images Per Second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Uber&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/9/14/how-uber-scales-their-real-time-market-platform.html"&gt;How Uber scales their real-time market platform&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/blog/2016/10/12/lessons-learned-from-scaling-uber-to-2000-engineers-1000-ser.html"&gt;Lessons Learned From Scaling Uber To 2000 Engineers, 1000 Services, And 8000 Git Repositories&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html"&gt;The WhatsApp architecture Facebook bought for $19 billion&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;YouTube&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=w5WVu624fY8"&gt;YouTube scalability&lt;/a&gt;&lt;br /&gt;&lt;a href="http://highscalability.com/youtube-architecture"&gt;YouTube architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company engineering blogs&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Architectures for companies you are interviewing with.&lt;/p&gt; 
 &lt;p&gt;Questions you encounter might be from the same domain.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://nerds.airbnb.com/"&gt;Airbnb Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.atlassian.com/blog/"&gt;Atlassian Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/blogs/aws/"&gt;AWS Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://word.bitly.com/"&gt;Bitly Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.box.com/blog/category/engineering"&gt;Box Blogs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://blog.cloudera.com/"&gt;Cloudera Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tech.dropbox.com/"&gt;Dropbox Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/q/quoraengineering"&gt;Engineering at Quora&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.ebaytechblog.com/"&gt;Ebay Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.evernote.com/tech/"&gt;Evernote Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://codeascraft.com/"&gt;Etsy Code as Craft&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.facebook.com/Engineering"&gt;Facebook Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://code.flickr.net/"&gt;Flickr Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineering.foursquare.com/"&gt;Foursquare Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.blog/category/engineering"&gt;GitHub Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://googleresearch.blogspot.com/"&gt;Google Research Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.groupon.com/"&gt;Groupon Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.heroku.com/"&gt;Heroku Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://product.hubspot.com/blog/topic/engineering"&gt;Hubspot Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/"&gt;High Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://instagram-engineering.tumblr.com/"&gt;Instagram Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://software.intel.com/en-us/blogs/"&gt;Intel Software Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blogs.janestreet.com/category/ocaml/"&gt;Jane Street Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineering.linkedin.com/blog"&gt;LinkedIn Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.microsoft.com/"&gt;Microsoft Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blogs.msdn.microsoft.com/pythonengineering/"&gt;Microsoft Python Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://techblog.netflix.com/"&gt;Netflix Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/paypal-engineering"&gt;Paypal Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@Pinterest_Engineering"&gt;Pinterest Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.redditblog.com/"&gt;Reddit Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.salesforce.com/blogs/engineering/"&gt;Salesforce Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://slack.engineering/"&gt;Slack Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://labs.spotify.com/"&gt;Spotify Labs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://stripe.com/blog/engineering"&gt;Stripe Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.twilio.com/engineering"&gt;Twilio Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.twitter.com/engineering/"&gt;Twitter Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://eng.uber.com/"&gt;Uber Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://yahooeng.tumblr.com/"&gt;Yahoo Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineeringblog.yelp.com/"&gt;Yelp Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.zynga.com/blogs/engineering"&gt;Zynga Engineering Blog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;p&gt;Looking to add a blog? To avoid duplicating work, consider adding your company blog to the following repo:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kilimchoi/engineering-blogs"&gt;kilimchoi/engineering-blogs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Under development&lt;/h2&gt; 
&lt;p&gt;Interested in adding a section or helping complete one in-progress? &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Distributed computing with MapReduce&lt;/li&gt; 
 &lt;li&gt;Consistent hashing&lt;/li&gt; 
 &lt;li&gt;Scatter gather&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Credits and sources are provided throughout this repo.&lt;/p&gt; 
&lt;p&gt;Special thanks to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design/the-system-design-process/"&gt;Hired in tech&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/dp/0984782850/"&gt;Cracking the coding interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/"&gt;High scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/checkcheckzz/system-design-interview"&gt;checkcheckzz/system-design-interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shashank88/system_design"&gt;shashank88/system_design&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmcgrana/services-engineering"&gt;mmcgrana/services-engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/vasanthk/485d1c25737e8e72759f"&gt;System design cheat sheet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://dancres.github.io/Pages/"&gt;A distributed systems reading list&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Cracking the system design interview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact info&lt;/h2&gt; 
&lt;p&gt;Feel free to contact me to discuss any issues, questions, or comments.&lt;/p&gt; 
&lt;p&gt;My contact info can be found on my &lt;a href="https://github.com/donnemartin"&gt;GitHub page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;I am providing code and resources in this repository to you under an open source license. Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Copyright 2017 Donne Martin

Creative Commons Attribution 4.0 International License (CC BY 4.0)

http://creativecommons.org/licenses/by/4.0/
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>ruvnet/wifi-densepose</title>
      <link>https://github.com/ruvnet/wifi-densepose</link>
      <description>&lt;p&gt;Production-ready implementation of InvisPose - a revolutionary WiFi-based dense human pose estimation system that enables real-time full-body tracking through walls using commodity mesh routers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;WiFi DensePose&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/badge/python-3.8+-blue.svg?sanitize=true" alt="Python 3.8+" /&gt;&lt;/a&gt; &lt;a href="https://fastapi.tiangolo.com/"&gt;&lt;img src="https://img.shields.io/badge/FastAPI-0.95+-green.svg?sanitize=true" alt="FastAPI" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/wifi-densepose/"&gt;&lt;img src="https://img.shields.io/pypi/v/wifi-densepose.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/wifi-densepose/"&gt;&lt;img src="https://img.shields.io/pypi/dm/wifi-densepose.svg?sanitize=true" alt="PyPI downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ruvnet/wifi-densepose"&gt;&lt;img src="https://img.shields.io/badge/coverage-100%25-brightgreen.svg?sanitize=true" alt="Test Coverage" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/ruvnet/wifi-densepose"&gt;&lt;img src="https://img.shields.io/badge/docker-ready-blue.svg?sanitize=true" alt="Docker" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A cutting-edge WiFi-based human pose estimation system that leverages Channel State Information (CSI) data and advanced machine learning to provide real-time, privacy-preserving pose detection without cameras.&lt;/p&gt; 
&lt;h2&gt;üöÄ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy-First&lt;/strong&gt;: No cameras required - uses WiFi signals for pose detection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Processing&lt;/strong&gt;: Sub-50ms latency with 30 FPS pose estimation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Person Tracking&lt;/strong&gt;: Simultaneous tracking of up to 10 individuals&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Domain-Specific Optimization&lt;/strong&gt;: Healthcare, fitness, smart home, and security applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise-Ready&lt;/strong&gt;: Production-grade API with authentication, rate limiting, and monitoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hardware Agnostic&lt;/strong&gt;: Works with standard WiFi routers and access points&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive Analytics&lt;/strong&gt;: Fall detection, activity recognition, and occupancy monitoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WebSocket Streaming&lt;/strong&gt;: Real-time pose data streaming for live applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% Test Coverage&lt;/strong&gt;: Thoroughly tested with comprehensive test suite&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü¶Ä Rust Implementation (v2)&lt;/h2&gt; 
&lt;p&gt;A high-performance Rust port is available in &lt;code&gt;/rust-port/wifi-densepose-rs/&lt;/code&gt;:&lt;/p&gt; 
&lt;h3&gt;Performance Benchmarks (Validated)&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operation&lt;/th&gt; 
   &lt;th&gt;Python (v1)&lt;/th&gt; 
   &lt;th&gt;Rust (v2)&lt;/th&gt; 
   &lt;th&gt;Speedup&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CSI Preprocessing (4x64)&lt;/td&gt; 
   &lt;td&gt;~5ms&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;5.19 ¬µs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~1000x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phase Sanitization (4x64)&lt;/td&gt; 
   &lt;td&gt;~3ms&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;3.84 ¬µs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~780x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Feature Extraction (4x64)&lt;/td&gt; 
   &lt;td&gt;~8ms&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;9.03 ¬µs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~890x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Motion Detection&lt;/td&gt; 
   &lt;td&gt;~1ms&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;186 ns&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~5400x&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Full Pipeline&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~15ms&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;18.47 ¬µs&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~810x&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Throughput Metrics&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Throughput&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CSI Preprocessing&lt;/td&gt; 
   &lt;td&gt;49-66 Melem/s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Phase Sanitization&lt;/td&gt; 
   &lt;td&gt;67-85 Melem/s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Feature Extraction&lt;/td&gt; 
   &lt;td&gt;7-11 Melem/s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Full Pipeline&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;~54,000 fps&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Resource Comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Python (v1)&lt;/th&gt; 
   &lt;th&gt;Rust (v2)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Memory Usage&lt;/td&gt; 
   &lt;td&gt;~500MB&lt;/td&gt; 
   &lt;td&gt;~100MB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;WASM Support&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Binary Size&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;~10MB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Test Coverage&lt;/td&gt; 
   &lt;td&gt;100%&lt;/td&gt; 
   &lt;td&gt;107 tests&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Quick Start (Rust):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd rust-port/wifi-densepose-rs
cargo build --release
cargo test --workspace
cargo bench --package wifi-densepose-signal
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Validation Tests&lt;/h3&gt; 
&lt;p&gt;Mathematical correctness validated:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Phase unwrapping: 0.000000 radians max error&lt;/li&gt; 
 &lt;li&gt;‚úÖ Amplitude RMS: Exact match&lt;/li&gt; 
 &lt;li&gt;‚úÖ Doppler shift: 33.33 Hz (exact)&lt;/li&gt; 
 &lt;li&gt;‚úÖ Correlation: 1.0 for identical signals&lt;/li&gt; 
 &lt;li&gt;‚úÖ Phase coherence: 1.0 for coherent signals&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/rust-port/wifi-densepose-rs/docs/"&gt;Rust Port Documentation&lt;/a&gt; for ADRs and DDD patterns.&lt;/p&gt; 
&lt;h2&gt;üö® WiFi-Mat: Disaster Response Module&lt;/h2&gt; 
&lt;p&gt;A specialized extension for &lt;strong&gt;search and rescue operations&lt;/strong&gt; - detecting and localizing survivors trapped in rubble, earthquakes, and natural disasters.&lt;/p&gt; 
&lt;h3&gt;Key Capabilities&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Vital Signs Detection&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Breathing (4-60 BPM), heartbeat via micro-Doppler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;3D Localization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Position estimation through debris up to 5m depth&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;START Triage&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Automatic Immediate/Delayed/Minor/Deceased classification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Real-time Alerts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Priority-based notifications with escalation&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Use Cases&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Earthquake search and rescue&lt;/li&gt; 
 &lt;li&gt;Building collapse response&lt;/li&gt; 
 &lt;li&gt;Avalanche victim location&lt;/li&gt; 
 &lt;li&gt;Mine collapse detection&lt;/li&gt; 
 &lt;li&gt;Flood rescue operations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use wifi_densepose_mat::{DisasterResponse, DisasterConfig, DisasterType, ScanZone, ZoneBounds};

let config = DisasterConfig::builder()
    .disaster_type(DisasterType::Earthquake)
    .sensitivity(0.85)
    .max_depth(5.0)
    .build();

let mut response = DisasterResponse::new(config);
response.initialize_event(location, "Building collapse")?;
response.add_zone(ScanZone::new("North Wing", ZoneBounds::rectangle(0.0, 0.0, 30.0, 20.0)))?;
response.start_scanning().await?;

// Get survivors prioritized by triage status
let immediate = response.survivors_by_triage(TriageStatus::Immediate);
println!("{} survivors require immediate rescue", immediate.len());
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/wifi-mat-user-guide.md"&gt;WiFi-Mat User Guide&lt;/a&gt;&lt;/strong&gt; - Complete setup, configuration, and field deployment&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/adr/ADR-001-wifi-mat-disaster-detection.md"&gt;Architecture Decision Record&lt;/a&gt;&lt;/strong&gt; - Design decisions and rationale&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/ddd/wifi-mat-domain-model.md"&gt;Domain Model&lt;/a&gt;&lt;/strong&gt; - DDD bounded contexts and entities&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Build:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd rust-port/wifi-densepose-rs
cargo build --release --package wifi-densepose-mat
cargo test --package wifi-densepose-mat
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üìã Table of Contents&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;p&gt;&lt;strong&gt;üöÄ Getting Started&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-rust-implementation-v2"&gt;Rust Implementation (v2)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-wifi-mat-disaster-response-module"&gt;WiFi-Mat Disaster Response&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#%EF%B8%8F-system-architecture"&gt;System Architecture&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-installation"&gt;Installation&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#using-pip-recommended"&gt;Using pip (Recommended)&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#from-source"&gt;From Source&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#using-docker"&gt;Using Docker&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#system-requirements"&gt;System Requirements&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-quick-start"&gt;Quick Start&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#1-basic-setup"&gt;Basic Setup&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#2-start-the-system"&gt;Start the System&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#3-using-the-rest-api"&gt;Using the REST API&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#4-real-time-streaming"&gt;Real-time Streaming&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;üñ•Ô∏è Usage &amp;amp; Configuration&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#%EF%B8%8F-cli-usage"&gt;CLI Usage&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#cli-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#basic-commands"&gt;Basic Commands&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#configuration-commands"&gt;Configuration Commands&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#cli-examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-documentation"&gt;Documentation&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-core-documentation"&gt;Core Documentation&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-quick-links"&gt;Quick Links&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-api-overview"&gt;API Overview&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-hardware-setup"&gt;Hardware Setup&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#supported-hardware"&gt;Supported Hardware&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#physical-setup"&gt;Physical Setup&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#network-configuration"&gt;Network Configuration&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#environment-calibration"&gt;Environment Calibration&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;p&gt;&lt;strong&gt;‚öôÔ∏è Advanced Topics&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#%EF%B8%8F-configuration"&gt;Configuration&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#environment-variables"&gt;Environment Variables&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#domain-specific-configurations"&gt;Domain-Specific Configurations&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#advanced-configuration"&gt;Advanced Configuration&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-testing"&gt;Testing&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#running-tests"&gt;Running Tests&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#test-categories"&gt;Test Categories&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#mock-testing"&gt;Mock Testing&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#continuous-integration"&gt;Continuous Integration&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-deployment"&gt;Deployment&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#production-deployment"&gt;Production Deployment&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#infrastructure-as-code"&gt;Infrastructure as Code&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#monitoring-and-logging"&gt;Monitoring and Logging&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;üìä Performance &amp;amp; Community&lt;/strong&gt;&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-performance-metrics"&gt;Performance Metrics&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#benchmark-results"&gt;Benchmark Results&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#performance-optimization"&gt;Performance Optimization&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#load-testing"&gt;Load Testing&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-contributing"&gt;Contributing&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#development-setup"&gt;Development Setup&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#code-standards"&gt;Code Standards&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#contribution-process"&gt;Contribution Process&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#code-review-checklist"&gt;Code Review Checklist&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-acknowledgments"&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/#-support"&gt;Support&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;üèóÔ∏è System Architecture&lt;/h2&gt; 
&lt;p&gt;WiFi DensePose consists of several key components working together:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   WiFi Router   ‚îÇ    ‚îÇ   WiFi Router   ‚îÇ    ‚îÇ   WiFi Router   ‚îÇ
‚îÇ   (CSI Source)  ‚îÇ    ‚îÇ   (CSI Source)  ‚îÇ    ‚îÇ   (CSI Source)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                      ‚îÇ                      ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ     CSI Data Collector    ‚îÇ
                    ‚îÇ   (Hardware Interface)    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    Signal Processor       ‚îÇ
                    ‚îÇ  (Phase Sanitization)     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Neural Network Model    ‚îÇ
                    ‚îÇ    (DensePose Head)       ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Person Tracker          ‚îÇ
                    ‚îÇ  (Multi-Object Tracking)  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ                       ‚îÇ                       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   REST API        ‚îÇ   ‚îÇ  WebSocket API    ‚îÇ   ‚îÇ   Analytics       ‚îÇ
‚îÇ  (CRUD Operations)‚îÇ   ‚îÇ (Real-time Stream)‚îÇ   ‚îÇ  (Fall Detection) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Core Components&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CSI Processor&lt;/strong&gt;: Extracts and processes Channel State Information from WiFi signals&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Phase Sanitizer&lt;/strong&gt;: Removes hardware-specific phase offsets and noise&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DensePose Neural Network&lt;/strong&gt;: Converts CSI data to human pose keypoints&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Person Tracker&lt;/strong&gt;: Maintains consistent person identities across frames&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;REST API&lt;/strong&gt;: Comprehensive API for data access and system control&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WebSocket Streaming&lt;/strong&gt;: Real-time pose data broadcasting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Analytics Engine&lt;/strong&gt;: Advanced analytics including fall detection and activity recognition&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¶ Installation&lt;/h2&gt; 
&lt;h3&gt;Using pip (Recommended)&lt;/h3&gt; 
&lt;p&gt;WiFi-DensePose is now available on PyPI for easy installation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install the latest stable version
pip install wifi-densepose

# Install with specific version
pip install wifi-densepose==1.0.0

# Install with optional dependencies
pip install wifi-densepose[gpu]  # For GPU acceleration
pip install wifi-densepose[dev]  # For development
pip install wifi-densepose[all]  # All optional dependencies
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From Source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ruvnet/wifi-densepose.git
cd wifi-densepose
pip install -r requirements.txt
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ruvnet/wifi-densepose:latest
docker run -p 8000:8000 ruvnet/wifi-densepose:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;System Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt;: 3.8 or higher&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Operating System&lt;/strong&gt;: Linux (Ubuntu 18.04+), macOS (10.15+), Windows 10+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt;: Minimum 4GB RAM, Recommended 8GB+&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt;: 2GB free space for models and data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network&lt;/strong&gt;: WiFi interface with CSI capability&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPU&lt;/strong&gt;: Optional but recommended (NVIDIA GPU with CUDA support)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;h3&gt;1. Basic Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install the package
pip install wifi-densepose

# Copy example configuration
cp example.env .env

# Edit configuration (set your WiFi interface)
nano .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Start the System&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from wifi_densepose import WiFiDensePose

# Initialize with default configuration
system = WiFiDensePose()

# Start pose estimation
system.start()

# Get latest pose data
poses = system.get_latest_poses()
print(f"Detected {len(poses)} persons")

# Stop the system
system.stop()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Using the REST API&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start the API server
wifi-densepose start

# Start with custom configuration
wifi-densepose -c /path/to/config.yaml start

# Start with verbose logging
wifi-densepose -v start

# Check server status
wifi-densepose status
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The API will be available at &lt;code&gt;http://localhost:8000&lt;/code&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;API Documentation&lt;/strong&gt;: &lt;a href="http://localhost:8000/docs"&gt;http://localhost:8000/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Health Check&lt;/strong&gt;: &lt;a href="http://localhost:8000/api/v1/health"&gt;http://localhost:8000/api/v1/health&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Latest Poses&lt;/strong&gt;: &lt;a href="http://localhost:8000/api/v1/pose/latest"&gt;http://localhost:8000/api/v1/pose/latest&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. Real-time Streaming&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
import websockets
import json

async def stream_poses():
    uri = "ws://localhost:8000/ws/pose/stream"
    async with websockets.connect(uri) as websocket:
        while True:
            data = await websocket.recv()
            poses = json.loads(data)
            print(f"Received poses: {len(poses['persons'])} persons detected")

# Run the streaming client
asyncio.run(stream_poses())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üñ•Ô∏è CLI Usage&lt;/h2&gt; 
&lt;p&gt;WiFi DensePose provides a comprehensive command-line interface for easy system management, configuration, and monitoring.&lt;/p&gt; 
&lt;h3&gt;CLI Installation&lt;/h3&gt; 
&lt;p&gt;The CLI is automatically installed with the package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install WiFi DensePose with CLI
pip install wifi-densepose

# Verify CLI installation
wifi-densepose --help
wifi-densepose version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Basic Commands&lt;/h3&gt; 
&lt;p&gt;The WiFi-DensePose CLI provides the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wifi-densepose [OPTIONS] COMMAND [ARGS]...

Options:
  -c, --config PATH  Path to configuration file
  -v, --verbose      Enable verbose logging
  --debug            Enable debug mode
  --help             Show this message and exit.

Commands:
  config   Configuration management commands.
  db       Database management commands.
  start    Start the WiFi-DensePose API server.
  status   Show the status of the WiFi-DensePose API server.
  stop     Stop the WiFi-DensePose API server.
  tasks    Background task management commands.
  version  Show version information.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Server Management&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start the WiFi-DensePose API server
wifi-densepose start

# Start with custom configuration
wifi-densepose -c /path/to/config.yaml start

# Start with verbose logging
wifi-densepose -v start

# Start with debug mode
wifi-densepose --debug start

# Check server status
wifi-densepose status

# Stop the server
wifi-densepose stop

# Show version information
wifi-densepose version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration Commands&lt;/h3&gt; 
&lt;h4&gt;Configuration Management&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Configuration management commands
wifi-densepose config [SUBCOMMAND]

# Examples:
# Show current configuration
wifi-densepose config show

# Validate configuration file
wifi-densepose config validate

# Create default configuration
wifi-densepose config init

# Edit configuration
wifi-densepose config edit
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Database Management&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Database management commands
wifi-densepose db [SUBCOMMAND]

# Examples:
# Initialize database
wifi-densepose db init

# Run database migrations
wifi-densepose db migrate

# Check database status
wifi-densepose db status

# Backup database
wifi-densepose db backup

# Restore database
wifi-densepose db restore
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Background Tasks&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Background task management commands
wifi-densepose tasks [SUBCOMMAND]

# Examples:
# List running tasks
wifi-densepose tasks list

# Start background tasks
wifi-densepose tasks start

# Stop background tasks
wifi-densepose tasks stop

# Check task status
wifi-densepose tasks status
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Command Examples&lt;/h3&gt; 
&lt;h4&gt;Complete CLI Reference&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Show help for main command
wifi-densepose --help

# Show help for specific command
wifi-densepose start --help
wifi-densepose config --help
wifi-densepose db --help

# Use global options with commands
wifi-densepose -v status          # Verbose status check
wifi-densepose --debug start      # Start with debug logging
wifi-densepose -c custom.yaml start  # Start with custom config
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Common Usage Patterns&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic server lifecycle
wifi-densepose start              # Start the server
wifi-densepose status             # Check if running
wifi-densepose stop               # Stop the server

# Configuration management
wifi-densepose config show        # View current config
wifi-densepose config validate    # Check config validity

# Database operations
wifi-densepose db init            # Initialize database
wifi-densepose db migrate         # Run migrations
wifi-densepose db status          # Check database health

# Task management
wifi-densepose tasks list         # List background tasks
wifi-densepose tasks status       # Check task status

# Version and help
wifi-densepose version            # Show version info
wifi-densepose --help             # Show help message
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;CLI Examples&lt;/h3&gt; 
&lt;h4&gt;Complete Setup Workflow&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Check version and help
wifi-densepose version
wifi-densepose --help

# 2. Initialize configuration
wifi-densepose config init

# 3. Initialize database
wifi-densepose db init

# 4. Start the server
wifi-densepose start

# 5. Check status
wifi-densepose status
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Development Workflow&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with debug logging
wifi-densepose --debug start

# Use custom configuration
wifi-densepose -c dev-config.yaml start

# Check database status
wifi-densepose db status

# Manage background tasks
wifi-densepose tasks start
wifi-densepose tasks list
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Production Workflow&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with production config
wifi-densepose -c production.yaml start

# Check system status
wifi-densepose status

# Manage database
wifi-densepose db migrate
wifi-densepose db backup

# Monitor tasks
wifi-densepose tasks status
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Troubleshooting&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Enable verbose logging
wifi-densepose -v status

# Check configuration
wifi-densepose config validate

# Check database health
wifi-densepose db status

# Restart services
wifi-densepose stop
wifi-densepose start
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;p&gt;Comprehensive documentation is available to help you get started and make the most of WiFi-DensePose:&lt;/p&gt; 
&lt;h3&gt;üìñ Core Documentation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/user_guide.md"&gt;User Guide&lt;/a&gt;&lt;/strong&gt; - Complete guide covering installation, setup, basic usage, and examples&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/api_reference.md"&gt;API Reference&lt;/a&gt;&lt;/strong&gt; - Detailed documentation of all public classes, methods, and endpoints&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/deployment.md"&gt;Deployment Guide&lt;/a&gt;&lt;/strong&gt; - Production deployment, Docker setup, Kubernetes, and scaling strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/troubleshooting.md"&gt;Troubleshooting Guide&lt;/a&gt;&lt;/strong&gt; - Common issues, solutions, and diagnostic procedures&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üöÄ Quick Links&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive API Docs&lt;/strong&gt;: &lt;a href="http://localhost:8000/docs"&gt;http://localhost:8000/docs&lt;/a&gt; (when running)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Health Check&lt;/strong&gt;: &lt;a href="http://localhost:8000/api/v1/health"&gt;http://localhost:8000/api/v1/health&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Latest Poses&lt;/strong&gt;: &lt;a href="http://localhost:8000/api/v1/pose/latest"&gt;http://localhost:8000/api/v1/pose/latest&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;System Status&lt;/strong&gt;: &lt;a href="http://localhost:8000/api/v1/system/status"&gt;http://localhost:8000/api/v1/system/status&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìã API Overview&lt;/h3&gt; 
&lt;p&gt;The system provides a comprehensive REST API and WebSocket streaming:&lt;/p&gt; 
&lt;h4&gt;Key REST Endpoints&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Pose estimation
GET /api/v1/pose/latest          # Get latest pose data
GET /api/v1/pose/history         # Get historical data
GET /api/v1/pose/zones/{zone_id} # Get zone-specific data

# System management
GET /api/v1/system/status        # System health and status
POST /api/v1/system/calibrate    # Calibrate environment
GET /api/v1/analytics/summary    # Analytics dashboard data
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;WebSocket Streaming&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;// Real-time pose data
ws://localhost:8000/ws/pose/stream

// Analytics events (falls, alerts)
ws://localhost:8000/ws/analytics/events

// System status updates
ws://localhost:8000/ws/system/status
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Python SDK Quick Example&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from wifi_densepose import WiFiDensePoseClient

# Initialize client
client = WiFiDensePoseClient(base_url="http://localhost:8000")

# Get latest poses with confidence filtering
poses = client.get_latest_poses(min_confidence=0.7)
print(f"Detected {len(poses)} persons")

# Get zone occupancy
occupancy = client.get_zone_occupancy("living_room")
print(f"Living room occupancy: {occupancy.person_count}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For complete API documentation with examples, see the &lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/api_reference.md"&gt;API Reference Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üîß Hardware Setup&lt;/h2&gt; 
&lt;h3&gt;Supported Hardware&lt;/h3&gt; 
&lt;p&gt;WiFi DensePose works with standard WiFi equipment that supports CSI extraction:&lt;/p&gt; 
&lt;h4&gt;Recommended Routers&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ASUS AX6000&lt;/strong&gt; (RT-AX88U) - Excellent CSI quality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Netgear Nighthawk AX12&lt;/strong&gt; - High performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TP-Link Archer AX73&lt;/strong&gt; - Budget-friendly option&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ubiquiti UniFi 6 Pro&lt;/strong&gt; - Enterprise grade&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;CSI-Capable Devices&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Intel WiFi cards (5300, 7260, 8260, 9260)&lt;/li&gt; 
 &lt;li&gt;Atheros AR9300 series&lt;/li&gt; 
 &lt;li&gt;Broadcom BCM4366 series&lt;/li&gt; 
 &lt;li&gt;Qualcomm QCA9984 series&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Physical Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Router Placement&lt;/strong&gt;: Position routers to create overlapping coverage areas&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Height&lt;/strong&gt;: Mount routers 2-3 meters high for optimal coverage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Spacing&lt;/strong&gt;: 5-10 meter spacing between routers depending on environment&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Orientation&lt;/strong&gt;: Ensure antennas are positioned for maximum signal diversity&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Network Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Configure WiFi interface for CSI extraction
sudo iwconfig wlan0 mode monitor
sudo iwconfig wlan0 channel 6

# Set up CSI extraction (Intel 5300 example)
echo 0x4101 | sudo tee /sys/kernel/debug/ieee80211/phy0/iwlwifi/iwldvm/debug/monitor_tx_rate
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Environment Calibration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from wifi_densepose import Calibrator

# Run environment calibration
calibrator = Calibrator()
calibrator.calibrate_environment(
    duration_minutes=10,
    environment_id="room_001"
)

# Apply calibration
calibrator.apply_calibration()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚öôÔ∏è Configuration&lt;/h2&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;Copy &lt;code&gt;example.env&lt;/code&gt; to &lt;code&gt;.env&lt;/code&gt; and configure:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Application Settings
APP_NAME=WiFi-DensePose API
VERSION=1.0.0
ENVIRONMENT=production  # development, staging, production
DEBUG=false

# Server Settings
HOST=0.0.0.0
PORT=8000
WORKERS=4

# Security Settings
SECRET_KEY=your-secure-secret-key-here
JWT_ALGORITHM=HS256
JWT_EXPIRE_HOURS=24

# Hardware Settings
WIFI_INTERFACE=wlan0
CSI_BUFFER_SIZE=1000
HARDWARE_POLLING_INTERVAL=0.1

# Pose Estimation Settings
POSE_CONFIDENCE_THRESHOLD=0.7
POSE_PROCESSING_BATCH_SIZE=32
POSE_MAX_PERSONS=10

# Feature Flags
ENABLE_AUTHENTICATION=true
ENABLE_RATE_LIMITING=true
ENABLE_WEBSOCKETS=true
ENABLE_REAL_TIME_PROCESSING=true
ENABLE_HISTORICAL_DATA=true
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Domain-Specific Configurations&lt;/h3&gt; 
&lt;h4&gt;Healthcare Configuration&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;config = {
    "domain": "healthcare",
    "detection": {
        "confidence_threshold": 0.8,
        "max_persons": 5,
        "enable_tracking": True
    },
    "analytics": {
        "enable_fall_detection": True,
        "enable_activity_recognition": True,
        "alert_thresholds": {
            "fall_confidence": 0.9,
            "inactivity_timeout": 300
        }
    },
    "privacy": {
        "data_retention_days": 30,
        "anonymize_data": True,
        "enable_encryption": True
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Fitness Configuration&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;config = {
    "domain": "fitness",
    "detection": {
        "confidence_threshold": 0.6,
        "max_persons": 20,
        "enable_tracking": True
    },
    "analytics": {
        "enable_activity_recognition": True,
        "enable_form_analysis": True,
        "metrics": ["rep_count", "form_score", "intensity"]
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from wifi_densepose.config import Settings

# Load custom configuration
settings = Settings(
    pose_model_path="/path/to/custom/model.pth",
    neural_network={
        "batch_size": 64,
        "enable_gpu": True,
        "inference_timeout": 500
    },
    tracking={
        "max_age": 30,
        "min_hits": 3,
        "iou_threshold": 0.3
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üß™ Testing&lt;/h2&gt; 
&lt;p&gt;WiFi DensePose maintains 100% test coverage with comprehensive testing:&lt;/p&gt; 
&lt;h3&gt;Running Tests&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run all tests
pytest

# Run with coverage report
pytest --cov=wifi_densepose --cov-report=html

# Run specific test categories
pytest tests/unit/          # Unit tests
pytest tests/integration/   # Integration tests
pytest tests/e2e/          # End-to-end tests
pytest tests/performance/  # Performance tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Test Categories&lt;/h3&gt; 
&lt;h4&gt;Unit Tests (95% coverage)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;CSI processing algorithms&lt;/li&gt; 
 &lt;li&gt;Neural network components&lt;/li&gt; 
 &lt;li&gt;Tracking algorithms&lt;/li&gt; 
 &lt;li&gt;API endpoints&lt;/li&gt; 
 &lt;li&gt;Configuration validation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Integration Tests&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hardware interface integration&lt;/li&gt; 
 &lt;li&gt;Database operations&lt;/li&gt; 
 &lt;li&gt;WebSocket connections&lt;/li&gt; 
 &lt;li&gt;Authentication flows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;End-to-End Tests&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Complete pose estimation pipeline&lt;/li&gt; 
 &lt;li&gt;Multi-person tracking scenarios&lt;/li&gt; 
 &lt;li&gt;Real-time streaming&lt;/li&gt; 
 &lt;li&gt;Analytics generation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Performance Tests&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Latency benchmarks&lt;/li&gt; 
 &lt;li&gt;Throughput testing&lt;/li&gt; 
 &lt;li&gt;Memory usage profiling&lt;/li&gt; 
 &lt;li&gt;Stress testing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Mock Testing&lt;/h3&gt; 
&lt;p&gt;For development without hardware:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Enable mock mode
export MOCK_HARDWARE=true
export MOCK_POSE_DATA=true

# Run tests with mocked hardware
pytest tests/ --mock-hardware
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Continuous Integration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# .github/workflows/test.yml
name: Test Suite
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -e .
      - name: Run tests
        run: pytest --cov=wifi_densepose --cov-report=xml
      - name: Upload coverage
        uses: codecov/codecov-action@v1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üöÄ Deployment&lt;/h2&gt; 
&lt;h3&gt;Production Deployment&lt;/h3&gt; 
&lt;h4&gt;Using Docker&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build production image
docker build -t wifi-densepose:latest .

# Run with production configuration
docker run -d \
  --name wifi-densepose \
  -p 8000:8000 \
  -v /path/to/data:/app/data \
  -v /path/to/models:/app/models \
  -e ENVIRONMENT=production \
  -e SECRET_KEY=your-secure-key \
  wifi-densepose:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using Docker Compose&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# docker-compose.yml
version: '3.8'
services:
  wifi-densepose:
    image: wifi-densepose:latest
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=postgresql://user:pass@db:5432/wifi_densepose
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./data:/app/data
      - ./models:/app/models
    depends_on:
      - db
      - redis

  db:
    image: postgres:13
    environment:
      POSTGRES_DB: wifi_densepose
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:6-alpine
    volumes:
      - redis_data:/data

volumes:
  postgres_data:
  redis_data:
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Kubernetes Deployment&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wifi-densepose
spec:
  replicas: 3
  selector:
    matchLabels:
      app: wifi-densepose
  template:
    metadata:
      labels:
        app: wifi-densepose
    spec:
      containers:
      - name: wifi-densepose
        image: wifi-densepose:latest
        ports:
        - containerPort: 8000
        env:
        - name: ENVIRONMENT
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: wifi-densepose-secrets
              key: database-url
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Infrastructure as Code&lt;/h3&gt; 
&lt;h4&gt;Terraform (AWS)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-hcl"&gt;# terraform/main.tf
resource "aws_ecs_cluster" "wifi_densepose" {
  name = "wifi-densepose"
}

resource "aws_ecs_service" "wifi_densepose" {
  name            = "wifi-densepose"
  cluster         = aws_ecs_cluster.wifi_densepose.id
  task_definition = aws_ecs_task_definition.wifi_densepose.arn
  desired_count   = 3

  load_balancer {
    target_group_arn = aws_lb_target_group.wifi_densepose.arn
    container_name   = "wifi-densepose"
    container_port   = 8000
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Ansible Playbook&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# ansible/playbook.yml
- hosts: servers
  become: yes
  tasks:
    - name: Install Docker
      apt:
        name: docker.io
        state: present

    - name: Deploy WiFi DensePose
      docker_container:
        name: wifi-densepose
        image: wifi-densepose:latest
        ports:
          - "8000:8000"
        env:
          ENVIRONMENT: production
          DATABASE_URL: "{{ database_url }}"
        restart_policy: always
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Monitoring and Logging&lt;/h3&gt; 
&lt;h4&gt;Prometheus Metrics&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# monitoring/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'wifi-densepose'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/metrics'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Grafana Dashboard&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "dashboard": {
    "title": "WiFi DensePose Monitoring",
    "panels": [
      {
        "title": "Pose Detection Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(pose_detections_total[5m])"
          }
        ]
      },
      {
        "title": "Processing Latency",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, pose_processing_duration_seconds_bucket)"
          }
        ]
      }
    ]
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üìä Performance Metrics&lt;/h2&gt; 
&lt;h3&gt;Benchmark Results&lt;/h3&gt; 
&lt;h4&gt;Latency Performance&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Average Processing Time&lt;/strong&gt;: 45.2ms per frame&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;95th Percentile&lt;/strong&gt;: 67ms&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;99th Percentile&lt;/strong&gt;: 89ms&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time Capability&lt;/strong&gt;: 30 FPS sustained&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Accuracy Metrics&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pose Detection Accuracy&lt;/strong&gt;: 94.2% (compared to camera-based systems)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Person Tracking Accuracy&lt;/strong&gt;: 91.8%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fall Detection Sensitivity&lt;/strong&gt;: 96.5%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fall Detection Specificity&lt;/strong&gt;: 94.1%&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Resource Usage&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CPU Usage&lt;/strong&gt;: 65% (4-core system)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory Usage&lt;/strong&gt;: 2.1GB RAM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPU Usage&lt;/strong&gt;: 78% (NVIDIA RTX 3080)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network Bandwidth&lt;/strong&gt;: 15 Mbps (CSI data)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Scalability&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Maximum Concurrent Users&lt;/strong&gt;: 1000+ WebSocket connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Throughput&lt;/strong&gt;: 10,000 requests/minute&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Storage&lt;/strong&gt;: 50GB/month (with compression)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Environment Support&lt;/strong&gt;: Up to 50 simultaneous environments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Optimization&lt;/h3&gt; 
&lt;h4&gt;Hardware Optimization&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Enable GPU acceleration
config = {
    "neural_network": {
        "enable_gpu": True,
        "batch_size": 64,
        "mixed_precision": True
    },
    "processing": {
        "num_workers": 4,
        "prefetch_factor": 2
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Software Optimization&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Enable performance optimizations
config = {
    "caching": {
        "enable_redis": True,
        "cache_ttl": 300
    },
    "database": {
        "connection_pool_size": 20,
        "enable_query_cache": True
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Load Testing&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# API load testing with Apache Bench
ab -n 10000 -c 100 http://localhost:8000/api/v1/pose/latest

# WebSocket load testing
python scripts/websocket_load_test.py --connections 1000 --duration 300
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to WiFi DensePose! Please follow these guidelines:&lt;/p&gt; 
&lt;h3&gt;Development Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/ruvnet/wifi-densepose.git
cd wifi-densepose

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install development dependencies
pip install -r requirements-dev.txt
pip install -e .

# Install pre-commit hooks
pre-commit install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python Style&lt;/strong&gt;: Follow PEP 8, enforced by Black and Flake8&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type Hints&lt;/strong&gt;: Use type hints for all functions and methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Comprehensive docstrings for all public APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing&lt;/strong&gt;: Maintain 100% test coverage for new code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: Follow OWASP guidelines for security&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork&lt;/strong&gt; the repository&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; a feature branch (&lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit&lt;/strong&gt; your changes (&lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push&lt;/strong&gt; to the branch (&lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open&lt;/strong&gt; a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Code Review Checklist&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Code follows style guidelines&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Tests pass and coverage is maintained&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Documentation is updated&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Security considerations addressed&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Performance impact assessed&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Backward compatibility maintained&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Issue Templates&lt;/h3&gt; 
&lt;h4&gt;Bug Report&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;**Describe the bug**
A clear description of the bug.

**To Reproduce**
Steps to reproduce the behavior.

**Expected behavior**
What you expected to happen.

**Environment**
- OS: [e.g., Ubuntu 20.04]
- Python version: [e.g., 3.8.10]
- WiFi DensePose version: [e.g., 1.0.0]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Feature Request&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;**Feature Description**
A clear description of the feature.

**Use Case**
Describe the use case and benefits.

**Implementation Ideas**
Any ideas on how to implement this feature.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MIT License

Copyright (c) 2025 WiFi DensePose Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Research Foundation&lt;/strong&gt;: Based on groundbreaking research in WiFi-based human sensing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source Libraries&lt;/strong&gt;: Built on PyTorch, FastAPI, and other excellent open source projects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community&lt;/strong&gt;: Thanks to all contributors and users who make this project possible&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Hardware Partners&lt;/strong&gt;: Special thanks to router manufacturers for CSI support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìû Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/user_guide.md"&gt;User Guide&lt;/a&gt; - Complete setup and usage guide&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/api_reference.md"&gt;API Reference&lt;/a&gt; - Detailed API documentation&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/deployment.md"&gt;Deployment Guide&lt;/a&gt; - Production deployment instructions&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ruvnet/wifi-densepose/main/docs/troubleshooting.md"&gt;Troubleshooting Guide&lt;/a&gt; - Common issues and solutions&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: &lt;a href="https://github.com/ruvnet/wifi-densepose/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discussions&lt;/strong&gt;: &lt;a href="https://github.com/ruvnet/wifi-densepose/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PyPI Package&lt;/strong&gt;: &lt;a href="https://pypi.org/project/wifi-densepose/"&gt;https://pypi.org/project/wifi-densepose/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Email&lt;/strong&gt;: &lt;a href="mailto:support@wifi-densepose.com"&gt;support@wifi-densepose.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: &lt;a href="https://discord.gg/wifi-densepose"&gt;Join our community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;WiFi DensePose&lt;/strong&gt; - Revolutionizing human pose estimation through privacy-preserving WiFi technology.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>xai-org/grok-1</title>
      <link>https://github.com/xai-org/grok-1</link>
      <description>&lt;p&gt;Grok open release&lt;/p&gt;&lt;hr&gt;</description>
    </item>
    
  </channel>
</rss>