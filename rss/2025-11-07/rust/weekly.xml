<rss version="2.0">
  <channel>
    <title>GitHub Rust Weekly Trending</title>
    <description>Weekly Trending of Rust in GitHub</description>
    <pubDate>Thu, 06 Nov 2025 01:52:31 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>block/goose</title>
      <link>https://github.com/block/goose</link>
      <description>&lt;p&gt;an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;goose&lt;/h1&gt; 
 &lt;p&gt;&lt;em&gt;a local, extensible, open source AI agent that automates engineering tasks&lt;/em&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt; &lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/goose-oss"&gt; &lt;img src="https://img.shields.io/discord/1287729918100246654?logo=discord&amp;amp;logoColor=white&amp;amp;label=Join+Us&amp;amp;color=blueviolet" alt="Discord" /&gt; &lt;/a&gt; &lt;a href="https://github.com/block/goose/actions/workflows/ci.yml"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main" alt="CI" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - &lt;em&gt;autonomously&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;Whether you're prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.&lt;/p&gt; 
&lt;p&gt;Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/D-DpDunrbpo"&gt;&lt;img src="https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a" alt="Watch the video" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Quick Links&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/quickstart"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/getting-started/installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/category/tutorials"&gt;Tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/category/getting-started"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/block/goose/raw/main/HOWTOAI.md"&gt;Responsible AI-Assisted Coding Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/block/goose/raw/main/GOVERNANCE.md"&gt;Governance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Need Help?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting"&gt;Diagnostics &amp;amp; Reporting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://block.github.io/goose/docs/troubleshooting/known-issues"&gt;Known Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;a little goose humor ü¶¢&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Why did the developer choose goose as their AI agent?&lt;/p&gt; 
 &lt;p&gt;Because it always helps them "migrate" their code to production! üöÄ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;goose around with us&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/goose-oss"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@goose-oss"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linkedin.com/company/goose-oss"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/goose_oss"&gt;Twitter/X&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bsky.app/profile/opensource.block.xyz"&gt;Bluesky&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://njump.me/opensource@block.xyz"&gt;Nostr&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>astral-sh/uv</title>
      <link>https://github.com/astral-sh/uv</link>
      <description>&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;uv&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json" alt="uv" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/v/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/l/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv/actions"&gt;&lt;img src="https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Actions status" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/astral-sh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d" /&gt; 
  &lt;img alt="Shows a bar chart with benchmark results." src="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Installing &lt;a href="https://trio.readthedocs.io/"&gt;Trio&lt;/a&gt;'s dependencies with a warm cache.&lt;/i&gt; &lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ A single tool to replace &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, &lt;code&gt;pipx&lt;/code&gt;, &lt;code&gt;poetry&lt;/code&gt;, &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;twine&lt;/code&gt;, &lt;code&gt;virtualenv&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;‚ö°Ô∏è &lt;a href="https://github.com/astral-sh/uv/raw/main/BENCHMARKS.md"&gt;10-100x faster&lt;/a&gt; than &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;üóÇÔ∏è Provides &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#projects"&gt;comprehensive project management&lt;/a&gt;, with a &lt;a href="https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile"&gt;universal lockfile&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;‚ùáÔ∏è &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#scripts"&gt;Runs scripts&lt;/a&gt;, with support for &lt;a href="https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies"&gt;inline dependency metadata&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üêç &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#python-versions"&gt;Installs and manages&lt;/a&gt; Python versions.&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#tools"&gt;Runs and installs&lt;/a&gt; tools published as Python packages.&lt;/li&gt; 
 &lt;li&gt;üî© Includes a &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#the-pip-interface"&gt;pip-compatible interface&lt;/a&gt; for a performance boost with a familiar CLI.&lt;/li&gt; 
 &lt;li&gt;üè¢ Supports Cargo-style &lt;a href="https://docs.astral.sh/uv/concepts/projects/workspaces"&gt;workspaces&lt;/a&gt; for scalable projects.&lt;/li&gt; 
 &lt;li&gt;üíæ Disk-space efficient, with a &lt;a href="https://docs.astral.sh/uv/concepts/cache"&gt;global cache&lt;/a&gt; for dependency deduplication.&lt;/li&gt; 
 &lt;li&gt;‚è¨ Installable without Rust or Python via &lt;code&gt;curl&lt;/code&gt; or &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è Supports macOS, Linux, and Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;uv is backed by &lt;a href="https://astral.sh"&gt;Astral&lt;/a&gt;, the creators of &lt;a href="https://github.com/astral-sh/ruff"&gt;Ruff&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install uv with our standalone installers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On Windows.
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, from &lt;a href="https://pypi.org/project/uv/"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# With pip.
pip install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Or pipx.
pipx install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If installed via the standalone installer, uv can update itself to the latest version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv self update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;installation documentation&lt;/a&gt; for details and alternative installation methods.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;uv's documentation is available at &lt;a href="https://docs.astral.sh/uv"&gt;docs.astral.sh/uv&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, the command line reference documentation can be viewed with &lt;code&gt;uv help&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Projects&lt;/h3&gt; 
&lt;p&gt;uv manages project dependencies and environments, with support for lockfiles, workspaces, and more, similar to &lt;code&gt;rye&lt;/code&gt; or &lt;code&gt;poetry&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/projects/"&gt;project documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;uv also supports building and publishing projects, even if they're not managed with uv. See the &lt;a href="https://docs.astral.sh/uv/guides/publish/"&gt;publish guide&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h3&gt;Scripts&lt;/h3&gt; 
&lt;p&gt;uv manages dependencies and environments for single-file scripts.&lt;/p&gt; 
&lt;p&gt;Create a new script and add inline metadata declaring its dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ echo 'import requests; print(requests.get("https://astral.sh"))' &amp;gt; example.py

$ uv add --script example.py requests
Updated `example.py`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, run the script in an isolated virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&amp;lt;Response [200]&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/scripts/"&gt;scripts documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;uv executes and installs command-line tools provided by Python packages, similar to &lt;code&gt;pipx&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Run a tool in an ephemeral environment using &lt;code&gt;uvx&lt;/code&gt; (an alias for &lt;code&gt;uv tool run&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uvx pycowsay 'hello world!'
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  """

  ------------
&amp;lt; hello world! &amp;gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install a tool with &lt;code&gt;uv tool install&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/tools/"&gt;tools documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Python versions&lt;/h3&gt; 
&lt;p&gt;uv installs Python and allows quickly switching between versions.&lt;/p&gt; 
&lt;p&gt;Install multiple Python versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download Python versions as needed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&amp;gt;&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use a specific Python version in the current directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python pin 3.11
Pinned `.python-version` to `3.11`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/install-python/"&gt;Python installation documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;The pip interface&lt;/h3&gt; 
&lt;p&gt;uv provides a drop-in replacement for common &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, and &lt;code&gt;virtualenv&lt;/code&gt; commands.&lt;/p&gt; 
&lt;p&gt;uv extends their interfaces with advanced features, such as dependency version overrides, platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and more.&lt;/p&gt; 
&lt;p&gt;Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the &lt;code&gt;uv pip&lt;/code&gt; interface.&lt;/p&gt; 
&lt;p&gt;Compile requirements into a platform-independent requirements file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the locked requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/pip/index/"&gt;pip interface documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/platforms/"&gt;platform support&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Versioning policy&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/versioning/"&gt;versioning policy&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We are passionate about supporting contributors of all levels of experience and would love to see you get involved in the project. See the &lt;a href="https://github.com/astral-sh/uv/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h4&gt;How do you pronounce uv?&lt;/h4&gt; 
&lt;p&gt;It's pronounced as "you - vee" (&lt;a href="https://en.wikipedia.org/wiki/Help:IPA/English#Key"&gt;&lt;code&gt;/juÀê viÀê/&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; 
&lt;h4&gt;How should I stylize uv?&lt;/h4&gt; 
&lt;p&gt;Just "uv", please. See the &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/STYLE.md#styling-uv"&gt;style guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;uv's dependency resolver uses &lt;a href="https://github.com/pubgrub-rs/pubgrub"&gt;PubGrub&lt;/a&gt; under the hood. We're grateful to the PubGrub maintainers, especially &lt;a href="https://github.com/Eh2406"&gt;Jacob Finkelman&lt;/a&gt;, for their support.&lt;/p&gt; 
&lt;p&gt;uv's Git implementation is based on &lt;a href="https://github.com/rust-lang/cargo"&gt;Cargo&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some of uv's optimizations are inspired by the great work we've seen in &lt;a href="https://pnpm.io/"&gt;pnpm&lt;/a&gt;, &lt;a href="https://github.com/orogene/orogene"&gt;Orogene&lt;/a&gt;, and &lt;a href="https://github.com/oven-sh/bun"&gt;Bun&lt;/a&gt;. We've also learned a lot from Nathaniel J. Smith's &lt;a href="https://github.com/njsmith/posy"&gt;Posy&lt;/a&gt; and adapted its &lt;a href="https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline"&gt;trampoline&lt;/a&gt; for Windows support.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;uv is licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0, (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="https://opensource.org/licenses/MIT"&gt;https://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://astral.sh" style="background:none"&gt; &lt;img src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg?sanitize=true" alt="Made by Astral" /&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>openobserve/openobserve</title>
      <link>https://github.com/openobserve/openobserve</link>
      <description>&lt;p&gt;Modern observability platform: 10x easier, 140x lower storage cost, petabyte scale. Open-source alternative to Elasticsearch/Splunk/Datadog for logs, metrics, traces, RUM, and more.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://openobserve.ai"&gt;&lt;img src="https://openobserve.ai/img/logo/o2-logo-readme.svg?sanitize=true" alt="OpenObserve" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;em&gt;Modern observability platform: 10x easier, 140x lower storage cost, high performance, petabyte scale - Elasticsearch/Splunk/Datadog alternative for logs, metrics, traces, frontend monitoring and more.&lt;/em&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/openobserve/openobserve" target="_blank"&gt; &lt;img src="https://img.shields.io/github/last-commit/openobserve/openobserve" alt="Last Commit" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/stargazers" target="_blank"&gt; &lt;img src="https://img.shields.io/github/stars/openobserve/openobserve" alt="GitHub Stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/issues" target="_blank"&gt; &lt;img src="https://img.shields.io/github/issues/openobserve/openobserve" alt="GitHub Issues" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/graphs/contributors" target="_blank"&gt; &lt;img src="https://img.shields.io/github/contributors/openobserve/openobserve" alt="Contributors" /&gt; &lt;/a&gt; &lt;a href="https://github.com/openobserve/openobserve/releases" target="_blank"&gt; &lt;img src="https://img.shields.io/github/v/release/openobserve/openobserve" alt="GitHub Release" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;OpenObserve (O2 for short) is a cloud-native observability platform built specifically for logs, metrics, traces, analytics, frontend monitoring and more. Start with a single binary that scales to terabytes, or deploy in High Availability mode for petabyte-scale workloads.&lt;/p&gt; 
&lt;h2&gt;Why OpenObserve?&lt;/h2&gt; 
&lt;h3&gt;1. Simplicity&lt;/h3&gt; 
&lt;p&gt;It is straightforward and easy to operate compared to other observability tools that require understanding and tuning numerous settings. Get OpenObserve up and running on a single node in under 2 minutes. No PhD required.&lt;/p&gt; 
&lt;h3&gt;2. Cost Efficiency&lt;/h3&gt; 
&lt;p&gt;You can reduce your log storage costs by ~140x compared to Elasticsearch. Yes, you read that right - 140x, not a typo. This is achieved through columnar storage format (Parquet), aggressive compression, and S3-native architecture. See the detailed comparison below where we ingested the same amount of data in OpenObserve and Elasticsearch and found OpenObserve storage cost to be ~140x lower. Your CFO will love you.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/zo_vs_es.png" alt="OpenObserve Vs Elasticsearch" /&gt;&lt;/p&gt; 
&lt;h3&gt;3. Performance&lt;/h3&gt; 
&lt;p&gt;OpenObserve delivers better performance than Elasticsearch while using 1/4th the hardware resources. Users report faster search performance and significantly faster analytics queries. The columnar storage format (Parquet) with intelligent partitioning and caching reduces the search space by up to 99% for most queries. Built in Rust for memory safety and high performance, OpenObserve handles thousands of concurrent users querying a single cluster simultaneously.&lt;/p&gt; 
&lt;h3&gt;4. Single Binary Platform&lt;/h3&gt; 
&lt;p&gt;Consolidate metrics, logs, and traces on one single, efficient platform. OpenObserve comes with its own UI, eliminating the need for multiple installations. One binary to rule them all.&lt;/p&gt; 
&lt;h2&gt;üé• Introduction Video&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=4VwuC1tpRP4"&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/o2_intro.webp" alt="OpenObserve Introduction" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;OpenObserve achieves 140x lower storage costs and high performance through its modern architecture:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Parquet columnar storage&lt;/strong&gt;: Efficient compression and query performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3-native design&lt;/strong&gt;: Leverages inexpensive object storage with intelligent caching&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built in Rust&lt;/strong&gt;: Memory-safe, high-performance, single binary deployment&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Partitioning, indexing and smart caching&lt;/strong&gt;: Reduces search space by up to 99% for most queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Native multi-tenancy&lt;/strong&gt;: Organizations and streams as first-class concepts with complete data isolation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Stateless architecture&lt;/strong&gt;: Enables rapid scaling and low RPO/RTO for disaster recovery&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This architecture delivers 140x cost savings while providing better performance than Elasticsearch.&lt;/p&gt; 
&lt;h3&gt;Scale &amp;amp; Deployment&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Thousands of concurrent users&lt;/strong&gt; can query a single cluster simultaneously&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single binary&lt;/strong&gt; scales to terabytes - unique in the observability space&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Availability mode&lt;/strong&gt; scales to petabytes for the most demanding workloads&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-region deployments&lt;/strong&gt; with cluster federation via Super Cluster architecture (Enterprise feature)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Federated search&lt;/strong&gt; across regions and clusters (Enterprise feature)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Capacity planning tools&lt;/strong&gt; to size deployments for your workload&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;High Availability &amp;amp; Disaster Recovery&lt;/h3&gt; 
&lt;p&gt;Deploy in High Availability mode with clustering for mission-critical workloads requiring maximum uptime and performance.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Low RPO/RTO&lt;/strong&gt;: OpenObserve's stateless architecture with S3-backed storage enables very low Recovery Point Objective (RPO) and Recovery Time Objective (RTO). Stateless nodes can be rapidly restarted, and data durability is guaranteed by S3's 99.999999999% (11 nines) durability. That's a lot of nines.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://openobserve.ai/docs/architecture/"&gt;Read detailed architecture documentation ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://openobserve.ai/docs/ha_deployment/"&gt;Read enterprise deployment guide ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üåü Capabilities&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Logs, Metrics, Traces&lt;/strong&gt;: Full support for all three pillars of observability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenTelemetry Support&lt;/strong&gt;: Native OTLP ingestion for logs, metrics, and traces.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real User Monitoring (RUM)&lt;/strong&gt;: Performance tracking, error logging, and session replay.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dashboards, Reports, Alerts&lt;/strong&gt;: 19+ built-in chart types plus a custom chart capability that enables creating 200+ chart variations including 3D visualizations. Scheduled reports and flexible alerting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pipelines&lt;/strong&gt;: Enrich, redact, reduce, or normalize data on ingest. Stream processing for logs-to-metrics and more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in Web UI&lt;/strong&gt;: No separate frontend to install or manage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQL and PromQL Support&lt;/strong&gt;: Query logs and traces with SQL, metrics with SQL or PromQL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single Binary or High Availability Mode&lt;/strong&gt;: Start with one binary, scale to full High Availability when you need it.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Storage&lt;/strong&gt;: Local disk, S3, MinIO, GCS, or Azure Blob Storage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Availability and Clustering&lt;/strong&gt;: Production-grade High Availability deployment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic Schema&lt;/strong&gt;: No predefined schema required - just start sending data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in Authentication&lt;/strong&gt;: Secure by default.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple Upgrades&lt;/strong&gt;: No complex migration scripts required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multilingual UI&lt;/strong&gt;: Available in 11 languages including English, Spanish, German, French, Chinese, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For a full list of features, check the &lt;a href="https://openobserve.ai/docs/#project-status-features-and-roadmap"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ö°Ô∏è Quick start&lt;/h2&gt; 
&lt;h3&gt;üê≥ Docker:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
      --name openobserve \
      -v $PWD/data:/data \
      -p 5080:5080 \
      -e ZO_ROOT_USER_EMAIL="root@example.com" \
      -e ZO_ROOT_USER_PASSWORD="Complexpass#123" \
      public.ecr.aws/zinclabs/openobserve:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For other ways to quickly install OpenObserve or use OpenObserve cloud, check &lt;a href="https://openobserve.ai/docs/quickstart"&gt;quickstart documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For installing OpenObserve in High Availability mode, check &lt;a href="https://openobserve.ai/docs/ha_deployment/"&gt;High Availability deployment documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üèÜ Production Ready&lt;/h2&gt; 
&lt;p&gt;OpenObserve is battle-tested in production environments worldwide (and by "battle-tested", we mean real production traffic, not just our test lab):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Thousands of active deployments&lt;/strong&gt; across diverse industries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Largest deployment processes 2 PB/day&lt;/strong&gt; of data ingestion&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single binary scales to terabytes&lt;/strong&gt; - unique in the observability space, no other single-binary solution achieves this scale&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Availability mode scales to petabytes&lt;/strong&gt; - for the most demanding workloads&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://openobserve.ai/customer-stories/"&gt;Read customer stories ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∑ Screenshots&lt;/h2&gt; 
&lt;p&gt;OpenObserve includes a powerful web UI for logs, traces, dashboards, alerts, and more.&lt;/p&gt; 
&lt;h3&gt;Logs Search&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/logs.png" alt="Logs" /&gt;&lt;/p&gt; 
&lt;h3&gt;Distributed Tracing&lt;/h3&gt; 
&lt;p&gt;Trace details page with full request flow visualization: &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/traces.png" alt="Traces using OpenTelemetry" /&gt;&lt;/p&gt; 
&lt;h3&gt;Dashboards&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/dashboard.png" alt="Dashboard" /&gt;&lt;/p&gt; 
&lt;h3&gt;Frontend Monitoring&lt;/h3&gt; 
&lt;p&gt;Real user monitoring with session replay: &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/session-replay.png" alt="Session replay" /&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;See more screenshots&lt;/summary&gt; 
 &lt;h3&gt;Home&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/zo_home.png" alt="Home" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Golden Metrics from Traces&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/traces-overall.png" alt="Traces golden metrics" /&gt;&lt;/p&gt; 
 &lt;h3&gt;More Dashboard Examples&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/dashboard2.png" alt="Dashboard" /&gt; &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/create-panel.png" alt="Create panel" /&gt; &lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/map.png" alt="Map" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Performance Analytics&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/performance.png" alt="Performance" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Error Tracking&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/error-tracking.png" alt="Error tracking" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Alerts&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/alerts.png" alt="Alerts" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Streams&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/streams.png" alt="Streams" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Ingestion&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/ingestion1.png" alt="Ingestion" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Pipeline&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/pipeline.png" alt="Pipeline" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Functions&lt;/h3&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/function.png" alt="Function" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;üîê Security &amp;amp; Compliance&lt;/h2&gt; 
&lt;h3&gt;Security Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Highly secure architecture&lt;/strong&gt; with secure container images&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sensitive Data Redaction (SDR)&lt;/strong&gt;: Automatically redact sensitive data during ingestion and query time (Enterprise feature)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data encryption&lt;/strong&gt;: At rest and in transit&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single Sign-On (SSO)&lt;/strong&gt;: OIDC, OAuth, SAML, LDAP/AD integration (Enterprise feature)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Role-Based Access Control (RBAC)&lt;/strong&gt;: Granular permissions management (Enterprise feature) - &lt;a href="https://openobserve.ai/docs/user-guide/identity-and-access-management/role-based-access-control/"&gt;Learn more ‚Üí&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Compliance Certifications&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;SOC 2 Type II&lt;/strong&gt; certified&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;ISO 27001&lt;/strong&gt; certified&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;GDPR&lt;/strong&gt; compliant&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;HIPAA&lt;/strong&gt; ready (BAA available with Enterprise contracts)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;OpenObserve meets the stringent security and compliance requirements of regulated industries including finance, healthcare, and government.&lt;/p&gt; 
&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Open Source Edition&lt;/strong&gt;: Licensed under AGPL-3.0. We chose AGPL to ensure that improvements to OpenObserve remain open source and benefit the entire community. This license protects the commons while still allowing free commercial use.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Enterprise Edition&lt;/strong&gt;: Licensed under a commercial Enterprise License Agreement, not AGPL. This provides additional flexibility for enterprise deployments and eliminates any concerns about AGPL requirements.&lt;/p&gt; 
&lt;p&gt;For more details:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openobserve/openobserve/raw/main/LICENSE"&gt;Open Source LICENSE&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openobserve.ai/blog/what-are-apache-gpl-and-agpl-licenses-and-why-openobserve-moved-from-apache-to-agpl/"&gt;Why AGPL and why it's good for the community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíº Enterprise Support&lt;/h2&gt; 
&lt;p&gt;OpenObserve is built as a true open source project, and we're committed to the community. &lt;strong&gt;The open source version is feature-complete and production-ready&lt;/strong&gt; - it includes logs, metrics, traces, dashboards, alerts, pipelines, and everything you need to run observability at scale. It will always remain actively maintained and free to use without restrictions.&lt;/p&gt; 
&lt;h3&gt;Enterprise Edition&lt;/h3&gt; 
&lt;p&gt;For organizations requiring enterprise-grade features and support, we offer an Enterprise edition with:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Enterprise Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Single Sign-On (SSO)&lt;/strong&gt;: OIDC, OAuth, SAML 2.0, LDAP/AD, and integration with major identity providers (Okta, Azure Entra, Google, GitHub, GitLab, Keycloak)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced RBAC&lt;/strong&gt;: Granular role-based access control with custom roles and permissions - &lt;a href="https://openobserve.ai/docs/user-guide/identity-and-access-management/role-based-access-control/"&gt;Learn more ‚Üí&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Audit trails&lt;/strong&gt;: Comprehensive immutable audit logs with configurable retention&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Federated search&lt;/strong&gt;: Query across multiple clusters and regions with Super Cluster&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sensitive Data Redaction (SDR)&lt;/strong&gt;: Automatically redact PII and sensitive data during ingestion and queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced encryption&lt;/strong&gt;: AES-256 SIV cipher keys with Google Tink KeySet and Akeyless integration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Query management&lt;/strong&gt;: Control query resource usage and priorities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workload management (QoS)&lt;/strong&gt;: Quality of Service controls for multi-tenant environments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Enterprise Support &amp;amp; SLAs:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Dedicated support with contractual SLA guarantees&lt;/li&gt; 
 &lt;li&gt;Priority response times for critical issues&lt;/li&gt; 
 &lt;li&gt;Technical account management&lt;/li&gt; 
 &lt;li&gt;Architecture review and deployment assistance&lt;/li&gt; 
 &lt;li&gt;Migration support from existing tools&lt;/li&gt; 
 &lt;li&gt;Training and onboarding programs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Pricing:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Free tier&lt;/strong&gt;: Up to 200 GB/day of ingestion (roughly 6 TB/month), including full commercial use&lt;/li&gt; 
 &lt;li&gt;&lt;em&gt;Registration required at 100 GB/day&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Volume discounts and multi-year contracts available&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://openobserve.ai/downloads/"&gt;View complete feature comparison ‚Üí&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For enterprise inquiries and custom deployments, contact our sales team.&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! Whether you're fixing bugs, adding features, improving documentation, or sharing feedback, your help makes OpenObserve better for everyone.&lt;/p&gt; 
&lt;p&gt;To get started, please read our &lt;a href="https://raw.githubusercontent.com/openobserve/openobserve/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; which covers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;How to set up your development environment&lt;/li&gt; 
 &lt;li&gt;Code standards and best practices&lt;/li&gt; 
 &lt;li&gt;How to submit pull requests&lt;/li&gt; 
 &lt;li&gt;Reporting bugs and requesting features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåç Community&lt;/h2&gt; 
&lt;p&gt;The best way to get help, share ideas, and connect with other OpenObserve users is through our community channels. We're a friendly group of developers, operators, and observability enthusiasts.&lt;/p&gt; 
&lt;h3&gt;üîó Join us on Slack&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://short.openobserve.ai/community"&gt;&lt;img src="https://raw.githubusercontent.com/openobserve/openobserve/main/screenshots/slack.png" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Our Slack community is the most active place for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Getting help with installation and configuration&lt;/li&gt; 
 &lt;li&gt;Sharing best practices and use cases&lt;/li&gt; 
 &lt;li&gt;Discussing feature requests and roadmap&lt;/li&gt; 
 &lt;li&gt;Connecting with the core team and other users&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://short.openobserve.ai/community"&gt;Join the conversation ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Other ways to connect&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://github.com/openobserve/openobserve/discussions"&gt;GitHub Discussions&lt;/a&gt; - For longer-form discussions and Q&amp;amp;A&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/openobserve/openobserve/issues"&gt;GitHub Issues&lt;/a&gt; - Report bugs or request features&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://openobserve.ai/docs"&gt;Documentation&lt;/a&gt; - Guides, tutorials, and API references&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ùì FAQ&lt;/h2&gt; 
&lt;h3&gt;How does OpenObserve achieve 140x lower storage costs?&lt;/h3&gt; 
&lt;p&gt;Through a combination of Parquet columnar storage format (efficient compression), S3-native architecture (leveraging inexpensive object storage). See the detailed comparison chart in the "Why OpenObserve?" section above.&lt;/p&gt; 
&lt;h3&gt;What are the limitations?&lt;/h3&gt; 
&lt;p&gt;All data in OpenObserve is &lt;strong&gt;immutable&lt;/strong&gt; - once ingested, it cannot be modified or deleted (only entire retention periods can be dropped). This is by design and is actually a feature for logs and compliance requirements, ensuring data integrity and audit trails.&lt;/p&gt; 
&lt;h3&gt;Is this production-ready?&lt;/h3&gt; 
&lt;p&gt;Yes. OpenObserve is running in production with thousands of deployments worldwide, including environments processing in excess of 2 PB/day. See our &lt;a href="https://openobserve.ai/customer-stories/"&gt;customer stories&lt;/a&gt; for real-world examples.&lt;/p&gt; 
&lt;h3&gt;How does query performance compare to Elasticsearch?&lt;/h3&gt; 
&lt;p&gt;OpenObserve delivers better performance than Elasticsearch for most workloads. Users report faster search performance and significantly faster analytics queries, all while using 1/4th the hardware resources. The columnar storage format (Parquet) is particularly effective for complex aggregations and analytics workloads.&lt;/p&gt; 
&lt;h3&gt;Is there a steep learning curve?&lt;/h3&gt; 
&lt;p&gt;No. OpenObserve is designed to be intuitive from day one:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Familiar query languages&lt;/strong&gt;: Use SQL for logs and traces, PromQL for metrics - no proprietary query language to learn&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy-to-use GUI&lt;/strong&gt;: Intuitive interface with drag-and-drop dashboard builder&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Helpful community&lt;/strong&gt;: Active Slack community and comprehensive documentation to help you get started quickly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No complex tuning&lt;/strong&gt;: Unlike Elasticsearch, you don't need to understand shards, replicas, heap sizes, or other complex configurations. Just install and go.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Most users are productive within hours, not weeks. Some even claim minutes, but we'll let you be the judge.&lt;/p&gt; 
&lt;h2&gt;üîê SBOM&lt;/h2&gt; 
&lt;p&gt;Software Bill of Materials for OpenObserve&lt;/p&gt; 
&lt;h3&gt;Rust&lt;/h3&gt; 
&lt;p&gt;SBOM can be found &lt;a href="https://raw.githubusercontent.com/openobserve/openobserve/main/openobserve.cdx.xml"&gt;here&lt;/a&gt;. You can analyze it using &lt;a href="https://dependencytrack.org/"&gt;dependency track&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In order to generate the SBOM, you can use the following commands:&lt;/p&gt; 
&lt;p&gt;Install cargo-cyclonedx:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-cyclonedx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generate the SBOM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo-cyclonedx cyclonedx
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;JavaScript&lt;/h3&gt; 
&lt;p&gt;SBOM can be found &lt;a href="https://raw.githubusercontent.com/openobserve/openobserve/main/web/sbom.json"&gt;here&lt;/a&gt;. You can analyze it using &lt;a href="https://dependencytrack.org/"&gt;dependency track&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In order to generate the SBOM, you can use the following commands:&lt;/p&gt; 
&lt;p&gt;Install cyclonedx-npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install --global @cyclonedx/cyclonedx-npm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Generate the SBOM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd web
cyclonedx-npm &amp;gt; sbom.json
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>GraphiteEditor/Graphite</title>
      <link>https://github.com/GraphiteEditor/Graphite</link>
      <description>&lt;p&gt;An open source graphics editor for 2025: comprehensive 2D content creation tool suite for graphic design, digital art, and interactive real-time motion graphics ‚Äî featuring node-based procedural editing&lt;/p&gt;&lt;hr&gt;&lt;a href="https://graphite.rs/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/9366c148-4405-484f-909a-9a3526eb9209" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/791508ab-bcd5-4e31-a3b9-1187cfd7a2f6" /&gt; 
  &lt;img alt="Graphite logo" src="https://github.com/user-attachments/assets/791508ab-bcd5-4e31-a3b9-1187cfd7a2f6" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h1&gt;Your procedural toolbox for 2D content creation&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Graphite is a free, open source vector and raster graphics engine, &lt;a href="https://editor.graphite.rs"&gt;available now&lt;/a&gt; in alpha. Get creative with a fully nondestructive editing workflow that combines layer-based compositing with node-based generative design.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Having begun life as a vector editor, Graphite continues evolving into a generalized, all-in-one graphics toolbox that's built more like a game engine than a conventional creative app. The editor's tools wrap its node graph core, providing user-friendly workflows for vector, raster, and beyond. Photo editing, motion graphics, digital painting, desktop publishing, and VFX compositing are additional competencies on the planned &lt;a href="https://graphite.rs/features/#roadmap"&gt;roadmap&lt;/a&gt; making Graphite into a highly versatile content creation tool.&lt;/p&gt; 
&lt;p&gt;Learn more from the &lt;a href="https://graphite.rs/"&gt;website&lt;/a&gt;, subscribe to the &lt;a href="https://graphite.rs/#newsletter"&gt;newsletter&lt;/a&gt;, consider &lt;a href="https://graphite.rs/volunteer/"&gt;volunteering&lt;/a&gt; or &lt;a href="https://graphite.rs/donate/"&gt;donating&lt;/a&gt;, and remember to give this repository a ‚≠ê!&lt;/p&gt; 
&lt;br /&gt; 
&lt;a href="https://discord.graphite.rs/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/ad185fac-3b48-446d-863c-2bcb0724abee" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/aa23f503-f3bf-444a-9080-8eaa19fa2fa8" /&gt; 
  &lt;img alt="Discord" src="https://github.com/user-attachments/assets/aa23f503-f3bf-444a-9080-8eaa19fa2fa8" width="48" height="48" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
&lt;a href="https://www.reddit.com/r/graphite/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/d8c05686-2eb9-4ac1-8149-728c12b4e71a" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/6f32329a-4d6f-42d8-9a2f-42977c0b3c05" /&gt; 
  &lt;img alt="Reddit" src="https://github.com/user-attachments/assets/6f32329a-4d6f-42d8-9a2f-42977c0b3c05" width="48" height="48" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
&lt;a href="https://bsky.app/profile/graphiteeditor.bsky.social"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/c736d80c-e9bf-4591-a7e0-a7723057a906" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/3db9b0a1-5ab7-4bff-bfd3-8a4ade7b98bd" /&gt; 
  &lt;img alt="Bluesky" src="https://github.com/user-attachments/assets/3db9b0a1-5ab7-4bff-bfd3-8a4ade7b98bd" width="48" height="48" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
&lt;a href="https://twitter.com/graphiteeditor"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/115f04cc-e3c2-4f90-ac35-eb9edd3ca9be" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/4ed4185d-a622-418c-bbf4-a0419e690ca9" /&gt; 
  &lt;img alt="Twitter" src="https://github.com/user-attachments/assets/4ed4185d-a622-418c-bbf4-a0419e690ca9" width="48" height="48" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; 
&lt;a href="https://www.youtube.com/@GraphiteEditor"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/cbc02fad-5cbc-4715-a8e5-860198e989c7" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/user-attachments/assets/d13b484d-97a8-4d9e-bbe4-c60348b3f676" /&gt; 
  &lt;img alt="YouTube" src="https://github.com/user-attachments/assets/d13b484d-97a8-4d9e-bbe4-c60348b3f676" width="48" height="48" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;br /&gt;
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f4604aea-e8f1-45ce-9218-46ddc666f11d"&gt;https://github.com/user-attachments/assets/f4604aea-e8f1-45ce-9218-46ddc666f11d&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Support our mission ‚ù§Ô∏è&lt;/h2&gt; 
&lt;p&gt;Graphite is 100% community built and funded. Please become a part of keeping the project alive and thriving with a &lt;a href="https://graphite.rs/donate/"&gt;donation&lt;/a&gt; if you share a belief in our &lt;strong&gt;mission&lt;/strong&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Graphite strives to unshackle the creativity of every budding artist and seasoned professional by building the best comprehensive art and design tool that's accessible to all.&lt;/p&gt; 
 &lt;p&gt;Mission success will come when Graphite is an industry standard. A cohesive product vision and focus on innovation over imitation is the strategy that will make that possible.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/decb7011-18c2-4c68-82af-d1fa5064244a" alt="Made using nondestructive boolean operations and procedural polka dot patterns" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/9e023997-185b-4f43-a724-797d308d9e7b" alt="Mandelbrot fractal filled with a noise pattern, procedurally generated and infinitely scalable" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/90eca551-5868-4f8d-9016-33958bf96345" alt="Design for a magazine spread, a preview of the upcoming focus on desktop publishing" /&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing/building the code&lt;/h2&gt; 
&lt;p&gt;Are you a graphics programmer or Rust developer? Graphite aims to be one of the most approachable projects for putting your engineering skills to use in the world of open source. See &lt;a href="https://graphite.rs/volunteer/guide/"&gt;instructions here&lt;/a&gt; for setting up the project and getting started.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;By submitting code for inclusion in the project, you are agreeing to license your changes under the Apache 2.0 license, and that you have the authority to do so. Some directories may have other licenses, like dual-licensed MIT/Apache 2.0, and code submissions to those directories mean you agree to the applicable license(s).&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>esp-rs/esp-hal</title>
      <link>https://github.com/esp-rs/esp-hal</link>
      <description>&lt;p&gt;no_std Hardware Abstraction Layers for ESP32 microcontrollers&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/esp-rs/esp-hal/main/resources/esp-rs.svg?sanitize=true" alt="esp-rs logo" width="100px" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;esp-hal&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/esp-rs/esp-hal/ci.yml?labelColor=1C2C2E&amp;amp;label=CI&amp;amp;logo=github&amp;amp;style=flat-square" alt="GitHub Actions Workflow Status" /&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/esp-rs/esp-hal/hil.yml?labelColor=1C2C2E&amp;amp;label=HIL&amp;amp;logo=github&amp;amp;style=flat-square&amp;amp;event=merge_group" alt="GitHub Actions Workflow Status" /&gt; &lt;img src="https://img.shields.io/badge/license-MIT%2FApache--2.0-blue?labelColor=1C2C2E&amp;amp;style=flat-square" alt="MIT/Apache-2.0 licensed" /&gt; &lt;a href="https://matrix.to/#/#esp-rs:matrix.org"&gt; &lt;img src="https://img.shields.io/matrix/esp-rs:matrix.org?labelColor=1C2C2E&amp;amp;label=join%20matrix&amp;amp;color=BEC5C9&amp;amp;logo=matrix&amp;amp;style=flat-square" alt="Matrix" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Bare-metal (&lt;code&gt;no_std&lt;/code&gt;) hardware abstraction layer for Espressif devices. Currently supports, to varying degrees, the following devices:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ESP32 Series: &lt;em&gt;ESP32&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;ESP32-C Series: &lt;em&gt;ESP32-C2, ESP32-C3, ESP32-C6&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;ESP32-H Series: &lt;em&gt;ESP32-H2&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;ESP32-S Series: &lt;em&gt;ESP32-S2, ESP32-S3&lt;/em&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally provides limited support for programming the low-power RISC-V cores found on the &lt;em&gt;ESP32-C6&lt;/em&gt;, &lt;em&gt;ESP32-S2&lt;/em&gt;, and &lt;em&gt;ESP32-S3&lt;/em&gt; via the &lt;a href="https://github.com/esp-rs/esp-hal/tree/main/esp-lp-hal"&gt;esp-lp-hal&lt;/a&gt; package.&lt;/p&gt; 
&lt;p&gt;For additional information regarding any of the crates in this repository, please refer to the relevant crate's &lt;code&gt;README.md&lt;/code&gt; file. If you have any questions, comments, or concerns, please &lt;a href="https://github.com/esp-rs/esp-hal/issues/new"&gt;open an issue&lt;/a&gt;, &lt;a href="https://github.com/esp-rs/esp-hal/discussions/new"&gt;start a new discussion&lt;/a&gt;, or join us on &lt;a href="https://matrix.to/#/#esp-rs:matrix.org"&gt;Matrix&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you are currently using (or considering using) &lt;code&gt;esp-hal&lt;/code&gt; in a production environment and have any feedback or require support, please feel free to contact us at &lt;a href="mailto:rust.support@espressif.com"&gt;rust.support@espressif.com&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;This repository includes crates that are at various stages of maturity and stability. While many functionalities have already been implemented and are usable for most tasks, certain advanced or less common features may still be under development. Each crate may offer different levels of functionality and guarantees.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;For information relating to the development of Rust applications on ESP devices, please first read &lt;a href="https://docs.espressif.com/projects/rust/book/"&gt;The Rust on ESP Book&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For information about the HAL and how to use it in your own projects, please refer to the &lt;a href="https://docs.espressif.com/projects/rust/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When browsing the examples, we recommend viewing the tag for the &lt;code&gt;esp-hal&lt;/code&gt; release you are using to ensure compatibility, e.g. &lt;a href="https://github.com/esp-rs/esp-hal/tree/esp-hal-v1.0.0/examples"&gt;esp-hal-v1.0.0&lt;/a&gt;, as the &lt;code&gt;main&lt;/code&gt; branch is used for development and APIs may have changed in the meantime.&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://doc.rust-lang.org/book/"&gt;The Rust Programming Language&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rust-embedded.org/book/index.html"&gt;The Embedded Rust Book&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rust-embedded.org/embedonomicon/"&gt;The Embedonomicon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.espressif.com/projects/rust/esp-hal/latest/"&gt;The Rust on ESP Book&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.espressif.com/projects/rust/no_std-training/"&gt;Embedded Rust (no_std) on Espressif&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We have a number of living documents to aid contributing to the project, please give these a read before modifying code:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/esp-rs/esp-hal/raw/main/documentation/DEVELOPER-GUIDELINES.md"&gt;DEVELOPER-GUIDELINES&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/esp-rs/esp-hal/raw/main/documentation/CONTRIBUTING.md"&gt;CONTRIBUTING-GUIDE&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;All packages within this repository are licensed under either of:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0 (&lt;a href="https://raw.githubusercontent.com/esp-rs/esp-hal/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/esp-rs/esp-hal/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="http://opensource.org/licenses/MIT"&gt;http://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;h3&gt;Contribution notice&lt;/h3&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tracel-ai/burn</title>
      <link>https://github.com/tracel-ai/burn</link>
      <description>&lt;p&gt;Burn is a next generation tensor library and Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/logo-burn-neutral.webp" width="350px" /&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/uPEBbYYDB6"&gt;&lt;img src="https://img.shields.io/discord/1038839012602941528.svg?color=7289da&amp;amp;&amp;amp;logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/v/burn.svg?sanitize=true" alt="Current Crates.io Version" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/msrv/burn" alt="Minimum Supported Rust Version" /&gt;&lt;/a&gt; &lt;a href="https://burn.dev/docs/burn"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tracel-ai/burn/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/tracel-ai/burn/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Test Status" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/#license"&gt;&lt;img src="https://shields.io/badge/license-MIT%2FApache--2.0-blue" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/tracel-ai/burn"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.runblaze.dev"&gt;&lt;img src="https://www.runblaze.dev/ci-blaze-powered.png" width="125px" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;p&gt;&lt;strong&gt;Burn is a next generation Tensor Library and Deep Learning Framework that doesn't compromise on &lt;br /&gt; flexibility, efficiency and portability.&lt;/strong&gt;&lt;/p&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;div align="left"&gt; 
 &lt;p&gt;Burn is both a tensor library and a deep learning framework optimized for numerical computing, model inference and model training. Burn leverages Rust to perform optimizations normally only available in static-graph frameworks, offering optimal speed without impacting flexibility.&lt;/p&gt; 
 &lt;h2&gt;Backend&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/backend-chip.png" height="96px" /&gt; 
  &lt;p&gt;Burn strives to be as fast as possible on as many hardwares as possible, with robust implementations. We believe this flexibility is crucial for modern needs where you may train your models in the cloud, then deploy on customer hardwares, which vary from user to user.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;Supported Backends&lt;/h3&gt; 
 &lt;p&gt;Most backends support all operating systems, so we don't mention them in the tables below.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;GPU Backends:&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;CUDA&lt;/th&gt; 
    &lt;th&gt;ROCm&lt;/th&gt; 
    &lt;th&gt;Metal&lt;/th&gt; 
    &lt;th&gt;Vulkan&lt;/th&gt; 
    &lt;th&gt;WebGPU&lt;/th&gt; 
    &lt;th&gt;Candle&lt;/th&gt; 
    &lt;th&gt;LibTorch&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Nvidia&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;AMD&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Apple&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Intel&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Qualcom&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wasm&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;CPU Backends:&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;Cpu (CubeCL)&lt;/th&gt; 
    &lt;th&gt;NdArray&lt;/th&gt; 
    &lt;th&gt;Candle&lt;/th&gt; 
    &lt;th&gt;LibTorch&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;X86&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Arm&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wasm&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;no-std&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Compared to other frameworks, Burn has a very different approach to supporting many backends. By design, most code is generic over the Backend trait, which allows us to build Burn with swappable backends. This makes composing backend possible, augmenting them with additional functionalities such as autodifferentiation and automatic kernel fusion.&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Autodiff: Backend decorator that brings backpropagation to any backend üîÑ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Contrary to the aforementioned backends, Autodiff is actually a backend &lt;em&gt;decorator&lt;/em&gt;. This means that it cannot exist by itself; it must encapsulate another backend.&lt;/p&gt; 
  &lt;p&gt;The simple act of wrapping a base backend with Autodiff transparently equips it with autodifferentiation support, making it possible to call backward on your model.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::backend::{Autodiff, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&amp;lt;Wgpu&amp;gt;;

    let device = Default::default();

    let x: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default, &amp;amp;device);
    let y: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default, &amp;amp;device).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;amp;grads).unwrap();
    println!("{y_grad}");
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, it is impossible to make the mistake of calling backward on a model that runs on a backend that does not support autodiff (for inference), as this method is only offered by an Autodiff backend.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-autodiff/README.md"&gt;Autodiff Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Fusion: Backend decorator that brings kernel fusion to all first-party backends &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;This backend decorator enhances a backend with kernel fusion, provided that the inner backend supports it. Note that you can compose this backend with other backend decorators such as Autodiff. All first-party accelerated backends (like WGPU and CUDA) use Fusion by default (&lt;code&gt;burn/fusion&lt;/code&gt; feature flag), so you typically don't need to apply it manually.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#[cfg(not(feature = "fusion"))]
pub type Cuda&amp;lt;F = f32, I = i32&amp;gt; = CubeBackend&amp;lt;CudaRuntime, F, I, u8&amp;gt;;

#[cfg(feature = "fusion")]
pub type Cuda&amp;lt;F = f32, I = i32&amp;gt; = burn_fusion::Fusion&amp;lt;CubeBackend&amp;lt;CudaRuntime, F, I, u8&amp;gt;&amp;gt;;
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, we plan to implement automatic gradient checkpointing based on compute bound and memory bound operations, which will work gracefully with the fusion backend to make your code run even faster during training, see &lt;a href="https://github.com/tracel-ai/burn/issues/936"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-fusion/README.md"&gt;Fusion Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Router (Beta): Backend decorator that composes multiple backends into a single one &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;That backend simplifies hardware operability, if for instance you want to execute some operations on the CPU and other operations on the GPU.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::tensor::{Distribution, Tensor};
use burn::backend::{
    NdArray, Router, Wgpu, ndarray::NdArrayDevice, router::duo::MultiDevice, wgpu::WgpuDevice,
};

fn main() {
    type Backend = Router&amp;lt;(Wgpu, NdArray)&amp;gt;;

    let device_0 = MultiDevice::B1(WgpuDevice::DiscreteGpu(0));
    let device_1 = MultiDevice::B2(NdArrayDevice::Cpu);

    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_0);
    let tensor_cpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_1);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Remote (Beta): Backend decorator for remote backend execution, useful for distributed computations &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;That backend has two parts, one client and one server. The client sends tensor operations over the network to a remote compute backend. You can use any first-party backend as server in a single line of code:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;fn main_server() {
    // Start a server on port 3000.
    burn::server::start::&amp;lt;burn::backend::Cuda&amp;gt;(Default::default(), 3000);
}

fn main_client() {
    // Create a client that communicate with the server on port 3000.
    use burn::backend::{Autodiff, RemoteBackend};

    type Backend = Autodiff&amp;lt;RemoteDevice&amp;gt;;

    let device = RemoteDevice::new("ws://localhost:3000");
    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], Distribution::Default, &amp;amp;device);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;h2&gt;Training &amp;amp; Inference&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-wall.png" height="96px" /&gt; 
  &lt;p&gt;The whole deep learning workflow is made easy with Burn, as you can monitor your training progress with an ergonomic dashboard, and run inference everywhere from embedded devices to large GPU clusters.&lt;/p&gt; 
  &lt;p&gt;Burn was built from the ground up with training and inference in mind. It's also worth noting how Burn, in comparison to frameworks like PyTorch, simplifies the transition from training to deployment, eliminating the need for code changes.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;br /&gt; 
  &lt;a href="https://www.youtube.com/watch?v=N9RM5CQbNQc" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/burn-train-tui.png" alt="Burn Train TUI" width="75%" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Click on the following sections to expand üëá&lt;/strong&gt;&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Training Dashboard üìà &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;As you can see in the previous video (click on the picture!), a new terminal UI dashboard based on the &lt;a href="https://github.com/ratatui-org/ratatui"&gt;Ratatui&lt;/a&gt; crate allows users to follow their training with ease without having to connect to any external application.&lt;/p&gt; 
  &lt;p&gt;You can visualize your training and validation metrics updating in real-time and analyze the lifelong progression or recent history of any registered metrics using only the arrow keys. Break from the training loop without crashing, allowing potential checkpoints to be fully written or important pieces of code to complete without interruption üõ°&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; ONNX Support üê´ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Burn supports importing ONNX (Open Neural Network Exchange) models, allowing you to easily port models from TensorFlow or PyTorch to Burn. The ONNX model is converted into Rust code that uses Burn's native APIs, enabling the imported model to run on any Burn backend (CPU, GPU, WebAssembly) and benefit from all of Burn's optimizations like automatic kernel fusion.&lt;/p&gt; 
  &lt;p&gt;Our ONNX support is further described in &lt;a href="https://burn.dev/books/burn/import/onnx-model.html"&gt;this section of the Burn Book üî•&lt;/a&gt;.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This crate is in active development and currently supports a &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-import/SUPPORTED-ONNX-OPS.md"&gt;limited set of ONNX operators&lt;/a&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Importing PyTorch or Safetensors Models üöö &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;You can load weights from PyTorch or Safetensors formats directly into your Burn-defined models. This makes it easy to reuse existing models while benefiting from Burn's performance and deployment features.&lt;/p&gt; 
  &lt;p&gt;Learn more:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/pytorch-model.html"&gt;Import pre-trained PyTorch models into Burn&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/safetensors-model.html"&gt;Load models from Safetensors format&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Inference in the Browser üåê &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Several of our backends can run in WebAssembly environments: Candle and NdArray for CPU execution, and WGPU for GPU acceleration via WebGPU. This means that you can run inference directly within a browser. We provide several examples of this:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST&lt;/a&gt; where you can draw digits and a small convnet tries to find which one it is! 2Ô∏è‚É£ 7Ô∏è‚É£ üò∞&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification&lt;/a&gt; where you can upload images and classify them! üåÑ&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Embedded: &lt;i&gt;no_std&lt;/i&gt; support ‚öôÔ∏è &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Burn's core components support &lt;a href="https://docs.rust-embedded.org/book/intro/no-std.html"&gt;no_std&lt;/a&gt;. This means it can run in bare metal environment such as embedded devices without an operating system.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;As of now, only the NdArray backend can be used in a &lt;em&gt;no_std&lt;/em&gt; environment.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;Benchmarks&lt;/h3&gt; 
 &lt;p&gt;To evaluate performance across different backends and track improvements over time, we provide a dedicated benchmarking suite.&lt;/p&gt; 
 &lt;p&gt;Run and compare benchmarks using &lt;a href="https://github.com/tracel-ai/burn-bench"&gt;burn-bench&lt;/a&gt;.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Warning&lt;/strong&gt; When using one of the &lt;code&gt;wgpu&lt;/code&gt; backends, you may encounter compilation errors related to recursive type evaluation. This is due to complex type nesting within the &lt;code&gt;wgpu&lt;/code&gt; dependency chain. To resolve this issue, add the following line at the top of your &lt;code&gt;main.rs&lt;/code&gt; or &lt;code&gt;lib.rs&lt;/code&gt; file:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#![recursion_limit = "256"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;The default recursion limit (128) is often just below the required depth (typically 130-150) due to deeply nested associated types and trait bounds.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h2&gt;Getting Started&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-walking.png" height="96px" /&gt; 
  &lt;p&gt;Just heard of Burn? You are at the right place! Just continue reading this section and we hope you can get on board really quickly.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;details&gt; 
  &lt;summary&gt; The Burn Book üî• &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;To begin working effectively with Burn, it is crucial to understand its key components and philosophy. This is why we highly recommend new users to read the first sections of &lt;a href="https://burn.dev/books/burn/"&gt;The Burn Book üî•&lt;/a&gt;. It provides detailed examples and explanations covering every facet of the framework, including building blocks like tensors, modules, and optimizers, all the way to advanced usage, like coding your own GPU kernels.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;The project is constantly evolving, and we try as much as possible to keep the book up to date with new additions. However, we might miss some details sometimes, so if you see something weird, let us know! We also gladly accept Pull Requests üòÑ&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Examples üôè &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Let's start with a code snippet that shows how intuitive the framework is to use! In the following, we declare a neural network module with some parameters along with its forward pass.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::nn;
use burn::module::Module;
use burn::tensor::backend::Backend;

#[derive(Module, Debug)]
pub struct PositionWiseFeedForward&amp;lt;B: Backend&amp;gt; {
    linear_inner: nn::Linear&amp;lt;B&amp;gt;,
    linear_outer: nn::Linear&amp;lt;B&amp;gt;,
    dropout: nn::Dropout,
    gelu: nn::Gelu,
}

impl&amp;lt;B: Backend&amp;gt; PositionWiseFeedForward&amp;lt;B&amp;gt; {
    pub fn forward&amp;lt;const D: usize&amp;gt;(&amp;amp;self, input: Tensor&amp;lt;B, D&amp;gt;) -&amp;gt; Tensor&amp;lt;B, D&amp;gt; {
        let x = self.linear_inner.forward(input);
        let x = self.gelu.forward(x);
        let x = self.dropout.forward(x);

        self.linear_outer.forward(x)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;We have a somewhat large amount of &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples"&gt;examples&lt;/a&gt; in the repository that shows how to use the framework in different scenarios.&lt;/p&gt; 
  &lt;p&gt;Following &lt;a href="https://burn.dev/books/burn/"&gt;the book&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/guide"&gt;Basic Workflow&lt;/a&gt; : Creates a custom CNN &lt;code&gt;Module&lt;/code&gt; to train on the MNIST dataset and use for inference.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-training-loop"&gt;Custom Training Loop&lt;/a&gt; : Implements a basic training loop instead of using the &lt;code&gt;Learner&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-wgpu-kernel"&gt;Custom WGPU Kernel&lt;/a&gt; : Learn how to create your own custom operation with the WGPU backend.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;Additional examples:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-csv-dataset"&gt;Custom CSV Dataset&lt;/a&gt; : Implements a dataset to parse CSV data for a regression task.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/simple-regression"&gt;Regression&lt;/a&gt; : Trains a simple MLP on the California Housing dataset to predict the median house value for a district.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-image-dataset"&gt;Custom Image Dataset&lt;/a&gt; : Trains a simple CNN on custom image dataset following a simple folder structure.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-renderer"&gt;Custom Renderer&lt;/a&gt; : Implements a custom renderer to display the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/building-blocks/learner.md"&gt;&lt;code&gt;Learner&lt;/code&gt;&lt;/a&gt; progress.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification Web&lt;/a&gt; : Image classification web browser demo using Burn, WGPU and WebAssembly.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST Inference on Web&lt;/a&gt; : An interactive MNIST inference demo in the browser. The demo is available &lt;a href="https://burn.dev/demo/"&gt;online&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist"&gt;MNIST Training&lt;/a&gt; : Demonstrates how to train a custom &lt;code&gt;Module&lt;/code&gt; (MLP) with the &lt;code&gt;Learner&lt;/code&gt; configured to log metrics and keep training checkpoints.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/named-tensor"&gt;Named Tensor&lt;/a&gt; : Performs operations with the experimental &lt;code&gt;NamedTensor&lt;/code&gt; feature.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/onnx-inference"&gt;ONNX Import Inference&lt;/a&gt; : Imports an ONNX model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/import-model-weights"&gt;PyTorch Import Inference&lt;/a&gt; : Imports a PyTorch model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-classification"&gt;Text Classification&lt;/a&gt; : Trains a text classification transformer model on the AG News or DbPedia dataset. The trained model can then be used to classify a text sample.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-generation"&gt;Text Generation&lt;/a&gt; : Trains a text generation transformer model on the DbPedia dataset.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/wgan"&gt;Wasserstein GAN MNIST&lt;/a&gt; : Trains a WGAN model to generate new handwritten digits based on MNIST.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;For more practical insights, you can clone the repository and run any of them directly on your computer!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Pre-trained Models ü§ñ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;We keep an updated and curated list of models and examples built with Burn, see the &lt;a href="https://github.com/tracel-ai/models"&gt;tracel-ai/models repository&lt;/a&gt; for more details.&lt;/p&gt; 
  &lt;p&gt;Don't see the model you want? Don't hesitate to open an issue, and we may prioritize it. Built a model using Burn and want to share it? You can also open a Pull Request and add your model under the community section!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Why use Rust for Deep Learning? ü¶Ä &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Deep Learning is a special form of software where you need very high level abstractions as well as extremely fast execution time. Rust is the perfect candidate for that use case since it provides zero-cost abstractions to easily create neural network modules, and fine-grained control over memory to optimize every detail.&lt;/p&gt; 
  &lt;p&gt;It's important that a framework be easy to use at a high level so that its users can focus on innovating in the AI field. However, since running models relies so heavily on computations, performance can't be neglected.&lt;/p&gt; 
  &lt;p&gt;To this day, the mainstream solution to this problem has been to offer APIs in Python, but rely on bindings to low-level languages such as C/C++. This reduces portability, increases complexity and creates frictions between researchers and engineers. We feel like Rust's approach to abstractions makes it versatile enough to tackle this two languages dichotomy.&lt;/p&gt; 
  &lt;p&gt;Rust also comes with the Cargo package manager, which makes it incredibly easy to build, test, and deploy from any environment, which is usually a pain in Python.&lt;/p&gt; 
  &lt;p&gt;Although Rust has the reputation of being a difficult language at first, we strongly believe it leads to more reliable, bug-free solutions built faster (after some practice üòÖ)!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;Deprecation Note&lt;/strong&gt;&lt;br /&gt;Since &lt;code&gt;0.14.0&lt;/code&gt;, the internal structure for tensor data has changed. The previous &lt;code&gt;Data&lt;/code&gt; struct was deprecated and officially removed since &lt;code&gt;0.17.0&lt;/code&gt; in favor of the new &lt;code&gt;TensorData&lt;/code&gt; struct, which allows for more flexibility by storing the underlying data as bytes and keeping the data type as a field. If you are using &lt;code&gt;Data&lt;/code&gt; in your code, make sure to switch to &lt;code&gt;TensorData&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;!-- &gt;
&gt; In the event that you are trying to load a model record saved in a previous version, make sure to
&gt; enable the `record-backward-compat` feature using a previous version of burn (&lt;=0.16.0). Otherwise,
&gt; the record won't be deserialized correctly and you will get an error message (which will also point
&gt; you to the backward compatible feature flag). The backward compatibility was maintained for
&gt; deserialization (loading), so as soon as you have saved the record again it will be saved according
&gt; to the new structure and you will be able to upgrade to this version. Please note that binary formats
&gt; are not backward compatible. Thus, you will need to load your record in a previous version and save it
&gt; to another of the self-describing record formats before using a compatible version (as described) with the
&gt; `record-backward-compat` feature flag. --&gt; 
 &lt;details id="deprecation"&gt; 
  &lt;summary&gt; Loading Model Records From Previous Versions ‚ö†Ô∏è &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;In the event that you are trying to load a model record saved in a version older than &lt;code&gt;0.14.0&lt;/code&gt;, make sure to use a compatible version (&lt;code&gt;0.14&lt;/code&gt;, &lt;code&gt;0.15&lt;/code&gt; or &lt;code&gt;0.16&lt;/code&gt;) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
  &lt;pre&gt;&lt;code&gt;features = [..., "record-backward-compat"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Otherwise, the record won't be deserialized correctly and you will get an error message. This error will also point you to the backward compatible feature flag.&lt;/p&gt; 
  &lt;p&gt;The backward compatibility was maintained for deserialization when loading records. Therefore, as soon as you have saved the record again it will be saved according to the new structure and you can upgrade back to the current version&lt;/p&gt; 
  &lt;p&gt;Please note that binary formats are not backward compatible. Thus, you will need to load your record in a previous version and save it in any of the other self-describing record format (e.g., using the &lt;code&gt;NamedMpkFileRecorder&lt;/code&gt;) before using a compatible version (as described) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;h2&gt;Community&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-community.png" height="96px" /&gt; 
  &lt;p&gt;If you are excited about the project, don't hesitate to join our &lt;a href="https://discord.gg/uPEBbYYDB6"&gt;Discord&lt;/a&gt;! We try to be as welcoming as possible to everybody from any background. You can ask your questions and share what you built with the community!&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Before contributing, please take a moment to review our &lt;a href="https://github.com/tracel-ai/burn/tree/main/CODE-OF-CONDUCT.md"&gt;code of conduct&lt;/a&gt;. It's also highly recommended to read the &lt;a href="https://github.com/tracel-ai/burn/tree/main/contributor-book/src/project-architecture"&gt;architecture overview&lt;/a&gt;, which explains some of our architectural decisions. Refer to our &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;h2&gt;Status&lt;/h2&gt; 
 &lt;p&gt;Burn is currently in active development, and there will be breaking changes. While any resulting issues are likely to be easy to fix, there are no guarantees at this stage.&lt;/p&gt; 
 &lt;h2&gt;License&lt;/h2&gt; 
 &lt;p&gt;Burn is distributed under the terms of both the MIT license and the Apache License (Version 2.0). See &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; for details. Opening a pull request is assumed to signal agreement with these licensing terms.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>cloudflare/quiche</title>
      <link>https://github.com/cloudflare/quiche</link>
      <description>&lt;p&gt;ü•ß Savoury implementation of the QUIC transport protocol and HTTP/3&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/cloudflare/quiche/master/quiche.svg?sanitize=true" alt="quiche" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/quiche"&gt;&lt;img src="https://img.shields.io/crates/v/quiche.svg?sanitize=true" alt="crates.io" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/quiche"&gt;&lt;img src="https://docs.rs/quiche/badge.svg?sanitize=true" alt="docs.rs" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/BSD-2-Clause"&gt;&lt;img src="https://img.shields.io/github/license/cloudflare/quiche.svg?sanitize=true" alt="license" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/cloudflare/quiche/stable.yml?branch=master" alt="build" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.quic.tech/quiche/"&gt;quiche&lt;/a&gt; is an implementation of the QUIC transport protocol and HTTP/3 as specified by the &lt;a href="https://quicwg.org/"&gt;IETF&lt;/a&gt;. It provides a low level API for processing QUIC packets and handling connection state. The application is responsible for providing I/O (e.g. sockets handling) as well as an event loop with support for timers.&lt;/p&gt; 
&lt;p&gt;For more information on how quiche came about and some insights into its design you can read a &lt;a href="https://blog.cloudflare.com/enjoy-a-slice-of-quic-and-rust/"&gt;post&lt;/a&gt; on Cloudflare's blog that goes into some more detail.&lt;/p&gt; 
&lt;h2&gt;Who uses quiche?&lt;/h2&gt; 
&lt;h3&gt;Cloudflare&lt;/h3&gt; 
&lt;p&gt;quiche powers Cloudflare edge network's &lt;a href="https://blog.cloudflare.com/http3-the-past-present-and-future/"&gt;HTTP/3 support&lt;/a&gt;. The &lt;a href="https://cloudflare-quic.com"&gt;cloudflare-quic.com&lt;/a&gt; website can be used for testing and experimentation.&lt;/p&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;p&gt;Android's DNS resolver uses quiche to &lt;a href="https://security.googleblog.com/2022/07/dns-over-http3-in-android.html"&gt;implement DNS over HTTP/3&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;curl&lt;/h3&gt; 
&lt;p&gt;quiche can be &lt;a href="https://github.com/curl/curl/raw/master/docs/HTTP3.md#quiche-version"&gt;integrated into curl&lt;/a&gt; to provide support for HTTP/3.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Command-line apps&lt;/h3&gt; 
&lt;p&gt;Before diving into the quiche API, here are a few examples on how to use the quiche tools provided as part of the &lt;a href="https://raw.githubusercontent.com/cloudflare/quiche/master/apps/"&gt;quiche-apps&lt;/a&gt; crate.&lt;/p&gt; 
&lt;p&gt;After cloning the project according to the command mentioned in the &lt;a href="https://raw.githubusercontent.com/cloudflare/quiche/master/#building"&gt;building&lt;/a&gt; section, the client can be run as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo run --bin quiche-client -- https://cloudflare-quic.com/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;while the server can be run as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo run --bin quiche-server -- --cert apps/src/bin/cert.crt --key apps/src/bin/cert.key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(note that the certificate provided is self-signed and should not be used in production)&lt;/p&gt; 
&lt;p&gt;Use the &lt;code&gt;--help&lt;/code&gt; command-line flag to get a more detailed description of each tool's options.&lt;/p&gt; 
&lt;h3&gt;Configuring connections&lt;/h3&gt; 
&lt;p&gt;The first step in establishing a QUIC connection using quiche is creating a &lt;a href="https://docs.quic.tech/quiche/struct.Config.html"&gt;&lt;code&gt;Config&lt;/code&gt;&lt;/a&gt; object:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let mut config = quiche::Config::new(quiche::PROTOCOL_VERSION)?;
config.set_application_protos(&amp;amp;[b"example-proto"]);

// Additional configuration specific to application and use case...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;a href="https://docs.quic.tech/quiche/struct.Config.html"&gt;&lt;code&gt;Config&lt;/code&gt;&lt;/a&gt; object controls important aspects of the QUIC connection such as QUIC version, ALPN IDs, flow control, congestion control, idle timeout and other properties or features.&lt;/p&gt; 
&lt;p&gt;QUIC is a general-purpose transport protocol and there are several configuration properties where there is no reasonable default value. For example, the permitted number of concurrent streams of any particular type is dependent on the application running over QUIC, and other use-case specific concerns.&lt;/p&gt; 
&lt;p&gt;quiche defaults several properties to zero, applications most likely need to set these to something else to satisfy their needs using the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_bidi"&gt;&lt;code&gt;set_initial_max_streams_bidi()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_uni"&gt;&lt;code&gt;set_initial_max_streams_uni()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_data"&gt;&lt;code&gt;set_initial_max_data()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_local"&gt;&lt;code&gt;set_initial_max_stream_data_bidi_local()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_remote"&gt;&lt;code&gt;set_initial_max_stream_data_bidi_remote()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_uni"&gt;&lt;code&gt;set_initial_max_stream_data_uni()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://docs.quic.tech/quiche/struct.Config.html"&gt;&lt;code&gt;Config&lt;/code&gt;&lt;/a&gt; also holds TLS configuration. This can be changed by mutators on the an existing object, or by constructing a TLS context manually and creating a configuration using &lt;a href="https://docs.quic.tech/quiche/struct.Config.html#method.with_boring_ssl_ctx_builder"&gt;&lt;code&gt;with_boring_ssl_ctx_builder()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;A configuration object can be shared among multiple connections.&lt;/p&gt; 
&lt;h3&gt;Connection setup&lt;/h3&gt; 
&lt;p&gt;On the client-side the &lt;a href="https://docs.quic.tech/quiche/fn.connect.html"&gt;&lt;code&gt;connect()&lt;/code&gt;&lt;/a&gt; utility function can be used to create a new connection, while &lt;a href="https://docs.quic.tech/quiche/fn.accept.html"&gt;&lt;code&gt;accept()&lt;/code&gt;&lt;/a&gt; is for servers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;// Client connection.
let conn = quiche::connect(Some(&amp;amp;server_name), &amp;amp;scid, local, peer, &amp;amp;mut config)?;

// Server connection.
let conn = quiche::accept(&amp;amp;scid, None, local, peer, &amp;amp;mut config)?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Handling incoming packets&lt;/h3&gt; 
&lt;p&gt;Using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.recv"&gt;&lt;code&gt;recv()&lt;/code&gt;&lt;/a&gt; method the application can process incoming packets that belong to that connection from the network:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let to = socket.local_addr().unwrap();

loop {
    let (read, from) = socket.recv_from(&amp;amp;mut buf).unwrap();

    let recv_info = quiche::RecvInfo { from, to };

    let read = match conn.recv(&amp;amp;mut buf[..read], recv_info) {
        Ok(v) =&amp;gt; v,

        Err(e) =&amp;gt; {
            // An error occurred, handle it.
            break;
        },
    };
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Generating outgoing packets&lt;/h3&gt; 
&lt;p&gt;Outgoing packet are generated using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.send"&gt;&lt;code&gt;send()&lt;/code&gt;&lt;/a&gt; method instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;loop {
    let (write, send_info) = match conn.send(&amp;amp;mut out) {
        Ok(v) =&amp;gt; v,

        Err(quiche::Error::Done) =&amp;gt; {
            // Done writing.
            break;
        },

        Err(e) =&amp;gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;amp;out[..write], &amp;amp;send_info.to).unwrap();
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When packets are sent, the application is responsible for maintaining a timer to react to time-based connection events. The timer expiration can be obtained using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.timeout"&gt;&lt;code&gt;timeout()&lt;/code&gt;&lt;/a&gt; method.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;let timeout = conn.timeout();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The application is responsible for providing a timer implementation, which can be specific to the operating system or networking framework used. When a timer expires, the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.on_timeout"&gt;&lt;code&gt;on_timeout()&lt;/code&gt;&lt;/a&gt; method should be called, after which additional packets might need to be sent on the network:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;// Timeout expired, handle it.
conn.on_timeout();

// Send more packets as needed after timeout.
loop {
    let (write, send_info) = match conn.send(&amp;amp;mut out) {
        Ok(v) =&amp;gt; v,

        Err(quiche::Error::Done) =&amp;gt; {
            // Done writing.
            break;
        },

        Err(e) =&amp;gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;amp;out[..write], &amp;amp;send_info.to).unwrap();
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Pacing&lt;/h4&gt; 
&lt;p&gt;It is recommended that applications &lt;a href="https://datatracker.ietf.org/doc/html/rfc9002#section-7.7"&gt;pace&lt;/a&gt; sending of outgoing packets to avoid creating packet bursts that could cause short-term congestion and losses in the network.&lt;/p&gt; 
&lt;p&gt;quiche exposes pacing hints for outgoing packets through the [&lt;code&gt;at&lt;/code&gt;] field of the [&lt;code&gt;SendInfo&lt;/code&gt;] structure that is returned by the &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.send"&gt;&lt;code&gt;send()&lt;/code&gt;&lt;/a&gt; method. This field represents the time when a specific packet should be sent into the network.&lt;/p&gt; 
&lt;p&gt;Applications can use these hints by artificially delaying the sending of packets through platform-specific mechanisms (such as the &lt;a href="https://man7.org/linux/man-pages/man8/tc-etf.8.html"&gt;&lt;code&gt;SO_TXTIME&lt;/code&gt;&lt;/a&gt; socket option on Linux), or custom methods (for example by using user-space timers).&lt;/p&gt; 
&lt;h3&gt;Sending and receiving stream data&lt;/h3&gt; 
&lt;p&gt;After some back and forth, the connection will complete its handshake and will be ready for sending or receiving application data.&lt;/p&gt; 
&lt;p&gt;Data can be sent on a stream by using the &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.stream_send"&gt;&lt;code&gt;stream_send()&lt;/code&gt;&lt;/a&gt; method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;if conn.is_established() {
    // Handshake completed, send some data on stream 0.
    conn.stream_send(0, b"hello", true)?;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The application can check whether there are any readable streams by using the connection's &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.readable"&gt;&lt;code&gt;readable()&lt;/code&gt;&lt;/a&gt; method, which returns an iterator over all the streams that have outstanding data to read.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://docs.quic.tech/quiche/struct.Connection.html#method.stream_recv"&gt;&lt;code&gt;stream_recv()&lt;/code&gt;&lt;/a&gt; method can then be used to retrieve the application data from the readable stream:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;if conn.is_established() {
    // Iterate over readable streams.
    for stream_id in conn.readable() {
        // Stream is readable, read until there's no more data.
        while let Ok((read, fin)) = conn.stream_recv(stream_id, &amp;amp;mut buf) {
            println!("Got {} bytes on stream {}", read, stream_id);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;HTTP/3&lt;/h3&gt; 
&lt;p&gt;The quiche &lt;a href="https://docs.quic.tech/quiche/h3/index.html"&gt;HTTP/3 module&lt;/a&gt; provides a high level API for sending and receiving HTTP requests and responses on top of the QUIC transport protocol.&lt;/p&gt; 
&lt;p&gt;Have a look at the [quiche/examples/] directory for more complete examples on how to use the quiche API, including examples on how to use quiche in C/C++ applications (see below for more information).&lt;/p&gt; 
&lt;h2&gt;Calling quiche from C/C++&lt;/h2&gt; 
&lt;p&gt;quiche exposes a &lt;a href="https://github.com/cloudflare/quiche/raw/master/quiche/include/quiche.h"&gt;thin C API&lt;/a&gt; on top of the Rust API that can be used to more easily integrate quiche into C/C++ applications (as well as in other languages that allow calling C APIs via some form of FFI). The C API follows the same design of the Rust one, modulo the constraints imposed by the C language itself.&lt;/p&gt; 
&lt;p&gt;When running &lt;code&gt;cargo build&lt;/code&gt;, a static library called &lt;code&gt;libquiche.a&lt;/code&gt; will be built automatically alongside the Rust one. This is fully stand-alone and can be linked directly into C/C++ applications.&lt;/p&gt; 
&lt;p&gt;Note that in order to enable the FFI API, the &lt;code&gt;ffi&lt;/code&gt; feature must be enabled (it is disabled by default), by passing &lt;code&gt;--features ffi&lt;/code&gt; to &lt;code&gt;cargo&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;quiche requires Rust 1.83 or later to build. The latest stable Rust release can be installed using &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Once the Rust build environment is setup, the quiche source code can be fetched using git:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ git clone --recursive https://github.com/cloudflare/quiche
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and then built using cargo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo build --examples
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;cargo can also be used to run the testsuite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo test
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that &lt;a href="https://boringssl.googlesource.com/boringssl/"&gt;BoringSSL&lt;/a&gt;, which is used to implement QUIC's cryptographic handshake based on TLS, needs to be built and linked to quiche. This is done automatically when building quiche using cargo, but requires the &lt;code&gt;cmake&lt;/code&gt; command to be available during the build process. On Windows you also need &lt;a href="https://www.nasm.us/"&gt;NASM&lt;/a&gt;. The &lt;a href="https://github.com/google/boringssl/raw/master/BUILDING.md"&gt;official BoringSSL documentation&lt;/a&gt; has more details.&lt;/p&gt; 
&lt;p&gt;In alternative you can use your own custom build of BoringSSL by configuring the BoringSSL directory with the &lt;code&gt;QUICHE_BSSL_PATH&lt;/code&gt; environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ QUICHE_BSSL_PATH="/path/to/boringssl" cargo build --examples
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively you can use &lt;a href="https://github.com/quictls/openssl"&gt;OpenSSL/quictls&lt;/a&gt;. To enable quiche to use this vendor the &lt;code&gt;openssl&lt;/code&gt; feature can be added to the &lt;code&gt;--feature&lt;/code&gt; list. Be aware that &lt;code&gt;0-RTT&lt;/code&gt; is not supported if this vendor is used.&lt;/p&gt; 
&lt;h3&gt;Building for Android&lt;/h3&gt; 
&lt;p&gt;Building quiche for Android (NDK version 19 or higher, 21 recommended), can be done using &lt;a href="https://docs.rs/crate/cargo-ndk"&gt;cargo-ndk&lt;/a&gt; (v2.0 or later).&lt;/p&gt; 
&lt;p&gt;First the &lt;a href="https://developer.android.com/ndk"&gt;Android NDK&lt;/a&gt; needs to be installed, either using Android Studio or directly, and the &lt;code&gt;ANDROID_NDK_HOME&lt;/code&gt; environment variable needs to be set to the NDK installation path, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ export ANDROID_NDK_HOME=/usr/local/share/android-ndk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then the Rust toolchain for the Android architectures needed can be installed as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ rustup target add aarch64-linux-android armv7-linux-androideabi i686-linux-android x86_64-linux-android
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the minimum API level is 21 for all target architectures.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.rs/crate/cargo-ndk"&gt;cargo-ndk&lt;/a&gt; (v2.0 or later) also needs to be installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo install cargo-ndk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally the quiche library can be built using the following procedure. Note that the &lt;code&gt;-t &amp;lt;architecture&amp;gt;&lt;/code&gt; and &lt;code&gt;-p &amp;lt;NDK version&amp;gt;&lt;/code&gt; options are mandatory.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo ndk -t arm64-v8a -p 21 -- build --features ffi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://github.com/cloudflare/quiche/raw/master/tools/android/build_android_ndk19.sh"&gt;build_android_ndk19.sh&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h3&gt;Building for iOS&lt;/h3&gt; 
&lt;p&gt;To build quiche for iOS, you need the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install Xcode command-line tools. You can install them with Xcode or with the following command:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ xcode-select --install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the Rust toolchain for iOS architectures:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ rustup target add aarch64-apple-ios x86_64-apple-ios
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;cargo-lipo&lt;/code&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo install cargo-lipo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build libquiche, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo lipo --features ffi
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ cargo lipo --features ffi --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;iOS build is tested in Xcode 10.1 and Xcode 11.2.&lt;/p&gt; 
&lt;h3&gt;Building Docker images&lt;/h3&gt; 
&lt;p&gt;In order to build the Docker images, simply run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; $ make docker-build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find the quiche Docker images on the following Docker Hub repositories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/repository/docker/cloudflare/quiche"&gt;cloudflare/quiche&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/repository/docker/cloudflare/quiche-qns"&gt;cloudflare/quiche-qns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;code&gt;latest&lt;/code&gt; tag will be updated whenever quiche master branch updates.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;cloudflare/quiche&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Provides a server and client installed in /usr/local/bin.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;cloudflare/quiche-qns&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Provides the script to test quiche within the &lt;a href="https://github.com/marten-seemann/quic-interop-runner"&gt;quic-interop-runner&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Copyright&lt;/h2&gt; 
&lt;p&gt;Copyright (C) 2018-2019, Cloudflare, Inc.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/cloudflare/quiche/tree/master/COPYING"&gt;COPYING&lt;/a&gt; for the license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>RustPython/RustPython</title>
      <link>https://github.com/RustPython/RustPython</link>
      <description>&lt;p&gt;A Python Interpreter written in Rust&lt;/p&gt;&lt;hr&gt;&lt;img src="https://raw.githubusercontent.com/RustPython/RustPython/main/logo.png" width="125" height="125" align="right" /&gt; 
&lt;h1&gt;&lt;a href="https://rustpython.github.io/"&gt;RustPython&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;A Python-3 (CPython &amp;gt;= 3.13.0) Interpreter written in Rust &lt;span&gt;üêç&lt;/span&gt; &lt;span&gt;üò±&lt;/span&gt; &lt;span&gt;ü§ò&lt;/span&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/RustPython/RustPython/actions?query=workflow%3ACI"&gt;&lt;img src="https://github.com/RustPython/RustPython/workflows/CI/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/RustPython/RustPython"&gt;&lt;img src="https://codecov.io/gh/RustPython/RustPython/branch/main/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-green.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://github.com/RustPython/RustPython/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/RustPython/RustPython.svg?sanitize=true" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/vru8NypEhv"&gt;&lt;img src="https://discordapp.com/api/guilds/1043121930691149845/widget.png?style=shield" alt="Discord Shield" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/rustpython/"&gt;&lt;img src="https://docs.rs/rustpython/badge.svg?sanitize=true" alt="docs.rs" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/rustpython"&gt;&lt;img src="https://img.shields.io/crates/v/rustpython" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://deps.rs/crate/rustpython/0.1.1"&gt;&lt;img src="https://deps.rs/crate/rustpython/0.1.1/status.svg?sanitize=true" alt="dependency status" /&gt;&lt;/a&gt; &lt;a href="https://gitpod.io#https://github.com/RustPython/RustPython"&gt;&lt;img src="https://img.shields.io/static/v1?label=Open%20in&amp;amp;message=Gitpod&amp;amp;color=1aa6e4&amp;amp;logo=gitpod" alt="Open in Gitpod" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Check out our &lt;a href="https://rustpython.github.io/demo/"&gt;online demo&lt;/a&gt; running on WebAssembly.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;RustPython requires Rust latest stable version (e.g 1.67.1 at February 7th 2023). If you don't currently have Rust installed on your system you can do so by following the instructions at &lt;a href="https://rustup.rs/"&gt;rustup.rs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To check the version of Rust you're currently running, use &lt;code&gt;rustc --version&lt;/code&gt;. If you wish to update, &lt;code&gt;rustup update stable&lt;/code&gt; will update your Rust installation to the most recent stable release.&lt;/p&gt; 
&lt;p&gt;To build RustPython locally, first, clone the source code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/RustPython/RustPython
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RustPython uses symlinks to manage python libraries in &lt;code&gt;Lib/&lt;/code&gt;. If on windows, running the following helps:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git config core.symlinks true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can change into the RustPython directory and run the demo (Note: &lt;code&gt;--release&lt;/code&gt; is needed to prevent stack overflow on Windows):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ cd RustPython
$ cargo run --release demo_closures.py
Hello, RustPython!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use the interactive shell:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ cargo run --release
Welcome to rustpython
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; 2+2
4
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;NOTE: For windows users, please set &lt;code&gt;RUSTPYTHONPATH&lt;/code&gt; environment variable as &lt;code&gt;Lib&lt;/code&gt; path in project directory. (e.g. When RustPython directory is &lt;code&gt;C:\RustPython&lt;/code&gt;, set &lt;code&gt;RUSTPYTHONPATH&lt;/code&gt; as &lt;code&gt;C:\RustPython\Lib&lt;/code&gt;)&lt;/p&gt; 
&lt;p&gt;You can also install and run RustPython with the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ cargo install --git https://github.com/RustPython/RustPython rustpython
$ rustpython
Welcome to the magnificent Rust Python interpreter
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you'd like to make https requests, you can enable the &lt;code&gt;ssl&lt;/code&gt; feature, which also lets you install the &lt;code&gt;pip&lt;/code&gt; package manager. Note that on Windows, you may need to install OpenSSL, or you can enable the &lt;code&gt;ssl-vendor&lt;/code&gt; feature instead, which compiles OpenSSL for you but requires a C compiler, perl, and &lt;code&gt;make&lt;/code&gt;. OpenSSL version 3 is expected and tested in CI. Older versions may not work.&lt;/p&gt; 
&lt;p&gt;Once you've installed rustpython with SSL support, you can install pip by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install --git https://github.com/RustPython/RustPython --features ssl
rustpython --install-pip
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also install RustPython through the &lt;code&gt;conda&lt;/code&gt; package manager, though this isn't officially supported and may be out of date:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda install rustpython -c conda-forge
rustpython
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;WASI&lt;/h3&gt; 
&lt;p&gt;You can compile RustPython to a standalone WebAssembly WASI module so it can run anywhere.&lt;/p&gt; 
&lt;p&gt;Build&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo build --target wasm32-wasip1 --no-default-features --features freeze-stdlib,stdlib --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run by wasmer&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wasmer run --dir `pwd` -- target/wasm32-wasip1/release/rustpython.wasm `pwd`/extra_tests/snippets/stdlib_random.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run by wapm&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ wapm install rustpython
$ wapm run rustpython
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; 2+2
4
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Building the WASI file&lt;/h4&gt; 
&lt;p&gt;You can build the WebAssembly WASI file with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo build --release --target wasm32-wasip1 --features="freeze-stdlib"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: we use the &lt;code&gt;freeze-stdlib&lt;/code&gt; to include the standard library inside the binary. You also have to run once &lt;code&gt;rustup target add wasm32-wasip1&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;JIT (Just in time) compiler&lt;/h3&gt; 
&lt;p&gt;RustPython has a &lt;strong&gt;very&lt;/strong&gt; experimental JIT compiler that compile python functions into native code.&lt;/p&gt; 
&lt;h4&gt;Building&lt;/h4&gt; 
&lt;p&gt;By default the JIT compiler isn't enabled, it's enabled with the &lt;code&gt;jit&lt;/code&gt; cargo feature.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --features jit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This requires autoconf, automake, libtool, and clang to be installed.&lt;/p&gt; 
&lt;h4&gt;Using&lt;/h4&gt; 
&lt;p&gt;To compile a function, call &lt;code&gt;__jit__()&lt;/code&gt; on it.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def foo():
    a = 5
    return 10 + a

foo.__jit__()  # this will compile foo to native code and subsequent calls will execute that native code
assert foo() == 15
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Embedding RustPython into your Rust Applications&lt;/h2&gt; 
&lt;p&gt;Interested in exposing Python scripting in an application written in Rust, perhaps to allow quickly tweaking logic where Rust's compile times would be inhibitive? Then &lt;code&gt;examples/hello_embed.rs&lt;/code&gt; and &lt;code&gt;examples/mini_repl.rs&lt;/code&gt; may be of some assistance.&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;RustPython is in development, and while the interpreter certainly can be used in interesting use cases like running Python in WASM and embedding into a Rust project, do note that RustPython is not totally production-ready.&lt;/p&gt; 
&lt;p&gt;Contribution is more than welcome! See our contribution section for more information on this.&lt;/p&gt; 
&lt;h2&gt;Conference videos&lt;/h2&gt; 
&lt;p&gt;Checkout those talks on conferences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=nJDY9ASuiLc"&gt;FOSDEM 2019&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=YMmio0JHy_Y"&gt;EuroPython 2018&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Use cases&lt;/h2&gt; 
&lt;p&gt;Although RustPython is a fairly young project, a few people have used it to make cool projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GreptimeTeam/greptimedb"&gt;GreptimeDB&lt;/a&gt;: an open-source, cloud-native, distributed time-series database. Using RustPython for embedded scripting.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pickitup247/pyckitup"&gt;pyckitup&lt;/a&gt;: a game engine written in rust.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/robot-rumble/logic/"&gt;Robot Rumble&lt;/a&gt;: an arena-based AI competition platform&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charliermarsh/ruff/"&gt;Ruff&lt;/a&gt;: an extremely fast Python linter, written in Rust&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Goals&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Full Python-3 environment entirely in Rust (not CPython bindings)&lt;/li&gt; 
 &lt;li&gt;A clean implementation without compatibility hacks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Currently along with other areas of the project, documentation is still in an early phase.&lt;/p&gt; 
&lt;p&gt;You can read the &lt;a href="https://docs.rs/rustpython"&gt;online documentation&lt;/a&gt; for the latest release, or the &lt;a href="https://rustpython.github.io/docs/"&gt;user guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also generate documentation locally by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cargo doc # Including documentation for all dependencies
cargo doc --no-deps --all # Excluding all dependencies
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Documentation HTML files can then be found in the &lt;code&gt;target/doc&lt;/code&gt; directory or you can append &lt;code&gt;--open&lt;/code&gt; to the previous commands to have the documentation open automatically on your default browser.&lt;/p&gt; 
&lt;p&gt;For a high level overview of the components, see the &lt;a href="https://raw.githubusercontent.com/RustPython/RustPython/main/architecture/architecture.md"&gt;architecture&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are more than welcome, and in many cases we are happy to guide contributors through PRs or on Discord. Please refer to the &lt;a href="https://raw.githubusercontent.com/RustPython/RustPython/main/DEVELOPMENT.md"&gt;development guide&lt;/a&gt; as well for tips on developments.&lt;/p&gt; 
&lt;p&gt;With that in mind, please note this project is maintained by volunteers, some of the best ways to get started are below:&lt;/p&gt; 
&lt;p&gt;Most tasks are listed in the &lt;a href="https://github.com/RustPython/RustPython/issues"&gt;issue tracker&lt;/a&gt;. Check issues labeled with &lt;a href="https://github.com/RustPython/RustPython/issues?q=label%3A%22good+first+issue%22+is%3Aissue+is%3Aopen+"&gt;good first issue&lt;/a&gt; if you wish to start coding.&lt;/p&gt; 
&lt;p&gt;To enhance CPython compatibility, try to increase unittest coverage by checking this article: &lt;a href="https://rustpython.github.io/guideline/2020/04/04/how-to-contribute-by-cpython-unittest.html"&gt;How to contribute to RustPython by CPython unittest&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Another approach is to checkout the source code: builtin functions and object methods are often the simplest and easiest way to contribute.&lt;/p&gt; 
&lt;p&gt;You can also simply run &lt;code&gt;python -I whats_left.py&lt;/code&gt; to assist in finding any unimplemented method.&lt;/p&gt; 
&lt;h2&gt;Compiling to WebAssembly&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/RustPython/RustPython/main/wasm/README.md"&gt;See this doc&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/vru8NypEhv"&gt;&lt;img src="https://discordapp.com/api/guilds/1043121930691149845/widget.png?style=banner2" alt="Discord Banner" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Chat with us on &lt;a href="https://discord.gg/vru8NypEhv"&gt;Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Code of conduct&lt;/h2&gt; 
&lt;p&gt;Our code of conduct &lt;a href="https://raw.githubusercontent.com/RustPython/RustPython/main/code-of-conduct.md"&gt;can be found here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credit&lt;/h2&gt; 
&lt;p&gt;The initial work was based on &lt;a href="https://github.com/windelbouwman/rspython"&gt;windelbouwman/rspython&lt;/a&gt; and &lt;a href="https://github.com/shinglyu/RustPython"&gt;shinglyu/RustPython&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;p&gt;These are some useful links to related projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ProgVal/pythonvm-rust"&gt;https://github.com/ProgVal/pythonvm-rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shinglyu/RustPython"&gt;https://github.com/shinglyu/RustPython&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/windelbouwman/rspython"&gt;https://github.com/windelbouwman/rspython&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT license. Please see the &lt;a href="https://raw.githubusercontent.com/RustPython/RustPython/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for more details.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/RustPython/RustPython/main/logo.png"&gt;project logo&lt;/a&gt; is licensed under the CC-BY-4.0 license. Please see the &lt;a href="https://raw.githubusercontent.com/RustPython/RustPython/main/LICENSE-logo"&gt;LICENSE-logo&lt;/a&gt; file for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zackriya-Solutions/meeting-minutes</title>
      <link>https://github.com/Zackriya-Solutions/meeting-minutes</link>
      <description>&lt;p&gt;A free and open source, self hosted Ai based live meeting note taker and minutes summary generator that can completely run in your Local device (Mac OS and windows OS Support added. Working on adding linux support soon) https://meetily.ai/ is meetly ai&lt;/p&gt;&lt;hr&gt;&lt;div align="center" style="border-bottom: none"&gt; 
 &lt;h1&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/Meetily-6.png" style="border-radius: 10px;" /&gt; &lt;br /&gt; Privacy-First AI Meeting Assistant &lt;/h1&gt; 
 &lt;a href="https://trendshift.io/repositories/13272" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13272" alt="Zackriya-Solutions%2Fmeeting-minutes | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases/"&gt;&lt;img src="https://img.shields.io/badge/Pre_Release-Link-brightgreen" alt="Pre-Release" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"&gt;&lt;img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/zackriya-solutions/meeting-minutes?style=flat" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"&gt; &lt;img alt="GitHub Downloads (all assets, all releases)" src="https://img.shields.io/github/downloads/zackriya-solutions/meeting-minutes/total?style=plastic" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue" alt="License" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"&gt;&lt;img src="https://img.shields.io/badge/Supported_OS-macOS,_Windows-white" alt="Supported OS" /&gt;&lt;/a&gt; 
 &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases"&gt;&lt;img alt="GitHub Tag" src="https://img.shields.io/github/v/tag/zackriya-solutions/meeting-minutes?include_prereleases&amp;amp;color=yellow" /&gt; &lt;/a&gt; 
 &lt;br /&gt; 
 &lt;h3&gt; &lt;br /&gt; Open Source ‚Ä¢ Privacy-First ‚Ä¢ Enterprise-Ready &lt;/h3&gt; 
 &lt;p align="center"&gt; Get latest &lt;a href="https://www.zackriya.com/meetily-subscribe/"&gt;&lt;b&gt;Product updates&lt;/b&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt; &lt;a href="https://meetily.zackriya.com"&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.linkedin.com/company/106363062/"&gt;&lt;b&gt;LinkedIn&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.gg/crRymMQBFH"&gt;&lt;b&gt;Meetily Discord&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.com/invite/vCFJvN4BwJ"&gt;&lt;b&gt;Privacy-First AI&lt;/b&gt;&lt;/a&gt; ‚Ä¢ &lt;a href="https://www.reddit.com/r/meetily/"&gt;&lt;b&gt;Reddit&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;A privacy-first AI meeting assistant that captures, transcribes, and summarizes meetings entirely on your infrastructure. Built by expert AI engineers passionate about data sovereignty and open source solutions. Perfect for enterprises that need advanced meeting intelligence without compromising on privacy, compliance, or control.&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/meetily_demo.gif" width="650" alt="Meetily Demo" /&gt; &lt;br /&gt; &lt;a href="https://youtu.be/6FnhSC_eSz8"&gt;View full Demo Video&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;details&gt; 
 &lt;summary&gt;Table of Contents&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#why-meetily"&gt;Why Meetily?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#key-features-in-action"&gt;Key Features in Action&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#system-architecture"&gt;System Architecture&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#for-developers"&gt;For Developers&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#enterprise-solutions"&gt;Enterprise Solutions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Meetily is a privacy-first AI meeting assistant that runs entirely on your local machine. It captures your meetings, transcribes them in real-time, and generates summaries, all without sending any data to the cloud. This makes it the perfect solution for professionals and enterprises who need to maintain complete control over their sensitive information.&lt;/p&gt; 
&lt;h2&gt;Why Meetily?&lt;/h2&gt; 
&lt;p&gt;While there are many meeting transcription tools available, this solution stands out by offering:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy First:&lt;/strong&gt; All processing happens locally on your device.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cost-Effective:&lt;/strong&gt; Uses open-source AI models instead of expensive APIs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible:&lt;/strong&gt; Works offline and supports multiple meeting platforms.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable:&lt;/strong&gt; Self-host and modify for your specific needs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;The Privacy Problem&lt;/summary&gt; 
 &lt;p&gt;Meeting AI tools create significant privacy and compliance risks across all sectors:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;$4.4M average cost per data breach&lt;/strong&gt; (IBM 2024)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;‚Ç¨5.88 billion in GDPR fines&lt;/strong&gt; issued by 2025&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;400+ unlawful recording cases&lt;/strong&gt; filed in California this year&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Whether you're a defense consultant, enterprise executive, legal professional, or healthcare provider, your sensitive discussions shouldn't live on servers you don't control. Cloud meeting tools promise convenience but deliver privacy nightmares with unclear data storage practices and potential unauthorized access.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Meetily solves this:&lt;/strong&gt; Complete data sovereignty on your infrastructure, zero vendor lock-in, and full control over your sensitive conversations.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local First:&lt;/strong&gt; All processing is done on your machine. No data ever leaves your computer.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time Transcription:&lt;/strong&gt; Get a live transcript of your meeting as it happens.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI-Powered Summaries:&lt;/strong&gt; Generate summaries of your meetings using powerful language models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Platform:&lt;/strong&gt; Works on macOS, Windows, and Linux.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source:&lt;/strong&gt; Meetily is open source and free to use.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;ü™ü &lt;strong&gt;Windows&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download the latest &lt;code&gt;x64-setup.exe&lt;/code&gt; from &lt;a href="https://github.com/Zackriya-Solutions/meeting-minutes/releases/latest"&gt;Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Right-click the downloaded file ‚Üí &lt;strong&gt;Properties&lt;/strong&gt; ‚Üí Check &lt;strong&gt;Unblock&lt;/strong&gt; ‚Üí Click &lt;strong&gt;OK&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Run the installer (if Windows shows a security warning: Click &lt;strong&gt;More info&lt;/strong&gt; ‚Üí &lt;strong&gt;Run anyway&lt;/strong&gt;)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;üçé &lt;strong&gt;macOS&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Install via Homebrew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Meetily (single application - everything included!)
brew tap zackriya-solutions/meetily
brew install --cask meetily
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Upgrading from v0.0.5?&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew update
brew upgrade --cask meetily
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then open &lt;strong&gt;Meetily&lt;/strong&gt; from Applications folder.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Data Migration:&lt;/strong&gt; The application will ask whether to import your old database through a popup window on first launch.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üêß &lt;strong&gt;Linux&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Build from source following our detailed guides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/building_in_linux.md"&gt;Building on Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/BUILDING.md"&gt;General Build Instructions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick start:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Zackriya-Solutions/meeting-minutes
cd meeting-minutes/frontend
pnpm install
pnpm run tauri:build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Key Features in Action&lt;/h2&gt; 
&lt;h3&gt;üéØ Local Transcription&lt;/h3&gt; 
&lt;p&gt;Transcribe meetings entirely on your device using &lt;strong&gt;Whisper&lt;/strong&gt; or &lt;strong&gt;Parakeet&lt;/strong&gt; models. No cloud required.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/home.png" width="650" style="border-radius: 10px;" alt="Meetily Demo" /&gt; &lt;/p&gt; 
&lt;h3&gt;ü§ñ AI-Powered Summaries&lt;/h3&gt; 
&lt;p&gt;Generate meeting summaries with your choice of AI provider. &lt;strong&gt;Ollama&lt;/strong&gt; (local) is recommended, with support for Claude, Groq, OpenRouter, and OpenAI.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/summary.png" width="650" style="border-radius: 10px;" alt="Summary generation" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/editor1.png" width="650" style="border-radius: 10px;" alt="Editor Summary generation" /&gt; &lt;/p&gt; 
&lt;h3&gt;üîí Privacy-First Design&lt;/h3&gt; 
&lt;p&gt;All data stays on your machine. Transcription models, recordings, and transcripts are stored locally.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/settings.png" width="650" style="border-radius: 10px;" alt="Local Transcription and storage" /&gt; &lt;/p&gt; 
&lt;h3&gt;üéôÔ∏è Professional Audio Mixing&lt;/h3&gt; 
&lt;p&gt;Capture microphone and system audio simultaneously with intelligent ducking and clipping prevention.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/audio.png" width="650" style="border-radius: 10px;" alt="Device selection" /&gt; &lt;/p&gt; 
&lt;h3&gt;‚ö° GPU Acceleration&lt;/h3&gt; 
&lt;p&gt;Built-in support for hardware acceleration across platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: Apple Silicon (Metal) + CoreML&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows/Linux&lt;/strong&gt;: NVIDIA (CUDA), AMD/Intel (Vulkan)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Automatically enabled at build time - no configuration needed.&lt;/p&gt; 
&lt;h2&gt;System Architecture&lt;/h2&gt; 
&lt;p&gt;Meetily is a single, self-contained application built with &lt;a href="https://tauri.app/"&gt;Tauri&lt;/a&gt;. It uses a Rust-based backend to handle all the core logic, and a Next.js frontend for the user interface.&lt;/p&gt; 
&lt;p&gt;For more details, see the &lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/architecture.md"&gt;Architecture documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;For Developers&lt;/h2&gt; 
&lt;p&gt;If you want to contribute to Meetily or build it from source, you'll need to have Rust and Node.js installed. For detailed build instructions, please see the &lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/docs/BUILDING.md"&gt;Building from Source guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Enterprise Solutions&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Meetily Enterprise&lt;/strong&gt; is available for on-premise deployment, giving organizations complete control over their meeting intelligence infrastructure. This enterprise version includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;100% On-Premise Deployment&lt;/strong&gt;: Your data never leaves your infrastructure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Centralized Management&lt;/strong&gt;: Support for 100+ users with administrative controls&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero Vendor Lock-in&lt;/strong&gt;: Open source MIT license ensures complete ownership&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compliance Ready&lt;/strong&gt;: Meet GDPR, SOX, HIPAA, and industry-specific requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Integration&lt;/strong&gt;: APIs and webhooks for enterprise systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For enterprise solutions: &lt;a href="https://meetily.zackriya.com"&gt;https://meetily.zackriya.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the community! If you have any questions or suggestions, please open an issue or submit a pull request. Please follow the established project structure and guidelines. For more details, refer to the &lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License - Feel free to use this project for your own purposes.&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;Thanks for all the contributions. Our community is what makes this project possible. Below is the list of contributors:&lt;/p&gt; 
&lt;a href="https://github.com/zackriya-solutions/meeting-minutes/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=zackriya-solutions/meeting-minutes" /&gt; &lt;/a&gt; 
&lt;p&gt;We welcome contributions from the community! If you have any questions or suggestions, please open an issue or submit a pull request. Please follow the established project structure and guidelines. For more details, refer to the &lt;a href="https://raw.githubusercontent.com/Zackriya-Solutions/meeting-minutes/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;We borrowed some code from &lt;a href="https://github.com/ggerganov/whisper.cpp"&gt;Whisper.cpp&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed some code from &lt;a href="https://github.com/mediar-ai/screenpipe"&gt;Screenpipe&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We borrowed some code from &lt;a href="https://crates.io/crates/transcribe-rs"&gt;transcribe-rs&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;strong&gt;NVIDIA&lt;/strong&gt; for developing the &lt;strong&gt;Parakeet&lt;/strong&gt; model.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://huggingface.co/istupakov/parakeet-tdt-0.6b-v3-onnx"&gt;istupakov&lt;/a&gt; for providing the &lt;strong&gt;ONNX conversion&lt;/strong&gt; of the Parakeet model.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Zackriya-Solutions/meeting-minutes&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Zackriya-Solutions/meeting-minutes&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Fredolx/open-tv</title>
      <link>https://github.com/Fredolx/open-tv</link>
      <description>&lt;p&gt;Ultra-fast, simple and powerful cross-platform IPTV app&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Open TV&lt;/h1&gt; 
&lt;p&gt;Completely rewritten to accommodate new features and to be even speedier, Open TV has been carefully crafted to deliver the best IPTV experience.&lt;/p&gt; 
&lt;a href="https://apps.microsoft.com/detail/9PBWX3RKR1QX?launch=true&amp;amp;mode=mini"&gt; &lt;img src="https://get.microsoft.com/images/en-us%20dark.svg?sanitize=true" width="350" /&gt; &lt;/a&gt; 
&lt;a href="https://flathub.org/apps/dev.fredol.open-tv"&gt; &lt;img src="https://dl.flathub.org/assets/badges/flathub-badge-en.svg?sanitize=true" width="300" /&gt; &lt;/a&gt; 
&lt;a href="https://aur.archlinux.org/packages/open-tv-bin"&gt; &lt;img src="https://raw.githubusercontent.com/Fredolx/open-tv/refs/heads/main/readme_imgs/aur-open-tv.svg?sanitize=true" width="350" /&gt; &lt;/a&gt; 
&lt;a href="https://apps.apple.com/ca/app/open-tv-open-source-iptv/id6742751800"&gt; &lt;img src="https://raw.githubusercontent.com/Fredolx/open-tv/refs/heads/main/readme_imgs/app-store.svg?sanitize=true" width="300" /&gt; &lt;/a&gt; 
&lt;a href="https://play.google.com/store/apps/details?id=dev.fredol.open_tv"&gt; &lt;img src="https://raw.githubusercontent.com/Fredolx/open-tv/refs/heads/main/readme_imgs/gplay.png" /&gt; &lt;/a&gt; 
&lt;h1&gt;This project NEEDS your help. Please consider donating on &lt;a href="https://github.com/sponsors/Fredolx"&gt;Github&lt;/a&gt;, &lt;a href="https://paypal.me/fredolx"&gt;Paypal&lt;/a&gt; or directly by &lt;a href="https://raw.githubusercontent.com/Fredolx/open-tv/main/#donate-crypto-thank-you"&gt;crypto&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;I've been developing and maintaining this project alone and for entirely for free over the past 2 years. I am in dire need of support to continue developing this project. I've never added annoying donation pop-ups or anything of the sort to make sure you have the fastest and cleanest IPTV experience and I'm committed to keep this project FREE &amp;amp; OPEN-SOURCE. To keep that commitment, I need your support!&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/Fredolx/open-tv/raw/main/screenshots/demo1.png" alt="Image of the app" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Import your IPTV channels from any source (M3U File, M3U link, Xtream) üóÉÔ∏è&lt;/li&gt; 
 &lt;li&gt;Record while watching üé•&lt;/li&gt; 
 &lt;li&gt;Multi IPTV sources üéä&lt;/li&gt; 
 &lt;li&gt;Control the UI from a TV remote üì∫&lt;/li&gt; 
 &lt;li&gt;Super low RAM usage, crazy speeds, and instant search üöÖ&lt;/li&gt; 
 &lt;li&gt;Refresh your sources when you need it üîÑ&lt;/li&gt; 
 &lt;li&gt;Add channels to favorites üåü&lt;/li&gt; 
 &lt;li&gt;Make your own custom channels&lt;/li&gt; 
 &lt;li&gt;Share your custom channels with friends&lt;/li&gt; 
 &lt;li&gt;Re-stream channels to friends or other devices (phone, tv)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;If you are on Windows or use the flatpak on Linux; SKIP THIS PART.&lt;/p&gt; 
&lt;p&gt;The app depends on mpv, ffmpeg and yt-dlp. If you are on MacOS, you must use Brew or MacPorts to install those dependencies.&lt;/p&gt; 
&lt;p&gt;On Fedora, you must add rpmfusion to install those packages.&lt;/p&gt; 
&lt;p&gt;On Debian or LTS distro, I would strongly suggest using a backport for yt-dlp.&lt;/p&gt; 
&lt;p&gt;The Windows build &lt;strong&gt;comes with mpv included&lt;/strong&gt; (.msi), but you can still install mpv from a package manager of your choice to always have the latest version installed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;brew install mpv ffmpeg yt-dlp #MacOS
sudo dnf install mpv ffmpeg yt-dlp #Fedora
sudo zypper install mpv ffmpeg yt-dlp #OpenSUSE
sudo pacman -Syu mpv ffmpeg yt-dlp #Arch
sudo apt install mpv ffmpeg yt-dlp #Debian/Ubuntu
scoop install mpv ffmpeg yt-dlp # Windows
choco install mpv ffmpeg yt-dlp # Windows alternative
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Feedback&lt;/h2&gt; 
&lt;p&gt;Feel free to submit any kind of feedback by creating a new issue.&lt;/p&gt; 
&lt;h2&gt;Hotkeys&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;F1: Help&lt;/li&gt; 
 &lt;li&gt;Ctrl + a: Show all channels&lt;/li&gt; 
 &lt;li&gt;Ctrl + s: Show categories&lt;/li&gt; 
 &lt;li&gt;Ctrl + d: Show favorites&lt;/li&gt; 
 &lt;li&gt;Ctrl + f: Search&lt;/li&gt; 
 &lt;li&gt;Ctrl + q: Enable/Disable livestreams&lt;/li&gt; 
 &lt;li&gt;Ctrl + w: Enable/Disable movies&lt;/li&gt; 
 &lt;li&gt;Ctrl + e: Enable/Disable series&lt;/li&gt; 
 &lt;li&gt;Backspace/Esc: Go back&lt;/li&gt; 
 &lt;li&gt;Arrow keys/Tab/Shift+Tab: Navigation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you have a tv remote or air mouse that has slightly different bindings for general nav (back, up, down, left, right), please open an issue and I will add them if it's feasible. Otherwise, you can still use hwdb to make them match OpenTV's bindings.&lt;/p&gt; 
&lt;h2&gt;Settings explained&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Stream Caching&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Why enabling:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have a slow internet connection/IPTV provider causing the stream to pause often&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Why disabling:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If the stream often drops completely. It will prevent the stream from jumping too far ahead/behind&lt;/li&gt; 
 &lt;li&gt;If you have a good internet/provider and want lower latency&lt;/li&gt; 
 &lt;li&gt;Can prevent some weird bugs/slowdowns&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Donate Crypto (Thank you!)&lt;/h2&gt; 
&lt;p&gt;BTC:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bc1q7v27u4mrxhtqzl97pcp4vl52npss760epsheu3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ETH:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;0x171D5B628eff75c98c141aD5584FffA209274365
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;LTC:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ltc1qzxgp2grt9ayvpv0dur7lgzgf88yp09h2ytmga0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;BCH:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;bitcoincash:qz4mauqyytkvhp9yze0qhgn2nnlv4z5glckyysxg2n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;SOL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;AM7roSrxBKrS5mG7q6aXnQHZKh3ArtBxvG3x1B1VjKhj
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;BNB:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;0x0C8C5217a8044b3736aD82CCFB9f099597b65253
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;Open TV is an independent open-source project created to provide a fast and powerful IPTV experience. The name "Open TV" is used solely to represent this specific software and its purpose as described in the project documentation. Any other software, applications, or products bearing the same or similar name are unrelated to this project. Any resemblance to other software or applications is purely coincidental and unintended. We do not intend to cause confusion or imply affiliation with any other products or organizations that may share a similar name.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>longbridge/gpui-component</title>
      <link>https://github.com/longbridge/gpui-component</link>
      <description>&lt;p&gt;Rust GUI components for building fantastic cross-platform desktop application by using GPUI.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GPUI Component&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/longbridge/gpui-component/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/longbridge/gpui-component/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/gpui-component/"&gt;&lt;img src="https://docs.rs/gpui-component/badge.svg?sanitize=true" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/gpui-component"&gt;&lt;img src="https://img.shields.io/crates/v/gpui-component.svg?sanitize=true" alt="Crates.io" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;UI components for building fantastic desktop applications using &lt;a href="https://gpui.rs"&gt;GPUI&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Richness&lt;/strong&gt;: 60+ cross-platform desktop UI components.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Native&lt;/strong&gt;: Inspired by macOS and Windows controls, combined with shadcn/ui design for a modern experience.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ease of Use&lt;/strong&gt;: Stateless &lt;code&gt;RenderOnce&lt;/code&gt; components, simple and user-friendly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable&lt;/strong&gt;: Built-in &lt;code&gt;Theme&lt;/code&gt; and &lt;code&gt;ThemeColor&lt;/code&gt;, supporting multi-theme and variable-based configurations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Versatile&lt;/strong&gt;: Supports sizes like &lt;code&gt;xs&lt;/code&gt;, &lt;code&gt;sm&lt;/code&gt;, &lt;code&gt;md&lt;/code&gt;, and &lt;code&gt;lg&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Layout&lt;/strong&gt;: Dock layout for panel arrangements, resizing, and freeform (Tiles) layouts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Performance&lt;/strong&gt;: Virtualized Table and List components for smooth large-data rendering.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content Rendering&lt;/strong&gt;: Native support for Markdown and simple HTML.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Charting&lt;/strong&gt;: Built-in charts for visualizing your data.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Editor&lt;/strong&gt;: High performance code editor (support up to 200K lines) with LSP (diagnostics, completion, hover, etc).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Syntax Highlighting&lt;/strong&gt;: Syntax highlighting for editor and markdown components using Tree Sitter.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Showcase&lt;/h2&gt; 
&lt;p&gt;Here is the first application: &lt;a href="https://longbridge.com/desktop"&gt;Longbridge Pro&lt;/a&gt;, built using GPUI Component.&lt;/p&gt; 
&lt;img width="1763" alt="Image" src="https://github.com/user-attachments/assets/e1ecb9c3-2dd3-431e-bd97-5a819c30e551" /&gt; 
&lt;p&gt;We built multi-theme support in the application. This feature is not included in GPUI Component itself, but is based on the &lt;code&gt;Theme&lt;/code&gt; feature, so it's easy to implement.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;GPUI and GPUI Component are still in development, so you need to add dependencies by git.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;gpui = "0.2.2"
gpui-component = "0.3.0"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Basic Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-rs"&gt;use gpui::*;
use gpui_component::{button::*, *};

pub struct HelloWorld;
impl Render for HelloWorld {
    fn render(&amp;amp;mut self, _: &amp;amp;mut Window, _: &amp;amp;mut Context&amp;lt;Self&amp;gt;) -&amp;gt; impl IntoElement {
        div()
            .v_flex()
            .gap_2()
            .size_full()
            .items_center()
            .justify_center()
            .child("Hello, World!")
            .child(
                Button::new("ok")
                    .primary()
                    .label("Let's Go!")
                    .on_click(|_, _, _| println!("Clicked!")),
            )
    }
}

fn main() {
    let app = Application::new();

    app.run(move |cx| {
        // This must be called before using any GPUI Component features.
        gpui_component::init(cx);

        cx.spawn(async move |cx| {
            cx.open_window(WindowOptions::default(), |window, cx| {
                let view = cx.new(|_| HelloWorld);
                // This first level on the window, should be a Root.
                cx.new(|cx| Root::new(view.into(), window, cx))
            })?;

            Ok::&amp;lt;_, anyhow::Error&amp;gt;(())
        })
        .detach();
    });
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;WebView&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Still early and experimental; there are a lot of limitations.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;GPUI Component has a &lt;code&gt;WebView&lt;/code&gt; element based on &lt;a href="https://github.com/tauri-apps/wry"&gt;Wry&lt;/a&gt;. This is an optional feature, which you can enable with a feature flag.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;gpui-component = { version = "0.3.0", features = ["webview"] }
wry = { version = "0.53.3, package = "lb-wry" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More usage examples can be found in the &lt;a href="https://github.com/longbridge/gpui-component/tree/main/crates/story"&gt;story&lt;/a&gt; directory.&lt;/p&gt; 
&lt;h3&gt;Icons&lt;/h3&gt; 
&lt;p&gt;GPUI Component has an &lt;code&gt;Icon&lt;/code&gt; element, but it does not include SVG files by default.&lt;/p&gt; 
&lt;p&gt;The example uses &lt;a href="https://lucide.dev"&gt;Lucide&lt;/a&gt; icons, but you can use any icons you like. Just name the SVG files as defined in &lt;a href="https://github.com/longbridge/gpui-component/raw/main/crates/ui/src/icon.rs#L86"&gt;IconName&lt;/a&gt;. You can add any icons you need to your project.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;We have a gallery of applications built with GPUI Component.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More examples can be found in the &lt;code&gt;examples&lt;/code&gt; directory. You can run them with &lt;code&gt;cargo run --example &amp;lt;example_name&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://raw.githubusercontent.com/longbridge/gpui-component/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Compare to others&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Features&lt;/th&gt; 
   &lt;th&gt;GPUI Component&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://github.com/iced-rs/iced"&gt;Iced&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://github.com/emilk/egui"&gt;egui&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://www.qt.io/product/qt6"&gt;Qt 6&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Language&lt;/td&gt; 
   &lt;td&gt;Rust&lt;/td&gt; 
   &lt;td&gt;Rust&lt;/td&gt; 
   &lt;td&gt;Rust&lt;/td&gt; 
   &lt;td&gt;C++/QML&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Core Render&lt;/td&gt; 
   &lt;td&gt;GPUI&lt;/td&gt; 
   &lt;td&gt;wgpu&lt;/td&gt; 
   &lt;td&gt;wgpu&lt;/td&gt; 
   &lt;td&gt;QT&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;License&lt;/td&gt; 
   &lt;td&gt;Apache 2.0&lt;/td&gt; 
   &lt;td&gt;MIT&lt;/td&gt; 
   &lt;td&gt;MIT/Apache 2.0&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.qt.io/qt-licensing"&gt;Commercial/LGPL&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Min Binary Size [^1]&lt;/td&gt; 
   &lt;td&gt;12MB&lt;/td&gt; 
   &lt;td&gt;11MB&lt;/td&gt; 
   &lt;td&gt;5M&lt;/td&gt; 
   &lt;td&gt;20MB [^2]&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cross-Platform&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Documentation&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Good&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;UI Style&lt;/td&gt; 
   &lt;td&gt;Modern&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CJK Support&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Bad&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Chart&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Table (Large dataset)&lt;/td&gt; 
   &lt;td&gt;Yes&lt;br /&gt;(Virtual Rows, Columns)&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;br /&gt;(Virtual Rows)&lt;/td&gt; 
   &lt;td&gt;Yes&lt;br /&gt;(Virtual Rows, Columns)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Table Column Resize&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Text base&lt;/td&gt; 
   &lt;td&gt;Rope&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/pop-os/cosmic-text"&gt;COSMIC Text&lt;/a&gt; [^3]&lt;/td&gt; 
   &lt;td&gt;trait TextBuffer [^4]&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://doc.qt.io/qt-6/qtextdocument.html"&gt;QTextDocument&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CodeEditor&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Simple&lt;/td&gt; 
   &lt;td&gt;Basic API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dock Layout&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Syntax Highlight&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://tree-sitter.github.io/tree-sitter/"&gt;Tree Sitter&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/trishume/syntect"&gt;Syntect&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/trishume/syntect"&gt;Syntect&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://doc.qt.io/qt-6/qsyntaxhighlighter.html"&gt;QSyntaxHighlighter&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Markdown Rendering&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Markdown mix HTML&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HTML Rendering&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Basic&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Text Selection&lt;/td&gt; 
   &lt;td&gt;TextView&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Any Label&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Custom Theme&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Built Themes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;I18n&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Please submit an issue or PR if any mistakes or outdated are found.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;[^1]: Release builds by use simple hello world example.&lt;/p&gt; 
&lt;p&gt;[^2]: &lt;a href="https://www.qt.io/blog/reducing-binary-size-of-qt-applications-part-3-more-platforms"&gt;Reducing Binary Size of Qt Applications&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[^3]: Iced Editor: &lt;a href="https://github.com/iced-rs/iced/raw/db5a1f6353b9f8520c4f9633d1cdc90242c2afe1/graphics/src/text/editor.rs#L65-L68"&gt;https://github.com/iced-rs/iced/blob/db5a1f6353b9f8520c4f9633d1cdc90242c2afe1/graphics/src/text/editor.rs#L65-L68&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[^4]: egui TextBuffer: &lt;a href="https://github.com/emilk/egui/raw/0a81372cfd3a4deda640acdecbbaf24bf78bb6a2/crates/egui/src/widgets/text_edit/text_buffer.rs#L20"&gt;https://github.com/emilk/egui/blob/0a81372cfd3a4deda640acdecbbaf24bf78bb6a2/crates/egui/src/widgets/text_edit/text_buffer.rs#L20&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache-2.0&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;UI design based on &lt;a href="https://ui.shadcn.com"&gt;shadcn/ui&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Icons from &lt;a href="https://lucide.dev"&gt;Lucide&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>rust-lang/rust-clippy</title>
      <link>https://github.com/rust-lang/rust-clippy</link>
      <description>&lt;p&gt;A bunch of lints to catch common mistakes and improve your Rust code. Book: https://doc.rust-lang.org/clippy/&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Clippy&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rust-lang/rust-clippy/master/#license"&gt;&lt;img src="https://img.shields.io/crates/l/clippy.svg?sanitize=true" alt="License: MIT OR Apache-2.0" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A collection of lints to catch common mistakes and improve your &lt;a href="https://github.com/rust-lang/rust"&gt;Rust&lt;/a&gt; code.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html"&gt;There are over 750 lints included in this crate!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Lints are divided into categories, each with a default &lt;a href="https://doc.rust-lang.org/rustc/lints/levels.html"&gt;lint level&lt;/a&gt;. You can choose how much Clippy is supposed to &lt;del&gt;annoy&lt;/del&gt; help you by changing the lint level by category.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default level&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::all&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;all lints that are on by default (correctness, suspicious, style, complexity, perf)&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;warn/deny&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::correctness&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;code that is outright wrong or useless&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;deny&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::suspicious&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;code that is most likely wrong or useless&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;warn&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::style&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;code that should be written in a more idiomatic way&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;warn&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::complexity&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;code that does something simple but in a complex way&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;warn&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::perf&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;code that can be written to run faster&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;warn&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::pedantic&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;lints which are rather strict or have occasional false positives&lt;/td&gt; 
   &lt;td&gt;allow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::restriction&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;lints which prevent the use of language and library features[^restrict]&lt;/td&gt; 
   &lt;td&gt;allow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::nursery&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;new lints that are still under development&lt;/td&gt; 
   &lt;td&gt;allow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::cargo&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;lints for the cargo manifest&lt;/td&gt; 
   &lt;td&gt;allow&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More to come, please &lt;a href="https://github.com/rust-lang/rust-clippy/issues"&gt;file an issue&lt;/a&gt; if you have ideas!&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;restriction&lt;/code&gt; category should, &lt;em&gt;emphatically&lt;/em&gt;, not be enabled as a whole. The contained lints may lint against perfectly reasonable code, may not have an alternative suggestion, and may contradict any other lints (including other categories). Lints should be considered on a case-by-case basis before enabling.&lt;/p&gt; 
&lt;p&gt;[^restrict]: Some use cases for &lt;code&gt;restriction&lt;/code&gt; lints include: - Strict coding styles (e.g. &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#else_if_without_else"&gt;&lt;code&gt;clippy::else_if_without_else&lt;/code&gt;&lt;/a&gt;). - Additional restrictions on CI (e.g. &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#todo"&gt;&lt;code&gt;clippy::todo&lt;/code&gt;&lt;/a&gt;). - Preventing panicking in certain functions (e.g. &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#unwrap_used"&gt;&lt;code&gt;clippy::unwrap_used&lt;/code&gt;&lt;/a&gt;). - Running a lint only on a subset of code (e.g. &lt;code&gt;#[forbid(clippy::float_arithmetic)]&lt;/code&gt; on a module).&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Table of contents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rust-lang/rust-clippy/master/#usage"&gt;Usage instructions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rust-lang/rust-clippy/master/#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rust-lang/rust-clippy/master/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rust-lang/rust-clippy/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Below are instructions on how to use Clippy as a cargo subcommand, in projects that do not use cargo, or in Travis CI.&lt;/p&gt; 
&lt;h3&gt;As a cargo subcommand (&lt;code&gt;cargo clippy&lt;/code&gt;)&lt;/h3&gt; 
&lt;p&gt;One way to use Clippy is by installing Clippy through rustup as a cargo subcommand.&lt;/p&gt; 
&lt;h4&gt;Step 1: Install Rustup&lt;/h4&gt; 
&lt;p&gt;You can install &lt;a href="https://rustup.rs/"&gt;Rustup&lt;/a&gt; on supported platforms. This will help us install Clippy and its dependencies.&lt;/p&gt; 
&lt;p&gt;If you already have Rustup installed, update to ensure you have the latest Rustup and compiler:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;rustup update
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 2: Install Clippy&lt;/h4&gt; 
&lt;p&gt;Once you have rustup and the latest stable release (at least Rust 1.29) installed, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;rustup component add clippy
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If it says that it can't find the &lt;code&gt;clippy&lt;/code&gt; component, please run &lt;code&gt;rustup self update&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Step 3: Run Clippy&lt;/h4&gt; 
&lt;p&gt;Now you can run Clippy by invoking the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Automatically applying Clippy suggestions&lt;/h4&gt; 
&lt;p&gt;Clippy can automatically apply some lint suggestions, just like the compiler. Note that &lt;code&gt;--fix&lt;/code&gt; implies &lt;code&gt;--all-targets&lt;/code&gt;, so it can fix as much code as it can.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy --fix
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Workspaces&lt;/h4&gt; 
&lt;p&gt;All the usual workspace options should work with Clippy. For example the following command will run Clippy on the &lt;code&gt;example&lt;/code&gt; crate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -p example
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As with &lt;code&gt;cargo check&lt;/code&gt;, this includes dependencies that are members of the workspace, like path dependencies. If you want to run Clippy &lt;strong&gt;only&lt;/strong&gt; on the given crate, use the &lt;code&gt;--no-deps&lt;/code&gt; option like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -p example -- --no-deps
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using &lt;code&gt;clippy-driver&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Clippy can also be used in projects that do not use cargo. To do so, run &lt;code&gt;clippy-driver&lt;/code&gt; with the same arguments you use for &lt;code&gt;rustc&lt;/code&gt;. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;clippy-driver --edition 2018 -Cpanic=abort foo.rs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that &lt;code&gt;clippy-driver&lt;/code&gt; is designed for running Clippy only and should not be used as a general replacement for &lt;code&gt;rustc&lt;/code&gt;. &lt;code&gt;clippy-driver&lt;/code&gt; may produce artifacts that are not optimized as expected, for example.&lt;/p&gt; 
&lt;h3&gt;Travis CI&lt;/h3&gt; 
&lt;p&gt;You can add Clippy to Travis CI in the same way you use it locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;language: rust
rust:
  - stable
  - beta
before_script:
  - rustup component add clippy
script:
  - cargo clippy
  # if you want the build job to fail when encountering warnings, use
  - cargo clippy -- -D warnings
  # in order to also check tests and non-default crate features, use
  - cargo clippy --all-targets --all-features -- -D warnings
  - cargo test
  # etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that adding &lt;code&gt;-D warnings&lt;/code&gt; will cause your build to fail if &lt;strong&gt;any&lt;/strong&gt; warnings are found in your code. That includes warnings found by rustc (e.g. &lt;code&gt;dead_code&lt;/code&gt;, etc.). If you want to avoid this and only cause an error for Clippy warnings, use &lt;code&gt;#![deny(clippy::all)]&lt;/code&gt; in your code or &lt;code&gt;-D clippy::all&lt;/code&gt; on the command line. (You can swap &lt;code&gt;clippy::all&lt;/code&gt; with the specific lint category you are targeting.)&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;h3&gt;Allowing/denying lints&lt;/h3&gt; 
&lt;p&gt;You can add options to your code to &lt;code&gt;allow&lt;/code&gt;/&lt;code&gt;warn&lt;/code&gt;/&lt;code&gt;deny&lt;/code&gt; Clippy lints:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;the whole set of &lt;code&gt;Warn&lt;/code&gt; lints using the &lt;code&gt;clippy&lt;/code&gt; lint group (&lt;code&gt;#![deny(clippy::all)]&lt;/code&gt;). Note that &lt;code&gt;rustc&lt;/code&gt; has additional &lt;a href="https://doc.rust-lang.org/rustc/lints/groups.html"&gt;lint groups&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;all lints using both the &lt;code&gt;clippy&lt;/code&gt; and &lt;code&gt;clippy::pedantic&lt;/code&gt; lint groups (&lt;code&gt;#![deny(clippy::all)]&lt;/code&gt;, &lt;code&gt;#![deny(clippy::pedantic)]&lt;/code&gt;). Note that &lt;code&gt;clippy::pedantic&lt;/code&gt; contains some very aggressive lints prone to false positives.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;only some lints (&lt;code&gt;#![deny(clippy::single_match, clippy::box_vec)]&lt;/code&gt;, etc.)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;allow&lt;/code&gt;/&lt;code&gt;warn&lt;/code&gt;/&lt;code&gt;deny&lt;/code&gt; can be limited to a single function or module using &lt;code&gt;#[allow(...)]&lt;/code&gt;, etc.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: &lt;code&gt;allow&lt;/code&gt; means to suppress the lint for your code. With &lt;code&gt;warn&lt;/code&gt; the lint will only emit a warning, while with &lt;code&gt;deny&lt;/code&gt; the lint will emit an error, when triggering for your code. An error causes Clippy to exit with an error code, so is useful in scripts like CI/CD.&lt;/p&gt; 
&lt;p&gt;If you do not want to include your lint levels in your code, you can globally enable/disable lints by passing extra flags to Clippy during the run:&lt;/p&gt; 
&lt;p&gt;To allow &lt;code&gt;lint_name&lt;/code&gt;, run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -- -A clippy::lint_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And to warn on &lt;code&gt;lint_name&lt;/code&gt;, run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -- -W clippy::lint_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This also works with lint groups. For example, you can run Clippy with warnings for all lints enabled:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -- -W clippy::pedantic
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you care only about a single lint, you can allow all others and then explicitly warn on the lint(s) you are interested in:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -- -A clippy::all -W clippy::useless_format -W clippy::...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configure the behavior of some lints&lt;/h3&gt; 
&lt;p&gt;Some lints can be configured in a TOML file named &lt;code&gt;clippy.toml&lt;/code&gt; or &lt;code&gt;.clippy.toml&lt;/code&gt;. It contains a basic &lt;code&gt;variable = value&lt;/code&gt; mapping e.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;avoid-breaking-exported-api = false
disallowed-names = ["toto", "tata", "titi"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;a href="https://doc.rust-lang.org/nightly/clippy/lint_configuration.html"&gt;table of configurations&lt;/a&gt; contains all config values, their default, and a list of lints they affect. Each &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#Configuration"&gt;configurable lint&lt;/a&gt; , also contains information about these values.&lt;/p&gt; 
&lt;p&gt;For configurations that are a list type with default values such as &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#disallowed_names"&gt;disallowed-names&lt;/a&gt;, you can use the unique value &lt;code&gt;".."&lt;/code&gt; to extend the default values instead of replacing them.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# default of disallowed-names is ["foo", "baz", "quux"]
disallowed-names = ["bar", ".."] # -&amp;gt; ["bar", "foo", "baz", "quux"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;code&gt;clippy.toml&lt;/code&gt; or &lt;code&gt;.clippy.toml&lt;/code&gt; cannot be used to allow/deny lints.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To deactivate the ‚Äúfor further information visit &lt;em&gt;lint-link&lt;/em&gt;‚Äù message you can define the &lt;code&gt;CLIPPY_DISABLE_DOCS_LINKS&lt;/code&gt; environment variable.&lt;/p&gt; 
&lt;h3&gt;Specifying the minimum supported Rust version&lt;/h3&gt; 
&lt;p&gt;Projects that intend to support old versions of Rust can disable lints pertaining to newer features by specifying the minimum supported Rust version (MSRV) in the Clippy configuration file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;msrv = "1.30.0"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, the &lt;a href="https://doc.rust-lang.org/cargo/reference/manifest.html#the-rust-version-field"&gt;&lt;code&gt;rust-version&lt;/code&gt; field&lt;/a&gt; in the &lt;code&gt;Cargo.toml&lt;/code&gt; can be used.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# Cargo.toml
rust-version = "1.30"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The MSRV can also be specified as an attribute, like below.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust,ignore"&gt;#![feature(custom_inner_attributes)]
#![clippy::msrv = "1.30.0"]

fn main() {
  ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also omit the patch version when specifying the MSRV, so &lt;code&gt;msrv = 1.30&lt;/code&gt; is equivalent to &lt;code&gt;msrv = 1.30.0&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note: &lt;code&gt;custom_inner_attributes&lt;/code&gt; is an unstable feature, so it has to be enabled explicitly.&lt;/p&gt; 
&lt;p&gt;Lints that recognize this configuration option can be found &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#msrv"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you want to contribute to Clippy, you can find more information in &lt;a href="https://github.com/rust-lang/rust-clippy/raw/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;!-- REUSE-IgnoreStart --&gt; 
&lt;p&gt;Copyright 2014-2025 The Rust Project Developers&lt;/p&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 &amp;lt;LICENSE-APACHE or &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&amp;gt; or the MIT license &amp;lt;LICENSE-MIT or &lt;a href="https://opensource.org/licenses/MIT"&gt;https://opensource.org/licenses/MIT&lt;/a&gt;&amp;gt;, at your option. Files in the project may not be copied, modified, or distributed except according to those terms.&lt;/p&gt; 
&lt;!-- REUSE-IgnoreEnd --&gt;</description>
    </item>
    
    <item>
      <title>asterinas/asterinas</title>
      <link>https://github.com/asterinas/asterinas</link>
      <description>&lt;p&gt;Asterinas is a secure, fast, and general-purpose OS kernel, written in Rust and providing Linux-compatible ABI.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/asterinas/asterinas/main/book/src/images/logo_en.svg?sanitize=true" alt="asterinas-logo" width="620" /&gt;&lt;br /&gt; A secure, fast, and general-purpose OS kernel written in Rust and compatible with Linux&lt;br /&gt; &lt;a href="https://github.com/asterinas/asterinas/actions/workflows/test_x86.yml"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/test_x86.yml/badge.svg?event=push" alt="Test x86-64" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/asterinas/asterinas/actions/workflows/test_riscv.yml"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/test_riscv.yml/badge.svg?event=push" alt="Test riscv64" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/asterinas/asterinas/actions/workflows/test_loongarch.yml"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/test_loongarch.yml/badge.svg?event=push" alt="Test loongarch64" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/asterinas/asterinas/actions/workflows/test_x86_tdx.yml"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/test_x86_tdx.yml/badge.svg?sanitize=true" alt="Test Intel TDX" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;a href="https://asterinas.github.io/benchmark/x86-64/"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/benchmark_x86.yml/badge.svg?sanitize=true" alt="Benchmark x86-64" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;a href="https://asterinas.github.io/benchmark/tdx/"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/benchmark_x86_tdx.yml/badge.svg?sanitize=true" alt="Benchmark Intel TDX" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/asterinas/asterinas/main/README_CN.md"&gt;‰∏≠ÊñáÁâà&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/asterinas/asterinas/main/README_JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;News:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025-10-17: &lt;strong&gt;ICSE 2026&lt;/strong&gt; accepted yet another paper about Asterinas: &lt;em&gt;RusyFuzz: Unhandled Exception Guided Fuzzing for Rust OS Kernel&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;2025-10-14: &lt;a href="https://dl.acm.org/doi/10.1145/3731569.3764836"&gt;&lt;em&gt;CortenMM: Efficient Memory Management with Strong Correctness Guarantees&lt;/em&gt;&lt;/a&gt; received the &lt;strong&gt;Best Paper Award&lt;/strong&gt; at &lt;strong&gt;SOSP 2025&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;2025-07-23: &lt;strong&gt;SOSP 2025&lt;/strong&gt; accepted another Asterinas paper: &lt;a href="https://dl.acm.org/doi/10.1145/3731569.3764836"&gt;&lt;em&gt;CortenMM: Efficient Memory Management with Strong Correctness Guarantees&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;2025-06-18: &lt;strong&gt;USENIX &lt;em&gt;;login:&lt;/em&gt; magazine&lt;/strong&gt; published &lt;a href="https://www.usenix.org/publications/loginonline/asterinas-rust-based-framekernel-reimagine-linux-2020s"&gt;&lt;em&gt;Asterinas: A Rust-Based Framekernel to Reimagine Linux in the 2020s&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;2025-04-30: &lt;strong&gt;USENIX ATC 2025&lt;/strong&gt; accepted two Asterinas papers: 
  &lt;ol&gt; 
   &lt;li&gt;&lt;a href="https://www.usenix.org/conference/atc25/presentation/peng-yuke"&gt;&lt;em&gt;Asterinas: A Linux ABI-Compatible, Rust-Based Framekernel OS with a Small and Sound TCB&lt;/em&gt;&lt;/a&gt;;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.usenix.org/conference/atc25/presentation/tang"&gt;&lt;em&gt;Converos: Practical Model Checking for Verifying Rust OS Kernel Concurrency&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Congratulations to the Asterinas communityüéâüéâüéâ&lt;/p&gt; 
&lt;h2&gt;Introducing Asterinas&lt;/h2&gt; 
&lt;p&gt;Asterinas is a &lt;em&gt;secure&lt;/em&gt;, &lt;em&gt;fast&lt;/em&gt;, and &lt;em&gt;general-purpose&lt;/em&gt; OS kernel that provides &lt;em&gt;Linux-compatible&lt;/em&gt; ABI. It can serve as a seamless replacement for Linux while enhancing &lt;em&gt;memory safety&lt;/em&gt; and &lt;em&gt;developer friendliness&lt;/em&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Asterinas prioritizes memory safety by employing Rust as its sole programming language and limiting the use of &lt;em&gt;unsafe Rust&lt;/em&gt; to a clearly defined and minimal Trusted Computing Base (TCB). This innovative approach, known as &lt;a href="https://asterinas.github.io/book/kernel/the-framekernel-architecture.html"&gt;the framekernel architecture&lt;/a&gt;, establishes Asterinas as a more secure and dependable kernel option.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Asterinas surpasses Linux in terms of developer friendliness. It empowers kernel developers to (1) utilize the more productive Rust programming language, (2) leverage a purpose-built toolkit called &lt;a href="https://asterinas.github.io/book/osdk/guide/index.html"&gt;OSDK&lt;/a&gt; to streamline their workflows, and (3) choose between releasing their kernel modules as open source or keeping them proprietary, thanks to the flexibility offered by &lt;a href="https://raw.githubusercontent.com/asterinas/asterinas/main/#License"&gt;MPL&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;While the journey towards a production-grade OS kernel is challenging, we are steadfastly progressing towards this goal. Over the course of 2024, we significantly enhanced Asterinas's maturity, as detailed in &lt;a href="https://asterinas.github.io/2025/01/20/asterinas-in-2024.html"&gt;our end-year report&lt;/a&gt;. In 2025, our primary goal is to make Asterinas production-ready on x86-64 virtual machines and attract real users!&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Get yourself an x86-64 Linux machine with Docker installed. Follow the three simple steps below to get Asterinas up and running.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download the latest source code.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/asterinas/asterinas
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Run a Docker container as the development environment.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --privileged --network=host --device=/dev/kvm -v $(pwd)/asterinas:/root/asterinas asterinas/asterinas:0.16.1-20250922
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Inside the container, go to the project folder to build and run Asterinas.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make build
make run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If everything goes well, Asterinas is now up and running inside a VM.&lt;/p&gt; 
&lt;h2&gt;The Book&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://asterinas.github.io/book/"&gt;The Asterinas Book&lt;/a&gt; to learn more about the project.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Asterinas's source code and documentation primarily use the &lt;a href="https://github.com/asterinas/asterinas/raw/main/LICENSE-MPL"&gt;Mozilla Public License (MPL), Version 2.0&lt;/a&gt;. Select components are under more permissive licenses, detailed &lt;a href="https://github.com/asterinas/asterinas/raw/main/.licenserc.yaml"&gt;here&lt;/a&gt;. For the rationales behind the choice of MPL, see &lt;a href="https://asterinas.github.io/book/index.html#licensing"&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>n0-computer/iroh</title>
      <link>https://github.com/n0-computer/iroh</link>
      <description>&lt;p&gt;peer-2-peer that just works&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;&lt;a href="https://iroh.computer"&gt;&lt;img alt="iroh" src="https://raw.githubusercontent.com/n0-computer/iroh/main/.img/iroh_wordmark.svg?sanitize=true" width="100" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;h3 align="center"&gt; less net work for networks &lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://docs.rs/iroh/"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/iroh"&gt;&lt;img src="https://img.shields.io/crates/v/iroh.svg?style=flat-square" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/iroh"&gt;&lt;img src="https://img.shields.io/crates/d/iroh.svg?style=flat-square" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/DpmJgtU7cW"&gt;&lt;img src="https://img.shields.io/discord/1161119546170687619?logo=discord&amp;amp;style=flat-square" alt="Chat" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/@n0computer"&gt;&lt;img src="https://img.shields.io/badge/YouTube-red?logo=youtube&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="Youtube" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/n0-computer/iroh/main/LICENSE-MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/n0-computer/iroh/main/LICENSE-APACHE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?style=flat-square" alt="License: Apache 2.0" /&gt;&lt;/a&gt; &lt;a href="https://github.com/n0-computer/iroh/actions/workflows/ci.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/n0-computer/iroh/ci.yml?branch=main&amp;amp;style=flat-square&amp;amp;label=CI" alt="CI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt; &lt;a href="https://iroh.computer/docs"&gt; Docs Site &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://docs.rs/iroh"&gt; Rust Docs &lt;/a&gt; &lt;/h3&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;What is iroh?&lt;/h2&gt; 
&lt;p&gt;Iroh gives you an API for dialing by public key. You say ‚Äúconnect to that phone‚Äù, iroh will find &amp;amp; maintain the fastest connection for you, regardless of where it is.&lt;/p&gt; 
&lt;h3&gt;Hole-punching&lt;/h3&gt; 
&lt;p&gt;The fastest route is a direct connection, so if necessary, iroh tries to hole-punch. Should this fail, it can fall back to an open ecosystem of public relay servers. To ensure these connections are as fast as possible, we &lt;a href="https://perf.iroh.computer"&gt;continuously measure iroh&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Built on &lt;a href="https://en.wikipedia.org/wiki/QUIC"&gt;QUIC&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Iroh uses &lt;a href="https://github.com/quinn-rs/quinn"&gt;Quinn&lt;/a&gt; to establish &lt;a href="https://en.wikipedia.org/wiki/QUIC"&gt;QUIC&lt;/a&gt; connections between endpoints. This way you get authenticated encryption, concurrent streams with stream priorities, a datagram transport and avoid head-of-line-blocking out of the box.&lt;/p&gt; 
&lt;h2&gt;Compose Protocols&lt;/h2&gt; 
&lt;p&gt;Use pre-existing protocols built on iroh instead of writing your own:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-blobs"&gt;iroh-blobs&lt;/a&gt; for &lt;a href="https://github.com/BLAKE3-team/BLAKE3"&gt;BLAKE3&lt;/a&gt;-based content-addressed blob transfer scaling from kilobytes to terabytes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-gossip"&gt;iroh-gossip&lt;/a&gt; for establishing publish-subscribe overlay networks that scale, requiring only resources that your average phone can handle&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-docs"&gt;iroh-docs&lt;/a&gt; for an eventually-consistent key-value store of &lt;a href="https://github.com/n0-computer/iroh-blobs"&gt;iroh-blobs&lt;/a&gt; blobs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-willow"&gt;iroh-willow&lt;/a&gt; for an (in-construction) implementation of the &lt;a href="https://willowprotocol.org"&gt;willow protocol&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Rust Library&lt;/h3&gt; 
&lt;p&gt;It's easiest to use iroh from rust. Install it using &lt;code&gt;cargo add iroh&lt;/code&gt;, then on the connecting side:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rs"&gt;const ALPN: &amp;amp;[u8] = b"iroh-example/echo/0";

let endpoint = Endpoint::bind().await?;

// Open a connection to the accepting endpoint
let conn = endpoint.connect(addr, ALPN).await?;

// Open a bidirectional QUIC stream
let (mut send, mut recv) = conn.open_bi().await?;

// Send some data to be echoed
send.write_all(b"Hello, world!").await?;
send.finish()?;

// Receive the echo
let response = recv.read_to_end(1000).await?;
assert_eq!(&amp;amp;response, b"Hello, world!");

// As the side receiving the last application data - say goodbye
conn.close(0u32.into(), b"bye!");

// Close the endpoint and all its connections
endpoint.close().await;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And on the accepting side:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rs"&gt;let endpoint = Endpoint::bind().await?;

let router = Router::builder(endpoint)
    .accept(ALPN.to_vec(), Arc::new(Echo))
    .spawn()
    .await?;

// The protocol definition:
#[derive(Debug, Clone)]
struct Echo;

impl ProtocolHandler for Echo {
    async fn accept(&amp;amp;self, connection: Connection) -&amp;gt; Result&amp;lt;()&amp;gt; {
        let (mut send, mut recv) = connection.accept_bi().await?;

        // Echo any bytes received back directly.
        let bytes_sent = tokio::io::copy(&amp;amp;mut recv, &amp;amp;mut send).await?;

        send.finish()?;
        connection.closed().await;

        Ok(())
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The full example code with more comments can be found at &lt;a href="https://raw.githubusercontent.com/n0-computer/iroh/main/iroh/examples/echo.rs"&gt;&lt;code&gt;echo.rs&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Or use one of the pre-existing protocols, e.g. &lt;a href="https://github.com/n0-computer/iroh-blobs"&gt;iroh-blobs&lt;/a&gt; or &lt;a href="https://github.com/n0-computer/iroh-gossip"&gt;iroh-gossip&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Other Languages&lt;/h3&gt; 
&lt;p&gt;If you want to use iroh from other languages, make sure to check out &lt;a href="https://github.com/n0-computer/iroh-ffi"&gt;iroh-ffi&lt;/a&gt;, the repository for FFI bindings.&lt;/p&gt; 
&lt;h3&gt;Links&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=RwAt36Xe3UI_"&gt;Introducing Iroh (video)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://iroh.computer/docs"&gt;Iroh Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-examples"&gt;Iroh Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/iroh-experiments"&gt;Iroh Experiments&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Repository Structure&lt;/h2&gt; 
&lt;p&gt;This repository contains a workspace of crates:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;iroh&lt;/code&gt;: The core library for hole-punching &amp;amp; communicating with relays.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;iroh-relay&lt;/code&gt;: The relay server implementation. This is the code we run in production (and you can, too!).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;iroh-base&lt;/code&gt;: Common types like &lt;code&gt;Hash&lt;/code&gt;, key types or &lt;code&gt;RelayUrl&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;iroh-dns-server&lt;/code&gt;: DNS server implementation powering the &lt;code&gt;n0_discovery&lt;/code&gt; for EndpointIds, running at dns.iroh.link.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;iroh-net-report&lt;/code&gt;: Analyzes your host's networking ability &amp;amp; NAT.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright 2025 N0, INC.&lt;/p&gt; 
&lt;p&gt;This project is licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0, (&lt;a href="https://raw.githubusercontent.com/n0-computer/iroh/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/n0-computer/iroh/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="http://opensource.org/licenses/MIT"&gt;http://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in this project by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kata-containers/kata-containers</title>
      <link>https://github.com/kata-containers/kata-containers</link>
      <description>&lt;p&gt;Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs. https://katacontainers.io/&lt;/p&gt;&lt;hr&gt;&lt;img src="https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/6e4619c416ff4bd19e1c087f27a43eea/www-images-prod/openstack-logo/kata/SVG/kata-1.svg?sanitize=true" width="900" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml"&gt;&lt;img src="https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml/badge.svg?sanitize=true" alt="CI | Publish Kata Containers payload" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml"&gt;&lt;img src="https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml/badge.svg?sanitize=true" alt="Kata Containers Nightly CI" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/kata-containers/kata-containers"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/kata-containers/kata-containers/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Kata Containers&lt;/h1&gt; 
&lt;p&gt;Welcome to Kata Containers!&lt;/p&gt; 
&lt;p&gt;This repository is the home of the Kata Containers code for the 2.0 and newer releases.&lt;/p&gt; 
&lt;p&gt;If you want to learn about Kata Containers, visit the main &lt;a href="https://katacontainers.io"&gt;Kata Containers website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The code is licensed under the Apache 2.0 license. See &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/LICENSE"&gt;the license file&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;Kata Containers currently runs on 64-bit systems supporting the following technologies:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Architecture&lt;/th&gt; 
   &lt;th&gt;Virtualization technology&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;x86_64&lt;/code&gt;, &lt;code&gt;amd64&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.intel.com"&gt;Intel&lt;/a&gt; VT-x, AMD SVM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;aarch64&lt;/code&gt; ("&lt;code&gt;arm64&lt;/code&gt;")&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.arm.com"&gt;ARM&lt;/a&gt; Hyp&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ppc64le&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.ibm.com"&gt;IBM&lt;/a&gt; Power&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;s390x&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.ibm.com"&gt;IBM&lt;/a&gt; Z &amp;amp; LinuxONE SIE&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware requirements&lt;/h3&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;Kata Containers runtime&lt;/a&gt; provides a command to determine if your host system is capable of running and creating a Kata Container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ kata-runtime check
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;This command runs a number of checks including connecting to the network to determine if a newer release of Kata Containers is available on GitHub. If you do not wish this to check to run, add the &lt;code&gt;--no-network-checks&lt;/code&gt; option.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;By default, only a brief success / failure message is printed. If more details are needed, the &lt;code&gt;--verbose&lt;/code&gt; flag can be used to display the list of all the checks performed.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;If the command is run as the &lt;code&gt;root&lt;/code&gt; user additional checks are run (including checking if another incompatible hypervisor is running). When running as &lt;code&gt;root&lt;/code&gt;, network checks are automatically disabled.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install"&gt;installation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs"&gt;official documentation&lt;/a&gt; including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install"&gt;Installation guides&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/Developer-Guide.md"&gt;Developer guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design"&gt;Design documents&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design/architecture"&gt;Architecture overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/design/architecture_3.0/"&gt;Architecture 3.0 overview&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Kata Containers uses a single &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime/README.md#configuration"&gt;configuration file&lt;/a&gt; which contains a number of sections for various parts of the Kata Containers system including the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;runtime&lt;/a&gt;, the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/agent"&gt;agent&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/#hypervisors"&gt;hypervisor&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Hypervisors&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/hypervisors.md"&gt;hypervisors document&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime/README.md#hypervisor-specific-configuration"&gt;Hypervisor specific configuration details&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;To learn more about the project, its community and governance, see the &lt;a href="https://github.com/kata-containers/community"&gt;community repository&lt;/a&gt;. This is the first place to go if you wish to contribute to the project.&lt;/p&gt; 
&lt;h2&gt;Getting help&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/#community"&gt;community&lt;/a&gt; section for ways to contact us.&lt;/p&gt; 
&lt;h3&gt;Raising issues&lt;/h3&gt; 
&lt;p&gt;Please raise an issue &lt;a href="https://github.com/kata-containers/kata-containers/issues"&gt;in this repository&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you are reporting a security issue, please follow the &lt;a href="https://github.com/kata-containers/community#vulnerability-handling"&gt;vulnerability reporting process&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Developers&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/Developer-Guide.md"&gt;developer guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Components&lt;/h3&gt; 
&lt;h3&gt;Main components&lt;/h3&gt; 
&lt;p&gt;The table below lists the core parts of the project:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime"&gt;runtime&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;Main component run by a container manager and providing a containerd shimv2 runtime implementation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/runtime-rs"&gt;runtime-rs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;The Rust version runtime.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/agent"&gt;agent&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;Management process running inside the virtual machine / POD that sets up the container environment.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/dragonball"&gt;&lt;code&gt;dragonball&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;core&lt;/td&gt; 
   &lt;td&gt;An optional built-in VMM brings out-of-the-box Kata Containers experience with optimizations on container workloads&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs"&gt;documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;documentation&lt;/td&gt; 
   &lt;td&gt;Documentation common to all components (such as design and install documentation).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests"&gt;tests&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;tests&lt;/td&gt; 
   &lt;td&gt;Excludes unit tests which live with the main code.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Additional components&lt;/h3&gt; 
&lt;p&gt;The table below lists the remaining parts of the project:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging"&gt;packaging&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Scripts and metadata for producing packaged binaries&lt;br /&gt;(components, hypervisors, kernel and rootfs).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.kernel.org"&gt;kernel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;kernel&lt;/td&gt; 
   &lt;td&gt;Linux kernel used by the hypervisor to boot the guest image. Patches are stored &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kernel"&gt;here&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/osbuilder"&gt;osbuilder&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Tool to create "mini O/S" rootfs and initrd images and kernel for the hypervisor.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/packaging/kata-debug/README.md"&gt;kata-debug&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;infrastructure&lt;/td&gt; 
   &lt;td&gt;Utility tool to gather Kata Containers debug information from Kubernetes clusters.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/agent-ctl"&gt;&lt;code&gt;agent-ctl&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Tool that provides low-level access for testing the agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/kata-ctl"&gt;&lt;code&gt;kata-ctl&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Tool that provides advanced commands and debug facilities.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/trace-forwarder"&gt;&lt;code&gt;trace-forwarder&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Agent tracing helper.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/src/tools/runk"&gt;&lt;code&gt;runk&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Standard OCI container runtime based on the agent.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/.github/workflows"&gt;&lt;code&gt;ci&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CI&lt;/td&gt; 
   &lt;td&gt;Continuous Integration configuration files and scripts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/ci/openshift-ci/README.md"&gt;&lt;code&gt;ocp-ci&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CI&lt;/td&gt; 
   &lt;td&gt;Continuous Integration configuration for the OpenShift pipelines.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/kata-containers/www.katacontainers.io"&gt;&lt;code&gt;katacontainers.io&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Source for the &lt;a href="https://www.katacontainers.io"&gt;&lt;code&gt;katacontainers.io&lt;/code&gt;&lt;/a&gt; site.&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tools/testing/kata-webhook/README.md"&gt;&lt;code&gt;Webhook&lt;/code&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;utility&lt;/td&gt; 
   &lt;td&gt;Example of a simple admission controller webhook to annotate pods with the Kata runtime class&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Packaging and releases&lt;/h3&gt; 
&lt;p&gt;Kata Containers is now &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/install/README.md#packaged-installation-methods"&gt;available natively for most distributions&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;General tests&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests/README.md"&gt;tests documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Metrics tests&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/kata-containers/kata-containers/main/tests/metrics/README.md"&gt;metrics documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Glossary of Terms&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/kata-containers/kata-containers/wiki/Glossary"&gt;glossary of terms&lt;/a&gt; related to Kata Containers.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>zed-industries/zed</title>
      <link>https://github.com/zed-industries/zed</link>
      <description>&lt;p&gt;Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Zed&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://zed.dev"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/zed-industries/zed/main/assets/badge/v0.json" alt="Zed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/zed-industries/zed/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/zed-industries/zed/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Welcome to Zed, a high-performance, multiplayer code editor from the creators of &lt;a href="https://github.com/atom/atom"&gt;Atom&lt;/a&gt; and &lt;a href="https://github.com/tree-sitter/tree-sitter"&gt;Tree-sitter&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;On macOS, Linux, and Windows you can &lt;a href="https://zed.dev/download"&gt;download Zed directly&lt;/a&gt; or &lt;a href="https://zed.dev/docs/linux#installing-via-a-package-manager"&gt;install Zed via your local package manager&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Other platforms are not yet available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web (&lt;a href="https://github.com/zed-industries/zed/issues/5396"&gt;tracking issue&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Developing Zed&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/macos.md"&gt;Building Zed for macOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/linux.md"&gt;Building Zed for Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/windows.md"&gt;Building Zed for Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/docs/src/development/local-collaboration.md"&gt;Running Collaboration Locally&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/zed-industries/zed/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for ways you can contribute to Zed.&lt;/p&gt; 
&lt;p&gt;Also... we're hiring! Check out our &lt;a href="https://zed.dev/jobs"&gt;jobs&lt;/a&gt; page for open roles.&lt;/p&gt; 
&lt;h3&gt;Licensing&lt;/h3&gt; 
&lt;p&gt;License information for third party dependencies must be correctly provided for CI to pass.&lt;/p&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/EmbarkStudios/cargo-about"&gt;&lt;code&gt;cargo-about&lt;/code&gt;&lt;/a&gt; to automatically comply with open source licenses. If CI is failing, check the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Is it showing a &lt;code&gt;no license specified&lt;/code&gt; error for a crate you've created? If so, add &lt;code&gt;publish = false&lt;/code&gt; under &lt;code&gt;[package]&lt;/code&gt; in your crate's Cargo.toml.&lt;/li&gt; 
 &lt;li&gt;Is the error &lt;code&gt;failed to satisfy license requirements&lt;/code&gt; for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license's requirements. If you're unsure, ask a lawyer. Once you've verified that this system is acceptable add the license's SPDX identifier to the &lt;code&gt;accepted&lt;/code&gt; array in &lt;code&gt;script/licenses/zed-licenses.toml&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Is &lt;code&gt;cargo-about&lt;/code&gt; unable to find the license for a dependency? If so, add a clarification field at the end of &lt;code&gt;script/licenses/zed-licenses.toml&lt;/code&gt;, as specified in the &lt;a href="https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration"&gt;cargo-about book&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>helix-editor/helix</title>
      <link>https://github.com/helix-editor/helix</link>
      <description>&lt;p&gt;A post-modern modal text editor.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="logo_dark.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="logo_light.svg" /&gt; 
   &lt;img alt="Helix" height="128" src="https://raw.githubusercontent.com/helix-editor/helix/master/logo_light.svg?sanitize=true" /&gt; 
  &lt;/picture&gt; &lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/helix-editor/helix/actions"&gt;&lt;img src="https://github.com/helix-editor/helix/actions/workflows/build.yml/badge.svg?sanitize=true" alt="Build status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/helix-editor/helix/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/helix-editor/helix" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://docs.helix-editor.com/"&gt;&lt;img src="https://shields.io/badge/-documentation-452859" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/helix-editor/helix/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/helix-editor/helix" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://matrix.to/#/#helix-community:matrix.org"&gt;&lt;img src="https://img.shields.io/matrix/helix-community:matrix.org" alt="Matrix Space" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/helix-editor/helix/master/screenshot.png" alt="Screenshot" /&gt;&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://github.com/mawww/kakoune"&gt;Kakoune&lt;/a&gt; / &lt;a href="https://github.com/neovim/neovim"&gt;Neovim&lt;/a&gt; inspired editor, written in Rust.&lt;/p&gt; 
&lt;p&gt;The editing model is very heavily based on Kakoune; during development I found myself agreeing with most of Kakoune's design decisions.&lt;/p&gt; 
&lt;p&gt;For more information, see the &lt;a href="https://helix-editor.com"&gt;website&lt;/a&gt; or &lt;a href="https://docs.helix-editor.com/"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;All shortcuts/keymaps can be found &lt;a href="https://docs.helix-editor.com/keymap.html"&gt;in the documentation on the website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/helix-editor/helix/wiki/Troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Vim-like modal editing&lt;/li&gt; 
 &lt;li&gt;Multiple selections&lt;/li&gt; 
 &lt;li&gt;Built-in language server support&lt;/li&gt; 
 &lt;li&gt;Smart, incremental syntax highlighting and code editing via tree-sitter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Although it's primarily a terminal-based editor, I am interested in exploring a custom renderer (similar to Emacs) using wgpu or skulpin.&lt;/p&gt; 
&lt;p&gt;Note: Only certain languages have indentation definitions at the moment. Check &lt;code&gt;runtime/queries/&amp;lt;lang&amp;gt;/&lt;/code&gt; for &lt;code&gt;indents.scm&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://docs.helix-editor.com/install.html"&gt;Installation documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/helix-editor/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/helix-editor.svg?exclude_unsupported=1" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;Contributing guidelines can be found &lt;a href="https://raw.githubusercontent.com/helix-editor/helix/master/docs/CONTRIBUTING.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Getting help&lt;/h1&gt; 
&lt;p&gt;Your question might already be answered on the &lt;a href="https://github.com/helix-editor/helix/wiki/FAQ"&gt;FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Discuss the project on the community &lt;a href="https://matrix.to/#/#helix-community:matrix.org"&gt;Matrix Space&lt;/a&gt; (make sure to join &lt;code&gt;#helix-editor:matrix.org&lt;/code&gt; if you're on a client that doesn't support Matrix Spaces yet).&lt;/p&gt; 
&lt;h1&gt;Credits&lt;/h1&gt; 
&lt;p&gt;Thanks to &lt;a href="https://github.com/jakenvac"&gt;@jakenvac&lt;/a&gt; for designing the logo!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nautechsystems/nautilus_trader</title>
      <link>https://github.com/nautechsystems/nautilus_trader</link>
      <description>&lt;p&gt;A high-performance algorithmic trading platform and event-driven backtester&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png" width="500" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://codecov.io/gh/nautechsystems/nautilus_trader"&gt;&lt;img src="https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://codspeed.io/nautechsystems/nautilus_trader"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://codspeed.io/badge.json" alt="codspeed" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/pyversions/nautilus_trader" alt="pythons" /&gt; &lt;img src="https://img.shields.io/pypi/v/nautilus_trader" alt="pypi-version" /&gt; &lt;img src="https://img.shields.io/pypi/format/nautilus_trader?color=blue" alt="pypi-format" /&gt; &lt;a href="https://pepy.tech/project/nautilus-trader"&gt;&lt;img src="https://pepy.tech/badge/nautilus-trader" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/NautilusTrader"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Branch&lt;/th&gt; 
   &lt;th align="left"&gt;Version&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;master&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json" alt="version" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=master" alt="build" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;nightly&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json" alt="version" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly" alt="build" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;develop&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json" alt="version" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop" alt="build" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Rust&lt;/th&gt; 
   &lt;th align="left"&gt;Python&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.91.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.12-3.14&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.91.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.12-3.14&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;macOS (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.91.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.12-3.14&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Windows (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;1.91.0&lt;/td&gt; 
   &lt;td align="left"&gt;3.12-3.13&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://nautilustrader.io/docs/"&gt;https://nautilustrader.io/docs/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Website&lt;/strong&gt;: &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support&lt;/strong&gt;: &lt;a href="mailto:support@nautilustrader.io"&gt;support@nautilustrader.io&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform, providing quantitative traders with the ability to backtest portfolios of automated trading strategies on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.&lt;/p&gt; 
&lt;p&gt;The platform is &lt;em&gt;AI-first&lt;/em&gt;, designed to develop and deploy algorithmic trading strategies within a highly performant and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest environment consistent with the production live trading environment.&lt;/p&gt; 
&lt;p&gt;NautilusTrader's design, architecture, and implementation philosophy prioritizes software correctness and safety at the highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting and live deployment workloads.&lt;/p&gt; 
&lt;p&gt;The platform is also universal, and asset-class-agnostic ‚Äî with any REST API or WebSocket feed able to be integrated via modular adapters. It supports high-frequency trading across a wide range of asset classes and instrument types including FX, Equities, Futures, Options, Crypto, DeFi, and Betting ‚Äî enabling seamless operations across multiple venues simultaneously.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png" alt="nautilus-trader" title="nautilus-trader" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt;: Core is written in Rust with asynchronous networking using &lt;a href="https://crates.io/crates/tokio"&gt;tokio&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable&lt;/strong&gt;: Rust-powered type- and thread-safety, with optional Redis-backed state persistence.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Portable&lt;/strong&gt;: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible&lt;/strong&gt;: Modular adapters mean any REST API or WebSocket feed can be integrated.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced&lt;/strong&gt;: Time in force &lt;code&gt;IOC&lt;/code&gt;, &lt;code&gt;FOK&lt;/code&gt;, &lt;code&gt;GTC&lt;/code&gt;, &lt;code&gt;GTD&lt;/code&gt;, &lt;code&gt;DAY&lt;/code&gt;, &lt;code&gt;AT_THE_OPEN&lt;/code&gt;, &lt;code&gt;AT_THE_CLOSE&lt;/code&gt;, advanced order types and conditional triggers. Execution instructions &lt;code&gt;post-only&lt;/code&gt;, &lt;code&gt;reduce-only&lt;/code&gt;, and icebergs. Contingency orders including &lt;code&gt;OCO&lt;/code&gt;, &lt;code&gt;OUO&lt;/code&gt;, &lt;code&gt;OTO&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customizable&lt;/strong&gt;: Add user-defined custom components, or assemble entire systems from scratch leveraging the &lt;a href="https://nautilustrader.io/docs/latest/concepts/cache"&gt;cache&lt;/a&gt; and &lt;a href="https://nautilustrader.io/docs/latest/concepts/message_bus"&gt;message bus&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backtesting&lt;/strong&gt;: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live&lt;/strong&gt;: Use identical strategy implementations between backtesting and live deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-venue&lt;/strong&gt;: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Training&lt;/strong&gt;: Backtest engine fast enough to be used to train AI trading agents (RL/ES).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png" alt="Alt text" title="nautilus" /&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;nautilus - from ancient Greek 'sailor' and naus 'ship'.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral. The idea is that this can be translated to the aesthetics of design and architecture.&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Why NautilusTrader?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Highly performant event-driven Python&lt;/strong&gt;: Native binary core components.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parity between backtesting and live trading&lt;/strong&gt;: Identical strategy code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reduced operational risk&lt;/strong&gt;: Enhanced risk management functionality, logical accuracy, and type safety.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Highly extendable&lt;/strong&gt;: Message bus, custom components and actors, custom data, custom adapters.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Traditionally, trading strategy research and backtesting might be conducted in Python using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot express the granular time and event dependent complexity of real-time trading, where compiled languages have proven to be more suitable due to their inherently higher performance, and type safety.&lt;/p&gt; 
&lt;p&gt;One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform have all been written entirely in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; or &lt;a href="https://cython.org/"&gt;Cython&lt;/a&gt;. This means we're using the right tools for the job, where systems programming languages compile performant binaries, with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.&lt;/p&gt; 
&lt;h2&gt;Why Python?&lt;/h2&gt; 
&lt;p&gt;Python was originally created decades ago as a simple scripting language with a clean straightforward syntax. It has since evolved into a fully fledged general purpose object-oriented programming language. Based on the TIOBE index, Python is currently the most popular programming language in the world. Not only that, Python has become the &lt;em&gt;de facto lingua franca&lt;/em&gt; of data science, machine learning, and artificial intelligence.&lt;/p&gt; 
&lt;h2&gt;Why Rust?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; is a multi-paradigm programming language designed for performance and safety, especially safe concurrency. Rust is "blazingly fast" and memory-efficient (comparable to C and C++) with no garbage collector. It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.&lt;/p&gt; 
&lt;p&gt;Rust‚Äôs rich type system and ownership model guarantees memory-safety and thread-safety deterministically ‚Äî eliminating many classes of bugs at compile-time.&lt;/p&gt; 
&lt;p&gt;The project increasingly utilizes Rust for core performance-critical components. Python bindings are implemented via Cython and &lt;a href="https://pyo3.rs"&gt;PyO3&lt;/a&gt;‚Äîno Rust toolchain is required at install time.&lt;/p&gt; 
&lt;p&gt;This project makes the &lt;a href="https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html"&gt;Soundness Pledge&lt;/a&gt;:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ÄúThe intent of this project is to be free of soundness bugs. The developers will do their best to avoid them, and welcome help in analyzing and fixing them.‚Äù&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;MSRV:&lt;/strong&gt; NautilusTrader relies heavily on improvements in the Rust language and compiler. As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Integrations&lt;/h2&gt; 
&lt;p&gt;NautilusTrader is modularly designed to work with &lt;em&gt;adapters&lt;/em&gt;, enabling connectivity to trading venues and data providers by translating their raw APIs into a unified interface and normalized domain model.&lt;/p&gt; 
&lt;p&gt;The following integrations are currently supported; see &lt;a href="https://nautilustrader.io/docs/latest/integrations/"&gt;docs/integrations/&lt;/a&gt; for details:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Name&lt;/th&gt; 
   &lt;th align="left"&gt;ID&lt;/th&gt; 
   &lt;th align="left"&gt;Type&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
   &lt;th align="left"&gt;Docs&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://betfair.com"&gt;Betfair&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BETFAIR&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sports Betting Exchange&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/betfair.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://binance.com"&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BINANCE&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/binance.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bitmex.com"&gt;BitMEX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BITMEX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/bitmex.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.bybit.com"&gt;Bybit&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;BYBIT&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/bybit.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.coinbase.com/en/international-exchange"&gt;Coinbase International&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;COINBASE_INTX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/coinbase_intx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://databento.com"&gt;Databento&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DATABENTO&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Data Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/databento.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://dydx.exchange/"&gt;dYdX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;DYDX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/dydx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://hyperliquid.xyz"&gt;Hyperliquid&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;HYPERLIQUID&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/building-orange" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/hyperliquid.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.interactivebrokers.com"&gt;Interactive Brokers&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;INTERACTIVE_BROKERS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Brokerage (multi-venue)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/ib.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://okx.com"&gt;OKX&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;OKX&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Exchange (CEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/okx.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://polymarket.com"&gt;Polymarket&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;POLYMARKET&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Prediction Market (DEX)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/polymarket.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://tardis.dev"&gt;Tardis&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;TARDIS&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Crypto Data Provider&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;img src="https://img.shields.io/badge/stable-green" alt="status" /&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/docs/integrations/tardis.md"&gt;Guide&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ID&lt;/strong&gt;: The default client ID for the integrations adapter clients.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type&lt;/strong&gt;: The type of integration (often the venue type).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Status&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;building&lt;/code&gt;: Under construction and likely not in a usable state.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;beta&lt;/code&gt;: Completed to a minimally working state and in a beta testing phase.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt;: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/integrations/"&gt;Integrations&lt;/a&gt; documentation for further details.&lt;/p&gt; 
&lt;h2&gt;Versioning and releases&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;NautilusTrader is still under active development&lt;/strong&gt;. Some features may be incomplete, and while the API is becoming more stable, breaking changes can occur between releases. We strive to document these changes in the release notes on a &lt;strong&gt;best-effort basis&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;We aim to follow a &lt;strong&gt;bi-weekly release schedule&lt;/strong&gt;, though experimental or larger features may cause delays.&lt;/p&gt; 
&lt;h3&gt;Branches&lt;/h3&gt; 
&lt;p&gt;We aim to maintain a stable, passing build across all branches.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;master&lt;/code&gt;: Reflects the source code for the latest released version; recommended for production use.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt;: Daily snapshots of the &lt;code&gt;develop&lt;/code&gt; branch for early testing; merged at &lt;strong&gt;14:00 UTC&lt;/strong&gt; and as required.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt;: Active development branch for contributors and feature work.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Our &lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md"&gt;roadmap&lt;/a&gt; aims to achieve a &lt;strong&gt;stable API for version 2.x&lt;/strong&gt; (likely after the Rust port). Once this milestone is reached, we plan to implement a formal deprecation process for any API changes. This approach allows us to maintain a rapid development pace for now.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Precision mode&lt;/h2&gt; 
&lt;p&gt;NautilusTrader supports two precision modes for its core value types (&lt;code&gt;Price&lt;/code&gt;, &lt;code&gt;Quantity&lt;/code&gt;, &lt;code&gt;Money&lt;/code&gt;), which differ in their internal bit-width and maximum decimal precision.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High-precision&lt;/strong&gt;: 128-bit integers with up to 16 decimals of precision, and a larger value range.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standard-precision&lt;/strong&gt;: 64-bit integers with up to 9 decimals of precision, and a smaller value range.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;By default, the official Python wheels ship in high-precision (128-bit) mode on Linux and macOS. On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support. For the Rust crates, the default is standard-precision unless you explicitly enable the &lt;code&gt;high-precision&lt;/code&gt; feature flag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation"&gt;Installation Guide&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Rust feature flag&lt;/strong&gt;: To enable high-precision mode in Rust, add the &lt;code&gt;high-precision&lt;/code&gt; feature to your Cargo.toml:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
nautilus_model = { version = "*", features = ["high-precision"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;We recommend using the latest supported version of Python and installing &lt;a href="https://pypi.org/project/nautilus_trader/"&gt;nautilus_trader&lt;/a&gt; inside a virtual environment to isolate dependencies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;There are two supported ways to install&lt;/strong&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Pre-built binary wheel from PyPI &lt;em&gt;or&lt;/em&gt; the Nautech Systems package index.&lt;/li&gt; 
 &lt;li&gt;Build from source.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;We highly recommend installing using the &lt;a href="https://docs.astral.sh/uv"&gt;uv&lt;/a&gt; package manager with a "vanilla" CPython.&lt;/p&gt; 
 &lt;p&gt;Conda and other Python distributions &lt;em&gt;may&lt;/em&gt; work but aren‚Äôt officially supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;From PyPI&lt;/h3&gt; 
&lt;p&gt;To install the latest binary wheel (or sdist package) from PyPI using Python's pip package manager:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;From the Nautech Systems package index&lt;/h3&gt; 
&lt;p&gt;The Nautech Systems package index (&lt;code&gt;packages.nautechsystems.io&lt;/code&gt;) complies with &lt;a href="https://peps.python.org/pep-0503/"&gt;PEP-503&lt;/a&gt; and hosts both stable and development binary wheels for &lt;code&gt;nautilus_trader&lt;/code&gt;. This enables users to install either the latest stable release or pre-release versions for testing.&lt;/p&gt; 
&lt;h4&gt;Stable wheels&lt;/h4&gt; 
&lt;p&gt;Stable wheels correspond to official releases of &lt;code&gt;nautilus_trader&lt;/code&gt; on PyPI, and use standard versioning.&lt;/p&gt; 
&lt;p&gt;To install the latest stable release:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Use &lt;code&gt;--extra-index-url&lt;/code&gt; instead of &lt;code&gt;--index-url&lt;/code&gt; if you want pip to fall back to PyPI automatically:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Development wheels&lt;/h4&gt; 
&lt;p&gt;Development wheels are published from both the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;develop&lt;/code&gt; branches, allowing users to test features and fixes ahead of stable releases.&lt;/p&gt; 
&lt;p&gt;This process also helps preserve compute resources and provides easy access to the exact binaries tested in CI pipelines, while adhering to &lt;a href="https://peps.python.org/pep-0440/"&gt;PEP-440&lt;/a&gt; versioning standards:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; wheels use the version format &lt;code&gt;dev{date}+{build_number}&lt;/code&gt; (e.g., &lt;code&gt;1.208.0.dev20241212+7001&lt;/code&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; wheels use the version format &lt;code&gt;a{date}&lt;/code&gt; (alpha) (e.g., &lt;code&gt;1.208.0a20241212&lt;/code&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Nightly&lt;/th&gt; 
   &lt;th align="left"&gt;Develop&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Linux (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
   &lt;td align="left"&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;macOS (ARM64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;Windows (x86_64)&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
   &lt;td align="left"&gt;‚úì&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Development wheels from the &lt;code&gt;develop&lt;/code&gt; branch publish for every supported platform except Linux ARM64. Skipping that target keeps CI feedback fast while avoiding unnecessary build resource usage.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;We do not recommend using development wheels in production environments, such as live trading controlling real capital.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Installation commands&lt;/h4&gt; 
&lt;p&gt;By default, pip will install the latest stable release. Adding the &lt;code&gt;--pre&lt;/code&gt; flag ensures that pre-release versions, including development wheels, are considered.&lt;/p&gt; 
&lt;p&gt;To install the latest available pre-release (including development wheels):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install a specific development wheel (e.g., &lt;code&gt;1.221.0a20251026&lt;/code&gt; for October 26, 2025):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install nautilus_trader==1.221.0a20251026 --index-url=https://packages.nautechsystems.io/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Available versions&lt;/h4&gt; 
&lt;p&gt;You can view all available versions of &lt;code&gt;nautilus_trader&lt;/code&gt; on the &lt;a href="https://packages.nautechsystems.io/simple/nautilus-trader/index.html"&gt;package index&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To programmatically fetch and list available versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP '(?&amp;lt;=&amp;lt;a href=")[^"]+(?=")' | awk -F'#' '{print $1}' | sort
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;On Linux, confirm your glibc version with &lt;code&gt;ldd --version&lt;/code&gt; and ensure it reports &lt;strong&gt;2.35&lt;/strong&gt; or newer before installing binary wheels.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Branch updates&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; branch wheels (&lt;code&gt;.dev&lt;/code&gt;): Build and publish continuously with every merged commit.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; branch wheels (&lt;code&gt;a&lt;/code&gt;): Build and publish daily when we automatically merge the &lt;code&gt;develop&lt;/code&gt; branch at &lt;strong&gt;14:00 UTC&lt;/strong&gt; (if there are changes).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Retention policies&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;develop&lt;/code&gt; branch wheels (&lt;code&gt;.dev&lt;/code&gt;): We retain only the most recent wheel build.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nightly&lt;/code&gt; branch wheels (&lt;code&gt;a&lt;/code&gt;): We retain only the 30 most recent wheel builds.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Verifying build provenance&lt;/h4&gt; 
&lt;p&gt;All release artifacts (wheels and source distributions) published to PyPI, GitHub Releases, and the Nautech Systems package index include cryptographic attestations that prove their authenticity and build provenance.&lt;/p&gt; 
&lt;p&gt;These attestations are generated automatically during the CI/CD pipeline using &lt;a href="https://slsa.dev/"&gt;SLSA&lt;/a&gt; build provenance, and can be verified to ensure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The artifact was built by the official NautilusTrader GitHub Actions workflow.&lt;/li&gt; 
 &lt;li&gt;The artifact corresponds to a specific commit SHA in the repository.&lt;/li&gt; 
 &lt;li&gt;The artifact hasn't been tampered with since it was built.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To verify a wheel file using the GitHub CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;gh attestation verify nautilus_trader-1.220.0-*.whl --owner nautechsystems
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This provides supply chain security by allowing you to cryptographically verify that the installed package came from the official NautilusTrader build process.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Attestation verification requires the &lt;a href="https://cli.github.com/"&gt;GitHub CLI&lt;/a&gt; (&lt;code&gt;gh&lt;/code&gt;) to be installed. Development wheels from &lt;code&gt;develop&lt;/code&gt; and &lt;code&gt;nightly&lt;/code&gt; branches are also attested and can be verified the same way.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;From source&lt;/h3&gt; 
&lt;p&gt;It's possible to install from source using pip if you first install the build dependencies as specified in the &lt;code&gt;pyproject.toml&lt;/code&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt; (the Rust toolchain installer):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl https://sh.rustup.rs -sSf | sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Download and install &lt;a href="https://win.rustup.rs/x86_64"&gt;&lt;code&gt;rustup-init.exe&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;Install "Desktop development with C++" using &lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;Build Tools for Visual Studio 2022&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Verify (any system): from a terminal session run: &lt;code&gt;rustc --version&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Enable &lt;code&gt;cargo&lt;/code&gt; in the current shell:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Start a new PowerShell&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://clang.llvm.org/"&gt;clang&lt;/a&gt; (a C language frontend for LLVM):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt-get install clang
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
    &lt;ol&gt; 
     &lt;li&gt; &lt;p&gt;Add Clang to your &lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;Build Tools for Visual Studio 2022&lt;/a&gt;:&lt;/p&gt; 
      &lt;ul&gt; 
       &lt;li&gt;Start | Visual Studio Installer | Modify | C++ Clang tools for Windows (latest) = checked | Modify&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;Enable &lt;code&gt;clang&lt;/code&gt; in the current shell:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;[System.Environment]::SetEnvironmentVariable('path', "C:\Program Files\Microsoft Visual Studio\2022\BuildTools\VC\Tools\Llvm\x64\bin\;" + $env:Path,"User")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
    &lt;/ol&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Verify (any system): from a terminal session run: &lt;code&gt;clang --version&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install uv (see the &lt;a href="https://docs.astral.sh/uv/getting-started/installation"&gt;uv installation guide&lt;/a&gt; for more details):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Linux and macOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Windows (PowerShell):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://astral.sh/uv/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the source with &lt;code&gt;git&lt;/code&gt;, and install from the project's root directory:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone --branch develop --depth 1 https://github.com/nautechsystems/nautilus_trader
cd nautilus_trader
uv sync --all-extras
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;The &lt;code&gt;--depth 1&lt;/code&gt; flag fetches just the latest commit for a faster, lightweight clone.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="6"&gt; 
 &lt;li&gt; &lt;p&gt;Set environment variables for PyO3 compilation (Linux and macOS only):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Set the library path for the Python interpreter (in this case Python 3.13.4)
export LD_LIBRARY_PATH="$HOME/.local/share/uv/python/cpython-3.13.4-linux-x86_64-gnu/lib:$LD_LIBRARY_PATH"

# Set the Python executable path for PyO3
export PYO3_PYTHON=$(pwd)/.venv/bin/python
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Adjust the Python version and architecture in the &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; to match your system. Use &lt;code&gt;uv python list&lt;/code&gt; to find the exact path for your Python installation.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation"&gt;Installation Guide&lt;/a&gt; for other options and further details.&lt;/p&gt; 
&lt;h2&gt;Redis&lt;/h2&gt; 
&lt;p&gt;Using &lt;a href="https://redis.io"&gt;Redis&lt;/a&gt; with NautilusTrader is &lt;strong&gt;optional&lt;/strong&gt; and only required if configured as the backend for a &lt;a href="https://nautilustrader.io/docs/latest/concepts/cache"&gt;cache&lt;/a&gt; database or &lt;a href="https://nautilustrader.io/docs/latest/concepts/message_bus"&gt;message bus&lt;/a&gt;. See the &lt;strong&gt;Redis&lt;/strong&gt; section of the &lt;a href="https://nautilustrader.io/docs/latest/getting_started/installation#redis"&gt;Installation Guide&lt;/a&gt; for further details.&lt;/p&gt; 
&lt;h2&gt;Makefile&lt;/h2&gt; 
&lt;p&gt;A &lt;code&gt;Makefile&lt;/code&gt; is provided to automate most installation and build tasks for development. Some of the targets include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;make install&lt;/code&gt;: Installs in &lt;code&gt;release&lt;/code&gt; build mode with all dependency groups and extras.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make install-debug&lt;/code&gt;: Same as &lt;code&gt;make install&lt;/code&gt; but with &lt;code&gt;debug&lt;/code&gt; build mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make install-just-deps&lt;/code&gt;: Installs just the &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;dev&lt;/code&gt; and &lt;code&gt;test&lt;/code&gt; dependencies (does not install package).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build&lt;/code&gt;: Runs the build script in &lt;code&gt;release&lt;/code&gt; build mode (default).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-debug&lt;/code&gt;: Runs the build script in &lt;code&gt;debug&lt;/code&gt; build mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-wheel&lt;/code&gt;: Runs uv build with a wheel format in &lt;code&gt;release&lt;/code&gt; mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make build-wheel-debug&lt;/code&gt;: Runs uv build with a wheel format in &lt;code&gt;debug&lt;/code&gt; mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make cargo-test&lt;/code&gt;: Runs all Rust crate tests using &lt;code&gt;cargo-nextest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make clean&lt;/code&gt;: Deletes all build results, such as &lt;code&gt;.so&lt;/code&gt; or &lt;code&gt;.dll&lt;/code&gt; files.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make distclean&lt;/code&gt;: &lt;strong&gt;CAUTION&lt;/strong&gt; Removes all artifacts not in the git index from the repository. This includes source files which have not been &lt;code&gt;git add&lt;/code&gt;ed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make docs&lt;/code&gt;: Builds the documentation HTML using Sphinx.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make pre-commit&lt;/code&gt;: Runs the pre-commit checks over all files.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make ruff&lt;/code&gt;: Runs ruff over all files using the &lt;code&gt;pyproject.toml&lt;/code&gt; config (with autofix).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make pytest&lt;/code&gt;: Runs all tests with &lt;code&gt;pytest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;make test-performance&lt;/code&gt;: Runs performance tests with &lt;a href="https://codspeed.io"&gt;codspeed&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run &lt;code&gt;make help&lt;/code&gt; for documentation on all available make targets.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;See the &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/crates/infrastructure/TESTS.md"&gt;crates/infrastructure/TESTS.md&lt;/a&gt; file for running the infrastructure integration tests.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Indicators and strategies can be developed in both Python and Cython. For performance and latency-sensitive applications, we recommend using Cython. Below are some examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/indicators/ema_python.py"&gt;indicator&lt;/a&gt; example written in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/indicators/"&gt;indicator&lt;/a&gt; implementations written in Cython.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/nautilus_trader/examples/strategies/"&gt;strategy&lt;/a&gt; examples written in Python.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/examples/backtest/"&gt;backtest&lt;/a&gt; examples using a &lt;code&gt;BacktestEngine&lt;/code&gt; directly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;Docker containers are built using the base image &lt;code&gt;python:3.12-slim&lt;/code&gt; with the following variant tags:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;nautilus_trader:latest&lt;/code&gt; has the latest release version installed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nautilus_trader:nightly&lt;/code&gt; has the head of the &lt;code&gt;nightly&lt;/code&gt; branch installed.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jupyterlab:latest&lt;/code&gt; has the latest release version installed along with &lt;code&gt;jupyterlab&lt;/code&gt; and an example backtest notebook with accompanying data.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;jupyterlab:nightly&lt;/code&gt; has the head of the &lt;code&gt;nightly&lt;/code&gt; branch installed along with &lt;code&gt;jupyterlab&lt;/code&gt; and an example backtest notebook with accompanying data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can pull the container images as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/nautechsystems/&amp;lt;image_variant_tag&amp;gt; --platform linux/amd64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can launch the backtest example container by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull ghcr.io/nautechsystems/jupyterlab:nightly --platform linux/amd64
docker run -p 8888:8888 ghcr.io/nautechsystems/jupyterlab:nightly
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then open your browser at the following address:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;http://127.0.0.1:8888/lab
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;NautilusTrader currently exceeds the rate limit for Jupyter notebook logging (stdout output). Therefore, we set the &lt;code&gt;log_level&lt;/code&gt; to &lt;code&gt;ERROR&lt;/code&gt; in the examples. Lowering this level to see more logging will cause the notebook to hang during cell execution. We are investigating a fix that may involve either raising the configured rate limits for Jupyter or throttling the log flushing from Nautilus.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jupyterlab/jupyterlab/issues/12845"&gt;https://github.com/jupyterlab/jupyterlab/issues/12845&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/deshaw/jupyterlab-limit-output"&gt;https://github.com/deshaw/jupyterlab-limit-output&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;We aim to provide the most pleasant developer experience possible for this hybrid codebase of Python, Cython and Rust. See the &lt;a href="https://nautilustrader.io/docs/latest/developer_guide/"&gt;Developer Guide&lt;/a&gt; for helpful information.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run &lt;code&gt;make build-debug&lt;/code&gt; to compile after changes to Rust or Cython code for the most efficient development workflow.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Testing with Rust&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://nexte.st"&gt;cargo-nextest&lt;/a&gt; is the standard Rust test runner for NautilusTrader. Its key benefit is isolating each test in its own process, ensuring test reliability by avoiding interference.&lt;/p&gt; 
&lt;p&gt;You can install cargo-nextest by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-nextest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Run Rust tests with &lt;code&gt;make cargo-test&lt;/code&gt;, which uses &lt;strong&gt;cargo-nextest&lt;/strong&gt; with an efficient profile.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Thank you for considering contributing to NautilusTrader! We welcome any and all help to improve the project. If you have an idea for an enhancement or a bug fix, the first step is to open an &lt;a href="https://github.com/nautechsystems/nautilus_trader/issues"&gt;issue&lt;/a&gt; on GitHub to discuss it with the team. This helps to ensure that your contribution will be well-aligned with the goals of the project and avoids duplication of effort.&lt;/p&gt; 
&lt;p&gt;Before getting started, be sure to review the &lt;a href="https://raw.githubusercontent.com/nautechsystems/nautilus_trader/develop/ROADMAP.md#open-source-scope"&gt;open-source scope&lt;/a&gt; outlined in the project‚Äôs roadmap to understand what‚Äôs in and out of scope.&lt;/p&gt; 
&lt;p&gt;Once you're ready to start working on your contribution, make sure to follow the guidelines outlined in the &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file. This includes signing a Contributor License Agreement (CLA) to ensure that your contributions can be included in the project.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;Pull requests should target the &lt;code&gt;develop&lt;/code&gt; branch (the default branch). This is where new features and improvements are integrated before release.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Thank you again for your interest in NautilusTrader! We look forward to reviewing your contributions and working with you to improve the project.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Join our community of users and contributors on &lt;a href="https://discord.gg/NautilusTrader"&gt;Discord&lt;/a&gt; to chat and stay up-to-date with the latest announcements and features of NautilusTrader. Whether you're a developer looking to contribute or just want to learn more about the platform, all are welcome on our Discord server.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING]&lt;/p&gt; 
 &lt;p&gt;NautilusTrader does not issue, promote, or endorse any cryptocurrency tokens. Any claims or communications suggesting otherwise are unauthorized and false.&lt;/p&gt; 
 &lt;p&gt;All official updates and communications from NautilusTrader will be shared exclusively through &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;, our &lt;a href="https://discord.gg/NautilusTrader"&gt;Discord server&lt;/a&gt;, or our X (Twitter) account: &lt;a href="https://x.com/NautilusTrader"&gt;@NautilusTrader&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;If you encounter any suspicious activity, please report it to the appropriate platform and contact us at &lt;a href="mailto:info@nautechsystems.io"&gt;info@nautechsystems.io&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The source code for NautilusTrader is available on GitHub under the &lt;a href="https://www.gnu.org/licenses/lgpl-3.0.en.html"&gt;GNU Lesser General Public License v3.0&lt;/a&gt;. Contributions to the project are welcome and require the completion of a standard &lt;a href="https://github.com/nautechsystems/nautilus_trader/raw/develop/CLA.md"&gt;Contributor License Agreement (CLA)&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;NautilusTrader‚Ñ¢ is developed and maintained by Nautech Systems, a technology company specializing in the development of high-performance trading systems. For more information, visit &lt;a href="https://nautilustrader.io"&gt;https://nautilustrader.io&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;¬© 2015-2025 Nautech Systems Pty Ltd. All rights reserved.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ns-logo.png" alt="nautechsystems" title="nautechsystems" /&gt; &lt;img src="https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/ferris.png" width="128" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tokio-rs/axum</title>
      <link>https://github.com/tokio-rs/axum</link>
      <description>&lt;p&gt;Ergonomic and modular web framework built with Tokio, Tower, and Hyper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;axum&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;axum&lt;/code&gt; is a web application framework that focuses on ergonomics and modularity.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/tokio-rs/axum/actions/workflows/CI.yml"&gt;&lt;img src="https://github.com/tokio-rs/axum/actions/workflows/CI.yml/badge.svg?branch=main" alt="Build status" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/axum"&gt;&lt;img src="https://img.shields.io/crates/v/axum" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/axum"&gt;&lt;img src="https://docs.rs/axum/badge.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;More information about this crate can be found in the &lt;a href="https://docs.rs/axum"&gt;crate documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;High level features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Route requests to handlers with a macro free API.&lt;/li&gt; 
 &lt;li&gt;Declaratively parse requests using extractors.&lt;/li&gt; 
 &lt;li&gt;Simple and predictable error handling model.&lt;/li&gt; 
 &lt;li&gt;Generate responses with minimal boilerplate.&lt;/li&gt; 
 &lt;li&gt;Take full advantage of the &lt;a href="https://crates.io/crates/tower"&gt;&lt;code&gt;tower&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://crates.io/crates/tower-http"&gt;&lt;code&gt;tower-http&lt;/code&gt;&lt;/a&gt; ecosystem of middleware, services, and utilities.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In particular the last point is what sets &lt;code&gt;axum&lt;/code&gt; apart from other frameworks. &lt;code&gt;axum&lt;/code&gt; doesn't have its own middleware system but instead uses &lt;a href="https://docs.rs/tower/latest/tower/trait.Service.html"&gt;&lt;code&gt;tower::Service&lt;/code&gt;&lt;/a&gt;. This means &lt;code&gt;axum&lt;/code&gt; gets timeouts, tracing, compression, authorization, and more, for free. It also enables you to share middleware with applications written using &lt;a href="https://crates.io/crates/hyper"&gt;&lt;code&gt;hyper&lt;/code&gt;&lt;/a&gt; or &lt;a href="https://crates.io/crates/tonic"&gt;&lt;code&gt;tonic&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ö† Breaking changes ‚ö†&lt;/h2&gt; 
&lt;p&gt;We are currently working towards axum 0.9 so the &lt;code&gt;main&lt;/code&gt; branch contains breaking changes. See the &lt;a href="https://github.com/tokio-rs/axum/tree/v0.8.x"&gt;&lt;code&gt;0.8.x&lt;/code&gt;&lt;/a&gt; branch for what's released to crates.io.&lt;/p&gt; 
&lt;h2&gt;Usage example&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use axum::{
    routing::{get, post},
    http::StatusCode,
    Json, Router,
};
use serde::{Deserialize, Serialize};

#[tokio::main]
async fn main() {
    // initialize tracing
    tracing_subscriber::fmt::init();

    // build our application with a route
    let app = Router::new()
        // `GET /` goes to `root`
        .route("/", get(root))
        // `POST /users` goes to `create_user`
        .route("/users", post(create_user));

    // run our app with hyper, listening globally on port 3000
    let listener = tokio::net::TcpListener::bind("0.0.0.0:3000").await.unwrap();
    axum::serve(listener, app).await.unwrap();
}

// basic handler that responds with a static string
async fn root() -&amp;gt; &amp;amp;'static str {
    "Hello, World!"
}

async fn create_user(
    // this argument tells axum to parse the request body
    // as JSON into a `CreateUser` type
    Json(payload): Json&amp;lt;CreateUser&amp;gt;,
) -&amp;gt; (StatusCode, Json&amp;lt;User&amp;gt;) {
    // insert your application logic here
    let user = User {
        id: 1337,
        username: payload.username,
    };

    // this will be converted into a JSON response
    // with a status code of `201 Created`
    (StatusCode::CREATED, Json(user))
}

// the input to our `create_user` handler
#[derive(Deserialize)]
struct CreateUser {
    username: String,
}

// the output to our `create_user` handler
#[derive(Serialize)]
struct User {
    id: u64,
    username: String,
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find this &lt;a href="https://github.com/tokio-rs/axum/tree/main/examples/readme"&gt;example&lt;/a&gt; as well as other example projects in the &lt;a href="https://github.com/tokio-rs/axum/tree/main/examples"&gt;example directory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.rs/axum"&gt;crate documentation&lt;/a&gt; for way more examples.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;axum&lt;/code&gt; is a relatively thin layer on top of &lt;a href="https://crates.io/crates/hyper"&gt;&lt;code&gt;hyper&lt;/code&gt;&lt;/a&gt; and adds very little overhead. So &lt;code&gt;axum&lt;/code&gt;'s performance is comparable to &lt;a href="https://crates.io/crates/hyper"&gt;&lt;code&gt;hyper&lt;/code&gt;&lt;/a&gt;. You can find benchmarks &lt;a href="https://github.com/programatik29/rust-web-benchmarks"&gt;here&lt;/a&gt; and &lt;a href="https://web-frameworks-benchmark.netlify.app/result?l=rust"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Safety&lt;/h2&gt; 
&lt;p&gt;This crate uses &lt;code&gt;#![forbid(unsafe_code)]&lt;/code&gt; to ensure everything is implemented in 100% safe Rust.&lt;/p&gt; 
&lt;h2&gt;Minimum supported Rust version&lt;/h2&gt; 
&lt;p&gt;axum's MSRV is 1.78.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://github.com/tokio-rs/axum/tree/main/examples"&gt;examples&lt;/a&gt; folder contains various examples of how to use &lt;code&gt;axum&lt;/code&gt;. The &lt;a href="https://docs.rs/axum"&gt;docs&lt;/a&gt; also provide lots of code snippets and examples. For full-fledged examples, check out community-maintained &lt;a href="https://github.com/tokio-rs/axum/raw/main/ECOSYSTEM.md#project-showcase"&gt;showcases&lt;/a&gt; or &lt;a href="https://github.com/tokio-rs/axum/raw/main/ECOSYSTEM.md#tutorials"&gt;tutorials&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;p&gt;In the &lt;code&gt;axum&lt;/code&gt;'s repo we also have a &lt;a href="https://github.com/tokio-rs/axum/tree/main/examples"&gt;number of examples&lt;/a&gt; showing how to put everything together. Community-maintained &lt;a href="https://github.com/tokio-rs/axum/raw/main/ECOSYSTEM.md#project-showcase"&gt;showcases&lt;/a&gt; and &lt;a href="https://github.com/tokio-rs/axum/raw/main/ECOSYSTEM.md#tutorials"&gt;tutorials&lt;/a&gt; also demonstrate how to use &lt;code&gt;axum&lt;/code&gt; for real-world applications. You're also welcome to ask in the &lt;a href="https://discord.gg/tokio"&gt;Discord channel&lt;/a&gt; or open a &lt;a href="https://github.com/tokio-rs/axum/discussions/new?category=q-a"&gt;discussion&lt;/a&gt; with your question.&lt;/p&gt; 
&lt;h2&gt;Community projects&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/tokio-rs/axum/raw/main/ECOSYSTEM.md"&gt;here&lt;/a&gt; for a list of community maintained crates and projects built with &lt;code&gt;axum&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;üéà Thanks for your help improving the project! We are so happy to have you! We have a &lt;a href="https://github.com/tokio-rs/axum/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to help you get involved in the &lt;code&gt;axum&lt;/code&gt; project.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://github.com/tokio-rs/axum/raw/main/axum/LICENSE"&gt;MIT license&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contribution&lt;/h3&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in &lt;code&gt;axum&lt;/code&gt; by you, shall be licensed as MIT, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>apache/iggy</title>
      <link>https://github.com/apache/iggy</link>
      <description>&lt;p&gt;Apache Iggy: Hyper-Efficient Message Streaming at Laser Speed&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Apache Iggy (Incubating)&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://iggy.apache.org"&gt;Website&lt;/a&gt; | &lt;a href="https://iggy.apache.org/docs/introduction/getting-started/"&gt;Getting started&lt;/a&gt; | &lt;a href="https://iggy.apache.org/docs/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://iggy.apache.org/blogs/"&gt;Blog&lt;/a&gt; | &lt;a href="https://discord.gg/C5Sux5NcRa"&gt;Discord&lt;/a&gt; | &lt;a href="https://crates.io/crates/iggy"&gt;Crates&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div style="display: flex; flex-wrap: wrap; justify-content: center; align-items: center; text-align: center;"&gt; 
 &lt;p&gt;&lt;a href="https://crates.io/crates/iggy"&gt;&lt;img src="https://img.shields.io/crates/v/iggy.svg?sanitize=true" alt="crates.io" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/iggy"&gt;&lt;img src="https://img.shields.io/crates/d/iggy.svg?sanitize=true" alt="crates.io" /&gt;&lt;/a&gt; &lt;a href="https://coveralls.io/github/apache/iggy?branch=master"&gt;&lt;img src="https://coveralls.io/repos/github/apache/iggy/badge.svg?branch=master" alt="coverage" /&gt;&lt;/a&gt; &lt;a href="https://deps.rs/repo/github/apache/iggy"&gt;&lt;img src="https://deps.rs/repo/github/apache/iggy/status.svg?sanitize=true" alt="dependency" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/ApacheIggy"&gt;&lt;img src="https://img.shields.io/twitter/follow/ApacheIggy?style=social" alt="x" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/C5Sux5NcRa"&gt;&lt;img src="https://img.shields.io/discord/1144142576266530928" alt="discord-badge" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/apache/iggy/master/assets/iggy_black.png" alt="iggy" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Iggy&lt;/strong&gt; is a persistent message streaming platform written in Rust, supporting QUIC, TCP (custom binary specification) and HTTP (regular REST API) transport protocols, &lt;strong&gt;capable of processing millions of messages per second at ultra-low latency&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Iggy provides &lt;strong&gt;exceptionally high throughput and performance&lt;/strong&gt; while utilizing minimal computing resources.&lt;/p&gt; 
&lt;p&gt;This is &lt;strong&gt;not yet another extension&lt;/strong&gt; running on top of existing infrastructure, such as Kafka or SQL database.&lt;/p&gt; 
&lt;p&gt;Iggy is a persistent message streaming log &lt;strong&gt;built from the ground up&lt;/strong&gt; using low-level I/O for speed and efficiency.&lt;/p&gt; 
&lt;p&gt;The name is an abbreviation for the Italian Greyhound - small yet extremely fast dogs, the best in their class. See the lovely &lt;a href="https://www.instagram.com/fabio.and.cookie/"&gt;Fabio &amp;amp; Cookie&lt;/a&gt; ‚ù§Ô∏è&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Highly performant&lt;/strong&gt;, persistent append-only log for message streaming&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Very high throughput&lt;/strong&gt; for both writes and reads&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Low latency and predictable resource usage&lt;/strong&gt; thanks to the Rust compiled language (no GC)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User authentication and authorization&lt;/strong&gt; with granular permissions and Personal Access Tokens (PAT)&lt;/li&gt; 
 &lt;li&gt;Support for multiple streams, topics and partitions&lt;/li&gt; 
 &lt;li&gt;Support for &lt;strong&gt;multiple transport protocols&lt;/strong&gt; (QUIC, TCP, HTTP)&lt;/li&gt; 
 &lt;li&gt;Fully operational RESTful API which can be optionally enabled&lt;/li&gt; 
 &lt;li&gt;Available client SDK in multiple languages&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Works directly with binary data&lt;/strong&gt;, avoiding enforced schema and serialization/deserialization overhead&lt;/li&gt; 
 &lt;li&gt;Custom &lt;strong&gt;zero-copy (de)serialization&lt;/strong&gt;, which greatly improves the performance and reduces memory usage.&lt;/li&gt; 
 &lt;li&gt;Configurable server features (e.g. caching, segment size, data flush interval, transport protocols etc.)&lt;/li&gt; 
 &lt;li&gt;Server-side storage of &lt;strong&gt;consumer offsets&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Multiple ways of polling the messages: 
  &lt;ul&gt; 
   &lt;li&gt;By offset (using the indexes)&lt;/li&gt; 
   &lt;li&gt;By timestamp (using the time indexes)&lt;/li&gt; 
   &lt;li&gt;First/Last N messages&lt;/li&gt; 
   &lt;li&gt;Next N messages for the specific consumer&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Possibility of &lt;strong&gt;auto committing the offset&lt;/strong&gt; (e.g. to achieve &lt;em&gt;at-most-once&lt;/em&gt; delivery)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consumer groups&lt;/strong&gt; providing the message ordering and horizontal scaling across the connected clients&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Message expiry&lt;/strong&gt; with auto deletion based on the configurable &lt;strong&gt;retention policy&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Additional features such as &lt;strong&gt;server side message deduplication&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-tenant&lt;/strong&gt; support via abstraction of &lt;strong&gt;streams&lt;/strong&gt; which group &lt;strong&gt;topics&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TLS&lt;/strong&gt; support for all transport protocols (TCP, QUIC, HTTPS)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/apache/iggy/tree/master/core/connectors"&gt;Connectors&lt;/a&gt;&lt;/strong&gt; - sinks, sources and data transformations based on the &lt;strong&gt;custom Rust plugins&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/apache/iggy/tree/master/core/ai/mcp"&gt;Model Context Protocol&lt;/a&gt;&lt;/strong&gt; - provide context to LLM with &lt;strong&gt;MCP server&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Optional server-side as well as client-side &lt;strong&gt;data encryption&lt;/strong&gt; using AES-256-GCM&lt;/li&gt; 
 &lt;li&gt;Optional metadata support in the form of &lt;strong&gt;message headers&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Optional &lt;strong&gt;data backups and archiving&lt;/strong&gt; to disk or &lt;strong&gt;S3&lt;/strong&gt; compatible cloud storage (e.g. AWS S3)&lt;/li&gt; 
 &lt;li&gt;Support for &lt;strong&gt;OpenTelemetry&lt;/strong&gt; logs &amp;amp; traces + Prometheus metrics&lt;/li&gt; 
 &lt;li&gt;Built-in &lt;strong&gt;CLI&lt;/strong&gt; to manage the streaming server installable via &lt;code&gt;cargo install iggy-cli&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Built-in &lt;strong&gt;benchmarking app&lt;/strong&gt; to test the performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Single binary deployment&lt;/strong&gt; (no external dependencies)&lt;/li&gt; 
 &lt;li&gt;Running as a single node (clustering based on Viewstamped Replication will be implemented in the near future)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/apache/iggy/master/assets/server.png" alt="server" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/apache/iggy/master/assets/files_structure.png" alt="files structure" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;This is the high-level architecture of the Iggy message streaming server, where extremely high performance and ultra low and stable tail latencies are the primary goals. The server is designed to handle high throughput and very low latency (sub-millisecond tail latencies), making it suitable for real-time applications. For more details, please refer to the &lt;a href="https://iggy.apache.org/docs/introduction/architecture"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/apache/iggy/master/assets/iggy_architecture.png" alt="server" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Version&lt;/h2&gt; 
&lt;p&gt;The official releases follow the regular semver (&lt;code&gt;0.5.0&lt;/code&gt;) or have &lt;code&gt;latest&lt;/code&gt; tag applied (&lt;code&gt;apache/iggy:latest&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;We do also publish edge/dev/nightly releases (e.g. &lt;code&gt;0.5.0-edge.1&lt;/code&gt; or &lt;code&gt;apache/iggy:edge&lt;/code&gt;), for both, SDKs and the Docker images, which are typically compatible with the latest changes, but are not guaranteed to be stable, and as the name states, are not recommended for production use.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Shared-nothing&lt;/strong&gt; design and &lt;strong&gt;io_uring&lt;/strong&gt; support (PoC on experimental branch, WiP on the main branch)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Clustering&lt;/strong&gt; &amp;amp; data replication based on &lt;strong&gt;&lt;a href="http://pmg.csail.mit.edu/papers/vr-revisited.pdf"&gt;VSR&lt;/a&gt;&lt;/strong&gt; (on sandbox project using Raft, will be implemented after shared-nothing design is completed)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Supported languages SDK&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://crates.io/crates/iggy"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nuget.org/packages/Apache.Iggy/"&gt;C#&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://repository.apache.org/#nexus-search;quick~iggy"&gt;Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pypi.org/project/apache-iggy/"&gt;Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/package/apache-iggy"&gt;Node.js (TypeScript)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/apache/iggy/foreign/go"&gt;Go&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;C++ and Elixir are work in progress.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;CLI&lt;/h2&gt; 
&lt;p&gt;The interactive CLI is implemented under the &lt;code&gt;cli&lt;/code&gt; project, to provide the best developer experience. This is a great addition to the Web UI, especially for all the developers who prefer using the console tools.&lt;/p&gt; 
&lt;p&gt;Iggy CLI can be installed with &lt;code&gt;cargo install iggy-cli&lt;/code&gt; and then simply accessed by typing &lt;code&gt;iggy&lt;/code&gt; in your terminal.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/apache/iggy/master/assets/cli.png" alt="CLI" /&gt;&lt;/p&gt; 
&lt;h2&gt;Web UI&lt;/h2&gt; 
&lt;p&gt;There's a dedicated Web UI for the server, which allows managing the streams, topics, partitions, browsing the messages and so on. This is an ongoing effort to build a comprehensive dashboard for administrative purposes of the Iggy server. Check the Web UI in the &lt;code&gt;/web&lt;/code&gt; directory. The &lt;a href="https://hub.docker.com/r/apache/iggy-web-ui"&gt;docker image for Web UI&lt;/a&gt; is available, and can be fetched via &lt;code&gt;docker pull apache/iggy-web-ui&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/apache/iggy/master/assets/web_ui.png" alt="Web UI" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Connectors&lt;/h2&gt; 
&lt;p&gt;The highly performant and modular &lt;strong&gt;&lt;a href="https://github.com/apache/iggy/tree/master/core/connectors"&gt;runtime&lt;/a&gt;&lt;/strong&gt; for statically typed, yet dynamically loaded connectors. Ingest the data from the external sources and push it further to the Iggy streams, or fetch the data from the Iggy streams and push it further to the external sources. &lt;strong&gt;Create your own Rust plugins&lt;/strong&gt; by simply implementing either the &lt;code&gt;Source&lt;/code&gt; or &lt;code&gt;Sink&lt;/code&gt; trait and &lt;strong&gt;build custom pipelines for the data processing&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;## Configure a sink or source connector, depending on your needs
[sinks.quickwit]
enabled = true
name = "Quickwit sink"
path = "target/release/libiggy_connector_quickwit_sink"
config_format = "yaml"

[[sinks.quickwit.streams]]
stream = "qw"
topics = ["records"]
schema = "json"
batch_length = 1000
poll_interval = "5ms"
consumer_group = "qw_sink_connector"

[[sinks.quickwit.transforms.add_fields.fields]]
key = "random_id"
value.computed = "uuid_v7"

[sinks.quickwit.transforms.delete_fields]
enabled = true
fields = ["email", "created_at"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Model Context Protocol&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://modelcontextprotocol.io"&gt;Model Context Protocol&lt;/a&gt; (MCP) is an open protocol that standardizes how applications provide context to LLMs. The &lt;strong&gt;&lt;a href="https://github.com/apache/iggy/tree/master/core/ai/mcp"&gt;Iggy MCP Server&lt;/a&gt;&lt;/strong&gt; is an implementation of the MCP protocol for the message streaming infrastructure. It can be used to provide context to LLMs in real-time, allowing for more accurate and relevant responses.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/apache/iggy/master/assets/iggy_mcp_server.png" alt="server" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;p&gt;The official Apache Iggy images can be found in &lt;a href="https://hub.docker.com/r/apache/iggy"&gt;Docker Hub&lt;/a&gt;, simply type &lt;code&gt;docker pull apache/iggy&lt;/code&gt; to pull the image.&lt;/p&gt; 
&lt;p&gt;You can also find the images for all the different tooling such as Connectors, MCP Server etc. at &lt;a href="https://hub.docker.com/u/apache?page=1&amp;amp;search=iggy"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Please note that the images tagged as &lt;code&gt;latest&lt;/code&gt; are based on the official, stable releases, while the &lt;code&gt;edge&lt;/code&gt; ones are updated directly from latest version of the &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt; 
&lt;p&gt;You can find the &lt;code&gt;Dockerfile&lt;/code&gt; and &lt;code&gt;docker-compose&lt;/code&gt; in the root of the repository. To build and start the server, run: &lt;code&gt;docker compose up&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, you can run the &lt;code&gt;CLI&lt;/code&gt; which is available in the running container, by executing: &lt;code&gt;docker exec -it iggy-server /iggy&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Keep in mind that running the container on the OS other than Linux, where the Docker is running in the VM, might result in the performance degradation.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;The default configuration can be found in &lt;code&gt;server.toml&lt;/code&gt; file in &lt;code&gt;configs&lt;/code&gt; directory.&lt;/p&gt; 
&lt;p&gt;The configuration file is loaded from the current working directory, but you can specify the path to the configuration file by setting &lt;code&gt;IGGY_CONFIG_PATH&lt;/code&gt; environment variable, for example &lt;code&gt;export IGGY_CONFIG_PATH=configs/server.toml&lt;/code&gt; (or other command depending on OS).&lt;/p&gt; 
&lt;p&gt;When config file is not found, the default values from embedded &lt;code&gt;server.toml&lt;/code&gt; file are used.&lt;/p&gt; 
&lt;p&gt;For the detailed documentation of the configuration file, please refer to the &lt;a href="https://iggy.apache.org/docs/server/configuration"&gt;configuration&lt;/a&gt; section.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;Build the project (the longer compilation time is due to &lt;a href="https://doc.rust-lang.org/rustc/linker-plugin-lto.html"&gt;LTO&lt;/a&gt; enabled in release &lt;a href="https://github.com/apache/iggy/raw/master/Cargo.toml#L2"&gt;profile&lt;/a&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo build&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Run the tests:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo test&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Set root user credentials (OPTIONAL):&lt;/p&gt; 
&lt;p&gt;Iggy requires credentials to authenticate request to the server. You can set the root user &lt;strong&gt;before&lt;/strong&gt; starting the server.&lt;/p&gt; 
&lt;p&gt;(macOS/Linux)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export IGGY_ROOT_USERNAME=iggy
export IGGY_ROOT_PASSWORD=iggy
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(Windows(Powershell))&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$env:IGGY_ROOT_USERNAME = "iggy"
$env:IGGY_ROOT_PASSWORD = "iggy"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By default, &lt;code&gt;iggy-server&lt;/code&gt; will generate a randomized root user password and print it to &lt;code&gt;stdout&lt;/code&gt;, when there's NO users created.&lt;/p&gt; 
&lt;p&gt;Start the server:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy-server&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;All the data used by the server will be persisted under the &lt;code&gt;local_data&lt;/code&gt; directory by default, unless specified differently in the configuration (see &lt;code&gt;system.path&lt;/code&gt; in &lt;code&gt;server.toml&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;One can use default root credentials with optional &lt;code&gt;--with-default-root-credentials&lt;/code&gt;. This flag is equivalent to setting &lt;code&gt;IGGY_ROOT_USERNAME=iggy&lt;/code&gt; and &lt;code&gt;IGGY_ROOT_PASSWORD=iggy&lt;/code&gt;, plus it should only be used for development and testing.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy-server -- --with-default-root-credentials&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Root credentials are only set on the first server startup when the data directory doesn't exist yet. Once the server has been started and persisted data exists, the existing root credentials will be reused, and the &lt;code&gt;--with-default-root-credentials&lt;/code&gt; flag or environment variables will have no effect. To reset credentials, delete the data directory.&lt;/p&gt; 
&lt;p&gt;For configuration options and detailed help:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy-server -- --help&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;You can also use environment variables to override any configuration setting:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Override TCP address &lt;code&gt;IGGY_TCP_ADDRESS=0.0.0.0:8090 cargo run --bin iggy-server&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Set custom data path &lt;code&gt;IGGY_SYSTEM_PATH=/data/iggy cargo run --bin iggy-server&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Enable HTTP transport &lt;code&gt;IGGY_HTTP_ENABLED=true cargo run --bin iggy-server&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Set custom root user credentials &lt;code&gt;IGGY_ROOT_USERNAME=iggy IGGY_ROOT_PASSWORD=iggy cargo run --bin iggy-server&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To quickly generate the sample data:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin data-seeder-tool&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Please note that all commands below are using &lt;code&gt;iggy&lt;/code&gt; binary, which is part of release (&lt;code&gt;cli&lt;/code&gt; sub-crate).&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Create a stream with name &lt;code&gt;dev&lt;/code&gt; (numerical ID will be assigned by server automatically) using default credentials and &lt;code&gt;tcp&lt;/code&gt; transport (available transports: &lt;code&gt;quic&lt;/code&gt;, &lt;code&gt;tcp&lt;/code&gt;, &lt;code&gt;http&lt;/code&gt;, default &lt;code&gt;tcp&lt;/code&gt;):&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy -- --transport tcp --username &amp;lt;iggy_username&amp;gt; --password &amp;lt;iggy_password&amp;gt; stream create dev&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;List available streams:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy -- --username &amp;lt;iggy_username&amp;gt; --password &amp;lt;iggy_password&amp;gt; stream list&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Get &lt;code&gt;dev&lt;/code&gt; stream details:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy -- -u &amp;lt;iggy_username&amp;gt; -p &amp;lt;iggy_password&amp;gt; stream get dev&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Create a topic named &lt;code&gt;sample&lt;/code&gt; (numerical ID will be assigned by server automatically) for stream &lt;code&gt;dev&lt;/code&gt;, with 2 partitions (IDs 1 and 2), disabled compression (&lt;code&gt;none&lt;/code&gt;) and disabled message expiry (skipped optional parameter):&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy -- -u &amp;lt;iggy_username&amp;gt; -p &amp;lt;iggy_password&amp;gt; topic create dev sample 2 none&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;List available topics for stream &lt;code&gt;dev&lt;/code&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy -- -u &amp;lt;iggy_username&amp;gt; -p &amp;lt;iggy_password&amp;gt; topic list dev&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Get topic details for topic &lt;code&gt;sample&lt;/code&gt; in stream &lt;code&gt;dev&lt;/code&gt;:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy -- -u &amp;lt;iggy_username&amp;gt; -p &amp;lt;iggy_password&amp;gt; topic get dev sample&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Send a message 'hello world' (message ID 1) to the stream &lt;code&gt;dev&lt;/code&gt; to topic &lt;code&gt;sample&lt;/code&gt; and partition 1:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy -- -u &amp;lt;iggy_username&amp;gt; -p &amp;lt;iggy_password&amp;gt; message send --partition-id 1 dev sample "hello world"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Send another message 'lorem ipsum' (message ID 2) to the same stream, topic and partition:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy -- -u &amp;lt;iggy_username&amp;gt; -p &amp;lt;iggy_password&amp;gt; message send --partition-id 1 dev sample "lorem ipsum"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Poll messages by a regular consumer with ID 1 from the stream &lt;code&gt;dev&lt;/code&gt; for topic &lt;code&gt;sample&lt;/code&gt; and partition with ID 1, starting with offset 0, messages count 2, without auto commit (storing consumer offset on server):&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;cargo run --bin iggy -- -u &amp;lt;iggy_username&amp;gt; -p &amp;lt;iggy_password&amp;gt; message poll --consumer 1 --offset 0 --message-count 2 --auto-commit dev sample 1&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Finally, restart the server to see it is able to load the persisted data.&lt;/p&gt; 
&lt;p&gt;The HTTP API endpoints can be found in &lt;a href="https://github.com/apache/iggy/raw/master/core/server/server.http"&gt;server.http&lt;/a&gt; file, which can be used with &lt;a href="https://marketplace.visualstudio.com/items?itemName=humao.rest-client"&gt;REST Client&lt;/a&gt; extension for VS Code.&lt;/p&gt; 
&lt;p&gt;To see the detailed logs from the CLI/server, run it with &lt;code&gt;RUST_LOG=trace&lt;/code&gt; environment variable. See images below:&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;You can find comprehensive sample applications under the &lt;code&gt;examples/rust&lt;/code&gt; directory. These examples showcase various usage patterns of the Iggy client SDK, from basic operations to advanced multi-tenant scenarios.&lt;/p&gt; 
&lt;p&gt;For detailed information about available examples and how to run them, please see the &lt;a href="https://raw.githubusercontent.com/apache/iggy/master/examples/rust/README.md"&gt;Examples README&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;SDK&lt;/h2&gt; 
&lt;p&gt;Iggy comes with the Rust SDK, which is available on &lt;a href="https://crates.io/crates/iggy"&gt;crates.io&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The SDK provides both, low-level client for the specific transport, which includes the message sending and polling along with all the administrative actions such as managing the streams, topics, users etc., as well as the high-level client, which abstracts the low-level details and provides the easy-to-use API for both, message producers and consumers.&lt;/p&gt; 
&lt;p&gt;You can find the more examples, including the multi-tenant one under the &lt;code&gt;examples&lt;/code&gt; directory.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;// Create the Iggy client
let client = IggyClient::from_connection_string("iggy://user:secret@localhost:8090")?;

// Create a producer for the given stream and one of its topics
let mut producer = client
    .producer("dev01", "events")?
    .direct( // Use either direct (instant) or background message sending
        DirectConfig::builder()
            .batch_length(1000)
            .linger_time(IggyDuration::from_str("1ms")?)
            .build(),
    )
    .partitioning(Partitioning::balanced())
    .build();

producer.init().await?;

// Send some messages to the topic
let messages = vec![IggyMessage::from_str("Hello Apache Iggy")?];
producer.send(messages).await?;

// Create a consumer for the given stream and one of its topics
let mut consumer = client
    .consumer_group("my_app", "dev01", "events")?
    .auto_commit(AutoCommit::IntervalOrWhen(
        IggyDuration::from_str("1s")?,
        AutoCommitWhen::ConsumingAllMessages,
    ))
    .create_consumer_group_if_not_exists()
    .auto_join_consumer_group()
    .polling_strategy(PollingStrategy::next())
    .poll_interval(IggyDuration::from_str("1ms")?)
    .batch_length(1000)
    .build();

consumer.init().await?;

// Start consuming the messages
while let Some(message) = consumer.next().await {
    // Handle the message
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Benchmarks should be the first-class citizens&lt;/strong&gt;. We believe that performance is crucial for any system, and we strive to provide the best possible performance for our users. Please check, why we believe that the &lt;strong&gt;&lt;a href="https://iggy.apache.org/blogs/2025/02/17/transparent-benchmarks"&gt;transparent benchmarking&lt;/a&gt;&lt;/strong&gt; is so important.&lt;/p&gt; 
&lt;p&gt;We've also built the &lt;strong&gt;&lt;a href="https://benchmarks.iggy.apache.org"&gt;benchmarking platform&lt;/a&gt;&lt;/strong&gt; where anyone can upload the benchmarks and compare the results with others. Source code for the platform is available in the &lt;code&gt;core/bench/dashboard&lt;/code&gt; directory.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/apache/iggy/master/assets/benchmarking_platform.png" alt="server" /&gt;&lt;/p&gt; 
&lt;p&gt;For the benchmarking purposes, we've developed the dedicated &lt;strong&gt;iggy-bench&lt;/strong&gt; tool, which is a part of the &lt;strong&gt;iggy&lt;/strong&gt; project. It is a command-line tool that allows you to run the variety of fully customizable benchmarks.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/apache/iggy/master/assets/bench.png" alt="server" /&gt;&lt;/p&gt; 
&lt;p&gt;To benchmark the project, first build the project in release mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, run the benchmarking app with the desired options:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Sending (writing) benchmark&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --bin iggy-bench -r -- -v pinned-producer tcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Polling (reading) benchmark&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --bin iggy-bench -r -- -v pinned-consumer tcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Parallel sending and polling benchmark&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --bin iggy-bench -r -- -v pinned-producer-and-consumer tcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Balanced sending to multiple partitions benchmark&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --bin iggy-bench -r -- -v balanced-producer tcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Consumer group polling benchmark:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --bin iggy-bench -r -- -v balanced-consumer-group tcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Parallel balanced sending and polling from consumer group benchmark:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --bin iggy-bench -r -- -v balanced-producer-and-consumer-group tcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;End to end producing and consuming benchmark (single task produces and consumes messages in sequence):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cargo run --bin iggy-bench -r -- -v end-to-end-producing-consumer tcp
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;These benchmarks would start the server with the default configuration, create a stream, topic and partition, and then send or poll the messages. The default configuration is optimized for the best performance, so you might want to tweak it for your needs. If you need more options, please refer to &lt;code&gt;iggy-bench&lt;/code&gt; subcommands &lt;code&gt;help&lt;/code&gt; and &lt;code&gt;examples&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example, to run the benchmark for the already started server, provide the additional argument &lt;code&gt;--server-address 0.0.0.0:8090&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Depending on the hardware, transport protocol (&lt;code&gt;quic&lt;/code&gt;, &lt;code&gt;tcp&lt;/code&gt; or &lt;code&gt;http&lt;/code&gt;) and payload size (&lt;code&gt;messages-per-batch * message-size&lt;/code&gt;) you might expect &lt;strong&gt;over 5000 MB/s (e.g. 5M of 1 KB msg/sec) throughput for writes and reads&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Iggy is already capable of processing millions of messages per second at the microseconds range for p99+ latency&lt;/strong&gt;, and with the upcoming optimizations related to the io_uring support along with the shared-nothing design, it will only get better.&lt;/p&gt; 
&lt;p&gt;Please refer to the mentioned &lt;a href="https://benchmarks.iggy.apache.org"&gt;benchmarking platform&lt;/a&gt; where you can browse the results achieved on the different hardware configurations, using the different Iggy server versions.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://raw.githubusercontent.com/apache/iggy/master/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>