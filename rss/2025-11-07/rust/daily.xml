<rss version="2.0">
  <channel>
    <title>GitHub Rust Daily Trending</title>
    <description>Daily Trending of Rust in GitHub</description>
    <pubDate>Thu, 06 Nov 2025 01:41:41 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>tracel-ai/burn</title>
      <link>https://github.com/tracel-ai/burn</link>
      <description>&lt;p&gt;Burn is a next generation tensor library and Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/logo-burn-neutral.webp" width="350px" /&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/uPEBbYYDB6"&gt;&lt;img src="https://img.shields.io/discord/1038839012602941528.svg?color=7289da&amp;amp;&amp;amp;logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/v/burn.svg?sanitize=true" alt="Current Crates.io Version" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/msrv/burn" alt="Minimum Supported Rust Version" /&gt;&lt;/a&gt; &lt;a href="https://burn.dev/docs/burn"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tracel-ai/burn/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/tracel-ai/burn/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Test Status" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/#license"&gt;&lt;img src="https://shields.io/badge/license-MIT%2FApache--2.0-blue" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/tracel-ai/burn"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.runblaze.dev"&gt;&lt;img src="https://www.runblaze.dev/ci-blaze-powered.png" width="125px" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;p&gt;&lt;strong&gt;Burn is a next generation Tensor Library and Deep Learning Framework that doesn't compromise on &lt;br /&gt; flexibility, efficiency and portability.&lt;/strong&gt;&lt;/p&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;div align="left"&gt; 
 &lt;p&gt;Burn is both a tensor library and a deep learning framework optimized for numerical computing, model inference and model training. Burn leverages Rust to perform optimizations normally only available in static-graph frameworks, offering optimal speed without impacting flexibility.&lt;/p&gt; 
 &lt;h2&gt;Backend&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/backend-chip.png" height="96px" /&gt; 
  &lt;p&gt;Burn strives to be as fast as possible on as many hardwares as possible, with robust implementations. We believe this flexibility is crucial for modern needs where you may train your models in the cloud, then deploy on customer hardwares, which vary from user to user.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;Supported Backends&lt;/h3&gt; 
 &lt;p&gt;Most backends support all operating systems, so we don't mention them in the tables below.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;GPU Backends:&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;CUDA&lt;/th&gt; 
    &lt;th&gt;ROCm&lt;/th&gt; 
    &lt;th&gt;Metal&lt;/th&gt; 
    &lt;th&gt;Vulkan&lt;/th&gt; 
    &lt;th&gt;WebGPU&lt;/th&gt; 
    &lt;th&gt;Candle&lt;/th&gt; 
    &lt;th&gt;LibTorch&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Nvidia&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;AMD&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Apple&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Intel&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Qualcom&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wasm&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;CPU Backends:&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;Cpu (CubeCL)&lt;/th&gt; 
    &lt;th&gt;NdArray&lt;/th&gt; 
    &lt;th&gt;Candle&lt;/th&gt; 
    &lt;th&gt;LibTorch&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;X86&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Arm&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wasm&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;no-std&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;‚òëÔ∏è&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Compared to other frameworks, Burn has a very different approach to supporting many backends. By design, most code is generic over the Backend trait, which allows us to build Burn with swappable backends. This makes composing backend possible, augmenting them with additional functionalities such as autodifferentiation and automatic kernel fusion.&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Autodiff: Backend decorator that brings backpropagation to any backend üîÑ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Contrary to the aforementioned backends, Autodiff is actually a backend &lt;em&gt;decorator&lt;/em&gt;. This means that it cannot exist by itself; it must encapsulate another backend.&lt;/p&gt; 
  &lt;p&gt;The simple act of wrapping a base backend with Autodiff transparently equips it with autodifferentiation support, making it possible to call backward on your model.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::backend::{Autodiff, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&amp;lt;Wgpu&amp;gt;;

    let device = Default::default();

    let x: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default, &amp;amp;device);
    let y: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default, &amp;amp;device).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;amp;grads).unwrap();
    println!("{y_grad}");
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, it is impossible to make the mistake of calling backward on a model that runs on a backend that does not support autodiff (for inference), as this method is only offered by an Autodiff backend.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-autodiff/README.md"&gt;Autodiff Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Fusion: Backend decorator that brings kernel fusion to all first-party backends &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;This backend decorator enhances a backend with kernel fusion, provided that the inner backend supports it. Note that you can compose this backend with other backend decorators such as Autodiff. All first-party accelerated backends (like WGPU and CUDA) use Fusion by default (&lt;code&gt;burn/fusion&lt;/code&gt; feature flag), so you typically don't need to apply it manually.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#[cfg(not(feature = "fusion"))]
pub type Cuda&amp;lt;F = f32, I = i32&amp;gt; = CubeBackend&amp;lt;CudaRuntime, F, I, u8&amp;gt;;

#[cfg(feature = "fusion")]
pub type Cuda&amp;lt;F = f32, I = i32&amp;gt; = burn_fusion::Fusion&amp;lt;CubeBackend&amp;lt;CudaRuntime, F, I, u8&amp;gt;&amp;gt;;
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, we plan to implement automatic gradient checkpointing based on compute bound and memory bound operations, which will work gracefully with the fusion backend to make your code run even faster during training, see &lt;a href="https://github.com/tracel-ai/burn/issues/936"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-fusion/README.md"&gt;Fusion Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Router (Beta): Backend decorator that composes multiple backends into a single one &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;That backend simplifies hardware operability, if for instance you want to execute some operations on the CPU and other operations on the GPU.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::tensor::{Distribution, Tensor};
use burn::backend::{
    NdArray, Router, Wgpu, ndarray::NdArrayDevice, router::duo::MultiDevice, wgpu::WgpuDevice,
};

fn main() {
    type Backend = Router&amp;lt;(Wgpu, NdArray)&amp;gt;;

    let device_0 = MultiDevice::B1(WgpuDevice::DiscreteGpu(0));
    let device_1 = MultiDevice::B2(NdArrayDevice::Cpu);

    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_0);
    let tensor_cpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_1);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Remote (Beta): Backend decorator for remote backend execution, useful for distributed computations &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;That backend has two parts, one client and one server. The client sends tensor operations over the network to a remote compute backend. You can use any first-party backend as server in a single line of code:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;fn main_server() {
    // Start a server on port 3000.
    burn::server::start::&amp;lt;burn::backend::Cuda&amp;gt;(Default::default(), 3000);
}

fn main_client() {
    // Create a client that communicate with the server on port 3000.
    use burn::backend::{Autodiff, RemoteBackend};

    type Backend = Autodiff&amp;lt;RemoteDevice&amp;gt;;

    let device = RemoteDevice::new("ws://localhost:3000");
    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], Distribution::Default, &amp;amp;device);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;h2&gt;Training &amp;amp; Inference&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-wall.png" height="96px" /&gt; 
  &lt;p&gt;The whole deep learning workflow is made easy with Burn, as you can monitor your training progress with an ergonomic dashboard, and run inference everywhere from embedded devices to large GPU clusters.&lt;/p&gt; 
  &lt;p&gt;Burn was built from the ground up with training and inference in mind. It's also worth noting how Burn, in comparison to frameworks like PyTorch, simplifies the transition from training to deployment, eliminating the need for code changes.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;br /&gt; 
  &lt;a href="https://www.youtube.com/watch?v=N9RM5CQbNQc" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/burn-train-tui.png" alt="Burn Train TUI" width="75%" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Click on the following sections to expand üëá&lt;/strong&gt;&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Training Dashboard üìà &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;As you can see in the previous video (click on the picture!), a new terminal UI dashboard based on the &lt;a href="https://github.com/ratatui-org/ratatui"&gt;Ratatui&lt;/a&gt; crate allows users to follow their training with ease without having to connect to any external application.&lt;/p&gt; 
  &lt;p&gt;You can visualize your training and validation metrics updating in real-time and analyze the lifelong progression or recent history of any registered metrics using only the arrow keys. Break from the training loop without crashing, allowing potential checkpoints to be fully written or important pieces of code to complete without interruption üõ°&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; ONNX Support üê´ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Burn supports importing ONNX (Open Neural Network Exchange) models, allowing you to easily port models from TensorFlow or PyTorch to Burn. The ONNX model is converted into Rust code that uses Burn's native APIs, enabling the imported model to run on any Burn backend (CPU, GPU, WebAssembly) and benefit from all of Burn's optimizations like automatic kernel fusion.&lt;/p&gt; 
  &lt;p&gt;Our ONNX support is further described in &lt;a href="https://burn.dev/books/burn/import/onnx-model.html"&gt;this section of the Burn Book üî•&lt;/a&gt;.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This crate is in active development and currently supports a &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-import/SUPPORTED-ONNX-OPS.md"&gt;limited set of ONNX operators&lt;/a&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Importing PyTorch or Safetensors Models üöö &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;You can load weights from PyTorch or Safetensors formats directly into your Burn-defined models. This makes it easy to reuse existing models while benefiting from Burn's performance and deployment features.&lt;/p&gt; 
  &lt;p&gt;Learn more:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/pytorch-model.html"&gt;Import pre-trained PyTorch models into Burn&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/safetensors-model.html"&gt;Load models from Safetensors format&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Inference in the Browser üåê &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Several of our backends can run in WebAssembly environments: Candle and NdArray for CPU execution, and WGPU for GPU acceleration via WebGPU. This means that you can run inference directly within a browser. We provide several examples of this:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST&lt;/a&gt; where you can draw digits and a small convnet tries to find which one it is! 2Ô∏è‚É£ 7Ô∏è‚É£ üò∞&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification&lt;/a&gt; where you can upload images and classify them! üåÑ&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Embedded: &lt;i&gt;no_std&lt;/i&gt; support ‚öôÔ∏è &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Burn's core components support &lt;a href="https://docs.rust-embedded.org/book/intro/no-std.html"&gt;no_std&lt;/a&gt;. This means it can run in bare metal environment such as embedded devices without an operating system.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;As of now, only the NdArray backend can be used in a &lt;em&gt;no_std&lt;/em&gt; environment.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;Benchmarks&lt;/h3&gt; 
 &lt;p&gt;To evaluate performance across different backends and track improvements over time, we provide a dedicated benchmarking suite.&lt;/p&gt; 
 &lt;p&gt;Run and compare benchmarks using &lt;a href="https://github.com/tracel-ai/burn-bench"&gt;burn-bench&lt;/a&gt;.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Warning&lt;/strong&gt; When using one of the &lt;code&gt;wgpu&lt;/code&gt; backends, you may encounter compilation errors related to recursive type evaluation. This is due to complex type nesting within the &lt;code&gt;wgpu&lt;/code&gt; dependency chain. To resolve this issue, add the following line at the top of your &lt;code&gt;main.rs&lt;/code&gt; or &lt;code&gt;lib.rs&lt;/code&gt; file:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#![recursion_limit = "256"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;The default recursion limit (128) is often just below the required depth (typically 130-150) due to deeply nested associated types and trait bounds.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h2&gt;Getting Started&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-walking.png" height="96px" /&gt; 
  &lt;p&gt;Just heard of Burn? You are at the right place! Just continue reading this section and we hope you can get on board really quickly.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;details&gt; 
  &lt;summary&gt; The Burn Book üî• &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;To begin working effectively with Burn, it is crucial to understand its key components and philosophy. This is why we highly recommend new users to read the first sections of &lt;a href="https://burn.dev/books/burn/"&gt;The Burn Book üî•&lt;/a&gt;. It provides detailed examples and explanations covering every facet of the framework, including building blocks like tensors, modules, and optimizers, all the way to advanced usage, like coding your own GPU kernels.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;The project is constantly evolving, and we try as much as possible to keep the book up to date with new additions. However, we might miss some details sometimes, so if you see something weird, let us know! We also gladly accept Pull Requests üòÑ&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Examples üôè &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Let's start with a code snippet that shows how intuitive the framework is to use! In the following, we declare a neural network module with some parameters along with its forward pass.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::nn;
use burn::module::Module;
use burn::tensor::backend::Backend;

#[derive(Module, Debug)]
pub struct PositionWiseFeedForward&amp;lt;B: Backend&amp;gt; {
    linear_inner: nn::Linear&amp;lt;B&amp;gt;,
    linear_outer: nn::Linear&amp;lt;B&amp;gt;,
    dropout: nn::Dropout,
    gelu: nn::Gelu,
}

impl&amp;lt;B: Backend&amp;gt; PositionWiseFeedForward&amp;lt;B&amp;gt; {
    pub fn forward&amp;lt;const D: usize&amp;gt;(&amp;amp;self, input: Tensor&amp;lt;B, D&amp;gt;) -&amp;gt; Tensor&amp;lt;B, D&amp;gt; {
        let x = self.linear_inner.forward(input);
        let x = self.gelu.forward(x);
        let x = self.dropout.forward(x);

        self.linear_outer.forward(x)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;We have a somewhat large amount of &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples"&gt;examples&lt;/a&gt; in the repository that shows how to use the framework in different scenarios.&lt;/p&gt; 
  &lt;p&gt;Following &lt;a href="https://burn.dev/books/burn/"&gt;the book&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/guide"&gt;Basic Workflow&lt;/a&gt; : Creates a custom CNN &lt;code&gt;Module&lt;/code&gt; to train on the MNIST dataset and use for inference.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-training-loop"&gt;Custom Training Loop&lt;/a&gt; : Implements a basic training loop instead of using the &lt;code&gt;Learner&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-wgpu-kernel"&gt;Custom WGPU Kernel&lt;/a&gt; : Learn how to create your own custom operation with the WGPU backend.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;Additional examples:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-csv-dataset"&gt;Custom CSV Dataset&lt;/a&gt; : Implements a dataset to parse CSV data for a regression task.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/simple-regression"&gt;Regression&lt;/a&gt; : Trains a simple MLP on the California Housing dataset to predict the median house value for a district.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-image-dataset"&gt;Custom Image Dataset&lt;/a&gt; : Trains a simple CNN on custom image dataset following a simple folder structure.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-renderer"&gt;Custom Renderer&lt;/a&gt; : Implements a custom renderer to display the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/building-blocks/learner.md"&gt;&lt;code&gt;Learner&lt;/code&gt;&lt;/a&gt; progress.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification Web&lt;/a&gt; : Image classification web browser demo using Burn, WGPU and WebAssembly.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST Inference on Web&lt;/a&gt; : An interactive MNIST inference demo in the browser. The demo is available &lt;a href="https://burn.dev/demo/"&gt;online&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist"&gt;MNIST Training&lt;/a&gt; : Demonstrates how to train a custom &lt;code&gt;Module&lt;/code&gt; (MLP) with the &lt;code&gt;Learner&lt;/code&gt; configured to log metrics and keep training checkpoints.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/named-tensor"&gt;Named Tensor&lt;/a&gt; : Performs operations with the experimental &lt;code&gt;NamedTensor&lt;/code&gt; feature.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/onnx-inference"&gt;ONNX Import Inference&lt;/a&gt; : Imports an ONNX model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/import-model-weights"&gt;PyTorch Import Inference&lt;/a&gt; : Imports a PyTorch model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-classification"&gt;Text Classification&lt;/a&gt; : Trains a text classification transformer model on the AG News or DbPedia dataset. The trained model can then be used to classify a text sample.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-generation"&gt;Text Generation&lt;/a&gt; : Trains a text generation transformer model on the DbPedia dataset.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/wgan"&gt;Wasserstein GAN MNIST&lt;/a&gt; : Trains a WGAN model to generate new handwritten digits based on MNIST.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;For more practical insights, you can clone the repository and run any of them directly on your computer!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Pre-trained Models ü§ñ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;We keep an updated and curated list of models and examples built with Burn, see the &lt;a href="https://github.com/tracel-ai/models"&gt;tracel-ai/models repository&lt;/a&gt; for more details.&lt;/p&gt; 
  &lt;p&gt;Don't see the model you want? Don't hesitate to open an issue, and we may prioritize it. Built a model using Burn and want to share it? You can also open a Pull Request and add your model under the community section!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Why use Rust for Deep Learning? ü¶Ä &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Deep Learning is a special form of software where you need very high level abstractions as well as extremely fast execution time. Rust is the perfect candidate for that use case since it provides zero-cost abstractions to easily create neural network modules, and fine-grained control over memory to optimize every detail.&lt;/p&gt; 
  &lt;p&gt;It's important that a framework be easy to use at a high level so that its users can focus on innovating in the AI field. However, since running models relies so heavily on computations, performance can't be neglected.&lt;/p&gt; 
  &lt;p&gt;To this day, the mainstream solution to this problem has been to offer APIs in Python, but rely on bindings to low-level languages such as C/C++. This reduces portability, increases complexity and creates frictions between researchers and engineers. We feel like Rust's approach to abstractions makes it versatile enough to tackle this two languages dichotomy.&lt;/p&gt; 
  &lt;p&gt;Rust also comes with the Cargo package manager, which makes it incredibly easy to build, test, and deploy from any environment, which is usually a pain in Python.&lt;/p&gt; 
  &lt;p&gt;Although Rust has the reputation of being a difficult language at first, we strongly believe it leads to more reliable, bug-free solutions built faster (after some practice üòÖ)!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;Deprecation Note&lt;/strong&gt;&lt;br /&gt;Since &lt;code&gt;0.14.0&lt;/code&gt;, the internal structure for tensor data has changed. The previous &lt;code&gt;Data&lt;/code&gt; struct was deprecated and officially removed since &lt;code&gt;0.17.0&lt;/code&gt; in favor of the new &lt;code&gt;TensorData&lt;/code&gt; struct, which allows for more flexibility by storing the underlying data as bytes and keeping the data type as a field. If you are using &lt;code&gt;Data&lt;/code&gt; in your code, make sure to switch to &lt;code&gt;TensorData&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;!-- &gt;
&gt; In the event that you are trying to load a model record saved in a previous version, make sure to
&gt; enable the `record-backward-compat` feature using a previous version of burn (&lt;=0.16.0). Otherwise,
&gt; the record won't be deserialized correctly and you will get an error message (which will also point
&gt; you to the backward compatible feature flag). The backward compatibility was maintained for
&gt; deserialization (loading), so as soon as you have saved the record again it will be saved according
&gt; to the new structure and you will be able to upgrade to this version. Please note that binary formats
&gt; are not backward compatible. Thus, you will need to load your record in a previous version and save it
&gt; to another of the self-describing record formats before using a compatible version (as described) with the
&gt; `record-backward-compat` feature flag. --&gt; 
 &lt;details id="deprecation"&gt; 
  &lt;summary&gt; Loading Model Records From Previous Versions ‚ö†Ô∏è &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;In the event that you are trying to load a model record saved in a version older than &lt;code&gt;0.14.0&lt;/code&gt;, make sure to use a compatible version (&lt;code&gt;0.14&lt;/code&gt;, &lt;code&gt;0.15&lt;/code&gt; or &lt;code&gt;0.16&lt;/code&gt;) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
  &lt;pre&gt;&lt;code&gt;features = [..., "record-backward-compat"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Otherwise, the record won't be deserialized correctly and you will get an error message. This error will also point you to the backward compatible feature flag.&lt;/p&gt; 
  &lt;p&gt;The backward compatibility was maintained for deserialization when loading records. Therefore, as soon as you have saved the record again it will be saved according to the new structure and you can upgrade back to the current version&lt;/p&gt; 
  &lt;p&gt;Please note that binary formats are not backward compatible. Thus, you will need to load your record in a previous version and save it in any of the other self-describing record format (e.g., using the &lt;code&gt;NamedMpkFileRecorder&lt;/code&gt;) before using a compatible version (as described) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;h2&gt;Community&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-community.png" height="96px" /&gt; 
  &lt;p&gt;If you are excited about the project, don't hesitate to join our &lt;a href="https://discord.gg/uPEBbYYDB6"&gt;Discord&lt;/a&gt;! We try to be as welcoming as possible to everybody from any background. You can ask your questions and share what you built with the community!&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Before contributing, please take a moment to review our &lt;a href="https://github.com/tracel-ai/burn/tree/main/CODE-OF-CONDUCT.md"&gt;code of conduct&lt;/a&gt;. It's also highly recommended to read the &lt;a href="https://github.com/tracel-ai/burn/tree/main/contributor-book/src/project-architecture"&gt;architecture overview&lt;/a&gt;, which explains some of our architectural decisions. Refer to our &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;h2&gt;Status&lt;/h2&gt; 
 &lt;p&gt;Burn is currently in active development, and there will be breaking changes. While any resulting issues are likely to be easy to fix, there are no guarantees at this stage.&lt;/p&gt; 
 &lt;h2&gt;License&lt;/h2&gt; 
 &lt;p&gt;Burn is distributed under the terms of both the MIT license and the Apache License (Version 2.0). See &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; for details. Opening a pull request is assumed to signal agreement with these licensing terms.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>cocoindex-io/cocoindex</title>
      <link>https://github.com/cocoindex-io/cocoindex</link>
      <description>&lt;p&gt;Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/github.svg?sanitize=true" alt="CocoIndex" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Data transformation for AI&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;&lt;img src="https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;&lt;img src="https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;amp;logoColor=00B9FF" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/cocoindex/"&gt;&lt;img src="https://img.shields.io/pypi/v/cocoindex?color=5B5BD6" alt="PyPI version" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!--[![PyPI - Downloads](https://img.shields.io/pypi/dm/cocoindex)](https://pypistats.org/packages/cocoindex) --&gt; 
 &lt;p&gt;&lt;a href="https://pepy.tech/projects/cocoindex"&gt;&lt;img src="https://static.pepy.tech/badge/cocoindex/month" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;amp;color=5B5BD6" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml"&gt;&lt;img src="https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;amp;color=5B5BD6" alt="release" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/zpA9S2DR7s"&gt;&lt;img src="https://img.shields.io/discord/1314801574169673738?logo=discord&amp;amp;color=5B5BD6&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13939" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13939" alt="cocoindex-io%2Fcocoindex | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;Ultra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box. Exceptional developer velocity. Production-ready at day 0.&lt;/p&gt; 
&lt;p&gt;‚≠ê Drop a star to help us grow!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
 &lt;p&gt;&lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=en"&gt;English&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/transformation.svg?sanitize=true" alt="CocoIndex Transformation" /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;CocoIndex makes it effortless to transform data with AI, and keep source data and target in sync. Whether you‚Äôre building a vector index for RAG, creating knowledge graphs, or performing any custom data transformations ‚Äî goes beyond SQL.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;img alt="CocoIndex Features" src="https://cocoindex.io/images/venn2.svg?sanitize=true" /&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Exceptional velocity&lt;/h2&gt; 
&lt;p&gt;Just declare transformation in dataflow with ~100 lines of python&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# import
data['content'] = flow_builder.add_source(...)

# transform
data['out'] = data['content']
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;CocoIndex follows the idea of &lt;a href="https://en.wikipedia.org/wiki/Dataflow_programming"&gt;Dataflow&lt;/a&gt; programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Particularly&lt;/strong&gt;, developers don't explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.&lt;/p&gt; 
&lt;h2&gt;Plug-and-Play Building Blocks&lt;/h2&gt; 
&lt;p&gt;Native builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components - as easy as assembling building blocks.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://cocoindex.io/images/components.svg?sanitize=true" alt="CocoIndex Features" /&gt; &lt;/p&gt; 
&lt;h2&gt;Data Freshness&lt;/h2&gt; 
&lt;p&gt;CocoIndex keep source data and target in sync effortlessly.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6" alt="Incremental Processing" width="700" /&gt; &lt;/p&gt; 
&lt;p&gt;It has out-of-box support for incremental indexing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;minimal recomputation on source or logic change.&lt;/li&gt; 
 &lt;li&gt;(re-)processing necessary portions; reuse cache when possible&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;If you're new to CocoIndex, we recommend checking out&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìñ &lt;a href="https://cocoindex.io/docs"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ö° &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üé¨ &lt;a href="https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT"&gt;Quick Start Video Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install CocoIndex Python library&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U cocoindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://cocoindex.io/docs/getting_started/installation#-install-postgres"&gt;Install Postgres&lt;/a&gt; if you don't have one. CocoIndex uses it for incremental processing.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;(Optional) Install Claude Code skill for enhanced development experience. Run these commands in &lt;a href="https://claude.com/claude-code"&gt;Claude Code&lt;/a&gt;:&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;/plugin marketplace add cocoindex-io/cocoindex-claude
/plugin install cocoindex-skills@cocoindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Define data flow&lt;/h2&gt; 
&lt;p&gt;Follow &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quick Start Guide&lt;/a&gt; to define your first indexing flow. An example flow looks like:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@cocoindex.flow_def(name="TextEmbedding")
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope["documents"] = flow_builder.add_source(cocoindex.sources.LocalFile(path="markdown_files"))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope["documents"].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc["chunks"] = doc["content"].transform(
            cocoindex.functions.SplitRecursively(),
            language="markdown", chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc["chunks"].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk["embedding"] = chunk["text"].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model="sentence-transformers/all-MiniLM-L6-v2"))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc["filename"], location=chunk["location"],
                                   text=chunk["text"], embedding=chunk["embedding"])

    # Export collected data to a vector index.
    doc_embeddings.export(
        "doc_embeddings",
        cocoindex.targets.Postgres(),
        primary_key_fields=["filename", "location"],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name="embedding",
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It defines an index flow like this:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="400" alt="Data Flow" src="https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463" /&gt; &lt;/p&gt; 
&lt;h2&gt;üöÄ Examples and demo&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding"&gt;Text Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents with embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/code_embedding"&gt;Code Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index code embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/pdf_embedding"&gt;PDF Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Parse PDF and index text embeddings for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/pdf_elements_embedding"&gt;PDF Elements Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract text and images from PDFs; embed text with SentenceTransformers and images with CLIP; store in Qdrant for multimodal search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/manuals_llm_extraction"&gt;Manuals LLM Extraction&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured information from a manual using LLM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/amazon_s3_embedding"&gt;Amazon S3 Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Amazon S3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/azure_blob_embedding"&gt;Azure Blob Storage Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Azure Blob Storage&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/gdrive_text_embedding"&gt;Google Drive Text Embedding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index text documents from Google Drive&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/docs_to_knowledge_graph"&gt;Docs to Knowledge Graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract relationships from Markdown documents and build a knowledge graph&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding_qdrant"&gt;Embeddings to Qdrant&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index documents in a Qdrant collection for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/text_embedding_lancedb"&gt;Embeddings to LanceDB&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index documents in a LanceDB collection for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/fastapi_server_docker"&gt;FastAPI Server with Docker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Run the semantic search server in a Dockerized FastAPI setup&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/product_recommendation"&gt;Product Recommendation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Build real-time product recommendations with LLM and graph database&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/image_search"&gt;Image Search with Vision API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/face_recognition"&gt;Face Recognition&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Recognize faces in images and build embedding index&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/paper_metadata"&gt;Paper Metadata&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index papers in PDF files, and build metadata tables for each paper&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/multi_format_indexing"&gt;Multi Format Indexing&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Build visual document index from PDFs and images with ColPali for semantic search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/custom_source_hn"&gt;Custom Source HackerNews&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Index HackerNews threads and comments, using &lt;em&gt;CocoIndex Custom Source&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/custom_output_files"&gt;Custom Output Files&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Convert markdown files to HTML files and save them to a local directory, using &lt;em&gt;CocoIndex Custom Targets&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/patient_intake_extraction"&gt;Patient intake form extraction&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Use LLM to extract structured data from patient intake forms with different formats&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/hn_trending_topics"&gt;HackerNews Trending Topics&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract trending topics from HackerNews threads and comments, using &lt;em&gt;CocoIndex Custom Source&lt;/em&gt; and LLM&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/cocoindex-io/cocoindex/main/examples/patient_intake_extraction_baml"&gt;Patient Intake Form Extraction with BAML&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Extract structured data from patient intake forms using BAML&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More coming and stay tuned üëÄ!&lt;/p&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, visit &lt;a href="https://cocoindex.io/docs"&gt;CocoIndex Documentation&lt;/a&gt;, including a &lt;a href="https://cocoindex.io/docs/getting_started/quickstart"&gt;Quickstart guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We love contributions from our community ‚ù§Ô∏è. For details on contributing or running the project for development, check out our &lt;a href="https://cocoindex.io/docs/about/contributing"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üë• Community&lt;/h2&gt; 
&lt;p&gt;Welcome with a huge coconut hug ü••‚ãÜÔΩ°Àöü§ó. We are super excited for community contributions of all kinds - whether it's code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.&lt;/p&gt; 
&lt;p&gt;Join our community here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üåü &lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;Star us on GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üëã &lt;a href="https://discord.com/invite/zpA9S2DR7s"&gt;Join our Discord community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚ñ∂Ô∏è &lt;a href="https://www.youtube.com/@cocoindex-io"&gt;Subscribe to our YouTube channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìú &lt;a href="https://cocoindex.io/blogs/"&gt;Read our blog posts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support us&lt;/h2&gt; 
&lt;p&gt;We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ‚≠ê at GitHub repo &lt;a href="https://github.com/cocoindex-io/cocoindex"&gt;&lt;img src="https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6" alt="GitHub" /&gt;&lt;/a&gt; to stay tuned and help us grow.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;CocoIndex is Apache 2.0 licensed.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>openai/codex</title>
      <link>https://github.com/openai/codex</link>
      <description>&lt;p&gt;Lightweight coding agent that runs in your terminal&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install --cask codex&lt;/code&gt;&lt;/p&gt; 
&lt;p align="center"&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer. &lt;br /&gt; &lt;br /&gt;If you want Codex in your code editor (VS Code, Cursor, Windsurf), &lt;a href="https://developers.openai.com/codex/ide"&gt;install in your IDE&lt;/a&gt; &lt;br /&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, go to &lt;a href="https://chatgpt.com/codex"&gt;chatgpt.com/codex&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-splash.png" alt="Codex CLI splash" width="80%" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Installing and running Codex CLI&lt;/h3&gt; 
&lt;p&gt;Install globally with your preferred package manager. If you use npm:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install -g @openai/codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, if you use Homebrew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install --cask codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then simply run &lt;code&gt;codex&lt;/code&gt; to get started:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;codex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're running into upgrade issues with Homebrew, see the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/faq.md#brew-upgrade-codex-isnt-upgrading-me"&gt;FAQ entry on brew upgrade codex&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;You can also go to the &lt;a href="https://github.com/openai/codex/releases/latest"&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt; 
 &lt;p&gt;Each GitHub Release contains many executables, but in practice, you likely want one of these:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;macOS 
   &lt;ul&gt; 
    &lt;li&gt;Apple Silicon/arm64: &lt;code&gt;codex-aarch64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;x86_64 (older Mac hardware): &lt;code&gt;codex-x86_64-apple-darwin.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Linux 
   &lt;ul&gt; 
    &lt;li&gt;x86_64: &lt;code&gt;codex-x86_64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
    &lt;li&gt;arm64: &lt;code&gt;codex-aarch64-unknown-linux-musl.tar.gz&lt;/code&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Each archive contains a single entry with the platform baked into the name (e.g., &lt;code&gt;codex-x86_64-unknown-linux-musl&lt;/code&gt;), so you likely want to rename it to &lt;code&gt;codex&lt;/code&gt; after extracting it.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Using Codex with your ChatGPT plan&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/openai/codex/main/.github/codex-cli-login.png" alt="Codex CLI login" width="80%" /&gt; &lt;/p&gt; 
&lt;p&gt;Run &lt;code&gt;codex&lt;/code&gt; and select &lt;strong&gt;Sign in with ChatGPT&lt;/strong&gt;. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. &lt;a href="https://help.openai.com/en/articles/11369540-codex-in-chatgpt"&gt;Learn more about what's included in your ChatGPT plan&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also use Codex with an API key, but this requires &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key"&gt;additional setup&lt;/a&gt;. If you previously used an API key for usage-based billing, see the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#migrating-from-usage-based-billing-api-key"&gt;migration steps&lt;/a&gt;. If you're having trouble with login, please comment on &lt;a href="https://github.com/openai/codex/issues/1243"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Model Context Protocol (MCP)&lt;/h3&gt; 
&lt;p&gt;Codex can access MCP servers. To configure them, refer to the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md#mcp_servers"&gt;config docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;Codex CLI supports a rich set of configuration options, with preferences stored in &lt;code&gt;~/.codex/config.toml&lt;/code&gt;. For full configuration options, see &lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Docs &amp;amp; FAQ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md"&gt;&lt;strong&gt;Getting started&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#cli-usage"&gt;CLI usage&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/slash_commands.md"&gt;Slash Commands&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#running-with-a-prompt-as-input"&gt;Running with a prompt as input&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#example-prompts"&gt;Example prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/prompts.md"&gt;Custom prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/getting-started.md#memory-with-agentsmd"&gt;Memory with AGENTS.md&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/config.md"&gt;&lt;strong&gt;Configuration&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/example-config.md"&gt;Example config&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/sandbox.md"&gt;&lt;strong&gt;Sandbox &amp;amp; approvals&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md"&gt;&lt;strong&gt;Authentication&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#forcing-a-specific-auth-method-advanced"&gt;Auth methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/authentication.md#connecting-on-a-headless-machine"&gt;Login on a "Headless" machine&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automating Codex&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/openai/codex-action"&gt;GitHub Action&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/sdk/typescript/README.md"&gt;TypeScript SDK&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/exec.md"&gt;Non-interactive mode (&lt;code&gt;codex exec&lt;/code&gt;)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md"&gt;&lt;strong&gt;Advanced&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#tracing--verbose-logging"&gt;Tracing / verbose logging&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/advanced.md#model-context-protocol-mcp"&gt;Model Context Protocol (MCP)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/zdr.md"&gt;&lt;strong&gt;Zero data retention (ZDR)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/contributing.md"&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md"&gt;&lt;strong&gt;Install &amp;amp; build&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#system-requirements"&gt;System Requirements&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#dotslash"&gt;DotSlash&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/install.md#build-from-source"&gt;Build from source&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/faq.md"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/openai/codex/main/docs/open-source-fund.md"&gt;&lt;strong&gt;Open source fund&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/openai/codex/main/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dfinity/ic</title>
      <link>https://github.com/dfinity/ic</link>
      <description>&lt;p&gt;Internet Computer blockchain source: the client/replica software run by nodes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Internet Computer Protocol (ICP)&lt;/h1&gt; 
&lt;div id="preamble"&gt; 
 &lt;div class="sectionbody"&gt; 
  &lt;div class="paragraph"&gt; 
   &lt;p&gt;The Internet Computer is the world‚Äôs first blockchain that runs at web speed and can increase its capacity without bound. Like the Internet (which is composed of many machines adhering to TCP/IP protocol) and blockchain protocols (such as Bitcoin and Ethereum).&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;div id="toc" class="toc"&gt; 
   &lt;div id="toctitle" class="title"&gt;&lt;/div&gt; 
   &lt;ul class="sectlevel1"&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_resources_on_the_internet_computer"&gt;Resources on the Internet Computer&lt;/a&gt; 
     &lt;ul class="sectlevel2"&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_rd_documentation"&gt;R&amp;amp;D documentation&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_icp_dashboard"&gt;ICP Dashboard&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_the_community"&gt;The community&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_rust_implementation_of_the_icp"&gt;Rust implementation of the ICP&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_dfinity_foundation"&gt;DFINITY Foundation&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_getting_started"&gt;Getting Started&lt;/a&gt; 
     &lt;ul class="sectlevel2"&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_who_should_be_using_this_code"&gt;Who should be using this code&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_building_the_code"&gt;Building the code&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_verifying_releases"&gt;Verifying Releases&lt;/a&gt; 
     &lt;ul class="sectlevel2"&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_quick_start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_component_specific_verification"&gt;Component-Specific Verification&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_contributing"&gt;Contributing&lt;/a&gt; 
     &lt;ul class="sectlevel2"&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_the_network_nervous_system"&gt;The Network Nervous System&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_open_source_policy"&gt;Open Source Policy&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/#_rust_dependency_policy"&gt;Rust Dependency Policy&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div class="sect1"&gt; 
 &lt;h2 id="_resources_on_the_internet_computer"&gt;Resources on the Internet Computer&lt;/h2&gt; 
 &lt;div class="sectionbody"&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_rd_documentation"&gt;R&amp;amp;D documentation&lt;/h3&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;You can learn more about the Internet Computer‚Äôs Protocol, features, and designs here, here are some helpful resources:&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;Protocol Documentation:&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="ulist"&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/dfinity/a-technical-overview-of-the-internet-computer-f57c62abc20f"&gt;A Technical Overview of the Internet Computer (blog post)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/dfinity/software-canisters-an-evolution-of-smart-contracts-internet-computer-f1f92f1bfffb"&gt;Canisters, an Evolution of Smart Contracts&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/dfinity/applied-crypto-one-public-key-for-the-internet-computer-ni-dkg-4af800db869d"&gt;Noninteractive Distributed Key Generation&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/dfinity/the-internet-computers-token-economics-an-overview-29e238bd1d83"&gt;The Internet Computer‚Äôs Token Economics: An Overview&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/dfinity/understanding-the-internet-computers-network-nervous-system-neurons-and-icp-utility-tokens-730dab65cae8"&gt;Understanding the Internet Computer‚Äôs Network Nervous System, Neurons, and ICP Utility Tokens&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/dfinity/nns-proposals"&gt;List of NNS Proposals&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/dfinity/achieving-consensus-on-the-internet-computer-ee9fbfbafcbc"&gt;Consensus protocol&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;Engineering&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="ulist"&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://sdk.dfinity.org/docs/developers-guide/concepts/what-is-ic"&gt;What is the Internet Computer?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://sdk.dfinity.org/docs/quickstart/quickstart-intro.html"&gt;Tutorials, SDKs, and sample apps to get started&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://docs.dfinity.org/"&gt;Rust Cargo docs for the replica&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_icp_dashboard"&gt;ICP Dashboard&lt;/h3&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;You can observe the state of the Internet Computer‚Äôs infrastructure (Nodes, data centers, subnets) and traditional blockchain metrics (blocks/second, Token Supply, etc)&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="ulist"&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://dashboard.internetcomputer.org" class="bare"&gt;https://dashboard.internetcomputer.org&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_the_community"&gt;The community&lt;/h3&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;To interact with the community, check out the developer forum: &lt;a href="https://forum.dfinity.org/" class="bare"&gt;https://forum.dfinity.org/&lt;/a&gt;&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_rust_implementation_of_the_icp"&gt;Rust implementation of the ICP&lt;/h3&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;This repo contains many different pieces (including testing and other infrastructure components), but the most important one is the source code for the Rust implementation of the "&lt;strong&gt;replica&lt;/strong&gt;" (read: "client" in some blockchains) that is compiled and run by the machines that together make up the Internet Computer.&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_dfinity_foundation"&gt;DFINITY Foundation&lt;/h3&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;The &lt;a href="https://dfinity.org/"&gt;DFINITY Foundation&lt;/a&gt; is a Swiss not-for-profit organization based in Zurich, Switzerland, which oversees research centers in Palo Alto, San Francisco, and Zurich. Its goal is to further the design, development, and adoption of the Internet Computer Protocol.&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div class="sect1"&gt; 
 &lt;h2 id="_getting_started"&gt;Getting Started&lt;/h2&gt; 
 &lt;div class="sectionbody"&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_who_should_be_using_this_code"&gt;Who should be using this code&lt;/h3&gt; 
   &lt;div class="ulist"&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;If you are an app developer&lt;/strong&gt;, and your intent is to build apps so you want a local Internet Computer replica in your machine to deploy to, you are better off using the &lt;a href="https://sdk.dfinity.org/docs/quickstart/quickstart-intro.html"&gt;Canister SDK&lt;/a&gt; written by the DFINITY Foundation. It is optimized for this and much more lightweight (less than 2 minutes to get started). It will build and run a local replica and you do not need to get into systems code to run it.&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;If you are a blockchain enthusiast&lt;/strong&gt;, and your intent is to understand the protocol (not an implementation), you may be better off going to the &lt;a href="https://medium.com/dfinity/achieving-consensus-on-the-internet-computer-ee9fbfbafcbc"&gt;Consensus protocol&lt;/a&gt; and &lt;a href="https://sdk.dfinity.org/docs/interface-spec/index.html"&gt;IC Interface Specification&lt;/a&gt;. This content (by the DFINITY research team) is tailor made for understanding the protocol and design.&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;If you are a blockchain miner&lt;/strong&gt;, you should know that the Internet Computer Protocol (while it is a blockchain) does not have the traditional mining or validating you may come to expect from blockchain projects. The Internet Computer Protocol is designed using new and novel cryptography that does not require "mining"‚Ä¶‚Äã but it does require independent node providers, which may include yourself. You can of course check out the source code in this repo, but a better resource may be this: &lt;a href="https://wiki.internetcomputer.org/wiki/Internet_Computer_wiki#For_Node_Providers"&gt;Internet Computer Wiki - For Node Providers&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;If you are an engineer looking to build a new SDK, oracle, wallet or any part that enables and improves the Internet Computer ecosystem&lt;/strong&gt;, you should take a look at the &lt;a href="https://sdk.dfinity.org/docs/interface-spec/index.html"&gt;Interface Specification&lt;/a&gt; which is for low-level interaction with the Internet Computer.&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;strong&gt;If you are a systems engineer, security engineer or cryptographer&lt;/strong&gt;, and your intent is to see what is going on under the hood by digging through source and building this locally, &lt;strong&gt;&lt;em&gt;then you are in the right place&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div class="sect1"&gt; 
 &lt;h2 id="_building_the_code"&gt;Building the code&lt;/h2&gt; 
 &lt;div class="sectionbody"&gt; 
  &lt;div class="paragraph"&gt; 
   &lt;p&gt;&lt;strong&gt;System requirements&lt;/strong&gt;&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;div class="ulist"&gt; 
   &lt;ul&gt; 
    &lt;li&gt; &lt;p&gt;x86-64 based system (minimum: 16 GB MEM/SWAP, 100 GB available disk space)&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;Ubuntu 22.04 or newer&lt;/p&gt; &lt;/li&gt; 
    &lt;li&gt; &lt;p&gt;&lt;a href="https://podman.io/getting-started/installation"&gt;Podman&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;/ul&gt; 
  &lt;/div&gt; 
  &lt;div class="paragraph"&gt; 
   &lt;p&gt;For detailed information on building IC-OS images, please refer to the &lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/ic-os/README.adoc"&gt;IC-OS README&lt;/a&gt;&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;div class="paragraph"&gt; 
   &lt;p&gt;Alternatively, to build all IC-OS images using a simple, containerized environment, run:&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;div class="literalblock"&gt; 
   &lt;div class="content"&gt; 
    &lt;pre&gt;$ ./ci/container/build-ic.sh -i&lt;/pre&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div class="paragraph"&gt; 
   &lt;p&gt;To build only the binaries and canisters, use the &lt;code&gt;-b&lt;/code&gt; and/or &lt;code&gt;-c&lt;/code&gt; flags:&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;div class="literalblock"&gt; 
   &lt;div class="content"&gt; 
    &lt;pre&gt;$ ./ci/container/build-ic.sh -b -c&lt;/pre&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div class="paragraph"&gt; 
   &lt;p&gt;All built artifacts will be located in the top-level artifacts/ directory.&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div class="sect1"&gt; 
 &lt;h2 id="_verifying_releases"&gt;Verifying Releases&lt;/h2&gt; 
 &lt;div class="sectionbody"&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_overview"&gt;Overview&lt;/h3&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;The Internet Computer provides a robust system for verifying the build reproducibility of IC-OS update images. Each &lt;a href="https://dashboard.internetcomputer.org/releases"&gt;release proposal&lt;/a&gt; includes detailed verification instructions.&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_prerequisites"&gt;Prerequisites&lt;/h3&gt; 
   &lt;div class="ulist"&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;Ubuntu 22.04 or higher&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;Python 3.x&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;curl (&lt;code&gt;sudo apt install curl&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;About 100 GB of free disk space in &lt;code&gt;$HOME&lt;/code&gt; (or another volume, specifed via option &lt;code&gt;--cache-dir&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_quick_start"&gt;Quick Start&lt;/h3&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;To verify an IC OS Version Election proposal:&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="admonitionblock important"&gt; 
    &lt;table&gt; 
     &lt;tbody&gt;
      &lt;tr&gt; 
       &lt;td class="icon"&gt; 
        &lt;div class="title"&gt;
         Important
        &lt;/div&gt; &lt;/td&gt; 
       &lt;td class="content"&gt; Always use versioned repro-check URLs (replace &lt;code&gt;{COMMIT_ID}&lt;/code&gt; with the actual commit hash) instead of &lt;code&gt;master&lt;/code&gt; to ensure compatibility between the repro-check script and the build system for that specific commit. &lt;/td&gt; 
      &lt;/tr&gt; 
     &lt;/tbody&gt;
    &lt;/table&gt; 
   &lt;/div&gt; 
   &lt;div class="listingblock"&gt; 
    &lt;div class="content"&gt; 
     &lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;# Verify by proposal number
curl -fsSL https://raw.githubusercontent.com/dfinity/ic/{COMMIT_ID}/ci/scripts/repro-check |     python3 - -p &amp;lt;proposal_number&amp;gt;

# Verify by git commit
curl -fsSL https://raw.githubusercontent.com/dfinity/ic/{COMMIT_ID}/ci/scripts/repro-check |     python3 - -c {COMMIT_ID}&lt;/code&gt;&lt;/pre&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_component_specific_verification"&gt;Component-Specific Verification&lt;/h3&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;You can verify specific components individually:&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="listingblock"&gt; 
    &lt;div class="content"&gt; 
     &lt;pre class="highlight"&gt;&lt;code class="language-bash" data-lang="bash"&gt;# Verify GuestOS only
curl -fsSL https://raw.githubusercontent.com/dfinity/ic/{COMMIT_ID}/ci/scripts/repro-check |     python3 - -c {COMMIT_ID} --guestos

# Verify HostOS only
curl -fsSL https://raw.githubusercontent.com/dfinity/ic/{COMMIT_ID}/ci/scripts/repro-check |     python3 - -c {COMMIT_ID} --hostos

# Verify SetupOS only
curl -fsSL https://raw.githubusercontent.com/dfinity/ic/{COMMIT_ID}/ci/scripts/repro-check |     python3 - -c {COMMIT_ID} --setupos&lt;/code&gt;&lt;/pre&gt; 
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div class="sect1"&gt; 
 &lt;h2 id="_contributing"&gt;Contributing&lt;/h2&gt; 
 &lt;div class="sectionbody"&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_the_network_nervous_system"&gt;The Network Nervous System&lt;/h3&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;Thank you for taking the time to learn more about the Internet Computer Protocol. You can contribute to either, but it is important to note that the Internet Computer is governed by a decentralized system called the Network Nervous System (NNS). You can learn more here:&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="ulist"&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://medium.com/dfinity/understanding-the-internet-computers-network-nervous-system-neurons-and-icp-utility-tokens-730dab65cae8"&gt;Understanding the Internet Computer‚Äôs Network Nervous System, Neurons, and ICP Utility Tokens&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/dfinity/nns-proposals"&gt;List of NNS Proposals&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_open_source_policy"&gt;Open Source Policy&lt;/h3&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;The DFINITY Foundation makes the code of the Internet Computer available to the public.&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;This is important so that the community can review the code that defines the behaviour of the Internet Computer. Furthermore, the community will be able to build the code and verify that it derives from the same binary image that is referenced in upgrade proposals published via the Network Nervous System (NNS).&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;All code of the Internet Computer is be licensed under the Apache 2.0 license, except for a few components licensed under the &lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/licenses/IC-1.0.txt"&gt;Internet Computer Community Source License&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/dfinity/ic/master/licenses/IC-shared-1.0.txt"&gt;Internet Computer Shared Community Source License&lt;/a&gt; which are more restrictive than the Apache 2.0 license to protect the Intellectual Property (IP) of the DFINITY Foundation.&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;While we adapt our development processes and security reviews for a world of developing with our code in the open, we are not accepting any pull requests at this time. For now, please join our developer community at &lt;a href="https://forum.dfinity.org" class="bare"&gt;https://forum.dfinity.org&lt;/a&gt;. If you discover any bugs and vulnerabilities, please follow the procedure at &lt;a href="https://dfinity.org/vulnerability-disclosure-program/" class="bare"&gt;https://dfinity.org/vulnerability-disclosure-program/&lt;/a&gt;.&lt;/p&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div class="sect2"&gt; 
   &lt;h3 id="_rust_dependency_policy"&gt;Rust Dependency Policy&lt;/h3&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;To make the mono repository a success, there needs to be some basic rules to make development faster.&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="ulist"&gt; 
    &lt;ul&gt; 
     &lt;li&gt; &lt;p&gt;When adding a new external crate dependency please make sure it is necessary. Check that&lt;/p&gt; 
      &lt;div class="ulist"&gt; 
       &lt;ul&gt; 
        &lt;li&gt; &lt;p&gt;There isn‚Äôt another already imported crate with similar functionality.&lt;/p&gt; &lt;/li&gt; 
        &lt;li&gt; &lt;p&gt;The crate is well maintained and comes from reputable authors.&lt;/p&gt; &lt;/li&gt; 
       &lt;/ul&gt; 
      &lt;/div&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;When bumping the semantic version of an external crate, please do it for the whole repository. Avoid importing the same crate with multiple versions.&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;Keep the rust-lang up-to-date for Bazel and Cargo.&lt;/p&gt; &lt;/li&gt; 
     &lt;li&gt; &lt;p&gt;Use Cargo workspace for inferring external crate versions by adding the new crate to the section &lt;code&gt;[workspace.dependencies]&lt;/code&gt; of the workspace &lt;code&gt;Cargo.toml&lt;/code&gt; and adding &lt;code&gt;new-crate = { workspace = true }&lt;/code&gt; to each package-specific &lt;code&gt;Cargo.toml&lt;/code&gt; that needs it.&lt;/p&gt; &lt;/li&gt; 
    &lt;/ul&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>pola-rs/polars</title>
      <link>https://github.com/pola-rs/polars</link>
      <description>&lt;p&gt;Extremely fast Query Engine for DataFrames, written in Rust&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://pola.rs"&gt; &lt;img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/banner/polars_github_banner.svg?sanitize=true" alt="Polars logo" /&gt; &lt;/a&gt; &lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://crates.io/crates/polars"&gt; &lt;img src="https://img.shields.io/crates/v/polars.svg?sanitize=true" alt="crates.io Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://pypi.org/project/polars/"&gt; &lt;img src="https://img.shields.io/pypi/v/polars.svg?sanitize=true" alt="PyPi Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://www.npmjs.com/package/nodejs-polars"&gt; &lt;img src="https://img.shields.io/npm/v/nodejs-polars.svg?sanitize=true" alt="NPM Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://community.r-multiverse.org/polars"&gt; &lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fcommunity.r-multiverse.org%2Fapi%2Fpackages%2Fpolars&amp;amp;query=%24.Version&amp;amp;label=r-multiverse" alt="R-multiverse Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://doi.org/10.5281/zenodo.7697217"&gt; &lt;img src="https://zenodo.org/badge/DOI/10.5281/zenodo.7697217.svg?sanitize=true" alt="DOI Latest Release" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;b&gt;Documentation&lt;/b&gt;: &lt;a href="https://docs.pola.rs/api/python/stable/reference/index.html"&gt;Python&lt;/a&gt; - &lt;a href="https://docs.rs/polars/latest/polars/"&gt;Rust&lt;/a&gt; - &lt;a href="https://pola-rs.github.io/nodejs-polars/index.html"&gt;Node.js&lt;/a&gt; - &lt;a href="https://pola-rs.github.io/r-polars/index.html"&gt;R&lt;/a&gt; | &lt;b&gt;StackOverflow&lt;/b&gt;: &lt;a href="https://stackoverflow.com/questions/tagged/python-polars"&gt;Python&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/rust-polars"&gt;Rust&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/nodejs-polars"&gt;Node.js&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/r-polars"&gt;R&lt;/a&gt; | &lt;a href="https://docs.pola.rs/"&gt;User guide&lt;/a&gt; | &lt;a href="https://discord.gg/4UfP5cfBE7"&gt;Discord&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Polars: Extremely fast Query Engine for DataFrames, written in Rust&lt;/h2&gt; 
&lt;p&gt;Polars is an analytical query engine written for DataFrames. It is designed to be fast, easy to use and expressive. Key features are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Lazy | Eager execution&lt;/li&gt; 
 &lt;li&gt;Streaming (larger-than-RAM datasets)&lt;/li&gt; 
 &lt;li&gt;Query optimization&lt;/li&gt; 
 &lt;li&gt;Multi-threaded&lt;/li&gt; 
 &lt;li&gt;Written in Rust&lt;/li&gt; 
 &lt;li&gt;SIMD&lt;/li&gt; 
 &lt;li&gt;Powerful expression API&lt;/li&gt; 
 &lt;li&gt;Front end in Python | Rust | NodeJS | R | SQL&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arrow.apache.org/docs/format/Columnar.html"&gt;Apache Arrow Columnar Format&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To learn more, read the &lt;a href="https://docs.pola.rs/"&gt;user guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Performance üöÄüöÄ&lt;/h2&gt; 
&lt;h3&gt;Blazingly fast&lt;/h3&gt; 
&lt;p&gt;Polars is very fast. In fact, it is one of the best performing solutions available. See the &lt;a href="https://www.pola.rs/benchmarks.html"&gt;PDS-H benchmarks&lt;/a&gt; results.&lt;/p&gt; 
&lt;h3&gt;Lightweight&lt;/h3&gt; 
&lt;p&gt;Polars is also very lightweight. It comes with zero required dependencies, and this shows in the import times:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;polars: 70ms&lt;/li&gt; 
 &lt;li&gt;numpy: 104ms&lt;/li&gt; 
 &lt;li&gt;pandas: 520ms&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Handles larger-than-RAM data&lt;/h3&gt; 
&lt;p&gt;If you have data that does not fit into memory, Polars' query engine is able to process your query (or parts of your query) in a streaming fashion. This drastically reduces memory requirements, so you might be able to process your 250GB dataset on your laptop. Collect with &lt;code&gt;collect(engine='streaming')&lt;/code&gt; to run the query streaming.&lt;/p&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;p&gt;Install the latest Polars version with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install polars
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.pola.rs/user-guide/installation/#feature-flags"&gt;User Guide&lt;/a&gt; for more details on optional dependencies&lt;/p&gt; 
&lt;p&gt;To see the current Polars version and a full list of its optional dependencies, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pl.show_versions()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Want to contribute? Read our &lt;a href="https://docs.pola.rs/development/contributing/"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Managed/Distributed Polars&lt;/h2&gt; 
&lt;p&gt;Do you want a managed solution or scale out to distributed clusters? Consider our &lt;a href="https://cloud.pola.rs/"&gt;offering&lt;/a&gt; and help the project!&lt;/p&gt; 
&lt;h2&gt;Python: compile Polars from source&lt;/h2&gt; 
&lt;p&gt;If you want a bleeding edge release or maximal performance you should compile Polars from source.&lt;/p&gt; 
&lt;p&gt;This can be done by going through the following steps in sequence:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the latest &lt;a href="https://www.rust-lang.org/tools/install"&gt;Rust compiler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://maturin.rs/"&gt;maturin&lt;/a&gt;: &lt;code&gt;pip install maturin&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cd py-polars&lt;/code&gt; and choose one of the following: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;make build&lt;/code&gt;, slow binary with debug assertions and symbols, fast compile times&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-release&lt;/code&gt;, fast binary without debug assertions, minimal debug symbols, long compile times&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-nodebug-release&lt;/code&gt;, same as build-release but without any debug symbols, slightly faster to compile&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-debug-release&lt;/code&gt;, same as build-release but with full debug symbols, slightly slower to compile&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-dist-release&lt;/code&gt;, fastest binary, extreme compile times&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;By default the binary is compiled with optimizations turned on for a modern CPU. Specify &lt;code&gt;LTS_CPU=1&lt;/code&gt; with the command if your CPU is older and does not support e.g. AVX2.&lt;/p&gt; 
&lt;p&gt;Note that the Rust crate implementing the Python bindings is called &lt;code&gt;py-polars&lt;/code&gt; to distinguish from the wrapped Rust crate &lt;code&gt;polars&lt;/code&gt; itself. However, both the Python package and the Python module are named &lt;code&gt;polars&lt;/code&gt;, so you can &lt;code&gt;pip install polars&lt;/code&gt; and &lt;code&gt;import polars&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Using custom Rust functions in Python&lt;/h2&gt; 
&lt;p&gt;Extending Polars with UDFs compiled in Rust is easy. We expose PyO3 extensions for &lt;code&gt;DataFrame&lt;/code&gt; and &lt;code&gt;Series&lt;/code&gt; data structures. See more in &lt;a href="https://github.com/pola-rs/polars/tree/main/pyo3-polars"&gt;https://github.com/pola-rs/polars/tree/main/pyo3-polars&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Going big...&lt;/h2&gt; 
&lt;p&gt;Do you expect more than 2^32 (~4.2 billion) rows? Compile Polars with the &lt;code&gt;bigidx&lt;/code&gt; feature flag or, for Python users, install &lt;code&gt;pip install polars[rt64]&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Don't use this unless you hit the row boundary as the default build of Polars is faster and consumes less memory.&lt;/p&gt; 
&lt;h2&gt;Legacy&lt;/h2&gt; 
&lt;p&gt;Do you want Polars to run on an old CPU (e.g. dating from before 2011), or on an &lt;code&gt;x86-64&lt;/code&gt; build of Python on Apple Silicon under Rosetta? Install &lt;code&gt;pip install polars[rtcompat]&lt;/code&gt;. This version of Polars is compiled without &lt;a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions"&gt;AVX&lt;/a&gt; target features.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>modelcontextprotocol/rust-sdk</title>
      <link>https://github.com/modelcontextprotocol/rust-sdk</link>
      <description>&lt;p&gt;The official Rust SDK for the Model Context Protocol&lt;/p&gt;&lt;hr&gt;&lt;div align="right"&gt; 
 &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/docs/readme/README.zh-cn.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá(ÂæÖÊõ¥Êñ∞)&lt;/a&gt; 
&lt;/div&gt; 
&lt;h1&gt;RMCP&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/rmcp"&gt;&lt;img src="https://img.shields.io/crates/v/rmcp" alt="Crates.io Version" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- ![Release status](https://github.com/modelcontextprotocol/rust-sdk/actions/workflows/release.yml/badge.svg) --&gt; 
&lt;!-- [![docs.rs](todo)](todo) --&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/docs/coverage.svg?sanitize=true" alt="Coverage" /&gt;&lt;/p&gt; 
&lt;p&gt;An official Rust Model Context Protocol SDK implementation with tokio async runtime.&lt;/p&gt; 
&lt;p&gt;This repository contains the following crates:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp"&gt;rmcp&lt;/a&gt;: The core crate providing the RMCP protocol implementation (If you want to get more information, please visit &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp/README.md"&gt;rmcp&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp-macros"&gt;rmcp-macros&lt;/a&gt;: A procedural macro crate for generating RMCP tool implementations (If you want to get more information, please visit &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp-macros/README.md"&gt;rmcp-macros&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Import the crate&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;rmcp = { version = "0.8.0", features = ["server"] }
## or dev channel
rmcp = { git = "https://github.com/modelcontextprotocol/rust-sdk", branch = "main" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Third Dependencies&lt;/h3&gt; 
&lt;p&gt;Basic dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tokio-rs/tokio"&gt;tokio required&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/serde-rs/serde"&gt;serde required&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build a Client&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Start a client&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;use rmcp::{ServiceExt, transport::{TokioChildProcess, ConfigureCommandExt}};
use tokio::process::Command;

#[tokio::main]
async fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    let client = ().serve(TokioChildProcess::new(Command::new("npx").configure(|cmd| {
        cmd.arg("-y").arg("@modelcontextprotocol/server-everything");
    }))?).await?;
    Ok(())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;Build a Server&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;Build a transport&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;use tokio::io::{stdin, stdout};
let transport = (stdin(), stdout());
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Build a service&lt;/summary&gt; 
 &lt;p&gt;You can easily build a service by using &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp/src/handler/server.rs"&gt;&lt;code&gt;ServerHandler&lt;/code&gt;&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/crates/rmcp/src/handler/client.rs"&gt;&lt;code&gt;ClientHandler&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;let service = common::counter::Counter::new();
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Start the server&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;// this call will finish the initialization process
let server = service.serve(transport).await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Interact with the server&lt;/summary&gt; 
 &lt;p&gt;Once the server is initialized, you can send requests or notifications:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;// request
let roots = server.list_roots().await?;

// or send notification
server.notify_cancelled(...).await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Waiting for service shutdown&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-rust,"&gt;let quit_reason = server.waiting().await?;
// or cancel it
let quit_reason = server.cancel().await?;
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/examples/README.md"&gt;examples&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;OAuth Support&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/docs/OAUTH_SUPPORT.md"&gt;oauth_support&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Related Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://spec.modelcontextprotocol.io/specification/2024-11-05/"&gt;MCP Specification&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/modelcontextprotocol/specification/raw/main/schema/2024-11-05/schema.ts"&gt;Schema&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;h3&gt;Extending &lt;code&gt;rmcp&lt;/code&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/lx-industries/rmcp-actix-web"&gt;rmcp-actix-web&lt;/a&gt; - An &lt;code&gt;actix_web&lt;/code&gt; backend for &lt;code&gt;rmcp&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/lx-industries/rmcp-openapi"&gt;rmcp-openapi&lt;/a&gt; - Transform OpenAPI definition endpoints into MCP tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Built with &lt;code&gt;rmcp&lt;/code&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/tree/main/crates/mcp"&gt;rustfs-mcp&lt;/a&gt; - High-performance MCP server providing S3-compatible object storage operations for AI/LLM integration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jokemanfire/mcp-containerd"&gt;containerd-mcp-server&lt;/a&gt; - A containerd-based MCP server implementation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gitlab.com/lx-industries/rmcp-openapi/-/tree/main/crates/rmcp-openapi-server"&gt;rmcp-openapi-server&lt;/a&gt; - High-performance MCP server that exposes OpenAPI definition endpoints as MCP tools&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/linw1995/nvim-mcp"&gt;nvim-mcp&lt;/a&gt; - A MCP server to interact with Neovim&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mediar-ai/terminator"&gt;terminator&lt;/a&gt; - AI-powered desktop automation MCP server with cross-platform support and &amp;gt;95% success rate&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/stakpak/agent"&gt;stakpak-agent&lt;/a&gt; - Security-hardened terminal agent for DevOps with MCP over mTLS, streaming, secret tokenization, and async task management&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Tips for Contributors&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/docs/CONTRIBUTE.MD"&gt;docs/CONTRIBUTE.MD&lt;/a&gt; to get some tips for contributing.&lt;/p&gt; 
&lt;h3&gt;Using Dev Container&lt;/h3&gt; 
&lt;p&gt;If you want to use dev container, see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/rust-sdk/main/docs/DEVCONTAINER.md"&gt;docs/DEVCONTAINER.md&lt;/a&gt; for instructions on using Dev Container for development.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>asterinas/asterinas</title>
      <link>https://github.com/asterinas/asterinas</link>
      <description>&lt;p&gt;Asterinas is a secure, fast, and general-purpose OS kernel, written in Rust and providing Linux-compatible ABI.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/asterinas/asterinas/main/book/src/images/logo_en.svg?sanitize=true" alt="asterinas-logo" width="620" /&gt;&lt;br /&gt; A secure, fast, and general-purpose OS kernel written in Rust and compatible with Linux&lt;br /&gt; &lt;a href="https://github.com/asterinas/asterinas/actions/workflows/test_x86.yml"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/test_x86.yml/badge.svg?event=push" alt="Test x86-64" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/asterinas/asterinas/actions/workflows/test_riscv.yml"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/test_riscv.yml/badge.svg?event=push" alt="Test riscv64" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/asterinas/asterinas/actions/workflows/test_loongarch.yml"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/test_loongarch.yml/badge.svg?event=push" alt="Test loongarch64" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/asterinas/asterinas/actions/workflows/test_x86_tdx.yml"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/test_x86_tdx.yml/badge.svg?sanitize=true" alt="Test Intel TDX" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;a href="https://asterinas.github.io/benchmark/x86-64/"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/benchmark_x86.yml/badge.svg?sanitize=true" alt="Benchmark x86-64" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;a href="https://asterinas.github.io/benchmark/tdx/"&gt;&lt;img src="https://github.com/asterinas/asterinas/actions/workflows/benchmark_x86_tdx.yml/badge.svg?sanitize=true" alt="Benchmark Intel TDX" style="max-width: 100%;" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/asterinas/asterinas/main/README_CN.md"&gt;‰∏≠ÊñáÁâà&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/asterinas/asterinas/main/README_JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;News:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025-10-17: &lt;strong&gt;ICSE 2026&lt;/strong&gt; accepted yet another paper about Asterinas: &lt;em&gt;RusyFuzz: Unhandled Exception Guided Fuzzing for Rust OS Kernel&lt;/em&gt;.&lt;/li&gt; 
 &lt;li&gt;2025-10-14: &lt;a href="https://dl.acm.org/doi/10.1145/3731569.3764836"&gt;&lt;em&gt;CortenMM: Efficient Memory Management with Strong Correctness Guarantees&lt;/em&gt;&lt;/a&gt; received the &lt;strong&gt;Best Paper Award&lt;/strong&gt; at &lt;strong&gt;SOSP 2025&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;2025-07-23: &lt;strong&gt;SOSP 2025&lt;/strong&gt; accepted another Asterinas paper: &lt;a href="https://dl.acm.org/doi/10.1145/3731569.3764836"&gt;&lt;em&gt;CortenMM: Efficient Memory Management with Strong Correctness Guarantees&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;2025-06-18: &lt;strong&gt;USENIX &lt;em&gt;;login:&lt;/em&gt; magazine&lt;/strong&gt; published &lt;a href="https://www.usenix.org/publications/loginonline/asterinas-rust-based-framekernel-reimagine-linux-2020s"&gt;&lt;em&gt;Asterinas: A Rust-Based Framekernel to Reimagine Linux in the 2020s&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;2025-04-30: &lt;strong&gt;USENIX ATC 2025&lt;/strong&gt; accepted two Asterinas papers: 
  &lt;ol&gt; 
   &lt;li&gt;&lt;a href="https://www.usenix.org/conference/atc25/presentation/peng-yuke"&gt;&lt;em&gt;Asterinas: A Linux ABI-Compatible, Rust-Based Framekernel OS with a Small and Sound TCB&lt;/em&gt;&lt;/a&gt;;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.usenix.org/conference/atc25/presentation/tang"&gt;&lt;em&gt;Converos: Practical Model Checking for Verifying Rust OS Kernel Concurrency&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Congratulations to the Asterinas communityüéâüéâüéâ&lt;/p&gt; 
&lt;h2&gt;Introducing Asterinas&lt;/h2&gt; 
&lt;p&gt;Asterinas is a &lt;em&gt;secure&lt;/em&gt;, &lt;em&gt;fast&lt;/em&gt;, and &lt;em&gt;general-purpose&lt;/em&gt; OS kernel that provides &lt;em&gt;Linux-compatible&lt;/em&gt; ABI. It can serve as a seamless replacement for Linux while enhancing &lt;em&gt;memory safety&lt;/em&gt; and &lt;em&gt;developer friendliness&lt;/em&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Asterinas prioritizes memory safety by employing Rust as its sole programming language and limiting the use of &lt;em&gt;unsafe Rust&lt;/em&gt; to a clearly defined and minimal Trusted Computing Base (TCB). This innovative approach, known as &lt;a href="https://asterinas.github.io/book/kernel/the-framekernel-architecture.html"&gt;the framekernel architecture&lt;/a&gt;, establishes Asterinas as a more secure and dependable kernel option.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Asterinas surpasses Linux in terms of developer friendliness. It empowers kernel developers to (1) utilize the more productive Rust programming language, (2) leverage a purpose-built toolkit called &lt;a href="https://asterinas.github.io/book/osdk/guide/index.html"&gt;OSDK&lt;/a&gt; to streamline their workflows, and (3) choose between releasing their kernel modules as open source or keeping them proprietary, thanks to the flexibility offered by &lt;a href="https://raw.githubusercontent.com/asterinas/asterinas/main/#License"&gt;MPL&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;While the journey towards a production-grade OS kernel is challenging, we are steadfastly progressing towards this goal. Over the course of 2024, we significantly enhanced Asterinas's maturity, as detailed in &lt;a href="https://asterinas.github.io/2025/01/20/asterinas-in-2024.html"&gt;our end-year report&lt;/a&gt;. In 2025, our primary goal is to make Asterinas production-ready on x86-64 virtual machines and attract real users!&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Get yourself an x86-64 Linux machine with Docker installed. Follow the three simple steps below to get Asterinas up and running.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download the latest source code.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/asterinas/asterinas
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Run a Docker container as the development environment.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --privileged --network=host --device=/dev/kvm -v $(pwd)/asterinas:/root/asterinas asterinas/asterinas:0.16.1-20250922
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Inside the container, go to the project folder to build and run Asterinas.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make build
make run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If everything goes well, Asterinas is now up and running inside a VM.&lt;/p&gt; 
&lt;h2&gt;The Book&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://asterinas.github.io/book/"&gt;The Asterinas Book&lt;/a&gt; to learn more about the project.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Asterinas's source code and documentation primarily use the &lt;a href="https://github.com/asterinas/asterinas/raw/main/LICENSE-MPL"&gt;Mozilla Public License (MPL), Version 2.0&lt;/a&gt;. Select components are under more permissive licenses, detailed &lt;a href="https://github.com/asterinas/asterinas/raw/main/.licenserc.yaml"&gt;here&lt;/a&gt;. For the rationales behind the choice of MPL, see &lt;a href="https://asterinas.github.io/book/index.html#licensing"&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gopher64/gopher64</title>
      <link>https://github.com/gopher64/gopher64</link>
      <description>&lt;p&gt;Highly compatible N64 emulator&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;gopher64&lt;/h1&gt; 
&lt;h2&gt;download&lt;/h2&gt; 
&lt;p&gt;Windows: &lt;a href="https://github.com/gopher64/gopher64/releases/latest/download/gopher64-windows-x86_64.exe"&gt;https://github.com/gopher64/gopher64/releases/latest/download/gopher64-windows-x86_64.exe&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Linux: &lt;a href="https://flathub.org/apps/io.github.gopher64.gopher64"&gt;https://flathub.org/apps/io.github.gopher64.gopher64&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;wiki&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/gopher64/gopher64/wiki"&gt;https://github.com/gopher64/gopher64/wiki&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;discord&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/9RGXq8W8JQ"&gt;https://discord.gg/9RGXq8W8JQ&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;controls&lt;/h2&gt; 
&lt;p&gt;Keys are mapped according to &lt;a href="https://github.com/gopher64/gopher64/wiki/Default-Keyboard-Setup"&gt;these defaults&lt;/a&gt;. Xbox-style controllers also have a &lt;a href="https://github.com/gopher64/gopher64/wiki/Default-Gamepad-Setup"&gt;default mapping applied&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;netplay&lt;/h2&gt; 
&lt;p&gt;Gopher64 supports netplay (online play with others) via cloud hosted servers. You can also run the server (&lt;a href="https://github.com/gopher64/gopher64-netplay-server"&gt;https://github.com/gopher64/gopher64-netplay-server&lt;/a&gt;) yourself on a LAN.&lt;/p&gt; 
&lt;h2&gt;portable mode&lt;/h2&gt; 
&lt;p&gt;If you would like to keep all the game data in the same folder as the executable, you just need to create a file called "portable.txt" in the same directory as the executable.&lt;/p&gt; 
&lt;h2&gt;flatpak&lt;/h2&gt; 
&lt;p&gt;If you want to run the flatpak from the command line, you need to add the &lt;code&gt;--filesystem=host:ro&lt;/code&gt; option, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;flatpak run --filesystem=host:ro io.github.gopher64.gopher64 /path/to/rom.z64
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;building and usage&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Linux only: install the SDL3 dependencies: &lt;a href="https://wiki.libsdl.org/SDL3/README-linux#build-dependencies"&gt;https://wiki.libsdl.org/SDL3/README-linux#build-dependencies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install rust: &lt;a href="https://www.rust-lang.org/tools/install"&gt;https://www.rust-lang.org/tools/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;git clone --recursive https://github.com/gopher64/gopher64.git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cd gopher64&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cargo build --release&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;./target/release/gopher64 /path/to/rom.z64&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;contributing&lt;/h2&gt; 
&lt;p&gt;I am very open to contributions! Please contact me via a GitHub issue or Discord (loganmc10) before doing substantial work on a PR.&lt;/p&gt; 
&lt;h2&gt;license&lt;/h2&gt; 
&lt;p&gt;Gopher64 is licensed under the GPLv3 license. Many portions of gopher64 have been adapted from mupen64plus and/or ares. The license for mupen64plus can be found here: &lt;a href="https://github.com/mupen64plus/mupen64plus-core/raw/master/LICENSES"&gt;https://github.com/mupen64plus/mupen64plus-core/blob/master/LICENSES&lt;/a&gt;. The license for ares can be found here: &lt;a href="https://github.com/ares-emulator/ares/raw/master/LICENSE"&gt;https://github.com/ares-emulator/ares/blob/master/LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;privacy and code signing policy&lt;/h2&gt; 
&lt;p&gt;Free code signing for the Windows release is provided by &lt;a href="https://about.signpath.io"&gt;SignPath.io&lt;/a&gt;, certificate by &lt;a href="https://signpath.org"&gt;SignPath Foundation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;During online netplay sessions, the server logs your IP address and basic session information (game title and session name) for operational purposes. No additional personal data is collected or stored.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rustdesk/rustdesk</title>
      <link>https://github.com/rustdesk/rustdesk</link>
      <description>&lt;p&gt;An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/rustdesk/rustdesk/master/res/logo-header.svg?sanitize=true" alt="RustDesk - Your remote desktop" /&gt;&lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#raw-steps-to-build"&gt;Build&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#how-to-build-with-docker"&gt;Docker&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#file-structure"&gt;Structure&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/#snapshot"&gt;Snapshot&lt;/a&gt;&lt;br /&gt; [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-UA.md"&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-CS.md"&gt;ƒçesky&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ZH.md"&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-HU.md"&gt;Magyar&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ES.md"&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FA.md"&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FR.md"&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DE.md"&gt;Deutsch&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PL.md"&gt;Polski&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ID.md"&gt;Indonesian&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-FI.md"&gt;Suomi&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-ML.md"&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-JP.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-NL.md"&gt;Nederlands&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-IT.md"&gt;Italiano&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-RU.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-PTBR.md"&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-EO.md"&gt;Esperanto&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-KR.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-AR.md"&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-VN.md"&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-DA.md"&gt;Dansk&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-GR.md"&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-TR.md"&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-NO.md"&gt;Norsk&lt;/a&gt;] | [&lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/README-RO.md"&gt;Rom√¢nƒÉ&lt;/a&gt;]&lt;br /&gt; &lt;b&gt;We need your help to translate this README, &lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/lang"&gt;RustDesk UI&lt;/a&gt; and &lt;a href="https://github.com/rustdesk/doc.rustdesk.com"&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Caution] &lt;strong&gt;Misuse Disclaimer:&lt;/strong&gt; &lt;br /&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Chat with us: &lt;a href="https://discord.gg/nDceKgxnkV"&gt;Discord&lt;/a&gt; | &lt;a href="https://twitter.com/rustdesk"&gt;Twitter&lt;/a&gt; | &lt;a href="https://www.reddit.com/r/rustdesk"&gt;Reddit&lt;/a&gt; | &lt;a href="https://www.youtube.com/@rustdesk"&gt;YouTube&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://rustdesk.com/pricing.html"&gt;&lt;img src="https://img.shields.io/badge/RustDesk%20Server%20Pro-Advanced%20Features-blue" alt="RustDesk Server Pro" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, &lt;a href="https://rustdesk.com/server"&gt;set up your own&lt;/a&gt;, or &lt;a href="https://github.com/rustdesk/rustdesk-server-demo"&gt;write your own rendezvous/relay server&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png" alt="image" /&gt;&lt;/p&gt; 
&lt;p&gt;RustDesk welcomes contribution from everyone. See &lt;a href="https://raw.githubusercontent.com/rustdesk/rustdesk/master/docs/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for help getting started.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/wiki/FAQ"&gt;&lt;strong&gt;FAQ&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/releases"&gt;&lt;strong&gt;BINARY DOWNLOAD&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rustdesk/rustdesk/releases/tag/nightly"&gt;&lt;strong&gt;NIGHTLY BUILD&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://f-droid.org/en/packages/com.carriez.flutter_hbb"&gt;&lt;img src="https://f-droid.org/badge/get-it-on.png" alt="Get it on F-Droid" height="80" /&gt;&lt;/a&gt; &lt;a href="https://flathub.org/apps/com.rustdesk.RustDesk"&gt;&lt;img src="https://flathub.org/api/badge?svg&amp;amp;locale=en" alt="Get it on Flathub" height="80" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;p&gt;Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our &lt;a href="https://github.com/rustdesk/rustdesk/raw/master/.github/workflows/flutter-build.yml"&gt;CI&lt;/a&gt; for building Flutter version.&lt;/p&gt; 
&lt;p&gt;Please download Sciter dynamic library yourself.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll"&gt;Windows&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so"&gt;Linux&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib"&gt;macOS&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Raw Steps to build&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Prepare your Rust development env and C++ build env&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;a href="https://github.com/microsoft/vcpkg"&gt;vcpkg&lt;/a&gt;, and set &lt;code&gt;VCPKG_ROOT&lt;/code&gt; env variable correctly&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static&lt;/li&gt; 
   &lt;li&gt;Linux/macOS: vcpkg install libvpx libyuv opus aom&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;run &lt;code&gt;cargo run&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://rustdesk.com/docs/en/dev/build/"&gt;Build&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;How to Build on Linux&lt;/h2&gt; 
&lt;h3&gt;Ubuntu 18 (Debian 10)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;openSUSE Tumbleweed&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fedora 28 (CentOS 8)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Arch (Manjaro)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install vcpkg&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Fix libvpx (For Fedora)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i 's/CFLAGS+=-I/CFLAGS+=-fPIC -I/g' Makefile
sed -i 's/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g' Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;How to build with Docker&lt;/h2&gt; 
&lt;p&gt;Begin by cloning the repository and building the Docker container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t "rustdesk-builder" .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, each time you need to build the application, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID="$(id -u)" -e PGID="$(id -g)" rustdesk-builder
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the &lt;code&gt;&amp;lt;OPTIONAL-ARGS&amp;gt;&lt;/code&gt; position. For instance, if you wanted to build an optimized release version, you would run the command above followed by &lt;code&gt;--release&lt;/code&gt;. The resulting executable will be available in the target folder on your system, and can be run with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;target/debug/rustdesk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, if you're running a release executable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;target/release/rustdesk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as &lt;code&gt;install&lt;/code&gt; or &lt;code&gt;run&lt;/code&gt; are not currently supported via this method as they would install or run the program inside the container instead of the host.&lt;/p&gt; 
&lt;h2&gt;File Structure&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common"&gt;libs/hbb_common&lt;/a&gt;&lt;/strong&gt;: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/scrap"&gt;libs/scrap&lt;/a&gt;&lt;/strong&gt;: screen capture&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/enigo"&gt;libs/enigo&lt;/a&gt;&lt;/strong&gt;: platform specific keyboard/mouse control&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard"&gt;libs/clipboard&lt;/a&gt;&lt;/strong&gt;: file copy and paste implementation for Windows, Linux, macOS.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/ui"&gt;src/ui&lt;/a&gt;&lt;/strong&gt;: obsolete Sciter UI (deprecated)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/server"&gt;src/server&lt;/a&gt;&lt;/strong&gt;: audio/clipboard/input/video services, and network connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/client.rs"&gt;src/client.rs&lt;/a&gt;&lt;/strong&gt;: start a peer connection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs"&gt;src/rendezvous_mediator.rs&lt;/a&gt;&lt;/strong&gt;: Communicate with &lt;a href="https://github.com/rustdesk/rustdesk-server"&gt;rustdesk-server&lt;/a&gt;, wait for remote direct (TCP hole punching) or relayed connection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/src/platform"&gt;src/platform&lt;/a&gt;&lt;/strong&gt;: platform specific code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/flutter"&gt;flutter&lt;/a&gt;&lt;/strong&gt;: Flutter code for desktop and mobile&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js"&gt;flutter/web/js&lt;/a&gt;&lt;/strong&gt;: JavaScript for Flutter web client&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651" alt="Connection Manager" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea" alt="Connected to a Windows PC" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad" alt="File Transfer" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5" alt="TCP Tunneling" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vercel/turborepo</title>
      <link>https://github.com/vercel/turborepo</link>
      <description>&lt;p&gt;Build system optimized for JavaScript¬†and TypeScript, written in Rust&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://turborepo.com"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://user-images.githubusercontent.com/4060187/196936123-f6e1db90-784d-4174-b774-92502b718836.png" /&gt; 
   &lt;img src="https://user-images.githubusercontent.com/4060187/196936104-5797972c-ab10-4834-bd61-0d1e5f442c9c.png" height="128" /&gt; 
  &lt;/picture&gt; &lt;/a&gt;&lt;/p&gt;
&lt;h1 align="center"&gt;&lt;a href="https://turborepo.com"&gt;Turborepo&lt;/a&gt;&lt;/h1&gt;
&lt;a href="https://turborepo.com"&gt; &lt;/a&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a aria-label="Vercel logo" href="https://vercel.com/"&gt;&lt;img src="https://img.shields.io/badge/MADE%20BY%20Vercel-000000.svg?style=for-the-badge&amp;amp;logo=Vercel&amp;amp;labelColor=000" /&gt;&lt;/a&gt; &lt;a aria-label="NPM version" href="https://www.npmjs.com/package/turbo"&gt;&lt;img alt="" src="https://img.shields.io/npm/v/turbo.svg?style=for-the-badge&amp;amp;labelColor=000000" /&gt;&lt;/a&gt; &lt;a aria-label="License" href="https://github.com/vercel/turborepo/raw/main/LICENSE"&gt;&lt;img alt="" src="https://img.shields.io/npm/l/turbo.svg?style=for-the-badge&amp;amp;labelColor=000000&amp;amp;color=" /&gt;&lt;/a&gt; &lt;a aria-label="Join the community on GitHub" href="https://github.com/vercel/turborepo/discussions"&gt;&lt;img alt="" src="https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&amp;amp;logo=turborepo&amp;amp;labelColor=000000&amp;amp;logoWidth=20&amp;amp;logoColor=white" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Turborepo is a high-performance build system for JavaScript and TypeScript codebases, written in Rust.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Visit &lt;a href="https://turborepo.com"&gt;https://turborepo.com&lt;/a&gt; to get started with Turborepo.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/vercel/turborepo/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The Turborepo community can be found on &lt;a href="https://github.com/vercel/turborepo/discussions"&gt;GitHub Discussions&lt;/a&gt;, where you can ask questions, voice ideas, and share your projects.&lt;/p&gt; 
&lt;p&gt;To chat with other community members, you can join &lt;a href="https://vercel.community/tag/turborepo"&gt;Vercel Community's &lt;code&gt;#turborepo&lt;/code&gt; tag&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Our &lt;a href="https://github.com/vercel/turborepo/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; applies to all Turborepo community channels.&lt;/p&gt; 
&lt;h2&gt;Who is using Turborepo?&lt;/h2&gt; 
&lt;p&gt;Turborepo is used by the world's leading companies. Check out the &lt;a href="https://turborepo.com/showcase"&gt;Turborepo Showcase&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;p&gt;Follow &lt;a href="https://x.com/turborepo"&gt;@turborepo&lt;/a&gt; on X for project updates.&lt;/p&gt; 
&lt;h2&gt;Authors&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Turborepo&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jared Palmer (&lt;a href="https://x.com/jaredpalmer"&gt;@jaredpalmer&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you believe you have found a security vulnerability in Turborepo, we encourage you to responsibly disclose this and not open a public issue. We will investigate all legitimate reports. Email &lt;code&gt;security@vercel.com&lt;/code&gt; to disclose any security vulnerabilities.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://vercel.com/security"&gt;https://vercel.com/security&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lusingander/serie</title>
      <link>https://github.com/lusingander/serie</link>
      <description>&lt;p&gt;A rich git commit graph in your terminal, like magic üìö&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Serie&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/serie"&gt;&lt;img src="https://img.shields.io/crates/v/serie.svg?sanitize=true" alt="Crate Status" /&gt;&lt;/a&gt; &lt;a href="https://ratatui.rs"&gt;&lt;img src="https://img.shields.io/badge/Built_With-Ratatui-000?logo=ratatui&amp;amp;logoColor=fff&amp;amp;labelColor=000&amp;amp;color=fff" alt="Built With Ratatui" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A rich git commit graph in your terminal, like magic üìö&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/demo.gif" /&gt; 
&lt;p&gt;(This demo shows &lt;a href="https://github.com/ratatui/ratatui"&gt;Ratatui&lt;/a&gt; repository!)&lt;/p&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;Serie (&lt;code&gt;/z√©Àêri…ô/&lt;/code&gt;) is a TUI application that uses the terminal emulators' image display protocol to render commit graphs like &lt;code&gt;git log --graph --all&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Why?&lt;/h3&gt; 
&lt;p&gt;While some users prefer to use Git via CLI, they often rely on a GUI or feature-rich TUI to view commit logs. Others may find &lt;code&gt;git log --graph&lt;/code&gt; sufficient.&lt;/p&gt; 
&lt;p&gt;Personally, I found the output from &lt;code&gt;git log --graph&lt;/code&gt; difficult to read, even with additional options. Learning complex tools just to view logs seemed cumbersome.&lt;/p&gt; 
&lt;h3&gt;Goals&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Provide a rich &lt;code&gt;git log --graph&lt;/code&gt; experience in the terminal.&lt;/li&gt; 
 &lt;li&gt;Offer commit graph-centric browsing of Git repositories.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Non-Goals&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Implement a fully-featured Git client.&lt;/li&gt; 
 &lt;li&gt;Create a TUI application with a complex UI.&lt;/li&gt; 
 &lt;li&gt;Works in any terminal environment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Git&lt;/li&gt; 
 &lt;li&gt;Supported terminal emulator 
  &lt;ul&gt; 
   &lt;li&gt;Refer to &lt;a href="https://raw.githubusercontent.com/lusingander/serie/master/#compatibility"&gt;Compatibility&lt;/a&gt; for details.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://crates.io/crates/serie"&gt;Cargo&lt;/a&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ cargo install --locked serie
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;a href="https://archlinux.org/packages/extra/x86_64/serie/"&gt;Arch Linux&lt;/a&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ pacman -S serie
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;a href="https://formulae.brew.sh/formula/serie"&gt;Homebrew&lt;/a&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ brew install serie
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or from &lt;a href="https://github.com/lusingander/homebrew-tap/raw/master/serie.rb"&gt;tap&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ brew install lusingander/tap/serie
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;a href="https://pkgsrc.se/devel/serie"&gt;NetBSD&lt;/a&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;$ pkgin install serie
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Downloading binary&lt;/h3&gt; 
&lt;p&gt;You can download pre-compiled binaries from &lt;a href="https://github.com/lusingander/serie/releases"&gt;releases&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Build from source&lt;/h3&gt; 
&lt;p&gt;If you want to check the latest development version, build from source:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/lusingander/serie.git
$ cd serie
$ cargo build --release # Unless it's a release build, it's very slow.
$ ./target/release/serie
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;serie&lt;/code&gt; in the directory where your git repository exists.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ cd &amp;lt;your git repository&amp;gt;
$ serie
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Options&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Serie - A rich git commit graph in your terminal, like magic üìö

Usage: serie [OPTIONS]

Options:
  -p, --protocol &amp;lt;TYPE&amp;gt;     Image protocol to render graph [default: auto] [possible values: auto, iterm, kitty]
  -o, --order &amp;lt;TYPE&amp;gt;        Commit ordering algorithm [default: chrono] [possible values: chrono, topo]
  -g, --graph-width &amp;lt;TYPE&amp;gt;  Commit graph image cell width [default: auto] [possible values: auto, double, single]
      --preload             Preload all graph images
  -h, --help                Print help
  -V, --version             Print version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;-p, --protocol &amp;lt;TYPE&amp;gt;&lt;/h4&gt; 
&lt;p&gt;A protocol type for rendering images of commit graphs.&lt;/p&gt; 
&lt;p&gt;By default &lt;code&gt;auto&lt;/code&gt; will guess the best supported protocol for the current terminal (if listed in &lt;a href="https://raw.githubusercontent.com/lusingander/serie/master/#supported-terminals"&gt;Supported terminals&lt;/a&gt;).&lt;/p&gt; 
&lt;h4&gt;-o, --order &amp;lt;TYPE&amp;gt;&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;--order chrono&lt;/code&gt; will order commits by commit date if possible.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--order topo&lt;/code&gt; will order commits on the same branch consecutively if possible.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Screenshots&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/order-chrono.png" width="400" /&gt; 
 &lt;p&gt;&lt;code&gt;--order chrono&lt;/code&gt;&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/order-topo.png" width="400" /&gt; 
 &lt;p&gt;&lt;code&gt;--order topo&lt;/code&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h4&gt;-g, --graph-width &amp;lt;TYPE&amp;gt;&lt;/h4&gt; 
&lt;p&gt;The character width that a graph image unit cell occupies.&lt;/p&gt; 
&lt;p&gt;If not specified or &lt;code&gt;auto&lt;/code&gt; is specified, &lt;code&gt;double&lt;/code&gt; will be used automatically if there is enough width to display it, &lt;code&gt;single&lt;/code&gt; otherwise.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Screenshots&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/graph-width-double.png" width="300" /&gt; 
 &lt;p&gt;&lt;code&gt;--graph-width double&lt;/code&gt;&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/graph-width-single.png" width="300" /&gt; 
 &lt;p&gt;&lt;code&gt;--graph-width single&lt;/code&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h4&gt;--preload&lt;/h4&gt; 
&lt;p&gt;By default, graph images are generated and loaded lazily as needed.&lt;/p&gt; 
&lt;p&gt;If &lt;code&gt;--preload&lt;/code&gt; is specified, all graph images will be generated and loaded at startup. This can result in smoother scrolling, as the images are already available, and might reduce memory usage. However, this may lead to slower startup times, especially for large repositories.&lt;/p&gt; 
&lt;h3&gt;Keybindings&lt;/h3&gt; 
&lt;p&gt;You can see the keybindings by pressing the &lt;code&gt;?&lt;/code&gt; key.&lt;/p&gt; 
&lt;p&gt;The default key bindings can be overridden. Please refer to &lt;a href="https://raw.githubusercontent.com/lusingander/serie/master/assets/default-keybind.toml"&gt;default-keybind.toml&lt;/a&gt; and add it to &lt;a href="https://raw.githubusercontent.com/lusingander/serie/master/#config"&gt;config file&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;List of all default keybindings&lt;/summary&gt; 
 &lt;h4&gt;Common&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Key&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Corresponding keybind&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-c&lt;/kbd&gt; &lt;kbd&gt;q&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Quit app&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;force_quit&lt;/code&gt; &lt;code&gt;quit&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;?&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Open help&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;help_toggle&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;Commit List&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Key&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Corresponding keybind&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Down/Up&lt;/kbd&gt; &lt;kbd&gt;j/k&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Move down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;navigate_down&lt;/code&gt; &lt;code&gt;navigate_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Alt-Down&lt;/kbd&gt; &lt;kbd&gt;Alt-j&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Move to parent commit&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;go_to_parent&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;g/G&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Go to top/bottom&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;go_to_top&lt;/code&gt; &lt;code&gt;go_to_bottom&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-f/b&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll page down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;page_down&lt;/code&gt; &lt;code&gt;page_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-d/u&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll half page down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;half_page_down&lt;/code&gt; &lt;code&gt;half_page_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-e/y&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;scroll_down&lt;/code&gt; &lt;code&gt;scroll_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;H/M/L&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Select top/middle/bottom of the screen&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;select_top&lt;/code&gt; &lt;code&gt;select_middle&lt;/code&gt; &lt;code&gt;select_bottom&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Enter&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Show commit details&lt;br /&gt;Apply search (if searching)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;confirm&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Tab&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Open refs list&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;ref_list_toggle&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;/&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Start search&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;search&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Esc&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Cancel search&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;cancel&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;n/N&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Go to next/previous search match&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;go_to_next&lt;/code&gt; &lt;code&gt;go_to_previous&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-g&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Toggle ignore case (if searching)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;ignore_case_toggle&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-x&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Toggle fuzzy match (if searching)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;fuzzy_toggle&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;c/C&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Copy commit short/full hash&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;short_copy&lt;/code&gt; &lt;code&gt;full_copy&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;d&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Toggle custom user command view&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;user_command_view_toggle_1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;Commit Detail&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Key&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Corresponding keybind&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Esc&lt;/kbd&gt; &lt;kbd&gt;Backspace&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Close commit details&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;close&lt;/code&gt; &lt;code&gt;cancel&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Down/Up&lt;/kbd&gt; &lt;kbd&gt;j/k&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;navigate_down&lt;/code&gt; &lt;code&gt;navigate_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-f/b&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll page down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;page_down&lt;/code&gt; &lt;code&gt;page_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-d/u&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll half page down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;half_page_down&lt;/code&gt; &lt;code&gt;half_page_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;g/G&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Go to top/bottom&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;go_to_top&lt;/code&gt; &lt;code&gt;go_to_bottom&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;c/C&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Copy commit short/full hash&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;short_copy&lt;/code&gt; &lt;code&gt;full_copy&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;d&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Toggle custom user command view&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;user_command_view_toggle_1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;Refs List&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Key&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Corresponding keybind&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Esc&lt;/kbd&gt; &lt;kbd&gt;Backspace&lt;/kbd&gt; &lt;kbd&gt;Tab&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Close refs list&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;close&lt;/code&gt; &lt;code&gt;cancel&lt;/code&gt; &lt;code&gt;ref_list_toggle&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Down/Up&lt;/kbd&gt; &lt;kbd&gt;j/k&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Move down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;navigate_down&lt;/code&gt; &lt;code&gt;navigate_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;g/G&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Go to top/bottom&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;go_to_top&lt;/code&gt; &lt;code&gt;go_to_bottom&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Right/Left&lt;/kbd&gt; &lt;kbd&gt;l/h&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Open/Close node&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;navigate_right&lt;/code&gt; &lt;code&gt;navigate_left&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;c&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Copy ref name&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;short_copy&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;User Command&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Key&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Corresponding keybind&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Esc&lt;/kbd&gt; &lt;kbd&gt;Backspace&lt;/kbd&gt; &lt;kbd&gt;?&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Close user command&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;close&lt;/code&gt; &lt;code&gt;cancel&lt;/code&gt; &lt;code&gt;help_toggle&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Down/Up&lt;/kbd&gt; &lt;kbd&gt;j/k&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;navigate_down&lt;/code&gt; &lt;code&gt;navigate_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-f/b&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll page down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;page_down&lt;/code&gt; &lt;code&gt;page_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-d/u&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll half page down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;half_page_down&lt;/code&gt; &lt;code&gt;half_page_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;g/G&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Go to top/bottom&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;go_to_top&lt;/code&gt; &lt;code&gt;go_to_bottom&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;h4&gt;Help&lt;/h4&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Key&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Corresponding keybind&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Esc&lt;/kbd&gt; &lt;kbd&gt;Backspace&lt;/kbd&gt; &lt;kbd&gt;?&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Close help&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;close&lt;/code&gt; &lt;code&gt;cancel&lt;/code&gt; &lt;code&gt;help_toggle&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Down/Up&lt;/kbd&gt; &lt;kbd&gt;j/k&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;navigate_down&lt;/code&gt; &lt;code&gt;navigate_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-f/b&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll page down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;page_down&lt;/code&gt; &lt;code&gt;page_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;Ctrl-d/u&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Scroll half page down/up&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;half_page_down&lt;/code&gt; &lt;code&gt;half_page_up&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;kbd&gt;g/G&lt;/kbd&gt;&lt;/td&gt; 
    &lt;td&gt;Go to top/bottom&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;go_to_top&lt;/code&gt; &lt;code&gt;go_to_bottom&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h3&gt;Config&lt;/h3&gt; 
&lt;p&gt;Config files are loaded in the following order of priority:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;$SERIE_CONFIG_FILE&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If &lt;code&gt;$SERIE_CONFIG_FILE&lt;/code&gt; is set but the file does not exist, an error occurs.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$XDG_CONFIG_HOME/serie/config.toml&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If &lt;code&gt;$XDG_CONFIG_HOME&lt;/code&gt; is not set, &lt;code&gt;~/.config/&lt;/code&gt; will be used instead.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If the config file does not exist, the default values will be used for all items. If the config file exists but some items are not set, the default values will be used for those unset items.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Config file details&lt;/summary&gt; 
 &lt;h4&gt;Config file format&lt;/h4&gt; 
 &lt;p&gt;The values set in this example are the default values.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[core.option]
# The protocol type for rendering images of commit graphs.
# The value specified in the command line argument takes precedence.
# type: enum (possible values: "auto", "iterm", "kitty")
protocol = "auto"
# The commit ordering algorithm.
# The value specified in the command line argument takes precedence.
# type: enum (possible values: "chrono", "topo")
order = "chrono"
# The character width that a graph image unit cell occupies.
# The value specified in the command line argument takes precedence.
# type: enum (possible values: "auto", "double", "single")
graph_width = "auto"

[core.search]
# Whether to enable ignore case by default.
# type: boolean
ignore_case = false
# Whether to enable fuzzy matching by default.
# type: boolean
fuzzy = false

[core.user_command]
# The command definition for generating the content displayed in the user command view.
# Multiple commands can be specified in the format commands_{n}.
# For details about user command, see the separate User command section.
# type: object
commands_1 = { name = "git diff", commands = ["git", "--no-pager", "diff", "--color=always", "{{first_parent_hash}}", "{{target_hash}}"]}
# The number of spaces to replace tabs in the user command output.
# type: u16
tab_width = 4

[ui.common]
# The type of a cursor to display in the input.
# If `cursor_type = "Native"` is set, the terminal native cursor is used.
# If `cursor_type = { "Virtual" = "|" }` is set, a virtual cursor with the specified string will be used.
# type: enum
cursor_type = "Native"

[ui.list]
# The minimum width of a subject in the commit list.
# type: u16
subject_min_width = 20
# The date format of a author date in the commit list.
# The format must be specified in strftime format.
# https://docs.rs/chrono/latest/chrono/format/strftime/index.html
# type: string
date_format = "%Y-%m-%d"
# The width of a author date in the commit list.
# type: u16
date_width = 10
# Whether to show a author date in the commit list in local timezone.
# type: boolean
date_local = true
# The width of a author name in the commit list.
# type: u16
name_width = 20

[ui.detail]
# The height of a commit detail area.
# type: u16
height = 20
# The date format of a author/committer date in the commit detail.
# The format must be specified in strftime format.
# https://docs.rs/chrono/latest/chrono/format/strftime/index.html
# type: string
date_format = "%Y-%m-%d %H:%M:%S %z"
# Whether to show a author/committer date in the commit list in local timezone.
# type: boolean
date_local = true

[ui.user_command]
# The height of a user command area.
# type: u16
height = 20

[ui.refs]
# The width of a refs list area.
# type: u16
width = 26

[graph.color]
# Colors should be specified in the format #RRGGBB or #RRGGBBAA.

# Array of colors used for the commit graph.
# type: array of strings
branches = [
  "#E06C76",
  "#98C379",
  "#E5C07B",
  "#61AFEF",
  "#C678DD",
  "#56B6C2",
]
# Color of the edge surrounding the commit circles in the graph.
# type: string
edge = "#00000000"
# Background color of the commit graph.
# type: string
background = "#00000000"

[color]
# The colors of each element of the application.
# Note: Graph colors are specified with [graph.color].
#
# Colors should be specified in one of the following formats:
# - ANSI color name
#   - "red", "bright-blue", "light-red", "reset", ...
# - 8-bit color (256-color) index values
#   - "34", "128", "255", ...
# - 24-bit true color hex codes
#   - "#abcdef", ...
# type: string
fg = "reset"
bg = "reset"
list_selected_fg = "white"
list_selected_bg = "dark-gray"
list_ref_paren_fg = "yellow"
list_ref_branch_fg = "green"
list_ref_remote_branch_fg = "red"
list_ref_tag_fg = "yellow"
list_ref_stash_fg = "magenta"
list_head_fg = "cyan"
list_subject_fg = "reset"
list_name_fg = "cyan"
list_hash_fg = "yellow"
list_date_fg = "magenta"
list_match_fg = "black"
list_match_bg = "yellow"
detail_email_fg = "blue"
detail_ref_branch_fg = "green"
detail_ref_remote_branch_fg = "red"
detail_ref_tag_fg = "yellow"
detail_file_change_add_fg = "green"
detail_file_change_modify_fg = "yellow"
detail_file_change_delete_fg = "red"
detail_file_change_move_fg = "magenta"
ref_selected_fg = "white"
ref_selected_bg = "dark-gray"
help_block_title_fg = "green"
help_key_fg = "yellow"
virtual_cursor_fg = "reset"
status_input_fg = "reset"
status_input_transient_fg = "dark-gray"
status_info_fg = "cyan"
status_success_fg = "green"
status_warn_fg = "yellow"
status_error_fg = "red"
divider_fg = "dark-gray"

[keybind]
# See ./assets/default-keybind.toml for a specific example configuration.
# ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;User command&lt;/h3&gt; 
&lt;p&gt;The User command view allows you to display the output (stdout) of your custom external commands. This allows you to do things like view commit diffs using your favorite tools.&lt;/p&gt; 
&lt;p&gt;To define a user command, you need to configure the following two settings:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Keybinding definition. Specify the key to display each user command. 
  &lt;ul&gt; 
   &lt;li&gt;Config: &lt;code&gt;keybind.user_command_view_toggle_{n}&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Command definition. Specify the actual command you want to execute. 
  &lt;ul&gt; 
   &lt;li&gt;Config: &lt;code&gt;core.user_command.commands_{n}&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Configuration example&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-toml"&gt;[keybind]
user_command_view_toggle_1 = ["d"]
user_command_view_toggle_2 = ["shift-d"]

[core.user_command]
commands_1 = { "name" = "git diff", commands = ["git", "--no-pager", "diff", "--color=always", "{{first_parent_hash}}", "{{target_hash}}"] }
commands_2 = { "name" = "xxx", commands = ["xxx", "{{first_parent_hash}}", "{{target_hash}}", "--width", "{{area_width}}", "--height", "{{area_height}}"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;Variables&lt;/h4&gt; 
&lt;p&gt;The following variables can be used in command definitions. They will be replaced with their respective values command is executed.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;{{target_hash}}&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The hash of the selected commit.&lt;/li&gt; 
   &lt;li&gt;example: &lt;code&gt;b0ce4cb9c798576af9b4accc9f26ddce5e72063d&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;{{first_parent_hash}}&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The hash of the first parent of the selected commit.&lt;/li&gt; 
   &lt;li&gt;example: &lt;code&gt;c103d9744df8ebf100773a11345f011152ec5581&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;{{area_width}}&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Width of the user command display area (number of cells).&lt;/li&gt; 
   &lt;li&gt;example: &lt;code&gt;80&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;{{area_height}}&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Height of the user command display area (number of cells).&lt;/li&gt; 
   &lt;li&gt;example: &lt;code&gt;30&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Compatibility&lt;/h2&gt; 
&lt;h3&gt;Supported terminals&lt;/h3&gt; 
&lt;p&gt;These image protocols are supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline Images Protocol (iTerm2)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://sw.kovidgoyal.net/kitty/graphics-protocol/"&gt;Terminal graphics protocol (kitty)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The terminals on which each has been confirmed to work are listed below.&lt;/p&gt; 
&lt;h4&gt;Inline Images Protocol&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Terminal emulator&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com"&gt;iTerm2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;But slower than other terminals&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://wezfurlong.org/wezterm/"&gt;WezTerm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://code.visualstudio.com/docs/terminal/basics"&gt;VSCode integrated terminal&lt;/a&gt; *&lt;/td&gt; 
   &lt;td&gt;Requires the &lt;a href="https://code.visualstudio.com/docs/terminal/advanced#_image-support"&gt;&lt;code&gt;terminal.integrated.enableImages&lt;/code&gt; setting&lt;/a&gt; to be enabled&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Not only the VSCode integrated terminal, but any terminal emulator using &lt;a href="https://xtermjs.org"&gt;xterm.js&lt;/a&gt; may basically work in the same way as long as &lt;a href="https://github.com/xtermjs/xterm.js/tree/master/addons/addon-image"&gt;image display feature is enabled&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Terminal graphics protocol&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Terminal emulator&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://sw.kovidgoyal.net/kitty/"&gt;kitty&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://ghostty.org"&gt;Ghostty&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Unsupported environments&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sixel graphics is not supported.&lt;/li&gt; 
 &lt;li&gt;Terminal multiplexers (screen, tmux, Zellij, etc.) are not supported.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;To get started with contributing, please review &lt;a href="https://raw.githubusercontent.com/lusingander/serie/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Contributions that do not follow these guidelines may not be accepted.&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/list.png" width="600" /&gt; 
&lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/detail.png" width="600" /&gt; 
&lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/refs.png" width="600" /&gt; 
&lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/searching.png" width="600" /&gt; 
&lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/applied.png" width="600" /&gt; 
&lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/diff_git.png" width="600" /&gt; 
&lt;img src="https://raw.githubusercontent.com/lusingander/serie/master/img/diff_difft.png" width="600" /&gt; 
&lt;p&gt;The following repositories are used as these examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ratatui/ratatui"&gt;ratatui/ratatui&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/charmbracelet/vhs"&gt;charmbracelet/vhs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lusingander/stu"&gt;lusingander/stu&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>timescale/pgvectorscale</title>
      <link>https://github.com/timescale/pgvectorscale</link>
      <description>&lt;p&gt;A complement to pgvector for high performance, cost efficient vector search on large workloads.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;pgvectorscale&lt;/h1&gt; 
 &lt;h3&gt;pgvectorscale builds on pgvector with higher performance embedding search and cost-efficient storage for AI applications. &lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/KRdHVXAmkp"&gt;&lt;img src="https://img.shields.io/badge/Join_us_on_Discord-black?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://tsdb.co/gh-pgvector-signup"&gt;&lt;img src="https://img.shields.io/badge/Try_Timescale_for_free-black?style=for-the-badge&amp;amp;logo=timescale&amp;amp;logoColor=white" alt="Try Timescale for free" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;pgvectorscale complements &lt;a href="https://github.com/pgvector/pgvector/raw/master/README.md"&gt;pgvector&lt;/a&gt;, the open-source vector data extension for PostgreSQL, and introduces the following key innovations for pgvector data:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A new index type called StreamingDiskANN, inspired by the &lt;a href="https://github.com/microsoft/DiskANN"&gt;DiskANN&lt;/a&gt; algorithm, based on research from Microsoft.&lt;/li&gt; 
 &lt;li&gt;Statistical Binary Quantization: developed by Timescale researchers, This compression method improves on standard Binary Quantization.&lt;/li&gt; 
 &lt;li&gt;Label-based filtered vector search: based on Microsoft's Filtered DiskANN research, this allows you to combine vector similarity search with label filtering for more precise and efficient results.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;On a benchmark dataset of 50 million Cohere embeddings with 768 dimensions each, PostgreSQL with &lt;code&gt;pgvector&lt;/code&gt; and &lt;code&gt;pgvectorscale&lt;/code&gt; achieves &lt;strong&gt;28x lower p95 latency&lt;/strong&gt; and &lt;strong&gt;16x higher query throughput&lt;/strong&gt; compared to Pinecone's storage optimized (s1) index for approximate nearest neighbor queries at 99% recall, all at 75% less cost when self-hosted on AWS EC2.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://assets.timescale.com/docs/images/benchmark-comparison-pgvectorscale-pinecone.png" alt="Benchmarks" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;To learn more about the performance impact of pgvectorscale, and details about benchmark methodology and results, see the &lt;a href="http://www.timescale.com/blog/pgvector-vs-pinecone"&gt;pgvector vs Pinecone comparison blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In contrast to pgvector, which is written in C, pgvectorscale is developed in &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt; using the &lt;a href="https://github.com/pgcentralfoundation/pgrx"&gt;PGRX framework&lt;/a&gt;, offering the PostgreSQL community a new avenue for contributing to vector support.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Application developers or DBAs&lt;/strong&gt; can use pgvectorscale with their PostgreSQL databases.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/timescale/pgvectorscale/main/#installation"&gt;Install pgvectorscale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/timescale/pgvectorscale/main/#get-started-with-pgvectorscale"&gt;Get started using pgvectorscale&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you &lt;strong&gt;want to contribute&lt;/strong&gt; to this extension, see how to &lt;a href="https://raw.githubusercontent.com/timescale/pgvectorscale/main/DEVELOPMENT.md"&gt;build pgvectorscale from source in a developer environment&lt;/a&gt; and our &lt;a href="https://raw.githubusercontent.com/timescale/pgvectorscale/main/TESTING.md"&gt;testing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For production vector workloads, get &lt;strong&gt;private beta access to vector-optimized databases&lt;/strong&gt; with pgvector and pgvectorscale on Timescale. &lt;a href="https://timescale.typeform.com/to/H7lQ10eQ"&gt;Sign up here for priority access&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;The fastest ways to run PostgreSQL with pgvectorscale are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/timescale/pgvectorscale/main/#using-a-pre-built-docker-container"&gt;Using a pre-built Docker container&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/timescale/pgvectorscale/main/#installing-from-source"&gt;Installing from source&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/timescale/pgvectorscale/main/#enable-pgai-in-a-timescale-cloud-service"&gt;Enable pgvectorscale in a Timescale Cloud service&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Using a pre-built Docker container&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://docs.timescale.com/self-hosted/latest/install/installation-docker/"&gt;Run the TimescaleDB Docker image&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Connect to your database:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;psql -d "postgres://&amp;lt;username&amp;gt;:&amp;lt;password&amp;gt;@&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;database-name&amp;gt;"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create the pgvectorscale extension:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sql"&gt;CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;CASCADE&lt;/code&gt; automatically installs &lt;code&gt;pgvector&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Installing from source&lt;/h3&gt; 
&lt;p&gt;You can install pgvectorscale from source and install it in an existing PostgreSQL server&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Building pgvectorscale on macOS X86 (Intel) machines is currently not supported due to an &lt;a href="https://github.com/timescale/pgvectorscale/issues/155"&gt;open issue&lt;/a&gt;. As alternatives, you can:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Use an ARM-based Mac.&lt;/li&gt; 
  &lt;li&gt;Build using Linux.&lt;/li&gt; 
  &lt;li&gt;Use our pre-built Docker containers.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;We welcome community contributions to resolve this limitation. If you're interested in helping, please check the issue for details.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Compile and install the extension&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# install rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# download pgvectorscale
cd /tmp
git clone --branch &amp;lt;version&amp;gt; https://github.com/timescale/pgvectorscale
cd pgvectorscale/pgvectorscale
# install cargo-pgrx with the same version as pgrx
cargo install --locked cargo-pgrx --version $(cargo metadata --format-version 1 | jq -r '.packages[] | select(.name == "pgrx") | .version')
cargo pgrx init --pg18 pg_config
# build and install pgvectorscale
cargo pgrx install --release
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can also take a look at our &lt;a href="https://raw.githubusercontent.com/timescale/pgvectorscale/main/DEVELOPMENT.md"&gt;documentation for extension developers&lt;/a&gt; for more complete instructions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Connect to your database:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;psql -d "postgres://&amp;lt;username&amp;gt;:&amp;lt;password&amp;gt;@&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;database-name&amp;gt;"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ensure the pgvector extension is available:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sql"&gt;SELECT * FROM pg_available_extensions WHERE name = 'vector';
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If pgvector is not available, install it using the &lt;a href="https://github.com/pgvector/pgvector?tab=readme-ov-file#installation"&gt;pgvector installation instructions&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create the pgvectorscale extension:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sql"&gt;CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;CASCADE&lt;/code&gt; automatically installs &lt;code&gt;pgvector&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Enable pgvectorscale in a Timescale Cloud service&lt;/h3&gt; 
&lt;p&gt;Note: the instructions below are for Timescale's standard compute instance. For production vector workloads, we're offering &lt;strong&gt;private beta access to vector-optimized databases&lt;/strong&gt; with pgvector and pgvectorscale on Timescale. &lt;a href="https://timescale.typeform.com/to/H7lQ10eQ"&gt;Sign up here for priority access&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To enable pgvectorscale:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create a new &lt;a href="https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch"&gt;Timescale Service&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you want to use an existing service, pgvectorscale is added as an available extension on the first maintenance window after the pgvectorscale release date.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Connect to your Timescale service:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;psql -d "postgres://&amp;lt;username&amp;gt;:&amp;lt;password&amp;gt;@&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;database-name&amp;gt;"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create the pgvectorscale extension:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-postgresql"&gt;CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;CASCADE&lt;/code&gt; automatically installs &lt;code&gt;pgvector&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Get started with pgvectorscale&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create a table with an embedding column. For example:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-postgresql"&gt;CREATE TABLE IF NOT EXISTS document_embedding  (
    id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
    metadata JSONB,
    contents TEXT,
    embedding VECTOR(1536)
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Populate the table.&lt;/p&gt; &lt;p&gt;For more information, see the &lt;a href="https://github.com/pgvector/pgvector/raw/master/README.md#storing"&gt;pgvector instructions&lt;/a&gt; and &lt;a href="https://github.com/pgvector/pgvector/raw/master/README.md#languages"&gt;list of clients&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create a StreamingDiskANN index on the embedding column:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-postgresql"&gt;CREATE INDEX document_embedding_idx ON document_embedding
USING diskann (embedding vector_cosine_ops);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Find the 10 closest embeddings using the index.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-postgresql"&gt;SELECT *
FROM document_embedding
ORDER BY embedding &amp;lt;=&amp;gt; $1
LIMIT 10;
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note: pgvectorscale currently supports: cosine distance (&lt;code&gt;&amp;lt;=&amp;gt;&lt;/code&gt;) queries, for indices created with &lt;code&gt;vector_cosine_ops&lt;/code&gt;; L2 distance (&lt;code&gt;&amp;lt;-&amp;gt;&lt;/code&gt;) queries, for indices created with &lt;code&gt;vector_l2_ops&lt;/code&gt;; and inner product (&lt;code&gt;&amp;lt;#&amp;gt;&lt;/code&gt;) queries, for indices created with &lt;code&gt;vector_ip_ops&lt;/code&gt;. This is the same syntax used by &lt;code&gt;pgvector&lt;/code&gt;. If you would like additional distance types, &lt;a href="https://github.com/timescale/pgvectorscale/issues"&gt;create an issue&lt;/a&gt;. (Note: inner product indices are not compatible with plain storage.)&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Filtered Vector Search&lt;/h2&gt; 
&lt;p&gt;pgvectorscale supports combining vector similarity search with metadata filtering. There are two basic kinds of filtering, which can be combined in a single query:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Label-based filtering with the diskann index&lt;/strong&gt;: This provides optimized performance for filtering by labels.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Arbitrary WHERE clause filtering&lt;/strong&gt;: This uses post-filtering after the vector search.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The label-based filtering implementation is based on the &lt;a href="https://dl.acm.org/doi/10.1145/3543507.3583552"&gt;Filtered DiskANN&lt;/a&gt; approach developed by Microsoft researchers, which enables efficient filtered vector search while maintaining high recall.&lt;/p&gt; 
&lt;p&gt;The post-filtering implementation, while slower, is streaming and correct, ensuring accurate results without requiring the entire result set to be loaded into memory.&lt;/p&gt; 
&lt;h3&gt;Label-based Filtering with diskann&lt;/h3&gt; 
&lt;p&gt;For optimal performance with label filtering, you must specify the label column directly in the index creation:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create a table with an embedding column and a labels array:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-postgresql"&gt;CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    embedding VECTOR(1536),
    labels SMALLINT[],  -- Array of category labels
    status TEXT,
    created_at TIMESTAMPTZ
);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create a StreamingDiskANN index on the embedding column, including the labels column:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-postgresql"&gt;CREATE INDEX ON documents USING diskann (embedding vector_cosine_ops, labels);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Label values must be within the PostgreSQL &lt;code&gt;smallint&lt;/code&gt; range (-32768 to 32767). Using &lt;code&gt;smallint[]&lt;/code&gt; for labels ensures that PostgreSQL's type system will automatically enforce these bounds.&lt;/p&gt; 
 &lt;p&gt;pgvectorscale includes an implementation of the &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; overlap operator for &lt;code&gt;smallint[]&lt;/code&gt; arrays, which is used for efficient label-based filtering.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt; &lt;p&gt;Perform label-filtered vector searches using the &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; operator (array overlap):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-postgresql"&gt;-- Find similar documents with specific labels
SELECT * FROM documents
WHERE labels &amp;amp;&amp;amp; ARRAY[1, 3]  -- Documents with label 1 OR 3
ORDER BY embedding &amp;lt;=&amp;gt; '[...]'
LIMIT 10;
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The index directly supports this type of filtering, providing significantly lower latency results compared to post-filtering.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Giving Semantic Meaning to Labels&lt;/h4&gt; 
&lt;p&gt;While the labels must be stored as integers in the array for the index to work efficiently, you can give them semantic meaning by relating them to a separate labels table:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create a labels table with meaningful descriptions:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-postgresql"&gt;CREATE TABLE label_definitions (
    id INTEGER PRIMARY KEY,
    name TEXT,
    description TEXT,
    attributes JSONB  -- Can store additional metadata about the label
);

-- Insert some label definitions
INSERT INTO label_definitions (id, name, description, attributes) VALUES
(1, 'science', 'Scientific content', '{"domain": "academic", "confidence": 0.95}'),
(2, 'technology', 'Technology-related content', '{"domain": "technical", "confidence": 0.92}'),
(3, 'business', 'Business and finance content', '{"domain": "commercial", "confidence": 0.88}');
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;When inserting documents, use the appropriate label IDs:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-postgresql"&gt;-- Insert a document with science and technology labels
INSERT INTO documents (embedding, labels)
VALUES ('[...]', ARRAY[1, 2]);
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;When querying, you can join with the labels table to work with meaningful names:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-postgresql"&gt;-- Find similar science documents and include label information
SELECT d.*, array_agg(l.name) as label_names
FROM documents d
JOIN label_definitions l ON l.id = ANY(d.labels)
WHERE d.labels &amp;amp;&amp;amp; ARRAY[1]  -- Science label
GROUP BY d.id, d.embedding, d.labels, d.status, d.created_at
ORDER BY d.embedding &amp;lt;=&amp;gt; '[...]'
LIMIT 10;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can also convert between label names and IDs when filtering:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-postgresql"&gt;-- Find documents with specific label names
SELECT d.*
FROM documents d
WHERE d.labels &amp;amp;&amp;amp; (
    SELECT array_agg(id)
    FROM label_definitions
    WHERE name IN ('science', 'business')
)
ORDER BY d.embedding &amp;lt;=&amp;gt; '[...]'
LIMIT 10;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This approach gives you the performance benefits of integer-based label filtering while still allowing you to work with semantically meaningful labels in your application.&lt;/p&gt; 
&lt;h3&gt;Arbitrary WHERE Clause Filtering&lt;/h3&gt; 
&lt;p&gt;You can also use any PostgreSQL WHERE clause with vector search, but these conditions will be applied as post-filtering:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-postgresql"&gt;-- Find similar documents with specific status and date range
SELECT * FROM documents
WHERE status = 'active' AND created_at &amp;gt; '2024-01-01'
ORDER BY embedding &amp;lt;=&amp;gt; '[...]'
LIMIT 10;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For these arbitrary conditions, the vector search happens first, and then the WHERE conditions are applied to the results. For best performance with frequently used filters, consider using the label-based approach described above.&lt;/p&gt; 
&lt;h2&gt;Tuning&lt;/h2&gt; 
&lt;p&gt;The StreamingDiskANN index comes with &lt;strong&gt;smart defaults&lt;/strong&gt; but also the ability to customize its behavior. There are two types of parameters: index build-time parameters that are specified when an index is created and query-time parameters that can be tuned when querying an index.&lt;/p&gt; 
&lt;p&gt;We suggest setting the index build-time paramers for major changes to index operations while query-time parameters can be used to tune the accuracy/performance tradeoff for individual queries.&lt;/p&gt; 
&lt;p&gt;We expect most people to tune the query-time parameters (if any) and leave the index build time parameters set to default.&lt;/p&gt; 
&lt;h3&gt;StreamingDiskANN index build-time parameters&lt;/h3&gt; 
&lt;p&gt;The StreamingDiskANN index build process can be memory-intensive. You may need to increase the &lt;code&gt;maintenance_work_mem&lt;/code&gt; parameter to improve build performance. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;SET maintenance_work_mem = '2GB';
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This parameter controls the maximum amount of memory to be used by maintenance operations, including index builds. The default value is typically 64MB, which may be too low for building StreamingDiskANN indexes on large datasets.&lt;/p&gt; 
&lt;p&gt;These parameters can be set when an index is created.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Parameter name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;storage_layout&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;memory_optimized&lt;/code&gt; which uses SBQ to compress vector data or &lt;code&gt;plain&lt;/code&gt; which stores data uncompressed&lt;/td&gt; 
   &lt;td&gt;memory_optimized&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;num_neighbors&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Sets the maximum number of neighbors per node. Higher values increase accuracy but make the graph traversal slower.&lt;/td&gt; 
   &lt;td&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;search_list_size&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;This is the S parameter used in the greedy search algorithm used during construction. Higher values improve graph quality at the cost of slower index builds.&lt;/td&gt; 
   &lt;td&gt;100&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;max_alpha&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Is the alpha parameter in the algorithm. Higher values improve graph quality at the cost of slower index builds.&lt;/td&gt; 
   &lt;td&gt;1.2&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;num_dimensions&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The number of dimensions to index. By default, all dimensions are indexed. But you can also index less dimensions to make use of &lt;a href="https://huggingface.co/blog/matryoshka"&gt;Matryoshka embeddings&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;0 (all dimensions)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;num_bits_per_dimension&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Number of bits used to encode each dimension when using SBQ&lt;/td&gt; 
   &lt;td&gt;2 for less than 900 dimensions, 1 otherwise&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;An example of how to set the &lt;code&gt;num_neighbors&lt;/code&gt; parameter is:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE INDEX document_embedding_idx ON document_embedding
USING diskann (embedding) WITH(num_neighbors=50);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An example of creating an index with label-based filtering:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE INDEX document_embedding_idx ON document_embedding
USING diskann (embedding vector_cosine_ops, labels);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Parallel Index Build Parameters&lt;/h4&gt; 
&lt;p&gt;pgvectorscale supports parallel index building to improve performance on large datasets. These parameters control parallel build behavior:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Parameter name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;diskann.parallel_flush_interval&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The fraction of total vectors (0.0-1.0) processed before flushing neighbor cache in parallel builds&lt;/td&gt; 
   &lt;td&gt;0.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;diskann.parallel_initial_start_nodes_count&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The number of initial start nodes to process before starting parallel workers&lt;/td&gt; 
   &lt;td&gt;1024&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;diskann.min_vectors_for_parallel_build&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Minimum number of vectors required to enable parallel building&lt;/td&gt; 
   &lt;td&gt;65536&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;diskann.force_parallel_workers&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Force a specific number of parallel workers for index builds (-1 for automatic)&lt;/td&gt; 
   &lt;td&gt;-1&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Parallel building is automatically enabled when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The feature is compiled in (enabled by default)&lt;/li&gt; 
 &lt;li&gt;The table has no labels (label-based filtering not yet supported in parallel)&lt;/li&gt; 
 &lt;li&gt;Using SBQ compression storage layout&lt;/li&gt; 
 &lt;li&gt;The number of vectors meets the &lt;code&gt;min_vectors_for_parallel_build&lt;/code&gt; threshold&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can set these parameters using &lt;code&gt;SET&lt;/code&gt; before creating an index:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;-- Enable parallel building for smaller datasets
SET diskann.min_vectors_for_parallel_build = 10000;

-- Use 4 parallel workers regardless of PostgreSQL's automatic determination
SET diskann.force_parallel_workers = 4;

-- Adjust cache flushing frequency for memory usage (flush after processing 5% of vectors)
SET diskann.parallel_flush_interval = 0.05;

CREATE INDEX ON my_table USING diskann (embedding vector_cosine_ops);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;StreamingDiskANN query-time parameters&lt;/h4&gt; 
&lt;p&gt;You can also set two parameters to control the accuracy vs. query speed trade-off at query time. We suggest adjusting &lt;code&gt;diskann.query_rescore&lt;/code&gt; to fine-tune accuracy.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Parameter name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;diskann.query_search_list_size&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The number of additional candidates considered during the graph search.&lt;/td&gt; 
   &lt;td&gt;100&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;diskann.query_rescore&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The number of elements rescored (0 to disable rescoring)&lt;/td&gt; 
   &lt;td&gt;50&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;You can set the value by using &lt;code&gt;SET&lt;/code&gt; before executing a query. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;SET diskann.query_rescore = 400;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note the &lt;a href="https://www.postgresql.org/docs/current/sql-set.html"&gt;SET command&lt;/a&gt; applies to the entire session (database connection) from the point of execution. You can use a transaction-local variant using &lt;code&gt;LOCAL&lt;/code&gt; which will be reset after the end of the transaction:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;BEGIN;
SET LOCAL diskann.query_search_list_size= 10;
SELECT * FROM document_embedding ORDER BY embedding &amp;lt;=&amp;gt; $1 LIMIT 10
COMMIT;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Null Value Handling&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Null vectors are not indexed&lt;/li&gt; 
 &lt;li&gt;Null labels are treated as empty arrays&lt;/li&gt; 
 &lt;li&gt;Null values in label arrays are ignored&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ORDER BY vector distance&lt;/h2&gt; 
&lt;p&gt;pgvectorscale's diskann index uses relaxed ordering which allows results to be slightly out of order by distance. This is analogous to using &lt;a href="https://github.com/pgvector/pgvector?tab=readme-ov-file#iterative-index-scans"&gt;&lt;code&gt;iterative scan with relaxed ordering&lt;/code&gt;&lt;/a&gt; with pgvector's ivfflat or hnsw indexes.&lt;/p&gt; 
&lt;p&gt;If you need strict ordering you can use a &lt;a href="https://www.postgresql.org/docs/current/queries-with.html#QUERIES-WITH-CTE-MATERIALIZATION"&gt;materialized CTE&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;WITH relaxed_results AS MATERIALIZED (
    SELECT id, embedding &amp;lt;=&amp;gt; '[1,2,3]' AS distance
    FROM items
    WHERE category_id = 123
    ORDER BY distance
    LIMIT 5
) SELECT * FROM relaxed_results ORDER BY distance;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Index on an UNLOGGED table&lt;/h2&gt; 
&lt;p&gt;Creating an index on an UNLOGGED table is currently not supported. Trying will yield the error:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;ERROR:  ambuildempty: not yet implemented
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Get involved&lt;/h2&gt; 
&lt;p&gt;pgvectorscale is still at an early stage. Now is a great time to help shape the direction of this project; we are currently deciding priorities. Have a look at the list of features we're thinking of working on. Feel free to comment, expand the list, or hop on the Discussions forum.&lt;/p&gt; 
&lt;h2&gt;About Timescale&lt;/h2&gt; 
&lt;p&gt;Timescale is a PostgreSQL cloud company. To learn more visit the &lt;a href="https://www.timescale.com"&gt;timescale.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch"&gt;Timescale Cloud&lt;/a&gt; is a high-performance, developer focused, cloud platform that provides PostgreSQL services for the most demanding AI, time-series, analytics, and event workloads. Timescale Cloud is ideal for production applications and provides high availability, streaming backups, upgrades over time, roles and permissions, and great security.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tensorchord/VectorChord</title>
      <link>https://github.com/tensorchord/VectorChord</link>
      <description>&lt;p&gt;Scalable, fast, and disk-friendly vector search in Postgres, the successor of pgvecto.rs.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1 align="center"&gt;VectorChord&lt;/h1&gt; 
 &lt;h4 align="center"&gt;Effortlessly host 100 million 768-dimensional vectors (250GB+) on an AWS i4i.xlarge instance ($250/month), featuring 4 vCPUs and 32GB of RAM with VectorChord.&lt;/h4&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://vectorchord.ai/"&gt;Official Site&lt;/a&gt; ¬∑ &lt;a href="https://blog.vectorchord.ai/"&gt;Blog&lt;/a&gt; ¬∑ &lt;a href="https://docs.vectorchord.ai/vectorchord/"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://github.com/tensorchord/VectorChord/issues"&gt;Feedback&lt;/a&gt; ¬∑ &lt;a href="mailto:support@tensorchord.ai"&gt;Contact Us&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/tensorchord/VectorChord/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/tensorchord/VectorChord?color=369eff&amp;amp;labelColor=black&amp;amp;logo=github&amp;amp;style=flat" alt="" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/tensorchord/vchord-postgres"&gt;&lt;img src="https://img.shields.io/docker/v/tensorchord/vchord-postgres?color=369eff&amp;amp;label=docker&amp;amp;labelColor=black&amp;amp;logo=docker&amp;amp;logoColor=white&amp;amp;style=flat" alt="" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/tensorchord/vchord-postgres"&gt;&lt;img src="https://img.shields.io/docker/pulls/tensorchord/vchord-postgres?color=45cc11&amp;amp;labelColor=black&amp;amp;style=flat&amp;amp;sort=semver" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/orgs/tensorchord/packages/container/package/vchord-postgres"&gt;&lt;img src="https://img.shields.io/docker/v/tensorchord/vchord-postgres?color=369eff&amp;amp;label=GHCR&amp;amp;labelColor=black&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;style=flat" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tensorchord/VectorChord/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/tensorchord/VectorChord/total?color=45cc11&amp;amp;labelColor=black&amp;amp;style=flat&amp;amp;sort=semver" alt="" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/KqswhpVgdU"&gt;&lt;img src="https://img.shields.io/discord/974584200327991326?&amp;amp;logoColor=white&amp;amp;color=5865F2&amp;amp;style=flat&amp;amp;logo=discord&amp;amp;cacheSeconds=60" alt="" /&gt;&lt;/a&gt; &lt;a href="https://x.com/TensorChord"&gt;&lt;img src="https://img.shields.io/badge/follow-%40tensorchord-1DA1F2?logo=x&amp;amp;style=flat&amp;amp;logoColor=white&amp;amp;color=1da1f2" alt="" /&gt;&lt;/a&gt; &lt;a href="https://cloud.vectorchord.ai/"&gt;&lt;img src="https://img.shields.io/badge/VectorChord_Cloud-Try_For_Free-F2B263.svg?labelColor=DAFDBA&amp;amp;logo=data:image/svg%2bxml;base64,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" alt="" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/tensorchord/VectorChord"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tensorchord/VectorChord#license"&gt;&lt;img src="https://img.shields.io/badge/License-AGPLv3-green?logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0IiBoZWlnaHQ9IjI0IiBmaWxsPSIjZmZmZmZmIj48cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xMi43NSAyLjc1YS43NS43NSAwIDAwLTEuNSAwVjQuNUg5LjI3NmExLjc1IDEuNzUgMCAwMC0uOTg1LjMwM0w2LjU5NiA1Ljk1N0EuMjUuMjUgMCAwMTYuNDU1IDZIMi4zNTNhLjc1Ljc1IDAgMTAwIDEuNUgzLjkzTC41NjMgMTUuMThhLjc2Mi43NjIgMCAwMC4yMS44OGMuMDguMDY0LjE2MS4xMjUuMzA5LjIyMS4xODYuMTIxLjQ1Mi4yNzguNzkyLjQzMy42OC4zMTEgMS42NjIuNjIgMi44NzYuNjJhNi45MTkgNi45MTkgMCAwMDIuODc2LS42MmMuMzQtLjE1NS42MDYtLjMxMi43OTItLjQzMy4xNS0uMDk3LjIzLS4xNTguMzEtLjIyM2EuNzUuNzUgMCAwMC4yMDktLjg3OEw1LjU2OSA3LjVoLjg4NmMuMzUxIDAgLjY5NC0uMTA2Ljk4NC0uMzAzbDEuNjk2LTEuMTU0QS4yNS4yNSAwIDAxOS4yNzUgNmgxLjk3NXYxNC41SDYuNzYzYS43NS43NSAwIDAwMCAxLjVoMTAuNDc0YS43NS43NSAwIDAwMC0xLjVIMTIuNzVWNmgxLjk3NGMuMDUgMCAuMS4wMTUuMTQuMDQzbDEuNjk3IDEuMTU0Yy4yOS4xOTcuNjMzLjMwMy45ODQuMzAzaC44ODZsLTMuMzY4IDcuNjhhLjc1Ljc1IDAgMDAuMjMuODk2Yy4wMTIuMDA5IDAgMCAuMDAyIDBhMy4xNTQgMy4xNTQgMCAwMC4zMS4yMDZjLjE4NS4xMTIuNDUuMjU2Ljc5LjRhNy4zNDMgNy4zNDMgMCAwMDIuODU1LjU2OCA3LjM0MyA3LjM0MyAwIDAwMi44NTYtLjU2OWMuMzM4LS4xNDMuNjA0LS4yODcuNzktLjM5OWEzLjUgMy41IDAgMDAuMzEtLjIwNi43NS43NSAwIDAwLjIzLS44OTZMMjAuMDcgNy41aDEuNTc4YS43NS43NSAwIDAwMC0xLjVoLTQuMTAyYS4yNS4yNSAwIDAxLS4xNC0uMDQzbC0xLjY5Ny0xLjE1NGExLjc1IDEuNzUgMCAwMC0uOTg0LS4zMDNIMTIuNzVWMi43NXpNMi4xOTMgMTUuMTk4YTUuNDE4IDUuNDE4IDAgMDAyLjU1Ny42MzUgNS40MTggNS40MTggMCAwMDIuNTU3LS42MzVMNC43NSA5LjM2OGwtMi41NTcgNS44M3ptMTQuNTEtLjAyNGMuMDgyLjA0LjE3NC4wODMuMjc1LjEyNi41My4yMjMgMS4zMDUuNDUgMi4yNzIuNDVhNS44NDYgNS44NDYgMCAwMDIuNTQ3LS41NzZMMTkuMjUgOS4zNjdsLTIuNTQ3IDUuODA3eiI+PC9wYXRoPjwvc3ZnPgo=" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tensorchord/VectorChord#license"&gt;&lt;img src="https://img.shields.io/badge/License-ELv2-green?logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0IiBoZWlnaHQ9IjI0IiBmaWxsPSIjZmZmZmZmIj48cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xMi43NSAyLjc1YS43NS43NSAwIDAwLTEuNSAwVjQuNUg5LjI3NmExLjc1IDEuNzUgMCAwMC0uOTg1LjMwM0w2LjU5NiA1Ljk1N0EuMjUuMjUgMCAwMTYuNDU1IDZIMi4zNTNhLjc1Ljc1IDAgMTAwIDEuNUgzLjkzTC41NjMgMTUuMThhLjc2Mi43NjIgMCAwMC4yMS44OGMuMDguMDY0LjE2MS4xMjUuMzA5LjIyMS4xODYuMTIxLjQ1Mi4yNzguNzkyLjQzMy42OC4zMTEgMS42NjIuNjIgMi44NzYuNjJhNi45MTkgNi45MTkgMCAwMDIuODc2LS42MmMuMzQtLjE1NS42MDYtLjMxMi43OTItLjQzMy4xNS0uMDk3LjIzLS4xNTguMzEtLjIyM2EuNzUuNzUgMCAwMC4yMDktLjg3OEw1LjU2OSA3LjVoLjg4NmMuMzUxIDAgLjY5NC0uMTA2Ljk4NC0uMzAzbDEuNjk2LTEuMTU0QS4yNS4yNSAwIDAxOS4yNzUgNmgxLjk3NXYxNC41SDYuNzYzYS43NS43NSAwIDAwMCAxLjVoMTAuNDc0YS43NS43NSAwIDAwMC0xLjVIMTIuNzVWNmgxLjk3NGMuMDUgMCAuMS4wMTUuMTQuMDQzbDEuNjk3IDEuMTU0Yy4yOS4xOTcuNjMzLjMwMy45ODQuMzAzaC44ODZsLTMuMzY4IDcuNjhhLjc1Ljc1IDAgMDAuMjMuODk2Yy4wMTIuMDA5IDAgMCAuMDAyIDBhMy4xNTQgMy4xNTQgMCAwMC4zMS4yMDZjLjE4NS4xMTIuNDUuMjU2Ljc5LjRhNy4zNDMgNy4zNDMgMCAwMDIuODU1LjU2OCA3LjM0MyA3LjM0MyAwIDAwMi44NTYtLjU2OWMuMzM4LS4xNDMuNjA0LS4yODcuNzktLjM5OWEzLjUgMy41IDAgMDAuMzEtLjIwNi43NS43NSAwIDAwLjIzLS44OTZMMjAuMDcgNy41aDEuNTc4YS43NS43NSAwIDAwMC0xLjVoLTQuMTAyYS4yNS4yNSAwIDAxLS4xNC0uMDQzbC0xLjY5Ny0xLjE1NGExLjc1IDEuNzUgMCAwMC0uOTg0LS4zMDNIMTIuNzVWMi43NXpNMi4xOTMgMTUuMTk4YTUuNDE4IDUuNDE4IDAgMDAyLjU1Ny42MzUgNS40MTggNS40MTggMCAwMDIuNTU3LS42MzVMNC43NSA5LjM2OGwtMi41NTcgNS44M3ptMTQuNTEtLjAyNGMuMDgyLjA0LjE3NC4wODMuMjc1LjEyNi41My4yMjMgMS4zMDUuNDUgMi4yNzIuNDVhNS44NDYgNS44NDYgMCAwMDIuNTQ3LS41NzZMMTkuMjUgOS4zNjdsLTIuNTQ3IDUuODA3eiI+PC9wYXRoPjwvc3ZnPgo=" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] VectorChord serves as the successor to &lt;a href="https://github.com/tensorchord/pgvecto.rs"&gt;pgvecto.rs&lt;/a&gt; &lt;a href="https://hub.docker.com/r/tensorchord/pgvecto-rs"&gt;&lt;img src="https://img.shields.io/docker/pulls/tensorchord/pgvecto-rs?color=45cc11&amp;amp;labelColor=black&amp;amp;style=flat&amp;amp;sort=semver" alt="" /&gt;&lt;/a&gt; with better stability and performance. If you are interested in this new solution, you may find the &lt;a href="https://docs.vectorchord.ai/vectorchord/admin/migration.html"&gt;migration guide&lt;/a&gt; helpful.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;VectorChord (vchord) is a PostgreSQL extension designed for scalable, high-performance, and disk-efficient vector similarity search.&lt;/p&gt; 
&lt;p&gt;With VectorChord, you can store 400,000 vectors for just $1, enabling significant savings: 6x more vectors compared to Pinecone's optimized storage and 26x more than pgvector/pgvecto.rs for the same price[^1].&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/2d985f1e-7093-4c3a-8bf3-9f0b92c0e7e7" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;VectorChord introduces remarkable enhancements over pgvecto.rs and pgvector:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;‚ö° Enhanced Performance&lt;/strong&gt;: Delivering optimized operations with up to 5x faster queries, 16x higher insert throughput, and 16x quicker[^1] index building compared to pgvector's HNSW implementation.&lt;/p&gt; 
&lt;p&gt;[^1]: Based on &lt;a href="https://myscale.github.io/benchmark/"&gt;MyScale Benchmark&lt;/a&gt; with 768-dimensional vectors and 95% recall. Please checkout our &lt;a href="https://blog.vectorchord.ai/vectorchord-store-400k-vectors-for-1-in-postgresql"&gt;blog post&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üí∞ Affordable Vector Search&lt;/strong&gt;: Query 100M 768-dimensional vectors using just 32GB of memory, achieving 35ms P50 latency with top10 recall@95%, helping you keep infrastructure costs down while maintaining high search quality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üîå Seamless Integration&lt;/strong&gt;: Fully compatible with pgvector data types and syntax while providing optimal defaults out of the box - no manual parameter tuning needed. Just drop in VectorChord for enhanced performance.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üîß Accelerated Index Build&lt;/strong&gt;: Leverage IVF to build indexes externally (e.g., on GPU) for faster KMeans clustering, combined with RaBitQ[^2] compression to efficiently store vectors while maintaining search quality through autonomous reranking.&lt;/p&gt; 
&lt;p&gt;[^2]: Gao, Jianyang, and Cheng Long. "RaBitQ: Quantizing High-Dimensional Vectors with a Theoretical Error Bound for Approximate Nearest Neighbor Search." Proceedings of the ACM on Management of Data 2.3 (2024): 1-27.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üìè Long Vector Support&lt;/strong&gt;: Store and search vectors up to 60,000[^3] dimensions, enabling the use of the best high-dimensional models like text-embedding-3-large with ease.&lt;/p&gt; 
&lt;p&gt;[^3]: There is a &lt;a href="https://github.com/pgvector/pgvector#vector-type"&gt;limitation&lt;/a&gt; at pgvector of 16,000 dimensions now. If you really have a large dimension(&lt;code&gt;16,000&amp;lt;dim&amp;lt;60,000&lt;/code&gt;), consider changing &lt;a href="https://github.com/pgvector/pgvector/raw/fef635c9e5512597621e5669dce845c744170822/src/vector.h#L4"&gt;VECTOR_MAX_DIM&lt;/a&gt; and compile pgvector yourself.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üåê Scale As You Want&lt;/strong&gt;: Based on horizontal expansion, the query of 5M / 100M 768-dimensional vectors can be easily scaled to 10000+ QPS with top10 recall@90% at a competitive cost[^4]&lt;/p&gt; 
&lt;p&gt;[^4]: Please check our &lt;a href="https://blog.vectorchord.ai/vector-search-at-10000-qps-in-postgresql-with-vectorchord"&gt;blog post&lt;/a&gt; for more details, the PostgreSQL scalability is powered by &lt;a href="https://github.com/cloudnative-pg/cloudnative-pg"&gt;CloudNative-PG&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üè≠ Production Proven&lt;/strong&gt;: Deployed in mission-critical environments, VectorChord ‚Äã‚Äãreliably handles 3B+ vectors‚Äã‚Äã in production with consistent performance. Please check out &lt;a href="https://blog.vectorchord.ai/3-billion-vectors-in-postgresql-to-protect-the-earth"&gt;3B vectors in PostgreSQL to Protect the Earth&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;For new users, we recommend using the Docker image to get started quickly. If you do not prefer Docker, please read &lt;a href="https://docs.vectorchord.ai/vectorchord/getting-started/installation.html"&gt;installation guide&lt;/a&gt; for other installation methods.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run \
  --name vectorchord-demo \
  -e POSTGRES_PASSWORD=mysecretpassword \
  -p 5432:5432 \
  -d ghcr.io/tensorchord/vchord-postgres:pg18-v0.5.3
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] In addition to the base image with the VectorChord extension, we provide an all-in-one image, &lt;code&gt;tensorchord/vchord-suite:pg17-latest&lt;/code&gt;. This comprehensive image includes all official TensorChord extensions, including &lt;code&gt;VectorChord&lt;/code&gt;, &lt;code&gt;VectorChord-bm25&lt;/code&gt; and &lt;code&gt;pg_tokenizer.rs&lt;/code&gt; . Developers should select an image tag that is compatible with their extension's version, as indicated in &lt;a href="https://github.com/tensorchord/VectorChord-images?tab=readme-ov-file#support-matrix"&gt;the support matrix&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Then you can connect to the database using the &lt;code&gt;psql&lt;/code&gt; command line tool. The default username is &lt;code&gt;postgres&lt;/code&gt;, and the default password is &lt;code&gt;mysecretpassword&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;psql -h localhost -p 5432 -U postgres
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can play with VectorChord!&lt;/p&gt; 
&lt;p&gt;VectorChord depends on pgvector, including the vector representation. Since you can use them directly, your application can be easily migrated without pain!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE EXTENSION IF NOT EXISTS vchord CASCADE;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Similar to pgvector, you can create a table with vector column and insert some rows to it.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;CREATE TABLE items (id bigserial PRIMARY KEY, embedding vector(3));
INSERT INTO items (embedding) SELECT ARRAY[random(), random(), random()]::real[] FROM generate_series(1, 1000);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With VectorChord, you can create &lt;code&gt;vchordrq&lt;/code&gt; indexes.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-SQL"&gt;CREATE INDEX ON items USING vchordrq (embedding vector_l2_ops);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then perform a vector search using &lt;code&gt;SELECT ... ORDER BY ... LIMIT ...&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-SQL"&gt;SELECT * FROM items ORDER BY embedding &amp;lt;-&amp;gt; '[3,1,2]' LIMIT 5;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more usage, please read:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/indexing.html"&gt;Indexing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/indexing-with-maxsim-operators.html"&gt;Multi-Vector Retrieval&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/graph-index.html"&gt;Graph Index&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/range-query.html"&gt;Similarity Filter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/performance-tuning.html"&gt;PostgreSQL Tuning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/monitoring.html"&gt;Monitoring&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/measure-recall.html"&gt;Measure Recall&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/prewarm.html"&gt;Prewarm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/prefilter.html"&gt;Prefilter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/prefetch.html"&gt;Prefetch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/rerank-in-table.html"&gt;Rerank In Table&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vectorchord.ai/vectorchord/usage/external-index-precomputation.html"&gt;External Build&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This software is licensed under a dual license model:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GNU Affero General Public License v3 (AGPLv3)&lt;/strong&gt;: You may use, modify, and distribute this software under the terms of the AGPLv3.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Elastic License v2 (ELv2)&lt;/strong&gt;: You may also use, modify, and distribute this software under the Elastic License v2, which has specific restrictions.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You may choose either license based on your needs. We welcome any commercial collaboration or support, so please email us &lt;a href="mailto:vectorchord-inquiry@tensorchord.ai"&gt;vectorchord-inquiry@tensorchord.ai&lt;/a&gt; with any questions or requests regarding the licenses.&lt;/p&gt; 
&lt;!-- GHCR badge is not supported by shields.io yet, use docker badge instead --&gt;</description>
    </item>
    
    <item>
      <title>rust-lang/rust-clippy</title>
      <link>https://github.com/rust-lang/rust-clippy</link>
      <description>&lt;p&gt;A bunch of lints to catch common mistakes and improve your Rust code. Book: https://doc.rust-lang.org/clippy/&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Clippy&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rust-lang/rust-clippy/master/#license"&gt;&lt;img src="https://img.shields.io/crates/l/clippy.svg?sanitize=true" alt="License: MIT OR Apache-2.0" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A collection of lints to catch common mistakes and improve your &lt;a href="https://github.com/rust-lang/rust"&gt;Rust&lt;/a&gt; code.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html"&gt;There are over 750 lints included in this crate!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Lints are divided into categories, each with a default &lt;a href="https://doc.rust-lang.org/rustc/lints/levels.html"&gt;lint level&lt;/a&gt;. You can choose how much Clippy is supposed to &lt;del&gt;annoy&lt;/del&gt; help you by changing the lint level by category.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Default level&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::all&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;all lints that are on by default (correctness, suspicious, style, complexity, perf)&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;warn/deny&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::correctness&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;code that is outright wrong or useless&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;deny&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::suspicious&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;code that is most likely wrong or useless&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;warn&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::style&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;code that should be written in a more idiomatic way&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;warn&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::complexity&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;code that does something simple but in a complex way&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;warn&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::perf&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;code that can be written to run faster&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;warn&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::pedantic&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;lints which are rather strict or have occasional false positives&lt;/td&gt; 
   &lt;td&gt;allow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::restriction&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;lints which prevent the use of language and library features[^restrict]&lt;/td&gt; 
   &lt;td&gt;allow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::nursery&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;new lints that are still under development&lt;/td&gt; 
   &lt;td&gt;allow&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;clippy::cargo&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;lints for the cargo manifest&lt;/td&gt; 
   &lt;td&gt;allow&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;More to come, please &lt;a href="https://github.com/rust-lang/rust-clippy/issues"&gt;file an issue&lt;/a&gt; if you have ideas!&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;restriction&lt;/code&gt; category should, &lt;em&gt;emphatically&lt;/em&gt;, not be enabled as a whole. The contained lints may lint against perfectly reasonable code, may not have an alternative suggestion, and may contradict any other lints (including other categories). Lints should be considered on a case-by-case basis before enabling.&lt;/p&gt; 
&lt;p&gt;[^restrict]: Some use cases for &lt;code&gt;restriction&lt;/code&gt; lints include: - Strict coding styles (e.g. &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#else_if_without_else"&gt;&lt;code&gt;clippy::else_if_without_else&lt;/code&gt;&lt;/a&gt;). - Additional restrictions on CI (e.g. &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#todo"&gt;&lt;code&gt;clippy::todo&lt;/code&gt;&lt;/a&gt;). - Preventing panicking in certain functions (e.g. &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#unwrap_used"&gt;&lt;code&gt;clippy::unwrap_used&lt;/code&gt;&lt;/a&gt;). - Running a lint only on a subset of code (e.g. &lt;code&gt;#[forbid(clippy::float_arithmetic)]&lt;/code&gt; on a module).&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Table of contents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rust-lang/rust-clippy/master/#usage"&gt;Usage instructions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rust-lang/rust-clippy/master/#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rust-lang/rust-clippy/master/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rust-lang/rust-clippy/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Below are instructions on how to use Clippy as a cargo subcommand, in projects that do not use cargo, or in Travis CI.&lt;/p&gt; 
&lt;h3&gt;As a cargo subcommand (&lt;code&gt;cargo clippy&lt;/code&gt;)&lt;/h3&gt; 
&lt;p&gt;One way to use Clippy is by installing Clippy through rustup as a cargo subcommand.&lt;/p&gt; 
&lt;h4&gt;Step 1: Install Rustup&lt;/h4&gt; 
&lt;p&gt;You can install &lt;a href="https://rustup.rs/"&gt;Rustup&lt;/a&gt; on supported platforms. This will help us install Clippy and its dependencies.&lt;/p&gt; 
&lt;p&gt;If you already have Rustup installed, update to ensure you have the latest Rustup and compiler:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;rustup update
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 2: Install Clippy&lt;/h4&gt; 
&lt;p&gt;Once you have rustup and the latest stable release (at least Rust 1.29) installed, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;rustup component add clippy
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If it says that it can't find the &lt;code&gt;clippy&lt;/code&gt; component, please run &lt;code&gt;rustup self update&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Step 3: Run Clippy&lt;/h4&gt; 
&lt;p&gt;Now you can run Clippy by invoking the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Automatically applying Clippy suggestions&lt;/h4&gt; 
&lt;p&gt;Clippy can automatically apply some lint suggestions, just like the compiler. Note that &lt;code&gt;--fix&lt;/code&gt; implies &lt;code&gt;--all-targets&lt;/code&gt;, so it can fix as much code as it can.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy --fix
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Workspaces&lt;/h4&gt; 
&lt;p&gt;All the usual workspace options should work with Clippy. For example the following command will run Clippy on the &lt;code&gt;example&lt;/code&gt; crate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -p example
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;As with &lt;code&gt;cargo check&lt;/code&gt;, this includes dependencies that are members of the workspace, like path dependencies. If you want to run Clippy &lt;strong&gt;only&lt;/strong&gt; on the given crate, use the &lt;code&gt;--no-deps&lt;/code&gt; option like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -p example -- --no-deps
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using &lt;code&gt;clippy-driver&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Clippy can also be used in projects that do not use cargo. To do so, run &lt;code&gt;clippy-driver&lt;/code&gt; with the same arguments you use for &lt;code&gt;rustc&lt;/code&gt;. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;clippy-driver --edition 2018 -Cpanic=abort foo.rs
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that &lt;code&gt;clippy-driver&lt;/code&gt; is designed for running Clippy only and should not be used as a general replacement for &lt;code&gt;rustc&lt;/code&gt;. &lt;code&gt;clippy-driver&lt;/code&gt; may produce artifacts that are not optimized as expected, for example.&lt;/p&gt; 
&lt;h3&gt;Travis CI&lt;/h3&gt; 
&lt;p&gt;You can add Clippy to Travis CI in the same way you use it locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;language: rust
rust:
  - stable
  - beta
before_script:
  - rustup component add clippy
script:
  - cargo clippy
  # if you want the build job to fail when encountering warnings, use
  - cargo clippy -- -D warnings
  # in order to also check tests and non-default crate features, use
  - cargo clippy --all-targets --all-features -- -D warnings
  - cargo test
  # etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that adding &lt;code&gt;-D warnings&lt;/code&gt; will cause your build to fail if &lt;strong&gt;any&lt;/strong&gt; warnings are found in your code. That includes warnings found by rustc (e.g. &lt;code&gt;dead_code&lt;/code&gt;, etc.). If you want to avoid this and only cause an error for Clippy warnings, use &lt;code&gt;#![deny(clippy::all)]&lt;/code&gt; in your code or &lt;code&gt;-D clippy::all&lt;/code&gt; on the command line. (You can swap &lt;code&gt;clippy::all&lt;/code&gt; with the specific lint category you are targeting.)&lt;/p&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;h3&gt;Allowing/denying lints&lt;/h3&gt; 
&lt;p&gt;You can add options to your code to &lt;code&gt;allow&lt;/code&gt;/&lt;code&gt;warn&lt;/code&gt;/&lt;code&gt;deny&lt;/code&gt; Clippy lints:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;the whole set of &lt;code&gt;Warn&lt;/code&gt; lints using the &lt;code&gt;clippy&lt;/code&gt; lint group (&lt;code&gt;#![deny(clippy::all)]&lt;/code&gt;). Note that &lt;code&gt;rustc&lt;/code&gt; has additional &lt;a href="https://doc.rust-lang.org/rustc/lints/groups.html"&gt;lint groups&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;all lints using both the &lt;code&gt;clippy&lt;/code&gt; and &lt;code&gt;clippy::pedantic&lt;/code&gt; lint groups (&lt;code&gt;#![deny(clippy::all)]&lt;/code&gt;, &lt;code&gt;#![deny(clippy::pedantic)]&lt;/code&gt;). Note that &lt;code&gt;clippy::pedantic&lt;/code&gt; contains some very aggressive lints prone to false positives.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;only some lints (&lt;code&gt;#![deny(clippy::single_match, clippy::box_vec)]&lt;/code&gt;, etc.)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;allow&lt;/code&gt;/&lt;code&gt;warn&lt;/code&gt;/&lt;code&gt;deny&lt;/code&gt; can be limited to a single function or module using &lt;code&gt;#[allow(...)]&lt;/code&gt;, etc.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: &lt;code&gt;allow&lt;/code&gt; means to suppress the lint for your code. With &lt;code&gt;warn&lt;/code&gt; the lint will only emit a warning, while with &lt;code&gt;deny&lt;/code&gt; the lint will emit an error, when triggering for your code. An error causes Clippy to exit with an error code, so is useful in scripts like CI/CD.&lt;/p&gt; 
&lt;p&gt;If you do not want to include your lint levels in your code, you can globally enable/disable lints by passing extra flags to Clippy during the run:&lt;/p&gt; 
&lt;p&gt;To allow &lt;code&gt;lint_name&lt;/code&gt;, run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -- -A clippy::lint_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And to warn on &lt;code&gt;lint_name&lt;/code&gt;, run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -- -W clippy::lint_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This also works with lint groups. For example, you can run Clippy with warnings for all lints enabled:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -- -W clippy::pedantic
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you care only about a single lint, you can allow all others and then explicitly warn on the lint(s) you are interested in:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-terminal"&gt;cargo clippy -- -A clippy::all -W clippy::useless_format -W clippy::...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configure the behavior of some lints&lt;/h3&gt; 
&lt;p&gt;Some lints can be configured in a TOML file named &lt;code&gt;clippy.toml&lt;/code&gt; or &lt;code&gt;.clippy.toml&lt;/code&gt;. It contains a basic &lt;code&gt;variable = value&lt;/code&gt; mapping e.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;avoid-breaking-exported-api = false
disallowed-names = ["toto", "tata", "titi"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;a href="https://doc.rust-lang.org/nightly/clippy/lint_configuration.html"&gt;table of configurations&lt;/a&gt; contains all config values, their default, and a list of lints they affect. Each &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#Configuration"&gt;configurable lint&lt;/a&gt; , also contains information about these values.&lt;/p&gt; 
&lt;p&gt;For configurations that are a list type with default values such as &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#disallowed_names"&gt;disallowed-names&lt;/a&gt;, you can use the unique value &lt;code&gt;".."&lt;/code&gt; to extend the default values instead of replacing them.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# default of disallowed-names is ["foo", "baz", "quux"]
disallowed-names = ["bar", ".."] # -&amp;gt; ["bar", "foo", "baz", "quux"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;code&gt;clippy.toml&lt;/code&gt; or &lt;code&gt;.clippy.toml&lt;/code&gt; cannot be used to allow/deny lints.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To deactivate the ‚Äúfor further information visit &lt;em&gt;lint-link&lt;/em&gt;‚Äù message you can define the &lt;code&gt;CLIPPY_DISABLE_DOCS_LINKS&lt;/code&gt; environment variable.&lt;/p&gt; 
&lt;h3&gt;Specifying the minimum supported Rust version&lt;/h3&gt; 
&lt;p&gt;Projects that intend to support old versions of Rust can disable lints pertaining to newer features by specifying the minimum supported Rust version (MSRV) in the Clippy configuration file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;msrv = "1.30.0"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, the &lt;a href="https://doc.rust-lang.org/cargo/reference/manifest.html#the-rust-version-field"&gt;&lt;code&gt;rust-version&lt;/code&gt; field&lt;/a&gt; in the &lt;code&gt;Cargo.toml&lt;/code&gt; can be used.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;# Cargo.toml
rust-version = "1.30"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The MSRV can also be specified as an attribute, like below.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust,ignore"&gt;#![feature(custom_inner_attributes)]
#![clippy::msrv = "1.30.0"]

fn main() {
  ...
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also omit the patch version when specifying the MSRV, so &lt;code&gt;msrv = 1.30&lt;/code&gt; is equivalent to &lt;code&gt;msrv = 1.30.0&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note: &lt;code&gt;custom_inner_attributes&lt;/code&gt; is an unstable feature, so it has to be enabled explicitly.&lt;/p&gt; 
&lt;p&gt;Lints that recognize this configuration option can be found &lt;a href="https://rust-lang.github.io/rust-clippy/master/index.html#msrv"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;If you want to contribute to Clippy, you can find more information in &lt;a href="https://github.com/rust-lang/rust-clippy/raw/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;!-- REUSE-IgnoreStart --&gt; 
&lt;p&gt;Copyright 2014-2025 The Rust Project Developers&lt;/p&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 &amp;lt;LICENSE-APACHE or &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&amp;gt; or the MIT license &amp;lt;LICENSE-MIT or &lt;a href="https://opensource.org/licenses/MIT"&gt;https://opensource.org/licenses/MIT&lt;/a&gt;&amp;gt;, at your option. Files in the project may not be copied, modified, or distributed except according to those terms.&lt;/p&gt; 
&lt;!-- REUSE-IgnoreEnd --&gt;</description>
    </item>
    
    <item>
      <title>supabase/etl</title>
      <link>https://github.com/supabase/etl</link>
      <description>&lt;p&gt;Stream your Postgres data anywhere in real-time. Simple Rust building blocks for change data capture (CDC) pipelines.&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://supabase.com"&gt; 
  &lt;picture&gt; 
   &lt;img alt="ETL by Supabase" width="100%" src="https://raw.githubusercontent.com/supabase/etl/main/docs/assets/etl-logo-extended.png" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;ETL&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/supabase/etl/actions/workflows/ci.yml"&gt; &lt;img alt="CI" src="https://github.com/supabase/etl/actions/workflows/ci.yml/badge.svg?branch=main" /&gt; &lt;/a&gt; &lt;a href="https://coveralls.io/github/supabase/etl?branch=main"&gt; &lt;img alt="Coverage Status" src="https://coveralls.io/repos/github/supabase/etl/badge.svg?branch=main" /&gt; &lt;/a&gt; &lt;a href="https://github.com/supabase/etl/actions/workflows/docs.yml"&gt; &lt;img alt="Docs" src="https://github.com/supabase/etl/actions/workflows/docs.yml/badge.svg?branch=main" /&gt; &lt;/a&gt; &lt;a href="https://github.com/supabase/etl/actions/workflows/docker-build.yml"&gt; &lt;img alt="Docker Build" src="https://github.com/supabase/etl/actions/workflows/docker-build.yml/badge.svg?branch=main" /&gt; &lt;/a&gt; &lt;a href="https://github.com/supabase/etl/actions/workflows/audit.yml"&gt; &lt;img alt="Security Audit" src="https://github.com/supabase/etl/actions/workflows/audit.yml/badge.svg?branch=main" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/supabase/etl/main/LICENSE"&gt; &lt;img alt="License" src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;br /&gt; Build real-time Postgres replication applications in Rust &lt;br /&gt; &lt;a href="https://supabase.github.io/etl"&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; ¬∑ &lt;a href="https://github.com/supabase/etl/tree/main/etl-examples"&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/a&gt; ¬∑ &lt;a href="https://github.com/supabase/etl/issues"&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p&gt;ETL is a Rust framework by &lt;a href="https://supabase.com"&gt;Supabase&lt;/a&gt; for building high‚Äëperformance, real‚Äëtime data replication apps on Postgres. It sits on top of Postgres &lt;a href="https://www.postgresql.org/docs/current/protocol-logical-replication.html"&gt;logical replication&lt;/a&gt; and gives you a clean, Rust‚Äënative API for streaming changes to your own destinations.&lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real‚Äëtime replication&lt;/strong&gt;: stream changes in real time to your own destinations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High performance&lt;/strong&gt;: configurable batching and parallelism to maximize throughput.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fault-tolerant&lt;/strong&gt;: robust error handling and retry logic built-in.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt;: implement your own custom destinations and state/schema stores.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rust native&lt;/strong&gt;: typed and ergonomic Rust API.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;PostgreSQL Version:&lt;/strong&gt; ETL officially supports and tests against &lt;strong&gt;PostgreSQL 14, 15, 16, and 17&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL 15+&lt;/strong&gt; is recommended for access to advanced publication features including: 
  &lt;ul&gt; 
   &lt;li&gt;Column-level filtering&lt;/li&gt; 
   &lt;li&gt;Row-level filtering with &lt;code&gt;WHERE&lt;/code&gt; clauses&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;FOR ALL TABLES IN SCHEMA&lt;/code&gt; syntax&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For detailed configuration instructions, see the &lt;a href="https://supabase.github.io/etl/how-to/configure-postgres/"&gt;Configure Postgres documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;Install via Git while we prepare for a crates.io release:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
etl = { git = "https://github.com/supabase/etl" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Quick example using the in‚Äëmemory destination:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;use etl::{
    config::{BatchConfig, PgConnectionConfig, PipelineConfig, TlsConfig},
    destination::memory::MemoryDestination,
    pipeline::Pipeline,
    store::both::memory::MemoryStore,
};

#[tokio::main]
async fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn std::error::Error&amp;gt;&amp;gt; {
    let pg = PgConnectionConfig {
        host: "localhost".into(),
        port: 5432,
        name: "mydb".into(),
        username: "postgres".into(),
        password: Some("password".into()),
        tls: TlsConfig { enabled: false, trusted_root_certs: String::new() },
    };

    let store = MemoryStore::new();
    let destination = MemoryDestination::new();

    let config = PipelineConfig {
        id: 1,
        publication_name: "my_publication".into(),
        pg_connection: pg,
        batch: BatchConfig { max_size: 1000, max_fill_ms: 5000 },
        table_error_retry_delay_ms: 10_000,
        table_error_retry_max_attempts: 5,
        max_table_sync_workers: 4,
    };

    let mut pipeline = Pipeline::new(config, store, destination);
    pipeline.start().await?;
    // pipeline.wait().await?; // Optional: block until completion

    Ok(())
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For tutorials and deeper guidance, see the &lt;a href="https://supabase.github.io/etl"&gt;Documentation&lt;/a&gt; or jump into the &lt;a href="https://raw.githubusercontent.com/supabase/etl/main/etl-examples/README.md"&gt;examples&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Destinations&lt;/h2&gt; 
&lt;p&gt;ETL is designed to be extensible. You can implement your own destinations to send data to any destination you like, however it comes with a few built in destinations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;BigQuery&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Out-of-the-box destinations are available in the &lt;code&gt;etl-destinations&lt;/code&gt; crate:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
etl = { git = "https://github.com/supabase/etl" }
etl-destinations = { git = "https://github.com/supabase/etl", features = ["bigquery"] }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache‚Äë2.0. See &lt;code&gt;LICENSE&lt;/code&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; Made with ‚ù§Ô∏è by the &lt;a href="https://supabase.com"&gt;Supabase&lt;/a&gt; team &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>qdrant/qdrant</title>
      <link>https://github.com/qdrant/qdrant</link>
      <description>&lt;p&gt;Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/qdrant/qdrant/raw/master/docs/logo-dark.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/qdrant/qdrant/raw/master/docs/logo-light.svg" /&gt; 
  &lt;img height="100" alt="Qdrant" src="https://github.com/qdrant/qdrant/raw/master/docs/logo.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;b&gt;Vector Search Engine for the next generation of AI applications&lt;/b&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/qdrant/qdrant/actions/workflows/rust.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/qdrant/qdrant/rust.yml?style=flat-square" alt="Tests status" /&gt;&lt;/a&gt; &lt;a href="https://api.qdrant.tech/"&gt;&lt;img src="https://img.shields.io/badge/Docs-OpenAPI%203.0-success?style=flat-square" alt="OpenAPI Docs" /&gt;&lt;/a&gt; &lt;a href="https://github.com/qdrant/qdrant/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/qdrant/qdrant?style=flat-square" alt="Apache 2.0 License" /&gt;&lt;/a&gt; &lt;a href="https://qdrant.to/discord"&gt;&lt;img src="https://img.shields.io/discord/907569970500743200?logo=Discord&amp;amp;style=flat-square&amp;amp;color=7289da" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://qdrant.to/roadmap"&gt;&lt;img src="https://img.shields.io/badge/Roadmap-2025-bc1439.svg?style=flat-square" alt="Roadmap 2025" /&gt;&lt;/a&gt; &lt;a href="https://cloud.qdrant.io/"&gt;&lt;img src="https://img.shields.io/badge/Qdrant-Cloud-24386C.svg?logo=cloud&amp;amp;style=flat-square" alt="Qdrant Cloud" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Qdrant&lt;/strong&gt; (read: &lt;em&gt;quadrant&lt;/em&gt;) is a vector similarity search engine and vector database. It provides a production-ready service with a convenient API to store, search, and manage points‚Äîvectors with an additional payload Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications.&lt;/p&gt; 
&lt;p&gt;Qdrant is written in Rust ü¶Ä, which makes it fast and reliable even under high load. See &lt;a href="https://qdrant.tech/benchmarks/"&gt;benchmarks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!&lt;/p&gt; 
&lt;p&gt;Qdrant is also available as a fully managed &lt;strong&gt;&lt;a href="https://cloud.qdrant.io/"&gt;Qdrant Cloud&lt;/a&gt;&lt;/strong&gt; ‚õÖ including a &lt;strong&gt;free tier&lt;/strong&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/docs/QUICK_START.md"&gt;Quick Start&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/#clients"&gt;Client Libraries&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/#demo-projects"&gt;Demo Projects&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/#integrations"&gt;Integrations&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/#contacts"&gt;Contact&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;pip install qdrant-client
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The python client offers a convenient way to start with Qdrant locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from qdrant_client import QdrantClient
qdrant = QdrantClient(":memory:") # Create in-memory Qdrant instance, for testing, CI/CD
# OR
client = QdrantClient(path="path/to/db")  # Persists changes to disk, fast prototyping
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Client-Server&lt;/h3&gt; 
&lt;p&gt;To experience the full power of Qdrant locally, run the container with this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -p 6333:6333 qdrant/qdrant
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can connect to this with any client, including Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;qdrant = QdrantClient("http://localhost:6333") # Connect to existing Qdrant instance
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Before deploying Qdrant to production, be sure to read our &lt;a href="https://qdrant.tech/documentation/guides/installation/"&gt;installation&lt;/a&gt; and &lt;a href="https://qdrant.tech/documentation/guides/security/"&gt;security&lt;/a&gt; guides.&lt;/p&gt; 
&lt;h3&gt;Clients&lt;/h3&gt; 
&lt;p&gt;Qdrant offers the following client libraries to help you integrate it into your application stack with ease:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Official: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/go-client"&gt;Go client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/rust-client"&gt;Rust client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/qdrant-js"&gt;JavaScript/TypeScript client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/qdrant-client"&gt;Python client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/qdrant-dotnet"&gt;.NET/C# client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/java-client"&gt;Java client&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Community: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://hexdocs.pm/qdrant/readme.html"&gt;Elixir&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/hkulekci/qdrant-php"&gt;PHP&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/andreibondarev/qdrant-ruby"&gt;Ruby&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/metaloom/qdrant-java-client"&gt;Java&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Where do I go from here?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/docs/QUICK_START.md"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;End to End &lt;a href="https://colab.research.google.com/drive/1Bz8RSVHwnNDaNtDwotfPj0w7AYzsdXZ-?usp=sharing"&gt;Colab Notebook&lt;/a&gt; demo with SentenceBERT and Qdrant&lt;/li&gt; 
 &lt;li&gt;Detailed &lt;a href="https://qdrant.tech/documentation/"&gt;Documentation&lt;/a&gt; are great starting points&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://qdrant.to/qdrant-tutorial"&gt;Step-by-Step Tutorial&lt;/a&gt; to create your first neural network project with Qdrant&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo Projects&lt;a href="https://replit.com/@qdrant"&gt;&lt;img align="right" src="https://replit.com/badge/github/qdrant/qdrant" alt="Run on Repl.it" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Discover Semantic Text Search üîç&lt;/h3&gt; 
&lt;p&gt;Unlock the power of semantic embeddings with Qdrant, transcending keyword-based search to find meaningful connections in short texts. Deploy a neural search in minutes using a pre-trained neural network, and experience the future of text search. &lt;a href="https://qdrant.to/semantic-search-demo"&gt;Try it online!&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Explore Similar Image Search - Food Discovery üçï&lt;/h3&gt; 
&lt;p&gt;There's more to discovery than text search, especially when it comes to food. People often choose meals based on appearance rather than descriptions and ingredients. Let Qdrant help your users find their next delicious meal using visual search, even if they don't know the dish's name. &lt;a href="https://qdrant.to/food-discovery"&gt;Check it out!&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Master Extreme Classification - E-commerce Product Categorization üì∫&lt;/h3&gt; 
&lt;p&gt;Enter the cutting-edge realm of extreme classification, an emerging machine learning field tackling multi-class and multi-label problems with millions of labels. Harness the potential of similarity learning models, and see how a pre-trained transformer model and Qdrant can revolutionize e-commerce product categorization. &lt;a href="https://qdrant.to/extreme-classification-demo"&gt;Play with it online!&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; More solutions &lt;/summary&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="30%"&gt; &lt;img src="https://qdrant.tech/content/images/text_search.png" /&gt; &lt;/td&gt; 
    &lt;td width="30%"&gt; &lt;img src="https://qdrant.tech/content/images/image_search.png" /&gt; &lt;/td&gt; 
    &lt;td width="30%"&gt; &lt;img src="https://qdrant.tech/content/images/recommendations.png" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; Semantic Text Search &lt;/td&gt; 
    &lt;td&gt; Similar Image Search &lt;/td&gt; 
    &lt;td&gt; Recommendations &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt; &lt;img width="300px" src="https://qdrant.tech/content/images/chat_bots.png" /&gt; &lt;/td&gt; 
    &lt;td&gt; &lt;img width="300px" src="https://qdrant.tech/content/images/matching_engines.png" /&gt; &lt;/td&gt; 
    &lt;td&gt; &lt;img width="300px" src="https://qdrant.tech/content/images/anomalies_detection.png" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; Chat Bots &lt;/td&gt; 
    &lt;td&gt; Matching Engines &lt;/td&gt; 
    &lt;td&gt; Anomaly Detection &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;h3&gt;REST&lt;/h3&gt; 
&lt;p&gt;Online OpenAPI 3.0 documentation is available &lt;a href="https://api.qdrant.tech/"&gt;here&lt;/a&gt;. OpenAPI makes it easy to generate a client for virtually any framework or programming language.&lt;/p&gt; 
&lt;p&gt;You can also download raw OpenAPI &lt;a href="https://github.com/qdrant/qdrant/raw/master/docs/redoc/master/openapi.json"&gt;definitions&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;gRPC&lt;/h3&gt; 
&lt;p&gt;For faster production-tier searches, Qdrant also provides a gRPC interface. You can find gRPC documentation &lt;a href="https://qdrant.tech/documentation/interfaces/#grpc-interface"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Filtering and Payload&lt;/h3&gt; 
&lt;p&gt;Qdrant can attach any JSON payloads to vectors, allowing for both the storage and filtering of data based on the values in these payloads. Payload supports a wide range of data types and query conditions, including keyword matching, full-text filtering, numerical ranges, geo-locations, and more.&lt;/p&gt; 
&lt;p&gt;Filtering conditions can be combined in various ways, including &lt;code&gt;should&lt;/code&gt;, &lt;code&gt;must&lt;/code&gt;, and &lt;code&gt;must_not&lt;/code&gt; clauses, ensuring that you can implement any desired business logic on top of similarity matching.&lt;/p&gt; 
&lt;h3&gt;Hybrid Search with Sparse Vectors&lt;/h3&gt; 
&lt;p&gt;To address the limitations of vector embeddings when searching for specific keywords, Qdrant introduces support for sparse vectors in addition to the regular dense ones.&lt;/p&gt; 
&lt;p&gt;Sparse vectors can be viewed as an generalization of BM25 or TF-IDF ranking. They enable you to harness the capabilities of transformer-based neural networks to weigh individual tokens effectively.&lt;/p&gt; 
&lt;h3&gt;Vector Quantization and On-Disk Storage&lt;/h3&gt; 
&lt;p&gt;Qdrant provides multiple options to make vector search cheaper and more resource-efficient. Built-in vector quantization reduces RAM usage by up to 97% and dynamically manages the trade-off between search speed and precision.&lt;/p&gt; 
&lt;h3&gt;Distributed Deployment&lt;/h3&gt; 
&lt;p&gt;Qdrant offers comprehensive horizontal scaling support through two key mechanisms:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Size expansion via sharding and throughput enhancement via replication&lt;/li&gt; 
 &lt;li&gt;Zero-downtime rolling updates and seamless dynamic scaling of the collections&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Highlighted Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Query Planning and Payload Indexes&lt;/strong&gt; - leverages stored payload information to optimize query execution strategy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SIMD Hardware Acceleration&lt;/strong&gt; - utilizes modern CPU x86-x64 and Neon architectures to deliver better performance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Async I/O&lt;/strong&gt; - uses &lt;code&gt;io_uring&lt;/code&gt; to maximize disk throughput utilization even on a network-attached storage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Write-Ahead Logging&lt;/strong&gt; - ensures data persistence with update confirmation, even during power outages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Integrations&lt;/h1&gt; 
&lt;p&gt;Examples and/or documentation of Qdrant integrations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.cohere.com/docs/qdrant-and-cohere"&gt;Cohere&lt;/a&gt; (&lt;a href="https://qdrant.tech/articles/qa-with-cohere-and-qdrant/"&gt;blogpost on building a QA app with Cohere and Qdrant&lt;/a&gt;) - Use Cohere embeddings with Qdrant&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docarray.org/user_guide/storing/index_qdrant/"&gt;DocArray&lt;/a&gt; - Use Qdrant as a document store in DocArray&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://haystack.deepset.ai/integrations/qdrant-document-store"&gt;Haystack&lt;/a&gt; - Use Qdrant as a document store with Haystack (&lt;a href="https://haystack.deepset.ai/blog/qdrant-integration"&gt;blogpost&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/docs/integrations/providers/qdrant/"&gt;LangChain&lt;/a&gt; (&lt;a href="https://qdrant.tech/articles/langchain-integration/"&gt;blogpost&lt;/a&gt;) - Use Qdrant as a memory backend for LangChain.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/QdrantIndexDemo.html"&gt;LlamaIndex&lt;/a&gt; - Use Qdrant as a Vector Store with LlamaIndex.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openai/chatgpt-retrieval-plugin/raw/main/docs/providers/qdrant/setup.md"&gt;OpenAI - ChatGPT retrieval plugin&lt;/a&gt; - Use Qdrant as a memory backend for ChatGPT&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://devblogs.microsoft.com/semantic-kernel/the-power-of-persistent-memory-with-semantic-kernel-and-qdrant-vector-database/"&gt;Microsoft Semantic Kernel&lt;/a&gt; - Use Qdrant as persistent memory with Semantic Kernel&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contacts&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Have questions? Join our &lt;a href="https://qdrant.to/discord"&gt;Discord channel&lt;/a&gt; or mention &lt;a href="https://qdrant.to/twitter"&gt;@qdrant_engine on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Want to stay in touch with latest releases? Subscribe to our &lt;a href="https://qdrant.tech/subscribe/"&gt;Newsletters&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Looking for a managed cloud? Check &lt;a href="https://qdrant.tech/pricing/"&gt;pricing&lt;/a&gt;, need something personalised? We're at &lt;a href="mailto:info@qdrant.tech"&gt;info@qdrant.tech&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Qdrant is licensed under the Apache License, Version 2.0. View a copy of the &lt;a href="https://github.com/qdrant/qdrant/raw/master/LICENSE"&gt;License file&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rust-lang/rust</title>
      <link>https://github.com/rust-lang/rust</link>
      <description>&lt;p&gt;Empowering everyone to build reliable and efficient software.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-dark.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-light.svg" /&gt; 
  &lt;img alt="The Rust Programming Language: A language empowering everyone to build reliable and efficient software" src="https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-light.svg?sanitize=true" width="50%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;&lt;a href="https://www.rust-lang.org/"&gt;Website&lt;/a&gt; | &lt;a href="https://www.rust-lang.org/learn/get-started"&gt;Getting started&lt;/a&gt; | &lt;a href="https://www.rust-lang.org/learn"&gt;Learn&lt;/a&gt; | &lt;a href="https://www.rust-lang.org/learn#learn-use"&gt;Documentation&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/rust-lang/rust/master/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;This is the main source code repository for &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;. It contains the compiler, standard library, and documentation.&lt;/p&gt; 
&lt;h2&gt;Why Rust?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Performance:&lt;/strong&gt; Fast and memory-efficient, suitable for critical services, embedded devices, and easily integrated with other languages.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reliability:&lt;/strong&gt; Our rich type system and ownership model ensure memory and thread safety, reducing bugs at compile-time.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Productivity:&lt;/strong&gt; Comprehensive documentation, a compiler committed to providing great diagnostics, and advanced tooling including package manager and build tool (&lt;a href="https://github.com/rust-lang/cargo"&gt;Cargo&lt;/a&gt;), auto-formatter (&lt;a href="https://github.com/rust-lang/rustfmt"&gt;rustfmt&lt;/a&gt;), linter (&lt;a href="https://github.com/rust-lang/rust-clippy"&gt;Clippy&lt;/a&gt;) and editor support (&lt;a href="https://github.com/rust-lang/rust-analyzer"&gt;rust-analyzer&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Read &lt;a href="https://doc.rust-lang.org/book/ch01-01-installation.html"&gt;"Installation"&lt;/a&gt; from &lt;a href="https://doc.rust-lang.org/book/index.html"&gt;The Book&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installing from Source&lt;/h2&gt; 
&lt;p&gt;If you really want to install from source (though this is not recommended), see &lt;a href="https://raw.githubusercontent.com/rust-lang/rust/master/INSTALL.md"&gt;INSTALL.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://www.rust-lang.org/community"&gt;https://www.rust-lang.org/community&lt;/a&gt; for a list of chat platforms and forums.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rust-lang/rust/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Rust is primarily distributed under the terms of both the MIT license and the Apache License (Version 2.0), with portions covered by various BSD-like licenses.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rust-lang/rust/master/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/rust-lang/rust/master/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/rust-lang/rust/master/COPYRIGHT"&gt;COPYRIGHT&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Trademark&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://rustfoundation.org/"&gt;The Rust Foundation&lt;/a&gt; owns and protects the Rust and Cargo trademarks and logos (the "Rust Trademarks").&lt;/p&gt; 
&lt;p&gt;If you want to use these names or brands, please read the &lt;a href="https://rustfoundation.org/policy/rust-trademark-policy/"&gt;Rust language trademark policy&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Third-party logos may be subject to third-party copyrights and trademarks. See &lt;a href="https://www.rust-lang.org/policies/licenses"&gt;Licenses&lt;/a&gt; for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>libp2p/rust-libp2p</title>
      <link>https://github.com/libp2p/rust-libp2p</link>
      <description>&lt;p&gt;The Rust Implementation of the libp2p networking stack.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Central repository for work on libp2p&lt;/h1&gt; 
&lt;p&gt;&lt;a href="http://libp2p.io/"&gt;&lt;img src="https://img.shields.io/badge/project-libp2p-yellow.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://deps.rs/repo/github/libp2p/rust-libp2p"&gt;&lt;img src="https://deps.rs/repo/github/libp2p/rust-libp2p/status.svg?style=flat-square" alt="dependency status" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/libp2p"&gt;&lt;img src="https://img.shields.io/crates/v/libp2p.svg?sanitize=true" alt="Crates.io" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/libp2p"&gt;&lt;img src="https://img.shields.io/badge/api-rustdoc-blue.svg?sanitize=true" alt="docs.rs" /&gt;&lt;/a&gt; &lt;a href="https://libp2p.github.io/rust-libp2p/libp2p/"&gt;&lt;img src="https://img.shields.io/badge/docs-master-blueviolet" alt="docs.rs master" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repository is the central place for Rust development of the &lt;a href="https://libp2p.io"&gt;libp2p&lt;/a&gt; spec.&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Main documentation&lt;/strong&gt; can be found on &lt;a href="https://docs.rs/libp2p"&gt;https://docs.rs/libp2p&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/libp2p/rust-libp2p/master/examples"&gt;examples&lt;/a&gt;&lt;/strong&gt; folder contains small binaries showcasing the many protocols in this repository.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For &lt;strong&gt;security related issues&lt;/strong&gt; please &lt;a href="https://github.com/libp2p/rust-libp2p/security/advisories/new"&gt;file a private security vulnerability report&lt;/a&gt; . Please do not file a public issue on GitHub.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To &lt;strong&gt;report bugs, suggest improvements or request new features&lt;/strong&gt; please open a GitHub issue on this repository.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For &lt;strong&gt;rust-libp2p specific questions&lt;/strong&gt; please use the GitHub &lt;em&gt;Discussions&lt;/em&gt; forum &lt;a href="https://github.com/libp2p/rust-libp2p/discussions"&gt;https://github.com/libp2p/rust-libp2p/discussions&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For &lt;strong&gt;discussions and questions related to multiple libp2p implementations&lt;/strong&gt; please use the libp2p &lt;em&gt;Discourse&lt;/em&gt; forum &lt;a href="https://discuss.libp2p.io"&gt;https://discuss.libp2p.io&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For synchronous discussions join the &lt;a href="https://github.com/libp2p/rust-libp2p/discussions?discussions_q=open+maintainers+call+"&gt;open rust-libp2p maintainer calls&lt;/a&gt; or the &lt;a href="https://discuss.libp2p.io/t/libp2p-community-calls/1157"&gt;biweekly libp2p community calls&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Repository Structure&lt;/h2&gt; 
&lt;p&gt;The main components of this repository are structured as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;core/&lt;/code&gt;: The implementation of &lt;code&gt;libp2p-core&lt;/code&gt; with its &lt;code&gt;Transport&lt;/code&gt; and &lt;code&gt;StreamMuxer&lt;/code&gt; API on which almost all other crates depend.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;transports/&lt;/code&gt;: Implementations of transport protocols (e.g. TCP) and protocol upgrades (e.g. for authenticated encryption, compression, ...) based on the &lt;code&gt;libp2p-core&lt;/code&gt; &lt;code&gt;Transport&lt;/code&gt; API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;muxers/&lt;/code&gt;: Implementations of the &lt;code&gt;StreamMuxer&lt;/code&gt; interface of &lt;code&gt;libp2p-core&lt;/code&gt;, e.g. (sub)stream multiplexing protocols on top of (typically TCP) connections. Multiplexing protocols are (mandatory) &lt;code&gt;Transport&lt;/code&gt; upgrades.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;swarm/&lt;/code&gt;: The implementation of &lt;code&gt;libp2p-swarm&lt;/code&gt; building on &lt;code&gt;libp2p-core&lt;/code&gt; with the central interfaces &lt;code&gt;NetworkBehaviour&lt;/code&gt; and &lt;code&gt;ConnectionHandler&lt;/code&gt; used to implement application protocols (see &lt;code&gt;protocols/&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;protocols/&lt;/code&gt;: Implementations of application protocols based on the &lt;code&gt;libp2p-swarm&lt;/code&gt; APIs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;misc/&lt;/code&gt;: Utility libraries.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;libp2p/examples/&lt;/code&gt;: Worked examples of built-in application protocols (see &lt;code&gt;protocols/&lt;/code&gt;) with common &lt;code&gt;Transport&lt;/code&gt; configurations.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community Guidelines&lt;/h2&gt; 
&lt;p&gt;The libp2p project operates under the &lt;a href="https://github.com/ipfs/community/raw/master/code-of-conduct.md"&gt;IPFS Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;tl;dr&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Be respectful.&lt;/li&gt; 
  &lt;li&gt;We're here to help: &lt;a href="mailto:abuse@ipfs.io"&gt;abuse@ipfs.io&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Abusive behavior is never tolerated.&lt;/li&gt; 
  &lt;li&gt;Violations of this code may result in swift and permanent expulsion from the IPFS [and libp2p] community.&lt;/li&gt; 
  &lt;li&gt;"Too long, didn't read" is not a valid excuse for not knowing what is in this document.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Maintainers&lt;/h2&gt; 
&lt;p&gt;(In alphabetical order.)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jo√£o Oliveira (&lt;a href="https://github.com/jxs"&gt;@jxs&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Notable users&lt;/h2&gt; 
&lt;p&gt;(open a pull request if you want your project to be added here)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/comit-network/xmr-btc-swap"&gt;COMIT&lt;/a&gt; - Bitcoin‚ÄìMonero Cross-chain Atomic Swap.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ChainSafe/forest"&gt;Forest&lt;/a&gt; - An implementation of Filecoin written in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FuelLabs/fuel-core"&gt;fuel-core&lt;/a&gt; - A Rust implementation of the Fuel protocol.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EspressoSystems/HotShot"&gt;HotShot&lt;/a&gt; - Decentralized sequencer in Rust developed by &lt;a href="https://www.espressosys.com/"&gt;Espresso Systems&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ipfs-rust/ipfs-embed"&gt;ipfs-embed&lt;/a&gt; - A small embeddable ipfs implementation used and maintained by &lt;a href="https://www.actyx.com"&gt;Actyx&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ipvm-wg/homestar"&gt;Homestar&lt;/a&gt; - An InterPlanetary Virtual Machine (IPVM) implementation used and maintained by Fission.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/n0-computer/beetle"&gt;beetle&lt;/a&gt; - Next-generation implementation of IPFS for Cloud &amp;amp; Mobile platforms.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sigp/lighthouse"&gt;Lighthouse&lt;/a&gt; - Ethereum consensus client in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/freenet/locutus"&gt;Locutus&lt;/a&gt; - Global, observable, decentralized key-value store.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openmina/openmina"&gt;OpenMina&lt;/a&gt; - In-browser Mina Rust implementation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qaul/qaul.net"&gt;qaul ŸÇŸàŸÑ&lt;/a&gt; - Internet Independent Wireless Mesh Communication App&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rs-ipfs/rust-ipfs"&gt;rust-ipfs&lt;/a&gt; - IPFS implementation in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/maidsafe/safe_network"&gt;Safe Network&lt;/a&gt; - Safe Network implementation in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/subsquid/sqd-network"&gt;SQD Network&lt;/a&gt; - A decentralized storage for Web3 data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/starcoinorg/starcoin"&gt;Starcoin&lt;/a&gt; - A smart contract blockchain network that scales by layering.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/subspace/subspace"&gt;Subspace&lt;/a&gt; - Subspace Network reference implementation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paritytech/substrate"&gt;Substrate&lt;/a&gt; - Framework for blockchain innovation, used by &lt;a href="https://www.parity.io/technologies/polkadot/"&gt;Polkadot&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/algorealmInc/SwarmNL"&gt;Swarm NL&lt;/a&gt; - A library that makes it easy to configure the networking requirements for any distributed application.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/opencanarias/taple-core"&gt;Taple&lt;/a&gt; - Sustainable DLT for asset and process traceability by &lt;a href="https://www.opencanarias.com/en/"&gt;OpenCanarias&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ceylonai/ceylon"&gt;Ceylon&lt;/a&gt; - A Multi-Agent System (MAS) Development Framework.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/enbop/fungi"&gt;Fungi&lt;/a&gt; - A platform built for seamless multi-device integration.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>facebook/pyrefly</title>
      <link>https://github.com/facebook/pyrefly</link>
      <description>&lt;p&gt;A fast type checker and language server for Python&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Pyrefly: A fast type checker and language server for Python with powerful IDE features&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/facebook/pyrefly"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://pyrefly.org/badge.json" alt="pyrefly" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/pyrefly"&gt;&lt;img src="https://img.shields.io/pypi/v/pyrefly.svg?color=blue" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Cf7mFQtW7W"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-blue.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Pyrefly is a type checker and language server for Python, which provides lightning-fast type checking along with IDE features such as code navigation, semantic highlighting, and code completion. It is available as a &lt;a href="https://pyrefly.org/en/docs/installation/"&gt;command-line tool&lt;/a&gt; and a &lt;a href="https://marketplace.visualstudio.com/items?itemName=meta.pyrefly"&gt;VSCode extension&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://pyrefly.org"&gt;Pyrefly website&lt;/a&gt; for full documentation and how to add Pyrefly to your editor of choice.&lt;/p&gt; 
&lt;p&gt;Currently under active development with known issues. Please open an issue if you find bugs.&lt;/p&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Try out pyrefly in your browser: &lt;a href="https://pyrefly.org/sandbox/"&gt;Sandbox&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Get the command-line tool: &lt;code&gt;pip install pyrefly&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Get the VSCode extension: &lt;a href="https://marketplace.visualstudio.com/items?itemName=meta.pyrefly"&gt;Link&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Features:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Type Inference: Pyrefly infers types in most locations, apart from function parameters. It can infer types of variables and return types.&lt;/li&gt; 
 &lt;li&gt;Flow Types: Pyrefly can understand your program's control flow to refine static types.&lt;/li&gt; 
 &lt;li&gt;Incrementality: Pyrefly aims for large-scale incrementality at the module level, with optimized checking and parallelism.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Involved&lt;/h2&gt; 
&lt;p&gt;If you have questions or would like to report a bug, please &lt;a href="https://github.com/facebook/pyrefly/issues"&gt;create an issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See our &lt;a href="https://github.com/facebook/pyrefly/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for information on how to contribute to Pyrefly.&lt;/p&gt; 
&lt;p&gt;Join our &lt;a href="https://discord.com/invite/Cf7mFQtW7W"&gt;Discord&lt;/a&gt; to chat about Pyrefly and types. This is also where we hold biweekly office hours.&lt;/p&gt; 
&lt;h2&gt;Choices&lt;/h2&gt; 
&lt;p&gt;There are a number of choices when writing a Python type checker. We are taking inspiration from &lt;a href="https://pyre-check.org/"&gt;Pyre1&lt;/a&gt;, &lt;a href="https://github.com/microsoft/pyright"&gt;Pyright&lt;/a&gt; and &lt;a href="https://mypy.readthedocs.io/en/stable/"&gt;MyPy&lt;/a&gt;. Some notable choices:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We infer types in most locations, apart from parameters to functions. We do infer types of variables and return types. As an example, &lt;code&gt;def foo(x): return True&lt;/code&gt; would result in something equivalent to had you written &lt;code&gt;def foo(x: Any) -&amp;gt; bool: ...&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;We attempt to infer the type of &lt;code&gt;[]&lt;/code&gt; to however it is used first, then fix it after. For example &lt;code&gt;xs = []; xs.append(1); xs.append("")&lt;/code&gt; will infer that &lt;code&gt;xs: List[int]&lt;/code&gt; and then error on the final statement.&lt;/li&gt; 
 &lt;li&gt;We use flow types which refine static types, e.g. &lt;code&gt;x: int = 4&lt;/code&gt; will both know that &lt;code&gt;x&lt;/code&gt; has type &lt;code&gt;int&lt;/code&gt;, but also that the immediately next usage of &lt;code&gt;x&lt;/code&gt; will be aware the type is &lt;code&gt;Literal[4]&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;We aim for large-scale incrementality (at the module level) and optimized checking with parallelism, aiming to use the advantages of Rust to keep the code a bit simpler.&lt;/li&gt; 
 &lt;li&gt;We expect large strongly connected components of modules, and do not attempt to take advantage of a DAG-shape in the source code.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Code layout&lt;/h2&gt; 
&lt;p&gt;Pyrefly is split into a number of crates (mostly under &lt;code&gt;crates/&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_util&lt;/code&gt; are general purpose utilities, which have nothing to do with Python or type checking. Examples include IO wrappers, locking, command line helpers etc.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_derive&lt;/code&gt; are proc-macros for deriving traits such as &lt;code&gt;TypeEq&lt;/code&gt; and &lt;code&gt;Visit&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_python&lt;/code&gt; are Python utilities with no type-checking aspects, such as modelling modules or &lt;code&gt;sys.info&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_bundled&lt;/code&gt; are the third-party &lt;a href="https://github.com/python/typeshed"&gt;typeshed stubs&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_config&lt;/code&gt; defines the Pyrefly configuration, along with support for reading Mypy/Pyright configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_types&lt;/code&gt; defines the Pyrefly type along with operations on it.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly_wasm&lt;/code&gt; defines the sandbox code that compiles to WASM.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pyrefly&lt;/code&gt; itself is the type checker and everything else.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Design&lt;/h2&gt; 
&lt;p&gt;There are many nuances of design that change on a regular basis. But the basic substrate on which the checker is built involves three steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Figure out what each module exports. That requires solving all &lt;code&gt;import *&lt;/code&gt; statements transitively.&lt;/li&gt; 
 &lt;li&gt;For each module in isolation, convert it to bindings, dealing with all statements and scope information (both static and flow).&lt;/li&gt; 
 &lt;li&gt;Solve those bindings, which may require the solutions of bindings in other modules.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If we encounter unknowable information (e.g. recursion) we use &lt;code&gt;Type::Var&lt;/code&gt; to insert placeholders which are filled in later.&lt;/p&gt; 
&lt;p&gt;For each module, we solve the steps sequentially and completely. In particular, we do not try and solve a specific identifier first (like &lt;a href="https://github.com/dotnet/roslyn"&gt;Roslyn&lt;/a&gt; or &lt;a href="https://www.typescriptlang.org/"&gt;TypeScript&lt;/a&gt;), and do not use fine-grained incrementality (like &lt;a href="https://github.com/rust-lang/rust-analyzer"&gt;Rust Analyzer&lt;/a&gt; using &lt;a href="https://github.com/salsa-rs/salsa"&gt;Salsa&lt;/a&gt;). Instead, we aim for raw performance and a simpler module-centric design - there's no need to solve a single binding in isolation if solving all bindings in a module is fast enough.&lt;/p&gt; 
&lt;h3&gt;Example of bindings&lt;/h3&gt; 
&lt;p&gt;Given the program:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;1: x: int = 4
2: print(x)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We might produce the bindings:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;define int@0&lt;/code&gt; = &lt;code&gt;from builtins import int&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;define x@1&lt;/code&gt; = &lt;code&gt;4: int@0&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;use x@2&lt;/code&gt; = &lt;code&gt;x@1&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;anon @2&lt;/code&gt; = &lt;code&gt;print(x@2)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export x&lt;/code&gt; = &lt;code&gt;x@2&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Of note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The keys are things like &lt;code&gt;define&lt;/code&gt; (the definition of something), &lt;code&gt;use&lt;/code&gt; (a usage of a thing) and &lt;code&gt;anon&lt;/code&gt; (a statement we need to type check, but don't care about the result of).&lt;/li&gt; 
 &lt;li&gt;In many cases the value of a key refers to other keys.&lt;/li&gt; 
 &lt;li&gt;Some keys are imported from other modules, via &lt;code&gt;export&lt;/code&gt; keys and &lt;code&gt;import&lt;/code&gt; values.&lt;/li&gt; 
 &lt;li&gt;In order to disambiguate identifiers we use the textual position at which they occur (in the example we've used &lt;code&gt;@line&lt;/code&gt;, but in reality it's the byte offset in the file).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Example of &lt;code&gt;Var&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Given the program:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;1: x = 1
2: while test():
3:     x = x
4: print(x)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We end up with the bindings:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;x@1&lt;/code&gt; = &lt;code&gt;1&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;x@3&lt;/code&gt; = &lt;code&gt;phi(x@1, x@3)&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;x@4&lt;/code&gt; = &lt;code&gt;phi(x@1, x@3)&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The expression &lt;code&gt;phi&lt;/code&gt; is the join point of the two values, e.g. &lt;code&gt;phi(int, str)&lt;/code&gt; would be &lt;code&gt;int | str&lt;/code&gt;. We skip the distinction between &lt;code&gt;define&lt;/code&gt; and &lt;code&gt;use&lt;/code&gt;, since it is not necessary for this example.&lt;/p&gt; 
&lt;p&gt;When solving &lt;code&gt;x@3&lt;/code&gt; we encounter recursion. Operationally:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;We start solving &lt;code&gt;x@3&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;That requires us to solve &lt;code&gt;x@1&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;We solve &lt;code&gt;x@1&lt;/code&gt; to be &lt;code&gt;Literal[1]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;We start solving &lt;code&gt;x@3&lt;/code&gt;. But we are currently solving &lt;code&gt;x@3&lt;/code&gt;, so we invent a fresh &lt;code&gt;Var&lt;/code&gt; (let's call it &lt;code&gt;?1&lt;/code&gt;) and return that.&lt;/li&gt; 
 &lt;li&gt;We conclude that &lt;code&gt;x@3&lt;/code&gt; must be &lt;code&gt;Literal[1] | ?1&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Since &lt;code&gt;?1&lt;/code&gt; was introduced by &lt;code&gt;x@3&lt;/code&gt; we record that &lt;code&gt;?1 = Literal[1] | ?1&lt;/code&gt;. We can take the upper reachable bound of that and conclude that &lt;code&gt;?1 = Literal[1]&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;We simplify &lt;code&gt;x@3&lt;/code&gt; to just &lt;code&gt;Literal[1]&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>crate-ci/typos</title>
      <link>https://github.com/crate-ci/typos</link>
      <description>&lt;p&gt;Source code spell checker&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;typos&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Source code spell checker&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Finds and corrects spelling mistakes among source code:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fast enough to run on monorepos&lt;/li&gt; 
 &lt;li&gt;Low false positives so you can run on PRs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/crate-ci/typos/master/docs/screenshot.png" alt="Screenshot" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/crate-ci/typos/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/crate-ci/typos/total.svg?sanitize=true" alt="Downloads" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/crate-ci/typos"&gt;&lt;img src="https://codecov.io/gh/crate-ci/typos/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://docs.rs/typos"&gt;&lt;img src="https://img.shields.io/badge/docs-master-blue.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/crates/l/typos.svg?sanitize=true" alt="License" /&gt; &lt;a href="https://crates.io/crates/typos-cli"&gt;&lt;img src="https://img.shields.io/crates/v/typos.svg?sanitize=true" alt="Crates Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Dual-licensed under &lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/LICENSE-MIT"&gt;MIT&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/LICENSE-APACHE"&gt;Apache 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/#install"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/#getting-started"&gt;Getting Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/#false-positives"&gt;False Positives&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/#integrations"&gt;Integrations&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/docs/github-action.md"&gt;GitHub Action&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/docs/pre-commit.md"&gt;pre-commit&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/#custom"&gt;Custom&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/#debugging"&gt;Debugging&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/docs/reference.md"&gt;Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/#faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/docs/comparison.md"&gt;Comparison with other spell checkers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crate-ci/typos/wiki"&gt;Projects using typos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/benchsuite/runs"&gt;Benchmarks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/docs/design.md"&gt;Design&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/CONTRIBUTING.md"&gt;Contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/crate-ci/typos/releases"&gt;Download&lt;/a&gt; a pre-built binary (installable via &lt;a href="https://github.com/crate-ci/gh-install"&gt;gh-install&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Or use rust to install:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ cargo install typos-cli --locked
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use &lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt; to install:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ brew install typos-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use &lt;a href="https://conda.io/"&gt;Conda&lt;/a&gt; to install:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ conda install typos
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use &lt;a href="https://wiki.archlinux.org/title/pacman"&gt;Pacman&lt;/a&gt; to install:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ sudo pacman -S typos
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Most commonly, you'll either want to see what typos are available with&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ typos
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or have them fixed&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ typos --write-changes
$ typos -w
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If there is any ambiguity (multiple possible corrections), &lt;code&gt;typos&lt;/code&gt; will just report it to the user and move on.&lt;/p&gt; 
&lt;h3&gt;False Positives&lt;/h3&gt; 
&lt;p&gt;Sometimes, what looks like a typo is intentional, like with people's names, acronyms, or localized content.&lt;/p&gt; 
&lt;p&gt;To mark a word or an identifier (grouping of words) as valid, add it to your &lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/docs/reference.md"&gt;&lt;code&gt;_typos.toml&lt;/code&gt;&lt;/a&gt; by declaring itself as the valid spelling:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[default]
extend-ignore-identifiers-re = [
    # *sigh* this just isn't worth the cost of fixing
    "AttributeID.*Supress.*",
]

[default.extend-identifiers]
# *sigh* this just isn't worth the cost of fixing
AttributeIDSupressMenu = "AttributeIDSupressMenu"

[default.extend-words]
# Don't correct the surname "Teh"
teh = "teh"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more ways to ignore or extend the dictionary with examples, see the &lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/docs/reference.md"&gt;config reference&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For cases like localized content, you can disable spell checking of file contents while still checking the file name:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[type.po]
extend-glob = ["*.po"]
check-file = false
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;(run &lt;code&gt;typos --type-list&lt;/code&gt; to see configured file types)&lt;/p&gt; 
&lt;p&gt;If you need some more flexibility, you can completely exclude some files from consideration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[files]
extend-exclude = ["localized/*.po"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Integrations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/docs/github-action.md"&gt;GitHub Actions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/docs/pre-commit.md"&gt;pre-commit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/putoutjs/putout-processor-typos"&gt;üêäPutout Processor&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tekumara/typos-vscode"&gt;Visual Studio Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tekumara/typos-vscode"&gt;typos-lsp (Language Server Protocol server)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Custom&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;typos&lt;/code&gt; provides several building blocks for custom native integrations&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-&lt;/code&gt; reads from &lt;code&gt;stdin&lt;/code&gt;, &lt;code&gt;--write-changes&lt;/code&gt; will be written to &lt;code&gt;stdout&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--diff&lt;/code&gt; to provide a diff&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--format json&lt;/code&gt; to get jsonlines with exit code 0 on no errors, code 2 on typos, anything else is an error.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ # Read file from stdin, write corrected version to stdout
$ typos - --write-changes
$ # Creates a diff of what would change
$ typos dir/file --diff
$ # Fully programmatic control
$ typos dir/file --format json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Debugging&lt;/h3&gt; 
&lt;p&gt;You can see what the effective config looks like by running&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ typos --dump-config -
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then see how typos is processing your project with&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ typos --files
$ typos --identifiers
$ typos --words
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you need to dig in more, you can enable debug logging with &lt;code&gt;-v&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;Why was ... not corrected?&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Does the file show up in &lt;code&gt;typos --files&lt;/code&gt;?&lt;/strong&gt; If not, check your config with &lt;code&gt;typos --dump-config -&lt;/code&gt;. The &lt;code&gt;[files]&lt;/code&gt; table controls how we walk files. If you are using &lt;code&gt;files.extend-exclude&lt;/code&gt;, are you running into &lt;a href="https://github.com/crate-ci/typos/issues/593"&gt;#593&lt;/a&gt;? If you are using &lt;code&gt;files.ignore-vcs = true&lt;/code&gt;, is the file in your &lt;code&gt;.gitignore&lt;/code&gt; but git tracks it anyways? Prefer allowing the file explicitly (see &lt;a href="https://github.com/crate-ci/typos/issues/909"&gt;#909&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Does the identifier show up in &lt;code&gt;typos --identifiers&lt;/code&gt; or the word show up in &lt;code&gt;typos --words&lt;/code&gt;?&lt;/strong&gt; If not, it might be subject to one of typos' heuristics for detecting non-words (like hashes) or unambiguous words (like words after a &lt;code&gt;\&lt;/code&gt; escape).&lt;/p&gt; 
&lt;p&gt;If it is showing up, likely &lt;code&gt;typos&lt;/code&gt; doesn't know about it yet.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;typos&lt;/code&gt; maintains a list of known typo corrections to keep the false positive count low so it can safely run unassisted.&lt;/p&gt; 
&lt;p&gt;This is in contrast to most spell checking UIs people use where there is a known list of valid words. In this case, the spell checker tries to guess your intent by finding the closest-looking word. It then has a gauge for when a word isn't close enough and assumes you know best. The user has the opportunity to verify these corrections and explicitly allow or reject them.&lt;/p&gt; 
&lt;p&gt;For more on the trade offs of these approaches, see &lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/docs/design.md"&gt;Design&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;To correct it locally, see also our &lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/#false-positives"&gt;False Positives documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;To contribute your correction, see &lt;a href="https://raw.githubusercontent.com/crate-ci/typos/master/CONTRIBUTING.md"&gt;Contribute&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>meilisearch/meilisearch</title>
      <link>https://github.com/meilisearch/meilisearch</link>
      <description>&lt;p&gt;A lightning-fast search engine API bringing AI-powered hybrid search to your sites and applications.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=logo#gh-light-mode-only" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/meilisearch/meilisearch/main/assets/meilisearch-logo-light.svg?sanitize=true#gh-light-mode-only" /&gt; &lt;/a&gt; &lt;a href="https://www.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=logo#gh-dark-mode-only" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/meilisearch/meilisearch/main/assets/meilisearch-logo-dark.svg?sanitize=true#gh-dark-mode-only" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://www.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;Website&lt;/a&gt; | &lt;a href="https://roadmap.meilisearch.com/tabs/1-under-consideration"&gt;Roadmap&lt;/a&gt; | &lt;a href="https://www.meilisearch.com/pricing?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;Meilisearch Cloud&lt;/a&gt; | &lt;a href="https://blog.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;Blog&lt;/a&gt; | &lt;a href="https://www.meilisearch.com/docs?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;Documentation&lt;/a&gt; | &lt;a href="https://www.meilisearch.com/docs/faq?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;FAQ&lt;/a&gt; | &lt;a href="https://discord.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;Discord&lt;/a&gt; &lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a href="https://deps.rs/repo/github/meilisearch/meilisearch"&gt;&lt;img src="https://deps.rs/repo/github/meilisearch/meilisearch/status.svg?sanitize=true" alt="Dependency status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/meilisearch/meilisearch/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-informational" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/meilisearch/meilisearch/queue"&gt;&lt;img alt="Merge Queues enabled" src="https://img.shields.io/badge/Merge_Queues-enabled-%2357cf60?logo=github" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;‚ö° A lightning-fast search engine that fits effortlessly into your apps, websites, and workflow üîç&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.meilisearch.com?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=intro"&gt;Meilisearch&lt;/a&gt; helps you shape a delightful search experience in a snap, offering features that work out of the box to speed up your workflow.&lt;/p&gt; 
&lt;p align="center" name="demo"&gt; &lt;a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demo-gif#gh-light-mode-only" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/meilisearch/meilisearch/main/assets/demo-light.gif#gh-light-mode-only" alt="A bright colored application for finding movies screening near the user" /&gt; &lt;/a&gt; &lt;a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demo-gif#gh-dark-mode-only" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/meilisearch/meilisearch/main/assets/demo-dark.gif#gh-dark-mode-only" alt="A dark colored application for finding movies screening near the user" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üñ• Examples&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=organization"&gt;&lt;strong&gt;Movies&lt;/strong&gt;&lt;/a&gt; ‚Äî An application to help you find streaming platforms to watch movies using &lt;a href="https://www.meilisearch.com/solutions/hybrid-search?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;hybrid search&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://flickr.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=organization"&gt;&lt;strong&gt;Flickr&lt;/strong&gt;&lt;/a&gt; ‚Äî Search and explore one hundred million Flickr images with semantic search.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ecommerce.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;&lt;strong&gt;Ecommerce&lt;/strong&gt;&lt;/a&gt; ‚Äî Ecommerce website using disjunctive &lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;facets&lt;/a&gt;, range and rating filtering, and pagination.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://music.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;&lt;strong&gt;Songs&lt;/strong&gt;&lt;/a&gt; ‚Äî Search through 47 million of songs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://saas.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;&lt;strong&gt;SaaS&lt;/strong&gt;&lt;/a&gt; ‚Äî Search for contacts, deals, and companies in this &lt;a href="https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;multi-tenant&lt;/a&gt; CRM application.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the list of all our example apps in our &lt;a href="https://github.com/meilisearch/demos"&gt;demos repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;‚ú® Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hybrid search:&lt;/strong&gt; Combine the best of both &lt;a href="https://www.meilisearch.com/docs/learn/experimental/vector_search?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;semantic&lt;/a&gt; &amp;amp; full-text search to get the most relevant results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search-as-you-type:&lt;/strong&gt; Find &amp;amp; display results in less than 50 milliseconds to provide an intuitive experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/relevancy/typo_tolerance_settings?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Typo tolerance&lt;/a&gt;:&lt;/strong&gt; get relevant matches even when queries contain typos and misspellings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Filtering&lt;/a&gt; and &lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;faceted search&lt;/a&gt;:&lt;/strong&gt; enhance your users' search experience with custom filters and build a faceted search interface in a few lines of code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Sorting&lt;/a&gt;:&lt;/strong&gt; sort results based on price, date, or pretty much anything else your users need&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/relevancy/synonyms?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Synonym support&lt;/a&gt;:&lt;/strong&gt; configure synonyms to include more relevant content in your search results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Geosearch&lt;/a&gt;:&lt;/strong&gt; filter and sort documents based on geographic data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/language?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Extensive language support&lt;/a&gt;:&lt;/strong&gt; search datasets in any language, with optimized support for Chinese, Japanese, Hebrew, and languages using the Latin alphabet&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Security management&lt;/a&gt;:&lt;/strong&gt; control which users can access what data with API keys that allow fine-grained permissions handling&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Multi-Tenancy&lt;/a&gt;:&lt;/strong&gt; personalize search results for any number of application tenants&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Highly Customizable:&lt;/strong&gt; customize Meilisearch to your specific needs or use our out-of-the-box and hassle-free presets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;RESTful API&lt;/a&gt;:&lt;/strong&gt; integrate Meilisearch in your technical stack with our plugins and SDKs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI-ready:&lt;/strong&gt; works out of the box with &lt;a href="https://www.meilisearch.com/with/langchain"&gt;langchain&lt;/a&gt; and the &lt;a href="https://github.com/meilisearch/meilisearch-mcp"&gt;model context protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy to install, deploy, and maintain&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;p&gt;You can consult Meilisearch's documentation at &lt;a href="https://www.meilisearch.com/docs/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=docs"&gt;meilisearch.com/docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üöÄ Getting started&lt;/h2&gt; 
&lt;p&gt;For basic instructions on how to set up Meilisearch, add documents to an index, and search for documents, take a look at our &lt;a href="https://www.meilisearch.com/docs?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=get-started"&gt;documentation&lt;/a&gt; guide.&lt;/p&gt; 
&lt;h2&gt;üåç Supercharge your Meilisearch experience&lt;/h2&gt; 
&lt;p&gt;Say goodbye to server deployment and manual updates with &lt;a href="https://www.meilisearch.com/cloud?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch"&gt;Meilisearch Cloud&lt;/a&gt;. Additional features include analytics &amp;amp; monitoring in many regions around the world. No credit card is required.&lt;/p&gt; 
&lt;h2&gt;üß∞ SDKs &amp;amp; integration tools&lt;/h2&gt; 
&lt;p&gt;Install one of our SDKs in your project for seamless integration between Meilisearch and your favorite language or framework!&lt;/p&gt; 
&lt;p&gt;Take a look at the complete &lt;a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=sdks-link"&gt;Meilisearch integration list&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=sdks-logos"&gt;&lt;img src="https://raw.githubusercontent.com/meilisearch/meilisearch/main/assets/integrations.png" alt="Logos belonging to different languages and frameworks supported by Meilisearch, including React, Ruby on Rails, Go, Rust, and PHP" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚öôÔ∏è Advanced usage&lt;/h2&gt; 
&lt;p&gt;Experienced users will want to keep our &lt;a href="https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;API Reference&lt;/a&gt; close at hand.&lt;/p&gt; 
&lt;p&gt;We also offer a wide range of dedicated guides to all Meilisearch features, such as &lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;filtering&lt;/a&gt;, &lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;sorting&lt;/a&gt;, &lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;geosearch&lt;/a&gt;, &lt;a href="https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;API keys&lt;/a&gt;, and &lt;a href="https://www.meilisearch.com/docs/learn/security/tenant_tokens?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;tenant tokens&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Finally, for more in-depth information, refer to our articles explaining fundamental Meilisearch concepts such as &lt;a href="https://www.meilisearch.com/docs/learn/core_concepts/documents?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;documents&lt;/a&gt; and &lt;a href="https://www.meilisearch.com/docs/learn/core_concepts/indexes?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;indexes&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üßæ Editions &amp;amp; Licensing&lt;/h2&gt; 
&lt;p&gt;Meilisearch is available in two editions:&lt;/p&gt; 
&lt;h3&gt;üß™ Community Edition (CE)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fully open source under the &lt;a href="https://raw.githubusercontent.com/meilisearch/meilisearch/main/LICENSE"&gt;MIT license&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Core search engine with fast and relevant full-text, semantic or hybrid search&lt;/li&gt; 
 &lt;li&gt;Free to use for anyone, including commercial usage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üè¢ Enterprise Edition (EE)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Includes advanced features such as: 
  &lt;ul&gt; 
   &lt;li&gt;Sharding&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Governed by a &lt;a href="https://raw.githubusercontent.com/meilisearch/meilisearch/main/LICENSE-EE"&gt;commercial license&lt;/a&gt; or the &lt;a href="https://mariadb.com/bsl11"&gt;Business Source License 1.1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Not allowed in production without a commercial agreement with Meilisearch. 
  &lt;ul&gt; 
   &lt;li&gt;You may use, modify, and distribute the Licensed Work for non-production purposes only, such as testing, development, or evaluation.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Want access to Enterprise features? ‚Üí Contact us at &lt;a href="maito:sales@meilisearch.com"&gt;sales@meilisearch.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìä Telemetry&lt;/h2&gt; 
&lt;p&gt;Meilisearch collects &lt;strong&gt;anonymized&lt;/strong&gt; user data to help us improve our product. You can &lt;a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=telemetry#how-to-disable-data-collection"&gt;deactivate this&lt;/a&gt; whenever you want.&lt;/p&gt; 
&lt;p&gt;To request deletion of collected data, please write to us at &lt;a href="mailto:privacy@meilisearch.com"&gt;privacy@meilisearch.com&lt;/a&gt;. Remember to include your &lt;code&gt;Instance UID&lt;/code&gt; in the message, as this helps us quickly find and delete your data.&lt;/p&gt; 
&lt;p&gt;If you want to know more about the kind of data we collect and what we use it for, check the &lt;a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=telemetry#how-to-disable-data-collection"&gt;telemetry section&lt;/a&gt; of our documentation.&lt;/p&gt; 
&lt;h2&gt;üì´ Get in touch!&lt;/h2&gt; 
&lt;p&gt;Meilisearch is a search engine created by &lt;a href="https://www.meilisearch.com/careers"&gt;Meili&lt;/a&gt;, a software development company headquartered in France and with team members all over the world. Want to know more about us? &lt;a href="https://blog.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=contact"&gt;Check out our blog!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;üóû &lt;a href="https://share-eu1.hsforms.com/1LN5N0x_GQgq7ss7tXmSykwfg3aq"&gt;Subscribe to our newsletter&lt;/a&gt; if you don't want to miss any updates! We promise we won't clutter your mailbox: we only send one edition every two months.&lt;/p&gt; 
&lt;p&gt;üíå Want to make a suggestion or give feedback? Here are some of the channels where you can reach us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For feature requests, please visit our &lt;a href="https://github.com/meilisearch/product/discussions"&gt;product repository&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Found a bug? Open an &lt;a href="https://github.com/meilisearch/meilisearch/issues"&gt;issue&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;Want to be part of our Discord community? &lt;a href="https://discord.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=contact"&gt;Join us!&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Thank you for your support!&lt;/p&gt; 
&lt;h2&gt;üë©‚Äçüíª Contributing&lt;/h2&gt; 
&lt;p&gt;Meilisearch is, and will always be, open-source! If you want to contribute to the project, please look at &lt;a href="https://raw.githubusercontent.com/meilisearch/meilisearch/main/CONTRIBUTING.md"&gt;our contribution guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üì¶ Versioning&lt;/h2&gt; 
&lt;p&gt;Meilisearch releases and their associated binaries are available on the project's &lt;a href="https://github.com/meilisearch/meilisearch/releases"&gt;releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The binaries are versioned following &lt;a href="https://semver.org/"&gt;SemVer conventions&lt;/a&gt;. To know more, read our &lt;a href="https://raw.githubusercontent.com/meilisearch/meilisearch/main/documentation/versioning-policy.md"&gt;versioning policy&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Differently from the binaries, crates in this repository are not currently available on &lt;a href="https://crates.io/"&gt;crates.io&lt;/a&gt; and do not follow &lt;a href="https://semver.org"&gt;SemVer conventions&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>