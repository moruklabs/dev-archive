<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Thu, 02 Oct 2025 01:30:38 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>Done-0/fuck-u-code</title>
      <link>https://github.com/Done-0/fuck-u-code</link>
      <description>&lt;p&gt;Legacy-Mess Detector – assess the “legacy-mess level” of your code and output a beautiful report | 屎山代码检测器，评估代码的“屎山等级”并输出美观的报告&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;fuck-u-code &lt;a href="https://raw.githubusercontent.com/Done-0/fuck-u-code/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/%E6%96%87%E6%A1%A3-%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-blue?style=flat-square" alt="中文" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Done-0/fuck-u-code/main/README_EN.md"&gt;&lt;img src="https://img.shields.io/badge/Docs-English-red?style=flat-square" alt="English" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Done-0/fuck-u-code/main/README_RU.md"&gt;&lt;img src="https://img.shields.io/badge/Docs-%D0%A0%D1%83%D1%81%D1%81%D0%BA%D0%B8%D0%B9-blue?style=flat-square" alt="Русский" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] 📢 记住这个命令：fuck-u-code - 让代码不再烂到发指！&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;一款专门揭露屎山代码的质量分析工具，用犀利又搞笑的方式告诉你：&lt;strong&gt;你的代码到底有多烂&lt;/strong&gt;。&lt;/p&gt; 
&lt;h2&gt;特性&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;多语言支持&lt;/strong&gt;: Go、JS/TS、Python、Java、C/C++&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;屎山指数&lt;/strong&gt;: 0~100 分，越高越烂&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;七维度检测&lt;/strong&gt;: 复杂度 / 函数长度 / 注释率 / 错误处理 / 命名 / 重复度 / 结构&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;彩色终端报告&lt;/strong&gt;: 批评也能笑着听&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Markdown 输出&lt;/strong&gt;: 方便 AI 分析与文档集成&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;灵活配置&lt;/strong&gt;: 摘要 / 详细模式，多语言报告&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note]&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;分数越高越烂，欢迎“高分大佬”上榜&lt;/li&gt; 
  &lt;li&gt;全程本地运行，不上传代码，安全无忧&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;安装&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 方法一：Go 安装
go install github.com/Done-0/fuck-u-code/cmd/fuck-u-code@latest

# 方法二：源码构建
git clone https://github.com/Done-0/fuck-u-code.git
cd fuck-u-code &amp;amp;&amp;amp; go build -o fuck-u-code ./cmd/fuck-u-code

# 方法三：Docker 构建
docker build -t fuck-u-code .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;使用方法&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 基本分析
fuck-u-code analyze /path/to/project
# 或
fuck-u-code /path/to/project

# Docker 运行
docker run --rm -v "/path/to/project:/build" fuck-u-code analyze

# 默认分析当前目录
fuck-u-code analyze
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;常用选项&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;选项&lt;/th&gt; 
   &lt;th&gt;简写&lt;/th&gt; 
   &lt;th&gt;描述&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--verbose&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;-v&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;显示详细报告&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--top N&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;-t&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;最烂的前 N 个文件&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--issues N&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;-i&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;每文件显示 N 个问题&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--summary&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;-s&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;只看总结，不看过程&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--markdown&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;-m&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;输出 Markdown 格式报告&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--lang&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;-l&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;报告语言 (zh-CN/en-US/ru-RU)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--exclude&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;-e&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;排除指定目录或文件&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--skipindex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;-x&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;跳过 index.js/ts 文件&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;示例&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fuck-u-code analyze --verbose
fuck-u-code analyze --top 3
fuck-u-code analyze --lang en-US
fuck-u-code analyze --summary
fuck-u-code analyze --exclude "**/test/**"
fuck-u-code analyze --markdown &amp;gt; report.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;高级用法&lt;/h2&gt; 
&lt;h3&gt;Markdown 输出&lt;/h3&gt; 
&lt;p&gt;适合 &lt;strong&gt;AI 分析、文档集成、CI/CD、团队协作&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;fuck-u-code analyze --markdown
fuck-u-code analyze --markdown &amp;gt; report.md
fuck-u-code analyze --markdown --top 10 --lang en-US &amp;gt; report.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Markdown 报告包含：总体评分 / 指标表格 / 问题文件 / 改进建议&lt;/p&gt; 
&lt;h3&gt;默认排除路径&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;前端: &lt;code&gt;node_modules&lt;/code&gt;、&lt;code&gt;dist&lt;/code&gt;、&lt;code&gt;build&lt;/code&gt;、&lt;code&gt;*.min.js&lt;/code&gt; 等&lt;/li&gt; 
 &lt;li&gt;后端: &lt;code&gt;vendor&lt;/code&gt;、&lt;code&gt;bin&lt;/code&gt;、&lt;code&gt;target&lt;/code&gt;、&lt;code&gt;logs&lt;/code&gt;、&lt;code&gt;migrations&lt;/code&gt; 等&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;疑难解答&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;command not found&lt;/code&gt; → 把 Go bin 路径加到 &lt;code&gt;PATH&lt;/code&gt;：&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;export PATH="$PATH:$(go env GOPATH)/bin"
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;并写入 &lt;code&gt;.bash_profile&lt;/code&gt; / &lt;code&gt;.zshrc&lt;/code&gt; 等&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;许可证&lt;/h2&gt; 
&lt;p&gt;MIT&lt;/p&gt; 
&lt;h2&gt;贡献&lt;/h2&gt; 
&lt;p&gt;欢迎提 PR，一起优化“fuck-u-code” 🚀&lt;/p&gt; 
&lt;h2&gt;安利一下&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bazi.site"&gt;玄学工坊&lt;/a&gt; — AI 赛博算命网站&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Done-0/Jank"&gt;Jank&lt;/a&gt; — Go 语言开源博客&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>harry0703/MoneyPrinterTurbo</title>
      <link>https://github.com/harry0703/MoneyPrinterTurbo</link>
      <description>&lt;p&gt;利用AI大模型，一键生成高清短视频 Generate short videos with one click using AI LLM.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1 align="center"&gt;MoneyPrinterTurbo 💸&lt;/h1&gt; 
 &lt;p align="center"&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;&lt;img src="https://img.shields.io/github/issues/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="License" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;简体中文 | &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/README-en.md"&gt;English&lt;/a&gt;&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/8731" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/8731" alt="harry0703%2FMoneyPrinterTurbo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 只需提供一个视频 
 &lt;b&gt;主题&lt;/b&gt; 或 
 &lt;b&gt;关键词&lt;/b&gt; ，就可以全自动生成视频文案、视频素材、视频字幕、视频背景音乐，然后合成一个高清的短视频。 
 &lt;br /&gt; 
 &lt;h4&gt;Web界面&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/webui.jpg" alt="" /&gt;&lt;/p&gt; 
 &lt;h4&gt;API界面&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/api.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;特别感谢 🙏&lt;/h2&gt; 
&lt;p&gt;由于该项目的 &lt;strong&gt;部署&lt;/strong&gt; 和 &lt;strong&gt;使用&lt;/strong&gt;，对于一些小白用户来说，还是 &lt;strong&gt;有一定的门槛&lt;/strong&gt;，在此特别感谢 &lt;strong&gt;录咖（AI智能 多媒体服务平台）&lt;/strong&gt; 网站基于该项目，提供的免费&lt;code&gt;AI视频生成器&lt;/code&gt;服务，可以不用部署，直接在线使用，非常方便。&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;中文版：&lt;a href="https://reccloud.cn"&gt;https://reccloud.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;英文版：&lt;a href="https://reccloud.com"&gt;https://reccloud.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/reccloud.cn.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;感谢赞助 🙏&lt;/h2&gt; 
&lt;p&gt;感谢佐糖 &lt;a href="https://picwish.cn"&gt;https://picwish.cn&lt;/a&gt; 对该项目的支持和赞助，使得该项目能够持续的更新和维护。&lt;/p&gt; 
&lt;p&gt;佐糖专注于&lt;strong&gt;图像处理领域&lt;/strong&gt;，提供丰富的&lt;strong&gt;图像处理工具&lt;/strong&gt;，将复杂操作极致简化，真正实现让图像处理更简单。&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/picwish.jpg" alt="picwish.jpg" /&gt;&lt;/p&gt; 
&lt;h2&gt;功能特性 🎯&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 完整的 &lt;strong&gt;MVC架构&lt;/strong&gt;，代码 &lt;strong&gt;结构清晰&lt;/strong&gt;，易于维护，支持 &lt;code&gt;API&lt;/code&gt; 和 &lt;code&gt;Web界面&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持视频文案 &lt;strong&gt;AI自动生成&lt;/strong&gt;，也可以&lt;strong&gt;自定义文案&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持多种 &lt;strong&gt;高清视频&lt;/strong&gt; 尺寸 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 竖屏 9:16，&lt;code&gt;1080x1920&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 横屏 16:9，&lt;code&gt;1920x1080&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;批量视频生成&lt;/strong&gt;，可以一次生成多个视频，然后选择一个最满意的&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;视频片段时长&lt;/strong&gt; 设置，方便调节素材切换频率&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;中文&lt;/strong&gt; 和 &lt;strong&gt;英文&lt;/strong&gt; 视频文案&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;多种语音&lt;/strong&gt; 合成，可 &lt;strong&gt;实时试听&lt;/strong&gt; 效果&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;字幕生成&lt;/strong&gt;，可以调整 &lt;code&gt;字体&lt;/code&gt;、&lt;code&gt;位置&lt;/code&gt;、&lt;code&gt;颜色&lt;/code&gt;、&lt;code&gt;大小&lt;/code&gt;，同时支持&lt;code&gt;字幕描边&lt;/code&gt;设置&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;背景音乐&lt;/strong&gt;，随机或者指定音乐文件，可设置&lt;code&gt;背景音乐音量&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 视频素材来源 &lt;strong&gt;高清&lt;/strong&gt;，而且 &lt;strong&gt;无版权&lt;/strong&gt;，也可以使用自己的 &lt;strong&gt;本地素材&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 支持 &lt;strong&gt;OpenAI&lt;/strong&gt;、&lt;strong&gt;Moonshot&lt;/strong&gt;、&lt;strong&gt;Azure&lt;/strong&gt;、&lt;strong&gt;gpt4free&lt;/strong&gt;、&lt;strong&gt;one-api&lt;/strong&gt;、&lt;strong&gt;通义千问&lt;/strong&gt;、&lt;strong&gt;Google Gemini&lt;/strong&gt;、&lt;strong&gt;Ollama&lt;/strong&gt;、&lt;strong&gt;DeepSeek&lt;/strong&gt;、 &lt;strong&gt;文心一言&lt;/strong&gt;, &lt;strong&gt;Pollinations&lt;/strong&gt; 等多种模型接入 
  &lt;ul&gt; 
   &lt;li&gt;中国用户建议使用 &lt;strong&gt;DeepSeek&lt;/strong&gt; 或 &lt;strong&gt;Moonshot&lt;/strong&gt; 作为大模型提供商（国内可直接访问，不需要VPN。注册就送额度，基本够用）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;后期计划 📅&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; GPT-SoVITS 配音支持&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 优化语音合成，利用大模型，使其合成的声音，更加自然，情绪更加丰富&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 增加视频转场效果，使其看起来更加的流畅&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 增加更多视频素材来源，优化视频素材和文案的匹配度&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 增加视频长度选项：短、中、长&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 支持更多的语音合成服务商，比如 OpenAI TTS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 自动上传到YouTube平台&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;视频演示 📺&lt;/h2&gt; 
&lt;h3&gt;竖屏 9:16&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt; 《如何增加生活的乐趣》&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt; 《金钱的作用》&lt;br /&gt;更真实的合成声音&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt; 《生命的意义是什么》&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/a84d33d5-27a2-4aba-8fd0-9fb2bd91c6a6"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/af2f3b0b-002e-49fe-b161-18ba91c055e8"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/112c9564-d52b-4472-99ad-970b75f66476"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;横屏 16:9&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt;《生命的意义是什么》&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ▶️
    &lt;/g-emoji&gt;《为什么要运动》&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/346ebb15-c55f-47a9-a653-114f08bb8073"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/271f2fae-8283-44a0-8aa0-0ed8f9a6fa87"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;配置要求 📦&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;建议最低 CPU &lt;strong&gt;4核&lt;/strong&gt; 或以上，内存 &lt;strong&gt;4G&lt;/strong&gt; 或以上，显卡非必须&lt;/li&gt; 
 &lt;li&gt;Windows 10 或 MacOS 11.0 以上系统&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;快速开始 🚀&lt;/h2&gt; 
&lt;h3&gt;在 Google Colab 中运行&lt;/h3&gt; 
&lt;p&gt;免去本地环境配置，点击直接在 Google Colab 中快速体验 MoneyPrinterTurbo&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/github/harry0703/MoneyPrinterTurbo/blob/main/docs/MoneyPrinterTurbo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open in Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windows一键启动包&lt;/h3&gt; 
&lt;p&gt;下载一键启动包，解压直接使用（路径不要有 &lt;strong&gt;中文&lt;/strong&gt;、&lt;strong&gt;特殊字符&lt;/strong&gt;、&lt;strong&gt;空格&lt;/strong&gt;）&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;百度网盘（v1.2.6）: &lt;a href="https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx"&gt;https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx&lt;/a&gt; 提取码: sbqx&lt;/li&gt; 
 &lt;li&gt;Google Drive (v1.2.6): &lt;a href="https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing"&gt;https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;下载后，建议先&lt;strong&gt;双击执行&lt;/strong&gt; &lt;code&gt;update.bat&lt;/code&gt; 更新到&lt;strong&gt;最新代码&lt;/strong&gt;，然后双击 &lt;code&gt;start.bat&lt;/code&gt; 启动&lt;/p&gt; 
&lt;p&gt;启动后，会自动打开浏览器（如果打开是空白，建议换成 &lt;strong&gt;Chrome&lt;/strong&gt; 或者 &lt;strong&gt;Edge&lt;/strong&gt; 打开）&lt;/p&gt; 
&lt;h2&gt;安装部署 📥&lt;/h2&gt; 
&lt;h3&gt;前提条件&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;尽量不要使用 &lt;strong&gt;中文路径&lt;/strong&gt;，避免出现一些无法预料的问题&lt;/li&gt; 
 &lt;li&gt;请确保你的 &lt;strong&gt;网络&lt;/strong&gt; 是正常的，VPN需要打开&lt;code&gt;全局流量&lt;/code&gt;模式&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;① 克隆代码&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;② 修改配置文件（可选，建议启动后也可以在 WebUI 里面配置）&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;将 &lt;code&gt;config.example.toml&lt;/code&gt; 文件复制一份，命名为 &lt;code&gt;config.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;按照 &lt;code&gt;config.toml&lt;/code&gt; 文件中的说明，配置好 &lt;code&gt;pexels_api_keys&lt;/code&gt; 和 &lt;code&gt;llm_provider&lt;/code&gt;，并根据 llm_provider 对应的服务商，配置相关的 API Key&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Docker部署 🐳&lt;/h3&gt; 
&lt;h4&gt;① 启动Docker&lt;/h4&gt; 
&lt;p&gt;如果未安装 Docker，请先安装 &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;https://www.docker.com/products/docker-desktop/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;如果是Windows系统，请参考微软的文档：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/install"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd MoneyPrinterTurbo
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注意：最新版的docker安装时会自动以插件的形式安装docker compose，启动命令调整为docker compose up&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;② 访问Web界面&lt;/h4&gt; 
&lt;p&gt;打开浏览器，访问 &lt;a href="http://0.0.0.0:8501"&gt;http://0.0.0.0:8501&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;③ 访问API文档&lt;/h4&gt; 
&lt;p&gt;打开浏览器，访问 &lt;a href="http://0.0.0.0:8080/docs"&gt;http://0.0.0.0:8080/docs&lt;/a&gt; 或者 &lt;a href="http://0.0.0.0:8080/redoc"&gt;http://0.0.0.0:8080/redoc&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;手动部署 📦&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;视频教程&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;完整的使用演示：&lt;a href="https://v.douyin.com/iFhnwsKY/"&gt;https://v.douyin.com/iFhnwsKY/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;如何在Windows上部署：&lt;a href="https://v.douyin.com/iFyjoW3M"&gt;https://v.douyin.com/iFyjoW3M&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;① 创建虚拟环境&lt;/h4&gt; 
&lt;p&gt;建议使用 &lt;a href="https://conda.io/projects/conda/en/latest/user-guide/install/index.html"&gt;conda&lt;/a&gt; 创建 python 虚拟环境&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
cd MoneyPrinterTurbo
conda create -n MoneyPrinterTurbo python=3.11
conda activate MoneyPrinterTurbo
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;② 安装好 ImageMagick&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;下载 &lt;a href="https://imagemagick.org/script/download.php"&gt;https://imagemagick.org/script/download.php&lt;/a&gt; 选择Windows版本，切记一定要选择 &lt;strong&gt;静态库&lt;/strong&gt; 版本，比如 ImageMagick-7.1.1-32-Q16-x64-&lt;strong&gt;static&lt;/strong&gt;.exe&lt;/li&gt; 
   &lt;li&gt;安装下载好的 ImageMagick，&lt;strong&gt;注意不要修改安装路径&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;修改 &lt;code&gt;配置文件 config.toml&lt;/code&gt; 中的 &lt;code&gt;imagemagick_path&lt;/code&gt; 为你的 &lt;strong&gt;实际安装路径&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MacOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;brew install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ubuntu&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo apt-get install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CentOS&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo yum install ImageMagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;③ 启动Web界面 🌐&lt;/h4&gt; 
&lt;p&gt;注意需要到 MoneyPrinterTurbo 项目 &lt;code&gt;根目录&lt;/code&gt; 下执行以下命令&lt;/p&gt; 
&lt;h6&gt;Windows&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-bat"&gt;webui.bat
&lt;/code&gt;&lt;/pre&gt; 
&lt;h6&gt;MacOS or Linux&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sh webui.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;启动后，会自动打开浏览器（如果打开是空白，建议换成 &lt;strong&gt;Chrome&lt;/strong&gt; 或者 &lt;strong&gt;Edge&lt;/strong&gt; 打开）&lt;/p&gt; 
&lt;h4&gt;④ 启动API服务 🚀&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;启动后，可以查看 &lt;code&gt;API文档&lt;/code&gt; &lt;a href="http://127.0.0.1:8080/docs"&gt;http://127.0.0.1:8080/docs&lt;/a&gt; 或者 &lt;a href="http://127.0.0.1:8080/redoc"&gt;http://127.0.0.1:8080/redoc&lt;/a&gt; 直接在线调试接口，快速体验。&lt;/p&gt; 
&lt;h2&gt;语音合成 🗣&lt;/h2&gt; 
&lt;p&gt;所有支持的声音列表，可以查看：&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/voice-list.txt"&gt;声音列表&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;2024-04-16 v1.1.2 新增了9种Azure的语音合成声音，需要配置API KEY，该声音合成的更加真实。&lt;/p&gt; 
&lt;h2&gt;字幕生成 📜&lt;/h2&gt; 
&lt;p&gt;当前支持2种字幕生成方式：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;edge&lt;/strong&gt;: 生成&lt;code&gt;速度快&lt;/code&gt;，性能更好，对电脑配置没有要求，但是质量可能不稳定&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;whisper&lt;/strong&gt;: 生成&lt;code&gt;速度慢&lt;/code&gt;，性能较差，对电脑配置有一定要求，但是&lt;code&gt;质量更可靠&lt;/code&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;可以修改 &lt;code&gt;config.toml&lt;/code&gt; 配置文件中的 &lt;code&gt;subtitle_provider&lt;/code&gt; 进行切换&lt;/p&gt; 
&lt;p&gt;建议使用 &lt;code&gt;edge&lt;/code&gt; 模式，如果生成的字幕质量不好，再切换到 &lt;code&gt;whisper&lt;/code&gt; 模式&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;注意：&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;whisper 模式下需要到 HuggingFace 下载一个模型文件，大约 3GB 左右，请确保网络通畅&lt;/li&gt; 
 &lt;li&gt;如果留空，表示不生成字幕。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;由于国内无法访问 HuggingFace，可以使用以下方法下载 &lt;code&gt;whisper-large-v3&lt;/code&gt; 的模型文件&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;下载地址：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;百度网盘: &lt;a href="https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9"&gt;https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;夸克网盘：&lt;a href="https://pan.quark.cn/s/3ee3d991d64b"&gt;https://pan.quark.cn/s/3ee3d991d64b&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;模型下载后解压，整个目录放到 &lt;code&gt;.\MoneyPrinterTurbo\models&lt;/code&gt; 里面， 最终的文件路径应该是这样: &lt;code&gt;.\MoneyPrinterTurbo\models\whisper-large-v3&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MoneyPrinterTurbo  
  ├─models
  │   └─whisper-large-v3
  │          config.json
  │          model.bin
  │          preprocessor_config.json
  │          tokenizer.json
  │          vocabulary.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;背景音乐 🎵&lt;/h2&gt; 
&lt;p&gt;用于视频的背景音乐，位于项目的 &lt;code&gt;resource/songs&lt;/code&gt; 目录下。&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;当前项目里面放了一些默认的音乐，来自于 YouTube 视频，如有侵权，请删除。&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;字幕字体 🅰&lt;/h2&gt; 
&lt;p&gt;用于视频字幕的渲染，位于项目的 &lt;code&gt;resource/fonts&lt;/code&gt; 目录下，你也可以放进去自己的字体。&lt;/p&gt; 
&lt;h2&gt;常见问题 🤔&lt;/h2&gt; 
&lt;h3&gt;❓RuntimeError: No ffmpeg exe could be found&lt;/h3&gt; 
&lt;p&gt;通常情况下，ffmpeg 会被自动下载，并且会被自动检测到。 但是如果你的环境有问题，无法自动下载，可能会遇到如下错误：&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;RuntimeError: No ffmpeg exe could be found.
Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;此时你可以从 &lt;a href="https://www.gyan.dev/ffmpeg/builds/"&gt;https://www.gyan.dev/ffmpeg/builds/&lt;/a&gt; 下载ffmpeg，解压后，设置 &lt;code&gt;ffmpeg_path&lt;/code&gt; 为你的实际安装路径即可。&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[app]
# 请根据你的实际路径设置，注意 Windows 路径分隔符为 \\
ffmpeg_path = "C:\\Users\\harry\\Downloads\\ffmpeg.exe"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;❓ImageMagick的安全策略阻止了与临时文件@/tmp/tmpur5hyyto.txt相关的操作&lt;/h3&gt; 
&lt;p&gt;可以在ImageMagick的配置文件policy.xml中找到这些策略。 这个文件通常位于 /etc/ImageMagick-&lt;code&gt;X&lt;/code&gt;/ 或 ImageMagick 安装目录的类似位置。 修改包含&lt;code&gt;pattern="@"&lt;/code&gt;的条目，将&lt;code&gt;rights="none"&lt;/code&gt;更改为&lt;code&gt;rights="read|write"&lt;/code&gt;以允许对文件的读写操作。&lt;/p&gt; 
&lt;h3&gt;❓OSError: [Errno 24] Too many open files&lt;/h3&gt; 
&lt;p&gt;这个问题是由于系统打开文件数限制导致的，可以通过修改系统的文件打开数限制来解决。&lt;/p&gt; 
&lt;p&gt;查看当前限制&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;如果过低，可以调高一些，比如&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n 10240
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;❓Whisper 模型下载失败，出现如下错误&lt;/h3&gt; 
&lt;p&gt;LocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and outgoing trafic has been disabled. To enablerepo look-ups and downloads online, pass 'local files only=False' as input.&lt;/p&gt; 
&lt;p&gt;或者&lt;/p&gt; 
&lt;p&gt;An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Trying to load the model directly from the local cache, if it exists.&lt;/p&gt; 
&lt;p&gt;解决方法：&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/#%E5%AD%97%E5%B9%95%E7%94%9F%E6%88%90-"&gt;点击查看如何从网盘手动下载模型&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;反馈建议 📢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;可以提交 &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;issue&lt;/a&gt; 或者 &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/pulls"&gt;pull request&lt;/a&gt;。&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;许可证 📝&lt;/h2&gt; 
&lt;p&gt;点击查看 &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; 文件&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#harry0703/MoneyPrinterTurbo&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=harry0703/MoneyPrinterTurbo&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-agent-sdk-python</title>
      <link>https://github.com/anthropics/claude-agent-sdk-python</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Agent SDK for Python&lt;/h1&gt; 
&lt;p&gt;Python SDK for Claude Agent. See the &lt;a href="https://docs.anthropic.com/en/docs/claude-code/sdk/sdk-python"&gt;Claude Agent SDK documentation&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install claude-agent-sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10+&lt;/li&gt; 
 &lt;li&gt;Node.js&lt;/li&gt; 
 &lt;li&gt;Claude Code: &lt;code&gt;npm install -g @anthropic-ai/claude-code&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import anyio
from claude_agent_sdk import query

async def main():
    async for message in query(prompt="What is 2 + 2?"):
        print(message)

anyio.run(main)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Basic Usage: query()&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;query()&lt;/code&gt; is an async function for querying Claude Code. It returns an &lt;code&gt;AsyncIterator&lt;/code&gt; of response messages. See &lt;a href="https://raw.githubusercontent.com/anthropics/claude-agent-sdk-python/main/src/claude_agent_sdk/query.py"&gt;src/claude_agent_sdk/query.py&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from claude_agent_sdk import query, ClaudeAgentOptions, AssistantMessage, TextBlock

# Simple query
async for message in query(prompt="Hello Claude"):
    if isinstance(message, AssistantMessage):
        for block in message.content:
            if isinstance(block, TextBlock):
                print(block.text)

# With options
options = ClaudeAgentOptions(
    system_prompt="You are a helpful assistant",
    max_turns=1
)

async for message in query(prompt="Tell me a joke", options=options):
    print(message)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Tools&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;options = ClaudeAgentOptions(
    allowed_tools=["Read", "Write", "Bash"],
    permission_mode='acceptEdits'  # auto-accept file edits
)

async for message in query(
    prompt="Create a hello.py file",
    options=options
):
    # Process tool use and results
    pass
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Working Directory&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from pathlib import Path

options = ClaudeAgentOptions(
    cwd="/path/to/project"  # or Path("/path/to/project")
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ClaudeSDKClient&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;ClaudeSDKClient&lt;/code&gt; supports bidirectional, interactive conversations with Claude Code. See &lt;a href="https://raw.githubusercontent.com/anthropics/claude-agent-sdk-python/main/src/claude_agent_sdk/client.py"&gt;src/claude_agent_sdk/client.py&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unlike &lt;code&gt;query()&lt;/code&gt;, &lt;code&gt;ClaudeSDKClient&lt;/code&gt; additionally enables &lt;strong&gt;custom tools&lt;/strong&gt; and &lt;strong&gt;hooks&lt;/strong&gt;, both of which can be defined as Python functions.&lt;/p&gt; 
&lt;h3&gt;Custom Tools (as In-Process SDK MCP Servers)&lt;/h3&gt; 
&lt;p&gt;A &lt;strong&gt;custom tool&lt;/strong&gt; is a Python function that you can offer to Claude, for Claude to invoke as needed.&lt;/p&gt; 
&lt;p&gt;Custom tools are implemented in-process MCP servers that run directly within your Python application, eliminating the need for separate processes that regular MCP servers require.&lt;/p&gt; 
&lt;p&gt;For an end-to-end example, see &lt;a href="https://raw.githubusercontent.com/anthropics/claude-agent-sdk-python/main/examples/mcp_calculator.py"&gt;MCP Calculator&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Creating a Simple Tool&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from claude_agent_sdk import tool, create_sdk_mcp_server, ClaudeAgentOptions, ClaudeSDKClient

# Define a tool using the @tool decorator
@tool("greet", "Greet a user", {"name": str})
async def greet_user(args):
    return {
        "content": [
            {"type": "text", "text": f"Hello, {args['name']}!"}
        ]
    }

# Create an SDK MCP server
server = create_sdk_mcp_server(
    name="my-tools",
    version="1.0.0",
    tools=[greet_user]
)

# Use it with Claude
options = ClaudeAgentOptions(
    mcp_servers={"tools": server},
    allowed_tools=["mcp__tools__greet"]
)

async with ClaudeSDKClient(options=options) as client:
    await client.query("Greet Alice")

    # Extract and print response
    async for msg in client.receive_response():
        print(msg)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Benefits Over External MCP Servers&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;No subprocess management&lt;/strong&gt; - Runs in the same process as your application&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Better performance&lt;/strong&gt; - No IPC overhead for tool calls&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simpler deployment&lt;/strong&gt; - Single Python process instead of multiple&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easier debugging&lt;/strong&gt; - All code runs in the same process&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Type safety&lt;/strong&gt; - Direct Python function calls with type hints&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Migration from External Servers&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# BEFORE: External MCP server (separate process)
options = ClaudeAgentOptions(
    mcp_servers={
        "calculator": {
            "type": "stdio",
            "command": "python",
            "args": ["-m", "calculator_server"]
        }
    }
)

# AFTER: SDK MCP server (in-process)
from my_tools import add, subtract  # Your tool functions

calculator = create_sdk_mcp_server(
    name="calculator",
    tools=[add, subtract]
)

options = ClaudeAgentOptions(
    mcp_servers={"calculator": calculator}
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Mixed Server Support&lt;/h4&gt; 
&lt;p&gt;You can use both SDK and external MCP servers together:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;options = ClaudeAgentOptions(
    mcp_servers={
        "internal": sdk_server,      # In-process SDK server
        "external": {                # External subprocess server
            "type": "stdio",
            "command": "external-server"
        }
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Hooks&lt;/h3&gt; 
&lt;p&gt;A &lt;strong&gt;hook&lt;/strong&gt; is a Python function that the Claude Code &lt;em&gt;application&lt;/em&gt; (&lt;em&gt;not&lt;/em&gt; Claude) invokes at specific points of the Claude agent loop. Hooks can provide deterministic processing and automated feedback for Claude. Read more in &lt;a href="https://docs.anthropic.com/en/docs/claude-code/hooks"&gt;Claude Code Hooks Reference&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For more examples, see examples/hooks.py.&lt;/p&gt; 
&lt;h4&gt;Example&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from claude_agent_sdk import ClaudeAgentOptions, ClaudeSDKClient, HookMatcher

async def check_bash_command(input_data, tool_use_id, context):
    tool_name = input_data["tool_name"]
    tool_input = input_data["tool_input"]
    if tool_name != "Bash":
        return {}
    command = tool_input.get("command", "")
    block_patterns = ["foo.sh"]
    for pattern in block_patterns:
        if pattern in command:
            return {
                "hookSpecificOutput": {
                    "hookEventName": "PreToolUse",
                    "permissionDecision": "deny",
                    "permissionDecisionReason": f"Command contains invalid pattern: {pattern}",
                }
            }
    return {}

options = ClaudeAgentOptions(
    allowed_tools=["Bash"],
    hooks={
        "PreToolUse": [
            HookMatcher(matcher="Bash", hooks=[check_bash_command]),
        ],
    }
)

async with ClaudeSDKClient(options=options) as client:
    # Test 1: Command with forbidden pattern (will be blocked)
    await client.query("Run the bash command: ./foo.sh --help")
    async for msg in client.receive_response():
        print(msg)

    print("\n" + "=" * 50 + "\n")

    # Test 2: Safe command that should work
    await client.query("Run the bash command: echo 'Hello from hooks example!'")
    async for msg in client.receive_response():
        print(msg)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Types&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/anthropics/claude-agent-sdk-python/main/src/claude_agent_sdk/types.py"&gt;src/claude_agent_sdk/types.py&lt;/a&gt; for complete type definitions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ClaudeAgentOptions&lt;/code&gt; - Configuration options&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;AssistantMessage&lt;/code&gt;, &lt;code&gt;UserMessage&lt;/code&gt;, &lt;code&gt;SystemMessage&lt;/code&gt;, &lt;code&gt;ResultMessage&lt;/code&gt; - Message types&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;TextBlock&lt;/code&gt;, &lt;code&gt;ToolUseBlock&lt;/code&gt;, &lt;code&gt;ToolResultBlock&lt;/code&gt; - Content blocks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Error Handling&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from claude_agent_sdk import (
    ClaudeSDKError,      # Base error
    CLINotFoundError,    # Claude Code not installed
    CLIConnectionError,  # Connection issues
    ProcessError,        # Process failed
    CLIJSONDecodeError,  # JSON parsing issues
)

try:
    async for message in query(prompt="Hello"):
        pass
except CLINotFoundError:
    print("Please install Claude Code")
except ProcessError as e:
    print(f"Process failed with exit code: {e.exit_code}")
except CLIJSONDecodeError as e:
    print(f"Failed to parse response: {e}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/anthropics/claude-agent-sdk-python/main/src/claude_agent_sdk/_errors.py"&gt;src/claude_agent_sdk/_errors.py&lt;/a&gt; for all error types.&lt;/p&gt; 
&lt;h2&gt;Available Tools&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://docs.anthropic.com/en/docs/claude-code/settings#tools-available-to-claude"&gt;Claude Code documentation&lt;/a&gt; for a complete list of available tools.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/anthropics/claude-agent-sdk-python/main/examples/quick_start.py"&gt;examples/quick_start.py&lt;/a&gt; for a complete working example.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/anthropics/claude-agent-sdk-python/main/examples/streaming_mode.py"&gt;examples/streaming_mode.py&lt;/a&gt; for comprehensive examples involving &lt;code&gt;ClaudeSDKClient&lt;/code&gt;. You can even run interactive examples in IPython from &lt;a href="https://raw.githubusercontent.com/anthropics/claude-agent-sdk-python/main/examples/streaming_mode_ipython.py"&gt;examples/streaming_mode_ipython.py&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Migrating from Claude Code SDK&lt;/h2&gt; 
&lt;p&gt;If you're upgrading from the Claude Code SDK (versions &amp;lt; 0.1.0), please see the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-agent-sdk-python/main/CHANGELOG.md#010"&gt;CHANGELOG.md&lt;/a&gt; for details on breaking changes and new features, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ClaudeCodeOptions&lt;/code&gt; → &lt;code&gt;ClaudeAgentOptions&lt;/code&gt; rename&lt;/li&gt; 
 &lt;li&gt;Merged system prompt configuration&lt;/li&gt; 
 &lt;li&gt;Settings isolation and explicit control&lt;/li&gt; 
 &lt;li&gt;New programmatic subagents and session forking features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lobehub/lobe-chat</title>
      <link>https://github.com/lobehub/lobe-chat</link>
      <description>&lt;p&gt;🤯 Lobe Chat - an open-source, modern design AI chat framework. Supports multiple AI providers (OpenAI / Claude 4 / Gemini / DeepSeek / Ollama / Qwen), Knowledge Base (file upload / RAG ), one click install MCP Marketplace and Artifacts / Thinking. One-click FREE deployment of your private AI Agent application.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt;
 &lt;a name="readme-top"&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;a href="https://chat-preview.lobehub.com"&gt;&lt;img src="https://github.com/user-attachments/assets/6f293c7f-47b4-47eb-9202-fe68a942d35b" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h1&gt;Lobe Chat&lt;/h1&gt; 
 &lt;p&gt;An open-source, modern design ChatGPT/LLMs UI/framework.&lt;br /&gt; Supports speech synthesis, multi-modal, and extensible (&lt;a href="https://lobehub.com/blog/openai-function-call"&gt;function call&lt;/a&gt;) plugin system.&lt;br /&gt; One-click &lt;strong&gt;FREE&lt;/strong&gt; deployment of your private OpenAI ChatGPT/Claude/Gemini/Groq/Ollama chat application.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;English&lt;/strong&gt; · &lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/README.zh-CN.md"&gt;简体中文&lt;/a&gt; · &lt;a href="https://lobehub.com"&gt;Official Site&lt;/a&gt; · &lt;a href="https://lobehub.com/changelog"&gt;Changelog&lt;/a&gt; · &lt;a href="https://lobehub.com/docs/usage/start"&gt;Documents&lt;/a&gt; · &lt;a href="https://lobehub.com/blog"&gt;Blog&lt;/a&gt; · &lt;a href="https://github.com/lobehub/lobe-chat/issues"&gt;Feedback&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- SHIELD GROUP --&gt; 
 &lt;p&gt;&lt;a href="https://github.com/lobehub/lobe-chat/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/lobehub/lobe-chat?color=369eff&amp;amp;labelColor=black&amp;amp;logo=github&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/lobehub/lobe-chat-database"&gt;&lt;img src="https://img.shields.io/docker/v/lobehub/lobe-chat-database?color=369eff&amp;amp;label=docker&amp;amp;labelColor=black&amp;amp;logo=docker&amp;amp;logoColor=white&amp;amp;style=flat-square&amp;amp;sort=semver" alt="" /&gt;&lt;/a&gt; &lt;a href="https://chat-preview.lobehub.com"&gt;&lt;img src="https://img.shields.io/badge/vercel-online-55b467?labelColor=black&amp;amp;logo=vercel&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/AYFPHvv2jT"&gt;&lt;img src="https://img.shields.io/discord/1127171173982154893?color=5865F2&amp;amp;label=discord&amp;amp;labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://codecov.io/gh/lobehub/lobe-chat"&gt;&lt;img src="https://img.shields.io/codecov/c/github/lobehub/lobe-chat?labelColor=black&amp;amp;style=flat-square&amp;amp;logo=codecov&amp;amp;logoColor=white" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/actions/workflows/lobehub/lobe-chat/test.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/lobehub/lobe-chat/test.yml?label=test&amp;amp;labelColor=black&amp;amp;logo=githubactions&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/actions/workflows/lobehub/lobe-chat/release.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/lobehub/lobe-chat/release.yml?label=release&amp;amp;labelColor=black&amp;amp;logo=githubactions&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lobehub/lobe-chat/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/lobehub/lobe-chat?labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/lobehub/lobe-chat/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/lobehub/lobe-chat?color=c4f042&amp;amp;labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lobehub/lobe-chat/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/lobehub/lobe-chat?color=8ae8ff&amp;amp;labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lobehub/lobe-chat/network/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/lobehub/lobe-chat?color=ffcb47&amp;amp;labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lobehub/lobe-chat/issues"&gt;&lt;img src="https://img.shields.io/github/issues/lobehub/lobe-chat?color=ff80eb&amp;amp;labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lobehub/lobe-chat/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-apache%202.0-white?labelColor=black&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://opencollective.com/lobehub" title="Become ❤️ LobeHub Sponsor"&gt;&lt;img src="https://img.shields.io/badge/-Sponsor%20LobeHub-f04f88?logo=opencollective&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Share LobeChat Repository&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://x.com/intent/tweet?hashtags=chatbot%2CchatGPT%2CopenAI&amp;amp;text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.&amp;amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat"&gt;&lt;img src="https://img.shields.io/badge/-share%20on%20x-black?labelColor=black&amp;amp;logo=x&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://t.me/share/url%22?text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&amp;amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat"&gt;&lt;img src="https://img.shields.io/badge/-share%20on%20telegram-black?labelColor=black&amp;amp;logo=telegram&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://api.whatsapp.com/send?text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat%20%23chatbot%20%23chatGPT%20%23openAI"&gt;&lt;img src="https://img.shields.io/badge/-share%20on%20whatsapp-black?labelColor=black&amp;amp;logo=whatsapp&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/submit?title=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&amp;amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat"&gt;&lt;img src="https://img.shields.io/badge/-share%20on%20reddit-black?labelColor=black&amp;amp;logo=reddit&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="http://service.weibo.com/share/share.php?sharesource=weibo&amp;amp;title=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source%2C%20extensible%20%28Function%20Calling%29%2C%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20%23chatbot%20%23chatGPT%20%23openAI&amp;amp;url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat"&gt;&lt;img src="https://img.shields.io/badge/-share%20on%20weibo-black?labelColor=black&amp;amp;logo=sinaweibo&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://mastodon.social/share?text=Check%20this%20GitHub%20repository%20out%20%F0%9F%A4%AF%20LobeChat%20-%20An%20open-source,%20extensible%20%28Function%20Calling%29,%20high-performance%20chatbot%20framework.%20It%20supports%20one-click%20free%20deployment%20of%20your%20private%20ChatGPT%2FLLM%20web%20application.%20https://github.com/lobehub/lobe-chat%20#chatbot%20#chatGPT%20#openAI"&gt;&lt;img src="https://img.shields.io/badge/-share%20on%20mastodon-black?labelColor=black&amp;amp;logo=mastodon&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://linkedin.com/feed"&gt;&lt;img src="https://img.shields.io/badge/-share%20on%20linkedin-black?labelColor=black&amp;amp;logo=linkedin&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;sup&gt;Pioneering the new age of thinking and creating. Built for you, the Super Individual.&lt;/sup&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/2256"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/2256" alt="" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://vercel.com/oss"&gt; &lt;img alt="Vercel OSS Program" src="https://vercel.com/oss/program-badge.svg?sanitize=true" /&gt; &lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/dbfaa84a-2c82-4dd9-815c-5be616f264a4" alt="" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;h4&gt;TOC&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-getting-started--join-our-community"&gt;👋🏻 Getting Started &amp;amp; Join Our Community&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-features"&gt;✨ Features&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-mcp-plugin-one-click-installation"&gt;✨ MCP Plugin One-Click Installation&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-mcp-marketplace"&gt;🏪 MCP Marketplace&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#%EF%B8%8F-desktop-app"&gt;🖥️ Desktop App&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-smart-internet-search"&gt;🌐 Smart Internet Search&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#chain-of-thought"&gt;Chain of Thought&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#branching-conversations"&gt;Branching Conversations&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#artifacts-support"&gt;Artifacts Support&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#file-upload-knowledge-base"&gt;File Upload /Knowledge Base&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#multi-model-service-provider-support"&gt;Multi-Model Service Provider Support&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#local-large-language-model-llm-support"&gt;Local Large Language Model (LLM) Support&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#model-visual-recognition"&gt;Model Visual Recognition&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#tts--stt-voice-conversation"&gt;TTS &amp;amp; STT Voice Conversation&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#text-to-image-generation"&gt;Text to Image Generation&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#plugin-system-function-calling"&gt;Plugin System (Function Calling)&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#agent-market-gpts"&gt;Agent Market (GPTs)&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#support-local--remote-database"&gt;Support Local / Remote Database&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#support-multi-user-management"&gt;Support Multi-User Management&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#progressive-web-app-pwa"&gt;Progressive Web App (PWA)&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#mobile-device-adaptation"&gt;Mobile Device Adaptation&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#custom-themes"&gt;Custom Themes&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-whats-more"&gt;&lt;code&gt;*&lt;/code&gt; What's more&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#%EF%B8%8F-performance"&gt;⚡️ Performance&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-self-hosting"&gt;🛳 Self Hosting&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#a-deploying-with-vercel-zeabur--sealos-or-alibaba-cloud"&gt;&lt;code&gt;A&lt;/code&gt; Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#b-deploying-with-docker"&gt;&lt;code&gt;B&lt;/code&gt; Deploying with Docker&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#environment-variable"&gt;Environment Variable&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-ecosystem"&gt;📦 Ecosystem&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-plugins"&gt;🧩 Plugins&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#%EF%B8%8F-local-development"&gt;⌨️ Local Development&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-contributing"&gt;🤝 Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#%EF%B8%8F-sponsor"&gt;❤️ Sponsor&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#-more-products"&gt;🔗 More Products&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;/h4&gt; 
 &lt;br /&gt; 
&lt;/details&gt; 
&lt;h2&gt;👋🏻 Getting Started &amp;amp; Join Our Community&lt;/h2&gt; 
&lt;p&gt;We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC. By adopting the Bootstrapping approach, we aim to provide developers and users with a more open, transparent, and user-friendly product ecosystem.&lt;/p&gt; 
&lt;p&gt;Whether for users or professional developers, LobeHub will be your AI Agent playground. Please be aware that LobeChat is currently under active development, and feedback is welcome for any &lt;a href="https://img.shields.io/github/issues/lobehub/lobe-chat.svg?style=flat"&gt;issues&lt;/a&gt; encountered.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;&lt;a href="https://chat-preview.lobehub.com"&gt;&lt;img src="https://img.shields.io/badge/TRY%20LOBECHAT-ONLINE-55b467?labelColor=black&amp;amp;logo=vercel&amp;amp;style=for-the-badge" alt="" /&gt;&lt;/a&gt;&lt;/th&gt; 
   &lt;th align="left"&gt;No installation or registration necessary! Visit our website to experience it firsthand.&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://discord.gg/AYFPHvv2jT"&gt;&lt;img src="https://img.shields.io/discord/1127171173982154893?color=5865F2&amp;amp;label=discord&amp;amp;labelColor=black&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=for-the-badge" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Join our Discord community! This is where you can connect with developers and other enthusiastic users of LobeHub.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Star Us&lt;/strong&gt;, You will receive all release notifications from GitHub without any delay ~ ⭐️&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/lobehub/lobe-chat/network/stargazers"&gt;&lt;img src="https://github.com/user-attachments/assets/c3b482e7-cef5-4e94-bef9-226900ecfaab" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;amp;theme=dark&amp;amp;type=Date" /&gt; 
  &lt;img width="100%" src="https://api.star-history.com/svg?repos=lobehub%2Flobe-chat&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; 
&lt;/details&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;p&gt;Transform your AI experience with LobeChat's powerful features designed for seamless connectivity, enhanced productivity, and unlimited creativity.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/1be85d36-3975-4413-931f-27e05e440995" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;✨ MCP Plugin One-Click Installation&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Seamlessly Connect Your AI to the World&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Unlock the full potential of your AI by enabling smooth, secure, and dynamic interactions with external tools, data sources, and services. LobeChat's MCP (Model Context Protocol) plugin system breaks down the barriers between your AI and the digital ecosystem, allowing for unprecedented connectivity and functionality.&lt;/p&gt; 
&lt;p&gt;Transform your conversations into powerful workflows by connecting to databases, APIs, file systems, and more. Experience the freedom of AI that truly understands and interacts with your world.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/bb114f9f-24c5-4000-a984-c10d187da5a0" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;🏪 MCP Marketplace&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Discover, Connect, Extend&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Browse a growing library of MCP plugins to expand your AI's capabilities and streamline your workflows effortlessly. Visit &lt;a href="https://lobehub.com/mcp"&gt;lobehub.com/mcp&lt;/a&gt; to explore the MCP Marketplace, which offers a curated collection of integrations that enhance your AI's ability to work with various tools and services.&lt;/p&gt; 
&lt;p&gt;From productivity tools to development environments, discover new ways to extend your AI's reach and effectiveness. Connect with the community and find the perfect plugins for your specific needs.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/a7bac8d3-ea96-4000-bb39-fadc9b610f96" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;🖥️ Desktop App&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Peak Performance, Zero Distractions&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Get the full LobeChat experience without browser limitations—comprehensive, focused, and always ready to go. Our desktop application provides a dedicated environment for your AI interactions, ensuring optimal performance and minimal distractions.&lt;/p&gt; 
&lt;p&gt;Experience faster response times, better resource management, and a more stable connection to your AI assistant. The desktop app is designed for users who demand the best performance from their AI tools.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/cfdc48ac-b5f8-4a00-acee-db8f2eba09ad" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;🌐 Smart Internet Search&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Online Knowledge On Demand&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;With real-time internet access, your AI keeps up with the world—news, data, trends, and more. Stay informed and get the most current information available, enabling your AI to provide accurate and up-to-date responses.&lt;/p&gt; 
&lt;p&gt;Access live information, verify facts, and explore current events without leaving your conversation. Your AI becomes a gateway to the world's knowledge, always current and comprehensive.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/cot"&gt;&lt;img src="https://github.com/user-attachments/assets/f74f1139-d115-4e9c-8c43-040a53797a5e" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/cot"&gt;Chain of Thought&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Experience AI reasoning like never before. Watch as complex problems unfold step by step through our innovative Chain of Thought (CoT) visualization. This breakthrough feature provides unprecedented transparency into AI's decision-making process, allowing you to observe how conclusions are reached in real-time.&lt;/p&gt; 
&lt;p&gt;By breaking down complex reasoning into clear, logical steps, you can better understand and validate the AI's problem-solving approach. Whether you're debugging, learning, or simply curious about AI reasoning, CoT visualization transforms abstract thinking into an engaging, interactive experience.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/branching-conversations"&gt;&lt;img src="https://github.com/user-attachments/assets/92f72082-02bd-4835-9c54-b089aad7fd41" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/branching-conversations"&gt;Branching Conversations&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Introducing a more natural and flexible way to chat with AI. With Branch Conversations, your discussions can flow in multiple directions, just like human conversations do. Create new conversation branches from any message, giving you the freedom to explore different paths while preserving the original context.&lt;/p&gt; 
&lt;p&gt;Choose between two powerful modes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Continuation Mode:&lt;/strong&gt; Seamlessly extend your current discussion while maintaining valuable context&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Standalone Mode:&lt;/strong&gt; Start fresh with a new topic based on any previous message&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This groundbreaking feature transforms linear conversations into dynamic, tree-like structures, enabling deeper exploration of ideas and more productive interactions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/artifacts"&gt;&lt;img src="https://github.com/user-attachments/assets/7f95fad6-b210-4e6e-84a0-7f39e96f3a00" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/artifacts"&gt;Artifacts Support&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Experience the power of Claude Artifacts, now integrated into LobeChat. This revolutionary feature expands the boundaries of AI-human interaction, enabling real-time creation and visualization of diverse content formats.&lt;/p&gt; 
&lt;p&gt;Create and visualize with unprecedented flexibility:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generate and display dynamic SVG graphics&lt;/li&gt; 
 &lt;li&gt;Build and render interactive HTML pages in real-time&lt;/li&gt; 
 &lt;li&gt;Produce professional documents in multiple formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/blog/knowledge-base"&gt;&lt;img src="https://github.com/user-attachments/assets/7da7a3b2-92fd-4630-9f4e-8560c74955ae" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/blog/knowledge-base"&gt;File Upload /Knowledge Base&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;LobeChat supports file upload and knowledge base functionality. You can upload various types of files including documents, images, audio, and video, as well as create knowledge bases, making it convenient for users to manage and search for files. Additionally, you can utilize files and knowledge base features during conversations, enabling a richer dialogue experience.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175"&gt;https://github.com/user-attachments/assets/faa8cf67-e743-4590-8bf6-ebf6ccc34175&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Learn more on &lt;a href="https://lobehub.com/blog/knowledge-base"&gt;📘 LobeChat Knowledge Base Launch — From Now On, Every Step Counts&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/multi-ai-providers"&gt;&lt;img src="https://github.com/user-attachments/assets/e553e407-42de-4919-977d-7dbfcf44a821" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/multi-ai-providers"&gt;Multi-Model Service Provider Support&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;In the continuous development of LobeChat, we deeply understand the importance of diversity in model service providers for meeting the needs of the community when providing AI conversation services. Therefore, we have expanded our support to multiple model service providers, rather than being limited to a single one, in order to offer users a more diverse and rich selection of conversations.&lt;/p&gt; 
&lt;p&gt;In this way, LobeChat can more flexibly adapt to the needs of different users, while also providing developers with a wider range of choices.&lt;/p&gt; 
&lt;h4&gt;Supported Model Service Providers&lt;/h4&gt; 
&lt;p&gt;We have implemented support for the following model service providers:&lt;/p&gt; 
&lt;!-- PROVIDER LIST --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/openai"&gt;OpenAI&lt;/a&gt;&lt;/strong&gt;: OpenAI is a global leader in artificial intelligence research, with models like the GPT series pushing the frontiers of natural language processing. OpenAI is committed to transforming multiple industries through innovative and efficient AI solutions. Their products demonstrate significant performance and cost-effectiveness, widely used in research, business, and innovative applications.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/ollama"&gt;Ollama&lt;/a&gt;&lt;/strong&gt;: Ollama provides models that cover a wide range of fields, including code generation, mathematical operations, multilingual processing, and conversational interaction, catering to diverse enterprise-level and localized deployment needs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/anthropic"&gt;Anthropic&lt;/a&gt;&lt;/strong&gt;: Anthropic is a company focused on AI research and development, offering a range of advanced language models such as Claude 3.5 Sonnet, Claude 3 Sonnet, Claude 3 Opus, and Claude 3 Haiku. These models achieve an ideal balance between intelligence, speed, and cost, suitable for various applications from enterprise workloads to rapid-response scenarios. Claude 3.5 Sonnet, as their latest model, has excelled in multiple evaluations while maintaining a high cost-performance ratio.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/bedrock"&gt;Bedrock&lt;/a&gt;&lt;/strong&gt;: Bedrock is a service provided by Amazon AWS, focusing on delivering advanced AI language and visual models for enterprises. Its model family includes Anthropic's Claude series, Meta's Llama 3.1 series, and more, offering a range of options from lightweight to high-performance, supporting tasks such as text generation, conversation, and image processing for businesses of varying scales and needs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/google"&gt;Google&lt;/a&gt;&lt;/strong&gt;: Google's Gemini series represents its most advanced, versatile AI models, developed by Google DeepMind, designed for multimodal capabilities, supporting seamless understanding and processing of text, code, images, audio, and video. Suitable for various environments from data centers to mobile devices, it significantly enhances the efficiency and applicability of AI models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/deepseek"&gt;DeepSeek&lt;/a&gt;&lt;/strong&gt;: DeepSeek is a company focused on AI technology research and application, with its latest model DeepSeek-V2.5 integrating general dialogue and code processing capabilities, achieving significant improvements in human preference alignment, writing tasks, and instruction following.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/moonshot"&gt;Moonshot&lt;/a&gt;&lt;/strong&gt;: Moonshot is an open-source platform launched by Beijing Dark Side Technology Co., Ltd., providing various natural language processing models with a wide range of applications, including but not limited to content creation, academic research, intelligent recommendations, and medical diagnosis, supporting long text processing and complex generation tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/openrouter"&gt;OpenRouter&lt;/a&gt;&lt;/strong&gt;: OpenRouter is a service platform providing access to various cutting-edge large model interfaces, supporting OpenAI, Anthropic, LLaMA, and more, suitable for diverse development and application needs. Users can flexibly choose the optimal model and pricing based on their requirements, enhancing the AI experience.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/huggingface"&gt;HuggingFace&lt;/a&gt;&lt;/strong&gt;: The HuggingFace Inference API provides a fast and free way for you to explore thousands of models for various tasks. Whether you are prototyping for a new application or experimenting with the capabilities of machine learning, this API gives you instant access to high-performance models across multiple domains.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/cloudflare"&gt;Cloudflare Workers AI&lt;/a&gt;&lt;/strong&gt;: Run serverless GPU-powered machine learning models on Cloudflare's global network.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt;
 &lt;summary&gt;&lt;kbd&gt;See more providers (+32)&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/github"&gt;GitHub&lt;/a&gt;&lt;/strong&gt;: With GitHub Models, developers can become AI engineers and leverage the industry's leading AI models.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/novita"&gt;Novita&lt;/a&gt;&lt;/strong&gt;: Novita AI is a platform providing a variety of large language models and AI image generation API services, flexible, reliable, and cost-effective. It supports the latest open-source models like Llama3 and Mistral, offering a comprehensive, user-friendly, and auto-scaling API solution for generative AI application development, suitable for the rapid growth of AI startups.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/ppio"&gt;PPIO&lt;/a&gt;&lt;/strong&gt;: PPIO supports stable and cost-efficient open-source LLM APIs, such as DeepSeek, Llama, Qwen etc.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/ai302"&gt;302.AI&lt;/a&gt;&lt;/strong&gt;: 302.AI is an on-demand AI application platform offering the most comprehensive AI APIs and online AI applications available on the market.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/togetherai"&gt;Together AI&lt;/a&gt;&lt;/strong&gt;: Together AI is dedicated to achieving leading performance through innovative AI models, offering extensive customization capabilities, including rapid scaling support and intuitive deployment processes to meet various enterprise needs.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/fireworksai"&gt;Fireworks AI&lt;/a&gt;&lt;/strong&gt;: Fireworks AI is a leading provider of advanced language model services, focusing on functional calling and multimodal processing. Its latest model, Firefunction V2, is based on Llama-3, optimized for function calling, conversation, and instruction following. The visual language model FireLLaVA-13B supports mixed input of images and text. Other notable models include the Llama series and Mixtral series, providing efficient multilingual instruction following and generation support.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/groq"&gt;Groq&lt;/a&gt;&lt;/strong&gt;: Groq's LPU inference engine has excelled in the latest independent large language model (LLM) benchmarks, redefining the standards for AI solutions with its remarkable speed and efficiency. Groq represents instant inference speed, demonstrating strong performance in cloud-based deployments.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/perplexity"&gt;Perplexity&lt;/a&gt;&lt;/strong&gt;: Perplexity is a leading provider of conversational generation models, offering various advanced Llama 3.1 models that support both online and offline applications, particularly suited for complex natural language processing tasks.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/mistral"&gt;Mistral&lt;/a&gt;&lt;/strong&gt;: Mistral provides advanced general, specialized, and research models widely used in complex reasoning, multilingual tasks, and code generation. Through functional calling interfaces, users can integrate custom functionalities for specific applications.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/modelscope"&gt;ModelScope&lt;/a&gt;&lt;/strong&gt;: ModelScope is a model-as-a-service platform launched by Alibaba Cloud, offering a wide range of AI models and inference services.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/ai21"&gt;Ai21Labs&lt;/a&gt;&lt;/strong&gt;: AI21 Labs builds foundational models and AI systems for enterprises, accelerating the application of generative AI in production.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/upstage"&gt;Upstage&lt;/a&gt;&lt;/strong&gt;: Upstage focuses on developing AI models for various business needs, including Solar LLM and document AI, aiming to achieve artificial general intelligence (AGI) for work. It allows for the creation of simple conversational agents through Chat API and supports functional calling, translation, embedding, and domain-specific applications.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/xai"&gt;xAI (Grok)&lt;/a&gt;&lt;/strong&gt;: xAI is a company dedicated to building artificial intelligence to accelerate human scientific discovery. Our mission is to advance our collective understanding of the universe.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/qwen"&gt;Aliyun Bailian&lt;/a&gt;&lt;/strong&gt;: Tongyi Qianwen is a large-scale language model independently developed by Alibaba Cloud, featuring strong natural language understanding and generation capabilities. It can answer various questions, create written content, express opinions, and write code, playing a role in multiple fields.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/wenxin"&gt;Wenxin&lt;/a&gt;&lt;/strong&gt;: An enterprise-level one-stop platform for large model and AI-native application development and services, providing the most comprehensive and user-friendly toolchain for the entire process of generative artificial intelligence model development and application development.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/hunyuan"&gt;Hunyuan&lt;/a&gt;&lt;/strong&gt;: A large language model developed by Tencent, equipped with powerful Chinese creative capabilities, logical reasoning abilities in complex contexts, and reliable task execution skills.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/zhipu"&gt;ZhiPu&lt;/a&gt;&lt;/strong&gt;: Zhipu AI offers an open platform for multimodal and language models, supporting a wide range of AI application scenarios, including text processing, image understanding, and programming assistance.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/siliconcloud"&gt;SiliconCloud&lt;/a&gt;&lt;/strong&gt;: SiliconFlow is dedicated to accelerating AGI for the benefit of humanity, enhancing large-scale AI efficiency through an easy-to-use and cost-effective GenAI stack.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/zeroone"&gt;01.AI&lt;/a&gt;&lt;/strong&gt;: 01.AI focuses on AI 2.0 era technologies, vigorously promoting the innovation and application of 'human + artificial intelligence', using powerful models and advanced AI technologies to enhance human productivity and achieve technological empowerment.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/spark"&gt;Spark&lt;/a&gt;&lt;/strong&gt;: iFlytek's Spark model provides powerful AI capabilities across multiple domains and languages, utilizing advanced natural language processing technology to build innovative applications suitable for smart hardware, smart healthcare, smart finance, and other vertical scenarios.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/sensenova"&gt;SenseNova&lt;/a&gt;&lt;/strong&gt;: SenseNova, backed by SenseTime's robust infrastructure, offers efficient and user-friendly full-stack large model services.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/stepfun"&gt;Stepfun&lt;/a&gt;&lt;/strong&gt;: StepFun's large model possesses industry-leading multimodal and complex reasoning capabilities, supporting ultra-long text understanding and powerful autonomous scheduling search engine functions.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/baichuan"&gt;Baichuan&lt;/a&gt;&lt;/strong&gt;: Baichuan Intelligence is a company focused on the research and development of large AI models, with its models excelling in domestic knowledge encyclopedias, long text processing, and generative creation tasks in Chinese, surpassing mainstream foreign models. Baichuan Intelligence also possesses industry-leading multimodal capabilities, performing excellently in multiple authoritative evaluations. Its models include Baichuan 4, Baichuan 3 Turbo, and Baichuan 3 Turbo 128k, each optimized for different application scenarios, providing cost-effective solutions.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/minimax"&gt;Minimax&lt;/a&gt;&lt;/strong&gt;: MiniMax is a general artificial intelligence technology company established in 2021, dedicated to co-creating intelligence with users. MiniMax has independently developed general large models of different modalities, including trillion-parameter MoE text models, voice models, and image models, and has launched applications such as Conch AI.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/internlm"&gt;InternLM&lt;/a&gt;&lt;/strong&gt;: An open-source organization dedicated to the research and development of large model toolchains. It provides an efficient and user-friendly open-source platform for all AI developers, making cutting-edge large models and algorithm technologies easily accessible.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/higress"&gt;Higress&lt;/a&gt;&lt;/strong&gt;: Higress is a cloud-native API gateway that was developed internally at Alibaba to address the issues of Tengine reload affecting long-lived connections and the insufficient load balancing capabilities for gRPC/Dubbo.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/giteeai"&gt;Gitee AI&lt;/a&gt;&lt;/strong&gt;: Gitee AI's Serverless API provides AI developers with an out of the box large model inference API service.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/taichu"&gt;Taichu&lt;/a&gt;&lt;/strong&gt;: The Institute of Automation, Chinese Academy of Sciences, and Wuhan Artificial Intelligence Research Institute have launched a new generation of multimodal large models, supporting comprehensive question-answering tasks such as multi-turn Q&amp;amp;A, text creation, image generation, 3D understanding, and signal analysis, with stronger cognitive, understanding, and creative abilities, providing a new interactive experience.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/ai360"&gt;360 AI&lt;/a&gt;&lt;/strong&gt;: 360 AI is an AI model and service platform launched by 360 Company, offering various advanced natural language processing models, including 360GPT2 Pro, 360GPT Pro, 360GPT Turbo, and 360GPT Turbo Responsibility 8K. These models combine large-scale parameters and multimodal capabilities, widely applied in text generation, semantic understanding, dialogue systems, and code generation. With flexible pricing strategies, 360 AI meets diverse user needs, supports developer integration, and promotes the innovation and development of intelligent applications.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/search1api"&gt;Search1API&lt;/a&gt;&lt;/strong&gt;: Search1API provides access to the DeepSeek series of models that can connect to the internet as needed, including standard and fast versions, supporting a variety of model sizes.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/infiniai"&gt;InfiniAI&lt;/a&gt;&lt;/strong&gt;: Provides high-performance, easy-to-use, and secure large model services for application developers, covering the entire process from large model development to service deployment.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;&lt;a href="https://lobechat.com/discover/provider/qiniu"&gt;Qiniu&lt;/a&gt;&lt;/strong&gt;: Qiniu, as a long-established cloud service provider, delivers cost-effective and reliable AI inference services for both real-time and batch processing, with a simple and user-friendly experience.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;📊 Total providers: &lt;a href="https://lobechat.com/discover/providers"&gt;&lt;kbd&gt;&lt;strong&gt;42&lt;/strong&gt;&lt;/kbd&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- PROVIDER LIST --&gt; 
&lt;p&gt;At the same time, we are also planning to support more model service providers. If you would like LobeChat to support your favorite service provider, feel free to join our &lt;a href="https://github.com/lobehub/lobe-chat/discussions/1284"&gt;💬 community discussion&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/local-llm"&gt;&lt;img src="https://github.com/user-attachments/assets/1239da50-d832-4632-a7ef-bd754c0f3850" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/local-llm"&gt;Local Large Language Model (LLM) Support&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;To meet the specific needs of users, LobeChat also supports the use of local models based on &lt;a href="https://ollama.ai"&gt;Ollama&lt;/a&gt;, allowing users to flexibly use their own or third-party models.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Learn more about &lt;a href="https://lobehub.com/docs/usage/providers/ollama"&gt;📘 Using Ollama in LobeChat&lt;/a&gt; by checking it out.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/vision"&gt;&lt;img src="https://github.com/user-attachments/assets/18574a1f-46c2-4cbc-af2c-35a86e128a07" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/vision"&gt;Model Visual Recognition&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;LobeChat now supports OpenAI's latest &lt;a href="https://platform.openai.com/docs/guides/vision"&gt;&lt;code&gt;gpt-4-vision&lt;/code&gt;&lt;/a&gt; model with visual recognition capabilities, a multimodal intelligence that can perceive visuals. Users can easily upload or drag and drop images into the dialogue box, and the agent will be able to recognize the content of the images and engage in intelligent conversation based on this, creating smarter and more diversified chat scenarios.&lt;/p&gt; 
&lt;p&gt;This feature opens up new interactive methods, allowing communication to transcend text and include a wealth of visual elements. Whether it's sharing images in daily use or interpreting images within specific industries, the agent provides an outstanding conversational experience.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/tts"&gt;&lt;img src="https://github.com/user-attachments/assets/50189597-2cc3-4002-b4c8-756a52ad5c0a" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/tts"&gt;TTS &amp;amp; STT Voice Conversation&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;LobeChat supports Text-to-Speech (TTS) and Speech-to-Text (STT) technologies, enabling our application to convert text messages into clear voice outputs, allowing users to interact with our conversational agent as if they were talking to a real person. Users can choose from a variety of voices to pair with the agent.&lt;/p&gt; 
&lt;p&gt;Moreover, TTS offers an excellent solution for those who prefer auditory learning or desire to receive information while busy. In LobeChat, we have meticulously selected a range of high-quality voice options (OpenAI Audio, Microsoft Edge Speech) to meet the needs of users from different regions and cultural backgrounds. Users can choose the voice that suits their personal preferences or specific scenarios, resulting in a personalized communication experience.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/text-to-image"&gt;&lt;img src="https://github.com/user-attachments/assets/708274a7-2458-494b-a6ec-b73dfa1fa7c2" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/text-to-image"&gt;Text to Image Generation&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;With support for the latest text-to-image generation technology, LobeChat now allows users to invoke image creation tools directly within conversations with the agent. By leveraging the capabilities of AI tools such as &lt;a href="https://openai.com/dall-e-3"&gt;&lt;code&gt;DALL-E 3&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://www.midjourney.com/"&gt;&lt;code&gt;MidJourney&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://pollinations.ai/"&gt;&lt;code&gt;Pollinations&lt;/code&gt;&lt;/a&gt;, the agents are now equipped to transform your ideas into images.&lt;/p&gt; 
&lt;p&gt;This enables a more private and immersive creative process, allowing for the seamless integration of visual storytelling into your personal dialogue with the agent.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/plugin-system"&gt;&lt;img src="https://github.com/user-attachments/assets/66a891ac-01b6-4e3f-b978-2eb07b489b1b" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/plugin-system"&gt;Plugin System (Function Calling)&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;The plugin ecosystem of LobeChat is an important extension of its core functionality, greatly enhancing the practicality and flexibility of the LobeChat assistant.&lt;/p&gt; 
&lt;p&gt;
 &lt;video controls src="https://github.com/lobehub/lobe-chat/assets/28616219/f29475a3-f346-4196-a435-41a6373ab9e2" muted="false"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;p&gt;By utilizing plugins, LobeChat assistants can obtain and process real-time information, such as searching for web information and providing users with instant and relevant news.&lt;/p&gt; 
&lt;p&gt;In addition, these plugins are not limited to news aggregation, but can also extend to other practical functions, such as quickly searching documents, generating images, obtaining data from various platforms like Bilibili, Steam, and interacting with various third-party services.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Learn more about &lt;a href="https://lobehub.com/docs/usage/plugins/basic"&gt;📘 Plugin Usage&lt;/a&gt; by checking it out.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- PLUGIN LIST --&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Recent Submits&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lobechat.com/discover/plugin/StockData"&gt;PortfolioMeta&lt;/a&gt;&lt;br /&gt;&lt;sup&gt;By &lt;strong&gt;portfoliometa&lt;/strong&gt; on &lt;strong&gt;2025-09-27&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; 
   &lt;td&gt;Analyze stocks and get comprehensive real-time investment data and analytics.&lt;br /&gt;&lt;code&gt;stock&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lobechat.com/discover/plugin/web"&gt;Web&lt;/a&gt;&lt;br /&gt;&lt;sup&gt;By &lt;strong&gt;Proghit&lt;/strong&gt; on &lt;strong&gt;2025-01-24&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; 
   &lt;td&gt;Smart web search that reads and analyzes pages to deliver comprehensive answers from Google results.&lt;br /&gt;&lt;code&gt;web&lt;/code&gt; &lt;code&gt;search&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lobechat.com/discover/plugin/Bingsearch-identifier"&gt;Bing_websearch&lt;/a&gt;&lt;br /&gt;&lt;sup&gt;By &lt;strong&gt;FineHow&lt;/strong&gt; on &lt;strong&gt;2024-12-22&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; 
   &lt;td&gt;Search for information from the internet base BingApi&lt;br /&gt;&lt;code&gt;bingsearch&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lobechat.com/discover/plugin/google-cse"&gt;Google CSE&lt;/a&gt;&lt;br /&gt;&lt;sup&gt;By &lt;strong&gt;vsnthdev&lt;/strong&gt; on &lt;strong&gt;2024-12-02&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; 
   &lt;td&gt;Searches Google through their official CSE API.&lt;br /&gt;&lt;code&gt;web&lt;/code&gt; &lt;code&gt;search&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;📊 Total plugins: &lt;a href="https://lobechat.com/discover/plugins"&gt;&lt;kbd&gt;&lt;strong&gt;42&lt;/strong&gt;&lt;/kbd&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- PLUGIN LIST --&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/agent-market"&gt;&lt;img src="https://github.com/user-attachments/assets/b3ab6e35-4fbc-468d-af10-e3e0c687350f" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/agent-market"&gt;Agent Market (GPTs)&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;In LobeChat Agent Marketplace, creators can discover a vibrant and innovative community that brings together a multitude of well-designed agents, which not only play an important role in work scenarios but also offer great convenience in learning processes. Our marketplace is not just a showcase platform but also a collaborative space. Here, everyone can contribute their wisdom and share the agents they have developed.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;By &lt;a href="https://github.com/lobehub/lobe-chat-agents"&gt;🤖/🏪 Submit Agents&lt;/a&gt;, you can easily submit your agent creations to our platform. Importantly, LobeChat has established a sophisticated automated internationalization (i18n) workflow, capable of seamlessly translating your agent into multiple language versions. This means that no matter what language your users speak, they can experience your agent without barriers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;We welcome all users to join this growing ecosystem and participate in the iteration and optimization of agents. Together, we can create more interesting, practical, and innovative agents, further enriching the diversity and practicality of the agent offerings.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- AGENT LIST --&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Recent Submits&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lobechat.com/discover/assistant/lateral-thinking-puzzle"&gt;Turtle Soup Host&lt;/a&gt;&lt;br /&gt;&lt;sup&gt;By &lt;strong&gt;&lt;a href="https://github.com/CSY2022"&gt;CSY2022&lt;/a&gt;&lt;/strong&gt; on &lt;strong&gt;2025-06-19&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; 
   &lt;td&gt;A turtle soup host needs to provide the scenario, the complete story (truth of the event), and the key point (the condition for guessing correctly).&lt;br /&gt;&lt;code&gt;turtle-soup&lt;/code&gt; &lt;code&gt;reasoning&lt;/code&gt; &lt;code&gt;interaction&lt;/code&gt; &lt;code&gt;puzzle&lt;/code&gt; &lt;code&gt;role-playing&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lobechat.com/discover/assistant/food-reviewer"&gt;Gourmet Reviewer🍟&lt;/a&gt;&lt;br /&gt;&lt;sup&gt;By &lt;strong&gt;&lt;a href="https://github.com/renhai-lab"&gt;renhai-lab&lt;/a&gt;&lt;/strong&gt; on &lt;strong&gt;2025-06-17&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; 
   &lt;td&gt;Food critique expert&lt;br /&gt;&lt;code&gt;gourmet&lt;/code&gt; &lt;code&gt;review&lt;/code&gt; &lt;code&gt;writing&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lobechat.com/discover/assistant/academic-writing-assistant"&gt;Academic Writing Assistant&lt;/a&gt;&lt;br /&gt;&lt;sup&gt;By &lt;strong&gt;&lt;a href="https://github.com/swarfte"&gt;swarfte&lt;/a&gt;&lt;/strong&gt; on &lt;strong&gt;2025-06-17&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; 
   &lt;td&gt;Expert in academic research paper writing and formal documentation&lt;br /&gt;&lt;code&gt;academic-writing&lt;/code&gt; &lt;code&gt;research&lt;/code&gt; &lt;code&gt;formal-style&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://lobechat.com/discover/assistant/java-development"&gt;Minecraft Senior Developer&lt;/a&gt;&lt;br /&gt;&lt;sup&gt;By &lt;strong&gt;&lt;a href="https://github.com/iamyuuk"&gt;iamyuuk&lt;/a&gt;&lt;/strong&gt; on &lt;strong&gt;2025-06-17&lt;/strong&gt;&lt;/sup&gt;&lt;/td&gt; 
   &lt;td&gt;Expert in advanced Java development and Minecraft mod and server plugin development&lt;br /&gt;&lt;code&gt;development&lt;/code&gt; &lt;code&gt;programming&lt;/code&gt; &lt;code&gt;minecraft&lt;/code&gt; &lt;code&gt;java&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;📊 Total agents: &lt;a href="https://lobechat.com/discover/assistants"&gt;&lt;kbd&gt;&lt;strong&gt;505&lt;/strong&gt;&lt;/kbd&gt; &lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- AGENT LIST --&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/database"&gt;&lt;img src="https://github.com/user-attachments/assets/f1697c8b-d1fb-4dac-ba05-153c6295d91d" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/database"&gt;Support Local / Remote Database&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;LobeChat supports the use of both server-side and local databases. Depending on your needs, you can choose the appropriate deployment solution:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local database&lt;/strong&gt;: suitable for users who want more control over their data and privacy protection. LobeChat uses CRDT (Conflict-Free Replicated Data Type) technology to achieve multi-device synchronization. This is an experimental feature aimed at providing a seamless data synchronization experience.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server-side database&lt;/strong&gt;: suitable for users who want a more convenient user experience. LobeChat supports PostgreSQL as a server-side database. For detailed documentation on how to configure the server-side database, please visit &lt;a href="https://lobehub.com/docs/self-hosting/advanced/server-database"&gt;Configure Server-side Database&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Regardless of which database you choose, LobeChat can provide you with an excellent user experience.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/auth"&gt;&lt;img src="https://github.com/user-attachments/assets/80bb232e-19d1-4f97-98d6-e291f3585e6d" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/auth"&gt;Support Multi-User Management&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;LobeChat supports multi-user management and provides two main user authentication and management solutions to meet different needs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;next-auth&lt;/strong&gt;: LobeChat integrates &lt;code&gt;next-auth&lt;/code&gt;, a flexible and powerful identity verification library that supports multiple authentication methods, including OAuth, email login, credential login, etc. With &lt;code&gt;next-auth&lt;/code&gt;, you can easily implement user registration, login, session management, social login, and other functions to ensure the security and privacy of user data.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://go.clerk.com/exgqLG0"&gt;&lt;strong&gt;Clerk&lt;/strong&gt;&lt;/a&gt;: For users who need more advanced user management features, LobeChat also supports &lt;code&gt;Clerk&lt;/code&gt;, a modern user management platform. &lt;code&gt;Clerk&lt;/code&gt; provides richer functions, such as multi-factor authentication (MFA), user profile management, login activity monitoring, etc. With &lt;code&gt;Clerk&lt;/code&gt;, you can get higher security and flexibility, and easily cope with complex user management needs.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Regardless of which user management solution you choose, LobeChat can provide you with an excellent user experience and powerful functional support.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/pwa"&gt;&lt;img src="https://github.com/user-attachments/assets/9647f70f-b71b-43b6-9564-7cdd12d1c24d" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/pwa"&gt;Progressive Web App (PWA)&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;We deeply understand the importance of providing a seamless experience for users in today's multi-device environment. Therefore, we have adopted Progressive Web Application (&lt;a href="https://support.google.com/chrome/answer/9658361"&gt;PWA&lt;/a&gt;) technology, a modern web technology that elevates web applications to an experience close to that of native apps.&lt;/p&gt; 
&lt;p&gt;Through PWA, LobeChat can offer a highly optimized user experience on both desktop and mobile devices while maintaining high-performance characteristics. Visually and in terms of feel, we have also meticulously designed the interface to ensure it is indistinguishable from native apps, providing smooth animations, responsive layouts, and adapting to different device screen resolutions.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;If you are unfamiliar with the installation process of PWA, you can add LobeChat as your desktop application (also applicable to mobile devices) by following these steps:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Launch the Chrome or Edge browser on your computer.&lt;/li&gt; 
  &lt;li&gt;Visit the LobeChat webpage.&lt;/li&gt; 
  &lt;li&gt;In the upper right corner of the address bar, click on the &lt;kbd&gt;Install&lt;/kbd&gt; icon.&lt;/li&gt; 
  &lt;li&gt;Follow the instructions on the screen to complete the PWA Installation.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/mobile"&gt;&lt;img src="https://github.com/user-attachments/assets/32cf43c4-96bd-4a4c-bfb6-59acde6fe380" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/mobile"&gt;Mobile Device Adaptation&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;We have carried out a series of optimization designs for mobile devices to enhance the user's mobile experience. Currently, we are iterating on the mobile user experience to achieve smoother and more intuitive interactions. If you have any suggestions or ideas, we welcome you to provide feedback through GitHub Issues or Pull Requests.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://lobehub.com/docs/usage/features/theme"&gt;&lt;img src="https://github.com/user-attachments/assets/b47c39f1-806f-492b-8fcb-b0fa973937c1" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://lobehub.com/docs/usage/features/theme"&gt;Custom Themes&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;As a design-engineering-oriented application, LobeChat places great emphasis on users' personalized experiences, hence introducing flexible and diverse theme modes, including a light mode for daytime and a dark mode for nighttime. Beyond switching theme modes, a range of color customization options allow users to adjust the application's theme colors according to their preferences. Whether it's a desire for a sober dark blue, a lively peach pink, or a professional gray-white, users can find their style of color choices in LobeChat.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;The default configuration can intelligently recognize the user's system color mode and automatically switch themes to ensure a consistent visual experience with the operating system. For users who like to manually control details, LobeChat also offers intuitive setting options and a choice between chat bubble mode and document mode for conversation scenarios.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;code&gt;*&lt;/code&gt; What's more&lt;/h3&gt; 
&lt;p&gt;Beside these features, LobeChat also have much better basic technique underground:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 💨 &lt;strong&gt;Quick Deployment&lt;/strong&gt;: Using the Vercel platform or docker image, you can deploy with just one click and complete the process within 1 minute without any complex configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 🌐 &lt;strong&gt;Custom Domain&lt;/strong&gt;: If users have their own domain, they can bind it to the platform for quick access to the dialogue agent from anywhere.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 🔒 &lt;strong&gt;Privacy Protection&lt;/strong&gt;: All data is stored locally in the user's browser, ensuring user privacy.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 💎 &lt;strong&gt;Exquisite UI Design&lt;/strong&gt;: With a carefully designed interface, it offers an elegant appearance and smooth interaction. It supports light and dark themes and is mobile-friendly. PWA support provides a more native-like experience.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; 🗣️ &lt;strong&gt;Smooth Conversation Experience&lt;/strong&gt;: Fluid responses ensure a smooth conversation experience. It fully supports Markdown rendering, including code highlighting, LaTex formulas, Mermaid flowcharts, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;✨ more features will be added when LobeChat evolve.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;You can find our upcoming &lt;a href="https://github.com/lobehub/lobe-chat/projects"&gt;Roadmap&lt;/a&gt; plans in the Projects section.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;⚡️ Performance&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;The complete list of reports can be found in the &lt;a href="https://github.com/lobehub/lobe-chat/wiki/Lighthouse"&gt;📘 Lighthouse Reports&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Desktop&lt;/th&gt; 
   &lt;th align="center"&gt;Mobile&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/lobehub/lobe-chat/lighthouse/lighthouse/chat/desktop/pagespeed.svg?sanitize=true" alt="" /&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/lobehub/lobe-chat/lighthouse/lighthouse/chat/mobile/pagespeed.svg?sanitize=true" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://lobehub.github.io/lobe-chat/lighthouse/chat/desktop/chat_preview_lobehub_com_chat.html"&gt;📑 Lighthouse Report&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://lobehub.github.io/lobe-chat/lighthouse/chat/mobile/chat_preview_lobehub_com_chat.html"&gt;📑 Lighthouse Report&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🛳 Self Hosting&lt;/h2&gt; 
&lt;p&gt;LobeChat provides Self-Hosted Version with Vercel, Alibaba Cloud, and &lt;a href="https://hub.docker.com/r/lobehub/lobe-chat-database"&gt;Docker Image&lt;/a&gt;. This allows you to deploy your own chatbot within a few minutes without any prior knowledge.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;Learn more about &lt;a href="https://lobehub.com/docs/self-hosting/start"&gt;📘 Build your own LobeChat&lt;/a&gt; by checking it out.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;code&gt;A&lt;/code&gt; Deploying with Vercel, Zeabur , Sealos or Alibaba Cloud&lt;/h3&gt; 
&lt;p&gt;"If you want to deploy this service yourself on Vercel, Zeabur or Alibaba Cloud, you can follow these steps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Prepare your &lt;a href="https://platform.openai.com/account/api-keys"&gt;OpenAI API Key&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Click the button below to start deployment: Log in directly with your GitHub account, and remember to fill in the &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;(required) and &lt;code&gt;ACCESS_CODE&lt;/code&gt; (recommended) on the environment variable section.&lt;/li&gt; 
 &lt;li&gt;After deployment, you can start using it.&lt;/li&gt; 
 &lt;li&gt;Bind a custom domain (optional): The DNS of the domain assigned by Vercel is polluted in some areas; binding a custom domain can connect directly.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;Deploy with Vercel&lt;/th&gt; 
    &lt;th align="center"&gt;Deploy with Zeabur&lt;/th&gt; 
    &lt;th align="center"&gt;Deploy with Sealos&lt;/th&gt; 
    &lt;th align="center"&gt;Deploy with RepoCloud&lt;/th&gt; 
    &lt;th align="center"&gt;Deploy with Alibaba Cloud&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;a href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flobehub%2Flobe-chat&amp;amp;env=OPENAI_API_KEY,ACCESS_CODE&amp;amp;envDescription=Find%20your%20OpenAI%20API%20Key%20by%20click%20the%20right%20Learn%20More%20button.%20%7C%20Access%20Code%20can%20protect%20your%20website&amp;amp;envLink=https%3A%2F%2Fplatform.openai.com%2Faccount%2Fapi-keys&amp;amp;project-name=lobe-chat&amp;amp;repository-name=lobe-chat"&gt;&lt;img src="https://vercel.com/button" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://zeabur.com/templates/VZGGTI"&gt;&lt;img src="https://zeabur.com/button.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://template.usw.sealos.io/deploy?templateName=lobe-chat-db"&gt;&lt;img src="https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://repocloud.io/details/?app_id=248"&gt;&lt;img src="https://d16t0pc4846x52.cloudfront.net/deploylobe.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;a href="https://computenest.console.aliyun.com/service/instance/create/default?type=user&amp;amp;ServiceName=LobeChat%E7%A4%BE%E5%8C%BA%E7%89%88"&gt;&lt;img src="https://service-info-public.oss-cn-hangzhou.aliyuncs.com/computenest-en.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h4&gt;After Fork&lt;/h4&gt; 
&lt;p&gt;After fork, only retain the upstream sync action and disable other actions in your repository on GitHub.&lt;/p&gt; 
&lt;h4&gt;Keep Updated&lt;/h4&gt; 
&lt;p&gt;If you have deployed your own project following the one-click deployment steps in the README, you might encounter constant prompts indicating "updates available." This is because Vercel defaults to creating a new project instead of forking this one, resulting in an inability to detect updates accurately.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;We suggest you redeploy using the following steps, &lt;a href="https://lobehub.com/docs/self-hosting/advanced/upstream-sync"&gt;📘 Auto Sync With Latest&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h3&gt;&lt;code&gt;B&lt;/code&gt; Deploying with Docker&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/lobehub/lobe-chat-database"&gt;&lt;img src="https://img.shields.io/docker/v/lobehub/lobe-chat-database?color=369eff&amp;amp;label=docker&amp;amp;labelColor=black&amp;amp;logo=docker&amp;amp;logoColor=white&amp;amp;style=flat-square&amp;amp;sort=semver" alt="" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/lobehub/lobe-chat-database"&gt;&lt;img src="https://img.shields.io/docker/image-size/lobehub/lobe-chat-database?color=369eff&amp;amp;labelColor=black&amp;amp;style=flat-square&amp;amp;sort=semver" alt="" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/lobehub/lobe-chat-database"&gt;&lt;img src="https://img.shields.io/docker/pulls/lobehub/lobe-chat?color=45cc11&amp;amp;labelColor=black&amp;amp;style=flat-square&amp;amp;sort=semver" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We provide a Docker image for deploying the LobeChat service on your own private device. Use the following command to start the LobeChat service:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;create a folder to for storage files&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-fish"&gt;$ mkdir lobe-chat-db &amp;amp;&amp;amp; cd lobe-chat-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;init the LobeChat infrastructure&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-fish"&gt;bash &amp;lt;(curl -fsSL https://lobe.li/setup.sh)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Start the LobeChat service&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-fish"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;For detailed instructions on deploying with Docker, please refer to the &lt;a href="https://lobehub.com/docs/self-hosting/server-database/docker-compose"&gt;📘 Docker Deployment Guide&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h3&gt;Environment Variable&lt;/h3&gt; 
&lt;p&gt;This project provides some additional configuration items set with environment variables:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Environment Variable&lt;/th&gt; 
   &lt;th&gt;Required&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Example&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;This is the API key you apply on the OpenAI account page&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-xxxxxx...xxxxxx&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_PROXY_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;If you manually configure the OpenAI interface proxy, you can use this configuration item to override the default OpenAI API request base URL&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.chatanywhere.cn&lt;/code&gt; or &lt;code&gt;https://aihubmix.com/v1&lt;/code&gt; &lt;br /&gt;The default value is&lt;br /&gt;&lt;code&gt;https://api.openai.com/v1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ACCESS_CODE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Add a password to access this service; you can set a long password to avoid leaking. If this value contains a comma, it is a password array.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;awCTe)re_r74&lt;/code&gt; or &lt;code&gt;rtrt_ewee3@09!&lt;/code&gt; or &lt;code&gt;code1,code2,code3&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_MODEL_LIST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Used to control the model list. Use &lt;code&gt;+&lt;/code&gt; to add a model, &lt;code&gt;-&lt;/code&gt; to hide a model, and &lt;code&gt;model_name=display_name&lt;/code&gt; to customize the display name of a model, separated by commas.&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;qwen-7b-chat,+glm-6b,-gpt-3.5-turbo&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;The complete list of environment variables can be found in the &lt;a href="https://lobehub.com/docs/self-hosting/environment-variables"&gt;📘 Environment Variables&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;📦 Ecosystem&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;NPM&lt;/th&gt; 
   &lt;th&gt;Repository&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Version&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/@lobehub/ui"&gt;@lobehub/ui&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lobehub/lobe-ui"&gt;lobehub/lobe-ui&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Open-source UI component library dedicated to building AIGC web applications.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/@lobehub/ui"&gt;&lt;img src="https://img.shields.io/npm/v/@lobehub/ui?color=369eff&amp;amp;labelColor=black&amp;amp;logo=npm&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/@lobehub/icons"&gt;@lobehub/icons&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lobehub/lobe-icons"&gt;lobehub/lobe-icons&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Popular AI / LLM Model Brand SVG Logo and Icon Collection.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/@lobehub/icons"&gt;&lt;img src="https://img.shields.io/npm/v/@lobehub/icons?color=369eff&amp;amp;labelColor=black&amp;amp;logo=npm&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/@lobehub/tts"&gt;@lobehub/tts&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lobehub/lobe-tts"&gt;lobehub/lobe-tts&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;High-quality &amp;amp; reliable TTS/STT React Hooks library&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/@lobehub/tts"&gt;&lt;img src="https://img.shields.io/npm/v/@lobehub/tts?color=369eff&amp;amp;labelColor=black&amp;amp;logo=npm&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/@lobehub/lint"&gt;@lobehub/lint&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/lobehub/lobe-lint"&gt;lobehub/lobe-lint&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Configurations for ESlint, Stylelint, Commitlint, Prettier, Remark, and Semantic Release for LobeHub.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/@lobehub/lint"&gt;&lt;img src="https://img.shields.io/npm/v/@lobehub/lint?color=369eff&amp;amp;labelColor=black&amp;amp;logo=npm&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🧩 Plugins&lt;/h2&gt; 
&lt;p&gt;Plugins provide a means to extend the &lt;a href="https://lobehub.com/blog/openai-function-call"&gt;Function Calling&lt;/a&gt; capabilities of LobeChat. They can be used to introduce new function calls and even new ways to render message results. If you are interested in plugin development, please refer to our &lt;a href="https://lobehub.com/docs/usage/plugins/development"&gt;📘 Plugin Development Guide&lt;/a&gt; in the Wiki.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lobehub/lobe-chat-plugins"&gt;lobe-chat-plugins&lt;/a&gt;: This is the plugin index for LobeChat. It accesses index.json from this repository to display a list of available plugins for LobeChat to the user.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lobehub/chat-plugin-template"&gt;chat-plugin-template&lt;/a&gt;: This is the plugin template for LobeChat plugin development.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lobehub/chat-plugin-sdk"&gt;@lobehub/chat-plugin-sdk&lt;/a&gt;: The LobeChat Plugin SDK assists you in creating exceptional chat plugins for Lobe Chat.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lobehub/chat-plugins-gateway"&gt;@lobehub/chat-plugins-gateway&lt;/a&gt;: The LobeChat Plugins Gateway is a backend service that provides a gateway for LobeChat plugins. We deploy this service using Vercel. The primary API POST /api/v1/runner is deployed as an Edge Function.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;The plugin system is currently undergoing major development. You can learn more in the following issues:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;[x] &lt;a href="https://github.com/lobehub/lobe-chat/issues/73"&gt;&lt;strong&gt;Plugin Phase 1&lt;/strong&gt;&lt;/a&gt;: Implement separation of the plugin from the main body, split the plugin into an independent repository for maintenance, and realize dynamic loading of the plugin.&lt;/li&gt; 
  &lt;li&gt;[x] &lt;a href="https://github.com/lobehub/lobe-chat/issues/97"&gt;&lt;strong&gt;Plugin Phase 2&lt;/strong&gt;&lt;/a&gt;: The security and stability of the plugin's use, more accurately presenting abnormal states, the maintainability of the plugin architecture, and developer-friendly.&lt;/li&gt; 
  &lt;li&gt;[x] &lt;a href="https://github.com/lobehub/lobe-chat/issues/149"&gt;&lt;strong&gt;Plugin Phase 3&lt;/strong&gt;&lt;/a&gt;: Higher-level and more comprehensive customization capabilities, support for plugin authentication, and examples.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;⌨️ Local Development&lt;/h2&gt; 
&lt;p&gt;You can use GitHub Codespaces for online development:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/lobehub/lobe-chat"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Or clone it for local development:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-fish"&gt;$ git clone https://github.com/lobehub/lobe-chat.git
$ cd lobe-chat
$ pnpm install
$ pnpm dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you would like to learn more details, please feel free to look at our &lt;a href="https://github.com/lobehub/lobe-chat/wiki/index"&gt;📘 Development Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions of all types are more than welcome; if you are interested in contributing code, feel free to check out our GitHub &lt;a href="https://github.com/lobehub/lobe-chat/issues"&gt;Issues&lt;/a&gt; and &lt;a href="https://github.com/lobehub/lobe-chat/projects"&gt;Projects&lt;/a&gt; to get stuck in to show us what you're made of.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;We are creating a technology-driven forum, fostering knowledge interaction and the exchange of ideas that may culminate in mutual inspiration and collaborative innovation.&lt;/p&gt; 
 &lt;p&gt;Help us make LobeChat better. Welcome to provide product design feedback, user experience discussions directly to us.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Principal Maintainers:&lt;/strong&gt; &lt;a href="https://github.com/arvinxx"&gt;@arvinxx&lt;/a&gt; &lt;a href="https://github.com/canisminor1990"&gt;@canisminor1990&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/lobehub/lobe-chat/pulls"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%AF_pr_welcome-%E2%86%92-ffcb47?labelColor=black&amp;amp;style=for-the-badge" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lobehub/lobe-chat-agents"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%96/%F0%9F%8F%AA_submit_agent-%E2%86%92-c4f042?labelColor=black&amp;amp;style=for-the-badge" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lobehub/lobe-chat-plugins"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A7%A9/%F0%9F%8F%AA_submit_plugin-%E2%86%92-95f3d9?labelColor=black&amp;amp;style=for-the-badge" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://github.com/lobehub/lobe-chat/graphs/contributors" target="_blank"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;th colspan="2"&gt; &lt;br /&gt;&lt;img src="https://contrib.rocks/image?repo=lobehub/lobe-chat" /&gt;&lt;br /&gt;&lt;br /&gt; &lt;/th&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=2x3&amp;amp;color_scheme=dark" /&gt; 
      &lt;img src="https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=active&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=2x3&amp;amp;color_scheme=light" /&gt; 
     &lt;/picture&gt; &lt;/td&gt; 
    &lt;td rowspan="2"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=active&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=4x7&amp;amp;color_scheme=dark" /&gt; 
      &lt;img src="https://next.ossinsight.io/widgets/official/compose-org-participants-growth/thumbnail.png?activity=active&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=4x7&amp;amp;color_scheme=light" /&gt; 
     &lt;/picture&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=2x3&amp;amp;color_scheme=dark" /&gt; 
      &lt;img src="https://next.ossinsight.io/widgets/official/compose-org-active-contributors/thumbnail.png?activity=new&amp;amp;period=past_28_days&amp;amp;owner_id=131470832&amp;amp;repo_ids=643445235&amp;amp;image_size=2x3&amp;amp;color_scheme=light" /&gt; 
     &lt;/picture&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; &lt;/a&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;❤️ Sponsor&lt;/h2&gt; 
&lt;p&gt;Every bit counts and your one-time donation sparkles in our galaxy of support! You're a shooting star, making a swift and bright impact on our journey. Thank you for believing in us – your generosity guides us toward our mission, one brilliant flash at a time.&lt;/p&gt; 
&lt;a href="https://opencollective.com/lobehub" target="_blank"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/lobehub/.github/blob/main/static/sponsor-dark.png?raw=true" /&gt; 
  &lt;img src="https://github.com/lobehub/.github/raw/main/static/sponsor-light.png?raw=true" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🔗 More Products&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lobehub/sd-webui-lobe-theme"&gt;🅰️ Lobe SD Theme&lt;/a&gt;:&lt;/strong&gt; Modern theme for Stable Diffusion WebUI, exquisite interface design, highly customizable UI, and efficiency-boosting features.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lobehub/lobe-midjourney-webui"&gt;⛵️ Lobe Midjourney WebUI&lt;/a&gt;:&lt;/strong&gt; WebUI for Midjourney, leverages AI to quickly generate a wide array of rich and diverse images from text prompts, sparking creativity and enhancing conversations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lobehub/lobe-commit/tree/master/packages/lobe-i18n"&gt;🌏 Lobe i18n&lt;/a&gt; :&lt;/strong&gt; Lobe i18n is an automation tool for the i18n (internationalization) translation process, powered by ChatGPT. It supports features such as automatic splitting of large files, incremental updates, and customization options for the OpenAI model, API proxy, and temperature.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lobehub/lobe-commit/tree/master/packages/lobe-commit"&gt;💌 Lobe Commit&lt;/a&gt;:&lt;/strong&gt; Lobe Commit is a CLI tool that leverages Langchain/ChatGPT to generate Gitmoji-based commit messages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-BACK_TO_TOP-151515?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;details&gt;
 &lt;summary&gt;&lt;h4&gt;📝 License&lt;/h4&gt;&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Flobehub%2Flobe-chat"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Flobehub%2Flobe-chat.svg?type=large" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;p&gt;Copyright © 2025 &lt;a href="https://github.com/lobehub"&gt;LobeHub&lt;/a&gt;. &lt;br /&gt; This project is &lt;a href="https://raw.githubusercontent.com/lobehub/lobe-chat/main/LICENSE"&gt;LobeHub Community License&lt;/a&gt; licensed.&lt;/p&gt; 
&lt;!-- LINK GROUP --&gt;</description>
    </item>
    
    <item>
      <title>nextcloud/server</title>
      <link>https://github.com/nextcloud/server</link>
      <description>&lt;p&gt;☁️ Nextcloud server, a safe home for all your data&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Nextcloud Server ☁&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://api.reuse.software/info/github.com/nextcloud/server"&gt;&lt;img src="https://api.reuse.software/badge/github.com/nextcloud/server" alt="REUSE status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/nextcloud/server"&gt;&lt;img src="https://codecov.io/gh/nextcloud/server/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/209"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/209/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://contribute.design/nextcloud/server"&gt;&lt;img src="https://contribute.design/api/shield/nextcloud/server" alt="Design" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A safe home for all your data.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/nextcloud/screenshots/master/nextcloud-hub-files-25-preview.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Why is this so awesome? 🤩&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;📁 &lt;strong&gt;Access your Data&lt;/strong&gt; You can store your files, contacts, calendars, and more on a server of your choosing.&lt;/li&gt; 
 &lt;li&gt;🔄 &lt;strong&gt;Sync your Data&lt;/strong&gt; You keep your files, contacts, calendars, and more synchronized amongst your devices.&lt;/li&gt; 
 &lt;li&gt;🙌 &lt;strong&gt;Share your Data&lt;/strong&gt; …by giving others access to the stuff you want them to see or to collaborate with.&lt;/li&gt; 
 &lt;li&gt;🚀 &lt;strong&gt;Expandable with hundreds of Apps&lt;/strong&gt; ...like &lt;a href="https://github.com/nextcloud/calendar"&gt;Calendar&lt;/a&gt;, &lt;a href="https://github.com/nextcloud/contacts"&gt;Contacts&lt;/a&gt;, &lt;a href="https://github.com/nextcloud/mail"&gt;Mail&lt;/a&gt;, &lt;a href="https://github.com/nextcloud/spreed"&gt;Video Chat&lt;/a&gt; and all those you can discover in our &lt;a href="https://apps.nextcloud.com"&gt;App Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🔒 &lt;strong&gt;Security&lt;/strong&gt; with our encryption mechanisms, &lt;a href="https://hackerone.com/nextcloud"&gt;HackerOne bounty program&lt;/a&gt; and two-factor authentication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Do you want to learn more about how you can use Nextcloud to access, share, and protect your files, calendars, contacts, communication &amp;amp; more at home and in your organization? &lt;a href="https://nextcloud.com/athome/"&gt;&lt;strong&gt;Learn about all our Features&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Get your Nextcloud 🚚&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;☑️ &lt;a href="https://nextcloud.com/signup/"&gt;&lt;strong&gt;Simply sign up&lt;/strong&gt;&lt;/a&gt; at one of our providers either through our website or through the apps directly.&lt;/li&gt; 
 &lt;li&gt;🖥 &lt;a href="https://nextcloud.com/install/#instructions-server"&gt;&lt;strong&gt;Install&lt;/strong&gt; a server by yourself&lt;/a&gt; on your hardware or by using one of our ready-to-use &lt;strong&gt;appliances&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;📦 Buy one of the &lt;a href="https://nextcloud.com/devices/"&gt;awesome &lt;strong&gt;devices&lt;/strong&gt; coming with a preinstalled Nextcloud&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🏢 Find a &lt;a href="https://nextcloud.com/providers/"&gt;service &lt;strong&gt;provider&lt;/strong&gt;&lt;/a&gt; who hosts Nextcloud for you or your company&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Enterprise? Public Sector or Education user? You may want to have a look into &lt;a href="https://nextcloud.com/enterprise/"&gt;&lt;strong&gt;Nextcloud Enterprise&lt;/strong&gt;&lt;/a&gt; provided by Nextcloud GmbH.&lt;/p&gt; 
&lt;h2&gt;Get in touch 💬&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://help.nextcloud.com"&gt;📋 Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.facebook.com/nextclouders"&gt;👥 Facebook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/Nextclouders"&gt;🐣 Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.xyz/@nextcloud"&gt;🐘 Mastodon&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can also &lt;a href="https://nextcloud.com/support"&gt;get support for Nextcloud&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Join the team 👪&lt;/h2&gt; 
&lt;p&gt;There are many ways to contribute, of which development is only one! Find out &lt;a href="https://nextcloud.com/contribute/"&gt;how to get involved&lt;/a&gt;, including as a translator, designer, tester, helping others, and much more! 😍&lt;/p&gt; 
&lt;h3&gt;Development setup 👩‍💻&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;🚀 &lt;a href="https://docs.nextcloud.com/server/latest/developer_manual/getting_started/devenv.html"&gt;Set up your local development environment&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🐛 &lt;a href="https://github.com/nextcloud/server/labels/good%20first%20issue"&gt;Pick a good first issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;👩‍🔧 Create a branch and make your changes. Remember to sign off your commits using &lt;code&gt;git commit -sm "Your commit message"&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;⬆ Create a &lt;a href="https://opensource.guide/how-to-contribute/#opening-a-pull-request"&gt;pull request&lt;/a&gt; and &lt;code&gt;@mention&lt;/code&gt; the people from the issue to review&lt;/li&gt; 
 &lt;li&gt;👍 Fix things that come up during a review&lt;/li&gt; 
 &lt;li&gt;🎉 Wait for it to get merged!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Third-party components are handled as git submodules which have to be initialized first. So aside from the regular git checkout invoking &lt;code&gt;git submodule update --init&lt;/code&gt; or a similar command is needed, for details see Git documentation.&lt;/p&gt; 
&lt;p&gt;Several apps that are included by default in regular releases such as &lt;a href="https://github.com/nextcloud/firstrunwizard"&gt;First run wizard&lt;/a&gt; or &lt;a href="https://github.com/nextcloud/activity"&gt;Activity&lt;/a&gt; are missing in &lt;code&gt;master&lt;/code&gt; and have to be installed manually by cloning them into the &lt;code&gt;apps&lt;/code&gt; subfolder.&lt;/p&gt; 
&lt;p&gt;Otherwise, git checkouts can be handled the same as release archives, by using the &lt;code&gt;stable*&lt;/code&gt; branches. Note they should never be used on production systems.&lt;/p&gt; 
&lt;h3&gt;Tools we use 🛠&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://browserstack.com"&gt;👀 BrowserStack&lt;/a&gt; for cross-browser testing&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wave.webaim.org/extension/"&gt;🌊 WAVE&lt;/a&gt; for accessibility testing&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.google.com/web/tools/lighthouse/"&gt;🚨 Lighthouse&lt;/a&gt; for testing performance, accessibility, and more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Helpful bots at GitHub &lt;span&gt;🤖&lt;/span&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Comment on a pull request with &lt;code&gt;/update-3rdparty&lt;/code&gt; to update the 3rd party submodule. It will update to the last commit of the 3rd party branch named like the PR target.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Ignore code style updates in git blame&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;git config blame.ignoreRevsFile .git-blame-ignore-revs&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Contribution guidelines 📜&lt;/h2&gt; 
&lt;p&gt;All contributions to this repository from June 16, 2016, and onward are considered to be licensed under the AGPLv3 or any later version.&lt;/p&gt; 
&lt;p&gt;Nextcloud doesn't require a CLA (Contributor License Agreement). The copyright belongs to all the individual contributors. Therefore we recommend that every contributor adds the following line to the &lt;a href="https://raw.githubusercontent.com/nextcloud/server/master/AUTHORS"&gt;AUTHORS&lt;/a&gt; file if they made substantial changes to the code:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;- &amp;lt;your name&amp;gt; &amp;lt;your email address&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please read the &lt;a href="https://nextcloud.com/community/code-of-conduct/"&gt;Code of Conduct&lt;/a&gt;. This document offers some guidance to ensure Nextcloud participants can cooperate effectively in a positive and inspiring atmosphere and to explain how together we can strengthen and support each other.&lt;/p&gt; 
&lt;p&gt;Please review the &lt;a href="https://raw.githubusercontent.com/nextcloud/server/master/.github/CONTRIBUTING.md"&gt;guidelines for contributing&lt;/a&gt; to this repository.&lt;/p&gt; 
&lt;p&gt;More information on how to contribute: &lt;a href="https://nextcloud.com/contribute/"&gt;https://nextcloud.com/contribute/&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>YILING0013/AI_NovelGenerator</title>
      <link>https://github.com/YILING0013/AI_NovelGenerator</link>
      <description>&lt;p&gt;使用ai生成多章节的长篇小说，自动衔接上下文、伏笔&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;📖 自动小说生成工具&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;ul&gt; 
  &lt;li&gt;当前没有什么精力维护该项目，本身该项目并无任何收益，以及临近毕业，有很多内容要忙，如果后面有时间的话，再考虑基于更新的技术去重构吧。——2025/9/24&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;✨ &lt;strong&gt;核心功能&lt;/strong&gt; ✨&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;功能模块&lt;/th&gt; 
    &lt;th&gt;关键能力&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;🎨 小说设定工坊&lt;/td&gt; 
    &lt;td&gt;世界观架构 / 角色设定 / 剧情蓝图&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;📖 智能章节生成&lt;/td&gt; 
    &lt;td&gt;多阶段生成保障剧情连贯性&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;🧠 状态追踪系统&lt;/td&gt; 
    &lt;td&gt;角色发展轨迹 / 伏笔管理系统&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;🔍 语义检索引擎&lt;/td&gt; 
    &lt;td&gt;基于向量的长程上下文一致性维护&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;📚 知识库集成&lt;/td&gt; 
    &lt;td&gt;支持本地文档参考&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;✅ 自动审校机制&lt;/td&gt; 
    &lt;td&gt;检测剧情矛盾与逻辑冲突&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;🖥 可视化工作台&lt;/td&gt; 
    &lt;td&gt;全流程GUI操作，配置/生成/审校一体化&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;一款基于大语言模型的多功能小说生成器，助您高效创作逻辑严谨、设定统一的长篇故事&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📑 目录导航&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/YILING0013/AI_NovelGenerator/main/#-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"&gt;环境准备&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/YILING0013/AI_NovelGenerator/main/#-%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84"&gt;项目架构&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/YILING0013/AI_NovelGenerator/main/#%E2%9A%99%EF%B8%8F-%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97"&gt;配置指南&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/YILING0013/AI_NovelGenerator/main/#%F0%9F%9A%80-%E8%BF%90%E8%A1%8C%E8%AF%B4%E6%98%8E"&gt;运行说明&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/YILING0013/AI_NovelGenerator/main/#%F0%9F%93%98-%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B"&gt;使用教程&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/YILING0013/AI_NovelGenerator/main/#%E2%9D%93-%E7%96%91%E9%9A%BE%E8%A7%A3%E7%AD%94"&gt;疑难解答&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🛠 环境准备&lt;/h2&gt; 
&lt;p&gt;确保满足以下运行条件：&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.9+&lt;/strong&gt; 运行环境（推荐3.10-3.12之间）&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;pip&lt;/strong&gt; 包管理工具&lt;/li&gt; 
 &lt;li&gt;有效API密钥： 
  &lt;ul&gt; 
   &lt;li&gt;云端服务：OpenAI / DeepSeek 等&lt;/li&gt; 
   &lt;li&gt;本地服务：Ollama 等兼容 OpenAI 的接口&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📥 安装说明&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;下载项目&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;通过 &lt;a href="https://github.com"&gt;GitHub&lt;/a&gt; 下载项目 ZIP 文件，或使用以下命令克隆本项目： &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/YILING0013/AI_NovelGenerator
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;安装编译工具（可选）&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;如果对某些包无法正常安装，访问 &lt;a href="https://visualstudio.microsoft.com/zh-hans/visual-cpp-build-tools/"&gt;Visual Studio Build Tools&lt;/a&gt; 下载并安装C++编译工具，用于构建部分模块包；&lt;/li&gt; 
   &lt;li&gt;安装时，默认只包含 MSBuild 工具，需手动勾选左上角列表栏中的 &lt;strong&gt;C++ 桌面开发&lt;/strong&gt; 选项。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;安装依赖并运行&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;打开终端，进入项目源文件目录： &lt;pre&gt;&lt;code class="language-bash"&gt;cd AI_NovelGenerator
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt;安装项目依赖： &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt;安装完成后，运行主程序： &lt;pre&gt;&lt;code class="language-bash"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;如果缺失部分依赖，后续&lt;strong&gt;手动执行&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install XXX
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;进行安装即可&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;🗂 项目架构&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;novel-generator/
├── main.py                      # 入口文件, 运行 GUI
├── consistency_checker.py       # 一致性检查, 防止剧情冲突
|—— chapter_directory_parser.py  # 目录解析
|—— embedding_adapters.py        # Embedding 接口封装
|—— llm_adapters.py              # LLM 接口封装
├── prompt_definitions.py        # 定义 AI 提示词
├── utils.py                     # 常用工具函数, 文件操作
├── config_manager.py            # 管理配置 (API Key, Base URL)
├── config.json                  # 用户配置文件 (可选)
├── novel_generator/             # 章节生成核心逻辑
├── ui/                          # 图形界面
└── vectorstore/                 # (可选) 本地向量数据库存储
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;⚙️ 配置指南&lt;/h2&gt; 
&lt;h3&gt;📌 基础配置（config.json）&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "api_key": "sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX",
    "base_url": "https://api.openai.com/v1",
    "interface_format": "OpenAI",
    "model_name": "gpt-4o-mini",
    "temperature": 0.7,
    "max_tokens": 4096,
    "embedding_api_key": "sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX",
    "embedding_interface_format": "OpenAI",
    "embedding_url": "https://api.openai.com/v1",
    "embedding_model_name": "text-embedding-ada-002",
    "embedding_retrieval_k": 4,
    "topic": "星穹铁道主角星穿越到原神提瓦特大陆，拯救提瓦特大陆，并与其中的角色展开爱恨情仇的小说",
    "genre": "玄幻",
    "num_chapters": 120,
    "word_number": 4000,
    "filepath": "D:/AI_NovelGenerator/filepath"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;🔧 配置说明&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;生成模型配置&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;api_key&lt;/code&gt;: 大模型服务的API密钥&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;base_url&lt;/code&gt;: API终端地址（本地服务填Ollama等地址）&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;interface_format&lt;/code&gt;: 接口模式&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;model_name&lt;/code&gt;: 主生成模型名称（如gpt-4, claude-3等）&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;temperature&lt;/code&gt;: 创意度参数（0-1，越高越有创造性）&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;max_tokens&lt;/code&gt;: 模型最大回复长度&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Embedding模型配置&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;embedding_model_name&lt;/code&gt;: 模型名称（如Ollama的nomic-embed-text）&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;embedding_url&lt;/code&gt;: 服务地址&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;embedding_retrieval_k&lt;/code&gt;:&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;小说参数配置&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;topic&lt;/code&gt;: 核心故事主题&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;genre&lt;/code&gt;: 作品类型&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;num_chapters&lt;/code&gt;: 总章节数&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;word_number&lt;/code&gt;: 单章目标字数&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;filepath&lt;/code&gt;: 生成文件存储路径&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🚀 运行说明&lt;/h2&gt; 
&lt;h3&gt;&lt;strong&gt;方式 1：使用 Python 解释器&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;执行后，GUI 将会启动，你可以在图形界面中进行各项操作。&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;方式 2：打包为可执行文件&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;如果你想在无 Python 环境的机器上使用本工具，可以使用 &lt;strong&gt;PyInstaller&lt;/strong&gt; 进行打包：&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install pyinstaller
pyinstaller main.spec
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;打包完成后，会在 &lt;code&gt;dist/&lt;/code&gt; 目录下生成可执行文件（如 Windows 下的 &lt;code&gt;main.exe&lt;/code&gt;）。&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📘 使用教程&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;启动后，先完成基本参数设置：&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;API Key &amp;amp; Base URL&lt;/strong&gt;（如 &lt;code&gt;https://api.openai.com/v1&lt;/code&gt;）&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;模型名称&lt;/strong&gt;（如 &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;、&lt;code&gt;gpt-4o&lt;/code&gt; 等）&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Temperature&lt;/strong&gt; (0~1，决定文字创意程度)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;主题(Topic)&lt;/strong&gt;（如 “废土世界的 AI 叛乱”）&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;类型(Genre)&lt;/strong&gt;（如 “科幻”/“魔幻”/“都市幻想”）&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;章节数&lt;/strong&gt;、&lt;strong&gt;每章字数&lt;/strong&gt;（如 10 章，每章约 3000 字）&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;保存路径&lt;/strong&gt;（建议创建一个新的输出文件夹）&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;点击「Step1. 生成设定」&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;系统将基于主题、类型、章节数等信息，生成： 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;Novel_setting.txt&lt;/code&gt;：包含世界观、角色信息、雷点暗线等。&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;可以在生成后的 &lt;code&gt;Novel_setting.txt&lt;/code&gt; 中查看或修改设定内容。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;点击「Step2. 生成目录」&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;系统会根据已完成的 &lt;code&gt;Novel_setting.txt&lt;/code&gt; 内容，为全部章节生成： 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;Novel_directory.txt&lt;/code&gt;：包括每章标题和简要提示。&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;可以在生成后的文件中查看、修改或补充章节标题和描述。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;点击「Step3. 生成章节草稿」&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;在生成章节之前，你可以： 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;设置章节号&lt;/strong&gt;（如写第 1 章，就填 &lt;code&gt;1&lt;/code&gt;）&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;在“本章指导”输入框&lt;/strong&gt;中提供对本章剧情的任何期望或提示&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;点击按钮后，系统将： 
    &lt;ul&gt; 
     &lt;li&gt;自动读取前文设定、&lt;code&gt;Novel_directory.txt&lt;/code&gt;、以及已定稿章节&lt;/li&gt; 
     &lt;li&gt;调用向量检索回顾剧情，保证上下文连贯&lt;/li&gt; 
     &lt;li&gt;生成本章大纲 (&lt;code&gt;outline_X.txt&lt;/code&gt;) 及正文 (&lt;code&gt;chapter_X.txt&lt;/code&gt;)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;生成完成后，你可在左侧的文本框查看、编辑本章草稿内容。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;点击「Step4. 定稿当前章节」&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;系统将： 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;更新全局摘要&lt;/strong&gt;（写入 &lt;code&gt;global_summary.txt&lt;/code&gt;）&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;更新角色状态&lt;/strong&gt;（写入 &lt;code&gt;character_state.txt&lt;/code&gt;）&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;更新向量检索库&lt;/strong&gt;（保证后续章节可以调用最新信息）&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;更新剧情要点&lt;/strong&gt;（如 &lt;code&gt;plot_arcs.txt&lt;/code&gt;）&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;定稿完成后，你可以在 &lt;code&gt;chapter_X.txt&lt;/code&gt; 中看到定稿后的文本。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;一致性检查（可选）&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;点击「[可选] 一致性审校」按钮，对最新章节进行冲突检测，如角色逻辑、剧情前后矛盾等。&lt;/li&gt; 
   &lt;li&gt;若有冲突，会在日志区输出详细提示。&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;重复第 4-6 步&lt;/strong&gt; 直到所有章节生成并定稿！&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;向量检索配置提示&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;embedding模型需要显示指定接口和模型名称；&lt;/li&gt; 
  &lt;li&gt;使用&lt;strong&gt;本地Ollama&lt;/strong&gt;的&lt;strong&gt;Embedding&lt;/strong&gt;时需提前启动Ollama服务： &lt;pre&gt;&lt;code class="language-bash"&gt;ollama serve  # 启动服务
ollama pull nomic-embed-text  # 下载/启用模型
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt;切换不同Embedding模型后建议清空vectorstore目录&lt;/li&gt; 
  &lt;li&gt;云端Embedding需确保对应API权限已开通&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;❓ 疑难解答&lt;/h2&gt; 
&lt;h3&gt;Q1: Expecting value: line 1 column 1 (char 0)&lt;/h3&gt; 
&lt;p&gt;该问题大概率由于API未正确响应造成，也许响应了一个html？其它内容，导致出现该报错；&lt;/p&gt; 
&lt;h3&gt;Q2: HTTP/1.1 504 Gateway Timeout？&lt;/h3&gt; 
&lt;p&gt;确认接口是否稳定；&lt;/p&gt; 
&lt;h3&gt;Q3: 如何切换不同的Embedding提供商？&lt;/h3&gt; 
&lt;p&gt;在GUI界面中对应输入即可。&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;如有更多问题或需求，欢迎在&lt;strong&gt;项目 Issues&lt;/strong&gt; 中提出。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PHPMailer/PHPMailer</title>
      <link>https://github.com/PHPMailer/PHPMailer</link>
      <description>&lt;p&gt;The classic email sending library for PHP&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://supportukrainenow.org/"&gt;&lt;img src="https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/banner2-direct.svg?sanitize=true" alt="SWUbanner" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.github.com/PHPMailer/PHPMailer/master/examples/images/phpmailer.png" alt="PHPMailer" /&gt;&lt;/p&gt; 
&lt;h1&gt;PHPMailer – A full-featured email creation and transfer class for PHP&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/PHPMailer/PHPMailer/actions"&gt;&lt;img src="https://github.com/PHPMailer/PHPMailer/workflows/Tests/badge.svg?sanitize=true" alt="Test status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/PHPMailer/PHPMailer"&gt;&lt;img src="https://codecov.io/gh/PHPMailer/PHPMailer/branch/master/graph/badge.svg?token=iORZpwmYmM" alt="codecov.io" /&gt;&lt;/a&gt; &lt;a href="https://packagist.org/packages/phpmailer/phpmailer"&gt;&lt;img src="https://poser.pugx.org/phpmailer/phpmailer/v/stable.svg?sanitize=true" alt="Latest Stable Version" /&gt;&lt;/a&gt; &lt;a href="https://packagist.org/packages/phpmailer/phpmailer"&gt;&lt;img src="https://poser.pugx.org/phpmailer/phpmailer/downloads" alt="Total Downloads" /&gt;&lt;/a&gt; &lt;a href="https://packagist.org/packages/phpmailer/phpmailer"&gt;&lt;img src="https://poser.pugx.org/phpmailer/phpmailer/license.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://phpmailer.github.io/PHPMailer/"&gt;&lt;img src="https://github.com/phpmailer/phpmailer/workflows/Docs/badge.svg?sanitize=true" alt="API Docs" /&gt;&lt;/a&gt; &lt;a href="https://api.securityscorecards.dev/projects/github.com/PHPMailer/PHPMailer"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/PHPMailer/PHPMailer/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Probably the world's most popular code for sending email from PHP!&lt;/li&gt; 
 &lt;li&gt;Used by many open-source projects: WordPress, Drupal, 1CRM, SugarCRM, Yii, Joomla! and many more&lt;/li&gt; 
 &lt;li&gt;Integrated SMTP support – send without a local mail server&lt;/li&gt; 
 &lt;li&gt;Send emails with multiple To, CC, BCC, and Reply-to addresses&lt;/li&gt; 
 &lt;li&gt;Multipart/alternative emails for mail clients that do not read HTML email&lt;/li&gt; 
 &lt;li&gt;Add attachments, including inline&lt;/li&gt; 
 &lt;li&gt;Support for UTF-8 content and 8bit, base64, binary, and quoted-printable encodings&lt;/li&gt; 
 &lt;li&gt;Full UTF-8 support when using servers that support &lt;code&gt;SMTPUTF8&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Support for iCal events in multiparts and attachments&lt;/li&gt; 
 &lt;li&gt;SMTP authentication with &lt;code&gt;LOGIN&lt;/code&gt;, &lt;code&gt;PLAIN&lt;/code&gt;, &lt;code&gt;CRAM-MD5&lt;/code&gt;, and &lt;code&gt;XOAUTH2&lt;/code&gt; mechanisms over SMTPS and SMTP+STARTTLS transports&lt;/li&gt; 
 &lt;li&gt;Validates email addresses automatically&lt;/li&gt; 
 &lt;li&gt;Protects against header injection attacks&lt;/li&gt; 
 &lt;li&gt;Error messages in over 50 languages!&lt;/li&gt; 
 &lt;li&gt;DKIM and S/MIME signing support&lt;/li&gt; 
 &lt;li&gt;Compatible with PHP 5.5 and later, including PHP 8.4&lt;/li&gt; 
 &lt;li&gt;Namespaced to prevent name clashes&lt;/li&gt; 
 &lt;li&gt;Much more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why you might need it&lt;/h2&gt; 
&lt;p&gt;Many PHP developers need to send email from their code. The only PHP function that supports this directly is &lt;a href="https://www.php.net/manual/en/function.mail.php"&gt;&lt;code&gt;mail()&lt;/code&gt;&lt;/a&gt;. However, it does not provide any assistance for making use of popular features such as authentication, HTML messages, and attachments.&lt;/p&gt; 
&lt;p&gt;Formatting email correctly is surprisingly difficult. There are myriad overlapping (and conflicting) standards, requiring tight adherence to horribly complicated formatting and encoding rules – the vast majority of code that you'll find online that uses the &lt;code&gt;mail()&lt;/code&gt; function directly is just plain wrong, if not unsafe!&lt;/p&gt; 
&lt;p&gt;The PHP &lt;code&gt;mail()&lt;/code&gt; function usually sends via a local mail server, typically fronted by a &lt;code&gt;sendmail&lt;/code&gt; binary on Linux, BSD, and macOS platforms, however, Windows usually doesn't include a local mail server; PHPMailer's integrated SMTP client allows email sending on all platforms without needing a local mail server. Be aware though, that the &lt;code&gt;mail()&lt;/code&gt; function should be avoided when possible; it's both faster and &lt;a href="https://exploitbox.io/paper/Pwning-PHP-Mail-Function-For-Fun-And-RCE.html"&gt;safer&lt;/a&gt; to use SMTP to localhost.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Please&lt;/em&gt; don't be tempted to do it yourself – if you don't use PHPMailer, there are many other excellent libraries that you should look at before rolling your own. Try &lt;a href="https://symfony.com/doc/current/mailer.html"&gt;Symfony Mailer&lt;/a&gt;, &lt;a href="https://docs.laminas.dev/laminas-mail/"&gt;Laminas/Mail&lt;/a&gt;, &lt;a href="https://github.com/zetacomponents/Mail"&gt;ZetaComponents&lt;/a&gt;, etc.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This software is distributed under the &lt;a href="https://www.gnu.org/licenses/old-licenses/lgpl-2.1.html"&gt;LGPL 2.1&lt;/a&gt; license, along with the &lt;a href="https://gplcc.github.io/gplcc/"&gt;GPL Cooperation Commitment&lt;/a&gt;. Please read &lt;a href="https://github.com/PHPMailer/PHPMailer/raw/master/LICENSE"&gt;LICENSE&lt;/a&gt; for information on the software availability and distribution.&lt;/p&gt; 
&lt;h2&gt;Installation &amp;amp; loading&lt;/h2&gt; 
&lt;p&gt;PHPMailer is available on &lt;a href="https://packagist.org/packages/phpmailer/phpmailer"&gt;Packagist&lt;/a&gt; (using semantic versioning), and installation via &lt;a href="https://getcomposer.org"&gt;Composer&lt;/a&gt; is the recommended way to install PHPMailer. Just add this line to your &lt;code&gt;composer.json&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"phpmailer/phpmailer": "^6.11.1"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or run&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;composer require phpmailer/phpmailer
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that the &lt;code&gt;vendor&lt;/code&gt; folder and the &lt;code&gt;vendor/autoload.php&lt;/code&gt; script are generated by Composer; they are not part of PHPMailer.&lt;/p&gt; 
&lt;p&gt;If you want to use XOAUTH2 authentication, you will also need to add a dependency on the &lt;code&gt;league/oauth2-client&lt;/code&gt; and appropriate service adapters package in your &lt;code&gt;composer.json&lt;/code&gt;, or take a look at by @decomplexity's &lt;a href="https://github.com/decomplexity/SendOauth2"&gt;SendOauth2 wrapper&lt;/a&gt;, especially if you're using Microsoft services.&lt;/p&gt; 
&lt;p&gt;Alternatively, if you're not using Composer, you can &lt;a href="https://github.com/PHPMailer/PHPMailer/archive/master.zip"&gt;download PHPMailer as a zip file&lt;/a&gt;, (note that docs and examples are not included in the zip file), then copy the contents of the PHPMailer folder into one of the &lt;code&gt;include_path&lt;/code&gt; directories specified in your PHP configuration and load each class file manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-php"&gt;&amp;lt;?php
use PHPMailer\PHPMailer\PHPMailer;
use PHPMailer\PHPMailer\Exception;

require 'path/to/PHPMailer/src/Exception.php';
require 'path/to/PHPMailer/src/PHPMailer.php';
require 'path/to/PHPMailer/src/SMTP.php';
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're not using the &lt;code&gt;SMTP&lt;/code&gt; class explicitly (you're probably not), you don't need a &lt;code&gt;use&lt;/code&gt; line for it. Even if you're not using exceptions, you do still need to load the &lt;code&gt;Exception&lt;/code&gt; class as it is used internally.&lt;/p&gt; 
&lt;h2&gt;Legacy versions&lt;/h2&gt; 
&lt;p&gt;PHPMailer 5.2 (which is compatible with PHP 5.0 — 7.0) is no longer supported, even for security updates. You will find the latest version of 5.2 in the &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/5.2-stable"&gt;5.2-stable branch&lt;/a&gt;. If you're using PHP 5.5 or later (which you should be), switch to the 6.x releases.&lt;/p&gt; 
&lt;h3&gt;Upgrading from 5.2&lt;/h3&gt; 
&lt;p&gt;The biggest changes are that source files are now in the &lt;code&gt;src/&lt;/code&gt; folder, and PHPMailer now declares the namespace &lt;code&gt;PHPMailer\PHPMailer&lt;/code&gt;. This has several important effects – &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/UPGRADING.md"&gt;read the upgrade guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Minimal installation&lt;/h3&gt; 
&lt;p&gt;While installing the entire package manually or with Composer is simple, convenient, and reliable, you may want to include only vital files in your project. At the very least you will need &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/src/PHPMailer.php"&gt;src/PHPMailer.php&lt;/a&gt;. If you're using SMTP, you'll need &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/src/SMTP.php"&gt;src/SMTP.php&lt;/a&gt;, and if you're using POP-before SMTP (&lt;em&gt;very&lt;/em&gt; unlikely!), you'll need &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/src/POP3.php"&gt;src/POP3.php&lt;/a&gt;. You can skip the &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/language/"&gt;language&lt;/a&gt; folder if you're not showing errors to users and can make do with English-only errors. If you're using XOAUTH2 you will need &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/src/OAuth.php"&gt;src/OAuth.php&lt;/a&gt; as well as the Composer dependencies for the services you wish to authenticate with. Really, it's much easier to use Composer!&lt;/p&gt; 
&lt;h2&gt;A Simple Example&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-php"&gt;&amp;lt;?php
//Import PHPMailer classes into the global namespace
//These must be at the top of your script, not inside a function
use PHPMailer\PHPMailer\PHPMailer;
use PHPMailer\PHPMailer\SMTP;
use PHPMailer\PHPMailer\Exception;

//Load Composer's autoloader (created by composer, not included with PHPMailer)
require 'vendor/autoload.php';

//Create an instance; passing `true` enables exceptions
$mail = new PHPMailer(true);

try {
    //Server settings
    $mail-&amp;gt;SMTPDebug = SMTP::DEBUG_SERVER;                      //Enable verbose debug output
    $mail-&amp;gt;isSMTP();                                            //Send using SMTP
    $mail-&amp;gt;Host       = 'smtp.example.com';                     //Set the SMTP server to send through
    $mail-&amp;gt;SMTPAuth   = true;                                   //Enable SMTP authentication
    $mail-&amp;gt;Username   = 'user@example.com';                     //SMTP username
    $mail-&amp;gt;Password   = 'secret';                               //SMTP password
    $mail-&amp;gt;SMTPSecure = PHPMailer::ENCRYPTION_SMTPS;            //Enable implicit TLS encryption
    $mail-&amp;gt;Port       = 465;                                    //TCP port to connect to; use 587 if you have set `SMTPSecure = PHPMailer::ENCRYPTION_STARTTLS`

    //Recipients
    $mail-&amp;gt;setFrom('from@example.com', 'Mailer');
    $mail-&amp;gt;addAddress('joe@example.net', 'Joe User');     //Add a recipient
    $mail-&amp;gt;addAddress('ellen@example.com');               //Name is optional
    $mail-&amp;gt;addReplyTo('info@example.com', 'Information');
    $mail-&amp;gt;addCC('cc@example.com');
    $mail-&amp;gt;addBCC('bcc@example.com');

    //Attachments
    $mail-&amp;gt;addAttachment('/var/tmp/file.tar.gz');         //Add attachments
    $mail-&amp;gt;addAttachment('/tmp/image.jpg', 'new.jpg');    //Optional name

    //Content
    $mail-&amp;gt;isHTML(true);                                  //Set email format to HTML
    $mail-&amp;gt;Subject = 'Here is the subject';
    $mail-&amp;gt;Body    = 'This is the HTML message body &amp;lt;b&amp;gt;in bold!&amp;lt;/b&amp;gt;';
    $mail-&amp;gt;AltBody = 'This is the body in plain text for non-HTML mail clients';

    $mail-&amp;gt;send();
    echo 'Message has been sent';
} catch (Exception $e) {
    echo "Message could not be sent. Mailer Error: {$mail-&amp;gt;ErrorInfo}";
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You'll find plenty to play with in the &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/examples"&gt;examples&lt;/a&gt; folder, which covers many common scenarios including sending through Gmail, building contact forms, sending to mailing lists, and more.&lt;/p&gt; 
&lt;p&gt;If you are re-using the instance (e.g. when sending to a mailing list), you may need to clear the recipient list to avoid sending duplicate messages. See &lt;a href="https://github.com/PHPMailer/PHPMailer/raw/master/examples/mailing_list.phps"&gt;the mailing list example&lt;/a&gt; for further guidance.&lt;/p&gt; 
&lt;p&gt;That's it. You should now be ready to use PHPMailer!&lt;/p&gt; 
&lt;h2&gt;Localization&lt;/h2&gt; 
&lt;p&gt;PHPMailer defaults to English, but in the &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/language/"&gt;language&lt;/a&gt; folder, you'll find many translations for PHPMailer error messages that you may encounter. Their filenames contain &lt;a href="https://en.wikipedia.org/wiki/ISO_639-1"&gt;ISO 639-1&lt;/a&gt; language code for the translations, for example &lt;code&gt;fr&lt;/code&gt; for French. To specify a language, you need to tell PHPMailer which one to use, like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-php"&gt;//To load the French version
$mail-&amp;gt;setLanguage('fr', '/optional/path/to/language/directory/');
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We welcome corrections and new languages – if you're looking for corrections, run the &lt;a href="https://github.com/PHPMailer/PHPMailer/raw/master/test/Language/TranslationCompletenessTest.php"&gt;Language/TranslationCompletenessTest.php&lt;/a&gt; script in the tests folder and it will show any missing translations.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Start reading at the &lt;a href="https://github.com/PHPMailer/PHPMailer/wiki"&gt;GitHub wiki&lt;/a&gt;. If you're having trouble, head for &lt;a href="https://github.com/PHPMailer/PHPMailer/wiki/Troubleshooting"&gt;the troubleshooting guide&lt;/a&gt; as it's frequently updated.&lt;/p&gt; 
&lt;p&gt;Examples of how to use PHPMailer for common scenarios can be found in the &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/examples"&gt;examples&lt;/a&gt; folder. If you're looking for a good starting point, we recommend you start with &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/examples/gmail.phps"&gt;the Gmail example&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To reduce PHPMailer's deployed code footprint, examples are not included if you load PHPMailer via Composer or via &lt;a href="https://github.com/PHPMailer/PHPMailer/archive/master.zip"&gt;GitHub's zip file download&lt;/a&gt;, so you'll need to either clone the git repository or use the above links to get to the examples directly.&lt;/p&gt; 
&lt;p&gt;Complete generated API documentation is &lt;a href="https://phpmailer.github.io/PHPMailer/"&gt;available online&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can generate complete API-level documentation by running &lt;code&gt;phpdoc&lt;/code&gt; in the top-level folder, and documentation will appear in the &lt;code&gt;docs&lt;/code&gt; folder, though you'll need to have &lt;a href="https://www.phpdoc.org"&gt;PHPDocumentor&lt;/a&gt; installed. You may find &lt;a href="https://github.com/PHPMailer/PHPMailer/raw/master/test/PHPMailer/PHPMailerTest.php"&gt;the unit tests&lt;/a&gt; a good reference for how to do various operations such as encryption.&lt;/p&gt; 
&lt;p&gt;If the documentation doesn't cover what you need, search the &lt;a href="https://stackoverflow.com/questions/tagged/phpmailer"&gt;many questions on Stack Overflow&lt;/a&gt;, and before you ask a question about "SMTP Error: Could not connect to SMTP host.", &lt;a href="https://github.com/PHPMailer/PHPMailer/wiki/Troubleshooting"&gt;read the troubleshooting guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Tests&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/test/"&gt;PHPMailer tests&lt;/a&gt; use PHPUnit 9, with &lt;a href="https://github.com/Yoast/PHPUnit-Polyfills"&gt;a polyfill&lt;/a&gt; to let 9-style tests run on older PHPUnit and PHP versions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/PHPMailer/PHPMailer/actions"&gt;&lt;img src="https://github.com/PHPMailer/PHPMailer/workflows/Tests/badge.svg?sanitize=true" alt="Test status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If this isn't passing, is there something you can do to help?&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;Please disclose any vulnerabilities found responsibly – report security issues to the maintainers privately.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/PHPMailer/PHPMailer/tree/master/SECURITY.md"&gt;SECURITY&lt;/a&gt; and &lt;a href="https://github.com/PHPMailer/PHPMailer/security"&gt;PHPMailer's security advisories on GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please submit bug reports, suggestions, and pull requests to the &lt;a href="https://github.com/PHPMailer/PHPMailer/issues"&gt;GitHub issue tracker&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We're particularly interested in fixing edge cases, expanding test coverage, and updating translations.&lt;/p&gt; 
&lt;p&gt;If you found a mistake in the docs, or want to add something, go ahead and amend the wiki – anyone can edit it.&lt;/p&gt; 
&lt;p&gt;If you have git clones from prior to the move to the PHPMailer GitHub organisation, you'll need to update any remote URLs referencing the old GitHub location with a command like this from within your clone:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git remote set-url upstream https://github.com/PHPMailer/PHPMailer.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please &lt;em&gt;don't&lt;/em&gt; use the SourceForge or Google Code projects any more; they are obsolete and no longer maintained.&lt;/p&gt; 
&lt;h2&gt;Sponsorship&lt;/h2&gt; 
&lt;p&gt;Development time and resources for PHPMailer are provided by &lt;a href="https://info.smartmessages.net/"&gt;Smartmessages.net&lt;/a&gt;, the world's only privacy-first email marketing system.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://info.smartmessages.net/"&gt;&lt;img src="https://www.smartmessages.net/img/smartmessages-logo.svg?sanitize=true" width="550" alt="Smartmessages.net privacy-first email marketing logo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Donations are very welcome, whether in beer 🍺, T-shirts 👕, or cold, hard cash 💰. Sponsorship through GitHub is a simple and convenient way to say "thank you" to PHPMailer's maintainers and contributors – just click the "Sponsor" button &lt;a href="https://github.com/PHPMailer/PHPMailer"&gt;on the project page&lt;/a&gt;. If your company uses PHPMailer, consider taking part in Tidelift's enterprise support programme.&lt;/p&gt; 
&lt;h2&gt;PHPMailer For Enterprise&lt;/h2&gt; 
&lt;p&gt;Available as part of the Tidelift Subscription.&lt;/p&gt; 
&lt;p&gt;The maintainers of PHPMailer and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open-source packages you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact packages you use. &lt;a href="https://tidelift.com/subscription/pkg/packagist-phpmailer-phpmailer?utm_source=packagist-phpmailer-phpmailer&amp;amp;utm_medium=referral&amp;amp;utm_campaign=enterprise&amp;amp;utm_term=repo"&gt;Learn more.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Changelog&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/PHPMailer/PHPMailer/master/changelog.md"&gt;changelog&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;History&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;PHPMailer was originally written in 2001 by Brent R. Matzelle as a &lt;a href="https://sourceforge.net/projects/phpmailer/"&gt;SourceForge project&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Synchro"&gt;Marcus Bointon&lt;/a&gt; (&lt;code&gt;coolbru&lt;/code&gt; on SF) and Andy Prevost (&lt;code&gt;codeworxtech&lt;/code&gt;) took over the project in 2004.&lt;/li&gt; 
 &lt;li&gt;Became an Apache incubator project on Google Code in 2010, managed by Jim Jagielski.&lt;/li&gt; 
 &lt;li&gt;Marcus created &lt;a href="https://github.com/Synchro/PHPMailer"&gt;his fork on GitHub&lt;/a&gt; in 2008.&lt;/li&gt; 
 &lt;li&gt;Jim and Marcus decide to join forces and use GitHub as the canonical and official repo for PHPMailer in 2013.&lt;/li&gt; 
 &lt;li&gt;PHPMailer moves to &lt;a href="https://github.com/PHPMailer"&gt;the PHPMailer organisation&lt;/a&gt; on GitHub in 2013.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;What's changed since moving from SourceForge?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Official successor to the SourceForge and Google Code projects.&lt;/li&gt; 
 &lt;li&gt;Test suite.&lt;/li&gt; 
 &lt;li&gt;Continuous integration with GitHub Actions.&lt;/li&gt; 
 &lt;li&gt;Composer support.&lt;/li&gt; 
 &lt;li&gt;Public development.&lt;/li&gt; 
 &lt;li&gt;Additional languages and language strings.&lt;/li&gt; 
 &lt;li&gt;CRAM-MD5 authentication support.&lt;/li&gt; 
 &lt;li&gt;Preserves full repo history of authors, commits, and branches from the original SourceForge project.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>github/awesome-copilot</title>
      <link>https://github.com/github/awesome-copilot</link>
      <description>&lt;p&gt;Community-contributed instructions, prompts, and configurations to help you make the most of GitHub Copilot.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🤖 Awesome GitHub Copilot Customizations&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://aka.ms/awesome-github-copilot"&gt;&lt;img src="https://img.shields.io/badge/Powered_by-Awesome_Copilot-blue?logo=githubcopilot" alt="Powered by Awesome Copilot" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/#contributors-"&gt;&lt;img src="https://img.shields.io/badge/all_contributors-86-orange.svg?style=flat-square" alt="All Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-BADGE:END --&gt; 
&lt;p&gt;A curated collection of prompts, instructions, and chat modes to supercharge your GitHub Copilot experience across different domains, languages, and use cases.&lt;/p&gt; 
&lt;h2&gt;🚀 What is Awesome GitHub Copilot?&lt;/h2&gt; 
&lt;p&gt;This repository provides a comprehensive toolkit for enhancing GitHub Copilot with specialized:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/README.prompts.md"&gt;&lt;img src="https://img.shields.io/badge/Awesome-Prompts-blue?logo=githubcopilot" alt="Awesome Prompts" /&gt;&lt;/a&gt;&lt;/strong&gt; - Focused, task-specific prompts for generating code, documentation, and solving specific problems&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/README.instructions.md"&gt;&lt;img src="https://img.shields.io/badge/Awesome-Instructions-blue?logo=githubcopilot" alt="Awesome Instructions" /&gt;&lt;/a&gt;&lt;/strong&gt; - Comprehensive coding standards and best practices that apply to specific file patterns or entire projects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/README.chatmodes.md"&gt;&lt;img src="https://img.shields.io/badge/Awesome-Chat_Modes-blue?logo=githubcopilot" alt="Awesome Chat Modes" /&gt;&lt;/a&gt;&lt;/strong&gt; - Specialized AI personas and conversation modes for different roles and contexts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/README.collections.md"&gt;&lt;img src="https://img.shields.io/badge/Awesome-Collections-blue?logo=githubcopilot" alt="Awesome Collections" /&gt;&lt;/a&gt;&lt;/strong&gt; - Curated collections of related prompts, instructions, and chat modes organized around specific themes and workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;MCP Server&lt;/h2&gt; 
&lt;p&gt;To make it easy to add these customizations to your editor, we have created a &lt;a href="https://developer.microsoft.com/blog/announcing-awesome-copilot-mcp-server"&gt;MCP Server&lt;/a&gt; that provides a prompt for searching and installing prompts, instructions, and chat modes directly from this repository. You'll need to have Docker installed and running to run the server.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aka.ms/awesome-copilot/mcp/vscode"&gt;&lt;img src="https://img.shields.io/badge/VS_Code-Install-0098FF?logo=visualstudiocode&amp;amp;logoColor=white" alt="Install in VS Code" /&gt;&lt;/a&gt; &lt;a href="https://aka.ms/awesome-copilot/mcp/vscode-insiders"&gt;&lt;img src="https://img.shields.io/badge/VS_Code_Insiders-Install-24bfa5?logo=visualstudiocode&amp;amp;logoColor=white" alt="Install in VS Code Insiders" /&gt;&lt;/a&gt; &lt;a href="https://aka.ms/awesome-copilot/mcp/vs"&gt;&lt;img src="https://img.shields.io/badge/Visual_Studio-Install-C16FDE?logo=visualstudio&amp;amp;logoColor=white" alt="Install in Visual Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Show MCP Server JSON configuration&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-json"&gt;{
  "servers": {
    "awesome-copilot": {
      "type": "stdio",
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "ghcr.io/microsoft/mcp-dotnet-samples/awesome-copilot:latest"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;🔧 How to Use&lt;/h2&gt; 
&lt;h3&gt;🎯 Prompts&lt;/h3&gt; 
&lt;p&gt;Use the &lt;code&gt;/&lt;/code&gt; command in GitHub Copilot Chat to access prompts:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/awesome-copilot create-readme
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;📋 Instructions&lt;/h3&gt; 
&lt;p&gt;Instructions automatically apply to files based on their patterns and provide contextual guidance for coding standards, frameworks, and best practices.&lt;/p&gt; 
&lt;h3&gt;💭 Chat Modes&lt;/h3&gt; 
&lt;p&gt;Activate chat modes to get specialized assistance from AI personas tailored for specific roles like architects, DBAs, or security experts.&lt;/p&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt; for details on how to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add new prompts, instructions, or chat modes&lt;/li&gt; 
 &lt;li&gt;Improve existing content&lt;/li&gt; 
 &lt;li&gt;Report issues or suggest enhancements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Contribution Guide&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Follow our file naming conventions and frontmatter requirements&lt;/li&gt; 
 &lt;li&gt;Test your contributions thoroughly&lt;/li&gt; 
 &lt;li&gt;Update the appropriate README tables&lt;/li&gt; 
 &lt;li&gt;Submit a pull request with a clear description&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;📖 Repository Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;├── prompts/          # Task-specific prompts (.prompt.md)
├── instructions/     # Coding standards and best practices (.instructions.md)
├── chatmodes/        # AI personas and specialized modes (.chatmode.md)
├── collections/      # Curated collections of related items (.collection.yml)
└── scripts/          # Utility scripts for maintenance
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;🌟 Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Browse the Collections&lt;/strong&gt;: Check out our comprehensive lists of &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/README.prompts.md"&gt;prompts&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/README.instructions.md"&gt;instructions&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/README.chatmodes.md"&gt;chat modes&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/README.collections.md"&gt;collections&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add to your editor&lt;/strong&gt;: Click the "Install" button to install to VS Code, or copy the file contents for other editors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Start Using&lt;/strong&gt;: Copy prompts to use with &lt;code&gt;/&lt;/code&gt; commands, let instructions enhance your coding experience, or activate chat modes for specialized assistance.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;📄 License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;🛡️ Security &amp;amp; Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Security Issues&lt;/strong&gt;: Please see our &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/SECURITY.md"&gt;Security Policy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Support&lt;/strong&gt;: Check our &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/SUPPORT.md"&gt;Support Guide&lt;/a&gt; for getting help&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code of Conduct&lt;/strong&gt;: We follow the &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/CODE_OF_CONDUCT.md"&gt;Contributor Covenant&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🎯 Why Use Awesome GitHub Copilot?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Productivity&lt;/strong&gt;: Pre-built prompts and instructions save time and provide consistent results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Best Practices&lt;/strong&gt;: Benefit from community-curated coding standards and patterns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Specialized Assistance&lt;/strong&gt;: Access expert-level guidance through specialized chat modes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Continuous Learning&lt;/strong&gt;: Stay updated with the latest patterns and practices across technologies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Ready to supercharge your coding experience?&lt;/strong&gt; Start exploring our &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/README.prompts.md"&gt;prompts&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/README.instructions.md"&gt;instructions&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/README.chatmodes.md"&gt;chat modes&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Contributors ✨&lt;/h2&gt; 
&lt;p&gt;Thanks goes to these wonderful people (&lt;a href="https://allcontributors.org/docs/en/emoji-key"&gt;emoji key&lt;/a&gt;):&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.aaron-powell.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/434140?v=4?s=100" width="100px;" alt="Aaron Powell" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Aaron Powell&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=aaronpowell" title="Code"&gt;💻&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/#maintenance-aaronpowell" title="Maintenance"&gt;🚧&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/#projectManagement-aaronpowell" title="Project Management"&gt;📆&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/github/awesome-copilot/main/#promotion-aaronpowell" title="Promotion"&gt;📣&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://mubaidr.js.org/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2222702?v=4?s=100" width="100px;" alt="Muhammad Ubaid Raza" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Muhammad Ubaid Raza&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mubaidr" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://digitarald.de/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/8599?v=4?s=100" width="100px;" alt="Harald Kirschner" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Harald Kirschner&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=digitarald" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/mbianchidev"&gt;&lt;img src="https://avatars.githubusercontent.com/u/37507190?v=4?s=100" width="100px;" alt="Matteo Bianchi" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matteo Bianchi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mbianchidev" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/AungMyoKyaw"&gt;&lt;img src="https://avatars.githubusercontent.com/u/9404824?v=4?s=100" width="100px;" alt="Aung Myo Kyaw" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Aung Myo Kyaw&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=AungMyoKyaw" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://danielscottraynsford.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/7589164?v=4?s=100" width="100px;" alt="Daniel Scott-Raynsford" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Daniel Scott-Raynsford&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=PlagueHO" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/burkeholland"&gt;&lt;img src="https://avatars.githubusercontent.com/u/686963?v=4?s=100" width="100px;" alt="Burke Holland" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Burke Holland&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=burkeholland" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://calva.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/30010?v=4?s=100" width="100px;" alt="Peter Strömberg" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Peter Strömberg&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=PEZ" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.devprodlogs.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/51440732?v=4?s=100" width="100px;" alt="Daniel Meppiel" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Daniel Meppiel&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=danielmeppiel" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://montemagno.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1676321?v=4?s=100" width="100px;" alt="James Montemagno" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;James Montemagno&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=jamesmontemagno" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/VamshiVerma"&gt;&lt;img src="https://avatars.githubusercontent.com/u/21999324?v=4?s=100" width="100px;" alt="Vamshi Verma" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vamshi Verma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=VamshiVerma" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/sinedied"&gt;&lt;img src="https://avatars.githubusercontent.com/u/593151?v=4?s=100" width="100px;" alt="Yohan Lasorsa" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Yohan Lasorsa&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=sinedied" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/OrenMe"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5461862?v=4?s=100" width="100px;" alt="Oren Me" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Oren Me&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=OrenMe" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/mjrousos"&gt;&lt;img src="https://avatars.githubusercontent.com/u/10077254?v=4?s=100" width="100px;" alt="Mike Rousos" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mike Rousos&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mjrousos" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/guiopen"&gt;&lt;img src="https://avatars.githubusercontent.com/u/94094527?v=4?s=100" width="100px;" alt="Guilherme do Amaral Alves " /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Guilherme do Amaral Alves &lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=guiopen" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.buymeacoffee.com/troystaylor"&gt;&lt;img src="https://avatars.githubusercontent.com/u/44444967?v=4?s=100" width="100px;" alt="Troy Simeon Taylor" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Troy Simeon Taylor&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=troystaylor" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.linkedin.com/in/ambilykk/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/10282550?v=4?s=100" width="100px;" alt="Ambily" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ambily&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=ambilykk" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://tgrall.github.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/541250?v=4?s=100" width="100px;" alt="Tugdual Grall" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Tugdual Grall&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=tgrall" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/TianqiZhang"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5326582?v=4?s=100" width="100px;" alt="Tianqi Zhang" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Tianqi Zhang&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=TianqiZhang" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/shubham070"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5480589?v=4?s=100" width="100px;" alt="Shubham Gaikwad" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Shubham Gaikwad&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=shubham070" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/sdolgin"&gt;&lt;img src="https://avatars.githubusercontent.com/u/576449?v=4?s=100" width="100px;" alt="Saul Dolgin" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Saul Dolgin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=sdolgin" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/nullchimp"&gt;&lt;img src="https://avatars.githubusercontent.com/u/58362593?v=4?s=100" width="100px;" alt="NULLchimp" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;NULLchimp&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=nullchimp" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/MattVevang"&gt;&lt;img src="https://avatars.githubusercontent.com/u/20714898?v=4?s=100" width="100px;" alt="Matt Vevang" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matt Vevang&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=MattVevang" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://devkimchi.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1538528?v=4?s=100" width="100px;" alt="Justin Yoo" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Justin Yoo&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=justinyoo" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://hachyderm.io/@0gis0"&gt;&lt;img src="https://avatars.githubusercontent.com/u/175379?v=4?s=100" width="100px;" alt="Gisela Torres" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Gisela Torres&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=0GiS0" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://debbie.codes/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/13063165?v=4?s=100" width="100px;" alt="Debbie O'Brien" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Debbie O'Brien&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=debs-obrien" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/agreaves-ms"&gt;&lt;img src="https://avatars.githubusercontent.com/u/111466195?v=4?s=100" width="100px;" alt="Allen Greaves" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Allen Greaves&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=agreaves-ms" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/AmeliaRose802"&gt;&lt;img src="https://avatars.githubusercontent.com/u/26167931?v=4?s=100" width="100px;" alt="Amelia Payne" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Amelia Payne&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=AmeliaRose802" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/SebastienDegodez"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2349146?v=4?s=100" width="100px;" alt="Sebastien DEGODEZ" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sebastien DEGODEZ&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=SebastienDegodez" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://graef.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/19261257?v=4?s=100" width="100px;" alt="Sebastian Gräf" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sebastian Gräf&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=segraef" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://9ssi7.dev/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/76786120?v=4?s=100" width="100px;" alt="Salih İbrahimbaş" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Salih İbrahimbaş&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=9ssi7" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/inquinity"&gt;&lt;img src="https://avatars.githubusercontent.com/u/406234?v=4?s=100" width="100px;" alt="Robert Altman" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Robert Altman&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=inquinity" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/pertrai1"&gt;&lt;img src="https://avatars.githubusercontent.com/u/442374?v=4?s=100" width="100px;" alt="Rob Simpson" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Rob Simpson&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=pertrai1" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://ricksm.it/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/7207783?v=4?s=100" width="100px;" alt="Rick Smit" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Rick Smit&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=ricksmit3000" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://dotneteers.net/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/28162552?v=4?s=100" width="100px;" alt="Peter Smulovics" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Peter Smulovics&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=psmulovics" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/pelikhan"&gt;&lt;img src="https://avatars.githubusercontent.com/u/4175913?v=4?s=100" width="100px;" alt="Peli de Halleux" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Peli de Halleux&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=pelikhan" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.paulomorgado.net/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/470455?v=4?s=100" width="100px;" alt="Paulo Morgado" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Paulo Morgado&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=paulomorgado" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://nickyt.co/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/833231?v=4?s=100" width="100px;" alt="Nick Taylor" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Nick Taylor&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=nickytonline" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/mikeparker104"&gt;&lt;img src="https://avatars.githubusercontent.com/u/12763221?v=4?s=100" width="100px;" alt="Mike Parker" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mike Parker&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mikeparker104" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/mikekistler"&gt;&lt;img src="https://avatars.githubusercontent.com/u/85643503?v=4?s=100" width="100px;" alt="Mike Kistler" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mike Kistler&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mikekistler" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://a11ysupport.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/498678?v=4?s=100" width="100px;" alt="Michael Fairchild" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Michael Fairchild&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=mfairchild365" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.linkedin.com/in/michael-volz/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/129928?v=4?s=100" width="100px;" alt="Michael A. Volz (Flynn)" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Michael A. Volz (Flynn)&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=michaelvolz" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/4regab"&gt;&lt;img src="https://avatars.githubusercontent.com/u/178603515?v=4?s=100" width="100px;" alt="4regab" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;4regab&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=4regab" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/TheovanKraay"&gt;&lt;img src="https://avatars.githubusercontent.com/u/24420698?v=4?s=100" width="100px;" alt="Theo van Kraay" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Theo van Kraay&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=TheovanKraay" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://glsauto.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/132710946?v=4?s=100" width="100px;" alt="Troy Witthoeft (glsauto)" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Troy Witthoeft (glsauto)&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=twitthoeft-gls" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/iletai"&gt;&lt;img src="https://avatars.githubusercontent.com/u/26614687?v=4?s=100" width="100px;" alt="Tài Lê" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Tài Lê&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=iletai" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://tinyurl.com/3p5j9mwe"&gt;&lt;img src="https://avatars.githubusercontent.com/u/9591887?v=4?s=100" width="100px;" alt="Udaya Veeramreddygari" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Udaya Veeramreddygari&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=udayakumarreddyv" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://bio.warengonzaga.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/15052701?v=4?s=100" width="100px;" alt="Waren Gonzaga" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Waren Gonzaga&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=warengonzaga" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://blog.miniasp.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/88981?v=4?s=100" width="100px;" alt="Will 保哥" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Will 保哥&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=doggy8088" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/yukiomoto"&gt;&lt;img src="https://avatars.githubusercontent.com/u/38450410?v=4?s=100" width="100px;" alt="Yuki Omoto" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Yuki Omoto&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=yukiomoto" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/hueanmy"&gt;&lt;img src="https://avatars.githubusercontent.com/u/20430626?v=4?s=100" width="100px;" alt="Meii" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Meii&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=hueanmy" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/samqbush"&gt;&lt;img src="https://avatars.githubusercontent.com/u/74389839?v=4?s=100" width="100px;" alt="samqbush" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;samqbush&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=samqbush" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/sdanzo-hrb"&gt;&lt;img src="https://avatars.githubusercontent.com/u/136493100?v=4?s=100" width="100px;" alt="sdanzo-hrb" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;sdanzo-hrb&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=sdanzo-hrb" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/voidfnc"&gt;&lt;img src="https://avatars.githubusercontent.com/u/194750710?v=4?s=100" width="100px;" alt="voidfnc" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;voidfnc&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=voidfnc" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/webreidi"&gt;&lt;img src="https://avatars.githubusercontent.com/u/55603905?v=4?s=100" width="100px;" alt="Wendy Breiding" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Wendy Breiding&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=webreidi" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/zooav"&gt;&lt;img src="https://avatars.githubusercontent.com/u/12625412?v=4?s=100" width="100px;" alt="Ankur Sharma" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ankur Sharma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=zooav" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://jianminhuang.cc/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/6296280?v=4?s=100" width="100px;" alt="黃健旻 Vincent Huang" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;黃健旻 Vincent Huang&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=Jian-Min-Huang" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/dgh06175"&gt;&lt;img src="https://avatars.githubusercontent.com/u/77305722?v=4?s=100" width="100px;" alt="이상현" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;이상현&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=dgh06175" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/abdidaudpropel"&gt;&lt;img src="https://avatars.githubusercontent.com/u/51310019?v=4?s=100" width="100px;" alt="Abdi Daud" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Abdi Daud&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=abdidaudpropel" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://www.senseof.tech/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/50712277?v=4?s=100" width="100px;" alt="Adrien Clerbois" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Adrien Clerbois&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=AClerbois" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://www.qreate.it/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1868590?v=4?s=100" width="100px;" alt="Alan Sprecacenere" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Alan Sprecacenere&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=tegola" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://asilva.dev/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2493377?v=4?s=100" width="100px;" alt="André Silva" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;André Silva&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=askpt" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://javaetmoi.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/838318?v=4?s=100" width="100px;" alt="Antoine Rey" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Antoine Rey&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=arey" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/artemsaveliev"&gt;&lt;img src="https://avatars.githubusercontent.com/u/15679218?v=4?s=100" width="100px;" alt="Artem Saveliev" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Artem Saveliev&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=artemsaveliev" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://brunoborges.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/129743?v=4?s=100" width="100px;" alt="Bruno Borges" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Bruno Borges&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=brunoborges" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.peug.net/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/3845786?v=4?s=100" width="100px;" alt="Christophe Peugnet" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Christophe Peugnet&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=tossnet" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.movinglive.ca/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/14792628?v=4?s=100" width="100px;" alt="Chtive" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Chtive&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=MovingLive" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/craigbekker"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1115912?v=4?s=100" width="100px;" alt="Craig Bekker" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Craig Bekker&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=craigbekker" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/breakid"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1446918?v=4?s=100" width="100px;" alt="Dan" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Dan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=breakid" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/ewega"&gt;&lt;img src="https://avatars.githubusercontent.com/u/26189114?v=4?s=100" width="100px;" alt="Eldrick Wega" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Eldrick Wega&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=ewega" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://www.felixarjuna.dev/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/79026094?v=4?s=100" width="100px;" alt="Felix Arjuna" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Felix Arjuna&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=felixarjuna" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/feapaydin"&gt;&lt;img src="https://avatars.githubusercontent.com/u/19946639?v=4?s=100" width="100px;" alt="Furkan Enes" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Furkan Enes&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=feapaydin" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://learn.microsoft.com/dotnet"&gt;&lt;img src="https://avatars.githubusercontent.com/u/24882762?v=4?s=100" width="100px;" alt="Genevieve Warren" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Genevieve Warren&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=gewarren" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/geoder101"&gt;&lt;img src="https://avatars.githubusercontent.com/u/145904?v=4?s=100" width="100px;" alt="George Dernikos" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;George Dernikos&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=geoder101" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/giomartinsdev"&gt;&lt;img src="https://avatars.githubusercontent.com/u/125399281?v=4?s=100" width="100px;" alt="Giovanni de Almeida Martins" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Giovanni de Almeida Martins&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=giomartinsdev" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/Ioana37"&gt;&lt;img src="https://avatars.githubusercontent.com/u/69301842?v=4?s=100" width="100px;" alt="Ioana A" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ioana A&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=Ioana37" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/nohwnd"&gt;&lt;img src="https://avatars.githubusercontent.com/u/5735905?v=4?s=100" width="100px;" alt="Jakub Jareš" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jakub Jareš&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=nohwnd" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://joe-watkins.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/3695795?v=4?s=100" width="100px;" alt="Joe Watkins" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Joe Watkins&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=joe-watkins" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://johnpapa.net/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/1202528?v=4?s=100" width="100px;" alt="John Papa" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;John Papa&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=johnpapa" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://www.sugbo4j.co.nz/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/15100839?v=4?s=100" width="100px;" alt="Joseph Gonzales" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Joseph Gonzales&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=josephgonzales01" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://digio.es/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/173672918?v=4?s=100" width="100px;" alt="José Antonio Garrido" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;José Antonio Garrido&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=josegarridodigio" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/Ranrar"&gt;&lt;img src="https://avatars.githubusercontent.com/u/95967772?v=4?s=100" width="100px;" alt="Kim Skov Rasmussen" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kim Skov Rasmussen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=Ranrar" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/whiteken"&gt;&lt;img src="https://avatars.githubusercontent.com/u/20211937?v=4?s=100" width="100px;" alt="Kenny White" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kenny White&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=whiteken" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://github.com/LouellaCreemers"&gt;&lt;img src="https://avatars.githubusercontent.com/u/46204894?v=4?s=100" width="100px;" alt="Louella Creemers" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Louella Creemers&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=LouellaCreemers" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="https://linktr.ee/lukemurray"&gt;&lt;img src="https://avatars.githubusercontent.com/u/24467442?v=4?s=100" width="100px;" alt="Luke Murray" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Luke Murray&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=lukemurraynz" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="14.28%"&gt;&lt;a href="http://marknoble.com/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/3819700?v=4?s=100" width="100px;" alt="Mark Noble" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mark Noble&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://github.com/github/awesome-copilot/commits?author=marknoble" title="Code"&gt;💻&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
 &lt;tfoot&gt; 
  &lt;tr&gt; 
   &lt;td align="center" size="13px" colspan="7"&gt; &lt;img src="https://raw.githubusercontent.com/all-contributors/all-contributors-cli/1b8533af435da9854653492b1327a23a4dbd0a10/assets/logo-small.svg?sanitize=true" /&gt; &lt;a href="https://all-contributors.js.org/docs/en/bot/usage"&gt;Add your contributions&lt;/a&gt;  &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tfoot&gt; 
&lt;/table&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;p&gt;This project follows the &lt;a href="https://github.com/all-contributors/all-contributors"&gt;all-contributors&lt;/a&gt; specification. Contributions of any kind welcome!&lt;/p&gt; 
&lt;h2&gt;📚 Additional Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/docs/copilot/copilot-customization"&gt;VS Code Copilot Customization Documentation&lt;/a&gt; - Official Microsoft documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/docs/copilot/chat/copilot-chat"&gt;GitHub Copilot Chat Documentation&lt;/a&gt; - Complete chat feature guide&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/docs/copilot/chat/chat-modes"&gt;Custom Chat Modes&lt;/a&gt; - Advanced chat configuration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.visualstudio.com/docs/getstarted/settings"&gt;VS Code Settings&lt;/a&gt; - General VS Code configuration guide&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;™️ Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mlabonne/llm-course</title>
      <link>https://github.com/mlabonne/llm-course</link>
      <description>&lt;p&gt;Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/banner.png" alt="LLM Course" /&gt; 
 &lt;p align="center"&gt; 𝕏 &lt;a href="https://twitter.com/maximelabonne"&gt;Follow me on X&lt;/a&gt; • 🤗 &lt;a href="https://huggingface.co/mlabonne"&gt;Hugging Face&lt;/a&gt; • 💻 &lt;a href="https://mlabonne.github.io/blog"&gt;Blog&lt;/a&gt; • 📙 &lt;a href="https://packt.link/a/9781836200079"&gt;LLM Engineer's Handbook&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://a.co/d/a2M67rE"&gt;&lt;img align="right" width="25%" src="https://i.imgur.com/7iNjEq2.png" alt="LLM Engineer's Handbook Cover" /&gt;&lt;/a&gt;The LLM course is divided into three parts:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;🧩 &lt;strong&gt;LLM Fundamentals&lt;/strong&gt; is optional and covers fundamental knowledge about mathematics, Python, and neural networks.&lt;/li&gt; 
 &lt;li&gt;🧑‍🔬 &lt;strong&gt;The LLM Scientist&lt;/strong&gt; focuses on building the best possible LLMs using the latest techniques.&lt;/li&gt; 
 &lt;li&gt;👷 &lt;strong&gt;The LLM Engineer&lt;/strong&gt; focuses on creating LLM-based applications and deploying them.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Based on this course, I wrote the &lt;a href="https://packt.link/a/9781836200079"&gt;LLM Engineer's Handbook&lt;/a&gt; with Paul Iuzstin. It's a hands-on and detailed book that covers an end-to-end LLM application from design to deployment. The LLM course will always stay free but feel free to support my work by purchasing the book.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For an interactive version of this course, I created an LLM assistant that will answer questions and test your knowledge in a personalized way on &lt;a href="https://hf.co/chat/assistant/66029d2e5f4a884f7aabc9d1"&gt;&lt;strong&gt;HuggingChat&lt;/strong&gt;&lt;/a&gt; or &lt;a href="https://chat.openai.com/g/g-yviLuLqvI-llm-course"&gt;&lt;strong&gt;ChatGPT&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;📝 Notebooks&lt;/h2&gt; 
&lt;p&gt;A list of notebooks and articles I wrote about LLMs.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Notebook&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Notebook&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🧐 &lt;a href="https://github.com/mlabonne/llm-autoeval"&gt;LLM AutoEval&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Automatically evaluate your LLMs using RunPod&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1Igs3WZuXAIv9X0vwqiE90QlEPys8e8Oa?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🥱 LazyMergekit&lt;/td&gt; 
   &lt;td&gt;Easily merge models using MergeKit in one click.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🦎 LazyAxolotl&lt;/td&gt; 
   &lt;td&gt;Fine-tune models in the cloud using Axolotl in one click.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1TsDKNo2riwVmU55gjuBgB1AXVtRRfRHW?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;⚡ AutoQuant&lt;/td&gt; 
   &lt;td&gt;Quantize LLMs in GGUF, GPTQ, EXL2, AWQ, and HQQ formats in one click.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1b6nqC7UZVt8bx4MksX7s656GXPM-eWw4?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🌳 Model Family Tree&lt;/td&gt; 
   &lt;td&gt;Visualize the family tree of merged models.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1s2eQlolcI1VGgDhqWIANfkfKvcKrMyNr?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🚀 ZeroSpace&lt;/td&gt; 
   &lt;td&gt;Automatically create a Gradio chat interface using a free ZeroGPU.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1LcVUW5wsJTO2NGmozjji5CkC--646LgC"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;✂️ AutoAbliteration&lt;/td&gt; 
   &lt;td&gt;Automatically abliteration models with custom datasets.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1RmLv-pCMBBsQGXQIM8yF-OdCNyoylUR1?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;🧼 AutoDedup&lt;/td&gt; 
   &lt;td&gt;Automatically deduplicate datasets using the Rensa library.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1o1nzwXWAa8kdkEJljbJFW1VuI-3VZLUn?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Fine-tuning&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Notebook&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Article&lt;/th&gt; 
   &lt;th&gt;Notebook&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fine-tune Llama 3.1 with Unsloth&lt;/td&gt; 
   &lt;td&gt;Ultra-efficient supervised fine-tuning in Google Colab.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/2024-07-29_Finetune_Llama31.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/164cg_O7SV7G8kZr_JXqLd6VC7pd86-1Z?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fine-tune Llama 3 with ORPO&lt;/td&gt; 
   &lt;td&gt;Cheaper and faster fine-tuning in a single stage with ORPO.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/2024-04-19_Fine_tune_Llama_3_with_ORPO.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1eHNWg9gnaXErdAa8_mcvjMupbSS6rDvi"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fine-tune Mistral-7b with DPO&lt;/td&gt; 
   &lt;td&gt;Boost the performance of supervised fine-tuned models with DPO.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/Fine_tune_Mistral_7b_with_DPO.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/15iFBr1xWgztXvhrj5I9fBv20c7CFOPBE?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fine-tune Mistral-7b with QLoRA&lt;/td&gt; 
   &lt;td&gt;Supervised fine-tune Mistral-7b in a free-tier Google Colab with TRL.&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1o_w0KastmEJNVwT5GoqMCciH-18ca5WS?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fine-tune CodeLlama using Axolotl&lt;/td&gt; 
   &lt;td&gt;End-to-end guide to the state-of-the-art tool for fine-tuning.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1Xu0BrCB7IShwSWKVcfAfhehwjDrDMH5m?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fine-tune Llama 2 with QLoRA&lt;/td&gt; 
   &lt;td&gt;Step-by-step guide to supervised fine-tune Llama 2 in Google Colab.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/Fine_Tune_Your_Own_Llama_2_Model_in_a_Colab_Notebook.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Quantization&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Notebook&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Article&lt;/th&gt; 
   &lt;th&gt;Notebook&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Introduction to Quantization&lt;/td&gt; 
   &lt;td&gt;Large language model optimization using 8-bit quantization.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1DPr4mUQ92Cc-xf4GgAaB6dFcFnWIvqYi?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4-bit Quantization using GPTQ&lt;/td&gt; 
   &lt;td&gt;Quantize your own open-source LLMs to run them on consumer hardware.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/4bit_quantization/"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1lSvVDaRgqQp_mWK_jC9gydz6_-y6Aq4A?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Quantization with GGUF and llama.cpp&lt;/td&gt; 
   &lt;td&gt;Quantize Llama 2 models with llama.cpp and upload GGUF versions to the HF Hub.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1pL8k7m04mgE5jo2NrjGi8atB0j_37aDD?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ExLlamaV2: The Fastest Library to Run&amp;nbsp;LLMs&lt;/td&gt; 
   &lt;td&gt;Quantize and run EXL2&amp;nbsp;models and upload them to the HF Hub.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/ExLlamaV2_The_Fastest_Library_to_Run%C2%A0LLMs.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1yrq4XBlxiA0fALtMoT2dwiACVc77PHou?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Other&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Notebook&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Article&lt;/th&gt; 
   &lt;th&gt;Notebook&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Merge LLMs with MergeKit&lt;/td&gt; 
   &lt;td&gt;Create your own models easily, no GPU required!&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/2024-01-08_Merge_LLMs_with_mergekit%20copy.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Create MoEs with MergeKit&lt;/td&gt; 
   &lt;td&gt;Combine multiple experts into a single frankenMoE&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/2024-03-28_Create_Mixture_of_Experts_with_MergeKit.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Uncensor any LLM with abliteration&lt;/td&gt; 
   &lt;td&gt;Fine-tuning without retraining&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/2024-06-04_Uncensor_any_LLM_with_abliteration.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1VYm3hOcvCpbGiqKZb141gJwjdmmCcVpR?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Improve ChatGPT with Knowledge Graphs&lt;/td&gt; 
   &lt;td&gt;Augment ChatGPT's answers with knowledge graphs.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/Article_Improve_ChatGPT_with_Knowledge_Graphs.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/1mwhOSw9Y9bgEaIFKT4CLi0n18pXRM4cj?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Decoding Strategies in Large Language Models&lt;/td&gt; 
   &lt;td&gt;A guide to text generation from beam search to nucleus sampling&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlabonne.github.io/blog/posts/2022-06-07-Decoding_strategies.html"&gt;Article&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://colab.research.google.com/drive/19CJlOS5lI29g-B3dziNn93Enez1yiHk2?usp=sharing"&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/colab.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🧩 LLM Fundamentals&lt;/h2&gt; 
&lt;p&gt;This section introduces essential knowledge about mathematics, Python, and neural networks. You might not want to start here but refer to it as needed.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Toggle section (optional)&lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/roadmap_fundamentals.png" alt="" /&gt;&lt;/p&gt; 
 &lt;h3&gt;1. Mathematics for Machine Learning&lt;/h3&gt; 
 &lt;p&gt;Before mastering machine learning, it is important to understand the fundamental mathematical concepts that power these algorithms.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Linear Algebra&lt;/strong&gt;: This is crucial for understanding many algorithms, especially those used in deep learning. Key concepts include vectors, matrices, determinants, eigenvalues and eigenvectors, vector spaces, and linear transformations.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Calculus&lt;/strong&gt;: Many machine learning algorithms involve the optimization of continuous functions, which requires an understanding of derivatives, integrals, limits, and series. Multivariable calculus and the concept of gradients are also important.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Probability and Statistics&lt;/strong&gt;: These are crucial for understanding how models learn from data and make predictions. Key concepts include probability theory, random variables, probability distributions, expectations, variance, covariance, correlation, hypothesis testing, confidence intervals, maximum likelihood estimation, and Bayesian inference.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;📚 Resources:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab"&gt;3Blue1Brown - The Essence of Linear Algebra&lt;/a&gt;: Series of videos that give a geometric intuition to these concepts.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qBigTkBLU6g&amp;amp;list=PLblh5JKOoLUK0FLuzwntyYI10UQFUhsY9"&gt;StatQuest with Josh Starmer - Statistics Fundamentals&lt;/a&gt;: Offers simple and clear explanations for many statistical concepts.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://automata88.medium.com/list/cacc224d5e7d"&gt;AP Statistics Intuition by Ms Aerin&lt;/a&gt;: List of Medium articles that provide the intuition behind every probability distribution.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://immersivemath.com/ila/learnmore.html"&gt;Immersive Linear Algebra&lt;/a&gt;: Another visual interpretation of linear algebra.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.khanacademy.org/math/linear-algebra"&gt;Khan Academy - Linear Algebra&lt;/a&gt;: Great for beginners as it explains the concepts in a very intuitive way.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.khanacademy.org/math/calculus-1"&gt;Khan Academy - Calculus&lt;/a&gt;: An interactive course that covers all the basics of calculus.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.khanacademy.org/math/statistics-probability"&gt;Khan Academy - Probability and Statistics&lt;/a&gt;: Delivers the material in an easy-to-understand format.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;2. Python for Machine Learning&lt;/h3&gt; 
 &lt;p&gt;Python is a powerful and flexible programming language that's particularly good for machine learning, thanks to its readability, consistency, and robust ecosystem of data science libraries.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Python Basics&lt;/strong&gt;: Python programming requires a good understanding of the basic syntax, data types, error handling, and object-oriented programming.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Data Science Libraries&lt;/strong&gt;: It includes familiarity with NumPy for numerical operations, Pandas for data manipulation and analysis, Matplotlib and Seaborn for data visualization.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Data Preprocessing&lt;/strong&gt;: This involves feature scaling and normalization, handling missing data, outlier detection, categorical data encoding, and splitting data into training, validation, and test sets.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Machine Learning Libraries&lt;/strong&gt;: Proficiency with Scikit-learn, a library providing a wide selection of supervised and unsupervised learning algorithms, is vital. Understanding how to implement algorithms like linear regression, logistic regression, decision trees, random forests, k-nearest neighbors (K-NN), and K-means clustering is important. Dimensionality reduction techniques like PCA and t-SNE are also helpful for visualizing high-dimensional data.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;📚 Resources:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://realpython.com/"&gt;Real Python&lt;/a&gt;: A comprehensive resource with articles and tutorials for both beginner and advanced Python concepts.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=rfscVS0vtbw"&gt;freeCodeCamp - Learn Python&lt;/a&gt;: Long video that provides a full introduction into all of the core concepts in Python.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://jakevdp.github.io/PythonDataScienceHandbook/"&gt;Python Data Science Handbook&lt;/a&gt;: Free digital book that is a great resource for learning pandas, NumPy, Matplotlib, and Seaborn.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://youtu.be/i_LwzRVP7bg"&gt;freeCodeCamp - Machine Learning for Everybody&lt;/a&gt;: Practical introduction to different machine learning algorithms for beginners.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.udacity.com/course/intro-to-machine-learning--ud120"&gt;Udacity - Intro to Machine Learning&lt;/a&gt;: Free course that covers PCA and several other machine learning concepts.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;3. Neural Networks&lt;/h3&gt; 
 &lt;p&gt;Neural networks are a fundamental part of many machine learning models, particularly in the realm of deep learning. To utilize them effectively, a comprehensive understanding of their design and mechanics is essential.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Fundamentals&lt;/strong&gt;: This includes understanding the structure of a neural network, such as layers, weights, biases, and activation functions (sigmoid, tanh, ReLU, etc.)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Training and Optimization&lt;/strong&gt;: Familiarize yourself with backpropagation and different types of loss functions, like Mean Squared Error (MSE) and Cross-Entropy. Understand various optimization algorithms like Gradient Descent, Stochastic Gradient Descent, RMSprop, and Adam.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Overfitting&lt;/strong&gt;: Understand the concept of overfitting (where a model performs well on training data but poorly on unseen data) and learn various regularization techniques (dropout, L1/L2 regularization, early stopping, data augmentation) to prevent it.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Implement a Multilayer Perceptron (MLP)&lt;/strong&gt;: Build an MLP, also known as a fully connected network, using PyTorch.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;📚 Resources:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=aircAruvnKk"&gt;3Blue1Brown - But what is a Neural Network?&lt;/a&gt;: This video gives an intuitive explanation of neural networks and their inner workings.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=VyWAvY2CF9c"&gt;freeCodeCamp - Deep Learning Crash Course&lt;/a&gt;: This video efficiently introduces all the most important concepts in deep learning.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://course.fast.ai/"&gt;Fast.ai - Practical Deep Learning&lt;/a&gt;: Free course designed for people with coding experience who want to learn about deep learning.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4"&gt;Patrick Loeber - PyTorch Tutorials&lt;/a&gt;: Series of videos for complete beginners to learn about PyTorch.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;4. Natural Language Processing (NLP)&lt;/h3&gt; 
 &lt;p&gt;NLP is a fascinating branch of artificial intelligence that bridges the gap between human language and machine understanding. From simple text processing to understanding linguistic nuances, NLP plays a crucial role in many applications like translation, sentiment analysis, chatbots, and much more.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Text Preprocessing&lt;/strong&gt;: Learn various text preprocessing steps like tokenization (splitting text into words or sentences), stemming (reducing words to their root form), lemmatization (similar to stemming but considers the context), stop word removal, etc.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Feature Extraction Techniques&lt;/strong&gt;: Become familiar with techniques to convert text data into a format that can be understood by machine learning algorithms. Key methods include Bag-of-words (BoW), Term Frequency-Inverse Document Frequency (TF-IDF), and n-grams.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Word Embeddings&lt;/strong&gt;: Word embeddings are a type of word representation that allows words with similar meanings to have similar representations. Key methods include Word2Vec, GloVe, and FastText.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Recurrent Neural Networks (RNNs)&lt;/strong&gt;: Understand the working of RNNs, a type of neural network designed to work with sequence data. Explore LSTMs and GRUs, two RNN variants that are capable of learning long-term dependencies.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;📚 Resources:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://lena-voita.github.io/nlp_course/word_embeddings.html"&gt;Lena Voita - Word Embeddings&lt;/a&gt;: Beginner-friendly course about concepts related to word embeddings.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://realpython.com/natural-language-processing-spacy-python/"&gt;RealPython - NLP with spaCy in Python&lt;/a&gt;: Exhaustive guide about the spaCy library for NLP tasks in Python.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.kaggle.com/learn-guide/natural-language-processing"&gt;Kaggle - NLP Guide&lt;/a&gt;: A few notebooks and resources for a hands-on explanation of NLP in Python.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://jalammar.github.io/illustrated-word2vec/"&gt;Jay Alammar - The Illustration Word2Vec&lt;/a&gt;: A good reference to understand the famous Word2Vec architecture.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://jaketae.github.io/study/pytorch-rnn/"&gt;Jake Tae - PyTorch RNN from Scratch&lt;/a&gt;: Practical and simple implementation of RNN, LSTM, and GRU models in PyTorch.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;colah's blog - Understanding LSTM Networks&lt;/a&gt;: A more theoretical article about the LSTM network.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;🧑‍🔬 The LLM Scientist&lt;/h2&gt; 
&lt;p&gt;This section of the course focuses on learning how to build the best possible LLMs using the latest techniques.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/roadmap_scientist.png" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;1. The LLM architecture&lt;/h3&gt; 
&lt;p&gt;An in-depth knowledge of the Transformer architecture is not required, but it's important to understand the main steps of modern LLMs: converting text into numbers through tokenization, processing these tokens through layers including attention mechanisms, and finally generating new text through various sampling strategies.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Architectural Overview&lt;/strong&gt;: Understand the evolution from encoder-decoder Transformers to decoder-only architectures like GPT, which form the basis of modern LLMs. Focus on how these models process and generate text at a high level.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tokenization&lt;/strong&gt;: Learn the principles of tokenization - how text is converted into numerical representations that LLMs can process. Explore different tokenization strategies and their impact on model performance and output quality.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Attention mechanisms&lt;/strong&gt;: Master the core concepts of attention mechanisms, particularly self-attention and its variants. Understand how these mechanisms enable LLMs to process long-range dependencies and maintain context throughout sequences.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sampling techniques&lt;/strong&gt;: Explore various text generation approaches and their tradeoffs. Compare deterministic methods like greedy search and beam search with probabilistic approaches like temperature sampling and nucleus sampling.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wjZofJX0v4M"&gt;Visual intro to Transformers&lt;/a&gt; by 3Blue1Brown: Visual introduction to Transformers for complete beginners.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bbycroft.net/llm"&gt;LLM Visualization&lt;/a&gt; by Brendan Bycroft: Interactive 3D visualization of LLM internals.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=kCc8FmEb1nY"&gt;nanoGPT&lt;/a&gt; by Andrej Karpathy: A 2h-long YouTube video to reimplement GPT from scratch (for programmers). He also made a video about &lt;a href="https://www.youtube.com/watch?v=zduSFxRajkE"&gt;tokenization&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lilianweng.github.io/posts/2018-06-24-attention/"&gt;Attention? Attention!&lt;/a&gt; by Lilian Weng: Historical overview to introduce the need for attention mechanisms.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mlabonne.github.io/blog/posts/2023-06-07-Decoding_strategies.html"&gt;Decoding Strategies in LLMs&lt;/a&gt; by Maxime Labonne: Provide code and a visual introduction to the different decoding strategies to generate text.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;2. Pre-training models&lt;/h3&gt; 
&lt;p&gt;Pre-training is a computationally intensive and expensive process. While it's not the focus of this course, it's important to have a solid understanding of how models are pre-trained, especially in terms of data and parameters. Pre-training can also be performed by hobbyists at a small scale with &amp;lt;1B models.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data preparation&lt;/strong&gt;: Pre-training requires massive datasets (e.g., &lt;a href="https://arxiv.org/abs/2307.09288"&gt;Llama 3.1&lt;/a&gt; was trained on 15 trillion tokens) that need careful curation, cleaning, deduplication, and tokenization. Modern pre-training pipelines implement sophisticated filtering to remove low-quality or problematic content.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed training&lt;/strong&gt;: Combine different parallelization strategies: data parallel (batch distribution), pipeline parallel (layer distribution), and tensor parallel (operation splitting). These strategies require optimized network communication and memory management across GPU clusters.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Training optimization&lt;/strong&gt;: Use adaptive learning rates with warm-up, gradient clipping, and normalization to prevent explosions, mixed-precision training for memory efficiency, and modern optimizers (AdamW, Lion) with tuned hyperparameters.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt;: Track key metrics (loss, gradients, GPU stats) using dashboards, implement targeted logging for distributed training issues, and set up performance profiling to identify bottlenecks in computation and communication across devices.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1"&gt;FineWeb&lt;/a&gt; by Penedo et al.: Article to recreate a large-scale dataset for LLM pretraining (15T), including FineWeb-Edu, a high-quality subset.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.together.ai/blog/redpajama-data-v2"&gt;RedPajama v2&lt;/a&gt; by Weber et al.: Another article and paper about a large-scale pre-training dataset with a lot of interesting quality filters.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/nanotron"&gt;nanotron&lt;/a&gt; by Hugging Face: Minimalistic LLM training codebase used to make &lt;a href="https://github.com/huggingface/smollm"&gt;SmolLM2&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.andrew.cmu.edu/course/11-667/lectures/W10L2%20Scaling%20Up%20Parallel%20Training.pdf"&gt;Parallel training&lt;/a&gt; by Chenyan Xiong: Overview of optimization and parallelism techniques.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2407.20018"&gt;Distributed training&lt;/a&gt; by Duan et al.: A survey about efficient training of LLM on distributed architectures.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://allenai.org/olmo"&gt;OLMo 2&lt;/a&gt; by AI2: Open-source language model with model, data, training, and evaluation code.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.llm360.ai/"&gt;LLM360&lt;/a&gt; by LLM360: A framework for open-source LLMs with training and data preparation code, data, metrics, and models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;3. Post-training datasets&lt;/h3&gt; 
&lt;p&gt;Post-training datasets have a precise structure with instructions and answers (supervised fine-tuning) or instructions and chosen/rejected answers (preference alignment). Conversational structures are a lot rarer than the raw text used for pre-training, which is why we often need to process seed data and refine it to improve the accuracy, diversity, and complexity of the samples. More information and examples are available in my repo &lt;a href="https://github.com/mlabonne/llm-datasets"&gt;💾 LLM Datasets&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Storage &amp;amp; chat templates&lt;/strong&gt;: Because of the conversational structure, post-training datasets are stored in a specific format like ShareGPT or OpenAI/HF. Then, these formats are mapped to a chat template like ChatML or Alpaca to produce the final samples the model is trained on.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Synthetic data generation&lt;/strong&gt;: Create instruction-response pairs based on seed data using frontier models like GPT-4o. This approach allows for flexible and scalable dataset creation with high-quality answers. Key considerations include designing diverse seed tasks and effective system prompts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data enhancement&lt;/strong&gt;: Enhance existing samples using techniques like verified outputs (using unit tests or solvers), multiple answers with rejection sampling, &lt;a href="https://arxiv.org/abs/2406.00770"&gt;Auto-Evol&lt;/a&gt;, Chain-of-Thought, Branch-Solve-Merge, personas, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality filtering&lt;/strong&gt;: Traditional techniques involve rule-based filtering, removing duplicates or near-duplicates (with MinHash or embeddings), and n-gram decontamination. Reward models and judge LLMs complement this step with fine-grained and customizable quality control.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/argilla/synthetic-data-generator"&gt;Synthetic Data Generator&lt;/a&gt; by Argilla: Beginner-friendly way of building datasets using natural language in a Hugging Face space.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mlabonne/llm-datasets"&gt;LLM Datasets&lt;/a&gt; by Maxime Labonne: Curated list of datasets and tools for post-training.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/NVIDIA/NeMo-Curator"&gt;NeMo-Curator&lt;/a&gt; by Nvidia: Dataset preparation and curation framework for pre- and post-training data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://distilabel.argilla.io/dev/sections/pipeline_samples/"&gt;Distilabel&lt;/a&gt; by Argilla: Framework to generate synthetic data. It also includes interesting reproductions of papers like UltraFeedback.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MinishLab/semhash"&gt;Semhash&lt;/a&gt; by MinishLab: Minimalistic library for near-deduplication and decontamination with a distilled embedding model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/docs/transformers/main/en/chat_templating"&gt;Chat Template&lt;/a&gt; by Hugging Face: Hugging Face's documentation about chat templates.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;4. Supervised Fine-Tuning&lt;/h3&gt; 
&lt;p&gt;SFT turns base models into helpful assistants, capable of answering questions and following instructions. During this process, they learn how to structure answers and reactivate a subset of knowledge learned during pre-training. Instilling new knowledge is possible but superficial: it cannot be used to learn a completely new language. Always prioritize data quality over parameter optimization.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Training techniques&lt;/strong&gt;: Full fine-tuning updates all model parameters but requires significant compute. Parameter-efficient fine-tuning techniques like LoRA and QLoRA reduce memory requirements by training a small number of adapter parameters while keeping base weights frozen. QLoRA combines 4-bit quantization with LoRA to reduce VRAM usage. These techniques are all implemented in the most popular fine-tuning frameworks: &lt;a href="https://huggingface.co/docs/trl/en/index"&gt;TRL&lt;/a&gt;, &lt;a href="https://docs.unsloth.ai/"&gt;Unsloth&lt;/a&gt;, and &lt;a href="https://axolotl.ai/"&gt;Axolotl&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Training parameters&lt;/strong&gt;: Key parameters include learning rate with schedulers, batch size, gradient accumulation, number of epochs, optimizer (like 8-bit AdamW), weight decay for regularization, and warmup steps for training stability. LoRA also adds three parameters: rank (typically 16-128), alpha (1-2x rank), and target modules.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed training&lt;/strong&gt;: Scale training across multiple GPUs using DeepSpeed or FSDP. DeepSpeed provides three ZeRO optimization stages with increasing levels of memory efficiency through state partitioning. Both methods support gradient checkpointing for memory efficiency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt;: Track training metrics including loss curves, learning rate schedules, and gradient norms. Monitor for common issues like loss spikes, gradient explosions, or performance degradation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/blog/mlabonne/sft-llama3"&gt;Fine-tune Llama 3.1 Ultra-Efficiently with Unsloth&lt;/a&gt; by Maxime Labonne: Hands-on tutorial on how to fine-tune a Llama 3.1 model using Unsloth.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://axolotl-ai-cloud.github.io/axolotl/"&gt;Axolotl - Documentation&lt;/a&gt; by Wing Lian: Lots of interesting information related to distributed training and dataset formats.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://parlance-labs.com/education/"&gt;Mastering LLMs&lt;/a&gt; by Hamel Husain: Collection of educational resources about fine-tuning (but also RAG, evaluation, applications, and prompt engineering).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lightning.ai/pages/community/lora-insights/"&gt;LoRA insights&lt;/a&gt; by Sebastian Raschka: Practical insights about LoRA and how to select the best parameters.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;5. Preference Alignment&lt;/h3&gt; 
&lt;p&gt;Preference alignment is a second stage in the post-training pipeline, focused on aligning generated answers with human preferences. This stage was designed to tune the tone of LLMs and reduce toxicity and hallucinations. However, it has become increasingly important to also boost their performance and improve usefulness. Unlike SFT, there are many preference alignment algorithms. Here, we'll focus on the three most important ones: DPO, GRPO, and PPO.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Rejection sampling&lt;/strong&gt;: For each prompt, use the trained model to generate multiple responses, and score them to infer chosen/rejected answers. This creates on-policy data, where both responses come from the model being trained, improving alignment stability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://arxiv.org/abs/2305.18290"&gt;Direct Preference Optimization&lt;/a&gt;&lt;/strong&gt; Directly optimizes the policy to maximize the likelihood of chosen responses over rejected ones. It doesn't require reward modeling, which makes it more computationally efficient than RL techniques but slightly worse in terms of quality. Great for creating chat models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reward model&lt;/strong&gt;: Train a reward model with human feedback to predict metrics like human preferences. It can leverage frameworks like &lt;a href="https://huggingface.co/docs/trl/en/index"&gt;TRL&lt;/a&gt;, &lt;a href="https://github.com/volcengine/verl"&gt;verl&lt;/a&gt;, and &lt;a href="https://github.com/OpenRLHF/OpenRLHF"&gt;OpenRLHF&lt;/a&gt; for scalable training.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reinforcement Learning&lt;/strong&gt;: RL techniques like &lt;a href="https://arxiv.org/abs/2402.03300"&gt;GRPO&lt;/a&gt; and &lt;a href="https://arxiv.org/abs/1707.06347"&gt;PPO&lt;/a&gt; iteratively update a policy to maximize rewards while staying close to the initial behavior. They can use a reward model or reward functions to score responses. They tend to be computationally expensive and require careful tuning of hyperparameters, including learning rate, batch size, and clip range. Ideal for creating reasoning models.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/blog/rlhf"&gt;Illustrating RLHF&lt;/a&gt; by Hugging Face: Introduction to RLHF with reward model training and fine-tuning with reinforcement learning.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives"&gt;LLM Training: RLHF and Its Alternatives&lt;/a&gt; by Sebastian Raschka: Overview of the RLHF process and alternatives like RLAIF.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/blog/pref-tuning"&gt;Preference Tuning LLMs&lt;/a&gt; by Hugging Face: Comparison of the DPO, IPO, and KTO algorithms to perform preference alignment.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mlabonne.github.io/blog/posts/Fine_tune_Mistral_7b_with_DPO.html"&gt;Fine-tune with DPO&lt;/a&gt; by Maxime Labonne: Tutorial to fine-tune a Mistral-7b model with DPO and reproduce &lt;a href="https://huggingface.co/mlabonne/NeuralHermes-2.5-Mistral-7B"&gt;NeuralHermes-2.5&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/learn/llm-course/en/chapter12/5"&gt;Fine-tune with GRPO&lt;/a&gt; by Maxime Labonne: Practical exercise to fine-tune a small model with GRPO.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wandb.ai/alexander-vishnevskiy/dpo/reports/TRL-Original-DPO--Vmlldzo1NjI4MTc4"&gt;DPO Wandb logs&lt;/a&gt; by Alexander Vishnevskiy: It shows you the main DPO metrics to track and the trends you should expect.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;6. Evaluation&lt;/h3&gt; 
&lt;p&gt;Reliably evaluating LLMs is a complex but essential task guiding data generation and training. It provides invaluable feedback about areas of improvement, which can be leveraged to modify the data mixture, quality, and training parameters. However, it's always good to remember Goodhart's law: "When a measure becomes a target, it ceases to be a good measure."&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automated benchmarks&lt;/strong&gt;: Evaluate models on specific tasks using curated datasets and metrics, like MMLU. It works well for concrete tasks but struggles with abstract and creative capabilities. It is also prone to data contamination.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Human evaluation&lt;/strong&gt;: It involves humans prompting models and grading responses. Methods range from vibe checks to systematic annotations with specific guidelines and large-scale community voting (arena). It is more suited for subjective tasks and less reliable for factual accuracy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model-based evaluation&lt;/strong&gt;: Use judge and reward models to evaluate model outputs. It highly correlates with human preferences but suffers from bias toward their own outputs and inconsistent scoring.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feedback signal&lt;/strong&gt;: Analyze error patterns to identify specific weaknesses, such as limitations in following complex instructions, lack of specific knowledge, or susceptibility to adversarial prompts. This can be improved with better data generation and training parameters.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/evaluation-guidebook"&gt;Evaluation guidebook&lt;/a&gt; by Clémentine Fourrier: Practical insights and theoretical knowledge about LLM evaluation.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard"&gt;Open LLM Leaderboard&lt;/a&gt; by Hugging Face: Main leaderboard to compare LLMs in an open and reproducible way (automated benchmarks).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EleutherAI/lm-evaluation-harness"&gt;Language Model Evaluation Harness&lt;/a&gt; by EleutherAI: A popular framework for evaluating LLMs using automated benchmarks.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/lighteval"&gt;Lighteval&lt;/a&gt; by Hugging Face: Alternative evaluation framework that also includes model-based evaluations.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lmarena.ai/"&gt;Chatbot Arena&lt;/a&gt; by LMSYS: Elo rating of general-purpose LLMs, based on comparisons made by humans (human evaluation).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;7. Quantization&lt;/h3&gt; 
&lt;p&gt;Quantization is the process of converting the parameters and activations of a model using a lower precision. For example, weights stored using 16 bits can be converted into a 4-bit representation. This technique has become increasingly important to reduce the computational and memory costs associated with LLMs.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Base techniques&lt;/strong&gt;: Learn the different levels of precision (FP32, FP16, INT8, etc.) and how to perform naïve quantization with absmax and zero-point techniques.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GGUF &amp;amp; llama.cpp&lt;/strong&gt;: Originally designed to run on CPUs, &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt; and the GGUF format have become the most popular tools to run LLMs on consumer-grade hardware. It supports storing special tokens, vocabulary, and metadata in a single file.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPTQ &amp;amp; AWQ&lt;/strong&gt;: Techniques like &lt;a href="https://arxiv.org/abs/2210.17323"&gt;GPTQ&lt;/a&gt;/&lt;a href="https://github.com/turboderp/exllamav2"&gt;EXL2&lt;/a&gt; and &lt;a href="https://arxiv.org/abs/2306.00978"&gt;AWQ&lt;/a&gt; introduce layer-by-layer calibration that retains performance at extremely low bitwidths. They reduce catastrophic outliers using dynamic scaling, selectively skipping or re-centering the heaviest parameters.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SmoothQuant &amp;amp; ZeroQuant&lt;/strong&gt;: New quantization-friendly transformations (SmoothQuant) and compiler-based optimizations (ZeroQuant) help mitigate outliers before quantization. They also reduce hardware overhead by fusing certain ops and optimizing dataflow.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html"&gt;Introduction to quantization&lt;/a&gt; by Maxime Labonne: Overview of quantization, absmax and zero-point quantization, and LLM.int8() with code.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mlabonne.github.io/blog/posts/Quantize_Llama_2_models_using_ggml.html"&gt;Quantize Llama models with llama.cpp&lt;/a&gt; by Maxime Labonne: Tutorial on how to quantize a Llama 2 model using llama.cpp and the GGUF format.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mlabonne.github.io/blog/posts/4_bit_Quantization_with_GPTQ.html"&gt;4-bit LLM Quantization with GPTQ&lt;/a&gt; by Maxime Labonne: Tutorial on how to quantize an LLM using the GPTQ algorithm with AutoGPTQ.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/friendliai/understanding-activation-aware-weight-quantization-awq-boosting-inference-serving-efficiency-in-10bb0faf63a8"&gt;Understanding Activation-Aware Weight Quantization&lt;/a&gt; by FriendliAI: Overview of the AWQ technique and its benefits.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mit-han-lab/smoothquant/raw/main/examples/smoothquant_llama_demo.ipynb"&gt;SmoothQuant on Llama 2 7B&lt;/a&gt; by MIT HAN Lab: Tutorial on how to use SmoothQuant with a Llama 2 model in 8-bit precision.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.deepspeed.ai/tutorials/model-compression/"&gt;DeepSpeed Model Compression&lt;/a&gt; by DeepSpeed: Tutorial on how to use ZeroQuant and extreme compression (XTC) with DeepSpeed Compression.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;8. New Trends&lt;/h3&gt; 
&lt;p&gt;Here are notable topics that didn't fit into other categories. Some are established (model merging, multimodal) techniques, but others are more experimental (interpretability, test-time compute scaling) and the focus of numerous research papers.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Model merging&lt;/strong&gt;: Merging trained models has become a popular way of creating performant models without any fine-tuning. The popular &lt;a href="https://github.com/cg123/mergekit"&gt;mergekit&lt;/a&gt; library implements the most popular merging methods, like SLERP, &lt;a href="https://arxiv.org/abs/2311.03099"&gt;DARE&lt;/a&gt;, and &lt;a href="https://arxiv.org/abs/2311.03099"&gt;TIES&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multimodal models&lt;/strong&gt;: These models (like &lt;a href="https://openai.com/research/clip"&gt;CLIP&lt;/a&gt;, &lt;a href="https://stability.ai/stable-image"&gt;Stable Diffusion&lt;/a&gt;, or &lt;a href="https://llava-vl.github.io/"&gt;LLaVA&lt;/a&gt;) process multiple types of inputs (text, images, audio, etc.) with a unified embedding space, which unlocks powerful applications like text-to-image.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interpretability&lt;/strong&gt;: Mechanistic interpretability techniques like Sparse Autoencoders (SAEs) have made remarkable progress to provide insights about the inner workings of LLMs. This has also been applied with techniques such as abliteration, which allow you to modify the behavior of models without training.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test-time compute&lt;/strong&gt;: Reasoning models trained with RL techniques can be further improved by scaling the compute budget during test time. It can involve multiple calls, MCTS, or specialized models like a Process Reward Model (PRM). Iterative steps with precise scoring significantly improve performance for complex reasoning tasks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mlabonne.github.io/blog/posts/2024-01-08_Merge_LLMs_with_mergekit.html"&gt;Merge LLMs with mergekit&lt;/a&gt; by Maxime Labonne: Tutorial about model merging using mergekit.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/merveenoyan/smol-vision"&gt;Smol Vision&lt;/a&gt; by Merve Noyan: Collection of notebooks and scripts dedicated to small multimodal models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huyenchip.com/2023/10/10/multimodal.html"&gt;Large Multimodal Models&lt;/a&gt; by Chip Huyen: Overview of multimodal systems and the recent history of this field.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/blog/mlabonne/abliteration"&gt;Unsensor any LLM with abliteration&lt;/a&gt; by Maxime Labonne: Direct application of interpretability techniques to modify the style of a model.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://adamkarvonen.github.io/machine_learning/2024/06/11/sae-intuitions.html"&gt;Intuitive Explanation of SAEs&lt;/a&gt; by Adam Karvonen: Article about how SAEs work and why they make sense for interpretability.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute"&gt;Scaling test-time compute&lt;/a&gt; by Beeching et al.: Tutorial and experiments to outperform Llama 3.1 70B on MATH-500 with a 3B model.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;👷 The LLM Engineer&lt;/h2&gt; 
&lt;p&gt;This section of the course focuses on learning how to build LLM-powered applications that can be used in production, with a focus on augmenting models and deploying them.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/mlabonne/llm-course/main/img/roadmap_engineer.png" alt="" /&gt;&lt;/p&gt; 
&lt;h3&gt;1. Running LLMs&lt;/h3&gt; 
&lt;p&gt;Running LLMs can be difficult due to high hardware requirements. Depending on your use case, you might want to simply consume a model through an API (like GPT-4) or run it locally. In any case, additional prompting and guidance techniques can improve and constrain the output for your applications.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LLM APIs&lt;/strong&gt;: APIs are a convenient way to deploy LLMs. This space is divided between private LLMs (&lt;a href="https://platform.openai.com/"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview"&gt;Google&lt;/a&gt;, &lt;a href="https://docs.anthropic.com/claude/reference/getting-started-with-the-api"&gt;Anthropic&lt;/a&gt;, etc.) and open-source LLMs (&lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt;, &lt;a href="https://huggingface.co/inference-api"&gt;Hugging Face&lt;/a&gt;, &lt;a href="https://www.together.ai/"&gt;Together AI&lt;/a&gt;, etc.).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open-source LLMs&lt;/strong&gt;: The &lt;a href="https://huggingface.co/models"&gt;Hugging Face Hub&lt;/a&gt; is a great place to find LLMs. You can directly run some of them in &lt;a href="https://huggingface.co/spaces"&gt;Hugging Face Spaces&lt;/a&gt;, or download and run them locally in apps like &lt;a href="https://lmstudio.ai/"&gt;LM Studio&lt;/a&gt; or through the CLI with &lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt; or &lt;a href="https://ollama.ai/"&gt;ollama&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt engineering&lt;/strong&gt;: Common techniques include zero-shot prompting, few-shot prompting, chain of thought, and ReAct. They work better with bigger models, but can be adapted to smaller ones.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Structuring outputs&lt;/strong&gt;: Many tasks require a structured output, like a strict template or a JSON format. Libraries like &lt;a href="https://github.com/outlines-dev/outlines"&gt;Outlines&lt;/a&gt; can be used to guide the generation and respect a given structure. Some APIs also support structured output generation natively using JSON schemas.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio"&gt;Run an LLM locally with LM Studio&lt;/a&gt; by Nisha Arya: Short guide on how to use LM Studio.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.promptingguide.ai/"&gt;Prompt engineering guide&lt;/a&gt; by DAIR.AI: Exhaustive list of prompt techniques with examples&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dottxt-ai.github.io/outlines/latest/quickstart/"&gt;Outlines - Quickstart&lt;/a&gt;: List of guided generation techniques enabled by Outlines.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lmql.ai/docs/language/overview.html"&gt;LMQL - Overview&lt;/a&gt;: Introduction to the LMQL language.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;2. Building a Vector Storage&lt;/h3&gt; 
&lt;p&gt;Creating a vector storage is the first step to building a Retrieval Augmented Generation (RAG) pipeline. Documents are loaded, split, and relevant chunks are used to produce vector representations (embeddings) that are stored for future use during inference.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Ingesting documents&lt;/strong&gt;: Document loaders are convenient wrappers that can handle many formats: PDF, JSON, HTML, Markdown, etc. They can also directly retrieve data from some databases and APIs (GitHub, Reddit, Google Drive, etc.).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Splitting documents&lt;/strong&gt;: Text splitters break down documents into smaller, semantically meaningful chunks. Instead of splitting text after &lt;em&gt;n&lt;/em&gt; characters, it's often better to split by header or recursively, with some additional metadata.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Embedding models&lt;/strong&gt;: Embedding models convert text into vector representations. Picking task-specific models significantly improves performance for semantic search and RAG.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vector databases&lt;/strong&gt;: Vector databases (like &lt;a href="https://www.trychroma.com/"&gt;Chroma&lt;/a&gt;, &lt;a href="https://www.pinecone.io/"&gt;Pinecone&lt;/a&gt;, &lt;a href="https://milvus.io/"&gt;Milvus&lt;/a&gt;, &lt;a href="https://faiss.ai/"&gt;FAISS&lt;/a&gt;, &lt;a href="https://github.com/spotify/annoy"&gt;Annoy&lt;/a&gt;, etc.) are designed to store embedding vectors. They enable efficient retrieval of data that is 'most similar' to a query based on vector similarity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/docs/how_to/#text-splitters"&gt;LangChain - Text splitters&lt;/a&gt;: List of different text splitters implemented in LangChain.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sbert.net/"&gt;Sentence Transformers library&lt;/a&gt;: Popular library for embedding models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/spaces/mteb/leaderboard"&gt;MTEB Leaderboard&lt;/a&gt;: Leaderboard for embedding models.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.datacamp.com/blog/the-top-5-vector-databases"&gt;The Top 7 Vector Databases&lt;/a&gt; by Moez Ali: A comparison of the best and most popular vector databases.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;3. Retrieval Augmented Generation&lt;/h3&gt; 
&lt;p&gt;With RAG, LLMs retrieve contextual documents from a database to improve the accuracy of their answers. RAG is a popular way of augmenting the model's knowledge without any fine-tuning.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Orchestrators&lt;/strong&gt;: Orchestrators like &lt;a href="https://python.langchain.com/docs/get_started/introduction"&gt;LangChain&lt;/a&gt; and &lt;a href="https://docs.llamaindex.ai/en/stable/"&gt;LlamaIndex&lt;/a&gt; are popular frameworks to connect your LLMs with tools and databases. The Model Context Protocol (MCP) introduces a new standard to pass data and context to models across providers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Retrievers&lt;/strong&gt;: Query rewriters and generative retrievers like CoRAG and HyDE enhance search by transforming user queries. Multi-vector and hybrid retrieval methods combine embeddings with keyword signals to improve recall and precision.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt;: To remember previous instructions and answers, LLMs and chatbots like ChatGPT add this history to their context window. This buffer can be improved with summarization (e.g., using a smaller LLM), a vector store + RAG, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;: We need to evaluate both the document retrieval (context precision and recall) and generation stages (faithfulness and answer relevancy). It can be simplified with tools &lt;a href="https://github.com/explodinggradients/ragas/tree/main"&gt;Ragas&lt;/a&gt; and &lt;a href="https://github.com/confident-ai/deepeval"&gt;DeepEval&lt;/a&gt; (assessing quality).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.llamaindex.ai/en/stable/getting_started/concepts.html"&gt;Llamaindex - High-level concepts&lt;/a&gt;: Main concepts to know when building RAG pipelines.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://modelcontextprotocol.io/introduction"&gt;Model Context Protocol&lt;/a&gt;: Introduction to MCP with motivate, architecture, and quick starts.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pinecone.io/learn/series/langchain/langchain-retrieval-augmentation/"&gt;Pinecone - Retrieval Augmentation&lt;/a&gt;: Overview of the retrieval augmentation process.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/docs/tutorials/rag/"&gt;LangChain - Q&amp;amp;A with RAG&lt;/a&gt;: Step-by-step tutorial to build a typical RAG pipeline.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/docs/how_to/chatbots_memory/"&gt;LangChain - Memory types&lt;/a&gt;: List of different types of memories with relevant usage.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.ragas.io/en/stable/concepts/metrics/index.html"&gt;RAG pipeline - Metrics&lt;/a&gt;: Overview of the main metrics used to evaluate RAG pipelines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;4. Advanced RAG&lt;/h3&gt; 
&lt;p&gt;Real-life applications can require complex pipelines, including SQL or graph databases, as well as automatically selecting relevant tools and APIs. These advanced techniques can improve a baseline solution and provide additional features.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Query construction&lt;/strong&gt;: Structured data stored in traditional databases requires a specific query language like SQL, Cypher, metadata, etc. We can directly translate the user instruction into a query to access the data with query construction.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Agents augment LLMs by automatically selecting the most relevant tools to provide an answer. These tools can be as simple as using Google or Wikipedia, or more complex like a Python interpreter or Jira.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Post-processing&lt;/strong&gt;: Final step that processes the inputs that are fed to the LLM. It enhances the relevance and diversity of documents retrieved with re-ranking, &lt;a href="https://github.com/Raudaschl/rag-fusion"&gt;RAG-fusion&lt;/a&gt;, and classification.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Program LLMs&lt;/strong&gt;: Frameworks like &lt;a href="https://github.com/stanfordnlp/dspy"&gt;DSPy&lt;/a&gt; allow you to optimize prompts and weights based on automated evaluations in a programmatic way.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://blog.langchain.dev/query-construction/"&gt;LangChain - Query Construction&lt;/a&gt;: Blog post about different types of query construction.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/docs/tutorials/sql_qa/"&gt;LangChain - SQL&lt;/a&gt;: Tutorial on how to interact with SQL databases with LLMs, involving Text-to-SQL and an optional SQL agent.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pinecone.io/learn/series/langchain/langchain-agents/"&gt;Pinecone - LLM agents&lt;/a&gt;: Introduction to agents and tools with different types.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lilianweng.github.io/posts/2023-06-23-agent/"&gt;LLM Powered Autonomous Agents&lt;/a&gt; by Lilian Weng: A more theoretical article about LLM agents.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.langchain.dev/applying-openai-rag/"&gt;LangChain - OpenAI's RAG&lt;/a&gt;: Overview of the RAG strategies employed by OpenAI, including post-processing.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dspy-docs.vercel.app/docs/building-blocks/solving_your_task"&gt;DSPy in 8 Steps&lt;/a&gt;: General-purpose guide to DSPy introducing modules, signatures, and optimizers.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;5. Agents&lt;/h3&gt; 
&lt;p&gt;An LLM agent can autonomously perform tasks by taking actions based on reasoning about its environment, typically through the use of tools or functions to interact with external systems.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Agent fundamentals&lt;/strong&gt;: Agents operate using thoughts (internal reasoning to decide what to do next), action (executing tasks, often by interacting with external tools), and observation (analyzing feedback or results to refine the next step).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agent frameworks&lt;/strong&gt;: Agent development can be streamlined using different frameworks like &lt;a href="https://www.langchain.com/langgraph"&gt;LangGraph&lt;/a&gt; (design and visualization of workflows), &lt;a href="https://docs.llamaindex.ai/en/stable/use_cases/agents/"&gt;LlamaIndex&lt;/a&gt; (data-augmented agents with RAG), or &lt;a href="https://github.com/huggingface/smolagents"&gt;smolagents&lt;/a&gt; (beginner-friendly, lightweight option).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-agents&lt;/strong&gt;: More experimental frameworks include collaboration between different agents, such as &lt;a href="https://docs.crewai.com/introduction"&gt;CrewAI&lt;/a&gt; (role-based team orchestration), &lt;a href="https://github.com/microsoft/autogen"&gt;AutoGen&lt;/a&gt; (conversation-driven multi-agent systems), and &lt;a href="https://github.com/openai/openai-agents-python"&gt;OpenAI Agents SDK&lt;/a&gt; (production-ready with strong OpenAI model integration).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/learn/agents-course/unit0/introduction"&gt;Agents Course&lt;/a&gt;: Popular course about AI agents made by Hugging Face.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://langfuse.com/blog/2025-03-19-ai-agent-comparison"&gt;AI Agents Comparison&lt;/a&gt; by Jannik Maierhöfer: Comparison of features across different open-source AI agent frameworks.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://langchain-ai.github.io/langgraph/concepts/why-langgraph/"&gt;LangGraph&lt;/a&gt;: Overview of how to build AI agents with LangGraph.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.llamaindex.ai/en/stable/use_cases/agents/"&gt;LlamaIndex Agents&lt;/a&gt;: Uses cases and resources to build agents with LlamaIndex.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/docs/smolagents/index"&gt;smolagents&lt;/a&gt;: Documentation with a guided tour, how-to guides, and more conceptual articles.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;6. Inference optimization&lt;/h3&gt; 
&lt;p&gt;Text generation is a costly process that requires expensive hardware. In addition to quantization, various techniques have been proposed to maximize throughput and reduce inference costs.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Flash Attention&lt;/strong&gt;: Optimization of the attention mechanism to transform its complexity from quadratic to linear, speeding up both training and inference.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Key-value cache&lt;/strong&gt;: Understand the key-value cache and the improvements introduced in &lt;a href="https://arxiv.org/abs/1911.02150"&gt;Multi-Query Attention&lt;/a&gt; (MQA) and &lt;a href="https://arxiv.org/abs/2305.13245"&gt;Grouped-Query Attention&lt;/a&gt; (GQA).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Speculative decoding&lt;/strong&gt;: Use a small model to produce drafts that are then reviewed by a larger model to speed up text generation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/docs/transformers/main/en/perf_infer_gpu_one"&gt;GPU Inference&lt;/a&gt; by Hugging Face: Explain how to optimize inference on GPUs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices"&gt;LLM Inference&lt;/a&gt; by Databricks: Best practices for how to optimize LLM inference in production.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/docs/transformers/main/en/llm_tutorial_optimization"&gt;Optimizing LLMs for Speed and Memory&lt;/a&gt; by Hugging Face: Explain three main techniques to optimize speed and memory, namely quantization, Flash Attention, and architectural innovations.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/blog/assisted-generation"&gt;Assisted Generation&lt;/a&gt; by Hugging Face: HF's version of speculative decoding, it's an interesting blog post about how it works with code to implement it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;7. Deploying LLMs&lt;/h3&gt; 
&lt;p&gt;Deploying LLMs at scale is an engineering feat that can require multiple clusters of GPUs. In other scenarios, demos and local apps can be achieved with a much lower complexity.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local deployment&lt;/strong&gt;: Privacy is an important advantage that open-source LLMs have over private ones. Local LLM servers (&lt;a href="https://lmstudio.ai/"&gt;LM Studio&lt;/a&gt;, &lt;a href="https://ollama.ai/"&gt;Ollama&lt;/a&gt;, &lt;a href="https://github.com/oobabooga/text-generation-webui"&gt;oobabooga&lt;/a&gt;, &lt;a href="https://github.com/LostRuins/koboldcpp"&gt;kobold.cpp&lt;/a&gt;, etc.) capitalize on this advantage to power local apps.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Demo deployment&lt;/strong&gt;: Frameworks like &lt;a href="https://www.gradio.app/"&gt;Gradio&lt;/a&gt; and &lt;a href="https://docs.streamlit.io/"&gt;Streamlit&lt;/a&gt; are helpful to prototype applications and share demos. You can also easily host them online, for example using &lt;a href="https://huggingface.co/spaces"&gt;Hugging Face Spaces&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server deployment&lt;/strong&gt;: Deploy LLMs at scale requires cloud (see also &lt;a href="https://skypilot.readthedocs.io/en/latest/"&gt;SkyPilot&lt;/a&gt;) or on-prem infrastructure and often leverage optimized text generation frameworks like &lt;a href="https://github.com/huggingface/text-generation-inference"&gt;TGI&lt;/a&gt;, &lt;a href="https://github.com/vllm-project/vllm/tree/main"&gt;vLLM&lt;/a&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Edge deployment&lt;/strong&gt;: In constrained environments, high-performance frameworks like &lt;a href="https://github.com/mlc-ai/mlc-llm"&gt;MLC LLM&lt;/a&gt; and &lt;a href="https://github.com/wangzhaode/mnn-llm/raw/master/README_en.md"&gt;mnn-llm&lt;/a&gt; can deploy LLM in web browsers, Android, and iOS.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps"&gt;Streamlit - Build a basic LLM app&lt;/a&gt;: Tutorial to make a basic ChatGPT-like app using Streamlit.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/blog/sagemaker-huggingface-llm"&gt;HF LLM Inference Container&lt;/a&gt;: Deploy LLMs on Amazon SageMaker using Hugging Face's inference container.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.philschmid.de/"&gt;Philschmid&amp;nbsp;blog&lt;/a&gt; by Philipp Schmid: Collection of high-quality articles about LLM deployment using Amazon SageMaker.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hamel.dev/notes/llm/inference/03_inference.html"&gt;Optimizing latence&lt;/a&gt; by Hamel Husain: Comparison of TGI, vLLM, CTranslate2, and mlc in terms of throughput and latency.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;8. Securing LLMs&lt;/h3&gt; 
&lt;p&gt;In addition to traditional security problems associated with software, LLMs have unique weaknesses due to the way they are trained and prompted.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt hacking&lt;/strong&gt;: Different techniques related to prompt engineering, including prompt injection (additional instruction to hijack the model's answer), data/prompt leaking (retrieve its original data/prompt), and jailbreaking (craft prompts to bypass safety features).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backdoors&lt;/strong&gt;: Attack vectors can target the training data itself, by poisoning the training data (e.g., with false information) or creating backdoors (secret triggers to change the model's behavior during inference).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Defensive measures&lt;/strong&gt;: The best way to protect your LLM applications is to test them against these vulnerabilities (e.g., using red teaming and checks like &lt;a href="https://github.com/leondz/garak/"&gt;garak&lt;/a&gt;) and observe them in production (with a framework like &lt;a href="https://github.com/langfuse/langfuse"&gt;langfuse&lt;/a&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;📚 &lt;strong&gt;References&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://owasp.org/www-project-top-10-for-large-language-model-applications/"&gt;OWASP LLM Top 10&lt;/a&gt; by HEGO Wiki: List of the 10 most critical vulnerabilities seen in LLM applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jthack/PIPE"&gt;Prompt Injection Primer&lt;/a&gt; by Joseph Thacker: Short guide dedicated to prompt injection for engineers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://llmsecurity.net/"&gt;LLM Security&lt;/a&gt; by &lt;a href="https://twitter.com/llm_sec"&gt;@llm_sec&lt;/a&gt;: Extensive list of resources related to LLM security.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming"&gt;Red teaming LLMs&lt;/a&gt; by Microsoft: Guide on how to perform red teaming with LLMs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This roadmap was inspired by the excellent &lt;a href="https://github.com/milanm/DevOps-Roadmap"&gt;DevOps Roadmap&lt;/a&gt; from Milan Milanović and Romano Roth.&lt;/p&gt; 
&lt;p&gt;Special thanks to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thomas Thelen for motivating me to create a roadmap&lt;/li&gt; 
 &lt;li&gt;André Frade for his input and review of the first draft&lt;/li&gt; 
 &lt;li&gt;Dino Dunn for providing resources about LLM security&lt;/li&gt; 
 &lt;li&gt;Magdalena Kuhn for improving the "human evaluation" part&lt;/li&gt; 
 &lt;li&gt;Odoverdose for suggesting 3Blue1Brown's video about Transformers&lt;/li&gt; 
 &lt;li&gt;Everyone who contributed to the educational references in this course :)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Disclaimer: I am not affiliated with any sources listed here.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#mlabonne/llm-course&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=mlabonne/llm-course&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>x1xhlol/system-prompts-and-models-of-ai-tools</title>
      <link>https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools</link>
      <description>&lt;p&gt;FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus Agent Tools, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, dia &amp; v0. (And other Open Sourced) System Prompts, Internal Tools &amp; AI Models&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;strong&gt;System Prompts and Models of AI Tools&lt;/strong&gt;&lt;/h1&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;sub&gt;Special thanks to&lt;/sub&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://latitude.so/developers?utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=prompt_repo_sponsorship"&gt; &lt;img src="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/assets/Latitude_logo.png" alt="Latitude Logo" width="700" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;h3&gt;&lt;a href="https://latitude.so/developers?utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=prompt_repo_sponsorship"&gt;The tools you need for building reliable Agents and Prompts&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://latitude.so/developers?utm_source=github&amp;amp;utm_medium=readme&amp;amp;utm_campaign=prompt_repo_sponsorship"&gt;Open Source AI Engineering Platform&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;a href="https://discord.gg/NwzrWErdMU" target="_blank"&gt; &lt;img src="https://img.shields.io/discord/1402660735833604126?label=LeaksLab%20Discord&amp;amp;logo=discord&amp;amp;style=for-the-badge" alt="LeaksLab Discord" /&gt; &lt;/a&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Join the Conversation:&lt;/strong&gt; New system instructions are released on Discord &lt;strong&gt;before&lt;/strong&gt; they appear in this repository. Get early access and discuss them in real time.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/14084" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14084" alt="x1xhlol%2Fsystem-prompts-and-models-of-ai-tools | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;📜 Over &lt;strong&gt;20,000+ lines&lt;/strong&gt; of insights into their structure and functionality.&lt;/p&gt; 
&lt;p&gt;⭐ &lt;strong&gt;Star to follow updates&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://cloudback.it"&gt;&lt;img src="https://app.cloudback.it/badge/x1xhlol/system-prompts-and-models-of-ai-tools" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/x1xhlol/system-prompts-and-models-of-ai-tools"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;❤️ Support the Project&lt;/h2&gt; 
&lt;p&gt;If you find this collection valuable and appreciate the effort involved in obtaining and sharing these insights, please consider supporting the project. Your contribution helps keep this resource updated and allows for further exploration.&lt;/p&gt; 
&lt;p&gt;You can show your support via:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PayPal:&lt;/strong&gt; &lt;code&gt;lucknitelol@proton.me&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cryptocurrency:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;BTC:&lt;/strong&gt; &lt;code&gt;bc1q7zldmzjwspnaa48udvelwe6k3fef7xrrhg5625&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;LTC:&lt;/strong&gt; &lt;code&gt;LRWgqwEYDwqau1WeiTs6Mjg85NJ7m3fsdQ&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;ETH:&lt;/strong&gt; &lt;code&gt;0x3f844B2cc3c4b7242964373fB0A41C4fdffB192A&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Patreon:&lt;/strong&gt; &lt;a href="https://patreon.com/lucknite"&gt;https://patreon.com/lucknite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ko-fi:&lt;/strong&gt; &lt;a href="https://ko-fi.com/lucknite"&gt;https://ko-fi.com/lucknite&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;🙏 Thank you for your support!&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📑 Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#-table-of-contents"&gt;📑 Table of Contents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#-available-files"&gt;📂 Available Files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#-roadmap--feedback"&gt;🛠 Roadmap &amp;amp; Feedback&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#-connect-with-me"&gt;🔗 Connect With Me&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#%EF%B8%8F-security-notice-for-ai-startups"&gt;🛡️ Security Notice for AI Startups&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/#-star-history"&gt;📊 Star History&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📂 Available Files&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/v0%20Prompts%20and%20Tools/"&gt;&lt;strong&gt;v0&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Manus%20Agent%20Tools%20&amp;amp;%20Prompt/"&gt;&lt;strong&gt;Manus&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Augment%20Code/"&gt;&lt;strong&gt;Augment Code&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Lovable/"&gt;&lt;strong&gt;Lovable&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Devin%20AI/"&gt;&lt;strong&gt;Devin&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Same.dev/"&gt;&lt;strong&gt;Same.dev&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Replit/"&gt;&lt;strong&gt;Replit&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Windsurf/"&gt;&lt;strong&gt;Windsurf Agent&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/VSCode%20Agent/"&gt;&lt;strong&gt;VSCode (Copilot) Agent&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Cursor%20Prompts/"&gt;&lt;strong&gt;Cursor&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/dia/"&gt;&lt;strong&gt;Dia&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Trae/"&gt;&lt;strong&gt;Trae AI&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Perplexity/"&gt;&lt;strong&gt;Perplexity&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Cluely/"&gt;&lt;strong&gt;Cluely&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Xcode/"&gt;&lt;strong&gt;Xcode&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Leap.new/"&gt;&lt;strong&gt;Leap.new&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/NotionAi/"&gt;&lt;strong&gt;Notion AI&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Orchids.app/"&gt;&lt;strong&gt;Orchids.app&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Junie/"&gt;&lt;strong&gt;Junie&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Kiro/"&gt;&lt;strong&gt;Kiro&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Warp.dev/"&gt;&lt;strong&gt;Warp.dev&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Z.ai%20Code/"&gt;&lt;strong&gt;Z.ai Code&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Qoder/"&gt;&lt;strong&gt;Qoder&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Claude%20Code/"&gt;&lt;strong&gt;Claude Code&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/"&gt;&lt;strong&gt;Open Source prompts&lt;/strong&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/Codex%20CLI/"&gt;Codex CLI&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/Cline/"&gt;Cline&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/Bolt/"&gt;Bolt&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/RooCode/"&gt;RooCode&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/Lumo/"&gt;Lumo&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Open%20Source%20prompts/Gemini%20CLI/"&gt;Gemini CLI&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/CodeBuddy%20Prompts/"&gt;&lt;strong&gt;CodeBuddy&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Poke/"&gt;&lt;strong&gt;Poke&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Comet%20Assistant/"&gt;&lt;strong&gt;Comet Assistant&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/Anthropic/"&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/x1xhlol/system-prompts-and-models-of-ai-tools/main/AMp/"&gt;&lt;strong&gt;Amp&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🛠 Roadmap &amp;amp; Feedback&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Open an issue.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Latest Update:&lt;/strong&gt; 29/09/2025&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🔗 Connect With Me&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;X:&lt;/strong&gt; &lt;a href="https://x.com/NotLucknite"&gt;NotLucknite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: &lt;code&gt;x1xh&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;🛡️ Security Notice for AI Startups&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;⚠️ &lt;strong&gt;Warning:&lt;/strong&gt; If you're an AI startup, make sure your data is secure. Exposed prompts or AI models can easily become a target for hackers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🔐 &lt;strong&gt;Important:&lt;/strong&gt; Interested in securing your AI systems?&lt;br /&gt; Check out &lt;strong&gt;&lt;a href="https://zeroleaks.io/"&gt;ZeroLeaks&lt;/a&gt;&lt;/strong&gt;, a service designed to help startups &lt;strong&gt;identify and secure&lt;/strong&gt; leaks in system instructions, internal tools, and model configurations. &lt;strong&gt;Get a free AI security audit&lt;/strong&gt; to ensure your AI is protected from vulnerabilities.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;The company is mine, this is NOT a 3rd party AD.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;📊 Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#x1xhlol/system-prompts-and-models-of-ai-tools&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=x1xhlol/system-prompts-and-models-of-ai-tools&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=x1xhlol/system-prompts-and-models-of-ai-tools&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=x1xhlol/system-prompts-and-models-of-ai-tools&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;p&gt;⭐ &lt;strong&gt;Drop a star if you find this useful!&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>commaai/openpilot</title>
      <link>https://github.com/commaai/openpilot</link>
      <description>&lt;p&gt;openpilot is an operating system for robotics. Currently, it upgrades the driver assistance system on 300+ supported cars.&lt;/p&gt;&lt;hr&gt;&lt;div align="center" style="text-align: center;"&gt; 
 &lt;h1&gt;openpilot&lt;/h1&gt; 
 &lt;p&gt; &lt;b&gt;openpilot is an operating system for robotics.&lt;/b&gt; &lt;br /&gt; Currently, it upgrades the driver assistance system in 300+ supported cars. &lt;/p&gt; 
 &lt;h3&gt; &lt;a href="https://docs.comma.ai"&gt;Docs&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://docs.comma.ai/contributing/roadmap/"&gt;Roadmap&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://github.com/commaai/openpilot/raw/master/docs/CONTRIBUTING.md"&gt;Contribute&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://discord.comma.ai"&gt;Community&lt;/a&gt; &lt;span&gt; · &lt;/span&gt; &lt;a href="https://comma.ai/shop"&gt;Try it on a comma 3X&lt;/a&gt; &lt;/h3&gt; 
 &lt;p&gt;Quick start: &lt;code&gt;bash &amp;lt;(curl -fsSL openpilot.comma.ai)&lt;/code&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/commaai/openpilot/actions/workflows/selfdrive_tests.yaml"&gt;&lt;img src="https://github.com/commaai/openpilot/actions/workflows/selfdrive_tests.yaml/badge.svg?sanitize=true" alt="openpilot tests" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://x.com/comma_ai"&gt;&lt;img src="https://img.shields.io/twitter/follow/comma_ai" alt="X Follow" /&gt;&lt;/a&gt; &lt;a href="https://discord.comma.ai"&gt;&lt;img src="https://img.shields.io/discord/469524606043160576" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/NmBfgOanCyk" title="Video By Greer Viau"&gt;&lt;img src="https://github.com/commaai/openpilot/assets/8762862/2f7112ae-f748-4f39-b617-fabd689c3772" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/VHKyqZ7t8Gw" title="Video By Logan LeGrand"&gt;&lt;img src="https://github.com/commaai/openpilot/assets/8762862/92351544-2833-40d7-9e0b-7ef7ae37ec4c" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/SUIZYzxtMQs" title="A drive to Taco Bell"&gt;&lt;img src="https://github.com/commaai/openpilot/assets/8762862/05ceefc5-2628-439c-a9b2-89ce77dc6f63" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Using openpilot in a car&lt;/h2&gt; 
&lt;p&gt;To use openpilot in a car, you need four things:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Supported Device:&lt;/strong&gt; a comma 3X, available at &lt;a href="https://comma.ai/shop/comma-3x"&gt;comma.ai/shop&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Software:&lt;/strong&gt; The setup procedure for the comma 3X allows users to enter a URL for custom software. Use the URL &lt;code&gt;openpilot.comma.ai&lt;/code&gt; to install the release version.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Supported Car:&lt;/strong&gt; Ensure that you have one of &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/docs/CARS.md"&gt;the 275+ supported cars&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Car Harness:&lt;/strong&gt; You will also need a &lt;a href="https://comma.ai/shop/car-harness"&gt;car harness&lt;/a&gt; to connect your comma 3X to your car.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;We have detailed instructions for &lt;a href="https://comma.ai/setup"&gt;how to install the harness and device in a car&lt;/a&gt;. Note that it's possible to run openpilot on &lt;a href="https://blog.comma.ai/self-driving-car-for-free/"&gt;other hardware&lt;/a&gt;, although it's not plug-and-play.&lt;/p&gt; 
&lt;h3&gt;Branches&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;branch&lt;/th&gt; 
   &lt;th&gt;URL&lt;/th&gt; 
   &lt;th&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;release3&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;openpilot.comma.ai&lt;/td&gt; 
   &lt;td&gt;This is openpilot's release branch.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;release3-staging&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;openpilot-test.comma.ai&lt;/td&gt; 
   &lt;td&gt;This is the staging branch for releases. Use it to get new releases slightly early.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nightly&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;openpilot-nightly.comma.ai&lt;/td&gt; 
   &lt;td&gt;This is the bleeding edge development branch. Do not expect this to be stable.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;nightly-dev&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;installer.comma.ai/commaai/nightly-dev&lt;/td&gt; 
   &lt;td&gt;Same as nightly, but includes experimental development features for some cars.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;To start developing openpilot&lt;/h2&gt; 
&lt;p&gt;openpilot is developed by &lt;a href="https://comma.ai/"&gt;comma&lt;/a&gt; and by users like you. We welcome both pull requests and issues on &lt;a href="http://github.com/commaai/openpilot"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join the &lt;a href="https://discord.comma.ai"&gt;community Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check out &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/docs/CONTRIBUTING.md"&gt;the contributing docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/tools/"&gt;openpilot tools&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Code documentation lives at &lt;a href="https://docs.comma.ai"&gt;https://docs.comma.ai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Information about running openpilot lives on the &lt;a href="https://github.com/commaai/openpilot/wiki"&gt;community wiki&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Want to get paid to work on openpilot? &lt;a href="https://comma.ai/jobs#open-positions"&gt;comma is hiring&lt;/a&gt; and offers lots of &lt;a href="https://comma.ai/bounties"&gt;bounties&lt;/a&gt; for external contributors.&lt;/p&gt; 
&lt;h2&gt;Safety and Testing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;openpilot observes &lt;a href="https://en.wikipedia.org/wiki/ISO_26262"&gt;ISO26262&lt;/a&gt; guidelines, see &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/docs/SAFETY.md"&gt;SAFETY.md&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;li&gt;openpilot has software-in-the-loop &lt;a href="https://raw.githubusercontent.com/commaai/openpilot/master/.github/workflows/selfdrive_tests.yaml"&gt;tests&lt;/a&gt; that run on every commit.&lt;/li&gt; 
 &lt;li&gt;The code enforcing the safety model lives in panda and is written in C, see &lt;a href="https://github.com/commaai/panda#code-rigor"&gt;code rigor&lt;/a&gt; for more details.&lt;/li&gt; 
 &lt;li&gt;panda has software-in-the-loop &lt;a href="https://github.com/commaai/panda/tree/master/tests/safety"&gt;safety tests&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Internally, we have a hardware-in-the-loop Jenkins test suite that builds and unit tests the various processes.&lt;/li&gt; 
 &lt;li&gt;panda has additional hardware-in-the-loop &lt;a href="https://github.com/commaai/panda/raw/master/Jenkinsfile"&gt;tests&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;We run the latest openpilot in a testing closet containing 10 comma devices continuously replaying routes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;MIT Licensed&lt;/summary&gt; 
 &lt;p&gt;openpilot is released under the MIT license. Some parts of the software are released under other licenses as specified.&lt;/p&gt; 
 &lt;p&gt;Any user of this software shall indemnify and hold harmless Comma.ai, Inc. and its directors, officers, employees, agents, stockholders, affiliates, subcontractors and customers from and against all allegations, claims, actions, suits, demands, damages, liabilities, obligations, losses, settlements, judgments, costs and expenses (including without limitation attorneys’ fees and costs) which arise out of, relate to or result from any use of this software by user.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;THIS IS ALPHA QUALITY SOFTWARE FOR RESEARCH PURPOSES ONLY. THIS IS NOT A PRODUCT. YOU ARE RESPONSIBLE FOR COMPLYING WITH LOCAL LAWS AND REGULATIONS. NO WARRANTY EXPRESSED OR IMPLIED.&lt;/strong&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;User Data and comma Account&lt;/summary&gt; 
 &lt;p&gt;By default, openpilot uploads the driving data to our servers. You can also access your data through &lt;a href="https://connect.comma.ai/"&gt;comma connect&lt;/a&gt;. We use your data to train better models and improve openpilot for everyone.&lt;/p&gt; 
 &lt;p&gt;openpilot is open source software: the user is free to disable data collection if they wish to do so.&lt;/p&gt; 
 &lt;p&gt;openpilot logs the road-facing cameras, CAN, GPS, IMU, magnetometer, thermal sensors, crashes, and operating system logs. The driver-facing camera and microphone are only logged if you explicitly opt-in in settings.&lt;/p&gt; 
 &lt;p&gt;By using openpilot, you agree to &lt;a href="https://comma.ai/privacy"&gt;our Privacy Policy&lt;/a&gt;. You understand that use of this software or its related services will generate certain types of user data, which may be logged and stored at the sole discretion of comma. By accepting this agreement, you grant an irrevocable, perpetual, worldwide right to comma for the use of this data.&lt;/p&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>aquasecurity/trivy</title>
      <link>https://github.com/aquasecurity/trivy</link>
      <description>&lt;p&gt;Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/aquasecurity/trivy/main/docs/imgs/logo.png" width="200" /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/aquasecurity/trivy/releases"&gt;&lt;img src="https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/actions/workflows/test.yaml"&gt;&lt;img src="https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg?sanitize=true" alt="Test" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/aquasecurity/trivy"&gt;&lt;img src="https://goreportcard.com/badge/github.com/aquasecurity/trivy" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;a href="https://github.com/aquasecurity/trivy/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github" alt="GitHub Downloads" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;amp;label=docker%20pulls%20%2F%20trivy" alt="Docker Pulls" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trivy.dev/latest/docs/"&gt;📖 Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Trivy (&lt;a href="https://raw.githubusercontent.com/aquasecurity/trivy/main/#how-to-pronounce-the-name-trivy"&gt;pronunciation&lt;/a&gt;) is a comprehensive and versatile security scanner. Trivy has &lt;em&gt;scanners&lt;/em&gt; that look for security issues, and &lt;em&gt;targets&lt;/em&gt; where it can find those issues.&lt;/p&gt; 
&lt;p&gt;Targets (what Trivy can scan):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Container Image&lt;/li&gt; 
 &lt;li&gt;Filesystem&lt;/li&gt; 
 &lt;li&gt;Git Repository (remote)&lt;/li&gt; 
 &lt;li&gt;Virtual Machine Image&lt;/li&gt; 
 &lt;li&gt;Kubernetes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Scanners (what Trivy can find there):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;OS packages and software dependencies in use (SBOM)&lt;/li&gt; 
 &lt;li&gt;Known vulnerabilities (CVEs)&lt;/li&gt; 
 &lt;li&gt;IaC issues and misconfigurations&lt;/li&gt; 
 &lt;li&gt;Sensitive information and secrets&lt;/li&gt; 
 &lt;li&gt;Software licenses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the &lt;a href="https://trivy.dev/latest/docs/coverage/"&gt;Scanning Coverage&lt;/a&gt; page.&lt;/p&gt; 
&lt;p&gt;To learn more, go to the &lt;a href="https://trivy.dev"&gt;Trivy homepage&lt;/a&gt; for feature highlights, or to the &lt;a href="https://trivy.dev/latest/docs/"&gt;Documentation site&lt;/a&gt; for detailed information.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Get Trivy&lt;/h3&gt; 
&lt;p&gt;Trivy is available in most common distribution channels. The full list of installation options is available in the &lt;a href="https://trivy.dev/latest/getting-started/installation/"&gt;Installation&lt;/a&gt; page. Here are a few popular examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;brew install trivy&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;docker run aquasec/trivy&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Download binary from &lt;a href="https://github.com/aquasecurity/trivy/releases/latest/"&gt;https://github.com/aquasecurity/trivy/releases/latest/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://trivy.dev/latest/getting-started/installation/"&gt;Installation&lt;/a&gt; for more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the &lt;a href="https://trivy.dev/latest/ecosystem/"&gt;Ecosystem&lt;/a&gt; page. Here are a few popular examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-action"&gt;GitHub Actions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-operator"&gt;Kubernetes operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aquasecurity/trivy-vscode-extension"&gt;VS Code plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://trivy.dev/latest/ecosystem/"&gt;Ecosystem&lt;/a&gt; for more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Canary builds&lt;/h3&gt; 
&lt;p&gt;There are canary builds (&lt;a href="https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;amp;name=canary"&gt;Docker Hub&lt;/a&gt;, &lt;a href="https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary"&gt;GitHub&lt;/a&gt;, &lt;a href="https://gallery.ecr.aws/aquasecurity/trivy#canary"&gt;ECR&lt;/a&gt; images and &lt;a href="https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml"&gt;binaries&lt;/a&gt;) as generated every push to main branch.&lt;/p&gt; 
&lt;p&gt;Please be aware: canary builds might have critical bugs, it's not recommended for use in production.&lt;/p&gt; 
&lt;h3&gt;General usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy &amp;lt;target&amp;gt; [--scanners &amp;lt;scanner1,scanner2&amp;gt;] &amp;lt;subject&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Examples:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy image python:3.4-alpine
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov"&gt;https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy fs --scanners vuln,secret,misconfig myproject/
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov"&gt;https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;trivy k8s --report summary cluster
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;Result&lt;/summary&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/aquasecurity/trivy/main/docs/imgs/trivy-k8s.png" alt="k8s summary" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;How to pronounce the name "Trivy"?&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;tri&lt;/code&gt; is pronounced like &lt;strong&gt;tri&lt;/strong&gt;gger, &lt;code&gt;vy&lt;/code&gt; is pronounced like en&lt;strong&gt;vy&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Want more? Check out Aqua&lt;/h2&gt; 
&lt;p&gt;If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.&lt;br /&gt; You can find a high level comparison table specific to Trivy users &lt;a href="https://trivy.dev/latest/commercial/compare/"&gt;here&lt;/a&gt;. In addition check out the &lt;a href="https://aquasec.com"&gt;https://aquasec.com&lt;/a&gt; website for more information about our products and services. If you'd like to contact Aqua or request a demo, please use this form: &lt;a href="https://www.aquasec.com/demo"&gt;https://www.aquasec.com/demo&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Trivy is an &lt;a href="https://aquasec.com"&gt;Aqua Security&lt;/a&gt; open source project.&lt;br /&gt; Learn about our open source work and portfolio &lt;a href="https://www.aquasec.com/products/open-source-projects/"&gt;here&lt;/a&gt;.&lt;br /&gt; Contact us about any matter by opening a GitHub Discussion &lt;a href="https://github.com/aquasecurity/trivy/discussions"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Please ensure to abide by our &lt;a href="https://github.com/aquasecurity/community/raw/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; during all interactions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/ai-agents-for-beginners</title>
      <link>https://github.com/microsoft/ai-agents-for-beginners</link>
      <description>&lt;p&gt;12 Lessons to Get Started Building AI Agents&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Agents for Beginners - A Course&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/images/repo-thumbnailv2.png" alt="Generative AI For Beginners" /&gt;&lt;/p&gt; 
&lt;h2&gt;A course teaching everything you need to know to start building AI Agents&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/ai-agents-for-beginners/raw/master/LICENSE?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/license/microsoft/ai-agents-for-beginners.svg?sanitize=true" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/graphs/contributors/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/contributors/microsoft/ai-agents-for-beginners.svg?sanitize=true" alt="GitHub contributors" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/issues/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/issues/microsoft/ai-agents-for-beginners.svg?sanitize=true" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/pulls/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/issues-pr/microsoft/ai-agents-for-beginners.svg?sanitize=true" alt="GitHub pull-requests" /&gt;&lt;/a&gt; &lt;a href="http://makeapullrequest.com?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;🌐 Multi-Language Support&lt;/h3&gt; 
&lt;h4&gt;Supported via GitHub Action (Automated &amp;amp; Always Up-to-Date)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/fr/README.md"&gt;French&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/es/README.md"&gt;Spanish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/de/README.md"&gt;German&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ru/README.md"&gt;Russian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ar/README.md"&gt;Arabic&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/fa/README.md"&gt;Persian (Farsi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ur/README.md"&gt;Urdu&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/zh/README.md"&gt;Chinese (Simplified)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/mo/README.md"&gt;Chinese (Traditional, Macau)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hk/README.md"&gt;Chinese (Traditional, Hong Kong)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/tw/README.md"&gt;Chinese (Traditional, Taiwan)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ja/README.md"&gt;Japanese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ko/README.md"&gt;Korean&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hi/README.md"&gt;Hindi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/bn/README.md"&gt;Bengali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/mr/README.md"&gt;Marathi&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ne/README.md"&gt;Nepali&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/pa/README.md"&gt;Punjabi (Gurmukhi)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/pt/README.md"&gt;Portuguese (Portugal)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/br/README.md"&gt;Portuguese (Brazil)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/it/README.md"&gt;Italian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/pl/README.md"&gt;Polish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/tr/README.md"&gt;Turkish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/el/README.md"&gt;Greek&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/th/README.md"&gt;Thai&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sv/README.md"&gt;Swedish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/da/README.md"&gt;Danish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/no/README.md"&gt;Norwegian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/fi/README.md"&gt;Finnish&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/nl/README.md"&gt;Dutch&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/he/README.md"&gt;Hebrew&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/vi/README.md"&gt;Vietnamese&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/id/README.md"&gt;Indonesian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ms/README.md"&gt;Malay&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/tl/README.md"&gt;Tagalog (Filipino)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sw/README.md"&gt;Swahili&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hu/README.md"&gt;Hungarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/cs/README.md"&gt;Czech&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sk/README.md"&gt;Slovak&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/ro/README.md"&gt;Romanian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/bg/README.md"&gt;Bulgarian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sr/README.md"&gt;Serbian (Cyrillic)&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/hr/README.md"&gt;Croatian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/sl/README.md"&gt;Slovenian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/uk/README.md"&gt;Ukrainian&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/translations/my/README.md"&gt;Burmese (Myanmar)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;If you wish to have additional translations languages supported are listed &lt;a href="https://github.com/Azure/co-op-translator/raw/main/getting_started/supported-languages.md"&gt;here&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/watchers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/watchers/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Watch" alt="GitHub watchers" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/network/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/forks/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Fork" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/microsoft/ai-agents-for-beginners/stargazers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/ai-agents-for-beginners.svg?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/kzRShWzttr"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/kzRShWzttr" alt="Azure AI Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;🌱 Getting Started&lt;/h2&gt; 
&lt;p&gt;This course has lessons covering the fundamentals of building AI Agents. Each lesson covers its own topic so start wherever you like!&lt;/p&gt; 
&lt;p&gt;There is multi-language support for this course. Go to our &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/#-multi-language-support"&gt;available languages here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If this is your first time building with Generative AI models, check out our &lt;a href="https://aka.ms/genai-beginners"&gt;Generative AI For Beginners&lt;/a&gt; course, which includes 21 lessons on building with GenAI.&lt;/p&gt; 
&lt;p&gt;Don't forget to &lt;a href="https://docs.github.com/en/get-started/exploring-projects-on-github/saving-repositories-with-stars?WT.mc_id=academic-105485-koreyst"&gt;star (🌟) this repo&lt;/a&gt; and &lt;a href="https://github.com/microsoft/ai-agents-for-beginners/fork"&gt;fork this repo&lt;/a&gt; to run the code.&lt;/p&gt; 
&lt;h3&gt;Meet Other Learners, Get Your Questions Answered&lt;/h3&gt; 
&lt;p&gt;If you get stuck or have any questions about building AI Agents, join our dedicated Discord Channel in the &lt;a href="https://aka.ms/ai-agents/discord"&gt;Azure AI Foundry Community Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;What You Need&lt;/h3&gt; 
&lt;p&gt;Each lesson in this course includes code examples, which can be found in the code_samples folder. You can &lt;a href="https://github.com/microsoft/ai-agents-for-beginners/fork"&gt;fork this repo&lt;/a&gt; to create your own copy.&lt;/p&gt; 
&lt;p&gt;The code example in these exercises, utilize Azure AI Foundry and GitHub Model Catalogs for interacting with Language Models:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-agents-beginners/github-models"&gt;Github Models&lt;/a&gt; - Free / Limited&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-agents-beginners/ai-foundry"&gt;Azure AI Foundry&lt;/a&gt; - Azure Account Required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This course also uses the following AI Agent frameworks and services from Microsoft:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-agents-beginners/agent-framewrok"&gt;Microsoft Agent Framework (MAF) - New!&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-agents-beginners/ai-agent-service"&gt;Azure AI Agent Service&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-agents-beginners/semantic-kernel"&gt;Semantic Kernel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-agents/autogen"&gt;AutoGen&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more information on running the code for this course, go to the &lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/00-course-setup/README.md"&gt;Course Setup&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🙏 Want to help?&lt;/h2&gt; 
&lt;p&gt;Do you have suggestions or found spelling or code errors? &lt;a href="https://github.com/microsoft/ai-agents-for-beginners/issues?WT.mc_id=academic-105485-koreyst"&gt;Raise an issue&lt;/a&gt; or &lt;a href="https://github.com/microsoft/ai-agents-for-beginners/pulls?WT.mc_id=academic-105485-koreyst"&gt;Create a pull request&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📂 Each lesson includes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A written lesson located in the README and a short video&lt;/li&gt; 
 &lt;li&gt;Python code samples supporting Azure AI Foundry and Github Models (Free)&lt;/li&gt; 
 &lt;li&gt;Links to extra resources to continue your learning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🗃️ Lessons&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;strong&gt;Lesson&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Text &amp;amp; Code&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Video&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;strong&gt;Extra Learning&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Intro to AI Agents and Agent Use Cases&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/01-intro-to-ai-agents/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/3zgm60bXmQk?si=z8QygFvYQv-9WtO1"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Exploring AI Agentic Frameworks&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/02-explore-agentic-frameworks/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/ODwF-EZo_O8?si=Vawth4hzVaHv-u0H"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Understanding AI Agentic Design Patterns&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/03-agentic-design-patterns/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/m9lM8qqoOEA?si=BIzHwzstTPL8o9GF"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tool Use Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/04-tool-use/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/vieRiPRx-gI?si=2z6O2Xu2cu_Jz46N"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agentic RAG&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/05-agentic-rag/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/WcjAARvdL7I?si=gKPWsQpKiIlDH9A3"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Building Trustworthy AI Agents&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/06-building-trustworthy-agents/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/iZKkMEGBCUQ?si=jZjpiMnGFOE9L8OK"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Planning Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/07-planning-design/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/kPfJ2BrBCMY?si=6SC_iv_E5-mzucnC"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Multi-Agent Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/08-multi-agent/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/V6HpE9hZEx0?si=rMgDhEu7wXo2uo6g"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Metacognition Design Pattern&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/09-metacognition/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/His9R6gw6Ec?si=8gck6vvdSNCt6OcF"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AI Agents in Production&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/10-ai-agents-production/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/l4TP6IyJxmQ?si=31dnhexRo6yLRJDl"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Using Agentic Protocols (MCP, A2A and NLWeb)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/11-agentic-protocols/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/X-Dh9R3Opn8"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Context Engineering for AI Agents&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/12-context-engineering/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/F5zqRV7gEag"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/ai-agents-beginners/collection?WT.mc_id=academic-105485-koreyst"&gt;Link&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Managing Agentic Memory&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/13-agent-memory/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/QrYbHesIxpw?si=vZkVwKrQ4ieCcIPx"&gt;Video&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Exploring Microsoft Agent Framework&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/ai-agents-for-beginners/main/14-microsoft-agent-framework/README.md"&gt;Link&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Building Computer Use Agents (CUA)&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deploying Scalable Agents&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Creating Local AI Agents&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Securing AI Agents&lt;/td&gt; 
   &lt;td&gt;Coming Soon&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🎒 Other Courses&lt;/h2&gt; 
&lt;p&gt;Our team produces other courses! Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/edgeai-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;&lt;strong&gt;NEW&lt;/strong&gt; Edge AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mcp-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;Model Context Protocol (MCP) For Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Generative-AI-for-beginners-dotnet?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using .NET&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/generative-ai-for-beginners-java?WT.mc_id=academic-105485-koreyst"&gt;Generative AI for Beginners using Java&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ml-beginners?WT.mc_id=academic-105485-koreyst"&gt;ML for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/datascience-beginners?WT.mc_id=academic-105485-koreyst"&gt;Data Science for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/ai-beginners?WT.mc_id=academic-105485-koreyst"&gt;AI for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/Security-101??WT.mc_id=academic-96948-sayoung"&gt;Cybersecurity for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/webdev-beginners?WT.mc_id=academic-105485-koreyst"&gt;Web Dev for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/iot-beginners?WT.mc_id=academic-105485-koreyst"&gt;IoT for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/xr-development-for-beginners?WT.mc_id=academic-105485-koreyst"&gt;XR Development for Beginners&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/GitHubCopilotAI?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for AI Paired Programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/mastering-github-copilot-for-dotnet-csharp-developers?WT.mc_id=academic-105485-koreyst"&gt;Mastering GitHub Copilot for C#/.NET Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/CopilotAdventures?WT.mc_id=academic-105485-koreyst"&gt;Choose Your Own Copilot Adventure&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🌟 Community Thanks&lt;/h2&gt; 
&lt;p&gt;Thanks to &lt;a href="https://www.linkedin.com/in/shivam2003/"&gt;Shivam Goyal&lt;/a&gt; for contributing important code samples demonstrating Agentic RAG.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos is subject to those third-parties' policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lukas-blecher/LaTeX-OCR</title>
      <link>https://github.com/lukas-blecher/LaTeX-OCR</link>
      <description>&lt;p&gt;pix2tex: Using a ViT to convert images of equations into LaTeX code.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;pix2tex - LaTeX OCR&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/lukas-blecher/LaTeX-OCR"&gt;&lt;img src="https://img.shields.io/github/license/lukas-blecher/LaTeX-OCR" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://pix2tex.readthedocs.io/en/latest/?badge=latest"&gt;&lt;img src="https://readthedocs.org/projects/pix2tex/badge/?version=latest" alt="Documentation Status" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pix2tex"&gt;&lt;img src="https://img.shields.io/pypi/v/pix2tex?logo=pypi" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/pix2tex"&gt;&lt;img src="https://img.shields.io/pypi/dm/pix2tex?logo=pypi" alt="PyPI - Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lukas-blecher/LaTeX-OCR/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/lukas-blecher/LaTeX-OCR/total?color=blue&amp;amp;logo=github" alt="GitHub all releases" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/lukasblecher/pix2tex"&gt;&lt;img src="https://img.shields.io/docker/pulls/lukasblecher/pix2tex?logo=docker" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/lukas-blecher/LaTeX-OCR/blob/main/notebooks/LaTeX_OCR_test.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/lukbl/LaTeX-OCR"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" alt="Hugging Face Spaces" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The goal of this project is to create a learning based system that takes an image of a math formula and returns corresponding LaTeX code.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/55287601/109183599-69431f00-778e-11eb-9809-d42b9451e018.png" alt="header" /&gt;&lt;/p&gt; 
&lt;h2&gt;Using the model&lt;/h2&gt; 
&lt;p&gt;To run the model you need Python 3.7+&lt;/p&gt; 
&lt;p&gt;If you don't have PyTorch installed. Follow their instructions &lt;a href="https://pytorch.org/get-started/locally/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Install the package &lt;code&gt;pix2tex&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install "pix2tex[gui]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Model checkpoints will be downloaded automatically.&lt;/p&gt; 
&lt;p&gt;There are three ways to get a prediction from an image.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;You can use the command line tool by calling &lt;code&gt;pix2tex&lt;/code&gt;. Here you can parse already existing images from the disk and images in your clipboard.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Thanks to &lt;a href="https://github.com/katie-lim"&gt;@katie-lim&lt;/a&gt;, you can use a nice user interface as a quick way to get the model prediction. Just call the GUI with &lt;code&gt;latexocr&lt;/code&gt;. From here you can take a screenshot and the predicted latex code is rendered using &lt;a href="https://www.mathjax.org/"&gt;MathJax&lt;/a&gt; and copied to your clipboard.&lt;/p&gt; &lt;p&gt;Under linux, it is possible to use the GUI with &lt;code&gt;gnome-screenshot&lt;/code&gt; (which comes with multiple monitor support). For other Wayland compositers, &lt;code&gt;grim&lt;/code&gt; and &lt;code&gt;slurp&lt;/code&gt; will be used for wlroots-based Wayland compositers and &lt;code&gt;spectacle&lt;/code&gt; for KDE Plasma. Note that &lt;code&gt;gnome-screenshot&lt;/code&gt; is not compatible with wlroots or Qt based compositers. Since &lt;code&gt;gnome-screenshot&lt;/code&gt; will be preferred when available, you may have to set the environment variable &lt;code&gt;SCREENSHOT_TOOL&lt;/code&gt; to &lt;code&gt;grim&lt;/code&gt; or &lt;code&gt;spectacle&lt;/code&gt; in these cases (other available values are &lt;code&gt;gnome-screenshot&lt;/code&gt; and &lt;code&gt;pil&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/55287601/117812740-77b7b780-b262-11eb-81f6-fc19766ae2ae.gif" alt="demo" /&gt;&lt;/p&gt; &lt;p&gt;If the model is unsure about the what's in the image it might output a different prediction every time you click "Retry". With the &lt;code&gt;temperature&lt;/code&gt; parameter you can control this behavior (low temperature will produce the same result).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can use an API. This has additional dependencies. Install via &lt;code&gt;pip install -U "pix2tex[api]"&lt;/code&gt; and run&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python -m pix2tex.api.run
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;to start a &lt;a href="https://streamlit.io/"&gt;Streamlit&lt;/a&gt; demo that connects to the API at port 8502. There is also a docker image available for the API: &lt;a href="https://hub.docker.com/r/lukasblecher/pix2tex"&gt;https://hub.docker.com/r/lukasblecher/pix2tex&lt;/a&gt; &lt;a href="https://hub.docker.com/r/lukasblecher/pix2tex"&gt;&lt;img src="https://img.shields.io/docker/image-size/lukasblecher/pix2tex?logo=docker" alt="Docker Image Size (latest by date)" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docker pull lukasblecher/pix2tex:api
docker run --rm -p 8502:8502 lukasblecher/pix2tex:api
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To also run the streamlit demo run&lt;/p&gt; &lt;pre&gt;&lt;code&gt;docker run --rm -it -p 8501:8501 --entrypoint python lukasblecher/pix2tex:api pix2tex/api/run.py
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;and navigate to &lt;a href="http://localhost:8501/"&gt;http://localhost:8501/&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Use from within Python&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;from PIL import Image
from pix2tex.cli import LatexOCR

img = Image.open('path/to/image.png')
model = LatexOCR()
print(model(img))
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The model works best with images of smaller resolution. That's why I added a preprocessing step where another neural network predicts the optimal resolution of the input image. This model will automatically resize the custom image to best resemble the training data and thus increase performance of images found in the wild. Still it's not perfect and might not be able to handle huge images optimally, so don't zoom in all the way before taking a picture.&lt;/p&gt; 
&lt;p&gt;Always double check the result carefully. You can try to redo the prediction with an other resolution if the answer was wrong.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Want to use the package?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;I'm trying to compile a documentation right now.&lt;/p&gt; 
&lt;p&gt;Visit here: &lt;a href="https://pix2tex.readthedocs.io/"&gt;https://pix2tex.readthedocs.io/&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Training the model &lt;a href="https://colab.research.google.com/github/lukas-blecher/LaTeX-OCR/blob/main/notebooks/LaTeX_OCR_training.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Install a couple of dependencies &lt;code&gt;pip install "pix2tex[train]"&lt;/code&gt;.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;First we need to combine the images with their ground truth labels. I wrote a dataset class (which needs further improving) that saves the relative paths to the images with the LaTeX code they were rendered with. To generate the dataset pickle file run&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;python -m pix2tex.dataset.dataset --equations path_to_textfile --images path_to_images --out dataset.pkl
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use your own tokenizer pass it via &lt;code&gt;--tokenizer&lt;/code&gt; (See below).&lt;/p&gt; 
&lt;p&gt;You can find my generated training data on the &lt;a href="https://drive.google.com/drive/folders/13CA4vAmOmD_I_dSbvLp-Lf0s6KiaNfuO"&gt;Google Drive&lt;/a&gt; as well (formulae.zip - images, math.txt - labels). Repeat the step for the validation and test data. All use the same label text file.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Edit the &lt;code&gt;data&lt;/code&gt; (and &lt;code&gt;valdata&lt;/code&gt;) entry in the config file to the newly generated &lt;code&gt;.pkl&lt;/code&gt; file. Change other hyperparameters if you want to. See &lt;code&gt;pix2tex/model/settings/config.yaml&lt;/code&gt; for a template.&lt;/li&gt; 
 &lt;li&gt;Now for the actual training run&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;python -m pix2tex.train --config path_to_config_file
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to use your own data you might be interested in creating your own tokenizer with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m pix2tex.dataset.dataset --equations path_to_textfile --vocab-size 8000 --out tokenizer.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Don't forget to update the path to the tokenizer in the config file and set &lt;code&gt;num_tokens&lt;/code&gt; to your vocabulary size.&lt;/p&gt; 
&lt;h2&gt;Model&lt;/h2&gt; 
&lt;p&gt;The model consist of a ViT [&lt;a href="https://raw.githubusercontent.com/lukas-blecher/LaTeX-OCR/main/#References"&gt;1&lt;/a&gt;] encoder with a ResNet backbone and a Transformer [&lt;a href="https://raw.githubusercontent.com/lukas-blecher/LaTeX-OCR/main/#References"&gt;2&lt;/a&gt;] decoder.&lt;/p&gt; 
&lt;h3&gt;Performance&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;BLEU score&lt;/th&gt; 
   &lt;th&gt;normed edit distance&lt;/th&gt; 
   &lt;th&gt;token accuracy&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;0.88&lt;/td&gt; 
   &lt;td&gt;0.10&lt;/td&gt; 
   &lt;td&gt;0.60&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Data&lt;/h2&gt; 
&lt;p&gt;We need paired data for the network to learn. Luckily there is a lot of LaTeX code on the internet, e.g. &lt;a href="https://www.wikipedia.org"&gt;wikipedia&lt;/a&gt;, &lt;a href="https://www.arxiv.org"&gt;arXiv&lt;/a&gt;. We also use the formulae from the &lt;a href="https://zenodo.org/record/56198#.V2px0jXT6eA"&gt;im2latex-100k&lt;/a&gt; [&lt;a href="https://raw.githubusercontent.com/lukas-blecher/LaTeX-OCR/main/#References"&gt;3&lt;/a&gt;] dataset. All of it can be found &lt;a href="https://drive.google.com/drive/folders/13CA4vAmOmD_I_dSbvLp-Lf0s6KiaNfuO"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Dataset Requirements&lt;/h3&gt; 
&lt;p&gt;In order to render the math in many different fonts we use XeLaTeX, generate a PDF and finally convert it to a PNG. For the last step we need to use some third party tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.ctan.org/pkg/xetex"&gt;XeLaTeX&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://imagemagick.org/"&gt;ImageMagick&lt;/a&gt; with &lt;a href="https://www.ghostscript.com/index.html"&gt;Ghostscript&lt;/a&gt;. (for converting pdf to png)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; to run &lt;a href="https://github.com/KaTeX/KaTeX"&gt;KaTeX&lt;/a&gt; (for normalizing Latex code)&lt;/li&gt; 
 &lt;li&gt;Python 3.7+ &amp;amp; dependencies (specified in &lt;code&gt;setup.py&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Fonts&lt;/h3&gt; 
&lt;p&gt;Latin Modern Math, GFSNeohellenicMath.otf, Asana Math, XITS Math, Cambria Math&lt;/p&gt; 
&lt;h2&gt;TODO&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; add more evaluation metrics&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; create a GUI&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; add beam search&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; support handwritten formulae (kinda done, see training colab notebook)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; reduce model size (distillation)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; find optimal hyperparameters&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; tweak model structure&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; fix data scraping and scrape more data&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; trace the model (&lt;a href="https://github.com/lukas-blecher/LaTeX-OCR/issues/2"&gt;#2&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Contributions of any kind are welcome.&lt;/p&gt; 
&lt;h2&gt;Acknowledgment&lt;/h2&gt; 
&lt;p&gt;Code taken and modified from &lt;a href="https://github.com/lucidrains"&gt;lucidrains&lt;/a&gt;, &lt;a href="https://github.com/rwightman/pytorch-image-models"&gt;rwightman&lt;/a&gt;, &lt;a href="https://github.com/harvardnlp/im2markup"&gt;im2markup&lt;/a&gt;, &lt;a href="https://github.com/soskek/arxiv_leaks"&gt;arxiv_leaks&lt;/a&gt;, &lt;a href="https://github.com/pkra/MathJax-single-file"&gt;pkra: Mathjax&lt;/a&gt;, &lt;a href="https://github.com/harupy/snipping-tool"&gt;harupy: snipping tool&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;References&lt;/h2&gt; 
&lt;p&gt;[1] &lt;a href="https://arxiv.org/abs/2010.11929"&gt;An Image is Worth 16x16 Words&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[2] &lt;a href="https://arxiv.org/abs/1706.03762"&gt;Attention Is All You Need&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;[3] &lt;a href="https://arxiv.org/abs/1609.04938v2"&gt;Image-to-Markup Generation with Coarse-to-Fine Attention&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SDWebImage/SDWebImage</title>
      <link>https://github.com/SDWebImage/SDWebImage</link>
      <description>&lt;p&gt;Asynchronous image downloader with cache support as a UIImageView category&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SDWebImage/SDWebImage/master/SDWebImage_logo.png" title="SDWebImage logo" float="left" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/SDWebImage/SDWebImage/actions/workflows/CI.yml"&gt;&lt;img src="https://github.com/SDWebImage/SDWebImage/actions/workflows/CI.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="http://cocoadocs.org/docsets/SDWebImage/"&gt;&lt;img src="http://img.shields.io/cocoapods/v/SDWebImage.svg?style=flat" alt="Pod Version" /&gt;&lt;/a&gt; &lt;a href="http://cocoadocs.org/docsets/SDWebImage/"&gt;&lt;img src="http://img.shields.io/cocoapods/p/SDWebImage.svg?style=flat" alt="Pod Platform" /&gt;&lt;/a&gt; &lt;a href="https://www.apache.org/licenses/LICENSE-2.0.html"&gt;&lt;img src="http://img.shields.io/cocoapods/l/SDWebImage.svg?style=flat" alt="Pod License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/SDWebImage/SDWebImage"&gt;&lt;img src="https://img.shields.io/badge/Carthage-compatible-brightgreen.svg?sanitize=true" alt="Carthage compatible" /&gt;&lt;/a&gt; &lt;a href="https://swift.org/package-manager/"&gt;&lt;img src="https://img.shields.io/badge/SwiftPM-compatible-brightgreen.svg?sanitize=true" alt="SwiftPM compatible" /&gt;&lt;/a&gt; &lt;a href="https://developer.apple.com/documentation/xcode/creating_a_mac_version_of_your_ipad_app/"&gt;&lt;img src="https://img.shields.io/badge/Catalyst-compatible-brightgreen.svg?sanitize=true" alt="Mac Catalyst compatible" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/SDWebImage/SDWebImage"&gt;&lt;img src="https://codecov.io/gh/SDWebImage/SDWebImage/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This library provides an async image downloader with cache support. For convenience, we added categories for UI elements like &lt;code&gt;UIImageView&lt;/code&gt;, &lt;code&gt;UIButton&lt;/code&gt;, &lt;code&gt;MKAnnotationView&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💡NOTE: &lt;code&gt;SD&lt;/code&gt; is the prefix for &lt;strong&gt;Simple Design&lt;/strong&gt; (which is the team name in Daily Motion company from the author Olivier Poitrey)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Categories for &lt;code&gt;UIImageView&lt;/code&gt;, &lt;code&gt;UIButton&lt;/code&gt;, &lt;code&gt;MKAnnotationView&lt;/code&gt; adding web image and cache management&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; An asynchronous image downloader&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; An asynchronous memory + disk image caching with automatic cache expiration handling&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; A background image decompression to avoid frame rate drop&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#progressive-animation"&gt;Progressive image loading&lt;/a&gt; (including animated image, like GIF showing in Web browser)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#thumbnail-decoding-550"&gt;Thumbnail image decoding&lt;/a&gt; to save CPU &amp;amp;&amp;amp; Memory for large images&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#custom-coder-420"&gt;Extendable image coder&lt;/a&gt; to support massive image format, like WebP&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#animated-image-50"&gt;Full-stack solution for animated images&lt;/a&gt; which keep a balance between CPU &amp;amp;&amp;amp; Memory&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#transformer-50"&gt;Customizable and composable transformations&lt;/a&gt; can be applied to the images right after download&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#custom-cache-50"&gt;Customizable and multiple caches system&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#custom-loader-50"&gt;Customizable and multiple loaders system&lt;/a&gt; to expand the capabilities, like &lt;a href="https://github.com/SDWebImage/SDWebImagePhotosPlugin"&gt;Photos Library&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/How-to-use#use-view-indicator-50"&gt;Image loading indicators&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#image-transition-430"&gt;Image loading transition animation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; A guarantee that the same URL won't be downloaded several times&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; A guarantee that bogus URLs won't be retried again and again&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; A guarantee that main thread will never be blocked&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Modern Objective-C and better Swift support&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Performances!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;For Apple visionOS&lt;/h2&gt; 
&lt;p&gt;From 5.19+, SDWebImage supports visionOS on all Package Managers (include CocoaPods/Carthage/SPM). Upgrade the related tools if you're facing issues.&lt;/p&gt; 
&lt;p&gt;For 5.18+, SDWebImage can be compiled for visionOS platform. However, it's still in beta and may contains issues unlike the stable iOS UIKit support. Welcome to have a try and &lt;a href="https://github.com/SDWebImage/SDWebImage/issues"&gt;report issue&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To build on visionOS, currently we only support the standard Xcode integration.&lt;/p&gt; 
&lt;p&gt;See &lt;code&gt;Installation with Swift Package Manager&lt;/code&gt; and &lt;code&gt;Manual Installation Guide&lt;/code&gt; below.&lt;/p&gt; 
&lt;h2&gt;Supported Image Formats&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Image formats supported by Apple system (JPEG, PNG, TIFF, BMP, ...), including &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#gif-coder"&gt;GIF&lt;/a&gt;/&lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#apng-coder"&gt;APNG&lt;/a&gt; animated image&lt;/li&gt; 
 &lt;li&gt;HEIC format from iOS 11/macOS 10.13, including animated HEIC from iOS 13/macOS 10.15 via &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#heic-coder"&gt;SDWebImageHEICCoder&lt;/a&gt;. For lower firmware, use coder plugin &lt;a href="https://github.com/SDWebImage/SDWebImageHEIFCoder"&gt;SDWebImageHEIFCoder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;WebP format from iOS 14/macOS 11.0 via &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#awebp-coder"&gt;SDWebImageAWebPCoder&lt;/a&gt;. For lower firmware, use coder plugin &lt;a href="https://github.com/SDWebImage/SDWebImageWebPCoder"&gt;SDWebImageWebPCoder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;JPEG-XL format from iOS 17/macOS 14.0 built-in. For lower firmware, use coder plugin &lt;a href="https://github.com/SDWebImage/SDWebImageJPEGXLCoder"&gt;SDWebImageJPEGXLCoder&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Support extendable coder plugins for new image formats like BPG, AVIF. And vector format like PDF, SVG. See all the list in &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Coder-Plugin-List"&gt;Image coder plugin List&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💡NOTE: For new user&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;SDWebImage use &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Coder-Plugin-List"&gt;Coder Plugin System&lt;/a&gt; to support both Apple's built-in and external image format. For static image we always use Apple's built-in as fallback, but not for animated image. Currently (updated to 5.19.x version) we only register traditional animated format like GIF/APNG by default, without the modern format like AWebP/HEICS/AVIF, even on the latest firmware.&lt;/p&gt; 
&lt;p&gt;If you want these animated image format support, simply register by yourself with one-line code, see more in &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#awebp-coder"&gt;WebP Coder&lt;/a&gt; and &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#heic-coder"&gt;HEIC Coder&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;In future we will change this behavior by always registering all Apple's built-in animated image format, to make it easy for new user to integrate.&lt;/p&gt; 
&lt;h2&gt;Additional modules and Ecosystem&lt;/h2&gt; 
&lt;p&gt;In order to keep SDWebImage focused and limited to the core features, but also allow extensibility and custom behaviors, during the 5.0 refactoring we focused on modularizing the library. As such, we have moved/built new modules to &lt;a href="https://github.com/SDWebImage"&gt;SDWebImage org&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;SwiftUI&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://developer.apple.com/xcode/swiftui/"&gt;SwiftUI&lt;/a&gt; is an innovative UI framework written in Swift to build user interfaces across all Apple platforms.&lt;/p&gt; 
&lt;p&gt;We support SwiftUI by building a brand new framework called &lt;a href="https://github.com/SDWebImage/SDWebImageSwiftUI"&gt;SDWebImageSwiftUI&lt;/a&gt;, which is built on top of SDWebImage core functions (caching, loading and animation).&lt;/p&gt; 
&lt;p&gt;The new framework introduce two View structs &lt;code&gt;WebImage&lt;/code&gt; and &lt;code&gt;AnimatedImage&lt;/code&gt; for SwiftUI world, &lt;code&gt;ImageIndicator&lt;/code&gt; modifier for any View, &lt;code&gt;ImageManager&lt;/code&gt; observable object for data source. Supports iOS 13+/macOS 10.15+/tvOS 13+/watchOS 6+ and Swift 5.1. Have a nice try and provide feedback!&lt;/p&gt; 
&lt;h4&gt;Coders for additional image formats&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageWebPCoder"&gt;SDWebImageWebPCoder&lt;/a&gt; - coder for WebP format. iOS 9+/macOS 10.11+. Based on &lt;a href="https://chromium.googlesource.com/webm/libwebp"&gt;libwebp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageHEIFCoder"&gt;SDWebImageHEIFCoder&lt;/a&gt; - coder for HEIF format, iOS 9+/macOS 10.11+ support. Based on &lt;a href="https://github.com/strukturag/libheif"&gt;libheif&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageBPGCoder"&gt;SDWebImageBPGCoder&lt;/a&gt; - coder for BPG format. Based on &lt;a href="https://github.com/mirrorer/libbpg"&gt;libbpg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageFLIFCoder"&gt;SDWebImageFLIFCoder&lt;/a&gt; - coder for FLIF format. Based on &lt;a href="https://github.com/FLIF-hub/FLIF"&gt;libflif&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageAVIFCoder"&gt;SDWebImageAVIFCoder&lt;/a&gt; - coder for AVIF (AV1-based) format. Based on &lt;a href="https://github.com/AOMediaCodec/libavif"&gt;libavif&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImagePDFCoder"&gt;SDWebImagePDFCoder&lt;/a&gt; - coder for PDF vector format. Using built-in frameworks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageSVGCoder"&gt;SDWebImageSVGCoder&lt;/a&gt; - coder for SVG vector format. Using built-in frameworks&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageSVGNativeCoder"&gt;SDWebImageSVGNativeCoder&lt;/a&gt; - coder for SVG-Native vector format. Based on &lt;a href="https://github.com/adobe/svg-native-viewer"&gt;svg-native&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageLottieCoder"&gt;SDWebImageLottieCoder&lt;/a&gt; - coder for Lottie animation format. Based on &lt;a href="https://github.com/Samsung/rlottie"&gt;rlottie&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageJPEGXLCoder"&gt;SDWebImageJPEGXLCoder&lt;/a&gt; - coder for JPEG-XL format. iOS 9+/macOS 10.11+. Based on &lt;a href="https://github.com/libjxl/libjxl"&gt;libjxl&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;and more from community!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Custom Caches&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageYYPlugin"&gt;SDWebImageYYPlugin&lt;/a&gt; - plugin to support caching images with &lt;a href="https://github.com/ibireme/YYCache"&gt;YYCache&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImagePINPlugin"&gt;SDWebImagePINPlugin&lt;/a&gt; - plugin to support caching images with &lt;a href="https://github.com/pinterest/PINCache"&gt;PINCache&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Custom Loaders&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImagePhotosPlugin"&gt;SDWebImagePhotosPlugin&lt;/a&gt; - plugin to support loading images from Photos (using &lt;code&gt;Photos.framework&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageLinkPlugin"&gt;SDWebImageLinkPlugin&lt;/a&gt; - plugin to support loading images from rich link url, as well as &lt;code&gt;LPLinkView&lt;/code&gt; (using &lt;code&gt;LinkPresentation.framework&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Integration with 3rd party libraries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageLottiePlugin"&gt;SDWebImageLottiePlugin&lt;/a&gt; - plugin to support &lt;a href="https://github.com/airbnb/lottie-ios"&gt;Lottie-iOS&lt;/a&gt;, vector animation rending with remote JSON files&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageSVGKitPlugin"&gt;SDWebImageSVGKitPlugin&lt;/a&gt; - plugin to support &lt;a href="https://github.com/SVGKit/SVGKit"&gt;SVGKit&lt;/a&gt;, SVG rendering using Core Animation, iOS 9+/macOS 10.11+ support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageFLPlugin"&gt;SDWebImageFLPlugin&lt;/a&gt; - plugin to support &lt;a href="https://github.com/Flipboard/FLAnimatedImage"&gt;FLAnimatedImage&lt;/a&gt; as the engine for animated GIFs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/SDWebImageYYPlugin"&gt;SDWebImageYYPlugin&lt;/a&gt; - plugin to integrate &lt;a href="https://github.com/ibireme/YYImage"&gt;YYImage&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/ibireme/YYCache"&gt;YYCache&lt;/a&gt; for image rendering &amp;amp; caching&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Community driven popular libraries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/firebase/FirebaseUI-iOS"&gt;FirebaseUI&lt;/a&gt; - Firebase Storage binding for query images, based on SDWebImage loader system&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DylanVann/react-native-fast-image"&gt;react-native-fast-image&lt;/a&gt; - React Native fast image component, based on SDWebImage Animated Image solution&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenFlutter/flutter_image_compress"&gt;flutter_image_compress&lt;/a&gt; - Flutter compresses image plugin, based on SDWebImage WebP coder plugin&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Make our lives easier&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/libwebp-Xcode"&gt;libwebp-Xcode&lt;/a&gt; - A wrapper for &lt;a href="https://chromium.googlesource.com/webm/libwebp"&gt;libwebp&lt;/a&gt; + an Xcode project.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/libheif-Xcode"&gt;libheif-Xcode&lt;/a&gt; - A wrapper for &lt;a href="https://github.com/strukturag/libheif"&gt;libheif&lt;/a&gt; + an Xcode project.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/SDWebImage/libavif-Xcode"&gt;libavif-Xcode&lt;/a&gt; - A wrapper for &lt;a href="https://github.com/AOMediaCodec/libavif"&gt;libavif&lt;/a&gt; + an Xcode project.&lt;/li&gt; 
 &lt;li&gt;and more third-party C/C++ image codec libraries with CocoaPods/Carthage/SwiftPM support.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can use those directly, or create similar components of your own, by using the customizable architecture of SDWebImage.&lt;/p&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;iOS 9.0 or later&lt;/li&gt; 
 &lt;li&gt;tvOS 9.0 or later&lt;/li&gt; 
 &lt;li&gt;watchOS 2.0 or later&lt;/li&gt; 
 &lt;li&gt;macOS 10.11 or later (10.15 for Catalyst)&lt;/li&gt; 
 &lt;li&gt;visionOS 1.0 or later&lt;/li&gt; 
 &lt;li&gt;Xcode 15.0 or later&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Backwards compatibility&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;For iOS 8, macOS 10.10 or Xcode &amp;lt; 11, use &lt;a href="https://github.com/SDWebImage/SDWebImage/releases/tag/5.9.5"&gt;any 5.x version up to 5.9.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For iOS 7, macOS 10.9 or Xcode &amp;lt; 8, use &lt;a href="https://github.com/SDWebImage/SDWebImage/releases/tag/4.4.6"&gt;any 4.x version up to 4.4.6&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For macOS 10.8, use &lt;a href="https://github.com/SDWebImage/SDWebImage/releases/tag/4.3.0"&gt;any 4.x version up to 4.3.0&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For iOS 5 and 6, use &lt;a href="https://github.com/SDWebImage/SDWebImage/releases/tag/3.7.6"&gt;any 3.x version up to 3.7.6&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For iOS &amp;lt; 5.0, please use the last &lt;a href="https://github.com/SDWebImage/SDWebImage/tree/2.0-compat"&gt;2.0 version&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read this Readme doc&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://github.com/SDWebImage/SDWebImage#how-to-use"&gt;How to use section&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://sdwebimage.github.io/"&gt;Latest Documentation&lt;/a&gt; and &lt;a href="http://cocoadocs.org/docsets/SDWebImage/"&gt;CocoaDocs for old version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Try the example by downloading the project from Github or even easier using CocoaPods try &lt;code&gt;pod try SDWebImage&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Installation-Guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://github.com/SDWebImage/SDWebImage/raw/master/Docs/SDWebImage-5.0-Migration-guide.md"&gt;SDWebImage 5.0 Migration Guide&lt;/a&gt; to get an idea of the changes from 4.x to 5.x&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://github.com/SDWebImage/SDWebImage/raw/master/Docs/SDWebImage-4.0-Migration-guide.md"&gt;SDWebImage 4.0 Migration Guide&lt;/a&gt; to get an idea of the changes from 3.x to 4.x&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Common-Problems"&gt;Common Problems&lt;/a&gt; to find the solution for common problems&lt;/li&gt; 
 &lt;li&gt;Go to the &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki"&gt;Wiki Page&lt;/a&gt; for more information such as &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage"&gt;Advanced Usage&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Who Uses It&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Find out &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Who-Uses-SDWebImage"&gt;who uses SDWebImage&lt;/a&gt; and add your app to the list.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you &lt;strong&gt;need help&lt;/strong&gt;, use &lt;a href="http://stackoverflow.com/questions/tagged/sdwebimage"&gt;Stack Overflow&lt;/a&gt;. (Tag 'sdwebimage')&lt;/li&gt; 
 &lt;li&gt;If you'd like to &lt;strong&gt;ask a general question&lt;/strong&gt;, use &lt;a href="http://stackoverflow.com/questions/tagged/sdwebimage"&gt;Stack Overflow&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;If you &lt;strong&gt;found a bug&lt;/strong&gt;, open an issue.&lt;/li&gt; 
 &lt;li&gt;If you &lt;strong&gt;have a feature request&lt;/strong&gt;, open an issue.&lt;/li&gt; 
 &lt;li&gt;If you &lt;strong&gt;need IRC channel&lt;/strong&gt;, use &lt;a href="https://gitter.im/SDWebImage/community"&gt;Gitter&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you &lt;strong&gt;want to contribute&lt;/strong&gt;, read the &lt;a href="https://github.com/SDWebImage/SDWebImage/raw/master/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For &lt;strong&gt;development contribution guide&lt;/strong&gt;, read the &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/How-to-Contribute"&gt;How-To-Contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For &lt;strong&gt;understanding code architecture&lt;/strong&gt;, read the &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/5.6-Code-Architecture-Analysis"&gt;Code Architecture Analysis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How To Use&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Objective-C&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-objective-c"&gt;#import &amp;lt;SDWebImage/SDWebImage.h&amp;gt;
...
[imageView sd_setImageWithURL:[NSURL URLWithString:@"http://www.domain.com/path/to/image.jpg"]
             placeholderImage:[UIImage imageNamed:@"placeholder.png"]];
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Swift&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;import SDWebImage

imageView.sd_setImage(with: URL(string: "http://www.domain.com/path/to/image.jpg"), placeholderImage: UIImage(named: "placeholder.png"))
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;For details about how to use the library and clear examples, see &lt;a href="https://github.com/SDWebImage/SDWebImage/raw/master/Docs/HowToUse.md"&gt;The detailed How to use&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Animated Images (GIF) support&lt;/h2&gt; 
&lt;p&gt;In 5.0, we introduced a brand new mechanism for supporting animated images. This includes animated image loading, rendering, decoding, and also supports customizations (for advanced users).&lt;/p&gt; 
&lt;p&gt;This animated image solution is available for &lt;code&gt;iOS&lt;/code&gt;/&lt;code&gt;tvOS&lt;/code&gt;/&lt;code&gt;macOS&lt;/code&gt;. The &lt;code&gt;SDAnimatedImage&lt;/code&gt; is subclass of &lt;code&gt;UIImage/NSImage&lt;/code&gt;, and &lt;code&gt;SDAnimatedImageView&lt;/code&gt; is subclass of &lt;code&gt;UIImageView/NSImageView&lt;/code&gt;, to make them compatible with the common frameworks APIs.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;SDAnimatedImageView&lt;/code&gt; supports the familiar image loading category methods, works like drop-in replacement for &lt;code&gt;UIImageView/NSImageView&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Don't have &lt;code&gt;UIView&lt;/code&gt; (like &lt;code&gt;WatchKit&lt;/code&gt; or &lt;code&gt;CALayer&lt;/code&gt;)? you can still use &lt;code&gt;SDAnimatedPlayer&lt;/code&gt; the player engine for advanced playback and rendering.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Advanced-Usage#animated-image-50"&gt;Animated Image&lt;/a&gt; for more detailed information.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Objective-C&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-objective-c"&gt;SDAnimatedImageView *imageView = [SDAnimatedImageView new];
SDAnimatedImage *animatedImage = [SDAnimatedImage imageNamed:@"image.gif"];
imageView.image = animatedImage;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Swift&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;let imageView = SDAnimatedImageView()
let animatedImage = SDAnimatedImage(named: "image.gif")
imageView.image = animatedImage
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;FLAnimatedImage integration has its own dedicated repo&lt;/h4&gt; 
&lt;p&gt;In order to clean up things and make our core project do less things, we decided that the &lt;code&gt;FLAnimatedImage&lt;/code&gt; integration does not belong here. From 5.0, this will still be available, but under a dedicated repo &lt;a href="https://github.com/SDWebImage/SDWebImageFLPlugin"&gt;SDWebImageFLPlugin&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;There are 5 ways to use SDWebImage in your project:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;using CocoaPods&lt;/li&gt; 
 &lt;li&gt;using Carthage&lt;/li&gt; 
 &lt;li&gt;using Swift Package Manager&lt;/li&gt; 
 &lt;li&gt;download binary XCFramework&lt;/li&gt; 
 &lt;li&gt;manual install (build frameworks or embed Xcode Project)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation with CocoaPods&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://cocoapods.org/"&gt;CocoaPods&lt;/a&gt; is a dependency manager for Objective-C, which automates and simplifies the process of using 3rd-party libraries in your projects. See the &lt;a href="http://cocoapods.org/#get_started"&gt;Get Started&lt;/a&gt; section for more details.&lt;/p&gt; 
&lt;h4&gt;Podfile&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;platform :ios, '8.0'
pod 'SDWebImage', '~&amp;gt; 5.0'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Swift and static framework&lt;/h5&gt; 
&lt;p&gt;Swift project previously had to use &lt;code&gt;use_frameworks!&lt;/code&gt; to make all Pods into dynamic framework to let CocoaPods work.&lt;/p&gt; 
&lt;p&gt;However, starting with &lt;code&gt;CocoaPods 1.5.0+&lt;/code&gt; (with &lt;code&gt;Xcode 9+&lt;/code&gt;), which supports to build both Objective-C &amp;amp;&amp;amp; Swift code into static framework. You can use modular headers to use SDWebImage as static framework, without the need of &lt;code&gt;use_frameworks!&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;platform :ios, '8.0'
# Uncomment the next line when you want all Pods as static framework
# use_modular_headers!
pod 'SDWebImage', :modular_headers =&amp;gt; true
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See more on &lt;a href="http://blog.cocoapods.org/CocoaPods-1.5.0/"&gt;CocoaPods 1.5.0 — Swift Static Libraries&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If not, you still need to add &lt;code&gt;use_frameworks!&lt;/code&gt; to use SDWebImage as dynamic framework:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;platform :ios, '8.0'
use_frameworks!
pod 'SDWebImage'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Subspecs&lt;/h4&gt; 
&lt;p&gt;There are 2 subspecs available now: &lt;code&gt;Core&lt;/code&gt; and &lt;code&gt;MapKit&lt;/code&gt; (this means you can install only some of the SDWebImage modules. By default, you get just &lt;code&gt;Core&lt;/code&gt;, so if you need &lt;code&gt;MapKit&lt;/code&gt;, you need to specify it).&lt;/p&gt; 
&lt;p&gt;Podfile example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pod 'SDWebImage/MapKit'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installation with Carthage&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/Carthage/Carthage"&gt;Carthage&lt;/a&gt; is a lightweight dependency manager for Swift and Objective-C. It leverages CocoaTouch modules and is less invasive than CocoaPods.&lt;/p&gt; 
&lt;p&gt;To install with carthage, follow the instruction on &lt;a href="https://github.com/Carthage/Carthage"&gt;Carthage&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Carthage users can point to this repository and use whichever generated framework they'd like: SDWebImage, SDWebImageMapKit or both.&lt;/p&gt; 
&lt;p&gt;Make the following entry in your Cartfile: &lt;code&gt;github "SDWebImage/SDWebImage"&lt;/code&gt; Then run &lt;code&gt;carthage update&lt;/code&gt; If this is your first time using Carthage in the project, you'll need to go through some additional steps as explained &lt;a href="https://github.com/Carthage/Carthage#adding-frameworks-to-an-application"&gt;over at Carthage&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💡NOTE: At this time, Carthage does not provide a way to build only specific repository subcomponents (or equivalent of CocoaPods's subspecs). All components and their dependencies will be built with the above command. However, you don't need to copy frameworks you aren't using into your project. For instance, if you aren't using &lt;code&gt;SDWebImageMapKit&lt;/code&gt;, feel free to delete that framework from the Carthage Build directory after &lt;code&gt;carthage update&lt;/code&gt; completes.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;💡NOTE: &lt;a href="https://developer.apple.com/support/third-party-SDK-requirements/"&gt;Apple requires SDWebImage contains signatures&lt;/a&gt;. So, by default the &lt;code&gt;carthage build&lt;/code&gt; binary framework does not do codesign, this will cause validation error. You can sign yourself with the Apple Developer Program identity, or using the binary framework:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code&gt;binary "https://github.com/SDWebImage/SDWebImage/raw/master/SDWebImage.json"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installation with Swift Package Manager (Xcode 11+)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://swift.org/package-manager/"&gt;Swift Package Manager&lt;/a&gt; (SwiftPM) is a tool for managing the distribution of Swift code as well as C-family dependency. From Xcode 11, SwiftPM got natively integrated with Xcode.&lt;/p&gt; 
&lt;p&gt;SDWebImage support SwiftPM from version 5.1.0. To use SwiftPM, you should use Xcode 11 to open your project. Click &lt;code&gt;File&lt;/code&gt; -&amp;gt; &lt;code&gt;Swift Packages&lt;/code&gt; -&amp;gt; &lt;code&gt;Add Package Dependency&lt;/code&gt;, enter &lt;a href="https://github.com/SDWebImage/SDWebImage.git"&gt;SDWebImage repo's URL&lt;/a&gt;. Or you can login Xcode with your GitHub account and just type &lt;code&gt;SDWebImage&lt;/code&gt; to search.&lt;/p&gt; 
&lt;p&gt;After select the package, you can choose the dependency type (tagged version, branch or commit). Then Xcode will setup all the stuff for you.&lt;/p&gt; 
&lt;p&gt;If you're a framework author and use SDWebImage as a dependency, update your &lt;code&gt;Package.swift&lt;/code&gt; file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-swift"&gt;let package = Package(
    // 5.1.0 ..&amp;lt; 6.0.0
    dependencies: [
        .package(url: "https://github.com/SDWebImage/SDWebImage.git", from: "5.1.0")
    ],
    // ...
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Download binary XCFramework&lt;/h3&gt; 
&lt;p&gt;From 5.19.2, SDWebImage provide the canonical official binary XCFramework on &lt;a href="https://github.com/SDWebImage/SDWebImage/releases"&gt;GitHub release pages&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download XCFramework&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can choose to download &lt;code&gt;SDWebImage-dynamic.xcframework.zip&lt;/code&gt; for dynamic linked one, or &lt;code&gt;SDWebImage-static.xcframework.zip&lt;/code&gt; for static-linked one.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Integrate to Xcode Project&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Drag the unzipped &lt;code&gt;.xcframework&lt;/code&gt; into your Xcode Project's Framework tab.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Verify signature of binary XCFramework&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;From Xcode 15 Apple will verify the signature of binary XCFramework, to avoid supply chain attack.&lt;/p&gt; 
&lt;p&gt;The fingerprint currently should be &lt;code&gt;FC 3B 10 13 86 34 4C 50 DB 70 2A 9A D1 01 6F B5 1A 3E CC 8B 9D A9 B7 AE 47 A0 48 D4 D0 63 39 83&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;The certificate is stored in the repo &lt;a href="https://github.com/SDWebImage/SDWebImage/raw/master/Certificate/SDWebImage%20Signing%20Certificate.cer"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The public key is stored in the repo &lt;a href="https://github.com/SDWebImage/SDWebImage/raw/master/Certificate/SDWebImage%20Signing%20Certificate.pem"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;See more: &lt;a href="https://developer.apple.com/documentation/Xcode/verifying-the-origin-of-your-xcframeworks"&gt;Verifying the origin of your XCFrameworks&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Manual Installation Guide&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check your command line Xcode version&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;sudo xcode-select -s /path/to/Xcode.app
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export DEVELOPER_DIR=/path/to/Xcode.app/Contents/Developer
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run the script to build frameworks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;./Scripts/build-frameworks.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Run the script to merge XCFramework&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;./Scripts/create-xcframework.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use your own certificate to sign XCFramework&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;// https://developer.apple.com/support/third-party-SDK-requirements/
codesign --timestamp -v --sign "your own certificate" SDWebImage.xcframework
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See more on wiki: &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/Installation-Guide#manual-installation-guide"&gt;Manual install Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Import headers in your source files&lt;/h3&gt; 
&lt;p&gt;In the source files where you need to use the library, import the umbrella header file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-objective-c"&gt;#import &amp;lt;SDWebImage/SDWebImage.h&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It's also recommend to use the module import syntax, available for CocoaPods(enable &lt;code&gt;modular_headers&lt;/code&gt;)/Carthage/SwiftPM.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-objecitivec"&gt;@import SDWebImage;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build Project&lt;/h3&gt; 
&lt;p&gt;At this point your workspace should build without error. If you are having problem, post to the Issue and the community can help you solve it.&lt;/p&gt; 
&lt;h2&gt;Data Collection Practices&lt;/h2&gt; 
&lt;p&gt;From Xcode 15, we provide the new &lt;code&gt;PrivacyInfo.xcprivacy&lt;/code&gt; file for privacy details, see &lt;a href="https://developer.apple.com/documentation/bundleresources/privacy_manifest_files/describing_data_use_in_privacy_manifests?language=objc"&gt;Describing data use in privacy manifests&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can exports the privacy report after archive your App by integrate SDWebImage via SwiftPM/XCFramework or CocoaPods (&lt;code&gt;use_frameworks&lt;/code&gt; set to true).&lt;/p&gt; 
&lt;p&gt;For old version or if you're using static ar archive, as required by the &lt;a href="https://developer.apple.com/app-store/app-privacy-details/"&gt;App privacy details on the App Store&lt;/a&gt;, here's SDWebImage's list of &lt;a href="https://sdwebimage.github.io/DataCollection/index.html"&gt;Data Collection Practices&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Author&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rs"&gt;Olivier Poitrey&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Collaborators&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mythodeia"&gt;Konstantinos K.&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bpoplauschi"&gt;Bogdan Poplauschi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/skyline75489"&gt;Chester Liu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dreampiggy"&gt;DreamPiggy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zhongwuzw"&gt;Wu Zhong&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Thank you to all the people who have already contributed to SDWebImage.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/SDWebImage/SDWebImage/graphs/contributors"&gt;&lt;img src="https://opencollective.com/SDWebImage/contributors.svg?width=890" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;All source code is licensed under the &lt;a href="https://github.com/SDWebImage/SDWebImage/raw/master/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;To learn about SDWebImage's architecture design for contribution, read &lt;a href="https://github.com/SDWebImage/SDWebImage/wiki/5.6-Code-Architecture-Analysis"&gt;The Core of SDWebImage v5.6 Architecture&lt;/a&gt;. Thanks @looseyi for the post and translation.&lt;/p&gt; 
&lt;h4&gt;High Level Diagram&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SDWebImage/SDWebImage/master/Docs/Diagrams/SDWebImageHighLevelDiagram.jpeg" title="SDWebImage high level diagram" /&gt; &lt;/p&gt; 
&lt;h4&gt;Overall Class Diagram&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SDWebImage/SDWebImage/master/Docs/Diagrams/SDWebImageClassDiagram.png" title="SDWebImage overall class diagram" /&gt; &lt;/p&gt; 
&lt;h4&gt;Top Level API Diagram&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SDWebImage/SDWebImage/master/Docs/Diagrams/SDWebImageTopLevelClassDiagram.png" title="SDWebImage top level API diagram" /&gt; &lt;/p&gt; 
&lt;h4&gt;Main Sequence Diagram&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SDWebImage/SDWebImage/master/Docs/Diagrams/SDWebImageSequenceDiagram.png" title="SDWebImage sequence diagram" /&gt; &lt;/p&gt; 
&lt;h4&gt;More detailed diagrams&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SDWebImage/SDWebImage/master/Docs/Diagrams/SDWebImageManagerClassDiagram.png"&gt;Manager API Diagram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SDWebImage/SDWebImage/master/Docs/Diagrams/SDWebImageCodersClassDiagram.png"&gt;Coders API Diagram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SDWebImage/SDWebImage/master/Docs/Diagrams/SDWebImageLoaderClassDiagram.png"&gt;Loader API Diagram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/SDWebImage/SDWebImage/master/Docs/Diagrams/SDWebImageCacheClassDiagram.png"&gt;Cache API Diagram&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>