<rss version="2.0">
  <channel>
    <title>GitHub Python Weekly Trending</title>
    <description>Weekly Trending of Python in GitHub</description>
    <pubDate>Mon, 28 Jul 2025 01:48:47 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>hummingbot/hummingbot</title>
      <link>https://github.com/hummingbot/hummingbot</link>
      <description>&lt;p&gt;Open source software that helps you create and deploy high-frequency crypto trading bots&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/3213d7f8-414b-4df8-8c1b-a0cd142a82d8" alt="Hummingbot"&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;a href="https://github.com/hummingbot/hummingbot/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-informational.svg?sanitize=true" alt="License"&gt;&lt;/a&gt; &lt;a href="https://twitter.com/_hummingbot"&gt;&lt;img src="https://img.shields.io/twitter/url?url=https://twitter.com/_hummingbot?style=social&amp;amp;label=_hummingbot" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/@hummingbot"&gt;&lt;img src="https://img.shields.io/youtube/channel/subscribers/UCxzzdEnDRbylLMWmaMjywOA" alt="Youtube"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/hummingbot"&gt;&lt;img src="https://img.shields.io/discord/530578568154054663?logo=discord&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="Discord"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Hummingbot is an open-source framework that helps you design and deploy automated trading strategies, or &lt;strong&gt;bots&lt;/strong&gt;, that can run on many centralized or decentralized exchanges. Over the past year, Hummingbot users have generated over $34 billion in trading volume across 140+ unique trading venues.&lt;/p&gt; 
&lt;p&gt;The Hummingbot codebase is free and publicly available under the Apache 2.0 open-source license. Our mission is to &lt;strong&gt;democratize high-frequency trading&lt;/strong&gt; by creating a global community of algorithmic traders and developers that share knowledge and contribute to the codebase.&lt;/p&gt; 
&lt;h2&gt;Quick Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hummingbot.org"&gt;Website and Docs&lt;/a&gt;: Official Hummingbot website and documeniuntation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hummingbot.org/installation/docker/"&gt;Installation&lt;/a&gt;: Install Hummingbot on various platforms&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/hummingbot"&gt;Discord&lt;/a&gt;: The main gathering spot for the global Hummingbot community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/c/hummingbot"&gt;YouTube&lt;/a&gt;: Videos that teach you how to get the most of of Hummingbot&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/_hummingbot"&gt;Twitter&lt;/a&gt;: Get the latest announcements about Hummingbot&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://p.datadoghq.com/sb/a96a744f5-a15479d77992ccba0d23aecfd4c87a52"&gt;Reported Volumes&lt;/a&gt;: Reported trading volumes across all Hummingbot instances&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hummingbot.substack.com"&gt;Newsletter&lt;/a&gt;: Get our newsletter whenever we ship a new release&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Exchange Connectors&lt;/h2&gt; 
&lt;p&gt;Hummingbot connectors standardize REST and WebSocket API interfaces to different types of exchanges, enabling you to build sophisticated trading strategies that can be deployed across many exchanges with minimal changes. We classify exchanges into the following categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CEX&lt;/strong&gt;: Centralized exchanges that take custody of your funds. Use API keys to connect with Hummingbot.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DEX&lt;/strong&gt;: Decentralized, non-custodial exchanges that operate on a blockchain. Use wallet keys to connect with Hummingbot.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition, connectors differ based on the type of market supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CLOB Spot&lt;/strong&gt;: Connectors to spot markets on central limit order book (CLOB) exchanges&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CLOB Perp&lt;/strong&gt;: Connectors to perpetual futures markets on CLOB exchanges&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AMM&lt;/strong&gt;: Connectors to spot markets on Automatic Market Maker (AMM) decentralized exchanges&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Exchange Sponsors&lt;/h3&gt; 
&lt;p&gt;We are grateful for the following exchanges that support the development and maintenance of Hummingbot via broker partnerships and sponsorships.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connector ID&lt;/th&gt; 
   &lt;th&gt;Exchange&lt;/th&gt; 
   &lt;th&gt;CEX/DEX&lt;/th&gt; 
   &lt;th&gt;Market Type&lt;/th&gt; 
   &lt;th&gt;Docs&lt;/th&gt; 
   &lt;th&gt;Discount&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;binance&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://accounts.binance.com/register?ref=CBWO4LU6"&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/binance/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://accounts.binance.com/register?ref=CBWO4LU6"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d10%25&amp;amp;color=orange" alt="Sign up for Binance using Hummingbot's referral link for a 10% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;binance_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://accounts.binance.com/register?ref=CBWO4LU6"&gt;Binance&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/binance/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://accounts.binance.com/register?ref=CBWO4LU6"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d10%25&amp;amp;color=orange" alt="Sign up for Binance using Hummingbot's referral link for a 10% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;gate_io&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gate.io/referral/invite/HBOTGATE_0_103"&gt;Gate.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/gate-io/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gate.io/referral/invite/HBOTGATE_0_103"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Gate.io using Hummingbot's referral link for a 10% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;gate_io_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gate.io/referral/invite/HBOTGATE_0_103"&gt;Gate.io&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/gate-io/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.gate.io/referral/invite/HBOTGATE_0_103"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Gate.io using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;htx&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.htx.com.pk/invite/en-us/1h?invite_code=re4w9223"&gt;HTX (Huobi)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/huobi/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.htx.com.pk/invite/en-us/1h?invite_code=re4w9223"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for HTX using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;kucoin&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.kucoin.com/r/af/hummingbot"&gt;KuCoin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/kucoin/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.kucoin.com/r/af/hummingbot"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Kucoin using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;kucoin_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.kucoin.com/r/af/hummingbot"&gt;KuCoin&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/kucoin/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.kucoin.com/r/af/hummingbot"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Kucoin using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;okx&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.okx.com/join/1931920269"&gt;OKX&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/okx/okx/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.okx.com/join/1931920269"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Kucoin using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;okx_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.okx.com/join/1931920269"&gt;OKX&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/okx/okx/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.okx.com/join/1931920269"&gt;&lt;img src="https://img.shields.io/static/v1?label=Fee&amp;amp;message=%2d20%25&amp;amp;color=orange" alt="Sign up for Kucoin using Hummingbot's referral link for a 20% discount!"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;dydx_v4_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.dydx.exchange/"&gt;dYdX&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/dydx/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;hyperliquid_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hyperliquid.io/"&gt;Hyperliquid&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/hyperliquid/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;xrpl&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://xrpl.org/"&gt;XRP Ledger&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/xrpl/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Other Exchange Connectors&lt;/h3&gt; 
&lt;p&gt;Currently, the master branch of Hummingbot also includes the following exchange connectors, which are maintained and updated through the Hummingbot Foundation governance process. See &lt;a href="https://hummingbot.org/governance/"&gt;Governance&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Connector ID&lt;/th&gt; 
   &lt;th&gt;Exchange&lt;/th&gt; 
   &lt;th&gt;CEX/DEX&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Docs&lt;/th&gt; 
   &lt;th&gt;Discount&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ascend_ex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;AscendEx&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/ascendex/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;balancer&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Balancer&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/balancer/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bing_x&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;BingX&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bing_x/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitget_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bitget&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bitget-perpetual/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitmart&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;BitMart&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bitmart/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitrue&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bitrue&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bitrue/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bitstamp&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bitstamp&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bitstamp/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;btc_markets&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;BTC Markets&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/btc-markets/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bybit&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bybit&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bybit/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;bybit_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Bybit&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/bybit/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;carbon&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Carbon&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/carbon/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;coinbase_advanced_trade&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Coinbase&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/coinbase/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;cube&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Cube&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/cube/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;curve&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Curve&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/curve/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;dexalot&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Dexalot&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/dexalot/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;injective_v2&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Injective Helix&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/injective/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;injective_v2_perpetual&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Injective Helix&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Perp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/injective/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;kraken&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Kraken&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/kraken/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;mad_meerkat&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Mad Meerkat&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/mad-meerkat/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;mexc&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;MEXC&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/mexc/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;openocean&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenOcean&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/openocean/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pancakeswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;PancakeSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/pancakeswap/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;pangolin&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Pangolin&lt;/td&gt; 
   &lt;td&gt;CEX&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/pangolin/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;quickswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;QuickSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/quickswap/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;sushiswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;SushiSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/sushiswap/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tinyman&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Tinyman&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/tinyman/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;traderjoe&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Trader Joe&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/traderjoe/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;uniswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Uniswap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/gateway/uniswap/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vertex&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Vertex&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;CLOB Spot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/vertex/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;vvs&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;VVS&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/vvs/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;xsswap&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;XSSwap&lt;/td&gt; 
   &lt;td&gt;DEX&lt;/td&gt; 
   &lt;td&gt;AMM&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hummingbot.org/exchanges/xswap/"&gt;Docs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Other Hummingbot Repos&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hummingbot/deploy"&gt;Deploy&lt;/a&gt;: Deploy Hummingbot in various configurations with Docker&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hummingbot/dashboard"&gt;Dashboard&lt;/a&gt;: Web app that help you create, backtest, deploy, and manage Hummingbot instances&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hummingbot/quants-lab"&gt;Quants Lab&lt;/a&gt;: Juypter notebooks that enable you to fetch data and perform research using Hummingbot&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hummingbot/gateway"&gt;Gateway&lt;/a&gt;: Typescript based API client for DEX connectors&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hummingbot/hummingbot-site"&gt;Hummingbot Site&lt;/a&gt;: Official documentation for Hummingbot - we welcome contributions here too!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;The Hummingbot architecture features modular components that can be maintained and extended by individual community members.&lt;/p&gt; 
&lt;p&gt;We welcome contributions from the community! Please review these &lt;a href="https://raw.githubusercontent.com/hummingbot/hummingbot/master/CONTRIBUTING.md"&gt;guidelines&lt;/a&gt; before submitting a pull request.&lt;/p&gt; 
&lt;p&gt;To have your exchange connector or other pull request merged into the codebase, please submit a New Connector Proposal or Pull Request Proposal, following these &lt;a href="https://hummingbot.org/governance/proposals/"&gt;guidelines&lt;/a&gt;. Note that you will need some amount of &lt;a href="https://etherscan.io/token/0xe5097d9baeafb89f9bcb78c9290d545db5f9e9cb"&gt;HBOT tokens&lt;/a&gt; in your Ethereum wallet to submit a proposal.&lt;/p&gt; 
&lt;h2&gt;Legal&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;License&lt;/strong&gt;: Hummingbot is open source and licensed under &lt;a href="https://raw.githubusercontent.com/hummingbot/hummingbot/master/LICENSE"&gt;Apache 2.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data collection&lt;/strong&gt;: See &lt;a href="https://hummingbot.org/reporting/"&gt;Reporting&lt;/a&gt; for information on anonymous data collection and reporting in Hummingbot.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Alvin9999/new-pac</title>
      <link>https://github.com/Alvin9999/new-pac</link>
      <description>&lt;p&gt;翻墙-科学上网、自由上网、免费科学上网、免费翻墙、fanqiang、油管youtube/视频下载、软件、VPN、一键翻墙浏览器，vps一键搭建翻墙服务器脚本/教程，免费shadowsocks/ss/ssr/v2ray/goflyway账号/节点，翻墙梯子，电脑、手机、iOS、安卓、windows、Mac、Linux、路由器翻墙、科学上网、youtube视频下载、youtube油管镜像/免翻墙网站、美区apple id共享账号、翻墙-科学上网-梯子&lt;/p&gt;&lt;hr&gt;&lt;p&gt;科学上网-翻墙、免费翻墙、免费科学上网、软件、VPN、一键翻墙浏览器，vps一键搭建翻墙服务器脚本/教程，免费shadowsocks/ss/ssr/v2ray/goflyway账号/节点，免费自由上网、fanqiang、翻墙梯子，电脑、手机、iOS、安卓、windows、Mac、Linux、路由器翻墙、youtube视频下载、youtube油管镜像/免翻墙网站、美区apple id共享账号&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/Alvin9999/new-pac/wiki"&gt;https://github.com/Alvin9999/new-pac/wiki&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;北京时间2025年07月28日09点15分更新。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>roboflow/supervision</title>
      <link>https://github.com/roboflow/supervision</link>
      <description>&lt;p&gt;We write your reusable computer vision tools. 💜&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://supervision.roboflow.com"&gt; &lt;img width="100%" src="https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529"&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://github.com/roboflow/notebooks"&gt;notebooks&lt;/a&gt; | &lt;a href="https://github.com/roboflow/inference"&gt;inference&lt;/a&gt; | &lt;a href="https://github.com/autodistill/autodistill"&gt;autodistill&lt;/a&gt; | &lt;a href="https://github.com/roboflow/multimodal-maestro"&gt;maestro&lt;/a&gt;&lt;/p&gt; 
 &lt;br&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://badge.fury.io/py/supervision.svg?sanitize=true" alt="version"&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/supervision"&gt;&lt;img src="https://img.shields.io/pypi/dm/supervision" alt="downloads"&gt;&lt;/a&gt; &lt;a href="https://snyk.io/advisor/python/supervision"&gt;&lt;img src="https://snyk.io/advisor/python/supervision/badge.svg?sanitize=true" alt="snyk"&gt;&lt;/a&gt; &lt;a href="https://github.com/roboflow/supervision/raw/main/LICENSE.md"&gt;&lt;img src="https://img.shields.io/pypi/l/supervision" alt="license"&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/supervision" alt="python-version"&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="colab"&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/Roboflow/Annotators"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" alt="gradio"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/GbfgXGJ8Bk"&gt;&lt;img src="https://img.shields.io/discord/1159501506232451173?logo=discord&amp;amp;label=discord&amp;amp;labelColor=fff&amp;amp;color=5865f2&amp;amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk" alt="discord"&gt;&lt;/a&gt; &lt;a href="https://squidfunk.github.io/mkdocs-material/"&gt;&lt;img src="https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;amp;logoColor=white" alt="built-with-material-for-mkdocs"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/124" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/124" alt="roboflow%2Fsupervision | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;👋 hello&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We write your reusable computer vision tools.&lt;/strong&gt; Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! 🤝&lt;/p&gt; 
&lt;h2&gt;💻 install&lt;/h2&gt; 
&lt;p&gt;Pip install the supervision package in a &lt;a href="https://www.python.org/"&gt;&lt;strong&gt;Python&amp;gt;=3.9&lt;/strong&gt;&lt;/a&gt; environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install supervision
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about conda, mamba, and installing from source in our &lt;a href="https://roboflow.github.io/supervision/"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🔥 quickstart&lt;/h2&gt; 
&lt;h3&gt;models&lt;/h3&gt; 
&lt;p&gt;Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created &lt;a href="https://supervision.roboflow.com/latest/detection/core/#detections"&gt;connectors&lt;/a&gt; for the most popular libraries like Ultralytics, Transformers, or MMDetection.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO("yolov8s.pt")
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;👉 more model connectors&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;inference&lt;/p&gt; &lt;p&gt;Running with &lt;a href="https://github.com/roboflow/inference"&gt;Inference&lt;/a&gt; requires a &lt;a href="https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key"&gt;Roboflow API KEY&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from inference import get_model

image = cv2.imread(...)
model = get_model(model_id="yolov8s-640", api_key=&amp;lt;ROBOFLOW API KEY&amp;gt;)
result = model.infer(image)[0]
detections = sv.Detections.from_inference(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;annotators&lt;/h3&gt; 
&lt;p&gt;Supervision offers a wide range of highly customizable &lt;a href="https://supervision.roboflow.com/latest/detection/annotators/"&gt;annotators&lt;/a&gt;, allowing you to compose the perfect visualization for your use case.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce"&gt;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;datasets&lt;/h3&gt; 
&lt;p&gt;Supervision provides a set of &lt;a href="https://supervision.roboflow.com/latest/datasets/core/"&gt;utils&lt;/a&gt; that allow you to load, split, merge, and save datasets in one of the supported formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&amp;lt;WORKSPACE_ID&amp;gt;).project(&amp;lt;PROJECT_ID&amp;gt;)
dataset = project.version(&amp;lt;PROJECT_VERSION&amp;gt;).download("coco")

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f"{dataset.location}/train",
    annotations_path=f"{dataset.location}/train/_annotations.coco.json",
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
&lt;/code&gt;&lt;/pre&gt; 
&lt;details close&gt; 
 &lt;summary&gt;👉 more dataset utils&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;load&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset = sv.DetectionDataset.from_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset = sv.DetectionDataset.from_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;split&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;train_dataset, test_dataset = dataset.split(split_ratio=0.7)
test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

len(train_dataset), len(test_dataset), len(valid_dataset)
# (700, 150, 150)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;merge&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;ds_1 = sv.DetectionDataset(...)
len(ds_1)
# 100
ds_1.classes
# ['dog', 'person']

ds_2 = sv.DetectionDataset(...)
len(ds_2)
# 200
ds_2.classes
# ['cat']

ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
len(ds_merged)
# 300
ds_merged.classes
# ['cat', 'dog', 'person']
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;save&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset.as_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset.as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset.as_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;convert&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
).as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;🎬 tutorials&lt;/h2&gt; 
&lt;p&gt;Want to learn how to use Supervision? Explore our &lt;a href="https://supervision.roboflow.com/develop/how_to/detect_and_annotate/"&gt;how-to guides&lt;/a&gt;, &lt;a href="https://github.com/roboflow/supervision/tree/develop/examples"&gt;end-to-end examples&lt;/a&gt;, &lt;a href="https://roboflow.github.io/cheatsheet-supervision/"&gt;cheatsheet&lt;/a&gt;, and &lt;a href="https://supervision.roboflow.com/develop/cookbooks/"&gt;cookbooks&lt;/a&gt;!&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1" alt="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing" width="300px" align="left"&gt;&lt;/a&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.
&lt;p&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91" alt="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source" width="300px" align="left"&gt;&lt;/a&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;strong&gt;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;💜 built with supervision&lt;/h2&gt; 
&lt;p&gt;Did you build something cool using supervision? &lt;a href="https://github.com/roboflow/supervision/discussions/categories/built-with-supervision"&gt;Let us know!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4"&gt;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900"&gt;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f"&gt;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;📚 documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://roboflow.github.io/supervision"&gt;documentation&lt;/a&gt; page to learn how supervision can help you build computer vision applications faster and more reliably.&lt;/p&gt; 
&lt;h2&gt;🏆 contribution&lt;/h2&gt; 
&lt;p&gt;We love your input! Please see our &lt;a href="https://github.com/roboflow/supervision/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started. Thank you 🙏 to all our contributors!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/roboflow/supervision/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=roboflow/supervision"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;div align="center"&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://youtube.com/roboflow"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634652" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949746649" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://www.linkedin.com/company/roboflow-ai/"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633691" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://docs.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634511" width="3%"&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; 
  &lt;a href="https://discuss.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633584" width="3%"&gt; &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%"&gt; &lt;/a&gt;
  &lt;a href="https://blog.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633605" width="3%"&gt; &lt;/a&gt;  
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>unclecode/crawl4ai</title>
      <link>https://github.com/unclecode/crawl4ai</link>
      <description>&lt;p&gt;🚀🤖 Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scraper. Don't be shy, join here: https://discord.gg/jP8KfhDhyN&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;🚀🤖 Crawl4AI: Open-source LLM Friendly Web Crawler &amp;amp; Scraper.&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11716" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11716" alt="unclecode%2Fcrawl4ai | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/unclecode/crawl4ai/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/unclecode/crawl4ai?style=social" alt="GitHub Stars"&gt;&lt;/a&gt; &lt;a href="https://github.com/unclecode/crawl4ai/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/unclecode/crawl4ai?style=social" alt="GitHub Forks"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/crawl4ai"&gt;&lt;img src="https://badge.fury.io/py/crawl4ai.svg?sanitize=true" alt="PyPI version"&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/crawl4ai/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/crawl4ai" alt="Python Version"&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/crawl4ai"&gt;&lt;img src="https://static.pepy.tech/badge/crawl4ai/month" alt="Downloads"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://x.com/crawl4ai"&gt; &lt;img src="https://img.shields.io/badge/Follow%20on%20X-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="Follow on X"&gt; &lt;/a&gt; &lt;a href="https://www.linkedin.com/company/crawl4ai"&gt; &lt;img src="https://img.shields.io/badge/Follow%20on%20LinkedIn-0077B5?style=for-the-badge&amp;amp;logo=linkedin&amp;amp;logoColor=white" alt="Follow on LinkedIn"&gt; &lt;/a&gt; &lt;a href="https://discord.gg/jP8KfhDhyN"&gt; &lt;img src="https://img.shields.io/badge/Join%20our%20Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Join our Discord"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Crawl4AI is the #1 trending GitHub repository, actively maintained by a vibrant community. It delivers blazing-fast, AI-ready web crawling tailored for LLMs, AI agents, and data pipelines. Open source, flexible, and built for real-time performance, Crawl4AI empowers developers with unmatched speed, precision, and deployment ease.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/unclecode/crawl4ai/main/#-recent-updates"&gt;✨ Check out latest update v0.7.0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🎉 &lt;strong&gt;Version 0.7.0 is now available!&lt;/strong&gt; The Adaptive Intelligence Update introduces groundbreaking features: Adaptive Crawling that learns website patterns, Virtual Scroll support for infinite pages, intelligent Link Preview with 3-layer scoring, Async URL Seeder for massive discovery, and significant performance improvements. &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/docs/blog/release-v0.7.0.md"&gt;Read the release notes →&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;🤓 &lt;strong&gt;My Personal Story&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;My journey with computers started in childhood when my dad, a computer scientist, introduced me to an Amstrad computer. Those early days sparked a fascination with technology, leading me to pursue computer science and specialize in NLP during my postgraduate studies. It was during this time that I first delved into web crawling, building tools to help researchers organize papers and extract information from publications a challenging yet rewarding experience that honed my skills in data extraction.&lt;/p&gt; 
 &lt;p&gt;Fast forward to 2023, I was working on a tool for a project and needed a crawler to convert a webpage into markdown. While exploring solutions, I found one that claimed to be open-source but required creating an account and generating an API token. Worse, it turned out to be a SaaS model charging $16, and its quality didn’t meet my standards. Frustrated, I realized this was a deeper problem. That frustration turned into turbo anger mode, and I decided to build my own solution. In just a few days, I created Crawl4AI. To my surprise, it went viral, earning thousands of GitHub stars and resonating with a global community.&lt;/p&gt; 
 &lt;p&gt;I made Crawl4AI open-source for two reasons. First, it’s my way of giving back to the open-source community that has supported me throughout my career. Second, I believe data should be accessible to everyone, not locked behind paywalls or monopolized by a few. Open access to data lays the foundation for the democratization of AI, a vision where individuals can train their own models and take ownership of their information. This library is the first step in a larger journey to create the best open-source data extraction and generation tool the world has ever seen, built collaboratively by a passionate community.&lt;/p&gt; 
 &lt;p&gt;Thank you to everyone who has supported this project, used it, and shared feedback. Your encouragement motivates me to dream even bigger. Join us, file issues, submit PRs, or spread the word. Together, we can build a tool that truly empowers people to access their own data and reshape the future of AI.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;🧐 Why Crawl4AI?&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Built for LLMs&lt;/strong&gt;: Creates smart, concise Markdown optimized for RAG and fine-tuning applications.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Lightning Fast&lt;/strong&gt;: Delivers results 6x faster with real-time, cost-efficient performance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Browser Control&lt;/strong&gt;: Offers session management, proxies, and custom hooks for seamless data access.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Heuristic Intelligence&lt;/strong&gt;: Uses advanced algorithms for efficient extraction, reducing reliance on costly models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source &amp;amp; Deployable&lt;/strong&gt;: Fully open-source with no API keys—ready for Docker and cloud integration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Thriving Community&lt;/strong&gt;: Actively maintained by a vibrant community and the #1 trending GitHub repository.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;🚀 Quick Start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Crawl4AI:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install the package
pip install -U crawl4ai

# For pre release versions
pip install crawl4ai --pre

# Run post-installation setup
crawl4ai-setup

# Verify your installation
crawl4ai-doctor
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you encounter any browser-related issues, you can install them manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m playwright install --with-deps chromium
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Run a simple web crawl with Python:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from crawl4ai import *

async def main():
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url="https://www.nbcnews.com/business",
        )
        print(result.markdown)

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Or use the new command-line interface:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic crawl with markdown output
crwl https://www.nbcnews.com/business -o markdown

# Deep crawl with BFS strategy, max 10 pages
crwl https://docs.crawl4ai.com --deep-crawl bfs --max-pages 10

# Use LLM extraction with a specific question
crwl https://www.example.com/products -q "Extract all product prices"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;📝 &lt;strong&gt;Markdown Generation&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;🧹 &lt;strong&gt;Clean Markdown&lt;/strong&gt;: Generates clean, structured Markdown with accurate formatting.&lt;/li&gt; 
  &lt;li&gt;🎯 &lt;strong&gt;Fit Markdown&lt;/strong&gt;: Heuristic-based filtering to remove noise and irrelevant parts for AI-friendly processing.&lt;/li&gt; 
  &lt;li&gt;🔗 &lt;strong&gt;Citations and References&lt;/strong&gt;: Converts page links into a numbered reference list with clean citations.&lt;/li&gt; 
  &lt;li&gt;🛠️ &lt;strong&gt;Custom Strategies&lt;/strong&gt;: Users can create their own Markdown generation strategies tailored to specific needs.&lt;/li&gt; 
  &lt;li&gt;📚 &lt;strong&gt;BM25 Algorithm&lt;/strong&gt;: Employs BM25-based filtering for extracting core information and removing irrelevant content.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;📊 &lt;strong&gt;Structured Data Extraction&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;🤖 &lt;strong&gt;LLM-Driven Extraction&lt;/strong&gt;: Supports all LLMs (open-source and proprietary) for structured data extraction.&lt;/li&gt; 
  &lt;li&gt;🧱 &lt;strong&gt;Chunking Strategies&lt;/strong&gt;: Implements chunking (topic-based, regex, sentence-level) for targeted content processing.&lt;/li&gt; 
  &lt;li&gt;🌌 &lt;strong&gt;Cosine Similarity&lt;/strong&gt;: Find relevant content chunks based on user queries for semantic extraction.&lt;/li&gt; 
  &lt;li&gt;🔎 &lt;strong&gt;CSS-Based Extraction&lt;/strong&gt;: Fast schema-based data extraction using XPath and CSS selectors.&lt;/li&gt; 
  &lt;li&gt;🔧 &lt;strong&gt;Schema Definition&lt;/strong&gt;: Define custom schemas for extracting structured JSON from repetitive patterns.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🌐 &lt;strong&gt;Browser Integration&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;🖥️ &lt;strong&gt;Managed Browser&lt;/strong&gt;: Use user-owned browsers with full control, avoiding bot detection.&lt;/li&gt; 
  &lt;li&gt;🔄 &lt;strong&gt;Remote Browser Control&lt;/strong&gt;: Connect to Chrome Developer Tools Protocol for remote, large-scale data extraction.&lt;/li&gt; 
  &lt;li&gt;👤 &lt;strong&gt;Browser Profiler&lt;/strong&gt;: Create and manage persistent profiles with saved authentication states, cookies, and settings.&lt;/li&gt; 
  &lt;li&gt;🔒 &lt;strong&gt;Session Management&lt;/strong&gt;: Preserve browser states and reuse them for multi-step crawling.&lt;/li&gt; 
  &lt;li&gt;🧩 &lt;strong&gt;Proxy Support&lt;/strong&gt;: Seamlessly connect to proxies with authentication for secure access.&lt;/li&gt; 
  &lt;li&gt;⚙️ &lt;strong&gt;Full Browser Control&lt;/strong&gt;: Modify headers, cookies, user agents, and more for tailored crawling setups.&lt;/li&gt; 
  &lt;li&gt;🌍 &lt;strong&gt;Multi-Browser Support&lt;/strong&gt;: Compatible with Chromium, Firefox, and WebKit.&lt;/li&gt; 
  &lt;li&gt;📐 &lt;strong&gt;Dynamic Viewport Adjustment&lt;/strong&gt;: Automatically adjusts the browser viewport to match page content, ensuring complete rendering and capturing of all elements.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🔎 &lt;strong&gt;Crawling &amp;amp; Scraping&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;🖼️ &lt;strong&gt;Media Support&lt;/strong&gt;: Extract images, audio, videos, and responsive image formats like &lt;code&gt;srcset&lt;/code&gt; and &lt;code&gt;picture&lt;/code&gt;.&lt;/li&gt; 
  &lt;li&gt;🚀 &lt;strong&gt;Dynamic Crawling&lt;/strong&gt;: Execute JS and wait for async or sync for dynamic content extraction.&lt;/li&gt; 
  &lt;li&gt;📸 &lt;strong&gt;Screenshots&lt;/strong&gt;: Capture page screenshots during crawling for debugging or analysis.&lt;/li&gt; 
  &lt;li&gt;📂 &lt;strong&gt;Raw Data Crawling&lt;/strong&gt;: Directly process raw HTML (&lt;code&gt;raw:&lt;/code&gt;) or local files (&lt;code&gt;file://&lt;/code&gt;).&lt;/li&gt; 
  &lt;li&gt;🔗 &lt;strong&gt;Comprehensive Link Extraction&lt;/strong&gt;: Extracts internal, external links, and embedded iframe content.&lt;/li&gt; 
  &lt;li&gt;🛠️ &lt;strong&gt;Customizable Hooks&lt;/strong&gt;: Define hooks at every step to customize crawling behavior.&lt;/li&gt; 
  &lt;li&gt;💾 &lt;strong&gt;Caching&lt;/strong&gt;: Cache data for improved speed and to avoid redundant fetches.&lt;/li&gt; 
  &lt;li&gt;📄 &lt;strong&gt;Metadata Extraction&lt;/strong&gt;: Retrieve structured metadata from web pages.&lt;/li&gt; 
  &lt;li&gt;📡 &lt;strong&gt;IFrame Content Extraction&lt;/strong&gt;: Seamless extraction from embedded iframe content.&lt;/li&gt; 
  &lt;li&gt;🕵️ &lt;strong&gt;Lazy Load Handling&lt;/strong&gt;: Waits for images to fully load, ensuring no content is missed due to lazy loading.&lt;/li&gt; 
  &lt;li&gt;🔄 &lt;strong&gt;Full-Page Scanning&lt;/strong&gt;: Simulates scrolling to load and capture all dynamic content, perfect for infinite scroll pages.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🚀 &lt;strong&gt;Deployment&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;🐳 &lt;strong&gt;Dockerized Setup&lt;/strong&gt;: Optimized Docker image with FastAPI server for easy deployment.&lt;/li&gt; 
  &lt;li&gt;🔑 &lt;strong&gt;Secure Authentication&lt;/strong&gt;: Built-in JWT token authentication for API security.&lt;/li&gt; 
  &lt;li&gt;🔄 &lt;strong&gt;API Gateway&lt;/strong&gt;: One-click deployment with secure token authentication for API-based workflows.&lt;/li&gt; 
  &lt;li&gt;🌐 &lt;strong&gt;Scalable Architecture&lt;/strong&gt;: Designed for mass-scale production and optimized server performance.&lt;/li&gt; 
  &lt;li&gt;☁️ &lt;strong&gt;Cloud Deployment&lt;/strong&gt;: Ready-to-deploy configurations for major cloud platforms.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🎯 &lt;strong&gt;Additional Features&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;🕶️ &lt;strong&gt;Stealth Mode&lt;/strong&gt;: Avoid bot detection by mimicking real users.&lt;/li&gt; 
  &lt;li&gt;🏷️ &lt;strong&gt;Tag-Based Content Extraction&lt;/strong&gt;: Refine crawling based on custom tags, headers, or metadata.&lt;/li&gt; 
  &lt;li&gt;🔗 &lt;strong&gt;Link Analysis&lt;/strong&gt;: Extract and analyze all links for detailed data exploration.&lt;/li&gt; 
  &lt;li&gt;🛡️ &lt;strong&gt;Error Handling&lt;/strong&gt;: Robust error management for seamless execution.&lt;/li&gt; 
  &lt;li&gt;🔐 &lt;strong&gt;CORS &amp;amp; Static Serving&lt;/strong&gt;: Supports filesystem-based caching and cross-origin requests.&lt;/li&gt; 
  &lt;li&gt;📖 &lt;strong&gt;Clear Documentation&lt;/strong&gt;: Simplified and updated guides for onboarding and advanced usage.&lt;/li&gt; 
  &lt;li&gt;🙌 &lt;strong&gt;Community Recognition&lt;/strong&gt;: Acknowledges contributors and pull requests for transparency.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Try it Now!&lt;/h2&gt; 
&lt;p&gt;✨ Play around with this &lt;a href="https://colab.research.google.com/drive/1SgRPrByQLzjRfwoRNq1wSGE9nYY_EE8C?usp=sharing"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;✨ Visit our &lt;a href="https://docs.crawl4ai.com/"&gt;Documentation Website&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation 🛠️&lt;/h2&gt; 
&lt;p&gt;Crawl4AI offers flexible installation options to suit various use cases. You can install it as a Python package or use Docker.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;🐍 &lt;strong&gt;Using pip&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;Choose the installation option that best fits your needs:&lt;/p&gt; 
 &lt;h3&gt;Basic Installation&lt;/h3&gt; 
 &lt;p&gt;For basic web crawling and scraping tasks:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install crawl4ai
crawl4ai-setup # Setup the browser
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;By default, this will install the asynchronous version of Crawl4AI, using Playwright for web crawling.&lt;/p&gt; 
 &lt;p&gt;👉 &lt;strong&gt;Note&lt;/strong&gt;: When you install Crawl4AI, the &lt;code&gt;crawl4ai-setup&lt;/code&gt; should automatically install and set up Playwright. However, if you encounter any Playwright-related errors, you can manually install it using one of these methods:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Through the command line:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;playwright install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;If the above doesn't work, try this more specific command:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python -m playwright install chromium
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;This second method has proven to be more reliable in some cases.&lt;/p&gt; 
 &lt;hr&gt; 
 &lt;h3&gt;Installation with Synchronous Version&lt;/h3&gt; 
 &lt;p&gt;The sync version is deprecated and will be removed in future versions. If you need the synchronous version using Selenium:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install crawl4ai[sync]
&lt;/code&gt;&lt;/pre&gt; 
 &lt;hr&gt; 
 &lt;h3&gt;Development Installation&lt;/h3&gt; 
 &lt;p&gt;For contributors who plan to modify the source code:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/unclecode/crawl4ai.git
cd crawl4ai
pip install -e .                    # Basic installation in editable mode
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Install optional features:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -e ".[torch]"           # With PyTorch features
pip install -e ".[transformer]"     # With Transformer features
pip install -e ".[cosine]"          # With cosine similarity features
pip install -e ".[sync]"            # With synchronous crawling (Selenium)
pip install -e ".[all]"             # Install all optional features
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🐳 &lt;strong&gt;Docker Deployment&lt;/strong&gt;&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;🚀 &lt;strong&gt;Now Available!&lt;/strong&gt; Our completely redesigned Docker implementation is here! This new solution makes deployment more efficient and seamless than ever.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h3&gt;New Docker Features&lt;/h3&gt; 
 &lt;p&gt;The new Docker implementation includes:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Browser pooling&lt;/strong&gt; with page pre-warming for faster response times&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Interactive playground&lt;/strong&gt; to test and generate request code&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;MCP integration&lt;/strong&gt; for direct connection to AI tools like Claude Code&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Comprehensive API endpoints&lt;/strong&gt; including HTML extraction, screenshots, PDF generation, and JavaScript execution&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Multi-architecture support&lt;/strong&gt; with automatic detection (AMD64/ARM64)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Optimized resources&lt;/strong&gt; with improved memory management&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Getting Started&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Pull and run the latest release candidate
docker pull unclecode/crawl4ai:0.7.0
docker run -d -p 11235:11235 --name crawl4ai --shm-size=1g unclecode/crawl4ai:0.7.0

# Visit the playground at http://localhost:11235/playground
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For complete documentation, see our &lt;a href="https://docs.crawl4ai.com/core/docker-deployment/"&gt;Docker Deployment Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h3&gt;Quick Test&lt;/h3&gt; 
&lt;p&gt;Run a quick test (works for both Docker options):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import requests

# Submit a crawl job
response = requests.post(
    "http://localhost:11235/crawl",
    json={"urls": ["https://example.com"], "priority": 10}
)
if response.status_code == 200:
    print("Crawl job submitted successfully.")
    
if "results" in response.json():
    results = response.json()["results"]
    print("Crawl job completed. Results:")
    for result in results:
        print(result)
else:
    task_id = response.json()["task_id"]
    print(f"Crawl job submitted. Task ID:: {task_id}")
    result = requests.get(f"http://localhost:11235/task/{task_id}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more examples, see our &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/docs/examples/docker_example.py"&gt;Docker Examples&lt;/a&gt;. For advanced configuration, environment variables, and usage examples, see our &lt;a href="https://docs.crawl4ai.com/basic/docker-deployment/"&gt;Docker Deployment Guide&lt;/a&gt;.&lt;/p&gt;  
&lt;h2&gt;🔬 Advanced Usage Examples 🔬&lt;/h2&gt; 
&lt;p&gt;You can check the project structure in the directory &lt;a href="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/examples"&gt;https://github.com/unclecode/crawl4ai/docs/examples&lt;/a&gt;. Over there, you can find a variety of examples; here, some popular examples are shared.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;📝 &lt;strong&gt;Heuristic Markdown Generation with Clean and Fit Markdown&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from crawl4ai.content_filter_strategy import PruningContentFilter, BM25ContentFilter
from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator

async def main():
    browser_config = BrowserConfig(
        headless=True,  
        verbose=True,
    )
    run_config = CrawlerRunConfig(
        cache_mode=CacheMode.ENABLED,
        markdown_generator=DefaultMarkdownGenerator(
            content_filter=PruningContentFilter(threshold=0.48, threshold_type="fixed", min_word_threshold=0)
        ),
        # markdown_generator=DefaultMarkdownGenerator(
        #     content_filter=BM25ContentFilter(user_query="WHEN_WE_FOCUS_BASED_ON_A_USER_QUERY", bm25_threshold=1.0)
        # ),
    )
    
    async with AsyncWebCrawler(config=browser_config) as crawler:
        result = await crawler.arun(
            url="https://docs.micronaut.io/4.7.6/guide/",
            config=run_config
        )
        print(len(result.markdown.raw_markdown))
        print(len(result.markdown.fit_markdown))

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🖥️ &lt;strong&gt;Executing JavaScript &amp;amp; Extract Structured Data without LLMs&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode
from crawl4ai import JsonCssExtractionStrategy
import json

async def main():
    schema = {
    "name": "KidoCode Courses",
    "baseSelector": "section.charge-methodology .w-tab-content &amp;gt; div",
    "fields": [
        {
            "name": "section_title",
            "selector": "h3.heading-50",
            "type": "text",
        },
        {
            "name": "section_description",
            "selector": ".charge-content",
            "type": "text",
        },
        {
            "name": "course_name",
            "selector": ".text-block-93",
            "type": "text",
        },
        {
            "name": "course_description",
            "selector": ".course-content-text",
            "type": "text",
        },
        {
            "name": "course_icon",
            "selector": ".image-92",
            "type": "attribute",
            "attribute": "src"
        }
    }
}

    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)

    browser_config = BrowserConfig(
        headless=False,
        verbose=True
    )
    run_config = CrawlerRunConfig(
        extraction_strategy=extraction_strategy,
        js_code=["""(async () =&amp;gt; {const tabs = document.querySelectorAll("section.charge-methodology .tabs-menu-3 &amp;gt; div");for(let tab of tabs) {tab.scrollIntoView();tab.click();await new Promise(r =&amp;gt; setTimeout(r, 500));}})();"""],
        cache_mode=CacheMode.BYPASS
    )
        
    async with AsyncWebCrawler(config=browser_config) as crawler:
        
        result = await crawler.arun(
            url="https://www.kidocode.com/degrees/technology",
            config=run_config
        )

        companies = json.loads(result.extracted_content)
        print(f"Successfully extracted {len(companies)} companies")
        print(json.dumps(companies[0], indent=2))


if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;📚 &lt;strong&gt;Extracting Structured Data with LLMs&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import os
import asyncio
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode, LLMConfig
from crawl4ai import LLMExtractionStrategy
from pydantic import BaseModel, Field

class OpenAIModelFee(BaseModel):
    model_name: str = Field(..., description="Name of the OpenAI model.")
    input_fee: str = Field(..., description="Fee for input token for the OpenAI model.")
    output_fee: str = Field(..., description="Fee for output token for the OpenAI model.")

async def main():
    browser_config = BrowserConfig(verbose=True)
    run_config = CrawlerRunConfig(
        word_count_threshold=1,
        extraction_strategy=LLMExtractionStrategy(
            # Here you can use any provider that Litellm library supports, for instance: ollama/qwen2
            # provider="ollama/qwen2", api_token="no-token", 
            llm_config = LLMConfig(provider="openai/gpt-4o", api_token=os.getenv('OPENAI_API_KEY')), 
            schema=OpenAIModelFee.schema(),
            extraction_type="schema",
            instruction="""From the crawled content, extract all mentioned model names along with their fees for input and output tokens. 
            Do not miss any models in the entire content. One extracted model JSON format should look like this: 
            {"model_name": "GPT-4", "input_fee": "US$10.00 / 1M tokens", "output_fee": "US$30.00 / 1M tokens"}."""
        ),            
        cache_mode=CacheMode.BYPASS,
    )
    
    async with AsyncWebCrawler(config=browser_config) as crawler:
        result = await crawler.arun(
            url='https://openai.com/api/pricing/',
            config=run_config
        )
        print(result.extracted_content)

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🤖 &lt;strong&gt;Using You own Browser with Custom User Profile&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;import os, sys
from pathlib import Path
import asyncio, time
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode

async def test_news_crawl():
    # Create a persistent user data directory
    user_data_dir = os.path.join(Path.home(), ".crawl4ai", "browser_profile")
    os.makedirs(user_data_dir, exist_ok=True)

    browser_config = BrowserConfig(
        verbose=True,
        headless=True,
        user_data_dir=user_data_dir,
        use_persistent_context=True,
    )
    run_config = CrawlerRunConfig(
        cache_mode=CacheMode.BYPASS
    )
    
    async with AsyncWebCrawler(config=browser_config) as crawler:
        url = "ADDRESS_OF_A_CHALLENGING_WEBSITE"
        
        result = await crawler.arun(
            url,
            config=run_config,
            magic=True,
        )
        
        print(f"Successfully crawled {url}")
        print(f"Content length: {len(result.markdown)}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;✨ Recent Updates&lt;/h2&gt; 
&lt;h3&gt;Version 0.7.0 Release Highlights - The Adaptive Intelligence Update&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🧠 Adaptive Crawling&lt;/strong&gt;: Your crawler now learns and adapts to website patterns automatically:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;config = AdaptiveConfig(
    confidence_threshold=0.7, # Min confidence to stop crawling
    max_depth=5, # Maximum crawl depth
    max_pages=20, # Maximum number of pages to crawl
    strategy="statistical"
)

async with AsyncWebCrawler() as crawler:
    adaptive_crawler = AdaptiveCrawler(crawler, config)
    state = await adaptive_crawler.digest(
        start_url="https://news.example.com",
        query="latest news content"
    )
# Crawler learns patterns and improves extraction over time
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🌊 Virtual Scroll Support&lt;/strong&gt;: Complete content extraction from infinite scroll pages:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;scroll_config = VirtualScrollConfig(
    container_selector="[data-testid='feed']",
    scroll_count=20,
    scroll_by="container_height",
    wait_after_scroll=1.0
)

result = await crawler.arun(url, config=CrawlerRunConfig(
    virtual_scroll_config=scroll_config
))
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔗 Intelligent Link Analysis&lt;/strong&gt;: 3-layer scoring system for smart link prioritization:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;link_config = LinkPreviewConfig(
    query="machine learning tutorials",
    score_threshold=0.3,
    concurrent_requests=10
)

result = await crawler.arun(url, config=CrawlerRunConfig(
    link_preview_config=link_config,
    score_links=True
))
# Links ranked by relevance and quality
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🎣 Async URL Seeder&lt;/strong&gt;: Discover thousands of URLs in seconds:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;seeder = AsyncUrlSeeder(SeedingConfig(
    source="sitemap+cc",
    pattern="*/blog/*",
    query="python tutorials",
    score_threshold=0.4
))

urls = await seeder.discover("https://example.com")
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;⚡ Performance Boost&lt;/strong&gt;: Up to 3x faster with optimized resource handling and memory efficiency&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read the full details in our &lt;a href="https://docs.crawl4ai.com/blog/release-v0.7.0"&gt;0.7.0 Release Notes&lt;/a&gt; or check the &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Previous Version: 0.6.0 Release Highlights&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🌎 World-aware Crawling&lt;/strong&gt;: Set geolocation, language, and timezone for authentic locale-specific content:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;  crun_cfg = CrawlerRunConfig(
      url="https://browserleaks.com/geo",          # test page that shows your location
      locale="en-US",                              # Accept-Language &amp;amp; UI locale
      timezone_id="America/Los_Angeles",           # JS Date()/Intl timezone
      geolocation=GeolocationConfig(                 # override GPS coords
          latitude=34.0522,
          longitude=-118.2437,
          accuracy=10.0,
      )
  )
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;📊 Table-to-DataFrame Extraction&lt;/strong&gt;: Extract HTML tables directly to CSV or pandas DataFrames:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;  crawler = AsyncWebCrawler(config=browser_config)
  await crawler.start()

  try:
      # Set up scraping parameters
      crawl_config = CrawlerRunConfig(
          table_score_threshold=8,  # Strict table detection
      )

      # Execute market data extraction
      results: List[CrawlResult] = await crawler.arun(
          url="https://coinmarketcap.com/?page=1", config=crawl_config
      )

      # Process results
      raw_df = pd.DataFrame()
      for result in results:
          if result.success and result.media["tables"]:
              raw_df = pd.DataFrame(
                  result.media["tables"][0]["rows"],
                  columns=result.media["tables"][0]["headers"],
              )
              break
      print(raw_df.head())

  finally:
      await crawler.stop()
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🚀 Browser Pooling&lt;/strong&gt;: Pages launch hot with pre-warmed browser instances for lower latency and memory usage&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🕸️ Network and Console Capture&lt;/strong&gt;: Full traffic logs and MHTML snapshots for debugging:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;crawler_config = CrawlerRunConfig(
    capture_network=True,
    capture_console=True,
    mhtml=True
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🔌 MCP Integration&lt;/strong&gt;: Connect to AI tools like Claude Code through the Model Context Protocol&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Add Crawl4AI to Claude Code
claude mcp add --transport sse c4ai-sse http://localhost:11235/mcp/sse
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🖥️ Interactive Playground&lt;/strong&gt;: Test configurations and generate API requests with the built-in web interface at &lt;code&gt;http://localhost:11235//playground&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;🐳 Revamped Docker Deployment&lt;/strong&gt;: Streamlined multi-architecture Docker image with improved resource efficiency&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;📱 Multi-stage Build System&lt;/strong&gt;: Optimized Dockerfile with platform-specific performance enhancements&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Previous Version: 0.5.0 Major Release Highlights&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;🚀 Deep Crawling System&lt;/strong&gt;: Explore websites beyond initial URLs with BFS, DFS, and BestFirst strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;⚡ Memory-Adaptive Dispatcher&lt;/strong&gt;: Dynamically adjusts concurrency based on system memory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🔄 Multiple Crawling Strategies&lt;/strong&gt;: Browser-based and lightweight HTTP-only crawlers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;💻 Command-Line Interface&lt;/strong&gt;: New &lt;code&gt;crwl&lt;/code&gt; CLI provides convenient terminal access&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;👤 Browser Profiler&lt;/strong&gt;: Create and manage persistent browser profiles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🧠 Crawl4AI Coding Assistant&lt;/strong&gt;: AI-powered coding assistant&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🏎️ LXML Scraping Mode&lt;/strong&gt;: Fast HTML parsing using the &lt;code&gt;lxml&lt;/code&gt; library&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🌐 Proxy Rotation&lt;/strong&gt;: Built-in support for proxy switching&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;🤖 LLM Content Filter&lt;/strong&gt;: Intelligent markdown generation using LLMs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;📄 PDF Processing&lt;/strong&gt;: Extract text, images, and metadata from PDF files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read the full details in our &lt;a href="https://docs.crawl4ai.com/blog/releases/0.5.0.html"&gt;0.5.0 Release Notes&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Version Numbering in Crawl4AI&lt;/h2&gt; 
&lt;p&gt;Crawl4AI follows standard Python version numbering conventions (PEP 440) to help users understand the stability and features of each release.&lt;/p&gt; 
&lt;h3&gt;Version Numbers Explained&lt;/h3&gt; 
&lt;p&gt;Our version numbers follow this pattern: &lt;code&gt;MAJOR.MINOR.PATCH&lt;/code&gt; (e.g., 0.4.3)&lt;/p&gt; 
&lt;h4&gt;Pre-release Versions&lt;/h4&gt; 
&lt;p&gt;We use different suffixes to indicate development stages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;dev&lt;/code&gt; (0.4.3dev1): Development versions, unstable&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;a&lt;/code&gt; (0.4.3a1): Alpha releases, experimental features&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b&lt;/code&gt; (0.4.3b1): Beta releases, feature complete but needs testing&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;rc&lt;/code&gt; (0.4.3): Release candidates, potential final version&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Installation&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Regular installation (stable version):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U crawl4ai
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install pre-release versions:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install crawl4ai --pre
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install specific version:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pip install crawl4ai==0.4.3b1
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Why Pre-releases?&lt;/h4&gt; 
&lt;p&gt;We use pre-releases to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Test new features in real-world scenarios&lt;/li&gt; 
 &lt;li&gt;Gather feedback before final releases&lt;/li&gt; 
 &lt;li&gt;Ensure stability for production users&lt;/li&gt; 
 &lt;li&gt;Allow early adopters to try new features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For production environments, we recommend using the stable version. For testing new features, you can opt-in to pre-releases using the &lt;code&gt;--pre&lt;/code&gt; flag.&lt;/p&gt; 
&lt;h2&gt;📖 Documentation &amp;amp; Roadmap&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🚨 &lt;strong&gt;Documentation Update Alert&lt;/strong&gt;: We're undertaking a major documentation overhaul next week to reflect recent updates and improvements. Stay tuned for a more comprehensive and up-to-date guide!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For current documentation, including installation instructions, advanced features, and API reference, visit our &lt;a href="https://docs.crawl4ai.com/"&gt;Documentation Website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To check our development plans and upcoming features, visit our &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/ROADMAP.md"&gt;Roadmap&lt;/a&gt;.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;📈 &lt;strong&gt;Development TODOs&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; 0. Graph Crawler: Smart website traversal using graph search algorithms for comprehensive nested page extraction&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; 1. Question-Based Crawler: Natural language driven web discovery and content extraction&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; 2. Knowledge-Optimal Crawler: Smart crawling that maximizes knowledge while minimizing data extraction&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; 3. Agentic Crawler: Autonomous system for complex multi-step crawling operations&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; 4. Automated Schema Generator: Convert natural language to extraction schemas&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; 5. Domain-Specific Scrapers: Pre-configured extractors for common platforms (academic, e-commerce)&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; 6. Web Embedding Index: Semantic search infrastructure for crawled content&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; 7. Interactive Playground: Web UI for testing, comparing strategies with AI assistance&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; 8. Performance Monitor: Real-time insights into crawler operations&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; 9. Cloud Integration: One-click deployment solutions across cloud providers&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; 10. Sponsorship Program: Structured support system with tiered benefits&lt;/li&gt; 
  &lt;li&gt;&lt;input type="checkbox" disabled&gt; 11. Educational Content: "How to Crawl" video series and interactive tutorials&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;🤝 Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from the open-source community. Check out our &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/CONTRIBUTORS.md"&gt;contribution guidelines&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;p&gt;I'll help modify the license section with badges. For the halftone effect, here's a version with it:&lt;/p&gt; 
&lt;p&gt;Here's the updated license section:&lt;/p&gt; 
&lt;h2&gt;📄 License &amp;amp; Attribution&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 with a required attribution clause. See the &lt;a href="https://github.com/unclecode/crawl4ai/raw/main/LICENSE"&gt;Apache 2.0 License&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h3&gt;Attribution Requirements&lt;/h3&gt; 
&lt;p&gt;When using Crawl4AI, you must include one of the following attribution methods:&lt;/p&gt; 
&lt;h4&gt;1. Badge Attribution (Recommended)&lt;/h4&gt; 
&lt;p&gt;Add one of these badges to your README, documentation, or website:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Theme&lt;/th&gt; 
   &lt;th&gt;Badge&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Disco Theme (Animated)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/unclecode/crawl4ai"&gt;&lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-disco.svg?sanitize=true" alt="Powered by Crawl4AI" width="200"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Night Theme (Dark with Neon)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/unclecode/crawl4ai"&gt;&lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-night.svg?sanitize=true" alt="Powered by Crawl4AI" width="200"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Dark Theme (Classic)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/unclecode/crawl4ai"&gt;&lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-dark.svg?sanitize=true" alt="Powered by Crawl4AI" width="200"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Light Theme (Classic)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/unclecode/crawl4ai"&gt;&lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-light.svg?sanitize=true" alt="Powered by Crawl4AI" width="200"&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;HTML code for adding the badges:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-html"&gt;&amp;lt;!-- Disco Theme (Animated) --&amp;gt;
&amp;lt;a href="https://github.com/unclecode/crawl4ai"&amp;gt;
  &amp;lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-disco.svg" alt="Powered by Crawl4AI" width="200"/&amp;gt;
&amp;lt;/a&amp;gt;

&amp;lt;!-- Night Theme (Dark with Neon) --&amp;gt;
&amp;lt;a href="https://github.com/unclecode/crawl4ai"&amp;gt;
  &amp;lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-night.svg" alt="Powered by Crawl4AI" width="200"/&amp;gt;
&amp;lt;/a&amp;gt;

&amp;lt;!-- Dark Theme (Classic) --&amp;gt;
&amp;lt;a href="https://github.com/unclecode/crawl4ai"&amp;gt;
  &amp;lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-dark.svg" alt="Powered by Crawl4AI" width="200"/&amp;gt;
&amp;lt;/a&amp;gt;

&amp;lt;!-- Light Theme (Classic) --&amp;gt;
&amp;lt;a href="https://github.com/unclecode/crawl4ai"&amp;gt;
  &amp;lt;img src="https://raw.githubusercontent.com/unclecode/crawl4ai/main/docs/assets/powered-by-light.svg" alt="Powered by Crawl4AI" width="200"/&amp;gt;
&amp;lt;/a&amp;gt;

&amp;lt;!-- Simple Shield Badge --&amp;gt;
&amp;lt;a href="https://github.com/unclecode/crawl4ai"&amp;gt;
  &amp;lt;img src="https://img.shields.io/badge/Powered%20by-Crawl4AI-blue?style=flat-square" alt="Powered by Crawl4AI"/&amp;gt;
&amp;lt;/a&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Text Attribution&lt;/h4&gt; 
&lt;p&gt;Add this line to your documentation:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;This project uses Crawl4AI (https://github.com/unclecode/crawl4ai) for web data extraction.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;📚 Citation&lt;/h2&gt; 
&lt;p&gt;If you use Crawl4AI in your research or project, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@software{crawl4ai2024,
  author = {UncleCode},
  title = {Crawl4AI: Open-source LLM Friendly Web Crawler &amp;amp; Scraper},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub Repository},
  howpublished = {\url{https://github.com/unclecode/crawl4ai}},
  commit = {Please use the commit hash you're working with}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Text citation format:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;UncleCode. (2024). Crawl4AI: Open-source LLM Friendly Web Crawler &amp;amp; Scraper [Computer software]. 
GitHub. https://github.com/unclecode/crawl4ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;📧 Contact&lt;/h2&gt; 
&lt;p&gt;For questions, suggestions, or feedback, feel free to reach out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub: &lt;a href="https://github.com/unclecode"&gt;unclecode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Twitter: &lt;a href="https://twitter.com/unclecode"&gt;@unclecode&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Website: &lt;a href="https://crawl4ai.com"&gt;crawl4ai.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Happy Crawling! 🕸️🚀&lt;/p&gt; 
&lt;h2&gt;🗾 Mission&lt;/h2&gt; 
&lt;p&gt;Our mission is to unlock the value of personal and enterprise data by transforming digital footprints into structured, tradeable assets. Crawl4AI empowers individuals and organizations with open-source tools to extract and structure data, fostering a shared data economy.&lt;/p&gt; 
&lt;p&gt;We envision a future where AI is powered by real human knowledge, ensuring data creators directly benefit from their contributions. By democratizing data and enabling ethical sharing, we are laying the foundation for authentic AI advancement.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;🔑 &lt;strong&gt;Key Opportunities&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Data Capitalization&lt;/strong&gt;: Transform digital footprints into measurable, valuable assets.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Authentic AI Data&lt;/strong&gt;: Provide AI systems with real human insights.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Shared Economy&lt;/strong&gt;: Create a fair data marketplace that benefits data creators.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;🚀 &lt;strong&gt;Development Pathway&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Open-Source Tools&lt;/strong&gt;: Community-driven platforms for transparent data extraction.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Digital Asset Structuring&lt;/strong&gt;: Tools to organize and value digital knowledge.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Ethical Data Marketplace&lt;/strong&gt;: A secure, fair platform for exchanging structured data.&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;For more details, see our &lt;a href="https://raw.githubusercontent.com/unclecode/crawl4ai/main/MISSION.md"&gt;full mission statement&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#unclecode/crawl4ai&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=unclecode/crawl4ai&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>getzep/graphiti</title>
      <link>https://github.com/getzep/graphiti</link>
      <description>&lt;p&gt;Build Real-Time Knowledge Graphs for AI Agents&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.getzep.com/"&gt; &lt;img src="https://github.com/user-attachments/assets/119c5682-9654-4257-8922-56b7cb8ffd73" width="150" alt="Zep Logo"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; Graphiti &lt;/h1&gt; 
&lt;h2 align="center"&gt; Build Real-Time Knowledge Graphs for AI Agents&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/getzep/Graphiti/actions/workflows/lint.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/lint.yml/badge.svg?style=flat" alt="Lint"&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/unit_tests.yml/badge.svg?sanitize=true" alt="Unit Tests"&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml"&gt;&lt;img src="https://github.com/getzep/Graphiti/actions/workflows/typecheck.yml/badge.svg?sanitize=true" alt="MyPy Check"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/github/stars/getzep/graphiti" alt="GitHub Repo stars"&gt; &lt;a href="https://discord.com/invite/W8Kw6bsgXQ"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord"&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2501.13956"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2501.13956-b31b1b.svg?style=flat" alt="arXiv"&gt;&lt;/a&gt; &lt;a href="https://github.com/getzep/graphiti/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/getzep/graphiti?style=flat&amp;amp;label=Release&amp;amp;color=limegreen" alt="Release"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/12986" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/12986" alt="getzep%2Fgraphiti | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;span&gt;⭐&lt;/span&gt; &lt;em&gt;Help us reach more developers and grow the Graphiti community. Star this repo!&lt;/em&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Check out the new &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md"&gt;MCP server for Graphiti&lt;/a&gt;! Give Claude, Cursor, and other MCP clients powerful Knowledge Graph-based memory.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Graphiti is a framework for building and querying temporally-aware knowledge graphs, specifically tailored for AI agents operating in dynamic environments. Unlike traditional retrieval-augmented generation (RAG) methods, Graphiti continuously integrates user interactions, structured and unstructured enterprise data, and external information into a coherent, queryable graph. The framework supports incremental data updates, efficient retrieval, and precise historical queries without requiring complete graph recomputation, making it suitable for developing interactive, context-aware AI applications.&lt;/p&gt; 
&lt;p&gt;Use Graphiti to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Integrate and maintain dynamic user interactions and business data.&lt;/li&gt; 
 &lt;li&gt;Facilitate state-based reasoning and task automation for agents.&lt;/li&gt; 
 &lt;li&gt;Query complex, evolving data with semantic, keyword, and graph-based search methods.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-graph-intro.gif" alt="Graphiti temporal walkthrough" width="700px"&gt; &lt;/p&gt; 
&lt;br&gt; 
&lt;p&gt;A knowledge graph is a network of interconnected facts, such as &lt;em&gt;"Kendra loves Adidas shoes."&lt;/em&gt; Each fact is a "triplet" represented by two entities, or nodes ("Kendra", "Adidas shoes"), and their relationship, or edge ("loves"). Knowledge Graphs have been explored extensively for information retrieval. What makes Graphiti unique is its ability to autonomously build a knowledge graph while handling changing relationships and maintaining historical context.&lt;/p&gt; 
&lt;h2&gt;Graphiti and Zep's Context Engineering Platform.&lt;/h2&gt; 
&lt;p&gt;Graphiti powers the core of &lt;a href="https://www.getzep.com"&gt;Zep&lt;/a&gt;, a turn-key context engineering platform for AI Agents. Zep offers agent memory, Graph RAG for dynamic data, and context retrieval and assembly.&lt;/p&gt; 
&lt;p&gt;Using Graphiti, we've demonstrated Zep is the &lt;a href="https://blog.getzep.com/state-of-the-art-agent-memory/"&gt;State of the Art in Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Read our paper: &lt;a href="https://arxiv.org/abs/2501.13956"&gt;Zep: A Temporal Knowledge Graph Architecture for Agent Memory&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We're excited to open-source Graphiti, believing its potential reaches far beyond AI memory applications.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://arxiv.org/abs/2501.13956"&gt;&lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/arxiv-screenshot.png" alt="Zep: A Temporal Knowledge Graph Architecture for Agent Memory" width="700px"&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Why Graphiti?&lt;/h2&gt; 
&lt;p&gt;Traditional RAG approaches often rely on batch processing and static data summarization, making them inefficient for frequently changing data. Graphiti addresses these challenges by providing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Incremental Updates:&lt;/strong&gt; Immediate integration of new data episodes without batch recomputation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bi-Temporal Data Model:&lt;/strong&gt; Explicit tracking of event occurrence and ingestion times, allowing accurate point-in-time queries.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Hybrid Retrieval:&lt;/strong&gt; Combines semantic embeddings, keyword (BM25), and graph traversal to achieve low-latency queries without reliance on LLM summarization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Entity Definitions:&lt;/strong&gt; Flexible ontology creation and support for developer-defined entities through straightforward Pydantic models.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalability:&lt;/strong&gt; Efficiently manages large datasets with parallel processing, suitable for enterprise environments.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/getzep/graphiti/main/images/graphiti-intro-slides-stock-2.gif" alt="Graphiti structured + unstructured demo" width="700px"&gt; &lt;/p&gt; 
&lt;h2&gt;Graphiti vs. GraphRAG&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Aspect&lt;/th&gt; 
   &lt;th&gt;GraphRAG&lt;/th&gt; 
   &lt;th&gt;Graphiti&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Primary Use&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Static document summarization&lt;/td&gt; 
   &lt;td&gt;Dynamic data management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Data Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Batch-oriented processing&lt;/td&gt; 
   &lt;td&gt;Continuous, incremental updates&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Knowledge Structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Entity clusters &amp;amp; community summaries&lt;/td&gt; 
   &lt;td&gt;Episodic data, semantic entities, communities&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Retrieval Method&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Sequential LLM summarization&lt;/td&gt; 
   &lt;td&gt;Hybrid semantic, keyword, and graph-based search&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Adaptability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Low&lt;/td&gt; 
   &lt;td&gt;High&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Temporal Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Basic timestamp tracking&lt;/td&gt; 
   &lt;td&gt;Explicit bi-temporal tracking&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Contradiction Handling&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM-driven summarization judgments&lt;/td&gt; 
   &lt;td&gt;Temporal edge invalidation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Query Latency&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Seconds to tens of seconds&lt;/td&gt; 
   &lt;td&gt;Typically sub-second latency&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Custom Entity Types&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes, customizable&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Moderate&lt;/td&gt; 
   &lt;td&gt;High, optimized for large datasets&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Graphiti is specifically designed to address the challenges of dynamic and frequently updated datasets, making it particularly suitable for applications requiring real-time interaction and precise historical queries.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python 3.10 or higher&lt;/li&gt; 
 &lt;li&gt;Neo4j 5.26 / FalkorDB 1.1.2 or higher (serves as the embeddings storage backend)&lt;/li&gt; 
 &lt;li&gt;OpenAI API key (Graphiti defaults to OpenAI for LLM inference and embedding)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti works best with LLM services that support Structured Output (such as OpenAI and Gemini). Using other services may result in incorrect output schemas and ingestion failures. This is particularly problematic when using smaller models.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Optional:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Google Gemini, Anthropic, or Groq API key (for alternative LLM providers)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The simplest way to install Neo4j is via &lt;a href="https://neo4j.com/download/"&gt;Neo4j Desktop&lt;/a&gt;. It provides a user-friendly interface to manage Neo4j instances and databases. Alternatively, you can use FalkorDB on-premises via Docker and instantly start with the quickstart example:&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -p 6379:6379 -p 3000:3000 -it --rm falkordb/falkordb:latest

&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add graphiti-core
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing with FalkorDB Support&lt;/h3&gt; 
&lt;p&gt;If you plan to use FalkorDB as your graph database backend, install with the FalkorDB extra:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install graphiti-core[falkordb]

# or with uv
uv add graphiti-core[falkordb]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;You can also install optional LLM providers as extras:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install with Anthropic support
pip install graphiti-core[anthropic]

# Install with Groq support
pip install graphiti-core[groq]

# Install with Google Gemini support
pip install graphiti-core[google-genai]

# Install with multiple providers
pip install graphiti-core[anthropic,groq,google-genai]

# Install with FalkorDB and LLM providers
pip install graphiti-core[falkordb,anthropic,google-genai]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Default to Low Concurrency; LLM Provider 429 Rate Limit Errors&lt;/h2&gt; 
&lt;p&gt;Graphiti's ingestion pipelines are designed for high concurrency. By default, concurrency is set low to avoid LLM Provider 429 Rate Limit Errors. If you find Graphiti slow, please increase concurrency as described below.&lt;/p&gt; 
&lt;p&gt;Concurrency controlled by the &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; environment variable. By default, &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; is set to &lt;code&gt;10&lt;/code&gt; concurrent operations to help prevent &lt;code&gt;429&lt;/code&gt; rate limit errors from your LLM provider. If you encounter such errors, try lowering this value.&lt;/p&gt; 
&lt;p&gt;If your LLM provider allows higher throughput, you can increase &lt;code&gt;SEMAPHORE_LIMIT&lt;/code&gt; to boost episode ingestion performance.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Graphiti defaults to using OpenAI for LLM inference and embedding. Ensure that an &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; is set in your environment. Support for Anthropic and Groq LLM inferences is available, too. Other LLM providers may be supported via OpenAI compatible APIs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For a complete working example, see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/examples/quickstart/README.md"&gt;Quickstart Example&lt;/a&gt; in the examples directory. The quickstart demonstrates:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Connecting to a Neo4j or FalkorDB database&lt;/li&gt; 
 &lt;li&gt;Initializing Graphiti indices and constraints&lt;/li&gt; 
 &lt;li&gt;Adding episodes to the graph (both text and structured JSON)&lt;/li&gt; 
 &lt;li&gt;Searching for relationships (edges) using hybrid search&lt;/li&gt; 
 &lt;li&gt;Reranking search results using graph distance&lt;/li&gt; 
 &lt;li&gt;Searching for nodes using predefined search recipes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The example is fully documented with clear explanations of each functionality and includes a comprehensive README with setup instructions and next steps.&lt;/p&gt; 
&lt;h2&gt;MCP Server&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;mcp_server&lt;/code&gt; directory contains a Model Context Protocol (MCP) server implementation for Graphiti. This server allows AI assistants to interact with Graphiti's knowledge graph capabilities through the MCP protocol.&lt;/p&gt; 
&lt;p&gt;Key features of the MCP server include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Episode management (add, retrieve, delete)&lt;/li&gt; 
 &lt;li&gt;Entity management and relationship handling&lt;/li&gt; 
 &lt;li&gt;Semantic and hybrid search capabilities&lt;/li&gt; 
 &lt;li&gt;Group management for organizing related data&lt;/li&gt; 
 &lt;li&gt;Graph maintenance operations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The MCP server can be deployed using Docker with Neo4j, making it easy to integrate Graphiti into your AI assistant workflows.&lt;/p&gt; 
&lt;p&gt;For detailed setup instructions and usage examples, see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/mcp_server/README.md"&gt;MCP server README&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;REST Service&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;server&lt;/code&gt; directory contains an API service for interacting with the Graphiti API. It is built using FastAPI.&lt;/p&gt; 
&lt;p&gt;Please see the &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/server/README.md"&gt;server README&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Optional Environment Variables&lt;/h2&gt; 
&lt;p&gt;In addition to the Neo4j and OpenAi-compatible credentials, Graphiti also has a few optional environment variables. If you are using one of our supported models, such as Anthropic or Voyage models, the necessary environment variables must be set.&lt;/p&gt; 
&lt;h3&gt;Database Configuration&lt;/h3&gt; 
&lt;p&gt;Database names are configured directly in the driver constructors:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Neo4j&lt;/strong&gt;: Database name defaults to &lt;code&gt;neo4j&lt;/code&gt; (hardcoded in Neo4jDriver)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FalkorDB&lt;/strong&gt;: Database name defaults to &lt;code&gt;default_db&lt;/code&gt; (hardcoded in FalkorDriver)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;As of v0.17.0, if you need to customize your database configuration, you can instantiate a database driver and pass it to the Graphiti constructor using the &lt;code&gt;graph_driver&lt;/code&gt; parameter.&lt;/p&gt; 
&lt;h4&gt;Neo4j with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.driver.neo4j_driver import Neo4jDriver

# Create a Neo4j driver with custom database name
driver = Neo4jDriver(
    uri="bolt://localhost:7687",
    user="neo4j",
    password="password",
    database="my_custom_database"  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;FalkorDB with Custom Database Name&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.driver.falkordb_driver import FalkorDriver

# Create a FalkorDB driver with custom database name
driver = FalkorDriver(
    host="localhost",
    port=6379,
    username="falkor_user",  # Optional
    password="falkor_password",  # Optional
    database="my_custom_graph"  # Custom database name
)

# Pass the driver to Graphiti
graphiti = Graphiti(graph_driver=driver)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Performance Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;USE_PARALLEL_RUNTIME&lt;/code&gt; is an optional boolean variable that can be set to true if you wish to enable Neo4j's parallel runtime feature for several of our search queries. Note that this feature is not supported for Neo4j Community edition or for smaller AuraDB instances, as such this feature is off by default.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Azure OpenAI&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Azure OpenAI for both LLM inference and embeddings. Azure deployments often require different endpoints for LLM and embedding services, and separate deployments for default and small models.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import AsyncAzureOpenAI
from graphiti_core import Graphiti
from graphiti_core.llm_client import LLMConfig, OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Azure OpenAI configuration - use separate endpoints for different services
api_key = "&amp;lt;your-api-key&amp;gt;"
api_version = "&amp;lt;your-api-version&amp;gt;"
llm_endpoint = "&amp;lt;your-llm-endpoint&amp;gt;"  # e.g., "https://your-llm-resource.openai.azure.com/"
embedding_endpoint = "&amp;lt;your-embedding-endpoint&amp;gt;"  # e.g., "https://your-embedding-resource.openai.azure.com/"

# Create separate Azure OpenAI clients for different services
llm_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=llm_endpoint
)

embedding_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=embedding_endpoint
)

# Create LLM Config with your Azure deployment names
azure_llm_config = LLMConfig(
    small_model="gpt-4.1-nano",
    model="gpt-4.1-mini",
)

# Initialize Graphiti with Azure OpenAI clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=OpenAIClient(
        llm_config=azure_llm_config,
        client=llm_client_azure
    ),
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            embedding_model="text-embedding-3-small-deployment"  # Your Azure embedding deployment name
        ),
        client=embedding_client_azure
    ),
    cross_encoder=OpenAIRerankerClient(
        llm_config=LLMConfig(
            model=azure_llm_config.small_model  # Use small model for reranking
        ),
        client=llm_client_azure
    )
)

# Now you can use Graphiti with Azure OpenAI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Make sure to replace the placeholder values with your actual Azure OpenAI credentials and deployment names that match your Azure OpenAI service configuration.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Google Gemini&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Google's Gemini models for LLM inference, embeddings, and cross-encoding/reranking. To use Gemini, you'll need to configure the LLM client, embedder, and the cross-encoder with your Google API key.&lt;/p&gt; 
&lt;p&gt;Install Graphiti:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add "graphiti-core[google-genai]"

# or

pip install "graphiti-core[google-genai]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.gemini_client import GeminiClient, LLMConfig
from graphiti_core.embedder.gemini import GeminiEmbedder, GeminiEmbedderConfig
from graphiti_core.cross_encoder.gemini_reranker_client import GeminiRerankerClient

# Google API key configuration
api_key = "&amp;lt;your-google-api-key&amp;gt;"

# Initialize Graphiti with Gemini clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=GeminiClient(
        config=LLMConfig(
            api_key=api_key,
            model="gemini-2.0-flash"
        )
    ),
    embedder=GeminiEmbedder(
        config=GeminiEmbedderConfig(
            api_key=api_key,
            embedding_model="embedding-001"
        )
    ),
    cross_encoder=GeminiRerankerClient(
        config=LLMConfig(
            api_key=api_key,
            model="gemini-2.5-flash-lite-preview-06-17"
        )
    )
)

# Now you can use Graphiti with Google Gemini for all components
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Gemini reranker uses the &lt;code&gt;gemini-2.5-flash-lite-preview-06-17&lt;/code&gt; model by default, which is optimized for cost-effective and low-latency classification tasks. It uses the same boolean classification approach as the OpenAI reranker, leveraging Gemini's log probabilities feature to rank passage relevance.&lt;/p&gt; 
&lt;h2&gt;Using Graphiti with Ollama (Local LLM)&lt;/h2&gt; 
&lt;p&gt;Graphiti supports Ollama for running local LLMs and embedding models via Ollama's OpenAI-compatible API. This is ideal for privacy-focused applications or when you want to avoid API costs.&lt;/p&gt; 
&lt;p&gt;Install the models: ollama pull deepseek-r1:7b # LLM ollama pull nomic-embed-text # embeddings&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from graphiti_core import Graphiti
from graphiti_core.llm_client.config import LLMConfig
from graphiti_core.llm_client.openai_client import OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Configure Ollama LLM client
llm_config = LLMConfig(
    api_key="abc",  # Ollama doesn't require a real API key
    model="deepseek-r1:7b",
    small_model="deepseek-r1:7b",
    base_url="http://localhost:11434/v1", # Ollama provides this port
)

llm_client = OpenAIClient(config=llm_config)

# Initialize Graphiti with Ollama clients
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=llm_client,
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            api_key="abc",
            embedding_model="nomic-embed-text",
            embedding_dim=768,
            base_url="http://localhost:11434/v1",
        )
    ),
    cross_encoder=OpenAIRerankerClient(client=llm_client, config=llm_config),
)

# Now you can use Graphiti with local Ollama models
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ensure Ollama is running (&lt;code&gt;ollama serve&lt;/code&gt;) and that you have pulled the models you want to use.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti"&gt;Guides and API documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti/graphiti/quick-start"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://help.getzep.com/graphiti/graphiti/lang-graph-agent"&gt;Building an agent with LangChain's LangGraph and Graphiti&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;Graphiti collects anonymous usage statistics to help us understand how the framework is being used and improve it for everyone. We believe transparency is important, so here's exactly what we collect and why.&lt;/p&gt; 
&lt;h3&gt;What We Collect&lt;/h3&gt; 
&lt;p&gt;When you initialize a Graphiti instance, we collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Anonymous identifier&lt;/strong&gt;: A randomly generated UUID stored locally in &lt;code&gt;~/.cache/graphiti/telemetry_anon_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;System information&lt;/strong&gt;: Operating system, Python version, and system architecture&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Graphiti version&lt;/strong&gt;: The version you're using&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configuration choices&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;LLM provider type (OpenAI, Azure, Anthropic, etc.)&lt;/li&gt; 
   &lt;li&gt;Database backend (Neo4j, FalkorDB)&lt;/li&gt; 
   &lt;li&gt;Embedder provider (OpenAI, Azure, Voyage, etc.)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;What We Don't Collect&lt;/h3&gt; 
&lt;p&gt;We are committed to protecting your privacy. We &lt;strong&gt;never&lt;/strong&gt; collect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Personal information or identifiers&lt;/li&gt; 
 &lt;li&gt;API keys or credentials&lt;/li&gt; 
 &lt;li&gt;Your actual data, queries, or graph content&lt;/li&gt; 
 &lt;li&gt;IP addresses or hostnames&lt;/li&gt; 
 &lt;li&gt;File paths or system-specific information&lt;/li&gt; 
 &lt;li&gt;Any content from your episodes, nodes, or edges&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Why We Collect This Data&lt;/h3&gt; 
&lt;p&gt;This information helps us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Understand which configurations are most popular to prioritize support and testing&lt;/li&gt; 
 &lt;li&gt;Identify which LLM and database providers to focus development efforts on&lt;/li&gt; 
 &lt;li&gt;Track adoption patterns to guide our roadmap&lt;/li&gt; 
 &lt;li&gt;Ensure compatibility across different Python versions and operating systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By sharing this anonymous information, you help us make Graphiti better for everyone in the community.&lt;/p&gt; 
&lt;h3&gt;View the Telemetry Code&lt;/h3&gt; 
&lt;p&gt;The Telemetry code &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/graphiti_core/telemetry/telemetry.py"&gt;may be found here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;How to Disable Telemetry&lt;/h3&gt; 
&lt;p&gt;Telemetry is &lt;strong&gt;opt-out&lt;/strong&gt; and can be disabled at any time. To disable telemetry collection:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option 1: Environment Variable&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export GRAPHITI_TELEMETRY_ENABLED=false
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 2: Set in your shell profile&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For bash users (~/.bashrc or ~/.bash_profile)
echo 'export GRAPHITI_TELEMETRY_ENABLED=false' &amp;gt;&amp;gt; ~/.bashrc

# For zsh users (~/.zshrc)
echo 'export GRAPHITI_TELEMETRY_ENABLED=false' &amp;gt;&amp;gt; ~/.zshrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option 3: Set for a specific Python session&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import os
os.environ['GRAPHITI_TELEMETRY_ENABLED'] = 'false'

# Then initialize Graphiti as usual
from graphiti_core import Graphiti
graphiti = Graphiti(...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Telemetry is automatically disabled during test runs (when &lt;code&gt;pytest&lt;/code&gt; is detected).&lt;/p&gt; 
&lt;h3&gt;Technical Details&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Telemetry uses PostHog for anonymous analytics collection&lt;/li&gt; 
 &lt;li&gt;All telemetry operations are designed to fail silently - they will never interrupt your application or affect Graphiti functionality&lt;/li&gt; 
 &lt;li&gt;The anonymous ID is stored locally and is not tied to any personal information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Status and Roadmap&lt;/h2&gt; 
&lt;p&gt;Graphiti is under active development. We aim to maintain API stability while working on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Supporting custom graph schemas: 
  &lt;ul&gt; 
   &lt;li&gt;Allow developers to provide their own defined node and edge classes when ingesting episodes&lt;/li&gt; 
   &lt;li&gt;Enable more flexible knowledge representation tailored to specific use cases&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Enhancing retrieval capabilities with more robust and configurable options&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled&gt; Graphiti MCP Server&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled&gt; Expanding test coverage to ensure reliability and catch edge cases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We encourage and appreciate all forms of contributions, whether it's code, documentation, addressing GitHub Issues, or answering questions in the Graphiti Discord channel. For detailed guidelines on code contributions, please refer to &lt;a href="https://raw.githubusercontent.com/getzep/graphiti/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href="https://discord.com/invite/W8Kw6bsgXQ"&gt;Zep Discord server&lt;/a&gt; and make your way to the &lt;strong&gt;#Graphiti&lt;/strong&gt; channel!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>langchain-ai/open_deep_research</title>
      <link>https://github.com/langchain-ai/open_deep_research</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Open Deep Research&lt;/h1&gt; 
&lt;img width="1388" height="298" alt="full_diagram" src="https://github.com/user-attachments/assets/12a2371b-8be2-4219-9b48-90503eb43c69"&gt; 
&lt;p&gt;Deep research has broken out as one of the most popular agent applications. This is a simple, configurable, fully open source deep research agent that works across many model providers, search tools, and MCP servers.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read more in our &lt;a href="https://blog.langchain.com/open-deep-research/"&gt;blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;See our &lt;a href="https://www.youtube.com/watch?v=agGiWUpxkhg"&gt;video&lt;/a&gt; for a quick overview&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🚀 Quickstart&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository and activate a virtual environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/langchain-ai/open_deep_research.git
cd open_deep_research
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv pip install -r pyproject.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up your &lt;code&gt;.env&lt;/code&gt; file to customize the environment variables (for model selection, search tools, and other configuration settings):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Launch the assistant with the LangGraph server locally to open LangGraph Studio in your browser:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies and start the LangGraph server
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.11 langgraph dev --allow-blocking
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use this to open the Studio UI:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;- 🚀 API: http://127.0.0.1:2024
- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- 📚 API Docs: http://127.0.0.1:2024/docs
&lt;/code&gt;&lt;/pre&gt; 
&lt;img width="817" height="666" alt="Screenshot 2025-07-13 at 11 21 12 PM" src="https://github.com/user-attachments/assets/052f2ed3-c664-4a4f-8ec2-074349dcaa3f"&gt; 
&lt;p&gt;Ask a question in the &lt;code&gt;messages&lt;/code&gt; input field and click &lt;code&gt;Submit&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Configurations&lt;/h3&gt; 
&lt;p&gt;Open Deep Research offers extensive configuration options to customize the research process and model behavior. All configurations can be set via the web UI, environment variables, or by modifying the configuration directly.&lt;/p&gt; 
&lt;h4&gt;General Settings&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Max Structured Output Retries&lt;/strong&gt; (default: 3): Maximum number of retries for structured output calls from models when parsing fails&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Allow Clarification&lt;/strong&gt; (default: true): Whether to allow the researcher to ask clarifying questions before starting research&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Max Concurrent Research Units&lt;/strong&gt; (default: 5): Maximum number of research units to run concurrently using sub-agents. Higher values enable faster research but may hit rate limits&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Research Configuration&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Search API&lt;/strong&gt; (default: Tavily): Choose from Tavily (works with all models), OpenAI Native Web Search, Anthropic Native Web Search, or None&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Max Researcher Iterations&lt;/strong&gt; (default: 3): Number of times the Research Supervisor will reflect on research and ask follow-up questions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Max React Tool Calls&lt;/strong&gt; (default: 5): Maximum number of tool calling iterations in a single researcher step&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Models&lt;/h4&gt; 
&lt;p&gt;Open Deep Research uses multiple specialized models for different research tasks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Summarization Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1-nano&lt;/code&gt;): Summarizes research results from search APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Research Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Conducts research and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compression Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1-mini&lt;/code&gt;): Compresses research findings from sub-agents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Final Report Model&lt;/strong&gt; (default: &lt;code&gt;openai:gpt-4.1&lt;/code&gt;): Writes the final comprehensive report&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All models are configured using &lt;a href="https://python.langchain.com/docs/how_to/chat_models_universal_init/"&gt;init_chat_model() API&lt;/a&gt; which supports providers like OpenAI, Anthropic, Google Vertex AI, and others.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important Model Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Structured Outputs&lt;/strong&gt;: All models must support structured outputs. Check support &lt;a href="https://python.langchain.com/docs/integrations/chat/"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Search API Compatibility&lt;/strong&gt;: Research and Compression models must support your selected search API:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Anthropic search requires Anthropic models with web search capability&lt;/li&gt; 
   &lt;li&gt;OpenAI search requires OpenAI models with web search capability&lt;/li&gt; 
   &lt;li&gt;Tavily works with all models&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tool Calling&lt;/strong&gt;: All models must support tool calling functionality&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Special Configurations&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;For OpenRouter: Follow &lt;a href="https://github.com/langchain-ai/open_deep_research/issues/75#issuecomment-2811472408"&gt;this guide&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;For local models via Ollama: See &lt;a href="https://github.com/langchain-ai/open_deep_research/issues/65#issuecomment-2743586318"&gt;setup instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Example MCP (Model Context Protocol) Servers&lt;/h4&gt; 
&lt;p&gt;Open Deep Research supports MCP servers to extend research capabilities.&lt;/p&gt; 
&lt;h4&gt;Local MCP Servers&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Filesystem MCP Server&lt;/strong&gt; provides secure file system operations with robust access control:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read, write, and manage files and directories&lt;/li&gt; 
 &lt;li&gt;Perform operations like reading file contents, creating directories, moving files, and searching&lt;/li&gt; 
 &lt;li&gt;Restrict operations to predefined directories for security&lt;/li&gt; 
 &lt;li&gt;Support for both command-line configuration and dynamic MCP roots&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mcp-server-filesystem /path/to/allowed/dir1 /path/to/allowed/dir2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Remote MCP Servers&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Remote MCP servers&lt;/strong&gt; enable distributed agent coordination and support streamable HTTP requests. Unlike local servers, they can be multi-tenant and require more complex authentication.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Arcade MCP Server Example&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "url": "https://api.arcade.dev/v1/mcps/ms_0ujssxh0cECutqzMgbtXSGnjorm",
  "tools": ["Search_SearchHotels", "Search_SearchOneWayFlights", "Search_SearchRoundtripFlights"]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Remote servers can be configured as authenticated or unauthenticated and support JWT-based authentication through OAuth endpoints.&lt;/p&gt; 
&lt;h3&gt;Evaluation&lt;/h3&gt; 
&lt;p&gt;A comprehensive batch evaluation system designed for detailed analysis and comparative studies.&lt;/p&gt; 
&lt;h4&gt;&lt;strong&gt;Features:&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-dimensional Scoring&lt;/strong&gt;: Specialized evaluators with 0-1 scale ratings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dataset-driven Evaluation&lt;/strong&gt;: Batch processing across multiple test cases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;strong&gt;Usage:&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run comprehensive evaluation on LangSmith datasets
python tests/run_evaluate.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;strong&gt;Key Files:&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tests/run_evaluate.py&lt;/code&gt;: Main evaluation script&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tests/evaluators.py&lt;/code&gt;: Specialized evaluator functions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tests/prompts.py&lt;/code&gt;: Evaluation prompts for each dimension&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deployments and Usages&lt;/h3&gt; 
&lt;h4&gt;LangGraph Studio&lt;/h4&gt; 
&lt;p&gt;Follow the &lt;a href="https://raw.githubusercontent.com/langchain-ai/open_deep_research/main/#-quickstart"&gt;quickstart&lt;/a&gt; to start LangGraph server locally and test the agent out on LangGraph Studio.&lt;/p&gt; 
&lt;h4&gt;Hosted deployment&lt;/h4&gt; 
&lt;p&gt;You can easily deploy to &lt;a href="https://langchain-ai.github.io/langgraph/concepts/#deployment-options"&gt;LangGraph Platform&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Open Agent Platform&lt;/h4&gt; 
&lt;p&gt;Open Agent Platform (OAP) is a UI from which non-technical users can build and configure their own agents. OAP is great for allowing users to configure the Deep Researcher with different MCP tools and search APIs that are best suited to their needs and the problems that they want to solve.&lt;/p&gt; 
&lt;p&gt;We've deployed Open Deep Research to our public demo instance of OAP. All you need to do is add your API Keys, and you can test out the Deep Researcher for yourself! Try it out &lt;a href="https://oap.langchain.com"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also deploy your own instance of OAP, and make your own custom agents (like Deep Researcher) available on it to your users.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.oap.langchain.com/quickstart"&gt;Deploy Open Agent Platform&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.oap.langchain.com/setup/agents"&gt;Add Deep Researcher to OAP&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Updates 🔥&lt;/h3&gt; 
&lt;h3&gt;Legacy Implementations 🏛️&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;src/legacy/&lt;/code&gt; folder contains two earlier implementations that provide alternative approaches to automated research:&lt;/p&gt; 
&lt;h4&gt;1. Workflow Implementation (&lt;code&gt;legacy/graph.py&lt;/code&gt;)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Plan-and-Execute&lt;/strong&gt;: Structured workflow with human-in-the-loop planning&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sequential Processing&lt;/strong&gt;: Creates sections one by one with reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Control&lt;/strong&gt;: Allows feedback and approval of report plans&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality Focused&lt;/strong&gt;: Emphasizes accuracy through iterative refinement&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;2. Multi-Agent Implementation (&lt;code&gt;legacy/multi_agent.py&lt;/code&gt;)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Supervisor-Researcher Architecture&lt;/strong&gt;: Coordinated multi-agent system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel Processing&lt;/strong&gt;: Multiple researchers work simultaneously&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Speed Optimized&lt;/strong&gt;: Faster report generation through concurrency&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Support&lt;/strong&gt;: Extensive Model Context Protocol integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;code&gt;src/legacy/legacy.md&lt;/code&gt; for detailed documentation, configuration options, and usage examples for both legacy implementations.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>vllm-project/vllm</title>
      <link>https://github.com/vllm-project/vllm</link>
      <description>&lt;p&gt;A high-throughput and memory-efficient inference and serving engine for LLMs&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-dark.png"&gt; 
  &lt;img alt="vLLM" src="https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-light.png" width="55%"&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; Easy, fast, and cheap LLM serving for everyone &lt;/h3&gt; 
&lt;p align="center"&gt; | &lt;a href="https://docs.vllm.ai"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://blog.vllm.ai/"&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://arxiv.org/abs/2309.06180"&gt;&lt;b&gt;Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://x.com/vllm_project"&gt;&lt;b&gt;Twitter/X&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://discuss.vllm.ai"&gt;&lt;b&gt;User Forum&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://slack.vllm.ai"&gt;&lt;b&gt;Developer Slack&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;hr&gt; 
&lt;p&gt;&lt;em&gt;Latest News&lt;/em&gt; 🔥&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;[2025/05] We hosted &lt;a href="https://lu.ma/c1rqyf1f"&gt;NYC vLLM Meetup&lt;/a&gt;! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1_q_aW_ioMJWUImf1s1YM-ZhjXz8cUeL0IJvaquOYBeA/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/05] vLLM is now a hosted project under PyTorch Foundation! Please find the announcement &lt;a href="https://pytorch.org/blog/pytorch-foundation-welcomes-vllm/"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/04] We hosted &lt;a href="https://www.sginnovate.com/event/limited-availability-morning-evening-slots-remaining-inaugural-vllm-asia-developer-day"&gt;Asia Developer Day&lt;/a&gt;! Please find the meetup slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/19cp6Qu8u48ihB91A064XfaXruNYiBOUKrBxAmDOllOo/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;[2025/01] We are excited to announce the alpha release of vLLM V1: A major architectural upgrade with 1.7x speedup! Clean code, optimized execution loop, zero-overhead prefix caching, enhanced multimodal support, and more. Please check out our blog post &lt;a href="https://blog.vllm.ai/2025/01/27/v1-alpha-release.html"&gt;here&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Previous News&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://lu.ma/vllm-ollama"&gt;vLLM x Ollama Inference Night&lt;/a&gt;! Please find the meetup slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/16T2PDD1YwRnZ4Tu8Q5r6n53c5Lr5c73UV9Vd2_eBo4U/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://mp.weixin.qq.com/s/n77GibL2corAtQHtVEAzfg"&gt;the first vLLM China Meetup&lt;/a&gt;! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1REHvfQMKGnvz6p3Fd23HhSO4c8j5WPGZV0bKYLwnHyQ/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/03] We hosted &lt;a href="https://lu.ma/7mu4k4xx"&gt;the East Coast vLLM Meetup&lt;/a&gt;! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1NHiv8EUFF1NLd3fEYODm56nDmL26lEeXCaDgyDlTsRs/edit#slide=id.g31441846c39_0_0"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2025/02] We hosted &lt;a href="https://lu.ma/h7g3kuj9"&gt;the ninth vLLM meetup&lt;/a&gt; with Meta! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1jzC_PZVXrVNSFVCW-V4cFXb6pn7zZ2CyP_Flwo05aqg/edit?usp=sharing"&gt;here&lt;/a&gt; and AMD &lt;a href="https://drive.google.com/file/d/1Zk5qEJIkTmlQ2eQcXQZlljAx3m9s7nwn/view?usp=sharing"&gt;here&lt;/a&gt;. The slides from Meta will not be posted.&lt;/li&gt; 
  &lt;li&gt;[2025/01] We hosted &lt;a href="https://lu.ma/zep56hui"&gt;the eighth vLLM meetup&lt;/a&gt; with Google Cloud! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1epVkt4Zu8Jz_S5OhEHPc798emsYh2BwYfRuDDVEF7u4/edit?usp=sharing"&gt;here&lt;/a&gt;, and Google Cloud team &lt;a href="https://drive.google.com/file/d/1h24pHewANyRL11xy5dXUbvRC9F9Kkjix/view?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/12] vLLM joins &lt;a href="https://pytorch.org/blog/vllm-joins-pytorch"&gt;pytorch ecosystem&lt;/a&gt;! Easy, Fast, and Cheap LLM Serving for Everyone!&lt;/li&gt; 
  &lt;li&gt;[2024/11] We hosted &lt;a href="https://lu.ma/h0qvrajz"&gt;the seventh vLLM meetup&lt;/a&gt; with Snowflake! Please find the meetup slides from vLLM team &lt;a href="https://docs.google.com/presentation/d/1e3CxQBV3JsfGp30SwyvS3eM_tW-ghOhJ9PAJGK6KR54/edit?usp=sharing"&gt;here&lt;/a&gt;, and Snowflake team &lt;a href="https://docs.google.com/presentation/d/1qF3RkDAbOULwz9WK5TOltt2fE9t6uIc_hVNLFAaQX6A/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/10] We have just created a developer slack (&lt;a href="https://slack.vllm.ai"&gt;slack.vllm.ai&lt;/a&gt;) focusing on coordinating contributions and discussing features. Please feel free to join us there!&lt;/li&gt; 
  &lt;li&gt;[2024/10] Ray Summit 2024 held a special track for vLLM! Please find the opening talk slides from the vLLM team &lt;a href="https://docs.google.com/presentation/d/1B_KQxpHBTRa_mDF-tR6i8rWdOU5QoTZNcEg2MKZxEHM/edit?usp=sharing"&gt;here&lt;/a&gt;. Learn more from the &lt;a href="https://www.youtube.com/playlist?list=PLzTswPQNepXl6AQwifuwUImLPFRVpksjR"&gt;talks&lt;/a&gt; from other vLLM contributors and users!&lt;/li&gt; 
  &lt;li&gt;[2024/09] We hosted &lt;a href="https://lu.ma/87q3nvnh"&gt;the sixth vLLM meetup&lt;/a&gt; with NVIDIA! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1wrLGwytQfaOTd5wCGSPNhoaW3nq0E-9wqyP7ny93xRs/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/07] We hosted &lt;a href="https://lu.ma/lp0gyjqr"&gt;the fifth vLLM meetup&lt;/a&gt; with AWS! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1RgUD8aCfcHocghoP3zmXzck9vX3RCI9yfUAB2Bbcl4Y/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/07] In partnership with Meta, vLLM officially supports Llama 3.1 with FP8 quantization and pipeline parallelism! Please check out our blog post &lt;a href="https://blog.vllm.ai/2024/07/23/llama31.html"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/06] We hosted &lt;a href="https://lu.ma/agivllm"&gt;the fourth vLLM meetup&lt;/a&gt; with Cloudflare and BentoML! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1iJ8o7V2bQEi0BFEljLTwc5G1S10_Rhv3beed5oB0NJ4/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/04] We hosted &lt;a href="https://robloxandvllmmeetup2024.splashthat.com/"&gt;the third vLLM meetup&lt;/a&gt; with Roblox! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1A--47JAK4BJ39t954HyTkvtfwn0fkqtsL8NGFuslReM/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2024/01] We hosted &lt;a href="https://lu.ma/ygxbpzhl"&gt;the second vLLM meetup&lt;/a&gt; with IBM! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/12mI2sKABnUw5RBWXDYY-HtHth4iMSNcEoQ10jDQbxgA/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2023/10] We hosted &lt;a href="https://lu.ma/first-vllm-meetup"&gt;the first vLLM meetup&lt;/a&gt; with a16z! Please find the meetup slides &lt;a href="https://docs.google.com/presentation/d/1QL-XPFXiFpDBh86DbEegFXBXFXjix4v032GhShbKf3s/edit?usp=sharing"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;[2023/08] We would like to express our sincere gratitude to &lt;a href="https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/"&gt;Andreessen Horowitz&lt;/a&gt; (a16z) for providing a generous grant to support the open-source development and research of vLLM.&lt;/li&gt; 
  &lt;li&gt;[2023/06] We officially released vLLM! FastChat-vLLM integration has powered &lt;a href="https://chat.lmsys.org"&gt;LMSYS Vicuna and Chatbot Arena&lt;/a&gt; since mid-April. Check out our &lt;a href="https://vllm.ai"&gt;blog post&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr&gt; 
&lt;h2&gt;About&lt;/h2&gt; 
&lt;p&gt;vLLM is a fast and easy-to-use library for LLM inference and serving.&lt;/p&gt; 
&lt;p&gt;Originally developed in the &lt;a href="https://sky.cs.berkeley.edu"&gt;Sky Computing Lab&lt;/a&gt; at UC Berkeley, vLLM has evolved into a community-driven project with contributions from both academia and industry.&lt;/p&gt; 
&lt;p&gt;vLLM is fast with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;State-of-the-art serving throughput&lt;/li&gt; 
 &lt;li&gt;Efficient management of attention key and value memory with &lt;a href="https://blog.vllm.ai/2023/06/20/vllm.html"&gt;&lt;strong&gt;PagedAttention&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Continuous batching of incoming requests&lt;/li&gt; 
 &lt;li&gt;Fast model execution with CUDA/HIP graph&lt;/li&gt; 
 &lt;li&gt;Quantizations: &lt;a href="https://arxiv.org/abs/2210.17323"&gt;GPTQ&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2306.00978"&gt;AWQ&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/2309.05516"&gt;AutoRound&lt;/a&gt;, INT4, INT8, and FP8&lt;/li&gt; 
 &lt;li&gt;Optimized CUDA kernels, including integration with FlashAttention and FlashInfer&lt;/li&gt; 
 &lt;li&gt;Speculative decoding&lt;/li&gt; 
 &lt;li&gt;Chunked prefill&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM is flexible and easy to use with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Seamless integration with popular Hugging Face models&lt;/li&gt; 
 &lt;li&gt;High-throughput serving with various decoding algorithms, including &lt;em&gt;parallel sampling&lt;/em&gt;, &lt;em&gt;beam search&lt;/em&gt;, and more&lt;/li&gt; 
 &lt;li&gt;Tensor, pipeline, data and expert parallelism support for distributed inference&lt;/li&gt; 
 &lt;li&gt;Streaming outputs&lt;/li&gt; 
 &lt;li&gt;OpenAI-compatible API server&lt;/li&gt; 
 &lt;li&gt;Support NVIDIA GPUs, AMD CPUs and GPUs, Intel CPUs and GPUs, PowerPC CPUs, TPU, and AWS Neuron&lt;/li&gt; 
 &lt;li&gt;Prefix caching support&lt;/li&gt; 
 &lt;li&gt;Multi-LoRA support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;vLLM seamlessly supports most popular open-source models on HuggingFace, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Transformer-like LLMs (e.g., Llama)&lt;/li&gt; 
 &lt;li&gt;Mixture-of-Expert LLMs (e.g., Mixtral, Deepseek-V2 and V3)&lt;/li&gt; 
 &lt;li&gt;Embedding Models (e.g., E5-Mistral)&lt;/li&gt; 
 &lt;li&gt;Multi-modal LLMs (e.g., LLaVA)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Find the full list of supported models &lt;a href="https://docs.vllm.ai/en/latest/models/supported_models.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Install vLLM with &lt;code&gt;pip&lt;/code&gt; or &lt;a href="https://docs.vllm.ai/en/latest/getting_started/installation/gpu/index.html#build-wheel-from-source"&gt;from source&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install vllm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Visit our &lt;a href="https://docs.vllm.ai/en/latest/"&gt;documentation&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/installation.html"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/getting_started/quickstart.html"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.vllm.ai/en/latest/models/supported_models.html"&gt;List of Supported Models&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome and value any contributions and collaborations. Please check out &lt;a href="https://docs.vllm.ai/en/latest/contributing/index.html"&gt;Contributing to vLLM&lt;/a&gt; for how to get involved.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;vLLM is a community project. Our compute resources for development and testing are supported by the following organizations. Thank you for your support!&lt;/p&gt; 
&lt;!-- Note: Please sort them in alphabetical order. --&gt; 
&lt;!-- Note: Please keep these consistent with docs/community/sponsors.md --&gt; 
&lt;p&gt;Cash Donations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;a16z&lt;/li&gt; 
 &lt;li&gt;Dropbox&lt;/li&gt; 
 &lt;li&gt;Sequoia Capital&lt;/li&gt; 
 &lt;li&gt;Skywork AI&lt;/li&gt; 
 &lt;li&gt;ZhenFund&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Compute Resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AMD&lt;/li&gt; 
 &lt;li&gt;Anyscale&lt;/li&gt; 
 &lt;li&gt;AWS&lt;/li&gt; 
 &lt;li&gt;Crusoe Cloud&lt;/li&gt; 
 &lt;li&gt;Databricks&lt;/li&gt; 
 &lt;li&gt;DeepInfra&lt;/li&gt; 
 &lt;li&gt;Google Cloud&lt;/li&gt; 
 &lt;li&gt;Intel&lt;/li&gt; 
 &lt;li&gt;Lambda Lab&lt;/li&gt; 
 &lt;li&gt;Nebius&lt;/li&gt; 
 &lt;li&gt;Novita AI&lt;/li&gt; 
 &lt;li&gt;NVIDIA&lt;/li&gt; 
 &lt;li&gt;Replicate&lt;/li&gt; 
 &lt;li&gt;Roblox&lt;/li&gt; 
 &lt;li&gt;RunPod&lt;/li&gt; 
 &lt;li&gt;Trainy&lt;/li&gt; 
 &lt;li&gt;UC Berkeley&lt;/li&gt; 
 &lt;li&gt;UC San Diego&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Slack Sponsor: Anyscale&lt;/p&gt; 
&lt;p&gt;We also have an official fundraising venue through &lt;a href="https://opencollective.com/vllm"&gt;OpenCollective&lt;/a&gt;. We plan to use the fund to support the development, maintenance, and adoption of vLLM.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you use vLLM for your research, please cite our &lt;a href="https://arxiv.org/abs/2309.06180"&gt;paper&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;!-- --8&lt;-- [start:contact-us] --&gt; 
&lt;ul&gt; 
 &lt;li&gt;For technical questions and feature requests, please use GitHub &lt;a href="https://github.com/vllm-project/vllm/issues"&gt;Issues&lt;/a&gt; or &lt;a href="https://github.com/vllm-project/vllm/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For discussing with fellow users, please use the &lt;a href="https://discuss.vllm.ai"&gt;vLLM Forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For coordinating contributions and development, please use &lt;a href="https://slack.vllm.ai"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For security disclosures, please use GitHub's &lt;a href="https://github.com/vllm-project/vllm/security/advisories"&gt;Security Advisories&lt;/a&gt; feature&lt;/li&gt; 
 &lt;li&gt;For collaborations and partnerships, please contact us at &lt;a href="mailto:vllm-questions@lists.berkeley.edu"&gt;vllm-questions@lists.berkeley.edu&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- --8&lt;-- [end:contact-us] --&gt; 
&lt;h2&gt;Media Kit&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you wish to use vLLM's logo, please refer to &lt;a href="https://github.com/vllm-project/media-kit"&gt;our media kit repo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>KurtBestor/Hitomi-Downloader</title>
      <link>https://github.com/KurtBestor/Hitomi-Downloader</link>
      <description>&lt;p&gt;🍰 Desktop utility to download images/videos/music/text from various websites, and more.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/KurtBestor/Hitomi-Downloader/master/imgs/card_crop.png" width="50%"&gt; &lt;br&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/KurtBestor/Hitomi-Downloader/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release/KurtBestor/Hitomi-Downloader.svg?logo=github" alt="GitHub release"&gt;&lt;/a&gt; &lt;a href="https://github.com/KurtBestor/Hitomi-Downloader/releases/latest"&gt;&lt;img src="https://img.shields.io/github/downloads/KurtBestor/Hitomi-Downloader/latest/total.svg?logo=github" alt="GitHub downloads"&gt;&lt;/a&gt; &lt;a href="https://github.com/KurtBestor/Hitomi-Downloader/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/KurtBestor/Hitomi-Downloader/total.svg?logo=github" alt="GitHub downloads"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KurtBestor/Hitomi-Downloader/releases/latest"&gt;Download&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KurtBestor/Hitomi-Downloader/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KurtBestor/Hitomi-Downloader/wiki/Scripts-&amp;amp;-Plugins"&gt;Scripts &amp;amp; Plugins&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/KurtBestor/Hitomi-Downloader/wiki/Chrome-Extension"&gt;Chrome Extension&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;img src="https://raw.githubusercontent.com/KurtBestor/Hitomi-Downloader/master/imgs/how_to_download.gif"&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🍰 Simple and clear user interface&lt;/li&gt; 
 &lt;li&gt;🚀 Download acceleration&lt;/li&gt; 
 &lt;li&gt;💻 Supports 24 threads in a single task&lt;/li&gt; 
 &lt;li&gt;🚥 Supports speed limit&lt;/li&gt; 
 &lt;li&gt;📜 Supports user scripts&lt;/li&gt; 
 &lt;li&gt;🧲 Supports BitTorrent &amp;amp; Magnet&lt;/li&gt; 
 &lt;li&gt;🎞️ Supports M3U8 &amp;amp; MPD format videos&lt;/li&gt; 
 &lt;li&gt;🌙 Dark mode&lt;/li&gt; 
 &lt;li&gt;🧳 Portable&lt;/li&gt; 
 &lt;li&gt;📋 Clipboard monitor&lt;/li&gt; 
 &lt;li&gt;🗃️ Easy to organize tasks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Sites&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Site&lt;/th&gt; 
   &lt;th&gt;URL&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;4chan&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://4chan.org"&gt;https://4chan.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;AfreecaTV&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://afreecatv.com"&gt;https://afreecatv.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;ArtStation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://artstation.com"&gt;https://artstation.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;baraag.net&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://baraag.net"&gt;https://baraag.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;bilibili&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://bilibili.com"&gt;https://bilibili.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;ComicWalker&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://comic-walker.com"&gt;https://comic-walker.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Coub&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://coub.com"&gt;https://coub.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;DeviantArt&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://deviantart.com"&gt;https://deviantart.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Facebook&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://facebook.com"&gt;https://facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;FC2 Video&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://video.fc2.com"&gt;https://video.fc2.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Flickr&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://flickr.com"&gt;https://flickr.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Hameln&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://syosetu.org"&gt;https://syosetu.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Imgur&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://imgur.com"&gt;https://imgur.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Instagram&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://instagram.com"&gt;https://instagram.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;カクヨム&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://kakuyomu.jp"&gt;https://kakuyomu.jp&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Mastodon&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mastodon.social"&gt;https://mastodon.social&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Misskey&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://misskey.io"&gt;https://misskey.io&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Naver Blog&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://blog.naver.com"&gt;https://blog.naver.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Naver Cafe&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://cafe.naver.com"&gt;https://cafe.naver.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Naver Post&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://post.naver.com"&gt;https://post.naver.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Naver Webtoon&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://comic.naver.com"&gt;https://comic.naver.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Naver TV&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://tv.naver.com"&gt;https://tv.naver.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Niconico&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://nicovideo.jp"&gt;http://nicovideo.jp&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Pawoo&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://pawoo.net"&gt;https://pawoo.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Pinterest&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://pinterest.com"&gt;https://pinterest.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Pixiv&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://pixiv.net"&gt;https://pixiv.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;pixivコミック&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://comic.pixiv.net"&gt;https://comic.pixiv.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Soundcloud&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://soundcloud.com"&gt;https://soundcloud.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;小説家になろう&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://syosetu.com"&gt;https://syosetu.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;TikTok&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://tiktok.com"&gt;https://tiktok.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://douyin.com"&gt;https://douyin.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Tumblr&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://tumblr.com"&gt;https://tumblr.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Twitch&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://twitch.tv"&gt;https://twitch.tv&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Twitter&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://twitter.com"&gt;https://twitter.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Vimeo&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://vimeo.com"&gt;https://vimeo.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Wayback Machine&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://archive.org"&gt;https://archive.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Weibo&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://weibo.com"&gt;https://weibo.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;WikiArt&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.wikiart.org"&gt;https://www.wikiart.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Youku&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youku.com"&gt;https://youku.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;YouTube&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtube.com"&gt;https://youtube.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;and more...&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/supportedsites.md"&gt;Supported sites by yt-dlp&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>QwenLM/Qwen3</title>
      <link>https://github.com/QwenLM/Qwen3</link>
      <description>&lt;p&gt;Qwen3 is the large language model series developed by Qwen team, Alibaba Cloud.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Qwen3&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/logo_qwen3.png" width="400"&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; 💜 &lt;a href="https://chat.qwen.ai/"&gt;&lt;b&gt;Qwen Chat&lt;/b&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🤗 &lt;a href="https://huggingface.co/Qwen"&gt;Hugging Face&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🤖 &lt;a href="https://modelscope.cn/organization/qwen"&gt;ModelScope&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; 📑 &lt;a href="https://arxiv.org/abs/2505.09388"&gt;Paper&lt;/a&gt; &amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp; 📑 &lt;a href="https://qwenlm.github.io/blog/qwen3/"&gt;Blog&lt;/a&gt; &amp;nbsp;&amp;nbsp; ｜ &amp;nbsp;&amp;nbsp;📖 &lt;a href="https://qwen.readthedocs.io/"&gt;Documentation&lt;/a&gt; &lt;br&gt; 🖥️ &lt;a href="https://huggingface.co/spaces/Qwen/Qwen3-Demo"&gt;Demo&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;💬 &lt;a href="https://github.com/QwenLM/Qwen/raw/main/assets/wechat.png"&gt;WeChat (微信)&lt;/a&gt;&amp;nbsp;&amp;nbsp; | &amp;nbsp;&amp;nbsp;🫨 &lt;a href="https://discord.gg/CV4E9rpNSD"&gt;Discord&lt;/a&gt;&amp;nbsp;&amp;nbsp; &lt;/p&gt; 
&lt;p&gt;Visit our Hugging Face or ModelScope organization (click links above), search checkpoints with names starting with &lt;code&gt;Qwen3-&lt;/code&gt; or visit the &lt;a href="https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f"&gt;Qwen3 collection&lt;/a&gt;, and you will find all you need! Enjoy!&lt;/p&gt; 
&lt;p&gt;To learn more about Qwen3, feel free to read our documentation [&lt;a href="https://qwen.readthedocs.io/en/latest/"&gt;EN&lt;/a&gt;|&lt;a href="https://qwen.readthedocs.io/zh-cn/latest/"&gt;ZH&lt;/a&gt;]. Our documentation consists of the following sections:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Quickstart: the basic usages and demonstrations;&lt;/li&gt; 
 &lt;li&gt;Inference: the guidance for the inference with Transformers, including batch inference, streaming, etc.;&lt;/li&gt; 
 &lt;li&gt;Run Locally: the instructions for running LLM locally on CPU and GPU, with frameworks like llama.cpp and Ollama;&lt;/li&gt; 
 &lt;li&gt;Deployment: the demonstration of how to deploy Qwen for large-scale inference with frameworks like SGLang, vLLM, TGI, etc.;&lt;/li&gt; 
 &lt;li&gt;Quantization: the practice of quantizing LLMs with GPTQ, AWQ, as well as the guidance for how to make high-quality quantized GGUF files;&lt;/li&gt; 
 &lt;li&gt;Training: the instructions for post-training, including SFT and RLHF (TODO) with frameworks like Axolotl, LLaMA-Factory, etc.&lt;/li&gt; 
 &lt;li&gt;Framework: the usage of Qwen with frameworks for application, e.g., RAG, Agent, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;h3&gt;Qwen3-Instruct-2507&lt;/h3&gt; 
&lt;p&gt;We are excited to introduce the updated version of the &lt;strong&gt;Qwen3-235B-A22B non-thinking mode&lt;/strong&gt;, named &lt;strong&gt;Qwen3-235B-A22B-Instruct-2507&lt;/strong&gt;, featuring the following key enhancements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Significant improvements&lt;/strong&gt; in general capabilities, including &lt;strong&gt;instruction following, logical reasoning, text comprehension, mathematics, science, coding and tool usage&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Substantial gains&lt;/strong&gt; in long-tail knowledge coverage across &lt;strong&gt;multiple languages&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Markedly better alignment&lt;/strong&gt; with user preferences in &lt;strong&gt;subjective and open-ended tasks&lt;/strong&gt;, enabling more helpful responses and higher-quality text generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced capabilities&lt;/strong&gt; in &lt;strong&gt;256K-token long-context understanding&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://qianwen-res.oss-accelerate.aliyuncs.com/Qwen3-235B-A22B-Instruct-2507.jpeg" alt="Qwen3-235B-A22B-Instruct-2507"&gt;&lt;/p&gt; 
&lt;h3&gt;Qwen3-Thinking-2507&lt;/h3&gt; 
&lt;p&gt;Over the past three months, we have continued to scale the &lt;strong&gt;thinking capability&lt;/strong&gt; of Qwen3-235B-A22B, improving both the &lt;strong&gt;quality and depth&lt;/strong&gt; of reasoning. We are pleased to introduce &lt;strong&gt;Qwen3-235B-A22B-Thinking-2507&lt;/strong&gt;, featuring the following key enhancements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Significantly improved performance&lt;/strong&gt; on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise — achieving &lt;strong&gt;state-of-the-art results among open-source thinking models&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Markedly better general capabilities&lt;/strong&gt;, such as instruction following, tool usage, text generation, and alignment with human preferences.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced 256K long-context understanding&lt;/strong&gt; capabilities.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-2507/Qwen3-235B-A22B-Thinking-2507.jpeg" alt="Qwen3-235B-A22B-Thinking-2507"&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] This version has an increased thinking length. We strongly recommend its use in highly complex reasoning tasks with adequate maximum generation length.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The updated versions of &lt;strong&gt;more Qwen3 model sizes&lt;/strong&gt; are also expected to be released very soon. Stay tuned🚀&lt;/p&gt; 
&lt;h3&gt;Qwen3&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Previous Qwen3 Release&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt; We are excited to announce the release of Qwen3, the latest addition to the Qwen family of large language models. These models represent our most advanced and intelligent systems to date, improving from our experience in building QwQ and Qwen2.5. We are making the weights of Qwen3 available to the public, including both dense and Mixture-of-Expert (MoE) models. &lt;br&gt;&lt;br&gt; The highlights from Qwen3 include: &lt;/p&gt;
 &lt;ul&gt; 
  &lt;li&gt;&lt;b&gt;Dense and Mixture-of-Experts (MoE) models of various sizes&lt;/b&gt;, available in 0.6B, 1.7B, 4B, 8B, 14B, 32B and 30B-A3B, 235B-A22B.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Seamless switching between thinking mode&lt;/b&gt; (for complex logical reasoning, math, and coding) and &lt;b&gt;non-thinking mode&lt;/b&gt; (for efficient, general-purpose chat), ensuring optimal performance across various scenarios.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Significantly enhancement in reasoning capabilities&lt;/b&gt;, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Superior human preference alignment&lt;/b&gt;, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Expertise in agent capabilities&lt;/b&gt;, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.&lt;/li&gt; 
  &lt;li&gt;&lt;b&gt;Support of 100+ languages and dialects&lt;/b&gt; with strong capabilities for &lt;b&gt;multilingual instruction following&lt;/b&gt; and &lt;b&gt;translation&lt;/b&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025.07.25: We released the updated version of Qwen3-235B-A22B thinking mode, named Qwen3-235B-A22B-Thinking-2507. Check out the &lt;a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507"&gt;modelcard&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2025.07.21: We released the updated version of Qwen3-235B-A22B non-thinking mode, named Qwen3-235B-A22B-Instruct-2507, featuring significant enhancements over the previous version and supporting 256K-token long-context understanding. Check our &lt;a href="https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507"&gt;modelcard&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2025.04.29: We released the Qwen3 series. Check our &lt;a href="https://qwenlm.github.io/blog/qwen3"&gt;blog&lt;/a&gt; for more details!&lt;/li&gt; 
 &lt;li&gt;2024.09.19: We released the Qwen2.5 series. This time there are 3 extra model sizes: 3B, 14B, and 32B for more possibilities. Check our &lt;a href="https://qwenlm.github.io/blog/qwen2.5"&gt;blog&lt;/a&gt; for more!&lt;/li&gt; 
 &lt;li&gt;2024.06.06: We released the Qwen2 series. Check our &lt;a href="https://qwenlm.github.io/blog/qwen2/"&gt;blog&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;2024.03.28: We released the first MoE model of Qwen: Qwen1.5-MoE-A2.7B! Temporarily, only HF transformers and vLLM support the model. We will soon add the support of llama.cpp, mlx-lm, etc. Check our &lt;a href="https://qwenlm.github.io/blog/qwen-moe/"&gt;blog&lt;/a&gt; for more information!&lt;/li&gt; 
 &lt;li&gt;2024.02.05: We released the Qwen1.5 series.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;Detailed evaluation results are reported in this &lt;a href="https://qwenlm.github.io/blog/qwen3/"&gt;📑 blog&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For requirements on GPU memory and the respective throughput, see results &lt;a href="https://qwen.readthedocs.io/en/latest/getting_started/speed_benchmark.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Run Qwen3&lt;/h2&gt; 
&lt;h3&gt;🤗 Transformers&lt;/h3&gt; 
&lt;p&gt;Transformers is a library of pretrained natural language processing for inference and training. The latest version of &lt;code&gt;transformers&lt;/code&gt; is recommended and &lt;code&gt;transformers&amp;gt;=4.51.0&lt;/code&gt; is required.&lt;/p&gt; 
&lt;h4&gt;Qwen3 Instruct&lt;/h4&gt; 
&lt;p&gt;The following contains a code snippet illustrating how to use Qwen3-235B-A22B-Instruct-2507 to generate content based on given inputs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen3-235B-A22B-Instruct-2507"

# load the tokenizer and the model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)

# prepare the model input
prompt = "Give me a short introduction to large language model."
messages = [
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

# conduct text completion
generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=16384
)
output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() 

content = tokenizer.decode(output_ids, skip_special_tokens=True)

print("content:", content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] The updated version of Qwen3-235B-A22B, namely &lt;strong&gt;Qwen3-235B-A22B-Instruct-2507&lt;/strong&gt; supports &lt;strong&gt;only non-thinking mode&lt;/strong&gt; and &lt;strong&gt;does not generate &lt;code&gt;&amp;lt;think&amp;gt;&amp;lt;/think&amp;gt;&lt;/code&gt; blocks&lt;/strong&gt; in its output. Meanwhile, &lt;strong&gt;specifying &lt;code&gt;enable_thinking=False&lt;/code&gt; is no longer required&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Qwen3 Thinking&lt;/h4&gt; 
&lt;p&gt;The following contains a code snippet illustrating how to use Qwen3-235B-A22B-Thinking-2507 to generate content based on given inputs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen3-235B-A22B-Thinking-2507"

# load the tokenizer and the model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)

# prepare the model input
prompt = "Give me a short introduction to large language model."
messages = [
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

# conduct text completion
generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=32768
)
output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() 

# parsing thinking content
try:
    # rindex finding 151668 (&amp;lt;/think&amp;gt;)
    index = len(output_ids) - output_ids[::-1].index(151668)
except ValueError:
    index = 0

thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip("\n")
content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip("\n")

print("thinking content:", thinking_content)  # no opening &amp;lt;think&amp;gt; tag
print("content:", content)

&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] The updated version of Qwen3-235B-A22B, namely &lt;strong&gt;Qwen3-235B-A22B-Thinking-2507&lt;/strong&gt; supports &lt;strong&gt;only thinking mode&lt;/strong&gt;. Additionally, to enforce model thinking, the default chat template automatically includes &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt;. Therefore, it is normal for the model's output to contain only &lt;code&gt;&amp;lt;/think&amp;gt;&lt;/code&gt; without an explicit opening &lt;code&gt;&amp;lt;think&amp;gt;&lt;/code&gt; tag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Switching Thinking/Non-thinking Modes for Previous Qwen3 Hybrid Models&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt; By default, Qwen3 models will think before response. This could be controlled by &lt;/p&gt;
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;enable_thinking=False&lt;/code&gt;: Passing &lt;code&gt;enable_thinking=False&lt;/code&gt; to `tokenizer.apply_chat_template` will strictly prevent the model from generating thinking content.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;/think&lt;/code&gt; and &lt;code&gt;/no_think&lt;/code&gt; instructions: Use those words in the system or user message to signify whether Qwen3 should think. In multi-turn conversations, the latest instruction is followed.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;ModelScope&lt;/h3&gt; 
&lt;p&gt;We strongly advise users especially those in mainland China to use ModelScope. ModelScope adopts a Python API similar to Transformers. The CLI tool &lt;code&gt;modelscope download&lt;/code&gt; can help you solve issues concerning downloading checkpoints.&lt;/p&gt; 
&lt;h3&gt;llama.cpp&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/ggml-org/llama.cpp"&gt;&lt;code&gt;llama.cpp&lt;/code&gt;&lt;/a&gt; enables LLM inference with minimal setup and state-of-the-art performance on a wide range of hardware. &lt;code&gt;llama.cpp&amp;gt;=b5092&lt;/code&gt; is required for the support of Qwen3 architecture. &lt;code&gt;llama.cpp&amp;gt;=b5401&lt;/code&gt; is recommended for the full support of the official Qwen3 chat template.&lt;/p&gt; 
&lt;p&gt;To use the CLI, run the following in a terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./llama-cli -hf Qwen/Qwen3-8B-GGUF:Q8_0 --jinja --color -ngl 99 -fa -sm row --temp 0.6 --top-k 20 --top-p 0.95 --min-p 0 -c 40960 -n 32768 --no-context-shift
# CTRL+C to exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use the API server, run the following in a terminal:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;./llama-server -hf Qwen/Qwen3-8B-GGUF:Q8_0 --jinja --reasoning-format deepseek -ngl 99 -fa -sm row --temp 0.6 --top-k 20 --top-p 0.95 --min-p 0 -c 40960 -n 32768 --no-context-shift --port 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A simple web front end will be at &lt;code&gt;http://localhost:8080&lt;/code&gt; and an OpenAI-compatible API will be at &lt;code&gt;http://localhost:8080/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For additional guides, please refer to &lt;a href="https://qwen.readthedocs.io/en/latest/run_locally/llama.cpp.html"&gt;our documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] llama.cpp adopts "rotating context management" and infinite generation is made possible by evicting earlier tokens. It could configured by parameters and the commands above effectively disable it. For more details, please refer to &lt;a href="https://qwen.readthedocs.io/en/latest/run_locally/llama.cpp.html#llama-cli"&gt;our documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Ollama&lt;/h3&gt; 
&lt;p&gt;After &lt;a href="https://ollama.com/"&gt;installing Ollama&lt;/a&gt;, you can initiate the Ollama service with the following command (Ollama v0.6.6 or higher is required):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama serve
# You need to keep this service running whenever you are using ollama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To pull a model checkpoint and run the model, use the &lt;code&gt;ollama run&lt;/code&gt; command. You can specify a model size by adding a suffix to &lt;code&gt;qwen3&lt;/code&gt;, such as &lt;code&gt;:8b&lt;/code&gt; or &lt;code&gt;:30b-a3b&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ollama run qwen3:8b
# Setting parameters, type "/set parameter num_ctx 40960" and "/set parameter num_predict 32768"
# To exit, type "/bye" and press ENTER
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also access the Ollama service via its OpenAI-compatible API. Please note that you need to (1) keep &lt;code&gt;ollama serve&lt;/code&gt; running while using the API, and (2) execute &lt;code&gt;ollama run qwen3:8b&lt;/code&gt; before utilizing this API to ensure that the model checkpoint is prepared. The API is at &lt;code&gt;http://localhost:11434/v1/&lt;/code&gt; by default.&lt;/p&gt; 
&lt;p&gt;For additional details, please visit &lt;a href="https://ollama.com/"&gt;ollama.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Ollama adopts the same "rotating context management" with llama.cpp. However, its default settings (&lt;code&gt;num_ctx&lt;/code&gt; 2048 and &lt;code&gt;num_predict&lt;/code&gt; -1), suggesting infinite generation with a 2048-token context, could lead to trouble for Qwen3 models. We recommend setting &lt;code&gt;num_ctx&lt;/code&gt; and &lt;code&gt;num_predict&lt;/code&gt; properly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;LMStudio&lt;/h3&gt; 
&lt;p&gt;Qwen3 has already been supported by &lt;a href="https://lmstudio.ai/"&gt;lmstudio.ai&lt;/a&gt;. You can directly use LMStudio with our GGUF files.&lt;/p&gt; 
&lt;h3&gt;ExecuTorch&lt;/h3&gt; 
&lt;p&gt;To export and run on ExecuTorch (iOS, Android, Mac, Linux, and more), please follow this &lt;a href="https://github.com/pytorch/executorch/raw/main/examples/models/qwen3/README.md"&gt;example&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MNN&lt;/h3&gt; 
&lt;p&gt;To export and run on MNN, which supports Qwen3 on mobile devices, please visit &lt;a href="https://github.com/alibaba/MNN"&gt;Alibaba MNN&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MLX LM&lt;/h3&gt; 
&lt;p&gt;If you are running on Apple Silicon, &lt;a href="https://github.com/ml-explore/mlx-lm"&gt;&lt;code&gt;mlx-lm&lt;/code&gt;&lt;/a&gt; also supports Qwen3 (&lt;code&gt;mlx-lm&amp;gt;=0.24.0&lt;/code&gt;). Look for models ending with MLX on Hugging Face Hub.&lt;/p&gt; 
&lt;h3&gt;OpenVINO&lt;/h3&gt; 
&lt;p&gt;If you are running on Intel CPU or GPU, &lt;a href="https://github.com/openvinotoolkit"&gt;OpenVINO toolkit&lt;/a&gt; supports Qwen3. You can follow this &lt;a href="https://github.com/openvinotoolkit/openvino_notebooks/raw/latest/notebooks/llm-chatbot/llm-chatbot.ipynb"&gt;chatbot example&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- ### Text generation web UI

You can directly use [`text-generation-webui`](https://github.com/oobabooga/text-generation-webui) for creating a web UI demo. If you use GGUF, remember to install the latest wheel of `llama.cpp` with the support of Qwen2.5. --&gt; 
&lt;!-- ### llamafile

Clone [`llamafile`](https://github.com/Mozilla-Ocho/llamafile), run source install, and then create your own llamafile with the GGUF file following the guide [here](https://github.com/Mozilla-Ocho/llamafile?tab=readme-ov-file#creating-llamafiles). You are able to run one line of command, say `./qwen.llamafile`, to create a demo. --&gt; 
&lt;h2&gt;Deploy Qwen3&lt;/h2&gt; 
&lt;p&gt;Qwen3 is supported by multiple inference frameworks. Here we demonstrate the usage of &lt;code&gt;SGLang&lt;/code&gt;, &lt;code&gt;vLLM&lt;/code&gt; and &lt;code&gt;TensorRT-LLM&lt;/code&gt;. You can also find Qwen3 models from various inference providers, e.g., &lt;a href="https://www.alibabacloud.com/en/product/modelstudio"&gt;Alibaba Cloud Model Studio&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;SGLang&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/sgl-project/sglang"&gt;SGLang&lt;/a&gt; is a fast serving framework for large language models and vision language models. SGLang could be used to launch a server with OpenAI-compatible API service. &lt;code&gt;sglang&amp;gt;=0.4.6.post1&lt;/code&gt; is required. It is as easy as&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python -m sglang.launch_server --model-path Qwen/Qwen3-8B --port 30000 --reasoning-parser qwen3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:30000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] For Qwen3-Thinking-2507, e.g., Qwen3-235B-A22B-Thinking-2507, please use the following command at the moment:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;python -m sglang.launch_server --model-path Qwen/Qwen3-235B-A22B-Thinking-2507 --port 30000 --tp 8 --context-length 262144  --reasoning-parser deepseek-r1
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;vLLM&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt; is a high-throughput and memory-efficient inference and serving engine for LLMs. &lt;code&gt;vllm&amp;gt;=0.9.0&lt;/code&gt; is recommended.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;vllm serve Qwen/Qwen3-8B --port 8000 --enable-reasoning --reasoning-parser qwen3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] For Qwen3-Thinking-2507, e.g., Qwen3-235B-A22B-Thinking-2507, please use the following command at the moment:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-shell"&gt;vllm serve Qwen/Qwen3-235B-A22B-Thinking-2507 --port 8000 --tensor-parallel-size 8 --max-model-len 262144 --enable-reasoning --reasoning-parser deepseek_r1
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;TensorRT-LLM&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/NVIDIA/TensorRT-LLM"&gt;TensorRT-LLM&lt;/a&gt; is an open-source LLM inference engine from NVIDIA, which provides optimizations including custom attention kernels, quantization and more on NVIDIA GPUs. Qwen3 is supported in its re-architected &lt;a href="https://nvidia.github.io/TensorRT-LLM/torch.html"&gt;PyTorch backend&lt;/a&gt;. &lt;code&gt;tensorrt_llm&amp;gt;=0.20.0rc3&lt;/code&gt; is recommended. Please refer to the &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/main/examples/models/core/qwen/README.md#qwen3"&gt;README&lt;/a&gt; page for more details.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;trtllm-serve Qwen/Qwen3-8B --host localhost --port 8000 --backend pytorch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An OpenAI-compatible API will be available at &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;MindIE&lt;/h3&gt; 
&lt;p&gt;For deployment on Ascend NPUs, please visit &lt;a href="https://modelers.cn/"&gt;Modelers&lt;/a&gt; and search for Qwen3.&lt;/p&gt; 
&lt;!-- 
### OpenLLM

[OpenLLM](https://github.com/bentoml/OpenLLM) allows you to easily run Qwen2.5 as OpenAI-compatible APIs. You can start a model server using `openllm serve`. For example:

```bash
openllm serve qwen2.5:7b
```

The server is active at `http://localhost:3000/`, providing OpenAI-compatible APIs. You can create an OpenAI client to call its chat API. For more information, refer to [our documentation](https://qwen.readthedocs.io/en/latest/deployment/openllm.html). --&gt; 
&lt;h2&gt;Build with Qwen3&lt;/h2&gt; 
&lt;h3&gt;Tool Use&lt;/h3&gt; 
&lt;p&gt;For tool use capabilities, we recommend taking a look at &lt;a href="https://github.com/QwenLM/Qwen-Agent"&gt;Qwen-Agent&lt;/a&gt;, which provides a wrapper around these APIs to support tool use or function calling with MCP support. Tool use with Qwen3 can also be conducted with SGLang, vLLM, Transformers, llama.cpp, Ollama, etc. Follow guides in our documentation to see how to enable the support.&lt;/p&gt; 
&lt;h3&gt;Finetuning&lt;/h3&gt; 
&lt;p&gt;We advise you to use training frameworks, including &lt;a href="https://github.com/OpenAccess-AI-Collective/axolotl"&gt;Axolotl&lt;/a&gt;, &lt;a href="https://github.com/unslothai/unsloth"&gt;UnSloth&lt;/a&gt;, &lt;a href="https://github.com/modelscope/swift"&gt;Swift&lt;/a&gt;, &lt;a href="https://github.com/hiyouga/LLaMA-Factory"&gt;Llama-Factory&lt;/a&gt;, etc., to finetune your models with SFT, DPO, GRPO, etc.&lt;/p&gt; 
&lt;h2&gt;License Agreement&lt;/h2&gt; 
&lt;p&gt;All our open-weight models are licensed under Apache 2.0. You can find the license files in the respective Hugging Face repositories.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find our work helpful, feel free to give us a cite.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{qwen3,
    title={Qwen3 Technical Report}, 
    author={An Yang and Anfeng Li and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Gao and Chengen Huang and Chenxu Lv and Chujie Zheng and Dayiheng Liu and Fan Zhou and Fei Huang and Feng Hu and Hao Ge and Haoran Wei and Huan Lin and Jialong Tang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jing Zhou and Jingren Zhou and Junyang Lin and Kai Dang and Keqin Bao and Kexin Yang and Le Yu and Lianghao Deng and Mei Li and Mingfeng Xue and Mingze Li and Pei Zhang and Peng Wang and Qin Zhu and Rui Men and Ruize Gao and Shixuan Liu and Shuang Luo and Tianhao Li and Tianyi Tang and Wenbiao Yin and Xingzhang Ren and Xinyu Wang and Xinyu Zhang and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yinger Zhang and Yu Wan and Yuqiong Liu and Zekun Wang and Zeyu Cui and Zhenru Zhang and Zhipeng Zhou and Zihan Qiu},
    journal = {arXiv preprint arXiv:2505.09388},
    year={2025}
}

@article{qwen2.5,
    title   = {Qwen2.5 Technical Report}, 
    author  = {An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
    journal = {arXiv preprint arXiv:2412.15115},
    year    = {2024}
}

@article{qwen2,
    title   = {Qwen2 Technical Report}, 
    author  = {An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
    journal = {arXiv preprint arXiv:2407.10671},
    year    = {2024}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contact Us&lt;/h2&gt; 
&lt;p&gt;If you are interested to leave a message to either our research team or product team, join our &lt;a href="https://discord.gg/z3GAxXZ9Ce"&gt;Discord&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/QwenLM/Qwen3/main/assets/wechat.png"&gt;WeChat groups&lt;/a&gt;!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>frappe/hrms</title>
      <link>https://github.com/frappe/hrms</link>
      <description>&lt;p&gt;Open Source HR and Payroll Software&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt; &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/frappe-hr-logo.png" height="80px" width="80px" alt="Frappe HR Logo"&gt; &lt;/a&gt; 
 &lt;h2&gt;Frappe HR&lt;/h2&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;Open Source, modern, and easy-to-use HR and Payroll Software&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/frappe/hrms/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/frappe/hrms/actions/workflows/ci.yml/badge.svg?branch=develop" alt="CI"&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/frappe/hrms"&gt;&lt;img src="https://codecov.io/gh/frappe/hrms/branch/develop/graph/badge.svg?token=0TwvyUg3I5" alt="codecov"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/10972" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/10972" alt="frappe%2Fhrms | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-hero.png"&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/hr"&gt;Website&lt;/a&gt; - 
 &lt;a href="https://docs.frappe.io/hr/introduction"&gt;Documentation&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Frappe HR&lt;/h2&gt; 
&lt;p&gt;Frappe HR has everything you need to drive excellence within the company. It's a complete HRMS solution with over 13 different modules right from Employee Management, Onboarding, Leaves, to Payroll, Taxation, and more!&lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;p&gt;When Frappe team started growing in terms of size, we needed an open-source HR and Payroll software. We didn't find any "true" open-source HR software out there and so decided to build one ourselves. Initially, it was a set of modules within ERPNext but version 14 onwards, as the modules became more mature, Frappe HR was created as a separate product.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Employee Lifecycle&lt;/strong&gt;: From onboarding employees, managing promotions and transfers, all the way to documenting feedback with exit interviews, make life easier for employees throughout their life cycle.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Leave and Attendance&lt;/strong&gt;: Configure leave policies, pull regional holidays with a click, check-in and check-out with geolocation capturing, track leave balances and attendance with reports.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expense Claims and Advances&lt;/strong&gt;: Manage employee advances, claim expenses, configure multi-level approval workflows, all this with seamless integration with ERPNext accounting.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Management&lt;/strong&gt;: Track goals, align goals with key result areas (KRAs), enable employees to evaluate themselves, make managing appraisal cycles easy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Payroll &amp;amp; Taxation&lt;/strong&gt;: Create salary structures, configure income tax slabs, run standard payroll, accomodate additional salaries and off cycle payments, view income breakup on salary slips and so much more.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frappe HR Mobile App&lt;/strong&gt;: Apply for and approve leaves on the go, check-in and check-out, access employee profile right from the mobile app.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details open&gt; 
 &lt;summary&gt;View Screenshots&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-appraisal.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-requisition.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-attendance.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-salary.png"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/hrms/develop/.github/hrms-pwa.png"&gt; 
&lt;/details&gt; 
&lt;h3&gt;Under the Hood&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe"&gt;&lt;strong&gt;Frappe Framework&lt;/strong&gt;&lt;/a&gt;: A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe-ui"&gt;&lt;strong&gt;Frappe UI&lt;/strong&gt;&lt;/a&gt;: A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production Setup&lt;/h2&gt; 
&lt;h3&gt;Managed Hosting&lt;/h3&gt; 
&lt;p&gt;You can try &lt;a href="https://frappecloud.com"&gt;Frappe Cloud&lt;/a&gt;, a simple, user-friendly and sophisticated &lt;a href="https://github.com/frappe/press"&gt;open-source&lt;/a&gt; platform to host Frappe applications with peace of mind.&lt;/p&gt; 
&lt;p&gt;It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.&lt;/p&gt; 
&lt;div&gt; 
 &lt;a href="https://frappecloud.com/hrms/signup" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/try-on-fc-white.png"&gt; 
   &lt;img src="https://frappe.io/files/try-on-fc-black.png" alt="Try on Frappe Cloud" height="28"&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Development setup&lt;/h2&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;You need Docker, docker-compose and git setup on your machine. Refer &lt;a href="https://docs.docker.com/"&gt;Docker documentation&lt;/a&gt;. After that, run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/frappe/hrms
cd hrms/docker
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for some time until the setup script creates a site. After that you can access &lt;code&gt;http://localhost:8000&lt;/code&gt; in your browser and the login screen for HR should show up.&lt;/p&gt; 
&lt;p&gt;Use the following credentials to log in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Username: &lt;code&gt;Administrator&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Password: &lt;code&gt;admin&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Local&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Set up bench by following the &lt;a href="https://frappeframework.com/docs/user/en/installation"&gt;Installation Steps&lt;/a&gt; and start the server and keep it running &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench start
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;In a separate terminal window, run the following commands &lt;pre&gt;&lt;code class="language-sh"&gt;$ bench new-site hrms.local
$ bench get-app erpnext
$ bench get-app hrms
$ bench --site hrms.local install-app hrms
$ bench --site hrms.local add-to-hosts
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;You can access the site at &lt;code&gt;http://hrms.local:8080&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Learning and Community&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://frappe.school"&gt;Frappe School&lt;/a&gt; - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.frappe.io/hr"&gt;Documentation&lt;/a&gt; - Extensive documentation for Frappe HR.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discuss.erpnext.com/"&gt;User Forum&lt;/a&gt; - Engage with the community of ERPNext users and service providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/frappehr"&gt;Telegram Group&lt;/a&gt; - Get instant help from the community of users.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Issue-Guidelines"&gt;Issue Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext.com/security"&gt;Report Security Vulnerabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Contribution-Guidelines"&gt;Pull Request Requirements&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Logo and Trademark Policy&lt;/h2&gt; 
&lt;p&gt;Please read our &lt;a href="https://raw.githubusercontent.com/frappe/hrms/develop/TRADEMARK_POLICY.md"&gt;Logo and Trademark Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;div align="center" style="padding-top: 0.75rem;"&gt; 
 &lt;a href="https://frappe.io" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/Frappe-white.png"&gt; 
   &lt;img src="https://frappe.io/files/Frappe-black.png" alt="Frappe Technologies" height="28"&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>OpenBB-finance/OpenBB</title>
      <link>https://github.com/OpenBB-finance/OpenBB</link>
      <description>&lt;p&gt;Investment Research for Everyone, Everywhere.&lt;/p&gt;&lt;hr&gt;&lt;br&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-light.svg?raw=true#gh-light-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;img src="https://github.com/OpenBB-finance/OpenBB/raw/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only" alt="OpenBB Platform logo" width="600"&gt; 
&lt;br&gt; 
&lt;br&gt; 
&lt;p&gt;&lt;a href="https://x.com/openbb_finance"&gt;&lt;img src="https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;amp;label=Follow%20%40openbb_finance" alt="Twitter"&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/xPHTuHCmuV"&gt;&lt;img src="https://img.shields.io/discord/831165782750789672" alt="Discord Shield"&gt;&lt;/a&gt; &lt;a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB"&gt;&lt;img src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode" alt="Open in Dev Containers"&gt;&lt;/a&gt; &lt;a href="https://codespaces.new/OpenBB-finance/OpenBB"&gt; &lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" height="20"&gt; &lt;/a&gt; &lt;a target="_blank" href="https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/openbb/"&gt;&lt;img src="https://img.shields.io/pypi/v/openbb?color=blue&amp;amp;label=PyPI%20Package" alt="PyPI"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The first financial Platform that is open source.&lt;/p&gt; 
&lt;p&gt;The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.&lt;/p&gt; 
&lt;p&gt;Get started with: &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openbb import obb
output = obb.equity.price.historical("AAPL")
df = output.to_dataframe()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can sign up to the &lt;a href="https://my.openbb.co/login"&gt;OpenBB Hub&lt;/a&gt; to get the most out of the OpenBB ecosystem.&lt;/p&gt; 
&lt;p&gt;Data integrations available can be found here: &lt;a href="https://docs.openbb.co/platform/reference"&gt;https://docs.openbb.co/platform/reference&lt;/a&gt;&lt;/p&gt; 
&lt;hr&gt; 
&lt;h2&gt;OpenBB Workspace&lt;/h2&gt; 
&lt;p&gt;While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.&lt;/p&gt; 
&lt;p&gt;If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;a href="https://pro.openbb.co"&gt;https://pro.openbb.co&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://pro.openbb.co"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png" alt="Logo" width="1000"&gt; 
 &lt;/div&gt; &lt;/a&gt; 
&lt;p&gt;Data integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding data to the OpenBB workspace from the &lt;a href="https://docs.openbb.co/workspace"&gt;docs&lt;/a&gt; or &lt;a href="https://github.com/OpenBB-finance/backends-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI Agents integration:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can learn more about adding AI agents to the OpenBB workspace from &lt;a href="https://github.com/OpenBB-finance/agents-for-openbb"&gt;this open source repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Integrating OpenBB Platform to the OpenBB Workspace&lt;/h3&gt; 
&lt;p&gt;Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.&lt;/p&gt; 
&lt;h4&gt;Run OpenBB Platform backend&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install the packages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install "openbb[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start the API server over localhost.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;openbb-api
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will launch a FastAPI server, via Uvicorn, at &lt;code&gt;127.0.0.1:6900&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can check that it works by going to &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Integrate OpenBB Platform backend to OpenBB Workspace&lt;/h4&gt; 
&lt;p&gt;Sign-in to the &lt;a href="https://pro.openbb.co/"&gt;OpenBB Workspace&lt;/a&gt;, and follow the following steps:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069" alt="CleanShot 2025-05-17 at 09 51 56@2x"&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to the "Apps" tab&lt;/li&gt; 
 &lt;li&gt;Click on "Connect backend"&lt;/li&gt; 
 &lt;li&gt;Fill in the form with: Name: OpenBB Platform URL: &lt;a href="http://127.0.0.1:6900"&gt;http://127.0.0.1:6900&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click on "Test". You should get a "Test successful" with the number of apps found.&lt;/li&gt; 
 &lt;li&gt;Click on "Add".&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;That's it.&lt;/p&gt; 
&lt;hr&gt; 
&lt;!-- TABLE OF CONTENTS --&gt; 
&lt;details closed="closed"&gt; 
 &lt;summary&gt;&lt;h2 style="display: inline-block"&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#1-installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#2-contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#3-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#4-disclaimer"&gt;Disclaimer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#5-contacts"&gt;Contacts&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#6-star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/OpenBB-finance/OpenBB/develop/#7-contributors"&gt;Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/details&gt; 
&lt;h2&gt;1. Installation&lt;/h2&gt; 
&lt;p&gt;The OpenBB Platform can be installed as a &lt;a href="https://pypi.org/project/openbb/"&gt;PyPI package&lt;/a&gt; by running &lt;code&gt;pip install openbb&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process, in the &lt;a href="https://docs.openbb.co/platform/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;OpenBB Platform CLI installation&lt;/h3&gt; 
&lt;p&gt;The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.&lt;/p&gt; 
&lt;p&gt;It can be installed by running &lt;code&gt;pip install openbb-cli&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;or by cloning the repository directly with &lt;code&gt;git clone https://github.com/OpenBB-finance/OpenBB.git&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Please find more about the installation process in the &lt;a href="https://docs.openbb.co/cli/installation"&gt;OpenBB Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;2. Contributing&lt;/h2&gt; 
&lt;p&gt;There are three main ways of contributing to this project. (Hopefully you have starred the project by now ⭐️)&lt;/p&gt; 
&lt;h3&gt;Become a Contributor&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;More information on our &lt;a href="https://docs.openbb.co/platform/developer_guide/misc/contributing"&gt;Contributing Documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Create a GitHub ticket&lt;/h3&gt; 
&lt;p&gt;Before creating a ticket make sure the one you are creating doesn't exist already &lt;a href="https://github.com/OpenBB-finance/OpenBB/issues"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=bug&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D"&gt;Report bug&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;template=enhancement.md&amp;amp;title=%5BIMPROVE%5D"&gt;Suggest improvement&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;amp;labels=new+feature&amp;amp;template=feature_request.md&amp;amp;title=%5BFR%5D"&gt;Request a feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Provide feedback&lt;/h3&gt; 
&lt;p&gt;We are most active on &lt;a href="https://openbb.co/discord"&gt;our Discord&lt;/a&gt;, but feel free to reach out to us in any of &lt;a href="https://openbb.co/links"&gt;our social media&lt;/a&gt; for feedback.&lt;/p&gt; 
&lt;h2&gt;3. License&lt;/h2&gt; 
&lt;p&gt;Distributed under the AGPLv3 License. See &lt;a href="https://github.com/OpenBB-finance/OpenBB/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;4. Disclaimer&lt;/h2&gt; 
&lt;p&gt;Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment amount, and may not be suitable for all investors.&lt;/p&gt; 
&lt;p&gt;Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.&lt;/p&gt; 
&lt;p&gt;The data contained in the OpenBB Platform is not necessarily accurate.&lt;/p&gt; 
&lt;p&gt;OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.&lt;/p&gt; 
&lt;p&gt;All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.&lt;/p&gt; 
&lt;p&gt;Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.&lt;/p&gt; 
&lt;h2&gt;5. Contacts&lt;/h2&gt; 
&lt;p&gt;If you have any questions about the platform or anything OpenBB, feel free to email us at &lt;code&gt;support@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If you want to say hi, or are interested in partnering with us, feel free to reach us at &lt;code&gt;hello@openbb.co&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Any of our social media platforms: &lt;a href="https://openbb.co/links"&gt;openbb.co/links&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;6. Star History&lt;/h2&gt; 
&lt;p&gt;This is a proxy of our growth and that we are just getting started.&lt;/p&gt; 
&lt;p&gt;But for more metrics important to us check &lt;a href="https://openbb.co/open"&gt;openbb.co/open&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark"&gt;&lt;img src="https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;amp;type=Date&amp;amp;theme=dark" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;7. Contributors&lt;/h2&gt; 
&lt;p&gt;OpenBB wouldn't be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.&lt;/p&gt; 
&lt;a href="https://github.com/OpenBB-finance/OpenBB/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB" width="800"&gt; &lt;/a&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>landing-ai/agentic-doc</title>
      <link>https://github.com/landing-ai/agentic-doc</link>
      <description>&lt;p&gt;Python library for Agentic Document Extraction from LandingAI&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;Agentic&amp;nbsp;Document&amp;nbsp;Extraction – Python&amp;nbsp;Library&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://github.com/landing-ai/agentic-doc/actions/workflows/ci-unit.yml"&gt;&lt;img src="https://github.com/landing-ai/agentic-doc/actions/workflows/ci-unit.yml/badge.svg?sanitize=true" alt="Unit test status"&gt;&lt;/a&gt; &lt;a href="https://github.com/landing-ai/agentic-doc/actions/workflows/ci-integ.yml"&gt;&lt;img src="https://github.com/landing-ai/agentic-doc/actions/workflows/ci-integ.yml/badge.svg?sanitize=true" alt="Integration test status"&gt;&lt;/a&gt; &lt;a href="https://discord.gg/RVcW3j9RgR"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/wPdN8RCYew?compact=true&amp;amp;style=flat" alt=""&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/agentic-doc"&gt;&lt;img src="https://badge.fury.io/py/agentic-doc.svg?sanitize=true" alt="PyPI version"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://va.landing.ai/demo/doc-extraction"&gt;Web App&lt;/a&gt;&amp;nbsp;· &lt;a href="https://discord.com/invite/RVcW3j9RgR"&gt;Discord&lt;/a&gt;&amp;nbsp;· &lt;a href="https://landing.ai/blog/going-beyond-ocrllm-introducing-agentic-document-extraction"&gt;Blog&lt;/a&gt;&amp;nbsp;· &lt;a href="https://support.landing.ai/docs/document-extraction"&gt;Docs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;The LandingAI &lt;strong&gt;Agentic&amp;nbsp;Document&amp;nbsp;Extraction&lt;/strong&gt; API pulls structured data out of visually complex documents—think tables, pictures, and charts—and returns a hierarchical JSON with exact element locations.&lt;/p&gt; 
&lt;p&gt;This Python library wraps that API to provide:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Long‑document support&lt;/strong&gt; – process 100+&amp;nbsp;page PDFs in a single call&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Auto‑retry / paging&lt;/strong&gt; – handles concurrency, time‑outs, and rate limits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Helper utilities&lt;/strong&gt; – bounding‑box snippets, visual debuggers, and more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;📦 &lt;strong&gt;Batteries‑included install:&lt;/strong&gt; &lt;code&gt;pip install agentic-doc&lt;/code&gt; – nothing else needed → see&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🗂️ &lt;strong&gt;All file types:&lt;/strong&gt; parse PDFs of &lt;em&gt;any&lt;/em&gt; length, single images, or URLs → see&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/#supported-files"&gt;Supported&amp;nbsp;Files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;📚 &lt;strong&gt;Long‑doc ready:&lt;/strong&gt; auto‑split&amp;nbsp;&amp;amp;&amp;nbsp;parallel‑process 1000+&amp;nbsp;page PDFs, then stitch results → see&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/#parse-large-pdf-files"&gt;Parse&amp;nbsp;Large&amp;nbsp;PDF&amp;nbsp;Files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🧩 &lt;strong&gt;Structured output:&lt;/strong&gt; returns hierarchical JSON plus ready‑to‑render Markdown → see&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/#result-schema"&gt;Result&amp;nbsp;Schema&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;👁️ &lt;strong&gt;Ground‑truth visuals:&lt;/strong&gt; optional bounding‑box snippets and full‑page visualizations → see&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/#save-groundings-as-images"&gt;Save&amp;nbsp;Groundings&amp;nbsp;as&amp;nbsp;Images&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🏃 &lt;strong&gt;Batch&amp;nbsp;&amp;amp;&amp;nbsp;parallel:&lt;/strong&gt; feed a list; library manages threads&amp;nbsp;&amp;amp;&amp;nbsp;rate limits (&lt;code&gt;BATCH_SIZE&lt;/code&gt;, &lt;code&gt;MAX_WORKERS&lt;/code&gt;) → see&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/#parse-multiple-files-in-a-batch"&gt;Parse&amp;nbsp;Multiple&amp;nbsp;Files&amp;nbsp;in&amp;nbsp;a&amp;nbsp;Batch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🔄 &lt;strong&gt;Resilient:&lt;/strong&gt; exponential‑backoff retries for 408/429/502/503/504 and rate‑limit hits → see&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/#automatically-handle-api-errors-and-rate-limits-with-retries"&gt;Automatically&amp;nbsp;Handle&amp;nbsp;API&amp;nbsp;Errors&amp;nbsp;and&amp;nbsp;Rate&amp;nbsp;Limits&amp;nbsp;with&amp;nbsp;Retries&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🛠️ &lt;strong&gt;Drop‑in helpers:&lt;/strong&gt; &lt;code&gt;parse_documents&lt;/code&gt;, &lt;code&gt;parse_and_save_documents&lt;/code&gt;, &lt;code&gt;parse_and_save_document&lt;/code&gt; → see&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/#main-functions"&gt;Main&amp;nbsp;Functions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;⚙️ &lt;strong&gt;Config via env / .env:&lt;/strong&gt; tweak parallelism, logging style, retry caps—no code changes → see&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/#configuration-options"&gt;Configuration&amp;nbsp;Options&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🌐 &lt;strong&gt;Raw API ready:&lt;/strong&gt; advanced users can still hit the REST endpoint directly → see&amp;nbsp;the&amp;nbsp;&lt;a href="https://support.landing.ai/docs/document-extraction"&gt;API&amp;nbsp;Docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install agentic-doc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Python version 3.9, 3.10, 3.11 or 3.12&lt;/li&gt; 
 &lt;li&gt;LandingAI agentic AI API key (get the key &lt;a href="https://va.landing.ai/settings/api-key"&gt;here&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Set the API Key as an Environment Variable&lt;/h3&gt; 
&lt;p&gt;After you get the LandingAI agentic AI API key, set the key as an environment variable (or put it in a &lt;code&gt;.env&lt;/code&gt; file):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export VISION_AGENT_API_KEY=&amp;lt;your-api-key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Supported Files&lt;/h3&gt; 
&lt;p&gt;The library can extract data from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PDFs (any length)&lt;/li&gt; 
 &lt;li&gt;Images that are supported by OpenCV-Python (i.e. the &lt;code&gt;cv2&lt;/code&gt; library)&lt;/li&gt; 
 &lt;li&gt;URLs pointing to PDF or image files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Basic Usage&lt;/h3&gt; 
&lt;h4&gt;Extract Data from One Document&lt;/h4&gt; 
&lt;p&gt;Run the following script to extract data from one document and return the results in both markdown and structured chunks.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from agentic_doc.parse import parse

# Parse a local file
result = parse("path/to/image.png")
print(result[0].markdown)  # Get the extracted data as markdown
print(result[0].chunks)  # Get the extracted data as structured chunks of content

# Parse a document from a URL
result = parse("https://example.com/document.pdf")
print(result[0].markdown)

# Legacy approach (still supported)
from agentic_doc.parse import parse_documents
results = parse_documents(["path/to/image.png"])
parsed_doc = results[0]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extract Data from Multiple Documents&lt;/h4&gt; 
&lt;p&gt;Run the following script to extract data from multiple documents.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from agentic_doc.parse import parse

# Parse multiple local files
file_paths = ["path/to/your/document1.pdf", "path/to/another/document2.pdf"]
results = parse(file_paths)
for result in results:
    print(result.markdown)

# Parse and save results to a directory
results = parse(file_paths, result_save_dir="path/to/save/results")
result_paths = []
for result in results:
    result_paths.append(result.result_path)
# result_paths: ["path/to/save/results/document1_20250313_070305.json", ...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using field extraction&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from pydantic import BaseModel, Field
from agentic_doc.parse import parse

class ExtractedFields(BaseModel):
    employee_name: str = Field(description="the full name of the employee")
    employee_ssn: str = Field(description="the social security number of the employee")
    gross_pay: float = Field(description="the gross pay of the employee")
    employee_address: str = Field(description="the address of the employee")

results = parse("mydoc.pdf", extraction_model=ExtractedFields)
fields = results[0].extraction
metadata = results[0].extraction_metadata
print(f"Field value: {fields.employee_name}, confidence: {metadata.employee_name.confidence}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extract Data Using Connectors&lt;/h4&gt; 
&lt;p&gt;The library now supports various connectors to easily access documents from different sources:&lt;/p&gt; 
&lt;h5&gt;Google Drive Connector&lt;/h5&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites: Follow the &lt;a href="https://developers.google.com/workspace/drive/api/quickstart/python"&gt;Google Drive API Python Quickstart&lt;/a&gt; tutorial first to set up your credentials.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The Google Drive API quickstart will guide you through:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Creating a Google Cloud project&lt;/li&gt; 
 &lt;li&gt;Enabling the Google Drive API&lt;/li&gt; 
 &lt;li&gt;Setting up OAuth 2.0 credentials&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;After completing the quickstart tutorial, you can use the Google Drive connector as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from agentic_doc.parse import parse
from agentic_doc.connectors import GoogleDriveConnectorConfig

# Using OAuth credentials file (from quickstart tutorial)
config = GoogleDriveConnectorConfig(
    client_secret_file="path/to/credentials.json",
    folder_id="your-google-drive-folder-id"  # Optional
)

# Parse all documents in the folder
results = parse(config)

# Parse with filtering
results = parse(config, connector_pattern="*.pdf")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Amazon S3 Connector&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from agentic_doc.parse import parse
from agentic_doc.connectors import S3ConnectorConfig

config = S3ConnectorConfig(
    bucket_name="your-bucket-name",
    aws_access_key_id="your-access-key",  # Optional if using IAM roles
    aws_secret_access_key="your-secret-key",  # Optional if using IAM roles
    region_name="us-east-1"
)

# Parse all documents in the bucket
results = parse(config)

# Parse documents in a specific prefix/folder
results = parse(config, connector_path="documents/")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Local Directory Connector&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from agentic_doc.parse import parse
from agentic_doc.connectors import LocalConnectorConfig

config = LocalConnectorConfig()

# Parse all supported documents in a directory
results = parse(config, connector_path="/path/to/documents")

# Parse with pattern filtering
results = parse(config, connector_path="/path/to/documents", connector_pattern="*.pdf")

# Parse all supported documents in a directory recursively (search subdirectories as well)
config = LocalConnectorConfig(recursive=True)
results = parse(config, connector_path="/path/to/documents")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;URL Connector&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from agentic_doc.parse import parse
from agentic_doc.connectors import URLConnectorConfig

config = URLConnectorConfig(
    headers={"Authorization": "Bearer your-token"},  # Optional
    timeout=60  # Optional
)

# Parse document from URL
results = parse(config, connector_path="https://example.com/document.pdf")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Raw Bytes Input&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from agentic_doc.parse import parse

# Load a PDF or image file as bytes
with open("document.pdf", "rb") as f:
    raw_bytes = f.read()

# Parse the document from bytes
results = parse(raw_bytes)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also parse image bytes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;with open("image.png", "rb") as f:
    image_bytes = f.read()

results = parse(image_bytes)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is useful when documents are already loaded into memory (e.g., from an API response or uploaded via a web interface). The parser will auto-detect the file type from the bytes.&lt;/p&gt; 
&lt;h2&gt;Why Use It?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Simplified Setup:&lt;/strong&gt; No need to manage API keys or handle low-level REST calls.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Large File Processing:&lt;/strong&gt; Splits large PDFs into manageable parts and processes them in parallel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-In Error Handling:&lt;/strong&gt; Automatically retries requests with exponential backoff and jitter for common HTTP errors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel Processing:&lt;/strong&gt; Efficiently parse multiple documents at once with configurable parallelism.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Main Features&lt;/h2&gt; 
&lt;p&gt;With this library, you can do things that are otherwise hard to do with the Agentic Document Extraction API alone. This section describes some of the key features this library offers.&lt;/p&gt; 
&lt;h3&gt;Parse Large PDF Files&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;A single REST API call can only handle up to certain amount of pages at a time&lt;/strong&gt; (see &lt;a href="https://docs.landing.ai/ade/ade-rate-limits#maximum-pages-per-document"&gt;rate limits&lt;/a&gt;). This library automatically splits a large PDF into multiple calls, uses a thread pool to process the calls in parallel, and stitches the results back together as a single result.&lt;/p&gt; 
&lt;p&gt;We've used this library to successfully parse PDFs that are 1000+ pages long.&lt;/p&gt; 
&lt;h3&gt;Parse Multiple Files in a Batch&lt;/h3&gt; 
&lt;p&gt;You can parse multiple files in a single function call with this library. The library processes files in parallel.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; You can change the parallelism by setting the &lt;code&gt;batch_size&lt;/code&gt; setting.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Save Groundings as Images&lt;/h3&gt; 
&lt;p&gt;The library can extract and save the visual regions (groundings) of the document where each chunk of content was found. This is useful for visualizing exactly what parts of the document were extracted and for debugging extraction issues.&lt;/p&gt; 
&lt;p&gt;Each grounding represents a bounding box in the original document, and the library can save these regions as individual PNG images. The images are organized by page number and chunk ID.&lt;/p&gt; 
&lt;p&gt;Here's how to use this feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from agentic_doc.parse import parse_documents

# Save groundings when parsing a document
results = parse_documents(
    ["path/to/document.pdf"],
    grounding_save_dir="path/to/save/groundings"
)

# The grounding images will be saved to:
# path/to/save/groundings/document_TIMESTAMP/page_X/CHUNK_TYPE_CHUNK_ID_Y.png
# Where X is the page number, CHUNK_ID is the unique ID of each chunk,
# and Y is the index of the grounding within the chunk

# Each chunk's grounding in the result will have the image_path set
for chunk in results[0].chunks:
    for grounding in chunk.grounding:
        if grounding.image_path:
            print(f"Grounding saved to: {grounding.image_path}")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This feature works with all parsing functions: &lt;code&gt;parse_documents&lt;/code&gt;, &lt;code&gt;parse_and_save_documents&lt;/code&gt;, and &lt;code&gt;parse_and_save_document&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Visualize Parsing Result&lt;/h3&gt; 
&lt;p&gt;The library provides a visualization utility that creates annotated images showing where each chunk of content was extracted from the document. This is useful for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Verifying the accuracy of the extraction&lt;/li&gt; 
 &lt;li&gt;Debugging extraction issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here's how to use the visualization feature:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from agentic_doc.parse import parse
from agentic_doc.utils import viz_parsed_document
from agentic_doc.config import VisualizationConfig

# Parse a document
results = parse("path/to/document.pdf")
parsed_doc = results[0]

# Create visualizations with default settings
# The output images have a PIL.Image.Image type
images = viz_parsed_document(
    "path/to/document.pdf",
    parsed_doc,
    output_dir="path/to/save/visualizations"
)

# Or customize the visualization appearance
viz_config = VisualizationConfig(
    thickness=2,  # Thicker bounding boxes
    text_bg_opacity=0.8,  # More opaque text background
    font_scale=0.7,  # Larger text
    # Custom colors for different chunk types
    color_map={
        ChunkType.TITLE: (0, 0, 255),  # Red for titles
        ChunkType.TEXT: (255, 0, 0),  # Blue for regular text
        # ... other chunk types ...
    }
)

images = viz_parsed_document(
    "path/to/document.pdf",
    parsed_doc,
    output_dir="path/to/save/visualizations",
    viz_config=viz_config
)

# The visualization images will be saved as:
# path/to/save/visualizations/document_viz_page_X.png
# Where X is the page number
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The visualization shows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bounding boxes around each extracted chunk&lt;/li&gt; 
 &lt;li&gt;Chunk type and index labels&lt;/li&gt; 
 &lt;li&gt;Different colors for different types of content (titles, text, tables, etc.)&lt;/li&gt; 
 &lt;li&gt;Semi-transparent text backgrounds for better readability&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Automatically Handle API Errors and Rate Limits with Retries&lt;/h3&gt; 
&lt;p&gt;The REST API endpoint imposes rate limits per API key. This library automatically handles the rate limit error or other intermittent HTTP errors with retries.&lt;/p&gt; 
&lt;p&gt;For more information, see &lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/#error-handling"&gt;Error Handling&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/#configuration-options"&gt;Configuration Options&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Error Handling&lt;/h3&gt; 
&lt;p&gt;This library implements a retry mechanism for handling API failures:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Retries are performed for these HTTP status codes: 408, 429, 502, 503, 504.&lt;/li&gt; 
 &lt;li&gt;Exponential backoff with jitter is used for retry wait time.&lt;/li&gt; 
 &lt;li&gt;The initial retry wait time is 1 second, which increases exponentially.&lt;/li&gt; 
 &lt;li&gt;Retry will stop after &lt;code&gt;max_retries&lt;/code&gt; attempts. Exceeding the limit raises an exception and results in a failure for this request.&lt;/li&gt; 
 &lt;li&gt;Retry wait time is capped at &lt;code&gt;max_retry_wait_time&lt;/code&gt; seconds.&lt;/li&gt; 
 &lt;li&gt;Retries include a random jitter of up to 10 seconds to distribute requests and prevent the thundering herd problem.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Parsing Errors&lt;/h3&gt; 
&lt;p&gt;If the REST API request encounters an unrecoverable error during parsing (either from client-side or server-side), the library includes an &lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/agentic_doc/common.py#L75"&gt;errors&lt;/a&gt; field in the final result for the affected page(s). Each error contains the error message, error_code and corresponding page number.&lt;/p&gt; 
&lt;h2&gt;Configuration Options&lt;/h2&gt; 
&lt;p&gt;The library uses a &lt;a href="https://raw.githubusercontent.com/landing-ai/agentic-doc/main/agentic_doc/config.py"&gt;&lt;code&gt;Settings&lt;/code&gt;&lt;/a&gt; object to manage configuration. You can customize these settings either through environment variables or a &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;p&gt;Below is an example &lt;code&gt;.env&lt;/code&gt; file that customizes the configurations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Number of files to process in parallel, defaults to 4
BATCH_SIZE=4
# Number of threads used to process parts of each file in parallel, defaults to 5.
MAX_WORKERS=2
# Maximum number of retry attempts for failed intermittent requests, defaults to 100
MAX_RETRIES=80
# Maximum wait time in seconds for each retry, defaults to 60
MAX_RETRY_WAIT_TIME=30
# Logging style for retry, defaults to log_msg
RETRY_LOGGING_STYLE=log_msg
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Max Parallelism&lt;/h3&gt; 
&lt;p&gt;The maximum number of parallel requests is determined by multiplying &lt;code&gt;BATCH_SIZE&lt;/code&gt; × &lt;code&gt;MAX_WORKERS&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; The maximum parallelism allowed by this library is 100.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Specifically, increasing &lt;code&gt;MAX_WORKERS&lt;/code&gt; can speed up the processing of large individual files, while increasing &lt;code&gt;BATCH_SIZE&lt;/code&gt; improves throughput when processing multiple files.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Your job's maximum processing throughput may be limited by your API rate limit. If your rate limit isn't high enough, you may encounter rate limit errors, which the library will automatically handle through retries.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The optimal values for &lt;code&gt;MAX_WORKERS&lt;/code&gt; and &lt;code&gt;BATCH_SIZE&lt;/code&gt; depend on your API rate limit and the latency of each REST API call. For example, if your account has a rate limit of 5 requests per minute, and each REST API call takes approximately 60 seconds to complete, and you're processing a single large file, then &lt;code&gt;MAX_WORKERS&lt;/code&gt; should be set to 5 and &lt;code&gt;BATCH_SIZE&lt;/code&gt; to 1.&lt;/p&gt; 
&lt;p&gt;You can find your REST API latency in the logs. If you want to increase your rate limit, schedule a time to meet with us &lt;a href="https://scheduler.zoom.us/d/56i81uc2/landingai-document-extraction"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Set &lt;code&gt;RETRY_LOGGING_STYLE&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;RETRY_LOGGING_STYLE&lt;/code&gt; setting controls how the library logs the retry attempts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;log_msg&lt;/code&gt;: Log the retry attempts as a log messages. Each attempt is logged as a separate message. This is the default setting.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;inline_block&lt;/code&gt;: Print a yellow progress block ('█') on the same line. Each block represents one retry attempt. Choose this if you don't want to see the verbose retry logging message and still want to track the number of retries that have been made.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;none&lt;/code&gt;: Do not log the retry attempts.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Troubleshooting &amp;amp; FAQ&lt;/h2&gt; 
&lt;h3&gt;Common Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;API Key Errors:&lt;/strong&gt; Ensure your API key is correctly set as an environment variable.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rate Limits:&lt;/strong&gt; The library automatically retries requests if you hit the API rate limit. Adjust &lt;code&gt;BATCH_SIZE&lt;/code&gt; or &lt;code&gt;MAX_WORKERS&lt;/code&gt; if you encounter frequent rate limit errors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parsing Failures:&lt;/strong&gt; If a document fails to parse, an error chunk will be included in the result, detailing the error message and page index.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;URL Access Issues:&lt;/strong&gt; If you're having trouble accessing documents from URLs, check that the URLs are publicly accessible and point to supported file types (PDF or images).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Note on &lt;code&gt;include_marginalia&lt;/code&gt; and &lt;code&gt;include_metadata_in_markdown&lt;/code&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;include_marginalia&lt;/code&gt;: If True, the parser will attempt to extract and include marginalia (footer notes, page number, etc.) from the document in the output.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;include_metadata_in_markdown&lt;/code&gt;: If True, the output markdown will include metadata.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Both parameters default to True. You can set them to False to exclude these elements from the output.&lt;/p&gt; 
&lt;h4&gt;Example: Using the new parameters&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from agentic_doc.parse import parse

results = parse(
    "path/to/document.pdf",
    include_marginalia=False,  # Exclude marginalia from output
    include_metadata_in_markdown=False  # Exclude metadata from markdown
)
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>hesreallyhim/awesome-claude-code</title>
      <link>https://github.com/hesreallyhim/awesome-claude-code</link>
      <description>&lt;p&gt;A curated list of awesome commands, files, and workflows for Claude Code&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;/h1&gt; 
&lt;!-- [![Awesome](https://awesome.re/badge-flat2.svg)](https://awesome.re) --&gt; 
&lt;pre style="display: inline-block; text-align: left;"&gt;
 █████┐ ██┐    ██┐███████┐███████┐ ██████┐ ███┐   ███┐███████┐
██┌──██┐██│    ██│██┌────┘██┌────┘██┌───██┐████┐ ████│██┌────┘
███████│██│ █┐ ██│█████┐  ███████┐██│   ██│██┌████┌██│█████┐
██┌──██│██│███┐██│██┌──┘  └────██│██│   ██│██│└██┌┘██│██┌──┘
██│  ██│└███┌███┌┘███████┐███████│└██████┌┘██│ └─┘ ██│███████┐
└─┘  └─┘ └──┘└──┘ └──────┘└──────┘ └─────┘ └─┘     └─┘└──────┘

 ────────────────────────────────────────────────────────────────────────────────────

 ██████┐██┐      █████┐ ██┐   ██┐██████┐ ███████┐     ██████┐ ██████┐ ██████┐ ███████┐
██┌────┘██│     ██┌──██┐██│   ██│██┌──██┐██┌────┘    ██┌────┘██┌───██┐██┌──██┐██┌────┘
██│     ██│     ███████│██│   ██│██│  ██│█████┐      ██│     ██│   ██│██│  ██│█████┐
██│     ██│     ██┌──██│██│   ██│██│  ██│██┌──┘      ██│     ██│   ██│██│  ██│██┌──┘
└██████┐███████┐██│  ██│└██████┌┘██████┌┘███████┐    └██████┐└██████┌┘██████┌┘███████┐
 └─────┘└──────┘└─┘  └─┘ └─────┘ └─────┘ └──────┘     └─────┘ └─────┘ └─────┘ └──────┘
&lt;/pre&gt; 
&lt;!--lint enable remark-lint:awesome-badge--&gt; 
&lt;p&gt;&lt;a href="https://awesome.re"&gt;&lt;img src="https://awesome.re/badge-flat2.svg?sanitize=true" alt="Awesome"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;&lt;a href="https://github.com/hesreallyhim/awesome-claude-code"&gt;Awesome Claude Code&lt;/a&gt; 🤝 &lt;a href="https://github.com/hesreallyhim/awesome-claude-code-agents"&gt;Awesome Claude Code Agents&lt;/a&gt;&lt;/h1&gt; 
&lt;!--lint enable remark-lint:awesome-badge--&gt; 
&lt;!--lint disable double-link--&gt; 
&lt;p&gt;This is a curated list of slash-commands, &lt;code&gt;CLAUDE.md&lt;/code&gt; files, CLI tools, and other resources and guides for enhancing your &lt;a href="https://docs.anthropic.com/en/docs/claude-code"&gt;Claude Code&lt;/a&gt; workflow, productivity, and vibes.&lt;/p&gt; 
&lt;!--lint enable double-link--&gt; 
&lt;p&gt;Claude Code is a cutting-edge CLI-based coding assistant and agent that you can access in your terminal or IDE. It is a rapidly evolving tool that offers a number of powerful capabilities, and allows for a lot of configuration, in a lot of different ways. Users are actively working out best practices and workflows. It is the hope that this repo will help the community share knowledge and understand how to get the most out of Claude Code.&lt;/p&gt; 
&lt;h3&gt;Announcements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;2025-07-26 - Anthropic done done it again, and Claude Code now has another super-power in its arsenal - custom user Sub Agents! I was thinking I might add a little section at the bottom about this "agent" thing, but then I tried it, and I think they're amazing, and probably deserve their own repo, so come and check out &lt;a href="https://github.com/hesreallyhim/awesome-claude-code-agents"&gt;awesome-claude-code-agents&lt;/a&gt; and get those submissions rolling in. Can't wait to see what people are getting up to already with this new tech.&lt;/li&gt; 
 &lt;li&gt;2025-07-25 - The new-new submission workflow is up now, I've managed to make it about 4-5 times more complicated than it should be 😜 so check out &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/CONTRIBUTING.md"&gt;&lt;code&gt;CONTRIBUTING.md&lt;/code&gt;&lt;/a&gt; if you'd like to submit a new resource.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br&gt; 
&lt;h2&gt;Contents&lt;/h2&gt; 
&lt;p&gt;▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#workflows--knowledge-guides-"&gt;Workflows &amp;amp; Knowledge Guides&lt;/a&gt;&lt;br&gt; ▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#tooling-"&gt;Tooling&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#ide-integrations"&gt;IDE Integrations&lt;/a&gt;&lt;br&gt; ▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#hooks-"&gt;Hooks&lt;/a&gt;&lt;br&gt; ▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#slash-commands-"&gt;Slash-Commands&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#version-control--git"&gt;Version Control &amp;amp; Git&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#code-analysis--testing"&gt;Code Analysis &amp;amp; Testing&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#context-loading--priming"&gt;Context Loading &amp;amp; Priming&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#documentation--changelogs"&gt;Documentation &amp;amp; Changelogs&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#ci--deployment"&gt;CI / Deployment&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#project--task-management"&gt;Project &amp;amp; Task Management&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#miscellaneous"&gt;Miscellaneous&lt;/a&gt;&lt;br&gt; ▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#claudemd-files-"&gt;CLAUDE.md Files&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#language-specific"&gt;Language-Specific&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#domain-specific"&gt;Domain-Specific&lt;/a&gt;&lt;br&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;▫&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#project-scaffolding--mcp"&gt;Project Scaffolding &amp;amp; MCP&lt;/a&gt;&lt;br&gt; ▪&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/#official-documentation-"&gt;Official Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Workflows &amp;amp; Knowledge Guides 🧠&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A &lt;strong&gt;workflow&lt;/strong&gt; is a tightly coupled set of Claude Code-native resources that facilitate specific projects&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/cloudartisan/cloudartisan.github.io/tree/main/.claude/commands"&gt;&lt;code&gt;Blogging Platform Instructions&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/cloudartisan"&gt;cloudartisan&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;CC-BY-SA-4.0&lt;br&gt; Provides a well-structured set of commands for publishing and maintaining a blogging platform, including commands for creating posts, managing categories, and handling media files.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://claudelog.com"&gt;&lt;code&gt;ClaudeLog&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://www.reddit.com/user/inventor_black/"&gt;InventorBlack&lt;/a&gt;&lt;br&gt; A comprehensive knowledge base with detailed breakdowns of advanced &lt;a href="https://claudelog.com/mechanics/you-are-the-main-thread/"&gt;mechanics&lt;/a&gt; including &lt;a href="https://claudelog.com/mechanics/claude-md-supremacy"&gt;CLAUDE.md best practices&lt;/a&gt;, practical technique guides like &lt;a href="https://claudelog.com/mechanics/plan-mode"&gt;plan mode&lt;/a&gt;, &lt;a href="https://claudelog.com/faqs/what-is-ultrathink/"&gt;ultrathink&lt;/a&gt;, &lt;a href="https://claudelog.com/mechanics/task-agent-tools/"&gt;sub-agents&lt;/a&gt;, &lt;a href="https://claudelog.com/mechanics/agent-first-design/"&gt;agent-first design&lt;/a&gt; and &lt;a href="https://claudelog.com/configuration"&gt;configuration guides&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/disler/just-prompt/tree/main/.claude/commands"&gt;&lt;code&gt;Context Priming&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/disler"&gt;disler&lt;/a&gt;&lt;br&gt; Provides a systematic approach to priming Claude Code with comprehensive project context through specialized commands for different project scenarios and development contexts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kingler/n8n_agent/tree/main/.claude/commands"&gt;&lt;code&gt;n8n_agent&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/kingler"&gt;kingler&lt;/a&gt;&lt;br&gt; Amazing comprehensive set of comments for code analysis, QA, design, documentation, project structure, project management, optimization, and many more.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/steadycursor/steadystart/tree/main/.claude/commands"&gt;&lt;code&gt;Project Bootstrapping and Task Management&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt;&lt;br&gt; Provides a structured set of commands for bootstrapping and managing a new project, including meta-commands for creating and editing custom slash-commands.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/scopecraft/command/tree/main/.claude/commands"&gt;&lt;code&gt;Project Management, Implementation, Planning, and Release&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/scopecraft"&gt;scopecraft&lt;/a&gt;&lt;br&gt; Really comprehensive set of commands for all aspects of SDLC.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/harperreed/dotfiles/tree/master/.claude/commands"&gt;&lt;code&gt;Project Workflow System&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/harperreed"&gt;harperreed&lt;/a&gt;&lt;br&gt; A set of commands that provide a comprehensive workflow system for managing projects, including task management, code review, and deployment processes.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://diwank.space/field-notes-from-shipping-real-code-with-claude"&gt;&lt;code&gt;Shipping Real Code w/ Claude&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/creatorrr"&gt;Diwank&lt;/a&gt;&lt;br&gt; A detailed blog post explaining the author's process for shipping a product with Claude Code, including CLAUDE.md files and other interesting resources.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Helmi/claude-simone"&gt;&lt;code&gt;Simone&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Helmi"&gt;Helmi&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A broader project management workflow for Claude Code that encompasses not just a set of commands, but a system of documents, guidelines, and processes to facilitate project planning and execution.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/wcygan/dotfiles/tree/d8ab6b9f5a7a81007b7f5fa3025d4f83ce12cc02/claude/commands"&gt;&lt;code&gt;Slash-commands megalist&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/wcygan"&gt;wcygan&lt;/a&gt;&lt;br&gt; A pretty stunning list (88 at the time of this post!) of slash-commands ranging from agent orchestration, code review, project management, security, documentation, self-assessment, almost anything you can dream of.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Tooling 🧰&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Tooling&lt;/strong&gt; denotes applications that are built on top of Claude Code and consist of more components than slash-commands and &lt;code&gt;CLAUDE.md&lt;/code&gt; files&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/ryoppippi/ccusage"&gt;&lt;code&gt;CC Usage&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ryoppippi"&gt;ryoppippi&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Handy CLI tool for managing and analyzing Claude Code usage, based on analyzing local Claude Code logs. Presents a nice dashboard regarding cost information, token consumption, etc.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/nyatinte/ccexp"&gt;&lt;code&gt;ccexp&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/nyatinte"&gt;nyatinte&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Interactive CLI tool for discovering and managing Claude Code configuration files and slash commands with a beautiful terminal UI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ruvnet/claude-code-flow"&gt;&lt;code&gt;Claude Code Flow&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ruvnet"&gt;ruvnet&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; This mode serves as a code-first orchestration layer, enabling Claude to write, edit, test, and optimize code autonomously across recursive agent cycles.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor"&gt;&lt;code&gt;Claude Code Usage Monitor&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Maciek-roboblog"&gt;Maciek-roboblog&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A real-time terminal-based tool for monitoring Claude Code token usage. It shows live token consumption, burn rate, and predictions for token depletion. Features include visual progress bars, session-aware analytics, and support for multiple subscription plans.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/possibilities/claude-composer"&gt;&lt;code&gt;Claude Composer&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/possibilities"&gt;Mike Bannister&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Unlicense&lt;br&gt; A tool that adds small enhancements to Claude Code.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/claude-did-this/claude-hub"&gt;&lt;code&gt;Claude Hub&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/claude-did-this"&gt;Claude Did This&lt;/a&gt;&lt;br&gt; A webhook service that connects Claude Code to GitHub repositories, enabling AI-powered code assistance directly through pull requests and issues. This integration allows Claude to analyze repositories, answer technical questions, and help developers understand and improve their codebase through simple @mentions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/smtg-ai/claude-squad"&gt;&lt;code&gt;Claude Squad&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/smtg-ai"&gt;smtg-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br&gt; Claude Squad is a terminal app that manages multiple Claude Code, Codex (and other local agents including Aider) in separate workspaces, allowing you to work on multiple tasks simultaneously.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/parruda/claude-swarm"&gt;&lt;code&gt;Claude Swarm&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/parruda"&gt;parruda&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Launch Claude Code session that is connected to a swarm of Claude Code Agents.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/eyaltoledano/claude-task-master"&gt;&lt;code&gt;Claude Task Master&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/eyaltoledano"&gt;eyaltoledano&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; A task management system for AI-driven development with Claude, designed to work seamlessly with Cursor AI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/grahama1970/claude-task-runner"&gt;&lt;code&gt;Claude Task Runner&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/grahama1970"&gt;grahama1970&lt;/a&gt;&lt;br&gt; A specialized tool to manage context isolation and focused task execution with Claude Code, solving the critical challenge of context length limitations and task focus when working with Claude on complex, multi-step projects.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/dagger/container-use"&gt;&lt;code&gt;Container Use&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/dagger"&gt;dagger&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Development environments for coding agents. Enable multiple agents to work safely and independently with your preferred stack.&lt;/p&gt; 
&lt;h3&gt;IDE Integrations&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=AndrePimenta.claude-code-chat"&gt;&lt;code&gt;Claude Code Chat&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/andrepimenta"&gt;andrepimenta&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;©&lt;br&gt; An elegant and user-friendly Claude Code chat interface for VS Code.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/stevemolitor/claude-code.el"&gt;&lt;code&gt;claude-code.el&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/stevemolitor"&gt;stevemolitor&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; An Emacs interface for Claude Code CLI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/greggh/claude-code.nvim"&gt;&lt;code&gt;claude-code.nvim&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/greggh"&gt;greggh&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A seamless integration between Claude Code AI assistant and Neovim.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/stravu/crystal"&gt;&lt;code&gt;crystal&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/stravu"&gt;stravu&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A full-fledged desktop application for orchestrating, monitoring, and interacting with Claude Code agents.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Hooks 🪝&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Hooks&lt;/strong&gt; are a brand new API for Claude Code that allows users to activate commands and run scripts at different points in Claude's agentic lifecycle.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;[Experimental]&lt;/strong&gt; - The resources listed in this section have not been fully vetted and may not work as expected, given the bleeding-edge nature of Claude Code hooks. Nevertheless, I wished to include them at least as a source of inspiration and to explore this unknown terrain. YMMV!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/beyondcode/claude-hooks-sdk"&gt;&lt;code&gt;claude-code-hooks-sdk&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/beyondcode"&gt;beyondcode&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A Laravel-inspired PHP SDK for building Claude Code hook responses with a clean, fluent API. This SDK makes it easy to create structured JSON responses for Claude Code hooks using an expressive, chainable interface.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/johnlindquist/claude-hooks"&gt;&lt;code&gt;claude-hooks&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/johnlindquist"&gt;John Lindquist&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A TypeScript-based system for configuring and customizing Claude Code hooks with a powerful and flexible interface.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Veraticus/nix-config/tree/main/home-manager/claude-code/hooks"&gt;&lt;code&gt;Linting, testing, and notifications (in go)&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Veraticus"&gt;Josh Symonds&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Nice set of hooks for enforcing code quality (linting, testing, notifications), with a nice configuration setup as well.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/nizos/tdd-guard"&gt;&lt;code&gt;TDD Guard&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/nizos"&gt;Nizar Selander&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A hooks-driven system that monitors file operations in real-time and blocks changes that violate TDD principles.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Slash-Commands 🔪&lt;/h2&gt; 
&lt;h3&gt;Version Control &amp;amp; Git&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/danielscholl/mvn-mcp-server/raw/main/.claude/commands/bug-fix.md"&gt;&lt;code&gt;/bug-fix&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/danielscholl"&gt;danielscholl&lt;/a&gt;&lt;br&gt; Streamlines bug fixing by creating a GitHub issue first, then a feature branch for implementing and thoroughly testing the solution before merging.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/commit.md"&gt;&lt;code&gt;/commit&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Creates git commits using conventional commit format with appropriate emojis, following project standards and creating descriptive messages that explain the purpose of changes.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/steadycursor/steadystart/raw/main/.claude/commands/2-commit-fast.md"&gt;&lt;code&gt;/commit-fast&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt;&lt;br&gt; Automates git commit process by selecting the first suggested message, generating structured commits with consistent formatting while skipping manual confirmation and removing Claude co-Contributorship footer&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/toyamarinyon/giselle/raw/main/.claude/commands/create-pr.md"&gt;&lt;code&gt;/create-pr&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/toyamarinyon"&gt;toyamarinyon&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Streamlines pull request creation by handling the entire workflow: creating a new branch, committing changes, formatting modified files with Biome, and submitting the PR.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/liam-hq/liam/raw/main/.claude/commands/create-pull-request.md"&gt;&lt;code&gt;/create-pull-request&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/liam-hq"&gt;liam-hq&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Provides comprehensive PR creation guidance with GitHub CLI, enforcing title conventions, following template structure, and offering concrete command examples with best practices.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/create-worktrees.md"&gt;&lt;code&gt;/create-worktrees&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Creates git worktrees for all open PRs or specific branches, handling branches with slashes, cleaning up stale worktrees, and supporting custom branch creation for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/jeremymailen/kotlinter-gradle/raw/master/.claude/commands/fix-github-issue.md"&gt;&lt;code&gt;/fix-github-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/jeremymailen"&gt;jeremymailen&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Analyzes and fixes GitHub issues using a structured approach with GitHub CLI for issue details, implementing necessary code changes, running tests, and creating proper commit messages.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/.claude/commands/fix-issue.md"&gt;&lt;code&gt;/fix-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Addresses GitHub issues by taking issue number as parameter, analyzing context, implementing solution, and testing/validating the fix for proper integration.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/.claude/commands/fix-pr.md"&gt;&lt;code&gt;/fix-pr&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Fetches and fixes unresolved PR comments by automatically retrieving feedback, addressing reviewer concerns, making targeted code improvements, and streamlining the review process.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/evmts/tevm-monorepo/raw/main/.claude/commands/husky.md"&gt;&lt;code&gt;/husky&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/evmts"&gt;evmts&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Sets up and manages Husky Git hooks by configuring pre-commit hooks, establishing commit message standards, integrating with linting tools, and ensuring code quality on commits.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/arkavo-org/opentdf-rs/raw/main/.claude/commands/pr-review.md"&gt;&lt;code&gt;/pr-review&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/arkavo-org"&gt;arkavo-org&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Reviews pull request changes to provide feedback, check for issues, and suggest improvements before merging into the main codebase.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/giselles-ai/giselle/raw/main/.claude/commands/update-branch-name.md"&gt;&lt;code&gt;/update-branch-name&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/giselles-ai"&gt;giselles-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Updates branch names with proper prefixes and formats, enforcing naming conventions, supporting semantic prefixes, and managing remote branch updates.&lt;/p&gt; 
&lt;h3&gt;Code Analysis &amp;amp; Testing&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/rygwdn/slack-tools/raw/main/.claude/commands/check.md"&gt;&lt;code&gt;/check&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/rygwdn"&gt;rygwdn&lt;/a&gt;&lt;br&gt; Performs comprehensive code quality and security checks, featuring static analysis integration, security vulnerability scanning, code style enforcement, and detailed reporting.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Graphlet-AI/eridu/raw/main/.claude/commands/clean.md"&gt;&lt;code&gt;/clean&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Graphlet-AI"&gt;Graphlet-AI&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Addresses code formatting and quality issues by fixing black formatting problems, organizing imports with isort, resolving flake8 linting issues, and correcting mypy type errors.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kingler/n8n_agent/raw/main/.claude/commands/code_analysis.md"&gt;&lt;code&gt;/code_analysis&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/kingler"&gt;kingler&lt;/a&gt;&lt;br&gt; Provides a menu of advanced code analysis commands for deep inspection, including knowledge graph generation, optimization suggestions, and quality evaluation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/to4iki/ai-project-rules/raw/main/.claude/commands/optimize.md"&gt;&lt;code&gt;/optimize&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/to4iki"&gt;to4iki&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Analyzes code performance to identify bottlenecks, proposing concrete optimizations with implementation guidance for improved application performance.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/rzykov/metabase/raw/master/.claude/commands/repro-issue.md"&gt;&lt;code&gt;/repro-issue&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/rzykov"&gt;rzykov&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Creates reproducible test cases for GitHub issues, ensuring tests fail reliably and documenting clear reproduction steps for developers.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/zscott/pane/raw/main/.claude/commands/tdd.md"&gt;&lt;code&gt;/tdd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/zscott"&gt;zscott&lt;/a&gt;&lt;br&gt; Guides development using Test-Driven Development principles, enforcing Red-Green-Refactor discipline, integrating with git workflow, and managing PR creation.&lt;/p&gt; 
&lt;h3&gt;Context Loading &amp;amp; Priming&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/elizaOS/elizaos.github.io/raw/main/.claude/commands/context-prime.md"&gt;&lt;code&gt;/context-prime&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/elizaOS"&gt;elizaOS&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Primes Claude with comprehensive project understanding by loading repository structure, setting development context, establishing project goals, and defining collaboration parameters.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/okuvshynov/cubestat/raw/main/.claude/commands/initref.md"&gt;&lt;code&gt;/initref&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/okuvshynov"&gt;okuvshynov&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Initializes reference documentation structure with standard doc templates, API reference setup, documentation conventions, and placeholder content generation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ethpandaops/xatu-data/raw/master/.claude/commands/load-llms-txt.md"&gt;&lt;code&gt;/load-llms-txt&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ethpandaops"&gt;ethpandaops&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Loads LLM configuration files to context, importing specific terminology, model configurations, and establishing baseline terminology for AI discussions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/load_coo_context.md"&gt;&lt;code&gt;/load_coo_context&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br&gt; References specific files for sparse matrix operations, explains transform usage, compares with previous approaches, and sets data formatting context for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/load_dango_pipeline.md"&gt;&lt;code&gt;/load_dango_pipeline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br&gt; Sets context for model training by referencing pipeline files, establishing working context, and preparing for pipeline work with relevant documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/yzyydev/AI-Engineering-Structure/raw/main/.claude/commands/prime.md"&gt;&lt;code&gt;/prime&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/yzyydev"&gt;yzyydev&lt;/a&gt;&lt;br&gt; Sets up initial project context by viewing directory structure and reading key files, creating standardized context with directory visualization and key documentation focus.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ddisisto/si/raw/main/.claude/commands/rsi.md"&gt;&lt;code&gt;/rsi&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ddisisto"&gt;ddisisto&lt;/a&gt;&lt;br&gt; Reads all commands and key project files to optimize AI-assisted development by streamlining the process, loading command context, and setting up for better development workflow.&lt;/p&gt; 
&lt;h3&gt;Documentation &amp;amp; Changelogs&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/berrydev-ai/blockdoc-python/raw/main/.claude/commands/add-to-changelog.md"&gt;&lt;code&gt;/add-to-changelog&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/berrydev-ai"&gt;berrydev-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Adds new entries to changelog files while maintaining format consistency, properly documenting changes, and following established project standards for version tracking.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/jerseycheese/Narraitor/tree/feature/issue-227-ai-suggestions/.claude/commands/analyze-issue.md"&gt;&lt;code&gt;/create-docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/jerseycheese"&gt;jerseycheese&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Analyzes code structure and purpose to create comprehensive documentation detailing inputs/outputs, behavior, user interaction flows, and edge cases with error handling.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/slunsford/coffee-analytics/raw/main/.claude/commands/docs.md"&gt;&lt;code&gt;/docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/slunsford"&gt;slunsford&lt;/a&gt;&lt;br&gt; Generates comprehensive documentation that follows project structure, documenting APIs and usage patterns with consistent formatting for better user understanding.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hackdays-io/toban-contribution-viewer/raw/main/.claude/commands/explain-issue-fix.md"&gt;&lt;code&gt;/explain-issue-fix&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/hackdays-io"&gt;hackdays-io&lt;/a&gt;&lt;br&gt; Documents solution approaches for GitHub issues, explaining technical decisions, detailing challenges overcome, and providing implementation context for better understanding.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Consiliency/Flutter-Structurizr/raw/main/.claude/commands/update-docs.md"&gt;&lt;code&gt;/update-docs&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Consiliency"&gt;Consiliency&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Reviews current documentation status, updates implementation progress, reviews phase documents, and maintains documentation consistency across the project.&lt;/p&gt; 
&lt;h3&gt;CI / Deployment&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/kelp/webdown/raw/main/.claude/commands/release.md"&gt;&lt;code&gt;/release&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/kelp"&gt;kelp&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Manages software releases by updating changelogs, reviewing README changes, evaluating version increments, and documenting release changes for better version tracking.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hackdays-io/toban-contribution-viewer/raw/main/.claude/commands/run-ci.md"&gt;&lt;code&gt;/run-ci&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/hackdays-io"&gt;hackdays-io&lt;/a&gt;&lt;br&gt; Activates virtual environments, runs CI-compatible check scripts, iteratively fixes errors, and ensures all tests pass before completion.&lt;/p&gt; 
&lt;h3&gt;Project &amp;amp; Task Management&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/scopecraft/command/raw/main/.claude/commands/create-command.md"&gt;&lt;code&gt;/create-command&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/scopecraft"&gt;scopecraft&lt;/a&gt;&lt;br&gt; Guides Claude through creating new custom commands with proper structure by analyzing requirements, templating commands by category, enforcing command standards, and creating supporting documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/taddyorg/inkverse/raw/main/.claude/commands/create-jtbd.md"&gt;&lt;code&gt;/create-jtbd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/taddyorg"&gt;taddyorg&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br&gt; Creates Jobs-to-be-Done frameworks that outline user needs with structured format, focusing on specific user problems and organizing by job categories for product development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/taddyorg/inkverse/raw/main/.claude/commands/create-prd.md"&gt;&lt;code&gt;/create-prd&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/taddyorg"&gt;taddyorg&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br&gt; Generates comprehensive product requirement documents outlining detailed specifications, requirements, and features following standardized document structure and format.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Wirasm/claudecode-utils/raw/main/.claude/commands/create-prp.md"&gt;&lt;code&gt;/create-prp&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Wirasm"&gt;Wirasm&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Creates product requirement plans by reading PRP methodology, following template structure, creating comprehensive requirements, and structuring product definitions for development.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/disler/just-prompt/raw/main/.claude/commands/project_hello_w_name.md"&gt;&lt;code&gt;/project_hello_w_name&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/disler"&gt;disler&lt;/a&gt;&lt;br&gt; Creates customizable greeting components with name input, demonstrating argument passing, component reusability, state management, and user input handling.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/chrisleyva/todo-slash-command/raw/main/todo.md"&gt;&lt;code&gt;/todo&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/chrisleyva"&gt;chrisleyva&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; A convenient command to quickly manage project todo items without leaving the Claude Code interface, featuring due dates, sorting, task prioritization, and comprehensive todo list management.&lt;/p&gt; 
&lt;h3&gt;Miscellaneous&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/TuckerTucker/tkr-portfolio/raw/main/.claude/commands/five.md"&gt;&lt;code&gt;/five&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/TuckerTucker"&gt;TuckerTucker&lt;/a&gt;&lt;br&gt; Applies the "five whys" methodology to perform root cause analysis, identify underlying issues, and create solution approaches for complex problems.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/fixing_go_in_graph.md"&gt;&lt;code&gt;/fixing_go_in_graph&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br&gt; Focuses on Gene Ontology annotation integration in graph databases, handling multiple data sources, addressing graph representation issues, and ensuring correct data incorporation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/GaloyMoney/lana-bank/raw/main/.claude/commands/mermaid.md"&gt;&lt;code&gt;/mermaid&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/GaloyMoney"&gt;GaloyMoney&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Generates Mermaid diagrams from SQL schema files, creating entity relationship diagrams with table properties, validating diagram compilation, and ensuring complete entity coverage.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Mjvolk3/torchcell/raw/main/.claude/commands/review_dcell_model.md"&gt;&lt;code&gt;/review_dcell_model&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Mjvolk3"&gt;Mjvolk3&lt;/a&gt;&lt;br&gt; Reviews old Dcell implementation files, comparing with newer Dango model, noting changes over time, and analyzing refactoring approaches for better code organization.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/zuplo/docs/raw/main/.claude/commands/use-stepper.md"&gt;&lt;code&gt;/use-stepper&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/zuplo"&gt;zuplo&lt;/a&gt;&lt;br&gt; Reformats documentation to use React Stepper component, transforming heading formats, applying proper indentation, and maintaining markdown compatibility with admonition formatting.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;CLAUDE.md Files 📂&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;code&gt;CLAUDE.md&lt;/code&gt; files&lt;/strong&gt; are files that contain important guidelines and context-specfic information or instructions that help Claude Code to better understand your project and your coding standards&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Language-Specific&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/didalgolab/ai-intellij-plugin/raw/main/CLAUDE.md"&gt;&lt;code&gt;AI IntelliJ Plugin&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/didalgolab"&gt;didalgolab&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Provides comprehensive Gradle commands for IntelliJ plugin development with platform-specific coding patterns, detailed package structure guidelines, and clear internationalization standards.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/alexei-led/aws-mcp-server/raw/main/CLAUDE.md"&gt;&lt;code&gt;AWS MCP Server&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/alexei-led"&gt;alexei-led&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Features multiple Python environment setup options with detailed code style guidelines, comprehensive error handling recommendations, and security considerations for AWS CLI interactions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/touchlab/DroidconKotlin/raw/main/CLAUDE.md"&gt;&lt;code&gt;DroidconKotlin&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/touchlab"&gt;touchlab&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Delivers comprehensive Gradle commands for cross-platform Kotlin Multiplatform development with clear module structure and practical guidance for dependency injection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/expectedparrot/edsl/raw/main/CLAUDE.md"&gt;&lt;code&gt;EDSL&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/expectedparrot"&gt;expectedparrot&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Offers detailed build and test commands with strict code style enforcement, comprehensive testing requirements, and standardized development workflow using Black and mypy.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/giselles-ai/giselle/raw/main/CLAUDE.md"&gt;&lt;code&gt;Giselle&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/giselles-ai"&gt;giselles-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Provides detailed build and test commands using pnpm and Vitest with strict code formatting requirements and comprehensive naming conventions for code consistency.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/hashintel/hash/raw/main/CLAUDE.md"&gt;&lt;code&gt;HASH&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/hashintel"&gt;hashintel&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Features comprehensive repository structure breakdown with strong emphasis on coding standards, detailed Rust documentation guidelines, and systematic PR review process.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/inkline/inkline/raw/main/CLAUDE.md"&gt;&lt;code&gt;Inkline&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/inkline"&gt;inkline&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Structures development workflow using pnpm with emphasis on TypeScript and Vue 3 Composition API, detailed component creation process, and comprehensive testing recommendations.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/mattgodbolt/jsbeeb/raw/main/CLAUDE.md"&gt;&lt;code&gt;JSBeeb&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/mattgodbolt"&gt;mattgodbolt&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;GPL-3.0&lt;br&gt; Provides development guide for JavaScript BBC Micro emulator with build and testing instructions, architecture documentation, and debugging workflows.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/LamoomAI/lamoom-python/raw/main/CLAUDE.md"&gt;&lt;code&gt;Lamoom Python&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/LamoomAI"&gt;LamoomAI&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;Apache-2.0&lt;br&gt; Serves as reference for production prompt engineering library with load balancing of AI Models, API documentation, and usage patterns with examples.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/langchain-ai/langgraphjs/raw/main/CLAUDE.md"&gt;&lt;code&gt;LangGraphJS&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/langchain-ai"&gt;langchain-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Offers comprehensive build and test commands with detailed TypeScript style guidelines, layered library architecture, and monorepo structure using yarn workspaces.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/metabase/metabase/raw/master/CLAUDE.md"&gt;&lt;code&gt;Metabase&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/metabase"&gt;metabase&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;NOASSERTION&lt;br&gt; Details workflow for REPL-driven development in Clojure/ClojureScript with emphasis on incremental development, testing, and step-by-step approach for feature implementation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sgcarstrends/backend/raw/main/CLAUDE.md"&gt;&lt;code&gt;SG Cars Trends Backend&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/sgcarstrends"&gt;sgcarstrends&lt;/a&gt;&lt;br&gt; Provides comprehensive structure for TypeScript monorepo projects with detailed commands for development, testing, deployment, and AWS/Cloudflare integration.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/spylang/spy/raw/main/CLAUDE.md"&gt;&lt;code&gt;SPy&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/spylang"&gt;spylang&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Enforces strict coding conventions with comprehensive testing guidelines, multiple code compilation options, and backend-specific test decorators for targeted filtering.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/KarpelesLab/tpl/raw/master/CLAUDE.md"&gt;&lt;code&gt;TPL&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/KarpelesLab"&gt;KarpelesLab&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Details Go project conventions with comprehensive error handling recommendations, table-driven testing approach guidelines, and modernization suggestions for latest Go features.&lt;/p&gt; 
&lt;h3&gt;Domain-Specific&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/Layr-Labs/avs-vibe-developer-guide/raw/master/CLAUDE.md"&gt;&lt;code&gt;AVS Vibe Developer Guide&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Layr-Labs"&gt;Layr-Labs&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Structures AI-assisted EigenLayer AVS development workflow with consistent naming conventions for prompt files and established terminology standards for blockchain concepts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/CommE2E/comm/raw/master/CLAUDE.md"&gt;&lt;code&gt;Comm&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/CommE2E"&gt;CommE2E&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;BSD-3-Clause&lt;br&gt; Serves as a development reference for E2E-encrypted messaging applications with code organization architecture, security implementation details, and testing procedures.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/badass-courses/course-builder/raw/main/CLAUDE.md"&gt;&lt;code&gt;Course Builder&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/badass-courses"&gt;badass-courses&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Enables real-time multiplayer capabilities for collaborative course creation with diverse tech stack integration and monorepo architecture using Turborepo.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/eastlondoner/cursor-tools/raw/main/CLAUDE.md"&gt;&lt;code&gt;Cursor Tools&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/eastlondoner"&gt;eastlondoner&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Creates a versatile AI command interface supporting multiple providers and models with flexible command options and browser automation through "Stagehand" feature.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/soramimi/Guitar/raw/master/CLAUDE.md"&gt;&lt;code&gt;Guitar&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/soramimi"&gt;soramimi&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;GPL-2.0&lt;br&gt; Serves as development guide for Guitar Git GUI Client with build commands for various platforms, code style guidelines for contributing, and project structure explanation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Fimeg/NetworkChronicles/raw/legacy-v1/CLAUDE.md"&gt;&lt;code&gt;Network Chronicles&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Fimeg"&gt;Fimeg&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Presents detailed implementation plan for AI-driven game characters with technical specifications for LLM integration, character guidelines, and service discovery mechanics.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/different-ai/note-companion/raw/master/CLAUDE.md"&gt;&lt;code&gt;Note Companion&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/different-ai"&gt;different-ai&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Provides detailed styling isolation techniques for Obsidian plugins using Tailwind with custom prefix to prevent style conflicts and practical troubleshooting steps.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ParetoSecurity/pareto-mac/raw/main/CLAUDE.md"&gt;&lt;code&gt;Pareto Mac&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/ParetoSecurity"&gt;ParetoSecurity&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;GPL-3.0&lt;br&gt; Serves as development guide for Mac security audit tool with build instructions, contribution guidelines, testing procedures, and workflow documentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/steadycursor/steadystart/raw/main/CLAUDE.md"&gt;&lt;code&gt;SteadyStart&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/steadycursor"&gt;steadycursor&lt;/a&gt;&lt;br&gt; Clear and direct instructives about style, permissions, Claude's "role", communications, and documentation of Claude Code sessions for other team members to stay abreast.&lt;/p&gt; 
&lt;h3&gt;Project Scaffolding &amp;amp; MCP&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/basicmachines-co/basic-memory/raw/main/CLAUDE.md"&gt;&lt;code&gt;Basic Memory&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/basicmachines-co"&gt;basicmachines-co&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;AGPL-3.0&lt;br&gt; Presents an innovative AI-human collaboration framework with Model Context Protocol for bidirectional LLM-markdown communication and flexible knowledge structure for complex projects.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/grahama1970/claude-code-mcp-enhanced/raw/main/CLAUDE.md"&gt;&lt;code&gt;claude-code-mcp-enhanced&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/grahama1970"&gt;grahama1970&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Provides detailed and emphatic instructions for Claude to follow as a coding agent, with testing guidance, code examples, and compliance checks.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Family-IT-Guy/perplexity-mcp/raw/main/CLAUDE.md"&gt;&lt;code&gt;Perplexity MCP&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/Family-IT-Guy"&gt;Family-IT-Guy&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;ISC&lt;br&gt; Offers clear step-by-step installation instructions with multiple configuration options, detailed troubleshooting guidance, and concise architecture overview of the MCP protocol.&lt;/p&gt; 
&lt;br&gt; 
&lt;h2&gt;Official Documentation 🏛️&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Links to some of Anthropic's terrific documentation and resources regarding Claude Code&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!--lint disable double-link--&gt; 
&lt;p&gt;&lt;a href="https://docs.anthropic.com/en/docs/claude-code"&gt;&lt;code&gt;Anthropic Documentation&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;©&lt;br&gt; The official documentation for Claude Code, including installation instructions, usage guidelines, API references, tutorials, examples, loads of information that I won't list individually. Like Claude Code, the documentation is frequently updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/anthropics/anthropic-quickstarts/raw/main/CLAUDE.md"&gt;&lt;code&gt;Anthropic Quickstarts&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Offers comprehensive development guides for three distinct AI-powered demo projects with standardized workflows, strict code style guidelines, and containerization instructions.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/anthropics/claude-code-action/tree/main/examples"&gt;&lt;code&gt;Claude Code GitHub Actions&lt;/code&gt;&lt;/a&gt; &amp;nbsp; by &amp;nbsp; &lt;a href="https://github.com/anthropics"&gt;Anthropic&lt;/a&gt; &amp;nbsp;&amp;nbsp;⚖️&amp;nbsp;&amp;nbsp;MIT&lt;br&gt; Official GitHub Actions integration for Claude Code with examples and documentation for automating AI-powered workflows in CI/CD pipelines.&lt;/p&gt; 
&lt;h2&gt;Contributing 🌻&lt;/h2&gt; 
&lt;p&gt;Please note that this project is released with a &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/code-of-conduct.md"&gt;Contributor Code of Conduct&lt;/a&gt;. By participating in this project you agree to abide by its terms.&lt;/p&gt; 
&lt;p&gt;Regarding content, we especially welcome:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Proven, effective resources that follow best practices and may even be in use in production.&lt;/li&gt; 
 &lt;li&gt;Innovative, creative, or experimental workflows that perhaps are still being iterated upon, but have high potential value, and push the boundaries of Claude Code's documented capabilities and use cases.&lt;/li&gt; 
 &lt;li&gt;Additional libraries and tooling that are built on top of Claude Code and offer enhanced functionality.&lt;/li&gt; 
 &lt;li&gt;Applications of Claude Code outside of the traditional "coding assistant" context, e.g., CI/CD integration, testing, documentation, dev-ops, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/hesreallyhim/awesome-claude-code/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more information on how to contribute to this project. Or, fire up Claude Code and invoke the &lt;code&gt;/project:add-new-resource&lt;/code&gt; command and let Claude walk you through it!&lt;/p&gt; 
&lt;p&gt;If you have any suggestions or thoughts on how to improve the repo, or how to best organize the list, feel free to start a Discussion topic. This is meant to be for the Claude Code community, and in general I prefer not to act on sole authority.&lt;/p&gt; 
&lt;h3&gt;A note about licenses&lt;/h3&gt; 
&lt;p&gt;Because simply listing a hyperlink does not qualify as redistribution, the license of the original source is not relevant to its inclusion. However, for posterity and convenience, we do host copies of all resources whose license permits it. Therefore, please include information about the resource's license. Additionally, take note: &lt;em&gt;if you do not include a LICENSE in your GitHub repo, then by default it is fully copyrighted and redistribution is not allowed&lt;/em&gt;. So, if you are intending to make an open source project, it's critical to pick from one of the many available open source licenses. This is just a reminder that without a LICENSE, your project is not open source (it's merely source-code-available) - it may of course still be included on this list, but this notice is to inform readers about the default rules regarding GitHub and LICENSE files. See &lt;a href="https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/licensing-a-repository"&gt;here&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>BerriAI/litellm</title>
      <link>https://github.com/BerriAI/litellm</link>
      <description>&lt;p&gt;Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; 🚅 LiteLLM &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://render.com/deploy?repo=https://github.com/BerriAI/litellm" target="_blank" rel="nofollow"&gt;&lt;img src="https://render.com/images/deploy-to-render-button.svg?sanitize=true" alt="Deploy to Render"&gt;&lt;/a&gt; &lt;a href="https://railway.app/template/HLP0Ub?referralCode=jch2ME"&gt; &lt;img src="https://railway.app/button.svg?sanitize=true" alt="Deploy on Railway"&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Call all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.] &lt;br&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt;&lt;a href="https://docs.litellm.ai/docs/simple_proxy" target="_blank"&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt; | &lt;a href="https://docs.litellm.ai/docs/hosted" target="_blank"&gt; Hosted Proxy (Preview)&lt;/a&gt; | &lt;a href="https://docs.litellm.ai/docs/enterprise" target="_blank"&gt;Enterprise Tier&lt;/a&gt;&lt;/h4&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://pypi.org/project/litellm/" target="_blank"&gt; &lt;img src="https://img.shields.io/pypi/v/litellm.svg?sanitize=true" alt="PyPI Version"&gt; &lt;/a&gt; &lt;a href="https://www.ycombinator.com/companies/berriai"&gt; &lt;img src="https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square" alt="Y Combinator W23"&gt; &lt;/a&gt; &lt;a href="https://wa.link/huol9n"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=WhatsApp&amp;amp;color=success&amp;amp;logo=WhatsApp&amp;amp;style=flat-square" alt="Whatsapp"&gt; &lt;/a&gt; &lt;a href="https://discord.gg/wuPM9dRgDw"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Discord&amp;amp;color=blue&amp;amp;logo=Discord&amp;amp;style=flat-square" alt="Discord"&gt; &lt;/a&gt; &lt;a href="https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3"&gt; &lt;img src="https://img.shields.io/static/v1?label=Chat%20on&amp;amp;message=Slack&amp;amp;color=black&amp;amp;logo=Slack&amp;amp;style=flat-square" alt="Slack"&gt; &lt;/a&gt; &lt;/h4&gt; 
&lt;p&gt;LiteLLM manages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Translate inputs to provider's &lt;code&gt;completion&lt;/code&gt;, &lt;code&gt;embedding&lt;/code&gt;, and &lt;code&gt;image_generation&lt;/code&gt; endpoints&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/completion/output"&gt;Consistent output&lt;/a&gt;, text responses will always be available at &lt;code&gt;['choices'][0]['message']['content']&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Retry/fallback logic across multiple deployments (e.g. Azure/OpenAI) - &lt;a href="https://docs.litellm.ai/docs/routing"&gt;Router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Set Budgets &amp;amp; Rate limits per project, api key, model &lt;a href="https://docs.litellm.ai/docs/simple_proxy"&gt;LiteLLM Proxy Server (LLM Gateway)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/BerriAI/litellm?tab=readme-ov-file#openai-proxy---docs"&gt;&lt;strong&gt;Jump to LiteLLM Proxy (LLM Gateway) Docs&lt;/strong&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://github.com/BerriAI/litellm?tab=readme-ov-file#supported-providers-docs"&gt;&lt;strong&gt;Jump to Supported LLM Providers&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🚨 &lt;strong&gt;Stable Release:&lt;/strong&gt; Use docker images with the &lt;code&gt;-stable&lt;/code&gt; tag. These have undergone 12 hour load tests, before being published. &lt;a href="https://docs.litellm.ai/docs/proxy/release_cycle"&gt;More information about the release cycle here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Support for more providers. Missing a provider or LLM Platform, raise a &lt;a href="https://github.com/BerriAI/litellm/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;projects=&amp;amp;template=feature_request.yml&amp;amp;title=%5BFeature%5D%3A+"&gt;feature request&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Usage (&lt;a href="https://docs.litellm.ai/docs/"&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/a&gt;)&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] LiteLLM v1.0.0 now requires &lt;code&gt;openai&amp;gt;=1.0.0&lt;/code&gt;. Migration guide &lt;a href="https://docs.litellm.ai/docs/migration"&gt;here&lt;/a&gt;&lt;br&gt; LiteLLM v1.40.14+ now requires &lt;code&gt;pydantic&amp;gt;=2.0.0&lt;/code&gt;. No changes required.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a target="_blank" href="https://colab.research.google.com/github/BerriAI/litellm/blob/main/cookbook/liteLLM_Getting_Started.ipynb"&gt; &lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab"&gt; &lt;/a&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install litellm
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion
import os

## set ENV variables
os.environ["OPENAI_API_KEY"] = "your-openai-key"
os.environ["ANTHROPIC_API_KEY"] = "your-anthropic-key"

messages = [{ "content": "Hello, how are you?","role": "user"}]

# openai call
response = completion(model="openai/gpt-4o", messages=messages)

# anthropic call
response = completion(model="anthropic/claude-sonnet-4-20250514", messages=messages)
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "id": "chatcmpl-1214900a-6cdd-4148-b663-b5e2f642b4de",
    "created": 1751494488,
    "model": "claude-sonnet-4-20250514",
    "object": "chat.completion",
    "system_fingerprint": null,
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "content": "Hello! I'm doing well, thank you for asking. I'm here and ready to help with whatever you'd like to discuss or work on. How are you doing today?",
                "role": "assistant",
                "tool_calls": null,
                "function_call": null
            }
        }
    ],
    "usage": {
        "completion_tokens": 39,
        "prompt_tokens": 13,
        "total_tokens": 52,
        "completion_tokens_details": null,
        "prompt_tokens_details": {
            "audio_tokens": null,
            "cached_tokens": 0
        },
        "cache_creation_input_tokens": 0,
        "cache_read_input_tokens": 0
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Call any model supported by a provider, with &lt;code&gt;model=&amp;lt;provider_name&amp;gt;/&amp;lt;model_name&amp;gt;&lt;/code&gt;. There might be provider-specific details here, so refer to &lt;a href="https://docs.litellm.ai/docs/providers"&gt;provider docs for more information&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Async (&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-completion"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import acompletion
import asyncio

async def test_get_response():
    user_message = "Hello, how are you?"
    messages = [{"content": user_message, "role": "user"}]
    response = await acompletion(model="openai/gpt-4o", messages=messages)
    return response

response = asyncio.run(test_get_response())
print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Streaming (&lt;a href="https://docs.litellm.ai/docs/completion/stream"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;liteLLM supports streaming the model response back, pass &lt;code&gt;stream=True&lt;/code&gt; to get a streaming iterator in response.&lt;br&gt; Streaming is supported for all models (Bedrock, Huggingface, TogetherAI, Azure, OpenAI, etc.)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion
response = completion(model="openai/gpt-4o", messages=messages, stream=True)
for part in response:
    print(part.choices[0].delta.content or "")

# claude sonnet 4
response = completion('anthropic/claude-sonnet-4-20250514', messages, stream=True)
for part in response:
    print(part)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Response chunk (OpenAI Format)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
    "id": "chatcmpl-fe575c37-5004-4926-ae5e-bfbc31f356ca",
    "created": 1751494808,
    "model": "claude-sonnet-4-20250514",
    "object": "chat.completion.chunk",
    "system_fingerprint": null,
    "choices": [
        {
            "finish_reason": null,
            "index": 0,
            "delta": {
                "provider_specific_fields": null,
                "content": "Hello",
                "role": "assistant",
                "function_call": null,
                "tool_calls": null,
                "audio": null
            },
            "logprobs": null
        }
    ],
    "provider_specific_fields": null,
    "stream_options": null,
    "citations": null
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Logging Observability (&lt;a href="https://docs.litellm.ai/docs/observability/callbacks"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;LiteLLM exposes pre defined callbacks to send data to Lunary, MLflow, Langfuse, DynamoDB, s3 Buckets, Helicone, Promptlayer, Traceloop, Athina, Slack&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from litellm import completion

## set env variables for logging tools (when using MLflow, no API key set up is required)
os.environ["LUNARY_PUBLIC_KEY"] = "your-lunary-public-key"
os.environ["HELICONE_API_KEY"] = "your-helicone-auth-key"
os.environ["LANGFUSE_PUBLIC_KEY"] = ""
os.environ["LANGFUSE_SECRET_KEY"] = ""
os.environ["ATHINA_API_KEY"] = "your-athina-api-key"

os.environ["OPENAI_API_KEY"] = "your-openai-key"

# set callbacks
litellm.success_callback = ["lunary", "mlflow", "langfuse", "athina", "helicone"] # log input/output to lunary, langfuse, supabase, athina, helicone etc

#openai call
response = completion(model="openai/gpt-4o", messages=[{"role": "user", "content": "Hi 👋 - i'm openai"}])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;LiteLLM Proxy Server (LLM Gateway) - (&lt;a href="https://docs.litellm.ai/docs/simple_proxy"&gt;Docs&lt;/a&gt;)&lt;/h1&gt; 
&lt;p&gt;Track spend + Load Balance across multiple projects&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/hosted"&gt;Hosted Proxy (Preview)&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The proxy provides:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys#custom-auth"&gt;Hooks for auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/logging#step-1---create-your-custom-litellm-callback-class"&gt;Hooks for logging&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys#tracking-spend"&gt;Cost tracking&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.litellm.ai/docs/proxy/users#set-rate-limits"&gt;Rate Limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;📖 Proxy Endpoints - &lt;a href="https://litellm-api.up.railway.app/"&gt;Swagger Docs&lt;/a&gt;&lt;/h2&gt; 
&lt;h2&gt;Quick Start Proxy - CLI&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install 'litellm[proxy]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 1: Start litellm proxy&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ litellm --model huggingface/bigcode/starcoder

#INFO: Proxy running on http://0.0.0.0:4000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Step 2: Make ChatCompletions Request to Proxy&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] 💡 &lt;a href="https://docs.litellm.ai/docs/proxy/user_keys"&gt;Use LiteLLM Proxy with Langchain (Python, JS), OpenAI SDK (Python, JS) Anthropic SDK, Mistral SDK, LlamaIndex, Instructor, Curl&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import openai # openai v1.0.0+
client = openai.OpenAI(api_key="anything",base_url="http://0.0.0.0:4000") # set proxy to base_url
# request sent to model set on litellm proxy, `litellm --model`
response = client.chat.completions.create(model="gpt-3.5-turbo", messages = [
    {
        "role": "user",
        "content": "this is a test request, write a short poem"
    }
])

print(response)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Proxy Key Management (&lt;a href="https://docs.litellm.ai/docs/proxy/virtual_keys"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;p&gt;Connect the proxy with a Postgres DB to create proxy keys&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Get the code
git clone https://github.com/BerriAI/litellm

# Go to folder
cd litellm

# Add the master key - you can change this after setup
echo 'LITELLM_MASTER_KEY="sk-1234"' &amp;gt; .env

# Add the litellm salt key - you cannot change this after adding a model
# It is used to encrypt / decrypt your LLM API Key credentials
# We recommend - https://1password.com/password-generator/ 
# password generator to get a random hash for litellm salt key
echo 'LITELLM_SALT_KEY="sk-1234"' &amp;gt;&amp;gt; .env

source .env

# Start
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;UI on &lt;code&gt;/ui&lt;/code&gt; on your proxy server &lt;img src="https://github.com/BerriAI/litellm/assets/29436595/47c97d5e-b9be-4839-b28c-43d7f4f10033" alt="ui_3"&gt;&lt;/p&gt; 
&lt;p&gt;Set budgets and rate limits across multiple projects &lt;code&gt;POST /key/generate&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Request&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl 'http://0.0.0.0:4000/key/generate' \
--header 'Authorization: Bearer sk-1234' \
--header 'Content-Type: application/json' \
--data-raw '{"models": ["gpt-3.5-turbo", "gpt-4", "claude-2"], "duration": "20m","metadata": {"user": "ishaan@berri.ai", "team": "core-infra"}}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Expected Response&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;{
    "key": "sk-kdEXbIqZRwEeEiHwdg7sFA", # Bearer token
    "expires": "2023-11-19T01:38:25.838000+00:00" # datetime object
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Supported Providers (&lt;a href="https://docs.litellm.ai/docs/providers"&gt;Docs&lt;/a&gt;)&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/#basic-usage"&gt;Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#streaming-responses"&gt;Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-completion"&gt;Async Completion&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/completion/stream#async-streaming"&gt;Async Streaming&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/embedding/supported_embedding"&gt;Async Embedding&lt;/a&gt;&lt;/th&gt; 
   &lt;th&gt;&lt;a href="https://docs.litellm.ai/docs/image_generation"&gt;Async Image Generation&lt;/a&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/openai"&gt;openai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/meta_llama"&gt;Meta - Llama API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/azure"&gt;azure&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aiml"&gt;AI/ML API&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aws_sagemaker"&gt;aws - sagemaker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/bedrock"&gt;aws - bedrock&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/vertex"&gt;google - vertex_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/palm"&gt;google - palm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/gemini"&gt;google AI Studio - gemini&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/mistral"&gt;mistral ai api&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/cloudflare_workers"&gt;cloudflare AI Workers&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/cohere"&gt;cohere&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/anthropic"&gt;anthropic&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/empower"&gt;empower&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/huggingface"&gt;huggingface&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/replicate"&gt;replicate&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/togetherai"&gt;together_ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/openrouter"&gt;openrouter&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/ai21"&gt;ai21&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/baseten"&gt;baseten&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/vllm"&gt;vllm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/nlp_cloud"&gt;nlp_cloud&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/aleph_alpha"&gt;aleph alpha&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/petals"&gt;petals&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/ollama"&gt;ollama&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/deepinfra"&gt;deepinfra&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/perplexity"&gt;perplexity-ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/groq"&gt;Groq AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/deepseek"&gt;Deepseek&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/anyscale"&gt;anyscale&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/watsonx"&gt;IBM - watsonx.ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/voyage"&gt;voyage ai&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/xinference"&gt;xinference [Xorbits Inference]&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/friendliai"&gt;FriendliAI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/galadriel"&gt;Galadriel&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://novita.ai/models/llm?utm_source=github_litellm&amp;amp;utm_medium=github_readme&amp;amp;utm_campaign=github_link"&gt;Novita AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/featherless_ai"&gt;Featherless AI&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://docs.litellm.ai/docs/providers/nebius"&gt;Nebius AI Studio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://docs.litellm.ai/docs/"&gt;&lt;strong&gt;Read the Docs&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in contributing? Contributions to LiteLLM Python SDK, Proxy Server, and LLM integrations are both accepted and highly encouraged!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick start:&lt;/strong&gt; &lt;code&gt;git clone&lt;/code&gt; → &lt;code&gt;make install-dev&lt;/code&gt; → &lt;code&gt;make format&lt;/code&gt; → &lt;code&gt;make lint&lt;/code&gt; → &lt;code&gt;make test-unit&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;See our comprehensive &lt;a href="https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md"&gt;Contributing Guide (CONTRIBUTING.md)&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h1&gt;Enterprise&lt;/h1&gt; 
&lt;p&gt;For companies that need better security, user management and professional support&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://calendly.com/d/4mp-gd3-k5k/litellm-1-1-onboarding-chat"&gt;Talk to founders&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This covers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Features under the &lt;a href="https://docs.litellm.ai/docs/proxy/enterprise"&gt;LiteLLM Commercial License&lt;/a&gt;:&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Feature Prioritization&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Custom Integrations&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Professional Support - Dedicated discord + slack&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Custom SLAs&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;✅ &lt;strong&gt;Secure access with Single Sign-On&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome contributions to LiteLLM! Whether you're fixing bugs, adding features, or improving documentation, we appreciate your help.&lt;/p&gt; 
&lt;h2&gt;Quick Start for Contributors&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/BerriAI/litellm.git
cd litellm
make install-dev    # Install development dependencies
make format         # Format your code
make lint           # Run all linting checks
make test-unit      # Run unit tests
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For detailed contributing guidelines, see &lt;a href="https://raw.githubusercontent.com/BerriAI/litellm/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Code Quality / Linting&lt;/h2&gt; 
&lt;p&gt;LiteLLM follows the &lt;a href="https://google.github.io/styleguide/pyguide.html"&gt;Google Python Style Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Our automated checks include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Black&lt;/strong&gt; for code formatting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ruff&lt;/strong&gt; for linting and code quality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MyPy&lt;/strong&gt; for type checking&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Circular import detection&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Import safety checks&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run all checks locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make lint           # Run all linting (matches CI)
make format-check   # Check formatting only
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;All these checks must pass before your PR can be merged.&lt;/p&gt; 
&lt;h1&gt;Support / talk with founders&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://calendly.com/d/4mp-gd3-k5k/berriai-1-1-onboarding-litellm-hosted-version"&gt;Schedule Demo 👋&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/wuPM9dRgDw"&gt;Community Discord 💭&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/share/enQtOTE0ODczMzk2Nzk4NC01YjUxNjY2YjBlYTFmNDRiZTM3NDFiYTM3MzVkODFiMDVjOGRjMmNmZTZkZTMzOWQzZGQyZWIwYjQ0MWExYmE3"&gt;Community Slack 💭&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Our numbers 📞 +1 (770) 8783-106 / ‭+1 (412) 618-6238‬&lt;/li&gt; 
 &lt;li&gt;Our emails ✉️ &lt;a href="mailto:ishaan@berri.ai"&gt;ishaan@berri.ai&lt;/a&gt; / &lt;a href="mailto:krrish@berri.ai"&gt;krrish@berri.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Why did we build this&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Need for simplicity&lt;/strong&gt;: Our code started to get extremely complicated managing &amp;amp; translating calls between Azure, OpenAI and Cohere.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;a href="https://github.com/BerriAI/litellm/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=BerriAI/litellm"&gt; &lt;/a&gt; 
&lt;h2&gt;Run in Developer mode&lt;/h2&gt; 
&lt;h3&gt;Services&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Setup .env file in root&lt;/li&gt; 
 &lt;li&gt;Run dependant services &lt;code&gt;docker-compose up db prometheus&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Backend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;(In root) create virtual environment &lt;code&gt;python -m venv .venv&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Activate virtual environment &lt;code&gt;source .venv/bin/activate&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;pip install -e ".[all]"&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Start proxy backend &lt;code&gt;uvicorn litellm.proxy.proxy_server:app --host localhost --port 4000 --reload&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;ui/litellm-dashboard&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies &lt;code&gt;npm install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;npm run dev&lt;/code&gt; to start the dashboard&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>yeongpin/cursor-free-vip</title>
      <link>https://github.com/yeongpin/cursor-free-vip</link>
      <description>&lt;p&gt;[Support 0.49.x]（Reset Cursor AI MachineID &amp; Bypass Higher Token Limit） Cursor Ai ，自动重置机器ID ， 免费升级使用Pro功能: You've reached your trial request limit. / Too many free trial accounts used on this machine. Please upgrade to pro. We have this limit in place to prevent abuse. Please let us know if you believe this is a mistake.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;➤ Cursor Free VIP&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/logo.png" alt="Cursor Pro Logo" width="200" style="border-radius: 6px;"&gt; &lt;/p&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;&lt;a href="https://github.com/yeongpin/cursor-free-vip/releases/latest"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/release/yeongpin/cursor-free-vip" alt="Release"&gt;&lt;/a&gt; &lt;a href="https://creativecommons.org/licenses/by-nc-nd/4.0/"&gt;&lt;img src="https://img.shields.io/badge/License-CC_BY--NC--ND_4.0-lightgrey.svg?sanitize=true" alt="License: CC BY-NC-ND 4.0"&gt;&lt;/a&gt; &lt;a href="https://github.com/yeongpin/cursor-free-vip/stargazers"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/stars/yeongpin/cursor-free-vip" alt="Stars"&gt;&lt;/a&gt; &lt;a href="https://github.com/yeongpin/cursor-free-vip/releases/latest"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/yeongpin/cursor-free-vip/total" alt="Downloads"&gt;&lt;/a&gt; &lt;a href="https://buymeacoffee.com/yeongpin" target="_blank"&gt;&lt;img alt="Buy Me a Coffee" src="https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support%20Me-FFDA33"&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/yeongpin/cursor-free-vip"&gt;&lt;img src="https://devin.ai/assets/deepwiki-badge.png" alt="Ask DeepWiki.com" height="20"&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/13425" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13425" alt="yeongpin%2Fcursor-free-vip | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"&gt;&lt;/a&gt; &lt;br&gt; &lt;a href="https://www.buymeacoffee.com/yeongpin" target="_blank"&gt; &lt;img src="https://img.buymeacoffee.com/button-api/?text=buy%20me%20a%20coffee&amp;amp;emoji=%E2%98%95&amp;amp;slug=yeongpin&amp;amp;button_colour=ffda33&amp;amp;font_colour=000000&amp;amp;font_family=Bree&amp;amp;outline_colour=000000&amp;amp;coffee_colour=FFDD00&amp;amp;latest=2" width="160" height="55" alt="Buy Me a Coffee"&gt; &lt;/a&gt;&lt;/p&gt; 
 &lt;h4&gt;Support Latest 0.49.x Version | 支持最新 0.49.x 版本&lt;/h4&gt; 
 &lt;p&gt;This tool is for educational purposes, currently the repo does not violate any laws. Please support the original project. This tool will not generate any fake email accounts and OAuth access.&lt;/p&gt; 
 &lt;p&gt;Supports Windows, macOS and Linux.&lt;/p&gt; 
 &lt;p&gt;For optimal performance, run with privileges and always stay up to date.&lt;/p&gt; 
 &lt;p&gt;這是一款用於學習和研究的工具，目前 repo 沒有違反任何法律。請支持原作者。 這款工具不會生成任何假的電子郵件帳戶和 OAuth 訪問。&lt;/p&gt; 
 &lt;p&gt;支持 Windows、macOS 和 Linux。&lt;/p&gt; 
 &lt;p&gt;對於最佳性能，請以管理員身份運行並始終保持最新。&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/product_2025-04-16_10-40-21.png" alt="new" width="800" style="border-radius: 6px;"&gt;&lt;br&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;🔄 Change Log | 更新日志&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/CHANGELOG.md"&gt;Watch Change Log | 查看更新日志&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;✨ Features | 功能特點&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Support Windows macOS and Linux systems&lt;br&gt;支持 Windows、macOS 和 Linux 系統&lt;br&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Reset Cursor's configuration&lt;br&gt;重置 Cursor 的配置&lt;br&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Multi-language support (English, 简体中文, 繁體中文, Vietnamese)&lt;br&gt;多語言支持（英文、简体中文、繁體中文、越南語）&lt;br&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;💻 System Support | 系統支持&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operating System&lt;/th&gt; 
   &lt;th&gt;Architecture&lt;/th&gt; 
   &lt;th&gt;Supported&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;x64, x86&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS&lt;/td&gt; 
   &lt;td&gt;Intel, Apple Silicon&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;x64, x86, ARM64&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;👀 How to use | 如何使用&lt;/h2&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;⭐ Auto Run Script | 腳本自動化運行&lt;/b&gt;&lt;/summary&gt; 
 &lt;h3&gt;&lt;strong&gt;Linux/macOS&lt;/strong&gt;&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.sh -o install.sh &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;&lt;strong&gt;Archlinux&lt;/strong&gt;&lt;/h3&gt; 
 &lt;p&gt;Install via &lt;a href="https://aur.archlinux.org/packages/cursor-free-vip-git"&gt;AUR&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;yay -S cursor-free-vip-git
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h3&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/h3&gt; 
 &lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/scripts/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;If you want to stop the script, please press Ctrl+C&lt;br&gt;要停止腳本，請按 Ctrl+C&lt;/p&gt; 
&lt;h2&gt;❗ Note | 注意事項&lt;/h2&gt; 
&lt;p&gt;📝 Config | 文件配置 &lt;code&gt;Win / Macos / Linux Path | 路徑 [Documents/.cursor-free-vip/config.ini]&lt;/code&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;⭐ Config | 文件配置&lt;/b&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code&gt;[Chrome]
# Default Google Chrome Path | 默認Google Chrome 遊覽器路徑
chromepath = C:\Program Files\Google/Chrome/Application/chrome.exe

[Turnstile]
# Handle Turnstile Wait Time | 等待人機驗證時間
handle_turnstile_time = 2
# Handle Turnstile Wait Random Time (must merge 1-3 or 1,3) | 等待人機驗證隨機時間（必須是 1-3 或者 1,3 這樣的組合）
handle_turnstile_random_time = 1-3

[OSPaths]
# Storage Path | 存儲路徑
storage_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/storage.json
# SQLite Path | SQLite路徑
sqlite_path = /Users/username/Library/Application Support/Cursor/User/globalStorage/state.vscdb
# Machine ID Path | 機器ID路徑
machine_id_path = /Users/username/Library/Application Support/Cursor/machineId
# For Linux users: ~/.config/cursor/machineid

[Timing]
# Min Random Time | 最小隨機時間
min_random_time = 0.1
# Max Random Time | 最大隨機時間
max_random_time = 0.8
# Page Load Wait | 頁面加載等待時間
page_load_wait = 0.1-0.8
# Input Wait | 輸入等待時間
input_wait = 0.3-0.8
# Submit Wait | 提交等待時間
submit_wait = 0.5-1.5
# Verification Code Input | 驗證碼輸入等待時間
verification_code_input = 0.1-0.3
# Verification Success Wait | 驗證成功等待時間
verification_success_wait = 2-3
# Verification Retry Wait | 驗證重試等待時間
verification_retry_wait = 2-3
# Email Check Initial Wait | 郵件檢查初始等待時間
email_check_initial_wait = 4-6
# Email Refresh Wait | 郵件刷新等待時間
email_refresh_wait = 2-4
# Settings Page Load Wait | 設置頁面加載等待時間
settings_page_load_wait = 1-2
# Failed Retry Time | 失敗重試時間
failed_retry_time = 0.5-1
# Retry Interval | 重試間隔
retry_interval = 8-12
# Max Timeout | 最大超時時間
max_timeout = 160

[Utils]
# Check Update | 檢查更新
check_update = True
# Show Account Info | 顯示賬號信息
show_account_info = True

[TempMailPlus]
# Enable TempMailPlus | 啓用 TempMailPlus（任何轉發到TempMailPlus的郵件都支持獲取驗證碼，例如cloudflare郵件Catch-all）
enabled = false
# TempMailPlus Email | TempMailPlus 電子郵件
email = xxxxx@mailto.plus
# TempMailPlus pin | TempMailPlus pin碼
epin = 

[WindowsPaths]
storage_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\storage.json
sqlite_path = C:\Users\yeongpin\AppData\Roaming\Cursor\User\globalStorage\state.vscdb
machine_id_path = C:\Users\yeongpin\AppData\Roaming\Cursor\machineId
cursor_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app
updater_path = C:\Users\yeongpin\AppData\Local\cursor-updater
update_yml_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app-update.yml
product_json_path = C:\Users\yeongpin\AppData\Local\Programs\Cursor\resources\app\product.json

[Browser]
default_browser = opera
chrome_path = C:\Program Files\Google\Chrome\Application\chrome.exe
edge_path = C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe
firefox_path = C:\Program Files\Mozilla Firefox\firefox.exe
brave_path = C:\Program Files\BraveSoftware/Brave-Browser/Application/brave.exe
chrome_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
edge_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\msedgedriver.exe
firefox_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\geckodriver.exe
brave_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe
opera_path = C:\Users\yeongpin\AppData\Local\Programs\Opera\opera.exe
opera_driver_path = D:\VisualCode\cursor-free-vip-new\drivers\chromedriver.exe

[OAuth]
show_selection_alert = False
timeout = 120
max_attempts = 3
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Use administrator privileges to run the script &lt;br&gt;請使用管理員身份運行腳本&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Confirm that Cursor is closed before running the script &lt;br&gt;請確保在運行腳本前已經關閉 Cursor&lt;br&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;This tool is only for learning and research purposes &lt;br&gt;此工具僅供學習和研究使用&lt;br&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Please comply with the relevant software usage terms when using this tool &lt;br&gt;使用本工具時請遵守相關軟件使用條款&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚨 Common Issues | 常見問題&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;如果遇到權限問題，請確保：&lt;/th&gt; 
   &lt;th align="center"&gt;此腳本以管理員身份運行&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;If you encounter permission issues, please ensure:&lt;/td&gt; 
   &lt;td align="center"&gt;This script is run with administrator privileges&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Error 'User is not authorized'&lt;/td&gt; 
   &lt;td align="center"&gt;This means your account was banned for using temporary (disposal) mail. Ensure using a non-temporary mail service&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;🤩 Contribution | 貢獻&lt;/h2&gt; 
&lt;p&gt;歡迎提交 Issue 和 Pull Request！&lt;/p&gt; 
&lt;a href="https://github.com/yeongpin/cursor-free-vip/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=yeongpin/cursor-free-vip&amp;amp;preview=true&amp;amp;max=&amp;amp;columns="&gt; &lt;/a&gt; 
&lt;br&gt;
&lt;br&gt; 
&lt;h2&gt;📩 Disclaimer | 免責聲明&lt;/h2&gt; 
&lt;p&gt;本工具僅供學習和研究使用，使用本工具所產生的任何後果由使用者自行承擔。 &lt;br&gt;&lt;/p&gt; 
&lt;p&gt;This tool is only for learning and research purposes, and any consequences arising from the use of this tool are borne by the user.&lt;/p&gt; 
&lt;h2&gt;💰 Buy Me a Coffee | 請我喝杯咖啡&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/provi-code.jpg" alt="buy_me_a_coffee" width="280"&gt;&lt;br&gt; &lt;/td&gt; 
    &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/images/paypal.png" alt="buy_me_a_coffee" width="280"&gt;&lt;br&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;⭐ Star History | 星星數&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#yeongpin/cursor-free-vip&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=yeongpin/cursor-free-vip&amp;amp;type=Date" alt="Star History Chart"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;📝 License | 授權&lt;/h2&gt; 
&lt;p&gt;本項目採用 &lt;a href="https://creativecommons.org/licenses/by-nc-nd/4.0/"&gt;CC BY-NC-ND 4.0&lt;/a&gt; 授權。 Please refer to the &lt;a href="https://raw.githubusercontent.com/yeongpin/cursor-free-vip/main/LICENSE.md"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>donnemartin/system-design-primer</title>
      <link>https://github.com/donnemartin/system-design-primer</link>
      <description>&lt;p&gt;Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;em&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README.md"&gt;English&lt;/a&gt; ∙ &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-ja.md"&gt;日本語&lt;/a&gt; ∙ &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-Hans.md"&gt;简体中文&lt;/a&gt; ∙ &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/README-zh-TW.md"&gt;繁體中文&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/170"&gt;العَرَبِيَّة‎&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/220"&gt;বাংলা&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/40"&gt;Português do Brasil&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/186"&gt;Deutsch&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/130"&gt;ελληνικά&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/272"&gt;עברית&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/104"&gt;Italiano&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/102"&gt;한국어&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/110"&gt;فارسی&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/68"&gt;Polski&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/87"&gt;русский язык&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/136"&gt;Español&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/187"&gt;ภาษาไทย&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/39"&gt;Türkçe&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/127"&gt;tiếng Việt&lt;/a&gt; ∙ &lt;a href="https://github.com/donnemartin/system-design-primer/issues/250"&gt;Français&lt;/a&gt; | &lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Add Translation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Help &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/TRANSLATIONS.md"&gt;translate&lt;/a&gt; this guide!&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;The System Design Primer&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png"&gt; &lt;br&gt; &lt;/p&gt; 
&lt;h2&gt;Motivation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn how to design large-scale systems.&lt;/p&gt; 
 &lt;p&gt;Prep for the system design interview.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Learn how to design large-scale systems&lt;/h3&gt; 
&lt;p&gt;Learning how to design scalable systems will help you become a better engineer.&lt;/p&gt; 
&lt;p&gt;System design is a broad topic. There is a &lt;strong&gt;vast amount of resources scattered throughout the web&lt;/strong&gt; on system design principles.&lt;/p&gt; 
&lt;p&gt;This repo is an &lt;strong&gt;organized collection&lt;/strong&gt; of resources to help you learn how to build systems at scale.&lt;/p&gt; 
&lt;h3&gt;Learn from the open source community&lt;/h3&gt; 
&lt;p&gt;This is a continually updated, open source project.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contributions&lt;/a&gt; are welcome!&lt;/p&gt; 
&lt;h3&gt;Prep for the system design interview&lt;/h3&gt; 
&lt;p&gt;In addition to coding interviews, system design is a &lt;strong&gt;required component&lt;/strong&gt; of the &lt;strong&gt;technical interview process&lt;/strong&gt; at many tech companies.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Practice common system design interview questions&lt;/strong&gt; and &lt;strong&gt;compare&lt;/strong&gt; your results with &lt;strong&gt;sample solutions&lt;/strong&gt;: discussions, code, and diagrams.&lt;/p&gt; 
&lt;p&gt;Additional topics for interview prep:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#study-guide"&gt;Study guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions, &lt;strong&gt;with solutions&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Anki flashcards&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/zdCAkB3.png"&gt; &lt;br&gt; &lt;/p&gt; 
&lt;p&gt;The provided &lt;a href="https://apps.ankiweb.net/"&gt;Anki flashcard decks&lt;/a&gt; use spaced repetition to help you retain key system design concepts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design.apkg"&gt;System design deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/System%20Design%20Exercises.apkg"&gt;System design exercises deck&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/tree/master/resources/flash_cards/OO%20Design.apkg"&gt;Object oriented design exercises deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Great for use while on-the-go.&lt;/p&gt; 
&lt;h3&gt;Coding Resource: Interactive Coding Challenges&lt;/h3&gt; 
&lt;p&gt;Looking for resources to help you prep for the &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Coding Interview&lt;/strong&gt;&lt;/a&gt;?&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/b4YtAEN.png"&gt; &lt;br&gt; &lt;/p&gt; 
&lt;p&gt;Check out the sister repo &lt;a href="https://github.com/donnemartin/interactive-coding-challenges"&gt;&lt;strong&gt;Interactive Coding Challenges&lt;/strong&gt;&lt;/a&gt;, which contains an additional Anki deck:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/interactive-coding-challenges/tree/master/anki_cards/Coding.apkg"&gt;Coding deck&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Learn from the community.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Feel free to submit pull requests to help:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fix errors&lt;/li&gt; 
 &lt;li&gt;Improve sections&lt;/li&gt; 
 &lt;li&gt;Add new sections&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/donnemartin/system-design-primer/issues/28"&gt;Translate&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Content that needs some polishing is placed &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development"&gt;under development&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Review the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/CONTRIBUTING.md"&gt;Contributing Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Index of system design topics&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Summaries of various system design topics, including pros and cons. &lt;strong&gt;Everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Each section contains links to more in-depth resources.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png"&gt; &lt;br&gt; &lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-topics-start-here"&gt;System design topics: start here&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-1-review-the-scalability-video-lecture"&gt;Step 1: Review the scalability video lecture&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#step-2-review-the-scalability-article"&gt;Step 2: Review the scalability article&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#next-steps"&gt;Next steps&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#performance-vs-scalability"&gt;Performance vs scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-vs-throughput"&gt;Latency vs throughput&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-vs-consistency"&gt;Availability vs consistency&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP theorem&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cp---consistency-and-partition-tolerance"&gt;CP - consistency and partition tolerance&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#ap---availability-and-partition-tolerance"&gt;AP - availability and partition tolerance&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#consistency-patterns"&gt;Consistency patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#weak-consistency"&gt;Weak consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;Eventual consistency&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#strong-consistency"&gt;Strong consistency&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-patterns"&gt;Availability patterns&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#fail-over"&gt;Fail-over&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#replication"&gt;Replication&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#availability-in-numbers"&gt;Availability in numbers&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#domain-name-system"&gt;Domain name system&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network"&gt;Content delivery network&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#push-cdns"&gt;Push CDNs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#pull-cdns"&gt;Pull CDNs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer"&gt;Load balancer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive"&gt;Active-passive&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active"&gt;Active-active&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#horizontal-scaling"&gt;Horizontal scaling&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;Reverse proxy (web server)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#load-balancer-vs-reverse-proxy"&gt;Load balancer vs reverse proxy&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-layer"&gt;Application layer&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#microservices"&gt;Microservices&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#service-discovery"&gt;Service discovery&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;Database&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#relational-database-management-system-rdbms"&gt;Relational database management system (RDBMS)&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;Federation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding"&gt;Sharding&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization"&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-tuning"&gt;SQL tuning&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#nosql"&gt;NoSQL&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store"&gt;Key-value store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#document-store"&gt;Document store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#wide-column-store"&gt;Wide column store&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#graph-database"&gt;Graph Database&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache"&gt;Cache&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#client-caching"&gt;Client caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cdn-caching"&gt;CDN caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#web-server-caching"&gt;Web server caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database-caching"&gt;Database caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#application-caching"&gt;Application caching&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-database-query-level"&gt;Caching at the database query level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#caching-at-the-object-level"&gt;Caching at the object level&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#when-to-update-the-cache"&gt;When to update the cache&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache-aside"&gt;Cache-aside&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-through"&gt;Write-through&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#write-behind-write-back"&gt;Write-behind (write-back)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#refresh-ahead"&gt;Refresh-ahead&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism"&gt;Asynchronism&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#message-queues"&gt;Message queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#task-queues"&gt;Task queues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#back-pressure"&gt;Back pressure&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;Communication&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#transmission-control-protocol-tcp"&gt;Transmission control protocol (TCP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#user-datagram-protocol-udp"&gt;User datagram protocol (UDP)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#remote-procedure-call-rpc"&gt;Remote procedure call (RPC)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest"&gt;Representational state transfer (REST)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#security"&gt;Security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix"&gt;Appendix&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-architectures"&gt;Company architectures&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#under-development"&gt;Under development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#credits"&gt;Credits&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contact-info"&gt;Contact info&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Study guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Suggested topics to review based on your interview timeline (short, medium, long).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/OfVllex.png" alt="Imgur"&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Q: For interviews, do I need to know everything here?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;A: No, you don't need to know everything here to prepare for the interview&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;What you are asked in an interview depends on variables such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;How much experience you have&lt;/li&gt; 
 &lt;li&gt;What your technical background is&lt;/li&gt; 
 &lt;li&gt;What positions you are interviewing for&lt;/li&gt; 
 &lt;li&gt;Which companies you are interviewing with&lt;/li&gt; 
 &lt;li&gt;Luck&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;More experienced candidates are generally expected to know more about system design. Architects or team leads might be expected to know more than individual contributors. Top tech companies are likely to have one or more design interview rounds.&lt;/p&gt; 
&lt;p&gt;Start broad and go deeper in a few areas. It helps to know a little about various key system design topics. Adjust the following guide based on your timeline, experience, what positions you are interviewing for, and which companies you are interviewing with.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Short timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;some&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;some depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;many&lt;/strong&gt; interview questions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Long timeline&lt;/strong&gt; - Aim for &lt;strong&gt;breadth&lt;/strong&gt; and &lt;strong&gt;more depth&lt;/strong&gt; with system design topics. Practice by solving &lt;strong&gt;most&lt;/strong&gt; interview questions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Short&lt;/th&gt; 
   &lt;th&gt;Medium&lt;/th&gt; 
   &lt;th&gt;Long&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics"&gt;System design topics&lt;/a&gt; to get a broad understanding of how systems work&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few articles in the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#company-engineering-blogs"&gt;Company engineering blogs&lt;/a&gt; for the companies you are interviewing with&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read through a few &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#real-world-architectures"&gt;Real world architectures&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#how-to-approach-a-system-design-interview-question"&gt;How to approach a system design interview question&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;span&gt;👍&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Work through &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#object-oriented-design-interview-questions-with-solutions"&gt;Object-oriented design interview questions with solutions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Review &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#additional-system-design-interview-questions"&gt;Additional system design interview questions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Some&lt;/td&gt; 
   &lt;td&gt;Many&lt;/td&gt; 
   &lt;td&gt;Most&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;How to approach a system design interview question&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;How to tackle a system design interview question.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The system design interview is an &lt;strong&gt;open-ended conversation&lt;/strong&gt;. You are expected to lead it.&lt;/p&gt; 
&lt;p&gt;You can use the following steps to guide the discussion. To help solidify this process, work through the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#system-design-interview-questions-with-solutions"&gt;System design interview questions with solutions&lt;/a&gt; section using the following steps.&lt;/p&gt; 
&lt;h3&gt;Step 1: Outline use cases, constraints, and assumptions&lt;/h3&gt; 
&lt;p&gt;Gather requirements and scope the problem. Ask questions to clarify use cases and constraints. Discuss assumptions.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Who is going to use it?&lt;/li&gt; 
 &lt;li&gt;How are they going to use it?&lt;/li&gt; 
 &lt;li&gt;How many users are there?&lt;/li&gt; 
 &lt;li&gt;What does the system do?&lt;/li&gt; 
 &lt;li&gt;What are the inputs and outputs of the system?&lt;/li&gt; 
 &lt;li&gt;How much data do we expect to handle?&lt;/li&gt; 
 &lt;li&gt;How many requests per second do we expect?&lt;/li&gt; 
 &lt;li&gt;What is the expected read to write ratio?&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Create a high level design&lt;/h3&gt; 
&lt;p&gt;Outline a high level design with all important components.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sketch the main components and connections&lt;/li&gt; 
 &lt;li&gt;Justify your ideas&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 3: Design core components&lt;/h3&gt; 
&lt;p&gt;Dive into details for each core component. For example, if you were asked to &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;design a url shortening service&lt;/a&gt;, discuss:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generating and storing a hash of the full url 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;MD5&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;Base62&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Hash collisions&lt;/li&gt; 
   &lt;li&gt;SQL or NoSQL&lt;/li&gt; 
   &lt;li&gt;Database schema&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Translating a hashed url to the full url 
  &lt;ul&gt; 
   &lt;li&gt;Database lookup&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;API and object-oriented design&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 4: Scale the design&lt;/h3&gt; 
&lt;p&gt;Identify and address bottlenecks, given the constraints. For example, do you need the following to address scalability issues?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Load balancer&lt;/li&gt; 
 &lt;li&gt;Horizontal scaling&lt;/li&gt; 
 &lt;li&gt;Caching&lt;/li&gt; 
 &lt;li&gt;Database sharding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Discuss potential solutions and trade-offs. Everything is a trade-off. Address bottlenecks using &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#index-of-system-design-topics"&gt;principles of scalable system design&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Back-of-the-envelope calculations&lt;/h3&gt; 
&lt;p&gt;You might be asked to do some estimates by hand. Refer to the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#appendix"&gt;Appendix&lt;/a&gt; for the following resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html"&gt;Use back of the envelope calculations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#powers-of-two-table"&gt;Powers of two table&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#latency-numbers-every-programmer-should-know"&gt;Latency numbers every programmer should know&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;p&gt;Check out the following links to get a better idea of what to expect:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/"&gt;How to ace a systems design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design"&gt;The system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ZgdS0EUmn70"&gt;Intro to Architecture and Systems Design Interviews&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://leetcode.com/discuss/career/229177/My-System-Design-Template"&gt;System design template&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;System design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Pastebin.com (or Bit.ly)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a web crawler&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Mint.com&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the data structures for a social network&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store for a search engine&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Amazon's sales ranking by category feature&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that scales to millions of users on AWS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Design Pastebin.com (or Bit.ly)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/pastebin/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4edXG0T.png" alt="Imgur"&gt;&lt;/p&gt; 
&lt;h3&gt;Design the Twitter timeline and search (or Facebook feed and search)&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/twitter/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jrUBAF7.png" alt="Imgur"&gt;&lt;/p&gt; 
&lt;h3&gt;Design a web crawler&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/web_crawler/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bWxPtQA.png" alt="Imgur"&gt;&lt;/p&gt; 
&lt;h3&gt;Design Mint.com&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/mint/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/V5q57vU.png" alt="Imgur"&gt;&lt;/p&gt; 
&lt;h3&gt;Design the data structures for a social network&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/social_graph/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/cdCv5g7.png" alt="Imgur"&gt;&lt;/p&gt; 
&lt;h3&gt;Design a key-value store for a search engine&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/query_cache/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/4j99mhe.png" alt="Imgur"&gt;&lt;/p&gt; 
&lt;h3&gt;Design Amazon's sales ranking by category feature&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/sales_rank/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/MzExP06.png" alt="Imgur"&gt;&lt;/p&gt; 
&lt;h3&gt;Design a system that scales to millions of users on AWS&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/system_design/scaling_aws/README.md"&gt;View exercise and solution&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/jj3A5N8.png" alt="Imgur"&gt;&lt;/p&gt; 
&lt;h2&gt;Object-oriented design interview questions with solutions&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common object-oriented design interview questions with sample discussions, code, and diagrams.&lt;/p&gt; 
 &lt;p&gt;Solutions linked to content in the &lt;code&gt;solutions/&lt;/code&gt; folder.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note: This section is under development&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a hash map&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/hash_table/hash_map.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a least recently used cache&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/lru_cache/lru_cache.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a call center&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/call_center/call_center.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a deck of cards&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/deck_of_cards/deck_of_cards.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a parking lot&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/parking_lot/parking_lot.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat server&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/solutions/object_oriented_design/online_chat/online_chat.ipynb"&gt;Solution&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a circular array&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an object-oriented design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;System design topics: start here&lt;/h2&gt; 
&lt;p&gt;New to system design?&lt;/p&gt; 
&lt;p&gt;First, you'll need a basic understanding of common principles, learning about what they are, how they are used, and their pros and cons.&lt;/p&gt; 
&lt;h3&gt;Step 1: Review the scalability video lecture&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=-W9F__D3oY4"&gt;Scalability Lecture at Harvard&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;Vertical scaling&lt;/li&gt; 
   &lt;li&gt;Horizontal scaling&lt;/li&gt; 
   &lt;li&gt;Caching&lt;/li&gt; 
   &lt;li&gt;Load balancing&lt;/li&gt; 
   &lt;li&gt;Database replication&lt;/li&gt; 
   &lt;li&gt;Database partitioning&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Step 2: Review the scalability article&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://web.archive.org/web/20221030091841/http://www.lecloud.net/tagged/scalability/chrono"&gt;Scalability&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Topics covered: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones"&gt;Clones&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database"&gt;Databases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache"&gt;Caches&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://web.archive.org/web/20220926171507/https://www.lecloud.net/post/9699762917/scalability-for-dummies-part-4-asynchronism"&gt;Asynchronism&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next steps&lt;/h3&gt; 
&lt;p&gt;Next, we'll look at high-level trade-offs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt; vs &lt;strong&gt;scalability&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Latency&lt;/strong&gt; vs &lt;strong&gt;throughput&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; vs &lt;strong&gt;consistency&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Keep in mind that &lt;strong&gt;everything is a trade-off&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Then we'll dive into more specific topics such as DNS, CDNs, and load balancers.&lt;/p&gt; 
&lt;h2&gt;Performance vs scalability&lt;/h2&gt; 
&lt;p&gt;A service is &lt;strong&gt;scalable&lt;/strong&gt; if it results in increased &lt;strong&gt;performance&lt;/strong&gt; in a manner proportional to resources added. Generally, increasing performance means serving more units of work, but it can also be to handle larger units of work, such as when datasets grow.&lt;sup&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Another way to look at performance vs scalability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;performance&lt;/strong&gt; problem, your system is slow for a single user.&lt;/li&gt; 
 &lt;li&gt;If you have a &lt;strong&gt;scalability&lt;/strong&gt; problem, your system is fast for a single user but slow under heavy load.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.allthingsdistributed.com/2006/03/a_word_on_scalability.html"&gt;A word on scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Latency vs throughput&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt; is the time to perform some action or to produce some result.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Throughput&lt;/strong&gt; is the number of such actions or results per unit of time.&lt;/p&gt; 
&lt;p&gt;Generally, you should aim for &lt;strong&gt;maximal throughput&lt;/strong&gt; with &lt;strong&gt;acceptable latency&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://community.cadence.com/cadence_blogs_8/b/fv/posts/understanding-latency-vs-throughput"&gt;Understanding latency vs throughput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability vs consistency&lt;/h2&gt; 
&lt;h3&gt;CAP theorem&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/bgLMI2u.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://robertgreiner.com/2014/08/cap-theorem-revisited"&gt;Source: CAP theorem revisited&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In a distributed computer system, you can only support two of the following guarantees:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Every read receives the most recent write or an error&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Availability&lt;/strong&gt; - Every request receives a response, without guarantee that it contains the most recent version of the information&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Partition Tolerance&lt;/strong&gt; - The system continues to operate despite arbitrary partitioning due to network failures&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;Networks aren't reliable, so you'll need to support partition tolerance. You'll need to make a software tradeoff between consistency and availability.&lt;/em&gt;&lt;/p&gt; 
&lt;h4&gt;CP - consistency and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Waiting for a response from the partitioned node might result in a timeout error. CP is a good choice if your business needs require atomic reads and writes.&lt;/p&gt; 
&lt;h4&gt;AP - availability and partition tolerance&lt;/h4&gt; 
&lt;p&gt;Responses return the most readily available version of the data available on any node, which might not be the latest. Writes might take some time to propagate when the partition is resolved.&lt;/p&gt; 
&lt;p&gt;AP is a good choice if the business needs to allow for &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;eventual consistency&lt;/a&gt; or when the system needs to continue working despite external errors.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://robertgreiner.com/2014/08/cap-theorem-revisited/"&gt;CAP theorem revisited&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://ksat.me/a-plain-english-introduction-to-cap-theorem"&gt;A plain english introduction to CAP theorem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/henryr/cap-faq"&gt;CAP FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=k-Yaq8AHlFA"&gt;The CAP theorem&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Consistency patterns&lt;/h2&gt; 
&lt;p&gt;With multiple copies of the same data, we are faced with options on how to synchronize them so clients have a consistent view of the data. Recall the definition of consistency from the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP theorem&lt;/a&gt; - Every read receives the most recent write or an error.&lt;/p&gt; 
&lt;h3&gt;Weak consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads may or may not see it. A best effort approach is taken.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as memcached. Weak consistency works well in real time use cases such as VoIP, video chat, and realtime multiplayer games. For example, if you are on a phone call and lose reception for a few seconds, when you regain connection you do not hear what was spoken during connection loss.&lt;/p&gt; 
&lt;h3&gt;Eventual consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will eventually see it (typically within milliseconds). Data is replicated asynchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in systems such as DNS and email. Eventual consistency works well in highly available systems.&lt;/p&gt; 
&lt;h3&gt;Strong consistency&lt;/h3&gt; 
&lt;p&gt;After a write, reads will see it. Data is replicated synchronously.&lt;/p&gt; 
&lt;p&gt;This approach is seen in file systems and RDBMSes. Strong consistency works well in systems that need transactions.&lt;/p&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://snarfed.org/transactions_across_datacenters_io.html"&gt;Transactions across data centers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Availability patterns&lt;/h2&gt; 
&lt;p&gt;There are two complementary patterns to support high availability: &lt;strong&gt;fail-over&lt;/strong&gt; and &lt;strong&gt;replication&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;Fail-over&lt;/h3&gt; 
&lt;h4&gt;Active-passive&lt;/h4&gt; 
&lt;p&gt;With active-passive fail-over, heartbeats are sent between the active and the passive server on standby. If the heartbeat is interrupted, the passive server takes over the active's IP address and resumes service.&lt;/p&gt; 
&lt;p&gt;The length of downtime is determined by whether the passive server is already running in 'hot' standby or whether it needs to start up from 'cold' standby. Only the active server handles traffic.&lt;/p&gt; 
&lt;p&gt;Active-passive failover can also be referred to as master-slave failover.&lt;/p&gt; 
&lt;h4&gt;Active-active&lt;/h4&gt; 
&lt;p&gt;In active-active, both servers are managing traffic, spreading the load between them.&lt;/p&gt; 
&lt;p&gt;If the servers are public-facing, the DNS would need to know about the public IPs of both servers. If the servers are internal-facing, application logic would need to know about both servers.&lt;/p&gt; 
&lt;p&gt;Active-active failover can also be referred to as master-master failover.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): failover&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fail-over adds more hardware and additional complexity.&lt;/li&gt; 
 &lt;li&gt;There is a potential for loss of data if the active system fails before any newly written data can be replicated to the passive.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Replication&lt;/h3&gt; 
&lt;h4&gt;Master-slave and master-master&lt;/h4&gt; 
&lt;p&gt;This topic is further discussed in the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;Database&lt;/a&gt; section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-slave-replication"&gt;Master-slave replication&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#master-master-replication"&gt;Master-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Availability in numbers&lt;/h3&gt; 
&lt;p&gt;Availability is often quantified by uptime (or downtime) as a percentage of time the service is available. Availability is generally measured in number of 9s--a service with 99.99% availability is described as having four 9s.&lt;/p&gt; 
&lt;h4&gt;99.9% availability - three 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;8h 45min 57s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;43m 49.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;10m 4.8s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;1m 26.4s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;99.99% availability - four 9s&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Duration&lt;/th&gt; 
   &lt;th&gt;Acceptable downtime&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per year&lt;/td&gt; 
   &lt;td&gt;52min 35.7s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per month&lt;/td&gt; 
   &lt;td&gt;4m 23s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per week&lt;/td&gt; 
   &lt;td&gt;1m 5s&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Downtime per day&lt;/td&gt; 
   &lt;td&gt;8.6s&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Availability in parallel vs in sequence&lt;/h4&gt; 
&lt;p&gt;If a service consists of multiple components prone to failure, the service's overall availability depends on whether the components are in sequence or in parallel.&lt;/p&gt; 
&lt;h6&gt;In sequence&lt;/h6&gt; 
&lt;p&gt;Overall availability decreases when two components with availability &amp;lt; 100% are in sequence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = Availability (Foo) * Availability (Bar)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in sequence would be 99.8%.&lt;/p&gt; 
&lt;h6&gt;In parallel&lt;/h6&gt; 
&lt;p&gt;Overall availability increases when two components with availability &amp;lt; 100% are in parallel:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Availability (Total) = 1 - (1 - Availability (Foo)) * (1 - Availability (Bar))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If both &lt;code&gt;Foo&lt;/code&gt; and &lt;code&gt;Bar&lt;/code&gt; each had 99.9% availability, their total availability in parallel would be 99.9999%.&lt;/p&gt; 
&lt;h2&gt;Domain name system&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/IOyLj4i.jpg"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/srikrupa5/dns-security-presentation-issa"&gt;Source: DNS security presentation&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A Domain Name System (DNS) translates a domain name such as &lt;a href="http://www.example.com"&gt;www.example.com&lt;/a&gt; to an IP address.&lt;/p&gt; 
&lt;p&gt;DNS is hierarchical, with a few authoritative servers at the top level. Your router or ISP provides information about which DNS server(s) to contact when doing a lookup. Lower level DNS servers cache mappings, which could become stale due to DNS propagation delays. DNS results can also be cached by your browser or OS for a certain period of time, determined by the &lt;a href="https://en.wikipedia.org/wiki/Time_to_live"&gt;time to live (TTL)&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;NS record (name server)&lt;/strong&gt; - Specifies the DNS servers for your domain/subdomain.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MX record (mail exchange)&lt;/strong&gt; - Specifies the mail servers for accepting messages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A record (address)&lt;/strong&gt; - Points a name to an IP address.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CNAME (canonical)&lt;/strong&gt; - Points a name to another name or &lt;code&gt;CNAME&lt;/code&gt; (example.com to &lt;a href="http://www.example.com"&gt;www.example.com&lt;/a&gt;) or to an &lt;code&gt;A&lt;/code&gt; record.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Services such as &lt;a href="https://www.cloudflare.com/dns/"&gt;CloudFlare&lt;/a&gt; and &lt;a href="https://aws.amazon.com/route53/"&gt;Route 53&lt;/a&gt; provide managed DNS services. Some DNS services can route traffic through various methods:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.jscape.com/blog/load-balancing-algorithms"&gt;Weighted round robin&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Prevent traffic from going to servers under maintenance&lt;/li&gt; 
   &lt;li&gt;Balance between varying cluster sizes&lt;/li&gt; 
   &lt;li&gt;A/B testing&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-latency.html"&gt;Latency-based&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html"&gt;Geolocation-based&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): DNS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Accessing a DNS server introduces a slight delay, although mitigated by caching described above.&lt;/li&gt; 
 &lt;li&gt;DNS server management could be complex and is generally managed by &lt;a href="http://superuser.com/questions/472695/who-controls-the-dns-servers/472729"&gt;governments, ISPs, and large companies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;DNS services have recently come under &lt;a href="http://dyn.com/blog/dyn-analysis-summary-of-friday-october-21-attack/"&gt;DDoS attack&lt;/a&gt;, preventing users from accessing websites such as Twitter without knowing Twitter's IP address(es).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://technet.microsoft.com/en-us/library/dd197427(v=ws.10).aspx"&gt;DNS architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Domain_Name_System"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.dnsimple.com/categories/dns/"&gt;DNS articles&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Content delivery network&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h9TAuGI.jpg"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="https://www.creative-artworks.eu/why-use-a-content-delivery-network-cdn/"&gt;Source: Why use a CDN&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;A content delivery network (CDN) is a globally distributed network of proxy servers, serving content from locations closer to the user. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN, although some CDNs such as Amazon's CloudFront support dynamic content. The site's DNS resolution will tell clients which server to contact.&lt;/p&gt; 
&lt;p&gt;Serving content from CDNs can significantly improve performance in two ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Users receive content from data centers close to them&lt;/li&gt; 
 &lt;li&gt;Your servers do not have to serve requests that the CDN fulfills&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Push CDNs&lt;/h3&gt; 
&lt;p&gt;Push CDNs receive new content whenever changes occur on your server. You take full responsibility for providing content, uploading directly to the CDN and rewriting URLs to point to the CDN. You can configure when content expires and when it is updated. Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.&lt;/p&gt; 
&lt;p&gt;Sites with a small amount of traffic or sites with content that isn't often updated work well with push CDNs. Content is placed on the CDNs once, instead of being re-pulled at regular intervals.&lt;/p&gt; 
&lt;h3&gt;Pull CDNs&lt;/h3&gt; 
&lt;p&gt;Pull CDNs grab new content from your server when the first user requests the content. You leave the content on your server and rewrite URLs to point to the CDN. This results in a slower request until the content is cached on the CDN.&lt;/p&gt; 
&lt;p&gt;A &lt;a href="https://en.wikipedia.org/wiki/Time_to_live"&gt;time-to-live (TTL)&lt;/a&gt; determines how long content is cached. Pull CDNs minimize storage space on the CDN, but can create redundant traffic if files expire and are pulled before they have actually changed.&lt;/p&gt; 
&lt;p&gt;Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): CDN&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CDN costs could be significant depending on traffic, although this should be weighed with additional costs you would incur not using a CDN.&lt;/li&gt; 
 &lt;li&gt;Content might be stale if it is updated before the TTL expires it.&lt;/li&gt; 
 &lt;li&gt;CDNs require changing URLs for static content to point to the CDN.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972"&gt;Globally distributed content delivery&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.travelblogadvice.com/technical/the-differences-between-push-and-pull-cdns/"&gt;The differences between push and pull CDNs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Content_delivery_network"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Load balancer&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/h81n9iK.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Load balancers distribute incoming client requests to computing resources such as application servers and databases. In each case, the load balancer returns the response from the computing resource to the appropriate client. Load balancers are effective at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Preventing requests from going to unhealthy servers&lt;/li&gt; 
 &lt;li&gt;Preventing overloading resources&lt;/li&gt; 
 &lt;li&gt;Helping to eliminate a single point of failure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Load balancers can be implemented with hardware (expensive) or with software such as HAProxy.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session persistence&lt;/strong&gt; - Issue cookies and route a specific client's requests to same instance if the web apps do not keep track of sessions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To protect against failures, it's common to set up multiple load balancers, either in &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-passive"&gt;active-passive&lt;/a&gt; or &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#active-active"&gt;active-active&lt;/a&gt; mode.&lt;/p&gt; 
&lt;p&gt;Load balancers can route traffic based on various metrics, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Random&lt;/li&gt; 
 &lt;li&gt;Least loaded&lt;/li&gt; 
 &lt;li&gt;Session/cookies&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.g33kinfo.com/info/round-robin-vs-weighted-round-robin-lb"&gt;Round robin or weighted round robin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-4-load-balancing"&gt;Layer 4&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#layer-7-load-balancing"&gt;Layer 7&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Layer 4 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 4 load balancers look at info at the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;transport layer&lt;/a&gt; to decide how to distribute requests. Generally, this involves the source, destination IP addresses, and ports in the header, but not the contents of the packet. Layer 4 load balancers forward network packets to and from the upstream server, performing &lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/"&gt;Network Address Translation (NAT)&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Layer 7 load balancing&lt;/h3&gt; 
&lt;p&gt;Layer 7 load balancers look at the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#communication"&gt;application layer&lt;/a&gt; to decide how to distribute requests. This can involve contents of the header, message, and cookies. Layer 7 load balancers terminate network traffic, reads the message, makes a load-balancing decision, then opens a connection to the selected server. For example, a layer 7 load balancer can direct video traffic to servers that host videos while directing more sensitive user billing traffic to security-hardened servers.&lt;/p&gt; 
&lt;p&gt;At the cost of flexibility, layer 4 load balancing requires less time and computing resources than Layer 7, although the performance impact can be minimal on modern commodity hardware.&lt;/p&gt; 
&lt;h3&gt;Horizontal scaling&lt;/h3&gt; 
&lt;p&gt;Load balancers can also help with horizontal scaling, improving performance and availability. Scaling out using commodity machines is more cost efficient and results in higher availability than scaling up a single server on more expensive hardware, called &lt;strong&gt;Vertical Scaling&lt;/strong&gt;. It is also easier to hire for talent working on commodity hardware than it is for specialized enterprise systems.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): horizontal scaling&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Scaling horizontally introduces complexity and involves cloning servers 
  &lt;ul&gt; 
   &lt;li&gt;Servers should be stateless: they should not contain any user-related data like sessions or profile pictures&lt;/li&gt; 
   &lt;li&gt;Sessions can be stored in a centralized data store such as a &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#database"&gt;database&lt;/a&gt; (SQL, NoSQL) or a persistent &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cache"&gt;cache&lt;/a&gt; (Redis, Memcached)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Downstream servers such as caches and databases need to handle more simultaneous connections as upstream servers scale out&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): load balancer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The load balancer can become a performance bottleneck if it does not have enough resources or if it is not configured properly.&lt;/li&gt; 
 &lt;li&gt;Introducing a load balancer to help eliminate a single point of failure results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single load balancer is a single point of failure, configuring multiple load balancers further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20220530193911/https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Load_balancing_(computing)"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-4-load-balancing/"&gt;Layer 4 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/layer-7-load-balancing/"&gt;Layer 7 load balancing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html"&gt;ELB listener config&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reverse proxy (web server)&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n41Azff.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="https://upload.wikimedia.org/wikipedia/commons/6/67/Reverse_proxy_h2g2bob.svg"&gt;Source: Wikipedia&lt;/a&gt;&lt;/i&gt; &lt;br&gt; &lt;/p&gt; 
&lt;p&gt;A reverse proxy is a web server that centralizes internal services and provides unified interfaces to the public. Requests from clients are forwarded to a server that can fulfill it before the reverse proxy returns the server's response to the client.&lt;/p&gt; 
&lt;p&gt;Additional benefits include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Increased security&lt;/strong&gt; - Hide information about backend servers, blacklist IPs, limit number of connections per client&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Increased scalability and flexibility&lt;/strong&gt; - Clients only see the reverse proxy's IP, allowing you to scale servers or change their configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SSL termination&lt;/strong&gt; - Decrypt incoming requests and encrypt server responses so backend servers do not have to perform these potentially expensive operations 
  &lt;ul&gt; 
   &lt;li&gt;Removes the need to install &lt;a href="https://en.wikipedia.org/wiki/X.509"&gt;X.509 certificates&lt;/a&gt; on each server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compression&lt;/strong&gt; - Compress server responses&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt; - Return the response for cached requests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Static content&lt;/strong&gt; - Serve static content directly 
  &lt;ul&gt; 
   &lt;li&gt;HTML/CSS/JS&lt;/li&gt; 
   &lt;li&gt;Photos&lt;/li&gt; 
   &lt;li&gt;Videos&lt;/li&gt; 
   &lt;li&gt;Etc&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Load balancer vs reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploying a load balancer is useful when you have multiple servers. Often, load balancers route traffic to a set of servers serving the same function.&lt;/li&gt; 
 &lt;li&gt;Reverse proxies can be useful even with just one web server or application server, opening up the benefits described in the previous section.&lt;/li&gt; 
 &lt;li&gt;Solutions such as NGINX and HAProxy can support both layer 7 reverse proxying and load balancing.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): reverse proxy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Introducing a reverse proxy results in increased complexity.&lt;/li&gt; 
 &lt;li&gt;A single reverse proxy is a single point of failure, configuring multiple reverse proxies (ie a &lt;a href="https://en.wikipedia.org/wiki/Failover"&gt;failover&lt;/a&gt;) further increases complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/reverse-proxy-vs-load-balancer/"&gt;Reverse proxy vs load balancer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/"&gt;NGINX architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.haproxy.org/download/1.2/doc/architecture.txt"&gt;HAProxy architecture guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Reverse_proxy"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Application layer&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yB5SYwm.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Separating out the web layer from the application layer (also known as platform layer) allows you to scale and configure both layers independently. Adding a new API results in adding application servers without necessarily adding additional web servers. The &lt;strong&gt;single responsibility principle&lt;/strong&gt; advocates for small and autonomous services that work together. Small teams with small services can plan more aggressively for rapid growth.&lt;/p&gt; 
&lt;p&gt;Workers in the application layer also help enable &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#asynchronism"&gt;asynchronism&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Microservices&lt;/h3&gt; 
&lt;p&gt;Related to this discussion are &lt;a href="https://en.wikipedia.org/wiki/Microservices"&gt;microservices&lt;/a&gt;, which can be described as a suite of independently deployable, small, modular services. Each service runs a unique process and communicates through a well-defined, lightweight mechanism to serve a business goal. &lt;sup&gt;&lt;a href="https://smartbear.com/learn/api-design/what-are-microservices"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Pinterest, for example, could have the following microservices: user profile, follower, feed, search, photo upload, etc.&lt;/p&gt; 
&lt;h3&gt;Service Discovery&lt;/h3&gt; 
&lt;p&gt;Systems such as &lt;a href="https://www.consul.io/docs/index.html"&gt;Consul&lt;/a&gt;, &lt;a href="https://coreos.com/etcd/docs/latest"&gt;Etcd&lt;/a&gt;, and &lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;Zookeeper&lt;/a&gt; can help services find each other by keeping track of registered names, addresses, and ports. &lt;a href="https://www.consul.io/intro/getting-started/checks.html"&gt;Health checks&lt;/a&gt; help verify service integrity and are often done using an &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#hypertext-transfer-protocol-http"&gt;HTTP&lt;/a&gt; endpoint. Both Consul and Etcd have a built in &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#key-value-store"&gt;key-value store&lt;/a&gt; that can be useful for storing config values and other shared data.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): application layer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Adding an application layer with loosely coupled services requires a different approach from an architectural, operations, and process viewpoint (vs a monolithic system).&lt;/li&gt; 
 &lt;li&gt;Microservices can add complexity in terms of deployments and operations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale"&gt;Intro to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Service-oriented_architecture"&gt;Service oriented architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;Introduction to Zookeeper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudncode.wordpress.com/2016/07/22/msa-getting-started/"&gt;Here's what you need to know about building microservices&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Database&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Xkm5CXz.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Relational database management system (RDBMS)&lt;/h3&gt; 
&lt;p&gt;A relational database like SQL is a collection of data items organized in tables.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ACID&lt;/strong&gt; is a set of properties of relational database &lt;a href="https://en.wikipedia.org/wiki/Database_transaction"&gt;transactions&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Atomicity&lt;/strong&gt; - Each transaction is all or nothing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt; - Any transaction will bring the database from one valid state to another&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt; - Executing transactions concurrently has the same results as if the transactions were executed serially&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Durability&lt;/strong&gt; - Once a transaction has been committed, it will remain so&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are many techniques to scale a relational database: &lt;strong&gt;master-slave replication&lt;/strong&gt;, &lt;strong&gt;master-master replication&lt;/strong&gt;, &lt;strong&gt;federation&lt;/strong&gt;, &lt;strong&gt;sharding&lt;/strong&gt;, &lt;strong&gt;denormalization&lt;/strong&gt;, and &lt;strong&gt;SQL tuning&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Master-slave replication&lt;/h4&gt; 
&lt;p&gt;The master serves reads and writes, replicating writes to one or more slaves, which serve only reads. Slaves can also replicate to additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/C9ioGtn.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-slave replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Additional logic is needed to promote a slave to a master.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Master-master replication&lt;/h4&gt; 
&lt;p&gt;Both masters serve reads and writes and coordinate with each other on writes. If either master goes down, the system can continue to operate with both reads and writes.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/krAHLGg.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): master-master replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You'll need a load balancer or you'll need to make changes to your application logic to determine where to write.&lt;/li&gt; 
 &lt;li&gt;Most master-master systems are either loosely consistent (violating ACID) or have increased write latency due to synchronization.&lt;/li&gt; 
 &lt;li&gt;Conflict resolution comes more into play as more write nodes are added and as latency increases.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#disadvantages-replication"&gt;Disadvantage(s): replication&lt;/a&gt; for points related to &lt;strong&gt;both&lt;/strong&gt; master-slave and master-master.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There is a potential for loss of data if the master fails before any newly written data can be replicated to other nodes.&lt;/li&gt; 
 &lt;li&gt;Writes are replayed to the read replicas. If there are a lot of writes, the read replicas can get bogged down with replaying writes and can't do as many reads.&lt;/li&gt; 
 &lt;li&gt;The more read slaves, the more you have to replicate, which leads to greater replication lag.&lt;/li&gt; 
 &lt;li&gt;On some systems, writing to the master can spawn multiple threads to write in parallel, whereas read replicas only support writing sequentially with a single thread.&lt;/li&gt; 
 &lt;li&gt;Replication adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: replication&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Multi-master_replication"&gt;Multi-master replication&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Federation&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/U3qV33e.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Source: Scaling up to your first 10 million users&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Federation (or functional partitioning) splits up databases by function. For example, instead of a single, monolithic database, you could have three databases: &lt;strong&gt;forums&lt;/strong&gt;, &lt;strong&gt;users&lt;/strong&gt;, and &lt;strong&gt;products&lt;/strong&gt;, resulting in less read and write traffic to each database and therefore less replication lag. Smaller databases result in more data that can fit in memory, which in turn results in more cache hits due to improved cache locality. With no single central master serializing writes you can write in parallel, increasing throughput.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Federation is not effective if your schema requires huge functions or tables.&lt;/li&gt; 
 &lt;li&gt;You'll need to update your application logic to determine which database to read and write.&lt;/li&gt; 
 &lt;li&gt;Joining data from two databases is more complex with a &lt;a href="http://stackoverflow.com/questions/5145637/querying-data-by-joining-two-tables-in-two-database-on-different-servers"&gt;server link&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Federation adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: federation&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Sharding&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wU8x5Id.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Sharding distributes data across different databases such that each database can only manage a subset of the data. Taking a users database as an example, as the number of users increases, more shards are added to the cluster.&lt;/p&gt; 
&lt;p&gt;Similar to the advantages of &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;federation&lt;/a&gt;, sharding results in less read and write traffic, less replication, and more cache hits. Index size is also reduced, which generally improves performance with faster queries. If one shard goes down, the other shards are still operational, although you'll want to add some form of replication to avoid data loss. Like federation, there is no single central master serializing writes, allowing you to write in parallel with increased throughput.&lt;/p&gt; 
&lt;p&gt;Common ways to shard a table of users is either through the user's last name initial or the user's geographic location.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;You'll need to update your application logic to work with shards, which could result in complex SQL queries.&lt;/li&gt; 
 &lt;li&gt;Data distribution can become lopsided in a shard. For example, a set of power users on a shard could result in increased load to that shard compared to others. 
  &lt;ul&gt; 
   &lt;li&gt;Rebalancing adds additional complexity. A sharding function based on &lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html"&gt;consistent hashing&lt;/a&gt; can reduce the amount of transferred data.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Joining data from multiple shards is more complex.&lt;/li&gt; 
 &lt;li&gt;Sharding adds more hardware and additional complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: sharding&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/blog/2009/8/6/an-unorthodox-approach-to-database-design-the-coming-of-the.html"&gt;The coming of the shard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Shard_(database_architecture)"&gt;Shard database architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html"&gt;Consistent hashing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Denormalization&lt;/h4&gt; 
&lt;p&gt;Denormalization attempts to improve read performance at the expense of some write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins. Some RDBMS such as &lt;a href="https://en.wikipedia.org/wiki/PostgreSQL"&gt;PostgreSQL&lt;/a&gt; and Oracle support &lt;a href="https://en.wikipedia.org/wiki/Materialized_view"&gt;materialized views&lt;/a&gt; which handle the work of storing redundant information and keeping redundant copies consistent.&lt;/p&gt; 
&lt;p&gt;Once data becomes distributed with techniques such as &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#federation"&gt;federation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sharding"&gt;sharding&lt;/a&gt;, managing joins across data centers further increases complexity. Denormalization might circumvent the need for such complex joins.&lt;/p&gt; 
&lt;p&gt;In most systems, reads can heavily outnumber writes 100:1 or even 1000:1. A read resulting in a complex database join can be very expensive, spending a significant amount of time on disk operations.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): denormalization&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Data is duplicated.&lt;/li&gt; 
 &lt;li&gt;Constraints can help redundant copies of information stay in sync, which increases complexity of the database design.&lt;/li&gt; 
 &lt;li&gt;A denormalized database under heavy write load might perform worse than its normalized counterpart.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h6&gt;Source(s) and further reading: denormalization&lt;/h6&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Denormalization"&gt;Denormalization&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;SQL tuning&lt;/h4&gt; 
&lt;p&gt;SQL tuning is a broad topic and many &lt;a href="https://www.amazon.com/s/ref=nb_sb_noss_2?url=search-alias%3Daps&amp;amp;field-keywords=sql+tuning"&gt;books&lt;/a&gt; have been written as reference.&lt;/p&gt; 
&lt;p&gt;It's important to &lt;strong&gt;benchmark&lt;/strong&gt; and &lt;strong&gt;profile&lt;/strong&gt; to simulate and uncover bottlenecks.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark&lt;/strong&gt; - Simulate high-load situations with tools such as &lt;a href="http://httpd.apache.org/docs/2.2/programs/ab.html"&gt;ab&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Profile&lt;/strong&gt; - Enable tools such as the &lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html"&gt;slow query log&lt;/a&gt; to help track performance issues.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Benchmarking and profiling might point you to the following optimizations.&lt;/p&gt; 
&lt;h5&gt;Tighten up the schema&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;MySQL dumps to disk in contiguous blocks for fast access.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;CHAR&lt;/code&gt; instead of &lt;code&gt;VARCHAR&lt;/code&gt; for fixed-length fields. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;CHAR&lt;/code&gt; effectively allows for fast, random access, whereas with &lt;code&gt;VARCHAR&lt;/code&gt;, you must find the end of a string before moving onto the next one.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;TEXT&lt;/code&gt; for large blocks of text such as blog posts. &lt;code&gt;TEXT&lt;/code&gt; also allows for boolean searches. Using a &lt;code&gt;TEXT&lt;/code&gt; field results in storing a pointer on disk that is used to locate the text block.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;INT&lt;/code&gt; for larger numbers up to 2^32 or 4 billion.&lt;/li&gt; 
 &lt;li&gt;Use &lt;code&gt;DECIMAL&lt;/code&gt; for currency to avoid floating point representation errors.&lt;/li&gt; 
 &lt;li&gt;Avoid storing large &lt;code&gt;BLOBS&lt;/code&gt;, store the location of where to get the object instead.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;VARCHAR(255)&lt;/code&gt; is the largest number of characters that can be counted in an 8 bit number, often maximizing the use of a byte in some RDBMS.&lt;/li&gt; 
 &lt;li&gt;Set the &lt;code&gt;NOT NULL&lt;/code&gt; constraint where applicable to &lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search"&gt;improve search performance&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Use good indices&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Columns that you are querying (&lt;code&gt;SELECT&lt;/code&gt;, &lt;code&gt;GROUP BY&lt;/code&gt;, &lt;code&gt;ORDER BY&lt;/code&gt;, &lt;code&gt;JOIN&lt;/code&gt;) could be faster with indices.&lt;/li&gt; 
 &lt;li&gt;Indices are usually represented as self-balancing &lt;a href="https://en.wikipedia.org/wiki/B-tree"&gt;B-tree&lt;/a&gt; that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time.&lt;/li&gt; 
 &lt;li&gt;Placing an index can keep the data in memory, requiring more space.&lt;/li&gt; 
 &lt;li&gt;Writes could also be slower since the index also needs to be updated.&lt;/li&gt; 
 &lt;li&gt;When loading large amounts of data, it might be faster to disable indices, load the data, then rebuild the indices.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Avoid expensive joins&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#denormalization"&gt;Denormalize&lt;/a&gt; where performance demands it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Partition tables&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Break up a table by putting hot spots in a separate table to help keep it in memory.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Tune the query cache&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;In some cases, the &lt;a href="https://dev.mysql.com/doc/refman/5.7/en/query-cache.html"&gt;query cache&lt;/a&gt; could lead to &lt;a href="https://www.percona.com/blog/2016/10/12/mysql-5-7-performance-tuning-immediately-after-installation/"&gt;performance issues&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL tuning&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://aiddroid.com/10-tips-optimizing-mysql-queries-dont-suck/"&gt;Tips for optimizing MySQL queries&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1217466/is-there-a-good-reason-i-see-varchar255-used-so-often-as-opposed-to-another-l"&gt;Is there a good reason i see VARCHAR(255) used so often?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/1017239/how-do-null-values-affect-performance-in-a-database-search"&gt;How do null values affect performance?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html"&gt;Slow query log&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;NoSQL&lt;/h3&gt; 
&lt;p&gt;NoSQL is a collection of data items represented in a &lt;strong&gt;key-value store&lt;/strong&gt;, &lt;strong&gt;document store&lt;/strong&gt;, &lt;strong&gt;wide column store&lt;/strong&gt;, or a &lt;strong&gt;graph database&lt;/strong&gt;. Data is denormalized, and joins are generally done in the application code. Most NoSQL stores lack true ACID transactions and favor &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#eventual-consistency"&gt;eventual consistency&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;BASE&lt;/strong&gt; is often used to describe the properties of NoSQL databases. In comparison with the &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#cap-theorem"&gt;CAP Theorem&lt;/a&gt;, BASE chooses availability over consistency.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Basically available&lt;/strong&gt; - the system guarantees availability.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Soft state&lt;/strong&gt; - the state of the system may change over time, even without input.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Eventual consistency&lt;/strong&gt; - the system will become consistent over a period of time, given that the system doesn't receive input during that period.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to choosing between &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#sql-or-nosql"&gt;SQL or NoSQL&lt;/a&gt;, it is helpful to understand which type of NoSQL database best fits your use case(s). We'll review &lt;strong&gt;key-value stores&lt;/strong&gt;, &lt;strong&gt;document stores&lt;/strong&gt;, &lt;strong&gt;wide column stores&lt;/strong&gt;, and &lt;strong&gt;graph databases&lt;/strong&gt; in the next section.&lt;/p&gt; 
&lt;h4&gt;Key-value store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: hash table&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A key-value store generally allows for O(1) reads and writes and is often backed by memory or SSD. Data stores can maintain keys in &lt;a href="https://en.wikipedia.org/wiki/Lexicographical_order"&gt;lexicographic order&lt;/a&gt;, allowing efficient retrieval of key ranges. Key-value stores can allow for storing of metadata with a value.&lt;/p&gt; 
&lt;p&gt;Key-value stores provide high performance and are often used for simple data models or for rapidly-changing data, such as an in-memory cache layer. Since they offer only a limited set of operations, complexity is shifted to the application layer if additional operations are needed.&lt;/p&gt; 
&lt;p&gt;A key-value store is the basis for more complex systems such as a document store, and in some cases, a graph database.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: key-value store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Key-value_database"&gt;Key-value database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/4056093/what-are-the-disadvantages-of-using-a-key-value-table-over-nullable-columns-or"&gt;Disadvantages of key-value stores&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://qnimate.com/overview-of-redis-architecture/"&gt;Redis architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://adayinthelifeof.nl/2011/02/06/memcache-internals/"&gt;Memcached architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Document store&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: key-value store with documents stored as values&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A document store is centered around documents (XML, JSON, binary, etc), where a document stores all information for a given object. Document stores provide APIs or a query language to query based on the internal structure of the document itself. &lt;em&gt;Note, many key-value stores include features for working with a value's metadata, blurring the lines between these two storage types.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Based on the underlying implementation, documents are organized by collections, tags, metadata, or directories. Although documents can be organized or grouped together, documents may have fields that are completely different from each other.&lt;/p&gt; 
&lt;p&gt;Some document stores like &lt;a href="https://www.mongodb.com/mongodb-architecture"&gt;MongoDB&lt;/a&gt; and &lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/"&gt;CouchDB&lt;/a&gt; also provide a SQL-like language to perform complex queries. &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf"&gt;DynamoDB&lt;/a&gt; supports both key-values and documents.&lt;/p&gt; 
&lt;p&gt;Document stores provide high flexibility and are often used for working with occasionally changing data.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: document store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Document-oriented_database"&gt;Document-oriented database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.mongodb.com/mongodb-architecture"&gt;MongoDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.couchdb.org/2016/08/01/couchdb-2-0-architecture/"&gt;CouchDB architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up"&gt;Elasticsearch architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Wide column store&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/n16iOGk.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html"&gt;Source: SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: nested map &lt;code&gt;ColumnFamily&amp;lt;RowKey, Columns&amp;lt;ColKey, Value, Timestamp&amp;gt;&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;A wide column store's basic unit of data is a column (name/value pair). A column can be grouped in column families (analogous to a SQL table). Super column families further group column families. You can access each column independently with a row key, and columns with the same row key form a row. Each value contains a timestamp for versioning and for conflict resolution.&lt;/p&gt; 
&lt;p&gt;Google introduced &lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;Bigtable&lt;/a&gt; as the first wide column store, which influenced the open-source &lt;a href="https://www.edureka.co/blog/hbase-architecture/"&gt;HBase&lt;/a&gt; often-used in the Hadoop ecosystem, and &lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html"&gt;Cassandra&lt;/a&gt; from Facebook. Stores such as BigTable, HBase, and Cassandra maintain keys in lexicographic order, allowing efficient retrieval of selective key ranges.&lt;/p&gt; 
&lt;p&gt;Wide column stores offer high availability and high scalability. They are often used for very large data sets.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: wide column store&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://blog.grio.com/2015/11/sql-nosql-a-brief-history.html"&gt;SQL &amp;amp; NoSQL, a brief history&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;Bigtable architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.edureka.co/blog/hbase-architecture/"&gt;HBase architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archIntro.html"&gt;Cassandra architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Graph database&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/fNcl65g.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="https://en.wikipedia.org/wiki/File:GraphDatabase_PropertyGraph.png"&gt;Source: Graph database&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Abstraction: graph&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;In a graph database, each node is a record and each arc is a relationship between two nodes. Graph databases are optimized to represent complex relationships with many foreign keys or many-to-many relationships.&lt;/p&gt; 
&lt;p&gt;Graphs databases offer high performance for data models with complex relationships, such as a social network. They are relatively new and are not yet widely-used; it might be more difficult to find development tools and resources. Many graphs can only be accessed with &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#representational-state-transfer-rest"&gt;REST APIs&lt;/a&gt;.&lt;/p&gt; 
&lt;h5&gt;Source(s) and further reading: graph&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Graph_database"&gt;Graph database&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://neo4j.com/"&gt;Neo4j&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.twitter.com/2010/introducing-flockdb"&gt;FlockDB&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: NoSQL&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/3342497/explanation-of-base-terminology"&gt;Explanation of base terminology&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.wskogqenq"&gt;NoSQL databases a survey and decision guidance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20220602114024/https://www.lecloud.net/post/7994751381/scalability-for-dummies-part-2-database"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qI_g07C_Q5I"&gt;Introduction to NoSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://horicky.blogspot.com/2009/11/nosql-patterns.html"&gt;NoSQL patterns&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;SQL or NoSQL&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/wXGqG5f.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="https://www.infoq.com/articles/Transition-RDBMS-NoSQL/"&gt;Source: Transitioning from RDBMS to NoSQL&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;SQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Structured data&lt;/li&gt; 
 &lt;li&gt;Strict schema&lt;/li&gt; 
 &lt;li&gt;Relational data&lt;/li&gt; 
 &lt;li&gt;Need for complex joins&lt;/li&gt; 
 &lt;li&gt;Transactions&lt;/li&gt; 
 &lt;li&gt;Clear patterns for scaling&lt;/li&gt; 
 &lt;li&gt;More established: developers, community, code, tools, etc&lt;/li&gt; 
 &lt;li&gt;Lookups by index are very fast&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Reasons for &lt;strong&gt;NoSQL&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Semi-structured data&lt;/li&gt; 
 &lt;li&gt;Dynamic or flexible schema&lt;/li&gt; 
 &lt;li&gt;Non-relational data&lt;/li&gt; 
 &lt;li&gt;No need for complex joins&lt;/li&gt; 
 &lt;li&gt;Store many TB (or PB) of data&lt;/li&gt; 
 &lt;li&gt;Very data intensive workload&lt;/li&gt; 
 &lt;li&gt;Very high throughput for IOPS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample data well-suited for NoSQL:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Rapid ingest of clickstream and log data&lt;/li&gt; 
 &lt;li&gt;Leaderboard or scoring data&lt;/li&gt; 
 &lt;li&gt;Temporary data, such as a shopping cart&lt;/li&gt; 
 &lt;li&gt;Frequently accessed ('hot') tables&lt;/li&gt; 
 &lt;li&gt;Metadata/lookup tables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Source(s) and further reading: SQL or NoSQL&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=kKjm4ehYiMs"&gt;Scaling up to your first 10 million users&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.sitepoint.com/sql-vs-nosql-differences/"&gt;SQL vs NoSQL differences&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cache&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/Q6z24La.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Source: Scalable system design patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Caching improves page load times and can reduce the load on your servers and databases. In this model, the dispatcher will first lookup if the request has been made before and try to find the previous result to return, in order to save the actual execution.&lt;/p&gt; 
&lt;p&gt;Databases often benefit from a uniform distribution of reads and writes across its partitions. Popular items can skew the distribution, causing bottlenecks. Putting a cache in front of a database can help absorb uneven loads and spikes in traffic.&lt;/p&gt; 
&lt;h3&gt;Client caching&lt;/h3&gt; 
&lt;p&gt;Caches can be located on the client side (OS or browser), &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;server side&lt;/a&gt;, or in a distinct cache layer.&lt;/p&gt; 
&lt;h3&gt;CDN caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#content-delivery-network"&gt;CDNs&lt;/a&gt; are considered a type of cache.&lt;/p&gt; 
&lt;h3&gt;Web server caching&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#reverse-proxy-web-server"&gt;Reverse proxies&lt;/a&gt; and caches such as &lt;a href="https://www.varnish-cache.org/"&gt;Varnish&lt;/a&gt; can serve static and dynamic content directly. Web servers can also cache requests, returning responses without having to contact application servers.&lt;/p&gt; 
&lt;h3&gt;Database caching&lt;/h3&gt; 
&lt;p&gt;Your database usually includes some level of caching in a default configuration, optimized for a generic use case. Tweaking these settings for specific usage patterns can further boost performance.&lt;/p&gt; 
&lt;h3&gt;Application caching&lt;/h3&gt; 
&lt;p&gt;In-memory caches such as Memcached and Redis are key-value stores between your application and your data storage. Since the data is held in RAM, it is much faster than typical databases where data is stored on disk. RAM is more limited than disk, so &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms"&gt;cache invalidation&lt;/a&gt; algorithms such as &lt;a href="https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)"&gt;least recently used (LRU)&lt;/a&gt; can help invalidate 'cold' entries and keep 'hot' data in RAM.&lt;/p&gt; 
&lt;p&gt;Redis has the following additional features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Persistence option&lt;/li&gt; 
 &lt;li&gt;Built-in data structures such as sorted sets and lists&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are multiple levels you can cache that fall into two general categories: &lt;strong&gt;database queries&lt;/strong&gt; and &lt;strong&gt;objects&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Row level&lt;/li&gt; 
 &lt;li&gt;Query-level&lt;/li&gt; 
 &lt;li&gt;Fully-formed serializable objects&lt;/li&gt; 
 &lt;li&gt;Fully-rendered HTML&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Generally, you should try to avoid file-based caching, as it makes cloning and auto-scaling more difficult.&lt;/p&gt; 
&lt;h3&gt;Caching at the database query level&lt;/h3&gt; 
&lt;p&gt;Whenever you query the database, hash the query as a key and store the result to the cache. This approach suffers from expiration issues:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hard to delete a cached result with complex queries&lt;/li&gt; 
 &lt;li&gt;If one piece of data changes such as a table cell, you need to delete all cached queries that might include the changed cell&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Caching at the object level&lt;/h3&gt; 
&lt;p&gt;See your data as an object, similar to what you do with your application code. Have your application assemble the dataset from the database into a class instance or a data structure(s):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Remove the object from cache if its underlying data has changed&lt;/li&gt; 
 &lt;li&gt;Allows for asynchronous processing: workers assemble objects by consuming the latest cached object&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Suggestions of what to cache:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;User sessions&lt;/li&gt; 
 &lt;li&gt;Fully rendered web pages&lt;/li&gt; 
 &lt;li&gt;Activity streams&lt;/li&gt; 
 &lt;li&gt;User graph data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;When to update the cache&lt;/h3&gt; 
&lt;p&gt;Since you can only store a limited amount of data in cache, you'll need to determine which cache update strategy works best for your use case.&lt;/p&gt; 
&lt;h4&gt;Cache-aside&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/ONjORqk.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application is responsible for reading and writing from storage. The cache does not interact with storage directly. The application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Look for entry in cache, resulting in a cache miss&lt;/li&gt; 
 &lt;li&gt;Load entry from the database&lt;/li&gt; 
 &lt;li&gt;Add entry to cache&lt;/li&gt; 
 &lt;li&gt;Return entry&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def get_user(self, user_id):
    user = cache.get("user.{0}", user_id)
    if user is None:
        user = db.query("SELECT * FROM users WHERE user_id = {0}", user_id)
        if user is not None:
            key = "user.{0}".format(user_id)
            cache.set(key, json.dumps(user))
    return user
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://memcached.org/"&gt;Memcached&lt;/a&gt; is generally used in this manner.&lt;/p&gt; 
&lt;p&gt;Subsequent reads of data added to cache are fast. Cache-aside is also referred to as lazy loading. Only requested data is cached, which avoids filling up the cache with data that isn't requested.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): cache-aside&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Each cache miss results in three trips, which can cause a noticeable delay.&lt;/li&gt; 
 &lt;li&gt;Data can become stale if it is updated in the database. This issue is mitigated by setting a time-to-live (TTL) which forces an update of the cache entry, or by using write-through.&lt;/li&gt; 
 &lt;li&gt;When a node fails, it is replaced by a new, empty node, increasing latency.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-through&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/0vBc0hN.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;The application uses the cache as the main data store, reading and writing data to it, while the cache is responsible for reading and writing to the database:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Application adds/updates entry in cache&lt;/li&gt; 
 &lt;li&gt;Cache synchronously writes entry to data store&lt;/li&gt; 
 &lt;li&gt;Return&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Application code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;set_user(12345, {"foo":"bar"})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Cache code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def set_user(user_id, values):
    user = db.query("UPDATE Users WHERE id = {0}", user_id, values)
    cache.set(user_id, user)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Write-through is a slow overall operation due to the write operation, but subsequent reads of just written data are fast. Users are generally more tolerant of latency when updating data than reading data. Data in the cache is not stale.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): write through&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;When a new node is created due to failure or scaling, the new node will not cache entries until the entry is updated in the database. Cache-aside in conjunction with write through can mitigate this issue.&lt;/li&gt; 
 &lt;li&gt;Most data written might never be read, which can be minimized with a TTL.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Write-behind (write-back)&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/rgSrvjG.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Source: Scalability, availability, stability, patterns&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In write-behind, the application does the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add/update entry in cache&lt;/li&gt; 
 &lt;li&gt;Asynchronously write entry to the data store, improving write performance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;Disadvantage(s): write-behind&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;There could be data loss if the cache goes down prior to its contents hitting the data store.&lt;/li&gt; 
 &lt;li&gt;It is more complex to implement write-behind than it is to implement cache-aside or write-through.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Refresh-ahead&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/kxtjqgE.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;Source: From cache to in-memory data grid&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;You can configure the cache to automatically refresh any recently accessed cache entry prior to its expiration.&lt;/p&gt; 
&lt;p&gt;Refresh-ahead can result in reduced latency vs read-through if the cache can accurately predict which items are likely to be needed in the future.&lt;/p&gt; 
&lt;h5&gt;Disadvantage(s): refresh-ahead&lt;/h5&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not accurately predicting which items are likely to be needed in the future can result in reduced performance than without refresh-ahead.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Disadvantage(s): cache&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Need to maintain consistency between caches and the source of truth such as the database through &lt;a href="https://en.wikipedia.org/wiki/Cache_algorithms"&gt;cache invalidation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Cache invalidation is a difficult problem, there is additional complexity associated with when to update the cache.&lt;/li&gt; 
 &lt;li&gt;Need to make application changes such as adding Redis or memcached.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/tmatyashovsky/from-cache-to-in-memory-data-grid-introduction-to-hazelcast"&gt;From cache to in-memory data grid&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html"&gt;Scalable system design patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/"&gt;Introduction to architecting systems for scale&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.slideshare.net/jboner/scalability-availability-stability-patterns/"&gt;Scalability, availability, stability, patterns&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20230126233752/https://www.lecloud.net/post/9246290032/scalability-for-dummies-part-3-cache"&gt;Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://docs.aws.amazon.com/AmazonElastiCache/latest/UserGuide/Strategies.html"&gt;AWS ElastiCache strategies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Cache_(computing)"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Asynchronism&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/54GYsSx.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://lethain.com/introduction-to-architecting-systems-for-scale/#platform_layer"&gt;Source: Intro to architecting systems for scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Asynchronous workflows help reduce request times for expensive operations that would otherwise be performed in-line. They can also help by doing time-consuming work in advance, such as periodic aggregation of data.&lt;/p&gt; 
&lt;h3&gt;Message queues&lt;/h3&gt; 
&lt;p&gt;Message queues receive, hold, and deliver messages. If an operation is too slow to perform inline, you can use a message queue with the following workflow:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;An application publishes a job to the queue, then notifies the user of job status&lt;/li&gt; 
 &lt;li&gt;A worker picks up the job from the queue, processes it, then signals the job is complete&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The user is not blocked and the job is processed in the background. During this time, the client might optionally do a small amount of processing to make it seem like the task has completed. For example, if posting a tweet, the tweet could be instantly posted to your timeline, but it could take some time before your tweet is actually delivered to all of your followers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://redis.io/"&gt;Redis&lt;/a&gt;&lt;/strong&gt; is useful as a simple message broker but messages can be lost.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt;&lt;/strong&gt; is popular but requires you to adapt to the 'AMQP' protocol and manage your own nodes.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://aws.amazon.com/sqs/"&gt;Amazon SQS&lt;/a&gt;&lt;/strong&gt; is hosted but can have high latency and has the possibility of messages being delivered twice.&lt;/p&gt; 
&lt;h3&gt;Task queues&lt;/h3&gt; 
&lt;p&gt;Tasks queues receive tasks and their related data, runs them, then delivers their results. They can support scheduling and can be used to run computationally-intensive jobs in the background.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.celeryproject.org/en/stable/"&gt;Celery&lt;/a&gt;&lt;/strong&gt; has support for scheduling and primarily has python support.&lt;/p&gt; 
&lt;h3&gt;Back pressure&lt;/h3&gt; 
&lt;p&gt;If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance. &lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html"&gt;Back pressure&lt;/a&gt; can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue. Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later. Clients can retry the request at a later time, perhaps with &lt;a href="https://en.wikipedia.org/wiki/Exponential_backoff"&gt;exponential backoff&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Disadvantage(s): asynchronism&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use cases such as inexpensive calculations and realtime workflows might be better suited for synchronous operations, as introducing queues can add delays and complexity.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=1KRYH75wgy4"&gt;It's all a numbers game&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mechanical-sympathy.blogspot.com/2012/05/apply-back-pressure-when-overloaded.html"&gt;Applying back pressure when overloaded&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Little%27s_law"&gt;Little's law&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-a-message-queue-and-a-task-queue-Why-would-a-task-queue-require-a-message-broker-like-RabbitMQ-Redis-Celery-or-IronMQ-to-function"&gt;What is the difference between a message queue and a task queue?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Communication&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/5KeocQs.jpg"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.escotal.com/osilayer.html"&gt;Source: OSI 7 layer model&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h3&gt;Hypertext transfer protocol (HTTP)&lt;/h3&gt; 
&lt;p&gt;HTTP is a method for encoding and transporting data between a client and a server. It is a request/response protocol: clients issue requests and servers issue responses with relevant content and completion status info about the request. HTTP is self-contained, allowing requests and responses to flow through many intermediate routers and servers that perform load balancing, caching, encryption, and compression.&lt;/p&gt; 
&lt;p&gt;A basic HTTP request consists of a verb (method) and a resource (endpoint). Below are common HTTP verbs:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Verb&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Idempotent*&lt;/th&gt; 
   &lt;th&gt;Safe&lt;/th&gt; 
   &lt;th&gt;Cacheable&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GET&lt;/td&gt; 
   &lt;td&gt;Reads a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;POST&lt;/td&gt; 
   &lt;td&gt;Creates a resource or trigger a process that handles data&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PUT&lt;/td&gt; 
   &lt;td&gt;Creates or replace a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PATCH&lt;/td&gt; 
   &lt;td&gt;Partially updates a resource&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Yes if response contains freshness info&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DELETE&lt;/td&gt; 
   &lt;td&gt;Deletes a resource&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Can be called many times without different outcomes.&lt;/p&gt; 
&lt;p&gt;HTTP is an application layer protocol relying on lower-level protocols such as &lt;strong&gt;TCP&lt;/strong&gt; and &lt;strong&gt;UDP&lt;/strong&gt;.&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: HTTP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.nginx.com/resources/glossary/http/"&gt;What is HTTP?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-is-the-difference-between-HTTP-protocol-and-TCP-protocol"&gt;Difference between HTTP and TCP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://laracasts.com/discuss/channels/general-discussion/whats-the-differences-between-put-and-patch?page=1"&gt;Difference between PUT and PATCH&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Transmission control protocol (TCP)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/JdAsdvG.jpg"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;TCP is a connection-oriented protocol over an &lt;a href="https://en.wikipedia.org/wiki/Internet_Protocol"&gt;IP network&lt;/a&gt;. Connection is established and terminated using a &lt;a href="https://en.wikipedia.org/wiki/Handshaking"&gt;handshake&lt;/a&gt;. All packets sent are guaranteed to reach the destination in the original order and without corruption through:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sequence numbers and &lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Checksum_computation"&gt;checksum fields&lt;/a&gt; for each packet&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)"&gt;Acknowledgement&lt;/a&gt; packets and automatic retransmission&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If the sender does not receive a correct response, it will resend the packets. If there are multiple timeouts, the connection is dropped. TCP also implements &lt;a href="https://en.wikipedia.org/wiki/Flow_control_(data)"&gt;flow control&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Network_congestion#Congestion_control"&gt;congestion control&lt;/a&gt;. These guarantees cause delays and generally result in less efficient transmission than UDP.&lt;/p&gt; 
&lt;p&gt;To ensure high throughput, web servers can keep a large number of TCP connections open, resulting in high memory usage. It can be expensive to have a large number of open connections between web server threads and say, a &lt;a href="https://memcached.org/"&gt;memcached&lt;/a&gt; server. &lt;a href="https://en.wikipedia.org/wiki/Connection_pool"&gt;Connection pooling&lt;/a&gt; can help in addition to switching to UDP where applicable.&lt;/p&gt; 
&lt;p&gt;TCP is useful for applications that require high reliability but are less time critical. Some examples include web servers, database info, SMTP, FTP, and SSH.&lt;/p&gt; 
&lt;p&gt;Use TCP over UDP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need all of the data to arrive intact&lt;/li&gt; 
 &lt;li&gt;You want to automatically make a best estimate use of the network throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User datagram protocol (UDP)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/yzDrJtA.jpg"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.wildbunny.co.uk/blog/2012/10/09/how-to-make-a-multi-player-game-part-1/"&gt;Source: How to make a multiplayer game&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;UDP is connectionless. Datagrams (analogous to packets) are guaranteed only at the datagram level. Datagrams might reach their destination out of order or not at all. UDP does not support congestion control. Without the guarantees that TCP support, UDP is generally more efficient.&lt;/p&gt; 
&lt;p&gt;UDP can broadcast, sending datagrams to all devices on the subnet. This is useful with &lt;a href="https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol"&gt;DHCP&lt;/a&gt; because the client has not yet received an IP address, thus preventing a way for TCP to stream without the IP address.&lt;/p&gt; 
&lt;p&gt;UDP is less reliable but works well in real time use cases such as VoIP, video chat, streaming, and realtime multiplayer games.&lt;/p&gt; 
&lt;p&gt;Use UDP over TCP when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You need the lowest latency&lt;/li&gt; 
 &lt;li&gt;Late data is worse than loss of data&lt;/li&gt; 
 &lt;li&gt;You want to implement your own error correction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading: TCP and UDP&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://gafferongames.com/networking-for-game-programmers/udp-vs-tcp/"&gt;Networking for game programming&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cyberciti.biz/faq/key-differences-between-tcp-and-udp-protocols/"&gt;Key differences between TCP and UDP protocols&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/5970383/difference-between-tcp-and-udp"&gt;Difference between TCP and UDP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol"&gt;Transmission control protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol"&gt;User datagram protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cs.bu.edu/~jappavoo/jappavoo.github.com/451/papers/memcache-fb.pdf"&gt;Scaling memcache at Facebook&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Remote procedure call (RPC)&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/iF4Mkb5.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Source: Crack the system design interview&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;In an RPC, a client causes a procedure to execute on a different address space, usually a remote server. The procedure is coded as if it were a local procedure call, abstracting away the details of how to communicate with the server from the client program. Remote calls are usually slower and less reliable than local calls so it is helpful to distinguish RPC calls from local calls. Popular RPC frameworks include &lt;a href="https://developers.google.com/protocol-buffers/"&gt;Protobuf&lt;/a&gt;, &lt;a href="https://thrift.apache.org/"&gt;Thrift&lt;/a&gt;, and &lt;a href="https://avro.apache.org/docs/current/"&gt;Avro&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;RPC is a request-response protocol:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Client program&lt;/strong&gt; - Calls the client stub procedure. The parameters are pushed onto the stack like a local procedure call.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client stub procedure&lt;/strong&gt; - Marshals (packs) procedure id and arguments into a request message.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client communication module&lt;/strong&gt; - OS sends the message from the client to the server.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server communication module&lt;/strong&gt; - OS passes the incoming packets to the server stub procedure.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Server stub procedure&lt;/strong&gt; - Unmarshalls the results, calls the server procedure matching the procedure id and passes the given arguments.&lt;/li&gt; 
 &lt;li&gt;The server response repeats the steps above in reverse order.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample RPC calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someoperation?data=anId

POST /anotheroperation
{
  "data":"anId";
  "anotherdata": "another value"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;RPC is focused on exposing behaviors. RPCs are often used for performance reasons with internal communications, as you can hand-craft native calls to better fit your use cases.&lt;/p&gt; 
&lt;p&gt;Choose a native library (aka SDK) when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You know your target platform.&lt;/li&gt; 
 &lt;li&gt;You want to control how your "logic" is accessed.&lt;/li&gt; 
 &lt;li&gt;You want to control how error control happens off your library.&lt;/li&gt; 
 &lt;li&gt;Performance and end user experience is your primary concern.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;HTTP APIs following &lt;strong&gt;REST&lt;/strong&gt; tend to be used more often for public APIs.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;RPC clients become tightly coupled to the service implementation.&lt;/li&gt; 
 &lt;li&gt;A new API must be defined for every new operation or use case.&lt;/li&gt; 
 &lt;li&gt;It can be difficult to debug RPC.&lt;/li&gt; 
 &lt;li&gt;You might not be able to leverage existing technologies out of the box. For example, it might require additional effort to ensure &lt;a href="https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/"&gt;RPC calls are properly cached&lt;/a&gt; on caching servers such as &lt;a href="http://www.squid-cache.org/"&gt;Squid&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Representational state transfer (REST)&lt;/h3&gt; 
&lt;p&gt;REST is an architectural style enforcing a client/server model where the client acts on a set of resources managed by the server. The server provides a representation of resources and actions that can either manipulate or get a new representation of resources. All communication must be stateless and cacheable.&lt;/p&gt; 
&lt;p&gt;There are four qualities of a RESTful interface:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Identify resources (URI in HTTP)&lt;/strong&gt; - use the same URI regardless of any operation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change with representations (Verbs in HTTP)&lt;/strong&gt; - use verbs, headers, and body.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-descriptive error message (status response in HTTP)&lt;/strong&gt; - Use status codes, don't reinvent the wheel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="http://restcookbook.com/Basics/hateoas/"&gt;HATEOAS&lt;/a&gt; (HTML interface for HTTP)&lt;/strong&gt; - your web service should be fully accessible in a browser.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Sample REST calls:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;GET /someresources/anId

PUT /someresources/anId
{"anotherdata": "another value"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;REST is focused on exposing data. It minimizes the coupling between client/server and is often used for public HTTP APIs. REST uses a more generic and uniform method of exposing resources through URIs, &lt;a href="https://github.com/for-GET/know-your-http-well/raw/master/headers.md"&gt;representation through headers&lt;/a&gt;, and actions through verbs such as GET, POST, PUT, DELETE, and PATCH. Being stateless, REST is great for horizontal scaling and partitioning.&lt;/p&gt; 
&lt;h4&gt;Disadvantage(s): REST&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;With REST being focused on exposing data, it might not be a good fit if resources are not naturally organized or accessed in a simple hierarchy. For example, returning all updated records from the past hour matching a particular set of events is not easily expressed as a path. With REST, it is likely to be implemented with a combination of URI path, query parameters, and possibly the request body.&lt;/li&gt; 
 &lt;li&gt;REST typically relies on a few verbs (GET, POST, PUT, DELETE, and PATCH) which sometimes doesn't fit your use case. For example, moving expired documents to the archive folder might not cleanly fit within these verbs.&lt;/li&gt; 
 &lt;li&gt;Fetching complicated resources with nested hierarchies requires multiple round trips between the client and server to render single views, e.g. fetching content of a blog entry and the comments on that entry. For mobile applications operating in variable network conditions, these multiple roundtrips are highly undesirable.&lt;/li&gt; 
 &lt;li&gt;Over time, more fields might be added to an API response and older clients will receive all new data fields, even those that they do not need, as a result, it bloats the payload size and leads to larger latencies.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;RPC and REST calls comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Operation&lt;/th&gt; 
   &lt;th&gt;RPC&lt;/th&gt; 
   &lt;th&gt;REST&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /signup&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Resign&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /resign&lt;br&gt;{&lt;br&gt;"personid": "1234"&lt;br&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a person&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readPerson?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Read a person’s items list&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /readUsersItemsList?personid=1234&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;GET&lt;/strong&gt; /persons/1234/items&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add an item to a person’s items&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /addItemToUsersItemsList&lt;br&gt;{&lt;br&gt;"personid": "1234";&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /persons/1234/items&lt;br&gt;{&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Update an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /modifyItem&lt;br&gt;{&lt;br&gt;"itemid": "456";&lt;br&gt;"key": "value"&lt;br&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;PUT&lt;/strong&gt; /items/456&lt;br&gt;{&lt;br&gt;"key": "value"&lt;br&gt;}&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Delete an item&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;POST&lt;/strong&gt; /removeItem&lt;br&gt;{&lt;br&gt;"itemid": "456"&lt;br&gt;}&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DELETE&lt;/strong&gt; /items/456&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p align="center"&gt; &lt;i&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/"&gt;Source: Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading: REST and RPC&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://apihandyman.io/do-you-really-know-why-you-prefer-rest-over-rpc/"&gt;Do you really know why you prefer REST over RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://programmers.stackexchange.com/a/181186"&gt;When are RPC-ish approaches more appropriate than REST?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://stackoverflow.com/questions/15056878/rest-vs-json-rpc"&gt;REST vs JSON-RPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.archive.org/web/20170608193645/http://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/"&gt;Debunking the myths of RPC and REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/What-are-the-drawbacks-of-using-RESTful-APIs"&gt;What are the drawbacks of using REST&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Crack the system design interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://code.facebook.com/posts/1468950976659943/"&gt;Thrift&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://arstechnica.com/civis/viewtopic.php?t=1190508"&gt;Why REST for internal use and not RPC&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;This section could use some updates. Consider &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;contributing&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Security is a broad topic. Unless you have considerable experience, a security background, or are applying for a position that requires knowledge of security, you probably won't need to know more than the basics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Encrypt in transit and at rest.&lt;/li&gt; 
 &lt;li&gt;Sanitize all user inputs or any input parameters exposed to user to prevent &lt;a href="https://en.wikipedia.org/wiki/Cross-site_scripting"&gt;XSS&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/SQL_injection"&gt;SQL injection&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Use parameterized queries to prevent SQL injection.&lt;/li&gt; 
 &lt;li&gt;Use the principle of &lt;a href="https://en.wikipedia.org/wiki/Principle_of_least_privilege"&gt;least privilege&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Source(s) and further reading&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shieldfy/API-Security-Checklist"&gt;API security checklist&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FallibleInc/security-guide-for-developers"&gt;Security guide for developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.owasp.org/index.php/OWASP_Top_Ten_Cheat_Sheet"&gt;OWASP top ten&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Appendix&lt;/h2&gt; 
&lt;p&gt;You'll sometimes be asked to do 'back-of-the-envelope' estimates. For example, you might need to determine how long it will take to generate 100 image thumbnails from disk or how much memory a data structure will take. The &lt;strong&gt;Powers of two table&lt;/strong&gt; and &lt;strong&gt;Latency numbers every programmer should know&lt;/strong&gt; are handy references.&lt;/p&gt; 
&lt;h3&gt;Powers of two table&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Power           Exact Value         Approx Value        Bytes
---------------------------------------------------------------
7                             128
8                             256
10                           1024   1 thousand           1 KB
16                         65,536                       64 KB
20                      1,048,576   1 million            1 MB
30                  1,073,741,824   1 billion            1 GB
32                  4,294,967,296                        4 GB
40              1,099,511,627,776   1 trillion           1 TB
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Power_of_two"&gt;Powers of two&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Latency numbers every programmer should know&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;Latency Comparison Numbers
--------------------------
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns                      14x L1 cache
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache
Compress 1K bytes with Zippy            10,000   ns       10 us
Send 1 KB bytes over 1 Gbps network     10,000   ns       10 us
Read 4 KB randomly from SSD*           150,000   ns      150 us          ~1GB/sec SSD
Read 1 MB sequentially from memory     250,000   ns      250 us
Round trip within same datacenter      500,000   ns      500 us
Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory
HDD seek                            10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip
Read 1 MB sequentially from 1 Gbps  10,000,000   ns   10,000 us   10 ms  40x memory, 10X SSD
Read 1 MB sequentially from HDD     30,000,000   ns   30,000 us   30 ms 120x memory, 30X SSD
Send packet CA-&amp;gt;Netherlands-&amp;gt;CA    150,000,000   ns  150,000 us  150 ms

Notes
-----
1 ns = 10^-9 seconds
1 us = 10^-6 seconds = 1,000 ns
1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Handy metrics based on numbers above:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read sequentially from HDD at 30 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from 1 Gbps Ethernet at 100 MB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from SSD at 1 GB/s&lt;/li&gt; 
 &lt;li&gt;Read sequentially from main memory at 4 GB/s&lt;/li&gt; 
 &lt;li&gt;6-7 world-wide round trips per second&lt;/li&gt; 
 &lt;li&gt;2,000 round trips per second within a data center&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Latency numbers visualized&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://camo.githubusercontent.com/77f72259e1eb58596b564d1ad823af1853bc60a3/687474703a2f2f692e696d6775722e636f6d2f6b307431652e706e67" alt=""&gt;&lt;/p&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/jboner/2841832"&gt;Latency numbers every programmer should know - 1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/hellerbarde/2843375"&gt;Latency numbers every programmer should know - 2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.cs.cornell.edu/projects/ladis2009/talks/dean-keynote-ladis2009.pdf"&gt;Designs, lessons, and advice from building large distributed systems&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf"&gt;Software Engineering Advice from Building Large-Scale Distributed Systems&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Additional system design interview questions&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Common system design interview questions, with links to resources on how to solve each.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Question&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a file sync service like Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc"&gt;youtube.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a search engine like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://queue.acm.org/detail.cfm?id=988407"&gt;queue.acm.org&lt;/a&gt;&lt;br&gt;&lt;a href="http://programmers.stackexchange.com/questions/38324/interview-question-how-would-you-implement-google-search"&gt;stackexchange.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.ardendertat.com/2012/01/11/implementing-search-engines/"&gt;ardendertat.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://infolab.stanford.edu/~backrub/google.html"&gt;stanford.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a scalable web crawler like Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.quora.com/How-can-I-build-a-web-crawler-from-scratch"&gt;quora.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design Google docs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://code.google.com/p/google-mobwrite/"&gt;code.google.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://neil.fraser.name/writing/sync/"&gt;neil.fraser.name&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a key-value store like Redis&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a cache system like Memcached&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a recommendation system like Amazon's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://web.archive.org/web/20170406065247/http://tech.hulu.com/blog/2011/09/19/recommendation-system.html"&gt;hulu.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://ijcai13.org/files/tutorial_slides/td3.pdf"&gt;ijcai13.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a tinyurl system like Bitly&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://n00tc0d3r.blogspot.com/"&gt;n00tc0d3r.blogspot.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a chat app like WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a picture sharing system like Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture"&gt;highscalability.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook news feed function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.quora.com/What-are-best-practices-for-building-something-like-a-News-Feed"&gt;quora.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.quora.com/Activity-Streams/What-are-the-scaling-issues-to-keep-in-mind-while-developing-a-social-network-feed"&gt;quora.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://www.slideshare.net/danmckinley/etsy-activity-feeds-architecture"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook timeline function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.facebook.com/note.php?note_id=10150468255628920"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2012/1/23/facebook-timeline-brought-to-you-by-the-power-of-denormaliza.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design the Facebook chat function&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf"&gt;erlang-factory.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/note.php?note_id=14218138919&amp;amp;id=9445547199&amp;amp;index=0"&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a graph search function like Facebook's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-building-out-the-infrastructure-for-graph-search/10151347573598920"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-indexing-and-ranking-in-graph-search/10151361720763920"&gt;facebook.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.facebook.com/notes/facebook-engineering/under-the-hood-the-natural-language-interface-of-graph-search/10151432733048920"&gt;facebook.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a content delivery network like CloudFlare&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://figshare.com/articles/Globally_distributed_content_delivery/6605972"&gt;figshare.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a trending topic system like Twitter's&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/"&gt;michael-noll.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/"&gt;snikolov .wordpress.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a random ID generation system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://blog.twitter.com/2010/announcing-snowflake"&gt;blog.twitter.com&lt;/a&gt;&lt;br&gt;&lt;a href="https://github.com/twitter/snowflake/"&gt;github.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Return the top k requests during a time interval&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.cs.ucsb.edu/sites/default/files/documents/2005-23.pdf"&gt;cs.ucsb.edu&lt;/a&gt;&lt;br&gt;&lt;a href="http://davis.wpi.edu/xmdv/docs/EDBT11-diyang.pdf"&gt;wpi.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a system that serves data from multiple data centers&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/24/how-google-serves-data-from-multiple-datacenters.html"&gt;highscalability.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an online multiplayer card game&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://web.archive.org/web/20180929181117/http://www.indieflashblog.com/how-to-create-an-asynchronous-multiplayer-game.html"&gt;indieflashblog.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://buildnewgames.com/real-time-multiplayer/"&gt;buildnewgames.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a garbage collection system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/"&gt;stuffwithstuff.com&lt;/a&gt;&lt;br&gt;&lt;a href="http://courses.cs.washington.edu/courses/csep521/07wi/prj/rick.pdf"&gt;washington.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design an API rate limiter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://stripe.com/blog/rate-limiters"&gt;https://stripe.com/blog/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Design a Stock Exchange (like NASDAQ or Binance)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/b1e4t2k2KJY"&gt;Jane Street&lt;/a&gt;&lt;br&gt;&lt;a href="https://around25.com/blog/building-a-trading-engine-for-a-crypto-exchange/"&gt;Golang Implementation&lt;/a&gt;&lt;br&gt;&lt;a href="http://bhomnick.net/building-a-simple-limit-order-in-go/"&gt;Go Implementation&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a system design question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Real world architectures&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Articles on how real world systems are designed.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/images/TcUo2fw.png"&gt; &lt;br&gt; &lt;i&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability"&gt;Source: Twitter timelines at scale&lt;/a&gt;&lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Don't focus on nitty gritty details for the following articles, instead:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Identify shared principles, common technologies, and patterns within these articles&lt;/li&gt; 
 &lt;li&gt;Study what problems are solved by each component, where it works, where it doesn't&lt;/li&gt; 
 &lt;li&gt;Review the lessons learned&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MapReduce&lt;/strong&gt; - Distributed data processing from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/mapreduce-osdi04.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spark&lt;/strong&gt; - Distributed data processing from Databricks&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/AGrishchenko/apache-spark-architecture"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data processing&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Storm&lt;/strong&gt; - Distributed data processing from Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/previa/storm-16094009"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Bigtable&lt;/strong&gt; - Distributed column-oriented database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/chang06bigtable.pdf"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;HBase&lt;/strong&gt; - Open source implementation of Bigtable&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/alexbaranau/intro-to-hbase"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Cassandra&lt;/strong&gt; - Distributed column-oriented database from Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/planetcassandra/cassandra-introduction-features-30103666"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;DynamoDB&lt;/strong&gt; - Document-oriented database from Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf"&gt;harvard.edu&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;MongoDB&lt;/strong&gt; - Document-oriented database&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/mdirolf/introduction-to-mongodb"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Spanner&lt;/strong&gt; - Globally-distributed database from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://research.google.com/archive/spanner-osdi2012.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Memcached&lt;/strong&gt; - Distributed memory caching system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/oemebamo/introduction-to-memcached"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data store&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Redis&lt;/strong&gt; - Distributed memory caching system with persistence and value types&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/dvirsky/introduction-to-redis"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Google File System (GFS)&lt;/strong&gt; - Distributed file system&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/zh-CN/us/archive/gfs-sosp2003.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File system&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Hadoop File System (HDFS)&lt;/strong&gt; - Open source implementation of GFS&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html"&gt;apache.org&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Chubby&lt;/strong&gt; - Lock service for loosely-coupled distributed systems from Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/chubby-osdi06.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Dapper&lt;/strong&gt; - Distributed systems tracing infrastructure&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf"&gt;research.google.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Kafka&lt;/strong&gt; - Pub/sub message queue from LinkedIn&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/mumrah/kafka-talk-tri-hug"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Misc&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt; - Centralized infrastructure and services enabling synchronization&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://www.slideshare.net/sauravhaloi/introduction-to-apache-zookeeper"&gt;slideshare.net&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Add an architecture&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company architectures&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Company&lt;/th&gt; 
   &lt;th&gt;Reference(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Amazon&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/amazon-architecture"&gt;Amazon architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cinchcast&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/7/16/cinchcast-architecture-producing-1500-hours-of-audio-every-d.html"&gt;Producing 1,500 hours of audio every day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DataSift&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/11/29/datasift-architecture-realtime-datamining-at-120000-tweets-p.html"&gt;Realtime datamining At 120,000 tweets per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Dropbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=PE4gwstWhmc"&gt;How we've scaled Dropbox&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ESPN&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html"&gt;Operating At 100,000 duh nuh nuhs per second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/google-architecture"&gt;Google architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Instagram&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html"&gt;14 million users, terabytes of photos&lt;/a&gt;&lt;br&gt;&lt;a href="http://instagram-engineering.tumblr.com/post/13649370142/what-powers-instagram-hundreds-of-instances"&gt;What powers Instagram&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Justin.tv&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/3/16/justintvs-live-video-broadcasting-architecture.html"&gt;Justin.Tv's live video broadcasting architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Facebook&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/key-value/fb-memcached-nsdi-2013.pdf"&gt;Scaling memcached at Facebook&lt;/a&gt;&lt;br&gt;&lt;a href="https://cs.uwaterloo.ca/~brecht/courses/854-Emerging-2014/readings/data-store/tao-facebook-distributed-datastore-atc-2013.pdf"&gt;TAO: Facebook’s distributed data store for the social graph&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook’s photo storage&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/6/27/how-facebook-live-streams-to-800000-simultaneous-viewers.html"&gt;How Facebook Live Streams To 800,000 Simultaneous Viewers&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Flickr&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/flickr-architecture"&gt;Flickr architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mailbox&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/6/18/scaling-mailbox-from-0-to-one-million-users-in-6-weeks-and-1.html"&gt;From 0 to one million users in 6 weeks&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Netflix&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/11/9/a-360-degree-view-of-the-entire-netflix-stack.html"&gt;A 360 Degree View Of The Entire Netflix Stack&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2017/12/11/netflix-what-happens-when-you-press-play.html"&gt;Netflix: What Happens When You Press Play?&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Pinterest&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html"&gt;From 0 To 10s of billions of page views a month&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html"&gt;18 million visitors, 10x growth, 12 employees&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Playfish&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2010/9/21/playfishs-social-gaming-architecture-50-million-monthly-user.html"&gt;50 million monthly users and growing&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;PlentyOfFish&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/plentyoffish-architecture"&gt;PlentyOfFish architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Salesforce&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html"&gt;How they handle 1.3 billion transactions a day&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Stack Overflow&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2009/8/5/stack-overflow-architecture.html"&gt;Stack Overflow architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TripAdvisor&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2011/6/27/tripadvisor-architecture-40m-visitors-200m-dynamic-page-view.html"&gt;40M visitors, 200M dynamic page views, 30TB data&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tumblr&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html"&gt;15 billion page views a month&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Twitter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster"&gt;Making Twitter 10000 percent faster&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2011/12/19/how-twitter-stores-250-million-tweets-a-day-using-mysql.html"&gt;Storing 250 million tweets a day using MySQL&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2013/7/8/the-architecture-twitter-uses-to-deal-with-150m-active-users.html"&gt;150M active users, 300K QPS, a 22 MB/S firehose&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.infoq.com/presentations/Twitter-Timeline-Scalability"&gt;Timelines at scale&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.youtube.com/watch?v=5cKTP36HVgI"&gt;Big and small data at Twitter&lt;/a&gt;&lt;br&gt;&lt;a href="https://www.youtube.com/watch?v=z8LU0Cj6BOU"&gt;Operations at Twitter: scaling beyond 100 million users&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/4/20/how-twitter-handles-3000-images-per-second.html"&gt;How Twitter Handles 3,000 Images Per Second&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Uber&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2015/9/14/how-uber-scales-their-real-time-market-platform.html"&gt;How Uber scales their real-time market platform&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/blog/2016/10/12/lessons-learned-from-scaling-uber-to-2000-engineers-1000-ser.html"&gt;Lessons Learned From Scaling Uber To 2000 Engineers, 1000 Services, And 8000 Git Repositories&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;WhatsApp&lt;/td&gt; 
   &lt;td&gt;&lt;a href="http://highscalability.com/blog/2014/2/26/the-whatsapp-architecture-facebook-bought-for-19-billion.html"&gt;The WhatsApp architecture Facebook bought for $19 billion&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;YouTube&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=w5WVu624fY8"&gt;YouTube scalability&lt;/a&gt;&lt;br&gt;&lt;a href="http://highscalability.com/youtube-architecture"&gt;YouTube architecture&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Company engineering blogs&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Architectures for companies you are interviewing with.&lt;/p&gt; 
 &lt;p&gt;Questions you encounter might be from the same domain.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://nerds.airbnb.com/"&gt;Airbnb Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.atlassian.com/blog/"&gt;Atlassian Developers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aws.amazon.com/blogs/aws/"&gt;AWS Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://word.bitly.com/"&gt;Bitly Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.box.com/blog/category/engineering"&gt;Box Blogs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://blog.cloudera.com/"&gt;Cloudera Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tech.dropbox.com/"&gt;Dropbox Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.quora.com/q/quoraengineering"&gt;Engineering at Quora&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.ebaytechblog.com/"&gt;Ebay Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.evernote.com/tech/"&gt;Evernote Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://codeascraft.com/"&gt;Etsy Code as Craft&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.facebook.com/Engineering"&gt;Facebook Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://code.flickr.net/"&gt;Flickr Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineering.foursquare.com/"&gt;Foursquare Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.blog/category/engineering"&gt;GitHub Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://googleresearch.blogspot.com/"&gt;Google Research Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.groupon.com/"&gt;Groupon Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.heroku.com/"&gt;Heroku Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://product.hubspot.com/blog/topic/engineering"&gt;Hubspot Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/"&gt;High Scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://instagram-engineering.tumblr.com/"&gt;Instagram Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://software.intel.com/en-us/blogs/"&gt;Intel Software Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blogs.janestreet.com/category/ocaml/"&gt;Jane Street Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineering.linkedin.com/blog"&gt;LinkedIn Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://engineering.microsoft.com/"&gt;Microsoft Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blogs.msdn.microsoft.com/pythonengineering/"&gt;Microsoft Python Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://techblog.netflix.com/"&gt;Netflix Tech Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/paypal-engineering"&gt;Paypal Developer Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@Pinterest_Engineering"&gt;Pinterest Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.redditblog.com/"&gt;Reddit Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.salesforce.com/blogs/engineering/"&gt;Salesforce Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://slack.engineering/"&gt;Slack Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://labs.spotify.com/"&gt;Spotify Labs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://stripe.com/blog/engineering"&gt;Stripe Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.twilio.com/engineering"&gt;Twilio Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.twitter.com/engineering/"&gt;Twitter Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://eng.uber.com/"&gt;Uber Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://yahooeng.tumblr.com/"&gt;Yahoo Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://engineeringblog.yelp.com/"&gt;Yelp Engineering Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.zynga.com/blogs/engineering"&gt;Zynga Engineering Blog&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Source(s) and further reading&lt;/h4&gt; 
&lt;p&gt;Looking to add a blog? To avoid duplicating work, consider adding your company blog to the following repo:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kilimchoi/engineering-blogs"&gt;kilimchoi/engineering-blogs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Under development&lt;/h2&gt; 
&lt;p&gt;Interested in adding a section or helping complete one in-progress? &lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Distributed computing with MapReduce&lt;/li&gt; 
 &lt;li&gt;Consistent hashing&lt;/li&gt; 
 &lt;li&gt;Scatter gather&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/donnemartin/system-design-primer/master/#contributing"&gt;Contribute&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Credits and sources are provided throughout this repo.&lt;/p&gt; 
&lt;p&gt;Special thanks to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://www.hiredintech.com/system-design/the-system-design-process/"&gt;Hired in tech&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.amazon.com/dp/0984782850/"&gt;Cracking the coding interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://highscalability.com/"&gt;High scalability&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/checkcheckzz/system-design-interview"&gt;checkcheckzz/system-design-interview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/shashank88/system_design"&gt;shashank88/system_design&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mmcgrana/services-engineering"&gt;mmcgrana/services-engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gist.github.com/vasanthk/485d1c25737e8e72759f"&gt;System design cheat sheet&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://dancres.github.io/Pages/"&gt;A distributed systems reading list&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://www.puncsky.com/blog/2016-02-13-crack-the-system-design-interview"&gt;Cracking the system design interview&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact info&lt;/h2&gt; 
&lt;p&gt;Feel free to contact me to discuss any issues, questions, or comments.&lt;/p&gt; 
&lt;p&gt;My contact info can be found on my &lt;a href="https://github.com/donnemartin"&gt;GitHub page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;I am providing code and resources in this repository to you under an open source license. Because this is my personal repository, the license you receive to my code and resources is from me and not my employer (Facebook).&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Copyright 2017 Donne Martin

Creative Commons Attribution 4.0 International License (CC BY 4.0)

http://creativecommons.org/licenses/by/4.0/
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>