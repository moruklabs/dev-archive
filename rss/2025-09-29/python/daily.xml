<rss version="2.0">
  <channel>
    <title>GitHub Python Daily Trending</title>
    <description>Daily Trending of Python in GitHub</description>
    <pubDate>Sun, 28 Sep 2025 01:37:29 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>roboflow/supervision</title>
      <link>https://github.com/roboflow/supervision</link>
      <description>&lt;p&gt;We write your reusable computer vision tools. üíú&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://supervision.roboflow.com"&gt; &lt;img width="100%" src="https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/roboflow/notebooks"&gt;notebooks&lt;/a&gt; | &lt;a href="https://github.com/roboflow/inference"&gt;inference&lt;/a&gt; | &lt;a href="https://github.com/autodistill/autodistill"&gt;autodistill&lt;/a&gt; | &lt;a href="https://github.com/roboflow/multimodal-maestro"&gt;maestro&lt;/a&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://badge.fury.io/py/supervision.svg?sanitize=true" alt="version" /&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/supervision"&gt;&lt;img src="https://img.shields.io/pypi/dm/supervision" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://snyk.io/advisor/python/supervision"&gt;&lt;img src="https://snyk.io/advisor/python/supervision/badge.svg?sanitize=true" alt="snyk" /&gt;&lt;/a&gt; &lt;a href="https://github.com/roboflow/supervision/raw/main/LICENSE.md"&gt;&lt;img src="https://img.shields.io/pypi/l/supervision" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/supervision" alt="python-version" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="colab" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/Roboflow/Annotators"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" alt="gradio" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/GbfgXGJ8Bk"&gt;&lt;img src="https://img.shields.io/discord/1159501506232451173?logo=discord&amp;amp;label=discord&amp;amp;labelColor=fff&amp;amp;color=5865f2&amp;amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk" alt="discord" /&gt;&lt;/a&gt; &lt;a href="https://squidfunk.github.io/mkdocs-material/"&gt;&lt;img src="https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;amp;logoColor=white" alt="built-with-material-for-mkdocs" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/124" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/124" alt="roboflow%2Fsupervision | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;üëã hello&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We write your reusable computer vision tools.&lt;/strong&gt; Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ü§ù&lt;/p&gt; 
&lt;h2&gt;üíª install&lt;/h2&gt; 
&lt;p&gt;Pip install the supervision package in a &lt;a href="https://www.python.org/"&gt;&lt;strong&gt;Python&amp;gt;=3.9&lt;/strong&gt;&lt;/a&gt; environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install supervision
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about conda, mamba, and installing from source in our &lt;a href="https://roboflow.github.io/supervision/"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üî• quickstart&lt;/h2&gt; 
&lt;h3&gt;models&lt;/h3&gt; 
&lt;p&gt;Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created &lt;a href="https://supervision.roboflow.com/latest/detection/core/#detections"&gt;connectors&lt;/a&gt; for the most popular libraries like Ultralytics, Transformers, or MMDetection.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO("yolov8s.pt")
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;üëâ more model connectors&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;inference&lt;/p&gt; &lt;p&gt;Running with &lt;a href="https://github.com/roboflow/inference"&gt;Inference&lt;/a&gt; requires a &lt;a href="https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key"&gt;Roboflow API KEY&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from inference import get_model

image = cv2.imread(...)
model = get_model(model_id="yolov8s-640", api_key=&amp;lt;ROBOFLOW API KEY&amp;gt;)
result = model.infer(image)[0]
detections = sv.Detections.from_inference(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;annotators&lt;/h3&gt; 
&lt;p&gt;Supervision offers a wide range of highly customizable &lt;a href="https://supervision.roboflow.com/latest/detection/annotators/"&gt;annotators&lt;/a&gt;, allowing you to compose the perfect visualization for your use case.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce"&gt;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;datasets&lt;/h3&gt; 
&lt;p&gt;Supervision provides a set of &lt;a href="https://supervision.roboflow.com/latest/datasets/core/"&gt;utils&lt;/a&gt; that allow you to load, split, merge, and save datasets in one of the supported formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&amp;lt;WORKSPACE_ID&amp;gt;).project(&amp;lt;PROJECT_ID&amp;gt;)
dataset = project.version(&amp;lt;PROJECT_VERSION&amp;gt;).download("coco")

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f"{dataset.location}/train",
    annotations_path=f"{dataset.location}/train/_annotations.coco.json",
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
&lt;/code&gt;&lt;/pre&gt; 
&lt;details close&gt; 
 &lt;summary&gt;üëâ more dataset utils&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;load&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset = sv.DetectionDataset.from_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset = sv.DetectionDataset.from_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;split&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;train_dataset, test_dataset = dataset.split(split_ratio=0.7)
test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

len(train_dataset), len(test_dataset), len(valid_dataset)
# (700, 150, 150)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;merge&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;ds_1 = sv.DetectionDataset(...)
len(ds_1)
# 100
ds_1.classes
# ['dog', 'person']

ds_2 = sv.DetectionDataset(...)
len(ds_2)
# 200
ds_2.classes
# ['cat']

ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
len(ds_merged)
# 300
ds_merged.classes
# ['cat', 'dog', 'person']
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;save&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset.as_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset.as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset.as_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;convert&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
).as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üé¨ tutorials&lt;/h2&gt; 
&lt;p&gt;Want to learn how to use Supervision? Explore our &lt;a href="https://supervision.roboflow.com/develop/how_to/detect_and_annotate/"&gt;how-to guides&lt;/a&gt;, &lt;a href="https://github.com/roboflow/supervision/tree/develop/examples"&gt;end-to-end examples&lt;/a&gt;, &lt;a href="https://roboflow.github.io/cheatsheet-supervision/"&gt;cheatsheet&lt;/a&gt;, and &lt;a href="https://supervision.roboflow.com/develop/cookbooks/"&gt;cookbooks&lt;/a&gt;!&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1" alt="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing" width="300px" align="left" /&gt;&lt;/a&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br /&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.
&lt;p&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91" alt="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source" width="300px" align="left" /&gt;&lt;/a&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;strong&gt;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br /&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;üíú built with supervision&lt;/h2&gt; 
&lt;p&gt;Did you build something cool using supervision? &lt;a href="https://github.com/roboflow/supervision/discussions/categories/built-with-supervision"&gt;Let us know!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4"&gt;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900"&gt;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f"&gt;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìö documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://roboflow.github.io/supervision"&gt;documentation&lt;/a&gt; page to learn how supervision can help you build computer vision applications faster and more reliably.&lt;/p&gt; 
&lt;h2&gt;üèÜ contribution&lt;/h2&gt; 
&lt;p&gt;We love your input! Please see our &lt;a href="https://github.com/roboflow/supervision/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started. Thank you üôè to all our contributors!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/roboflow/supervision/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=roboflow/supervision" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://youtube.com/roboflow"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634652" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949746649" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://www.linkedin.com/company/roboflow-ai/"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633691" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://docs.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634511" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://discuss.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633584" width="3%" /&gt; &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; &lt;/a&gt;
  &lt;a href="https://blog.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633605" width="3%" /&gt; &lt;/a&gt;  
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>dataease/SQLBot</title>
      <link>https://github.com/dataease/SQLBot</link>
      <description>&lt;p&gt;üî• Âü∫‰∫éÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªü„ÄÇText-to-SQL Generation via LLMs using RAG.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://resource-fit2cloud-com.oss-cn-hangzhou.aliyuncs.com/sqlbot/sqlbot.png" alt="SQLBot" width="300" /&gt;&lt;/p&gt; 
&lt;h3 align="center"&gt;Âü∫‰∫éÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªü&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/dataease/SQLBot/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dataease/SQLBot" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dataease/SQLBot"&gt;&lt;img src="https://img.shields.io/github/stars/dataease/SQLBot?color=%231890FF&amp;amp;style=flat-square" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dataease/SQLbot"&gt;&lt;img src="https://img.shields.io/docker/pulls/dataease/sqlbot?label=downloads" alt="Download" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;SQLBot ÊòØ‰∏ÄÊ¨æÂü∫‰∫éÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÊô∫ËÉΩÈóÆÊï∞Á≥ªÁªü„ÄÇSQLBot ÁöÑ‰ºòÂäøÂåÖÊã¨Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ÂºÄÁÆ±Âç≥Áî®&lt;/strong&gt;: Âè™ÈúÄÈÖçÁΩÆÂ§ßÊ®°ÂûãÂíåÊï∞ÊçÆÊ∫êÂç≥ÂèØÂºÄÂêØÈóÆÊï∞‰πãÊóÖÔºåÈÄöËøáÂ§ßÊ®°ÂûãÂíå RAG ÁöÑÁªìÂêàÊù•ÂÆûÁé∞È´òË¥®ÈáèÁöÑ text2sqlÔºõ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Êòì‰∫éÈõÜÊàê&lt;/strong&gt;: ÊîØÊåÅÂø´ÈÄüÂµåÂÖ•Âà∞Á¨¨‰∏âÊñπ‰∏öÂä°Á≥ªÁªüÔºå‰πüÊîØÊåÅË¢´ n8n„ÄÅMaxKB„ÄÅDify„ÄÅCoze Á≠â AI Â∫îÁî®ÂºÄÂèëÂπ≥Âè∞ÈõÜÊàêË∞ÉÁî®ÔºåËÆ©ÂêÑÁ±ªÂ∫îÁî®Âø´ÈÄüÊã•ÊúâÊô∫ËÉΩÈóÆÊï∞ËÉΩÂäõÔºõ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂÆâÂÖ®ÂèØÊéß&lt;/strong&gt;: Êèê‰æõÂü∫‰∫éÂ∑•‰ΩúÁ©∫Èó¥ÁöÑËµÑÊ∫êÈöîÁ¶ªÊú∫Âà∂ÔºåËÉΩÂ§üÂÆûÁé∞ÁªÜÁ≤íÂ∫¶ÁöÑÊï∞ÊçÆÊùÉÈôêÊéßÂà∂„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Â∑•‰ΩúÂéüÁêÜ&lt;/h2&gt; 
&lt;img width="1105" height="577" alt="system-arch" src="https://github.com/user-attachments/assets/462603fc-980b-4b8b-a6d4-a821c070a048" /&gt; 
&lt;h2&gt;Âø´ÈÄüÂºÄÂßã&lt;/h2&gt; 
&lt;h3&gt;ÂÆâË£ÖÈÉ®ÁΩ≤&lt;/h3&gt; 
&lt;p&gt;ÂáÜÂ§á‰∏ÄÂè∞ Linux ÊúçÂä°Âô®ÔºåÂÆâË£ÖÂ•Ω &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt;ÔºåÊâßË°å‰ª•‰∏ã‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨Ôºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name sqlbot \
  --restart unless-stopped \
  -p 8000:8000 \
  -p 8001:8001 \
  -v ./data/sqlbot/excel:/opt/sqlbot/data/excel \
  -v ./data/sqlbot/file:/opt/sqlbot/data/file \
  -v ./data/sqlbot/images:/opt/sqlbot/images \
  -v ./data/sqlbot/logs:/opt/sqlbot/app/logs \
  -v ./data/postgresql:/var/lib/postgresql/data \
  --privileged=true \
  dataease/sqlbot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‰Ω†‰πüÂèØ‰ª•ÈÄöËøá &lt;a href="https://apps.fit2cloud.com/1panel"&gt;1Panel Â∫îÁî®ÂïÜÂ∫ó&lt;/a&gt; Âø´ÈÄüÈÉ®ÁΩ≤ SQLBot„ÄÇ&lt;/p&gt; 
&lt;p&gt;Â¶ÇÊûúÊòØÂÜÖÁΩëÁéØÂ¢ÉÔºå‰Ω†ÂèØ‰ª•ÈÄöËøá &lt;a href="https://community.fit2cloud.com/#/products/sqlbot/downloads"&gt;Á¶ªÁ∫øÂÆâË£ÖÂåÖÊñπÂºè&lt;/a&gt; ÈÉ®ÁΩ≤ SQLBot„ÄÇ&lt;/p&gt; 
&lt;h3&gt;ËÆøÈóÆÊñπÂºè&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âú®ÊµèËßàÂô®‰∏≠ÊâìÂºÄ: http://&amp;lt;‰Ω†ÁöÑÊúçÂä°Âô®IP&amp;gt;:8000/&lt;/li&gt; 
 &lt;li&gt;Áî®Êà∑Âêç: admin&lt;/li&gt; 
 &lt;li&gt;ÂØÜÁ†Å: SQLBot@123456&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ËÅîÁ≥ªÊàë‰ª¨&lt;/h3&gt; 
&lt;p&gt;Â¶Ç‰Ω†ÊúâÊõ¥Â§öÈóÆÈ¢òÔºåÂèØ‰ª•Âä†ÂÖ•Êàë‰ª¨ÁöÑÊäÄÊúØ‰∫§ÊµÅÁæ§‰∏éÊàë‰ª¨‰∫§ÊµÅ„ÄÇ&lt;/p&gt; 
&lt;img width="180" height="180" alt="contact_me_qr" src="https://github.com/user-attachments/assets/2594ff29-5426-4457-b051-279855610030" /&gt; 
&lt;h2&gt;UI Â±ïÁ§∫&lt;/h2&gt;  
&lt;img alt="q&amp;amp;a" src="https://github.com/user-attachments/assets/55526514-52f3-4cfe-98ec-08a986259280" /&gt;  
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#dataease/sqlbot&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=dataease/sqlbot&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;È£ûËá¥‰∫ëÊóó‰∏ãÁöÑÂÖ∂‰ªñÊòéÊòüÈ°πÁõÆ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dataease/dataease/"&gt;DataEase&lt;/a&gt; - ‰∫∫‰∫∫ÂèØÁî®ÁöÑÂºÄÊ∫ê BI Â∑•ÂÖ∑&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/1panel/"&gt;1Panel&lt;/a&gt; - Áé∞‰ª£Âåñ„ÄÅÂºÄÊ∫êÁöÑ Linux ÊúçÂä°Âô®ËøêÁª¥ÁÆ°ÁêÜÈù¢Êùø&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; - Âº∫Â§ßÊòìÁî®ÁöÑ‰ºÅ‰∏öÁ∫ßÊô∫ËÉΩ‰ΩìÂπ≥Âè∞&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jumpserver/jumpserver/"&gt;JumpServer&lt;/a&gt; - ÂπøÂèóÊ¨¢ËøéÁöÑÂºÄÊ∫êÂ†°ÂûíÊú∫&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/CordysCRM"&gt;Cordys CRM&lt;/a&gt; - Êñ∞‰∏Ä‰ª£ÁöÑÂºÄÊ∫ê AI CRM Á≥ªÁªü&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/halo-dev/halo/"&gt;Halo&lt;/a&gt; - Âº∫Â§ßÊòìÁî®ÁöÑÂºÄÊ∫êÂª∫Á´ôÂ∑•ÂÖ∑&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metersphere/metersphere/"&gt;MeterSphere&lt;/a&gt; - Êñ∞‰∏Ä‰ª£ÁöÑÂºÄÊ∫êÊåÅÁª≠ÊµãËØïÂ∑•ÂÖ∑&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Êú¨‰ªìÂ∫ìÈÅµÂæ™ &lt;a href="https://raw.githubusercontent.com/dataease/SQLBot/main/LICENSE"&gt;FIT2CLOUD Open Source License&lt;/a&gt; ÂºÄÊ∫êÂçèËÆÆÔºåËØ•ËÆ∏ÂèØËØÅÊú¨Ë¥®‰∏äÊòØ GPLv3Ôºå‰ΩÜÊúâ‰∏Ä‰∫õÈ¢ùÂ§ñÁöÑÈôêÂà∂„ÄÇ&lt;/p&gt; 
&lt;p&gt;‰Ω†ÂèØ‰ª•Âü∫‰∫é SQLBot ÁöÑÊ∫ê‰ª£Á†ÅËøõË°å‰∫åÊ¨°ÂºÄÂèëÔºå‰ΩÜÊòØÈúÄË¶ÅÈÅµÂÆà‰ª•‰∏ãËßÑÂÆöÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‰∏çËÉΩÊõøÊç¢Âíå‰øÆÊîπ SQLBot ÁöÑ Logo ÂíåÁâàÊùÉ‰ø°ÊÅØÔºõ&lt;/li&gt; 
 &lt;li&gt;‰∫åÊ¨°ÂºÄÂèëÂêéÁöÑË°çÁîü‰ΩúÂìÅÂøÖÈ°ªÈÅµÂÆà GPL V3 ÁöÑÂºÄÊ∫ê‰πâÂä°„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Â¶ÇÈúÄÂïÜ‰∏öÊéàÊùÉÔºåËØ∑ËÅîÁ≥ª &lt;a href="mailto:support@fit2cloud.com"&gt;support@fit2cloud.com&lt;/a&gt; „ÄÇ&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hacksider/Deep-Live-Cam</title>
      <link>https://github.com/hacksider/Deep-Live-Cam</link>
      <description>&lt;p&gt;real time face swap and one-click video deepfake with only a single image&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Deep-Live-Cam&lt;/h1&gt; 
&lt;p align="center"&gt; Real-time face swap and video deepfake with a single click and only a single image. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/11395" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11395" alt="hacksider%2FDeep-Live-Cam | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/demo.gif" alt="Demo GIF" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This deepfake software is designed to be a productive tool for the AI-generated media industry. It can assist artists in animating custom characters, creating engaging content, and even using models for clothing design.&lt;/p&gt; 
&lt;p&gt;We are aware of the potential for unethical applications and are committed to preventative measures. A built-in check prevents the program from processing inappropriate media (nudity, graphic content, sensitive material like war footage, etc.). We will continue to develop this project responsibly, adhering to the law and ethics. We may shut down the project or add watermarks if legally required.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Ethical Use: Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Content Restrictions: The software includes built-in checks to prevent processing inappropriate media, such as nudity, graphic content, or sensitive material.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Legal Compliance: We adhere to all relevant laws and ethical guidelines. If legally required, we may shut down the project or add watermarks to the output.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;User Responsibility: We are not responsible for end-user actions. Users must ensure their use of the software aligns with ethical standards and legal requirements.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to these terms and commit to using it in a manner that respects the rights and dignity of others.&lt;/p&gt; 
&lt;p&gt;Users are expected to use this software responsibly and legally. If using a real person's face, obtain their consent and clearly label any output as a deepfake when sharing online. We are not responsible for end-user actions.&lt;/p&gt; 
&lt;h2&gt;Exclusive v2.2 Quick Start - Pre-built (Windows/Mac Silicon)&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/Download.png" width="285" height="77" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;h5&gt;This is the fastest build you can get if you have a discrete NVIDIA or AMD GPU or Mac Silicon, And you'll receive special priority support.&lt;/h5&gt; &lt;h6&gt;These Pre-builts are perfect for non-technical users or those who don't have time to, or can't manually install all the requirements. Just a heads-up: this is an open-source project, so you can also install it manually.&lt;/h6&gt; &lt;h2&gt;TLDR; Live Deepfake in just 3 Clicks&lt;/h2&gt; &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/af825228-852c-411b-b787-ffd9aac72fc6" alt="easysteps" /&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Select a face&lt;/li&gt; 
  &lt;li&gt;Select which camera to use&lt;/li&gt; 
  &lt;li&gt;Press live!&lt;/li&gt; 
 &lt;/ol&gt; &lt;h2&gt;Features &amp;amp; Uses - Everything is in real-time&lt;/h2&gt; &lt;h3&gt;Mouth Mask&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Retain your original mouth for accurate movement using Mouth Mask&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/ludwig.gif" alt="resizable-gif" /&gt; &lt;/p&gt; &lt;h3&gt;Face Mapping&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Use different faces on multiple subjects simultaneously&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/streamers.gif" alt="face_mapping_source" /&gt; &lt;/p&gt; &lt;h3&gt;Your Movie, Your Face&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Watch movies with any face in real-time&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/movie.gif" alt="movie" /&gt; &lt;/p&gt; &lt;h3&gt;Live Show&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Run Live shows and performances&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/live_show.gif" alt="show" /&gt; &lt;/p&gt; &lt;h3&gt;Memes&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Create Your Most Viral Meme Yet&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/hacksider/Deep-Live-Cam/main/media/meme.gif" alt="show" width="450" /&gt; &lt;br /&gt; &lt;sub&gt;Created using Many Faces feature in Deep-Live-Cam&lt;/sub&gt; &lt;/p&gt; &lt;h3&gt;Omegle&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Surprise people on Omegle&lt;/strong&gt;&lt;/p&gt; &lt;p align="center"&gt; 
  &lt;video src="https://github.com/user-attachments/assets/2e9b9b82-fa04-4b70-9f56-b1f68e7672d0" width="450" controls&gt;&lt;/video&gt; &lt;/p&gt; &lt;h2&gt;Installation (Manual)&lt;/h2&gt; &lt;p&gt;&lt;strong&gt;Please be aware that the installation requires technical skills and is not for beginners. Consider downloading the quickstart version.&lt;/strong&gt;&lt;/p&gt; &lt;/a&gt;
&lt;details&gt;
 &lt;a href="https://deeplivecam.net/index.php/quickstart"&gt; &lt;summary&gt;Click to see the process&lt;/summary&gt; &lt;h3&gt;Installation&lt;/h3&gt; &lt;p&gt;This is more likely to work on your computer but will be slower as it utilizes the CPU.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;1. Set up Your Platform&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Python (3.11 recommended)&lt;/li&gt; 
   &lt;li&gt;pip&lt;/li&gt; 
   &lt;li&gt;git&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=OlNWCpFdVMA"&gt;ffmpeg&lt;/a&gt; - &lt;code&gt;iex (irm ffmpeg.tc.ht)&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/"&gt;Visual Studio 2022 Runtimes (Windows)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;strong&gt;2. Clone the Repository&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/hacksider/Deep-Live-Cam.git
cd Deep-Live-Cam
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;3. Download the Models&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/GFPGANv1.4.pth"&gt;GFPGANv1.4&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/hacksider/deep-live-cam/resolve/main/inswapper_128_fp16.onnx"&gt;inswapper_128_fp16.onnx&lt;/a&gt;&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;Place these files in the "&lt;strong&gt;models&lt;/strong&gt;" folder.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4. Install Dependencies&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We highly recommend using a &lt;code&gt;venv&lt;/code&gt; to avoid issues.&lt;/p&gt; 
 &lt;p&gt;For Windows:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For Linux:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Ensure you use the installed Python 3.10
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;For macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) requires specific setup:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Install Python 3.11 (specific version is important)
brew install python@3.11

# Install tkinter package (required for the GUI)
brew install python-tk@3.10

# Create and activate virtual environment with Python 3.11
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;** In case something goes wrong and you need to reinstall the virtual environment **&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Deactivate the virtual environment
rm -rf venv

# Reinstall the virtual environment
python -m venv venv
source venv/bin/activate

# install the dependencies again
pip install -r requirements.txt

# gfpgan and basicsrs issue fix
pip install git+https://github.com/xinntao/BasicSR.git@master
pip uninstall gfpgan -y
pip install git+https://github.com/TencentARC/GFPGAN.git@master
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Run:&lt;/strong&gt; If you don't have a GPU, you can run Deep-Live-Cam using &lt;code&gt;python run.py&lt;/code&gt;. Note that initial execution will download models (~300MB).&lt;/p&gt; 
 &lt;h3&gt;GPU Acceleration&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;CUDA Execution Provider (Nvidia)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/cuda-12-8-0-download-archive"&gt;CUDA Toolkit 12.8.0&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Install &lt;a href="https://developer.nvidia.com/rdp/cudnn-archive"&gt;cuDNN v8.9.7 for CUDA 12.x&lt;/a&gt; (required for onnxruntime-gpu): 
   &lt;ul&gt; 
    &lt;li&gt;Download cuDNN v8.9.7 for CUDA 12.x&lt;/li&gt; 
    &lt;li&gt;Make sure the cuDNN bin directory is in your system PATH&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip uninstall onnxruntime onnxruntime-gpu
pip install onnxruntime-gpu==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider cuda
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Silicon)&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Apple Silicon (M1/M2/M3) specific installation:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Make sure you've completed the macOS setup above using Python 3.10.&lt;/li&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-silicon
pip install onnxruntime-silicon==1.13.1
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="3"&gt; 
  &lt;li&gt;Usage (important: specify Python 3.10):&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python3.10 run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Important Notes for macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;You &lt;strong&gt;must&lt;/strong&gt; use Python 3.10, not newer versions like 3.11 or 3.13&lt;/li&gt; 
  &lt;li&gt;Always run with &lt;code&gt;python3.10&lt;/code&gt; command not just &lt;code&gt;python&lt;/code&gt; if you have multiple Python versions installed&lt;/li&gt; 
  &lt;li&gt;If you get error about &lt;code&gt;_tkinter&lt;/code&gt; missing, reinstall the tkinter package: &lt;code&gt;brew reinstall python-tk@3.10&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;If you get model loading errors, check that your models are in the correct folder&lt;/li&gt; 
  &lt;li&gt;If you encounter conflicts with other Python versions, consider uninstalling them: &lt;pre&gt;&lt;code class="language-bash"&gt;# List all installed Python versions
brew list | grep python

# Uninstall conflicting versions if needed
brew uninstall --ignore-dependencies python@3.11 python@3.13

# Keep only Python 3.11
brew cleanup
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;CoreML Execution Provider (Apple Legacy)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-coreml
pip install onnxruntime-coreml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider coreml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;DirectML Execution Provider (Windows)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-directml
pip install onnxruntime-directml==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider directml
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;OpenVINO‚Ñ¢ Execution Provider (Intel)&lt;/strong&gt;&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Install dependencies:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip uninstall onnxruntime onnxruntime-openvino
pip install onnxruntime-openvino==1.21.0
&lt;/code&gt;&lt;/pre&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;Usage:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;python run.py --execution-provider openvino
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;1. Image/Video Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Choose a source face image and a target image/video.&lt;/li&gt; 
 &lt;li&gt;Click "Start".&lt;/li&gt; 
 &lt;li&gt;The output will be saved in a directory named after the target video.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;2. Webcam Mode&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Execute &lt;code&gt;python run.py&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Select a source face image.&lt;/li&gt; 
 &lt;li&gt;Click "Live".&lt;/li&gt; 
 &lt;li&gt;Wait for the preview to appear (10-30 seconds).&lt;/li&gt; 
 &lt;li&gt;Use a screen capture tool like OBS to stream.&lt;/li&gt; 
 &lt;li&gt;To change the face, select a new source image.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Command Line Arguments (Unmaintained)&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;options:
  -h, --help                                               show this help message and exit
  -s SOURCE_PATH, --source SOURCE_PATH                     select a source image
  -t TARGET_PATH, --target TARGET_PATH                     select a target image or video
  -o OUTPUT_PATH, --output OUTPUT_PATH                     select output file or directory
  --frame-processor FRAME_PROCESSOR [FRAME_PROCESSOR ...]  frame processors (choices: face_swapper, face_enhancer, ...)
  --keep-fps                                               keep original fps
  --keep-audio                                             keep original audio
  --keep-frames                                            keep temporary frames
  --many-faces                                             process every face
  --map-faces                                              map source target faces
  --mouth-mask                                             mask the mouth region
  --video-encoder {libx264,libx265,libvpx-vp9}             adjust output video encoder
  --video-quality [0-51]                                   adjust output video quality
  --live-mirror                                            the live camera display as you see it in the front-facing camera frame
  --live-resizable                                         the live camera frame is resizable
  --max-memory MAX_MEMORY                                  maximum amount of RAM in GB
  --execution-provider {cpu} [{cpu} ...]                   available execution provider (choices: cpu, ...)
  --execution-threads EXECUTION_THREADS                    number of execution threads
  -v, --version                                            show program's version number and exit
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Looking for a CLI mode? Using the -s/--source argument will make the run program in cli mode.&lt;/p&gt; 
&lt;h2&gt;Press&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We are always open to criticism and are ready to improve, that's why we didn't cherry-pick anything.&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://arstechnica.com/information-technology/2024/08/new-ai-tool-enables-real-time-face-swapping-on-webcams-raising-fraud-concerns/"&gt;&lt;em&gt;"Deep-Live-Cam goes viral, allowing anyone to become a digital doppelganger"&lt;/em&gt;&lt;/a&gt; - Ars Technica&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dataconomy.com/2024/08/15/what-is-deep-live-cam-github-deepfake/"&gt;&lt;em&gt;"Thanks Deep Live Cam, shapeshifters are among us now"&lt;/em&gt;&lt;/a&gt; - Dataconomy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.newsbytesapp.com/news/science/deep-live-cam-ai-impersonation-tool-goes-viral/story"&gt;&lt;em&gt;"This free AI tool lets you become anyone during video-calls"&lt;/em&gt;&lt;/a&gt; - NewsBytes&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.creativebloq.com/ai/ok-this-viral-ai-live-stream-software-is-truly-terrifying"&gt;&lt;em&gt;"OK, this viral AI live stream software is truly terrifying"&lt;/em&gt;&lt;/a&gt; - Creative Bloq&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://petapixel.com/2024/08/14/deep-live-cam-deepfake-ai-tool-lets-you-become-anyone-in-a-video-call-with-single-photo-mark-zuckerberg-jd-vance-elon-musk/"&gt;&lt;em&gt;"Deepfake AI Tool Lets You Become Anyone in a Video Call With Single Photo"&lt;/em&gt;&lt;/a&gt; - PetaPixel&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.techeblog.com/deep-live-cam-ai-transform-face/"&gt;&lt;em&gt;"Deep-Live-Cam Uses AI to Transform Your Face in Real-Time, Celebrities Included"&lt;/em&gt;&lt;/a&gt; - TechEBlog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://telegrafi.com/en/a-tool-that-makes-you-look-like-anyone-during-a-video-call-is-going-viral-on-the-Internet/"&gt;&lt;em&gt;"An AI tool that "makes you look like anyone" during a video call is going viral online"&lt;/em&gt;&lt;/a&gt; - Telegrafi&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://decrypt.co/244565/this-deepfake-tool-turning-images-into-livestreams-is-topping-the-github-charts"&gt;&lt;em&gt;"This Deepfake Tool Turning Images Into Livestreams is Topping the GitHub Charts"&lt;/em&gt;&lt;/a&gt; - Emerge&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.digitalmusicnews.com/2024/08/15/face-swapping-ai-real-time-mimic/"&gt;&lt;em&gt;"New Real-Time Face-Swapping AI Allows Anyone to Mimic Famous Faces"&lt;/em&gt;&lt;/a&gt; - Digital Music News&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.diyphotography.net/this-real-time-webcam-deepfake-tool-raises-alarms-about-the-future-of-identity-theft/"&gt;&lt;em&gt;"This real-time webcam deepfake tool raises alarms about the future of identity theft"&lt;/em&gt;&lt;/a&gt; - DIYPhotography&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?time_continue=1074&amp;amp;v=py4Tc-Y8BcY"&gt;&lt;em&gt;"That's Crazy, Oh God. That's Fucking Freaky Dude... That's So Wild Dude"&lt;/em&gt;&lt;/a&gt; - SomeOrdinaryGamers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/live/mFsCe7AIxq8?feature=shared&amp;amp;t=2686"&gt;&lt;em&gt;"Alright look look look, now look chat, we can do any face we want to look like chat"&lt;/em&gt;&lt;/a&gt; - IShowSpeed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wnCghLjqv3s&amp;amp;t=551s"&gt;&lt;em&gt;"They do a pretty good job matching poses, expression and even the lighting"&lt;/em&gt;&lt;/a&gt; - TechLinked (LTT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.golem.de/news/deepfakes-als-sean-connery-an-der-redaktionskonferenz-teilnahm-2408-188172.html"&gt;&lt;em&gt;"Als Sean Connery an der Redaktionskonferenz teilnahm"&lt;/em&gt;&lt;/a&gt; - Golem.de (German)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ffmpeg.org/"&gt;ffmpeg&lt;/a&gt;: for making video-related operations easy&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/deepinsight"&gt;deepinsight&lt;/a&gt;: for their &lt;a href="https://github.com/deepinsight/insightface"&gt;insightface&lt;/a&gt; project which provided a well-made library and models. Please be reminded that the &lt;a href="https://github.com/deepinsight/insightface?tab=readme-ov-file#license"&gt;use of the model is for non-commercial research purposes only&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/havok2-htwo"&gt;havok2-htwo&lt;/a&gt;: for sharing the code for webcam&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/GosuDRM"&gt;GosuDRM&lt;/a&gt;: for the open version of roop&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pereiraroland26"&gt;pereiraroland26&lt;/a&gt;: Multiple faces support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vic4key"&gt;vic4key&lt;/a&gt;: For supporting/contributing to this project&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/kier007"&gt;kier007&lt;/a&gt;: for improving the user experience&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/qitianai"&gt;qitianai&lt;/a&gt;: for multi-lingual support&lt;/li&gt; 
 &lt;li&gt;and &lt;a href="https://github.com/hacksider/Deep-Live-Cam/graphs/contributors"&gt;all developers&lt;/a&gt; behind libraries used in this project.&lt;/li&gt; 
 &lt;li&gt;Footnote: Please be informed that the base author of the code is &lt;a href="https://github.com/s0md3v/roop"&gt;s0md3v&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;All the wonderful users who helped make this project go viral by starring the repo ‚ù§Ô∏è&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/hacksider/Deep-Live-Cam/stargazers"&gt;&lt;img src="https://reporoster.com/stars/hacksider/Deep-Live-Cam" alt="Stargazers" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/fec8e29c45dfdb9c5916f3a7830e1249308d20e1.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Stars to the Moon üöÄ&lt;/h2&gt; 
&lt;a href="https://star-history.com/#hacksider/deep-live-cam&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=hacksider/deep-live-cam&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>Olow304/memvid</title>
      <link>https://github.com/Olow304/memvid</link>
      <description>&lt;p&gt;Video-based AI memory library. Store millions of text chunks in MP4 files with lightning-fast semantic search. No database needed.&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;What to expect in v2&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Early-access notice&lt;/strong&gt;&lt;br /&gt; Memvid v1 is still experimental. The file format and API may change until we lock in a stable release.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Memvid v2 ‚Äì what's next&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Living-Memory Engine&lt;/strong&gt; ‚Äì keep adding new data and let LLMs remember it across sessions.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Capsule Context&lt;/strong&gt; ‚Äì shareable &lt;code&gt;.mv2&lt;/code&gt; capsules, each with its own rules and expiry.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Time-Travel Debugging&lt;/strong&gt; ‚Äì rewind or branch any chat to review or test.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Smart Recall&lt;/strong&gt; ‚Äì local cache guesses what you‚Äôll need and loads it in under 5 ms.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Codec Intelligence&lt;/strong&gt; ‚Äì auto-tunes AV1 now and future codecs later, so files keep shrinking.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;CLI &amp;amp; Dashboard&lt;/strong&gt; ‚Äì simple tools for branching, analytics, and one-command cloud publish.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Sneak peek of Memvid v2 - a living memory engine that can be used to chat with your knowledge base. &lt;img src="https://raw.githubusercontent.com/Olow304/memvid/main/assets/mv2.png" alt="Memvid v2 Preview" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Memvid v1&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/memvid/"&gt;&lt;img src="https://img.shields.io/pypi/v/memvid" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://github.com/olow304/memvid"&gt;&lt;img src="https://img.shields.io/github/stars/olow304/memvid" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/badge/python-3.8+-blue.svg?sanitize=true" alt="Python 3.8+" /&gt;&lt;/a&gt; &lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" alt="Code style: black" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Memvid - Turn millions of text chunks into a single, searchable video file&lt;/h1&gt; 
&lt;p&gt;Memvid compresses an entire knowledge base into &lt;strong&gt;MP4&lt;/strong&gt; files while keeping millisecond-level semantic search. Think of it as &lt;em&gt;SQLite for AI memory&lt;/em&gt; portable, efficient, and self-contained. By encoding text as &lt;strong&gt;QR codes in video frames&lt;/strong&gt;, we deliver &lt;strong&gt;50-100√ó&lt;/strong&gt; smaller storage than vector databases with &lt;strong&gt;zero infrastructure&lt;/strong&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Why Video Compression Changes Everything üöÄ&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;What it enables&lt;/th&gt; 
   &lt;th&gt;How video codecs make it possible&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;50-100√ó smaller storage&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Modern video codecs compress repetitive visual patterns (QR codes) far better than raw embeddings&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Sub-100ms retrieval&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct frame seek via index ‚Üí QR decode ‚Üí your text. No server round-trips&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Zero infrastructure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Just Python and MP4 files-no DB clusters, no Docker, no ops&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;True portability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Copy or stream &lt;code&gt;memory.mp4&lt;/code&gt;-it works anywhere video plays&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Offline-first design&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;After encoding, everything runs without internet&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Under the Hood - Memvid v1 üîç&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Text ‚Üí QR ‚Üí Frame&lt;/strong&gt;&lt;br /&gt; Each text chunk becomes a QR code, packed into video frames. Modern codecs excel at compressing these repetitive patterns.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Smart indexing&lt;/strong&gt;&lt;br /&gt; Embeddings map queries ‚Üí frame numbers. One seek, one decode, millisecond results.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Codec leverage&lt;/strong&gt;&lt;br /&gt; 30 years of video R&amp;amp;D means your text gets compressed better than any custom algorithm could achieve.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Future-proof&lt;/strong&gt;&lt;br /&gt; Next-gen codecs (AV1, H.266) automatically make your memories smaller and faster-no code changes needed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install memvid
# For PDF support
pip install memvid PyPDF2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from memvid import MemvidEncoder, MemvidChat

# Create video memory from text
chunks = ["NASA founded 1958", "Apollo 11 landed 1969", "ISS launched 1998"]
encoder = MemvidEncoder()
encoder.add_chunks(chunks)
encoder.build_video("space.mp4", "space_index.json")

# Chat with your memory
chat = MemvidChat("space.mp4", "space_index.json")
response = chat.chat("When did humans land on the moon?")
print(response)  # References Apollo 11 in 1969
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Real-World Examples&lt;/h2&gt; 
&lt;h3&gt;Documentation Assistant&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from memvid import MemvidEncoder
import os

encoder = MemvidEncoder(chunk_size=512)

# Index all markdown files
for file in os.listdir("docs"):
    if file.endswith(".md"):
        with open(f"docs/{file}") as f:
            encoder.add_text(f.read(), metadata={"file": file})

encoder.build_video("docs.mp4", "docs_index.json")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;PDF Library Search&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Index multiple PDFs
encoder = MemvidEncoder()
encoder.add_pdf("deep_learning.pdf")
encoder.add_pdf("machine_learning.pdf") 
encoder.build_video("ml_library.mp4", "ml_index.json")

# Semantic search across all books
from memvid import MemvidRetriever
retriever = MemvidRetriever("ml_library.mp4", "ml_index.json")
results = retriever.search("backpropagation", top_k=5)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Interactive Web UI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from memvid import MemvidInteractive

# Launch at http://localhost:7860
interactive = MemvidInteractive("knowledge.mp4", "index.json")
interactive.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Advanced Features&lt;/h2&gt; 
&lt;h3&gt;Scale Optimization&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Maximum compression for huge datasets
encoder.build_video(
    "compressed.mp4",
    "index.json", 
    fps=60,              # More frames/second
    frame_size=256,      # Smaller QR codes
    video_codec='h265',  # Better compression
    crf=28              # Quality tradeoff
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Custom Embeddings&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-mpnet-base-v2')
encoder = MemvidEncoder(embedding_model=model)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Parallel Processing&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;encoder = MemvidEncoder(n_workers=8)
encoder.add_chunks_parallel(million_chunks)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;CLI Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process documents
python examples/file_chat.py --input-dir /docs --provider openai

# Advanced codecs
python examples/file_chat.py --files doc.pdf --codec h265

# Load existing
python examples/file_chat.py --load-existing output/memory
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Indexing&lt;/strong&gt;: ~10K chunks/second on modern CPUs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search&lt;/strong&gt;: &amp;lt;100ms for 1M chunks (includes decode)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt;: 100MB text ‚Üí 1-2MB video&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt;: Constant 500MB RAM regardless of size&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What's Coming in v2&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Delta encoding&lt;/strong&gt;: Time-travel through knowledge versions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Streaming ingest&lt;/strong&gt;: Add to videos in real-time&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud dashboard&lt;/strong&gt;: Web UI with API management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart codecs&lt;/strong&gt;: Auto-select AV1/HEVC per content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPU boost&lt;/strong&gt;: 100√ó faster bulk encoding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Get Involved&lt;/h2&gt; 
&lt;p&gt;Memvid is redefining AI memory. Join us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚≠ê Star on &lt;a href="https://github.com/olow304/memvid"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üêõ Report issues or request features&lt;/li&gt; 
 &lt;li&gt;üîß Submit PRs (we review quickly!)&lt;/li&gt; 
 &lt;li&gt;üí¨ Discuss video-based AI memory&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Tencent-Hunyuan/Hunyuan3D-2.1</title>
      <link>https://github.com/Tencent-Hunyuan/Hunyuan3D-2.1</link>
      <description>&lt;p&gt;From Images to High-Fidelity 3D Assets with Production-Ready PBR Material&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Tencent-Hunyuan/Hunyuan3D-2.1/main/assets/images/teaser.jpg" /&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://3d.hunyuan.tencent.com" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/Official%20Site-333399.svg?logo=homepage" height="22px" /&gt;&lt;/a&gt; 
 &lt;a href="https://huggingface.co/spaces/tencent/Hunyuan3D-2.1" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Demo-276cb4.svg?sanitize=true" height="22px" /&gt;&lt;/a&gt; 
 &lt;a href="https://huggingface.co/tencent/Hunyuan3D-2.1" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Models-d96902.svg?sanitize=true" height="22px" /&gt;&lt;/a&gt; 
 &lt;a href="https://3d-models.hunyuan.tencent.com/" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/Page-bb8a2e.svg?logo=github" height="22px" /&gt;&lt;/a&gt; 
 &lt;a href="https://discord.gg/dNBrdrGGMa" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/Discord-white.svg?logo=discord" height="22px" /&gt;&lt;/a&gt; 
 &lt;a href="https://arxiv.org/pdf/2506.15442" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/Report-b5212f.svg?logo=arxiv" height="22px" /&gt;&lt;/a&gt; 
 &lt;a href="https://x.com/TencentHunyuan" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/Hunyuan-black.svg?logo=x" height="22px" /&gt;&lt;/a&gt; 
 &lt;a href="https://raw.githubusercontent.com/Tencent-Hunyuan/Hunyuan3D-2.1/main/#community-resources" target="_blank"&gt;&lt;img src="https://img.shields.io/badge/Community-lavender.svg?logo=homeassistantcommunitystore" height="22px" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h2&gt;üî• News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jul 26, 2025: ü§ó We release the first open-source, simulation-capable, immersive 3D world generation model, &lt;a href="https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0"&gt;HunyuanWorld-1.0&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;Jun 19, 2025: üëã We present the &lt;a href="https://arxiv.org/pdf/2506.15442"&gt;technical report&lt;/a&gt; of Hunyuan3D-2.1, please check out the details and spark some discussion!&lt;/li&gt; 
 &lt;li&gt;Jun 13, 2025: ü§ó We release the first production-ready 3D asset generation model, Hunyuan3D-2.1!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Join our &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/Tencent-Hunyuan/Hunyuan3D-2.1/main/#"&gt;Wechat&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://discord.gg/dNBrdrGGMa"&gt;Discord&lt;/a&gt;&lt;/strong&gt; group to discuss and find help from us.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Wechat Group&lt;/th&gt; 
   &lt;th&gt;Xiaohongshu&lt;/th&gt; 
   &lt;th&gt;X&lt;/th&gt; 
   &lt;th&gt;Discord&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent-Hunyuan/Hunyuan3D-2.1/main/assets/qrcode/wechat.png" height="140" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent-Hunyuan/Hunyuan3D-2.1/main/assets/qrcode/xiaohongshu.png" height="140" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent-Hunyuan/Hunyuan3D-2.1/main/assets/qrcode/x.png" height="140" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/Tencent-Hunyuan/Hunyuan3D-2.1/main/assets/qrcode/discord.png" height="140" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ü§ó Community Contribution Leaderboard&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;By &lt;a href="https://github.com/visualbruno"&gt;@visualbruno&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;ComfyUI-Hunyuan3d-2-1: &lt;a href="https://github.com/visualbruno/ComfyUI-Hunyuan3d-2-1"&gt;https://github.com/visualbruno/ComfyUI-Hunyuan3d-2-1&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;By &lt;a href="https://github.com/VR-Jobs"&gt;@VR-Jobs&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hunyuan3d-2-1 Unity Support: &lt;a href="https://github.com/VR-Jobs/Hunyuan3D-2.1-Unity-XR-PC-Phone"&gt;https://github.com/VR-Jobs/Hunyuan3D-2.1-Unity-XR-PC-Phone&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚òØÔ∏è &lt;strong&gt;Hunyuan3D 2.1&lt;/strong&gt;&lt;/h2&gt; 
&lt;h3&gt;Architecture&lt;/h3&gt; 
&lt;p&gt;Tencent Hunyuan3D-2.1 is a scalable 3D asset creation system that advances state-of-the-art 3D generation through two pivotal innovations: Fully Open-Source Framework and Physically-Based Rendering (PBR) Texture Synthesis. For the first time, the system releases full model weights and training code, enabling community developers to directly fine-tune and extend the model for diverse downstream applications. This transparency accelerates academic research and industrial deployment. Moreover, replacing the prior RGB-based texture model, the upgraded PBR pipeline leverages physics-grounded material simulation to generate textures with photorealistic light interaction (e.g., metallic reflections, subsurface scattering).&lt;/p&gt; 
&lt;p align="left"&gt; &lt;img src="https://raw.githubusercontent.com/Tencent-Hunyuan/Hunyuan3D-2.1/main/assets/images/pipeline.png" /&gt; &lt;/p&gt; 
&lt;h3&gt;Performance&lt;/h3&gt; 
&lt;p&gt;We have evaluated Hunyuan3D 2.1 with other open-source as well as close-source 3d-generation methods. The numerical results indicate that Hunyuan3D 2.1 surpasses all baselines in the quality of generated textured 3D assets and the condition following ability.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;ULIP-T(‚¨Ü)&lt;/th&gt; 
   &lt;th&gt;ULIP-I(‚¨Ü)&lt;/th&gt; 
   &lt;th&gt;Uni3D-T(‚¨Ü)&lt;/th&gt; 
   &lt;th&gt;Uni3D-I(‚¨Ü)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Michelangelo&lt;/td&gt; 
   &lt;td&gt;0.0752&lt;/td&gt; 
   &lt;td&gt;0.1152&lt;/td&gt; 
   &lt;td&gt;0.2133&lt;/td&gt; 
   &lt;td&gt;0.2611&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Craftsman&lt;/td&gt; 
   &lt;td&gt;0.0745&lt;/td&gt; 
   &lt;td&gt;0.1296&lt;/td&gt; 
   &lt;td&gt;0.2375&lt;/td&gt; 
   &lt;td&gt;0.2987&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TripoSG&lt;/td&gt; 
   &lt;td&gt;0.0767&lt;/td&gt; 
   &lt;td&gt;0.1225&lt;/td&gt; 
   &lt;td&gt;0.2506&lt;/td&gt; 
   &lt;td&gt;0.3129&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Step1X-3D&lt;/td&gt; 
   &lt;td&gt;0.0735&lt;/td&gt; 
   &lt;td&gt;0.1183&lt;/td&gt; 
   &lt;td&gt;0.2554&lt;/td&gt; 
   &lt;td&gt;0.3195&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Trellis&lt;/td&gt; 
   &lt;td&gt;0.0769&lt;/td&gt; 
   &lt;td&gt;0.1267&lt;/td&gt; 
   &lt;td&gt;0.2496&lt;/td&gt; 
   &lt;td&gt;0.3116&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Direct3D-S2&lt;/td&gt; 
   &lt;td&gt;0.0706&lt;/td&gt; 
   &lt;td&gt;0.1134&lt;/td&gt; 
   &lt;td&gt;0.2346&lt;/td&gt; 
   &lt;td&gt;0.2930&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hunyuan3D-Shape-2.1&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.0774&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.1395&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.2556&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.3213&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;CLIP-FiD(‚¨á)&lt;/th&gt; 
   &lt;th&gt;CMMD(‚¨á)&lt;/th&gt; 
   &lt;th&gt;CLIP-I(‚¨Ü)&lt;/th&gt; 
   &lt;th&gt;LPIPS(‚¨á)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SyncMVD-IPA&lt;/td&gt; 
   &lt;td&gt;28.39&lt;/td&gt; 
   &lt;td&gt;2.397&lt;/td&gt; 
   &lt;td&gt;0.8823&lt;/td&gt; 
   &lt;td&gt;0.1423&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;TexGen&lt;/td&gt; 
   &lt;td&gt;28.24&lt;/td&gt; 
   &lt;td&gt;2.448&lt;/td&gt; 
   &lt;td&gt;0.8818&lt;/td&gt; 
   &lt;td&gt;0.1331&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hunyuan3D-2.0&lt;/td&gt; 
   &lt;td&gt;26.44&lt;/td&gt; 
   &lt;td&gt;2.318&lt;/td&gt; 
   &lt;td&gt;0.8893&lt;/td&gt; 
   &lt;td&gt;0.1261&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hunyuan3D-Paint-2.1&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;24.78&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;2.191&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.9207&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;0.1211&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üéÅ Models Zoo&lt;/h2&gt; 
&lt;p&gt;It takes 10 GB VRAM for shape generation, 21GB for texture generation and 29GB for shape and texture generation in total.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Date&lt;/th&gt; 
   &lt;th&gt;Size&lt;/th&gt; 
   &lt;th&gt;Huggingface&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hunyuan3D-Shape-v2-1&lt;/td&gt; 
   &lt;td&gt;Image to Shape Model&lt;/td&gt; 
   &lt;td&gt;2025-06-14&lt;/td&gt; 
   &lt;td&gt;3.3B&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/tencent/Hunyuan3D-2.1/tree/main/hunyuan3d-dit-v2-1"&gt;Download&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hunyuan3D-Paint-v2-1&lt;/td&gt; 
   &lt;td&gt;Texture Generation Model&lt;/td&gt; 
   &lt;td&gt;2025-06-14&lt;/td&gt; 
   &lt;td&gt;2B&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/tencent/Hunyuan3D-2.1/tree/main/hunyuan3d-paintpbr-v2-1"&gt;Download&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ü§ó Get Started with Hunyuan3D 2.1&lt;/h2&gt; 
&lt;p&gt;Hunyuan3D 2.1 supports Macos, Windows, Linux. You may follow the next steps to use Hunyuan3D 2.1 via:&lt;/p&gt; 
&lt;h3&gt;Install Requirements&lt;/h3&gt; 
&lt;p&gt;We test our model with Python 3.10 and PyTorch 2.5.1+cu124.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124
pip install -r requirements.txt

cd hy3dpaint/custom_rasterizer
pip install -e .
cd ../..
cd hy3dpaint/DifferentiableRenderer
bash compile_mesh_painter.sh
cd ../..

wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P hy3dpaint/ckpt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Code Usage&lt;/h3&gt; 
&lt;p&gt;We designed a diffusers-like API to use our shape generation model - Hunyuan3D-Shape and texture synthesis model - Hunyuan3D-Paint.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import sys
sys.path.insert(0, './hy3dshape')
sys.path.insert(0, './hy3dpaint')
from textureGenPipeline import Hunyuan3DPaintPipeline
from textureGenPipeline import Hunyuan3DPaintPipeline, Hunyuan3DPaintConfig
from hy3dshape.pipelines import Hunyuan3DDiTFlowMatchingPipeline

# let's generate a mesh first
shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained('tencent/Hunyuan3D-2.1')
mesh_untextured = shape_pipeline(image='assets/demo.png')[0]

paint_pipeline = Hunyuan3DPaintPipeline(Hunyuan3DPaintConfig(max_num_view=6, resolution=512))
mesh_textured = paint_pipeline(mesh_path, image_path='assets/demo.png')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Gradio App&lt;/h3&gt; 
&lt;p&gt;You could also host a &lt;a href="https://www.gradio.app/"&gt;Gradio&lt;/a&gt; App in your own computer via:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 gradio_app.py \
  --model_path tencent/Hunyuan3D-2.1 \
  --subfolder hunyuan3d-dit-v2-1 \
  --texgen_model_path tencent/Hunyuan3D-2.1 \
  --low_vram_mode
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîó BibTeX&lt;/h2&gt; 
&lt;p&gt;If you found this repository helpful, please cite our reports:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{hunyuan3d2025hunyuan3d,
    title={Hunyuan3D 2.1: From Images to High-Fidelity 3D Assets with Production-Ready PBR Material},
    author={Tencent Hunyuan3D Team},
    year={2025},
    eprint={2506.15442},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{hunyuan3d22025tencent,
    title={Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation},
    author={Tencent Hunyuan3D Team},
    year={2025},
    eprint={2501.12202},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{yang2024hunyuan3d,
    title={Hunyuan3D 1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation},
    author={Tencent Hunyuan3D Team},
    year={2024},
    eprint={2411.02293},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We would like to thank the contributors to the &lt;a href="https://github.com/VAST-AI-Research/TripoSG"&gt;TripoSG&lt;/a&gt;, &lt;a href="https://github.com/microsoft/TRELLIS"&gt;Trellis&lt;/a&gt;, &lt;a href="https://github.com/facebookresearch/dinov2"&gt;DINOv2&lt;/a&gt;, &lt;a href="https://github.com/Stability-AI/stablediffusion"&gt;Stable Diffusion&lt;/a&gt;, &lt;a href="https://github.com/black-forest-labs/flux"&gt;FLUX&lt;/a&gt;, &lt;a href="https://github.com/huggingface/diffusers"&gt;diffusers&lt;/a&gt;, &lt;a href="https://huggingface.co"&gt;HuggingFace&lt;/a&gt;, &lt;a href="https://github.com/wyysf-98/CraftsMan3D"&gt;CraftsMan3D&lt;/a&gt;, &lt;a href="https://github.com/NeuralCarver/Michelangelo/tree/main"&gt;Michelangelo&lt;/a&gt;, &lt;a href="https://github.com/Tencent-Hunyuan/HunyuanDiT"&gt;Hunyuan-DiT&lt;/a&gt;, and &lt;a href="https://github.com/Tencent-Hunyuan/HunyuanVideo"&gt;HunyuanVideo&lt;/a&gt; repositories, for their open research and exploration.&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://star-history.com/#Tencent-Hunyuan/Hunyuan3D-2.1&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent-Hunyuan/Hunyuan3D-2.1&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent-Hunyuan/Hunyuan3D-2.1&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent-Hunyuan/Hunyuan3D-2.1&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>crewAIInc/crewAI</title>
      <link>https://github.com/crewAIInc/crewAI</link>
      <description>&lt;p&gt;Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://github.com/crewAIInc/crewAI"&gt; &lt;img src="https://raw.githubusercontent.com/crewAIInc/crewAI/main/docs/images/crewai_logo.png" width="600px" alt="Open source Multi-AI Agent orchestration framework" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center" style="display: flex; justify-content: center; gap: 20px; align-items: center;"&gt; &lt;a href="https://trendshift.io/repositories/11239" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/11239" alt="crewAIInc%2FcrewAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://crewai.com"&gt;Homepage&lt;/a&gt; ¬∑ &lt;a href="https://docs.crewai.com"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://app.crewai.com"&gt;Start Cloud Trial&lt;/a&gt; ¬∑ &lt;a href="https://blog.crewai.com"&gt;Blog&lt;/a&gt; ¬∑ &lt;a href="https://community.crewai.com"&gt;Forum&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/crewAIInc/crewAI"&gt; &lt;img src="https://img.shields.io/github/stars/crewAIInc/crewAI" alt="GitHub Repo stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/crewAIInc/crewAI/network/members"&gt; &lt;img src="https://img.shields.io/github/forks/crewAIInc/crewAI" alt="GitHub forks" /&gt; &lt;/a&gt; &lt;a href="https://github.com/crewAIInc/crewAI/issues"&gt; &lt;img src="https://img.shields.io/github/issues/crewAIInc/crewAI" alt="GitHub issues" /&gt; &lt;/a&gt; &lt;a href="https://github.com/crewAIInc/crewAI/pulls"&gt; &lt;img src="https://img.shields.io/github/issues-pr/crewAIInc/crewAI" alt="GitHub pull requests" /&gt; &lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-green.svg?sanitize=true" alt="License: MIT" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://pypi.org/project/crewai/"&gt; &lt;img src="https://img.shields.io/pypi/v/crewai" alt="PyPI version" /&gt; &lt;/a&gt; &lt;a href="https://pypi.org/project/crewai/"&gt; &lt;img src="https://img.shields.io/pypi/dm/crewai" alt="PyPI downloads" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/crewAIInc"&gt; &lt;img src="https://img.shields.io/twitter/follow/crewAIInc?style=social" alt="Twitter Follow" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3&gt;Fast and Flexible Multi-Agent Automation Framework&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;CrewAI is a lean, lightning-fast Python framework built entirely from scratch‚Äîcompletely &lt;strong&gt;independent of LangChain or other agent frameworks&lt;/strong&gt;. It empowers developers with both high-level simplicity and precise low-level control, ideal for creating autonomous AI agents tailored to any scenario.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CrewAI Crews&lt;/strong&gt;: Optimize for autonomy and collaborative intelligence.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CrewAI Flows&lt;/strong&gt;: Enable granular, event-driven control, single LLM calls for precise task orchestration and supports Crews natively&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;With over 100,000 developers certified through our community courses at &lt;a href="https://learn.crewai.com"&gt;learn.crewai.com&lt;/a&gt;, CrewAI is rapidly becoming the standard for enterprise-ready AI automation.&lt;/p&gt; 
&lt;h1&gt;CrewAI Enterprise Suite&lt;/h1&gt; 
&lt;p&gt;CrewAI Enterprise Suite is a comprehensive bundle tailored for organizations that require secure, scalable, and easy-to-manage agent-driven automation.&lt;/p&gt; 
&lt;p&gt;You can try one part of the suite the &lt;a href="https://app.crewai.com"&gt;Crew Control Plane for free&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Crew Control Plane Key Features:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Tracing &amp;amp; Observability&lt;/strong&gt;: Monitor and track your AI agents and workflows in real-time, including metrics, logs, and traces.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unified Control Plane&lt;/strong&gt;: A centralized platform for managing, monitoring, and scaling your AI agents and workflows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Integrations&lt;/strong&gt;: Easily connect with existing enterprise systems, data sources, and cloud infrastructure.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Security&lt;/strong&gt;: Built-in robust security and compliance measures ensuring safe deployment and management.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Actionable Insights&lt;/strong&gt;: Real-time analytics and reporting to optimize performance and decision-making.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;24/7 Support&lt;/strong&gt;: Dedicated enterprise support to ensure uninterrupted operation and quick resolution of issues.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;On-premise and Cloud Deployment Options&lt;/strong&gt;: Deploy CrewAI Enterprise on-premise or in the cloud, depending on your security and compliance requirements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CrewAI Enterprise is designed for enterprises seeking a powerful, reliable solution to transform complex business processes into efficient, intelligent automations.&lt;/p&gt; 
&lt;h2&gt;Table of contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#why-crewai"&gt;Why CrewAI?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#getting-started"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#understanding-flows-and-crews"&gt;Understanding Flows and Crews&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#how-crewai-compares"&gt;CrewAI vs LangGraph&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#examples"&gt;Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#quick-tutorial"&gt;Quick Tutorial&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#write-job-descriptions"&gt;Write Job Descriptions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#trip-planner"&gt;Trip Planner&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#stock-analysis"&gt;Stock Analysis&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#using-crews-and-flows-together"&gt;Using Crews and Flows Together&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#connecting-your-crew-to-a-model"&gt;Connecting Your Crew to a Model&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#how-crewai-compares"&gt;How CrewAI Compares&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#frequently-asked-questions-faq"&gt;Frequently Asked Questions (FAQ)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#contribution"&gt;Contribution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#telemetry"&gt;Telemetry&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why CrewAI?&lt;/h2&gt; 
&lt;div align="center" style="margin-bottom: 30px;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/crewAIInc/crewAI/main/docs/images/asset.png" alt="CrewAI Logo" width="100%" /&gt; 
&lt;/div&gt; 
&lt;p&gt;CrewAI unlocks the true potential of multi-agent automation, delivering the best-in-class combination of speed, flexibility, and control with either Crews of AI Agents or Flows of Events:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Standalone Framework&lt;/strong&gt;: Built from scratch, independent of LangChain or any other agent framework.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High Performance&lt;/strong&gt;: Optimized for speed and minimal resource usage, enabling faster execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Low Level Customization&lt;/strong&gt;: Complete freedom to customize at both high and low levels - from overall workflows and system architecture to granular agent behaviors, internal prompts, and execution logic.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ideal for Every Use Case&lt;/strong&gt;: Proven effective for both simple tasks and highly complex, real-world, enterprise-grade scenarios.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Robust Community&lt;/strong&gt;: Backed by a rapidly growing community of over &lt;strong&gt;100,000 certified&lt;/strong&gt; developers offering comprehensive support and resources.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CrewAI empowers developers and enterprises to confidently build intelligent automations, bridging the gap between simplicity, flexibility, and performance.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Setup and run your first CrewAI agents by following this tutorial.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=-kSOTtYzgEw" title="CrewAI Getting Started Tutorial"&gt;&lt;img src="https://img.youtube.com/vi/-kSOTtYzgEw/hqdefault.jpg" alt="CrewAI Getting Started Tutorial" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;/h3&gt; 
&lt;p&gt;Learning Resources&lt;/p&gt; 
&lt;p&gt;Learn CrewAI through our comprehensive courses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/"&gt;Multi AI Agent Systems with CrewAI&lt;/a&gt; - Master the fundamentals of multi-agent systems&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.deeplearning.ai/short-courses/practical-multi-ai-agents-and-advanced-use-cases-with-crewai/"&gt;Practical Multi AI Agents and Advanced Use Cases&lt;/a&gt; - Deep dive into advanced implementations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Understanding Flows and Crews&lt;/h3&gt; 
&lt;p&gt;CrewAI offers two powerful, complementary approaches that work seamlessly together to build sophisticated AI applications:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Crews&lt;/strong&gt;: Teams of AI agents with true autonomy and agency, working together to accomplish complex tasks through role-based collaboration. Crews enable:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Natural, autonomous decision-making between agents&lt;/li&gt; 
   &lt;li&gt;Dynamic task delegation and collaboration&lt;/li&gt; 
   &lt;li&gt;Specialized roles with defined goals and expertise&lt;/li&gt; 
   &lt;li&gt;Flexible problem-solving approaches&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flows&lt;/strong&gt;: Production-ready, event-driven workflows that deliver precise control over complex automations. Flows provide:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fine-grained control over execution paths for real-world scenarios&lt;/li&gt; 
   &lt;li&gt;Secure, consistent state management between tasks&lt;/li&gt; 
   &lt;li&gt;Clean integration of AI agents with production Python code&lt;/li&gt; 
   &lt;li&gt;Conditional branching for complex business logic&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The true power of CrewAI emerges when combining Crews and Flows. This synergy allows you to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Build complex, production-grade applications&lt;/li&gt; 
 &lt;li&gt;Balance autonomy with precise control&lt;/li&gt; 
 &lt;li&gt;Handle sophisticated real-world scenarios&lt;/li&gt; 
 &lt;li&gt;Maintain clean, maintainable code structure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting Started with Installation&lt;/h3&gt; 
&lt;p&gt;To get started with CrewAI, follow these simple steps:&lt;/p&gt; 
&lt;h3&gt;1. Installation&lt;/h3&gt; 
&lt;p&gt;Ensure you have Python &amp;gt;=3.10 &amp;lt;3.14 installed on your system. CrewAI uses &lt;a href="https://docs.astral.sh/uv/"&gt;UV&lt;/a&gt; for dependency management and package handling, offering a seamless setup and execution experience.&lt;/p&gt; 
&lt;p&gt;First, install CrewAI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install crewai
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to install the 'crewai' package along with its optional features that include additional tools for agents, you can do so by using the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install 'crewai[tools]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The command above installs the basic package and also adds extra components which require more dependencies to function.&lt;/p&gt; 
&lt;h3&gt;Troubleshooting Dependencies&lt;/h3&gt; 
&lt;p&gt;If you encounter issues during installation or usage, here are some common solutions:&lt;/p&gt; 
&lt;h4&gt;Common Issues&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ModuleNotFoundError: No module named 'tiktoken'&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Install tiktoken explicitly: &lt;code&gt;pip install 'crewai[embeddings]'&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If using embedchain or other tools: &lt;code&gt;pip install 'crewai[tools]'&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Failed building wheel for tiktoken&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Ensure Rust compiler is installed (see installation steps above)&lt;/li&gt; 
   &lt;li&gt;For Windows: Verify Visual C++ Build Tools are installed&lt;/li&gt; 
   &lt;li&gt;Try upgrading pip: &lt;code&gt;pip install --upgrade pip&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If issues persist, use a pre-built wheel: &lt;code&gt;pip install tiktoken --prefer-binary&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;2. Setting Up Your Crew with the YAML Configuration&lt;/h3&gt; 
&lt;p&gt;To create a new CrewAI project, run the following CLI (Command Line Interface) command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;crewai create crew &amp;lt;project_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command creates a new project folder with the following structure:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;my_project/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ my_project/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ main.py
        ‚îú‚îÄ‚îÄ crew.py
        ‚îú‚îÄ‚îÄ tools/
        ‚îÇ   ‚îú‚îÄ‚îÄ custom_tool.py
        ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
        ‚îî‚îÄ‚îÄ config/
            ‚îú‚îÄ‚îÄ agents.yaml
            ‚îî‚îÄ‚îÄ tasks.yaml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can now start developing your crew by editing the files in the &lt;code&gt;src/my_project&lt;/code&gt; folder. The &lt;code&gt;main.py&lt;/code&gt; file is the entry point of the project, the &lt;code&gt;crew.py&lt;/code&gt; file is where you define your crew, the &lt;code&gt;agents.yaml&lt;/code&gt; file is where you define your agents, and the &lt;code&gt;tasks.yaml&lt;/code&gt; file is where you define your tasks.&lt;/p&gt; 
&lt;h4&gt;To customize your project, you can:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Modify &lt;code&gt;src/my_project/config/agents.yaml&lt;/code&gt; to define your agents.&lt;/li&gt; 
 &lt;li&gt;Modify &lt;code&gt;src/my_project/config/tasks.yaml&lt;/code&gt; to define your tasks.&lt;/li&gt; 
 &lt;li&gt;Modify &lt;code&gt;src/my_project/crew.py&lt;/code&gt; to add your own logic, tools, and specific arguments.&lt;/li&gt; 
 &lt;li&gt;Modify &lt;code&gt;src/my_project/main.py&lt;/code&gt; to add custom inputs for your agents and tasks.&lt;/li&gt; 
 &lt;li&gt;Add your environment variables into the &lt;code&gt;.env&lt;/code&gt; file.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Example of a simple crew with a sequential process:&lt;/h4&gt; 
&lt;p&gt;Instantiate your crew:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;crewai create crew latest-ai-development
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Modify the files as needed to fit your use case:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;agents.yaml&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# src/my_project/config/agents.yaml
researcher:
  role: &amp;gt;
    {topic} Senior Data Researcher
  goal: &amp;gt;
    Uncover cutting-edge developments in {topic}
  backstory: &amp;gt;
    You're a seasoned researcher with a knack for uncovering the latest
    developments in {topic}. Known for your ability to find the most relevant
    information and present it in a clear and concise manner.

reporting_analyst:
  role: &amp;gt;
    {topic} Reporting Analyst
  goal: &amp;gt;
    Create detailed reports based on {topic} data analysis and research findings
  backstory: &amp;gt;
    You're a meticulous analyst with a keen eye for detail. You're known for
    your ability to turn complex data into clear and concise reports, making
    it easy for others to understand and act on the information you provide.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;tasks.yaml&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# src/my_project/config/tasks.yaml
research_task:
  description: &amp;gt;
    Conduct a thorough research about {topic}
    Make sure you find any interesting and relevant information given
    the current year is 2025.
  expected_output: &amp;gt;
    A list with 10 bullet points of the most relevant information about {topic}
  agent: researcher

reporting_task:
  description: &amp;gt;
    Review the context you got and expand each topic into a full section for a report.
    Make sure the report is detailed and contains any and all relevant information.
  expected_output: &amp;gt;
    A fully fledge reports with the mains topics, each with a full section of information.
    Formatted as markdown without '```'
  agent: reporting_analyst
  output_file: report.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;crew.py&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# src/my_project/crew.py
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List

@CrewBase
class LatestAiDevelopmentCrew():
	"""LatestAiDevelopment crew"""
	agents: List[BaseAgent]
	tasks: List[Task]

	@agent
	def researcher(self) -&amp;gt; Agent:
		return Agent(
			config=self.agents_config['researcher'],
			verbose=True,
			tools=[SerperDevTool()]
		)

	@agent
	def reporting_analyst(self) -&amp;gt; Agent:
		return Agent(
			config=self.agents_config['reporting_analyst'],
			verbose=True
		)

	@task
	def research_task(self) -&amp;gt; Task:
		return Task(
			config=self.tasks_config['research_task'],
		)

	@task
	def reporting_task(self) -&amp;gt; Task:
		return Task(
			config=self.tasks_config['reporting_task'],
			output_file='report.md'
		)

	@crew
	def crew(self) -&amp;gt; Crew:
		"""Creates the LatestAiDevelopment crew"""
		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=True,
		)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;main.py&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;#!/usr/bin/env python
# src/my_project/main.py
import sys
from latest_ai_development.crew import LatestAiDevelopmentCrew

def run():
    """
    Run the crew.
    """
    inputs = {
        'topic': 'AI Agents'
    }
    LatestAiDevelopmentCrew().crew().kickoff(inputs=inputs)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Running Your Crew&lt;/h3&gt; 
&lt;p&gt;Before running your crew, make sure you have the following keys set as environment variables in your &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;An &lt;a href="https://platform.openai.com/account/api-keys"&gt;OpenAI API key&lt;/a&gt; (or other LLM API key): &lt;code&gt;OPENAI_API_KEY=sk-...&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;A &lt;a href="https://serper.dev/"&gt;Serper.dev&lt;/a&gt; API key: &lt;code&gt;SERPER_API_KEY=YOUR_KEY_HERE&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Lock the dependencies and install them by using the CLI command but first, navigate to your project directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd my_project
crewai install (Optional)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run your crew, execute the following command in the root of your project:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;crewai run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python src/my_project/main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If an error happens due to the usage of poetry, please run the following command to update your crewai package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;crewai update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should see the output in the console and the &lt;code&gt;report.md&lt;/code&gt; file should be created in the root of your project with the full final report.&lt;/p&gt; 
&lt;p&gt;In addition to the sequential process, you can use the hierarchical process, which automatically assigns a manager to the defined crew to properly coordinate the planning and execution of tasks through delegation and validation of results. &lt;a href="https://docs.crewai.com/core-concepts/Processes/"&gt;See more about the processes here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;p&gt;CrewAI stands apart as a lean, standalone, high-performance multi-AI Agent framework delivering simplicity, flexibility, and precise control‚Äîfree from the complexity and limitations found in other agent frameworks.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Standalone &amp;amp; Lean&lt;/strong&gt;: Completely independent from other frameworks like LangChain, offering faster execution and lighter resource demands.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible &amp;amp; Precise&lt;/strong&gt;: Easily orchestrate autonomous agents through intuitive &lt;a href="https://docs.crewai.com/concepts/crews"&gt;Crews&lt;/a&gt; or precise &lt;a href="https://docs.crewai.com/concepts/flows"&gt;Flows&lt;/a&gt;, achieving perfect balance for your needs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Integration&lt;/strong&gt;: Effortlessly combine Crews (autonomy) and Flows (precision) to create complex, real-world automations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deep Customization&lt;/strong&gt;: Tailor every aspect‚Äîfrom high-level workflows down to low-level internal prompts and agent behaviors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reliable Performance&lt;/strong&gt;: Consistent results across simple tasks and complex, enterprise-level automations.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Thriving Community&lt;/strong&gt;: Backed by robust documentation and over 100,000 certified developers, providing exceptional support and guidance.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Choose CrewAI to easily build powerful, adaptable, and production-ready AI automations.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;You can test different real life examples of AI crews in the &lt;a href="https://github.com/crewAIInc/crewAI-examples?tab=readme-ov-file"&gt;CrewAI-examples repo&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/landing_page_generator"&gt;Landing Page Generator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.crewai.com/how-to/Human-Input-on-Execution"&gt;Having Human input on the execution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/trip_planner"&gt;Trip Planner&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/stock_analysis"&gt;Stock Analysis&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick Tutorial&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=tnejrr-0a94" title="CrewAI Tutorial"&gt;&lt;img src="https://img.youtube.com/vi/tnejrr-0a94/maxresdefault.jpg" alt="CrewAI Tutorial" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Write Job Descriptions&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/job-posting"&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=u98wEMz-9to" title="Jobs postings"&gt;&lt;img src="https://img.youtube.com/vi/u98wEMz-9to/maxresdefault.jpg" alt="Jobs postings" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Trip Planner&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/trip_planner"&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=xis7rWp-hjs" title="Trip Planner"&gt;&lt;img src="https://img.youtube.com/vi/xis7rWp-hjs/maxresdefault.jpg" alt="Trip Planner" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Stock Analysis&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/crews/stock_analysis"&gt;Check out code for this example&lt;/a&gt; or watch a video below:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=e0Uj4yWdaAg" title="Stock Analysis"&gt;&lt;img src="https://img.youtube.com/vi/e0Uj4yWdaAg/maxresdefault.jpg" alt="Stock Analysis" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Using Crews and Flows Together&lt;/h3&gt; 
&lt;p&gt;CrewAI's power truly shines when combining Crews with Flows to create sophisticated automation pipelines. CrewAI flows support logical operators like &lt;code&gt;or_&lt;/code&gt; and &lt;code&gt;and_&lt;/code&gt; to combine multiple conditions. This can be used with &lt;code&gt;@start&lt;/code&gt;, &lt;code&gt;@listen&lt;/code&gt;, or &lt;code&gt;@router&lt;/code&gt; decorators to create complex triggering conditions.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;or_&lt;/code&gt;: Triggers when any of the specified conditions are met.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;and_&lt;/code&gt;Triggers when all of the specified conditions are met.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Here's how you can orchestrate multiple Crews within a Flow:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from crewai.flow.flow import Flow, listen, start, router, or_
from crewai import Crew, Agent, Task, Process
from pydantic import BaseModel

# Define structured state for precise control
class MarketState(BaseModel):
    sentiment: str = "neutral"
    confidence: float = 0.0
    recommendations: list = []

class AdvancedAnalysisFlow(Flow[MarketState]):
    @start()
    def fetch_market_data(self):
        # Demonstrate low-level control with structured state
        self.state.sentiment = "analyzing"
        return {"sector": "tech", "timeframe": "1W"}  # These parameters match the task description template

    @listen(fetch_market_data)
    def analyze_with_crew(self, market_data):
        # Show crew agency through specialized roles
        analyst = Agent(
            role="Senior Market Analyst",
            goal="Conduct deep market analysis with expert insight",
            backstory="You're a veteran analyst known for identifying subtle market patterns"
        )
        researcher = Agent(
            role="Data Researcher",
            goal="Gather and validate supporting market data",
            backstory="You excel at finding and correlating multiple data sources"
        )

        analysis_task = Task(
            description="Analyze {sector} sector data for the past {timeframe}",
            expected_output="Detailed market analysis with confidence score",
            agent=analyst
        )
        research_task = Task(
            description="Find supporting data to validate the analysis",
            expected_output="Corroborating evidence and potential contradictions",
            agent=researcher
        )

        # Demonstrate crew autonomy
        analysis_crew = Crew(
            agents=[analyst, researcher],
            tasks=[analysis_task, research_task],
            process=Process.sequential,
            verbose=True
        )
        return analysis_crew.kickoff(inputs=market_data)  # Pass market_data as named inputs

    @router(analyze_with_crew)
    def determine_next_steps(self):
        # Show flow control with conditional routing
        if self.state.confidence &amp;gt; 0.8:
            return "high_confidence"
        elif self.state.confidence &amp;gt; 0.5:
            return "medium_confidence"
        return "low_confidence"

    @listen("high_confidence")
    def execute_strategy(self):
        # Demonstrate complex decision making
        strategy_crew = Crew(
            agents=[
                Agent(role="Strategy Expert",
                      goal="Develop optimal market strategy")
            ],
            tasks=[
                Task(description="Create detailed strategy based on analysis",
                     expected_output="Step-by-step action plan")
            ]
        )
        return strategy_crew.kickoff()

    @listen(or_("medium_confidence", "low_confidence"))
    def request_additional_analysis(self):
        self.state.recommendations.append("Gather more data")
        return "Additional analysis required"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This example demonstrates how to:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Use Python code for basic data operations&lt;/li&gt; 
 &lt;li&gt;Create and execute Crews as steps in your workflow&lt;/li&gt; 
 &lt;li&gt;Use Flow decorators to manage the sequence of operations&lt;/li&gt; 
 &lt;li&gt;Implement conditional branching based on Crew results&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Connecting Your Crew to a Model&lt;/h2&gt; 
&lt;p&gt;CrewAI supports using various LLMs through a variety of connection options. By default your agents will use the OpenAI API when querying the model. However, there are several other ways to allow your agents to connect to models. For example, you can configure your agents to use a local model via the Ollama tool.&lt;/p&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://docs.crewai.com/how-to/LLM-Connections/"&gt;Connect CrewAI to LLMs&lt;/a&gt; page for details on configuring your agents' connections to models.&lt;/p&gt; 
&lt;h2&gt;How CrewAI Compares&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;CrewAI's Advantage&lt;/strong&gt;: CrewAI combines autonomous agent intelligence with precise workflow control through its unique Crews and Flows architecture. The framework excels at both high-level orchestration and low-level customization, enabling complex, production-grade systems with granular control.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LangGraph&lt;/strong&gt;: While LangGraph provides a foundation for building agent workflows, its approach requires significant boilerplate code and complex state management patterns. The framework's tight coupling with LangChain can limit flexibility when implementing custom agent behaviors or integrating with external systems.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;P.S. CrewAI demonstrates significant performance advantages over LangGraph, executing 5.76x faster in certain cases like this QA task example (&lt;a href="https://github.com/crewAIInc/crewAI-examples/tree/main/Notebooks/CrewAI%20Flows%20%26%20Langgraph/QA%20Agent"&gt;see comparison&lt;/a&gt;) while achieving higher evaluation scores with faster completion times in certain coding tasks, like in this example (&lt;a href="https://github.com/crewAIInc/crewAI-examples/raw/main/Notebooks/CrewAI%20Flows%20%26%20Langgraph/Coding%20Assistant/coding_assistant_eval.ipynb"&gt;detailed analysis&lt;/a&gt;).&lt;/em&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Autogen&lt;/strong&gt;: While Autogen excels at creating conversational agents capable of working together, it lacks an inherent concept of process. In Autogen, orchestrating agents' interactions requires additional programming, which can become complex and cumbersome as the scale of tasks grows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ChatDev&lt;/strong&gt;: ChatDev introduced the idea of processes into the realm of AI agents, but its implementation is quite rigid. Customizations in ChatDev are limited and not geared towards production environments, which can hinder scalability and flexibility in real-world applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;CrewAI is open-source and we welcome contributions. If you're looking to contribute, please:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fork the repository.&lt;/li&gt; 
 &lt;li&gt;Create a new branch for your feature.&lt;/li&gt; 
 &lt;li&gt;Add your feature or improvement.&lt;/li&gt; 
 &lt;li&gt;Send a pull request.&lt;/li&gt; 
 &lt;li&gt;We appreciate your input!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installing Dependencies&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv lock
uv sync
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Virtual Env&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Pre-commit hooks&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pre-commit install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running Tests&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run pytest .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running static type checks&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uvx mypy src
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Packaging&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing Locally&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install dist/*.tar.gz
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Telemetry&lt;/h2&gt; 
&lt;p&gt;CrewAI uses anonymous telemetry to collect usage data with the main purpose of helping us improve the library by focusing our efforts on the most used features, integrations and tools.&lt;/p&gt; 
&lt;p&gt;It's pivotal to understand that &lt;strong&gt;NO data is collected&lt;/strong&gt; concerning prompts, task descriptions, agents' backstories or goals, usage of tools, API calls, responses, any data processed by the agents, or secrets and environment variables, with the exception of the conditions mentioned. When the &lt;code&gt;share_crew&lt;/code&gt; feature is enabled, detailed data including task descriptions, agents' backstories or goals, and other specific attributes are collected to provide deeper insights while respecting user privacy. Users can disable telemetry by setting the environment variable OTEL_SDK_DISABLED to true.&lt;/p&gt; 
&lt;p&gt;Data collected includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Version of CrewAI 
  &lt;ul&gt; 
   &lt;li&gt;So we can understand how many users are using the latest version&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Version of Python 
  &lt;ul&gt; 
   &lt;li&gt;So we can decide on what versions to better support&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;General OS (e.g. number of CPUs, macOS/Windows/Linux) 
  &lt;ul&gt; 
   &lt;li&gt;So we know what OS we should focus on and if we could build specific OS related features&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Number of agents and tasks in a crew 
  &lt;ul&gt; 
   &lt;li&gt;So we make sure we are testing internally with similar use cases and educate people on the best practices&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Crew Process being used 
  &lt;ul&gt; 
   &lt;li&gt;Understand where we should focus our efforts&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;If Agents are using memory or allowing delegation 
  &lt;ul&gt; 
   &lt;li&gt;Understand if we improved the features or maybe even drop them&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;If Tasks are being executed in parallel or sequentially 
  &lt;ul&gt; 
   &lt;li&gt;Understand if we should focus more on parallel execution&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Language model being used 
  &lt;ul&gt; 
   &lt;li&gt;Improved support on most used languages&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Roles of agents in a crew 
  &lt;ul&gt; 
   &lt;li&gt;Understand high level use cases so we can build better tools, integrations and examples about it&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Tools names available 
  &lt;ul&gt; 
   &lt;li&gt;Understand out of the publicly available tools, which ones are being used the most so we can improve them&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Users can opt-in to Further Telemetry, sharing the complete telemetry data by setting the &lt;code&gt;share_crew&lt;/code&gt; attribute to &lt;code&gt;True&lt;/code&gt; on their Crews. Enabling &lt;code&gt;share_crew&lt;/code&gt; results in the collection of detailed crew and task execution data, including &lt;code&gt;goal&lt;/code&gt;, &lt;code&gt;backstory&lt;/code&gt;, &lt;code&gt;context&lt;/code&gt;, and &lt;code&gt;output&lt;/code&gt; of tasks. This enables a deeper insight into usage patterns while respecting the user's choice to share.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;CrewAI is released under the &lt;a href="https://github.com/crewAIInc/crewAI/raw/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Frequently Asked Questions (FAQ)&lt;/h2&gt; 
&lt;h3&gt;General&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-what-exactly-is-crewai"&gt;What exactly is CrewAI?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-how-do-i-install-crewai"&gt;How do I install CrewAI?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-does-crewai-depend-on-langchain"&gt;Does CrewAI depend on LangChain?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-is-crewai-open-source"&gt;Is CrewAI open-source?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-does-crewai-collect-data-from-users"&gt;Does CrewAI collect data from users?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Features and Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-can-crewai-handle-complex-use-cases"&gt;Can CrewAI handle complex use cases?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-can-i-use-crewai-with-local-ai-models"&gt;Can I use CrewAI with local AI models?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-what-makes-crews-different-from-flows"&gt;What makes Crews different from Flows?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-how-is-crewai-better-than-langchain"&gt;How is CrewAI better than LangChain?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-does-crewai-support-fine-tuning-or-training-custom-models"&gt;Does CrewAI support fine-tuning or training custom models?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Resources and Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-where-can-i-find-real-world-crewai-examples"&gt;Where can I find real-world CrewAI examples?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-how-can-i-contribute-to-crewai"&gt;How can I contribute to CrewAI?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Enterprise Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-what-additional-features-does-crewai-enterprise-offer"&gt;What additional features does CrewAI Enterprise offer?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-is-crewai-enterprise-available-for-cloud-and-on-premise-deployments"&gt;Is CrewAI Enterprise available for cloud and on-premise deployments?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/crewAIInc/crewAI/main/#q-can-i-try-crewai-enterprise-for-free"&gt;Can I try CrewAI Enterprise for free?&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Q: What exactly is CrewAI?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI is a standalone, lean, and fast Python framework built specifically for orchestrating autonomous AI agents. Unlike frameworks like LangChain, CrewAI does not rely on external dependencies, making it leaner, faster, and simpler.&lt;/p&gt; 
&lt;h3&gt;Q: How do I install CrewAI?&lt;/h3&gt; 
&lt;p&gt;A: Install CrewAI using pip:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install crewai
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For additional tools, use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install 'crewai[tools]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Q: Does CrewAI depend on LangChain?&lt;/h3&gt; 
&lt;p&gt;A: No. CrewAI is built entirely from the ground up, with no dependencies on LangChain or other agent frameworks. This ensures a lean, fast, and flexible experience.&lt;/p&gt; 
&lt;h3&gt;Q: Can CrewAI handle complex use cases?&lt;/h3&gt; 
&lt;p&gt;A: Yes. CrewAI excels at both simple and highly complex real-world scenarios, offering deep customization options at both high and low levels, from internal prompts to sophisticated workflow orchestration.&lt;/p&gt; 
&lt;h3&gt;Q: Can I use CrewAI with local AI models?&lt;/h3&gt; 
&lt;p&gt;A: Absolutely! CrewAI supports various language models, including local ones. Tools like Ollama and LM Studio allow seamless integration. Check the &lt;a href="https://docs.crewai.com/how-to/LLM-Connections/"&gt;LLM Connections documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h3&gt;Q: What makes Crews different from Flows?&lt;/h3&gt; 
&lt;p&gt;A: Crews provide autonomous agent collaboration, ideal for tasks requiring flexible decision-making and dynamic interaction. Flows offer precise, event-driven control, ideal for managing detailed execution paths and secure state management. You can seamlessly combine both for maximum effectiveness.&lt;/p&gt; 
&lt;h3&gt;Q: How is CrewAI better than LangChain?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI provides simpler, more intuitive APIs, faster execution speeds, more reliable and consistent results, robust documentation, and an active community‚Äîaddressing common criticisms and limitations associated with LangChain.&lt;/p&gt; 
&lt;h3&gt;Q: Is CrewAI open-source?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI is open-source and actively encourages community contributions and collaboration.&lt;/p&gt; 
&lt;h3&gt;Q: Does CrewAI collect data from users?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI collects anonymous telemetry data strictly for improvement purposes. Sensitive data such as prompts, tasks, or API responses are never collected unless explicitly enabled by the user.&lt;/p&gt; 
&lt;h3&gt;Q: Where can I find real-world CrewAI examples?&lt;/h3&gt; 
&lt;p&gt;A: Check out practical examples in the &lt;a href="https://github.com/crewAIInc/crewAI-examples"&gt;CrewAI-examples repository&lt;/a&gt;, covering use cases like trip planners, stock analysis, and job postings.&lt;/p&gt; 
&lt;h3&gt;Q: How can I contribute to CrewAI?&lt;/h3&gt; 
&lt;p&gt;A: Contributions are warmly welcomed! Fork the repository, create your branch, implement your changes, and submit a pull request. See the Contribution section of the README for detailed guidelines.&lt;/p&gt; 
&lt;h3&gt;Q: What additional features does CrewAI Enterprise offer?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI Enterprise provides advanced features such as a unified control plane, real-time observability, secure integrations, advanced security, actionable insights, and dedicated 24/7 enterprise support.&lt;/p&gt; 
&lt;h3&gt;Q: Is CrewAI Enterprise available for cloud and on-premise deployments?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI Enterprise supports both cloud-based and on-premise deployment options, allowing enterprises to meet their specific security and compliance requirements.&lt;/p&gt; 
&lt;h3&gt;Q: Can I try CrewAI Enterprise for free?&lt;/h3&gt; 
&lt;p&gt;A: Yes, you can explore part of the CrewAI Enterprise Suite by accessing the &lt;a href="https://app.crewai.com"&gt;Crew Control Plane&lt;/a&gt; for free.&lt;/p&gt; 
&lt;h3&gt;Q: Does CrewAI support fine-tuning or training custom models?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI can integrate with custom-trained or fine-tuned models, allowing you to enhance your agents with domain-specific knowledge and accuracy.&lt;/p&gt; 
&lt;h3&gt;Q: Can CrewAI agents interact with external tools and APIs?&lt;/h3&gt; 
&lt;p&gt;A: Absolutely! CrewAI agents can easily integrate with external tools, APIs, and databases, empowering them to leverage real-world data and resources.&lt;/p&gt; 
&lt;h3&gt;Q: Is CrewAI suitable for production environments?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI is explicitly designed with production-grade standards, ensuring reliability, stability, and scalability for enterprise deployments.&lt;/p&gt; 
&lt;h3&gt;Q: How scalable is CrewAI?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI is highly scalable, supporting simple automations and large-scale enterprise workflows involving numerous agents and complex tasks simultaneously.&lt;/p&gt; 
&lt;h3&gt;Q: Does CrewAI offer debugging and monitoring tools?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI Enterprise includes advanced debugging, tracing, and real-time observability features, simplifying the management and troubleshooting of your automations.&lt;/p&gt; 
&lt;h3&gt;Q: What programming languages does CrewAI support?&lt;/h3&gt; 
&lt;p&gt;A: CrewAI is primarily Python-based but easily integrates with services and APIs written in any programming language through its flexible API integration capabilities.&lt;/p&gt; 
&lt;h3&gt;Q: Does CrewAI offer educational resources for beginners?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI provides extensive beginner-friendly tutorials, courses, and documentation through learn.crewai.com, supporting developers at all skill levels.&lt;/p&gt; 
&lt;h3&gt;Q: Can CrewAI automate human-in-the-loop workflows?&lt;/h3&gt; 
&lt;p&gt;A: Yes, CrewAI fully supports human-in-the-loop workflows, allowing seamless collaboration between human experts and AI agents for enhanced decision-making.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>strands-agents/sdk-python</title>
      <link>https://github.com/strands-agents/sdk-python</link>
      <description>&lt;p&gt;A model-driven approach to building AI agents in just a few lines of code.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div&gt; 
  &lt;a href="https://strandsagents.com"&gt; &lt;img src="https://strandsagents.com/latest/assets/logo-github.svg?sanitize=true" alt="Strands Agents" width="55px" height="105px" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h1&gt; Strands Agents &lt;/h1&gt; 
 &lt;h2&gt; A model-driven approach to building AI agents in just a few lines of code. &lt;/h2&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/graphs/commit-activity"&gt;&lt;img alt="GitHub commit activity" src="https://img.shields.io/github/commit-activity/m/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/issues"&gt;&lt;img alt="GitHub open issues" src="https://img.shields.io/github/issues/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/pulls"&gt;&lt;img alt="GitHub open pull requests" src="https://img.shields.io/github/issues-pr/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://github.com/strands-agents/sdk-python/raw/main/LICENSE"&gt;&lt;img alt="License" src="https://img.shields.io/github/license/strands-agents/sdk-python" /&gt;&lt;/a&gt; 
  &lt;a href="https://pypi.org/project/strands-agents/"&gt;&lt;img alt="PyPI version" src="https://img.shields.io/pypi/v/strands-agents" /&gt;&lt;/a&gt; 
  &lt;a href="https://python.org"&gt;&lt;img alt="Python versions" src="https://img.shields.io/pypi/pyversions/strands-agents" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;p&gt; &lt;a href="https://strandsagents.com/"&gt;Documentation&lt;/a&gt; ‚óÜ &lt;a href="https://github.com/strands-agents/samples"&gt;Samples&lt;/a&gt; ‚óÜ &lt;a href="https://github.com/strands-agents/sdk-python"&gt;Python SDK&lt;/a&gt; ‚óÜ &lt;a href="https://github.com/strands-agents/tools"&gt;Tools&lt;/a&gt; ‚óÜ &lt;a href="https://github.com/strands-agents/agent-builder"&gt;Agent Builder&lt;/a&gt; ‚óÜ &lt;a href="https://github.com/strands-agents/mcp-server"&gt;MCP Server&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Strands Agents is a simple yet powerful SDK that takes a model-driven approach to building and running AI agents. From simple conversational assistants to complex autonomous workflows, from local development to production deployment, Strands Agents scales with your needs.&lt;/p&gt; 
&lt;h2&gt;Feature Overview&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight &amp;amp; Flexible&lt;/strong&gt;: Simple agent loop that just works and is fully customizable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model Agnostic&lt;/strong&gt;: Support for Amazon Bedrock, Anthropic, Gemini, LiteLLM, Llama, Ollama, OpenAI, Writer, and custom providers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Capabilities&lt;/strong&gt;: Multi-agent systems, autonomous agents, and streaming support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in MCP&lt;/strong&gt;: Native support for Model Context Protocol (MCP) servers, enabling access to thousands of pre-built tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install Strands Agents
pip install strands-agents strands-agents-tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands_tools import calculator
agent = Agent(tools=[calculator])
agent("What is the square root of 1764")
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: For the default Amazon Bedrock model provider, you'll need AWS credentials configured and model access enabled for Claude 4 Sonnet in the us-west-2 region. See the &lt;a href="https://strandsagents.com/"&gt;Quickstart Guide&lt;/a&gt; for details on configuring other model providers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Ensure you have Python 3.10+ installed, then:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows use: .venv\Scripts\activate

# Install Strands and tools
pip install strands-agents strands-agents-tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features at a Glance&lt;/h2&gt; 
&lt;h3&gt;Python-Based Tools&lt;/h3&gt; 
&lt;p&gt;Easily build tools using Python decorators:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent, tool

@tool
def word_count(text: str) -&amp;gt; int:
    """Count words in text.

    This docstring is used by the LLM to understand the tool's purpose.
    """
    return len(text.split())

agent = Agent(tools=[word_count])
response = agent("How many words are in this sentence?")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Hot Reloading from Directory:&lt;/strong&gt; Enable automatic tool loading and reloading from the &lt;code&gt;./tools/&lt;/code&gt; directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent

# Agent will watch ./tools/ directory for changes
agent = Agent(load_tools_from_directory=True)
response = agent("Use any tools you find in the tools directory")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MCP Support&lt;/h3&gt; 
&lt;p&gt;Seamlessly integrate Model Context Protocol (MCP) servers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands.tools.mcp import MCPClient
from mcp import stdio_client, StdioServerParameters

aws_docs_client = MCPClient(
    lambda: stdio_client(StdioServerParameters(command="uvx", args=["awslabs.aws-documentation-mcp-server@latest"]))
)

with aws_docs_client:
   agent = Agent(tools=aws_docs_client.list_tools_sync())
   response = agent("Tell me about Amazon Bedrock and how to use it with Python")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Multiple Model Providers&lt;/h3&gt; 
&lt;p&gt;Support for various model providers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands.models import BedrockModel
from strands.models.ollama import OllamaModel
from strands.models.llamaapi import LlamaAPIModel
from strands.models.gemini import GeminiModel
from strands.models.llamacpp import LlamaCppModel

# Bedrock
bedrock_model = BedrockModel(
  model_id="us.amazon.nova-pro-v1:0",
  temperature=0.3,
  streaming=True, # Enable/disable streaming
)
agent = Agent(model=bedrock_model)
agent("Tell me about Agentic AI")

# Google Gemini
gemini_model = GeminiModel(
  api_key="your_gemini_api_key",
  model_id="gemini-2.5-flash",
  params={"temperature": 0.7}
)
agent = Agent(model=gemini_model)
agent("Tell me about Agentic AI")

# Ollama
ollama_model = OllamaModel(
  host="http://localhost:11434",
  model_id="llama3"
)
agent = Agent(model=ollama_model)
agent("Tell me about Agentic AI")

# Llama API
llama_model = LlamaAPIModel(
    model_id="Llama-4-Maverick-17B-128E-Instruct-FP8",
)
agent = Agent(model=llama_model)
response = agent("Tell me about Agentic AI")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Built-in providers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/amazon-bedrock/"&gt;Amazon Bedrock&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/anthropic/"&gt;Anthropic&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/gemini/"&gt;Gemini&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/cohere/"&gt;Cohere&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/litellm/"&gt;LiteLLM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/llamacpp/"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/llamaapi/"&gt;LlamaAPI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/mistral/"&gt;MistralAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/ollama/"&gt;Ollama&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/openai/"&gt;OpenAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/sagemaker/"&gt;SageMaker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/writer/"&gt;Writer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Custom providers can be implemented using &lt;a href="https://strandsagents.com/latest/user-guide/concepts/model-providers/custom_model_provider/"&gt;Custom Providers&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Example tools&lt;/h3&gt; 
&lt;p&gt;Strands offers an optional strands-agents-tools package with pre-built tools for quick experimentation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from strands import Agent
from strands_tools import calculator
agent = Agent(tools=[calculator])
agent("What is the square root of 1764")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It's also available on GitHub via &lt;a href="https://github.com/strands-agents/tools"&gt;strands-agents/tools&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed guidance &amp;amp; examples, explore our documentation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/"&gt;User Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/quickstart/"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/concepts/agents/agent-loop/"&gt;Agent Loop&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/examples/"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/api-reference/agent/"&gt;API Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://strandsagents.com/latest/user-guide/deploy/operating-agents-in-production/"&gt;Production &amp;amp; Deployment Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing ‚ù§Ô∏è&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! See our &lt;a href="https://raw.githubusercontent.com/strands-agents/sdk-python/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reporting bugs &amp;amp; features&lt;/li&gt; 
 &lt;li&gt;Development setup&lt;/li&gt; 
 &lt;li&gt;Contributing via Pull Requests&lt;/li&gt; 
 &lt;li&gt;Code of Conduct&lt;/li&gt; 
 &lt;li&gt;Reporting of security issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/strands-agents/sdk-python/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/strands-agents/sdk-python/main/CONTRIBUTING.md#security-issue-notifications"&gt;CONTRIBUTING&lt;/a&gt; for more information.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>imputnet/helium</title>
      <link>https://github.com/imputnet/helium</link>
      <description>&lt;p&gt;Private, fast, and honest web browser&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;p&gt; &lt;img src="https://raw.githubusercontent.com/imputnet/helium/main/resources/branding/app_icon/raw.png" title="Helium" alt="Helium logo" width="120" /&gt; &lt;/p&gt;
 &lt;h1&gt;Helium&lt;/h1&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p width="120"&gt; The Chromium-based web browser made for people, with love. &lt;br /&gt; Best privacy by default, unbiased ad-blocking, no bloat and no noise. &lt;/p&gt; 
 &lt;a href="https://helium.computer/"&gt; helium.computer &lt;/a&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Downloads&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Helium is still in beta, so unexpected issues may occur. We are not responsible for any damage caused by usage of beta software.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Best way to download Helium is to open &lt;a href="https://helium.computer/"&gt;helium.computer&lt;/a&gt; on your computer. It'll pick the right build for your OS and architecture automatically.&lt;/p&gt; 
&lt;p&gt;If you wish to download builds "straight from the tap" with all options in one place, you can do it on GitHub in the Releases section in each platform's repo:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-macos/releases/latest"&gt;macOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-linux/releases/latest"&gt;Linux&lt;/a&gt; (AppImage)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-windows/releases/latest"&gt;Windows&lt;/a&gt; (no auto-updates yet)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Platform packaging&lt;/h2&gt; 
&lt;p&gt;Helium is available on all major desktop platforms, with entirety of source code for all of them published here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-macos"&gt;Helium for macOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-linux"&gt;Helium for Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-windows"&gt;Helium for Windows&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Other Helium repos&lt;/h2&gt; 
&lt;p&gt;Along with the main repo and platform packaging, these projects are also a part of Helium:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-services"&gt;Helium services&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-onboarding"&gt;Helium onboarding&lt;/a&gt; (the onboarding page seen in Helium at &lt;code&gt;helium://setup&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/ublock-origin-crx"&gt;uBlock Origin packaging&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;h3&gt;ungoogled-chromium&lt;/h3&gt; 
&lt;p&gt;Helium is proudly based on &lt;a href="https://github.com/ungoogled-software/ungoogled-chromium"&gt;ungoogled-chromium&lt;/a&gt;. It wouldn't be possible for us to get rid of Google's bloat and get a development+building pipeline this fast without it. Huge shout-out to everyone behind this amazing project! (and we intend to contribute even more stuff upstream in the future)&lt;/p&gt; 
&lt;h3&gt;The Chromium project&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.chromium.org/"&gt;The Chromium Project&lt;/a&gt; is obviously at the core of Helium, making it possible to exist in the first place.&lt;/p&gt; 
&lt;h3&gt;ungoogled-chromium's dependencies&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gcarq/inox-patchset"&gt;Inox patchset&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tracker.debian.org/pkg/chromium-browser"&gt;Debian&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bromite/bromite"&gt;Bromite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://iridiumbrowser.de/"&gt;Iridium Browser&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;All code, patches, modified portions of imported code or patches, and any other content that is unique to Helium and not imported from other repositories is licensed under GPL-3.0. See &lt;a href="https://raw.githubusercontent.com/imputnet/helium/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Any content imported from other projects retains its original license (for example, any original unmodified code imported from ungoogled-chromium remains licensed under their &lt;a href="https://raw.githubusercontent.com/imputnet/helium/main/LICENSE.ungoogled_chromium"&gt;BSD 3-Clause license&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;More documentation (soon)&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] We will add more documentation along with design and motivation guidelines in the future. All docs will be linked here along with other related content.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Significant-Gravitas/AutoGPT</title>
      <link>https://github.com/Significant-Gravitas/AutoGPT</link>
      <description>&lt;p&gt;AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AutoGPT: Build, Deploy, and Run AI Agents&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/autogpt"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscord.com%2Fapi%2Finvites%2Fautogpt%3Fwith_counts%3Dtrue&amp;amp;query=%24.approximate_member_count&amp;amp;label=total%20members&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;color=7289da" alt="Discord Follow" /&gt;&lt;/a&gt; ‚ÄÇ &lt;a href="https://twitter.com/Auto_GPT"&gt;&lt;img src="https://img.shields.io/twitter/follow/Auto_GPT?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; ‚ÄÇ&lt;/p&gt; 
&lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
&lt;p&gt;&lt;a href="https://zdoc.app/de/Significant-Gravitas/AutoGPT"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://zdoc.app/es/Significant-Gravitas/AutoGPT"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://zdoc.app/fr/Significant-Gravitas/AutoGPT"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://zdoc.app/ja/Significant-Gravitas/AutoGPT"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://zdoc.app/ko/Significant-Gravitas/AutoGPT"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://zdoc.app/pt/Significant-Gravitas/AutoGPT"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://zdoc.app/ru/Significant-Gravitas/AutoGPT"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://zdoc.app/zh/Significant-Gravitas/AutoGPT"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AutoGPT&lt;/strong&gt; is a powerful platform that allows you to create, deploy, and manage continuous AI agents that automate complex workflows.&lt;/p&gt; 
&lt;h2&gt;Hosting Options&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download to self-host (Free!)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bit.ly/3ZDijAI"&gt;Join the Waitlist&lt;/a&gt; for the cloud-hosted beta (Closed Beta - Public release Coming Soon!)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Self-Host the AutoGPT Platform&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Setting up and hosting the AutoGPT Platform yourself is a technical process. If you'd rather something that just works, we recommend &lt;a href="https://bit.ly/3ZDijAI"&gt;joining the waitlist&lt;/a&gt; for the cloud-hosted beta.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;System Requirements&lt;/h3&gt; 
&lt;p&gt;Before proceeding with the installation, ensure your system meets the following requirements:&lt;/p&gt; 
&lt;h4&gt;Hardware Requirements&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;CPU: 4+ cores recommended&lt;/li&gt; 
 &lt;li&gt;RAM: Minimum 8GB, 16GB recommended&lt;/li&gt; 
 &lt;li&gt;Storage: At least 10GB of free space&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Software Requirements&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Operating Systems: 
  &lt;ul&gt; 
   &lt;li&gt;Linux (Ubuntu 20.04 or newer recommended)&lt;/li&gt; 
   &lt;li&gt;macOS (10.15 or newer)&lt;/li&gt; 
   &lt;li&gt;Windows 10/11 with WSL2&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Required Software (with minimum versions): 
  &lt;ul&gt; 
   &lt;li&gt;Docker Engine (20.10.0 or newer)&lt;/li&gt; 
   &lt;li&gt;Docker Compose (2.0.0 or newer)&lt;/li&gt; 
   &lt;li&gt;Git (2.30 or newer)&lt;/li&gt; 
   &lt;li&gt;Node.js (16.x or newer)&lt;/li&gt; 
   &lt;li&gt;npm (8.x or newer)&lt;/li&gt; 
   &lt;li&gt;VSCode (1.60 or newer) or any modern code editor&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Network Requirements&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Stable internet connection&lt;/li&gt; 
 &lt;li&gt;Access to required ports (will be configured in Docker)&lt;/li&gt; 
 &lt;li&gt;Ability to make outbound HTTPS connections&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Updated Setup Instructions:&lt;/h3&gt; 
&lt;p&gt;We've moved to a fully maintained and regularly updated documentation site.&lt;/p&gt; 
&lt;p&gt;üëâ &lt;a href="https://docs.agpt.co/platform/getting-started/"&gt;Follow the official self-hosting guide here&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This tutorial assumes you have Docker, VSCode, git and npm installed.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h4&gt;‚ö° Quick Setup with One-Line Script (Recommended for Local Hosting)&lt;/h4&gt; 
&lt;p&gt;Skip the manual steps and get started in minutes using our automatic setup script.&lt;/p&gt; 
&lt;p&gt;For macOS/Linux:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -fsSL https://setup.agpt.co/install.sh -o install.sh &amp;amp;&amp;amp; bash install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Windows (PowerShell):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;powershell -c "iwr https://setup.agpt.co/install.bat -o install.bat; ./install.bat"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will install dependencies, configure Docker, and launch your local instance ‚Äî all in one go.&lt;/p&gt; 
&lt;h3&gt;üß± AutoGPT Frontend&lt;/h3&gt; 
&lt;p&gt;The AutoGPT frontend is where users interact with our powerful AI automation platform. It offers multiple ways to engage with and leverage our AI agents. This is the interface where you'll bring your AI automation ideas to life:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Builder:&lt;/strong&gt; For those who want to customize, our intuitive, low-code interface allows you to design and configure your own AI agents.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Workflow Management:&lt;/strong&gt; Build, modify, and optimize your automation workflows with ease. You build your agent by connecting blocks, where each block performs a single action.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deployment Controls:&lt;/strong&gt; Manage the lifecycle of your agents, from testing to production.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Ready-to-Use Agents:&lt;/strong&gt; Don't want to build? Simply select from our library of pre-configured agents and put them to work immediately.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Interaction:&lt;/strong&gt; Whether you've built your own or are using pre-configured agents, easily run and interact with them through our user-friendly interface.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Monitoring and Analytics:&lt;/strong&gt; Keep track of your agents' performance and gain insights to continually improve your automation processes.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.agpt.co/platform/new_blocks/"&gt;Read this guide&lt;/a&gt; to learn how to build your own custom blocks.&lt;/p&gt; 
&lt;h3&gt;üíΩ AutoGPT Server&lt;/h3&gt; 
&lt;p&gt;The AutoGPT Server is the powerhouse of our platform This is where your agents run. Once deployed, agents can be triggered by external sources and can operate continuously. It contains all the essential components that make AutoGPT run smoothly.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Source Code:&lt;/strong&gt; The core logic that drives our agents and automation processes.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Infrastructure:&lt;/strong&gt; Robust systems that ensure reliable and scalable performance.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Marketplace:&lt;/strong&gt; A comprehensive marketplace where you can find and deploy a wide range of pre-built agents.&lt;/p&gt; 
&lt;h3&gt;üêô Example Agents&lt;/h3&gt; 
&lt;p&gt;Here are two examples of what you can do with AutoGPT:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Generate Viral Videos from Trending Topics&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;This agent reads topics on Reddit.&lt;/li&gt; 
   &lt;li&gt;It identifies trending topics.&lt;/li&gt; 
   &lt;li&gt;It then automatically creates a short-form video based on the content.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Identify Top Quotes from Videos for Social Media&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;This agent subscribes to your YouTube channel.&lt;/li&gt; 
   &lt;li&gt;When you post a new video, it transcribes it.&lt;/li&gt; 
   &lt;li&gt;It uses AI to identify the most impactful quotes to generate a summary.&lt;/li&gt; 
   &lt;li&gt;Then, it writes a post to automatically publish to your social media.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;These examples show just a glimpse of what you can achieve with AutoGPT! You can create customized workflows to build agents for any use case.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;&lt;strong&gt;License Overview:&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;üõ°Ô∏è &lt;strong&gt;Polyform Shield License:&lt;/strong&gt; All code and content within the &lt;code&gt;autogpt_platform&lt;/code&gt; folder is licensed under the Polyform Shield License. This new project is our in-developlemt platform for building, deploying and managing agents.&lt;br /&gt;&lt;em&gt;&lt;a href="https://agpt.co/blog/introducing-the-autogpt-platform"&gt;Read more about this effort&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;ü¶â &lt;strong&gt;MIT License:&lt;/strong&gt; All other portions of the AutoGPT repository (i.e., everything outside the &lt;code&gt;autogpt_platform&lt;/code&gt; folder) are licensed under the MIT License. This includes the original stand-alone AutoGPT Agent, along with projects such as &lt;a href="https://github.com/Significant-Gravitas/AutoGPT/tree/master/classic/forge"&gt;Forge&lt;/a&gt;, &lt;a href="https://github.com/Significant-Gravitas/AutoGPT/tree/master/classic/benchmark"&gt;agbenchmark&lt;/a&gt; and the &lt;a href="https://github.com/Significant-Gravitas/AutoGPT/tree/master/classic/frontend"&gt;AutoGPT Classic GUI&lt;/a&gt;.&lt;br /&gt;We also publish additional work under the MIT Licence in other repositories, such as &lt;a href="https://github.com/Significant-Gravitas/gravitasml"&gt;GravitasML&lt;/a&gt; which is developed for and used in the AutoGPT Platform. See also our MIT Licenced &lt;a href="https://github.com/Significant-Gravitas/AutoGPT-Code-Ability"&gt;Code Ability&lt;/a&gt; project.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Mission&lt;/h3&gt; 
&lt;p&gt;Our mission is to provide the tools, so that you can focus on what matters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üèóÔ∏è &lt;strong&gt;Building&lt;/strong&gt; - Lay the foundation for something amazing.&lt;/li&gt; 
 &lt;li&gt;üß™ &lt;strong&gt;Testing&lt;/strong&gt; - Fine-tune your agent to perfection.&lt;/li&gt; 
 &lt;li&gt;ü§ù &lt;strong&gt;Delegating&lt;/strong&gt; - Let AI work for you, and have your ideas come to life.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Be part of the revolution! &lt;strong&gt;AutoGPT&lt;/strong&gt; is here to stay, at the forefront of AI innovation.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;üìñ &lt;a href="https://docs.agpt.co"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; ‚ÄÇ|‚ÄÇ &lt;strong&gt;üöÄ &lt;a href="https://raw.githubusercontent.com/Significant-Gravitas/AutoGPT/master/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ñ AutoGPT Classic&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Below is information about the classic version of AutoGPT.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;üõ†Ô∏è &lt;a href="https://raw.githubusercontent.com/Significant-Gravitas/AutoGPT/master/classic/FORGE-QUICKSTART.md"&gt;Build your own Agent - Quickstart&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;üèóÔ∏è Forge&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Forge your own agent!&lt;/strong&gt; ‚Äì Forge is a ready-to-go toolkit to build your own agent application. It handles most of the boilerplate code, letting you channel all your creativity into the things that set &lt;em&gt;your&lt;/em&gt; agent apart. All tutorials are located &lt;a href="https://medium.com/@aiedge/autogpt-forge-e3de53cc58ec"&gt;here&lt;/a&gt;. Components from &lt;a href="https://raw.githubusercontent.com/Significant-Gravitas/AutoGPT/master/classic/forge/"&gt;&lt;code&gt;forge&lt;/code&gt;&lt;/a&gt; can also be used individually to speed up development and reduce boilerplate in your agent project.&lt;/p&gt; 
&lt;p&gt;üöÄ &lt;a href="https://github.com/Significant-Gravitas/AutoGPT/raw/master/classic/forge/tutorials/001_getting_started.md"&gt;&lt;strong&gt;Getting Started with Forge&lt;/strong&gt;&lt;/a&gt; ‚Äì This guide will walk you through the process of creating your own agent and using the benchmark and user interface.&lt;/p&gt; 
&lt;p&gt;üìò &lt;a href="https://github.com/Significant-Gravitas/AutoGPT/tree/master/classic/forge"&gt;Learn More&lt;/a&gt; about Forge&lt;/p&gt; 
&lt;h3&gt;üéØ Benchmark&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Measure your agent's performance!&lt;/strong&gt; The &lt;code&gt;agbenchmark&lt;/code&gt; can be used with any agent that supports the agent protocol, and the integration with the project's &lt;a href="https://raw.githubusercontent.com/Significant-Gravitas/AutoGPT/master/#-cli"&gt;CLI&lt;/a&gt; makes it even easier to use with AutoGPT and forge-based agents. The benchmark offers a stringent testing environment. Our framework allows for autonomous, objective performance evaluations, ensuring your agents are primed for real-world action.&lt;/p&gt; 
&lt;!-- TODO: insert visual demonstrating the benchmark --&gt; 
&lt;p&gt;üì¶ &lt;a href="https://pypi.org/project/agbenchmark/"&gt;&lt;code&gt;agbenchmark&lt;/code&gt;&lt;/a&gt; on Pypi ‚ÄÇ|‚ÄÇ üìò &lt;a href="https://github.com/Significant-Gravitas/AutoGPT/tree/master/classic/benchmark"&gt;Learn More&lt;/a&gt; about the Benchmark&lt;/p&gt; 
&lt;h3&gt;üíª UI&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Makes agents easy to use!&lt;/strong&gt; The &lt;code&gt;frontend&lt;/code&gt; gives you a user-friendly interface to control and monitor your agents. It connects to agents through the &lt;a href="https://raw.githubusercontent.com/Significant-Gravitas/AutoGPT/master/#-agent-protocol"&gt;agent protocol&lt;/a&gt;, ensuring compatibility with many agents from both inside and outside of our ecosystem.&lt;/p&gt; 
&lt;!-- TODO: insert screenshot of front end --&gt; 
&lt;p&gt;The frontend works out-of-the-box with all agents in the repo. Just use the &lt;a href="https://raw.githubusercontent.com/Significant-Gravitas/AutoGPT/master/#-cli"&gt;CLI&lt;/a&gt; to run your agent of choice!&lt;/p&gt; 
&lt;p&gt;üìò &lt;a href="https://github.com/Significant-Gravitas/AutoGPT/tree/master/classic/frontend"&gt;Learn More&lt;/a&gt; about the Frontend&lt;/p&gt; 
&lt;h3&gt;‚å®Ô∏è CLI&lt;/h3&gt; 
&lt;p&gt;To make it as easy as possible to use all of the tools offered by the repository, a CLI is included at the root of the repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ ./run
Usage: cli.py [OPTIONS] COMMAND [ARGS]...

Options:
  --help  Show this message and exit.

Commands:
  agent      Commands to create, start and stop agents
  benchmark  Commands to start the benchmark and list tests and categories
  setup      Installs dependencies needed for your system.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Just clone the repo, install dependencies with &lt;code&gt;./run setup&lt;/code&gt;, and you should be good to go!&lt;/p&gt; 
&lt;h2&gt;ü§î Questions? Problems? Suggestions?&lt;/h2&gt; 
&lt;h3&gt;Get help - &lt;a href="https://discord.gg/autogpt"&gt;Discord üí¨&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/autogpt"&gt;&lt;img src="https://invidget.switchblade.xyz/autogpt" alt="Join us on Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;To report a bug or request a feature, create a &lt;a href="https://github.com/Significant-Gravitas/AutoGPT/issues/new/choose"&gt;GitHub Issue&lt;/a&gt;. Please ensure someone else hasn't created an issue for the same topic.&lt;/p&gt; 
&lt;h2&gt;ü§ù Sister projects&lt;/h2&gt; 
&lt;h3&gt;üîÑ Agent Protocol&lt;/h3&gt; 
&lt;p&gt;To maintain a uniform standard and ensure seamless compatibility with many current and future applications, AutoGPT employs the &lt;a href="https://agentprotocol.ai/"&gt;agent protocol&lt;/a&gt; standard by the AI Engineer Foundation. This standardizes the communication pathways from your agent to the frontend and benchmark.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Stars stats&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;a href="https://star-history.com/#Significant-Gravitas/AutoGPT"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Significant-Gravitas/AutoGPT&amp;amp;type=Date" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;‚ö° Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/Significant-Gravitas/AutoGPT/graphs/contributors" alt="View Contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=Significant-Gravitas/AutoGPT&amp;amp;max=1000&amp;amp;columns=10" alt="Contributors" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>harry0703/MoneyPrinterTurbo</title>
      <link>https://github.com/harry0703/MoneyPrinterTurbo</link>
      <description>&lt;p&gt;Âà©Áî®AIÂ§ßÊ®°ÂûãÔºå‰∏ÄÈîÆÁîüÊàêÈ´òÊ∏ÖÁü≠ËßÜÈ¢ë Generate short videos with one click using AI LLM.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1 align="center"&gt;MoneyPrinterTurbo üí∏&lt;/h1&gt; 
 &lt;p align="center"&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;&lt;img src="https://img.shields.io/github/issues/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="License" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;ÁÆÄ‰Ωì‰∏≠Êñá | &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/README-en.md"&gt;English&lt;/a&gt;&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/8731" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/8731" alt="harry0703%2FMoneyPrinterTurbo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; Âè™ÈúÄÊèê‰æõ‰∏Ä‰∏™ËßÜÈ¢ë 
 &lt;b&gt;‰∏ªÈ¢ò&lt;/b&gt; Êàñ 
 &lt;b&gt;ÂÖ≥ÈîÆËØç&lt;/b&gt; ÔºåÂ∞±ÂèØ‰ª•ÂÖ®Ëá™Âä®ÁîüÊàêËßÜÈ¢ëÊñáÊ°à„ÄÅËßÜÈ¢ëÁ¥†Êùê„ÄÅËßÜÈ¢ëÂ≠óÂπï„ÄÅËßÜÈ¢ëËÉåÊôØÈü≥‰πêÔºåÁÑ∂ÂêéÂêàÊàê‰∏Ä‰∏™È´òÊ∏ÖÁöÑÁü≠ËßÜÈ¢ë„ÄÇ 
 &lt;br /&gt; 
 &lt;h4&gt;WebÁïåÈù¢&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/webui.jpg" alt="" /&gt;&lt;/p&gt; 
 &lt;h4&gt;APIÁïåÈù¢&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/api.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ÁâπÂà´ÊÑüË∞¢ üôè&lt;/h2&gt; 
&lt;p&gt;Áî±‰∫éËØ•È°πÁõÆÁöÑ &lt;strong&gt;ÈÉ®ÁΩ≤&lt;/strong&gt; Âíå &lt;strong&gt;‰ΩøÁî®&lt;/strong&gt;ÔºåÂØπ‰∫é‰∏Ä‰∫õÂ∞èÁôΩÁî®Êà∑Êù•ËØ¥ÔºåËøòÊòØ &lt;strong&gt;Êúâ‰∏ÄÂÆöÁöÑÈó®Êßõ&lt;/strong&gt;ÔºåÂú®Ê≠§ÁâπÂà´ÊÑüË∞¢ &lt;strong&gt;ÂΩïÂíñÔºàAIÊô∫ËÉΩ Â§öÂ™í‰ΩìÊúçÂä°Âπ≥Âè∞Ôºâ&lt;/strong&gt; ÁΩëÁ´ôÂü∫‰∫éËØ•È°πÁõÆÔºåÊèê‰æõÁöÑÂÖçË¥π&lt;code&gt;AIËßÜÈ¢ëÁîüÊàêÂô®&lt;/code&gt;ÊúçÂä°ÔºåÂèØ‰ª•‰∏çÁî®ÈÉ®ÁΩ≤ÔºåÁõ¥Êé•Âú®Á∫ø‰ΩøÁî®ÔºåÈùûÂ∏∏Êñπ‰æø„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‰∏≠ÊñáÁâàÔºö&lt;a href="https://reccloud.cn"&gt;https://reccloud.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ëã±ÊñáÁâàÔºö&lt;a href="https://reccloud.com"&gt;https://reccloud.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/reccloud.cn.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;ÊÑüË∞¢ËµûÂä© üôè&lt;/h2&gt; 
&lt;p&gt;ÊÑüË∞¢‰ΩêÁ≥ñ &lt;a href="https://picwish.cn"&gt;https://picwish.cn&lt;/a&gt; ÂØπËØ•È°πÁõÆÁöÑÊîØÊåÅÂíåËµûÂä©Ôºå‰ΩøÂæóËØ•È°πÁõÆËÉΩÂ§üÊåÅÁª≠ÁöÑÊõ¥Êñ∞ÂíåÁª¥Êä§„ÄÇ&lt;/p&gt; 
&lt;p&gt;‰ΩêÁ≥ñ‰∏ìÊ≥®‰∫é&lt;strong&gt;ÂõæÂÉèÂ§ÑÁêÜÈ¢ÜÂüü&lt;/strong&gt;ÔºåÊèê‰æõ‰∏∞ÂØåÁöÑ&lt;strong&gt;ÂõæÂÉèÂ§ÑÁêÜÂ∑•ÂÖ∑&lt;/strong&gt;ÔºåÂ∞ÜÂ§çÊùÇÊìç‰ΩúÊûÅËá¥ÁÆÄÂåñÔºåÁúüÊ≠£ÂÆûÁé∞ËÆ©ÂõæÂÉèÂ§ÑÁêÜÊõ¥ÁÆÄÂçï„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/picwish.jpg" alt="picwish.jpg" /&gt;&lt;/p&gt; 
&lt;h2&gt;ÂäüËÉΩÁâπÊÄß üéØ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÂÆåÊï¥ÁöÑ &lt;strong&gt;MVCÊû∂ÊûÑ&lt;/strong&gt;Ôºå‰ª£Á†Å &lt;strong&gt;ÁªìÊûÑÊ∏ÖÊô∞&lt;/strong&gt;ÔºåÊòì‰∫éÁª¥Êä§ÔºåÊîØÊåÅ &lt;code&gt;API&lt;/code&gt; Âíå &lt;code&gt;WebÁïåÈù¢&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅËßÜÈ¢ëÊñáÊ°à &lt;strong&gt;AIËá™Âä®ÁîüÊàê&lt;/strong&gt;Ôºå‰πüÂèØ‰ª•&lt;strong&gt;Ëá™ÂÆö‰πâÊñáÊ°à&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅÂ§öÁßç &lt;strong&gt;È´òÊ∏ÖËßÜÈ¢ë&lt;/strong&gt; Â∞∫ÂØ∏ 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Á´ñÂ±è 9:16Ôºå&lt;code&gt;1080x1920&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Ê®™Â±è 16:9Ôºå&lt;code&gt;1920x1080&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;ÊâπÈáèËßÜÈ¢ëÁîüÊàê&lt;/strong&gt;ÔºåÂèØ‰ª•‰∏ÄÊ¨°ÁîüÊàêÂ§ö‰∏™ËßÜÈ¢ëÔºåÁÑ∂ÂêéÈÄâÊã©‰∏Ä‰∏™ÊúÄÊª°ÊÑèÁöÑ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;ËßÜÈ¢ëÁâáÊÆµÊó∂Èïø&lt;/strong&gt; ËÆæÁΩÆÔºåÊñπ‰æøË∞ÉËäÇÁ¥†ÊùêÂàáÊç¢È¢ëÁéá&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;‰∏≠Êñá&lt;/strong&gt; Âíå &lt;strong&gt;Ëã±Êñá&lt;/strong&gt; ËßÜÈ¢ëÊñáÊ°à&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;Â§öÁßçËØ≠Èü≥&lt;/strong&gt; ÂêàÊàêÔºåÂèØ &lt;strong&gt;ÂÆûÊó∂ËØïÂê¨&lt;/strong&gt; ÊïàÊûú&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;Â≠óÂπïÁîüÊàê&lt;/strong&gt;ÔºåÂèØ‰ª•Ë∞ÉÊï¥ &lt;code&gt;Â≠ó‰Ωì&lt;/code&gt;„ÄÅ&lt;code&gt;‰ΩçÁΩÆ&lt;/code&gt;„ÄÅ&lt;code&gt;È¢úËâ≤&lt;/code&gt;„ÄÅ&lt;code&gt;Â§ßÂ∞è&lt;/code&gt;ÔºåÂêåÊó∂ÊîØÊåÅ&lt;code&gt;Â≠óÂπïÊèèËæπ&lt;/code&gt;ËÆæÁΩÆ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;ËÉåÊôØÈü≥‰πê&lt;/strong&gt;ÔºåÈöèÊú∫ÊàñËÄÖÊåáÂÆöÈü≥‰πêÊñá‰ª∂ÔºåÂèØËÆæÁΩÆ&lt;code&gt;ËÉåÊôØÈü≥‰πêÈü≥Èáè&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ËßÜÈ¢ëÁ¥†ÊùêÊù•Ê∫ê &lt;strong&gt;È´òÊ∏Ö&lt;/strong&gt;ÔºåËÄå‰∏î &lt;strong&gt;Êó†ÁâàÊùÉ&lt;/strong&gt;Ôºå‰πüÂèØ‰ª•‰ΩøÁî®Ëá™Â∑±ÁöÑ &lt;strong&gt;Êú¨Âú∞Á¥†Êùê&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ÊîØÊåÅ &lt;strong&gt;OpenAI&lt;/strong&gt;„ÄÅ&lt;strong&gt;Moonshot&lt;/strong&gt;„ÄÅ&lt;strong&gt;Azure&lt;/strong&gt;„ÄÅ&lt;strong&gt;gpt4free&lt;/strong&gt;„ÄÅ&lt;strong&gt;one-api&lt;/strong&gt;„ÄÅ&lt;strong&gt;ÈÄö‰πâÂçÉÈóÆ&lt;/strong&gt;„ÄÅ&lt;strong&gt;Google Gemini&lt;/strong&gt;„ÄÅ&lt;strong&gt;Ollama&lt;/strong&gt;„ÄÅ&lt;strong&gt;DeepSeek&lt;/strong&gt;„ÄÅ &lt;strong&gt;ÊñáÂøÉ‰∏ÄË®Ä&lt;/strong&gt;, &lt;strong&gt;Pollinations&lt;/strong&gt; Á≠âÂ§öÁßçÊ®°ÂûãÊé•ÂÖ• 
  &lt;ul&gt; 
   &lt;li&gt;‰∏≠ÂõΩÁî®Êà∑Âª∫ËÆÆ‰ΩøÁî® &lt;strong&gt;DeepSeek&lt;/strong&gt; Êàñ &lt;strong&gt;Moonshot&lt;/strong&gt; ‰Ωú‰∏∫Â§ßÊ®°ÂûãÊèê‰æõÂïÜÔºàÂõΩÂÜÖÂèØÁõ¥Êé•ËÆøÈóÆÔºå‰∏çÈúÄË¶ÅVPN„ÄÇÊ≥®ÂÜåÂ∞±ÈÄÅÈ¢ùÂ∫¶ÔºåÂü∫Êú¨Â§üÁî®Ôºâ&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ÂêéÊúüËÆ°Âàí üìÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; GPT-SoVITS ÈÖçÈü≥ÊîØÊåÅ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; ‰ºòÂåñËØ≠Èü≥ÂêàÊàêÔºåÂà©Áî®Â§ßÊ®°ÂûãÔºå‰ΩøÂÖ∂ÂêàÊàêÁöÑÂ£∞Èü≥ÔºåÊõ¥Âä†Ëá™ÁÑ∂ÔºåÊÉÖÁª™Êõ¥Âä†‰∏∞ÂØå&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Â¢ûÂä†ËßÜÈ¢ëËΩ¨Âú∫ÊïàÊûúÔºå‰ΩøÂÖ∂ÁúãËµ∑Êù•Êõ¥Âä†ÁöÑÊµÅÁïÖ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Â¢ûÂä†Êõ¥Â§öËßÜÈ¢ëÁ¥†ÊùêÊù•Ê∫êÔºå‰ºòÂåñËßÜÈ¢ëÁ¥†ÊùêÂíåÊñáÊ°àÁöÑÂåπÈÖçÂ∫¶&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Â¢ûÂä†ËßÜÈ¢ëÈïøÂ∫¶ÈÄâÈ°πÔºöÁü≠„ÄÅ‰∏≠„ÄÅÈïø&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; ÊîØÊåÅÊõ¥Â§öÁöÑËØ≠Èü≥ÂêàÊàêÊúçÂä°ÂïÜÔºåÊØîÂ¶Ç OpenAI TTS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Ëá™Âä®‰∏ä‰º†Âà∞YouTubeÂπ≥Âè∞&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ËßÜÈ¢ëÊºîÁ§∫ üì∫&lt;/h2&gt; 
&lt;h3&gt;Á´ñÂ±è 9:16&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ‚ñ∂Ô∏è
    &lt;/g-emoji&gt; „ÄäÂ¶Ç‰ΩïÂ¢ûÂä†ÁîüÊ¥ªÁöÑ‰πêË∂£„Äã&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ‚ñ∂Ô∏è
    &lt;/g-emoji&gt; „ÄäÈáëÈí±ÁöÑ‰ΩúÁî®„Äã&lt;br /&gt;Êõ¥ÁúüÂÆûÁöÑÂêàÊàêÂ£∞Èü≥&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ‚ñ∂Ô∏è
    &lt;/g-emoji&gt; „ÄäÁîüÂëΩÁöÑÊÑè‰πâÊòØ‰ªÄ‰πà„Äã&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/a84d33d5-27a2-4aba-8fd0-9fb2bd91c6a6"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/af2f3b0b-002e-49fe-b161-18ba91c055e8"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/112c9564-d52b-4472-99ad-970b75f66476"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Ê®™Â±è 16:9&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ‚ñ∂Ô∏è
    &lt;/g-emoji&gt;„ÄäÁîüÂëΩÁöÑÊÑè‰πâÊòØ‰ªÄ‰πà„Äã&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     ‚ñ∂Ô∏è
    &lt;/g-emoji&gt;„Ää‰∏∫‰ªÄ‰πàË¶ÅËøêÂä®„Äã&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/346ebb15-c55f-47a9-a653-114f08bb8073"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/271f2fae-8283-44a0-8aa0-0ed8f9a6fa87"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ÈÖçÁΩÆË¶ÅÊ±Ç üì¶&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âª∫ËÆÆÊúÄ‰Ωé CPU &lt;strong&gt;4Ê†∏&lt;/strong&gt; Êàñ‰ª•‰∏äÔºåÂÜÖÂ≠ò &lt;strong&gt;4G&lt;/strong&gt; Êàñ‰ª•‰∏äÔºåÊòæÂç°ÈùûÂøÖÈ°ª&lt;/li&gt; 
 &lt;li&gt;Windows 10 Êàñ MacOS 11.0 ‰ª•‰∏äÁ≥ªÁªü&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Âø´ÈÄüÂºÄÂßã üöÄ&lt;/h2&gt; 
&lt;h3&gt;Âú® Google Colab ‰∏≠ËøêË°å&lt;/h3&gt; 
&lt;p&gt;ÂÖçÂéªÊú¨Âú∞ÁéØÂ¢ÉÈÖçÁΩÆÔºåÁÇπÂáªÁõ¥Êé•Âú® Google Colab ‰∏≠Âø´ÈÄü‰ΩìÈ™å MoneyPrinterTurbo&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/github/harry0703/MoneyPrinterTurbo/blob/main/docs/MoneyPrinterTurbo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open in Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windows‰∏ÄÈîÆÂêØÂä®ÂåÖ&lt;/h3&gt; 
&lt;p&gt;‰∏ãËΩΩ‰∏ÄÈîÆÂêØÂä®ÂåÖÔºåËß£ÂéãÁõ¥Êé•‰ΩøÁî®ÔºàË∑ØÂæÑ‰∏çË¶ÅÊúâ &lt;strong&gt;‰∏≠Êñá&lt;/strong&gt;„ÄÅ&lt;strong&gt;ÁâπÊÆäÂ≠óÁ¨¶&lt;/strong&gt;„ÄÅ&lt;strong&gt;Á©∫Ê†º&lt;/strong&gt;Ôºâ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÁôæÂ∫¶ÁΩëÁõòÔºàv1.2.6Ôºâ: &lt;a href="https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx"&gt;https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx&lt;/a&gt; ÊèêÂèñÁ†Å: sbqx&lt;/li&gt; 
 &lt;li&gt;Google Drive (v1.2.6): &lt;a href="https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing"&gt;https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‰∏ãËΩΩÂêéÔºåÂª∫ËÆÆÂÖà&lt;strong&gt;ÂèåÂáªÊâßË°å&lt;/strong&gt; &lt;code&gt;update.bat&lt;/code&gt; Êõ¥Êñ∞Âà∞&lt;strong&gt;ÊúÄÊñ∞‰ª£Á†Å&lt;/strong&gt;ÔºåÁÑ∂ÂêéÂèåÂáª &lt;code&gt;start.bat&lt;/code&gt; ÂêØÂä®&lt;/p&gt; 
&lt;p&gt;ÂêØÂä®ÂêéÔºå‰ºöËá™Âä®ÊâìÂºÄÊµèËßàÂô®ÔºàÂ¶ÇÊûúÊâìÂºÄÊòØÁ©∫ÁôΩÔºåÂª∫ËÆÆÊç¢Êàê &lt;strong&gt;Chrome&lt;/strong&gt; ÊàñËÄÖ &lt;strong&gt;Edge&lt;/strong&gt; ÊâìÂºÄÔºâ&lt;/p&gt; 
&lt;h2&gt;ÂÆâË£ÖÈÉ®ÁΩ≤ üì•&lt;/h2&gt; 
&lt;h3&gt;ÂâçÊèêÊù°‰ª∂&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Â∞ΩÈáè‰∏çË¶Å‰ΩøÁî® &lt;strong&gt;‰∏≠ÊñáË∑ØÂæÑ&lt;/strong&gt;ÔºåÈÅøÂÖçÂá∫Áé∞‰∏Ä‰∫õÊó†Ê≥ïÈ¢ÑÊñôÁöÑÈóÆÈ¢ò&lt;/li&gt; 
 &lt;li&gt;ËØ∑Á°Æ‰øù‰Ω†ÁöÑ &lt;strong&gt;ÁΩëÁªú&lt;/strong&gt; ÊòØÊ≠£Â∏∏ÁöÑÔºåVPNÈúÄË¶ÅÊâìÂºÄ&lt;code&gt;ÂÖ®Â±ÄÊµÅÈáè&lt;/code&gt;Ê®°Âºè&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ë† ÂÖãÈöÜ‰ª£Á†Å&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° ‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂ÔºàÂèØÈÄâÔºåÂª∫ËÆÆÂêØÂä®Âêé‰πüÂèØ‰ª•Âú® WebUI ÈáåÈù¢ÈÖçÁΩÆÔºâ&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Â∞Ü &lt;code&gt;config.example.toml&lt;/code&gt; Êñá‰ª∂Â§çÂà∂‰∏Ä‰ªΩÔºåÂëΩÂêç‰∏∫ &lt;code&gt;config.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;ÊåâÁÖß &lt;code&gt;config.toml&lt;/code&gt; Êñá‰ª∂‰∏≠ÁöÑËØ¥ÊòéÔºåÈÖçÁΩÆÂ•Ω &lt;code&gt;pexels_api_keys&lt;/code&gt; Âíå &lt;code&gt;llm_provider&lt;/code&gt;ÔºåÂπ∂Ê†πÊçÆ llm_provider ÂØπÂ∫îÁöÑÊúçÂä°ÂïÜÔºåÈÖçÁΩÆÁõ∏ÂÖ≥ÁöÑ API Key&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;DockerÈÉ®ÁΩ≤ üê≥&lt;/h3&gt; 
&lt;h4&gt;‚ë† ÂêØÂä®Docker&lt;/h4&gt; 
&lt;p&gt;Â¶ÇÊûúÊú™ÂÆâË£Ö DockerÔºåËØ∑ÂÖàÂÆâË£Ö &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;https://www.docker.com/products/docker-desktop/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Â¶ÇÊûúÊòØWindowsÁ≥ªÁªüÔºåËØ∑ÂèÇËÄÉÂæÆËΩØÁöÑÊñáÊ°£Ôºö&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/install"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd MoneyPrinterTurbo
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®ÊÑèÔºöÊúÄÊñ∞ÁâàÁöÑdockerÂÆâË£ÖÊó∂‰ºöËá™Âä®‰ª•Êèí‰ª∂ÁöÑÂΩ¢ÂºèÂÆâË£Ödocker composeÔºåÂêØÂä®ÂëΩ‰ª§Ë∞ÉÊï¥‰∏∫docker compose up&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;‚ë° ËÆøÈóÆWebÁïåÈù¢&lt;/h4&gt; 
&lt;p&gt;ÊâìÂºÄÊµèËßàÂô®ÔºåËÆøÈóÆ &lt;a href="http://0.0.0.0:8501"&gt;http://0.0.0.0:8501&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;‚ë¢ ËÆøÈóÆAPIÊñáÊ°£&lt;/h4&gt; 
&lt;p&gt;ÊâìÂºÄÊµèËßàÂô®ÔºåËÆøÈóÆ &lt;a href="http://0.0.0.0:8080/docs"&gt;http://0.0.0.0:8080/docs&lt;/a&gt; ÊàñËÄÖ &lt;a href="http://0.0.0.0:8080/redoc"&gt;http://0.0.0.0:8080/redoc&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;ÊâãÂä®ÈÉ®ÁΩ≤ üì¶&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËßÜÈ¢ëÊïôÁ®ã&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÂÆåÊï¥ÁöÑ‰ΩøÁî®ÊºîÁ§∫Ôºö&lt;a href="https://v.douyin.com/iFhnwsKY/"&gt;https://v.douyin.com/iFhnwsKY/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Â¶Ç‰ΩïÂú®Windows‰∏äÈÉ®ÁΩ≤Ôºö&lt;a href="https://v.douyin.com/iFyjoW3M"&gt;https://v.douyin.com/iFyjoW3M&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ë† ÂàõÂª∫ËôöÊãüÁéØÂ¢É&lt;/h4&gt; 
&lt;p&gt;Âª∫ËÆÆ‰ΩøÁî® &lt;a href="https://conda.io/projects/conda/en/latest/user-guide/install/index.html"&gt;conda&lt;/a&gt; ÂàõÂª∫ python ËôöÊãüÁéØÂ¢É&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
cd MoneyPrinterTurbo
conda create -n MoneyPrinterTurbo python=3.11
conda activate MoneyPrinterTurbo
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;‚ë° ÂÆâË£ÖÂ•Ω ImageMagick&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;‰∏ãËΩΩ &lt;a href="https://imagemagick.org/script/download.php"&gt;https://imagemagick.org/script/download.php&lt;/a&gt; ÈÄâÊã©WindowsÁâàÊú¨ÔºåÂàáËÆ∞‰∏ÄÂÆöË¶ÅÈÄâÊã© &lt;strong&gt;ÈùôÊÄÅÂ∫ì&lt;/strong&gt; ÁâàÊú¨ÔºåÊØîÂ¶Ç ImageMagick-7.1.1-32-Q16-x64-&lt;strong&gt;static&lt;/strong&gt;.exe&lt;/li&gt; 
   &lt;li&gt;ÂÆâË£Ö‰∏ãËΩΩÂ•ΩÁöÑ ImageMagickÔºå&lt;strong&gt;Ê≥®ÊÑè‰∏çË¶Å‰øÆÊîπÂÆâË£ÖË∑ØÂæÑ&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;‰øÆÊîπ &lt;code&gt;ÈÖçÁΩÆÊñá‰ª∂ config.toml&lt;/code&gt; ‰∏≠ÁöÑ &lt;code&gt;imagemagick_path&lt;/code&gt; ‰∏∫‰Ω†ÁöÑ &lt;strong&gt;ÂÆûÈôÖÂÆâË£ÖË∑ØÂæÑ&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MacOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;brew install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ubuntu&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo apt-get install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CentOS&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo yum install ImageMagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;‚ë¢ ÂêØÂä®WebÁïåÈù¢ üåê&lt;/h4&gt; 
&lt;p&gt;Ê≥®ÊÑèÈúÄË¶ÅÂà∞ MoneyPrinterTurbo È°πÁõÆ &lt;code&gt;Ê†πÁõÆÂΩï&lt;/code&gt; ‰∏ãÊâßË°å‰ª•‰∏ãÂëΩ‰ª§&lt;/p&gt; 
&lt;h6&gt;Windows&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-bat"&gt;webui.bat
&lt;/code&gt;&lt;/pre&gt; 
&lt;h6&gt;MacOS or Linux&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sh webui.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂêØÂä®ÂêéÔºå‰ºöËá™Âä®ÊâìÂºÄÊµèËßàÂô®ÔºàÂ¶ÇÊûúÊâìÂºÄÊòØÁ©∫ÁôΩÔºåÂª∫ËÆÆÊç¢Êàê &lt;strong&gt;Chrome&lt;/strong&gt; ÊàñËÄÖ &lt;strong&gt;Edge&lt;/strong&gt; ÊâìÂºÄÔºâ&lt;/p&gt; 
&lt;h4&gt;‚ë£ ÂêØÂä®APIÊúçÂä° üöÄ&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂêØÂä®ÂêéÔºåÂèØ‰ª•Êü•Áúã &lt;code&gt;APIÊñáÊ°£&lt;/code&gt; &lt;a href="http://127.0.0.1:8080/docs"&gt;http://127.0.0.1:8080/docs&lt;/a&gt; ÊàñËÄÖ &lt;a href="http://127.0.0.1:8080/redoc"&gt;http://127.0.0.1:8080/redoc&lt;/a&gt; Áõ¥Êé•Âú®Á∫øË∞ÉËØïÊé•Âè£ÔºåÂø´ÈÄü‰ΩìÈ™å„ÄÇ&lt;/p&gt; 
&lt;h2&gt;ËØ≠Èü≥ÂêàÊàê üó£&lt;/h2&gt; 
&lt;p&gt;ÊâÄÊúâÊîØÊåÅÁöÑÂ£∞Èü≥ÂàóË°®ÔºåÂèØ‰ª•Êü•ÁúãÔºö&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/voice-list.txt"&gt;Â£∞Èü≥ÂàóË°®&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;2024-04-16 v1.1.2 Êñ∞Â¢û‰∫Ü9ÁßçAzureÁöÑËØ≠Èü≥ÂêàÊàêÂ£∞Èü≥ÔºåÈúÄË¶ÅÈÖçÁΩÆAPI KEYÔºåËØ•Â£∞Èü≥ÂêàÊàêÁöÑÊõ¥Âä†ÁúüÂÆû„ÄÇ&lt;/p&gt; 
&lt;h2&gt;Â≠óÂπïÁîüÊàê üìú&lt;/h2&gt; 
&lt;p&gt;ÂΩìÂâçÊîØÊåÅ2ÁßçÂ≠óÂπïÁîüÊàêÊñπÂºèÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;edge&lt;/strong&gt;: ÁîüÊàê&lt;code&gt;ÈÄüÂ∫¶Âø´&lt;/code&gt;ÔºåÊÄßËÉΩÊõ¥Â•ΩÔºåÂØπÁîµËÑëÈÖçÁΩÆÊ≤°ÊúâË¶ÅÊ±ÇÔºå‰ΩÜÊòØË¥®ÈáèÂèØËÉΩ‰∏çÁ®≥ÂÆö&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;whisper&lt;/strong&gt;: ÁîüÊàê&lt;code&gt;ÈÄüÂ∫¶ÊÖ¢&lt;/code&gt;ÔºåÊÄßËÉΩËæÉÂ∑ÆÔºåÂØπÁîµËÑëÈÖçÁΩÆÊúâ‰∏ÄÂÆöË¶ÅÊ±ÇÔºå‰ΩÜÊòØ&lt;code&gt;Ë¥®ÈáèÊõ¥ÂèØÈù†&lt;/code&gt;„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ÂèØ‰ª•‰øÆÊîπ &lt;code&gt;config.toml&lt;/code&gt; ÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑ &lt;code&gt;subtitle_provider&lt;/code&gt; ËøõË°åÂàáÊç¢&lt;/p&gt; 
&lt;p&gt;Âª∫ËÆÆ‰ΩøÁî® &lt;code&gt;edge&lt;/code&gt; Ê®°ÂºèÔºåÂ¶ÇÊûúÁîüÊàêÁöÑÂ≠óÂπïË¥®Èáè‰∏çÂ•ΩÔºåÂÜçÂàáÊç¢Âà∞ &lt;code&gt;whisper&lt;/code&gt; Ê®°Âºè&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®ÊÑèÔºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;whisper Ê®°Âºè‰∏ãÈúÄË¶ÅÂà∞ HuggingFace ‰∏ãËΩΩ‰∏Ä‰∏™Ê®°ÂûãÊñá‰ª∂ÔºåÂ§ßÁ∫¶ 3GB Â∑¶Âè≥ÔºåËØ∑Á°Æ‰øùÁΩëÁªúÈÄöÁïÖ&lt;/li&gt; 
 &lt;li&gt;Â¶ÇÊûúÁïôÁ©∫ÔºåË°®Á§∫‰∏çÁîüÊàêÂ≠óÂπï„ÄÇ&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Áî±‰∫éÂõΩÂÜÖÊó†Ê≥ïËÆøÈóÆ HuggingFaceÔºåÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÊñπÊ≥ï‰∏ãËΩΩ &lt;code&gt;whisper-large-v3&lt;/code&gt; ÁöÑÊ®°ÂûãÊñá‰ª∂&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;‰∏ãËΩΩÂú∞ÂùÄÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÁôæÂ∫¶ÁΩëÁõò: &lt;a href="https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9"&gt;https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Â§∏ÂÖãÁΩëÁõòÔºö&lt;a href="https://pan.quark.cn/s/3ee3d991d64b"&gt;https://pan.quark.cn/s/3ee3d991d64b&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Ê®°Âûã‰∏ãËΩΩÂêéËß£ÂéãÔºåÊï¥‰∏™ÁõÆÂΩïÊîæÂà∞ &lt;code&gt;.\MoneyPrinterTurbo\models&lt;/code&gt; ÈáåÈù¢Ôºå ÊúÄÁªàÁöÑÊñá‰ª∂Ë∑ØÂæÑÂ∫îËØ•ÊòØËøôÊ†∑: &lt;code&gt;.\MoneyPrinterTurbo\models\whisper-large-v3&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MoneyPrinterTurbo  
  ‚îú‚îÄmodels
  ‚îÇ   ‚îî‚îÄwhisper-large-v3
  ‚îÇ          config.json
  ‚îÇ          model.bin
  ‚îÇ          preprocessor_config.json
  ‚îÇ          tokenizer.json
  ‚îÇ          vocabulary.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ËÉåÊôØÈü≥‰πê üéµ&lt;/h2&gt; 
&lt;p&gt;Áî®‰∫éËßÜÈ¢ëÁöÑËÉåÊôØÈü≥‰πêÔºå‰Ωç‰∫éÈ°πÁõÆÁöÑ &lt;code&gt;resource/songs&lt;/code&gt; ÁõÆÂΩï‰∏ã„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÂΩìÂâçÈ°πÁõÆÈáåÈù¢Êîæ‰∫Ü‰∏Ä‰∫õÈªòËÆ§ÁöÑÈü≥‰πêÔºåÊù•Ëá™‰∫é YouTube ËßÜÈ¢ëÔºåÂ¶ÇÊúâ‰æµÊùÉÔºåËØ∑Âà†Èô§„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Â≠óÂπïÂ≠ó‰Ωì üÖ∞&lt;/h2&gt; 
&lt;p&gt;Áî®‰∫éËßÜÈ¢ëÂ≠óÂπïÁöÑÊ∏≤ÊüìÔºå‰Ωç‰∫éÈ°πÁõÆÁöÑ &lt;code&gt;resource/fonts&lt;/code&gt; ÁõÆÂΩï‰∏ãÔºå‰Ω†‰πüÂèØ‰ª•ÊîæËøõÂéªËá™Â∑±ÁöÑÂ≠ó‰Ωì„ÄÇ&lt;/p&gt; 
&lt;h2&gt;Â∏∏ËßÅÈóÆÈ¢ò ü§î&lt;/h2&gt; 
&lt;h3&gt;‚ùìRuntimeError: No ffmpeg exe could be found&lt;/h3&gt; 
&lt;p&gt;ÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÔºåffmpeg ‰ºöË¢´Ëá™Âä®‰∏ãËΩΩÔºåÂπ∂‰∏î‰ºöË¢´Ëá™Âä®Ê£ÄÊµãÂà∞„ÄÇ ‰ΩÜÊòØÂ¶ÇÊûú‰Ω†ÁöÑÁéØÂ¢ÉÊúâÈóÆÈ¢òÔºåÊó†Ê≥ïËá™Âä®‰∏ãËΩΩÔºåÂèØËÉΩ‰ºöÈÅáÂà∞Â¶Ç‰∏ãÈîôËØØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;RuntimeError: No ffmpeg exe could be found.
Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ê≠§Êó∂‰Ω†ÂèØ‰ª•‰ªé &lt;a href="https://www.gyan.dev/ffmpeg/builds/"&gt;https://www.gyan.dev/ffmpeg/builds/&lt;/a&gt; ‰∏ãËΩΩffmpegÔºåËß£ÂéãÂêéÔºåËÆæÁΩÆ &lt;code&gt;ffmpeg_path&lt;/code&gt; ‰∏∫‰Ω†ÁöÑÂÆûÈôÖÂÆâË£ÖË∑ØÂæÑÂç≥ÂèØ„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[app]
# ËØ∑Ê†πÊçÆ‰Ω†ÁöÑÂÆûÈôÖË∑ØÂæÑËÆæÁΩÆÔºåÊ≥®ÊÑè Windows Ë∑ØÂæÑÂàÜÈöîÁ¨¶‰∏∫ \\
ffmpeg_path = "C:\\Users\\harry\\Downloads\\ffmpeg.exe"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ùìImageMagickÁöÑÂÆâÂÖ®Á≠ñÁï•ÈòªÊ≠¢‰∫Ü‰∏é‰∏¥Êó∂Êñá‰ª∂@/tmp/tmpur5hyyto.txtÁõ∏ÂÖ≥ÁöÑÊìç‰Ωú&lt;/h3&gt; 
&lt;p&gt;ÂèØ‰ª•Âú®ImageMagickÁöÑÈÖçÁΩÆÊñá‰ª∂policy.xml‰∏≠ÊâæÂà∞Ëøô‰∫õÁ≠ñÁï•„ÄÇ Ëøô‰∏™Êñá‰ª∂ÈÄöÂ∏∏‰Ωç‰∫é /etc/ImageMagick-&lt;code&gt;X&lt;/code&gt;/ Êàñ ImageMagick ÂÆâË£ÖÁõÆÂΩïÁöÑÁ±ª‰ºº‰ΩçÁΩÆ„ÄÇ ‰øÆÊîπÂåÖÂê´&lt;code&gt;pattern="@"&lt;/code&gt;ÁöÑÊù°ÁõÆÔºåÂ∞Ü&lt;code&gt;rights="none"&lt;/code&gt;Êõ¥Êîπ‰∏∫&lt;code&gt;rights="read|write"&lt;/code&gt;‰ª•ÂÖÅËÆ∏ÂØπÊñá‰ª∂ÁöÑËØªÂÜôÊìç‰Ωú„ÄÇ&lt;/p&gt; 
&lt;h3&gt;‚ùìOSError: [Errno 24] Too many open files&lt;/h3&gt; 
&lt;p&gt;Ëøô‰∏™ÈóÆÈ¢òÊòØÁî±‰∫éÁ≥ªÁªüÊâìÂºÄÊñá‰ª∂Êï∞ÈôêÂà∂ÂØºËá¥ÁöÑÔºåÂèØ‰ª•ÈÄöËøá‰øÆÊîπÁ≥ªÁªüÁöÑÊñá‰ª∂ÊâìÂºÄÊï∞ÈôêÂà∂Êù•Ëß£ÂÜ≥„ÄÇ&lt;/p&gt; 
&lt;p&gt;Êü•ÁúãÂΩìÂâçÈôêÂà∂&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Â¶ÇÊûúËøá‰ΩéÔºåÂèØ‰ª•Ë∞ÉÈ´ò‰∏Ä‰∫õÔºåÊØîÂ¶Ç&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n 10240
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;‚ùìWhisper Ê®°Âûã‰∏ãËΩΩÂ§±Ë¥•ÔºåÂá∫Áé∞Â¶Ç‰∏ãÈîôËØØ&lt;/h3&gt; 
&lt;p&gt;LocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and outgoing trafic has been disabled. To enablerepo look-ups and downloads online, pass 'local files only=False' as input.&lt;/p&gt; 
&lt;p&gt;ÊàñËÄÖ&lt;/p&gt; 
&lt;p&gt;An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Trying to load the model directly from the local cache, if it exists.&lt;/p&gt; 
&lt;p&gt;Ëß£ÂÜ≥ÊñπÊ≥ïÔºö&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/#%E5%AD%97%E5%B9%95%E7%94%9F%E6%88%90-"&gt;ÁÇπÂáªÊü•ÁúãÂ¶Ç‰Ωï‰ªéÁΩëÁõòÊâãÂä®‰∏ãËΩΩÊ®°Âûã&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ÂèçÈ¶àÂª∫ËÆÆ üì¢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÂèØ‰ª•Êèê‰∫§ &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;issue&lt;/a&gt; ÊàñËÄÖ &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/pulls"&gt;pull request&lt;/a&gt;„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ËÆ∏ÂèØËØÅ üìù&lt;/h2&gt; 
&lt;p&gt;ÁÇπÂáªÊü•Áúã &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; Êñá‰ª∂&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#harry0703/MoneyPrinterTurbo&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=harry0703/MoneyPrinterTurbo&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>onyx-dot-app/onyx</title>
      <link>https://github.com/onyx-dot-app/onyx</link>
      <description>&lt;p&gt;Open Source AI Platform - AI Chat with advanced features that works with every LLM&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt; &lt;a href="https://www.onyx.app/"&gt; &lt;img width="50%" src="https://github.com/onyx-dot-app/onyx/raw/logo/OnyxLogoCropped.jpg?raw=true)" /&gt;&lt;/a&gt; &lt;/h2&gt; 
&lt;p align="center"&gt;Open Source AI Platform&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/TDJ59cGV2X" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/discord-join-blue.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt; &lt;/a&gt; &lt;a href="https://docs.onyx.app/" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/docs-view-blue" alt="Documentation" /&gt; &lt;/a&gt; &lt;a href="https://docs.onyx.app/" target="_blank"&gt; &lt;img src="https://img.shields.io/website?url=https://www.onyx.app&amp;amp;up_message=visit&amp;amp;up_color=blue" alt="Documentation" /&gt; &lt;/a&gt; &lt;a href="https://github.com/onyx-dot-app/onyx/raw/main/LICENSE" target="_blank"&gt; &lt;img src="https://img.shields.io/static/v1?label=license&amp;amp;message=MIT&amp;amp;color=blue" alt="License" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.onyx.app/"&gt;Onyx&lt;/a&gt;&lt;/strong&gt; is a feature-rich, self-hostable Chat UI that works with any LLM. It is easy to deploy and can run in a completely airgapped environment.&lt;/p&gt; 
&lt;p&gt;Onyx comes loaded with advanced features like Agents, Web Search, RAG, MCP, Deep Research, Connectors to 40+ knowledge sources, and more.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Run Onyx with one command (or see deployment section below):&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;curl -fsSL https://raw.githubusercontent.com/onyx-dot-app/onyx/main/deployment/docker_compose/install.sh &amp;gt; install.sh &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;img src="https://github.com/onyx-dot-app/onyx/releases/download/v0.21.1/OnyxChatSilentDemo.gif" alt="Onyx Chat Silent Demo" /&gt;&lt;/p&gt; 
&lt;h2&gt;‚≠ê Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Custom Agents:&lt;/strong&gt; Build AI Agents with unique instructions, knowledge and actions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåç Web Search:&lt;/strong&gt; Browse the web with Google PSE, Exa, and Serper as well as an in-house scraper or Firecrawl.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç RAG:&lt;/strong&gt; Best in class hybrid-search + knowledge graph for uploaded files and ingested documents from connectors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîÑ Connectors:&lt;/strong&gt; Pull knowledge, metadata, and access information from over 40 applications.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üî¨ Deep Research:&lt;/strong&gt; Get in depth answers with an agentic multi-step search.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;‚ñ∂Ô∏è Actions &amp;amp; MCP:&lt;/strong&gt; Give AI Agents the ability to interact with external systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üíª Code Interpreter:&lt;/strong&gt; Execute code to analyze data, render graphs and create files.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üé® Image Generation:&lt;/strong&gt; Generate images based on user prompts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üë• Collaboration:&lt;/strong&gt; Chat sharing, feedback gathering, user management, usage analytics, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Onyx works with all LLMs (like OpenAI, Anthropic, Gemini, etc.) and self-hosted LLMs (like Ollama, vLLM, etc.)&lt;/p&gt; 
&lt;p&gt;To learn more about the features, check out our &lt;a href="https://docs.onyx.app/welcome"&gt;documentation&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;üöÄ Deployment&lt;/h2&gt; 
&lt;p&gt;Onyx supports deployments in Docker, Kubernetes, Terraform, along with guides for major cloud providers.&lt;/p&gt; 
&lt;p&gt;See guides below:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.onyx.app/deployment/local/docker"&gt;Docker&lt;/a&gt; or &lt;a href="https://docs.onyx.app/deployment/getting_started/quickstart"&gt;Quickstart&lt;/a&gt; (best for most users)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.onyx.app/deployment/local/kubernetes"&gt;Kubernetes&lt;/a&gt; (best for large teams)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.onyx.app/deployment/local/terraform"&gt;Terraform&lt;/a&gt; (best for teams already using Terraform)&lt;/li&gt; 
 &lt;li&gt;Cloud specific guides (best if specifically using &lt;a href="https://docs.onyx.app/deployment/cloud/aws/eks"&gt;AWS EKS&lt;/a&gt;, &lt;a href="https://docs.onyx.app/deployment/cloud/azure"&gt;Azure VMs&lt;/a&gt;, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;br /&gt; &lt;strong&gt;To try Onyx for free without deploying, check out &lt;a href="https://cloud.onyx.app/signup"&gt;Onyx Cloud&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;üîç Other Notable Benefits&lt;/h2&gt; 
&lt;p&gt;Onyx is built for teams of all sizes, from individual users to the largest global enterprises.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise Search&lt;/strong&gt;: far more than simple RAG, Onyx has custom indexing and retrieval that remains performant and accurate for scales of up to tens of millions of documents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: SSO (OIDC/SAML/OAuth2), RBAC, encryption of credentials, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Management UI&lt;/strong&gt;: different user roles such as basic, curator, and admin.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document Permissioning&lt;/strong&gt;: mirrors user access from external apps for RAG use cases.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöß Roadmap&lt;/h2&gt; 
&lt;p&gt;To see ongoing and upcoming projects, check out our &lt;a href="https://github.com/orgs/onyx-dot-app/projects/2"&gt;roadmap&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;üìö Licensing&lt;/h2&gt; 
&lt;p&gt;There are two editions of Onyx:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Onyx Community Edition (CE) is available freely under the MIT license.&lt;/li&gt; 
 &lt;li&gt;Onyx Enterprise Edition (EE) includes extra features that are primarily useful for larger organizations. For feature details, check out &lt;a href="https://www.onyx.app/pricing"&gt;our website&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üë™ Community&lt;/h2&gt; 
&lt;p&gt;Join our open source community on &lt;strong&gt;&lt;a href="https://discord.gg/TDJ59cGV2X"&gt;Discord&lt;/a&gt;&lt;/strong&gt;!&lt;/p&gt; 
&lt;h2&gt;üí° Contributing&lt;/h2&gt; 
&lt;p&gt;Looking to contribute? Please check out the &lt;a href="https://raw.githubusercontent.com/onyx-dot-app/onyx/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>streamlit/streamlit</title>
      <link>https://github.com/streamlit/streamlit</link>
      <description>&lt;p&gt;Streamlit ‚Äî A faster way to build and share data apps.&lt;/p&gt;&lt;hr&gt;&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/7164864/217935870-c0bc60a3-6fc0-4047-b011-7b4c59488c91.png" alt="Streamlit logo" style="margin-top:50px" /&gt;&lt;/p&gt; 
&lt;h1&gt;Welcome to Streamlit üëã&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;A faster way to build and share data apps.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;What is Streamlit?&lt;/h2&gt; 
&lt;p&gt;Streamlit lets you transform Python scripts into interactive web apps in minutes, instead of weeks. Build dashboards, generate reports, or create chat apps. Once you‚Äôve created an app, you can use our &lt;a href="https://streamlit.io/cloud"&gt;Community Cloud platform&lt;/a&gt; to deploy, manage, and share your app.&lt;/p&gt; 
&lt;h3&gt;Why choose Streamlit?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Simple and Pythonic:&lt;/strong&gt; Write beautiful, easy-to-read code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast, interactive prototyping:&lt;/strong&gt; Let others interact with your data and provide feedback quickly.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Live editing:&lt;/strong&gt; See your app update instantly as you edit your script.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open-source and free:&lt;/strong&gt; Join a vibrant community and contribute to Streamlit's future.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Open a terminal and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ pip install streamlit
$ streamlit hello
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If this opens our sweet &lt;em&gt;Streamlit Hello&lt;/em&gt; app in your browser, you're all set! If not, head over to &lt;a href="https://docs.streamlit.io/get-started"&gt;our docs&lt;/a&gt; for specific installs.&lt;/p&gt; 
&lt;p&gt;The app features a bunch of examples of what you can do with Streamlit. Jump to the &lt;a href="https://raw.githubusercontent.com/streamlit/streamlit/develop/#quickstart"&gt;quickstart&lt;/a&gt; section to understand how that all works.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/7164864/217936487-1017784e-68ec-4e0d-a7f6-6b97525ddf88.gif" alt="Streamlit Hello" width="500" href="none" /&gt;&lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;A little example&lt;/h3&gt; 
&lt;p&gt;Create a new file named &lt;code&gt;streamlit_app.py&lt;/code&gt; in your project directory with the following code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import streamlit as st
x = st.slider("Select a value")
st.write(x, "squared is", x * x)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now run it to open the app!&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ streamlit run streamlit_app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/7164864/215172915-cf087c56-e7ae-449a-83a4-b5fa0328d954.gif" width="300" alt="Little example" /&gt;&lt;/p&gt; 
&lt;h3&gt;Give me more!&lt;/h3&gt; 
&lt;p&gt;Streamlit comes in with &lt;a href="https://docs.streamlit.io/develop/api-reference"&gt;a ton of additional powerful elements&lt;/a&gt; to spice up your data apps and delight your viewers. Some examples:&lt;/p&gt; 
&lt;table border="0"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;a target="_blank" href="https://docs.streamlit.io/develop/api-reference/widgets"&gt; &lt;img src="https://user-images.githubusercontent.com/7164864/217936099-12c16f8c-7fe4-44b1-889a-1ac9ee6a1b44.png" style="max-height:150px; width:auto; display:block;" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a target="_blank" href="https://docs.streamlit.io/develop/api-reference/data/st.dataframe"&gt; &lt;img src="https://user-images.githubusercontent.com/7164864/215110064-5eb4e294-8f30-4933-9563-0275230e52b5.gif" style="max-height:150px; width:auto; display:block;" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a target="_blank" href="https://docs.streamlit.io/develop/api-reference/charts"&gt; &lt;img src="https://user-images.githubusercontent.com/7164864/215174472-bca8a0d7-cf4b-4268-9c3b-8c03dad50bcd.gif" style="max-height:150px; width:auto; display:block;" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a target="_blank" href="https://docs.streamlit.io/develop/api-reference/layout"&gt; &lt;img src="https://user-images.githubusercontent.com/7164864/217936149-a35c35be-0d96-4c63-8c6a-1c4b52aa8f60.png" style="max-height:150px; width:auto; display:block;" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a target="_blank" href="https://docs.streamlit.io/develop/concepts/multipage-apps"&gt; &lt;img src="https://user-images.githubusercontent.com/7164864/215173883-eae0de69-7c1d-4d78-97d0-3bc1ab865e5b.gif" style="max-height:150px; width:auto; display:block;" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;a target="_blank" href="https://streamlit.io/gallery"&gt; &lt;img src="https://user-images.githubusercontent.com/7164864/215109229-6ae9111f-e5c1-4f0b-b3a2-87a79268ccc9.gif" style="max-height:150px; width:auto; display:block;" /&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Input widgets&lt;/td&gt; 
   &lt;td&gt;Dataframes&lt;/td&gt; 
   &lt;td&gt;Charts&lt;/td&gt; 
   &lt;td&gt;Layout&lt;/td&gt; 
   &lt;td&gt;Multi-page apps&lt;/td&gt; 
   &lt;td&gt;Fun&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;Our vibrant creators community also extends Streamlit capabilities using &amp;nbsp;üß© &lt;a href="https://streamlit.io/components"&gt;Streamlit Components&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Get inspired&lt;/h2&gt; 
&lt;p&gt;There's so much you can build with Streamlit:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü§ñ&amp;nbsp;&amp;nbsp;&lt;a href="https://streamlit.io/gallery?category=llms"&gt;LLMs &amp;amp; chatbot apps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß¨&amp;nbsp;&amp;nbsp;&lt;a href="https://streamlit.io/gallery?category=science-technology"&gt;Science &amp;amp; technology apps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí¨&amp;nbsp;&amp;nbsp;&lt;a href="https://streamlit.io/gallery?category=nlp-language"&gt;NLP &amp;amp; language apps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üè¶&amp;nbsp;&amp;nbsp;&lt;a href="https://streamlit.io/gallery?category=finance-business"&gt;Finance &amp;amp; business apps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üó∫&amp;nbsp;&amp;nbsp;&lt;a href="https://streamlit.io/gallery?category=geography-society"&gt;Geography &amp;amp; society apps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;and more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Check out &lt;a href="https://streamlit.io/gallery"&gt;our gallery!&lt;/a&gt;&lt;/strong&gt; üéà&lt;/p&gt; 
&lt;h2&gt;Community Cloud&lt;/h2&gt; 
&lt;p&gt;Deploy, manage and share your apps for free using our &lt;a href="https://streamlit.io/cloud"&gt;Community Cloud&lt;/a&gt;! Sign-up &lt;a href="https://share.streamlit.io/signup"&gt;here&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt; &lt;img src="https://user-images.githubusercontent.com/7164864/214965336-64500db3-0d79-4a20-8052-2dda883902d2.gif" width="400" /&gt;&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Explore our &lt;a href="https://docs.streamlit.io"&gt;docs&lt;/a&gt; to learn how Streamlit works.&lt;/li&gt; 
 &lt;li&gt;Ask questions and get help in our &lt;a href="https://discuss.streamlit.io"&gt;community forum&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Read our &lt;a href="https://blog.streamlit.io"&gt;blog&lt;/a&gt; for tips from developers and creators.&lt;/li&gt; 
 &lt;li&gt;Extend Streamlit's capabilities by installing or creating your own &lt;a href="https://streamlit.io/components"&gt;Streamlit Components&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Help others find and play with your app by using the Streamlit GitHub badge in your repository:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](URL_TO_YOUR_APP)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://share.streamlit.io/streamlit/roadmap"&gt;&lt;img src="https://static.streamlit.io/badges/streamlit_badge_black_white.svg?sanitize=true" alt="Streamlit App" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;üéâ Thanks for your interest in helping improve Streamlit! üéâ&lt;/p&gt; 
&lt;p&gt;Before contributing, please read our guidelines here: &lt;a href="https://github.com/streamlit/streamlit/wiki/Contributing"&gt;https://github.com/streamlit/streamlit/wiki/Contributing&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Streamlit is completely free and open-source and licensed under the &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;Apache 2.0&lt;/a&gt; license.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Asabeneh/30-Days-Of-Python</title>
      <link>https://github.com/Asabeneh/30-Days-Of-Python</link>
      <description>&lt;p&gt;30 days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than100 days, follow your own pace. These videos may help too: https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üêç 30 Days Of Python&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;Learn with Asabeneh by joining the upcoming &lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSf0oNIYR9XU1DCctfl-pY36KbWse-SQX5aQaUgetqSinFYnmQ/viewform"&gt;&lt;em&gt;CODING BOOTCAMP&lt;/em&gt;&lt;/a&gt; &lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;# Day&lt;/th&gt; 
   &lt;th align="center"&gt;Topics&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;01&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/readme.md"&gt;Introduction&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;02&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md"&gt;Variables, Built-in Functions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;03&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/03_Day_Operators/03_operators.md"&gt;Operators&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;04&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/04_Day_Strings/04_strings.md"&gt;Strings&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;05&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/05_Day_Lists/05_lists.md"&gt;Lists&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;06&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/06_Day_Tuples/06_tuples.md"&gt;Tuples&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;07&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/07_Day_Sets/07_sets.md"&gt;Sets&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;08&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/08_Day_Dictionaries/08_dictionaries.md"&gt;Dictionaries&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;09&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/09_Day_Conditionals/09_conditionals.md"&gt;Conditionals&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/10_Day_Loops/10_loops.md"&gt;Loops&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;11&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/11_Day_Functions/11_functions.md"&gt;Functions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/12_Day_Modules/12_modules.md"&gt;Modules&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;13&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/13_Day_List_comprehension/13_list_comprehension.md"&gt;List Comprehension&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/14_Day_Higher_order_functions/14_higher_order_functions.md"&gt;Higher Order Functions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/15_Day_Python_type_errors/15_python_type_errors.md"&gt;Python Type Errors&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/16_Day_Python_date_time/16_python_datetime.md"&gt;Python Date time&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/17_Day_Exception_handling/17_exception_handling.md"&gt;Exception Handling&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/18_Day_Regular_expressions/18_regular_expressions.md"&gt;Regular Expressions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/19_Day_File_handling/19_file_handling.md"&gt;File Handling&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/20_Day_Python_package_manager/20_python_package_manager.md"&gt;Python Package Manager&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;21&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/21_Day_Classes_and_objects/21_classes_and_objects.md"&gt;Classes and Objects&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/22_Day_Web_scraping/22_web_scraping.md"&gt;Web Scraping&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/23_Day_Virtual_environment/23_virtual_environment.md"&gt;Virtual Environment&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/24_Day_Statistics/24_statistics.md"&gt;Statistics&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/25_Day_Pandas/25_pandas.md"&gt;Pandas&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/26_Day_Python_web/26_python_web.md"&gt;Python web&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/27_Day_Python_with_mongodb/27_python_with_mongodb.md"&gt;Python with MongoDB&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/28_Day_API/28_API.md"&gt;API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/29_Day_Building_API/29_building_API.md"&gt;Building API&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;30&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/30_Day_Conclusions/30_conclusions.md"&gt;Conclusions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Learn with Asabeneh by joining the upcoming &lt;a href="https://docs.google.com/forms/d/e/1FAIpQLSf0oNIYR9XU1DCctfl-pY36KbWse-SQX5aQaUgetqSinFYnmQ/viewform"&gt;&lt;em&gt;CODING BOOTCAMP&lt;/em&gt;&lt;/a&gt; &lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;üß°üß°üß° HAPPY CODING üß°üß°üß°&lt;/p&gt; 
&lt;div&gt; 
 &lt;small&gt;Support the &lt;strong&gt;author&lt;/strong&gt; to create more educational materials&lt;/small&gt; 
 &lt;br /&gt; 
 &lt;a href="https://www.paypal.me/asabeneh"&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/paypal_lg.png" alt="Paypal Logo" style="width:10%" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt; 30 Days Of Python: Day 1 - Introduction&lt;/h1&gt; 
 &lt;a class="header-badge" target="_blank" href="https://www.linkedin.com/in/asabeneh/"&gt; &lt;img src="https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&amp;amp;logo=linkedin&amp;amp;style=social" /&gt; &lt;/a&gt; 
 &lt;a class="header-badge" target="_blank" href="https://twitter.com/Asabeneh"&gt; &lt;img alt="Twitter Follow" src="https://img.shields.io/twitter/follow/asabeneh?style=social" /&gt; &lt;/a&gt; 
 &lt;p&gt;&lt;sub&gt;Author: &lt;a href="https://www.linkedin.com/in/asabeneh/" target="_blank"&gt;Asabeneh Yetayeh&lt;/a&gt;&lt;br /&gt; &lt;small&gt; Second Edition: July, 2021&lt;/small&gt; &lt;/sub&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;üáßüá∑ &lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/Portuguese/README.md"&gt;Portuguese&lt;/a&gt; üá®üá≥ &lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/Chinese/README.md"&gt;‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md"&gt;Day 2 &amp;gt;&amp;gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/30DaysOfPython_banner3@2x.png" alt="30DaysOfPython" /&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-30-days-of-python"&gt;üêç 30 Days Of Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-day-1"&gt;üìò Day 1&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#welcome"&gt;Welcome&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#why-python-"&gt;Why Python ?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#environment-setup"&gt;Environment Setup&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#installing-python"&gt;Installing Python&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-shell"&gt;Python Shell&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#installing-visual-studio-code"&gt;Installing Visual Studio Code&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#how-to-use-visual-studio-code"&gt;How to use visual studio code&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#basic-python"&gt;Basic Python&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-syntax"&gt;Python Syntax&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-indentation"&gt;Python Indentation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#comments"&gt;Comments&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#data-types"&gt;Data types&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#number"&gt;Number&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#string"&gt;String&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#booleans"&gt;Booleans&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#list"&gt;List&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#dictionary"&gt;Dictionary&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#tuple"&gt;Tuple&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#set"&gt;Set&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#checking-data-types"&gt;Checking Data types&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#python-file"&gt;Python File&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#-exercises---day-1"&gt;üíª Exercises - Day 1&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-1"&gt;Exercise: Level 1&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-2"&gt;Exercise: Level 2&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/#exercise-level-3"&gt;Exercise: Level 3&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;üìò Day 1&lt;/h1&gt; 
&lt;h2&gt;Welcome&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Congratulations&lt;/strong&gt; for deciding to participate in a &lt;em&gt;30 days of Python&lt;/em&gt; programming challenge. In this challenge, you will learn everything you need to be a python programmer and the whole concept of programming. At the end of the challenge, you will get a &lt;em&gt;30DaysOfPython&lt;/em&gt; programming challenge certificate.&lt;/p&gt; 
&lt;p&gt;If you would like to actively engage in the challenge, you may join the &lt;a href="https://t.me/ThirtyDaysOfPython"&gt;30DaysOfPython challenge&lt;/a&gt; telegram group.&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Python is a high-level programming language for general-purpose programming. It is an open source, interpreted, objected-oriented programming language. Python was created by a Dutch programmer, Guido van Rossum. The name of the Python programming language was derived from a British sketch comedy series, &lt;em&gt;Monty Python's Flying Circus&lt;/em&gt;. The first version was released on February 20, 1991. This 30 days of Python challenge will help you learn the latest version of Python, Python 3 step by step. The topics are broken down into 30 days, where each day contains several topics with easy-to-understand explanations, real-world examples, and many hands on exercises and projects.&lt;/p&gt; 
&lt;p&gt;This challenge is designed for beginners and professionals who want to learn python programming language. It may take 30 to 100 days to complete the challenge. People who actively participate in the telegram group have a high probability of completing the challenge.&lt;/p&gt; 
&lt;p&gt;This challenge is easy to read, written in conversational English, engaging, motivating and at the same time, it is very demanding. You need to allocate much time to finish this challenge. If you are a visual learner, you may get the video lesson on &lt;a href="https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw"&gt; Washera&lt;/a&gt; YouTube channel. You may start from &lt;a href="https://youtu.be/OCCWZheOesI"&gt;Python for Absolute Beginners video&lt;/a&gt;. Subscribe the channel, comment and ask questions on YouTube vidoes and be proactive, the author will eventually notice you.&lt;/p&gt; 
&lt;p&gt;The author likes to hear your opinion about the challenge, share the author by expressing your thoughts about the 30DaysOfPython challenge. You can leave your testimonial on this &lt;a href="https://www.asabeneh.com/testimonials"&gt;link&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why Python ?&lt;/h2&gt; 
&lt;p&gt;It is a programming language which is very close to human language and because of that, it is easy to learn and use. Python is used by various industries and companies (including Google). It has been used to develop web applications, desktop applications, system administration, and machine learning libraries. Python is a highly embraced language in the data science and machine learning community. I hope this is enough to convince you to start learning Python. Python is eating the world and you are killing it before it eats you.&lt;/p&gt; 
&lt;h2&gt;Environment Setup&lt;/h2&gt; 
&lt;h3&gt;Installing Python&lt;/h3&gt; 
&lt;p&gt;To run a python script you need to install python. Let's &lt;a href="https://www.python.org/"&gt;download&lt;/a&gt; python. If your are a windows user. Click the button encircled in red.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/installing_on_windows.png" alt="installing on Windows" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you are a macOS user. Click the button encircled in red.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/installing_on_macOS.png" alt="installing on Windows" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;To check if python is installed write the following command on your device terminal.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/python_versio.png" alt="Python Version" /&gt;&lt;/p&gt; 
&lt;p&gt;As you can see from the terminal, I am using &lt;em&gt;Python 3.7.5&lt;/em&gt; version at the moment. Your version of Python might be different from mine by but it should be 3.6 or above. If you mange to see the python version, well done. Python has been installed on your machine. Continue to the next section.&lt;/p&gt; 
&lt;h3&gt;Python Shell&lt;/h3&gt; 
&lt;p&gt;Python is an interpreted scripting language, so it does not need to be compiled. It means it executes the code line by line. Python comes with a &lt;em&gt;Python Shell (Python Interactive Shell)&lt;/em&gt;. It is used to execute a single python command and get the result.&lt;/p&gt; 
&lt;p&gt;Python Shell waits for the Python code from the user. When you enter the code, it interprets the code and shows the result in the next line. Open your terminal or command prompt(cmd) and write:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_python_shell.png" alt="Python Scripting Shell" /&gt;&lt;/p&gt; 
&lt;p&gt;The Python interactive shell is opened and it is waiting for you to write Python code(Python script). You will write your Python script next to this symbol &amp;gt;&amp;gt;&amp;gt; and then click Enter. Let us write our very first script on the Python scripting shell.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/adding_on_python_shell.png" alt="Python script on Python shell" /&gt;&lt;/p&gt; 
&lt;p&gt;Well done, you wrote your first Python script on Python interactive shell. How do we close the Python interactive shell ? To close the shell, next to this symbol &amp;gt;&amp;gt; write &lt;strong&gt;exit()&lt;/strong&gt; command and press Enter.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/exit_from_shell.png" alt="Exit from python shell" /&gt;&lt;/p&gt; 
&lt;p&gt;Now, you know how to open the Python interactive shell and how to exit from it.&lt;/p&gt; 
&lt;p&gt;Python will give you results if you write scripts that Python understands, if not it returns errors. Let's make a deliberate mistake and see what Python will return.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/invalid_syntax_error.png" alt="Invalid Syntax Error" /&gt;&lt;/p&gt; 
&lt;p&gt;As you can see from the returned error, Python is so clever that it knows the mistake we made and which was &lt;em&gt;Syntax Error: invalid syntax&lt;/em&gt;. Using x as multiplication in Python is a syntax error because (x) is not a valid syntax in Python. Instead of (&lt;strong&gt;x&lt;/strong&gt;) we use asterisk (*) for multiplication. The returned error clearly shows what to fix.&lt;/p&gt; 
&lt;p&gt;The process of identifying and removing errors from a program is called &lt;em&gt;debugging&lt;/em&gt;. Let us debug it by putting * in place of &lt;strong&gt;x&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/fixing_syntax_error.png" alt="Fixing Syntax Error" /&gt;&lt;/p&gt; 
&lt;p&gt;Our bug was fixed, the code ran and we got a result we were expecting. As a programmer you will see such kind of errors on daily basis. It is good to know how to debug. To be good at debugging you should understand what kind of errors you are facing. Some of the Python errors you may encounter are &lt;em&gt;SyntaxError&lt;/em&gt;, &lt;em&gt;IndexError&lt;/em&gt;, &lt;em&gt;NameError&lt;/em&gt;, &lt;em&gt;ModuleNotFoundError&lt;/em&gt;, &lt;em&gt;KeyError&lt;/em&gt;, &lt;em&gt;ImportError&lt;/em&gt;, &lt;em&gt;AttributeError&lt;/em&gt;, &lt;em&gt;TypeError&lt;/em&gt;, &lt;em&gt;ValueError&lt;/em&gt;, &lt;em&gt;ZeroDivisionError&lt;/em&gt; etc. We will see more about different Python &lt;strong&gt;&lt;em&gt;error types&lt;/em&gt;&lt;/strong&gt; in later sections.&lt;/p&gt; 
&lt;p&gt;Let us practice more how to use Python interactive shell. Go to your terminal or command prompt and write the word &lt;strong&gt;python&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_python_shell.png" alt="Python Scripting Shell" /&gt;&lt;/p&gt; 
&lt;p&gt;The Python interactive shell is opened. Let us do some basic mathematical operations (addition, subtraction, multiplication, division, modulus, exponential).&lt;/p&gt; 
&lt;p&gt;Let us do some maths first before we write any Python code:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;2 + 3 is 5&lt;/li&gt; 
 &lt;li&gt;3 - 2 is 1&lt;/li&gt; 
 &lt;li&gt;3 * 2 is 6&lt;/li&gt; 
 &lt;li&gt;3 / 2 is 1.5&lt;/li&gt; 
 &lt;li&gt;3 ** 2 is the same as 3 * 3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In python we have the following additional operations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;3 % 2 = 1 =&amp;gt; which means finding the remainder&lt;/li&gt; 
 &lt;li&gt;3 // 2 = 1 =&amp;gt; which means removing the remainder&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Let us change the above mathematical expressions to Python code. The Python shell has been opened and let us write a comment at the very beginning of the shell.&lt;/p&gt; 
&lt;p&gt;A &lt;em&gt;comment&lt;/em&gt; is a part of the code which is not executed by python. So we can leave some text in our code to make our code more readable. Python does not run the comment part. A comment in python starts with hash(#) symbol. This is how you write a comment in python&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt; # comment starts with hash
 # this is a python comment, because it starts with a (#) symbol
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/maths_on_python_shell.png" alt="Maths on python shell" /&gt;&lt;/p&gt; 
&lt;p&gt;Before we move on to the next section, let us practice more on the Python interactive shell. Close the opened shell by writing &lt;em&gt;exit()&lt;/em&gt; on the shell and open it again and let us practice how to write text on the Python shell.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/writing_string_on_shell.png" alt="Writing String on python shell" /&gt;&lt;/p&gt; 
&lt;h3&gt;Installing Visual Studio Code&lt;/h3&gt; 
&lt;p&gt;The Python interactive shell is good to try and test small script codes but it will not be for a big project. In real work environment, developers use different code editors to write codes. In this 30 days of Python programming challenge we will use visual studio code. Visual studio code is a very popular open source text editor. I am a fan of vscode and I would recommend to &lt;a href="https://code.visualstudio.com/"&gt;download&lt;/a&gt; visual studio code, but if you are in favor of other editors, feel free to follow with what you have.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://code.visualstudio.com/"&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/vscode.png" alt="Visual Studio Code" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you installed visual studio code, let us see how to use it. If you prefer a video, you can follow this Visual Studio Code for Python &lt;a href="https://www.youtube.com/watch?v=bn7Cx4z-vSo"&gt;Video tutorial&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;How to use visual studio code&lt;/h4&gt; 
&lt;p&gt;Open the visual studio code by double clicking the visual studio icon. When you open it you will get this kind of interface. Try to interact with the labeled icons.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/vscode_ui.png" alt="Visual studio Code" /&gt;&lt;/p&gt; 
&lt;p&gt;Create a folder named 30DaysOfPython on your desktop. Then open it using visual studio code.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/how_to_open_project_on_vscode.png" alt="Opening Project on Visual studio" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/opening_project.png" alt="Opening a project" /&gt;&lt;/p&gt; 
&lt;p&gt;After opening it you will see shortcuts for creating files and folders inside of 30DaysOfPython project's directory. As you can see below, I have created the very first file, helloworld.py. You can do the same.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/helloworld.png" alt="Creating a python file" /&gt;&lt;/p&gt; 
&lt;p&gt;After a long day of coding, you want to close your code editor, right? This is how you will close the opened project.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/closing_opened_project.png" alt="Closing project" /&gt;&lt;/p&gt; 
&lt;p&gt;Congratulations, you have finished setting up the development environment. Let us start coding.&lt;/p&gt; 
&lt;h2&gt;Basic Python&lt;/h2&gt; 
&lt;h3&gt;Python Syntax&lt;/h3&gt; 
&lt;p&gt;A Python script can be written in Python interactive shell or in the code editor. A Python file has an extension .py.&lt;/p&gt; 
&lt;h3&gt;Python Indentation&lt;/h3&gt; 
&lt;p&gt;An indentation is a white space in a text. Indentation in many languages is used to increase code readability; however, Python uses indentation to create blocks of code. In other programming languages, curly brackets are used to create code blocks instead of indentation. One of the common bugs when writing Python code is incorrect indentation.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/indentation.png" alt="Indentation Error" /&gt;&lt;/p&gt; 
&lt;h3&gt;Comments&lt;/h3&gt; 
&lt;p&gt;Comments play a crucial role in enhancing code readability and allowing developers to leave notes within their code. In Python, any text preceded by a hash (#) symbol is considered a comment and is not executed when the code runs.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example: Single Line Comment&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;    # This is the first comment
    # This is the second comment
    # Python is eating the world
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Example: Multiline Comment&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Triple quote can be used for multiline comment if it is not assigned to a variable&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;"""This is multiline comment
multiline comment takes multiple lines.
python is eating the world
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Data types&lt;/h3&gt; 
&lt;p&gt;In Python there are several types of data types. Let us get started with the most common ones. Different data types will be covered in detail in other sections. For the time being, let us just go through the different data types and get familiar with them. You do not have to have a clear understanding now.&lt;/p&gt; 
&lt;h4&gt;Number&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Integer: Integer(negative, zero and positive) numbers Example: ... -3, -2, -1, 0, 1, 2, 3 ...&lt;/li&gt; 
 &lt;li&gt;Float: Decimal number Example ... -3.5, -2.25, -1.0, 0.0, 1.1, 2.2, 3.5 ...&lt;/li&gt; 
 &lt;li&gt;Complex Example 1 + j, 2 + 4j&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;String&lt;/h4&gt; 
&lt;p&gt;A collection of one or more characters under a single or double quote. If a string is more than one sentence then we use a triple quote.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;'Asabeneh'
'Finland'
'Python'
'I love teaching'
'I hope you are enjoying the first day of 30DaysOfPython Challenge'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Booleans&lt;/h4&gt; 
&lt;p&gt;A boolean data type is either a True or False value. T and F should be always uppercase.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;    True  #  Is the light on? If it is on, then the value is True
    False # Is the light on? If it is off, then the value is False
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;List&lt;/h4&gt; 
&lt;p&gt;Python list is an ordered collection which allows to store different data type items. A list is similar to an array in JavaScript.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;[0, 1, 2, 3, 4, 5]  # all are the same data types - a list of numbers
['Banana', 'Orange', 'Mango', 'Avocado'] # all the same data types - a list of strings (fruits)
['Finland','Estonia', 'Sweden','Norway'] # all the same data types - a list of strings (countries)
['Banana', 10, False, 9.81] # different data types in the list - string, integer, boolean and float
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Dictionary&lt;/h4&gt; 
&lt;p&gt;A Python dictionary object is an unordered collection of data in a key value pair format.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;{
'first_name':'Asabeneh',
'last_name':'Yetayeh',
'country':'Finland', 
'age':250, 
'is_married':True,
'skills':['JS', 'React', 'Node', 'Python']
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Tuple&lt;/h4&gt; 
&lt;p&gt;A tuple is an ordered collection of different data types like list but tuples can not be modified once they are created. They are immutable.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;('Asabeneh', 'Pawel', 'Brook', 'Abraham', 'Lidiya') # Names
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;('Earth', 'Jupiter', 'Neptune', 'Mars', 'Venus', 'Saturn', 'Uranus', 'Mercury') # planets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Set&lt;/h4&gt; 
&lt;p&gt;A set is a collection of data types similar to list and tuple. Unlike list and tuple, set is not an ordered collection of items. Like in Mathematics, set in Python stores only unique items.&lt;/p&gt; 
&lt;p&gt;In later sections, we will go in detail about each and every Python data type.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;{2, 4, 3, 5}
{3.14, 9.81, 2.7} # order is not important in set
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Checking Data types&lt;/h3&gt; 
&lt;p&gt;To check the data type of certain data/variable we use the &lt;strong&gt;type&lt;/strong&gt; function. In the following terminal you will see different python data types:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/checking_data_types.png" alt="Checking Data types" /&gt;&lt;/p&gt; 
&lt;h3&gt;Python File&lt;/h3&gt; 
&lt;p&gt;First open your project folder, 30DaysOfPython. If you don't have this folder, create a folder name called 30DaysOfPython. Inside this folder, create a file called helloworld.py. Now, let's do what we did on python interactive shell using visual studio code.&lt;/p&gt; 
&lt;p&gt;The Python interactive shell was printing without using &lt;strong&gt;print&lt;/strong&gt; but on visual studio code to see our result we should use a built in function _print(). The &lt;em&gt;print()&lt;/em&gt; built-in function takes one or more arguments as follows &lt;em&gt;print('arument1', 'argument2', 'argument3')&lt;/em&gt;. See the examples below.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The file name is helloworld.py&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;# Day 1 - 30DaysOfPython Challenge

print(2 + 3)             # addition(+)
print(3 - 1)             # subtraction(-)
print(2 * 3)             # multiplication(*)
print(3 / 2)             # division(/)
print(3 ** 2)            # exponential(**)
print(3 % 2)             # modulus(%)
print(3 // 2)            # Floor division operator(//)

# Checking data types
print(type(10))          # Int
print(type(3.14))        # Float
print(type(1 + 3j))      # Complex number
print(type('Asabeneh'))  # String
print(type([1, 2, 3]))   # List
print(type({'name':'Asabeneh'})) # Dictionary
print(type({9.8, 3.14, 2.7}))    # Set
print(type((9.8, 3.14, 2.7)))    # Tuple
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run the python file check the image below. You can run the python file either by running the green button on Visual Studio Code or by typing &lt;em&gt;python helloworld.py&lt;/em&gt; in the terminal .&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/images/running_python_script.png" alt="Running python script" /&gt;&lt;/p&gt; 
&lt;p&gt;üåï You are amazing. You have just completed day 1 challenge and you are on your way to greatness. Now do some exercises for your brain and muscles.&lt;/p&gt; 
&lt;h2&gt;üíª Exercises - Day 1&lt;/h2&gt; 
&lt;h3&gt;Exercise: Level 1&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check the python version you are using&lt;/li&gt; 
 &lt;li&gt;Open the python interactive shell and do the following operations. The operands are 3 and 4. 
  &lt;ul&gt; 
   &lt;li&gt;addition(+)&lt;/li&gt; 
   &lt;li&gt;subtraction(-)&lt;/li&gt; 
   &lt;li&gt;multiplication(*)&lt;/li&gt; 
   &lt;li&gt;modulus(%)&lt;/li&gt; 
   &lt;li&gt;division(/)&lt;/li&gt; 
   &lt;li&gt;exponential(**)&lt;/li&gt; 
   &lt;li&gt;floor division operator(//)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Write strings on the python interactive shell. The strings are the following: 
  &lt;ul&gt; 
   &lt;li&gt;Your name&lt;/li&gt; 
   &lt;li&gt;Your family name&lt;/li&gt; 
   &lt;li&gt;Your country&lt;/li&gt; 
   &lt;li&gt;I am enjoying 30 days of python&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Check the data types of the following data: 
  &lt;ul&gt; 
   &lt;li&gt;10&lt;/li&gt; 
   &lt;li&gt;9.8&lt;/li&gt; 
   &lt;li&gt;3.14&lt;/li&gt; 
   &lt;li&gt;4 - 4j&lt;/li&gt; 
   &lt;li&gt;['Asabeneh', 'Python', 'Finland']&lt;/li&gt; 
   &lt;li&gt;Your name&lt;/li&gt; 
   &lt;li&gt;Your family name&lt;/li&gt; 
   &lt;li&gt;Your country&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Exercise: Level 2&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a folder named day_1 inside 30DaysOfPython folder. Inside day_1 folder, create a python file helloworld.py and repeat questions 1, 2, 3 and 4. Remember to use &lt;em&gt;print()&lt;/em&gt; when you are working on a python file. Navigate to the directory where you have saved your file, and run it.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Exercise: Level 3&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Write an example for different Python data types such as Number(Integer, Float, Complex), String, Boolean, List, Tuple, Set and Dictionary.&lt;/li&gt; 
 &lt;li&gt;Find an &lt;a href="https://en.wikipedia.org/wiki/Euclidean_distance#:~:text=In%20mathematics%2C%20the%20Euclidean%20distance,being%20called%20the%20Pythagorean%20distance."&gt;Euclidian distance&lt;/a&gt; between (2, 3) and (10, 8)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;üéâ CONGRATULATIONS ! üéâ&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Asabeneh/30-Days-Of-Python/master/02_Day_Variables_builtin_functions/02_variables_builtin_functions.md"&gt;Day 2 &amp;gt;&amp;gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>confident-ai/deepeval</title>
      <link>https://github.com/confident-ai/deepeval</link>
      <description>&lt;p&gt;The LLM Evaluation Framework&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://github.com/confident-ai/deepeval/raw/main/docs/static/img/deepeval.png" alt="DeepEval Logo" width="100%" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;The LLM Evaluation Framework&lt;/h1&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/5917" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/5917" alt="confident-ai%2Fdeepeval | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/3SEyvpgu2f"&gt; &lt;img alt="discord-invite" src="https://dcbadge.vercel.app/api/server/3SEyvpgu2f?style=flat" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt; &lt;p&gt; &lt;a href="https://deepeval.com/docs/getting-started?utm_source=GitHub"&gt;Documentation&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/confident-ai/deepeval/main/#-metrics-and-features"&gt;Metrics and Features&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/confident-ai/deepeval/main/#-quickstart"&gt;Getting Started&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/confident-ai/deepeval/main/#-integrations"&gt;Integrations&lt;/a&gt; | &lt;a href="https://confident-ai.com?utm_source=GitHub"&gt;DeepEval Platform&lt;/a&gt; &lt;/p&gt;&lt;p&gt; &lt;/p&gt;&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/confident-ai/deepeval/releases"&gt; &lt;img alt="GitHub release" src="https://img.shields.io/github/release/confident-ai/deepeval.svg?color=violet" /&gt; &lt;/a&gt; &lt;a href="https://colab.research.google.com/drive/1PPxYEBa6eu__LquGoFFJZkhYgWVYE6kh?usp=sharing"&gt; &lt;img alt="Try Quickstart in Colab" src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://github.com/confident-ai/deepeval/raw/master/LICENSE.md"&gt; &lt;img alt="License" src="https://img.shields.io/github/license/confident-ai/deepeval.svg?color=yellow" /&gt; &lt;/a&gt; &lt;a href="https://x.com/deepeval"&gt; &lt;img alt="Twitter Follow" src="https://img.shields.io/twitter/follow/deepeval?style=social&amp;amp;logo=x" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://www.readme-i18n.com/confident-ai/deepeval?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/confident-ai/deepeval?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/confident-ai/deepeval?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/confident-ai/deepeval?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/confident-ai/deepeval?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/confident-ai/deepeval?lang=pt"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/confident-ai/deepeval?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://www.readme-i18n.com/confident-ai/deepeval?lang=zh"&gt;‰∏≠Êñá&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;DeepEval&lt;/strong&gt; is a simple-to-use, open-source LLM evaluation framework, for evaluating and testing large-language model systems. It is similar to Pytest but specialized for unit testing LLM outputs. DeepEval incorporates the latest research to evaluate LLM outputs based on metrics such as G-Eval, hallucination, answer relevancy, RAGAS, etc., which uses LLMs and various other NLP models that runs &lt;strong&gt;locally on your machine&lt;/strong&gt; for evaluation.&lt;/p&gt; 
&lt;p&gt;Whether your LLM applications are RAG pipelines, chatbots, AI agents, implemented via LangChain or LlamaIndex, DeepEval has you covered. With it, you can easily determine the optimal models, prompts, and architecture to improve your RAG pipeline, agentic workflows, prevent prompt drifting, or even transition from OpenAI to hosting your own Deepseek R1 with confidence.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Need a place for your DeepEval testing data to live üè°‚ù§Ô∏è? &lt;a href="https://confident-ai.com?utm_source=GitHub"&gt;Sign up to the DeepEval platform&lt;/a&gt; to compare iterations of your LLM app, generate &amp;amp; share testing reports, and more.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/confident-ai/deepeval/main/assets/demo.gif" alt="Demo GIF" /&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Want to talk LLM evaluation, need help picking metrics, or just to say hi? &lt;a href="https://discord.com/invite/3SEyvpgu2f"&gt;Come join our discord.&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h1&gt;üî• Metrics and Features&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ü•≥ You can now share DeepEval's test results on the cloud directly on &lt;a href="https://confident-ai.com?utm_source=GitHub"&gt;Confident AI&lt;/a&gt;'s infrastructure&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports both end-to-end and component-level LLM evaluation.&lt;/li&gt; 
 &lt;li&gt;Large variety of ready-to-use LLM evaluation metrics (all with explanations) powered by &lt;strong&gt;ANY&lt;/strong&gt; LLM of your choice, statistical methods, or NLP models that runs &lt;strong&gt;locally on your machine&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;G-Eval&lt;/li&gt; 
   &lt;li&gt;DAG (&lt;a href="https://deepeval.com/docs/metrics-dag"&gt;deep acyclic graph&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;RAG metrics:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Answer Relevancy&lt;/li&gt; 
     &lt;li&gt;Faithfulness&lt;/li&gt; 
     &lt;li&gt;Contextual Recall&lt;/li&gt; 
     &lt;li&gt;Contextual Precision&lt;/li&gt; 
     &lt;li&gt;Contextual Relevancy&lt;/li&gt; 
     &lt;li&gt;RAGAS&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Agentic metrics:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Task Completion&lt;/li&gt; 
     &lt;li&gt;Tool Correctness&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Others:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Hallucination&lt;/li&gt; 
     &lt;li&gt;Summarization&lt;/li&gt; 
     &lt;li&gt;Bias&lt;/li&gt; 
     &lt;li&gt;Toxicity&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Conversational metrics:&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;Knowledge Retention&lt;/li&gt; 
     &lt;li&gt;Conversation Completeness&lt;/li&gt; 
     &lt;li&gt;Conversation Relevancy&lt;/li&gt; 
     &lt;li&gt;Role Adherence&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;etc.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Build your own custom metrics that are automatically integrated with DeepEval's ecosystem.&lt;/li&gt; 
 &lt;li&gt;Generate synthetic datasets for evaluation.&lt;/li&gt; 
 &lt;li&gt;Integrates seamlessly with &lt;strong&gt;ANY&lt;/strong&gt; CI/CD environment.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://deepeval.com/docs/red-teaming-introduction"&gt;Red team your LLM application&lt;/a&gt; for 40+ safety vulnerabilities in a few lines of code, including: 
  &lt;ul&gt; 
   &lt;li&gt;Toxicity&lt;/li&gt; 
   &lt;li&gt;Bias&lt;/li&gt; 
   &lt;li&gt;SQL Injection&lt;/li&gt; 
   &lt;li&gt;etc., using advanced 10+ attack enhancement strategies such as prompt injections.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Easily benchmark &lt;strong&gt;ANY&lt;/strong&gt; LLM on popular LLM benchmarks in &lt;a href="https://deepeval.com/docs/benchmarks-introduction?utm_source=GitHub"&gt;under 10 lines of code.&lt;/a&gt;, which includes: 
  &lt;ul&gt; 
   &lt;li&gt;MMLU&lt;/li&gt; 
   &lt;li&gt;HellaSwag&lt;/li&gt; 
   &lt;li&gt;DROP&lt;/li&gt; 
   &lt;li&gt;BIG-Bench Hard&lt;/li&gt; 
   &lt;li&gt;TruthfulQA&lt;/li&gt; 
   &lt;li&gt;HumanEval&lt;/li&gt; 
   &lt;li&gt;GSM8K&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://confident-ai.com?utm_source=GitHub"&gt;100% integrated with Confident AI&lt;/a&gt; for the full evaluation lifecycle: 
  &lt;ul&gt; 
   &lt;li&gt;Curate/annotate evaluation datasets on the cloud&lt;/li&gt; 
   &lt;li&gt;Benchmark LLM app using dataset, and compare with previous iterations to experiment which models/prompts works best&lt;/li&gt; 
   &lt;li&gt;Fine-tune metrics for custom results&lt;/li&gt; 
   &lt;li&gt;Debug evaluation results via LLM traces&lt;/li&gt; 
   &lt;li&gt;Monitor &amp;amp; evaluate LLM responses in product to improve datasets with real-world data&lt;/li&gt; 
   &lt;li&gt;Repeat until perfection&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Confident AI is the DeepEval platform. Create an account &lt;a href="https://app.confident-ai.com?utm_source=GitHub"&gt;here.&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h1&gt;üîå Integrations&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;ü¶Ñ LlamaIndex, to &lt;a href="https://www.deepeval.com/integrations/frameworks/llamaindex?utm_source=GitHub"&gt;&lt;strong&gt;unit test RAG applications in CI/CD&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ü§ó Hugging Face, to &lt;a href="https://www.deepeval.com/integrations/frameworks/huggingface?utm_source=GitHub"&gt;&lt;strong&gt;enable real-time evaluations during LLM fine-tuning&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h1&gt;üöÄ QuickStart&lt;/h1&gt; 
&lt;p&gt;Let's pretend your LLM application is a RAG based customer support chatbot; here's how DeepEval can help test what you've built.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Deepeval works with &lt;strong&gt;Python&amp;gt;=3.9+&lt;/strong&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install -U deepeval
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Create an account (highly recommended)&lt;/h2&gt; 
&lt;p&gt;Using the &lt;code&gt;deepeval&lt;/code&gt; platform will allow you to generate sharable testing reports on the cloud. It is free, takes no additional code to setup, and we highly recommend giving it a try.&lt;/p&gt; 
&lt;p&gt;To login, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;deepeval login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the instructions in the CLI to create an account, copy your API key, and paste it into the CLI. All test cases will automatically be logged (find more information on data privacy &lt;a href="https://deepeval.com/docs/data-privacy?utm_source=GitHub"&gt;here&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;Writing your first test case&lt;/h2&gt; 
&lt;p&gt;Create a test file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;touch test_chatbot.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;code&gt;test_chatbot.py&lt;/code&gt; and write your first test case to run an &lt;strong&gt;end-to-end&lt;/strong&gt; evaluation using DeepEval, which treats your LLM app as a black-box:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pytest
from deepeval import assert_test
from deepeval.metrics import GEval
from deepeval.test_case import LLMTestCase, LLMTestCaseParams

def test_case():
    correctness_metric = GEval(
        name="Correctness",
        criteria="Determine if the 'actual output' is correct based on the 'expected output'.",
        evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],
        threshold=0.5
    )
    test_case = LLMTestCase(
        input="What if these shoes don't fit?",
        # Replace this with the actual output from your LLM application
        actual_output="You have 30 days to get a full refund at no extra cost.",
        expected_output="We offer a 30-day full refund at no extra costs.",
        retrieval_context=["All customers are eligible for a 30 day full refund at no extra costs."]
    )
    assert_test(test_case, [correctness_metric])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Set your &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; as an environment variable (you can also evaluate using your own custom model, for more details visit &lt;a href="https://deepeval.com/docs/metrics-introduction#using-a-custom-llm?utm_source=GitHub"&gt;this part of our docs&lt;/a&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;export OPENAI_API_KEY="..."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And finally, run &lt;code&gt;test_chatbot.py&lt;/code&gt; in the CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;deepeval test run test_chatbot.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Congratulations! Your test case should have passed ‚úÖ&lt;/strong&gt; Let's breakdown what happened.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The variable &lt;code&gt;input&lt;/code&gt; mimics a user input, and &lt;code&gt;actual_output&lt;/code&gt; is a placeholder for what your application's supposed to output based on this input.&lt;/li&gt; 
 &lt;li&gt;The variable &lt;code&gt;expected_output&lt;/code&gt; represents the ideal answer for a given &lt;code&gt;input&lt;/code&gt;, and &lt;a href="https://deepeval.com/docs/metrics-llm-evals"&gt;&lt;code&gt;GEval&lt;/code&gt;&lt;/a&gt; is a research-backed metric provided by &lt;code&gt;deepeval&lt;/code&gt; for you to evaluate your LLM output's on any custom with human-like accuracy.&lt;/li&gt; 
 &lt;li&gt;In this example, the metric &lt;code&gt;criteria&lt;/code&gt; is correctness of the &lt;code&gt;actual_output&lt;/code&gt; based on the provided &lt;code&gt;expected_output&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;All metric scores range from 0 - 1, which the &lt;code&gt;threshold=0.5&lt;/code&gt; threshold ultimately determines if your test have passed or not.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://deepeval.com/docs/getting-started?utm_source=GitHub"&gt;Read our documentation&lt;/a&gt; for more information on more options to run end-to-end evaluation, how to use additional metrics, create your own custom metrics, and tutorials on how to integrate with other tools like LangChain and LlamaIndex.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Evaluating Nested Components&lt;/h2&gt; 
&lt;p&gt;If you wish to evaluate individual components within your LLM app, you need to run &lt;strong&gt;component-level&lt;/strong&gt; evals - a powerful way to evaluate any component within an LLM system.&lt;/p&gt; 
&lt;p&gt;Simply trace "components" such as LLM calls, retrievers, tool calls, and agents within your LLM application using the &lt;code&gt;@observe&lt;/code&gt; decorator to apply metrics on a component-level. Tracing with &lt;code&gt;deepeval&lt;/code&gt; is non-instrusive (learn more &lt;a href="https://deepeval.com/docs/evaluation-llm-tracing#dont-be-worried-about-tracing"&gt;here&lt;/a&gt;) and helps you avoid rewriting your codebase just for evals:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from deepeval.tracing import observe, update_current_span
from deepeval.test_case import LLMTestCase
from deepeval.dataset import Golden
from deepeval.metrics import GEval
from deepeval import evaluate

correctness = GEval(name="Correctness", criteria="Determine if the 'actual output' is correct based on the 'expected output'.", evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT])

@observe(metrics=[correctness])
def inner_component():
    # Component can be anything from an LLM call, retrieval, agent, tool use, etc.
    update_current_span(test_case=LLMTestCase(input="...", actual_output="..."))
    return

@observe
def llm_app(input: str):
    inner_component()
    return

evaluate(observed_callback=llm_app, goldens=[Golden(input="Hi!")])
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can learn everything about component-level evaluations &lt;a href="https://www.deepeval.com/docs/evaluation-component-level-llm-evals"&gt;here.&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Evaluating Without Pytest Integration&lt;/h2&gt; 
&lt;p&gt;Alternatively, you can evaluate without Pytest, which is more suited for a notebook environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from deepeval import evaluate
from deepeval.metrics import AnswerRelevancyMetric
from deepeval.test_case import LLMTestCase

answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.7)
test_case = LLMTestCase(
    input="What if these shoes don't fit?",
    # Replace this with the actual output from your LLM application
    actual_output="We offer a 30-day full refund at no extra costs.",
    retrieval_context=["All customers are eligible for a 30 day full refund at no extra costs."]
)
evaluate([test_case], [answer_relevancy_metric])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Using Standalone Metrics&lt;/h2&gt; 
&lt;p&gt;DeepEval is extremely modular, making it easy for anyone to use any of our metrics. Continuing from the previous example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from deepeval.metrics import AnswerRelevancyMetric
from deepeval.test_case import LLMTestCase

answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.7)
test_case = LLMTestCase(
    input="What if these shoes don't fit?",
    # Replace this with the actual output from your LLM application
    actual_output="We offer a 30-day full refund at no extra costs.",
    retrieval_context=["All customers are eligible for a 30 day full refund at no extra costs."]
)

answer_relevancy_metric.measure(test_case)
print(answer_relevancy_metric.score)
# All metrics also offer an explanation
print(answer_relevancy_metric.reason)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that some metrics are for RAG pipelines, while others are for fine-tuning. Make sure to use our docs to pick the right one for your use case.&lt;/p&gt; 
&lt;h2&gt;Evaluating a Dataset / Test Cases in Bulk&lt;/h2&gt; 
&lt;p&gt;In DeepEval, a dataset is simply a collection of test cases. Here is how you can evaluate these in bulk:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import pytest
from deepeval import assert_test
from deepeval.dataset import EvaluationDataset, Golden
from deepeval.metrics import AnswerRelevancyMetric
from deepeval.test_case import LLMTestCase

dataset = EvaluationDataset(goldens=[Golden(input="What's the weather like today?")])

for golden in dataset.goldens:
    test_case = LLMTestCase(
        input=golden.input,
        actual_output=your_llm_app(golden.input)
    )
    dataset.add_test_case(test_case)

@pytest.mark.parametrize(
    "test_case",
    dataset,
)
def test_customer_chatbot(test_case: LLMTestCase):
    answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.5)
    assert_test(test_case, [answer_relevancy_metric])
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run this in the CLI, you can also add an optional -n flag to run tests in parallel
deepeval test run test_&amp;lt;filename&amp;gt;.py -n 4
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;p&gt;Alternatively, although we recommend using &lt;code&gt;deepeval test run&lt;/code&gt;, you can evaluate a dataset/test cases without using our Pytest integration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from deepeval import evaluate
...

evaluate(dataset, [answer_relevancy_metric])
# or
dataset.evaluate([answer_relevancy_metric])
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;A Note on Env Variables (.env / .env.local)&lt;/h2&gt; 
&lt;p&gt;DeepEval auto-loads &lt;code&gt;.env.local&lt;/code&gt; then &lt;code&gt;.env&lt;/code&gt; from the current working directory &lt;strong&gt;at import time&lt;/strong&gt;. &lt;strong&gt;Precedence:&lt;/strong&gt; process env -&amp;gt; &lt;code&gt;.env.local&lt;/code&gt; -&amp;gt; &lt;code&gt;.env&lt;/code&gt;. Opt out with &lt;code&gt;DEEPEVAL_DISABLE_DOTENV=1&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env.local
# then edit .env.local (ignored by git)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;DeepEval With Confident AI&lt;/h1&gt; 
&lt;p&gt;DeepEval's cloud platform, &lt;a href="https://confident-ai.com?utm_source=Github"&gt;Confident AI&lt;/a&gt;, allows you to:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Curate/annotate evaluation datasets on the cloud&lt;/li&gt; 
 &lt;li&gt;Benchmark LLM app using dataset, and compare with previous iterations to experiment which models/prompts works best&lt;/li&gt; 
 &lt;li&gt;Fine-tune metrics for custom results&lt;/li&gt; 
 &lt;li&gt;Debug evaluation results via LLM traces&lt;/li&gt; 
 &lt;li&gt;Monitor &amp;amp; evaluate LLM responses in product to improve datasets with real-world data&lt;/li&gt; 
 &lt;li&gt;Repeat until perfection&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Everything on Confident AI, including how to use Confident is available &lt;a href="https://www.confident-ai.com/docs?utm_source=GitHub"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To begin, login from the CLI:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;deepeval login
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the instructions to log in, create your account, and paste your API key into the CLI.&lt;/p&gt; 
&lt;p&gt;Now, run your test file again:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;deepeval test run test_chatbot.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should see a link displayed in the CLI once the test has finished running. Paste it into your browser to view the results!&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/confident-ai/deepeval/main/assets/demo.gif" alt="Demo GIF" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;h3&gt;Environment variables via .env files&lt;/h3&gt; 
&lt;p&gt;Using &lt;code&gt;.env.local&lt;/code&gt; or &lt;code&gt;.env&lt;/code&gt; is optional. If they are missing, DeepEval uses your existing environment variables. When present, dotenv environment variables are auto-loaded at import time (unless you set &lt;code&gt;DEEPEVAL_DISABLE_DOTENV=1&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Precedence:&lt;/strong&gt; process env -&amp;gt; &lt;code&gt;.env.local&lt;/code&gt; -&amp;gt; &lt;code&gt;.env&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp .env.example .env.local
# then edit .env.local (ignored by git)

&amp;lt;br /&amp;gt;

# Contributing

Please read [CONTRIBUTING.md](https://github.com/confident-ai/deepeval/blob/main/CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.

&amp;lt;br /&amp;gt;

# Roadmap

Features:

- [x] Integration with Confident AI
- [x] Implement G-Eval
- [x] Implement RAG metrics
- [x] Implement Conversational metrics
- [x] Evaluation Dataset Creation
- [x] Red-Teaming
- [ ] DAG custom metrics
- [ ] Guardrails

&amp;lt;br /&amp;gt;

# Authors

Built by the founders of Confident AI. Contact jeffreyip@confident-ai.com for all enquiries.

&amp;lt;br /&amp;gt;

# License

DeepEval is licensed under Apache 2.0 - see the [LICENSE.md](https://github.com/confident-ai/deepeval/blob/main/LICENSE.md) file for details.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/RAG-Anything</title>
      <link>https://github.com/HKUDS/RAG-Anything</link>
      <description>&lt;p&gt;"RAG-Anything: All-in-One RAG Framework"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div style="margin: 20px 0;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/logo.png" width="120" height="120" alt="RAG-Anything Logo" style="border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);" /&gt; 
 &lt;/div&gt; 
 &lt;h1&gt;üöÄ RAG-Anything: All-in-One RAG Framework&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14959" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14959" alt="HKUDS%2FRAG-Anything | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://readme-typing-svg.herokuapp.com?font=Orbitron&amp;amp;size=24&amp;amp;duration=3000&amp;amp;pause=1000&amp;amp;color=00D9FF&amp;amp;center=true&amp;amp;vCenter=true&amp;amp;width=600&amp;amp;lines=Welcome+to+RAG-Anything;Next-Gen+Multimodal+RAG+System;Powered+by+Advanced+AI+Technology" alt="Typing Animation" /&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;"&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;&lt;img src="https://img.shields.io/badge/üî•Project-Page-00d9ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2410.05779"&gt;&lt;img src="https://img.shields.io/badge/üìÑarXiv-2410.05779-ff6b6b?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt;&lt;img src="https://img.shields.io/badge/‚ö°Based%20on-LightRAG-4ecdc4?style=for-the-badge&amp;amp;logo=lightning&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/RAG-Anything?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/üêçPython-3.10-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/raganything/"&gt;&lt;img src="https://img.shields.io/pypi/v/raganything.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/badge/‚ö°uv-Ready-ff6b6b?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/üí¨Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/issues/7"&gt;&lt;img src="https://img.shields.io/badge/üí¨WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README_zh.md"&gt;&lt;img src="https://img.shields.io/badge/üá®üá≥‰∏≠ÊñáÁâà-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/üá∫üá∏English-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéâ News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.08.12]üéØüì¢ üîç RAG-Anything now features &lt;strong&gt;VLM-Enhanced Query&lt;/strong&gt; mode! When documents include images, the system seamlessly integrates them into VLM for advanced multimodal analysis, combining visual and textual context for deeper insights.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.05]üéØüì¢ RAG-Anything now features a &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/docs/context_aware_processing.md"&gt;context configuration module&lt;/a&gt;, enabling intelligent integration of relevant contextual information to enhance multimodal content processing.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.04]üéØüì¢ üöÄ RAG-Anything now supports multimodal query capabilities, enabling enhanced RAG with seamless processing of text, images, tables, and equations.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.03]üéØüì¢ üéâ RAG-Anything has reached 1küåü stars on GitHub! Thank you for your incredible support and valuable contributions to the project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåü System Overview&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Next-Generation Multimodal Intelligence&lt;/em&gt;&lt;/p&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border: 2px solid #00d9ff; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);"&gt; 
 &lt;p&gt;Modern documents increasingly contain diverse multimodal content‚Äîtext, images, tables, equations, charts, and multimedia‚Äîthat traditional text-focused RAG systems cannot effectively process. &lt;strong&gt;RAG-Anything&lt;/strong&gt; addresses this challenge as a comprehensive &lt;strong&gt;All-in-One Multimodal Document Processing RAG system&lt;/strong&gt; built on &lt;a href="https://github.com/HKUDS/LightRAG"&gt;LightRAG&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;As a unified solution, RAG-Anything &lt;strong&gt;eliminates the need for multiple specialized tools&lt;/strong&gt;. It provides &lt;strong&gt;seamless processing and querying across all content modalities&lt;/strong&gt; within a single integrated framework. Unlike conventional RAG approaches that struggle with non-textual elements, our all-in-one system delivers &lt;strong&gt;comprehensive multimodal retrieval capabilities&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Users can query documents containing &lt;strong&gt;interleaved text&lt;/strong&gt;, &lt;strong&gt;visual diagrams&lt;/strong&gt;, &lt;strong&gt;structured tables&lt;/strong&gt;, and &lt;strong&gt;mathematical formulations&lt;/strong&gt; through &lt;strong&gt;one cohesive interface&lt;/strong&gt;. This consolidated approach makes RAG-Anything particularly valuable for academic research, technical documentation, financial reports, and enterprise knowledge management where rich, mixed-content documents demand a &lt;strong&gt;unified processing framework&lt;/strong&gt;.&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/rag_anything_framework.png" alt="RAG-Anything" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;üéØ Key Features&lt;/h3&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 15px; padding: 25px; margin: 20px 0;"&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;üîÑ End-to-End Multimodal Pipeline&lt;/strong&gt; - Complete workflow from document ingestion and parsing to intelligent multimodal query answering&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üìÑ Universal Document Support&lt;/strong&gt; - Seamless processing of PDFs, Office documents, images, and diverse file formats&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üß† Specialized Content Analysis&lt;/strong&gt; - Dedicated processors for images, tables, mathematical equations, and heterogeneous content types&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üîó Multimodal Knowledge Graph&lt;/strong&gt; - Automatic entity extraction and cross-modal relationship discovery for enhanced understanding&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;‚ö° Adaptive Processing Modes&lt;/strong&gt; - Flexible MinerU-based parsing or direct multimodal content injection workflows&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üìã Direct Content List Insertion&lt;/strong&gt; - Bypass document parsing by directly inserting pre-parsed content lists from external sources&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;üéØ Hybrid Intelligent Retrieval&lt;/strong&gt; - Advanced search capabilities spanning textual and multimodal content with contextual understanding&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è Algorithm &amp;amp; Architecture&lt;/h2&gt; 
&lt;div style="background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border-left: 5px solid #00d9ff;"&gt; 
 &lt;h3&gt;Core Algorithm&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;RAG-Anything&lt;/strong&gt; implements an effective &lt;strong&gt;multi-stage multimodal pipeline&lt;/strong&gt; that fundamentally extends traditional RAG architectures to seamlessly handle diverse content modalities through intelligent orchestration and cross-modal understanding.&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: space-around; align-items: center; flex-wrap: wrap; gap: 20px;"&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üìÑ
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Document Parsing
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    ‚Üí
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üß†
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Content Analysis
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    ‚Üí
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üîç
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Knowledge Graph
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    ‚Üí
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     üéØ
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Intelligent Retrieval
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;1. Document Parsing Stage&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The system provides high-fidelity document extraction through adaptive content decomposition. It intelligently segments heterogeneous elements while preserving contextual relationships. Universal format compatibility is achieved via specialized optimized parsers.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚öôÔ∏è MinerU Integration&lt;/strong&gt;: Leverages &lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt; for high-fidelity document structure extraction and semantic preservation across complex layouts.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üß© Adaptive Content Decomposition&lt;/strong&gt;: Automatically segments documents into coherent text blocks, visual elements, structured tables, mathematical equations, and specialized content types while preserving contextual relationships.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìÅ Universal Format Support&lt;/strong&gt;: Provides comprehensive handling of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and emerging formats through specialized parsers with format-specific optimization.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;2. Multi-Modal Content Understanding &amp;amp; Processing&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The system automatically categorizes and routes content through optimized channels. It uses concurrent pipelines for parallel text and multimodal processing. Document hierarchy and relationships are preserved during transformation.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üéØ Autonomous Content Categorization and Routing&lt;/strong&gt;: Automatically identify, categorize, and route different content types through optimized execution channels.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° Concurrent Multi-Pipeline Architecture&lt;/strong&gt;: Implements concurrent execution of textual and multimodal content through dedicated processing pipelines. This approach maximizes throughput efficiency while preserving content integrity.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üèóÔ∏è Document Hierarchy Extraction&lt;/strong&gt;: Extracts and preserves original document hierarchy and inter-element relationships during content transformation.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;3. Multimodal Analysis Engine&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #0f3460 0%, #1a1a2e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #00d9ff;"&gt; 
 &lt;p&gt;The system deploys modality-aware processing units for heterogeneous data modalities:&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Specialized Analyzers:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Visual Content Analyzer&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Integrate vision model for image analysis.&lt;/li&gt; 
    &lt;li&gt;Generates context-aware descriptive captions based on visual semantics.&lt;/li&gt; 
    &lt;li&gt;Extracts spatial relationships and hierarchical structures between visual elements.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìä Structured Data Interpreter&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Performs systematic interpretation of tabular and structured data formats.&lt;/li&gt; 
    &lt;li&gt;Implements statistical pattern recognition algorithms for data trend analysis.&lt;/li&gt; 
    &lt;li&gt;Identifies semantic relationships and dependencies across multiple tabular datasets.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìê Mathematical Expression Parser&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Parses complex mathematical expressions and formulas with high accuracy.&lt;/li&gt; 
    &lt;li&gt;Provides native LaTeX format support for seamless integration with academic workflows.&lt;/li&gt; 
    &lt;li&gt;Establishes conceptual mappings between mathematical equations and domain-specific knowledge bases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîß Extensible Modality Handler&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Provides configurable processing framework for custom and emerging content types.&lt;/li&gt; 
    &lt;li&gt;Enables dynamic integration of new modality processors through plugin architecture.&lt;/li&gt; 
    &lt;li&gt;Supports runtime configuration of processing pipelines for specialized use cases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;4. Multimodal Knowledge Graph Index&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The multi-modal knowledge graph construction module transforms document content into structured semantic representations. It extracts multimodal entities, establishes cross-modal relationships, and preserves hierarchical organization. The system applies weighted relevance scoring for optimized knowledge retrieval.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Core Functions:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîç Multi-Modal Entity Extraction&lt;/strong&gt;: Transforms significant multimodal elements into structured knowledge graph entities. The process includes semantic annotations and metadata preservation.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Cross-Modal Relationship Mapping&lt;/strong&gt;: Establishes semantic connections and dependencies between textual entities and multimodal components. This is achieved through automated relationship inference algorithms.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üèóÔ∏è Hierarchical Structure Preservation&lt;/strong&gt;: Maintains original document organization through "belongs_to" relationship chains. These chains preserve logical content hierarchy and sectional dependencies.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚öñÔ∏è Weighted Relationship Scoring&lt;/strong&gt;: Assigns quantitative relevance scores to relationship types. Scoring is based on semantic proximity and contextual significance within the document structure.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;5. Modality-Aware Retrieval&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The hybrid retrieval system combines vector similarity search with graph traversal algorithms for comprehensive content retrieval. It implements modality-aware ranking mechanisms and maintains relational coherence between retrieved elements to ensure contextually integrated information delivery.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Retrieval Mechanisms:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîÄ Vector-Graph Fusion&lt;/strong&gt;: Integrates vector similarity search with graph traversal algorithms. This approach leverages both semantic embeddings and structural relationships for comprehensive content retrieval.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìä Modality-Aware Ranking&lt;/strong&gt;: Implements adaptive scoring mechanisms that weight retrieval results based on content type relevance. The system adjusts rankings according to query-specific modality preferences.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Relational Coherence Maintenance&lt;/strong&gt;: Maintains semantic and structural relationships between retrieved elements. This ensures coherent information delivery and contextual integrity.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Initialize Your AI Journey&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212284158-e840e285-664b-44d7-b79b-e264b5e54825.gif" width="400" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Option 1: Install from PyPI (Recommended)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
pip install raganything

# With optional dependencies for extended format support:
pip install 'raganything[all]'              # All optional features
pip install 'raganything[image]'            # Image format conversion (BMP, TIFF, GIF, WebP)
pip install 'raganything[text]'             # Text file processing (TXT, MD)
pip install 'raganything[image,text]'       # Multiple features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option 2: Install from Source&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and setup the project with uv
git clone https://github.com/HKUDS/RAG-Anything.git
cd RAG-Anything

# Install the package and dependencies in a virtual environment
uv sync

# If you encounter network timeouts (especially for opencv packages):
# UV_HTTP_TIMEOUT=120 uv sync

# Run commands directly with uv (recommended approach)
uv run python examples/raganything_example.py --help

# Install with optional dependencies
uv sync --extra image --extra text  # Specific extras
uv sync --all-extras                 # All optional features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Optional Dependencies&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[image]&lt;/code&gt;&lt;/strong&gt; - Enables processing of BMP, TIFF, GIF, WebP image formats (requires Pillow)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[text]&lt;/code&gt;&lt;/strong&gt; - Enables processing of TXT and MD files (requires ReportLab)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[all]&lt;/code&gt;&lt;/strong&gt; - Includes all Python optional dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Office Document Processing Requirements:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Office documents (.doc, .docx, .ppt, .pptx, .xls, .xlsx) require &lt;strong&gt;LibreOffice&lt;/strong&gt; installation&lt;/li&gt; 
  &lt;li&gt;Download from &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice official website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: Download installer from official website&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: &lt;code&gt;brew install --cask libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Ubuntu/Debian&lt;/strong&gt;: &lt;code&gt;sudo apt-get install libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;CentOS/RHEL&lt;/strong&gt;: &lt;code&gt;sudo yum install libreoffice&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Check MinerU installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Verify installation
mineru --version

# Check if properly configured
python -c "from raganything import RAGAnything; rag = RAGAnything(); print('‚úÖ MinerU installed properly' if rag.check_parser_installation() else '‚ùå MinerU installation issue')"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Models are downloaded automatically on first use. For manual download, refer to &lt;a href="https://github.com/opendatalab/MinerU/raw/master/README.md#22-model-source-configuration"&gt;MinerU Model Source Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;h4&gt;1. End-to-End Document Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def main():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        parser="mineru",  # Parser selection: mineru or docling
        parse_method="auto",  # Parse method: auto, ocr, or txt
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define LLM model function
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Define embedding function
    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Process a document
    await rag.process_document_complete(
        file_path="path/to/your/document.pdf",
        output_dir="./output",
        parse_method="auto"
    )

    # Query the processed content
    # Pure text query - for basic knowledge base search
    text_result = await rag.aquery(
        "What are the main findings shown in the figures and tables?",
        mode="hybrid"
    )
    print("Text query result:", text_result)

    # Multimodal query with specific multimodal content
    multimodal_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
    print("Multimodal query result:", multimodal_result)

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Direct Multimodal Content Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc
from raganything.modalprocessors import ImageModalProcessor, TableModalProcessor

async def process_multimodal_content():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Initialize LightRAG
    rag = LightRAG(
        working_dir="./rag_storage",
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )
    await rag.initialize_storages()

    # Process an image
    image_processor = ImageModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(
            "gpt-4o",
            "",
            system_prompt=None,
            history_messages=[],
            messages=[
                {"role": "system", "content": system_prompt} if system_prompt else None,
                {"role": "user", "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                ]} if image_data else {"role": "user", "content": prompt}
            ],
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ) if image_data else openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    image_content = {
        "img_path": "path/to/image.jpg",
        "image_caption": ["Figure 1: Experimental results"],
        "image_footnote": ["Data collected in 2024"]
    }

    description, entity_info = await image_processor.process_multimodal_content(
        modal_content=image_content,
        content_type="image",
        file_path="research_paper.pdf",
        entity_name="Experimental Results Figure"
    )

    # Process a table
    table_processor = TableModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    table_content = {
        "table_body": """
        | Method | Accuracy | F1-Score |
        |--------|----------|----------|
        | RAGAnything | 95.2% | 0.94 |
        | Baseline | 87.3% | 0.85 |
        """,
        "table_caption": ["Performance Comparison"],
        "table_footnote": ["Results on test dataset"]
    }

    description, entity_info = await table_processor.process_multimodal_content(
        modal_content=table_content,
        content_type="table",
        file_path="research_paper.pdf",
        entity_name="Performance Results Table"
    )

if __name__ == "__main__":
    asyncio.run(process_multimodal_content())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Batch Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Process multiple documents
await rag.process_folder_complete(
    folder_path="./documents",
    output_dir="./output",
    file_extensions=[".pdf", ".docx", ".pptx"],
    recursive=True,
    max_workers=4
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Custom Modal Processors&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from raganything.modalprocessors import GenericModalProcessor

class CustomModalProcessor(GenericModalProcessor):
    async def process_multimodal_content(self, modal_content, content_type, file_path, entity_name):
        # Your custom processing logic
        enhanced_description = await self.analyze_custom_content(modal_content)
        entity_info = self.create_custom_entity(enhanced_description, entity_name)
        return await self._create_entity_and_chunk(enhanced_description, entity_info, file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. Query Options&lt;/h4&gt; 
&lt;p&gt;RAG-Anything provides three types of query methods:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Pure Text Queries&lt;/strong&gt; - Direct knowledge base search using LightRAG:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Different query modes for text queries
text_result_hybrid = await rag.aquery("Your question", mode="hybrid")
text_result_local = await rag.aquery("Your question", mode="local")
text_result_global = await rag.aquery("Your question", mode="global")
text_result_naive = await rag.aquery("Your question", mode="naive")

# Synchronous version
sync_text_result = rag.query("Your question", mode="hybrid")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;VLM Enhanced Queries&lt;/strong&gt; - Automatically analyze images in retrieved context using VLM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# VLM enhanced query (automatically enabled when vision_model_func is provided)
vlm_result = await rag.aquery(
    "Analyze the charts and figures in the document",
    mode="hybrid"
    # vlm_enhanced=True is automatically set when vision_model_func is available
)

# Manually control VLM enhancement
vlm_enabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=True  # Force enable VLM enhancement
)

vlm_disabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=False  # Force disable VLM enhancement
)

# When documents contain images, VLM can see and analyze them directly
# The system will automatically:
# 1. Retrieve relevant context containing image paths
# 2. Load and encode images as base64
# 3. Send both text context and images to VLM for comprehensive analysis
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Multimodal Queries&lt;/strong&gt; - Enhanced queries with specific multimodal content analysis:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Query with table data
table_result = await rag.aquery_with_multimodal(
    "Compare these performance metrics with the document content",
    multimodal_content=[{
        "type": "table",
        "table_data": """Method,Accuracy,Speed
                        RAGAnything,95.2%,120ms
                        Traditional,87.3%,180ms""",
        "table_caption": "Performance comparison"
    }],
    mode="hybrid"
)

# Query with equation content
equation_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;6. Loading Existing LightRAG Instance&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.kg.shared_storage import initialize_pipeline_status
from lightrag.utils import EmbeddingFunc
import os

async def load_existing_lightrag():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # First, create or load existing LightRAG instance
    lightrag_working_dir = "./existing_lightrag_storage"

    # Check if previous LightRAG instance exists
    if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):
        print("‚úÖ Found existing LightRAG instance, loading...")
    else:
        print("‚ùå No existing LightRAG instance found, will create new one")

    # Create/load LightRAG instance with your configuration
    lightrag_instance = LightRAG(
        working_dir=lightrag_working_dir,
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )

    # Initialize storage (this will load existing data if available)
    await lightrag_instance.initialize_storages()
    await initialize_pipeline_status()

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return lightrag_instance.llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Now use existing LightRAG instance to initialize RAGAnything
    rag = RAGAnything(
        lightrag=lightrag_instance,  # Pass existing LightRAG instance
        vision_model_func=vision_model_func,
        # Note: working_dir, llm_model_func, embedding_func, etc. are inherited from lightrag_instance
    )

    # Query existing knowledge base
    result = await rag.aquery(
        "What data has been processed in this LightRAG instance?",
        mode="hybrid"
    )
    print("Query result:", result)

    # Add new multimodal document to existing LightRAG instance
    await rag.process_document_complete(
        file_path="path/to/new/multimodal_document.pdf",
        output_dir="./output"
    )

if __name__ == "__main__":
    asyncio.run(load_existing_lightrag())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;7. Direct Content List Insertion&lt;/h4&gt; 
&lt;p&gt;For scenarios where you already have a pre-parsed content list (e.g., from external parsers or previous processing), you can directly insert it into RAGAnything without document parsing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def insert_content_list_example():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define model functions
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    def vision_model_func(prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                        ],
                    } if image_data else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Example: Pre-parsed content list from external source
    content_list = [
        {
            "type": "text",
            "text": "This is the introduction section of our research paper.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "image",
            "img_path": "/absolute/path/to/figure1.jpg",  # IMPORTANT: Use absolute path
            "image_caption": ["Figure 1: System Architecture"],
            "image_footnote": ["Source: Authors' original design"],
            "page_idx": 1  # Page number where this image appears
        },
        {
            "type": "table",
            "table_body": "| Method | Accuracy | F1-Score |\n|--------|----------|----------|\n| Ours | 95.2% | 0.94 |\n| Baseline | 87.3% | 0.85 |",
            "table_caption": ["Table 1: Performance Comparison"],
            "table_footnote": ["Results on test dataset"],
            "page_idx": 2  # Page number where this table appears
        },
        {
            "type": "equation",
            "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
            "text": "Document relevance probability formula",
            "page_idx": 3  # Page number where this equation appears
        },
        {
            "type": "text",
            "text": "In conclusion, our method demonstrates superior performance across all metrics.",
            "page_idx": 4  # Page number where this content appears
        }
    ]

    # Insert the content list directly
    await rag.insert_content_list(
        content_list=content_list,
        file_path="research_paper.pdf",  # Reference file name for citation
        split_by_character=None,         # Optional text splitting
        split_by_character_only=False,   # Optional text splitting mode
        doc_id=None,                     # Optional custom document ID (will be auto-generated if not provided)
        display_stats=True               # Show content statistics
    )

    # Query the inserted content
    result = await rag.aquery(
        "What are the key findings and performance metrics mentioned in the research?",
        mode="hybrid"
    )
    print("Query result:", result)

    # You can also insert multiple content lists with different document IDs
    another_content_list = [
        {
            "type": "text",
            "text": "This is content from another document.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "table",
            "table_body": "| Feature | Value |\n|---------|-------|\n| Speed | Fast |\n| Accuracy | High |",
            "table_caption": ["Feature Comparison"],
            "page_idx": 1  # Page number where this table appears
        }
    ]

    await rag.insert_content_list(
        content_list=another_content_list,
        file_path="another_document.pdf",
        doc_id="custom-doc-id-123"  # Custom document ID
    )

if __name__ == "__main__":
    asyncio.run(insert_content_list_example())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Content List Format:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;content_list&lt;/code&gt; should follow the standard format with each item being a dictionary containing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text content&lt;/strong&gt;: &lt;code&gt;{"type": "text", "text": "content text", "page_idx": 0}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image content&lt;/strong&gt;: &lt;code&gt;{"type": "image", "img_path": "/absolute/path/to/image.jpg", "image_caption": ["caption"], "image_footnote": ["note"], "page_idx": 1}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Table content&lt;/strong&gt;: &lt;code&gt;{"type": "table", "table_body": "markdown table", "table_caption": ["caption"], "table_footnote": ["note"], "page_idx": 2}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equation content&lt;/strong&gt;: &lt;code&gt;{"type": "equation", "latex": "LaTeX formula", "text": "description", "page_idx": 3}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic content&lt;/strong&gt;: &lt;code&gt;{"type": "custom_type", "content": "any content", "page_idx": 4}&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important Notes:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;img_path&lt;/code&gt;&lt;/strong&gt;: Must be an absolute path to the image file (e.g., &lt;code&gt;/home/user/images/chart.jpg&lt;/code&gt; or &lt;code&gt;C:\Users\user\images\chart.jpg&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;page_idx&lt;/code&gt;&lt;/strong&gt;: Represents the page number where the content appears in the original document (0-based indexing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content ordering&lt;/strong&gt;: Items are processed in the order they appear in the list&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This method is particularly useful when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You have content from external parsers (non-MinerU/Docling)&lt;/li&gt; 
 &lt;li&gt;You want to process programmatically generated content&lt;/li&gt; 
 &lt;li&gt;You need to insert content from multiple sources into a single knowledge base&lt;/li&gt; 
 &lt;li&gt;You have cached parsing results that you want to reuse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üõ†Ô∏è Examples&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Practical Implementation Demos&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212257455-13e3e01e-d6a6-45dc-bb92-3ab87b12dfc1.gif" width="300" /&gt; 
&lt;/div&gt; 
&lt;p&gt;The &lt;code&gt;examples/&lt;/code&gt; directory contains comprehensive usage examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;raganything_example.py&lt;/code&gt;&lt;/strong&gt;: End-to-end document processing with MinerU&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;modalprocessors_example.py&lt;/code&gt;&lt;/strong&gt;: Direct multimodal content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;office_document_test.py&lt;/code&gt;&lt;/strong&gt;: Office document parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;image_format_test.py&lt;/code&gt;&lt;/strong&gt;: Image format parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;text_format_test.py&lt;/code&gt;&lt;/strong&gt;: Text format parsing test with MinerU (no API key required)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Run examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# End-to-end processing with parser selection
python examples/raganything_example.py path/to/document.pdf --api-key YOUR_API_KEY --parser mineru

# Direct modal processing
python examples/modalprocessors_example.py --api-key YOUR_API_KEY

# Office document parsing test (MinerU only)
python examples/office_document_test.py --file path/to/document.docx

# Image format parsing test (MinerU only)
python examples/image_format_test.py --file path/to/image.bmp

# Text format parsing test (MinerU only)
python examples/text_format_test.py --file path/to/document.md

# Check LibreOffice installation
python examples/office_document_test.py --check-libreoffice --file dummy

# Check PIL/Pillow installation
python examples/image_format_test.py --check-pillow --file dummy

# Check ReportLab installation
python examples/text_format_test.py --check-reportlab --file dummy
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîß Configuration&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;System Optimization Parameters&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file (refer to &lt;code&gt;.env.example&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY=your_openai_api_key
OPENAI_BASE_URL=your_base_url  # Optional
OUTPUT_DIR=./output             # Default output directory for parsed documents
PARSER=mineru                   # Parser selection: mineru or docling
PARSE_METHOD=auto              # Parse method: auto, ocr, or txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For backward compatibility, legacy environment variable names are still supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;MINERU_PARSE_METHOD&lt;/code&gt; is deprecated, please use &lt;code&gt;PARSE_METHOD&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: API keys are only required for full RAG processing with LLM integration. The parsing test files (&lt;code&gt;office_document_test.py&lt;/code&gt; and &lt;code&gt;image_format_test.py&lt;/code&gt;) only test parser functionality and do not require API keys.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Parser Configuration&lt;/h3&gt; 
&lt;p&gt;RAGAnything now supports multiple parsers, each with specific advantages:&lt;/p&gt; 
&lt;h4&gt;MinerU Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports PDF, images, Office documents, and more formats&lt;/li&gt; 
 &lt;li&gt;Powerful OCR and table extraction capabilities&lt;/li&gt; 
 &lt;li&gt;GPU acceleration support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Docling Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Optimized for Office documents and HTML files&lt;/li&gt; 
 &lt;li&gt;Better document structure preservation&lt;/li&gt; 
 &lt;li&gt;Native support for multiple Office formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MinerU Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# MinerU 2.0 uses command-line parameters instead of config files
# Check available options:
mineru --help

# Common configurations:
mineru -p input.pdf -o output_dir -m auto    # Automatic parsing mode
mineru -p input.pdf -o output_dir -m ocr     # OCR-focused parsing
mineru -p input.pdf -o output_dir -b pipeline --device cuda  # GPU acceleration
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also configure parsing through RAGAnything parameters:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Basic parsing configuration with parser selection
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # or "ocr", "txt"
    parser="mineru"               # Optional: "mineru" or "docling"
)

# Advanced parsing configuration with special parameters
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # Parsing method: "auto", "ocr", "txt"
    parser="mineru",              # Parser selection: "mineru" or "docling"

    # MinerU special parameters - all supported kwargs:
    lang="ch",                   # Document language for OCR optimization (e.g., "ch", "en", "ja")
    device="cuda:0",             # Inference device: "cpu", "cuda", "cuda:0", "npu", "mps"
    start_page=0,                # Starting page number (0-based, for PDF)
    end_page=10,                 # Ending page number (0-based, for PDF)
    formula=True,                # Enable formula parsing
    table=True,                  # Enable table parsing
    backend="pipeline",          # Parsing backend: pipeline|vlm-transformers|vlm-sglang-engine|vlm-sglang-client.
    source="huggingface",        # Model source: "huggingface", "modelscope", "local"
    # vlm_url="http://127.0.0.1:3000" # Service address when using backend=vlm-sglang-client

    # Standard RAGAnything parameters
    display_stats=True,          # Display content statistics
    split_by_character=None,     # Optional character to split text by
    doc_id=None                  # Optional document ID
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: MinerU 2.0 no longer uses the &lt;code&gt;magic-pdf.json&lt;/code&gt; configuration file. All settings are now passed as command-line parameters or function arguments. RAG-Anything now supports multiple document parsers - you can choose between MinerU and Docling based on your needs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Processing Requirements&lt;/h3&gt; 
&lt;p&gt;Different content types require specific optional dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; (.doc, .docx, .ppt, .pptx, .xls, .xlsx): Install &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extended Image Formats&lt;/strong&gt; (.bmp, .tiff, .gif, .webp): Install with &lt;code&gt;pip install raganything[image]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; (.txt, .md): Install with &lt;code&gt;pip install raganything[text]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üìã Quick Install&lt;/strong&gt;: Use &lt;code&gt;pip install raganything[all]&lt;/code&gt; to enable all format support (Python dependencies only - LibreOffice still needs separate installation)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üß™ Supported Content Types&lt;/h2&gt; 
&lt;h3&gt;Document Formats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PDFs&lt;/strong&gt; - Research papers, reports, presentations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; - DOC, DOCX, PPT, PPTX, XLS, XLSX&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - JPG, PNG, BMP, TIFF, GIF, WebP&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; - TXT, MD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Multimodal Elements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - Photographs, diagrams, charts, screenshots&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tables&lt;/strong&gt; - Data tables, comparison charts, statistical summaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equations&lt;/strong&gt; - Mathematical formulas in LaTeX format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic Content&lt;/strong&gt; - Custom content types via extensible processors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;For installation of format-specific dependencies, see the &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-configuration"&gt;Configuration&lt;/a&gt; section.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìñ Citation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Academic Reference&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 60px; height: 60px; margin: 20px auto; position: relative;"&gt; 
  &lt;div style="width: 100%; height: 100%; border: 2px solid #00d9ff; border-radius: 50%; position: relative;"&gt; 
   &lt;div style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); font-size: 24px; color: #00d9ff;"&gt;
    üìñ
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div style="position: absolute; bottom: -5px; left: 50%; transform: translateX(-50%); width: 20px; height: 20px; background: white; border-right: 2px solid #00d9ff; border-bottom: 2px solid #00d9ff; transform: rotate(45deg);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;If you find RAG-Anything useful in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{guo2024lightrag,
  title={LightRAG: Simple and Fast Retrieval-Augmented Generation},
  author={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},
  year={2024},
  eprint={2410.05779},
  archivePrefix={arXiv},
  primaryClass={cs.IR}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîó Related Projects&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Ecosystem &amp;amp; Extensions&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;‚ö°&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;LightRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Simple and Fast RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/VideoRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;üé•&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;VideoRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extreme Long-Context Video RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/MiniRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;‚ú®&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;MiniRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extremely Simple RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://star-history.com/#HKUDS/RAG-Anything&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contribution&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Join the Innovation&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt;
  We thank all our contributors for their valuable contributions. 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/HKUDS/RAG-Anything/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=HKUDS/RAG-Anything" style="border-radius: 15px; box-shadow: 0 0 20px rgba(0, 217, 255, 0.3);" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 30px; margin: 30px 0;"&gt; 
 &lt;div&gt; 
  &lt;img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="500" /&gt; 
 &lt;/div&gt; 
 &lt;div style="margin-top: 20px;"&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/‚≠ê%20Star%20us%20on%20GitHub-1a1a2e?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/issues" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/üêõ%20Report%20Issues-ff6b6b?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/discussions" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/üí¨%20Discussions-4ecdc4?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: center; align-items: center; gap: 15px;"&gt; 
   &lt;span style="font-size: 24px;"&gt;‚≠ê&lt;/span&gt; 
   &lt;span style="color: #00d9ff; font-size: 18px;"&gt;Thank you for visiting RAG-Anything!&lt;/span&gt; 
   &lt;span style="font-size: 24px;"&gt;‚≠ê&lt;/span&gt; 
  &lt;/div&gt; 
  &lt;div style="margin-top: 10px; color: #00d9ff; font-size: 16px;"&gt;
   Building the Future of Multimodal AI
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>qodo-ai/pr-agent</title>
      <link>https://github.com/qodo-ai/pr-agent</link>
      <description>&lt;p&gt;üöÄ PR-Agent: An AI-Powered ü§ñ Tool for Automated Pull Request Analysis, Feedback, Suggestions and More! üíªüîç (For more advanced: check Qodo Merge)&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div align="center"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://www.qodo.ai/wp-content/uploads/2025/02/PR-Agent-Purple-2.png" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://www.qodo.ai/wp-content/uploads/2025/02/PR-Agent-Purple-2.png" /&gt; 
   &lt;img src="https://codium.ai/images/pr_agent/logo-light.png" alt="logo" width="330" /&gt; 
  &lt;/picture&gt; 
  &lt;br /&gt; 
  &lt;p&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/installation/"&gt;Installation Guide&lt;/a&gt; | &lt;a href="https://qodo-merge-docs.qodo.ai/usage-guide/"&gt;Usage Guide&lt;/a&gt; | &lt;a href="https://qodo-merge-docs.qodo.ai/tools/"&gt;Tools Guide&lt;/a&gt; | &lt;a href="https://qodo-merge-docs.qodo.ai/overview/pr_agent_pro/"&gt;Qodo Merge&lt;/a&gt; üíé&lt;/p&gt; 
  &lt;h2&gt;Open-Source AI-Powered Code Review Tool&lt;/h2&gt; 
  &lt;p&gt;&lt;strong&gt;PR-Agent&lt;/strong&gt; is a free, open-source tool that provides AI-powered code review and PR assistance. Run it locally, on your CI/CD, or self-host it.&lt;/p&gt; 
  &lt;p&gt;&lt;strong&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/overview/pr_agent_pro/"&gt;Qodo Merge&lt;/a&gt; üíé&lt;/strong&gt; is the hosted, enterprise version with additional features, zero-setup, and priority support.&lt;/p&gt; 
  &lt;hr /&gt; 
  &lt;h3&gt;Quick Start Options&lt;/h3&gt; 
  &lt;table&gt; 
   &lt;thead&gt; 
    &lt;tr&gt; 
     &lt;th&gt;&lt;strong&gt;Option&lt;/strong&gt;&lt;/th&gt; 
     &lt;th&gt;&lt;strong&gt;Best For&lt;/strong&gt;&lt;/th&gt; 
     &lt;th&gt;&lt;strong&gt;Setup Time&lt;/strong&gt;&lt;/th&gt; 
     &lt;th&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/th&gt; 
    &lt;/tr&gt; 
   &lt;/thead&gt; 
   &lt;tbody&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#-quick-start-for-pr-agent-open-source"&gt;PR-Agent (Open Source)&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;Developers who want full control, self-hosting, or custom integrations&lt;/td&gt; 
     &lt;td&gt;5-15 minutes&lt;/td&gt; 
     &lt;td&gt;Free&lt;/td&gt; 
    &lt;/tr&gt; 
    &lt;tr&gt; 
     &lt;td&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#-try-qodo-merge-zero-setup"&gt;Qodo Merge&lt;/a&gt;&lt;/strong&gt;&lt;/td&gt; 
     &lt;td&gt;Teams wanting zero-setup, enhancing the open-source features, additional enterprise features, and managed hosting&lt;/td&gt; 
     &lt;td&gt;2 minutes&lt;/td&gt; 
     &lt;td&gt;Free tier available&lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt; 
  &lt;/table&gt; 
 &lt;/div&gt; 
 &lt;p&gt;&lt;a href="https://chromewebstore.google.com/detail/qodo-merge-ai-powered-cod/ephlnjeghhogofkifjloamocljapahnl"&gt;&lt;img src="https://img.shields.io/badge/Chrome-Extension-violet" alt="Static Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/apps/qodo-merge-pro/"&gt;&lt;img src="https://img.shields.io/badge/Pro-App-blue" alt="Static Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/apps/qodo-merge-pro-for-open-source/"&gt;&lt;img src="https://img.shields.io/badge/OpenSource-App-red" alt="Static Badge" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/SgSxuQ65GF"&gt;&lt;img src="https://badgen.net/badge/icon/discord?icon=discord&amp;amp;label&amp;amp;color=purple" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Codium-ai/pr-agent/commits/main"&gt; &lt;img alt="GitHub" src="https://img.shields.io/github/last-commit/Codium-ai/pr-agent/main?style=for-the-badge" height="20" /&gt; &lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#pr-agent-vs-qodo-merge"&gt;PR-Agent vs Qodo Merge&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#getting-started"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#why-use-pr-agent"&gt;Why Use PR-Agent?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#see-it-in-action"&gt;See It in Action&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#try-it-now"&gt;Try It Now&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#qodo-merge-"&gt;Qodo Merge üíé&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#how-it-works"&gt;How It Works&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#data-privacy"&gt;Data Privacy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/#links"&gt;Links&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;PR-Agent vs Qodo Merge&lt;/h2&gt; 
&lt;h3&gt;PR-Agent (This Repository) - Open Source&lt;/h3&gt; 
&lt;p&gt;‚úÖ &lt;strong&gt;What you get:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Complete source code access and customization&lt;/li&gt; 
 &lt;li&gt;Self-hosted deployment options&lt;/li&gt; 
 &lt;li&gt;All core AI review tools (&lt;code&gt;/describe&lt;/code&gt;, &lt;code&gt;/review&lt;/code&gt;, &lt;code&gt;/improve&lt;/code&gt;, &lt;code&gt;/ask&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Support for GitHub, GitLab, BitBucket, Azure DevOps&lt;/li&gt; 
 &lt;li&gt;CLI usage for local development&lt;/li&gt; 
 &lt;li&gt;Free forever&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‚öôÔ∏è &lt;strong&gt;What you need to manage:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Your own API keys (OpenAI, Claude, etc.)&lt;/li&gt; 
 &lt;li&gt;Infrastructure and hosting&lt;/li&gt; 
 &lt;li&gt;Updates and maintenance&lt;/li&gt; 
 &lt;li&gt;Configuration management&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Qodo Merge - Hosted Solution&lt;/h3&gt; 
&lt;p&gt;‚úÖ &lt;strong&gt;What you get (everything above plus):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Zero-setup installation (2-minute GitHub app install)&lt;/li&gt; 
 &lt;li&gt;Managed infrastructure and automatic updates&lt;/li&gt; 
 &lt;li&gt;Advanced features: CI feedback, code suggestions tracking, custom prompts&lt;/li&gt; 
 &lt;li&gt;Priority support and feature requests&lt;/li&gt; 
 &lt;li&gt;Enhanced privacy with zero data retention&lt;/li&gt; 
 &lt;li&gt;Free tier: 75 PR reviews/month per organization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üí∞ &lt;strong&gt;Pricing:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Free tier available&lt;/li&gt; 
 &lt;li&gt;Paid plans for unlimited usage&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.qodo.ai/pricing/"&gt;View pricing details&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;üë®‚Äçüíª Developer Recommendation:&lt;/strong&gt; Start with PR-Agent if you want to experiment, customize heavily, or have specific self-hosting requirements. Choose Qodo Merge if you want to focus on coding rather than tool maintenance.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;üöÄ Quick Start for PR-Agent (Open Source)&lt;/h3&gt; 
&lt;h4&gt;1. Try it Instantly (No Setup)&lt;/h4&gt; 
&lt;p&gt;Test PR-Agent on any public GitHub repository by commenting &lt;code&gt;@CodiumAI-Agent /improve&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;2. GitHub Action (Recommended)&lt;/h4&gt; 
&lt;p&gt;Add automated PR reviews to your repository with a simple workflow file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# .github/workflows/pr-agent.yml
name: PR Agent
on:
  pull_request:
    types: [opened, synchronize]
jobs:
  pr_agent_job:
    runs-on: ubuntu-latest
    steps:
    - name: PR Agent action step
      uses: Codium-ai/pr-agent@main
      env:
        OPENAI_KEY: ${{ secrets.OPENAI_KEY }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/installation/github/#run-as-a-github-action"&gt;Full GitHub Action setup guide&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;3. CLI Usage (Local Development)&lt;/h4&gt; 
&lt;p&gt;Run PR-Agent locally on your repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install pr-agent
export OPENAI_KEY=your_key_here
pr-agent --pr_url https://github.com/owner/repo/pull/123 review
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/usage-guide/automations_and_usage/#local-repo-cli"&gt;Complete CLI setup guide&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;4. Other Platforms&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/installation/gitlab/"&gt;GitLab webhook setup&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/installation/bitbucket/"&gt;BitBucket app installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/installation/azure/"&gt;Azure DevOps setup&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üíé Try Qodo Merge (Zero Setup)&lt;/h3&gt; 
&lt;p&gt;If you prefer a hosted solution without managing infrastructure:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/marketplace/qodo-merge-pro"&gt;Install Qodo Merge GitHub App&lt;/a&gt;&lt;/strong&gt; (2 minutes)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/marketplace/qodo-merge-pro-for-open-source"&gt;FREE for Open Source&lt;/a&gt;&lt;/strong&gt;: Full features, zero cost for public repos&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Free Tier&lt;/strong&gt;: 75 PR reviews/month for private repos&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.qodo.ai/pricing/"&gt;View Plans &amp;amp; Pricing&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/installation/qodo_merge/"&gt;Complete Qodo Merge setup guide&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;üíª Local IDE Integration&lt;/h3&gt; 
&lt;p&gt;Receive automatic feedback in your IDE after each commit: &lt;a href="https://github.com/qodo-ai/agents/tree/main/agents/qodo-merge-post-commit"&gt;Qodo Merge post-commit agent&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why Use PR-Agent?&lt;/h2&gt; 
&lt;h3&gt;üéØ Built for Real Development Teams&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Fast &amp;amp; Affordable&lt;/strong&gt;: Each tool (&lt;code&gt;/review&lt;/code&gt;, &lt;code&gt;/improve&lt;/code&gt;, &lt;code&gt;/ask&lt;/code&gt;) uses a single LLM call (~30 seconds, low cost)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Handles Any PR Size&lt;/strong&gt;: Our &lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/#pr-compression-strategy"&gt;PR Compression strategy&lt;/a&gt; effectively processes both small and large PRs&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Highly Customizable&lt;/strong&gt;: JSON-based prompting allows easy customization of review categories and behavior via &lt;a href="https://raw.githubusercontent.com/qodo-ai/pr-agent/main/pr_agent/settings/configuration.toml"&gt;configuration files&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Platform Agnostic&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Git Providers&lt;/strong&gt;: GitHub, GitLab, BitBucket, Azure DevOps, Gitea&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;: CLI, GitHub Actions, Docker, self-hosted, webhooks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Models&lt;/strong&gt;: OpenAI GPT, Claude, Deepseek, and more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Open Source Benefits&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Full control over your data and infrastructure&lt;/li&gt; 
 &lt;li&gt;Customize prompts and behavior for your team's needs&lt;/li&gt; 
 &lt;li&gt;No vendor lock-in&lt;/li&gt; 
 &lt;li&gt;Community-driven development&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;div style="text-align:left;"&gt; 
 &lt;p&gt;PR-Agent and Qodo Merge offer comprehensive pull request functionalities integrated with various git providers:&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th align="center"&gt;GitHub&lt;/th&gt; 
    &lt;th align="center"&gt;GitLab&lt;/th&gt; 
    &lt;th align="center"&gt;Bitbucket&lt;/th&gt; 
    &lt;th align="center"&gt;Azure DevOps&lt;/th&gt; 
    &lt;th align="center"&gt;Gitea&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/"&gt;TOOLS&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/describe/"&gt;Describe&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/review/"&gt;Review&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/improve/"&gt;Improve&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/ask/"&gt;Ask&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;‚Æë &lt;a href="https://qodo-merge-docs.qodo.ai/tools/ask/#ask-lines"&gt;Ask on code lines&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/help_docs/?h=auto#auto-approval"&gt;Help Docs&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/update_changelog/"&gt;Update CHANGELOG&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/documentation/"&gt;Add Documentation&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/analyze/"&gt;Analyze&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/improve/?h=auto#auto-approval"&gt;Auto-Approve&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/ci_feedback/"&gt;CI Feedback&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/compliance/"&gt;Compliance&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/custom_prompt/"&gt;Custom Prompt&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/custom_labels/"&gt;Generate Custom Labels&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/test/"&gt;Generate Tests&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/implement/"&gt;Implement&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/scan_repo_discussions/"&gt;Scan Repo Discussions&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/similar_code/"&gt;Similar Code&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/improve/#best-practices"&gt;Utilizing Best Practices&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/chrome-extension/features/#pr-chat"&gt;PR Chat&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/pr_to_ticket/"&gt;PR to Ticket&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/tools/improve/#suggestion-tracking"&gt;Suggestion Tracking&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/usage-guide/"&gt;USAGE&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/usage-guide/automations_and_usage/#local-repo-cli"&gt;CLI&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/usage-guide/automations_and_usage/#github-app"&gt;App / webhook&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/Codium-ai/pr-agent#try-it-now"&gt;Tagging bot&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/installation/github/#run-as-a-github-action"&gt;Actions&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/"&gt;CORE&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/compression_strategy/"&gt;Adaptive and token-aware file patch fitting&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/auto_best_practices/"&gt;Auto Best Practices üíé&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/chat_on_code_suggestions/"&gt;Chat on code suggestions&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/code_validation/"&gt;Code Validation üíé&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/dynamic_context/"&gt;Dynamic context&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/fetching_ticket_context/"&gt;Fetching ticket context&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/usage-guide/configuration_options/"&gt;Global and wiki configurations&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/impact_evaluation/"&gt;Impact Evaluation&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/incremental_update/"&gt;Incremental Update&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/interactivity/"&gt;Interactivity&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/metadata/"&gt;Local and global metadata&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/usage-guide/changing_a_model/"&gt;Multiple models support&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/compression_strategy/"&gt;PR compression&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://www.qodo.ai/images/pr_agent/pr-actions.mp4"&gt;PR interactive actions&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/rag_context_enrichment/"&gt;RAG context enrichment&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/self_reflection/"&gt;Self reflection&lt;/a&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/static_code_analysis/"&gt;Static code analysis&lt;/a&gt; üíé&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;‚úÖ&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;ul&gt; 
  &lt;li&gt;üíé means this feature is available only in &lt;a href="https://www.qodo.ai/pricing/"&gt;Qodo Merge&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;hr /&gt; 
 &lt;h2&gt;See It in Action&lt;/h2&gt; 
&lt;/div&gt; 
&lt;h4&gt;&lt;a href="https://github.com/Codium-ai/pr-agent/pull/530"&gt;/describe&lt;/a&gt;&lt;/h4&gt; 
&lt;div align="center"&gt; 
 &lt;p float="center"&gt; &lt;img src="https://www.codium.ai/images/pr_agent/describe_new_short_main.png" width="512" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h4&gt;&lt;a href="https://github.com/Codium-ai/pr-agent/pull/732#issuecomment-1975099151"&gt;/review&lt;/a&gt;&lt;/h4&gt; 
&lt;div align="center"&gt; 
 &lt;p float="center"&gt; &lt;kbd&gt; &lt;img src="https://www.codium.ai/images/pr_agent/review_new_short_main.png" width="512" /&gt; &lt;/kbd&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h4&gt;&lt;a href="https://github.com/Codium-ai/pr-agent/pull/732#issuecomment-1975099159"&gt;/improve&lt;/a&gt;&lt;/h4&gt; 
&lt;div align="center"&gt; 
 &lt;p float="center"&gt; &lt;kbd&gt; &lt;img src="https://www.codium.ai/images/pr_agent/improve_new_short_main.png" width="512" /&gt; &lt;/kbd&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="left"&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Try It Now&lt;/h2&gt; 
&lt;p&gt;Try the GPT-5 powered PR-Agent instantly on &lt;em&gt;your public GitHub repository&lt;/em&gt;. Just mention &lt;code&gt;@CodiumAI-Agent&lt;/code&gt; and add the desired command in any PR comment. The agent will generate a response based on your command. For example, add a comment to any pull request with the following text:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@CodiumAI-Agent /review
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and the agent will respond with a review of your PR.&lt;/p&gt; 
&lt;p&gt;Note that this is a promotional bot, suitable only for initial experimentation. It does not have 'edit' access to your repo, for example, so it cannot update the PR description or add labels (&lt;code&gt;@CodiumAI-Agent /describe&lt;/code&gt; will publish PR description as a comment). In addition, the bot cannot be used on private repositories, as it does not have access to the files there.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Qodo Merge üíé&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.qodo.ai/pricing/"&gt;Qodo Merge&lt;/a&gt; is the hosted version of PR-Agent with additional enterprise features.&lt;/p&gt; 
&lt;h3&gt;Key Differences from Open Source PR-Agent:&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Infrastructure &amp;amp; Management:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fully managed hosting and automatic updates&lt;/li&gt; 
 &lt;li&gt;Zero-setup installation (GitHub/GitLab/BitBucket app)&lt;/li&gt; 
 &lt;li&gt;No need to manage API keys or infrastructure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Enhanced Privacy:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Zero data retention policy&lt;/li&gt; 
 &lt;li&gt;No data used for model training&lt;/li&gt; 
 &lt;li&gt;Enterprise-grade security&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Additional Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Advanced code suggestions with tracking&lt;/li&gt; 
 &lt;li&gt;CI feedback analysis&lt;/li&gt; 
 &lt;li&gt;Custom prompts and labels&lt;/li&gt; 
 &lt;li&gt;Static code analysis integration&lt;/li&gt; 
 &lt;li&gt;Priority support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Pricing:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Free tier: 75 PR reviews/month per organization&lt;/li&gt; 
 &lt;li&gt;Paid plans for unlimited usage&lt;/li&gt; 
 &lt;li&gt;Free for open source projects&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://qodo-merge-docs.qodo.ai/overview/pr_agent_pro/"&gt;complete feature comparison&lt;/a&gt; for detailed differences.&lt;/p&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;p&gt;The following diagram illustrates PR-Agent tools and their flow:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://www.qodo.ai/images/pr_agent/diagram-v0.9.png" alt="PR-Agent Tools" /&gt;&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://qodo-merge-docs.qodo.ai/core-abilities/#pr-compression-strategy"&gt;PR Compression strategy&lt;/a&gt; page for more details on how we convert a code diff to a manageable LLM prompt&lt;/p&gt; 
&lt;h2&gt;Data Privacy&lt;/h2&gt; 
&lt;h3&gt;Self-hosted PR-Agent&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you host PR-Agent with your OpenAI API key, it is between you and OpenAI. You can read their API data privacy policy here: &lt;a href="https://openai.com/enterprise-privacy"&gt;https://openai.com/enterprise-privacy&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Qodo-hosted Qodo Merge üíé&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;When using Qodo Merge üíé, hosted by Qodo, we will not store any of your data, nor will we use it for training. You will also benefit from an OpenAI account with zero data retention.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;For certain clients, Qodo-hosted Qodo Merge will use Qodo‚Äôs proprietary models ‚Äî if this is the case, you will be notified.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;No passive collection of Code and Pull Requests‚Äô data ‚Äî Qodo Merge will be active only when you invoke it, and it will then extract and analyze only data relevant to the executed command and queried pull request.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Qodo Merge Chrome extension&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://chromewebstore.google.com/detail/qodo-merge-ai-powered-cod/ephlnjeghhogofkifjloamocljapahnl"&gt;Qodo Merge Chrome extension&lt;/a&gt; serves solely to modify the visual appearance of a GitHub PR screen. It does not transmit any user's repo or pull request code. Code is only sent for processing when a user submits a GitHub comment that activates a PR-Agent tool, in accordance with the standard privacy policy of Qodo-Merge.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;To contribute to the project, get started by reading our &lt;a href="https://github.com/qodo-ai/pr-agent/raw/b09eec265ef7d36c232063f76553efb6b53979ff/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Discord community: &lt;a href="https://discord.com/invite/SgSxuQ65GF"&gt;https://discord.com/invite/SgSxuQ65GF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Qodo site: &lt;a href="https://www.qodo.ai/"&gt;https://www.qodo.ai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Blog: &lt;a href="https://www.qodo.ai/blog/"&gt;https://www.qodo.ai/blog/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Troubleshooting: &lt;a href="https://www.qodo.ai/blog/technical-faq-and-troubleshooting/"&gt;https://www.qodo.ai/blog/technical-faq-and-troubleshooting/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Support: &lt;a href="mailto:support@qodo.ai"&gt;support@qodo.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>frappe/erpnext</title>
      <link>https://github.com/frappe/erpnext</link>
      <description>&lt;p&gt;Free and Open Source Enterprise Resource Planning (ERP)&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/erpnext"&gt; &lt;img src="https://raw.githubusercontent.com/frappe/erpnext/develop/erpnext/public/images/v16/erpnext.svg?sanitize=true" alt="ERPNext Logo" height="80px" width="80xp" /&gt; &lt;/a&gt; 
 &lt;h2&gt;ERPNext&lt;/h2&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;Powerful, Intuitive and Open-Source ERP&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://frappe.school"&gt;&lt;img src="https://img.shields.io/badge/Frappe%20School-Learn%20ERPNext-blue?style=flat-square" alt="Learn on Frappe School" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://github.com/frappe/erpnext/actions/workflows/server-tests-mariadb.yml"&gt;&lt;img src="https://github.com/frappe/erpnext/actions/workflows/server-tests-mariadb.yml/badge.svg?event=schedule" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/frappe/erpnext-worker"&gt;&lt;img src="https://img.shields.io/docker/pulls/frappe/erpnext-worker.svg?sanitize=true" alt="docker pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/erpnext/develop/erpnext/public/images/v16/hero_image.png" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://erpnext-demo.frappe.cloud/api/method/erpnext_demo.erpnext_demo.auth.login_demo"&gt;Live Demo&lt;/a&gt; - 
 &lt;a href="https://frappe.io/erpnext"&gt;Website&lt;/a&gt; - 
 &lt;a href="https://docs.frappe.io/erpnext/"&gt;Documentation&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;ERPNext&lt;/h2&gt; 
&lt;p&gt;100% Open-Source ERP system to help you run your business.&lt;/p&gt; 
&lt;h3&gt;Motivation&lt;/h3&gt; 
&lt;p&gt;Running a business is a complex task - handling invoices, tracking stock, managing personnel and even more ad-hoc activities. In a market where software is sold separately to manage each of these tasks, ERPNext does all of the above and more, for free.&lt;/p&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Accounting&lt;/strong&gt;: All the tools you need to manage cash flow in one place, right from recording transactions to summarizing and analyzing financial reports.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Order Management&lt;/strong&gt;: Track inventory levels, replenish stock, and manage sales orders, customers, suppliers, shipments, deliverables, and order fulfillment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manufacturing&lt;/strong&gt;: Simplifies the production cycle, helps track material consumption, exhibits capacity planning, handles subcontracting, and more!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Asset Management&lt;/strong&gt;: From purchase to perishment, IT infrastructure to equipment. Cover every branch of your organization, all in one centralized system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Projects&lt;/strong&gt;: Delivery both internal and external Projects on time, budget and Profitability. Track tasks, timesheets, and issues by project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details open&gt; 
 &lt;summary&gt;More&lt;/summary&gt; 
 &lt;img src="https://erpnext.com/files/v16_bom.png" /&gt; 
 &lt;img src="https://erpnext.com/files/v16_stock_summary.png" /&gt; 
 &lt;img src="https://erpnext.com/files/v16_job_card.png" /&gt; 
 &lt;img src="https://erpnext.com/files/v16_tasks.png" /&gt; 
&lt;/details&gt; 
&lt;h3&gt;Under the Hood&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe"&gt;&lt;strong&gt;Frappe Framework&lt;/strong&gt;&lt;/a&gt;: A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe-ui"&gt;&lt;strong&gt;Frappe UI&lt;/strong&gt;&lt;/a&gt;: A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production Setup&lt;/h2&gt; 
&lt;h3&gt;Managed Hosting&lt;/h3&gt; 
&lt;p&gt;You can try &lt;a href="https://frappecloud.com"&gt;Frappe Cloud&lt;/a&gt;, a simple, user-friendly and sophisticated &lt;a href="https://github.com/frappe/press"&gt;open-source&lt;/a&gt; platform to host Frappe applications with peace of mind.&lt;/p&gt; 
&lt;p&gt;It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.&lt;/p&gt; 
&lt;div&gt; 
 &lt;a href="https://erpnext-demo.frappe.cloud/app/home" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/try-on-fc-white.png" /&gt; 
   &lt;img src="https://frappe.io/files/try-on-fc-black.png" alt="Try on Frappe Cloud" height="28" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Self-Hosted&lt;/h3&gt; 
&lt;h4&gt;Docker&lt;/h4&gt; 
&lt;p&gt;Prerequisites: docker, docker-compose, git. Refer &lt;a href="https://docs.docker.com"&gt;Docker Documentation&lt;/a&gt; for more details on Docker setup.&lt;/p&gt; 
&lt;p&gt;Run following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/frappe/frappe_docker
cd frappe_docker
docker compose -f pwd.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After a couple of minutes, site should be accessible on your localhost port: 8080. Use below default login credentials to access the site.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Username: Administrator&lt;/li&gt; 
 &lt;li&gt;Password: admin&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://github.com/frappe/frappe_docker?tab=readme-ov-file#to-run-on-arm64-architecture-follow-this-instructions"&gt;Frappe Docker&lt;/a&gt; for ARM based docker setup.&lt;/p&gt; 
&lt;h2&gt;Development Setup&lt;/h2&gt; 
&lt;h3&gt;Manual Install&lt;/h3&gt; 
&lt;p&gt;The Easy Way: our install script for bench will install all dependencies (e.g. MariaDB). See &lt;a href="https://github.com/frappe/bench"&gt;https://github.com/frappe/bench&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;New passwords will be created for the ERPNext "Administrator" user, the MariaDB root user, and the frappe user (the script displays the passwords and saves them to ~/frappe_passwords.txt).&lt;/p&gt; 
&lt;h3&gt;Local&lt;/h3&gt; 
&lt;p&gt;To setup the repository locally follow the steps mentioned below:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Setup bench by following the &lt;a href="https://frappeframework.com/docs/user/en/installation"&gt;Installation Steps&lt;/a&gt; and start the server&lt;/p&gt; &lt;pre&gt;&lt;code&gt;bench start
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In a separate terminal window, run the following commands:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Create a new site
bench new-site erpnext.localhost
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Get the ERPNext app and install it&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Get the ERPNext app
bench get-app https://github.com/frappe/erpnext

# Install the app
bench --site erpnext.localhost install-app erpnext
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Open the URL &lt;code&gt;http://erpnext.localhost:8000/app&lt;/code&gt; in your browser, you should see the app running&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Learning and community&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://school.frappe.io"&gt;Frappe School&lt;/a&gt; - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.erpnext.com/"&gt;Official documentation&lt;/a&gt; - Extensive documentation for ERPNext.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discuss.erpnext.com/"&gt;Discussion Forum&lt;/a&gt; - Engage with community of ERPNext users and service providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext_public.t.me"&gt;Telegram Group&lt;/a&gt; - Get instant help from huge community of users.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Issue-Guidelines"&gt;Issue Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext.com/security"&gt;Report Security Vulnerabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Contribution-Guidelines"&gt;Pull Request Requirements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://crowdin.com/project/frappe"&gt;Translations&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Logo and Trademark Policy&lt;/h2&gt; 
&lt;p&gt;Please read our &lt;a href="https://raw.githubusercontent.com/frappe/erpnext/develop/TRADEMARK_POLICY.md"&gt;Logo and Trademark Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;div align="center" style="padding-top: 0.75rem;"&gt; 
 &lt;a href="https://frappe.io" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/Frappe-white.png" /&gt; 
   &lt;img src="https://frappe.io/files/Frappe-black.png" alt="Frappe Technologies" height="28" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>yt-dlp/yt-dlp</title>
      <link>https://github.com/yt-dlp/yt-dlp</link>
      <description>&lt;p&gt;A feature-rich command-line audio/video downloader&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#readme"&gt;&lt;img src="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/banner.svg?sanitize=true" alt="YT-DLP" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation" title="Installation"&gt;&lt;img src="https://img.shields.io/github/v/release/yt-dlp/yt-dlp?color=brightgreen&amp;amp;label=Download&amp;amp;style=for-the-badge" alt="Release version" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp" title="PyPI"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Collaborators.md#collaborators" title="Donate"&gt;&lt;img src="https://img.shields.io/badge/_-Donate-red.svg?logo=githubsponsors&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="Donate" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/H5MNcFW63r" title="Discord"&gt;&lt;img src="https://img.shields.io/discord/807245652072857610?color=blue&amp;amp;labelColor=555555&amp;amp;label=&amp;amp;logo=discord&amp;amp;style=for-the-badge" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md" title="Supported Sites"&gt;&lt;img src="https://img.shields.io/badge/-Supported_Sites-brightgreen.svg?style=for-the-badge" alt="Supported Sites" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE" title="License"&gt;&lt;img src="https://img.shields.io/badge/-Unlicense-blue.svg?style=for-the-badge" alt="License: Unlicense" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/actions" title="CI Status"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/yt-dlp/yt-dlp/core.yml?branch=master&amp;amp;label=Tests&amp;amp;style=for-the-badge" alt="CI Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/commits" title="Commit History"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/yt-dlp/yt-dlp?label=commits&amp;amp;style=for-the-badge" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/pulse/monthly" title="Last activity"&gt;&lt;img src="https://img.shields.io/github/last-commit/yt-dlp/yt-dlp/master?label=&amp;amp;style=for-the-badge&amp;amp;display_timestamp=committer" alt="Last Commit" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;yt-dlp is a feature-rich command-line audio/video downloader with support for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;thousands of sites&lt;/a&gt;. The project is a fork of &lt;a href="https://github.com/ytdl-org/youtube-dl"&gt;youtube-dl&lt;/a&gt; based on the now inactive &lt;a href="https://github.com/blackjack4494/yt-dlc"&gt;youtube-dlc&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "USAGE AND OPTIONS" SECTION HERE --&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installation"&gt;INSTALLATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;Detailed instructions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;Release Files&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update"&gt;Update&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;Dependencies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#compile"&gt;Compile&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#usage-and-options"&gt;USAGE AND OPTIONS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#general-options"&gt;General Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#network-options"&gt;Network Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#geo-restriction"&gt;Geo-restriction&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-selection"&gt;Video Selection&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#download-options"&gt;Download Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filesystem-options"&gt;Filesystem Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#thumbnail-options"&gt;Thumbnail Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#internet-shortcut-options"&gt;Internet Shortcut Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#verbosity-and-simulation-options"&gt;Verbosity and Simulation Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#workarounds"&gt;Workarounds&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#video-format-options"&gt;Video Format Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#subtitle-options"&gt;Subtitle Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-options"&gt;Authentication Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;Post-processing Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-options"&gt;Extractor Options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#preset-aliases"&gt;Preset Aliases&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration-file-encoding"&gt;Configuration file encoding&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#authentication-with-netrc"&gt;Authentication with netrc&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;OUTPUT TEMPLATE&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;Output template examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;FORMAT SELECTION&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;Format Selection examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;MODIFYING METADATA&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata-examples"&gt;Modifying metadata examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extractor-arguments"&gt;EXTRACTOR ARGUMENTS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;PLUGINS&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#installing-plugins"&gt;Installing Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#developing-plugins"&gt;Developing Plugins&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-yt-dlp"&gt;EMBEDDING YT-DLP&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#embedding-examples"&gt;Embedding examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#changes-from-youtube-dl"&gt;CHANGES FROM YOUTUBE-DL&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#new-features"&gt;New features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#differences-in-default-behavior"&gt;Differences in default behavior&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#deprecated-options"&gt;Deprecated options&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;WIKI&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/FAQ"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;h1&gt;INSTALLATION&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;&lt;img src="https://img.shields.io/badge/-Windows_x64-blue.svg?style=for-the-badge&amp;amp;logo=windows" alt="Windows" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-Linux/BSD-red.svg?style=for-the-badge&amp;amp;logo=linux" alt="Unix" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;&lt;img src="https://img.shields.io/badge/-MacOS-lightblue.svg?style=for-the-badge&amp;amp;logo=apple" alt="MacOS" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/yt-dlp"&gt;&lt;img src="https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;amp;labelColor=555555&amp;amp;style=for-the-badge" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;&lt;img src="https://img.shields.io/badge/-Source_tar-green.svg?style=for-the-badge" alt="Source Tarball" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;&lt;img src="https://img.shields.io/badge/-Other-grey.svg?style=for-the-badge" alt="Other variants" /&gt;&lt;/a&gt; &lt;a href="https://github.com/yt-dlp/yt-dlp/releases"&gt;&lt;img src="https://img.shields.io/badge/-All_Versions-lightgrey.svg?style=for-the-badge" alt="All versions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;You can install yt-dlp using &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;the binaries&lt;/a&gt;, &lt;a href="https://pypi.org/project/yt-dlp"&gt;pip&lt;/a&gt; or one using a third-party package manager. See &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation"&gt;the wiki&lt;/a&gt; for detailed instructions&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;h2&gt;RELEASE FILES&lt;/h2&gt; 
&lt;h4&gt;Recommended&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp"&gt;yt-dlp&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Platform-independent &lt;a href="https://docs.python.org/3/library/zipimport.html"&gt;zipimport&lt;/a&gt; binary. Needs Python (recommended for &lt;strong&gt;Linux/BSD&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe"&gt;yt-dlp.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x64 binary (recommended for &lt;strong&gt;Windows&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos"&gt;yt-dlp_macos&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Universal MacOS (10.15+) standalone executable (recommended for &lt;strong&gt;MacOS&lt;/strong&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Alternatives&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux"&gt;yt-dlp_linux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (glibc 2.17+) standalone x86_64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux.zip"&gt;yt-dlp_linux.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.17+) x86_64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64"&gt;yt-dlp_linux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (glibc 2.17+) standalone aarch64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64.zip"&gt;yt-dlp_linux_aarch64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.17+) aarch64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_armv7l.zip"&gt;yt-dlp_linux_armv7l.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (glibc 2.31+) armv7l executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux"&gt;yt-dlp_musllinux&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (musl 1.2+) standalone x86_64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux.zip"&gt;yt-dlp_musllinux.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (musl 1.2+) x86_64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux_aarch64"&gt;yt-dlp_musllinux_aarch64&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Linux (musl 1.2+) standalone aarch64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_musllinux_aarch64.zip"&gt;yt-dlp_musllinux_aarch64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Linux (musl 1.2+) aarch64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_x86.exe"&gt;yt-dlp_x86.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win8+) standalone x86 (32-bit) binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_x86.zip"&gt;yt-dlp_win_x86.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x86 (32-bit) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_arm64.exe"&gt;yt-dlp_arm64.exe&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Windows (Win10+) standalone ARM64 binary&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win_arm64.zip"&gt;yt-dlp_win_arm64.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win10+) ARM64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win.zip"&gt;yt-dlp_win.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged Windows (Win8+) x64 executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos.zip"&gt;yt-dlp_macos.zip&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Unpackaged MacOS (10.15+) executable (no auto-update)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Misc&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;File&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;yt-dlp.tar.gz&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Source tarball&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS"&gt;SHA2-512SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS.sig"&gt;SHA2-512SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA512 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS"&gt;SHA2-256SUMS&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GNU-style SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS.sig"&gt;SHA2-256SUMS.sig&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;GPG signature file for SHA256 sums&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The public key that can be used to verify the GPG signatures is &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/public.key"&gt;available here&lt;/a&gt; Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import
gpg --verify SHA2-256SUMS.sig SHA2-256SUMS
gpg --verify SHA2-512SUMS.sig SHA2-512SUMS
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Licensing&lt;/h4&gt; 
&lt;p&gt;While yt-dlp is licensed under the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE"&gt;Unlicense&lt;/a&gt;, many of the release files contain code from other projects with different licenses.&lt;/p&gt; 
&lt;p&gt;Most notably, the PyInstaller-bundled executables include GPLv3+ licensed code, and as such the combined work is licensed under &lt;a href="https://www.gnu.org/licenses/gpl-3.0.html"&gt;GPLv3+&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/THIRD_PARTY_LICENSES.txt"&gt;THIRD_PARTY_LICENSES.txt&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;The zipimport binary (&lt;code&gt;yt-dlp&lt;/code&gt;), the source tarball (&lt;code&gt;yt-dlp.tar.gz&lt;/code&gt;), and the PyPI source distribution &amp;amp; wheel only contain code licensed under the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/LICENSE"&gt;Unlicense&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The manpages, shell completion (autocomplete) files etc. are available inside the &lt;a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz"&gt;source tarball&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;UPDATE&lt;/h2&gt; 
&lt;p&gt;You can use &lt;code&gt;yt-dlp -U&lt;/code&gt; to update if you are using the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#release-files"&gt;release binaries&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#with-pip"&gt;installed with pip&lt;/a&gt;, simply re-run the same command that was used to install the program&lt;/p&gt; 
&lt;p&gt;For other third-party package managers, see &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Installation#third-party-package-managers"&gt;the wiki&lt;/a&gt; or refer to their documentation&lt;/p&gt; 
&lt;p&gt;&lt;a id="update-channels"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;There are currently three release channels for binaries: &lt;code&gt;stable&lt;/code&gt;, &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;stable&lt;/code&gt; is the default channel, and many of its changes have been tested by users of the &lt;code&gt;nightly&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt; channels.&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;nightly&lt;/code&gt; channel has releases scheduled to build every day around midnight UTC, for a snapshot of the project's new patches and changes. This is the &lt;strong&gt;recommended channel for regular users&lt;/strong&gt; of yt-dlp. The &lt;code&gt;nightly&lt;/code&gt; releases are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-nightly-builds/releases"&gt;yt-dlp/yt-dlp-nightly-builds&lt;/a&gt; or as development releases of the &lt;code&gt;yt-dlp&lt;/code&gt; PyPI package (which can be installed with pip's &lt;code&gt;--pre&lt;/code&gt; flag).&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;master&lt;/code&gt; channel features releases that are built after each push to the master branch, and these will have the very latest fixes and additions, but may also be more prone to regressions. They are available from &lt;a href="https://github.com/yt-dlp/yt-dlp-master-builds/releases"&gt;yt-dlp/yt-dlp-master-builds&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When using &lt;code&gt;--update&lt;/code&gt;/&lt;code&gt;-U&lt;/code&gt;, a release binary will only update to its current channel. &lt;code&gt;--update-to CHANNEL&lt;/code&gt; can be used to switch to a different channel when a newer version is available. &lt;code&gt;--update-to [CHANNEL@]TAG&lt;/code&gt; can also be used to upgrade or downgrade to specific tags from a channel.&lt;/p&gt; 
&lt;p&gt;You may also use &lt;code&gt;--update-to &amp;lt;repository&amp;gt;&lt;/code&gt; (&lt;code&gt;&amp;lt;owner&amp;gt;/&amp;lt;repository&amp;gt;&lt;/code&gt;) to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories.&lt;/p&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to master&lt;/code&gt; switch to the &lt;code&gt;master&lt;/code&gt; channel and update to its latest release&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to stable@2023.07.06&lt;/code&gt; upgrade/downgrade to release to &lt;code&gt;stable&lt;/code&gt; channel tag &lt;code&gt;2023.07.06&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to 2023.10.07&lt;/code&gt; upgrade/downgrade to tag &lt;code&gt;2023.10.07&lt;/code&gt; if it exists on the current channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yt-dlp --update-to example/yt-dlp@2023.09.24&lt;/code&gt; upgrade/downgrade to the release from the &lt;code&gt;example/yt-dlp&lt;/code&gt; repository, tag &lt;code&gt;2023.09.24&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Any user experiencing an issue with the &lt;code&gt;stable&lt;/code&gt; release should install or update to the &lt;code&gt;nightly&lt;/code&gt; release before submitting a bug report:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# To update to nightly from stable executable/binary:
yt-dlp --update-to nightly

# To install nightly with pip:
python3 -m pip install -U --pre "yt-dlp[default]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running a yt-dlp version that is older than 90 days, you will see a warning message suggesting to update to the latest version. You can suppress this warning by adding &lt;code&gt;--no-update&lt;/code&gt; to your command or configuration file.&lt;/p&gt; 
&lt;h2&gt;DEPENDENCIES&lt;/h2&gt; 
&lt;p&gt;Python versions 3.9+ (CPython) and 3.11+ (PyPy) are supported. Other versions and implementations may or may not work correctly.&lt;/p&gt; 
&lt;!-- Python 3.5+ uses VC++14 and it is already embedded in the binary created
&lt;!x-- https://www.microsoft.com/en-us/download/details.aspx?id=26999 --x&gt;
On Windows, [Microsoft Visual C++ 2010 SP1 Redistributable Package (x86)](https://download.microsoft.com/download/1/6/5/165255E7-1014-4D0A-B094-B6A430A6BFFC/vcredist_x86.exe) is also necessary to run yt-dlp. You probably already have this, but if the executable throws an error due to missing `MSVCR100.dll` you need to install it manually.
--&gt; 
&lt;p&gt;While all the other dependencies are optional, &lt;code&gt;ffmpeg&lt;/code&gt; and &lt;code&gt;ffprobe&lt;/code&gt; are highly recommended&lt;/p&gt; 
&lt;h3&gt;Strongly recommended&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.ffmpeg.org"&gt;&lt;strong&gt;ffmpeg&lt;/strong&gt; and &lt;strong&gt;ffprobe&lt;/strong&gt;&lt;/a&gt; - Required for &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;merging separate video and audio files&lt;/a&gt;, as well as for various &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#post-processing-options"&gt;post-processing&lt;/a&gt; tasks. License &lt;a href="https://www.ffmpeg.org/legal.html"&gt;depends on the build&lt;/a&gt;&lt;/p&gt; &lt;p&gt;There are bugs in ffmpeg that cause various issues when used alongside yt-dlp. Since ffmpeg is such an important dependency, we provide &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#ffmpeg-static-auto-builds"&gt;custom builds&lt;/a&gt; with patches for some of these issues at &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds"&gt;yt-dlp/FFmpeg-Builds&lt;/a&gt;. See &lt;a href="https://github.com/yt-dlp/FFmpeg-Builds#patches-applied"&gt;the readme&lt;/a&gt; for details on the specific issues solved by these builds&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: What you need is ffmpeg &lt;em&gt;binary&lt;/em&gt;, &lt;strong&gt;NOT&lt;/strong&gt; &lt;a href="https://pypi.org/project/ffmpeg"&gt;the Python package of the same name&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Networking&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/certifi/python-certifi"&gt;&lt;strong&gt;certifi&lt;/strong&gt;&lt;/a&gt;* - Provides Mozilla's root certificate bundle. Licensed under &lt;a href="https://github.com/certifi/python-certifi/raw/master/LICENSE"&gt;MPLv2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/google/brotli"&gt;&lt;strong&gt;brotli&lt;/strong&gt;&lt;/a&gt;* or &lt;a href="https://github.com/python-hyper/brotlicffi"&gt;&lt;strong&gt;brotlicffi&lt;/strong&gt;&lt;/a&gt; - &lt;a href="https://en.wikipedia.org/wiki/Brotli"&gt;Brotli&lt;/a&gt; content encoding support. Both licensed under MIT &lt;sup&gt;&lt;a href="https://github.com/google/brotli/raw/master/LICENSE"&gt;1&lt;/a&gt; &lt;a href="https://github.com/python-hyper/brotlicffi/raw/master/LICENSE"&gt;2&lt;/a&gt; &lt;/sup&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aaugustin/websockets"&gt;&lt;strong&gt;websockets&lt;/strong&gt;&lt;/a&gt;* - For downloading over websocket. Licensed under &lt;a href="https://github.com/aaugustin/websockets/raw/main/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/psf/requests"&gt;&lt;strong&gt;requests&lt;/strong&gt;&lt;/a&gt;* - HTTP library. For HTTPS proxy and persistent connections support. Licensed under &lt;a href="https://github.com/psf/requests/raw/main/LICENSE"&gt;Apache-2.0&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Impersonation&lt;/h4&gt; 
&lt;p&gt;The following provide support for impersonating browser requests. This may be required for some sites that employ TLS fingerprinting.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/lexiforest/curl_cffi"&gt;&lt;strong&gt;curl_cffi&lt;/strong&gt;&lt;/a&gt; (recommended) - Python binding for &lt;a href="https://github.com/lexiforest/curl-impersonate"&gt;curl-impersonate&lt;/a&gt;. Provides impersonation targets for Chrome, Edge and Safari. Licensed under &lt;a href="https://github.com/lexiforest/curl_cffi/raw/main/LICENSE"&gt;MIT&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Can be installed with the &lt;code&gt;curl-cffi&lt;/code&gt; group, e.g. &lt;code&gt;pip install "yt-dlp[default,curl-cffi]"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Currently included in most builds &lt;em&gt;except&lt;/em&gt; &lt;code&gt;yt-dlp&lt;/code&gt; (Unix zipimport binary), &lt;code&gt;yt-dlp_x86&lt;/code&gt; (Windows 32-bit) and &lt;code&gt;yt-dlp_musllinux_aarch64&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Metadata&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/quodlibet/mutagen"&gt;&lt;strong&gt;mutagen&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in certain formats. Licensed under &lt;a href="https://github.com/quodlibet/mutagen/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wez/atomicparsley"&gt;&lt;strong&gt;AtomicParsley&lt;/strong&gt;&lt;/a&gt; - For &lt;code&gt;--embed-thumbnail&lt;/code&gt; in &lt;code&gt;mp4&lt;/code&gt;/&lt;code&gt;m4a&lt;/code&gt; files when &lt;code&gt;mutagen&lt;/code&gt;/&lt;code&gt;ffmpeg&lt;/code&gt; cannot. Licensed under &lt;a href="https://github.com/wez/atomicparsley/raw/master/COPYING"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xattr/xattr"&gt;&lt;strong&gt;xattr&lt;/strong&gt;&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr"&gt;&lt;strong&gt;pyxattr&lt;/strong&gt;&lt;/a&gt; or &lt;a href="http://savannah.nongnu.org/projects/attr"&gt;&lt;strong&gt;setfattr&lt;/strong&gt;&lt;/a&gt; - For writing xattr metadata (&lt;code&gt;--xattrs&lt;/code&gt;) on &lt;strong&gt;Mac&lt;/strong&gt; and &lt;strong&gt;BSD&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/xattr/xattr/raw/master/LICENSE.txt"&gt;MIT&lt;/a&gt;, &lt;a href="https://github.com/iustin/pyxattr/raw/master/COPYING"&gt;LGPL2.1&lt;/a&gt; and &lt;a href="http://git.savannah.nongnu.org/cgit/attr.git/tree/doc/COPYING"&gt;GPLv2+&lt;/a&gt; respectively&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Misc&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Legrandin/pycryptodome"&gt;&lt;strong&gt;pycryptodomex&lt;/strong&gt;&lt;/a&gt;* - For decrypting AES-128 HLS streams and various other data. Licensed under &lt;a href="https://github.com/Legrandin/pycryptodome/raw/master/LICENSE.rst"&gt;BSD-2-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ariya/phantomjs"&gt;&lt;strong&gt;phantomjs&lt;/strong&gt;&lt;/a&gt; - Used in extractors where javascript needs to be run. Licensed under &lt;a href="https://github.com/ariya/phantomjs/raw/master/LICENSE.BSD"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mitya57/secretstorage"&gt;&lt;strong&gt;secretstorage&lt;/strong&gt;&lt;/a&gt;* - For &lt;code&gt;--cookies-from-browser&lt;/code&gt; to access the &lt;strong&gt;Gnome&lt;/strong&gt; keyring while decrypting cookies of &lt;strong&gt;Chromium&lt;/strong&gt;-based browsers on &lt;strong&gt;Linux&lt;/strong&gt;. Licensed under &lt;a href="https://github.com/mitya57/secretstorage/raw/master/LICENSE"&gt;BSD-3-Clause&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Any external downloader that you want to use with &lt;code&gt;--downloader&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://rtmpdump.mplayerhq.hu"&gt;&lt;strong&gt;rtmpdump&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rtmp&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="http://rtmpdump.mplayerhq.hu"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://mplayerhq.hu/design7/info.html"&gt;&lt;strong&gt;mplayer&lt;/strong&gt;&lt;/a&gt; or &lt;a href="https://mpv.io"&gt;&lt;strong&gt;mpv&lt;/strong&gt;&lt;/a&gt; - For downloading &lt;code&gt;rstp&lt;/code&gt;/&lt;code&gt;mms&lt;/code&gt; streams. ffmpeg can be used instead with &lt;code&gt;--downloader ffmpeg&lt;/code&gt;. Licensed under &lt;a href="https://github.com/mpv-player/mpv/raw/master/Copyright"&gt;GPLv2+&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use or redistribute the dependencies, you must agree to their respective licensing terms.&lt;/p&gt; 
&lt;p&gt;The standalone release binaries are built with the Python interpreter and the packages marked with &lt;strong&gt;*&lt;/strong&gt; included.&lt;/p&gt; 
&lt;p&gt;If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the &lt;code&gt;--verbose&lt;/code&gt; output&lt;/p&gt; 
&lt;h2&gt;COMPILE&lt;/h2&gt; 
&lt;h3&gt;Standalone PyInstaller Builds&lt;/h3&gt; 
&lt;p&gt;To build the standalone executable, you must have Python and &lt;code&gt;pyinstaller&lt;/code&gt; (plus any of yt-dlp's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#dependencies"&gt;optional dependencies&lt;/a&gt; if needed). The executable will be built for the same CPU architecture as the Python used.&lt;/p&gt; 
&lt;p&gt;You can run the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python3 devscripts/install_deps.py --include pyinstaller
python3 devscripts/make_lazy_extractors.py
python3 -m bundle.pyinstaller
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On some systems, you may need to use &lt;code&gt;py&lt;/code&gt; or &lt;code&gt;python&lt;/code&gt; instead of &lt;code&gt;python3&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; accepts any arguments that can be passed to &lt;code&gt;pyinstaller&lt;/code&gt;, such as &lt;code&gt;--onefile/-F&lt;/code&gt; or &lt;code&gt;--onedir/-D&lt;/code&gt;, which is further &lt;a href="https://pyinstaller.org/en/stable/usage.html#what-to-generate"&gt;documented here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Pyinstaller versions below 4.4 &lt;a href="https://github.com/pyinstaller/pyinstaller#requirements-and-tested-platforms"&gt;do not support&lt;/a&gt; Python installed from the Windows store without using a virtual environment.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Running &lt;code&gt;pyinstaller&lt;/code&gt; directly &lt;strong&gt;instead of&lt;/strong&gt; using &lt;code&gt;python -m bundle.pyinstaller&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; officially supported. This may or may not work correctly.&lt;/p&gt; 
&lt;h3&gt;Platform-independent Binary (UNIX)&lt;/h3&gt; 
&lt;p&gt;You will need the build tools &lt;code&gt;python&lt;/code&gt; (3.9+), &lt;code&gt;zip&lt;/code&gt;, &lt;code&gt;make&lt;/code&gt; (GNU), &lt;code&gt;pandoc&lt;/code&gt;* and &lt;code&gt;pytest&lt;/code&gt;*.&lt;/p&gt; 
&lt;p&gt;After installing these, simply run &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can also run &lt;code&gt;make yt-dlp&lt;/code&gt; instead to compile only the binary without updating any of the additional files. (The build tools marked with &lt;strong&gt;*&lt;/strong&gt; are not needed for this)&lt;/p&gt; 
&lt;h3&gt;Related scripts&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/install_deps.py&lt;/code&gt;&lt;/strong&gt; - Install dependencies for yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/update-version.py&lt;/code&gt;&lt;/strong&gt; - Update the version number based on the current date.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/set-variant.py&lt;/code&gt;&lt;/strong&gt; - Set the build variant of the executable.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_changelog.py&lt;/code&gt;&lt;/strong&gt; - Create a markdown changelog using short commit messages and update &lt;code&gt;CONTRIBUTORS&lt;/code&gt; file.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;devscripts/make_lazy_extractors.py&lt;/code&gt;&lt;/strong&gt; - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable &lt;code&gt;YTDLP_NO_LAZY_EXTRACTORS&lt;/code&gt; to something nonempty to forcefully disable lazy extractor loading.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note: See their &lt;code&gt;--help&lt;/code&gt; for more info.&lt;/p&gt; 
&lt;h3&gt;Forking the project&lt;/h3&gt; 
&lt;p&gt;If you fork the project on GitHub, you can run your fork's &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/build.yml"&gt;build workflow&lt;/a&gt; to automatically build the selected version(s) as artifacts. Alternatively, you can run the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release.yml"&gt;release workflow&lt;/a&gt; or enable the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/workflows/release-nightly.yml"&gt;nightly workflow&lt;/a&gt; to create full (pre-)releases.&lt;/p&gt; 
&lt;h1&gt;USAGE AND OPTIONS&lt;/h1&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp [OPTIONS] [--] URL [URL...]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Tip: Use &lt;code&gt;CTRL&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt; (or &lt;code&gt;Command&lt;/code&gt;+&lt;code&gt;F&lt;/code&gt;) to search by keywords&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;!-- Auto generated --&gt; 
&lt;h2&gt;General Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-h, --help                      Print this help text and exit
--version                       Print program version and exit
-U, --update                    Update this program to the latest version
--no-update                     Do not check for updates (default)
--update-to [CHANNEL]@[TAG]     Upgrade/downgrade to a specific version.
                                CHANNEL can be a repository as well. CHANNEL
                                and TAG default to "stable" and "latest"
                                respectively if omitted; See "UPDATE" for
                                details. Supported channels: stable,
                                nightly, master
-i, --ignore-errors             Ignore download and postprocessing errors.
                                The download will be considered successful
                                even if the postprocessing fails
--no-abort-on-error             Continue with next video on download errors;
                                e.g. to skip unavailable videos in a
                                playlist (default)
--abort-on-error                Abort downloading of further videos if an
                                error occurs (Alias: --no-ignore-errors)
--list-extractors               List all supported extractors and exit
--extractor-descriptions        Output descriptions of all supported
                                extractors and exit
--use-extractors NAMES          Extractor names to use separated by commas.
                                You can also use regexes, "all", "default"
                                and "end" (end URL matching); e.g. --ies
                                "holodex.*,end,youtube". Prefix the name
                                with a "-" to exclude it, e.g. --ies
                                default,-generic. Use --list-extractors for
                                a list of extractor names. (Alias: --ies)
--default-search PREFIX         Use this prefix for unqualified URLs. E.g.
                                "gvsearch2:python" downloads two videos from
                                google videos for the search term "python".
                                Use the value "auto" to let yt-dlp guess
                                ("auto_warning" to emit a warning when
                                guessing). "error" just throws an error. The
                                default value "fixup_error" repairs broken
                                URLs, but emits an error if this is not
                                possible instead of searching
--ignore-config                 Don't load any more configuration files
                                except those given to --config-locations.
                                For backward compatibility, if this option
                                is found inside the system configuration
                                file, the user configuration is not loaded.
                                (Alias: --no-config)
--no-config-locations           Do not load any custom configuration files
                                (default). When given inside a configuration
                                file, ignore all previous --config-locations
                                defined in the current file
--config-locations PATH         Location of the main configuration file;
                                either the path to the config or its
                                containing directory ("-" for stdin). Can be
                                used multiple times and inside other
                                configuration files
--plugin-dirs PATH              Path to an additional directory to search
                                for plugins. This option can be used
                                multiple times to add multiple directories.
                                Use "default" to search the default plugin
                                directories (default)
--no-plugin-dirs                Clear plugin directories to search,
                                including defaults and those provided by
                                previous --plugin-dirs
--flat-playlist                 Do not extract a playlist's URL result
                                entries; some entry metadata may be missing
                                and downloading may be bypassed
--no-flat-playlist              Fully extract the videos of a playlist
                                (default)
--live-from-start               Download livestreams from the start.
                                Currently experimental and only supported
                                for YouTube and Twitch
--no-live-from-start            Download livestreams from the current time
                                (default)
--wait-for-video MIN[-MAX]      Wait for scheduled streams to become
                                available. Pass the minimum number of
                                seconds (or range) to wait between retries
--no-wait-for-video             Do not wait for scheduled streams (default)
--mark-watched                  Mark videos watched (even with --simulate)
--no-mark-watched               Do not mark videos watched (default)
--color [STREAM:]POLICY         Whether to emit color codes in output,
                                optionally prefixed by the STREAM (stdout or
                                stderr) to apply the setting to. Can be one
                                of "always", "auto" (default), "never", or
                                "no_color" (use non color terminal
                                sequences). Use "auto-tty" or "no_color-tty"
                                to decide based on terminal support only.
                                Can be used multiple times
--compat-options OPTS           Options that can help keep compatibility
                                with youtube-dl or youtube-dlc
                                configurations by reverting some of the
                                changes made in yt-dlp. See "Differences in
                                default behavior" for details
--alias ALIASES OPTIONS         Create aliases for an option string. Unless
                                an alias starts with a dash "-", it is
                                prefixed with "--". Arguments are parsed
                                according to the Python string formatting
                                mini-language. E.g. --alias get-audio,-X "-S
                                aext:{0},abr -x --audio-format {0}" creates
                                options "--get-audio" and "-X" that takes an
                                argument (ARG0) and expands to "-S
                                aext:ARG0,abr -x --audio-format ARG0". All
                                defined aliases are listed in the --help
                                output. Alias options can trigger more
                                aliases; so be careful to avoid defining
                                recursive options. As a safety measure, each
                                alias may be triggered a maximum of 100
                                times. This option can be used multiple times
-t, --preset-alias PRESET       Applies a predefined set of options. e.g.
                                --preset-alias mp3. The following presets
                                are available: mp3, aac, mp4, mkv, sleep.
                                See the "Preset Aliases" section at the end
                                for more info. This option can be used
                                multiple times
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Network Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--proxy URL                     Use the specified HTTP/HTTPS/SOCKS proxy. To
                                enable SOCKS proxy, specify a proper scheme,
                                e.g. socks5://user:pass@127.0.0.1:1080/.
                                Pass in an empty string (--proxy "") for
                                direct connection
--socket-timeout SECONDS        Time to wait before giving up, in seconds
--source-address IP             Client-side IP address to bind to
--impersonate CLIENT[:OS]       Client to impersonate for requests. E.g.
                                chrome, chrome-110, chrome:windows-10. Pass
                                --impersonate="" to impersonate any client.
                                Note that forcing impersonation for all
                                requests may have a detrimental impact on
                                download speed and stability
--list-impersonate-targets      List available clients to impersonate.
-4, --force-ipv4                Make all connections via IPv4
-6, --force-ipv6                Make all connections via IPv6
--enable-file-urls              Enable file:// URLs. This is disabled by
                                default for security reasons.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Geo-restriction:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--geo-verification-proxy URL    Use this proxy to verify the IP address for
                                some geo-restricted sites. The default proxy
                                specified by --proxy (or none, if the option
                                is not present) is used for the actual
                                downloading
--xff VALUE                     How to fake X-Forwarded-For HTTP header to
                                try bypassing geographic restriction. One of
                                "default" (only when known to be useful),
                                "never", an IP block in CIDR notation, or a
                                two-letter ISO 3166-2 country code
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Selection:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-I, --playlist-items ITEM_SPEC  Comma separated playlist_index of the items
                                to download. You can specify a range using
                                "[START]:[STOP][:STEP]". For backward
                                compatibility, START-STOP is also supported.
                                Use negative indices to count from the right
                                and negative STEP to download in reverse
                                order. E.g. "-I 1:3,7,-5::2" used on a
                                playlist of size 15 will download the items
                                at index 1,2,3,7,11,13,15
--min-filesize SIZE             Abort download if filesize is smaller than
                                SIZE, e.g. 50k or 44.6M
--max-filesize SIZE             Abort download if filesize is larger than
                                SIZE, e.g. 50k or 44.6M
--date DATE                     Download only videos uploaded on this date.
                                The date can be "YYYYMMDD" or in the format 
                                [now|today|yesterday][-N[day|week|month|year]].
                                E.g. "--date today-2weeks" downloads only
                                videos uploaded on the same day two weeks ago
--datebefore DATE               Download only videos uploaded on or before
                                this date. The date formats accepted are the
                                same as --date
--dateafter DATE                Download only videos uploaded on or after
                                this date. The date formats accepted are the
                                same as --date
--match-filters FILTER          Generic video filter. Any "OUTPUT TEMPLATE"
                                field can be compared with a number or a
                                string using the operators defined in
                                "Filtering Formats". You can also simply
                                specify a field to match if the field is
                                present, use "!field" to check if the field
                                is not present, and "&amp;amp;" to check multiple
                                conditions. Use a "\" to escape "&amp;amp;" or
                                quotes if needed. If used multiple times,
                                the filter matches if at least one of the
                                conditions is met. E.g. --match-filters
                                !is_live --match-filters "like_count&amp;gt;?100 &amp;amp;
                                description~='(?i)\bcats \&amp;amp; dogs\b'" matches
                                only videos that are not live OR those that
                                have a like count more than 100 (or the like
                                field is not available) and also has a
                                description that contains the phrase "cats &amp;amp;
                                dogs" (caseless). Use "--match-filters -" to
                                interactively ask whether to download each
                                video
--no-match-filters              Do not use any --match-filters (default)
--break-match-filters FILTER    Same as "--match-filters" but stops the
                                download process when a video is rejected
--no-break-match-filters        Do not use any --break-match-filters (default)
--no-playlist                   Download only the video, if the URL refers
                                to a video and a playlist
--yes-playlist                  Download the playlist, if the URL refers to
                                a video and a playlist
--age-limit YEARS               Download only videos suitable for the given
                                age
--download-archive FILE         Download only videos not listed in the
                                archive file. Record the IDs of all
                                downloaded videos in it
--no-download-archive           Do not use archive file (default)
--max-downloads NUMBER          Abort after downloading NUMBER files
--break-on-existing             Stop the download process when encountering
                                a file that is in the archive supplied with
                                the --download-archive option
--no-break-on-existing          Do not stop the download process when
                                encountering a file that is in the archive
                                (default)
--break-per-input               Alters --max-downloads, --break-on-existing,
                                --break-match-filters, and autonumber to
                                reset per input URL
--no-break-per-input            --break-on-existing and similar options
                                terminates the entire download queue
--skip-playlist-after-errors N  Number of allowed failures until the rest of
                                the playlist is skipped
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Download Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-N, --concurrent-fragments N    Number of fragments of a dash/hlsnative
                                video that should be downloaded concurrently
                                (default is 1)
-r, --limit-rate RATE           Maximum download rate in bytes per second,
                                e.g. 50K or 4.2M
--throttled-rate RATE           Minimum download rate in bytes per second
                                below which throttling is assumed and the
                                video data is re-extracted, e.g. 100K
-R, --retries RETRIES           Number of retries (default is 10), or
                                "infinite"
--file-access-retries RETRIES   Number of times to retry on file access
                                error (default is 3), or "infinite"
--fragment-retries RETRIES      Number of retries for a fragment (default is
                                10), or "infinite" (DASH, hlsnative and ISM)
--retry-sleep [TYPE:]EXPR       Time to sleep between retries in seconds
                                (optionally) prefixed by the type of retry
                                (http (default), fragment, file_access,
                                extractor) to apply the sleep to. EXPR can
                                be a number, linear=START[:END[:STEP=1]] or
                                exp=START[:END[:BASE=2]]. This option can be
                                used multiple times to set the sleep for the
                                different retry types, e.g. --retry-sleep
                                linear=1::2 --retry-sleep fragment:exp=1:20
--skip-unavailable-fragments    Skip unavailable fragments for DASH,
                                hlsnative and ISM downloads (default)
                                (Alias: --no-abort-on-unavailable-fragments)
--abort-on-unavailable-fragments
                                Abort download if a fragment is unavailable
                                (Alias: --no-skip-unavailable-fragments)
--keep-fragments                Keep downloaded fragments on disk after
                                downloading is finished
--no-keep-fragments             Delete downloaded fragments after
                                downloading is finished (default)
--buffer-size SIZE              Size of download buffer, e.g. 1024 or 16K
                                (default is 1024)
--resize-buffer                 The buffer size is automatically resized
                                from an initial value of --buffer-size
                                (default)
--no-resize-buffer              Do not automatically adjust the buffer size
--http-chunk-size SIZE          Size of a chunk for chunk-based HTTP
                                downloading, e.g. 10485760 or 10M (default
                                is disabled). May be useful for bypassing
                                bandwidth throttling imposed by a webserver
                                (experimental)
--playlist-random               Download playlist videos in random order
--lazy-playlist                 Process entries in the playlist as they are
                                received. This disables n_entries,
                                --playlist-random and --playlist-reverse
--no-lazy-playlist              Process videos in the playlist only after
                                the entire playlist is parsed (default)
--hls-use-mpegts                Use the mpegts container for HLS videos;
                                allowing some players to play the video
                                while downloading, and reducing the chance
                                of file corruption if download is
                                interrupted. This is enabled by default for
                                live streams
--no-hls-use-mpegts             Do not use the mpegts container for HLS
                                videos. This is default when not downloading
                                live streams
--download-sections REGEX       Download only chapters that match the
                                regular expression. A "*" prefix denotes
                                time-range instead of chapter. Negative
                                timestamps are calculated from the end.
                                "*from-url" can be used to download between
                                the "start_time" and "end_time" extracted
                                from the URL. Needs ffmpeg. This option can
                                be used multiple times to download multiple
                                sections, e.g. --download-sections
                                "*10:15-inf" --download-sections "intro"
--downloader [PROTO:]NAME       Name or path of the external downloader to
                                use (optionally) prefixed by the protocols
                                (http, ftp, m3u8, dash, rstp, rtmp, mms) to
                                use it for. Currently supports native,
                                aria2c, axel, curl, ffmpeg, httpie, wget.
                                You can use this option multiple times to
                                set different downloaders for different
                                protocols. E.g. --downloader aria2c
                                --downloader "dash,m3u8:native" will use
                                aria2c for http/ftp downloads, and the
                                native downloader for dash/m3u8 downloads
                                (Alias: --external-downloader)
--downloader-args NAME:ARGS     Give these arguments to the external
                                downloader. Specify the downloader name and
                                the arguments separated by a colon ":". For
                                ffmpeg, arguments can be passed to different
                                positions using the same syntax as
                                --postprocessor-args. You can use this
                                option multiple times to give different
                                arguments to different downloaders (Alias:
                                --external-downloader-args)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Filesystem Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-a, --batch-file FILE           File containing URLs to download ("-" for
                                stdin), one URL per line. Lines starting
                                with "#", ";" or "]" are considered as
                                comments and ignored
--no-batch-file                 Do not read URLs from batch file (default)
-P, --paths [TYPES:]PATH        The paths where the files should be
                                downloaded. Specify the type of file and the
                                path separated by a colon ":". All the same
                                TYPES as --output are supported.
                                Additionally, you can also provide "home"
                                (default) and "temp" paths. All intermediary
                                files are first downloaded to the temp path
                                and then the final files are moved over to
                                the home path after download is finished.
                                This option is ignored if --output is an
                                absolute path
-o, --output [TYPES:]TEMPLATE   Output filename template; see "OUTPUT
                                TEMPLATE" for details
--output-na-placeholder TEXT    Placeholder for unavailable fields in
                                --output (default: "NA")
--restrict-filenames            Restrict filenames to only ASCII characters,
                                and avoid "&amp;amp;" and spaces in filenames
--no-restrict-filenames         Allow Unicode characters, "&amp;amp;" and spaces in
                                filenames (default)
--windows-filenames             Force filenames to be Windows-compatible
--no-windows-filenames          Sanitize filenames only minimally
--trim-filenames LENGTH         Limit the filename length (excluding
                                extension) to the specified number of
                                characters
-w, --no-overwrites             Do not overwrite any files
--force-overwrites              Overwrite all video and metadata files. This
                                option includes --no-continue
--no-force-overwrites           Do not overwrite the video, but overwrite
                                related files (default)
-c, --continue                  Resume partially downloaded files/fragments
                                (default)
--no-continue                   Do not resume partially downloaded
                                fragments. If the file is not fragmented,
                                restart download of the entire file
--part                          Use .part files instead of writing directly
                                into output file (default)
--no-part                       Do not use .part files - write directly into
                                output file
--mtime                         Use the Last-modified header to set the file
                                modification time
--no-mtime                      Do not use the Last-modified header to set
                                the file modification time (default)
--write-description             Write video description to a .description file
--no-write-description          Do not write video description (default)
--write-info-json               Write video metadata to a .info.json file
                                (this may contain personal information)
--no-write-info-json            Do not write video metadata (default)
--write-playlist-metafiles      Write playlist metadata in addition to the
                                video metadata when using --write-info-json,
                                --write-description etc. (default)
--no-write-playlist-metafiles   Do not write playlist metadata when using
                                --write-info-json, --write-description etc.
--clean-info-json               Remove some internal metadata such as
                                filenames from the infojson (default)
--no-clean-info-json            Write all fields to the infojson
--write-comments                Retrieve video comments to be placed in the
                                infojson. The comments are fetched even
                                without this option if the extraction is
                                known to be quick (Alias: --get-comments)
--no-write-comments             Do not retrieve video comments unless the
                                extraction is known to be quick (Alias:
                                --no-get-comments)
--load-info-json FILE           JSON file containing the video information
                                (created with the "--write-info-json" option)
--cookies FILE                  Netscape formatted file to read cookies from
                                and dump cookie jar in
--no-cookies                    Do not read/dump cookies from/to file
                                (default)
--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]
                                The name of the browser to load cookies
                                from. Currently supported browsers are:
                                brave, chrome, chromium, edge, firefox,
                                opera, safari, vivaldi, whale. Optionally,
                                the KEYRING used for decrypting Chromium
                                cookies on Linux, the name/path of the
                                PROFILE to load cookies from, and the
                                CONTAINER name (if Firefox) ("none" for no
                                container) can be given with their
                                respective separators. By default, all
                                containers of the most recently accessed
                                profile are used. Currently supported
                                keyrings are: basictext, gnomekeyring,
                                kwallet, kwallet5, kwallet6
--no-cookies-from-browser       Do not load cookies from browser (default)
--cache-dir DIR                 Location in the filesystem where yt-dlp can
                                store some downloaded information (such as
                                client ids and signatures) permanently. By
                                default ${XDG_CACHE_HOME}/yt-dlp
--no-cache-dir                  Disable filesystem caching
--rm-cache-dir                  Delete all filesystem cache files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Thumbnail Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-thumbnail               Write thumbnail image to disk
--no-write-thumbnail            Do not write thumbnail image to disk (default)
--write-all-thumbnails          Write all thumbnail image formats to disk
--list-thumbnails               List available thumbnails of each video.
                                Simulate unless --no-simulate is used
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Internet Shortcut Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-link                    Write an internet shortcut file, depending
                                on the current platform (.url, .webloc or
                                .desktop). The URL may be cached by the OS
--write-url-link                Write a .url Windows internet shortcut. The
                                OS caches the URL based on the file path
--write-webloc-link             Write a .webloc macOS internet shortcut
--write-desktop-link            Write a .desktop Linux internet shortcut
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Verbosity and Simulation Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-q, --quiet                     Activate quiet mode. If used with --verbose,
                                print the log to stderr
--no-quiet                      Deactivate quiet mode. (Default)
--no-warnings                   Ignore warnings
-s, --simulate                  Do not download the video and do not write
                                anything to disk
--no-simulate                   Download the video even if printing/listing
                                options are used
--ignore-no-formats-error       Ignore "No video formats" error. Useful for
                                extracting metadata even if the videos are
                                not actually available for download
                                (experimental)
--no-ignore-no-formats-error    Throw error when no downloadable video
                                formats are found (default)
--skip-download                 Do not download the video but write all
                                related files (Alias: --no-download)
-O, --print [WHEN:]TEMPLATE     Field name or output template to print to
                                screen, optionally prefixed with when to
                                print it, separated by a ":". Supported
                                values of "WHEN" are the same as that of
                                --use-postprocessor (default: video).
                                Implies --quiet. Implies --simulate unless
                                --no-simulate or later stages of WHEN are
                                used. This option can be used multiple times
--print-to-file [WHEN:]TEMPLATE FILE
                                Append given template to the file. The
                                values of WHEN and TEMPLATE are the same as
                                that of --print. FILE uses the same syntax
                                as the output template. This option can be
                                used multiple times
-j, --dump-json                 Quiet, but print JSON information for each
                                video. Simulate unless --no-simulate is
                                used. See "OUTPUT TEMPLATE" for a
                                description of available keys
-J, --dump-single-json          Quiet, but print JSON information for each
                                URL or infojson passed. Simulate unless
                                --no-simulate is used. If the URL refers to
                                a playlist, the whole playlist information
                                is dumped in a single line
--force-write-archive           Force download archive entries to be written
                                as far as no errors occur, even if -s or
                                another simulation option is used (Alias:
                                --force-download-archive)
--newline                       Output progress bar as new lines
--no-progress                   Do not print progress bar
--progress                      Show progress bar, even if in quiet mode
--console-title                 Display progress in console titlebar
--progress-template [TYPES:]TEMPLATE
                                Template for progress outputs, optionally
                                prefixed with one of "download:" (default),
                                "download-title:" (the console title),
                                "postprocess:",  or "postprocess-title:".
                                The video's fields are accessible under the
                                "info" key and the progress attributes are
                                accessible under "progress" key. E.g.
                                --console-title --progress-template
                                "download-title:%(info.id)s-%(progress.eta)s"
--progress-delta SECONDS        Time between progress output (default: 0)
-v, --verbose                   Print various debugging information
--dump-pages                    Print downloaded pages encoded using base64
                                to debug problems (very verbose)
--write-pages                   Write downloaded intermediary pages to files
                                in the current directory to debug problems
--print-traffic                 Display sent and read HTTP traffic
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Workarounds:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--encoding ENCODING             Force the specified encoding (experimental)
--legacy-server-connect         Explicitly allow HTTPS connection to servers
                                that do not support RFC 5746 secure
                                renegotiation
--no-check-certificates         Suppress HTTPS certificate validation
--prefer-insecure               Use an unencrypted connection to retrieve
                                information about the video (Currently
                                supported only for YouTube)
--add-headers FIELD:VALUE       Specify a custom HTTP header and its value,
                                separated by a colon ":". You can use this
                                option multiple times
--bidi-workaround               Work around terminals that lack
                                bidirectional text support. Requires bidiv
                                or fribidi executable in PATH
--sleep-requests SECONDS        Number of seconds to sleep between requests
                                during data extraction
--sleep-interval SECONDS        Number of seconds to sleep before each
                                download. This is the minimum time to sleep
                                when used along with --max-sleep-interval
                                (Alias: --min-sleep-interval)
--max-sleep-interval SECONDS    Maximum number of seconds to sleep. Can only
                                be used along with --min-sleep-interval
--sleep-subtitles SECONDS       Number of seconds to sleep before each
                                subtitle download
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Video Format Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-f, --format FORMAT             Video format code, see "FORMAT SELECTION"
                                for more details
-S, --format-sort SORTORDER     Sort the formats by the fields given, see
                                "Sorting Formats" for more details
--format-sort-force             Force user specified sort order to have
                                precedence over all fields, see "Sorting
                                Formats" for more details (Alias: --S-force)
--no-format-sort-force          Some fields have precedence over the user
                                specified sort order (default)
--video-multistreams            Allow multiple video streams to be merged
                                into a single file
--no-video-multistreams         Only one video stream is downloaded for each
                                output file (default)
--audio-multistreams            Allow multiple audio streams to be merged
                                into a single file
--no-audio-multistreams         Only one audio stream is downloaded for each
                                output file (default)
--prefer-free-formats           Prefer video formats with free containers
                                over non-free ones of the same quality. Use
                                with "-S ext" to strictly prefer free
                                containers irrespective of quality
--no-prefer-free-formats        Don't give any special preference to free
                                containers (default)
--check-formats                 Make sure formats are selected only from
                                those that are actually downloadable
--check-all-formats             Check all formats for whether they are
                                actually downloadable
--no-check-formats              Do not check that the formats are actually
                                downloadable
-F, --list-formats              List available formats of each video.
                                Simulate unless --no-simulate is used
--merge-output-format FORMAT    Containers that may be used when merging
                                formats, separated by "/", e.g. "mp4/mkv".
                                Ignored if no merge is required. (currently
                                supported: avi, flv, mkv, mov, mp4, webm)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Subtitle Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--write-subs                    Write subtitle file
--no-write-subs                 Do not write subtitle file (default)
--write-auto-subs               Write automatically generated subtitle file
                                (Alias: --write-automatic-subs)
--no-write-auto-subs            Do not write auto-generated subtitles
                                (default) (Alias: --no-write-automatic-subs)
--list-subs                     List available subtitles of each video.
                                Simulate unless --no-simulate is used
--sub-format FORMAT             Subtitle format; accepts formats preference
                                separated by "/", e.g. "srt" or "ass/srt/best"
--sub-langs LANGS               Languages of the subtitles to download (can
                                be regex) or "all" separated by commas, e.g.
                                --sub-langs "en.*,ja" (where "en.*" is a
                                regex pattern that matches "en" followed by
                                0 or more of any character). You can prefix
                                the language code with a "-" to exclude it
                                from the requested languages, e.g. --sub-
                                langs all,-live_chat. Use --list-subs for a
                                list of available language tags
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Authentication Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-u, --username USERNAME         Login with this account ID
-p, --password PASSWORD         Account password. If this option is left
                                out, yt-dlp will ask interactively
-2, --twofactor TWOFACTOR       Two-factor authentication code
-n, --netrc                     Use .netrc authentication data
--netrc-location PATH           Location of .netrc authentication data;
                                either the path or its containing directory.
                                Defaults to ~/.netrc
--netrc-cmd NETRC_CMD           Command to execute to get the credentials
                                for an extractor.
--video-password PASSWORD       Video-specific password
--ap-mso MSO                    Adobe Pass multiple-system operator (TV
                                provider) identifier, use --ap-list-mso for
                                a list of available MSOs
--ap-username USERNAME          Multiple-system operator account login
--ap-password PASSWORD          Multiple-system operator account password.
                                If this option is left out, yt-dlp will ask
                                interactively
--ap-list-mso                   List all supported multiple-system operators
--client-certificate CERTFILE   Path to client certificate file in PEM
                                format. May include the private key
--client-certificate-key KEYFILE
                                Path to private key file for client
                                certificate
--client-certificate-password PASSWORD
                                Password for client certificate private key,
                                if encrypted. If not provided, and the key
                                is encrypted, yt-dlp will ask interactively
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Post-Processing Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;-x, --extract-audio             Convert video files to audio-only files
                                (requires ffmpeg and ffprobe)
--audio-format FORMAT           Format to convert the audio to when -x is
                                used. (currently supported: best (default),
                                aac, alac, flac, m4a, mp3, opus, vorbis,
                                wav). You can specify multiple rules using
                                similar syntax as --remux-video
--audio-quality QUALITY         Specify ffmpeg audio quality to use when
                                converting the audio with -x. Insert a value
                                between 0 (best) and 10 (worst) for VBR or a
                                specific bitrate like 128K (default 5)
--remux-video FORMAT            Remux the video into another container if
                                necessary (currently supported: avi, flv,
                                gif, mkv, mov, mp4, webm, aac, aiff, alac,
                                flac, m4a, mka, mp3, ogg, opus, vorbis,
                                wav). If the target container does not
                                support the video/audio codec, remuxing will
                                fail. You can specify multiple rules; e.g.
                                "aac&amp;gt;m4a/mov&amp;gt;mp4/mkv" will remux aac to m4a,
                                mov to mp4 and anything else to mkv
--recode-video FORMAT           Re-encode the video into another format if
                                necessary. The syntax and supported formats
                                are the same as --remux-video
--postprocessor-args NAME:ARGS  Give these arguments to the postprocessors.
                                Specify the postprocessor/executable name
                                and the arguments separated by a colon ":"
                                to give the argument to the specified
                                postprocessor/executable. Supported PP are:
                                Merger, ModifyChapters, SplitChapters,
                                ExtractAudio, VideoRemuxer, VideoConvertor,
                                Metadata, EmbedSubtitle, EmbedThumbnail,
                                SubtitlesConvertor, ThumbnailsConvertor,
                                FixupStretched, FixupM4a, FixupM3u8,
                                FixupTimestamp and FixupDuration. The
                                supported executables are: AtomicParsley,
                                FFmpeg and FFprobe. You can also specify
                                "PP+EXE:ARGS" to give the arguments to the
                                specified executable only when being used by
                                the specified postprocessor. Additionally,
                                for ffmpeg/ffprobe, "_i"/"_o" can be
                                appended to the prefix optionally followed
                                by a number to pass the argument before the
                                specified input/output file, e.g. --ppa
                                "Merger+ffmpeg_i1:-v quiet". You can use
                                this option multiple times to give different
                                arguments to different postprocessors.
                                (Alias: --ppa)
-k, --keep-video                Keep the intermediate video file on disk
                                after post-processing
--no-keep-video                 Delete the intermediate video file after
                                post-processing (default)
--post-overwrites               Overwrite post-processed files (default)
--no-post-overwrites            Do not overwrite post-processed files
--embed-subs                    Embed subtitles in the video (only for mp4,
                                webm and mkv videos)
--no-embed-subs                 Do not embed subtitles (default)
--embed-thumbnail               Embed thumbnail in the video as cover art
--no-embed-thumbnail            Do not embed thumbnail (default)
--embed-metadata                Embed metadata to the video file. Also
                                embeds chapters/infojson if present unless
                                --no-embed-chapters/--no-embed-info-json are
                                used (Alias: --add-metadata)
--no-embed-metadata             Do not add metadata to file (default)
                                (Alias: --no-add-metadata)
--embed-chapters                Add chapter markers to the video file
                                (Alias: --add-chapters)
--no-embed-chapters             Do not add chapter markers (default) (Alias:
                                --no-add-chapters)
--embed-info-json               Embed the infojson as an attachment to
                                mkv/mka video files
--no-embed-info-json            Do not embed the infojson as an attachment
                                to the video file
--parse-metadata [WHEN:]FROM:TO
                                Parse additional metadata like title/artist
                                from other fields; see "MODIFYING METADATA"
                                for details. Supported values of "WHEN" are
                                the same as that of --use-postprocessor
                                (default: pre_process)
--replace-in-metadata [WHEN:]FIELDS REGEX REPLACE
                                Replace text in a metadata field using the
                                given regex. This option can be used
                                multiple times. Supported values of "WHEN"
                                are the same as that of --use-postprocessor
                                (default: pre_process)
--xattrs                        Write metadata to the video file's xattrs
                                (using Dublin Core and XDG standards)
--concat-playlist POLICY        Concatenate videos in a playlist. One of
                                "never", "always", or "multi_video"
                                (default; only when the videos form a single
                                show). All the video files must have the
                                same codecs and number of streams to be
                                concatenable. The "pl_video:" prefix can be
                                used with "--paths" and "--output" to set
                                the output filename for the concatenated
                                files. See "OUTPUT TEMPLATE" for details
--fixup POLICY                  Automatically correct known faults of the
                                file. One of never (do nothing), warn (only
                                emit a warning), detect_or_warn (the
                                default; fix the file if we can, warn
                                otherwise), force (try fixing even if the
                                file already exists)
--ffmpeg-location PATH          Location of the ffmpeg binary; either the
                                path to the binary or its containing directory
--exec [WHEN:]CMD               Execute a command, optionally prefixed with
                                when to execute it, separated by a ":".
                                Supported values of "WHEN" are the same as
                                that of --use-postprocessor (default:
                                after_move). The same syntax as the output
                                template can be used to pass any field as
                                arguments to the command. If no fields are
                                passed, %(filepath,_filename|)q is appended
                                to the end of the command. This option can
                                be used multiple times
--no-exec                       Remove any previously defined --exec
--convert-subs FORMAT           Convert the subtitles to another format
                                (currently supported: ass, lrc, srt, vtt).
                                Use "--convert-subs none" to disable
                                conversion (default) (Alias: --convert-
                                subtitles)
--convert-thumbnails FORMAT     Convert the thumbnails to another format
                                (currently supported: jpg, png, webp). You
                                can specify multiple rules using similar
                                syntax as "--remux-video". Use "--convert-
                                thumbnails none" to disable conversion
                                (default)
--split-chapters                Split video into multiple files based on
                                internal chapters. The "chapter:" prefix can
                                be used with "--paths" and "--output" to set
                                the output filename for the split files. See
                                "OUTPUT TEMPLATE" for details
--no-split-chapters             Do not split video based on chapters (default)
--remove-chapters REGEX         Remove chapters whose title matches the
                                given regular expression. The syntax is the
                                same as --download-sections. This option can
                                be used multiple times
--no-remove-chapters            Do not remove any chapters from the file
                                (default)
--force-keyframes-at-cuts       Force keyframes at cuts when
                                downloading/splitting/removing sections.
                                This is slow due to needing a re-encode, but
                                the resulting video may have fewer artifacts
                                around the cuts
--no-force-keyframes-at-cuts    Do not force keyframes around the chapters
                                when cutting/splitting (default)
--use-postprocessor NAME[:ARGS]
                                The (case-sensitive) name of plugin
                                postprocessors to be enabled, and
                                (optionally) arguments to be passed to it,
                                separated by a colon ":". ARGS are a
                                semicolon ";" delimited list of NAME=VALUE.
                                The "when" argument determines when the
                                postprocessor is invoked. It can be one of
                                "pre_process" (after video extraction),
                                "after_filter" (after video passes filter),
                                "video" (after --format; before
                                --print/--output), "before_dl" (before each
                                video download), "post_process" (after each
                                video download; default), "after_move"
                                (after moving the video file to its final
                                location), "after_video" (after downloading
                                and processing all formats of a video), or
                                "playlist" (at end of playlist). This option
                                can be used multiple times to add different
                                postprocessors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;SponsorBlock Options:&lt;/h2&gt; 
&lt;p&gt;Make chapter entries for, or remove various segments (sponsor, introductions, etc.) from downloaded YouTube videos using the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock API&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponsorblock-mark CATS        SponsorBlock categories to create chapters
                                for, separated by commas. Available
                                categories are sponsor, intro, outro,
                                selfpromo, preview, filler, interaction,
                                music_offtopic, poi_highlight, chapter, all
                                and default (=all). You can prefix the
                                category with a "-" to exclude it. See [1]
                                for descriptions of the categories. E.g.
                                --sponsorblock-mark all,-preview
                                [1] https://wiki.sponsor.ajay.app/w/Segment_Categories
--sponsorblock-remove CATS      SponsorBlock categories to be removed from
                                the video file, separated by commas. If a
                                category is present in both mark and remove,
                                remove takes precedence. The syntax and
                                available categories are the same as for
                                --sponsorblock-mark except that "default"
                                refers to "all,-filler" and poi_highlight,
                                chapter are not available
--sponsorblock-chapter-title TEMPLATE
                                An output template for the title of the
                                SponsorBlock chapters created by
                                --sponsorblock-mark. The only available
                                fields are start_time, end_time, category,
                                categories, name, category_names. Defaults
                                to "[SponsorBlock]: %(category_names)l"
--no-sponsorblock               Disable both --sponsorblock-mark and
                                --sponsorblock-remove
--sponsorblock-api URL          SponsorBlock API location, defaults to
                                https://sponsor.ajay.app
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Extractor Options:&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;--extractor-retries RETRIES     Number of retries for known extractor errors
                                (default is 3), or "infinite"
--allow-dynamic-mpd             Process dynamic DASH manifests (default)
                                (Alias: --no-ignore-dynamic-mpd)
--ignore-dynamic-mpd            Do not process dynamic DASH manifests
                                (Alias: --no-allow-dynamic-mpd)
--hls-split-discontinuity       Split HLS playlists to different formats at
                                discontinuities such as ad breaks
--no-hls-split-discontinuity    Do not split HLS playlists into different
                                formats at discontinuities such as ad breaks
                                (default)
--extractor-args IE_KEY:ARGS    Pass ARGS arguments to the IE_KEY extractor.
                                See "EXTRACTOR ARGUMENTS" for details. You
                                can use this option multiple times to give
                                arguments for different extractors
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Preset Aliases:&lt;/h2&gt; 
&lt;p&gt;Predefined aliases for convenience and ease of use. Note that future versions of yt-dlp may add or adjust presets, but the existing preset names will not be changed or removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-t mp3                          -f 'ba[acodec^=mp3]/ba/b' -x --audio-format
                                mp3

-t aac                          -f
                                'ba[acodec^=aac]/ba[acodec^=mp4a.40.]/ba/b'
                                -x --audio-format aac

-t mp4                          --merge-output-format mp4 --remux-video mp4
                                -S vcodec:h264,lang,quality,res,fps,hdr:12,a
                                codec:aac

-t mkv                          --merge-output-format mkv --remux-video mkv

-t sleep                        --sleep-subtitles 5 --sleep-requests 0.75
                                --sleep-interval 10 --max-sleep-interval 20
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONFIGURATION&lt;/h1&gt; 
&lt;p&gt;You can configure yt-dlp by placing any supported command line option in a configuration file. The configuration is loaded from the following locations:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Main Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The file given to &lt;code&gt;--config-location&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: (Recommended for portable installations)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;If using a binary, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the same directory as the binary&lt;/li&gt; 
   &lt;li&gt;If running from source-code, &lt;code&gt;yt-dlp.conf&lt;/code&gt; in the parent directory of &lt;code&gt;yt_dlp&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Home Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;yt-dlp.conf&lt;/code&gt; in the home path given to &lt;code&gt;-P&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;If &lt;code&gt;-P&lt;/code&gt; is not given, the current directory is searched&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;User Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/yt-dlp.conf.txt&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;~/.yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;See also: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#notes-about-environment-variables"&gt;Notes about environment variables&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;System Configuration&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp.conf&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;/etc/yt-dlp/config.txt&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;E.g. with the following configuration file, yt-dlp will always extract the audio, copy the mtime, use a proxy and save all videos under &lt;code&gt;YouTube&lt;/code&gt; directory in your home directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Lines starting with # are comments

# Always extract audio
-x

# Copy the mtime
--mtime

# Use this proxy
--proxy 127.0.0.1:3128

# Save all videos under YouTube directory in your home directory
-o ~/YouTube/%(title)s.%(ext)s
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Options in a configuration file are just the same options aka switches used in regular command line calls; thus there &lt;strong&gt;must be no whitespace&lt;/strong&gt; after &lt;code&gt;-&lt;/code&gt; or &lt;code&gt;--&lt;/code&gt;, e.g. &lt;code&gt;-o&lt;/code&gt; or &lt;code&gt;--proxy&lt;/code&gt; but not &lt;code&gt;- o&lt;/code&gt; or &lt;code&gt;-- proxy&lt;/code&gt;. They must also be quoted when necessary, as if it were a UNIX shell.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;--ignore-config&lt;/code&gt; if you want to disable all configuration files for a particular yt-dlp run. If &lt;code&gt;--ignore-config&lt;/code&gt; is found inside any configuration file, no further configuration will be loaded. For example, having the option in the portable configuration file prevents loading of home, user, and system configurations. Additionally, (for backward compatibility) if &lt;code&gt;--ignore-config&lt;/code&gt; is found inside the system configuration file, the user configuration is not loaded.&lt;/p&gt; 
&lt;h3&gt;Configuration file encoding&lt;/h3&gt; 
&lt;p&gt;The configuration files are decoded according to the UTF BOM if present, and in the encoding from system locale otherwise.&lt;/p&gt; 
&lt;p&gt;If you want your file to be decoded differently, add &lt;code&gt;# coding: ENCODING&lt;/code&gt; to the beginning of the file (e.g. &lt;code&gt;# coding: shift-jis&lt;/code&gt;). There must be no characters before that, even spaces or BOM.&lt;/p&gt; 
&lt;h3&gt;Authentication with netrc&lt;/h3&gt; 
&lt;p&gt;You may also want to configure automatic credentials storage for extractors that support authentication (by providing login and password with &lt;code&gt;--username&lt;/code&gt; and &lt;code&gt;--password&lt;/code&gt;) in order not to pass credentials as command line arguments on every yt-dlp execution and prevent tracking plain text passwords in the shell command history. You can achieve this using a &lt;a href="https://stackoverflow.com/tags/.netrc/info"&gt;&lt;code&gt;.netrc&lt;/code&gt; file&lt;/a&gt; on a per-extractor basis. For that, you will need to create a &lt;code&gt;.netrc&lt;/code&gt; file in &lt;code&gt;--netrc-location&lt;/code&gt; and restrict permissions to read/write by only you:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;touch ${HOME}/.netrc
chmod a-rwx,u+rw ${HOME}/.netrc
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After that, you can add credentials for an extractor in the following format, where &lt;em&gt;extractor&lt;/em&gt; is the name of the extractor in lowercase:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine &amp;lt;extractor&amp;gt; login &amp;lt;username&amp;gt; password &amp;lt;password&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;E.g.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;machine youtube login myaccount@gmail.com password my_youtube_password
machine twitch login my_twitch_account_name password my_twitch_password
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To activate authentication with the &lt;code&gt;.netrc&lt;/code&gt; file you should pass &lt;code&gt;--netrc&lt;/code&gt; to yt-dlp or place it in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration file&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The default location of the .netrc file is &lt;code&gt;~&lt;/code&gt; (see below).&lt;/p&gt; 
&lt;p&gt;As an alternative to using the &lt;code&gt;.netrc&lt;/code&gt; file, which has the disadvantage of keeping your passwords in a plain text file, you can configure a custom shell command to provide the credentials for an extractor. This is done by providing the &lt;code&gt;--netrc-cmd&lt;/code&gt; parameter, it shall output the credentials in the netrc format and return &lt;code&gt;0&lt;/code&gt; on success, other values will be treated as an error. &lt;code&gt;{}&lt;/code&gt; in the command will be replaced by the name of the extractor to make it possible to select the credentials for the right extractor.&lt;/p&gt; 
&lt;p&gt;E.g. To use an encrypted &lt;code&gt;.netrc&lt;/code&gt; file stored as &lt;code&gt;.authinfo.gpg&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;yt-dlp --netrc-cmd 'gpg --decrypt ~/.authinfo.gpg' 'https://www.youtube.com/watch?v=BaW_jenozKc'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Notes about environment variables&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Environment variables are normally specified as &lt;code&gt;${VARIABLE}&lt;/code&gt;/&lt;code&gt;$VARIABLE&lt;/code&gt; on UNIX and &lt;code&gt;%VARIABLE%&lt;/code&gt; on Windows; but is always shown as &lt;code&gt;${VARIABLE}&lt;/code&gt; in this documentation&lt;/li&gt; 
 &lt;li&gt;yt-dlp also allows using UNIX-style variables on Windows for path-like options; e.g. &lt;code&gt;--output&lt;/code&gt;, &lt;code&gt;--config-location&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If unset, &lt;code&gt;${XDG_CONFIG_HOME}&lt;/code&gt; defaults to &lt;code&gt;~/.config&lt;/code&gt; and &lt;code&gt;${XDG_CACHE_HOME}&lt;/code&gt; to &lt;code&gt;~/.cache&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;~&lt;/code&gt; points to &lt;code&gt;${HOME}&lt;/code&gt; if present; or, &lt;code&gt;${USERPROFILE}&lt;/code&gt; or &lt;code&gt;${HOMEDRIVE}${HOMEPATH}&lt;/code&gt; otherwise&lt;/li&gt; 
 &lt;li&gt;On Windows, &lt;code&gt;${USERPROFILE}&lt;/code&gt; generally points to &lt;code&gt;C:\Users\&amp;lt;user name&amp;gt;&lt;/code&gt; and &lt;code&gt;${APPDATA}&lt;/code&gt; to &lt;code&gt;${USERPROFILE}\AppData\Roaming&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;OUTPUT TEMPLATE&lt;/h1&gt; 
&lt;p&gt;The &lt;code&gt;-o&lt;/code&gt; option is used to indicate a template for the output file names while &lt;code&gt;-P&lt;/code&gt; option is used to specify the path each type of file should be saved to.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest usage of &lt;code&gt;-o&lt;/code&gt; is not to set any template arguments when downloading a single file, like in &lt;code&gt;yt-dlp -o funny_video.flv "https://some/video"&lt;/code&gt; (hard-coding file extension like this is &lt;em&gt;not&lt;/em&gt; recommended and could break some post-processing).&lt;/p&gt; 
&lt;p&gt;It may however also contain special sequences that will be replaced when downloading each video. The special sequences may be formatted according to &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;Python string formatting operations&lt;/a&gt;, e.g. &lt;code&gt;%(NAME)s&lt;/code&gt; or &lt;code&gt;%(NAME)05d&lt;/code&gt;. To clarify, that is a percent symbol followed by a name in parentheses, followed by formatting operations.&lt;/p&gt; 
&lt;p&gt;The field names themselves (the part inside the parenthesis) can also have some special formatting:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Object traversal&lt;/strong&gt;: The dictionaries and lists available in metadata can be traversed by using a dot &lt;code&gt;.&lt;/code&gt; separator; e.g. &lt;code&gt;%(tags.0)s&lt;/code&gt;, &lt;code&gt;%(subtitles.en.-1.ext)s&lt;/code&gt;. You can do Python slicing with colon &lt;code&gt;:&lt;/code&gt;; E.g. &lt;code&gt;%(id.3:7)s&lt;/code&gt;, &lt;code&gt;%(id.6:2:-1)s&lt;/code&gt;, &lt;code&gt;%(formats.:.format_id)s&lt;/code&gt;. Curly braces &lt;code&gt;{}&lt;/code&gt; can be used to build dictionaries with only specific keys; e.g. &lt;code&gt;%(formats.:.{format_id,height})#j&lt;/code&gt;. An empty field name &lt;code&gt;%()s&lt;/code&gt; refers to the entire infodict; e.g. &lt;code&gt;%(.{id,title})s&lt;/code&gt;. Note that all the fields that become available using this method are not listed below. Use &lt;code&gt;-j&lt;/code&gt; to see such fields&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Arithmetic&lt;/strong&gt;: Simple arithmetic can be done on numeric fields using &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt; and &lt;code&gt;*&lt;/code&gt;. E.g. &lt;code&gt;%(playlist_index+10)03d&lt;/code&gt;, &lt;code&gt;%(n_entries+1-playlist_index)d&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Date/time Formatting&lt;/strong&gt;: Date/time fields can be formatted according to &lt;a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes"&gt;strftime formatting&lt;/a&gt; by specifying it separated from the field name using a &lt;code&gt;&amp;gt;&lt;/code&gt;. E.g. &lt;code&gt;%(duration&amp;gt;%H-%M-%S)s&lt;/code&gt;, &lt;code&gt;%(upload_date&amp;gt;%Y-%m-%d)s&lt;/code&gt;, &lt;code&gt;%(epoch-3600&amp;gt;%H-%M-%S)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternatives&lt;/strong&gt;: Alternate fields can be specified separated with a &lt;code&gt;,&lt;/code&gt;. E.g. &lt;code&gt;%(release_date&amp;gt;%Y,upload_date&amp;gt;%Y|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Replacement&lt;/strong&gt;: A replacement value can be specified using a &lt;code&gt;&amp;amp;&lt;/code&gt; separator according to the &lt;a href="https://docs.python.org/3/library/string.html#format-specification-mini-language"&gt;&lt;code&gt;str.format&lt;/code&gt; mini-language&lt;/a&gt;. If the field is &lt;em&gt;not&lt;/em&gt; empty, this replacement value will be used instead of the actual field content. This is done after alternate fields are considered; thus the replacement is used if &lt;em&gt;any&lt;/em&gt; of the alternative fields is &lt;em&gt;not&lt;/em&gt; empty. E.g. &lt;code&gt;%(chapters&amp;amp;has chapters|no chapters)s&lt;/code&gt;, &lt;code&gt;%(title&amp;amp;TITLE={:&amp;gt;20}|NO TITLE)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Default&lt;/strong&gt;: A literal default value can be specified for when the field is empty using a &lt;code&gt;|&lt;/code&gt; separator. This overrides &lt;code&gt;--output-na-placeholder&lt;/code&gt;. E.g. &lt;code&gt;%(uploader|Unknown)s&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;More Conversions&lt;/strong&gt;: In addition to the normal format types &lt;code&gt;diouxXeEfFgGcrs&lt;/code&gt;, yt-dlp additionally supports converting to &lt;code&gt;B&lt;/code&gt; = &lt;strong&gt;B&lt;/strong&gt;ytes, &lt;code&gt;j&lt;/code&gt; = &lt;strong&gt;j&lt;/strong&gt;son (flag &lt;code&gt;#&lt;/code&gt; for pretty-printing, &lt;code&gt;+&lt;/code&gt; for Unicode), &lt;code&gt;h&lt;/code&gt; = HTML escaping, &lt;code&gt;l&lt;/code&gt; = a comma separated &lt;strong&gt;l&lt;/strong&gt;ist (flag &lt;code&gt;#&lt;/code&gt; for &lt;code&gt;\n&lt;/code&gt; newline-separated), &lt;code&gt;q&lt;/code&gt; = a string &lt;strong&gt;q&lt;/strong&gt;uoted for the terminal (flag &lt;code&gt;#&lt;/code&gt; to split a list into different arguments), &lt;code&gt;D&lt;/code&gt; = add &lt;strong&gt;D&lt;/strong&gt;ecimal suffixes (e.g. 10M) (flag &lt;code&gt;#&lt;/code&gt; to use 1024 as factor), and &lt;code&gt;S&lt;/code&gt; = &lt;strong&gt;S&lt;/strong&gt;anitize as filename (flag &lt;code&gt;#&lt;/code&gt; for restricted)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unicode normalization&lt;/strong&gt;: The format type &lt;code&gt;U&lt;/code&gt; can be used for NFC &lt;a href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize"&gt;Unicode normalization&lt;/a&gt;. The alternate form flag (&lt;code&gt;#&lt;/code&gt;) changes the normalization to NFD and the conversion flag &lt;code&gt;+&lt;/code&gt; can be used for NFKC/NFKD compatibility equivalence normalization. E.g. &lt;code&gt;%(title)+.100U&lt;/code&gt; is NFKC&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;To summarize, the general syntax for a field is:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;%(name[.keys][addition][&amp;gt;strf][,alternate][&amp;amp;replacement][|default])[flags][width][.precision][length]type
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additionally, you can set different output templates for the various metadata files separately from the general output template by specifying the type of file followed by the template separated by a colon &lt;code&gt;:&lt;/code&gt;. The different file types supported are &lt;code&gt;subtitle&lt;/code&gt;, &lt;code&gt;thumbnail&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt;, &lt;code&gt;annotation&lt;/code&gt; (deprecated), &lt;code&gt;infojson&lt;/code&gt;, &lt;code&gt;link&lt;/code&gt;, &lt;code&gt;pl_thumbnail&lt;/code&gt;, &lt;code&gt;pl_description&lt;/code&gt;, &lt;code&gt;pl_infojson&lt;/code&gt;, &lt;code&gt;chapter&lt;/code&gt;, &lt;code&gt;pl_video&lt;/code&gt;. E.g. &lt;code&gt;-o "%(title)s.%(ext)s" -o "thumbnail:%(title)s\%(title)s.%(ext)s"&lt;/code&gt; will put the thumbnails in a folder with the same name as the video. If any of the templates is empty, that type of file will not be written. E.g. &lt;code&gt;--write-thumbnail -o "thumbnail:"&lt;/code&gt; will write thumbnails only for playlists and not for video.&lt;/p&gt; 
&lt;p&gt;&lt;a id="outtmpl-postprocess-note"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Due to post-processing (i.e. merging etc.), the actual output filename might differ. Use &lt;code&gt;--print after_move:filepath&lt;/code&gt; to get the name after all post-processing is complete.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;id&lt;/code&gt; (string): Video identifier&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;title&lt;/code&gt; (string): Video title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fulltitle&lt;/code&gt; (string): Video title ignoring live timestamp and generic title&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt; (string): Video filename extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;alt_title&lt;/code&gt; (string): A secondary title of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;description&lt;/code&gt; (string): The description of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;display_id&lt;/code&gt; (string): An alternative identifier for the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader&lt;/code&gt; (string): Full name of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_id&lt;/code&gt; (string): Nickname or id of the video uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;uploader_url&lt;/code&gt; (string): URL to the video uploader's profile&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;license&lt;/code&gt; (string): License name the video is licensed under&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creators&lt;/code&gt; (list): The creators of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;creator&lt;/code&gt; (string): The creators of the video; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video became available&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;upload_date&lt;/code&gt; (string): Video upload date in UTC (YYYYMMDD)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was released in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;release_year&lt;/code&gt; (numeric): Year (YYYY) when the video or album was released&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_timestamp&lt;/code&gt; (numeric): UNIX timestamp of the moment the video was last modified&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;modified_date&lt;/code&gt; (string): The date (YYYYMMDD) when the video was last modified in UTC&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel&lt;/code&gt; (string): Full name of the channel the video is uploaded on&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_id&lt;/code&gt; (string): Id of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_url&lt;/code&gt; (string): URL of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_follower_count&lt;/code&gt; (numeric): Number of followers of the channel&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channel_is_verified&lt;/code&gt; (boolean): Whether the channel is verified on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;location&lt;/code&gt; (string): Physical location where the video was filmed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration&lt;/code&gt; (numeric): Length of the video in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;duration_string&lt;/code&gt; (string): Length of the video (HH:mm:ss)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;view_count&lt;/code&gt; (numeric): How many users have watched the video on the platform&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;concurrent_view_count&lt;/code&gt; (numeric): How many users are currently watching the video on the platform.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;like_count&lt;/code&gt; (numeric): Number of positive ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dislike_count&lt;/code&gt; (numeric): Number of negative ratings of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;repost_count&lt;/code&gt; (numeric): Number of reposts of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;average_rating&lt;/code&gt; (numeric): Average rating given by users, the scale used depends on the webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_count&lt;/code&gt; (numeric): Number of comments on the video (For some extractors, comments are only downloaded at the end, and so this field cannot be used)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;age_limit&lt;/code&gt; (numeric): Age restriction for the video (years)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;live_status&lt;/code&gt; (string): One of "not_live", "is_live", "is_upcoming", "was_live", "post_live" (was live, but VOD is not yet processed)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt; (boolean): Whether this video is a live stream or a fixed-length video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;was_live&lt;/code&gt; (boolean): Whether this video was originally a live stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playable_in_embed&lt;/code&gt; (string): Whether this video is allowed to play in embedded players on other sites&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;availability&lt;/code&gt; (string): Whether the video is "private", "premium_only", "subscriber_only", "needs_auth", "unlisted" or "public"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;media_type&lt;/code&gt; (string): The type of media as classified by the site, e.g. "episode", "clip", "trailer"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should start, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): Time in seconds where the reproduction should end, as specified in the URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor&lt;/code&gt; (string): Name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;extractor_key&lt;/code&gt; (string): Key name of the extractor&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;epoch&lt;/code&gt; (numeric): Unix epoch of when the information extraction was completed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;autonumber&lt;/code&gt; (numeric): Number that will be increased with each download, starting at &lt;code&gt;--autonumber-start&lt;/code&gt;, padded with leading zeros to 5 digits&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;video_autonumber&lt;/code&gt; (numeric): Number that will be increased with each video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;n_entries&lt;/code&gt; (numeric): Total number of extracted items in the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_id&lt;/code&gt; (string): Identifier of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_title&lt;/code&gt; (string): Name of the playlist that contains the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist&lt;/code&gt; (string): &lt;code&gt;playlist_title&lt;/code&gt; if available or else &lt;code&gt;playlist_id&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_count&lt;/code&gt; (numeric): Total number of items in the playlist. May not be known if entire playlist is not extracted&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; (numeric): Index of the video in the playlist padded with leading zeros according the final index&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_autonumber&lt;/code&gt; (numeric): Position of the video in the playlist download queue padded with leading zeros according to the total length of the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader&lt;/code&gt; (string): Full name of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_uploader_id&lt;/code&gt; (string): Nickname or id of the playlist uploader&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel&lt;/code&gt; (string): Display name of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_channel_id&lt;/code&gt; (string): Identifier of the channel that uploaded the playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_webpage_url&lt;/code&gt; (string): URL of the playlist webpage&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url&lt;/code&gt; (string): A URL to the video webpage which, if given to yt-dlp, should yield the same result again&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_basename&lt;/code&gt; (string): The basename of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_url_domain&lt;/code&gt; (string): The domain of the webpage URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_url&lt;/code&gt; (string): The URL given by the user (or the same as &lt;code&gt;webpage_url&lt;/code&gt; for playlist entries)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): List of categories the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tags&lt;/code&gt; (list): List of tags assigned to the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cast&lt;/code&gt; (list): List of cast members&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All the fields in &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#filtering-formats"&gt;Filtering Formats&lt;/a&gt; can also be used&lt;/p&gt; 
&lt;p&gt;Available for the video that belongs to some logical chapter or section:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;chapter&lt;/code&gt; (string): Name or title of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_number&lt;/code&gt; (numeric): Number of the chapter the video belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;chapter_id&lt;/code&gt; (string): Id of the chapter the video belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the video that is an episode of some series or program:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;series&lt;/code&gt; (string): Title of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;series_id&lt;/code&gt; (string): Id of the series or program the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season&lt;/code&gt; (string): Title of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_number&lt;/code&gt; (numeric): Number of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;season_id&lt;/code&gt; (string): Id of the season the video episode belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode&lt;/code&gt; (string): Title of the video episode&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_number&lt;/code&gt; (numeric): Number of the video episode within a season&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;episode_id&lt;/code&gt; (string): Id of the video episode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available for the media that is a track or a part of a music album:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;track&lt;/code&gt; (string): Title of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_number&lt;/code&gt; (numeric): Number of the track within an album or a disc&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;track_id&lt;/code&gt; (string): Id of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artists&lt;/code&gt; (list): Artist(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;artist&lt;/code&gt; (string): Artist(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genres&lt;/code&gt; (list): Genre(s) of the track&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;genre&lt;/code&gt; (string): Genre(s) of the track; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composers&lt;/code&gt; (list): Composer(s) of the piece&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;composer&lt;/code&gt; (string): Composer(s) of the piece; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album&lt;/code&gt; (string): Title of the album the track belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_type&lt;/code&gt; (string): Type of the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artists&lt;/code&gt; (list): All artists appeared on the album&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;album_artist&lt;/code&gt; (string): All artists appeared on the album; comma-separated&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;disc_number&lt;/code&gt; (numeric): Number of the disc or other physical medium the track belongs to&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when using &lt;code&gt;--download-sections&lt;/code&gt; and for &lt;code&gt;chapter:&lt;/code&gt; prefix when using &lt;code&gt;--split-chapters&lt;/code&gt; for videos with internal chapters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;section_title&lt;/code&gt; (string): Title of the chapter&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_number&lt;/code&gt; (numeric): Number of the chapter within the file&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_start&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;section_end&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only when used in &lt;code&gt;--print&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;urls&lt;/code&gt; (string): The URLs of all requested formats, one in each line&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filename&lt;/code&gt; (string): Name of the video file. Note that the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#outtmpl-postprocess-note"&gt;actual filename may differ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats_table&lt;/code&gt; (table): The video format table as printed by &lt;code&gt;--list-formats&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;thumbnails_table&lt;/code&gt; (table): The thumbnail format table as printed by &lt;code&gt;--list-thumbnails&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;subtitles_table&lt;/code&gt; (table): The subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;automatic_captions_table&lt;/code&gt; (table): The automatic subtitle format table as printed by &lt;code&gt;--list-subs&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only after the video is downloaded (&lt;code&gt;post_process&lt;/code&gt;/&lt;code&gt;after_move&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filepath&lt;/code&gt;: Actual path of downloaded video file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Available only in &lt;code&gt;--sponsorblock-chapter-title&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;start_time&lt;/code&gt; (numeric): Start time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;end_time&lt;/code&gt; (numeric): End time of the chapter in seconds&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;categories&lt;/code&gt; (list): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Category"&gt;SponsorBlock categories&lt;/a&gt; the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category&lt;/code&gt; (string): The smallest SponsorBlock category the chapter belongs to&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;category_names&lt;/code&gt; (list): Friendly names of the categories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt; (string): Friendly name of the smallest category&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt; (string): The &lt;a href="https://wiki.sponsor.ajay.app/w/Types#Action_Type"&gt;SponsorBlock action type&lt;/a&gt; of the chapter&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each aforementioned sequence when referenced in an output template will be replaced by the actual value corresponding to the sequence name. E.g. for &lt;code&gt;-o %(title)s-%(id)s.%(ext)s&lt;/code&gt; and an mp4 video with title &lt;code&gt;yt-dlp test video&lt;/code&gt; and id &lt;code&gt;BaW_jenozKc&lt;/code&gt;, this will result in a &lt;code&gt;yt-dlp test video-BaW_jenozKc.mp4&lt;/code&gt; file created in the current directory.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Some of the sequences are not guaranteed to be present, since they depend on the metadata obtained by a particular extractor. Such sequences will be replaced with placeholder value provided with &lt;code&gt;--output-na-placeholder&lt;/code&gt; (&lt;code&gt;NA&lt;/code&gt; by default).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Look at the &lt;code&gt;-j&lt;/code&gt; output to identify which fields are available for the particular URL&lt;/p&gt; 
&lt;p&gt;For numeric sequences, you can use &lt;a href="https://docs.python.org/3/library/stdtypes.html#printf-style-string-formatting"&gt;numeric related formatting&lt;/a&gt;; e.g. &lt;code&gt;%(view_count)05d&lt;/code&gt; will result in a string with view count padded with zeros up to 5 characters, like in &lt;code&gt;00042&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Output templates can also contain arbitrary hierarchical path, e.g. &lt;code&gt;-o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s"&lt;/code&gt; which will result in downloading each video in a directory corresponding to this path template. Any missing directory will be automatically created for you.&lt;/p&gt; 
&lt;p&gt;To use percent literals in an output template use &lt;code&gt;%%&lt;/code&gt;. To output to stdout use &lt;code&gt;-o -&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The current default template is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In some cases, you don't want special characters such as ‰∏≠, spaces, or &amp;amp;, such as when transferring the downloaded filename to a Windows system or the filename through an 8bit-unsafe channel. In these cases, add the &lt;code&gt;--restrict-filenames&lt;/code&gt; flag to get a shorter title.&lt;/p&gt; 
&lt;h4&gt;Output template examples&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ yt-dlp --print filename -o "test video.%(ext)s" BaW_jenozKc
test video.webm    # Literal name with correct extension

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc
youtube-dl test video ''_√§‚Ü≠ùïê.webm    # All kinds of weird characters

$ yt-dlp --print filename -o "%(title)s.%(ext)s" BaW_jenozKc --restrict-filenames
youtube-dl_test_video_.webm    # Restricted file name

# Download YouTube playlist videos in separate directory indexed by video order in a playlist
$ yt-dlp -o "%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Download YouTube playlist videos in separate directories according to their uploaded year
$ yt-dlp -o "%(upload_date&amp;gt;%Y)s/%(title)s.%(ext)s" "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re"

# Prefix playlist index with " - " separator, but only if it is available
$ yt-dlp -o "%(playlist_index&amp;amp;{} - |)s%(title)s.%(ext)s" BaW_jenozKc "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download all playlists of YouTube channel/user keeping each playlist in separate directory:
$ yt-dlp -o "%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s" "https://www.youtube.com/user/TheLinuxFoundation/playlists"

# Download Udemy course keeping each chapter in separate directory under MyVideos directory in your home
$ yt-dlp -u user -p password -P "~/MyVideos" -o "%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s" "https://www.udemy.com/java-tutorial"

# Download entire series season keeping each series and each season in separate directory under C:/MyVideos
$ yt-dlp -P "C:/MyVideos" -o "%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s" "https://videomore.ru/kino_v_detalayah/5_sezon/367617"

# Download video as "C:\MyVideos\uploader\title.ext", subtitles as "C:\MyVideos\subs\uploader\title.ext"
# and put all temporary files in "C:\MyVideos\tmp"
$ yt-dlp -P "C:/MyVideos" -P "temp:tmp" -P "subtitle:subs" -o "%(uploader)s/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Download video as "C:\MyVideos\uploader\title.ext" and subtitles as "C:\MyVideos\uploader\subs\title.ext"
$ yt-dlp -P "C:/MyVideos" -o "%(uploader)s/%(title)s.%(ext)s" -o "subtitle:%(uploader)s/subs/%(title)s.%(ext)s" BaW_jenozKc --write-subs

# Stream the video being downloaded to stdout
$ yt-dlp -o - BaW_jenozKc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;FORMAT SELECTION&lt;/h1&gt; 
&lt;p&gt;By default, yt-dlp tries to download the best available quality if you &lt;strong&gt;don't&lt;/strong&gt; pass any options. This is generally equivalent to using &lt;code&gt;-f bestvideo*+bestaudio/best&lt;/code&gt;. However, if multiple audiostreams is enabled (&lt;code&gt;--audio-multistreams&lt;/code&gt;), the default format changes to &lt;code&gt;-f bestvideo+bestaudio/best&lt;/code&gt;. Similarly, if ffmpeg is unavailable, or if you use yt-dlp to stream to &lt;code&gt;stdout&lt;/code&gt; (&lt;code&gt;-o -&lt;/code&gt;), the default becomes &lt;code&gt;-f best/bestvideo+bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Latest versions of yt-dlp can stream multiple formats to the stdout simultaneously using ffmpeg. So, in future versions, the default for this will be set to &lt;code&gt;-f bv*+ba/b&lt;/code&gt; similar to normal downloads. If you want to preserve the &lt;code&gt;-f b/bv+ba&lt;/code&gt; setting, it is recommended to explicitly specify it in the configuration options.&lt;/p&gt; 
&lt;p&gt;The general syntax for format selection is &lt;code&gt;-f FORMAT&lt;/code&gt; (or &lt;code&gt;--format FORMAT&lt;/code&gt;) where &lt;code&gt;FORMAT&lt;/code&gt; is a &lt;em&gt;selector expression&lt;/em&gt;, i.e. an expression that describes format or formats you would like to download.&lt;/p&gt; 
&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt; 
&lt;p&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;navigate me to examples&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt; 
&lt;p&gt;The simplest case is requesting a specific format; e.g. with &lt;code&gt;-f 22&lt;/code&gt; you can download the format with format code equal to 22. You can get the list of available format codes for particular video using &lt;code&gt;--list-formats&lt;/code&gt; or &lt;code&gt;-F&lt;/code&gt;. Note that these format codes are extractor specific.&lt;/p&gt; 
&lt;p&gt;You can also use a file extension (currently &lt;code&gt;3gp&lt;/code&gt;, &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;flv&lt;/code&gt;, &lt;code&gt;m4a&lt;/code&gt;, &lt;code&gt;mp3&lt;/code&gt;, &lt;code&gt;mp4&lt;/code&gt;, &lt;code&gt;ogg&lt;/code&gt;, &lt;code&gt;wav&lt;/code&gt;, &lt;code&gt;webm&lt;/code&gt; are supported) to download the best quality format of a particular file extension served as a single file, e.g. &lt;code&gt;-f webm&lt;/code&gt; will download the best quality format with the &lt;code&gt;webm&lt;/code&gt; extension served as a single file.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;-f -&lt;/code&gt; to interactively provide the format selector &lt;em&gt;for each video&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;You can also use special names to select particular edge case formats:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;all&lt;/code&gt;: Select &lt;strong&gt;all formats&lt;/strong&gt; separately&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;mergeall&lt;/code&gt;: Select and &lt;strong&gt;merge all formats&lt;/strong&gt; (Must be used with &lt;code&gt;--audio-multistreams&lt;/code&gt;, &lt;code&gt;--video-multistreams&lt;/code&gt; or both)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b*&lt;/code&gt;, &lt;code&gt;best*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains either&lt;/strong&gt; a video or an audio or both (i.e.; &lt;code&gt;vcodec!=none or acodec!=none&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;b&lt;/code&gt;, &lt;code&gt;best&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains both&lt;/strong&gt; video and audio. Equivalent to &lt;code&gt;best*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv&lt;/code&gt;, &lt;code&gt;bestvideo&lt;/code&gt;: Select the best quality &lt;strong&gt;video-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;bv*&lt;/code&gt;, &lt;code&gt;bestvideo*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains video&lt;/strong&gt;. It may also contain audio. Equivalent to &lt;code&gt;best*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba&lt;/code&gt;, &lt;code&gt;bestaudio&lt;/code&gt;: Select the best quality &lt;strong&gt;audio-only&lt;/strong&gt; format. Equivalent to &lt;code&gt;best*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ba*&lt;/code&gt;, &lt;code&gt;bestaudio*&lt;/code&gt;: Select the best quality format that &lt;strong&gt;contains audio&lt;/strong&gt;. It may also contain video. Equivalent to &lt;code&gt;best*[acodec!=none]&lt;/code&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/979#issuecomment-919629354"&gt;Do not use!&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w*&lt;/code&gt;, &lt;code&gt;worst*&lt;/code&gt;: Select the worst quality format that contains either a video or an audio&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;w&lt;/code&gt;, &lt;code&gt;worst&lt;/code&gt;: Select the worst quality format that contains both video and audio. Equivalent to &lt;code&gt;worst*[vcodec!=none][acodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv&lt;/code&gt;, &lt;code&gt;worstvideo&lt;/code&gt;: Select the worst quality video-only format. Equivalent to &lt;code&gt;worst*[acodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wv*&lt;/code&gt;, &lt;code&gt;worstvideo*&lt;/code&gt;: Select the worst quality format that contains video. It may also contain audio. Equivalent to &lt;code&gt;worst*[vcodec!=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa&lt;/code&gt;, &lt;code&gt;worstaudio&lt;/code&gt;: Select the worst quality audio-only format. Equivalent to &lt;code&gt;worst*[vcodec=none]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;wa*&lt;/code&gt;, &lt;code&gt;worstaudio*&lt;/code&gt;: Select the worst quality format that contains audio. It may also contain video. Equivalent to &lt;code&gt;worst*[acodec!=none]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For example, to download the worst quality video-only format you can use &lt;code&gt;-f worstvideo&lt;/code&gt;. It is, however, recommended not to use &lt;code&gt;worst&lt;/code&gt; and related options. When your format selector is &lt;code&gt;worst&lt;/code&gt;, the format which is worst in all respects is selected. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-S +size&lt;/code&gt; or more rigorously, &lt;code&gt;-S +size,+br,+res,+fps&lt;/code&gt; instead of &lt;code&gt;-f worst&lt;/code&gt;. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Sorting Formats&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;You can select the n'th best format of a type by using &lt;code&gt;best&amp;lt;type&amp;gt;.&amp;lt;n&amp;gt;&lt;/code&gt;. For example, &lt;code&gt;best.2&lt;/code&gt; will select the 2nd best combined format. Similarly, &lt;code&gt;bv*.3&lt;/code&gt; will select the 3rd best format that contains a video stream.&lt;/p&gt; 
&lt;p&gt;If you want to download multiple videos, and they don't have the same formats available, you can specify the order of preference using slashes. Note that formats on the left hand side are preferred; e.g. &lt;code&gt;-f 22/17/18&lt;/code&gt; will download format 22 if it's available, otherwise it will download format 17 if it's available, otherwise it will download format 18 if it's available, otherwise it will complain that no suitable formats are available for download.&lt;/p&gt; 
&lt;p&gt;If you want to download several formats of the same video use a comma as a separator, e.g. &lt;code&gt;-f 22,17,18&lt;/code&gt; will download all these three formats, of course if they are available. Or a more sophisticated example combined with the precedence feature: &lt;code&gt;-f 136/137/mp4/bestvideo,140/m4a/bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can merge the video and audio of multiple formats into a single file using &lt;code&gt;-f &amp;lt;format1&amp;gt;+&amp;lt;format2&amp;gt;+...&lt;/code&gt; (requires ffmpeg installed); e.g. &lt;code&gt;-f bestvideo+bestaudio&lt;/code&gt; will download the best video-only format, the best audio-only format and mux them together with ffmpeg.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Since the &lt;em&gt;below&lt;/em&gt; described behavior is complex and counter-intuitive, this will be removed and multistreams will be enabled by default in the future. A new operator will be instead added to limit formats to single audio/video&lt;/p&gt; 
&lt;p&gt;Unless &lt;code&gt;--video-multistreams&lt;/code&gt; is used, all formats with a video stream except the first one are ignored. Similarly, unless &lt;code&gt;--audio-multistreams&lt;/code&gt; is used, all formats with an audio stream except the first one are ignored. E.g. &lt;code&gt;-f bestvideo+best+bestaudio --video-multistreams --audio-multistreams&lt;/code&gt; will download and merge all 3 given formats. The resulting file will have 2 video streams and 2 audio streams. But &lt;code&gt;-f bestvideo+best+bestaudio --no-video-multistreams&lt;/code&gt; will download and merge only &lt;code&gt;bestvideo&lt;/code&gt; and &lt;code&gt;bestaudio&lt;/code&gt;. &lt;code&gt;best&lt;/code&gt; is ignored since another format containing a video stream (&lt;code&gt;bestvideo&lt;/code&gt;) has already been selected. The order of the formats is therefore important. &lt;code&gt;-f best+bestaudio --no-audio-multistreams&lt;/code&gt; will download only &lt;code&gt;best&lt;/code&gt; while &lt;code&gt;-f bestaudio+best --no-audio-multistreams&lt;/code&gt; will ignore &lt;code&gt;best&lt;/code&gt; and download only &lt;code&gt;bestaudio&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Filtering Formats&lt;/h2&gt; 
&lt;p&gt;You can also filter the video formats by putting a condition in brackets, as in &lt;code&gt;-f "best[height=720]"&lt;/code&gt; (or &lt;code&gt;-f "[filesize&amp;gt;10M]"&lt;/code&gt; since filters without a selector are interpreted as &lt;code&gt;best&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;The following numeric meta fields can be used with comparisons &lt;code&gt;&amp;lt;&lt;/code&gt;, &lt;code&gt;&amp;lt;=&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt;, &lt;code&gt;&amp;gt;=&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;!=&lt;/code&gt; (not equals):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: The number of bytes, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize_approx&lt;/code&gt;: An estimate for the number of bytes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aspect_ratio&lt;/code&gt;: Aspect ratio of the video, if known&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Average bitrate of audio and video in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sampling rate in Hertz&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Frame rate&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;audio_channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;stretched_ratio&lt;/code&gt;: &lt;code&gt;width:height&lt;/code&gt; of the video's pixels, if not square&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also filtering work for comparisons &lt;code&gt;=&lt;/code&gt; (equals), &lt;code&gt;^=&lt;/code&gt; (starts with), &lt;code&gt;$=&lt;/code&gt; (ends with), &lt;code&gt;*=&lt;/code&gt; (contains), &lt;code&gt;~=&lt;/code&gt; (matches regex) and following string meta fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;url&lt;/code&gt;: Video URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: File extension&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Name of the audio codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Name of the video codec in use&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;container&lt;/code&gt;: Name of the container format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;protocol&lt;/code&gt;: The protocol that will be used for the actual download, lower-case (&lt;code&gt;http&lt;/code&gt;, &lt;code&gt;https&lt;/code&gt;, &lt;code&gt;rtsp&lt;/code&gt;, &lt;code&gt;rtmp&lt;/code&gt;, &lt;code&gt;rtmpe&lt;/code&gt;, &lt;code&gt;mms&lt;/code&gt;, &lt;code&gt;f4m&lt;/code&gt;, &lt;code&gt;ism&lt;/code&gt;, &lt;code&gt;http_dash_segments&lt;/code&gt;, &lt;code&gt;m3u8&lt;/code&gt;, or &lt;code&gt;m3u8_native&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;language&lt;/code&gt;: Language code&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dynamic_range&lt;/code&gt;: The dynamic range of the video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_id&lt;/code&gt;: A short description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format&lt;/code&gt;: A human-readable description of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;format_note&lt;/code&gt;: Additional info about the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;resolution&lt;/code&gt;: Textual description of width and height&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Any string comparison may be prefixed with negation &lt;code&gt;!&lt;/code&gt; in order to produce an opposite comparison, e.g. &lt;code&gt;!*=&lt;/code&gt; (does not contain). The comparand of a string comparison needs to be quoted with either double or single quotes if it contains spaces or special characters other than &lt;code&gt;._-&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: None of the aforementioned meta fields are guaranteed to be present since this solely depends on the metadata obtained by the particular extractor, i.e. the metadata offered by the website. Any other field made available by the extractor can also be used for filtering.&lt;/p&gt; 
&lt;p&gt;Formats for which the value is not known are excluded unless you put a question mark (&lt;code&gt;?&lt;/code&gt;) after the operator. You can combine format filters, so &lt;code&gt;-f "bv[height&amp;lt;=?720][tbr&amp;gt;500]"&lt;/code&gt; selects up to 720p videos (or videos where the height is not known) with a bitrate of at least 500 kbps. You can also use the filters with &lt;code&gt;all&lt;/code&gt; to download all formats that satisfy the filter, e.g. &lt;code&gt;-f "all[vcodec=none]"&lt;/code&gt; selects all audio-only formats.&lt;/p&gt; 
&lt;p&gt;Format selectors can also be grouped using parentheses; e.g. &lt;code&gt;-f "(mp4,webm)[height&amp;lt;480]"&lt;/code&gt; will download the best pre-merged mp4 and webm formats with a height lower than 480.&lt;/p&gt; 
&lt;h2&gt;Sorting Formats&lt;/h2&gt; 
&lt;p&gt;You can change the criteria for being considered the &lt;code&gt;best&lt;/code&gt; by using &lt;code&gt;-S&lt;/code&gt; (&lt;code&gt;--format-sort&lt;/code&gt;). The general format for this is &lt;code&gt;--format-sort field1,field2...&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The available fields are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;hasvid&lt;/code&gt;: Gives priority to formats that have a video stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hasaud&lt;/code&gt;: Gives priority to formats that have an audio stream&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ie_pref&lt;/code&gt;: The format preference&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: The language preference as determined by the extractor (e.g. original language preferred over audio description)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;quality&lt;/code&gt;: The quality of the format&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;source&lt;/code&gt;: The preference of the source&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;proto&lt;/code&gt;: Protocol used for download (&lt;code&gt;https&lt;/code&gt;/&lt;code&gt;ftps&lt;/code&gt; &amp;gt; &lt;code&gt;http&lt;/code&gt;/&lt;code&gt;ftp&lt;/code&gt; &amp;gt; &lt;code&gt;m3u8_native&lt;/code&gt;/&lt;code&gt;m3u8&lt;/code&gt; &amp;gt; &lt;code&gt;http_dash_segments&lt;/code&gt;&amp;gt; &lt;code&gt;websocket_frag&lt;/code&gt; &amp;gt; &lt;code&gt;mms&lt;/code&gt;/&lt;code&gt;rtsp&lt;/code&gt; &amp;gt; &lt;code&gt;f4f&lt;/code&gt;/&lt;code&gt;f4m&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: Video Codec (&lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;acodec&lt;/code&gt;: Audio Codec (&lt;code&gt;flac&lt;/code&gt;/&lt;code&gt;alac&lt;/code&gt; &amp;gt; &lt;code&gt;wav&lt;/code&gt;/&lt;code&gt;aiff&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac4&lt;/code&gt; &amp;gt; &lt;code&gt;eac3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt; &amp;gt; other)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;codec&lt;/code&gt;: Equivalent to &lt;code&gt;vcodec,acodec&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vext&lt;/code&gt;: Video Extension (&lt;code&gt;mp4&lt;/code&gt; &amp;gt; &lt;code&gt;mov&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;flv&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, &lt;code&gt;webm&lt;/code&gt; is preferred.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aext&lt;/code&gt;: Audio Extension (&lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; other). If &lt;code&gt;--prefer-free-formats&lt;/code&gt; is used, the order changes to &lt;code&gt;ogg&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;webm&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;m4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ext&lt;/code&gt;: Equivalent to &lt;code&gt;vext,aext&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;filesize&lt;/code&gt;: Exact filesize, if known in advance&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fs_approx&lt;/code&gt;: Approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;size&lt;/code&gt;: Exact filesize if available, otherwise approximate filesize&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;height&lt;/code&gt;: Height of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;width&lt;/code&gt;: Width of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: Video resolution, calculated as the smallest dimension.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fps&lt;/code&gt;: Framerate of video&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hdr&lt;/code&gt;: The dynamic range of the video (&lt;code&gt;DV&lt;/code&gt; &amp;gt; &lt;code&gt;HDR12&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10+&lt;/code&gt; &amp;gt; &lt;code&gt;HDR10&lt;/code&gt; &amp;gt; &lt;code&gt;HLG&lt;/code&gt; &amp;gt; &lt;code&gt;SDR&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;channels&lt;/code&gt;: The number of audio channels&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tbr&lt;/code&gt;: Total average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vbr&lt;/code&gt;: Average video bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;abr&lt;/code&gt;: Average audio bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;br&lt;/code&gt;: Average bitrate in &lt;a href="##" title="1000 bits/sec"&gt;kbps&lt;/a&gt;, &lt;code&gt;tbr&lt;/code&gt;/&lt;code&gt;vbr&lt;/code&gt;/&lt;code&gt;abr&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;asr&lt;/code&gt;: Audio sample rate in Hz&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Deprecation warning&lt;/strong&gt;: Many of these fields have (currently undocumented) aliases, that may be removed in a future version. It is recommended to use only the documented field names.&lt;/p&gt; 
&lt;p&gt;All fields, unless specified otherwise, are sorted in descending order. To reverse this, prefix the field with a &lt;code&gt;+&lt;/code&gt;. E.g. &lt;code&gt;+res&lt;/code&gt; prefers format with the smallest resolution. Additionally, you can suffix a preferred value for the fields, separated by a &lt;code&gt;:&lt;/code&gt;. E.g. &lt;code&gt;res:720&lt;/code&gt; prefers larger videos, but no larger than 720p and the smallest video if there are no videos less than 720p. For &lt;code&gt;codec&lt;/code&gt; and &lt;code&gt;ext&lt;/code&gt;, you can provide two preferred values, the first for video and the second for audio. E.g. &lt;code&gt;+codec:avc:m4a&lt;/code&gt; (equivalent to &lt;code&gt;+vcodec:avc,+acodec:m4a&lt;/code&gt;) sets the video codec preference to &lt;code&gt;h264&lt;/code&gt; &amp;gt; &lt;code&gt;h265&lt;/code&gt; &amp;gt; &lt;code&gt;vp9&lt;/code&gt; &amp;gt; &lt;code&gt;vp9.2&lt;/code&gt; &amp;gt; &lt;code&gt;av01&lt;/code&gt; &amp;gt; &lt;code&gt;vp8&lt;/code&gt; &amp;gt; &lt;code&gt;h263&lt;/code&gt; &amp;gt; &lt;code&gt;theora&lt;/code&gt; and audio codec preference to &lt;code&gt;mp4a&lt;/code&gt; &amp;gt; &lt;code&gt;aac&lt;/code&gt; &amp;gt; &lt;code&gt;vorbis&lt;/code&gt; &amp;gt; &lt;code&gt;opus&lt;/code&gt; &amp;gt; &lt;code&gt;mp3&lt;/code&gt; &amp;gt; &lt;code&gt;ac3&lt;/code&gt; &amp;gt; &lt;code&gt;dts&lt;/code&gt;. You can also make the sorting prefer the nearest values to the provided by using &lt;code&gt;~&lt;/code&gt; as the delimiter. E.g. &lt;code&gt;filesize~1G&lt;/code&gt; prefers the format with filesize closest to 1 GiB.&lt;/p&gt; 
&lt;p&gt;The fields &lt;code&gt;hasvid&lt;/code&gt; and &lt;code&gt;ie_pref&lt;/code&gt; are always given highest priority in sorting, irrespective of the user-defined order. This behavior can be changed by using &lt;code&gt;--format-sort-force&lt;/code&gt;. Apart from these, the default order used is: &lt;code&gt;lang,quality,res,fps,hdr:12,vcodec,channels,acodec,size,br,asr,proto,ext,hasaud,source,id&lt;/code&gt;. The extractors may override this default order, but they cannot override the user-provided order.&lt;/p&gt; 
&lt;p&gt;Note that the default for hdr is &lt;code&gt;hdr:12&lt;/code&gt;; i.e. Dolby Vision is not preferred. This choice was made since DV formats are not yet fully compatible with most devices. This may be changed in the future.&lt;/p&gt; 
&lt;p&gt;If your format selector is &lt;code&gt;worst&lt;/code&gt;, the last item is selected after sorting. This means it will select the format that is worst in all respects. Most of the time, what you actually want is the video with the smallest filesize instead. So it is generally better to use &lt;code&gt;-f best -S +size,+br,+res,+fps&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: You can use the &lt;code&gt;-v -F&lt;/code&gt; to see how the formats have been sorted (worst to best).&lt;/p&gt; 
&lt;h2&gt;Format Selection examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download and merge the best video-only format and the best audio-only format,
# or download the best combined format if video-only format is not available
$ yt-dlp -f "bv+ba/b"

# Download best format that contains video,
# and if it doesn't already have an audio stream, merge it with best audio-only format
$ yt-dlp -f "bv*+ba/b"

# Same as above
$ yt-dlp

# Download the best video-only format and the best audio-only format without merging them
# For this case, an output template should be used since
# by default, bestvideo and bestaudio will have the same file name.
$ yt-dlp -f "bv,ba" -o "%(title)s.f%(format_id)s.%(ext)s"

# Download and merge the best format that has a video stream,
# and all audio-only formats into one file
$ yt-dlp -f "bv*+mergeall[vcodec=none]" --audio-multistreams

# Download and merge the best format that has a video stream,
# and the best 2 audio-only formats into one file
$ yt-dlp -f "bv*+ba+ba.2" --audio-multistreams


# The following examples show the old method (without -S) of format selection
# and how to use -S to achieve a similar but (generally) better result

# Download the worst video available (old method)
$ yt-dlp -f "wv*+wa/w"

# Download the best video available but with the smallest resolution
$ yt-dlp -S "+res"

# Download the smallest video available
$ yt-dlp -S "+size,+br"



# Download the best mp4 video available, or the best video if no mp4 available
$ yt-dlp -f "bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b"

# Download the best video with the best extension
# (For video, mp4 &amp;gt; mov &amp;gt; webm &amp;gt; flv. For audio, m4a &amp;gt; aac &amp;gt; mp3 ...)
$ yt-dlp -S "ext"



# Download the best video available but no better than 480p,
# or the worst video if there is no video under 480p
$ yt-dlp -f "bv*[height&amp;lt;=480]+ba/b[height&amp;lt;=480] / wv*+ba/w"

# Download the best video available with the largest height but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
$ yt-dlp -S "height:480"

# Download the best video available with the largest resolution but no better than 480p,
# or the best video with the smallest resolution if there is no video under 480p
# Resolution is determined by using the smallest dimension.
# So this works correctly for vertical videos as well
$ yt-dlp -S "res:480"



# Download the best video (that also has audio) but no bigger than 50 MB,
# or the worst video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b[filesize&amp;lt;50M] / w"

# Download the largest video (that also has audio) but no bigger than 50 MB,
# or the smallest video (that also has audio) if there is no video under 50 MB
$ yt-dlp -f "b" -S "filesize:50M"

# Download the best video (that also has audio) that is closest in size to 50 MB
$ yt-dlp -f "b" -S "filesize~50M"



# Download best video available via direct link over HTTP/HTTPS protocol,
# or the best video available via any protocol if there is no such video
$ yt-dlp -f "(bv*+ba/b)[protocol^=http][protocol!*=dash] / (bv*+ba/b)"

# Download best video available via the best protocol
# (https/ftps &amp;gt; http/ftp &amp;gt; m3u8_native &amp;gt; m3u8 &amp;gt; http_dash_segments ...)
$ yt-dlp -S "proto"



# Download the best video with either h264 or h265 codec,
# or the best video if there is no such video
$ yt-dlp -f "(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)"

# Download the best video with best codec no better than h264,
# or the best video with worst codec if there is no such video
$ yt-dlp -S "codec:h264"

# Download the best video with worst codec no worse than h264,
# or the best video with best codec if there is no such video
$ yt-dlp -S "+codec:h264"



# More complex examples

# Download the best video no better than 720p preferring framerate greater than 30,
# or the worst video (still preferring framerate greater than 30) if there is no such video
$ yt-dlp -f "((bv*[fps&amp;gt;30]/bv*)[height&amp;lt;=720]/(wv*[fps&amp;gt;30]/wv*)) + ba / (b[fps&amp;gt;30]/b)[height&amp;lt;=720]/(w[fps&amp;gt;30]/w)"

# Download the video with the largest resolution no better than 720p,
# or the video with the smallest resolution available if there is no such video,
# preferring larger framerate for formats with the same resolution
$ yt-dlp -S "res:720,fps"



# Download the video with smallest resolution no worse than 480p,
# or the video with the largest resolution available if there is no such video,
# preferring better codec and then larger total bitrate for the same resolution
$ yt-dlp -S "+res:480,codec,br"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;MODIFYING METADATA&lt;/h1&gt; 
&lt;p&gt;The metadata obtained by the extractors can be modified by using &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--replace-in-metadata FIELDS REGEX REPLACE&lt;/code&gt; is used to replace text in any metadata field using &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt;. &lt;a href="https://docs.python.org/3/library/re.html?highlight=backreferences#re.sub"&gt;Backreferences&lt;/a&gt; can be used in the replace string for advanced use.&lt;/p&gt; 
&lt;p&gt;The general syntax of &lt;code&gt;--parse-metadata FROM:TO&lt;/code&gt; is to give the name of a field or an &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; to extract data from, and the format to interpret it as, separated by a colon &lt;code&gt;:&lt;/code&gt;. Either a &lt;a href="https://docs.python.org/3/library/re.html#regular-expression-syntax"&gt;Python regular expression&lt;/a&gt; with named capture groups, a single field name, or a similar syntax to the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; (only &lt;code&gt;%(field)s&lt;/code&gt; formatting is supported) can be used for &lt;code&gt;TO&lt;/code&gt;. The option can be used multiple times to parse and modify various fields.&lt;/p&gt; 
&lt;p&gt;Note that these options preserve their relative order, allowing replacements to be made in parsed fields and vice versa. Also, any field thus created can be used in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; and will also affect the media file's metadata added when using &lt;code&gt;--embed-metadata&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;This option also has a few special uses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can download an additional URL based on the metadata of the currently downloaded video. To do this, set the field &lt;code&gt;additional_urls&lt;/code&gt; to the URL that you want to download. E.g. &lt;code&gt;--parse-metadata "description:(?P&amp;lt;additional_urls&amp;gt;https?://www\.vimeo\.com/\d+)"&lt;/code&gt; will download the first vimeo video found in the description&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can use this to change the metadata that is embedded in the media file. To do this, set the value of the corresponding field with a &lt;code&gt;meta_&lt;/code&gt; prefix. For example, any value you set to &lt;code&gt;meta_description&lt;/code&gt; field will be added to the &lt;code&gt;description&lt;/code&gt; field in the file - you can use this to set a different "description" and "synopsis". To modify the metadata of individual streams, use the &lt;code&gt;meta&amp;lt;n&amp;gt;_&lt;/code&gt; prefix (e.g. &lt;code&gt;meta1_language&lt;/code&gt;). Any value set to the &lt;code&gt;meta_&lt;/code&gt; field will overwrite all default values.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Metadata modification happens before format selection, post-extraction and other post-processing operations. Some fields may be added or changed during these steps, overriding your changes.&lt;/p&gt; 
&lt;p&gt;For reference, these are the fields yt-dlp adds by default to the file metadata:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Metadata fields&lt;/th&gt; 
   &lt;th align="left"&gt;From&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt; or &lt;code&gt;title&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;date&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;upload_date&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;, &lt;code&gt;synopsis&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;description&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;purl&lt;/code&gt;, &lt;code&gt;comment&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;webpage_url&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;track_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;artist&lt;/code&gt;, &lt;code&gt;artists&lt;/code&gt;, &lt;code&gt;creator&lt;/code&gt;, &lt;code&gt;creators&lt;/code&gt;, &lt;code&gt;uploader&lt;/code&gt; or &lt;code&gt;uploader_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;composer&lt;/code&gt; or &lt;code&gt;composers&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;genre&lt;/code&gt; or &lt;code&gt;genres&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;album_artist&lt;/code&gt; or &lt;code&gt;album_artists&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;disc_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;show&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;series&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;season_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode&lt;/code&gt; or &lt;code&gt;episode_id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_sort&lt;/code&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;code&gt;episode_number&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;code&gt;language&lt;/code&gt; of each stream&lt;/td&gt; 
   &lt;td align="left"&gt;the format's &lt;code&gt;language&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The file format may not support some of these fields&lt;/p&gt; 
&lt;h2&gt;Modifying metadata examples&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Interpret the title as "Artist - Title"
$ yt-dlp --parse-metadata "title:%(artist)s - %(title)s"

# Regex example
$ yt-dlp --parse-metadata "description:Artist - (?P&amp;lt;artist&amp;gt;.+)"

# Set title as "Series name S01E05"
$ yt-dlp --parse-metadata "%(series)s S%(season_number)02dE%(episode_number)02d:%(title)s"

# Prioritize uploader as the "artist" field in video metadata
$ yt-dlp --parse-metadata "%(uploader|)s:%(meta_artist)s" --embed-metadata

# Set "comment" field in video metadata using description instead of webpage_url,
# handling multiple lines correctly
$ yt-dlp --parse-metadata "description:(?s)(?P&amp;lt;meta_comment&amp;gt;.+)" --embed-metadata

# Do not set any "synopsis" in the video metadata
$ yt-dlp --parse-metadata ":(?P&amp;lt;meta_synopsis&amp;gt;)"

# Remove "formats" field from the infojson by setting it to an empty string
$ yt-dlp --parse-metadata "video::(?P&amp;lt;formats&amp;gt;)" --write-info-json

# Replace all spaces and "_" in title and uploader with a `-`
$ yt-dlp --replace-in-metadata "title,uploader" "[ _]" "-"

&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;EXTRACTOR ARGUMENTS&lt;/h1&gt; 
&lt;p&gt;Some extractors accept additional arguments which can be passed using &lt;code&gt;--extractor-args KEY:ARGS&lt;/code&gt;. &lt;code&gt;ARGS&lt;/code&gt; is a &lt;code&gt;;&lt;/code&gt; (semicolon) separated string of &lt;code&gt;ARG=VAL1,VAL2&lt;/code&gt;. E.g. &lt;code&gt;--extractor-args "youtube:player-client=tv,mweb;formats=incomplete" --extractor-args "twitter:api=syndication"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: In CLI, &lt;code&gt;ARG&lt;/code&gt; can use &lt;code&gt;-&lt;/code&gt; instead of &lt;code&gt;_&lt;/code&gt;; e.g. &lt;code&gt;youtube:player-client"&lt;/code&gt; becomes &lt;code&gt;youtube:player_client"&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;The following extractors use this feature:&lt;/p&gt; 
&lt;h4&gt;youtube&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;lang&lt;/code&gt;: Prefer translated metadata (&lt;code&gt;title&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt; etc) of this language code (case-sensitive). By default, the video primary language metadata is preferred, with a fallback to &lt;code&gt;en&lt;/code&gt; translated. See &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/415b4c9f955b1a0391204bd24a7132590e7b3bdb/yt_dlp/extractor/youtube/_base.py#L402-L409"&gt;youtube/_base.py&lt;/a&gt; for the list of supported content language codes&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;hls&lt;/code&gt;, &lt;code&gt;dash&lt;/code&gt; or &lt;code&gt;translated_subs&lt;/code&gt; to skip extraction of the m3u8 manifests, dash manifests and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/4090#issuecomment-1158102032"&gt;auto-translated subtitles&lt;/a&gt; respectively&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_client&lt;/code&gt;: Clients to extract video data from. The currently available clients are &lt;code&gt;web&lt;/code&gt;, &lt;code&gt;web_safari&lt;/code&gt;, &lt;code&gt;web_embedded&lt;/code&gt;, &lt;code&gt;web_music&lt;/code&gt;, &lt;code&gt;web_creator&lt;/code&gt;, &lt;code&gt;mweb&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;android_vr&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_simply&lt;/code&gt; and &lt;code&gt;tv_embedded&lt;/code&gt;. By default, &lt;code&gt;tv,web_safari,web&lt;/code&gt; is used, and &lt;code&gt;tv,web_creator,web&lt;/code&gt; is used with premium accounts. The &lt;code&gt;web_music&lt;/code&gt; client is added for &lt;code&gt;music.youtube.com&lt;/code&gt; URLs when logged-in cookies are used. The &lt;code&gt;web_embedded&lt;/code&gt; client is added for age-restricted videos but only works if the video is embeddable. The &lt;code&gt;tv_embedded&lt;/code&gt; and &lt;code&gt;web_creator&lt;/code&gt; clients are added for age-restricted videos if account age-verification is required. Some clients, such as &lt;code&gt;web&lt;/code&gt; and &lt;code&gt;web_music&lt;/code&gt;, require a &lt;code&gt;po_token&lt;/code&gt; for their formats to be downloadable. Some clients, such as &lt;code&gt;web_creator&lt;/code&gt;, will only work with authentication. Not all clients support authentication via cookies. You can use &lt;code&gt;default&lt;/code&gt; for the default clients, or you can use &lt;code&gt;all&lt;/code&gt; for all clients (not recommended). You can prefix a client with &lt;code&gt;-&lt;/code&gt; to exclude it, e.g. &lt;code&gt;youtube:player_client=default,-ios&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_skip&lt;/code&gt;: Skip some network requests that are generally needed for robust extraction. One or more of &lt;code&gt;configs&lt;/code&gt; (skip client configs), &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage), &lt;code&gt;js&lt;/code&gt; (skip js player), &lt;code&gt;initial_data&lt;/code&gt; (skip initial data/next ep request). While these options can help reduce the number of requests needed or avoid some rate-limiting, they could cause issues such as missing formats or metadata. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/860"&gt;#860&lt;/a&gt; and &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/12826"&gt;#12826&lt;/a&gt; for more details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;webpage_skip&lt;/code&gt;: Skip extraction of embedded webpage data. One or both of &lt;code&gt;player_response&lt;/code&gt;, &lt;code&gt;initial_data&lt;/code&gt;. These options are for testing purposes and don't skip any network requests&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_params&lt;/code&gt;: YouTube player parameters to use for player requests. Will overwrite any default ones set by yt-dlp.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_variant&lt;/code&gt;: The player javascript variant to use for n/sig deciphering. The known variants are: &lt;code&gt;main&lt;/code&gt;, &lt;code&gt;tcc&lt;/code&gt;, &lt;code&gt;tce&lt;/code&gt;, &lt;code&gt;es5&lt;/code&gt;, &lt;code&gt;es6&lt;/code&gt;, &lt;code&gt;tv&lt;/code&gt;, &lt;code&gt;tv_es6&lt;/code&gt;, &lt;code&gt;phone&lt;/code&gt;, &lt;code&gt;tablet&lt;/code&gt;. The default is &lt;code&gt;main&lt;/code&gt;, and the others are for debugging purposes. You can use &lt;code&gt;actual&lt;/code&gt; to go with what is prescribed by the site&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;player_js_version&lt;/code&gt;: The player javascript version to use for n/sig deciphering, in the format of &lt;code&gt;signature_timestamp@hash&lt;/code&gt;. Currently, the default is to force &lt;code&gt;20348@0004de42&lt;/code&gt;. You can use &lt;code&gt;actual&lt;/code&gt; to go with what is prescribed by the site&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;top&lt;/code&gt; or &lt;code&gt;new&lt;/code&gt; (default) - choose comment sorting mode (on YouTube's side)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Limit the amount of comments to gather. Comma-separated list of integers representing &lt;code&gt;max-comments,max-parents,max-replies,max-replies-per-thread&lt;/code&gt;. Default is &lt;code&gt;all,all,all,all&lt;/code&gt; 
  &lt;ul&gt; 
   &lt;li&gt;E.g. &lt;code&gt;all,all,1000,10&lt;/code&gt; will get a maximum of 1000 replies total, with up to 10 replies per thread. &lt;code&gt;1000,all,100&lt;/code&gt; will get a maximum of 1000 comments, with a maximum of 100 replies total&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Change the types of formats to return. &lt;code&gt;dashy&lt;/code&gt; (convert HTTP to DASH), &lt;code&gt;duplicate&lt;/code&gt; (identical content but different URLs or protocol; includes &lt;code&gt;dashy&lt;/code&gt;), &lt;code&gt;incomplete&lt;/code&gt; (cannot be downloaded completely - live dash and post-live m3u8), &lt;code&gt;missing_pot&lt;/code&gt; (include formats that require a PO Token but are missing one)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_host&lt;/code&gt;: Innertube API host to use for all API requests; e.g. &lt;code&gt;studio.youtube.com&lt;/code&gt;, &lt;code&gt;youtubei.googleapis.com&lt;/code&gt;. Note that cookies exported from one subdomain will not work on others&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;innertube_key&lt;/code&gt;: Innertube API key to use for all API requests. By default, no API key is used&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;raise_incomplete_data&lt;/code&gt;: &lt;code&gt;Incomplete Data Received&lt;/code&gt; raises an error instead of reporting a warning&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;data_sync_id&lt;/code&gt;: Overrides the account Data Sync ID used in Innertube API requests. This may be needed if you are using an account with &lt;code&gt;youtube:player_skip=webpage,configs&lt;/code&gt; or &lt;code&gt;youtubetab:skip=webpage&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;visitor_data&lt;/code&gt;: Overrides the Visitor Data used in Innertube API requests. This should be used with &lt;code&gt;player_skip=webpage,configs&lt;/code&gt; and without cookies. Note: this may have adverse effects if used improperly. If a session from a browser is wanted, you should pass cookies instead (which contain the Visitor ID)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;po_token&lt;/code&gt;: Proof of Origin (PO) Token(s) to use. Comma seperated list of PO Tokens in the format &lt;code&gt;CLIENT.CONTEXT+PO_TOKEN&lt;/code&gt;, e.g. &lt;code&gt;youtube:po_token=web.gvs+XXX,web.player=XXX,web_safari.gvs+YYY&lt;/code&gt;. Context can be any of &lt;code&gt;gvs&lt;/code&gt; (Google Video Server URLs), &lt;code&gt;player&lt;/code&gt; (Innertube player request) or &lt;code&gt;subs&lt;/code&gt; (Subtitles)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pot_trace&lt;/code&gt;: Enable debug logging for PO Token fetching. Either &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;fetch_pot&lt;/code&gt;: Policy to use for fetching a PO Token from providers. One of &lt;code&gt;always&lt;/code&gt; (always try fetch a PO Token regardless if the client requires one for the given context), &lt;code&gt;never&lt;/code&gt; (never fetch a PO Token), or &lt;code&gt;auto&lt;/code&gt; (default; only fetch a PO Token if the client requires one for the given context)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playback_wait&lt;/code&gt;: Duration (in seconds) to wait inbetween the extraction and download stages in order to ensure the formats are available. The default is &lt;code&gt;6&lt;/code&gt; seconds&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubepot-webpo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bind_to_visitor_id&lt;/code&gt;: Whether to use the Visitor ID instead of Visitor Data for caching WebPO tokens. Either &lt;code&gt;true&lt;/code&gt; (default) or &lt;code&gt;false&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubetab (YouTube playlists, channels, feeds, etc.)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;skip&lt;/code&gt;: One or more of &lt;code&gt;webpage&lt;/code&gt; (skip initial webpage download), &lt;code&gt;authcheck&lt;/code&gt; (allow the download of playlists requiring authentication when no initial webpage is downloaded. This may cause unwanted behavior, see &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/1122"&gt;#1122&lt;/a&gt; for more details)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;approximate_date&lt;/code&gt;: Extract approximate &lt;code&gt;upload_date&lt;/code&gt; and &lt;code&gt;timestamp&lt;/code&gt; in flat-playlist. This may cause date-based filters to be slightly off&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;generic&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;fragment_query&lt;/code&gt;: Passthrough any query in mpd/m3u8 manifest URLs to their fragments if no value is provided, or else apply the query string given as &lt;code&gt;fragment_query=VALUE&lt;/code&gt;. Note that if the stream has an HLS AES-128 key, then the query parameters will be passed to the key URI as well, unless the &lt;code&gt;key_query&lt;/code&gt; extractor-arg is passed, or unless an external key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;variant_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its variant playlist URLs if no value is provided, or else apply the query string given as &lt;code&gt;variant_query=VALUE&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;key_query&lt;/code&gt;: Passthrough the master m3u8 URL query to its HLS AES-128 decryption key URI if no value is provided, or else apply the query string given as &lt;code&gt;key_query=VALUE&lt;/code&gt;. Note that this will have no effect if the key URI is provided via the &lt;code&gt;hls_key&lt;/code&gt; extractor-arg. Does not apply to ffmpeg&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;hls_key&lt;/code&gt;: An HLS AES-128 key URI &lt;em&gt;or&lt;/em&gt; key (as hex), and optionally the IV (as hex), in the form of &lt;code&gt;(URI|KEY)[,IV]&lt;/code&gt;; e.g. &lt;code&gt;generic:hls_key=ABCDEF1234567980,0xFEDCBA0987654321&lt;/code&gt;. Passing any of these values will force usage of the native HLS downloader and override the corresponding values found in the m3u8 playlist&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;is_live&lt;/code&gt;: Bypass live HLS detection and manually set &lt;code&gt;live_status&lt;/code&gt; - a value of &lt;code&gt;false&lt;/code&gt; will set &lt;code&gt;not_live&lt;/code&gt;, any other value (or no value) will set &lt;code&gt;is_live&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;impersonate&lt;/code&gt;: Target(s) to try and impersonate with the initial webpage request; e.g. &lt;code&gt;generic:impersonate=safari,chrome-110&lt;/code&gt;. Use &lt;code&gt;generic:impersonate&lt;/code&gt; to impersonate any available target, and use &lt;code&gt;generic:impersonate=false&lt;/code&gt; to disable impersonation (default)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vikichannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;video_types&lt;/code&gt;: Types of videos to download - one or more of &lt;code&gt;episodes&lt;/code&gt;, &lt;code&gt;movies&lt;/code&gt;, &lt;code&gt;clips&lt;/code&gt;, &lt;code&gt;trailers&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;youtubewebarchive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;check_all&lt;/code&gt;: Try to check more at the cost of more requests. One or more of &lt;code&gt;thumbnails&lt;/code&gt;, &lt;code&gt;captures&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;gamejolt&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;comment_sort&lt;/code&gt;: &lt;code&gt;hot&lt;/code&gt; (default), &lt;code&gt;you&lt;/code&gt; (cookies needed), &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;new&lt;/code&gt; - choose comment sorting mode (on GameJolt's side)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;hotstar&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;res&lt;/code&gt;: resolution to ignore - one or more of &lt;code&gt;sd&lt;/code&gt;, &lt;code&gt;hd&lt;/code&gt;, &lt;code&gt;fhd&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;vcodec&lt;/code&gt;: vcodec to ignore - one or more of &lt;code&gt;h264&lt;/code&gt;, &lt;code&gt;h265&lt;/code&gt;, &lt;code&gt;dvh265&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dr&lt;/code&gt;: dynamic range to ignore - one or more of &lt;code&gt;sdr&lt;/code&gt;, &lt;code&gt;hdr10&lt;/code&gt;, &lt;code&gt;dv&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;instagram&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;app_id&lt;/code&gt;: The value of the &lt;code&gt;X-IG-App-ID&lt;/code&gt; header used for API requests. Default is the web app ID, &lt;code&gt;936619743392459&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;niconicochannelplus&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;max_comments&lt;/code&gt;: Maximum number of comments to extract - default is &lt;code&gt;120&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tiktok&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api_hostname&lt;/code&gt;: Hostname to use for mobile API calls, e.g. &lt;code&gt;api22-normal-c-alisg.tiktokv.com&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_name&lt;/code&gt;: Default app name to use with mobile API calls, e.g. &lt;code&gt;trill&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_version&lt;/code&gt;: Default app version to use with mobile API calls - should be set along with &lt;code&gt;manifest_app_version&lt;/code&gt;, e.g. &lt;code&gt;34.1.2&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;manifest_app_version&lt;/code&gt;: Default numeric app version to use with mobile API calls, e.g. &lt;code&gt;2023401020&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;aid&lt;/code&gt;: Default app ID to use with mobile API calls, e.g. &lt;code&gt;1180&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app_info&lt;/code&gt;: Enable mobile API extraction with one or more app info strings in the format of &lt;code&gt;&amp;lt;iid&amp;gt;/[app_name]/[app_version]/[manifest_app_version]/[aid]&lt;/code&gt;, where &lt;code&gt;iid&lt;/code&gt; is the unique app install ID. &lt;code&gt;iid&lt;/code&gt; is the only required value; all other values and their &lt;code&gt;/&lt;/code&gt; separators can be omitted, e.g. &lt;code&gt;tiktok:app_info=1234567890123456789&lt;/code&gt; or &lt;code&gt;tiktok:app_info=123,456/trill///1180,789//34.0.1/340001&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: Enable mobile API extraction with a genuine device ID to be used with mobile API calls. Default is a random 19-digit string&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;rokfinchannel&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;tab&lt;/code&gt;: Which tab to download - one of &lt;code&gt;new&lt;/code&gt;, &lt;code&gt;top&lt;/code&gt;, &lt;code&gt;videos&lt;/code&gt;, &lt;code&gt;podcasts&lt;/code&gt;, &lt;code&gt;streams&lt;/code&gt;, &lt;code&gt;stacks&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitter&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;api&lt;/code&gt;: Select one of &lt;code&gt;graphql&lt;/code&gt; (default), &lt;code&gt;legacy&lt;/code&gt; or &lt;code&gt;syndication&lt;/code&gt; as the API for tweet extraction. Has no effect if logged in&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;stacommu, wrestleuniverse&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;device_id&lt;/code&gt;: UUID value assigned by the website and used to enforce device limits for paid livestream content. Can be found in browser local storage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;twitch&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client_id&lt;/code&gt;: Client ID value to be sent with GraphQL requests, e.g. &lt;code&gt;twitch:client_id=kimne78kx3ncx6brgo4mv6wki5h1ko&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nhkradirulive (NHK „Çâ„Åò„Çã‚òÖ„Çâ„Åò„Çã LIVE)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;area&lt;/code&gt;: Which regional variation to extract. Valid areas are: &lt;code&gt;sapporo&lt;/code&gt;, &lt;code&gt;sendai&lt;/code&gt;, &lt;code&gt;tokyo&lt;/code&gt;, &lt;code&gt;nagoya&lt;/code&gt;, &lt;code&gt;osaka&lt;/code&gt;, &lt;code&gt;hiroshima&lt;/code&gt;, &lt;code&gt;matsuyama&lt;/code&gt;, &lt;code&gt;fukuoka&lt;/code&gt;. Defaults to &lt;code&gt;tokyo&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;nflplusreplay&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: Type(s) of game replays to extract. Valid types are: &lt;code&gt;full_game&lt;/code&gt;, &lt;code&gt;full_game_spanish&lt;/code&gt;, &lt;code&gt;condensed_game&lt;/code&gt; and &lt;code&gt;all_22&lt;/code&gt;. You can use &lt;code&gt;all&lt;/code&gt; to extract all available replay types, which is the default&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiocinema&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;refresh_token&lt;/code&gt;: The &lt;code&gt;refreshToken&lt;/code&gt; UUID from browser local storage can be passed to extend the life of your login session when logging in with &lt;code&gt;token&lt;/code&gt; as username and the &lt;code&gt;accessToken&lt;/code&gt; from browser local storage as password&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;jiosaavn&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;bitrate&lt;/code&gt;: Audio bitrates to request. One or more of &lt;code&gt;16&lt;/code&gt;, &lt;code&gt;32&lt;/code&gt;, &lt;code&gt;64&lt;/code&gt;, &lt;code&gt;128&lt;/code&gt;, &lt;code&gt;320&lt;/code&gt;. Default is &lt;code&gt;128,320&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;afreecatvlive&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cdn&lt;/code&gt;: One or more CDN IDs to use with the API call for stream URLs, e.g. &lt;code&gt;gcp_cdn&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_app&lt;/code&gt;, &lt;code&gt;gs_cdn_mobile_web&lt;/code&gt;, &lt;code&gt;gs_cdn_pc_web&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;soundcloud&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;formats&lt;/code&gt;: Formats to request from the API. Requested values should be in the format of &lt;code&gt;{protocol}_{codec}&lt;/code&gt;, e.g. &lt;code&gt;hls_opus,http_aac&lt;/code&gt;. The &lt;code&gt;*&lt;/code&gt; character functions as a wildcard, e.g. &lt;code&gt;*_mp3&lt;/code&gt;, and can be passed by itself to request all formats. Known protocols include &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;hls&lt;/code&gt; and &lt;code&gt;hls-aes&lt;/code&gt;; known codecs include &lt;code&gt;aac&lt;/code&gt;, &lt;code&gt;opus&lt;/code&gt; and &lt;code&gt;mp3&lt;/code&gt;. Original &lt;code&gt;download&lt;/code&gt; formats are always extracted. Default is &lt;code&gt;http_aac,hls_aac,http_opus,hls_opus,http_mp3,hls_mp3&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;orfon (orf:on)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_segments_playlist&lt;/code&gt;: Prefer a playlist of program segments instead of a single complete video when available. If individual segments are desired, use &lt;code&gt;--concat-playlist never --extractor-args "orfon:prefer_segments_playlist"&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;bilibili&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;prefer_multi_flv&lt;/code&gt;: Prefer extracting flv formats over mp4 for older videos that still provide legacy formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;sonylivseries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;sort_order&lt;/code&gt;: Episode sort order for series extraction - one of &lt;code&gt;asc&lt;/code&gt; (ascending, oldest first) or &lt;code&gt;desc&lt;/code&gt; (descending, newest first). Default is &lt;code&gt;asc&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;tver&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;backend&lt;/code&gt;: Backend API to use for extraction - one of &lt;code&gt;streaks&lt;/code&gt; (default) or &lt;code&gt;brightcove&lt;/code&gt; (deprecated)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;vimeo&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;client&lt;/code&gt;: Client to extract video data from. The currently available clients are &lt;code&gt;android&lt;/code&gt;, &lt;code&gt;ios&lt;/code&gt;, and &lt;code&gt;web&lt;/code&gt;. Only one client can be used. The &lt;code&gt;web&lt;/code&gt; client is used by default. The &lt;code&gt;web&lt;/code&gt; client only works with account cookies or login credentials. The &lt;code&gt;android&lt;/code&gt; and &lt;code&gt;ios&lt;/code&gt; clients only work with previously cached OAuth tokens&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;original_format_policy&lt;/code&gt;: Policy for when to try extracting original formats. One of &lt;code&gt;always&lt;/code&gt;, &lt;code&gt;never&lt;/code&gt;, or &lt;code&gt;auto&lt;/code&gt;. The default &lt;code&gt;auto&lt;/code&gt; policy tries to avoid exceeding the web client's API rate-limit by only making an extra request when Vimeo publicizes the video's downloadability&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: These options may be changed/removed in the future without concern for backward compatibility&lt;/p&gt; 
&lt;!-- MANPAGE: MOVE "INSTALLATION" SECTION HERE --&gt; 
&lt;h1&gt;PLUGINS&lt;/h1&gt; 
&lt;p&gt;Note that &lt;strong&gt;all&lt;/strong&gt; plugins are imported even if not invoked, and that &lt;strong&gt;there are no checks&lt;/strong&gt; performed on plugin code. &lt;strong&gt;Use plugins at your own risk and only if you trust the code!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Plugins can be of &lt;code&gt;&amp;lt;type&amp;gt;&lt;/code&gt;s &lt;code&gt;extractor&lt;/code&gt; or &lt;code&gt;postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Extractor plugins do not need to be enabled from the CLI and are automatically invoked when the input URL is suitable for it.&lt;/li&gt; 
 &lt;li&gt;Extractor plugins take priority over built-in extractors.&lt;/li&gt; 
 &lt;li&gt;Postprocessor plugins can be invoked using &lt;code&gt;--use-postprocessor NAME&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Plugins are loaded from the namespace packages &lt;code&gt;yt_dlp_plugins.extractor&lt;/code&gt; and &lt;code&gt;yt_dlp_plugins.postprocessor&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In other words, the file structure on the disk looks something like:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;    yt_dlp_plugins/
        extractor/
            myplugin.py
        postprocessor/
            myplugin.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;yt-dlp looks for these &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folders in many locations (see below) and loads in plugins from &lt;strong&gt;all&lt;/strong&gt; of them. Set the environment variable &lt;code&gt;YTDLP_NO_PLUGINS&lt;/code&gt; to something nonempty to disable loading plugins entirely.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugins"&gt;wiki for some known plugins&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installing Plugins&lt;/h2&gt; 
&lt;p&gt;Plugins can be installed using various methods and locations.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configuration directories&lt;/strong&gt;: Plugin packages (containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder) can be dropped into the following standard &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;configuration locations&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;User Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Linux/macOS)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt; (recommended on Windows)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;${APPDATA}/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/.yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;~/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;System Plugins&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp/plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;/etc/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Executable location&lt;/strong&gt;: Plugin packages can similarly be installed in a &lt;code&gt;yt-dlp-plugins&lt;/code&gt; directory under the executable location (recommended for portable installations):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Binary: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp.exe&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Source: where &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt_dlp/__main__.py&lt;/code&gt;, &lt;code&gt;&amp;lt;root-dir&amp;gt;/yt-dlp-plugins/&amp;lt;package name&amp;gt;/yt_dlp_plugins/&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;pip and other locations in &lt;code&gt;PYTHONPATH&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Plugin packages can be installed and managed using &lt;code&gt;pip&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; for an example. 
    &lt;ul&gt; 
     &lt;li&gt;Note: plugin files between plugin packages installed with pip must have unique filenames.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Any path in &lt;code&gt;PYTHONPATH&lt;/code&gt; is searched in for the &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder. 
    &lt;ul&gt; 
     &lt;li&gt;Note: This does not apply for Pyinstaller builds.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;.zip&lt;/code&gt;, &lt;code&gt;.egg&lt;/code&gt; and &lt;code&gt;.whl&lt;/code&gt; archives containing a &lt;code&gt;yt_dlp_plugins&lt;/code&gt; namespace folder in their root are also supported as plugin packages.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;e.g. &lt;code&gt;${XDG_CONFIG_HOME}/yt-dlp/plugins/mypluginpkg.zip&lt;/code&gt; where &lt;code&gt;mypluginpkg.zip&lt;/code&gt; contains &lt;code&gt;yt_dlp_plugins/&amp;lt;type&amp;gt;/myplugin.py&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run yt-dlp with &lt;code&gt;--verbose&lt;/code&gt; to check if the plugin has been loaded.&lt;/p&gt; 
&lt;h2&gt;Developing Plugins&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp-sample-plugins"&gt;yt-dlp-sample-plugins&lt;/a&gt; repo for a template plugin package and the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki/Plugin-Development"&gt;Plugin Development&lt;/a&gt; section of the wiki for a plugin development guide.&lt;/p&gt; 
&lt;p&gt;All public classes with a name ending in &lt;code&gt;IE&lt;/code&gt;/&lt;code&gt;PP&lt;/code&gt; are imported from each file for extractors and postprocessors respectively. This respects underscore prefix (e.g. &lt;code&gt;_MyBasePluginIE&lt;/code&gt; is private) and &lt;code&gt;__all__&lt;/code&gt;. Modules can similarly be excluded by prefixing the module name with an underscore (e.g. &lt;code&gt;_myplugin.py&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;To replace an existing extractor with a subclass of one, set the &lt;code&gt;plugin_name&lt;/code&gt; class keyword argument (e.g. &lt;code&gt;class MyPluginIE(ABuiltInIE, plugin_name='myplugin')&lt;/code&gt; will replace &lt;code&gt;ABuiltInIE&lt;/code&gt; with &lt;code&gt;MyPluginIE&lt;/code&gt;). Since the extractor replaces the parent, you should exclude the subclass extractor from being imported separately by making it private using one of the methods described above.&lt;/p&gt; 
&lt;p&gt;If you are a plugin author, add &lt;a href="https://github.com/topics/yt-dlp-plugins"&gt;yt-dlp-plugins&lt;/a&gt; as a topic to your repository for discoverability.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/CONTRIBUTING.md#developer-instructions"&gt;Developer Instructions&lt;/a&gt; on how to write and test an extractor.&lt;/p&gt; 
&lt;h1&gt;EMBEDDING YT-DLP&lt;/h1&gt; 
&lt;p&gt;yt-dlp makes the best effort to be a good command-line program, and thus should be callable from any programming language.&lt;/p&gt; 
&lt;p&gt;Your program should avoid parsing the normal stdout since they may change in future versions. Instead, they should use options such as &lt;code&gt;-J&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--progress-template&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; etc to create console output that you can reliably reproduce and parse.&lt;/p&gt; 
&lt;p&gt;From a Python program, you can embed yt-dlp in a more powerful fashion, like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from yt_dlp import YoutubeDL

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']
with YoutubeDL() as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Most likely, you'll want to use various options. For a list of options available, have a look at &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/yt_dlp/YoutubeDL.py#L183"&gt;&lt;code&gt;yt_dlp/YoutubeDL.py&lt;/code&gt;&lt;/a&gt; or &lt;code&gt;help(yt_dlp.YoutubeDL)&lt;/code&gt; in a Python shell. If you are already familiar with the CLI, you can use &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/devscripts/cli_to_api.py"&gt;&lt;code&gt;devscripts/cli_to_api.py&lt;/code&gt;&lt;/a&gt; to translate any CLI switches to &lt;code&gt;YoutubeDL&lt;/code&gt; params.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: If you are porting your code from youtube-dl to yt-dlp, one important point to look out for is that we do not guarantee the return value of &lt;code&gt;YoutubeDL.extract_info&lt;/code&gt; to be json serializable, or even be a dictionary. It will be dictionary-like, but if you want to ensure it is a serializable dictionary, pass it through &lt;code&gt;YoutubeDL.sanitize_info&lt;/code&gt; as shown in the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#extracting-information"&gt;example below&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Embedding examples&lt;/h2&gt; 
&lt;h4&gt;Extracting information&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import json
import yt_dlp

URL = 'https://www.youtube.com/watch?v=BaW_jenozKc'

# ‚ÑπÔ∏è See help(yt_dlp.YoutubeDL) for a list of available options and public functions
ydl_opts = {}
with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    info = ydl.extract_info(URL, download=False)

    # ‚ÑπÔ∏è ydl.sanitize_info makes the info json-serializable
    print(json.dumps(ydl.sanitize_info(info)))
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Download using an info-json&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

INFO_FILE = 'path/to/video.info.json'

with yt_dlp.YoutubeDL() as ydl:
    error_code = ydl.download_with_info_file(INFO_FILE)

print('Some videos failed to download' if error_code
      else 'All videos successfully downloaded')
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Extract audio&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

ydl_opts = {
    'format': 'm4a/bestaudio/best',
    # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments
    'postprocessors': [{  # Extract audio using ffmpeg
        'key': 'FFmpegExtractAudio',
        'preferredcodec': 'm4a',
    }]
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Filter videos&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def longer_than_a_minute(info, *, incomplete):
    """Download only videos longer than a minute (or with unknown duration)"""
    duration = info.get('duration')
    if duration and duration &amp;lt; 60:
        return 'The video is too short'

ydl_opts = {
    'match_filter': longer_than_a_minute,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    error_code = ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Adding logger and progress hook&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

class MyLogger:
    def debug(self, msg):
        # For compatibility with youtube-dl, both debug and info are passed into debug
        # You can distinguish them by the prefix '[debug] '
        if msg.startswith('[debug] '):
            pass
        else:
            self.info(msg)

    def info(self, msg):
        pass

    def warning(self, msg):
        pass

    def error(self, msg):
        print(msg)


# ‚ÑπÔ∏è See "progress_hooks" in help(yt_dlp.YoutubeDL)
def my_hook(d):
    if d['status'] == 'finished':
        print('Done downloading, now post-processing ...')


ydl_opts = {
    'logger': MyLogger(),
    'progress_hooks': [my_hook],
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Add a custom PostProcessor&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

# ‚ÑπÔ∏è See help(yt_dlp.postprocessor.PostProcessor)
class MyCustomPP(yt_dlp.postprocessor.PostProcessor):
    def run(self, info):
        self.to_screen('Doing stuff')
        return [], info


with yt_dlp.YoutubeDL() as ydl:
    # ‚ÑπÔ∏è "when" can take any value in yt_dlp.utils.POSTPROCESS_WHEN
    ydl.add_post_processor(MyCustomPP(), when='pre_process')
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Use a custom format selector&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import yt_dlp

URLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']

def format_selector(ctx):
    """ Select the best video and the best audio that won't result in an mkv.
    NOTE: This is just an example and does not handle all cases """

    # formats are already sorted worst to best
    formats = ctx.get('formats')[::-1]

    # acodec='none' means there is no audio
    best_video = next(f for f in formats
                      if f['vcodec'] != 'none' and f['acodec'] == 'none')

    # find compatible audio extension
    audio_ext = {'mp4': 'm4a', 'webm': 'webm'}[best_video['ext']]
    # vcodec='none' means there is no video
    best_audio = next(f for f in formats if (
        f['acodec'] != 'none' and f['vcodec'] == 'none' and f['ext'] == audio_ext))

    # These are the minimum required fields for a merged format
    yield {
        'format_id': f'{best_video["format_id"]}+{best_audio["format_id"]}',
        'ext': best_video['ext'],
        'requested_formats': [best_video, best_audio],
        # Must be + separated list of protocols
        'protocol': f'{best_video["protocol"]}+{best_audio["protocol"]}'
    }


ydl_opts = {
    'format': format_selector,
}

with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    ydl.download(URLS)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CHANGES FROM YOUTUBE-DL&lt;/h1&gt; 
&lt;h3&gt;New features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Forked from &lt;a href="https://github.com/blackjack4494/yt-dlc/commit/f9401f2a91987068139c5f757b12fc711d4c0cee"&gt;&lt;strong&gt;yt-dlc@f9401f2&lt;/strong&gt;&lt;/a&gt; and merged with &lt;a href="https://github.com/ytdl-org/youtube-dl/commit/a08f2b7e4567cdc50c0614ee0a4ffdff49b8b6e6"&gt;&lt;strong&gt;youtube-dl@a08f2b7&lt;/strong&gt;&lt;/a&gt; (&lt;a href="https://github.com/yt-dlp/yt-dlp/issues/21"&gt;exceptions&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sponsorblock-options"&gt;SponsorBlock Integration&lt;/a&gt;&lt;/strong&gt;: You can mark/remove sponsor sections in YouTube videos by utilizing the &lt;a href="https://sponsor.ajay.app"&gt;SponsorBlock&lt;/a&gt; API&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;Format Sorting&lt;/a&gt;&lt;/strong&gt;: The default format sorting options have been changed so that higher resolution and better codecs will be now preferred instead of simply using larger bitrate. Furthermore, you can now specify the sort order using &lt;code&gt;-S&lt;/code&gt;. This allows for much easier format selection than what is possible by simply using &lt;code&gt;--format&lt;/code&gt; (&lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection-examples"&gt;examples&lt;/a&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Merged with animelover1984/youtube-dl&lt;/strong&gt;: You get most of the features and improvements from &lt;a href="https://github.com/animelover1984/youtube-dl"&gt;animelover1984/youtube-dl&lt;/a&gt; including &lt;code&gt;--write-comments&lt;/code&gt;, &lt;code&gt;BiliBiliSearch&lt;/code&gt;, &lt;code&gt;BilibiliChannel&lt;/code&gt;, Embedding thumbnail in mp4/ogg/opus, playlist infojson etc. See &lt;a href="https://github.com/yt-dlp/yt-dlp/pull/31"&gt;#31&lt;/a&gt; for details.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;YouTube improvements&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Supports Clips, Stories (&lt;code&gt;ytstories:&amp;lt;channel UCID&amp;gt;&lt;/code&gt;), Search (including filters)&lt;strong&gt;*&lt;/strong&gt;, YouTube Music Search, Channel-specific search, Search prefixes (&lt;code&gt;ytsearch:&lt;/code&gt;, &lt;code&gt;ytsearchdate:&lt;/code&gt;)&lt;strong&gt;*&lt;/strong&gt;, Mixes, and Feeds (&lt;code&gt;:ytfav&lt;/code&gt;, &lt;code&gt;:ytwatchlater&lt;/code&gt;, &lt;code&gt;:ytsubs&lt;/code&gt;, &lt;code&gt;:ythistory&lt;/code&gt;, &lt;code&gt;:ytrec&lt;/code&gt;, &lt;code&gt;:ytnotif&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Fix for &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/29326"&gt;n-sig based throttling&lt;/a&gt; &lt;strong&gt;*&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;Download livestreams from the start using &lt;code&gt;--live-from-start&lt;/code&gt; (&lt;em&gt;experimental&lt;/em&gt;)&lt;/li&gt; 
   &lt;li&gt;Channel URLs download all uploads of the channel, including shorts and live&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cookies from browser&lt;/strong&gt;: Cookies can be automatically extracted from all major web browsers using &lt;code&gt;--cookies-from-browser BROWSER[+KEYRING][:PROFILE][::CONTAINER]&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download time range&lt;/strong&gt;: Videos can be downloaded partially based on either timestamps or chapters using &lt;code&gt;--download-sections&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Split video by chapters&lt;/strong&gt;: Videos can be split into multiple files based on chapters using &lt;code&gt;--split-chapters&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multi-threaded fragment downloads&lt;/strong&gt;: Download multiple fragments of m3u8/mpd videos in parallel. Use &lt;code&gt;--concurrent-fragments&lt;/code&gt; (&lt;code&gt;-N&lt;/code&gt;) option to set the number of threads used&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Aria2c with HLS/DASH&lt;/strong&gt;: You can use &lt;code&gt;aria2c&lt;/code&gt; as the external downloader for DASH(mpd) and HLS(m3u8) formats&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New and fixed extractors&lt;/strong&gt;: Many new extractors have been added and a lot of existing ones have been fixed. See the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or the &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/supportedsites.md"&gt;list of supported sites&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MSOs&lt;/strong&gt;: Philo, Spectrum, SlingTV, Cablevision, RCN etc.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Subtitle extraction from manifests&lt;/strong&gt;: Subtitles can be extracted from streaming media manifests. See &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/be6202f12b97858b9d716e608394b51065d0419f"&gt;commit/be6202f&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Multiple paths and output templates&lt;/strong&gt;: You can give different &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output templates&lt;/a&gt; and download paths for different types of files. You can also set a temporary path where intermediary files are downloaded to using &lt;code&gt;--paths&lt;/code&gt; (&lt;code&gt;-P&lt;/code&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Portable Configuration&lt;/strong&gt;: Configuration files are automatically loaded from the home and root directories. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Output template improvements&lt;/strong&gt;: Output templates can now have date-time formatting, numeric offsets, object traversal etc. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; for details. Even more advanced operations can also be done with the help of &lt;code&gt;--parse-metadata&lt;/code&gt; and &lt;code&gt;--replace-in-metadata&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other new options&lt;/strong&gt;: Many new options have been added such as &lt;code&gt;--alias&lt;/code&gt;, &lt;code&gt;--print&lt;/code&gt;, &lt;code&gt;--concat-playlist&lt;/code&gt;, &lt;code&gt;--wait-for-video&lt;/code&gt;, &lt;code&gt;--retry-sleep&lt;/code&gt;, &lt;code&gt;--sleep-requests&lt;/code&gt;, &lt;code&gt;--convert-thumbnails&lt;/code&gt;, &lt;code&gt;--force-download-archive&lt;/code&gt;, &lt;code&gt;--force-overwrites&lt;/code&gt;, &lt;code&gt;--break-match-filters&lt;/code&gt; etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Improvements&lt;/strong&gt;: Regex and other operators in &lt;code&gt;--format&lt;/code&gt;/&lt;code&gt;--match-filters&lt;/code&gt;, multiple &lt;code&gt;--postprocessor-args&lt;/code&gt; and &lt;code&gt;--downloader-args&lt;/code&gt;, faster archive checking, more &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#format-selection"&gt;format selection options&lt;/a&gt;, merge multi-video/audio, multiple &lt;code&gt;--config-locations&lt;/code&gt;, &lt;code&gt;--exec&lt;/code&gt; at different stages, etc&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Plugins&lt;/strong&gt;: Extractors and PostProcessors can be loaded from an external file. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#plugins"&gt;plugins&lt;/a&gt; for details&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Self updater&lt;/strong&gt;: The releases can be updated using &lt;code&gt;yt-dlp -U&lt;/code&gt;, and downgraded using &lt;code&gt;--update-to&lt;/code&gt; if required&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automated builds&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#update-channels"&gt;Nightly/master builds&lt;/a&gt; can be used with &lt;code&gt;--update-to nightly&lt;/code&gt; and &lt;code&gt;--update-to master&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/Changelog.md"&gt;changelog&lt;/a&gt; or &lt;a href="https://github.com/yt-dlp/yt-dlp/commits"&gt;commits&lt;/a&gt; for the full list of changes&lt;/p&gt; 
&lt;p&gt;Features marked with a &lt;strong&gt;*&lt;/strong&gt; have been back-ported to youtube-dl&lt;/p&gt; 
&lt;h3&gt;Differences in default behavior&lt;/h3&gt; 
&lt;p&gt;Some of yt-dlp's default options are different from that of youtube-dl and youtube-dlc:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;yt-dlp supports only &lt;a href="##" title="Windows 8"&gt;Python 3.9+&lt;/a&gt;, and will remove support for more versions as they &lt;a href="https://devguide.python.org/versions/#python-release-cycle"&gt;become EOL&lt;/a&gt;; while &lt;a href="https://github.com/ytdl-org/youtube-dl/issues/30568#issue-1118238743"&gt;youtube-dl still supports Python 2.6+ and 3.2+&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The options &lt;code&gt;--auto-number&lt;/code&gt; (&lt;code&gt;-A&lt;/code&gt;), &lt;code&gt;--title&lt;/code&gt; (&lt;code&gt;-t&lt;/code&gt;) and &lt;code&gt;--literal&lt;/code&gt; (&lt;code&gt;-l&lt;/code&gt;), no longer work. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#Removed"&gt;removed options&lt;/a&gt; for details&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;avconv&lt;/code&gt; is not supported as an alternative to &lt;code&gt;ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp stores config files in slightly different locations to youtube-dl. See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#configuration"&gt;CONFIGURATION&lt;/a&gt; for a list of correct locations&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#output-template"&gt;output template&lt;/a&gt; is &lt;code&gt;%(title)s [%(id)s].%(ext)s&lt;/code&gt;. There is no real reason for this change. This was changed before yt-dlp was ever made public and now there are no plans to change it back to &lt;code&gt;%(title)s-%(id)s.%(ext)s&lt;/code&gt;. Instead, you may use &lt;code&gt;--compat-options filename&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;The default &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#sorting-formats"&gt;format sorting&lt;/a&gt; is different from youtube-dl and prefers higher resolution and better codecs rather than higher bitrates. You can use the &lt;code&gt;--format-sort&lt;/code&gt; option to change this to any order you prefer, or use &lt;code&gt;--compat-options format-sort&lt;/code&gt; to use youtube-dl's sorting order. Older versions of yt-dlp preferred VP9 due to its broader compatibility; you can use &lt;code&gt;--compat-options prefer-vp9-sort&lt;/code&gt; to revert to that format sorting preference. These two compat options cannot be used together&lt;/li&gt; 
 &lt;li&gt;The default format selector is &lt;code&gt;bv*+ba/b&lt;/code&gt;. This means that if a combined video + audio format that is better than the best video-only format is found, the former will be preferred. Use &lt;code&gt;-f bv+ba/b&lt;/code&gt; or &lt;code&gt;--compat-options format-spec&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Unlike youtube-dlc, yt-dlp does not allow merging multiple audio/video streams into one file by default (since this conflicts with the use of &lt;code&gt;-f bv*+ba&lt;/code&gt;). If needed, this feature must be enabled using &lt;code&gt;--audio-multistreams&lt;/code&gt; and &lt;code&gt;--video-multistreams&lt;/code&gt;. You can also use &lt;code&gt;--compat-options multistreams&lt;/code&gt; to enable both&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--no-abort-on-error&lt;/code&gt; is enabled by default. Use &lt;code&gt;--abort-on-error&lt;/code&gt; or &lt;code&gt;--compat-options abort-on-error&lt;/code&gt; to abort on errors instead&lt;/li&gt; 
 &lt;li&gt;When writing metadata files such as thumbnails, description or infojson, the same information (if available) is also written for playlists. Use &lt;code&gt;--no-write-playlist-metafiles&lt;/code&gt; or &lt;code&gt;--compat-options no-playlist-metafiles&lt;/code&gt; to not write these files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--add-metadata&lt;/code&gt; attaches the &lt;code&gt;infojson&lt;/code&gt; to &lt;code&gt;mkv&lt;/code&gt; files in addition to writing the metadata when used with &lt;code&gt;--write-info-json&lt;/code&gt;. Use &lt;code&gt;--no-embed-info-json&lt;/code&gt; or &lt;code&gt;--compat-options no-attach-info-json&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Some metadata are embedded into different fields when using &lt;code&gt;--add-metadata&lt;/code&gt; as compared to youtube-dl. Most notably, &lt;code&gt;comment&lt;/code&gt; field contains the &lt;code&gt;webpage_url&lt;/code&gt; and &lt;code&gt;synopsis&lt;/code&gt; contains the &lt;code&gt;description&lt;/code&gt;. You can &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/#modifying-metadata"&gt;use &lt;code&gt;--parse-metadata&lt;/code&gt;&lt;/a&gt; to modify this to your liking or use &lt;code&gt;--compat-options embed-metadata&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;playlist_index&lt;/code&gt; behaves differently when used with options like &lt;code&gt;--playlist-reverse&lt;/code&gt; and &lt;code&gt;--playlist-items&lt;/code&gt;. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/302"&gt;#302&lt;/a&gt; for details. You can use &lt;code&gt;--compat-options playlist-index&lt;/code&gt; if you want to keep the earlier behavior&lt;/li&gt; 
 &lt;li&gt;The output of &lt;code&gt;-F&lt;/code&gt; is listed in a new format. Use &lt;code&gt;--compat-options list-formats&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Live chats (if available) are considered as subtitles. Use &lt;code&gt;--sub-langs all,-live_chat&lt;/code&gt; to download all subtitles except live chat. You can also use &lt;code&gt;--compat-options no-live-chat&lt;/code&gt; to prevent any live chat/danmaku from downloading&lt;/li&gt; 
 &lt;li&gt;YouTube channel URLs download all uploads of the channel. To download only the videos in a specific tab, pass the tab's URL. If the channel does not show the requested tab, an error will be raised. Also, &lt;code&gt;/live&lt;/code&gt; URLs raise an error if there are no live videos instead of silently downloading the entire channel. You may use &lt;code&gt;--compat-options no-youtube-channel-redirect&lt;/code&gt; to revert all these redirections&lt;/li&gt; 
 &lt;li&gt;Unavailable videos are also listed for YouTube playlists. Use &lt;code&gt;--compat-options no-youtube-unavailable-videos&lt;/code&gt; to remove this&lt;/li&gt; 
 &lt;li&gt;The upload dates extracted from YouTube are in UTC.&lt;/li&gt; 
 &lt;li&gt;If &lt;code&gt;ffmpeg&lt;/code&gt; is used as the downloader, the downloading and merging of formats happen in a single step when possible. Use &lt;code&gt;--compat-options no-direct-merge&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;Thumbnail embedding in &lt;code&gt;mp4&lt;/code&gt; is done with mutagen if possible. Use &lt;code&gt;--compat-options embed-thumbnail-atomicparsley&lt;/code&gt; to force the use of AtomicParsley instead&lt;/li&gt; 
 &lt;li&gt;Some internal metadata such as filenames are removed by default from the infojson. Use &lt;code&gt;--no-clean-infojson&lt;/code&gt; or &lt;code&gt;--compat-options no-clean-infojson&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;When &lt;code&gt;--embed-subs&lt;/code&gt; and &lt;code&gt;--write-subs&lt;/code&gt; are used together, the subtitles are written to disk and also embedded in the media file. You can use just &lt;code&gt;--embed-subs&lt;/code&gt; to embed the subs and automatically delete the separate file. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/630#issuecomment-893659460"&gt;#630 (comment)&lt;/a&gt; for more info. &lt;code&gt;--compat-options no-keep-subs&lt;/code&gt; can be used to revert this&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;certifi&lt;/code&gt; will be used for SSL root certificates, if installed. If you want to use system certificates (e.g. self-signed), use &lt;code&gt;--compat-options no-certifi&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp's sanitization of invalid characters in filenames is different/smarter than in youtube-dl. You can use &lt;code&gt;--compat-options filename-sanitization&lt;/code&gt; to revert to youtube-dl's behavior&lt;/li&gt; 
 &lt;li&gt;&lt;del&gt;yt-dlp tries to parse the external downloader outputs into the standard progress output if possible (Currently implemented: &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/5931"&gt;aria2c&lt;/a&gt;). You can use &lt;code&gt;--compat-options no-external-downloader-progress&lt;/code&gt; to get the downloader output as-is&lt;/del&gt;&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.09.01 and 2023.01.02 applies &lt;code&gt;--match-filters&lt;/code&gt; to nested playlists. This was an unintentional side-effect of &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/8f18aca8717bb0dd49054555af8d386e5eda3a88"&gt;8f18ac&lt;/a&gt; and is fixed in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/d7b460d0e5fc710950582baed2e3fc616ed98a80"&gt;d7b460&lt;/a&gt;. Use &lt;code&gt;--compat-options playlist-match-filter&lt;/code&gt; to revert this&lt;/li&gt; 
 &lt;li&gt;yt-dlp versions between 2021.11.10 and 2023.06.21 estimated &lt;code&gt;filesize_approx&lt;/code&gt; values for fragmented/manifest formats. This was added for convenience in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/f2fe69c7b0d208bdb1f6292b4ae92bc1e1a7444a"&gt;f2fe69&lt;/a&gt;, but was reverted in &lt;a href="https://github.com/yt-dlp/yt-dlp/commit/0dff8e4d1e6e9fb938f4256ea9af7d81f42fd54f"&gt;0dff8e&lt;/a&gt; due to the potentially extreme inaccuracy of the estimated values. Use &lt;code&gt;--compat-options manifest-filesize-approx&lt;/code&gt; to keep extracting the estimated values&lt;/li&gt; 
 &lt;li&gt;yt-dlp uses modern http client backends such as &lt;code&gt;requests&lt;/code&gt;. Use &lt;code&gt;--compat-options prefer-legacy-http-handler&lt;/code&gt; to prefer the legacy http handler (&lt;code&gt;urllib&lt;/code&gt;) to be used for standard http requests.&lt;/li&gt; 
 &lt;li&gt;The sub-modules &lt;code&gt;swfinterp&lt;/code&gt;, &lt;code&gt;casefold&lt;/code&gt; are removed.&lt;/li&gt; 
 &lt;li&gt;Passing &lt;code&gt;--simulate&lt;/code&gt; (or calling &lt;code&gt;extract_info&lt;/code&gt; with &lt;code&gt;download=False&lt;/code&gt;) no longer alters the default format selection. See &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/9843"&gt;#9843&lt;/a&gt; for details.&lt;/li&gt; 
 &lt;li&gt;yt-dlp no longer applies the server modified time to downloaded files by default. Use &lt;code&gt;--mtime&lt;/code&gt; or &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt; to revert this.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For ease of use, a few more compat options are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options all&lt;/code&gt;: Use all compat options (&lt;strong&gt;Do NOT use this!&lt;/strong&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dl&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-multistreams,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options youtube-dlc&lt;/code&gt;: Same as &lt;code&gt;--compat-options all,-no-live-chat,-no-youtube-channel-redirect,-playlist-match-filter,-manifest-filesize-approx,-allow-unsafe-ext,-prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2021&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2022,no-certifi,filename-sanitization&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2022&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2023,playlist-match-filter,no-external-downloader-progress,prefer-legacy-http-handler,manifest-filesize-approx&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2023&lt;/code&gt;: Same as &lt;code&gt;--compat-options 2024,prefer-vp9-sort&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--compat-options 2024&lt;/code&gt;: Same as &lt;code&gt;--compat-options mtime-by-default&lt;/code&gt;. Use this to enable all future compat options&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The following compat options restore vulnerable behavior from before security patches:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;--compat-options allow-unsafe-ext&lt;/code&gt;: Allow files with any extension (including unsafe ones) to be downloaded (&lt;a href="https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-79w7-vh3h-8g4j"&gt;GHSA-79w7-vh3h-8g4j&lt;/a&gt;)&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;span&gt;‚ö†&lt;/span&gt; Only use if a valid file download is rejected because its extension is detected as uncommon&lt;/p&gt; 
   &lt;p&gt;&lt;strong&gt;This option can enable remote code execution! Consider &lt;a href="https://github.com/yt-dlp/yt-dlp/issues/new/choose"&gt;opening an issue&lt;/a&gt; instead!&lt;/strong&gt;&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deprecated options&lt;/h3&gt; 
&lt;p&gt;These are all the deprecated options and the current alternative to achieve the same effect&lt;/p&gt; 
&lt;h4&gt;Almost redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are almost the same as their new counterparts, there are some differences that prevents them being redundant&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-j, --dump-json                  --print "%()j"
-F, --list-formats               --print formats_table
--list-thumbnails                --print thumbnails_table --print playlist:thumbnails_table
--list-subs                      --print automatic_captions_table --print subtitles_table
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redundant options&lt;/h4&gt; 
&lt;p&gt;While these options are redundant, they are still expected to be used due to their ease of use&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--get-description                --print description
--get-duration                   --print duration_string
--get-filename                   --print filename
--get-format                     --print format
--get-id                         --print id
--get-thumbnail                  --print thumbnail
-e, --get-title                  --print title
-g, --get-url                    --print urls
--match-title REGEX              --match-filters "title ~= (?i)REGEX"
--reject-title REGEX             --match-filters "title !~= (?i)REGEX"
--min-views COUNT                --match-filters "view_count &amp;gt;=? COUNT"
--max-views COUNT                --match-filters "view_count &amp;lt;=? COUNT"
--break-on-reject                Use --break-match-filters
--user-agent UA                  --add-headers "User-Agent:UA"
--referer URL                    --add-headers "Referer:URL"
--playlist-start NUMBER          -I NUMBER:
--playlist-end NUMBER            -I :NUMBER
--playlist-reverse               -I ::-1
--no-playlist-reverse            Default
--no-colors                      --color no_color
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Not recommended&lt;/h4&gt; 
&lt;p&gt;While these options still work, their use is not recommended since there are other alternatives to achieve the same&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--force-generic-extractor        --ies generic,default
--exec-before-download CMD       --exec "before_dl:CMD"
--no-exec-before-download        --no-exec
--all-formats                    -f all
--all-subs                       --sub-langs all --write-subs
--print-json                     -j --no-simulate
--autonumber-size NUMBER         Use string formatting, e.g. %(autonumber)03d
--autonumber-start NUMBER        Use internal field formatting like %(autonumber+NUMBER)s
--id                             -o "%(id)s.%(ext)s"
--metadata-from-title FORMAT     --parse-metadata "%(title)s:FORMAT"
--hls-prefer-native              --downloader "m3u8:native"
--hls-prefer-ffmpeg              --downloader "m3u8:ffmpeg"
--list-formats-old               --compat-options list-formats (Alias: --no-list-formats-as-table)
--list-formats-as-table          --compat-options -list-formats [Default]
--geo-bypass                     --xff "default"
--no-geo-bypass                  --xff "never"
--geo-bypass-country CODE        --xff CODE
--geo-bypass-ip-block IP_BLOCK   --xff IP_BLOCK
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Developer options&lt;/h4&gt; 
&lt;p&gt;These options are not intended to be used by the end-user&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--test                           Download only part of video for testing extractors
--load-pages                     Load pages dumped by --write-pages
--allow-unplayable-formats       List unplayable formats also
--no-allow-unplayable-formats    Default
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Old aliases&lt;/h4&gt; 
&lt;p&gt;These are aliases that are no longer documented for various reasons&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--clean-infojson                 --clean-info-json
--force-write-download-archive   --force-write-archive
--no-clean-infojson              --no-clean-info-json
--no-split-tracks                --no-split-chapters
--no-write-srt                   --no-write-subs
--prefer-unsecure                --prefer-insecure
--rate-limit RATE                --limit-rate RATE
--split-tracks                   --split-chapters
--srt-lang LANGS                 --sub-langs LANGS
--trim-file-names LENGTH         --trim-filenames LENGTH
--write-srt                      --write-subs
--yes-overwrites                 --force-overwrites
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Sponskrub Options&lt;/h4&gt; 
&lt;p&gt;Support for &lt;a href="https://github.com/faissaloo/SponSkrub"&gt;SponSkrub&lt;/a&gt; has been removed in favor of the &lt;code&gt;--sponsorblock&lt;/code&gt; options&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--sponskrub                      --sponsorblock-mark all
--no-sponskrub                   --no-sponsorblock
--sponskrub-cut                  --sponsorblock-remove all
--no-sponskrub-cut               --sponsorblock-remove -all
--sponskrub-force                Not applicable
--no-sponskrub-force             Not applicable
--sponskrub-location             Not applicable
--sponskrub-args                 Not applicable
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;No longer supported&lt;/h4&gt; 
&lt;p&gt;These options may no longer work as intended&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;--prefer-avconv                  avconv is not officially supported by yt-dlp (Alias: --no-prefer-ffmpeg)
--prefer-ffmpeg                  Default (Alias: --no-prefer-avconv)
-C, --call-home                  Not implemented
--no-call-home                   Default
--include-ads                    No longer supported
--no-include-ads                 Default
--write-annotations              No supported site has annotations now
--no-write-annotations           Default
--avconv-location                Removed alias for --ffmpeg-location
--cn-verification-proxy URL      Removed alias for --geo-verification-proxy URL
--dump-headers                   Removed alias for --print-traffic
--dump-intermediate-pages        Removed alias for --dump-pages
--youtube-skip-dash-manifest     Removed alias for --extractor-args "youtube:skip=dash" (Alias: --no-youtube-include-dash-manifest)
--youtube-skip-hls-manifest      Removed alias for --extractor-args "youtube:skip=hls" (Alias: --no-youtube-include-hls-manifest)
--youtube-include-dash-manifest  Default (Alias: --no-youtube-skip-dash-manifest)
--youtube-include-hls-manifest   Default (Alias: --no-youtube-skip-hls-manifest)
--youtube-print-sig-code         Removed testing functionality
--dump-user-agent                No longer supported
--xattr-set-filesize             No longer supported
--compat-options seperate-video-versions  No longer needed
--compat-options no-youtube-prefer-utc-upload-date  No longer supported
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Removed&lt;/h4&gt; 
&lt;p&gt;These options were deprecated since 2014 and have now been entirely removed&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;-A, --auto-number                -o "%(autonumber)s-%(id)s.%(ext)s"
-t, -l, --title, --literal       -o "%(title)s-%(id)s.%(ext)s"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;CONTRIBUTING&lt;/h1&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#contributing-to-yt-dlp"&gt;CONTRIBUTING.md&lt;/a&gt; for instructions on &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#opening-an-issue"&gt;Opening an Issue&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/CONTRIBUTING.md#developer-instructions"&gt;Contributing code to the project&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;WIKI&lt;/h1&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/yt-dlp/yt-dlp/wiki"&gt;Wiki&lt;/a&gt; for more information&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>modelcontextprotocol/python-sdk</title>
      <link>https://github.com/modelcontextprotocol/python-sdk</link>
      <description>&lt;p&gt;The official Python SDK for Model Context Protocol servers and clients&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MCP Python SDK&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Python implementation of the Model Context Protocol (MCP)&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/mcp/"&gt;&lt;img src="https://img.shields.io/pypi/v/mcp.svg?sanitize=true" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/pypi/l/mcp.svg?sanitize=true" alt="MIT licensed" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/mcp.svg?sanitize=true" alt="Python Version" /&gt;&lt;/a&gt; &lt;a href="https://modelcontextprotocol.io"&gt;&lt;img src="https://img.shields.io/badge/docs-modelcontextprotocol.io-blue.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://spec.modelcontextprotocol.io"&gt;&lt;img src="https://img.shields.io/badge/spec-spec.modelcontextprotocol.io-blue.svg?sanitize=true" alt="Specification" /&gt;&lt;/a&gt; &lt;a href="https://github.com/modelcontextprotocol/python-sdk/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/modelcontextprotocol/python-sdk" alt="GitHub Discussions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;!-- omit in toc --&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#mcp-python-sdk"&gt;MCP Python SDK&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#installation"&gt;Installation&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#adding-mcp-to-your-python-project"&gt;Adding MCP to your python project&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#running-the-standalone-mcp-development-tools"&gt;Running the standalone MCP development tools&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#quickstart"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#what-is-mcp"&gt;What is MCP?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#core-concepts"&gt;Core Concepts&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#server"&gt;Server&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#resources"&gt;Resources&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#tools"&gt;Tools&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#structured-output"&gt;Structured Output&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#prompts"&gt;Prompts&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#images"&gt;Images&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#context"&gt;Context&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#getting-context-in-functions"&gt;Getting Context in Functions&lt;/a&gt;&lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#context-properties-and-methods"&gt;Context Properties and Methods&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#completions"&gt;Completions&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#elicitation"&gt;Elicitation&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#sampling"&gt;Sampling&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#logging-and-notifications"&gt;Logging and Notifications&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#authentication"&gt;Authentication&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#fastmcp-properties"&gt;FastMCP Properties&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#session-properties-and-methods"&gt;Session Properties and Methods&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#request-context-properties"&gt;Request Context Properties&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#running-your-server"&gt;Running Your Server&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#development-mode"&gt;Development Mode&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#claude-desktop-integration"&gt;Claude Desktop Integration&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#direct-execution"&gt;Direct Execution&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#streamable-http-transport"&gt;Streamable HTTP Transport&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#cors-configuration-for-browser-based-clients"&gt;CORS Configuration for Browser-Based Clients&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#mounting-to-an-existing-asgi-server"&gt;Mounting to an Existing ASGI Server&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#streamablehttp-servers"&gt;StreamableHTTP servers&lt;/a&gt; 
        &lt;ul&gt; 
         &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#basic-mounting"&gt;Basic mounting&lt;/a&gt;&lt;/li&gt; 
         &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#host-based-routing"&gt;Host-based routing&lt;/a&gt;&lt;/li&gt; 
         &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#multiple-servers-with-path-configuration"&gt;Multiple servers with path configuration&lt;/a&gt;&lt;/li&gt; 
         &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#path-configuration-at-initialization"&gt;Path configuration at initialization&lt;/a&gt;&lt;/li&gt; 
        &lt;/ul&gt; &lt;/li&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#sse-servers"&gt;SSE servers&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#advanced-usage"&gt;Advanced Usage&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#low-level-server"&gt;Low-Level Server&lt;/a&gt; 
      &lt;ul&gt; 
       &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#structured-output-support"&gt;Structured Output Support&lt;/a&gt;&lt;/li&gt; 
      &lt;/ul&gt; &lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#pagination-advanced"&gt;Pagination (Advanced)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#writing-mcp-clients"&gt;Writing MCP Clients&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#client-display-utilities"&gt;Client Display Utilities&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#oauth-authentication-for-clients"&gt;OAuth Authentication for Clients&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#parsing-tool-results"&gt;Parsing Tool Results&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#mcp-primitives"&gt;MCP Primitives&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#server-capabilities"&gt;Server Capabilities&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;The Model Context Protocol allows applications to provide context for LLMs in a standardized way, separating the concerns of providing context from the actual LLM interaction. This Python SDK implements the full MCP specification, making it easy to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Build MCP clients that can connect to any MCP server&lt;/li&gt; 
 &lt;li&gt;Create MCP servers that expose resources, prompts and tools&lt;/li&gt; 
 &lt;li&gt;Use standard transports like stdio, SSE, and Streamable HTTP&lt;/li&gt; 
 &lt;li&gt;Handle all MCP protocol messages and lifecycle events&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Adding MCP to your python project&lt;/h3&gt; 
&lt;p&gt;We recommend using &lt;a href="https://docs.astral.sh/uv/"&gt;uv&lt;/a&gt; to manage your Python projects.&lt;/p&gt; 
&lt;p&gt;If you haven't created a uv-managed project yet, create one:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv init mcp-server-demo
cd mcp-server-demo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then add MCP to your project dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv add "mcp[cli]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, for projects using pip for dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "mcp[cli]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running the standalone MCP development tools&lt;/h3&gt; 
&lt;p&gt;To run the mcp command with uv:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Let's create a simple MCP server that exposes a calculator tool and some data:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/fastmcp_quickstart.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
FastMCP quickstart example.

cd to the `examples/snippets/clients` directory and run:
    uv run server fastmcp_quickstart stdio
"""

from mcp.server.fastmcp import FastMCP

# Create an MCP server
mcp = FastMCP("Demo")


# Add an addition tool
@mcp.tool()
def add(a: int, b: int) -&amp;gt; int:
    """Add two numbers"""
    return a + b


# Add a dynamic greeting resource
@mcp.resource("greeting://{name}")
def get_greeting(name: str) -&amp;gt; str:
    """Get a personalized greeting"""
    return f"Hello, {name}!"


# Add a prompt
@mcp.prompt()
def greet_user(name: str, style: str = "friendly") -&amp;gt; str:
    """Generate a greeting prompt"""
    styles = {
        "friendly": "Please write a warm, friendly greeting",
        "formal": "Please write a formal, professional greeting",
        "casual": "Please write a casual, relaxed greeting",
    }

    return f"{styles.get(style, styles['friendly'])} for someone named {name}."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/fastmcp_quickstart.py"&gt;examples/snippets/servers/fastmcp_quickstart.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;You can install this server in &lt;a href="https://claude.ai/download"&gt;Claude Desktop&lt;/a&gt; and interact with it right away by running:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run mcp install server.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can test it with the MCP Inspector:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run mcp dev server.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What is MCP?&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://modelcontextprotocol.io"&gt;Model Context Protocol (MCP)&lt;/a&gt; lets you build servers that expose data and functionality to LLM applications in a secure, standardized way. Think of it like a web API, but specifically designed for LLM interactions. MCP servers can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Expose data through &lt;strong&gt;Resources&lt;/strong&gt; (think of these sort of like GET endpoints; they are used to load information into the LLM's context)&lt;/li&gt; 
 &lt;li&gt;Provide functionality through &lt;strong&gt;Tools&lt;/strong&gt; (sort of like POST endpoints; they are used to execute code or otherwise produce a side effect)&lt;/li&gt; 
 &lt;li&gt;Define interaction patterns through &lt;strong&gt;Prompts&lt;/strong&gt; (reusable templates for LLM interactions)&lt;/li&gt; 
 &lt;li&gt;And more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Core Concepts&lt;/h2&gt; 
&lt;h3&gt;Server&lt;/h3&gt; 
&lt;p&gt;The FastMCP server is your core interface to the MCP protocol. It handles connection management, protocol compliance, and message routing:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/lifespan_example.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""Example showing lifespan support for startup/shutdown with strong typing."""

from collections.abc import AsyncIterator
from contextlib import asynccontextmanager
from dataclasses import dataclass

from mcp.server.fastmcp import Context, FastMCP
from mcp.server.session import ServerSession


# Mock database class for example
class Database:
    """Mock database class for example."""

    @classmethod
    async def connect(cls) -&amp;gt; "Database":
        """Connect to database."""
        return cls()

    async def disconnect(self) -&amp;gt; None:
        """Disconnect from database."""
        pass

    def query(self) -&amp;gt; str:
        """Execute a query."""
        return "Query result"


@dataclass
class AppContext:
    """Application context with typed dependencies."""

    db: Database


@asynccontextmanager
async def app_lifespan(server: FastMCP) -&amp;gt; AsyncIterator[AppContext]:
    """Manage application lifecycle with type-safe context."""
    # Initialize on startup
    db = await Database.connect()
    try:
        yield AppContext(db=db)
    finally:
        # Cleanup on shutdown
        await db.disconnect()


# Pass lifespan to server
mcp = FastMCP("My App", lifespan=app_lifespan)


# Access type-safe lifespan context in tools
@mcp.tool()
def query_db(ctx: Context[ServerSession, AppContext]) -&amp;gt; str:
    """Tool that uses initialized resources."""
    db = ctx.request_context.lifespan_context.db
    return db.query()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/lifespan_example.py"&gt;examples/snippets/servers/lifespan_example.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h3&gt;Resources&lt;/h3&gt; 
&lt;p&gt;Resources are how you expose data to LLMs. They're similar to GET endpoints in a REST API - they provide data but shouldn't perform significant computation or have side effects:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/basic_resource.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mcp.server.fastmcp import FastMCP

mcp = FastMCP(name="Resource Example")


@mcp.resource("file://documents/{name}")
def read_document(name: str) -&amp;gt; str:
    """Read a document by name."""
    # This would normally read from disk
    return f"Content of {name}"


@mcp.resource("config://settings")
def get_settings() -&amp;gt; str:
    """Get application settings."""
    return """{
  "theme": "dark",
  "language": "en",
  "debug": false
}"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/basic_resource.py"&gt;examples/snippets/servers/basic_resource.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;Tools let LLMs take actions through your server. Unlike resources, tools are expected to perform computation and have side effects:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/basic_tool.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mcp.server.fastmcp import FastMCP

mcp = FastMCP(name="Tool Example")


@mcp.tool()
def sum(a: int, b: int) -&amp;gt; int:
    """Add two numbers together."""
    return a + b


@mcp.tool()
def get_weather(city: str, unit: str = "celsius") -&amp;gt; str:
    """Get weather for a city."""
    # This would normally call a weather API
    return f"Weather in {city}: 22degrees{unit[0].upper()}"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/basic_tool.py"&gt;examples/snippets/servers/basic_tool.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;Tools can optionally receive a Context object by including a parameter with the &lt;code&gt;Context&lt;/code&gt; type annotation. This context is automatically injected by the FastMCP framework and provides access to MCP capabilities:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/tool_progress.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mcp.server.fastmcp import Context, FastMCP
from mcp.server.session import ServerSession

mcp = FastMCP(name="Progress Example")


@mcp.tool()
async def long_running_task(task_name: str, ctx: Context[ServerSession, None], steps: int = 5) -&amp;gt; str:
    """Execute a task with progress updates."""
    await ctx.info(f"Starting: {task_name}")

    for i in range(steps):
        progress = (i + 1) / steps
        await ctx.report_progress(
            progress=progress,
            total=1.0,
            message=f"Step {i + 1}/{steps}",
        )
        await ctx.debug(f"Completed step {i + 1}")

    return f"Task '{task_name}' completed"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/tool_progress.py"&gt;examples/snippets/servers/tool_progress.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h4&gt;Structured Output&lt;/h4&gt; 
&lt;p&gt;Tools will return structured results by default, if their return type annotation is compatible. Otherwise, they will return unstructured results.&lt;/p&gt; 
&lt;p&gt;Structured output supports these return types:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pydantic models (BaseModel subclasses)&lt;/li&gt; 
 &lt;li&gt;TypedDicts&lt;/li&gt; 
 &lt;li&gt;Dataclasses and other classes with type hints&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;dict[str, T]&lt;/code&gt; (where T is any JSON-serializable type)&lt;/li&gt; 
 &lt;li&gt;Primitive types (str, int, float, bool, bytes, None) - wrapped in &lt;code&gt;{"result": value}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Generic types (list, tuple, Union, Optional, etc.) - wrapped in &lt;code&gt;{"result": value}&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Classes without type hints cannot be serialized for structured output. Only classes with properly annotated attributes will be converted to Pydantic models for schema generation and validation.&lt;/p&gt; 
&lt;p&gt;Structured results are automatically validated against the output schema generated from the annotation. This ensures the tool returns well-typed, validated data that clients can easily process.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For backward compatibility, unstructured results are also returned. Unstructured results are provided for backward compatibility with previous versions of the MCP specification, and are quirks-compatible with previous versions of FastMCP in the current version of the SDK.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In cases where a tool function's return type annotation causes the tool to be classified as structured &lt;em&gt;and this is undesirable&lt;/em&gt;, the classification can be suppressed by passing &lt;code&gt;structured_output=False&lt;/code&gt; to the &lt;code&gt;@tool&lt;/code&gt; decorator.&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/structured_output.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""Example showing structured output with tools."""

from typing import TypedDict

from pydantic import BaseModel, Field

from mcp.server.fastmcp import FastMCP

mcp = FastMCP("Structured Output Example")


# Using Pydantic models for rich structured data
class WeatherData(BaseModel):
    """Weather information structure."""

    temperature: float = Field(description="Temperature in Celsius")
    humidity: float = Field(description="Humidity percentage")
    condition: str
    wind_speed: float


@mcp.tool()
def get_weather(city: str) -&amp;gt; WeatherData:
    """Get weather for a city - returns structured data."""
    # Simulated weather data
    return WeatherData(
        temperature=22.5,
        humidity=45.0,
        condition="sunny",
        wind_speed=5.2,
    )


# Using TypedDict for simpler structures
class LocationInfo(TypedDict):
    latitude: float
    longitude: float
    name: str


@mcp.tool()
def get_location(address: str) -&amp;gt; LocationInfo:
    """Get location coordinates"""
    return LocationInfo(latitude=51.5074, longitude=-0.1278, name="London, UK")


# Using dict[str, Any] for flexible schemas
@mcp.tool()
def get_statistics(data_type: str) -&amp;gt; dict[str, float]:
    """Get various statistics"""
    return {"mean": 42.5, "median": 40.0, "std_dev": 5.2}


# Ordinary classes with type hints work for structured output
class UserProfile:
    name: str
    age: int
    email: str | None = None

    def __init__(self, name: str, age: int, email: str | None = None):
        self.name = name
        self.age = age
        self.email = email


@mcp.tool()
def get_user(user_id: str) -&amp;gt; UserProfile:
    """Get user profile - returns structured data"""
    return UserProfile(name="Alice", age=30, email="alice@example.com")


# Classes WITHOUT type hints cannot be used for structured output
class UntypedConfig:
    def __init__(self, setting1, setting2):  # type: ignore[reportMissingParameterType]
        self.setting1 = setting1
        self.setting2 = setting2


@mcp.tool()
def get_config() -&amp;gt; UntypedConfig:
    """This returns unstructured output - no schema generated"""
    return UntypedConfig("value1", "value2")


# Lists and other types are wrapped automatically
@mcp.tool()
def list_cities() -&amp;gt; list[str]:
    """Get a list of cities"""
    return ["London", "Paris", "Tokyo"]
    # Returns: {"result": ["London", "Paris", "Tokyo"]}


@mcp.tool()
def get_temperature(city: str) -&amp;gt; float:
    """Get temperature as a simple float"""
    return 22.5
    # Returns: {"result": 22.5}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/structured_output.py"&gt;examples/snippets/servers/structured_output.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h3&gt;Prompts&lt;/h3&gt; 
&lt;p&gt;Prompts are reusable templates that help LLMs interact with your server effectively:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/basic_prompt.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mcp.server.fastmcp import FastMCP
from mcp.server.fastmcp.prompts import base

mcp = FastMCP(name="Prompt Example")


@mcp.prompt(title="Code Review")
def review_code(code: str) -&amp;gt; str:
    return f"Please review this code:\n\n{code}"


@mcp.prompt(title="Debug Assistant")
def debug_error(error: str) -&amp;gt; list[base.Message]:
    return [
        base.UserMessage("I'm seeing this error:"),
        base.UserMessage(error),
        base.AssistantMessage("I'll help debug that. What have you tried so far?"),
    ]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/basic_prompt.py"&gt;examples/snippets/servers/basic_prompt.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h3&gt;Icons&lt;/h3&gt; 
&lt;p&gt;MCP servers can provide icons for UI display. Icons can be added to the server implementation, tools, resources, and prompts:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mcp.server.fastmcp import FastMCP, Icon

# Create an icon from a file path or URL
icon = Icon(
    src="icon.png",
    mimeType="image/png",
    sizes="64x64"
)

# Add icons to server
mcp = FastMCP(
    "My Server",
    website_url="https://example.com",
    icons=[icon]
)

# Add icons to tools, resources, and prompts
@mcp.tool(icons=[icon])
def my_tool():
    """Tool with an icon."""
    return "result"

@mcp.resource("demo://resource", icons=[icon])
def my_resource():
    """Resource with an icon."""
    return "content"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/fastmcp/icons_demo.py"&gt;examples/fastmcp/icons_demo.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Images&lt;/h3&gt; 
&lt;p&gt;FastMCP provides an &lt;code&gt;Image&lt;/code&gt; class that automatically handles image data:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/images.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""Example showing image handling with FastMCP."""

from PIL import Image as PILImage

from mcp.server.fastmcp import FastMCP, Image

mcp = FastMCP("Image Example")


@mcp.tool()
def create_thumbnail(image_path: str) -&amp;gt; Image:
    """Create a thumbnail from an image"""
    img = PILImage.open(image_path)
    img.thumbnail((100, 100))
    return Image(data=img.tobytes(), format="png")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/images.py"&gt;examples/snippets/servers/images.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h3&gt;Context&lt;/h3&gt; 
&lt;p&gt;The Context object is automatically injected into tool and resource functions that request it via type hints. It provides access to MCP capabilities like logging, progress reporting, resource reading, user interaction, and request metadata.&lt;/p&gt; 
&lt;h4&gt;Getting Context in Functions&lt;/h4&gt; 
&lt;p&gt;To use context in a tool or resource function, add a parameter with the &lt;code&gt;Context&lt;/code&gt; type annotation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mcp.server.fastmcp import Context, FastMCP

mcp = FastMCP(name="Context Example")


@mcp.tool()
async def my_tool(x: int, ctx: Context) -&amp;gt; str:
    """Tool that uses context capabilities."""
    # The context parameter can have any name as long as it's type-annotated
    return await process_with_context(x, ctx)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Context Properties and Methods&lt;/h4&gt; 
&lt;p&gt;The Context object provides the following capabilities:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ctx.request_id&lt;/code&gt; - Unique ID for the current request&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctx.client_id&lt;/code&gt; - Client ID if available&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctx.fastmcp&lt;/code&gt; - Access to the FastMCP server instance (see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#fastmcp-properties"&gt;FastMCP Properties&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctx.session&lt;/code&gt; - Access to the underlying session for advanced communication (see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#session-properties-and-methods"&gt;Session Properties and Methods&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctx.request_context&lt;/code&gt; - Access to request-specific data and lifespan resources (see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/#request-context-properties"&gt;Request Context Properties&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.debug(message)&lt;/code&gt; - Send debug log message&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.info(message)&lt;/code&gt; - Send info log message&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.warning(message)&lt;/code&gt; - Send warning log message&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.error(message)&lt;/code&gt; - Send error log message&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.log(level, message, logger_name=None)&lt;/code&gt; - Send log with custom level&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.report_progress(progress, total=None, message=None)&lt;/code&gt; - Report operation progress&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.read_resource(uri)&lt;/code&gt; - Read a resource by URI&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.elicit(message, schema)&lt;/code&gt; - Request additional information from user with validation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- snippet-source examples/snippets/servers/tool_progress.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mcp.server.fastmcp import Context, FastMCP
from mcp.server.session import ServerSession

mcp = FastMCP(name="Progress Example")


@mcp.tool()
async def long_running_task(task_name: str, ctx: Context[ServerSession, None], steps: int = 5) -&amp;gt; str:
    """Execute a task with progress updates."""
    await ctx.info(f"Starting: {task_name}")

    for i in range(steps):
        progress = (i + 1) / steps
        await ctx.report_progress(
            progress=progress,
            total=1.0,
            message=f"Step {i + 1}/{steps}",
        )
        await ctx.debug(f"Completed step {i + 1}")

    return f"Task '{task_name}' completed"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/tool_progress.py"&gt;examples/snippets/servers/tool_progress.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h3&gt;Completions&lt;/h3&gt; 
&lt;p&gt;MCP supports providing completion suggestions for prompt arguments and resource template parameters. With the context parameter, servers can provide completions based on previously resolved values:&lt;/p&gt; 
&lt;p&gt;Client usage:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/clients/completion_client.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
cd to the `examples/snippets` directory and run:
    uv run completion-client
"""

import asyncio
import os

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from mcp.types import PromptReference, ResourceTemplateReference

# Create server parameters for stdio connection
server_params = StdioServerParameters(
    command="uv",  # Using uv to run the server
    args=["run", "server", "completion", "stdio"],  # Server with completion support
    env={"UV_INDEX": os.environ.get("UV_INDEX", "")},
)


async def run():
    """Run the completion client example."""
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # Initialize the connection
            await session.initialize()

            # List available resource templates
            templates = await session.list_resource_templates()
            print("Available resource templates:")
            for template in templates.resourceTemplates:
                print(f"  - {template.uriTemplate}")

            # List available prompts
            prompts = await session.list_prompts()
            print("\nAvailable prompts:")
            for prompt in prompts.prompts:
                print(f"  - {prompt.name}")

            # Complete resource template arguments
            if templates.resourceTemplates:
                template = templates.resourceTemplates[0]
                print(f"\nCompleting arguments for resource template: {template.uriTemplate}")

                # Complete without context
                result = await session.complete(
                    ref=ResourceTemplateReference(type="ref/resource", uri=template.uriTemplate),
                    argument={"name": "owner", "value": "model"},
                )
                print(f"Completions for 'owner' starting with 'model': {result.completion.values}")

                # Complete with context - repo suggestions based on owner
                result = await session.complete(
                    ref=ResourceTemplateReference(type="ref/resource", uri=template.uriTemplate),
                    argument={"name": "repo", "value": ""},
                    context_arguments={"owner": "modelcontextprotocol"},
                )
                print(f"Completions for 'repo' with owner='modelcontextprotocol': {result.completion.values}")

            # Complete prompt arguments
            if prompts.prompts:
                prompt_name = prompts.prompts[0].name
                print(f"\nCompleting arguments for prompt: {prompt_name}")

                result = await session.complete(
                    ref=PromptReference(type="ref/prompt", name=prompt_name),
                    argument={"name": "style", "value": ""},
                )
                print(f"Completions for 'style' argument: {result.completion.values}")


def main():
    """Entry point for the completion client."""
    asyncio.run(run())


if __name__ == "__main__":
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/clients/completion_client.py"&gt;examples/snippets/clients/completion_client.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h3&gt;Elicitation&lt;/h3&gt; 
&lt;p&gt;Request additional information from users. This example shows an Elicitation during a Tool Call:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/elicitation.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from pydantic import BaseModel, Field

from mcp.server.fastmcp import Context, FastMCP
from mcp.server.session import ServerSession

mcp = FastMCP(name="Elicitation Example")


class BookingPreferences(BaseModel):
    """Schema for collecting user preferences."""

    checkAlternative: bool = Field(description="Would you like to check another date?")
    alternativeDate: str = Field(
        default="2024-12-26",
        description="Alternative date (YYYY-MM-DD)",
    )


@mcp.tool()
async def book_table(date: str, time: str, party_size: int, ctx: Context[ServerSession, None]) -&amp;gt; str:
    """Book a table with date availability check."""
    # Check if date is available
    if date == "2024-12-25":
        # Date unavailable - ask user for alternative
        result = await ctx.elicit(
            message=(f"No tables available for {party_size} on {date}. Would you like to try another date?"),
            schema=BookingPreferences,
        )

        if result.action == "accept" and result.data:
            if result.data.checkAlternative:
                return f"[SUCCESS] Booked for {result.data.alternativeDate}"
            return "[CANCELLED] No booking made"
        return "[CANCELLED] Booking cancelled"

    # Date available
    return f"[SUCCESS] Booked for {date} at {time}"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/elicitation.py"&gt;examples/snippets/servers/elicitation.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;Elicitation schemas support default values for all field types. Default values are automatically included in the JSON schema sent to clients, allowing them to pre-populate forms.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;elicit()&lt;/code&gt; method returns an &lt;code&gt;ElicitationResult&lt;/code&gt; with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;action&lt;/code&gt;: "accept", "decline", or "cancel"&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;data&lt;/code&gt;: The validated response (only when accepted)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;validation_error&lt;/code&gt;: Any validation error message&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Sampling&lt;/h3&gt; 
&lt;p&gt;Tools can interact with LLMs through sampling (generating text):&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/sampling.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mcp.server.fastmcp import Context, FastMCP
from mcp.server.session import ServerSession
from mcp.types import SamplingMessage, TextContent

mcp = FastMCP(name="Sampling Example")


@mcp.tool()
async def generate_poem(topic: str, ctx: Context[ServerSession, None]) -&amp;gt; str:
    """Generate a poem using LLM sampling."""
    prompt = f"Write a short poem about {topic}"

    result = await ctx.session.create_message(
        messages=[
            SamplingMessage(
                role="user",
                content=TextContent(type="text", text=prompt),
            )
        ],
        max_tokens=100,
    )

    if result.content.type == "text":
        return result.content.text
    return str(result.content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/sampling.py"&gt;examples/snippets/servers/sampling.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h3&gt;Logging and Notifications&lt;/h3&gt; 
&lt;p&gt;Tools can send logs and notifications through the context:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/notifications.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mcp.server.fastmcp import Context, FastMCP
from mcp.server.session import ServerSession

mcp = FastMCP(name="Notifications Example")


@mcp.tool()
async def process_data(data: str, ctx: Context[ServerSession, None]) -&amp;gt; str:
    """Process data with logging."""
    # Different log levels
    await ctx.debug(f"Debug: Processing '{data}'")
    await ctx.info("Info: Starting processing")
    await ctx.warning("Warning: This is experimental")
    await ctx.error("Error: (This is just a demo)")

    # Notify about resource changes
    await ctx.session.send_resource_list_changed()

    return f"Processed: {data}"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/notifications.py"&gt;examples/snippets/servers/notifications.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h3&gt;Authentication&lt;/h3&gt; 
&lt;p&gt;Authentication can be used by servers that want to expose tools accessing protected resources.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;mcp.server.auth&lt;/code&gt; implements OAuth 2.1 resource server functionality, where MCP servers act as Resource Servers (RS) that validate tokens issued by separate Authorization Servers (AS). This follows the &lt;a href="https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization"&gt;MCP authorization specification&lt;/a&gt; and implements RFC 9728 (Protected Resource Metadata) for AS discovery.&lt;/p&gt; 
&lt;p&gt;MCP servers can use authentication by providing an implementation of the &lt;code&gt;TokenVerifier&lt;/code&gt; protocol:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/oauth_server.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Run from the repository root:
    uv run examples/snippets/servers/oauth_server.py
"""

from pydantic import AnyHttpUrl

from mcp.server.auth.provider import AccessToken, TokenVerifier
from mcp.server.auth.settings import AuthSettings
from mcp.server.fastmcp import FastMCP


class SimpleTokenVerifier(TokenVerifier):
    """Simple token verifier for demonstration."""

    async def verify_token(self, token: str) -&amp;gt; AccessToken | None:
        pass  # This is where you would implement actual token validation


# Create FastMCP instance as a Resource Server
mcp = FastMCP(
    "Weather Service",
    # Token verifier for authentication
    token_verifier=SimpleTokenVerifier(),
    # Auth settings for RFC 9728 Protected Resource Metadata
    auth=AuthSettings(
        issuer_url=AnyHttpUrl("https://auth.example.com"),  # Authorization Server URL
        resource_server_url=AnyHttpUrl("http://localhost:3001"),  # This server's URL
        required_scopes=["user"],
    ),
)


@mcp.tool()
async def get_weather(city: str = "London") -&amp;gt; dict[str, str]:
    """Get weather data for a city"""
    return {
        "city": city,
        "temperature": "22",
        "condition": "Partly cloudy",
        "humidity": "65%",
    }


if __name__ == "__main__":
    mcp.run(transport="streamable-http")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/oauth_server.py"&gt;examples/snippets/servers/oauth_server.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;For a complete example with separate Authorization Server and Resource Server implementations, see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/examples/servers/simple-auth/"&gt;&lt;code&gt;examples/servers/simple-auth/&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Architecture:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Authorization Server (AS)&lt;/strong&gt;: Handles OAuth flows, user authentication, and token issuance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Resource Server (RS)&lt;/strong&gt;: Your MCP server that validates tokens and serves protected resources&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Client&lt;/strong&gt;: Discovers AS through RFC 9728, obtains tokens, and uses them with the MCP server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/src/mcp/server/auth/provider.py"&gt;TokenVerifier&lt;/a&gt; for more details on implementing token validation.&lt;/p&gt; 
&lt;h3&gt;FastMCP Properties&lt;/h3&gt; 
&lt;p&gt;The FastMCP server instance accessible via &lt;code&gt;ctx.fastmcp&lt;/code&gt; provides access to server configuration and metadata:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ctx.fastmcp.name&lt;/code&gt; - The server's name as defined during initialization&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctx.fastmcp.instructions&lt;/code&gt; - Server instructions/description provided to clients&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctx.fastmcp.website_url&lt;/code&gt; - Optional website URL for the server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctx.fastmcp.icons&lt;/code&gt; - Optional list of icons for UI display&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctx.fastmcp.settings&lt;/code&gt; - Complete server configuration object containing: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;debug&lt;/code&gt; - Debug mode flag&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;log_level&lt;/code&gt; - Current logging level&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;host&lt;/code&gt; and &lt;code&gt;port&lt;/code&gt; - Server network configuration&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;mount_path&lt;/code&gt;, &lt;code&gt;sse_path&lt;/code&gt;, &lt;code&gt;streamable_http_path&lt;/code&gt; - Transport paths&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;stateless_http&lt;/code&gt; - Whether the server operates in stateless mode&lt;/li&gt; 
   &lt;li&gt;And other configuration options&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@mcp.tool()
def server_info(ctx: Context) -&amp;gt; dict:
    """Get information about the current server."""
    return {
        "name": ctx.fastmcp.name,
        "instructions": ctx.fastmcp.instructions,
        "debug_mode": ctx.fastmcp.settings.debug,
        "log_level": ctx.fastmcp.settings.log_level,
        "host": ctx.fastmcp.settings.host,
        "port": ctx.fastmcp.settings.port,
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Session Properties and Methods&lt;/h3&gt; 
&lt;p&gt;The session object accessible via &lt;code&gt;ctx.session&lt;/code&gt; provides advanced control over client communication:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ctx.session.client_params&lt;/code&gt; - Client initialization parameters and declared capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.session.send_log_message(level, data, logger)&lt;/code&gt; - Send log messages with full control&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.session.create_message(messages, max_tokens)&lt;/code&gt; - Request LLM sampling/completion&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.session.send_progress_notification(token, progress, total, message)&lt;/code&gt; - Direct progress updates&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.session.send_resource_updated(uri)&lt;/code&gt; - Notify clients that a specific resource changed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.session.send_resource_list_changed()&lt;/code&gt; - Notify clients that the resource list changed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.session.send_tool_list_changed()&lt;/code&gt; - Notify clients that the tool list changed&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;await ctx.session.send_prompt_list_changed()&lt;/code&gt; - Notify clients that the prompt list changed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;@mcp.tool()
async def notify_data_update(resource_uri: str, ctx: Context) -&amp;gt; str:
    """Update data and notify clients of the change."""
    # Perform data update logic here
    
    # Notify clients that this specific resource changed
    await ctx.session.send_resource_updated(AnyUrl(resource_uri))
    
    # If this affects the overall resource list, notify about that too
    await ctx.session.send_resource_list_changed()
    
    return f"Updated {resource_uri} and notified clients"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Request Context Properties&lt;/h3&gt; 
&lt;p&gt;The request context accessible via &lt;code&gt;ctx.request_context&lt;/code&gt; contains request-specific information and resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ctx.request_context.lifespan_context&lt;/code&gt; - Access to resources initialized during server startup 
  &lt;ul&gt; 
   &lt;li&gt;Database connections, configuration objects, shared services&lt;/li&gt; 
   &lt;li&gt;Type-safe access to resources defined in your server's lifespan function&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctx.request_context.meta&lt;/code&gt; - Request metadata from the client including: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;progressToken&lt;/code&gt; - Token for progress notifications&lt;/li&gt; 
   &lt;li&gt;Other client-provided metadata&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctx.request_context.request&lt;/code&gt; - The original MCP request object for advanced processing&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ctx.request_context.request_id&lt;/code&gt; - Unique identifier for this request&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Example with typed lifespan context
@dataclass
class AppContext:
    db: Database
    config: AppConfig

@mcp.tool()
def query_with_config(query: str, ctx: Context) -&amp;gt; str:
    """Execute a query using shared database and configuration."""
    # Access typed lifespan context
    app_ctx: AppContext = ctx.request_context.lifespan_context
    
    # Use shared resources
    connection = app_ctx.db
    settings = app_ctx.config
    
    # Execute query with configuration
    result = connection.execute(query, timeout=settings.query_timeout)
    return str(result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full lifespan example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/lifespan_example.py"&gt;examples/snippets/servers/lifespan_example.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Running Your Server&lt;/h2&gt; 
&lt;h3&gt;Development Mode&lt;/h3&gt; 
&lt;p&gt;The fastest way to test and debug your server is with the MCP Inspector:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run mcp dev server.py

# Add dependencies
uv run mcp dev server.py --with pandas --with numpy

# Mount local code
uv run mcp dev server.py --with-editable .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Claude Desktop Integration&lt;/h3&gt; 
&lt;p&gt;Once your server is ready, install it in Claude Desktop:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv run mcp install server.py

# Custom name
uv run mcp install server.py --name "My Analytics Server"

# Environment variables
uv run mcp install server.py -v API_KEY=abc123 -v DB_URL=postgres://...
uv run mcp install server.py -f .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Direct Execution&lt;/h3&gt; 
&lt;p&gt;For advanced scenarios like custom deployments:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/direct_execution.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""Example showing direct execution of an MCP server.

This is the simplest way to run an MCP server directly.
cd to the `examples/snippets` directory and run:
    uv run direct-execution-server
    or
    python servers/direct_execution.py
"""

from mcp.server.fastmcp import FastMCP

mcp = FastMCP("My App")


@mcp.tool()
def hello(name: str = "World") -&amp;gt; str:
    """Say hello to someone."""
    return f"Hello, {name}!"


def main():
    """Entry point for the direct execution server."""
    mcp.run()


if __name__ == "__main__":
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/direct_execution.py"&gt;examples/snippets/servers/direct_execution.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;Run it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python servers/direct_execution.py
# or
uv run mcp run servers/direct_execution.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that &lt;code&gt;uv run mcp run&lt;/code&gt; or &lt;code&gt;uv run mcp dev&lt;/code&gt; only supports server using FastMCP and not the low-level server variant.&lt;/p&gt; 
&lt;h3&gt;Streamable HTTP Transport&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Streamable HTTP transport is superseding SSE transport for production deployments.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;!-- snippet-source examples/snippets/servers/streamable_config.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Run from the repository root:
    uv run examples/snippets/servers/streamable_config.py
"""

from mcp.server.fastmcp import FastMCP

# Stateful server (maintains session state)
mcp = FastMCP("StatefulServer")

# Other configuration options:
# Stateless server (no session persistence)
# mcp = FastMCP("StatelessServer", stateless_http=True)

# Stateless server (no session persistence, no sse stream with supported client)
# mcp = FastMCP("StatelessServer", stateless_http=True, json_response=True)


# Add a simple tool to demonstrate the server
@mcp.tool()
def greet(name: str = "World") -&amp;gt; str:
    """Greet someone by name."""
    return f"Hello, {name}!"


# Run server with streamable_http transport
if __name__ == "__main__":
    mcp.run(transport="streamable-http")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/streamable_config.py"&gt;examples/snippets/servers/streamable_config.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;You can mount multiple FastMCP servers in a Starlette application:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/streamable_starlette_mount.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Run from the repository root:
    uvicorn examples.snippets.servers.streamable_starlette_mount:app --reload
"""

import contextlib

from starlette.applications import Starlette
from starlette.routing import Mount

from mcp.server.fastmcp import FastMCP

# Create the Echo server
echo_mcp = FastMCP(name="EchoServer", stateless_http=True)


@echo_mcp.tool()
def echo(message: str) -&amp;gt; str:
    """A simple echo tool"""
    return f"Echo: {message}"


# Create the Math server
math_mcp = FastMCP(name="MathServer", stateless_http=True)


@math_mcp.tool()
def add_two(n: int) -&amp;gt; int:
    """Tool to add two to the input"""
    return n + 2


# Create a combined lifespan to manage both session managers
@contextlib.asynccontextmanager
async def lifespan(app: Starlette):
    async with contextlib.AsyncExitStack() as stack:
        await stack.enter_async_context(echo_mcp.session_manager.run())
        await stack.enter_async_context(math_mcp.session_manager.run())
        yield


# Create the Starlette app and mount the MCP servers
app = Starlette(
    routes=[
        Mount("/echo", echo_mcp.streamable_http_app()),
        Mount("/math", math_mcp.streamable_http_app()),
    ],
    lifespan=lifespan,
)

# Note: Clients connect to http://localhost:8000/echo/mcp and http://localhost:8000/math/mcp
# To mount at the root of each path (e.g., /echo instead of /echo/mcp):
# echo_mcp.settings.streamable_http_path = "/"
# math_mcp.settings.streamable_http_path = "/"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/streamable_starlette_mount.py"&gt;examples/snippets/servers/streamable_starlette_mount.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;For low level server with Streamable HTTP implementations, see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Stateful server: &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/examples/servers/simple-streamablehttp/"&gt;&lt;code&gt;examples/servers/simple-streamablehttp/&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Stateless server: &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/examples/servers/simple-streamablehttp-stateless/"&gt;&lt;code&gt;examples/servers/simple-streamablehttp-stateless/&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The streamable HTTP transport supports:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Stateful and stateless operation modes&lt;/li&gt; 
 &lt;li&gt;Resumability with event stores&lt;/li&gt; 
 &lt;li&gt;JSON or SSE response formats&lt;/li&gt; 
 &lt;li&gt;Better scalability for multi-node deployments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;CORS Configuration for Browser-Based Clients&lt;/h4&gt; 
&lt;p&gt;If you'd like your server to be accessible by browser-based MCP clients, you'll need to configure CORS headers. The &lt;code&gt;Mcp-Session-Id&lt;/code&gt; header must be exposed for browser clients to access it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from starlette.applications import Starlette
from starlette.middleware.cors import CORSMiddleware

# Create your Starlette app first
starlette_app = Starlette(routes=[...])

# Then wrap it with CORS middleware
starlette_app = CORSMiddleware(
    starlette_app,
    allow_origins=["*"],  # Configure appropriately for production
    allow_methods=["GET", "POST", "DELETE"],  # MCP streamable HTTP methods
    expose_headers=["Mcp-Session-Id"],
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This configuration is necessary because:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The MCP streamable HTTP transport uses the &lt;code&gt;Mcp-Session-Id&lt;/code&gt; header for session management&lt;/li&gt; 
 &lt;li&gt;Browsers restrict access to response headers unless explicitly exposed via CORS&lt;/li&gt; 
 &lt;li&gt;Without this configuration, browser-based clients won't be able to read the session ID from initialization responses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Mounting to an Existing ASGI Server&lt;/h3&gt; 
&lt;p&gt;By default, SSE servers are mounted at &lt;code&gt;/sse&lt;/code&gt; and Streamable HTTP servers are mounted at &lt;code&gt;/mcp&lt;/code&gt;. You can customize these paths using the methods described below.&lt;/p&gt; 
&lt;p&gt;For more information on mounting applications in Starlette, see the &lt;a href="https://www.starlette.io/routing/#submounting-routes"&gt;Starlette documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;StreamableHTTP servers&lt;/h4&gt; 
&lt;p&gt;You can mount the StreamableHTTP server to an existing ASGI server using the &lt;code&gt;streamable_http_app&lt;/code&gt; method. This allows you to integrate the StreamableHTTP server with other ASGI applications.&lt;/p&gt; 
&lt;h5&gt;Basic mounting&lt;/h5&gt; 
&lt;!-- snippet-source examples/snippets/servers/streamable_http_basic_mounting.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Basic example showing how to mount StreamableHTTP server in Starlette.

Run from the repository root:
    uvicorn examples.snippets.servers.streamable_http_basic_mounting:app --reload
"""

from starlette.applications import Starlette
from starlette.routing import Mount

from mcp.server.fastmcp import FastMCP

# Create MCP server
mcp = FastMCP("My App")


@mcp.tool()
def hello() -&amp;gt; str:
    """A simple hello tool"""
    return "Hello from MCP!"


# Mount the StreamableHTTP server to the existing ASGI server
app = Starlette(
    routes=[
        Mount("/", app=mcp.streamable_http_app()),
    ]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/streamable_http_basic_mounting.py"&gt;examples/snippets/servers/streamable_http_basic_mounting.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h5&gt;Host-based routing&lt;/h5&gt; 
&lt;!-- snippet-source examples/snippets/servers/streamable_http_host_mounting.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Example showing how to mount StreamableHTTP server using Host-based routing.

Run from the repository root:
    uvicorn examples.snippets.servers.streamable_http_host_mounting:app --reload
"""

from starlette.applications import Starlette
from starlette.routing import Host

from mcp.server.fastmcp import FastMCP

# Create MCP server
mcp = FastMCP("MCP Host App")


@mcp.tool()
def domain_info() -&amp;gt; str:
    """Get domain-specific information"""
    return "This is served from mcp.acme.corp"


# Mount using Host-based routing
app = Starlette(
    routes=[
        Host("mcp.acme.corp", app=mcp.streamable_http_app()),
    ]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/streamable_http_host_mounting.py"&gt;examples/snippets/servers/streamable_http_host_mounting.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h5&gt;Multiple servers with path configuration&lt;/h5&gt; 
&lt;!-- snippet-source examples/snippets/servers/streamable_http_multiple_servers.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Example showing how to mount multiple StreamableHTTP servers with path configuration.

Run from the repository root:
    uvicorn examples.snippets.servers.streamable_http_multiple_servers:app --reload
"""

from starlette.applications import Starlette
from starlette.routing import Mount

from mcp.server.fastmcp import FastMCP

# Create multiple MCP servers
api_mcp = FastMCP("API Server")
chat_mcp = FastMCP("Chat Server")


@api_mcp.tool()
def api_status() -&amp;gt; str:
    """Get API status"""
    return "API is running"


@chat_mcp.tool()
def send_message(message: str) -&amp;gt; str:
    """Send a chat message"""
    return f"Message sent: {message}"


# Configure servers to mount at the root of each path
# This means endpoints will be at /api and /chat instead of /api/mcp and /chat/mcp
api_mcp.settings.streamable_http_path = "/"
chat_mcp.settings.streamable_http_path = "/"

# Mount the servers
app = Starlette(
    routes=[
        Mount("/api", app=api_mcp.streamable_http_app()),
        Mount("/chat", app=chat_mcp.streamable_http_app()),
    ]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/streamable_http_multiple_servers.py"&gt;examples/snippets/servers/streamable_http_multiple_servers.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h5&gt;Path configuration at initialization&lt;/h5&gt; 
&lt;!-- snippet-source examples/snippets/servers/streamable_http_path_config.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Example showing path configuration during FastMCP initialization.

Run from the repository root:
    uvicorn examples.snippets.servers.streamable_http_path_config:app --reload
"""

from starlette.applications import Starlette
from starlette.routing import Mount

from mcp.server.fastmcp import FastMCP

# Configure streamable_http_path during initialization
# This server will mount at the root of wherever it's mounted
mcp_at_root = FastMCP("My Server", streamable_http_path="/")


@mcp_at_root.tool()
def process_data(data: str) -&amp;gt; str:
    """Process some data"""
    return f"Processed: {data}"


# Mount at /process - endpoints will be at /process instead of /process/mcp
app = Starlette(
    routes=[
        Mount("/process", app=mcp_at_root.streamable_http_app()),
    ]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/streamable_http_path_config.py"&gt;examples/snippets/servers/streamable_http_path_config.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h4&gt;SSE servers&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: SSE transport is being superseded by &lt;a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#streamable-http"&gt;Streamable HTTP transport&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You can mount the SSE server to an existing ASGI server using the &lt;code&gt;sse_app&lt;/code&gt; method. This allows you to integrate the SSE server with other ASGI applications.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from starlette.applications import Starlette
from starlette.routing import Mount, Host
from mcp.server.fastmcp import FastMCP


mcp = FastMCP("My App")

# Mount the SSE server to the existing ASGI server
app = Starlette(
    routes=[
        Mount('/', app=mcp.sse_app()),
    ]
)

# or dynamically mount as host
app.router.routes.append(Host('mcp.acme.corp', app=mcp.sse_app()))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When mounting multiple MCP servers under different paths, you can configure the mount path in several ways:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from starlette.applications import Starlette
from starlette.routing import Mount
from mcp.server.fastmcp import FastMCP

# Create multiple MCP servers
github_mcp = FastMCP("GitHub API")
browser_mcp = FastMCP("Browser")
curl_mcp = FastMCP("Curl")
search_mcp = FastMCP("Search")

# Method 1: Configure mount paths via settings (recommended for persistent configuration)
github_mcp.settings.mount_path = "/github"
browser_mcp.settings.mount_path = "/browser"

# Method 2: Pass mount path directly to sse_app (preferred for ad-hoc mounting)
# This approach doesn't modify the server's settings permanently

# Create Starlette app with multiple mounted servers
app = Starlette(
    routes=[
        # Using settings-based configuration
        Mount("/github", app=github_mcp.sse_app()),
        Mount("/browser", app=browser_mcp.sse_app()),
        # Using direct mount path parameter
        Mount("/curl", app=curl_mcp.sse_app("/curl")),
        Mount("/search", app=search_mcp.sse_app("/search")),
    ]
)

# Method 3: For direct execution, you can also pass the mount path to run()
if __name__ == "__main__":
    search_mcp.run(transport="sse", mount_path="/search")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information on mounting applications in Starlette, see the &lt;a href="https://www.starlette.io/routing/#submounting-routes"&gt;Starlette documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Advanced Usage&lt;/h2&gt; 
&lt;h3&gt;Low-Level Server&lt;/h3&gt; 
&lt;p&gt;For more control, you can use the low-level server implementation directly. This gives you full access to the protocol and allows you to customize every aspect of your server, including lifecycle management through the lifespan API:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/lowlevel/lifespan.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Run from the repository root:
    uv run examples/snippets/servers/lowlevel/lifespan.py
"""

from collections.abc import AsyncIterator
from contextlib import asynccontextmanager
from typing import Any

import mcp.server.stdio
import mcp.types as types
from mcp.server.lowlevel import NotificationOptions, Server
from mcp.server.models import InitializationOptions


# Mock database class for example
class Database:
    """Mock database class for example."""

    @classmethod
    async def connect(cls) -&amp;gt; "Database":
        """Connect to database."""
        print("Database connected")
        return cls()

    async def disconnect(self) -&amp;gt; None:
        """Disconnect from database."""
        print("Database disconnected")

    async def query(self, query_str: str) -&amp;gt; list[dict[str, str]]:
        """Execute a query."""
        # Simulate database query
        return [{"id": "1", "name": "Example", "query": query_str}]


@asynccontextmanager
async def server_lifespan(_server: Server) -&amp;gt; AsyncIterator[dict[str, Any]]:
    """Manage server startup and shutdown lifecycle."""
    # Initialize resources on startup
    db = await Database.connect()
    try:
        yield {"db": db}
    finally:
        # Clean up on shutdown
        await db.disconnect()


# Pass lifespan to server
server = Server("example-server", lifespan=server_lifespan)


@server.list_tools()
async def handle_list_tools() -&amp;gt; list[types.Tool]:
    """List available tools."""
    return [
        types.Tool(
            name="query_db",
            description="Query the database",
            inputSchema={
                "type": "object",
                "properties": {"query": {"type": "string", "description": "SQL query to execute"}},
                "required": ["query"],
            },
        )
    ]


@server.call_tool()
async def query_db(name: str, arguments: dict[str, Any]) -&amp;gt; list[types.TextContent]:
    """Handle database query tool call."""
    if name != "query_db":
        raise ValueError(f"Unknown tool: {name}")

    # Access lifespan context
    ctx = server.request_context
    db = ctx.lifespan_context["db"]

    # Execute query
    results = await db.query(arguments["query"])

    return [types.TextContent(type="text", text=f"Query results: {results}")]


async def run():
    """Run the server with lifespan management."""
    async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="example-server",
                server_version="0.1.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                ),
            ),
        )


if __name__ == "__main__":
    import asyncio

    asyncio.run(run())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/lowlevel/lifespan.py"&gt;examples/snippets/servers/lowlevel/lifespan.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;The lifespan API provides:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A way to initialize resources when the server starts and clean them up when it stops&lt;/li&gt; 
 &lt;li&gt;Access to initialized resources through the request context in handlers&lt;/li&gt; 
 &lt;li&gt;Type-safe context passing between lifespan and request handlers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- snippet-source examples/snippets/servers/lowlevel/basic.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Run from the repository root:
uv run examples/snippets/servers/lowlevel/basic.py
"""

import asyncio

import mcp.server.stdio
import mcp.types as types
from mcp.server.lowlevel import NotificationOptions, Server
from mcp.server.models import InitializationOptions

# Create a server instance
server = Server("example-server")


@server.list_prompts()
async def handle_list_prompts() -&amp;gt; list[types.Prompt]:
    """List available prompts."""
    return [
        types.Prompt(
            name="example-prompt",
            description="An example prompt template",
            arguments=[types.PromptArgument(name="arg1", description="Example argument", required=True)],
        )
    ]


@server.get_prompt()
async def handle_get_prompt(name: str, arguments: dict[str, str] | None) -&amp;gt; types.GetPromptResult:
    """Get a specific prompt by name."""
    if name != "example-prompt":
        raise ValueError(f"Unknown prompt: {name}")

    arg1_value = (arguments or {}).get("arg1", "default")

    return types.GetPromptResult(
        description="Example prompt",
        messages=[
            types.PromptMessage(
                role="user",
                content=types.TextContent(type="text", text=f"Example prompt text with argument: {arg1_value}"),
            )
        ],
    )


async def run():
    """Run the basic low-level server."""
    async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="example",
                server_version="0.1.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                ),
            ),
        )


if __name__ == "__main__":
    asyncio.run(run())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/lowlevel/basic.py"&gt;examples/snippets/servers/lowlevel/basic.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;Caution: The &lt;code&gt;uv run mcp run&lt;/code&gt; and &lt;code&gt;uv run mcp dev&lt;/code&gt; tool doesn't support low-level server.&lt;/p&gt; 
&lt;h4&gt;Structured Output Support&lt;/h4&gt; 
&lt;p&gt;The low-level server supports structured output for tools, allowing you to return both human-readable content and machine-readable structured data. Tools can define an &lt;code&gt;outputSchema&lt;/code&gt; to validate their structured output:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/servers/lowlevel/structured_output.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Run from the repository root:
    uv run examples/snippets/servers/lowlevel/structured_output.py
"""

import asyncio
from typing import Any

import mcp.server.stdio
import mcp.types as types
from mcp.server.lowlevel import NotificationOptions, Server
from mcp.server.models import InitializationOptions

server = Server("example-server")


@server.list_tools()
async def list_tools() -&amp;gt; list[types.Tool]:
    """List available tools with structured output schemas."""
    return [
        types.Tool(
            name="get_weather",
            description="Get current weather for a city",
            inputSchema={
                "type": "object",
                "properties": {"city": {"type": "string", "description": "City name"}},
                "required": ["city"],
            },
            outputSchema={
                "type": "object",
                "properties": {
                    "temperature": {"type": "number", "description": "Temperature in Celsius"},
                    "condition": {"type": "string", "description": "Weather condition"},
                    "humidity": {"type": "number", "description": "Humidity percentage"},
                    "city": {"type": "string", "description": "City name"},
                },
                "required": ["temperature", "condition", "humidity", "city"],
            },
        )
    ]


@server.call_tool()
async def call_tool(name: str, arguments: dict[str, Any]) -&amp;gt; dict[str, Any]:
    """Handle tool calls with structured output."""
    if name == "get_weather":
        city = arguments["city"]

        # Simulated weather data - in production, call a weather API
        weather_data = {
            "temperature": 22.5,
            "condition": "partly cloudy",
            "humidity": 65,
            "city": city,  # Include the requested city
        }

        # low-level server will validate structured output against the tool's
        # output schema, and additionally serialize it into a TextContent block
        # for backwards compatibility with pre-2025-06-18 clients.
        return weather_data
    else:
        raise ValueError(f"Unknown tool: {name}")


async def run():
    """Run the structured output server."""
    async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            InitializationOptions(
                server_name="structured-output-example",
                server_version="0.1.0",
                capabilities=server.get_capabilities(
                    notification_options=NotificationOptions(),
                    experimental_capabilities={},
                ),
            ),
        )


if __name__ == "__main__":
    asyncio.run(run())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/lowlevel/structured_output.py"&gt;examples/snippets/servers/lowlevel/structured_output.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;Tools can return data in three ways:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Content only&lt;/strong&gt;: Return a list of content blocks (default behavior before spec revision 2025-06-18)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Structured data only&lt;/strong&gt;: Return a dictionary that will be serialized to JSON (Introduced in spec revision 2025-06-18)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Both&lt;/strong&gt;: Return a tuple of (content, structured_data) preferred option to use for backwards compatibility&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;When an &lt;code&gt;outputSchema&lt;/code&gt; is defined, the server automatically validates the structured output against the schema. This ensures type safety and helps catch errors early.&lt;/p&gt; 
&lt;h3&gt;Pagination (Advanced)&lt;/h3&gt; 
&lt;p&gt;For servers that need to handle large datasets, the low-level server provides paginated versions of list operations. This is an optional optimization - most servers won't need pagination unless they're dealing with hundreds or thousands of items.&lt;/p&gt; 
&lt;h4&gt;Server-side Implementation&lt;/h4&gt; 
&lt;!-- snippet-source examples/snippets/servers/pagination_example.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Example of implementing pagination with MCP server decorators.
"""

from pydantic import AnyUrl

import mcp.types as types
from mcp.server.lowlevel import Server

# Initialize the server
server = Server("paginated-server")

# Sample data to paginate
ITEMS = [f"Item {i}" for i in range(1, 101)]  # 100 items


@server.list_resources()
async def list_resources_paginated(request: types.ListResourcesRequest) -&amp;gt; types.ListResourcesResult:
    """List resources with pagination support."""
    page_size = 10

    # Extract cursor from request params
    cursor = request.params.cursor if request.params is not None else None

    # Parse cursor to get offset
    start = 0 if cursor is None else int(cursor)
    end = start + page_size

    # Get page of resources
    page_items = [
        types.Resource(uri=AnyUrl(f"resource://items/{item}"), name=item, description=f"Description for {item}")
        for item in ITEMS[start:end]
    ]

    # Determine next cursor
    next_cursor = str(end) if end &amp;lt; len(ITEMS) else None

    return types.ListResourcesResult(resources=page_items, nextCursor=next_cursor)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/servers/pagination_example.py"&gt;examples/snippets/servers/pagination_example.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h4&gt;Client-side Consumption&lt;/h4&gt; 
&lt;!-- snippet-source examples/snippets/clients/pagination_client.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Example of consuming paginated MCP endpoints from a client.
"""

import asyncio

from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client
from mcp.types import Resource


async def list_all_resources() -&amp;gt; None:
    """Fetch all resources using pagination."""
    async with stdio_client(StdioServerParameters(command="uv", args=["run", "mcp-simple-pagination"])) as (
        read,
        write,
    ):
        async with ClientSession(read, write) as session:
            await session.initialize()

            all_resources: list[Resource] = []
            cursor = None

            while True:
                # Fetch a page of resources
                result = await session.list_resources(cursor=cursor)
                all_resources.extend(result.resources)

                print(f"Fetched {len(result.resources)} resources")

                # Check if there are more pages
                if result.nextCursor:
                    cursor = result.nextCursor
                else:
                    break

            print(f"Total resources: {len(all_resources)}")


if __name__ == "__main__":
    asyncio.run(list_all_resources())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/clients/pagination_client.py"&gt;examples/snippets/clients/pagination_client.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h4&gt;Key Points&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cursors are opaque strings&lt;/strong&gt; - the server defines the format (numeric offsets, timestamps, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Return &lt;code&gt;nextCursor=None&lt;/code&gt;&lt;/strong&gt; when there are no more pages&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backward compatible&lt;/strong&gt; - clients that don't support pagination will still work (they'll just get the first page)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible page sizes&lt;/strong&gt; - Each endpoint can define its own page size based on data characteristics&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/examples/servers/simple-pagination"&gt;simple-pagination example&lt;/a&gt; for a complete implementation.&lt;/p&gt; 
&lt;h3&gt;Writing MCP Clients&lt;/h3&gt; 
&lt;p&gt;The SDK provides a high-level client interface for connecting to MCP servers using various &lt;a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/transports"&gt;transports&lt;/a&gt;:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/clients/stdio_client.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
cd to the `examples/snippets/clients` directory and run:
    uv run client
"""

import asyncio
import os

from pydantic import AnyUrl

from mcp import ClientSession, StdioServerParameters, types
from mcp.client.stdio import stdio_client
from mcp.shared.context import RequestContext

# Create server parameters for stdio connection
server_params = StdioServerParameters(
    command="uv",  # Using uv to run the server
    args=["run", "server", "fastmcp_quickstart", "stdio"],  # We're already in snippets dir
    env={"UV_INDEX": os.environ.get("UV_INDEX", "")},
)


# Optional: create a sampling callback
async def handle_sampling_message(
    context: RequestContext[ClientSession, None], params: types.CreateMessageRequestParams
) -&amp;gt; types.CreateMessageResult:
    print(f"Sampling request: {params.messages}")
    return types.CreateMessageResult(
        role="assistant",
        content=types.TextContent(
            type="text",
            text="Hello, world! from model",
        ),
        model="gpt-3.5-turbo",
        stopReason="endTurn",
    )


async def run():
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write, sampling_callback=handle_sampling_message) as session:
            # Initialize the connection
            await session.initialize()

            # List available prompts
            prompts = await session.list_prompts()
            print(f"Available prompts: {[p.name for p in prompts.prompts]}")

            # Get a prompt (greet_user prompt from fastmcp_quickstart)
            if prompts.prompts:
                prompt = await session.get_prompt("greet_user", arguments={"name": "Alice", "style": "friendly"})
                print(f"Prompt result: {prompt.messages[0].content}")

            # List available resources
            resources = await session.list_resources()
            print(f"Available resources: {[r.uri for r in resources.resources]}")

            # List available tools
            tools = await session.list_tools()
            print(f"Available tools: {[t.name for t in tools.tools]}")

            # Read a resource (greeting resource from fastmcp_quickstart)
            resource_content = await session.read_resource(AnyUrl("greeting://World"))
            content_block = resource_content.contents[0]
            if isinstance(content_block, types.TextContent):
                print(f"Resource content: {content_block.text}")

            # Call a tool (add tool from fastmcp_quickstart)
            result = await session.call_tool("add", arguments={"a": 5, "b": 3})
            result_unstructured = result.content[0]
            if isinstance(result_unstructured, types.TextContent):
                print(f"Tool result: {result_unstructured.text}")
            result_structured = result.structuredContent
            print(f"Structured tool result: {result_structured}")


def main():
    """Entry point for the client script."""
    asyncio.run(run())


if __name__ == "__main__":
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/clients/stdio_client.py"&gt;examples/snippets/clients/stdio_client.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;Clients can also connect using &lt;a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#streamable-http"&gt;Streamable HTTP transport&lt;/a&gt;:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/clients/streamable_basic.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Run from the repository root:
    uv run examples/snippets/clients/streamable_basic.py
"""

import asyncio

from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client


async def main():
    # Connect to a streamable HTTP server
    async with streamablehttp_client("http://localhost:8000/mcp") as (
        read_stream,
        write_stream,
        _,
    ):
        # Create a session using the client streams
        async with ClientSession(read_stream, write_stream) as session:
            # Initialize the connection
            await session.initialize()
            # List available tools
            tools = await session.list_tools()
            print(f"Available tools: {[tool.name for tool in tools.tools]}")


if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/clients/streamable_basic.py"&gt;examples/snippets/clients/streamable_basic.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;h3&gt;Client Display Utilities&lt;/h3&gt; 
&lt;p&gt;When building MCP clients, the SDK provides utilities to help display human-readable names for tools, resources, and prompts:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/clients/display_utilities.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
cd to the `examples/snippets` directory and run:
    uv run display-utilities-client
"""

import asyncio
import os

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from mcp.shared.metadata_utils import get_display_name

# Create server parameters for stdio connection
server_params = StdioServerParameters(
    command="uv",  # Using uv to run the server
    args=["run", "server", "fastmcp_quickstart", "stdio"],
    env={"UV_INDEX": os.environ.get("UV_INDEX", "")},
)


async def display_tools(session: ClientSession):
    """Display available tools with human-readable names"""
    tools_response = await session.list_tools()

    for tool in tools_response.tools:
        # get_display_name() returns the title if available, otherwise the name
        display_name = get_display_name(tool)
        print(f"Tool: {display_name}")
        if tool.description:
            print(f"   {tool.description}")


async def display_resources(session: ClientSession):
    """Display available resources with human-readable names"""
    resources_response = await session.list_resources()

    for resource in resources_response.resources:
        display_name = get_display_name(resource)
        print(f"Resource: {display_name} ({resource.uri})")

    templates_response = await session.list_resource_templates()
    for template in templates_response.resourceTemplates:
        display_name = get_display_name(template)
        print(f"Resource Template: {display_name}")


async def run():
    """Run the display utilities example."""
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # Initialize the connection
            await session.initialize()

            print("=== Available Tools ===")
            await display_tools(session)

            print("\n=== Available Resources ===")
            await display_resources(session)


def main():
    """Entry point for the display utilities client."""
    asyncio.run(run())


if __name__ == "__main__":
    main()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/clients/display_utilities.py"&gt;examples/snippets/clients/display_utilities.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;The &lt;code&gt;get_display_name()&lt;/code&gt; function implements the proper precedence rules for displaying names:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For tools: &lt;code&gt;title&lt;/code&gt; &amp;gt; &lt;code&gt;annotations.title&lt;/code&gt; &amp;gt; &lt;code&gt;name&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;For other objects: &lt;code&gt;title&lt;/code&gt; &amp;gt; &lt;code&gt;name&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This ensures your client UI shows the most user-friendly names that servers provide.&lt;/p&gt; 
&lt;h3&gt;OAuth Authentication for Clients&lt;/h3&gt; 
&lt;p&gt;The SDK includes &lt;a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/authorization"&gt;authorization support&lt;/a&gt; for connecting to protected MCP servers:&lt;/p&gt; 
&lt;!-- snippet-source examples/snippets/clients/oauth_client.py --&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""
Before running, specify running MCP RS server URL.
To spin up RS server locally, see
    examples/servers/simple-auth/README.md

cd to the `examples/snippets` directory and run:
    uv run oauth-client
"""

import asyncio
from urllib.parse import parse_qs, urlparse

from pydantic import AnyUrl

from mcp import ClientSession
from mcp.client.auth import OAuthClientProvider, TokenStorage
from mcp.client.streamable_http import streamablehttp_client
from mcp.shared.auth import OAuthClientInformationFull, OAuthClientMetadata, OAuthToken


class InMemoryTokenStorage(TokenStorage):
    """Demo In-memory token storage implementation."""

    def __init__(self):
        self.tokens: OAuthToken | None = None
        self.client_info: OAuthClientInformationFull | None = None

    async def get_tokens(self) -&amp;gt; OAuthToken | None:
        """Get stored tokens."""
        return self.tokens

    async def set_tokens(self, tokens: OAuthToken) -&amp;gt; None:
        """Store tokens."""
        self.tokens = tokens

    async def get_client_info(self) -&amp;gt; OAuthClientInformationFull | None:
        """Get stored client information."""
        return self.client_info

    async def set_client_info(self, client_info: OAuthClientInformationFull) -&amp;gt; None:
        """Store client information."""
        self.client_info = client_info


async def handle_redirect(auth_url: str) -&amp;gt; None:
    print(f"Visit: {auth_url}")


async def handle_callback() -&amp;gt; tuple[str, str | None]:
    callback_url = input("Paste callback URL: ")
    params = parse_qs(urlparse(callback_url).query)
    return params["code"][0], params.get("state", [None])[0]


async def main():
    """Run the OAuth client example."""
    oauth_auth = OAuthClientProvider(
        server_url="http://localhost:8001",
        client_metadata=OAuthClientMetadata(
            client_name="Example MCP Client",
            redirect_uris=[AnyUrl("http://localhost:3000/callback")],
            grant_types=["authorization_code", "refresh_token"],
            response_types=["code"],
            scope="user",
        ),
        storage=InMemoryTokenStorage(),
        redirect_handler=handle_redirect,
        callback_handler=handle_callback,
    )

    async with streamablehttp_client("http://localhost:8001/mcp", auth=oauth_auth) as (read, write, _):
        async with ClientSession(read, write) as session:
            await session.initialize()

            tools = await session.list_tools()
            print(f"Available tools: {[tool.name for tool in tools.tools]}")

            resources = await session.list_resources()
            print(f"Available resources: {[r.uri for r in resources.resources]}")


def run():
    asyncio.run(main())


if __name__ == "__main__":
    run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;Full example: &lt;a href="https://github.com/modelcontextprotocol/python-sdk/raw/main/examples/snippets/clients/oauth_client.py"&gt;examples/snippets/clients/oauth_client.py&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;!-- /snippet-source --&gt; 
&lt;p&gt;For a complete working example, see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/examples/clients/simple-auth-client/"&gt;&lt;code&gt;examples/clients/simple-auth-client/&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Parsing Tool Results&lt;/h3&gt; 
&lt;p&gt;When calling tools through MCP, the &lt;code&gt;CallToolResult&lt;/code&gt; object contains the tool's response in a structured format. Understanding how to parse this result is essential for properly handling tool outputs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;"""examples/snippets/clients/parsing_tool_results.py"""

import asyncio

from mcp import ClientSession, StdioServerParameters, types
from mcp.client.stdio import stdio_client


async def parse_tool_results():
    """Demonstrates how to parse different types of content in CallToolResult."""
    server_params = StdioServerParameters(
        command="python", args=["path/to/mcp_server.py"]
    )

    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()

            # Example 1: Parsing text content
            result = await session.call_tool("get_data", {"format": "text"})
            for content in result.content:
                if isinstance(content, types.TextContent):
                    print(f"Text: {content.text}")

            # Example 2: Parsing structured content from JSON tools
            result = await session.call_tool("get_user", {"id": "123"})
            if hasattr(result, "structuredContent") and result.structuredContent:
                # Access structured data directly
                user_data = result.structuredContent
                print(f"User: {user_data.get('name')}, Age: {user_data.get('age')}")

            # Example 3: Parsing embedded resources
            result = await session.call_tool("read_config", {})
            for content in result.content:
                if isinstance(content, types.EmbeddedResource):
                    resource = content.resource
                    if isinstance(resource, types.TextResourceContents):
                        print(f"Config from {resource.uri}: {resource.text}")
                    elif isinstance(resource, types.BlobResourceContents):
                        print(f"Binary data from {resource.uri}")

            # Example 4: Parsing image content
            result = await session.call_tool("generate_chart", {"data": [1, 2, 3]})
            for content in result.content:
                if isinstance(content, types.ImageContent):
                    print(f"Image ({content.mimeType}): {len(content.data)} bytes")

            # Example 5: Handling errors
            result = await session.call_tool("failing_tool", {})
            if result.isError:
                print("Tool execution failed!")
                for content in result.content:
                    if isinstance(content, types.TextContent):
                        print(f"Error: {content.text}")


async def main():
    await parse_tool_results()


if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;MCP Primitives&lt;/h3&gt; 
&lt;p&gt;The MCP protocol defines three core primitives that servers can implement:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Primitive&lt;/th&gt; 
   &lt;th&gt;Control&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Example Use&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Prompts&lt;/td&gt; 
   &lt;td&gt;User-controlled&lt;/td&gt; 
   &lt;td&gt;Interactive templates invoked by user choice&lt;/td&gt; 
   &lt;td&gt;Slash commands, menu options&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Resources&lt;/td&gt; 
   &lt;td&gt;Application-controlled&lt;/td&gt; 
   &lt;td&gt;Contextual data managed by the client application&lt;/td&gt; 
   &lt;td&gt;File contents, API responses&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Tools&lt;/td&gt; 
   &lt;td&gt;Model-controlled&lt;/td&gt; 
   &lt;td&gt;Functions exposed to the LLM to take actions&lt;/td&gt; 
   &lt;td&gt;API calls, data updates&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Server Capabilities&lt;/h3&gt; 
&lt;p&gt;MCP servers declare capabilities during initialization:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Capability&lt;/th&gt; 
   &lt;th&gt;Feature Flag&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;prompts&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;listChanged&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Prompt template management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;resources&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;subscribe&lt;/code&gt;&lt;br /&gt;&lt;code&gt;listChanged&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Resource exposure and updates&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;tools&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;listChanged&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Tool discovery and execution&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;logging&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;Server logging configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;completions&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;Argument completion suggestions&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://modelcontextprotocol.github.io/python-sdk/api/"&gt;API Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://modelcontextprotocol.io"&gt;Model Context Protocol documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://spec.modelcontextprotocol.io"&gt;Model Context Protocol specification&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/modelcontextprotocol/servers"&gt;Officially supported servers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We are passionate about supporting contributors of all levels of experience and would love to see you get involved in the project. See the &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>