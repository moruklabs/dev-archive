<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Sun, 28 Sep 2025 01:31:03 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>imputnet/helium</title>
      <link>https://github.com/imputnet/helium</link>
      <description>&lt;p&gt;Private, fast, and honest web browser&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;p&gt; &lt;img src="https://raw.githubusercontent.com/imputnet/helium/main/resources/branding/app_icon/raw.png" title="Helium" alt="Helium logo" width="120" /&gt; &lt;/p&gt;
 &lt;h1&gt;Helium&lt;/h1&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p width="120"&gt; The Chromium-based web browser made for people, with love. &lt;br /&gt; Best privacy by default, unbiased ad-blocking, no bloat and no noise. &lt;/p&gt; 
 &lt;a href="https://helium.computer/"&gt; helium.computer &lt;/a&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Downloads&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Helium is still in beta, so unexpected issues may occur. We are not responsible for any damage caused by usage of beta software.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Best way to download Helium is to open &lt;a href="https://helium.computer/"&gt;helium.computer&lt;/a&gt; on your computer. It'll pick the right build for your OS and architecture automatically.&lt;/p&gt; 
&lt;p&gt;If you wish to download builds "straight from the tap" with all options in one place, you can do it on GitHub in the Releases section in each platform's repo:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-macos/releases/latest"&gt;macOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-linux/releases/latest"&gt;Linux&lt;/a&gt; (AppImage)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-windows/releases/latest"&gt;Windows&lt;/a&gt; (no auto-updates yet)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Platform packaging&lt;/h2&gt; 
&lt;p&gt;Helium is available on all major desktop platforms, with entirety of source code for all of them published here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-macos"&gt;Helium for macOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-linux"&gt;Helium for Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-windows"&gt;Helium for Windows&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Other Helium repos&lt;/h2&gt; 
&lt;p&gt;Along with the main repo and platform packaging, these projects are also a part of Helium:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-services"&gt;Helium services&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/helium-onboarding"&gt;Helium onboarding&lt;/a&gt; (the onboarding page seen in Helium at &lt;code&gt;helium://setup&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/imputnet/ublock-origin-crx"&gt;uBlock Origin packaging&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;h3&gt;ungoogled-chromium&lt;/h3&gt; 
&lt;p&gt;Helium is proudly based on &lt;a href="https://github.com/ungoogled-software/ungoogled-chromium"&gt;ungoogled-chromium&lt;/a&gt;. It wouldn't be possible for us to get rid of Google's bloat and get a development+building pipeline this fast without it. Huge shout-out to everyone behind this amazing project! (and we intend to contribute even more stuff upstream in the future)&lt;/p&gt; 
&lt;h3&gt;The Chromium project&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.chromium.org/"&gt;The Chromium Project&lt;/a&gt; is obviously at the core of Helium, making it possible to exist in the first place.&lt;/p&gt; 
&lt;h3&gt;ungoogled-chromium's dependencies&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gcarq/inox-patchset"&gt;Inox patchset&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://tracker.debian.org/pkg/chromium-browser"&gt;Debian&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bromite/bromite"&gt;Bromite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://iridiumbrowser.de/"&gt;Iridium Browser&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;All code, patches, modified portions of imported code or patches, and any other content that is unique to Helium and not imported from other repositories is licensed under GPL-3.0. See &lt;a href="https://raw.githubusercontent.com/imputnet/helium/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Any content imported from other projects retains its original license (for example, any original unmodified code imported from ungoogled-chromium remains licensed under their &lt;a href="https://raw.githubusercontent.com/imputnet/helium/main/LICENSE.ungoogled_chromium"&gt;BSD 3-Clause license&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;More documentation (soon)&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] We will add more documentation along with design and motivation guidelines in the future. All docs will be linked here along with other related content.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Olow304/memvid</title>
      <link>https://github.com/Olow304/memvid</link>
      <description>&lt;p&gt;Video-based AI memory library. Store millions of text chunks in MP4 files with lightning-fast semantic search. No database needed.&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;What to expect in v2&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Early-access notice&lt;/strong&gt;&lt;br /&gt; Memvid v1 is still experimental. The file format and API may change until we lock in a stable release.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Memvid v2 â€“ what's next&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Living-Memory Engine&lt;/strong&gt; â€“ keep adding new data and let LLMs remember it across sessions.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Capsule Context&lt;/strong&gt; â€“ shareable &lt;code&gt;.mv2&lt;/code&gt; capsules, each with its own rules and expiry.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Time-Travel Debugging&lt;/strong&gt; â€“ rewind or branch any chat to review or test.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Smart Recall&lt;/strong&gt; â€“ local cache guesses what youâ€™ll need and loads it in under 5 ms.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Codec Intelligence&lt;/strong&gt; â€“ auto-tunes AV1 now and future codecs later, so files keep shrinking.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;CLI &amp;amp; Dashboard&lt;/strong&gt; â€“ simple tools for branching, analytics, and one-command cloud publish.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Sneak peek of Memvid v2 - a living memory engine that can be used to chat with your knowledge base. &lt;img src="https://raw.githubusercontent.com/Olow304/memvid/main/assets/mv2.png" alt="Memvid v2 Preview" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Memvid v1&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/memvid/"&gt;&lt;img src="https://img.shields.io/pypi/v/memvid" alt="PyPI" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://github.com/olow304/memvid"&gt;&lt;img src="https://img.shields.io/github/stars/olow304/memvid" alt="GitHub Stars" /&gt;&lt;/a&gt; &lt;a href="https://www.python.org/downloads/"&gt;&lt;img src="https://img.shields.io/badge/python-3.8+-blue.svg?sanitize=true" alt="Python 3.8+" /&gt;&lt;/a&gt; &lt;a href="https://github.com/psf/black"&gt;&lt;img src="https://img.shields.io/badge/code%20style-black-000000.svg?sanitize=true" alt="Code style: black" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Memvid - Turn millions of text chunks into a single, searchable video file&lt;/h1&gt; 
&lt;p&gt;Memvid compresses an entire knowledge base into &lt;strong&gt;MP4&lt;/strong&gt; files while keeping millisecond-level semantic search. Think of it as &lt;em&gt;SQLite for AI memory&lt;/em&gt; portable, efficient, and self-contained. By encoding text as &lt;strong&gt;QR codes in video frames&lt;/strong&gt;, we deliver &lt;strong&gt;50-100Ã—&lt;/strong&gt; smaller storage than vector databases with &lt;strong&gt;zero infrastructure&lt;/strong&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Why Video Compression Changes Everything ğŸš€&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;What it enables&lt;/th&gt; 
   &lt;th&gt;How video codecs make it possible&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;50-100Ã— smaller storage&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Modern video codecs compress repetitive visual patterns (QR codes) far better than raw embeddings&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Sub-100ms retrieval&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct frame seek via index â†’ QR decode â†’ your text. No server round-trips&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Zero infrastructure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Just Python and MP4 files-no DB clusters, no Docker, no ops&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;True portability&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Copy or stream &lt;code&gt;memory.mp4&lt;/code&gt;-it works anywhere video plays&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Offline-first design&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;After encoding, everything runs without internet&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Under the Hood - Memvid v1 ğŸ”&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Text â†’ QR â†’ Frame&lt;/strong&gt;&lt;br /&gt; Each text chunk becomes a QR code, packed into video frames. Modern codecs excel at compressing these repetitive patterns.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Smart indexing&lt;/strong&gt;&lt;br /&gt; Embeddings map queries â†’ frame numbers. One seek, one decode, millisecond results.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Codec leverage&lt;/strong&gt;&lt;br /&gt; 30 years of video R&amp;amp;D means your text gets compressed better than any custom algorithm could achieve.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Future-proof&lt;/strong&gt;&lt;br /&gt; Next-gen codecs (AV1, H.266) automatically make your memories smaller and faster-no code changes needed.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install memvid
# For PDF support
pip install memvid PyPDF2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from memvid import MemvidEncoder, MemvidChat

# Create video memory from text
chunks = ["NASA founded 1958", "Apollo 11 landed 1969", "ISS launched 1998"]
encoder = MemvidEncoder()
encoder.add_chunks(chunks)
encoder.build_video("space.mp4", "space_index.json")

# Chat with your memory
chat = MemvidChat("space.mp4", "space_index.json")
response = chat.chat("When did humans land on the moon?")
print(response)  # References Apollo 11 in 1969
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Real-World Examples&lt;/h2&gt; 
&lt;h3&gt;Documentation Assistant&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from memvid import MemvidEncoder
import os

encoder = MemvidEncoder(chunk_size=512)

# Index all markdown files
for file in os.listdir("docs"):
    if file.endswith(".md"):
        with open(f"docs/{file}") as f:
            encoder.add_text(f.read(), metadata={"file": file})

encoder.build_video("docs.mp4", "docs_index.json")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;PDF Library Search&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Index multiple PDFs
encoder = MemvidEncoder()
encoder.add_pdf("deep_learning.pdf")
encoder.add_pdf("machine_learning.pdf") 
encoder.build_video("ml_library.mp4", "ml_index.json")

# Semantic search across all books
from memvid import MemvidRetriever
retriever = MemvidRetriever("ml_library.mp4", "ml_index.json")
results = retriever.search("backpropagation", top_k=5)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Interactive Web UI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from memvid import MemvidInteractive

# Launch at http://localhost:7860
interactive = MemvidInteractive("knowledge.mp4", "index.json")
interactive.run()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Advanced Features&lt;/h2&gt; 
&lt;h3&gt;Scale Optimization&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Maximum compression for huge datasets
encoder.build_video(
    "compressed.mp4",
    "index.json", 
    fps=60,              # More frames/second
    frame_size=256,      # Smaller QR codes
    video_codec='h265',  # Better compression
    crf=28              # Quality tradeoff
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Custom Embeddings&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-mpnet-base-v2')
encoder = MemvidEncoder(embedding_model=model)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Parallel Processing&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;encoder = MemvidEncoder(n_workers=8)
encoder.add_chunks_parallel(million_chunks)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;CLI Usage&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Process documents
python examples/file_chat.py --input-dir /docs --provider openai

# Advanced codecs
python examples/file_chat.py --files doc.pdf --codec h265

# Load existing
python examples/file_chat.py --load-existing output/memory
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Indexing&lt;/strong&gt;: ~10K chunks/second on modern CPUs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search&lt;/strong&gt;: &amp;lt;100ms for 1M chunks (includes decode)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt;: 100MB text â†’ 1-2MB video&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt;: Constant 500MB RAM regardless of size&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What's Coming in v2&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Delta encoding&lt;/strong&gt;: Time-travel through knowledge versions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Streaming ingest&lt;/strong&gt;: Add to videos in real-time&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud dashboard&lt;/strong&gt;: Web UI with API management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart codecs&lt;/strong&gt;: Auto-select AV1/HEVC per content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPU boost&lt;/strong&gt;: 100Ã— faster bulk encoding&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Get Involved&lt;/h2&gt; 
&lt;p&gt;Memvid is redefining AI memory. Join us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;â­ Star on &lt;a href="https://github.com/olow304/memvid"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ› Report issues or request features&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ Submit PRs (we review quickly!)&lt;/li&gt; 
 &lt;li&gt;ğŸ’¬ Discuss video-based AI memory&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>directus/directus</title>
      <link>https://github.com/directus/directus</link>
      <description>&lt;p&gt;The flexible backend for all your projects ğŸ° Turn your DB into a headless CMS, admin panels, or apps with a custom UI, instant APIs, auth &amp; more.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img alt="Directus Logo" src="https://user-images.githubusercontent.com/522079/158864859-0fbeae62-9d7a-4619-b35e-f8fa5f68e0c8.png" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ° Introduction&lt;/h2&gt; 
&lt;p&gt;Directus is a real-time API and App dashboard for managing SQL database content.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;REST &amp;amp; GraphQL API.&lt;/strong&gt; Instantly layers a blazingly fast Node.js API on top of any SQL database.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manage Pure SQL.&lt;/strong&gt; Works with new or existing SQL databases, no migration required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Choose your Database.&lt;/strong&gt; Supports PostgreSQL, MySQL, SQLite, OracleDB, CockroachDB, MariaDB, and MS-SQL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;On-Prem or Cloud.&lt;/strong&gt; Run locally, install on-premises, or use our &lt;a href="https://directus.io/pricing"&gt;self-service Cloud service&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Completely Extensible.&lt;/strong&gt; Built to white-label, it is easy to customize our modular platform.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A Modern Dashboard.&lt;/strong&gt; Our no-code Vue.js app is safe and intuitive for non-technical users, no training required.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://directus.io"&gt;Learn more about Directus&lt;/a&gt;&lt;/strong&gt; â€¢ &lt;strong&gt;&lt;a href="https://docs.directus.io"&gt;Documentation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸš€ Directus Cloud&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://directus.io/pricing"&gt;Directus Cloud&lt;/a&gt; allows you to create projects, hosted by the Directus team, from $15/month.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A self-service dashboard to create and monitor all your projects in one place.&lt;/li&gt; 
 &lt;li&gt;Everything you need: Directus, database, storage, auto-scaling, and a global CDN.&lt;/li&gt; 
 &lt;li&gt;Select your desired region and provision a new project in ~90 seconds.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://directus.cloud"&gt;Create a Directus Cloud Project&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ¤” Community Help&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://docs.directus.io"&gt;The Directus Documentation&lt;/a&gt; is a great place to start, or explore these other channels:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://community.directus.io"&gt;Community&lt;/a&gt; (Questions, Discussions)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://directus.chat"&gt;Discord&lt;/a&gt; (Live Chat)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/directus/directus/issues"&gt;GitHub Issues&lt;/a&gt; (Report Bugs)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/directus/directus/discussions"&gt;GitHub Discussions&lt;/a&gt; (Feature Requests)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/directus"&gt;Twitter&lt;/a&gt; (Latest News)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/c/DirectusVideos/featured"&gt;YouTube&lt;/a&gt; (Video Tutorials)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;â¤ï¸ Contributing &amp;amp; Sponsoring&lt;/h2&gt; 
&lt;p&gt;Please read our &lt;a href="https://raw.githubusercontent.com/directus/directus/main/contributing.md"&gt;Contributing Guide&lt;/a&gt; before submitting Pull Requests.&lt;/p&gt; 
&lt;p&gt;All security vulnerabilities should be reported in accordance with our &lt;a href="https://docs.directus.io/contributing/introduction/#reporting-security-vulnerabilities"&gt;Security Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Directus is made possible with support from our passionate core team, talented contributors, and amazing &lt;a href="https://github.com/sponsors/directus"&gt;GitHub Sponsors&lt;/a&gt;. Thank you all!&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ“„ Understanding Our License&lt;/h2&gt; 
&lt;p&gt;Directus is licensed under &lt;a href="https://raw.githubusercontent.com/directus/directus/main/license"&gt;the Business Source License (BSL) 1.1&lt;/a&gt; with a permissive additional use grant. For most users, it operates just like open source! Here's what that means for you:&lt;/p&gt; 
&lt;h3&gt;Free for Most Users&lt;/h3&gt; 
&lt;p&gt;If your organization has less than $5M in annual revenue and/or funding combined, you can use Directus freely in any way you'd like. Build that side project, launch your startup, or experiment with the platform â€” no strings attached.&lt;/p&gt; 
&lt;h3&gt;Enterprise Usage&lt;/h3&gt; 
&lt;p&gt;For larger organizations (&amp;gt;$5M in annual revenue/funding) using Directus in production, we require a commercial license. This model helps us maintain a sustainable balance: keeping Directus free for the majority of our community while ensuring larger organizations who benefit from the platform contribute to its continued development.&lt;/p&gt; 
&lt;h3&gt;Why This Approach?&lt;/h3&gt; 
&lt;p&gt;We believe in making powerful data tools accessible to everyone. This license lets us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Keep Directus free for individuals, startups, and smaller companies&lt;/li&gt; 
 &lt;li&gt;Maintain active development and strong support&lt;/li&gt; 
 &lt;li&gt;Continue improving the platform for everyone&lt;/li&gt; 
 &lt;li&gt;Stay sustainable as an independent project&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>coinbase/x402</title>
      <link>https://github.com/coinbase/x402</link>
      <description>&lt;p&gt;A payments protocol for the internet. Built on HTTP.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;x402 payments protocol&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"1 line of code to accept digital dollars. No fee, 2 second settlement, $0.001 minimum payment."&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;app.use(
  // How much you want to charge, and where you want the funds to land
  paymentMiddleware("0xYourAddress", { "/your-endpoint": "$0.01" })
);
// That's it! See examples/typescript/servers/express.ts for a complete example. Instruction below for running on base-sepolia.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Philosophy&lt;/h2&gt; 
&lt;p&gt;Payments on the internet are fundamentally flawed. Credit Cards are high friction, hard to accept, have minimum payments that are far too high, and don't fit into the programmatic nature of the internet. It's time for an open, internet-native form of payments. A payment rail that doesn't have high minimums + % based fee. Payments that are amazing for humans and AI agents.&lt;/p&gt; 
&lt;h2&gt;Principles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Open standard:&lt;/strong&gt; the x402 protocol will never force reliance on a single party&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP Native:&lt;/strong&gt; x402 is meant to seamlessly complement the existing HTTP request made by traditional web services, it should not mandate additional requests outside the scope of a typical client / server flow.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chain and token agnostic:&lt;/strong&gt; we welcome contributions that add support for new chains, signing standards, or schemes, so long as they meet our acceptance criteria laid out in &lt;a href="https://github.com/coinbase/x402/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Trust minimizing:&lt;/strong&gt; all payment schemes must not allow for the facilitator or resource server to move funds, other than in accordance with client intentions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy to use:&lt;/strong&gt; x402 needs to be 10x better than existing ways to pay on the internet. This means abstracting as many details of crypto as possible away from the client and resource server, and into the facilitator. This means the client/server should not need to think about gas, rpc, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;p&gt;The x402 ecosystem is growing! Check out our &lt;a href="https://x402.org/ecosystem"&gt;ecosystem page&lt;/a&gt; to see projects building with x402, including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Client-side integrations&lt;/li&gt; 
 &lt;li&gt;Services and endpoints&lt;/li&gt; 
 &lt;li&gt;Ecosystem infrastructure and tooling&lt;/li&gt; 
 &lt;li&gt;Learning and community resources&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Want to add your project to the ecosystem? See our &lt;a href="https://github.com/coinbase/x402/tree/main/typescript/site#adding-your-project-to-the-ecosystem"&gt;demo site README&lt;/a&gt; for detailed instructions on how to submit your project.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Roadmap:&lt;/strong&gt; see &lt;a href="https://github.com/coinbase/x402/raw/main/ROADMAP.md"&gt;ROADMAP.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Terms:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;resource&lt;/code&gt;: Something on the internet. This could be a webpage, file server, RPC service, API, any resource on the internet that accepts HTTP / HTTPS requests.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;client&lt;/code&gt;: An entity wanting to pay for a resource.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;facilitator server&lt;/code&gt;: A server that facilitates verification and execution of on-chain payments.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;resource server&lt;/code&gt;: An HTTP server that provides an API or other resource for a client.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Technical Goals:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Permissionless and secure for clients and servers&lt;/li&gt; 
 &lt;li&gt;Gasless for client and resource servers&lt;/li&gt; 
 &lt;li&gt;Minimal integration for the resource server and client (1 line for the server, 1 function for the client)&lt;/li&gt; 
 &lt;li&gt;Ability to trade off speed of response for guarantee of payment&lt;/li&gt; 
 &lt;li&gt;Extensible to different payment flows and chains&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;V1 Protocol&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;x402&lt;/code&gt; protocol is a chain agnostic standard for payments on top of HTTP, leverage the existing &lt;code&gt;402 Payment Required&lt;/code&gt; HTTP status code to indicate that a payment is required for access to the resource.&lt;/p&gt; 
&lt;p&gt;It specifies:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;A schema for how servers can respond to clients to facilitate payment for a resource (&lt;code&gt;PaymentRequirements&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;A standard header &lt;code&gt;X-PAYMENT&lt;/code&gt; that is set by clients paying for resources&lt;/li&gt; 
 &lt;li&gt;A standard schema and encoding method for data in the &lt;code&gt;X-PAYMENT&lt;/code&gt; header&lt;/li&gt; 
 &lt;li&gt;A recommended flow for how payments should be verified and settled by a resource server&lt;/li&gt; 
 &lt;li&gt;A REST specification for how a resource server can perform verification and settlement against a remote 3rd party server (&lt;code&gt;facilitator&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;A specification for a &lt;code&gt;X-PAYMENT-RESPONSE&lt;/code&gt; header that can be used by resource servers to communicate blockchain transactions details to the client in their HTTP response&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;V1 Protocol Sequencing&lt;/h3&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/coinbase/x402/main/static/x402-protocol-flow.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;The following outlines the flow of a payment using the &lt;code&gt;x402&lt;/code&gt; protocol. Note that steps (1) and (2) are optional if the client already knows the payment details accepted for a resource.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Client&lt;/code&gt; makes an HTTP request to a &lt;code&gt;resource server&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; responds with a &lt;code&gt;402 Payment Required&lt;/code&gt; status and a &lt;code&gt;Payment Required Response&lt;/code&gt; JSON object in the response body.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Client&lt;/code&gt; selects one of the &lt;code&gt;paymentRequirements&lt;/code&gt; returned by the server response and creates a &lt;code&gt;Payment Payload&lt;/code&gt; based on the &lt;code&gt;scheme&lt;/code&gt; of the &lt;code&gt;paymentRequirements&lt;/code&gt; they have selected.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Client&lt;/code&gt; sends the HTTP request with the &lt;code&gt;X-PAYMENT&lt;/code&gt; header containing the &lt;code&gt;Payment Payload&lt;/code&gt; to the resource server.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; verifies the &lt;code&gt;Payment Payload&lt;/code&gt; is valid either via local verification or by POSTing the &lt;code&gt;Payment Payload&lt;/code&gt; and &lt;code&gt;Payment Requirements&lt;/code&gt; to the &lt;code&gt;/verify&lt;/code&gt; endpoint of a &lt;code&gt;facilitator server&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; performs verification of the object based on the &lt;code&gt;scheme&lt;/code&gt; and &lt;code&gt;network&lt;/code&gt; of the &lt;code&gt;Payment Payload&lt;/code&gt; and returns a &lt;code&gt;Verification Response&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If the &lt;code&gt;Verification Response&lt;/code&gt; is valid, the resource server performs the work to fulfill the request. If the &lt;code&gt;Verification Response&lt;/code&gt; is invalid, the resource server returns a &lt;code&gt;402 Payment Required&lt;/code&gt; status and a &lt;code&gt;Payment Required Response&lt;/code&gt; JSON object in the response body.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; either settles the payment by interacting with a blockchain directly, or by POSTing the &lt;code&gt;Payment Payload&lt;/code&gt; and &lt;code&gt;Payment PaymentRequirements&lt;/code&gt; to the &lt;code&gt;/settle&lt;/code&gt; endpoint of a &lt;code&gt;facilitator server&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; submits the payment to the blockchain based on the &lt;code&gt;scheme&lt;/code&gt; and &lt;code&gt;network&lt;/code&gt; of the &lt;code&gt;Payment Payload&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; waits for the payment to be confirmed on the blockchain.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Facilitator server&lt;/code&gt; returns a &lt;code&gt;Payment Execution Response&lt;/code&gt; to the resource server.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;Resource server&lt;/code&gt; returns a &lt;code&gt;200 OK&lt;/code&gt; response to the &lt;code&gt;Client&lt;/code&gt; with the resource they requested as the body of the HTTP response, and a &lt;code&gt;X-PAYMENT-RESPONSE&lt;/code&gt; header containing the &lt;code&gt;Settlement Response&lt;/code&gt; as Base64 encoded JSON if the payment was executed successfully.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Type Specifications&lt;/h3&gt; 
&lt;h4&gt;Data types&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Payment Required Response&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Version of the x402 payment protocol
  x402Version: int,

  // List of payment requirements that the resource server accepts. A resource server may accept on multiple chains, or in multiple currencies.
  accepts: [paymentRequirements]

  // Message from the resource server to the client to communicate errors in processing payment
  error: string
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;paymentRequirements&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Scheme of the payment protocol to use
  scheme: string;

  // Network of the blockchain to send payment on
  network: string;

  // Maximum amount required to pay for the resource in atomic units of the asset
  maxAmountRequired: uint256 as string;

  // URL of resource to pay for
  resource: string;

  // Description of the resource
  description: string;

  // MIME type of the resource response
  mimeType: string;

  // Output schema of the resource response
  outputSchema?: object | null;

  // Address to pay value to
  payTo: string;

  // Maximum time in seconds for the resource server to respond
  maxTimeoutSeconds: number;

  // Address of the EIP-3009 compliant ERC20 contract
  asset: string;

  // Extra information about the payment details specific to the scheme
  // For `exact` scheme on a EVM network, expects extra to contain the records `name` and `version` pertaining to asset
  extra: object | null;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;code&gt;Payment Payload&lt;/code&gt;&lt;/strong&gt; (included as the &lt;code&gt;X-PAYMENT&lt;/code&gt; header in base64 encoded json)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Version of the x402 payment protocol
  x402Version: number;

  // scheme is the scheme value of the accepted `paymentRequirements` the client is using to pay
  scheme: string;

  // network is the network id of the accepted `paymentRequirements` the client is using to pay
  network: string;

  // payload is scheme dependent
  payload: &amp;lt;scheme dependent&amp;gt;;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Facilitator Types &amp;amp; Interface&lt;/h4&gt; 
&lt;p&gt;A &lt;code&gt;facilitator server&lt;/code&gt; is a 3rd party service that can be used by a &lt;code&gt;resource server&lt;/code&gt; to verify and settle payments, without the &lt;code&gt;resource server&lt;/code&gt; needing to have access to a blockchain node or wallet.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;POST /verify&lt;/strong&gt;. Verify a payment with a supported scheme and network:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Request body JSON: &lt;pre&gt;&lt;code class="language-json5"&gt;{
  x402Version: number;
  paymentHeader: string;
  paymentRequirements: paymentRequirements;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Response: &lt;pre&gt;&lt;code class="language-json5"&gt;{
  isValid: boolean;
  invalidReason: string | null;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;POST /settle&lt;/strong&gt;. Settle a payment with a supported scheme and network:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Request body JSON:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json5"&gt;{
  x402Version: number;
  paymentHeader: string;
  paymentRequirements: paymentRequirements;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Response:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-json5"&gt;{
  // Whether the payment was successful
  success: boolean;

  // Error message from the facilitator server
  error: string | null;

  // Transaction hash of the settled payment
  txHash: string | null;

  // Network id of the blockchain the payment was settled on
  networkId: string | null;
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;GET /supported&lt;/strong&gt;. Get supported payment schemes and networks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Response: &lt;pre&gt;&lt;code class="language-json5"&gt;{
  kinds: [
    {
      "scheme": string,
      "network": string,
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Schemes&lt;/h3&gt; 
&lt;p&gt;A scheme is a logical way of moving money.&lt;/p&gt; 
&lt;p&gt;Blockchains allow for a large number of flexible ways to move money. To help facilitate an expanding number of payment use cases, the &lt;code&gt;x402&lt;/code&gt; protocol is extensible to different ways of settling payments via its &lt;code&gt;scheme&lt;/code&gt; field.&lt;/p&gt; 
&lt;p&gt;Each payment scheme may have different operational functionality depending on what actions are necessary to fulfill the payment. For example &lt;code&gt;exact&lt;/code&gt;, the first scheme shipping as part of the protocol, would have different behavior than &lt;code&gt;upto&lt;/code&gt;. &lt;code&gt;exact&lt;/code&gt; transfers a specific amount (ex: pay $1 to read an article), while a theoretical &lt;code&gt;upto&lt;/code&gt; would transfer up to an amount, based on the resources consumed during a request (ex: generating tokens from an LLM).&lt;/p&gt; 
&lt;p&gt;See &lt;code&gt;specs/schemes&lt;/code&gt; for more details on schemes, and see &lt;code&gt;specs/schemes/exact/scheme_exact_evm.md&lt;/code&gt; to see the first proposed scheme for exact payment on EVM chains.&lt;/p&gt; 
&lt;h3&gt;Schemes vs Networks&lt;/h3&gt; 
&lt;p&gt;Because a scheme is a logical way of moving money, the way a scheme is implemented can be different for different blockchains. (ex: the way you need to implement &lt;code&gt;exact&lt;/code&gt; on Ethereum is very different from the way you need to implement &lt;code&gt;exact&lt;/code&gt; on Solana).&lt;/p&gt; 
&lt;p&gt;Clients and facilitators must explicitly support different &lt;code&gt;(scheme, network)&lt;/code&gt; pairs in order to be able to create proper payloads and verify / settle payments.&lt;/p&gt; 
&lt;h2&gt;Running example&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt; Node.js v24 or higher&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;From &lt;code&gt;examples/typescript&lt;/code&gt; run &lt;code&gt;pnpm install&lt;/code&gt; and &lt;code&gt;pnpm build&lt;/code&gt; to ensure all dependent packages and examples are setup.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Select a server, i.e. express, and &lt;code&gt;cd&lt;/code&gt; into that example. Add your server's ethereum address to get paid to into the &lt;code&gt;.env&lt;/code&gt; file, and then run &lt;code&gt;pnpm dev&lt;/code&gt; in that directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Select a client, i.e. axios, and &lt;code&gt;cd&lt;/code&gt; into that example. Add your private key for the account making payments into the &lt;code&gt;.env&lt;/code&gt; file, and then run &lt;code&gt;pnpm dev&lt;/code&gt; in that directory.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You should see activities in the client terminal, which will display a weather report.&lt;/p&gt; 
&lt;h2&gt;Running tests&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Navigate to the typescript directory: &lt;code&gt;cd typescript&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install dependencies: &lt;code&gt;pnpm install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run the unit tests: &lt;code&gt;pnpm test&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This will run the unit tests for the x402 packages.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>harry0703/MoneyPrinterTurbo</title>
      <link>https://github.com/harry0703/MoneyPrinterTurbo</link>
      <description>&lt;p&gt;åˆ©ç”¨AIå¤§æ¨¡å‹ï¼Œä¸€é”®ç”Ÿæˆé«˜æ¸…çŸ­è§†é¢‘ Generate short videos with one click using AI LLM.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1 align="center"&gt;MoneyPrinterTurbo ğŸ’¸&lt;/h1&gt; 
 &lt;p align="center"&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;&lt;img src="https://img.shields.io/github/issues/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge" alt="License" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;ç®€ä½“ä¸­æ–‡ | &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/README-en.md"&gt;English&lt;/a&gt;&lt;/h3&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/8731" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/8731" alt="harry0703%2FMoneyPrinterTurbo | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; åªéœ€æä¾›ä¸€ä¸ªè§†é¢‘ 
 &lt;b&gt;ä¸»é¢˜&lt;/b&gt; æˆ– 
 &lt;b&gt;å…³é”®è¯&lt;/b&gt; ï¼Œå°±å¯ä»¥å…¨è‡ªåŠ¨ç”Ÿæˆè§†é¢‘æ–‡æ¡ˆã€è§†é¢‘ç´ æã€è§†é¢‘å­—å¹•ã€è§†é¢‘èƒŒæ™¯éŸ³ä¹ï¼Œç„¶ååˆæˆä¸€ä¸ªé«˜æ¸…çš„çŸ­è§†é¢‘ã€‚ 
 &lt;br /&gt; 
 &lt;h4&gt;Webç•Œé¢&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/webui.jpg" alt="" /&gt;&lt;/p&gt; 
 &lt;h4&gt;APIç•Œé¢&lt;/h4&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/api.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ç‰¹åˆ«æ„Ÿè°¢ ğŸ™&lt;/h2&gt; 
&lt;p&gt;ç”±äºè¯¥é¡¹ç›®çš„ &lt;strong&gt;éƒ¨ç½²&lt;/strong&gt; å’Œ &lt;strong&gt;ä½¿ç”¨&lt;/strong&gt;ï¼Œå¯¹äºä¸€äº›å°ç™½ç”¨æˆ·æ¥è¯´ï¼Œè¿˜æ˜¯ &lt;strong&gt;æœ‰ä¸€å®šçš„é—¨æ§›&lt;/strong&gt;ï¼Œåœ¨æ­¤ç‰¹åˆ«æ„Ÿè°¢ &lt;strong&gt;å½•å’–ï¼ˆAIæ™ºèƒ½ å¤šåª’ä½“æœåŠ¡å¹³å°ï¼‰&lt;/strong&gt; ç½‘ç«™åŸºäºè¯¥é¡¹ç›®ï¼Œæä¾›çš„å…è´¹&lt;code&gt;AIè§†é¢‘ç”Ÿæˆå™¨&lt;/code&gt;æœåŠ¡ï¼Œå¯ä»¥ä¸ç”¨éƒ¨ç½²ï¼Œç›´æ¥åœ¨çº¿ä½¿ç”¨ï¼Œéå¸¸æ–¹ä¾¿ã€‚&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä¸­æ–‡ç‰ˆï¼š&lt;a href="https://reccloud.cn"&gt;https://reccloud.cn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;è‹±æ–‡ç‰ˆï¼š&lt;a href="https://reccloud.com"&gt;https://reccloud.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/reccloud.cn.jpg" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;æ„Ÿè°¢èµåŠ© ğŸ™&lt;/h2&gt; 
&lt;p&gt;æ„Ÿè°¢ä½ç³– &lt;a href="https://picwish.cn"&gt;https://picwish.cn&lt;/a&gt; å¯¹è¯¥é¡¹ç›®çš„æ”¯æŒå’ŒèµåŠ©ï¼Œä½¿å¾—è¯¥é¡¹ç›®èƒ½å¤ŸæŒç»­çš„æ›´æ–°å’Œç»´æŠ¤ã€‚&lt;/p&gt; 
&lt;p&gt;ä½ç³–ä¸“æ³¨äº&lt;strong&gt;å›¾åƒå¤„ç†é¢†åŸŸ&lt;/strong&gt;ï¼Œæä¾›ä¸°å¯Œçš„&lt;strong&gt;å›¾åƒå¤„ç†å·¥å…·&lt;/strong&gt;ï¼Œå°†å¤æ‚æ“ä½œæè‡´ç®€åŒ–ï¼ŒçœŸæ­£å®ç°è®©å›¾åƒå¤„ç†æ›´ç®€å•ã€‚&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/picwish.jpg" alt="picwish.jpg" /&gt;&lt;/p&gt; 
&lt;h2&gt;åŠŸèƒ½ç‰¹æ€§ ğŸ¯&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; å®Œæ•´çš„ &lt;strong&gt;MVCæ¶æ„&lt;/strong&gt;ï¼Œä»£ç  &lt;strong&gt;ç»“æ„æ¸…æ™°&lt;/strong&gt;ï¼Œæ˜“äºç»´æŠ¤ï¼Œæ”¯æŒ &lt;code&gt;API&lt;/code&gt; å’Œ &lt;code&gt;Webç•Œé¢&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; æ”¯æŒè§†é¢‘æ–‡æ¡ˆ &lt;strong&gt;AIè‡ªåŠ¨ç”Ÿæˆ&lt;/strong&gt;ï¼Œä¹Ÿå¯ä»¥&lt;strong&gt;è‡ªå®šä¹‰æ–‡æ¡ˆ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; æ”¯æŒå¤šç§ &lt;strong&gt;é«˜æ¸…è§†é¢‘&lt;/strong&gt; å°ºå¯¸ 
  &lt;ul&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; ç«–å± 9:16ï¼Œ&lt;code&gt;1080x1920&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; æ¨ªå± 16:9ï¼Œ&lt;code&gt;1920x1080&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; æ”¯æŒ &lt;strong&gt;æ‰¹é‡è§†é¢‘ç”Ÿæˆ&lt;/strong&gt;ï¼Œå¯ä»¥ä¸€æ¬¡ç”Ÿæˆå¤šä¸ªè§†é¢‘ï¼Œç„¶åé€‰æ‹©ä¸€ä¸ªæœ€æ»¡æ„çš„&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; æ”¯æŒ &lt;strong&gt;è§†é¢‘ç‰‡æ®µæ—¶é•¿&lt;/strong&gt; è®¾ç½®ï¼Œæ–¹ä¾¿è°ƒèŠ‚ç´ æåˆ‡æ¢é¢‘ç‡&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; æ”¯æŒ &lt;strong&gt;ä¸­æ–‡&lt;/strong&gt; å’Œ &lt;strong&gt;è‹±æ–‡&lt;/strong&gt; è§†é¢‘æ–‡æ¡ˆ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; æ”¯æŒ &lt;strong&gt;å¤šç§è¯­éŸ³&lt;/strong&gt; åˆæˆï¼Œå¯ &lt;strong&gt;å®æ—¶è¯•å¬&lt;/strong&gt; æ•ˆæœ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; æ”¯æŒ &lt;strong&gt;å­—å¹•ç”Ÿæˆ&lt;/strong&gt;ï¼Œå¯ä»¥è°ƒæ•´ &lt;code&gt;å­—ä½“&lt;/code&gt;ã€&lt;code&gt;ä½ç½®&lt;/code&gt;ã€&lt;code&gt;é¢œè‰²&lt;/code&gt;ã€&lt;code&gt;å¤§å°&lt;/code&gt;ï¼ŒåŒæ—¶æ”¯æŒ&lt;code&gt;å­—å¹•æè¾¹&lt;/code&gt;è®¾ç½®&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; æ”¯æŒ &lt;strong&gt;èƒŒæ™¯éŸ³ä¹&lt;/strong&gt;ï¼Œéšæœºæˆ–è€…æŒ‡å®šéŸ³ä¹æ–‡ä»¶ï¼Œå¯è®¾ç½®&lt;code&gt;èƒŒæ™¯éŸ³ä¹éŸ³é‡&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; è§†é¢‘ç´ ææ¥æº &lt;strong&gt;é«˜æ¸…&lt;/strong&gt;ï¼Œè€Œä¸” &lt;strong&gt;æ— ç‰ˆæƒ&lt;/strong&gt;ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨è‡ªå·±çš„ &lt;strong&gt;æœ¬åœ°ç´ æ&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; æ”¯æŒ &lt;strong&gt;OpenAI&lt;/strong&gt;ã€&lt;strong&gt;Moonshot&lt;/strong&gt;ã€&lt;strong&gt;Azure&lt;/strong&gt;ã€&lt;strong&gt;gpt4free&lt;/strong&gt;ã€&lt;strong&gt;one-api&lt;/strong&gt;ã€&lt;strong&gt;é€šä¹‰åƒé—®&lt;/strong&gt;ã€&lt;strong&gt;Google Gemini&lt;/strong&gt;ã€&lt;strong&gt;Ollama&lt;/strong&gt;ã€&lt;strong&gt;DeepSeek&lt;/strong&gt;ã€ &lt;strong&gt;æ–‡å¿ƒä¸€è¨€&lt;/strong&gt;, &lt;strong&gt;Pollinations&lt;/strong&gt; ç­‰å¤šç§æ¨¡å‹æ¥å…¥ 
  &lt;ul&gt; 
   &lt;li&gt;ä¸­å›½ç”¨æˆ·å»ºè®®ä½¿ç”¨ &lt;strong&gt;DeepSeek&lt;/strong&gt; æˆ– &lt;strong&gt;Moonshot&lt;/strong&gt; ä½œä¸ºå¤§æ¨¡å‹æä¾›å•†ï¼ˆå›½å†…å¯ç›´æ¥è®¿é—®ï¼Œä¸éœ€è¦VPNã€‚æ³¨å†Œå°±é€é¢åº¦ï¼ŒåŸºæœ¬å¤Ÿç”¨ï¼‰&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;åæœŸè®¡åˆ’ ğŸ“…&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; GPT-SoVITS é…éŸ³æ”¯æŒ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; ä¼˜åŒ–è¯­éŸ³åˆæˆï¼Œåˆ©ç”¨å¤§æ¨¡å‹ï¼Œä½¿å…¶åˆæˆçš„å£°éŸ³ï¼Œæ›´åŠ è‡ªç„¶ï¼Œæƒ…ç»ªæ›´åŠ ä¸°å¯Œ&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; å¢åŠ è§†é¢‘è½¬åœºæ•ˆæœï¼Œä½¿å…¶çœ‹èµ·æ¥æ›´åŠ çš„æµç•…&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; å¢åŠ æ›´å¤šè§†é¢‘ç´ ææ¥æºï¼Œä¼˜åŒ–è§†é¢‘ç´ æå’Œæ–‡æ¡ˆçš„åŒ¹é…åº¦&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; å¢åŠ è§†é¢‘é•¿åº¦é€‰é¡¹ï¼šçŸ­ã€ä¸­ã€é•¿&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; æ”¯æŒæ›´å¤šçš„è¯­éŸ³åˆæˆæœåŠ¡å•†ï¼Œæ¯”å¦‚ OpenAI TTS&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; è‡ªåŠ¨ä¸Šä¼ åˆ°YouTubeå¹³å°&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;è§†é¢‘æ¼”ç¤º ğŸ“º&lt;/h2&gt; 
&lt;h3&gt;ç«–å± 9:16&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     â–¶ï¸
    &lt;/g-emoji&gt; ã€Šå¦‚ä½•å¢åŠ ç”Ÿæ´»çš„ä¹è¶£ã€‹&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     â–¶ï¸
    &lt;/g-emoji&gt; ã€Šé‡‘é’±çš„ä½œç”¨ã€‹&lt;br /&gt;æ›´çœŸå®çš„åˆæˆå£°éŸ³&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     â–¶ï¸
    &lt;/g-emoji&gt; ã€Šç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä»€ä¹ˆã€‹&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/a84d33d5-27a2-4aba-8fd0-9fb2bd91c6a6"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/af2f3b0b-002e-49fe-b161-18ba91c055e8"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/112c9564-d52b-4472-99ad-970b75f66476"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;æ¨ªå± 16:9&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     â–¶ï¸
    &lt;/g-emoji&gt;ã€Šç”Ÿå‘½çš„æ„ä¹‰æ˜¯ä»€ä¹ˆã€‹&lt;/th&gt; 
   &lt;th align="center"&gt;
    &lt;g-emoji class="g-emoji" alias="arrow_forward"&gt;
     â–¶ï¸
    &lt;/g-emoji&gt;ã€Šä¸ºä»€ä¹ˆè¦è¿åŠ¨ã€‹&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/346ebb15-c55f-47a9-a653-114f08bb8073"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;
    &lt;video src="https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/271f2fae-8283-44a0-8aa0-0ed8f9a6fa87"&gt;&lt;/video&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;é…ç½®è¦æ±‚ ğŸ“¦&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;å»ºè®®æœ€ä½ CPU &lt;strong&gt;4æ ¸&lt;/strong&gt; æˆ–ä»¥ä¸Šï¼Œå†…å­˜ &lt;strong&gt;4G&lt;/strong&gt; æˆ–ä»¥ä¸Šï¼Œæ˜¾å¡éå¿…é¡»&lt;/li&gt; 
 &lt;li&gt;Windows 10 æˆ– MacOS 11.0 ä»¥ä¸Šç³»ç»Ÿ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;å¿«é€Ÿå¼€å§‹ ğŸš€&lt;/h2&gt; 
&lt;h3&gt;åœ¨ Google Colab ä¸­è¿è¡Œ&lt;/h3&gt; 
&lt;p&gt;å…å»æœ¬åœ°ç¯å¢ƒé…ç½®ï¼Œç‚¹å‡»ç›´æ¥åœ¨ Google Colab ä¸­å¿«é€Ÿä½“éªŒ MoneyPrinterTurbo&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://colab.research.google.com/github/harry0703/MoneyPrinterTurbo/blob/main/docs/MoneyPrinterTurbo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open in Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Windowsä¸€é”®å¯åŠ¨åŒ…&lt;/h3&gt; 
&lt;p&gt;ä¸‹è½½ä¸€é”®å¯åŠ¨åŒ…ï¼Œè§£å‹ç›´æ¥ä½¿ç”¨ï¼ˆè·¯å¾„ä¸è¦æœ‰ &lt;strong&gt;ä¸­æ–‡&lt;/strong&gt;ã€&lt;strong&gt;ç‰¹æ®Šå­—ç¬¦&lt;/strong&gt;ã€&lt;strong&gt;ç©ºæ ¼&lt;/strong&gt;ï¼‰&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ç™¾åº¦ç½‘ç›˜ï¼ˆv1.2.6ï¼‰: &lt;a href="https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx"&gt;https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx&lt;/a&gt; æå–ç : sbqx&lt;/li&gt; 
 &lt;li&gt;Google Drive (v1.2.6): &lt;a href="https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing"&gt;https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ä¸‹è½½åï¼Œå»ºè®®å…ˆ&lt;strong&gt;åŒå‡»æ‰§è¡Œ&lt;/strong&gt; &lt;code&gt;update.bat&lt;/code&gt; æ›´æ–°åˆ°&lt;strong&gt;æœ€æ–°ä»£ç &lt;/strong&gt;ï¼Œç„¶ååŒå‡» &lt;code&gt;start.bat&lt;/code&gt; å¯åŠ¨&lt;/p&gt; 
&lt;p&gt;å¯åŠ¨åï¼Œä¼šè‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼ˆå¦‚æœæ‰“å¼€æ˜¯ç©ºç™½ï¼Œå»ºè®®æ¢æˆ &lt;strong&gt;Chrome&lt;/strong&gt; æˆ–è€… &lt;strong&gt;Edge&lt;/strong&gt; æ‰“å¼€ï¼‰&lt;/p&gt; 
&lt;h2&gt;å®‰è£…éƒ¨ç½² ğŸ“¥&lt;/h2&gt; 
&lt;h3&gt;å‰ææ¡ä»¶&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;å°½é‡ä¸è¦ä½¿ç”¨ &lt;strong&gt;ä¸­æ–‡è·¯å¾„&lt;/strong&gt;ï¼Œé¿å…å‡ºç°ä¸€äº›æ— æ³•é¢„æ–™çš„é—®é¢˜&lt;/li&gt; 
 &lt;li&gt;è¯·ç¡®ä¿ä½ çš„ &lt;strong&gt;ç½‘ç»œ&lt;/strong&gt; æ˜¯æ­£å¸¸çš„ï¼ŒVPNéœ€è¦æ‰“å¼€&lt;code&gt;å…¨å±€æµé‡&lt;/code&gt;æ¨¡å¼&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;â‘  å…‹éš†ä»£ç &lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;â‘¡ ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œå»ºè®®å¯åŠ¨åä¹Ÿå¯ä»¥åœ¨ WebUI é‡Œé¢é…ç½®ï¼‰&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;å°† &lt;code&gt;config.example.toml&lt;/code&gt; æ–‡ä»¶å¤åˆ¶ä¸€ä»½ï¼Œå‘½åä¸º &lt;code&gt;config.toml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;æŒ‰ç…§ &lt;code&gt;config.toml&lt;/code&gt; æ–‡ä»¶ä¸­çš„è¯´æ˜ï¼Œé…ç½®å¥½ &lt;code&gt;pexels_api_keys&lt;/code&gt; å’Œ &lt;code&gt;llm_provider&lt;/code&gt;ï¼Œå¹¶æ ¹æ® llm_provider å¯¹åº”çš„æœåŠ¡å•†ï¼Œé…ç½®ç›¸å…³çš„ API Key&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Dockeréƒ¨ç½² ğŸ³&lt;/h3&gt; 
&lt;h4&gt;â‘  å¯åŠ¨Docker&lt;/h4&gt; 
&lt;p&gt;å¦‚æœæœªå®‰è£… Dockerï¼Œè¯·å…ˆå®‰è£… &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;https://www.docker.com/products/docker-desktop/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;å¦‚æœæ˜¯Windowsç³»ç»Ÿï¼Œè¯·å‚è€ƒå¾®è½¯çš„æ–‡æ¡£ï¼š&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/install"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers"&gt;https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;cd MoneyPrinterTurbo
docker-compose up
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨æ„ï¼šæœ€æ–°ç‰ˆçš„dockerå®‰è£…æ—¶ä¼šè‡ªåŠ¨ä»¥æ’ä»¶çš„å½¢å¼å®‰è£…docker composeï¼Œå¯åŠ¨å‘½ä»¤è°ƒæ•´ä¸ºdocker compose up&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;â‘¡ è®¿é—®Webç•Œé¢&lt;/h4&gt; 
&lt;p&gt;æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® &lt;a href="http://0.0.0.0:8501"&gt;http://0.0.0.0:8501&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;â‘¢ è®¿é—®APIæ–‡æ¡£&lt;/h4&gt; 
&lt;p&gt;æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® &lt;a href="http://0.0.0.0:8080/docs"&gt;http://0.0.0.0:8080/docs&lt;/a&gt; æˆ–è€… &lt;a href="http://0.0.0.0:8080/redoc"&gt;http://0.0.0.0:8080/redoc&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;æ‰‹åŠ¨éƒ¨ç½² ğŸ“¦&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;è§†é¢‘æ•™ç¨‹&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;å®Œæ•´çš„ä½¿ç”¨æ¼”ç¤ºï¼š&lt;a href="https://v.douyin.com/iFhnwsKY/"&gt;https://v.douyin.com/iFhnwsKY/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;å¦‚ä½•åœ¨Windowsä¸Šéƒ¨ç½²ï¼š&lt;a href="https://v.douyin.com/iFyjoW3M"&gt;https://v.douyin.com/iFyjoW3M&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;â‘  åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ&lt;/h4&gt; 
&lt;p&gt;å»ºè®®ä½¿ç”¨ &lt;a href="https://conda.io/projects/conda/en/latest/user-guide/install/index.html"&gt;conda&lt;/a&gt; åˆ›å»º python è™šæ‹Ÿç¯å¢ƒ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/harry0703/MoneyPrinterTurbo.git
cd MoneyPrinterTurbo
conda create -n MoneyPrinterTurbo python=3.11
conda activate MoneyPrinterTurbo
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;â‘¡ å®‰è£…å¥½ ImageMagick&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Windows:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;ä¸‹è½½ &lt;a href="https://imagemagick.org/script/download.php"&gt;https://imagemagick.org/script/download.php&lt;/a&gt; é€‰æ‹©Windowsç‰ˆæœ¬ï¼Œåˆ‡è®°ä¸€å®šè¦é€‰æ‹© &lt;strong&gt;é™æ€åº“&lt;/strong&gt; ç‰ˆæœ¬ï¼Œæ¯”å¦‚ ImageMagick-7.1.1-32-Q16-x64-&lt;strong&gt;static&lt;/strong&gt;.exe&lt;/li&gt; 
   &lt;li&gt;å®‰è£…ä¸‹è½½å¥½çš„ ImageMagickï¼Œ&lt;strong&gt;æ³¨æ„ä¸è¦ä¿®æ”¹å®‰è£…è·¯å¾„&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;ä¿®æ”¹ &lt;code&gt;é…ç½®æ–‡ä»¶ config.toml&lt;/code&gt; ä¸­çš„ &lt;code&gt;imagemagick_path&lt;/code&gt; ä¸ºä½ çš„ &lt;strong&gt;å®é™…å®‰è£…è·¯å¾„&lt;/strong&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;MacOS:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;brew install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ubuntu&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo apt-get install imagemagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;CentOS&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;sudo yum install ImageMagick
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;â‘¢ å¯åŠ¨Webç•Œé¢ ğŸŒ&lt;/h4&gt; 
&lt;p&gt;æ³¨æ„éœ€è¦åˆ° MoneyPrinterTurbo é¡¹ç›® &lt;code&gt;æ ¹ç›®å½•&lt;/code&gt; ä¸‹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤&lt;/p&gt; 
&lt;h6&gt;Windows&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-bat"&gt;webui.bat
&lt;/code&gt;&lt;/pre&gt; 
&lt;h6&gt;MacOS or Linux&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sh webui.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;å¯åŠ¨åï¼Œä¼šè‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼ˆå¦‚æœæ‰“å¼€æ˜¯ç©ºç™½ï¼Œå»ºè®®æ¢æˆ &lt;strong&gt;Chrome&lt;/strong&gt; æˆ–è€… &lt;strong&gt;Edge&lt;/strong&gt; æ‰“å¼€ï¼‰&lt;/p&gt; 
&lt;h4&gt;â‘£ å¯åŠ¨APIæœåŠ¡ ğŸš€&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;å¯åŠ¨åï¼Œå¯ä»¥æŸ¥çœ‹ &lt;code&gt;APIæ–‡æ¡£&lt;/code&gt; &lt;a href="http://127.0.0.1:8080/docs"&gt;http://127.0.0.1:8080/docs&lt;/a&gt; æˆ–è€… &lt;a href="http://127.0.0.1:8080/redoc"&gt;http://127.0.0.1:8080/redoc&lt;/a&gt; ç›´æ¥åœ¨çº¿è°ƒè¯•æ¥å£ï¼Œå¿«é€Ÿä½“éªŒã€‚&lt;/p&gt; 
&lt;h2&gt;è¯­éŸ³åˆæˆ ğŸ—£&lt;/h2&gt; 
&lt;p&gt;æ‰€æœ‰æ”¯æŒçš„å£°éŸ³åˆ—è¡¨ï¼Œå¯ä»¥æŸ¥çœ‹ï¼š&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/docs/voice-list.txt"&gt;å£°éŸ³åˆ—è¡¨&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;2024-04-16 v1.1.2 æ–°å¢äº†9ç§Azureçš„è¯­éŸ³åˆæˆå£°éŸ³ï¼Œéœ€è¦é…ç½®API KEYï¼Œè¯¥å£°éŸ³åˆæˆçš„æ›´åŠ çœŸå®ã€‚&lt;/p&gt; 
&lt;h2&gt;å­—å¹•ç”Ÿæˆ ğŸ“œ&lt;/h2&gt; 
&lt;p&gt;å½“å‰æ”¯æŒ2ç§å­—å¹•ç”Ÿæˆæ–¹å¼ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;edge&lt;/strong&gt;: ç”Ÿæˆ&lt;code&gt;é€Ÿåº¦å¿«&lt;/code&gt;ï¼Œæ€§èƒ½æ›´å¥½ï¼Œå¯¹ç”µè„‘é…ç½®æ²¡æœ‰è¦æ±‚ï¼Œä½†æ˜¯è´¨é‡å¯èƒ½ä¸ç¨³å®š&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;whisper&lt;/strong&gt;: ç”Ÿæˆ&lt;code&gt;é€Ÿåº¦æ…¢&lt;/code&gt;ï¼Œæ€§èƒ½è¾ƒå·®ï¼Œå¯¹ç”µè„‘é…ç½®æœ‰ä¸€å®šè¦æ±‚ï¼Œä½†æ˜¯&lt;code&gt;è´¨é‡æ›´å¯é &lt;/code&gt;ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;å¯ä»¥ä¿®æ”¹ &lt;code&gt;config.toml&lt;/code&gt; é…ç½®æ–‡ä»¶ä¸­çš„ &lt;code&gt;subtitle_provider&lt;/code&gt; è¿›è¡Œåˆ‡æ¢&lt;/p&gt; 
&lt;p&gt;å»ºè®®ä½¿ç”¨ &lt;code&gt;edge&lt;/code&gt; æ¨¡å¼ï¼Œå¦‚æœç”Ÿæˆçš„å­—å¹•è´¨é‡ä¸å¥½ï¼Œå†åˆ‡æ¢åˆ° &lt;code&gt;whisper&lt;/code&gt; æ¨¡å¼&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;æ³¨æ„ï¼š&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;whisper æ¨¡å¼ä¸‹éœ€è¦åˆ° HuggingFace ä¸‹è½½ä¸€ä¸ªæ¨¡å‹æ–‡ä»¶ï¼Œå¤§çº¦ 3GB å·¦å³ï¼Œè¯·ç¡®ä¿ç½‘ç»œé€šç•…&lt;/li&gt; 
 &lt;li&gt;å¦‚æœç•™ç©ºï¼Œè¡¨ç¤ºä¸ç”Ÿæˆå­—å¹•ã€‚&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ç”±äºå›½å†…æ— æ³•è®¿é—® HuggingFaceï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ä¸‹è½½ &lt;code&gt;whisper-large-v3&lt;/code&gt; çš„æ¨¡å‹æ–‡ä»¶&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ä¸‹è½½åœ°å€ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ç™¾åº¦ç½‘ç›˜: &lt;a href="https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9"&gt;https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;å¤¸å…‹ç½‘ç›˜ï¼š&lt;a href="https://pan.quark.cn/s/3ee3d991d64b"&gt;https://pan.quark.cn/s/3ee3d991d64b&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;æ¨¡å‹ä¸‹è½½åè§£å‹ï¼Œæ•´ä¸ªç›®å½•æ”¾åˆ° &lt;code&gt;.\MoneyPrinterTurbo\models&lt;/code&gt; é‡Œé¢ï¼Œ æœ€ç»ˆçš„æ–‡ä»¶è·¯å¾„åº”è¯¥æ˜¯è¿™æ ·: &lt;code&gt;.\MoneyPrinterTurbo\models\whisper-large-v3&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;MoneyPrinterTurbo  
  â”œâ”€models
  â”‚   â””â”€whisper-large-v3
  â”‚          config.json
  â”‚          model.bin
  â”‚          preprocessor_config.json
  â”‚          tokenizer.json
  â”‚          vocabulary.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;èƒŒæ™¯éŸ³ä¹ ğŸµ&lt;/h2&gt; 
&lt;p&gt;ç”¨äºè§†é¢‘çš„èƒŒæ™¯éŸ³ä¹ï¼Œä½äºé¡¹ç›®çš„ &lt;code&gt;resource/songs&lt;/code&gt; ç›®å½•ä¸‹ã€‚&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;å½“å‰é¡¹ç›®é‡Œé¢æ”¾äº†ä¸€äº›é»˜è®¤çš„éŸ³ä¹ï¼Œæ¥è‡ªäº YouTube è§†é¢‘ï¼Œå¦‚æœ‰ä¾µæƒï¼Œè¯·åˆ é™¤ã€‚&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;å­—å¹•å­—ä½“ ğŸ…°&lt;/h2&gt; 
&lt;p&gt;ç”¨äºè§†é¢‘å­—å¹•çš„æ¸²æŸ“ï¼Œä½äºé¡¹ç›®çš„ &lt;code&gt;resource/fonts&lt;/code&gt; ç›®å½•ä¸‹ï¼Œä½ ä¹Ÿå¯ä»¥æ”¾è¿›å»è‡ªå·±çš„å­—ä½“ã€‚&lt;/p&gt; 
&lt;h2&gt;å¸¸è§é—®é¢˜ ğŸ¤”&lt;/h2&gt; 
&lt;h3&gt;â“RuntimeError: No ffmpeg exe could be found&lt;/h3&gt; 
&lt;p&gt;é€šå¸¸æƒ…å†µä¸‹ï¼Œffmpeg ä¼šè¢«è‡ªåŠ¨ä¸‹è½½ï¼Œå¹¶ä¸”ä¼šè¢«è‡ªåŠ¨æ£€æµ‹åˆ°ã€‚ ä½†æ˜¯å¦‚æœä½ çš„ç¯å¢ƒæœ‰é—®é¢˜ï¼Œæ— æ³•è‡ªåŠ¨ä¸‹è½½ï¼Œå¯èƒ½ä¼šé‡åˆ°å¦‚ä¸‹é”™è¯¯ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;RuntimeError: No ffmpeg exe could be found.
Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;æ­¤æ—¶ä½ å¯ä»¥ä» &lt;a href="https://www.gyan.dev/ffmpeg/builds/"&gt;https://www.gyan.dev/ffmpeg/builds/&lt;/a&gt; ä¸‹è½½ffmpegï¼Œè§£å‹åï¼Œè®¾ç½® &lt;code&gt;ffmpeg_path&lt;/code&gt; ä¸ºä½ çš„å®é™…å®‰è£…è·¯å¾„å³å¯ã€‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[app]
# è¯·æ ¹æ®ä½ çš„å®é™…è·¯å¾„è®¾ç½®ï¼Œæ³¨æ„ Windows è·¯å¾„åˆ†éš”ç¬¦ä¸º \\
ffmpeg_path = "C:\\Users\\harry\\Downloads\\ffmpeg.exe"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;â“ImageMagickçš„å®‰å…¨ç­–ç•¥é˜»æ­¢äº†ä¸ä¸´æ—¶æ–‡ä»¶@/tmp/tmpur5hyyto.txtç›¸å…³çš„æ“ä½œ&lt;/h3&gt; 
&lt;p&gt;å¯ä»¥åœ¨ImageMagickçš„é…ç½®æ–‡ä»¶policy.xmlä¸­æ‰¾åˆ°è¿™äº›ç­–ç•¥ã€‚ è¿™ä¸ªæ–‡ä»¶é€šå¸¸ä½äº /etc/ImageMagick-&lt;code&gt;X&lt;/code&gt;/ æˆ– ImageMagick å®‰è£…ç›®å½•çš„ç±»ä¼¼ä½ç½®ã€‚ ä¿®æ”¹åŒ…å«&lt;code&gt;pattern="@"&lt;/code&gt;çš„æ¡ç›®ï¼Œå°†&lt;code&gt;rights="none"&lt;/code&gt;æ›´æ”¹ä¸º&lt;code&gt;rights="read|write"&lt;/code&gt;ä»¥å…è®¸å¯¹æ–‡ä»¶çš„è¯»å†™æ“ä½œã€‚&lt;/p&gt; 
&lt;h3&gt;â“OSError: [Errno 24] Too many open files&lt;/h3&gt; 
&lt;p&gt;è¿™ä¸ªé—®é¢˜æ˜¯ç”±äºç³»ç»Ÿæ‰“å¼€æ–‡ä»¶æ•°é™åˆ¶å¯¼è‡´çš„ï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ç³»ç»Ÿçš„æ–‡ä»¶æ‰“å¼€æ•°é™åˆ¶æ¥è§£å†³ã€‚&lt;/p&gt; 
&lt;p&gt;æŸ¥çœ‹å½“å‰é™åˆ¶&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;å¦‚æœè¿‡ä½ï¼Œå¯ä»¥è°ƒé«˜ä¸€äº›ï¼Œæ¯”å¦‚&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;ulimit -n 10240
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;â“Whisper æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œå‡ºç°å¦‚ä¸‹é”™è¯¯&lt;/h3&gt; 
&lt;p&gt;LocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and outgoing trafic has been disabled. To enablerepo look-ups and downloads online, pass 'local files only=False' as input.&lt;/p&gt; 
&lt;p&gt;æˆ–è€…&lt;/p&gt; 
&lt;p&gt;An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub: An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the specified revision on the local disk. Please check your internet connection and try again. Trying to load the model directly from the local cache, if it exists.&lt;/p&gt; 
&lt;p&gt;è§£å†³æ–¹æ³•ï¼š&lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/#%E5%AD%97%E5%B9%95%E7%94%9F%E6%88%90-"&gt;ç‚¹å‡»æŸ¥çœ‹å¦‚ä½•ä»ç½‘ç›˜æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;åé¦ˆå»ºè®® ğŸ“¢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;å¯ä»¥æäº¤ &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/issues"&gt;issue&lt;/a&gt; æˆ–è€… &lt;a href="https://github.com/harry0703/MoneyPrinterTurbo/pulls"&gt;pull request&lt;/a&gt;ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;è®¸å¯è¯ ğŸ“&lt;/h2&gt; 
&lt;p&gt;ç‚¹å‡»æŸ¥çœ‹ &lt;a href="https://raw.githubusercontent.com/harry0703/MoneyPrinterTurbo/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; æ–‡ä»¶&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#harry0703/MoneyPrinterTurbo&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=harry0703/MoneyPrinterTurbo&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>onyx-dot-app/onyx</title>
      <link>https://github.com/onyx-dot-app/onyx</link>
      <description>&lt;p&gt;Open Source AI Platform - AI Chat with advanced features that works with every LLM&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt; &lt;a href="https://www.onyx.app/"&gt; &lt;img width="50%" src="https://github.com/onyx-dot-app/onyx/raw/logo/OnyxLogoCropped.jpg?raw=true)" /&gt;&lt;/a&gt; &lt;/h2&gt; 
&lt;p align="center"&gt;Open Source AI Platform&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/TDJ59cGV2X" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/discord-join-blue.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt; &lt;/a&gt; &lt;a href="https://docs.onyx.app/" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/docs-view-blue" alt="Documentation" /&gt; &lt;/a&gt; &lt;a href="https://docs.onyx.app/" target="_blank"&gt; &lt;img src="https://img.shields.io/website?url=https://www.onyx.app&amp;amp;up_message=visit&amp;amp;up_color=blue" alt="Documentation" /&gt; &lt;/a&gt; &lt;a href="https://github.com/onyx-dot-app/onyx/raw/main/LICENSE" target="_blank"&gt; &lt;img src="https://img.shields.io/static/v1?label=license&amp;amp;message=MIT&amp;amp;color=blue" alt="License" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.onyx.app/"&gt;Onyx&lt;/a&gt;&lt;/strong&gt; is a feature-rich, self-hostable Chat UI that works with any LLM. It is easy to deploy and can run in a completely airgapped environment.&lt;/p&gt; 
&lt;p&gt;Onyx comes loaded with advanced features like Agents, Web Search, RAG, MCP, Deep Research, Connectors to 40+ knowledge sources, and more.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Run Onyx with one command (or see deployment section below):&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;curl -fsSL https://raw.githubusercontent.com/onyx-dot-app/onyx/main/deployment/docker_compose/install.sh &amp;gt; install.sh &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;img src="https://github.com/onyx-dot-app/onyx/releases/download/v0.21.1/OnyxChatSilentDemo.gif" alt="Onyx Chat Silent Demo" /&gt;&lt;/p&gt; 
&lt;h2&gt;â­ Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– Custom Agents:&lt;/strong&gt; Build AI Agents with unique instructions, knowledge and actions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸŒ Web Search:&lt;/strong&gt; Browse the web with Google PSE, Exa, and Serper as well as an in-house scraper or Firecrawl.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ” RAG:&lt;/strong&gt; Best in class hybrid-search + knowledge graph for uploaded files and ingested documents from connectors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”„ Connectors:&lt;/strong&gt; Pull knowledge, metadata, and access information from over 40 applications.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”¬ Deep Research:&lt;/strong&gt; Get in depth answers with an agentic multi-step search.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;â–¶ï¸ Actions &amp;amp; MCP:&lt;/strong&gt; Give AI Agents the ability to interact with external systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ’» Code Interpreter:&lt;/strong&gt; Execute code to analyze data, render graphs and create files.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¨ Image Generation:&lt;/strong&gt; Generate images based on user prompts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ‘¥ Collaboration:&lt;/strong&gt; Chat sharing, feedback gathering, user management, usage analytics, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Onyx works with all LLMs (like OpenAI, Anthropic, Gemini, etc.) and self-hosted LLMs (like Ollama, vLLM, etc.)&lt;/p&gt; 
&lt;p&gt;To learn more about the features, check out our &lt;a href="https://docs.onyx.app/welcome"&gt;documentation&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;ğŸš€ Deployment&lt;/h2&gt; 
&lt;p&gt;Onyx supports deployments in Docker, Kubernetes, Terraform, along with guides for major cloud providers.&lt;/p&gt; 
&lt;p&gt;See guides below:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.onyx.app/deployment/local/docker"&gt;Docker&lt;/a&gt; or &lt;a href="https://docs.onyx.app/deployment/getting_started/quickstart"&gt;Quickstart&lt;/a&gt; (best for most users)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.onyx.app/deployment/local/kubernetes"&gt;Kubernetes&lt;/a&gt; (best for large teams)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.onyx.app/deployment/local/terraform"&gt;Terraform&lt;/a&gt; (best for teams already using Terraform)&lt;/li&gt; 
 &lt;li&gt;Cloud specific guides (best if specifically using &lt;a href="https://docs.onyx.app/deployment/cloud/aws/eks"&gt;AWS EKS&lt;/a&gt;, &lt;a href="https://docs.onyx.app/deployment/cloud/azure"&gt;Azure VMs&lt;/a&gt;, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;br /&gt; &lt;strong&gt;To try Onyx for free without deploying, check out &lt;a href="https://cloud.onyx.app/signup"&gt;Onyx Cloud&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ” Other Notable Benefits&lt;/h2&gt; 
&lt;p&gt;Onyx is built for teams of all sizes, from individual users to the largest global enterprises.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise Search&lt;/strong&gt;: far more than simple RAG, Onyx has custom indexing and retrieval that remains performant and accurate for scales of up to tens of millions of documents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: SSO (OIDC/SAML/OAuth2), RBAC, encryption of credentials, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Management UI&lt;/strong&gt;: different user roles such as basic, curator, and admin.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document Permissioning&lt;/strong&gt;: mirrors user access from external apps for RAG use cases.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸš§ Roadmap&lt;/h2&gt; 
&lt;p&gt;To see ongoing and upcoming projects, check out our &lt;a href="https://github.com/orgs/onyx-dot-app/projects/2"&gt;roadmap&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;ğŸ“š Licensing&lt;/h2&gt; 
&lt;p&gt;There are two editions of Onyx:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Onyx Community Edition (CE) is available freely under the MIT license.&lt;/li&gt; 
 &lt;li&gt;Onyx Enterprise Edition (EE) includes extra features that are primarily useful for larger organizations. For feature details, check out &lt;a href="https://www.onyx.app/pricing"&gt;our website&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‘ª Community&lt;/h2&gt; 
&lt;p&gt;Join our open source community on &lt;strong&gt;&lt;a href="https://discord.gg/TDJ59cGV2X"&gt;Discord&lt;/a&gt;&lt;/strong&gt;!&lt;/p&gt; 
&lt;h2&gt;ğŸ’¡ Contributing&lt;/h2&gt; 
&lt;p&gt;Looking to contribute? Please check out the &lt;a href="https://raw.githubusercontent.com/onyx-dot-app/onyx/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>basecamp/omarchy</title>
      <link>https://github.com/basecamp/omarchy</link>
      <description>&lt;p&gt;Opinionated Arch/Hyprland Setup&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Omarchy&lt;/h1&gt; 
&lt;p&gt;Turn a fresh Arch installation into a fully-configured, beautiful, and modern web development system based on Hyprland by running a single command. That's the one-line pitch for Omarchy (like it was for Omakub). No need to write bespoke configs for every essential tool just to get started or to be up on all the latest command-line tools. Omarchy is an opinionated take on what Linux can be at its best.&lt;/p&gt; 
&lt;p&gt;Read more at &lt;a href="https://omarchy.org"&gt;omarchy.org&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Omarchy is released under the &lt;a href="https://opensource.org/licenses/MIT"&gt;MIT License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ai-dynamo/dynamo</title>
      <link>https://github.com/ai-dynamo/dynamo</link>
      <description>&lt;p&gt;A Datacenter Scale Distributed Inference Serving Framework&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-banner.png" alt="Dynamo banner" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ai-dynamo/dynamo/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/ai-dynamo/dynamo" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/D92uqZRjCZ"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/ai-dynamo/dynamo"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/issues/762"&gt;Roadmap&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/raw/main/docs/support_matrix.md"&gt;Support matrix&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://docs.nvidia.com/dynamo/latest/index.html"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/tree/main/examples"&gt;Examples&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo"&gt;Prebuilt containers&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/enhancements"&gt;Design Proposals&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://developer.nvidia.com/blog/tag/nvidia-dynamo"&gt;Blogs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;NVIDIA Dynamo&lt;/h1&gt; 
&lt;p&gt;High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.&lt;/p&gt; 
&lt;h2&gt;Latest News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[08/05] Deploy &lt;code&gt;openai/gpt-oss-120b&lt;/code&gt; with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/trtllm/gpt-oss.md"&gt;â¡ï¸ link&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;The Era of Multi-GPU, Multi-Node&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-gpu-vertical.png" alt="Multi Node Multi-GPU topology" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUsâ€”and sometimes many serversâ€”but it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.&lt;/p&gt; 
&lt;p&gt;Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Disaggregated prefill &amp;amp; decode inference&lt;/strong&gt; â€“ Maximizes GPU throughput and facilitates trade off between throughput and latency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic GPU scheduling&lt;/strong&gt; â€“ Optimizes performance based on fluctuating demand&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-aware request routing&lt;/strong&gt; â€“ Eliminates unnecessary KV cache re-computation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accelerated data transfer&lt;/strong&gt; â€“ Reduces inference response time using NIXL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;KV cache offloading&lt;/strong&gt; â€“ Leverages multiple memory hierarchies for higher system throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-architecture.png" alt="Dynamo architecture" width="600" /&gt; &lt;/p&gt; 
&lt;h2&gt;Framework Support Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;vLLM&lt;/th&gt; 
   &lt;th&gt;SGLang&lt;/th&gt; 
   &lt;th&gt;TensorRT-LLM&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/disagg_serving.md"&gt;&lt;strong&gt;Disaggregated Serving&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/disagg_serving.md#conditional-disaggregation"&gt;&lt;strong&gt;Conditional Disaggregation&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ğŸš§&lt;/td&gt; 
   &lt;td&gt;ğŸš§&lt;/td&gt; 
   &lt;td&gt;ğŸš§&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/kv_cache_routing.md"&gt;&lt;strong&gt;KV-Aware Routing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/load_planner.md"&gt;&lt;strong&gt;Load Based Planner&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ğŸš§&lt;/td&gt; 
   &lt;td&gt;ğŸš§&lt;/td&gt; 
   &lt;td&gt;ğŸš§&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/sla_planner.md"&gt;&lt;strong&gt;SLA-Based Planner&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/architecture/kvbm_architecture.md"&gt;&lt;strong&gt;KVBM&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;ğŸš§&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To learn more about each framework and their capabilities, check out each framework's README!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/vllm/README.md"&gt;vLLM&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/sglang/README.md"&gt;SGLang&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends/trtllm/README.md"&gt;TensorRT-LLM&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;The following examples require a few system level packages. Recommended to use Ubuntu 24.04 with a x86_64 CPU. See &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/support_matrix.md"&gt;docs/support_matrix.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;1. Initial setup&lt;/h2&gt; 
&lt;p&gt;The Dynamo team recommends the &lt;code&gt;uv&lt;/code&gt; Python package manager, although any way works. Install uv:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install etcd and NATS (required)&lt;/h3&gt; 
&lt;p&gt;To coordinate across a data center, Dynamo relies on etcd and NATS. To run Dynamo locally, these need to be available.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://etcd.io/"&gt;etcd&lt;/a&gt; can be run directly as &lt;code&gt;./etcd&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nats.io/"&gt;nats&lt;/a&gt; needs jetstream enabled: &lt;code&gt;nats-server -js&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To quickly setup etcd &amp;amp; NATS, you can also run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# At the root of the repository:
# Edit deploy/docker-compose.yml to comment out "runtime: nvidia" of the dcgm-exporter service if the nvidia container runtime isn't deployed or to be used.
docker compose -f deploy/docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;2. Select an engine&lt;/h2&gt; 
&lt;p&gt;We publish Python wheels specialized for each of our supported engines: vllm, sglang, trtllm, and llama.cpp. The examples that follow use SGLang; continue reading for other engines.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install "ai-dynamo[sglang]"  #replace with [vllm], [trtllm], etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Run Dynamo&lt;/h2&gt; 
&lt;h3&gt;Running an LLM API server&lt;/h3&gt; 
&lt;p&gt;Dynamo provides a simple way to spin up a local set of inference components including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI Compatible Frontend&lt;/strong&gt; â€“ High performance OpenAI compatible http api server written in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic and Kv Aware Router&lt;/strong&gt; â€“ Route and load balance traffic to a set of workers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workers&lt;/strong&gt; â€“ Set of pre-configured LLM serving engines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
python -m dynamo.frontend --http-port 8000 [--tls-cert-path cert.pem] [--tls-key-path key.pem]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
python -m dynamo.sglang.worker --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B --skip-tokenizer-init
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Send a Request&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl localhost:8000/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "messages": [
    {
        "role": "user",
        "content": "Hello, how are you?"
    }
    ],
    "stream":false,
    "max_tokens": 300
  }' | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Rerun with &lt;code&gt;curl -N&lt;/code&gt; and change &lt;code&gt;stream&lt;/code&gt; in the request to &lt;code&gt;true&lt;/code&gt; to get the responses as soon as the engine issues them.&lt;/p&gt; 
&lt;h3&gt;Deploying Dynamo&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/kubernetes/README.md"&gt;Quickstart Guide&lt;/a&gt; to deploy on Kubernetes.&lt;/li&gt; 
 &lt;li&gt;Check out &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends"&gt;Backends&lt;/a&gt; to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)&lt;/li&gt; 
 &lt;li&gt;Run some &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/examples"&gt;Examples&lt;/a&gt; to learn about building components in Dynamo and exploring various integrations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Benchmarking Dynamo&lt;/h3&gt; 
&lt;p&gt;Dynamo provides comprehensive benchmarking tools to evaluate and optimize your deployments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/benchmarks/benchmarking.md"&gt;Benchmarking Guide&lt;/a&gt;&lt;/strong&gt; â€“ Compare deployment topologies (aggregated vs. disaggregated vs. vanilla vLLM) using GenAI-Perf&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/benchmarks/pre_deployment_profiling.md"&gt;Pre-Deployment Profiling&lt;/a&gt;&lt;/strong&gt; â€“ Optimize configurations before deployment to meet SLA requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Engines&lt;/h1&gt; 
&lt;p&gt;Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (&lt;code&gt;python -m dynamo.frontend [--interactive]&lt;/code&gt;).&lt;/p&gt; 
&lt;h2&gt;vLLM&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[vllm]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.vllm --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass &lt;code&gt;--context-length &amp;lt;value&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To specify which GPUs to use set environment variable &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;SGLang&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.sglang.worker --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can pass any sglang flags directly to this worker, see &lt;a href="https://docs.sglang.ai/advanced_features/server_arguments.html"&gt;https://docs.sglang.ai/advanced_features/server_arguments.html&lt;/a&gt; . See there to use multiple GPUs.&lt;/p&gt; 
&lt;h2&gt;TensorRT-LLM&lt;/h2&gt; 
&lt;p&gt;It is recommended to use &lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch"&gt;NGC PyTorch Container&lt;/a&gt; for running the TensorRT-LLM engine.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using. For example, if you are using &lt;code&gt;tensorrt-llm==1.1.0rc5&lt;/code&gt;, use the PyTorch container image version &lt;code&gt;25.06&lt;/code&gt;. To find the correct PyTorch container version for your desired &lt;code&gt;tensorrt-llm&lt;/code&gt; release, visit the &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/main/docker/Dockerfile.multi"&gt;TensorRT-LLM Dockerfile.multi&lt;/a&gt; on GitHub. Switch to the branch that matches your &lt;code&gt;tensorrt-llm&lt;/code&gt; version, and look for the &lt;code&gt;BASE_TAG&lt;/code&gt; line to identify the recommended PyTorch container tag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] Launch container with the following additional settings &lt;code&gt;--shm-size=1g --ulimit memlock=-1&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Install prerequisites&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install "cuda-python&amp;gt;=12,&amp;lt;13"

sudo apt-get -y install libopenmpi-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Tip] You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation &lt;a href="https://nvidia.github.io/TensorRT-LLM/installation/linux.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;After installing the pre-requisites above, install Dynamo&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[trtllm]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.trtllm --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To specify which GPUs to use set environment variable &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Developing Locally&lt;/h1&gt; 
&lt;h2&gt;1. Install libraries&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Ubuntu:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# if brew is not installed on your system, install it
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If Metal is accessible, you should see an error like &lt;code&gt;metal: error: no input files&lt;/code&gt;, which confirms it is installed correctly.&lt;/p&gt; 
&lt;h2&gt;2. Install Rust&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Create a Python virtual env:&lt;/h2&gt; 
&lt;p&gt;Follow the instructions in &lt;a href="https://docs.astral.sh/uv/#installation"&gt;uv installation&lt;/a&gt; guide to install uv if you don't have &lt;code&gt;uv&lt;/code&gt; installed. Once uv is installed, create a virtual environment and activate it.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install uv&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a virtual environment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv dynamo
source dynamo/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4. Install build tools&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install pip maturin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/PyO3/maturin"&gt;Maturin&lt;/a&gt; is the Rust&amp;lt;-&amp;gt;Python bindings build tool.&lt;/p&gt; 
&lt;h2&gt;5. Build the Rust bindings&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd lib/bindings/python
maturin develop --uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;6. Install the wheel&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd $PROJECT_ROOT
uv pip install .
# For development, use
export PYTHONPATH="${PYTHONPATH}:$(pwd)/components/frontend/src:$(pwd)/components/planner/src:$(pwd)/components/backends/vllm/src:$(pwd)/components/backends/sglang/src:$(pwd)/components/backends/trtllm/src:$(pwd)/components/backends/llama_cpp/src:$(pwd)/components/backends/mocker/src"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Editable (&lt;code&gt;-e&lt;/code&gt;) does not work because the &lt;code&gt;dynamo&lt;/code&gt; package is split over multiple directories, one per backend.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You should now be able to run &lt;code&gt;python -m dynamo.frontend&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Remember that nats and etcd must be running (see earlier).&lt;/p&gt; 
&lt;p&gt;Set the environment variable &lt;code&gt;DYN_LOG&lt;/code&gt; to adjust the logging level; for example, &lt;code&gt;export DYN_LOG=debug&lt;/code&gt;. It has the same syntax as &lt;code&gt;RUST_LOG&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you use vscode or cursor, we have a .devcontainer folder built on &lt;a href="https://code.visualstudio.com/docs/devcontainers/containers"&gt;Microsofts Extension&lt;/a&gt;. For instructions see the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/.devcontainer/README.md"&gt;ReadMe&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ZuodaoTech/everyone-can-use-english</title>
      <link>https://github.com/ZuodaoTech/everyone-can-use-english</link>
      <description>&lt;p&gt;äººäººéƒ½èƒ½ç”¨è‹±è¯­&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/assets/icon.png" alt="Clash" width="128" /&gt; 
&lt;/div&gt; 
&lt;h3 align="center"&gt; AI æ˜¯å½“ä»Šä¸–ç•Œä¸Šæœ€å¥½çš„å¤–è¯­è€å¸ˆï¼ŒEnjoy åš AI æœ€å¥½çš„åŠ©æ•™ã€‚ &lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/deploy-1000h.yml"&gt;&lt;img src="https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/deploy-1000h.yml/badge.svg?sanitize=true" alt="Deploy 1000h website" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/test-enjoy-app.yml"&gt;&lt;img src="https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/test-enjoy-app.yml/badge.svg?sanitize=true" alt="Test Enjoy App" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/release-enjoy-app.yml"&gt;&lt;img src="https://github.com/ZuodaoTech/everyone-can-use-english/actions/workflows/release-enjoy-app.yml/badge.svg?sanitize=true" alt="Release Enjoy App" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fenjoy.bot%2Fapi%2Fconfig%2Fapp_version&amp;amp;query=%24.version&amp;amp;label=Latest&amp;amp;link=https%3A%2F%2F1000h.org%2Fenjoy-app%2Finstall.html" alt="Latest Version" /&gt; &lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fenjoy.bot%2Fapi%2Fbadges%2Frecordings" alt="Recording Duration" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ç½‘é¡µç‰ˆ&lt;/h2&gt; 
&lt;p&gt;Enjoy ç½‘é¡µç‰ˆå·²ç»ä¸Šçº¿ï¼Œå¯è®¿é—® &lt;a href="https://enjoy.bot"&gt;https://enjoy.bot&lt;/a&gt; ç›´æ¥ä½¿ç”¨ã€‚&lt;/p&gt; 
&lt;div align="center" style="display:flex;overflow:auto;gap:10px;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/snapshots/web-audios.jpg" alt="Audios" width="300" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/snapshots/web-add-audio.jpg" alt="Add Audio" width="300" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/snapshots/web-audio-shadow.jpg" alt="Shadow" width="300" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/snapshots/web-audio-assessment.jpg" alt="Assessment" width="300" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/snapshots/web-new-chat.jpg" alt="New Chat" width="300" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/snapshots/web-chat.jpg" alt="Chat" width="300" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;æ¡Œé¢ç‰ˆå®‰è£…åŠä½¿ç”¨&lt;/h2&gt; 
&lt;p&gt;ä¸‹è½½åŠä½¿ç”¨ç›¸å…³è¯´æ˜ï¼Œè¯·å‚é˜… &lt;a href="https://1000h.org/enjoy-app/"&gt;æ–‡æ¡£&lt;/a&gt;ã€‚&lt;/p&gt; 
&lt;h2&gt;é¢„è§ˆ&lt;/h2&gt; 
&lt;div align="center" style="display:flex;overflow:auto;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/snapshots/home.png" alt="Home" width="800" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/snapshots/shadow.png" alt="Home" width="800" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/snapshots/assessment.png" alt="Home" width="800" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/snapshots/document.png" alt="Home" width="800" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/enjoy/snapshots/chat.png" alt="Home" width="800" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;æ¡Œé¢ç‰ˆå¼€å‘&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;yarn install
yarn enjoy:start
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ç›¸å…³é˜…è¯»&lt;/h2&gt; 
&lt;h3&gt;ä¸€åƒå°æ—¶ï¼ˆ2024ï¼‰&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://1000h.org/intro.html"&gt;ç®€è¦è¯´æ˜&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://1000h.org/training-tasks/kick-off.html"&gt;è®­ç»ƒä»»åŠ¡&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://1000h.org/sounds-of-american-english/0-intro.html"&gt;è¯­éŸ³å¡‘é€ &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://1000h.org/in-the-brain/01-inifinite.html"&gt;å¤§è„‘å†…éƒ¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://1000h.org/self-training/00-intro.html"&gt;è‡ªæˆ‘è®­ç»ƒ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;äººäººéƒ½èƒ½ç”¨è‹±è¯­ï¼ˆ2010ï¼‰&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/book/README.md"&gt;ç®€ä»‹&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/book/chapter1.md"&gt;ç¬¬ä¸€ç« ï¼šèµ·ç‚¹&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/book/chapter2.md"&gt;ç¬¬äºŒç« ï¼šå£è¯­&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/book/chapter3.md"&gt;ç¬¬ä¸‰ç« ï¼šè¯­éŸ³&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/book/chapter4.md"&gt;ç¬¬å››ç« ï¼šæœ—è¯»&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/book/chapter5.md"&gt;ç¬¬äº”ç« ï¼šè¯å…¸&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/book/chapter6.md"&gt;ç¬¬å…­ç« ï¼šè¯­æ³•&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/book/chapter7.md"&gt;ç¬¬ä¸ƒç« ï¼šç²¾è¯»&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/book/chapter8.md"&gt;ç¬¬å…«ç« ï¼šå®å˜±&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ZuodaoTech/everyone-can-use-english/main/book/end.md"&gt;åè®°&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;å¸¸è§é—®é¢˜&lt;/h2&gt; 
&lt;p&gt;è¯·æŸ¥è¯¢ &lt;a href="https://1000h.org/enjoy-app/faq.html"&gt;æ–‡æ¡£ FAQ&lt;/a&gt;ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dotnet/aspnetcore</title>
      <link>https://github.com/dotnet/aspnetcore</link>
      <description>&lt;p&gt;ASP.NET Core is a cross-platform .NET framework for building modern cloud-based web applications on Windows, Mac, or Linux.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ASP.NET Core&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.dotnetfoundation.org/"&gt;&lt;img src="https://img.shields.io/badge/.NET%20Foundation-blueviolet.svg?sanitize=true" alt=".NET Foundation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dotnet/aspnetcore/raw/main/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/github/license/dotnet/aspnetcore?color=%230b0&amp;amp;style=flat-square" alt="MIT License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dotnet/aspnetcore/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22"&gt;&lt;img src="https://img.shields.io/github/issues/dotnet/aspnetcore/help%20wanted?color=%232EA043&amp;amp;label=help%20wanted&amp;amp;style=flat-square" alt="Help Wanted" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dotnet/aspnetcore/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22"&gt;&lt;img src="https://img.shields.io/github/issues/dotnet/aspnetcore/good%20first%20issue?color=%23512BD4&amp;amp;label=good%20first%20issue&amp;amp;style=flat-square" alt="Good First Issues" /&gt;&lt;/a&gt; &lt;a href="https://aka.ms/dotnet-discord"&gt;&lt;img src="https://img.shields.io/discord/732297728826277939?style=flat-square&amp;amp;label=Discord&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;color=7289DA" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ASP.NET Core is an open-source and cross-platform framework for building modern cloud-based internet-connected applications, such as web apps, IoT apps, and mobile backends. ASP.NET Core apps run on &lt;a href="https://dot.net"&gt;.NET&lt;/a&gt;, a free, cross-platform, and open-source application runtime. It was architected to provide an optimized development framework for apps that are deployed to the cloud or run on-premises. It consists of modular components with minimal overhead, so you retain flexibility while constructing your solutions. You can develop and run your ASP.NET Core apps cross-platform on Windows, Mac, and Linux. &lt;a href="https://learn.microsoft.com/aspnet/core/"&gt;Learn more about ASP.NET Core&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;p&gt;Follow the &lt;a href="https://learn.microsoft.com/aspnet/core/getting-started"&gt;Getting Started&lt;/a&gt; instructions.&lt;/p&gt; 
&lt;p&gt;Also check out the &lt;a href="https://www.microsoft.com/net"&gt;.NET Homepage&lt;/a&gt; for released versions of .NET, getting started guides, and learning resources.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/dotnet/aspnetcore/raw/main/docs/TriageProcess.md"&gt;Triage Process&lt;/a&gt; document for more information on how we handle incoming issues.&lt;/p&gt; 
&lt;h2&gt;How to engage, contribute, and give feedback&lt;/h2&gt; 
&lt;p&gt;Some of the best ways to contribute are to try things out, file issues, join in design conversations, and make pull-requests.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dotnet/aspnetcore/main/docs/DailyBuilds.md"&gt;Download our latest daily builds&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow along with the development of ASP.NET Core: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://live.asp.net"&gt;Community Standup&lt;/a&gt;: The community standup is held every week and streamed live on YouTube. You can view past standups in the linked playlist.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://aka.ms/aspnet/roadmap"&gt;Roadmap&lt;/a&gt;: The schedule and milestone themes for ASP.NET Core.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/dotnet/aspnetcore/main/docs/BuildFromSource.md"&gt;Build ASP.NET Core source code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check out the &lt;a href="https://raw.githubusercontent.com/dotnet/aspnetcore/main/CONTRIBUTING.md"&gt;contributing&lt;/a&gt; page to see the best places to log issues and start discussions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Reporting security issues and bugs&lt;/h2&gt; 
&lt;p&gt;Security issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) &lt;a href="mailto:secure@microsoft.com"&gt;secure@microsoft.com&lt;/a&gt;. You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the MSRC PGP key, can be found in the &lt;a href="https://technet.microsoft.com/en-us/security/ff852094.aspx"&gt;Security TechCenter&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Related projects&lt;/h2&gt; 
&lt;p&gt;These are some other repos for related projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aspnet/Docs"&gt;Documentation&lt;/a&gt; - documentation sources for &lt;a href="https://learn.microsoft.com/aspnet/core/"&gt;https://learn.microsoft.com/aspnet/core/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dotnet/efcore"&gt;Entity Framework Core&lt;/a&gt; - data access technology&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dotnet/runtime"&gt;Runtime&lt;/a&gt; - cross-platform runtime for cloud, mobile, desktop, and IoT apps&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dotnet/razor"&gt;Razor&lt;/a&gt; - the Razor compiler and tooling for working with Razor syntax (.cshtml, .razor)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Code of conduct&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/dotnet/aspnetcore/main/CODE-OF-CONDUCT.md"&gt;CODE-OF-CONDUCT&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Nightly builds&lt;/h2&gt; 
&lt;p&gt;This table includes links to download the latest builds of the ASP.NET Core Shared Framework. Also included are links to download the Windows Hosting Bundle, which includes the ASP.NET Core Shared Framework, the .NET Runtime Shared Framework, and the IIS plugin (ASP.NET Core Module). You can download the latest .NET Runtime builds &lt;a href="https://github.com/dotnet/runtime/raw/main/docs/project/dogfooding.md#nightly-builds-table"&gt;here&lt;/a&gt;, and the latest .NET SDK builds &lt;a href="https://github.com/dotnet/installer#table"&gt;here&lt;/a&gt;. &lt;strong&gt;If you're unsure what you need, then install the SDK; it has everything except the IIS plugin.&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="center"&gt;Shared Framework (Installer)&lt;/th&gt; 
   &lt;th align="center"&gt;Shared Framework (Binaries)&lt;/th&gt; 
   &lt;th align="center"&gt;Hosting Bundle (Installer)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Windows x64&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-win-x64.exe"&gt;Installer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-win-x64.zip"&gt;Binaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/dotnet-hosting-win.exe"&gt;Installer&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Windows x86&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-win-x86.exe"&gt;Installer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-win-x86.zip"&gt;Binaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/dotnet-hosting-win.exe"&gt;Installer&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Windows arm64&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-win-arm64.exe"&gt;Installer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-win-arm64.zip"&gt;Binaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/dotnet-hosting-win.exe"&gt;Installer&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;macOS x64&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-osx-x64.tar.gz"&gt;Binaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;macOS arm64&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-osx-arm64.tar.gz"&gt;Binaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Linux x64&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-x64.deb"&gt;Deb Installer&lt;/a&gt; - &lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-x64.rpm"&gt;RPM Installer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-linux-x64.tar.gz"&gt;Binaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Linux arm&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-linux-arm.tar.gz"&gt;Binaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Linux arm64&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-aarch64.rpm"&gt;RPM Installer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-linux-arm64.tar.gz"&gt;Binaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Linux-musl-x64&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-linux-musl-x64.tar.gz"&gt;Binaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Linux-musl-arm&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-linux-musl-arm.tar.gz"&gt;Binaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Linux-musl-arm64&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://aka.ms/dotnet/10.0/daily/aspnetcore-runtime-linux-musl-arm64.tar.gz"&gt;Binaries&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;N/A&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>oauth2-proxy/oauth2-proxy</title>
      <link>https://github.com/oauth2-proxy/oauth2-proxy</link>
      <description>&lt;p&gt;A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Continuous Integration" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/oauth2-proxy/oauth2-proxy"&gt;&lt;img src="https://goreportcard.com/badge/github.com/oauth2-proxy/oauth2-proxy" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/oauth2-proxy/oauth2-proxy"&gt;&lt;img src="https://godoc.org/github.com/oauth2-proxy/oauth2-proxy?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT licensed" /&gt;&lt;/a&gt; &lt;a href="https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/maintainability"&gt;&lt;img src="https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/maintainability" alt="Maintainability" /&gt;&lt;/a&gt; &lt;a href="https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/test_coverage"&gt;&lt;img src="https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/test_coverage" alt="Test Coverage" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/docs/static/img/logos/OAuth2_Proxy_horizontal.svg?sanitize=true" alt="OAuth2 Proxy" /&gt;&lt;/p&gt; 
&lt;p&gt;OAuth2-Proxy is a flexible, open-source tool that can act as either a standalone reverse proxy or a middleware component integrated into existing reverse proxy or load balancer setups. It provides a simple and secure way to protect your web applications with OAuth2 / OIDC authentication. As a reverse proxy, it intercepts requests to your application and redirects users to an OAuth2 provider for authentication. As a middleware, it can be seamlessly integrated into your existing infrastructure to handle authentication for multiple applications.&lt;/p&gt; 
&lt;p&gt;OAuth2-Proxy supports a lot of OAuth2 as well as OIDC providers. Either through a generic OIDC client or a specific implementation for Google, Microsoft Entra ID, GitHub, login.gov and others. Through specialised provider implementations oauth2-proxy can extract more details about the user like preferred usernames and groups. Those details can then be forwarded as HTTP headers to your upstream applications.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/docs/static/img/simplified-architecture.svg?sanitize=true" alt="Simplified Architecture" /&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;OAuth2-Proxy's &lt;a href="https://oauth2-proxy.github.io/oauth2-proxy/installation"&gt;Installation Docs&lt;/a&gt; cover how to install and configure your setup. Additionally you can take a further look at the &lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/tree/master/contrib/local-environment"&gt;example setup files&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;h3&gt;Binaries&lt;/h3&gt; 
&lt;p&gt;We publish oauth2-proxy as compiled binaries on GitHub for all major architectures as well as more exotic ones like &lt;code&gt;ppc64le&lt;/code&gt; as well as &lt;code&gt;s390x&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/releases/latest"&gt;latest release&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Images&lt;/h3&gt; 
&lt;p&gt;From &lt;code&gt;v7.6.0&lt;/code&gt; and up the base image has been changed from Alpine to &lt;a href="https://github.com/GoogleContainerTools/distroless"&gt;GoogleContainerTools/distroless&lt;/a&gt;. This image comes with even fewer installed dependencies and thus should improve security. The image therefore is also slightly smaller than Alpine. For debugging purposes (and those who really need it. e.g. &lt;code&gt;armv6&lt;/code&gt;) we still provide images based on Alpine. The tags of these images are suffixed with &lt;code&gt;-alpine&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Since 2023-11-18 we build nightly images directly from the &lt;code&gt;master&lt;/code&gt; branch and provide them at &lt;code&gt;quay.io/oauth2-proxy/oauth2-proxy-nightly&lt;/code&gt;. These images are considered unstable and therefore should &lt;strong&gt;NOT&lt;/strong&gt; be used for production purposes unless you know what you're doing.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/9/96/Microsoft_logo_%282012%29.svg?sanitize=true" alt="Microsoft" /&gt; Microsoft Azure credits for open source projects&lt;/p&gt; 
&lt;p&gt;Would you like to sponsor the project then please contact us at &lt;a href="mailto:sponsors@oauth2-proxy.dev"&gt;sponsors@oauth2-proxy.dev&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Getting Involved&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://gophers.slack.com/archives/CM2RSS25N"&gt;&lt;img src="https://img.shields.io/badge/slack-Gopher_%23oauth2--proxy-red?logo=slack" alt="Slack" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Join the #oauth2-proxy &lt;a href="https://gophers.slack.com/archives/CM2RSS25N"&gt;Slack channel&lt;/a&gt; to chat with other users of oauth2-proxy or reach out to the maintainers directly. Use the &lt;a href="https://invite.slack.golangbridge.org/"&gt;public invite link&lt;/a&gt; to get an invite for the Gopher Slack space.&lt;/p&gt; 
&lt;p&gt;OAuth2-Proxy is a community-driven project. We rely on the contributï¸ions of our users to continually improve it. While review times can vary, we appreciate your patience and understanding. As a volunteer-driven project, we strive to keep this project stable and might take longer to merge changes.&lt;/p&gt; 
&lt;p&gt;If you want to contribute to the project. Please see our &lt;a href="https://oauth2-proxy.github.io/oauth2-proxy/community/contribution"&gt;Contributing&lt;/a&gt; guide.&lt;/p&gt; 
&lt;p&gt;Who uses OAuth2-Proxy? Have a look at our new &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/ADOPTERS.md"&gt;ADOPTERS&lt;/a&gt; file and feel free to open a PR to add your organisation.&lt;/p&gt; 
&lt;p&gt;Thanks to all the people who already contributed â¤&lt;/p&gt; 
&lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=oauth2-proxy/oauth2-proxy&amp;amp;columns=15&amp;amp;max=75" /&gt; &lt;img src="https://img.shields.io/github/contributors/oauth2-proxy/oauth2-proxy" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you believe you have found a vulnerability within OAuth2 Proxy or any of its dependencies, please do &lt;strong&gt;NOT&lt;/strong&gt; open an issue or PR on GitHub, please do &lt;strong&gt;NOT&lt;/strong&gt; post any details publicly.&lt;/p&gt; 
&lt;p&gt;Security disclosures &lt;strong&gt;MUST&lt;/strong&gt; be done in private. If you have found an issue that you would like to bring to the attention of the maintainers, please compose an email and send it to the list of people listed in our &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/MAINTAINERS"&gt;MAINTAINERS&lt;/a&gt; file.&lt;/p&gt; 
&lt;p&gt;For more details read our full &lt;a href="https://oauth2-proxy.github.io/oauth2-proxy/community/security#security-disclosures"&gt;Security Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Security Notice for v6.0.0 and older&lt;/h3&gt; 
&lt;p&gt;If you are running a version older than v6.0.0 we &lt;strong&gt;strongly recommend&lt;/strong&gt; to the current version.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://github.com/oauth2-proxy/oauth2-proxy/security/advisories/GHSA-5m6c-jp6f-2vcv"&gt;open redirect vulnerability&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Repository History&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;2018-11-27:&lt;/strong&gt; This repository was forked from &lt;a href="https://github.com/bitly/oauth2_proxy"&gt;bitly/OAuth2_Proxy&lt;/a&gt;. Versions v3.0.0 and up are from this fork and will have diverged from any changes in the original fork. A list of changes can be seen in the &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2020-03-29:&lt;/strong&gt; This project was formerly hosted as &lt;code&gt;pusher/oauth2_proxy&lt;/code&gt; but has been renamed to &lt;code&gt;oauth2-proxy/oauth2-proxy&lt;/code&gt;. Going forward, all images shall be available at &lt;code&gt;quay.io/oauth2-proxy/oauth2-proxy&lt;/code&gt; and binaries will be named &lt;code&gt;oauth2-proxy&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;OAuth2-Proxy is distributed under &lt;a href="https://raw.githubusercontent.com/oauth2-proxy/oauth2-proxy/master/LICENSE"&gt;The MIT License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>wanghongenpin/proxypin</title>
      <link>https://github.com/wanghongenpin/proxypin</link>
      <description>&lt;p&gt;Open source free capture HTTP(S) traffic software ProxyPin, supporting full platform systems&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ProxyPin&lt;/h1&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/wanghongenpin/proxypin/main/README_CN.md"&gt;ä¸­æ–‡&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Open source free traffic capture HTTP(S)ï¼ŒSupport Windowsã€Macã€Androidã€IOSã€Linux Full platform system&lt;/h2&gt; 
&lt;p&gt;You can use it to intercept, inspect &amp;amp; rewrite HTTP(S) traffic, Support capturing Flutter app traffic, ProxyPin is based on Flutter develop, and the UI is beautiful and easy to use.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Mobile scan code connection: no need to manually configure WiFi proxy, including configuration synchronization. All terminals can scan codes to connect and forward traffic to each other.&lt;/li&gt; 
 &lt;li&gt;Domain name filtering: Only intercept the traffic you need, and do not intercept other traffic to avoid interference with other applications.&lt;/li&gt; 
 &lt;li&gt;Search: Search requests according to keywords, response types and other conditions&lt;/li&gt; 
 &lt;li&gt;Script: Support writing JavaScript scripts to process requests or responses.&lt;/li&gt; 
 &lt;li&gt;Request rewrite: Support redirection, support replacement of request or response message, and can also modify request or response according to the increase.&lt;/li&gt; 
 &lt;li&gt;Request mapping: Do not request remote services, use local configuration or scripts for response&lt;/li&gt; 
 &lt;li&gt;Request blocking: Support blocking requests according to URL, and do not send requests to the server.&lt;/li&gt; 
 &lt;li&gt;History: Automatically save the captured traffic data for easy backtracking and viewing. Support HAR format export and import.&lt;/li&gt; 
 &lt;li&gt;Others: Favorites, toolbox, common encoding tools, as well as QR codes, regular expressions, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Mac will prompt untrusted developers when first opened, you need to go to System Preferences-Security &amp;amp; Privacy-Allow any source.&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;If ProxyPin is helpful to you, you are welcome to support us in the following ways to help the project develop in the long term:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://buymeacoffee.com/proxypin"&gt;Buy Me A Coffee&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://afdian.com/a/proxypin"&gt;AFDIAN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Submit feedback and suggestions to help us improve&lt;/li&gt; 
 &lt;li&gt;Contribute code or documentation to the project&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Your support will be used for project maintenance, feature development, and user experience optimization. Thank you very much!&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Downloads&lt;/h2&gt; 
&lt;p&gt;Github Releases: &lt;a href="https://github.com/wanghongenpin/proxypin/releases"&gt;https://github.com/wanghongenpin/proxypin/releases&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;iOS App Storeï¼š&lt;a href="https://apps.apple.com/app/proxypin/id6450932949"&gt;https://apps.apple.com/app/proxypin/id6450932949&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Android Google Playï¼š&lt;a href="https://play.google.com/store/apps/details?id=com.network.proxy"&gt;https://play.google.com/store/apps/details?id=com.network.proxy&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;TG: &lt;a href="https://t.me/proxypin_en"&gt;https://t.me/proxypin_en&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We will continue to improve the features and experience, as well as optimize the UI.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img alt="image" width="580px" height="420px" src="https://github.com/user-attachments/assets/6c1345ab-c95c-415d-ac59-470c764b59a2" /&gt;.&lt;img alt="image" height="500px" src="https://github.com/user-attachments/assets/3c5572b0-a9e5-497c-8b42-f935e836c164" /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gin-gonic/gin</title>
      <link>https://github.com/gin-gonic/gin</link>
      <description>&lt;p&gt;Gin is a high-performance HTTP web framework written in Go. It provides a Martini-like API but with significantly better performanceâ€”up to 40 times fasterâ€”thanks to httprouter. Gin is designed for building REST APIs, web applications, and microservices.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gin Web Framework&lt;/h1&gt; 
&lt;img align="right" width="159px" src="https://raw.githubusercontent.com/gin-gonic/logo/master/color.png" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/gin-gonic/gin/actions/workflows/gin.yml"&gt;&lt;img src="https://github.com/gin-gonic/gin/actions/workflows/gin.yml/badge.svg?branch=master" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/gin-gonic/gin"&gt;&lt;img src="https://codecov.io/gh/gin-gonic/gin/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/gin-gonic/gin"&gt;&lt;img src="https://goreportcard.com/badge/github.com/gin-gonic/gin" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin?tab=doc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/gin-gonic/gin?status.svg?sanitize=true" alt="Go Reference" /&gt;&lt;/a&gt; &lt;a href="https://sourcegraph.com/github.com/gin-gonic/gin?badge"&gt;&lt;img src="https://sourcegraph.com/github.com/gin-gonic/gin/-/badge.svg?sanitize=true" alt="Sourcegraph" /&gt;&lt;/a&gt; &lt;a href="https://www.codetriage.com/gin-gonic/gin"&gt;&lt;img src="https://www.codetriage.com/gin-gonic/gin/badges/users.svg?sanitize=true" alt="Open Source Helpers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/gin-gonic/gin/releases"&gt;&lt;img src="https://img.shields.io/github/release/gin-gonic/gin.svg?style=flat-square" alt="Release" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“° &lt;a href="https://gin-gonic.com/en/blog/news/gin-1-11-0-release-announcement/"&gt;Announcing Gin 1.11.0!&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Read about the latest features and improvements in Gin 1.11.0 on our official blog.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Gin is a high-performance HTTP web framework written in &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt;. It provides a Martini-like API but with significantly better performanceâ€”up to 40 times fasterâ€”thanks to &lt;a href="https://github.com/julienschmidt/httprouter"&gt;httprouter&lt;/a&gt;. Gin is designed for building REST APIs, web applications, and microservices where speed and developer productivity are essential.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why choose Gin?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Gin combines the simplicity of Express.js-style routing with Go's performance characteristics, making it ideal for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Building high-throughput REST APIs&lt;/li&gt; 
 &lt;li&gt;Developing microservices that need to handle many concurrent requests&lt;/li&gt; 
 &lt;li&gt;Creating web applications that require fast response times&lt;/li&gt; 
 &lt;li&gt;Prototyping web services quickly with minimal boilerplate&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Gin's key features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero allocation router&lt;/strong&gt; - Extremely memory-efficient routing with no heap allocations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High performance&lt;/strong&gt; - Benchmarks show superior speed compared to other Go web frameworks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Middleware support&lt;/strong&gt; - Extensible middleware system for authentication, logging, CORS, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Crash-free&lt;/strong&gt; - Built-in recovery middleware prevents panics from crashing your server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;JSON validation&lt;/strong&gt; - Automatic request/response JSON binding and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Route grouping&lt;/strong&gt; - Organize related routes and apply common middleware&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Error management&lt;/strong&gt; - Centralized error handling and logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Built-in rendering&lt;/strong&gt; - Support for JSON, XML, HTML templates, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt; - Large ecosystem of community middleware and plugins&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Go version&lt;/strong&gt;: Gin requires &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt; version &lt;a href="https://go.dev/doc/devel/release#go1.23.0"&gt;1.23&lt;/a&gt; or above&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic Go knowledge&lt;/strong&gt;: Familiarity with Go syntax and package management is helpful&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;With &lt;a href="https://go.dev/wiki/Modules#how-to-use-modules"&gt;Go's module support&lt;/a&gt;, simply import Gin in your code and Go will automatically fetch it during build:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import "github.com/gin-gonic/gin"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Your First Gin Application&lt;/h3&gt; 
&lt;p&gt;Here's a complete example that demonstrates Gin's simplicity:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "net/http"

  "github.com/gin-gonic/gin"
)

func main() {
  // Create a Gin router with default middleware (logger and recovery)
  r := gin.Default()
  
  // Define a simple GET endpoint
  r.GET("/ping", func(c *gin.Context) {
    // Return JSON response
    c.JSON(http.StatusOK, gin.H{
      "message": "pong",
    })
  })
  
  // Start server on port 8080 (default)
  // Server will listen on 0.0.0.0:8080 (localhost:8080 on Windows)
  r.Run()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Running the application:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Save the code above as &lt;code&gt;main.go&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run the application:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;go run main.go
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Open your browser and visit &lt;a href="http://localhost:8080/ping"&gt;&lt;code&gt;http://localhost:8080/ping&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You should see: &lt;code&gt;{"message":"pong"}&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;What this example demonstrates:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Creating a Gin router with default middleware&lt;/li&gt; 
 &lt;li&gt;Defining HTTP endpoints with simple handler functions&lt;/li&gt; 
 &lt;li&gt;Returning JSON responses&lt;/li&gt; 
 &lt;li&gt;Starting an HTTP server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Next Steps&lt;/h3&gt; 
&lt;p&gt;After running your first Gin application, explore these resources to learn more:&lt;/p&gt; 
&lt;h4&gt;ğŸ“š Learning Resources&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/docs/doc.md"&gt;Gin Quick Start Guide&lt;/a&gt;&lt;/strong&gt; - Comprehensive tutorial with API examples and build configurations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/examples"&gt;Example Repository&lt;/a&gt;&lt;/strong&gt; - Ready-to-run examples demonstrating various Gin use cases: 
  &lt;ul&gt; 
   &lt;li&gt;REST API development&lt;/li&gt; 
   &lt;li&gt;Authentication &amp;amp; middleware&lt;/li&gt; 
   &lt;li&gt;File uploads and downloads&lt;/li&gt; 
   &lt;li&gt;WebSocket connections&lt;/li&gt; 
   &lt;li&gt;Template rendering&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“– Documentation&lt;/h2&gt; 
&lt;h3&gt;API Reference&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://pkg.go.dev/github.com/gin-gonic/gin"&gt;Go.dev API Documentation&lt;/a&gt;&lt;/strong&gt; - Complete API reference with examples&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Guides&lt;/h3&gt; 
&lt;p&gt;The comprehensive documentation is available on &lt;a href="https://gin-gonic.com"&gt;gin-gonic.com&lt;/a&gt; in multiple languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/en/docs/"&gt;English&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-cn/docs/"&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://gin-gonic.com/zh-tw/docs/"&gt;ç¹é«”ä¸­æ–‡&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ja/docs/"&gt;æ—¥æœ¬èª&lt;/a&gt; | &lt;a href="https://gin-gonic.com/ko-kr/docs/"&gt;í•œêµ­ì–´&lt;/a&gt; | &lt;a href="https://gin-gonic.com/es/docs/"&gt;EspaÃ±ol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/tr/docs/"&gt;Turkish&lt;/a&gt; | &lt;a href="https://gin-gonic.com/fa/docs/"&gt;Persian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/pt/docs/"&gt;PortuguÃªs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gin-gonic.com/ru/docs/"&gt;Russian&lt;/a&gt; | &lt;a href="https://gin-gonic.com/id/docs/"&gt;Indonesian&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Official Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://go.dev/doc/tutorial/web-service-gin"&gt;Go.dev Tutorial: Developing a RESTful API with Go and Gin&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;âš¡ Performance Benchmarks&lt;/h2&gt; 
&lt;p&gt;Gin demonstrates exceptional performance compared to other Go web frameworks. It uses a custom version of &lt;a href="https://github.com/julienschmidt/httprouter"&gt;HttpRouter&lt;/a&gt; for maximum efficiency. &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/BENCHMARKS.md"&gt;View detailed benchmarks â†’&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Gin vs. Other Go Frameworks&lt;/strong&gt; (GitHub API routing benchmark):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Benchmark name&lt;/th&gt; 
   &lt;th align="right"&gt;(1)&lt;/th&gt; 
   &lt;th align="right"&gt;(2)&lt;/th&gt; 
   &lt;th align="right"&gt;(3)&lt;/th&gt; 
   &lt;th align="right"&gt;(4)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGin_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;43550&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;27364 ns/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 B/op&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="right"&gt;&lt;strong&gt;0 allocs/op&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAce_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;40543&lt;/td&gt; 
   &lt;td align="right"&gt;29670 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkAero_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;57632&lt;/td&gt; 
   &lt;td align="right"&gt;20648 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBear_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;9234&lt;/td&gt; 
   &lt;td align="right"&gt;216179 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;86448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;943 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBeego_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7407&lt;/td&gt; 
   &lt;td align="right"&gt;243496 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;71456 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkBone_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;420&lt;/td&gt; 
   &lt;td align="right"&gt;2922835 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;720160 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;8620 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkChi_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;7620&lt;/td&gt; 
   &lt;td align="right"&gt;238331 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;87696 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkDenco_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;18355&lt;/td&gt; 
   &lt;td align="right"&gt;64494 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;20224 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkEcho_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;31251&lt;/td&gt; 
   &lt;td align="right"&gt;38479 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGocraftWeb_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;4117&lt;/td&gt; 
   &lt;td align="right"&gt;300062 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;131656 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1686 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoji_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3274&lt;/td&gt; 
   &lt;td align="right"&gt;416158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;56112 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;334 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGojiv2_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;1402&lt;/td&gt; 
   &lt;td align="right"&gt;870518 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;352720 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4321 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoJsonRest_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2976&lt;/td&gt; 
   &lt;td align="right"&gt;401507 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;134371 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2737 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGoRestful_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;410&lt;/td&gt; 
   &lt;td align="right"&gt;2913158 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;910144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2938 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGorillaMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;346&lt;/td&gt; 
   &lt;td align="right"&gt;3384987 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;251650 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1994 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkGowwwRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;143025 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;72144 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;501 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpRouter_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;55938&lt;/td&gt; 
   &lt;td align="right"&gt;21360 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkHttpTreeMux_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;153944 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;65856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;671 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkKocha_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;106315 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;23304 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;843 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkLARS_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;47779&lt;/td&gt; 
   &lt;td align="right"&gt;25084 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMacaron_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;3266&lt;/td&gt; 
   &lt;td align="right"&gt;371907 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;149409 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1624 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkMartini_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;331&lt;/td&gt; 
   &lt;td align="right"&gt;3444706 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;226551 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;2325 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPat_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;273&lt;/td&gt; 
   &lt;td align="right"&gt;4381818 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;1483152 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;26963 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkPossum_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;164367 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;84448 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkR2router_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;10000&lt;/td&gt; 
   &lt;td align="right"&gt;160220 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;77328 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;979 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkRivet_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;14625&lt;/td&gt; 
   &lt;td align="right"&gt;82453 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;16272 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;167 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTango_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6255&lt;/td&gt; 
   &lt;td align="right"&gt;279611 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;63826 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;1618 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTigerTonic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;2008&lt;/td&gt; 
   &lt;td align="right"&gt;687874 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;193856 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;4474 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkTraffic_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;355&lt;/td&gt; 
   &lt;td align="right"&gt;3478508 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;820744 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;14114 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BenchmarkVulcan_GithubAll&lt;/td&gt; 
   &lt;td align="right"&gt;6885&lt;/td&gt; 
   &lt;td align="right"&gt;193333 ns/op&lt;/td&gt; 
   &lt;td align="right"&gt;19894 B/op&lt;/td&gt; 
   &lt;td align="right"&gt;609 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;(1): Total Repetitions achieved in constant time, higher means more confident result&lt;/li&gt; 
 &lt;li&gt;(2): Single Repetition Duration (ns/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(3): Heap Memory (B/op), lower is better&lt;/li&gt; 
 &lt;li&gt;(4): Average Allocations per Repetition (allocs/op), lower is better&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ”Œ Middleware Ecosystem&lt;/h2&gt; 
&lt;p&gt;Gin has a rich ecosystem of middleware for common web development needs. Explore community-contributed middleware:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-contrib"&gt;gin-contrib&lt;/a&gt;&lt;/strong&gt; - Official middleware collection including:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Authentication (JWT, Basic Auth, Sessions)&lt;/li&gt; 
   &lt;li&gt;CORS, Rate limiting, Compression&lt;/li&gt; 
   &lt;li&gt;Logging, Metrics, Tracing&lt;/li&gt; 
   &lt;li&gt;Static file serving, Template engines&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/gin-gonic/contrib"&gt;gin-gonic/contrib&lt;/a&gt;&lt;/strong&gt; - Additional community middleware&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¢ Production Usage&lt;/h2&gt; 
&lt;p&gt;Gin powers many high-traffic applications and services in production:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/appleboy/gorush"&gt;gorush&lt;/a&gt;&lt;/strong&gt; - High-performance push notification server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/fnproject/fn"&gt;fnproject&lt;/a&gt;&lt;/strong&gt; - Container-native, serverless platform&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/photoprism/photoprism"&gt;photoprism&lt;/a&gt;&lt;/strong&gt; - AI-powered personal photo management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/luraproject/lura"&gt;lura&lt;/a&gt;&lt;/strong&gt; - Ultra-performant API Gateway framework&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/thoas/picfit"&gt;picfit&lt;/a&gt;&lt;/strong&gt; - Real-time image processing server&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/distribworks/dkron"&gt;dkron&lt;/a&gt;&lt;/strong&gt; - Distributed job scheduling system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;Gin is the work of hundreds of contributors from around the world. We welcome and appreciate your contributions!&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› &lt;strong&gt;Report bugs&lt;/strong&gt; - Help us identify and fix issues&lt;/li&gt; 
 &lt;li&gt;ğŸ’¡ &lt;strong&gt;Suggest features&lt;/strong&gt; - Share your ideas for improvements&lt;/li&gt; 
 &lt;li&gt;ğŸ“ &lt;strong&gt;Improve documentation&lt;/strong&gt; - Help make our docs clearer&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ &lt;strong&gt;Submit code&lt;/strong&gt; - Fix bugs or implement new features&lt;/li&gt; 
 &lt;li&gt;ğŸ§ª &lt;strong&gt;Write tests&lt;/strong&gt; - Improve our test coverage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Getting Started with Contributing&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check out our &lt;a href="https://raw.githubusercontent.com/gin-gonic/gin/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for detailed guidelines&lt;/li&gt; 
 &lt;li&gt;Join our community discussions and ask questions&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;All contributions are valued and help make Gin better for everyone!&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>roboflow/supervision</title>
      <link>https://github.com/roboflow/supervision</link>
      <description>&lt;p&gt;We write your reusable computer vision tools. ğŸ’œ&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a align="center" href="" target="https://supervision.roboflow.com"&gt; &lt;img width="100%" src="https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/roboflow/notebooks"&gt;notebooks&lt;/a&gt; | &lt;a href="https://github.com/roboflow/inference"&gt;inference&lt;/a&gt; | &lt;a href="https://github.com/autodistill/autodistill"&gt;autodistill&lt;/a&gt; | &lt;a href="https://github.com/roboflow/multimodal-maestro"&gt;maestro&lt;/a&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://badge.fury.io/py/supervision.svg?sanitize=true" alt="version" /&gt;&lt;/a&gt; &lt;a href="https://pypistats.org/packages/supervision"&gt;&lt;img src="https://img.shields.io/pypi/dm/supervision" alt="downloads" /&gt;&lt;/a&gt; &lt;a href="https://snyk.io/advisor/python/supervision"&gt;&lt;img src="https://snyk.io/advisor/python/supervision/badge.svg?sanitize=true" alt="snyk" /&gt;&lt;/a&gt; &lt;a href="https://github.com/roboflow/supervision/raw/main/LICENSE.md"&gt;&lt;img src="https://img.shields.io/pypi/l/supervision" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/py/supervision"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/supervision" alt="python-version" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="colab" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/Roboflow/Annotators"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue" alt="gradio" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/GbfgXGJ8Bk"&gt;&lt;img src="https://img.shields.io/discord/1159501506232451173?logo=discord&amp;amp;label=discord&amp;amp;labelColor=fff&amp;amp;color=5865f2&amp;amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk" alt="discord" /&gt;&lt;/a&gt; &lt;a href="https://squidfunk.github.io/mkdocs-material/"&gt;&lt;img src="https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;amp;logoColor=white" alt="built-with-material-for-mkdocs" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/124" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/124" alt="roboflow%2Fsupervision | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ‘‹ hello&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We write your reusable computer vision tools.&lt;/strong&gt; Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ğŸ¤&lt;/p&gt; 
&lt;h2&gt;ğŸ’» install&lt;/h2&gt; 
&lt;p&gt;Pip install the supervision package in a &lt;a href="https://www.python.org/"&gt;&lt;strong&gt;Python&amp;gt;=3.9&lt;/strong&gt;&lt;/a&gt; environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install supervision
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about conda, mamba, and installing from source in our &lt;a href="https://roboflow.github.io/supervision/"&gt;guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ”¥ quickstart&lt;/h2&gt; 
&lt;h3&gt;models&lt;/h3&gt; 
&lt;p&gt;Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created &lt;a href="https://supervision.roboflow.com/latest/detection/core/#detections"&gt;connectors&lt;/a&gt; for the most popular libraries like Ultralytics, Transformers, or MMDetection.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO("yolov8s.pt")
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;ğŸ‘‰ more model connectors&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;inference&lt;/p&gt; &lt;p&gt;Running with &lt;a href="https://github.com/roboflow/inference"&gt;Inference&lt;/a&gt; requires a &lt;a href="https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key"&gt;Roboflow API KEY&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv
from inference import get_model

image = cv2.imread(...)
model = get_model(model_id="yolov8s-640", api_key=&amp;lt;ROBOFLOW API KEY&amp;gt;)
result = model.infer(image)[0]
detections = sv.Detections.from_inference(result)

len(detections)
# 5
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;annotators&lt;/h3&gt; 
&lt;p&gt;Supervision offers a wide range of highly customizable &lt;a href="https://supervision.roboflow.com/latest/detection/annotators/"&gt;annotators&lt;/a&gt;, allowing you to compose the perfect visualization for your use case.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce"&gt;https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;datasets&lt;/h3&gt; 
&lt;p&gt;Supervision provides a set of &lt;a href="https://supervision.roboflow.com/latest/datasets/core/"&gt;utils&lt;/a&gt; that allow you to load, split, merge, and save datasets in one of the supported formats.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&amp;lt;WORKSPACE_ID&amp;gt;).project(&amp;lt;PROJECT_ID&amp;gt;)
dataset = project.version(&amp;lt;PROJECT_VERSION&amp;gt;).download("coco")

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f"{dataset.location}/train",
    annotations_path=f"{dataset.location}/train/_annotations.coco.json",
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
&lt;/code&gt;&lt;/pre&gt; 
&lt;details close&gt; 
 &lt;summary&gt;ğŸ‘‰ more dataset utils&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;load&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset = sv.DetectionDataset.from_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset = sv.DetectionDataset.from_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;split&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;train_dataset, test_dataset = dataset.split(split_ratio=0.7)
test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

len(train_dataset), len(test_dataset), len(valid_dataset)
# (700, 150, 150)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;merge&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;ds_1 = sv.DetectionDataset(...)
len(ds_1)
# 100
ds_1.classes
# ['dog', 'person']

ds_2 = sv.DetectionDataset(...)
len(ds_2)
# 200
ds_2.classes
# ['cat']

ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
len(ds_merged)
# 300
ds_merged.classes
# ['cat', 'dog', 'person']
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;save&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;dataset.as_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset.as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset.as_coco(
    images_directory_path=...,
    annotations_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;convert&lt;/p&gt; &lt;pre&gt;&lt;code class="language-python"&gt;sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
).as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸ¬ tutorials&lt;/h2&gt; 
&lt;p&gt;Want to learn how to use Supervision? Explore our &lt;a href="https://supervision.roboflow.com/develop/how_to/detect_and_annotate/"&gt;how-to guides&lt;/a&gt;, &lt;a href="https://github.com/roboflow/supervision/tree/develop/examples"&gt;end-to-end examples&lt;/a&gt;, &lt;a href="https://roboflow.github.io/cheatsheet-supervision/"&gt;cheatsheet&lt;/a&gt;, and &lt;a href="https://supervision.roboflow.com/develop/cookbooks/"&gt;cookbooks&lt;/a&gt;!&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1" alt="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing" width="300px" align="left" /&gt;&lt;/a&gt; &lt;a href="https://youtu.be/hAWpsIuem10" title="Dwell Time Analysis with Computer Vision | Real-Time Stream Processing"&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br /&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.
&lt;p&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="left"&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;img src="https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91" alt="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source" width="300px" align="left" /&gt;&lt;/a&gt; &lt;a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source"&gt;&lt;strong&gt;Speed Estimation &amp;amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt; &lt;/p&gt;
&lt;div&gt;
 &lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;
&lt;/div&gt; 
&lt;br /&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.
&lt;p&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ’œ built with supervision&lt;/h2&gt; 
&lt;p&gt;Did you build something cool using supervision? &lt;a href="https://github.com/roboflow/supervision/discussions/categories/built-with-supervision"&gt;Let us know!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4"&gt;https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900"&gt;https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f"&gt;https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“š documentation&lt;/h2&gt; 
&lt;p&gt;Visit our &lt;a href="https://roboflow.github.io/supervision"&gt;documentation&lt;/a&gt; page to learn how supervision can help you build computer vision applications faster and more reliably.&lt;/p&gt; 
&lt;h2&gt;ğŸ† contribution&lt;/h2&gt; 
&lt;p&gt;We love your input! Please see our &lt;a href="https://github.com/roboflow/supervision/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started. Thank you ğŸ™ to all our contributors!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/roboflow/supervision/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=roboflow/supervision" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://youtube.com/roboflow"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634652" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949746649" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://www.linkedin.com/company/roboflow-ai/"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633691" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://docs.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949634511" width="3%" /&gt; &lt;/a&gt; 
  &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; 
  &lt;a href="https://discuss.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633584" width="3%" /&gt; &lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png" width="3%" /&gt; &lt;/a&gt;
  &lt;a href="https://blog.roboflow.com"&gt; &lt;img src="https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;amp;updatedAt=1672949633605" width="3%" /&gt; &lt;/a&gt;  
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>modelcontextprotocol/typescript-sdk</title>
      <link>https://github.com/modelcontextprotocol/typescript-sdk</link>
      <description>&lt;p&gt;The official TypeScript SDK for Model Context Protocol servers and clients&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MCP TypeScript SDK &lt;img src="https://img.shields.io/npm/v/%40modelcontextprotocol%2Fsdk" alt="NPM Version" /&gt; &lt;img src="https://img.shields.io/npm/l/%40modelcontextprotocol%2Fsdk" alt="MIT licensed" /&gt;&lt;/h1&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#quick-start"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#what-is-mcp"&gt;What is MCP?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#core-concepts"&gt;Core Concepts&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#server"&gt;Server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#resources"&gt;Resources&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#tools"&gt;Tools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#prompts"&gt;Prompts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#completions"&gt;Completions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#sampling"&gt;Sampling&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#running-your-server"&gt;Running Your Server&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#stdio"&gt;stdio&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#streamable-http"&gt;Streamable HTTP&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#testing-and-debugging"&gt;Testing and Debugging&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#examples"&gt;Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#echo-server"&gt;Echo Server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#sqlite-explorer"&gt;SQLite Explorer&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#advanced-usage"&gt;Advanced Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#dynamic-servers"&gt;Dynamic Servers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#low-level-server"&gt;Low-Level Server&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#writing-mcp-clients"&gt;Writing MCP Clients&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#proxy-authorization-requests-upstream"&gt;Proxy Authorization Requests Upstream&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#backwards-compatibility"&gt;Backwards Compatibility&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;The Model Context Protocol allows applications to provide context for LLMs in a standardized way, separating the concerns of providing context from the actual LLM interaction. This TypeScript SDK implements the full MCP specification, making it easy to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Build MCP clients that can connect to any MCP server&lt;/li&gt; 
 &lt;li&gt;Create MCP servers that expose resources, prompts and tools&lt;/li&gt; 
 &lt;li&gt;Use standard transports like stdio and Streamable HTTP&lt;/li&gt; 
 &lt;li&gt;Handle all MCP protocol messages and lifecycle events&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install @modelcontextprotocol/sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âš ï¸ MCP requires Node.js v18.x or higher to work fine.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Let's create a simple MCP server that exposes a calculator tool and some data:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { McpServer, ResourceTemplate } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { z } from "zod";

// Create an MCP server
const server = new McpServer({
  name: "demo-server",
  version: "1.0.0"
});

// Add an addition tool
server.registerTool("add",
  {
    title: "Addition Tool",
    description: "Add two numbers",
    inputSchema: { a: z.number(), b: z.number() }
  },
  async ({ a, b }) =&amp;gt; ({
    content: [{ type: "text", text: String(a + b) }]
  })
);

// Add a dynamic greeting resource
server.registerResource(
  "greeting",
  new ResourceTemplate("greeting://{name}", { list: undefined }),
  { 
    title: "Greeting Resource",      // Display name for UI
    description: "Dynamic greeting generator"
  },
  async (uri, { name }) =&amp;gt; ({
    contents: [{
      uri: uri.href,
      text: `Hello, ${name}!`
    }]
  })
);

// Start receiving messages on stdin and sending messages on stdout
const transport = new StdioServerTransport();
await server.connect(transport);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What is MCP?&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://modelcontextprotocol.io"&gt;Model Context Protocol (MCP)&lt;/a&gt; lets you build servers that expose data and functionality to LLM applications in a secure, standardized way. Think of it like a web API, but specifically designed for LLM interactions. MCP servers can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Expose data through &lt;strong&gt;Resources&lt;/strong&gt; (think of these sort of like GET endpoints; they are used to load information into the LLM's context)&lt;/li&gt; 
 &lt;li&gt;Provide functionality through &lt;strong&gt;Tools&lt;/strong&gt; (sort of like POST endpoints; they are used to execute code or otherwise produce a side effect)&lt;/li&gt; 
 &lt;li&gt;Define interaction patterns through &lt;strong&gt;Prompts&lt;/strong&gt; (reusable templates for LLM interactions)&lt;/li&gt; 
 &lt;li&gt;And more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Core Concepts&lt;/h2&gt; 
&lt;h3&gt;Server&lt;/h3&gt; 
&lt;p&gt;The McpServer is your core interface to the MCP protocol. It handles connection management, protocol compliance, and message routing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;const server = new McpServer({
  name: "my-app",
  version: "1.0.0"
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Resources&lt;/h3&gt; 
&lt;p&gt;Resources are how you expose data to LLMs. They're similar to GET endpoints in a REST API - they provide data but shouldn't perform significant computation or have side effects:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Static resource
server.registerResource(
  "config",
  "config://app",
  {
    title: "Application Config",
    description: "Application configuration data",
    mimeType: "text/plain"
  },
  async (uri) =&amp;gt; ({
    contents: [{
      uri: uri.href,
      text: "App configuration here"
    }]
  })
);

// Dynamic resource with parameters
server.registerResource(
  "user-profile",
  new ResourceTemplate("users://{userId}/profile", { list: undefined }),
  {
    title: "User Profile",
    description: "User profile information"
  },
  async (uri, { userId }) =&amp;gt; ({
    contents: [{
      uri: uri.href,
      text: `Profile data for user ${userId}`
    }]
  })
);

// Resource with context-aware completion
server.registerResource(
  "repository",
  new ResourceTemplate("github://repos/{owner}/{repo}", {
    list: undefined,
    complete: {
      // Provide intelligent completions based on previously resolved parameters
      repo: (value, context) =&amp;gt; {
        if (context?.arguments?.["owner"] === "org1") {
          return ["project1", "project2", "project3"].filter(r =&amp;gt; r.startsWith(value));
        }
        return ["default-repo"].filter(r =&amp;gt; r.startsWith(value));
      }
    }
  }),
  {
    title: "GitHub Repository",
    description: "Repository information"
  },
  async (uri, { owner, repo }) =&amp;gt; ({
    contents: [{
      uri: uri.href,
      text: `Repository: ${owner}/${repo}`
    }]
  })
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;Tools let LLMs take actions through your server. Unlike resources, tools are expected to perform computation and have side effects:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Simple tool with parameters
server.registerTool(
  "calculate-bmi",
  {
    title: "BMI Calculator",
    description: "Calculate Body Mass Index",
    inputSchema: {
      weightKg: z.number(),
      heightM: z.number()
    }
  },
  async ({ weightKg, heightM }) =&amp;gt; ({
    content: [{
      type: "text",
      text: String(weightKg / (heightM * heightM))
    }]
  })
);

// Async tool with external API call
server.registerTool(
  "fetch-weather",
  {
    title: "Weather Fetcher",
    description: "Get weather data for a city",
    inputSchema: { city: z.string() }
  },
  async ({ city }) =&amp;gt; {
    const response = await fetch(`https://api.weather.com/${city}`);
    const data = await response.text();
    return {
      content: [{ type: "text", text: data }]
    };
  }
);

// Tool that returns ResourceLinks
server.registerTool(
  "list-files",
  {
    title: "List Files",
    description: "List project files",
    inputSchema: { pattern: z.string() }
  },
  async ({ pattern }) =&amp;gt; ({
    content: [
      { type: "text", text: `Found files matching "${pattern}":` },
      // ResourceLinks let tools return references without file content
      {
        type: "resource_link",
        uri: "file:///project/README.md",
        name: "README.md",
        mimeType: "text/markdown",
        description: 'A README file'
      },
      {
        type: "resource_link",
        uri: "file:///project/src/index.ts",
        name: "index.ts",
        mimeType: "text/typescript",
        description: 'An index file'
      }
    ]
  })
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ResourceLinks&lt;/h4&gt; 
&lt;p&gt;Tools can return &lt;code&gt;ResourceLink&lt;/code&gt; objects to reference resources without embedding their full content. This is essential for performance when dealing with large files or many resources - clients can then selectively read only the resources they need using the provided URIs.&lt;/p&gt; 
&lt;h3&gt;Prompts&lt;/h3&gt; 
&lt;p&gt;Prompts are reusable templates that help LLMs interact with your server effectively:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { completable } from "@modelcontextprotocol/sdk/server/completable.js";

server.registerPrompt(
  "review-code",
  {
    title: "Code Review",
    description: "Review code for best practices and potential issues",
    argsSchema: { code: z.string() }
  },
  ({ code }) =&amp;gt; ({
    messages: [{
      role: "user",
      content: {
        type: "text",
        text: `Please review this code:\n\n${code}`
      }
    }]
  })
);

// Prompt with context-aware completion
server.registerPrompt(
  "team-greeting",
  {
    title: "Team Greeting",
    description: "Generate a greeting for team members",
    argsSchema: {
      department: completable(z.string(), (value) =&amp;gt; {
        // Department suggestions
        return ["engineering", "sales", "marketing", "support"].filter(d =&amp;gt; d.startsWith(value));
      }),
      name: completable(z.string(), (value, context) =&amp;gt; {
        // Name suggestions based on selected department
        const department = context?.arguments?.["department"];
        if (department === "engineering") {
          return ["Alice", "Bob", "Charlie"].filter(n =&amp;gt; n.startsWith(value));
        } else if (department === "sales") {
          return ["David", "Eve", "Frank"].filter(n =&amp;gt; n.startsWith(value));
        } else if (department === "marketing") {
          return ["Grace", "Henry", "Iris"].filter(n =&amp;gt; n.startsWith(value));
        }
        return ["Guest"].filter(n =&amp;gt; n.startsWith(value));
      })
    }
  },
  ({ department, name }) =&amp;gt; ({
    messages: [{
      role: "assistant",
      content: {
        type: "text",
        text: `Hello ${name}, welcome to the ${department} team!`
      }
    }]
  })
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Completions&lt;/h3&gt; 
&lt;p&gt;MCP supports argument completions to help users fill in prompt arguments and resource template parameters. See the examples above for &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#resources"&gt;resource completions&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/#prompts"&gt;prompt completions&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Client Usage&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Request completions for any argument
const result = await client.complete({
  ref: {
    type: "ref/prompt",  // or "ref/resource"
    name: "example"      // or uri: "template://..."
  },
  argument: {
    name: "argumentName",
    value: "partial"     // What the user has typed so far
  },
  context: {             // Optional: Include previously resolved arguments
    arguments: {
      previousArg: "value"
    }
  }
});

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Display Names and Metadata&lt;/h3&gt; 
&lt;p&gt;All resources, tools, and prompts support an optional &lt;code&gt;title&lt;/code&gt; field for better UI presentation. The &lt;code&gt;title&lt;/code&gt; is used as a display name, while &lt;code&gt;name&lt;/code&gt; remains the unique identifier.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The &lt;code&gt;register*&lt;/code&gt; methods (&lt;code&gt;registerTool&lt;/code&gt;, &lt;code&gt;registerPrompt&lt;/code&gt;, &lt;code&gt;registerResource&lt;/code&gt;) are the recommended approach for new code. The older methods (&lt;code&gt;tool&lt;/code&gt;, &lt;code&gt;prompt&lt;/code&gt;, &lt;code&gt;resource&lt;/code&gt;) remain available for backwards compatibility.&lt;/p&gt; 
&lt;h4&gt;Title Precedence for Tools&lt;/h4&gt; 
&lt;p&gt;For tools specifically, there are two ways to specify a title:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;title&lt;/code&gt; field in the tool configuration&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;annotations.title&lt;/code&gt; field (when using the older &lt;code&gt;tool()&lt;/code&gt; method with annotations)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The precedence order is: &lt;code&gt;title&lt;/code&gt; â†’ &lt;code&gt;annotations.title&lt;/code&gt; â†’ &lt;code&gt;name&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Using registerTool (recommended)
server.registerTool("my_tool", {
  title: "My Tool",              // This title takes precedence
  annotations: {
    title: "Annotation Title"    // This is ignored if title is set
  }
}, handler);

// Using tool with annotations (older API)
server.tool("my_tool", "description", {
  title: "Annotation Title"      // This is used as title
}, handler);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When building clients, use the provided utility to get the appropriate display name:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { getDisplayName } from "@modelcontextprotocol/sdk/shared/metadataUtils.js";

// Automatically handles the precedence: title â†’ annotations.title â†’ name
const displayName = getDisplayName(tool);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Sampling&lt;/h3&gt; 
&lt;p&gt;MCP servers can request LLM completions from connected clients that support sampling.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { z } from "zod";

const mcpServer = new McpServer({
  name: "tools-with-sample-server",
  version: "1.0.0",
});

// Tool that uses LLM sampling to summarize any text
mcpServer.registerTool(
  "summarize",
  {
    description: "Summarize any text using an LLM",
    inputSchema: {
      text: z.string().describe("Text to summarize"),
    },
  },
  async ({ text }) =&amp;gt; {
    // Call the LLM through MCP sampling
    const response = await mcpServer.server.createMessage({
      messages: [
        {
          role: "user",
          content: {
            type: "text",
            text: `Please summarize the following text concisely:\n\n${text}`,
          },
        },
      ],
      maxTokens: 500,
    });

    return {
      content: [
        {
          type: "text",
          text: response.content.type === "text" ? response.content.text : "Unable to generate summary",
        },
      ],
    };
  }
);

async function main() {
  const transport = new StdioServerTransport();
  await mcpServer.connect(transport);
  console.error("MCP server is running...");
}

main().catch((error) =&amp;gt; {
  console.error("Server error:", error);
  process.exit(1);
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Running Your Server&lt;/h2&gt; 
&lt;p&gt;MCP servers in TypeScript need to be connected to a transport to communicate with clients. How you start the server depends on the choice of transport:&lt;/p&gt; 
&lt;h3&gt;stdio&lt;/h3&gt; 
&lt;p&gt;For command-line tools and direct integrations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

const server = new McpServer({
  name: "example-server",
  version: "1.0.0"
});

// ... set up server resources, tools, and prompts ...

const transport = new StdioServerTransport();
await server.connect(transport);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Streamable HTTP&lt;/h3&gt; 
&lt;p&gt;For remote servers, set up a Streamable HTTP transport that handles both client requests and server-to-client notifications.&lt;/p&gt; 
&lt;h4&gt;With Session Management&lt;/h4&gt; 
&lt;p&gt;In some cases, servers need to be stateful. This is achieved by &lt;a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#session-management"&gt;session management&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import express from "express";
import { randomUUID } from "node:crypto";
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StreamableHTTPServerTransport } from "@modelcontextprotocol/sdk/server/streamableHttp.js";
import { isInitializeRequest } from "@modelcontextprotocol/sdk/types.js"



const app = express();
app.use(express.json());

// Map to store transports by session ID
const transports: { [sessionId: string]: StreamableHTTPServerTransport } = {};

// Handle POST requests for client-to-server communication
app.post('/mcp', async (req, res) =&amp;gt; {
  // Check for existing session ID
  const sessionId = req.headers['mcp-session-id'] as string | undefined;
  let transport: StreamableHTTPServerTransport;

  if (sessionId &amp;amp;&amp;amp; transports[sessionId]) {
    // Reuse existing transport
    transport = transports[sessionId];
  } else if (!sessionId &amp;amp;&amp;amp; isInitializeRequest(req.body)) {
    // New initialization request
    transport = new StreamableHTTPServerTransport({
      sessionIdGenerator: () =&amp;gt; randomUUID(),
      onsessioninitialized: (sessionId) =&amp;gt; {
        // Store the transport by session ID
        transports[sessionId] = transport;
      },
      // DNS rebinding protection is disabled by default for backwards compatibility. If you are running this server
      // locally, make sure to set:
      // enableDnsRebindingProtection: true,
      // allowedHosts: ['127.0.0.1'],
    });

    // Clean up transport when closed
    transport.onclose = () =&amp;gt; {
      if (transport.sessionId) {
        delete transports[transport.sessionId];
      }
    };
    const server = new McpServer({
      name: "example-server",
      version: "1.0.0"
    });

    // ... set up server resources, tools, and prompts ...

    // Connect to the MCP server
    await server.connect(transport);
  } else {
    // Invalid request
    res.status(400).json({
      jsonrpc: '2.0',
      error: {
        code: -32000,
        message: 'Bad Request: No valid session ID provided',
      },
      id: null,
    });
    return;
  }

  // Handle the request
  await transport.handleRequest(req, res, req.body);
});

// Reusable handler for GET and DELETE requests
const handleSessionRequest = async (req: express.Request, res: express.Response) =&amp;gt; {
  const sessionId = req.headers['mcp-session-id'] as string | undefined;
  if (!sessionId || !transports[sessionId]) {
    res.status(400).send('Invalid or missing session ID');
    return;
  }
  
  const transport = transports[sessionId];
  await transport.handleRequest(req, res);
};

// Handle GET requests for server-to-client notifications via SSE
app.get('/mcp', handleSessionRequest);

// Handle DELETE requests for session termination
app.delete('/mcp', handleSessionRequest);

app.listen(3000);
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] When using this in a remote environment, make sure to allow the header parameter &lt;code&gt;mcp-session-id&lt;/code&gt; in CORS. Otherwise, it may result in a &lt;code&gt;Bad Request: No valid session ID provided&lt;/code&gt; error. Read the following section for examples.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;CORS Configuration for Browser-Based Clients&lt;/h4&gt; 
&lt;p&gt;If you'd like your server to be accessible by browser-based MCP clients, you'll need to configure CORS headers. The &lt;code&gt;Mcp-Session-Id&lt;/code&gt; header must be exposed for browser clients to access it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import cors from 'cors';

// Add CORS middleware before your MCP routes
app.use(cors({
  origin: '*', // Configure appropriately for production, for example:
  // origin: ['https://your-remote-domain.com', 'https://your-other-remote-domain.com'],
  exposedHeaders: ['Mcp-Session-Id'],
  allowedHeaders: ['Content-Type', 'mcp-session-id'],
}));
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This configuration is necessary because:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The MCP streamable HTTP transport uses the &lt;code&gt;Mcp-Session-Id&lt;/code&gt; header for session management&lt;/li&gt; 
 &lt;li&gt;Browsers restrict access to response headers unless explicitly exposed via CORS&lt;/li&gt; 
 &lt;li&gt;Without this configuration, browser-based clients won't be able to read the session ID from initialization responses&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Without Session Management (Stateless)&lt;/h4&gt; 
&lt;p&gt;For simpler use cases where session management isn't needed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;const app = express();
app.use(express.json());

app.post('/mcp', async (req: Request, res: Response) =&amp;gt; {
  // In stateless mode, create a new instance of transport and server for each request
  // to ensure complete isolation. A single instance would cause request ID collisions
  // when multiple clients connect concurrently.
  
  try {
    const server = getServer(); 
    const transport: StreamableHTTPServerTransport = new StreamableHTTPServerTransport({
      sessionIdGenerator: undefined,
    });
    res.on('close', () =&amp;gt; {
      console.log('Request closed');
      transport.close();
      server.close();
    });
    await server.connect(transport);
    await transport.handleRequest(req, res, req.body);
  } catch (error) {
    console.error('Error handling MCP request:', error);
    if (!res.headersSent) {
      res.status(500).json({
        jsonrpc: '2.0',
        error: {
          code: -32603,
          message: 'Internal server error',
        },
        id: null,
      });
    }
  }
});

// SSE notifications not supported in stateless mode
app.get('/mcp', async (req: Request, res: Response) =&amp;gt; {
  console.log('Received GET MCP request');
  res.writeHead(405).end(JSON.stringify({
    jsonrpc: "2.0",
    error: {
      code: -32000,
      message: "Method not allowed."
    },
    id: null
  }));
});

// Session termination not needed in stateless mode
app.delete('/mcp', async (req: Request, res: Response) =&amp;gt; {
  console.log('Received DELETE MCP request');
  res.writeHead(405).end(JSON.stringify({
    jsonrpc: "2.0",
    error: {
      code: -32000,
      message: "Method not allowed."
    },
    id: null
  }));
});


// Start the server
const PORT = 3000;
setupServer().then(() =&amp;gt; {
  app.listen(PORT, (error) =&amp;gt; {
    if (error) {
      console.error('Failed to start server:', error);
      process.exit(1);
    }
    console.log(`MCP Stateless Streamable HTTP Server listening on port ${PORT}`);
  });
}).catch(error =&amp;gt; {
  console.error('Failed to set up the server:', error);
  process.exit(1);
});

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This stateless approach is useful for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Simple API wrappers&lt;/li&gt; 
 &lt;li&gt;RESTful scenarios where each request is independent&lt;/li&gt; 
 &lt;li&gt;Horizontally scaled deployments without shared session state&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;DNS Rebinding Protection&lt;/h4&gt; 
&lt;p&gt;The Streamable HTTP transport includes DNS rebinding protection to prevent security vulnerabilities. By default, this protection is &lt;strong&gt;disabled&lt;/strong&gt; for backwards compatibility.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: If you are running this server locally, enable DNS rebinding protection:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;const transport = new StreamableHTTPServerTransport({
  sessionIdGenerator: () =&amp;gt; randomUUID(),
  enableDnsRebindingProtection: true,

  allowedHosts: ['127.0.0.1', ...],
  allowedOrigins: ['https://yourdomain.com', 'https://www.yourdomain.com']
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing and Debugging&lt;/h3&gt; 
&lt;p&gt;To test your server, you can use the &lt;a href="https://github.com/modelcontextprotocol/inspector"&gt;MCP Inspector&lt;/a&gt;. See its README for more information.&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;h3&gt;Echo Server&lt;/h3&gt; 
&lt;p&gt;A simple server demonstrating resources, tools, and prompts:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { McpServer, ResourceTemplate } from "@modelcontextprotocol/sdk/server/mcp.js";
import { z } from "zod";

const server = new McpServer({
  name: "echo-server",
  version: "1.0.0"
});

server.registerResource(
  "echo",
  new ResourceTemplate("echo://{message}", { list: undefined }),
  {
    title: "Echo Resource",
    description: "Echoes back messages as resources"
  },
  async (uri, { message }) =&amp;gt; ({
    contents: [{
      uri: uri.href,
      text: `Resource echo: ${message}`
    }]
  })
);

server.registerTool(
  "echo",
  {
    title: "Echo Tool",
    description: "Echoes back the provided message",
    inputSchema: { message: z.string() }
  },
  async ({ message }) =&amp;gt; ({
    content: [{ type: "text", text: `Tool echo: ${message}` }]
  })
);

server.registerPrompt(
  "echo",
  {
    title: "Echo Prompt",
    description: "Creates a prompt to process a message",
    argsSchema: { message: z.string() }
  },
  ({ message }) =&amp;gt; ({
    messages: [{
      role: "user",
      content: {
        type: "text",
        text: `Please process this message: ${message}`
      }
    }]
  })
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;SQLite Explorer&lt;/h3&gt; 
&lt;p&gt;A more complex example showing database integration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import sqlite3 from "sqlite3";
import { promisify } from "util";
import { z } from "zod";

const server = new McpServer({
  name: "sqlite-explorer",
  version: "1.0.0"
});

// Helper to create DB connection
const getDb = () =&amp;gt; {
  const db = new sqlite3.Database("database.db");
  return {
    all: promisify&amp;lt;string, any[]&amp;gt;(db.all.bind(db)),
    close: promisify(db.close.bind(db))
  };
};

server.registerResource(
  "schema",
  "schema://main",
  {
    title: "Database Schema",
    description: "SQLite database schema",
    mimeType: "text/plain"
  },
  async (uri) =&amp;gt; {
    const db = getDb();
    try {
      const tables = await db.all(
        "SELECT sql FROM sqlite_master WHERE type='table'"
      );
      return {
        contents: [{
          uri: uri.href,
          text: tables.map((t: {sql: string}) =&amp;gt; t.sql).join("\n")
        }]
      };
    } finally {
      await db.close();
    }
  }
);

server.registerTool(
  "query",
  {
    title: "SQL Query",
    description: "Execute SQL queries on the database",
    inputSchema: { sql: z.string() }
  },
  async ({ sql }) =&amp;gt; {
    const db = getDb();
    try {
      const results = await db.all(sql);
      return {
        content: [{
          type: "text",
          text: JSON.stringify(results, null, 2)
        }]
      };
    } catch (err: unknown) {
      const error = err as Error;
      return {
        content: [{
          type: "text",
          text: `Error: ${error.message}`
        }],
        isError: true
      };
    } finally {
      await db.close();
    }
  }
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Advanced Usage&lt;/h2&gt; 
&lt;h3&gt;Dynamic Servers&lt;/h3&gt; 
&lt;p&gt;If you want to offer an initial set of tools/prompts/resources, but later add additional ones based on user action or external state change, you can add/update/remove them &lt;em&gt;after&lt;/em&gt; the Server is connected. This will automatically emit the corresponding &lt;code&gt;listChanged&lt;/code&gt; notifications:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { z } from "zod";

const server = new McpServer({
  name: "Dynamic Example",
  version: "1.0.0"
});

const listMessageTool = server.tool(
  "listMessages",
  { channel: z.string() },
  async ({ channel }) =&amp;gt; ({
    content: [{ type: "text", text: await listMessages(channel) }]
  })
);

const putMessageTool = server.tool(
  "putMessage",
  { channel: z.string(), message: z.string() },
  async ({ channel, message }) =&amp;gt; ({
    content: [{ type: "text", text: await putMessage(channel, message) }]
  })
);
// Until we upgrade auth, `putMessage` is disabled (won't show up in listTools)
putMessageTool.disable()

const upgradeAuthTool = server.tool(
  "upgradeAuth",
  { permission: z.enum(["write", "admin"])},
  // Any mutations here will automatically emit `listChanged` notifications
  async ({ permission }) =&amp;gt; {
    const { ok, err, previous } = await upgradeAuthAndStoreToken(permission)
    if (!ok) return {content: [{ type: "text", text: `Error: ${err}` }]}

    // If we previously had read-only access, 'putMessage' is now available
    if (previous === "read") {
      putMessageTool.enable()
    }

    if (permission === 'write') {
      // If we've just upgraded to 'write' permissions, we can still call 'upgradeAuth' 
      // but can only upgrade to 'admin'. 
      upgradeAuthTool.update({
        paramsSchema: { permission: z.enum(["admin"]) }, // change validation rules
      })
    } else {
      // If we're now an admin, we no longer have anywhere to upgrade to, so fully remove that tool
      upgradeAuthTool.remove()
    }
  }
)

// Connect as normal
const transport = new StdioServerTransport();
await server.connect(transport);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Improving Network Efficiency with Notification Debouncing&lt;/h3&gt; 
&lt;p&gt;When performing bulk updates that trigger notifications (e.g., enabling or disabling multiple tools in a loop), the SDK can send a large number of messages in a short period. To improve performance and reduce network traffic, you can enable notification debouncing.&lt;/p&gt; 
&lt;p&gt;This feature coalesces multiple, rapid calls for the same notification type into a single message. For example, if you disable five tools in a row, only one &lt;code&gt;notifications/tools/list_changed&lt;/code&gt; message will be sent instead of five.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] This feature is designed for "simple" notifications that do not carry unique data in their parameters. To prevent silent data loss, debouncing is &lt;strong&gt;automatically bypassed&lt;/strong&gt; for any notification that contains a &lt;code&gt;params&lt;/code&gt; object or a &lt;code&gt;relatedRequestId&lt;/code&gt;. Such notifications will always be sent immediately.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This is an opt-in feature configured during server initialization.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";

const server = new McpServer(
  {
    name: "efficient-server",
    version: "1.0.0"
  },
  {
    // Enable notification debouncing for specific methods
    debouncedNotificationMethods: [
      'notifications/tools/list_changed',
      'notifications/resources/list_changed',
      'notifications/prompts/list_changed'
    ]
  }
);

// Now, any rapid changes to tools, resources, or prompts will result
// in a single, consolidated notification for each type.
server.registerTool("tool1", ...).disable();
server.registerTool("tool2", ...).disable();
server.registerTool("tool3", ...).disable();
// Only one 'notifications/tools/list_changed' is sent.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Low-Level Server&lt;/h3&gt; 
&lt;p&gt;For more control, you can use the low-level Server class directly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import {
  ListPromptsRequestSchema,
  GetPromptRequestSchema
} from "@modelcontextprotocol/sdk/types.js";

const server = new Server(
  {
    name: "example-server",
    version: "1.0.0"
  },
  {
    capabilities: {
      prompts: {}
    }
  }
);

server.setRequestHandler(ListPromptsRequestSchema, async () =&amp;gt; {
  return {
    prompts: [{
      name: "example-prompt",
      description: "An example prompt template",
      arguments: [{
        name: "arg1",
        description: "Example argument",
        required: true
      }]
    }]
  };
});

server.setRequestHandler(GetPromptRequestSchema, async (request) =&amp;gt; {
  if (request.params.name !== "example-prompt") {
    throw new Error("Unknown prompt");
  }
  return {
    description: "Example prompt",
    messages: [{
      role: "user",
      content: {
        type: "text",
        text: "Example prompt text"
      }
    }]
  };
});

const transport = new StdioServerTransport();
await server.connect(transport);
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Eliciting User Input&lt;/h3&gt; 
&lt;p&gt;MCP servers can request additional information from users through the elicitation feature. This is useful for interactive workflows where the server needs user input or confirmation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Server-side: Restaurant booking tool that asks for alternatives
server.tool(
  "book-restaurant",
  { 
    restaurant: z.string(),
    date: z.string(),
    partySize: z.number()
  },
  async ({ restaurant, date, partySize }) =&amp;gt; {
    // Check availability
    const available = await checkAvailability(restaurant, date, partySize);
    
    if (!available) {
      // Ask user if they want to try alternative dates
      const result = await server.server.elicitInput({
        message: `No tables available at ${restaurant} on ${date}. Would you like to check alternative dates?`,
        requestedSchema: {
          type: "object",
          properties: {
            checkAlternatives: {
              type: "boolean",
              title: "Check alternative dates",
              description: "Would you like me to check other dates?"
            },
            flexibleDates: {
              type: "string",
              title: "Date flexibility",
              description: "How flexible are your dates?",
              enum: ["next_day", "same_week", "next_week"],
              enumNames: ["Next day", "Same week", "Next week"]
            }
          },
          required: ["checkAlternatives"]
        }
      });

      if (result.action === "accept" &amp;amp;&amp;amp; result.content?.checkAlternatives) {
        const alternatives = await findAlternatives(
          restaurant, 
          date, 
          partySize, 
          result.content.flexibleDates as string
        );
        return {
          content: [{
            type: "text",
            text: `Found these alternatives: ${alternatives.join(", ")}`
          }]
        };
      }
      
      return {
        content: [{
          type: "text",
          text: "No booking made. Original date not available."
        }]
      };
    }
    
    // Book the table
    await makeBooking(restaurant, date, partySize);
    return {
      content: [{
        type: "text",
        text: `Booked table for ${partySize} at ${restaurant} on ${date}`
      }]
    };
  }
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Client-side: Handle elicitation requests&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// This is a placeholder - implement based on your UI framework
async function getInputFromUser(message: string, schema: any): Promise&amp;lt;{
  action: "accept" | "decline" | "cancel";
  data?: Record&amp;lt;string, any&amp;gt;;
}&amp;gt; {
  // This should be implemented depending on the app
  throw new Error("getInputFromUser must be implemented for your platform");
}

client.setRequestHandler(ElicitRequestSchema, async (request) =&amp;gt; {
  const userResponse = await getInputFromUser(
    request.params.message, 
    request.params.requestedSchema
  );
  
  return {
    action: userResponse.action,
    content: userResponse.action === "accept" ? userResponse.data : undefined
  };
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Elicitation requires client support. Clients must declare the &lt;code&gt;elicitation&lt;/code&gt; capability during initialization.&lt;/p&gt; 
&lt;h3&gt;Writing MCP Clients&lt;/h3&gt; 
&lt;p&gt;The SDK provides a high-level client interface:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StdioClientTransport } from "@modelcontextprotocol/sdk/client/stdio.js";

const transport = new StdioClientTransport({
  command: "node",
  args: ["server.js"]
});

const client = new Client(
  {
    name: "example-client",
    version: "1.0.0"
  }
);

await client.connect(transport);

// List prompts
const prompts = await client.listPrompts();

// Get a prompt
const prompt = await client.getPrompt({
  name: "example-prompt",
  arguments: {
    arg1: "value"
  }
});

// List resources
const resources = await client.listResources();

// Read a resource
const resource = await client.readResource({
  uri: "file:///example.txt"
});

// Call a tool
const result = await client.callTool({
  name: "example-tool",
  arguments: {
    arg1: "value"
  }
});

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Proxy Authorization Requests Upstream&lt;/h3&gt; 
&lt;p&gt;You can proxy OAuth requests to an external authorization provider:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import express from 'express';
import { ProxyOAuthServerProvider } from '@modelcontextprotocol/sdk/server/auth/providers/proxyProvider.js';
import { mcpAuthRouter } from '@modelcontextprotocol/sdk/server/auth/router.js';

const app = express();

const proxyProvider = new ProxyOAuthServerProvider({
    endpoints: {
        authorizationUrl: "https://auth.external.com/oauth2/v1/authorize",
        tokenUrl: "https://auth.external.com/oauth2/v1/token",
        revocationUrl: "https://auth.external.com/oauth2/v1/revoke",
    },
    verifyAccessToken: async (token) =&amp;gt; {
        return {
            token,
            clientId: "123",
            scopes: ["openid", "email", "profile"],
        }
    },
    getClient: async (client_id) =&amp;gt; {
        return {
            client_id,
            redirect_uris: ["http://localhost:3000/callback"],
        }
    }
})

app.use(mcpAuthRouter({
    provider: proxyProvider,
    issuerUrl: new URL("http://auth.external.com"),
    baseUrl: new URL("http://mcp.example.com"),
    serviceDocumentationUrl: new URL("https://docs.example.com/"),
}))
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This setup allows you to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Forward OAuth requests to an external provider&lt;/li&gt; 
 &lt;li&gt;Add custom token validation logic&lt;/li&gt; 
 &lt;li&gt;Manage client registrations&lt;/li&gt; 
 &lt;li&gt;Provide custom documentation URLs&lt;/li&gt; 
 &lt;li&gt;Maintain control over the OAuth flow while delegating to an external provider&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Backwards Compatibility&lt;/h3&gt; 
&lt;p&gt;Clients and servers with StreamableHttp transport can maintain &lt;a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#backwards-compatibility"&gt;backwards compatibility&lt;/a&gt; with the deprecated HTTP+SSE transport (from protocol version 2024-11-05) as follows&lt;/p&gt; 
&lt;h4&gt;Client-Side Compatibility&lt;/h4&gt; 
&lt;p&gt;For clients that need to work with both Streamable HTTP and older SSE servers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import { Client } from "@modelcontextprotocol/sdk/client/index.js";
import { StreamableHTTPClientTransport } from "@modelcontextprotocol/sdk/client/streamableHttp.js";
import { SSEClientTransport } from "@modelcontextprotocol/sdk/client/sse.js";
let client: Client|undefined = undefined
const baseUrl = new URL(url);
try {
  client = new Client({
    name: 'streamable-http-client',
    version: '1.0.0'
  });
  const transport = new StreamableHTTPClientTransport(
    new URL(baseUrl)
  );
  await client.connect(transport);
  console.log("Connected using Streamable HTTP transport");
} catch (error) {
  // If that fails with a 4xx error, try the older SSE transport
  console.log("Streamable HTTP connection failed, falling back to SSE transport");
  client = new Client({
    name: 'sse-client',
    version: '1.0.0'
  });
  const sseTransport = new SSEClientTransport(baseUrl);
  await client.connect(sseTransport);
  console.log("Connected using SSE transport");
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Server-Side Compatibility&lt;/h4&gt; 
&lt;p&gt;For servers that need to support both Streamable HTTP and older clients:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;import express from "express";
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StreamableHTTPServerTransport } from "@modelcontextprotocol/sdk/server/streamableHttp.js";
import { SSEServerTransport } from "@modelcontextprotocol/sdk/server/sse.js";

const server = new McpServer({
  name: "backwards-compatible-server",
  version: "1.0.0"
});

// ... set up server resources, tools, and prompts ...

const app = express();
app.use(express.json());

// Store transports for each session type
const transports = {
  streamable: {} as Record&amp;lt;string, StreamableHTTPServerTransport&amp;gt;,
  sse: {} as Record&amp;lt;string, SSEServerTransport&amp;gt;
};

// Modern Streamable HTTP endpoint
app.all('/mcp', async (req, res) =&amp;gt; {
  // Handle Streamable HTTP transport for modern clients
  // Implementation as shown in the "With Session Management" example
  // ...
});

// Legacy SSE endpoint for older clients
app.get('/sse', async (req, res) =&amp;gt; {
  // Create SSE transport for legacy clients
  const transport = new SSEServerTransport('/messages', res);
  transports.sse[transport.sessionId] = transport;
  
  res.on("close", () =&amp;gt; {
    delete transports.sse[transport.sessionId];
  });
  
  await server.connect(transport);
});

// Legacy message endpoint for older clients
app.post('/messages', async (req, res) =&amp;gt; {
  const sessionId = req.query.sessionId as string;
  const transport = transports.sse[sessionId];
  if (transport) {
    await transport.handlePostMessage(req, res, req.body);
  } else {
    res.status(400).send('No transport found for sessionId');
  }
});

app.listen(3000);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The SSE transport is now deprecated in favor of Streamable HTTP. New implementations should use Streamable HTTP, and existing SSE implementations should plan to migrate.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://modelcontextprotocol.io"&gt;Model Context Protocol documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://spec.modelcontextprotocol.io"&gt;MCP Specification&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/modelcontextprotocol/servers"&gt;Example Servers&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Issues and pull requests are welcome on GitHub at &lt;a href="https://github.com/modelcontextprotocol/typescript-sdk"&gt;https://github.com/modelcontextprotocol/typescript-sdk&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT Licenseâ€”see the &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/RAG-Anything</title>
      <link>https://github.com/HKUDS/RAG-Anything</link>
      <description>&lt;p&gt;"RAG-Anything: All-in-One RAG Framework"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div style="margin: 20px 0;"&gt; 
  &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/logo.png" width="120" height="120" alt="RAG-Anything Logo" style="border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);" /&gt; 
 &lt;/div&gt; 
 &lt;h1&gt;ğŸš€ RAG-Anything: All-in-One RAG Framework&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14959" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14959" alt="HKUDS%2FRAG-Anything | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://readme-typing-svg.herokuapp.com?font=Orbitron&amp;amp;size=24&amp;amp;duration=3000&amp;amp;pause=1000&amp;amp;color=00D9FF&amp;amp;center=true&amp;amp;vCenter=true&amp;amp;width=600&amp;amp;lines=Welcome+to+RAG-Anything;Next-Gen+Multimodal+RAG+System;Powered+by+Advanced+AI+Technology" alt="Typing Animation" /&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;"&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything"&gt;&lt;img src="https://img.shields.io/badge/ğŸ”¥Project-Page-00d9ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2410.05779"&gt;&lt;img src="https://img.shields.io/badge/ğŸ“„arXiv-2410.05779-ff6b6b?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt;&lt;img src="https://img.shields.io/badge/âš¡Based%20on-LightRAG-4ecdc4?style=for-the-badge&amp;amp;logo=lightning&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/RAG-Anything?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/ğŸPython-3.10-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;a href="https://pypi.org/project/raganything/"&gt;&lt;img src="https://img.shields.io/pypi/v/raganything.svg?style=for-the-badge&amp;amp;logo=pypi&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e&amp;amp;color=ff6b6b" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/badge/âš¡uv-Ready-ff6b6b?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/RAG-Anything/issues/7"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
   &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README_zh.md"&gt;&lt;img src="https://img.shields.io/badge/ğŸ‡¨ğŸ‡³ä¸­æ–‡ç‰ˆ-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/README.md"&gt;&lt;img src="https://img.shields.io/badge/ğŸ‡ºğŸ‡¸English-1a1a2e?style=for-the-badge" /&gt;&lt;/a&gt; &lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ‰ News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.08.12]ğŸ¯ğŸ“¢ ğŸ” RAG-Anything now features &lt;strong&gt;VLM-Enhanced Query&lt;/strong&gt; mode! When documents include images, the system seamlessly integrates them into VLM for advanced multimodal analysis, combining visual and textual context for deeper insights.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.05]ğŸ¯ğŸ“¢ RAG-Anything now features a &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/docs/context_aware_processing.md"&gt;context configuration module&lt;/a&gt;, enabling intelligent integration of relevant contextual information to enhance multimodal content processing.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.04]ğŸ¯ğŸ“¢ ğŸš€ RAG-Anything now supports multimodal query capabilities, enabling enhanced RAG with seamless processing of text, images, tables, and equations.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; [2025.07.03]ğŸ¯ğŸ“¢ ğŸ‰ RAG-Anything has reached 1kğŸŒŸ stars on GitHub! Thank you for your incredible support and valuable contributions to the project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸŒŸ System Overview&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Next-Generation Multimodal Intelligence&lt;/em&gt;&lt;/p&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border: 2px solid #00d9ff; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);"&gt; 
 &lt;p&gt;Modern documents increasingly contain diverse multimodal contentâ€”text, images, tables, equations, charts, and multimediaâ€”that traditional text-focused RAG systems cannot effectively process. &lt;strong&gt;RAG-Anything&lt;/strong&gt; addresses this challenge as a comprehensive &lt;strong&gt;All-in-One Multimodal Document Processing RAG system&lt;/strong&gt; built on &lt;a href="https://github.com/HKUDS/LightRAG"&gt;LightRAG&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;As a unified solution, RAG-Anything &lt;strong&gt;eliminates the need for multiple specialized tools&lt;/strong&gt;. It provides &lt;strong&gt;seamless processing and querying across all content modalities&lt;/strong&gt; within a single integrated framework. Unlike conventional RAG approaches that struggle with non-textual elements, our all-in-one system delivers &lt;strong&gt;comprehensive multimodal retrieval capabilities&lt;/strong&gt;.&lt;/p&gt; 
 &lt;p&gt;Users can query documents containing &lt;strong&gt;interleaved text&lt;/strong&gt;, &lt;strong&gt;visual diagrams&lt;/strong&gt;, &lt;strong&gt;structured tables&lt;/strong&gt;, and &lt;strong&gt;mathematical formulations&lt;/strong&gt; through &lt;strong&gt;one cohesive interface&lt;/strong&gt;. This consolidated approach makes RAG-Anything particularly valuable for academic research, technical documentation, financial reports, and enterprise knowledge management where rich, mixed-content documents demand a &lt;strong&gt;unified processing framework&lt;/strong&gt;.&lt;/p&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/assets/rag_anything_framework.png" alt="RAG-Anything" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;ğŸ¯ Key Features&lt;/h3&gt; 
&lt;div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 15px; padding: 25px; margin: 20px 0;"&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;ğŸ”„ End-to-End Multimodal Pipeline&lt;/strong&gt; - Complete workflow from document ingestion and parsing to intelligent multimodal query answering&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ğŸ“„ Universal Document Support&lt;/strong&gt; - Seamless processing of PDFs, Office documents, images, and diverse file formats&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ğŸ§  Specialized Content Analysis&lt;/strong&gt; - Dedicated processors for images, tables, mathematical equations, and heterogeneous content types&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ğŸ”— Multimodal Knowledge Graph&lt;/strong&gt; - Automatic entity extraction and cross-modal relationship discovery for enhanced understanding&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;âš¡ Adaptive Processing Modes&lt;/strong&gt; - Flexible MinerU-based parsing or direct multimodal content injection workflows&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ğŸ“‹ Direct Content List Insertion&lt;/strong&gt; - Bypass document parsing by directly inserting pre-parsed content lists from external sources&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ğŸ¯ Hybrid Intelligent Retrieval&lt;/strong&gt; - Advanced search capabilities spanning textual and multimodal content with contextual understanding&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ—ï¸ Algorithm &amp;amp; Architecture&lt;/h2&gt; 
&lt;div style="background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border-left: 5px solid #00d9ff;"&gt; 
 &lt;h3&gt;Core Algorithm&lt;/h3&gt; 
 &lt;p&gt;&lt;strong&gt;RAG-Anything&lt;/strong&gt; implements an effective &lt;strong&gt;multi-stage multimodal pipeline&lt;/strong&gt; that fundamentally extends traditional RAG architectures to seamlessly handle diverse content modalities through intelligent orchestration and cross-modal understanding.&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: space-around; align-items: center; flex-wrap: wrap; gap: 20px;"&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     ğŸ“„
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Document Parsing
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    â†’
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     ğŸ§ 
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Content Analysis
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    â†’
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     ğŸ”
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Knowledge Graph
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div style="font-size: 20px; color: #00d9ff;"&gt;
    â†’
   &lt;/div&gt; 
   &lt;div style="text-align: center;"&gt; 
    &lt;div style="font-size: 24px; margin-bottom: 10px;"&gt;
     ğŸ¯
    &lt;/div&gt; 
    &lt;div style="font-size: 14px; color: #00d9ff;"&gt;
     Intelligent Retrieval
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h3&gt;1. Document Parsing Stage&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The system provides high-fidelity document extraction through adaptive content decomposition. It intelligently segments heterogeneous elements while preserving contextual relationships. Universal format compatibility is achieved via specialized optimized parsers.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;âš™ï¸ MinerU Integration&lt;/strong&gt;: Leverages &lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt; for high-fidelity document structure extraction and semantic preservation across complex layouts.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ§© Adaptive Content Decomposition&lt;/strong&gt;: Automatically segments documents into coherent text blocks, visual elements, structured tables, mathematical equations, and specialized content types while preserving contextual relationships.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“ Universal Format Support&lt;/strong&gt;: Provides comprehensive handling of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and emerging formats through specialized parsers with format-specific optimization.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;2. Multi-Modal Content Understanding &amp;amp; Processing&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The system automatically categorizes and routes content through optimized channels. It uses concurrent pipelines for parallel text and multimodal processing. Document hierarchy and relationships are preserved during transformation.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Key Components:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ¯ Autonomous Content Categorization and Routing&lt;/strong&gt;: Automatically identify, categorize, and route different content types through optimized execution channels.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;âš¡ Concurrent Multi-Pipeline Architecture&lt;/strong&gt;: Implements concurrent execution of textual and multimodal content through dedicated processing pipelines. This approach maximizes throughput efficiency while preserving content integrity.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ—ï¸ Document Hierarchy Extraction&lt;/strong&gt;: Extracts and preserves original document hierarchy and inter-element relationships during content transformation.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;3. Multimodal Analysis Engine&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #0f3460 0%, #1a1a2e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #00d9ff;"&gt; 
 &lt;p&gt;The system deploys modality-aware processing units for heterogeneous data modalities:&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Specialized Analyzers:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Visual Content Analyzer&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Integrate vision model for image analysis.&lt;/li&gt; 
    &lt;li&gt;Generates context-aware descriptive captions based on visual semantics.&lt;/li&gt; 
    &lt;li&gt;Extracts spatial relationships and hierarchical structures between visual elements.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“Š Structured Data Interpreter&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Performs systematic interpretation of tabular and structured data formats.&lt;/li&gt; 
    &lt;li&gt;Implements statistical pattern recognition algorithms for data trend analysis.&lt;/li&gt; 
    &lt;li&gt;Identifies semantic relationships and dependencies across multiple tabular datasets.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“ Mathematical Expression Parser&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Parses complex mathematical expressions and formulas with high accuracy.&lt;/li&gt; 
    &lt;li&gt;Provides native LaTeX format support for seamless integration with academic workflows.&lt;/li&gt; 
    &lt;li&gt;Establishes conceptual mappings between mathematical equations and domain-specific knowledge bases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ”§ Extensible Modality Handler&lt;/strong&gt;:&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Provides configurable processing framework for custom and emerging content types.&lt;/li&gt; 
    &lt;li&gt;Enables dynamic integration of new modality processors through plugin architecture.&lt;/li&gt; 
    &lt;li&gt;Supports runtime configuration of processing pipelines for specialized use cases.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;4. Multimodal Knowledge Graph Index&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;"&gt; 
 &lt;p&gt;The multi-modal knowledge graph construction module transforms document content into structured semantic representations. It extracts multimodal entities, establishes cross-modal relationships, and preserves hierarchical organization. The system applies weighted relevance scoring for optimized knowledge retrieval.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Core Functions:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Multi-Modal Entity Extraction&lt;/strong&gt;: Transforms significant multimodal elements into structured knowledge graph entities. The process includes semantic annotations and metadata preservation.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ”— Cross-Modal Relationship Mapping&lt;/strong&gt;: Establishes semantic connections and dependencies between textual entities and multimodal components. This is achieved through automated relationship inference algorithms.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ—ï¸ Hierarchical Structure Preservation&lt;/strong&gt;: Maintains original document organization through "belongs_to" relationship chains. These chains preserve logical content hierarchy and sectional dependencies.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;âš–ï¸ Weighted Relationship Scoring&lt;/strong&gt;: Assigns quantitative relevance scores to relationship types. Scoring is based on semantic proximity and contextual significance within the document structure.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;h3&gt;5. Modality-Aware Retrieval&lt;/h3&gt; 
&lt;div style="background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;"&gt; 
 &lt;p&gt;The hybrid retrieval system combines vector similarity search with graph traversal algorithms for comprehensive content retrieval. It implements modality-aware ranking mechanisms and maintains relational coherence between retrieved elements to ensure contextually integrated information delivery.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Retrieval Mechanisms:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ”€ Vector-Graph Fusion&lt;/strong&gt;: Integrates vector similarity search with graph traversal algorithms. This approach leverages both semantic embeddings and structural relationships for comprehensive content retrieval.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“Š Modality-Aware Ranking&lt;/strong&gt;: Implements adaptive scoring mechanisms that weight retrieval results based on content type relevance. The system adjusts rankings according to query-specific modality preferences.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ”— Relational Coherence Maintenance&lt;/strong&gt;: Maintains semantic and structural relationships between retrieved elements. This ensures coherent information delivery and contextual integrity.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Initialize Your AI Journey&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212284158-e840e285-664b-44d7-b79b-e264b5e54825.gif" width="400" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Option 1: Install from PyPI (Recommended)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
pip install raganything

# With optional dependencies for extended format support:
pip install 'raganything[all]'              # All optional features
pip install 'raganything[image]'            # Image format conversion (BMP, TIFF, GIF, WebP)
pip install 'raganything[text]'             # Text file processing (TXT, MD)
pip install 'raganything[image,text]'       # Multiple features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Option 2: Install from Source&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and setup the project with uv
git clone https://github.com/HKUDS/RAG-Anything.git
cd RAG-Anything

# Install the package and dependencies in a virtual environment
uv sync

# If you encounter network timeouts (especially for opencv packages):
# UV_HTTP_TIMEOUT=120 uv sync

# Run commands directly with uv (recommended approach)
uv run python examples/raganything_example.py --help

# Install with optional dependencies
uv sync --extra image --extra text  # Specific extras
uv sync --all-extras                 # All optional features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Optional Dependencies&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[image]&lt;/code&gt;&lt;/strong&gt; - Enables processing of BMP, TIFF, GIF, WebP image formats (requires Pillow)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[text]&lt;/code&gt;&lt;/strong&gt; - Enables processing of TXT and MD files (requires ReportLab)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;[all]&lt;/code&gt;&lt;/strong&gt; - Includes all Python optional dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;âš ï¸ Office Document Processing Requirements:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Office documents (.doc, .docx, .ppt, .pptx, .xls, .xlsx) require &lt;strong&gt;LibreOffice&lt;/strong&gt; installation&lt;/li&gt; 
  &lt;li&gt;Download from &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice official website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: Download installer from official website&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: &lt;code&gt;brew install --cask libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Ubuntu/Debian&lt;/strong&gt;: &lt;code&gt;sudo apt-get install libreoffice&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;CentOS/RHEL&lt;/strong&gt;: &lt;code&gt;sudo yum install libreoffice&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Check MinerU installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Verify installation
mineru --version

# Check if properly configured
python -c "from raganything import RAGAnything; rag = RAGAnything(); print('âœ… MinerU installed properly' if rag.check_parser_installation() else 'âŒ MinerU installation issue')"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Models are downloaded automatically on first use. For manual download, refer to &lt;a href="https://github.com/opendatalab/MinerU/raw/master/README.md#22-model-source-configuration"&gt;MinerU Model Source Configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Usage Examples&lt;/h3&gt; 
&lt;h4&gt;1. End-to-End Document Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def main():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        parser="mineru",  # Parser selection: mineru or docling
        parse_method="auto",  # Parse method: auto, ocr, or txt
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define LLM model function
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Define embedding function
    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Process a document
    await rag.process_document_complete(
        file_path="path/to/your/document.pdf",
        output_dir="./output",
        parse_method="auto"
    )

    # Query the processed content
    # Pure text query - for basic knowledge base search
    text_result = await rag.aquery(
        "What are the main findings shown in the figures and tables?",
        mode="hybrid"
    )
    print("Text query result:", text_result)

    # Multimodal query with specific multimodal content
    multimodal_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
    print("Multimodal query result:", multimodal_result)

if __name__ == "__main__":
    asyncio.run(main())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Direct Multimodal Content Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc
from raganything.modalprocessors import ImageModalProcessor, TableModalProcessor

async def process_multimodal_content():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Initialize LightRAG
    rag = LightRAG(
        working_dir="./rag_storage",
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )
    await rag.initialize_storages()

    # Process an image
    image_processor = ImageModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], image_data=None, **kwargs: openai_complete_if_cache(
            "gpt-4o",
            "",
            system_prompt=None,
            history_messages=[],
            messages=[
                {"role": "system", "content": system_prompt} if system_prompt else None,
                {"role": "user", "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                ]} if image_data else {"role": "user", "content": prompt}
            ],
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ) if image_data else openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    image_content = {
        "img_path": "path/to/image.jpg",
        "image_caption": ["Figure 1: Experimental results"],
        "image_footnote": ["Data collected in 2024"]
    }

    description, entity_info = await image_processor.process_multimodal_content(
        modal_content=image_content,
        content_type="image",
        file_path="research_paper.pdf",
        entity_name="Experimental Results Figure"
    )

    # Process a table
    table_processor = TableModalProcessor(
        lightrag=rag,
        modal_caption_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )
    )

    table_content = {
        "table_body": """
        | Method | Accuracy | F1-Score |
        |--------|----------|----------|
        | RAGAnything | 95.2% | 0.94 |
        | Baseline | 87.3% | 0.85 |
        """,
        "table_caption": ["Performance Comparison"],
        "table_footnote": ["Results on test dataset"]
    }

    description, entity_info = await table_processor.process_multimodal_content(
        modal_content=table_content,
        content_type="table",
        file_path="research_paper.pdf",
        entity_name="Performance Results Table"
    )

if __name__ == "__main__":
    asyncio.run(process_multimodal_content())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Batch Processing&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Process multiple documents
await rag.process_folder_complete(
    folder_path="./documents",
    output_dir="./output",
    file_extensions=[".pdf", ".docx", ".pptx"],
    recursive=True,
    max_workers=4
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Custom Modal Processors&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from raganything.modalprocessors import GenericModalProcessor

class CustomModalProcessor(GenericModalProcessor):
    async def process_multimodal_content(self, modal_content, content_type, file_path, entity_name):
        # Your custom processing logic
        enhanced_description = await self.analyze_custom_content(modal_content)
        entity_info = self.create_custom_entity(enhanced_description, entity_name)
        return await self._create_entity_and_chunk(enhanced_description, entity_info, file_path)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. Query Options&lt;/h4&gt; 
&lt;p&gt;RAG-Anything provides three types of query methods:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Pure Text Queries&lt;/strong&gt; - Direct knowledge base search using LightRAG:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Different query modes for text queries
text_result_hybrid = await rag.aquery("Your question", mode="hybrid")
text_result_local = await rag.aquery("Your question", mode="local")
text_result_global = await rag.aquery("Your question", mode="global")
text_result_naive = await rag.aquery("Your question", mode="naive")

# Synchronous version
sync_text_result = rag.query("Your question", mode="hybrid")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;VLM Enhanced Queries&lt;/strong&gt; - Automatically analyze images in retrieved context using VLM:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# VLM enhanced query (automatically enabled when vision_model_func is provided)
vlm_result = await rag.aquery(
    "Analyze the charts and figures in the document",
    mode="hybrid"
    # vlm_enhanced=True is automatically set when vision_model_func is available
)

# Manually control VLM enhancement
vlm_enabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=True  # Force enable VLM enhancement
)

vlm_disabled = await rag.aquery(
    "What do the images show in this document?",
    mode="hybrid",
    vlm_enhanced=False  # Force disable VLM enhancement
)

# When documents contain images, VLM can see and analyze them directly
# The system will automatically:
# 1. Retrieve relevant context containing image paths
# 2. Load and encode images as base64
# 3. Send both text context and images to VLM for comprehensive analysis
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Multimodal Queries&lt;/strong&gt; - Enhanced queries with specific multimodal content analysis:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Query with table data
table_result = await rag.aquery_with_multimodal(
    "Compare these performance metrics with the document content",
    multimodal_content=[{
        "type": "table",
        "table_data": """Method,Accuracy,Speed
                        RAGAnything,95.2%,120ms
                        Traditional,87.3%,180ms""",
        "table_caption": "Performance comparison"
    }],
    mode="hybrid"
)

# Query with equation content
equation_result = await rag.aquery_with_multimodal(
    "Explain this formula and its relevance to the document content",
    multimodal_content=[{
        "type": "equation",
        "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
        "equation_caption": "Document relevance probability"
    }],
    mode="hybrid"
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;6. Loading Existing LightRAG Instance&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag import LightRAG
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.kg.shared_storage import initialize_pipeline_status
from lightrag.utils import EmbeddingFunc
import os

async def load_existing_lightrag():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # First, create or load existing LightRAG instance
    lightrag_working_dir = "./existing_lightrag_storage"

    # Check if previous LightRAG instance exists
    if os.path.exists(lightrag_working_dir) and os.listdir(lightrag_working_dir):
        print("âœ… Found existing LightRAG instance, loading...")
    else:
        print("âŒ No existing LightRAG instance found, will create new one")

    # Create/load LightRAG instance with your configuration
    lightrag_instance = LightRAG(
        working_dir=lightrag_working_dir,
        llm_model_func=lambda prompt, system_prompt=None, history_messages=[], **kwargs: openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        ),
        embedding_func=EmbeddingFunc(
            embedding_dim=3072,
            max_token_size=8192,
            func=lambda texts: openai_embed(
                texts,
                model="text-embedding-3-large",
                api_key=api_key,
                base_url=base_url,
            ),
        )
    )

    # Initialize storage (this will load existing data if available)
    await lightrag_instance.initialize_storages()
    await initialize_pipeline_status()

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt}
                    if system_prompt
                    else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_data}"
                                },
                            },
                        ],
                    }
                    if image_data
                    else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return lightrag_instance.llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    # Now use existing LightRAG instance to initialize RAGAnything
    rag = RAGAnything(
        lightrag=lightrag_instance,  # Pass existing LightRAG instance
        vision_model_func=vision_model_func,
        # Note: working_dir, llm_model_func, embedding_func, etc. are inherited from lightrag_instance
    )

    # Query existing knowledge base
    result = await rag.aquery(
        "What data has been processed in this LightRAG instance?",
        mode="hybrid"
    )
    print("Query result:", result)

    # Add new multimodal document to existing LightRAG instance
    await rag.process_document_complete(
        file_path="path/to/new/multimodal_document.pdf",
        output_dir="./output"
    )

if __name__ == "__main__":
    asyncio.run(load_existing_lightrag())
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;7. Direct Content List Insertion&lt;/h4&gt; 
&lt;p&gt;For scenarios where you already have a pre-parsed content list (e.g., from external parsers or previous processing), you can directly insert it into RAGAnything without document parsing:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def insert_content_list_example():
    # Set up API configuration
    api_key = "your-api-key"
    base_url = "your-base-url"  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir="./rag_storage",
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define model functions
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            "gpt-4o-mini",
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    def vision_model_func(prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                "gpt-4o",
                "",
                system_prompt=None,
                history_messages=[],
                messages=[
                    {"role": "system", "content": system_prompt} if system_prompt else None,
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                        ],
                    } if image_data else {"role": "user", "content": prompt},
                ],
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Pure text format
        else:
            return llm_model_func(prompt, system_prompt, history_messages, **kwargs)

    embedding_func = EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=api_key,
            base_url=base_url,
        ),
    )

    # Initialize RAGAnything
    rag = RAGAnything(
        config=config,
        llm_model_func=llm_model_func,
        vision_model_func=vision_model_func,
        embedding_func=embedding_func,
    )

    # Example: Pre-parsed content list from external source
    content_list = [
        {
            "type": "text",
            "text": "This is the introduction section of our research paper.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "image",
            "img_path": "/absolute/path/to/figure1.jpg",  # IMPORTANT: Use absolute path
            "image_caption": ["Figure 1: System Architecture"],
            "image_footnote": ["Source: Authors' original design"],
            "page_idx": 1  # Page number where this image appears
        },
        {
            "type": "table",
            "table_body": "| Method | Accuracy | F1-Score |\n|--------|----------|----------|\n| Ours | 95.2% | 0.94 |\n| Baseline | 87.3% | 0.85 |",
            "table_caption": ["Table 1: Performance Comparison"],
            "table_footnote": ["Results on test dataset"],
            "page_idx": 2  # Page number where this table appears
        },
        {
            "type": "equation",
            "latex": "P(d|q) = \\frac{P(q|d) \\cdot P(d)}{P(q)}",
            "text": "Document relevance probability formula",
            "page_idx": 3  # Page number where this equation appears
        },
        {
            "type": "text",
            "text": "In conclusion, our method demonstrates superior performance across all metrics.",
            "page_idx": 4  # Page number where this content appears
        }
    ]

    # Insert the content list directly
    await rag.insert_content_list(
        content_list=content_list,
        file_path="research_paper.pdf",  # Reference file name for citation
        split_by_character=None,         # Optional text splitting
        split_by_character_only=False,   # Optional text splitting mode
        doc_id=None,                     # Optional custom document ID (will be auto-generated if not provided)
        display_stats=True               # Show content statistics
    )

    # Query the inserted content
    result = await rag.aquery(
        "What are the key findings and performance metrics mentioned in the research?",
        mode="hybrid"
    )
    print("Query result:", result)

    # You can also insert multiple content lists with different document IDs
    another_content_list = [
        {
            "type": "text",
            "text": "This is content from another document.",
            "page_idx": 0  # Page number where this content appears
        },
        {
            "type": "table",
            "table_body": "| Feature | Value |\n|---------|-------|\n| Speed | Fast |\n| Accuracy | High |",
            "table_caption": ["Feature Comparison"],
            "page_idx": 1  # Page number where this table appears
        }
    ]

    await rag.insert_content_list(
        content_list=another_content_list,
        file_path="another_document.pdf",
        doc_id="custom-doc-id-123"  # Custom document ID
    )

if __name__ == "__main__":
    asyncio.run(insert_content_list_example())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Content List Format:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;content_list&lt;/code&gt; should follow the standard format with each item being a dictionary containing:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Text content&lt;/strong&gt;: &lt;code&gt;{"type": "text", "text": "content text", "page_idx": 0}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image content&lt;/strong&gt;: &lt;code&gt;{"type": "image", "img_path": "/absolute/path/to/image.jpg", "image_caption": ["caption"], "image_footnote": ["note"], "page_idx": 1}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Table content&lt;/strong&gt;: &lt;code&gt;{"type": "table", "table_body": "markdown table", "table_caption": ["caption"], "table_footnote": ["note"], "page_idx": 2}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equation content&lt;/strong&gt;: &lt;code&gt;{"type": "equation", "latex": "LaTeX formula", "text": "description", "page_idx": 3}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic content&lt;/strong&gt;: &lt;code&gt;{"type": "custom_type", "content": "any content", "page_idx": 4}&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Important Notes:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;img_path&lt;/code&gt;&lt;/strong&gt;: Must be an absolute path to the image file (e.g., &lt;code&gt;/home/user/images/chart.jpg&lt;/code&gt; or &lt;code&gt;C:\Users\user\images\chart.jpg&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;page_idx&lt;/code&gt;&lt;/strong&gt;: Represents the page number where the content appears in the original document (0-based indexing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content ordering&lt;/strong&gt;: Items are processed in the order they appear in the list&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This method is particularly useful when:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You have content from external parsers (non-MinerU/Docling)&lt;/li&gt; 
 &lt;li&gt;You want to process programmatically generated content&lt;/li&gt; 
 &lt;li&gt;You need to insert content from multiple sources into a single knowledge base&lt;/li&gt; 
 &lt;li&gt;You have cached parsing results that you want to reuse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ› ï¸ Examples&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Practical Implementation Demos&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://user-images.githubusercontent.com/74038190/212257455-13e3e01e-d6a6-45dc-bb92-3ab87b12dfc1.gif" width="300" /&gt; 
&lt;/div&gt; 
&lt;p&gt;The &lt;code&gt;examples/&lt;/code&gt; directory contains comprehensive usage examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;raganything_example.py&lt;/code&gt;&lt;/strong&gt;: End-to-end document processing with MinerU&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;modalprocessors_example.py&lt;/code&gt;&lt;/strong&gt;: Direct multimodal content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;office_document_test.py&lt;/code&gt;&lt;/strong&gt;: Office document parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;image_format_test.py&lt;/code&gt;&lt;/strong&gt;: Image format parsing test with MinerU (no API key required)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;text_format_test.py&lt;/code&gt;&lt;/strong&gt;: Text format parsing test with MinerU (no API key required)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Run examples:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# End-to-end processing with parser selection
python examples/raganything_example.py path/to/document.pdf --api-key YOUR_API_KEY --parser mineru

# Direct modal processing
python examples/modalprocessors_example.py --api-key YOUR_API_KEY

# Office document parsing test (MinerU only)
python examples/office_document_test.py --file path/to/document.docx

# Image format parsing test (MinerU only)
python examples/image_format_test.py --file path/to/image.bmp

# Text format parsing test (MinerU only)
python examples/text_format_test.py --file path/to/document.md

# Check LibreOffice installation
python examples/office_document_test.py --check-libreoffice --file dummy

# Check PIL/Pillow installation
python examples/image_format_test.py --check-pillow --file dummy

# Check ReportLab installation
python examples/text_format_test.py --check-reportlab --file dummy
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ”§ Configuration&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;System Optimization Parameters&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file (refer to &lt;code&gt;.env.example&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OPENAI_API_KEY=your_openai_api_key
OPENAI_BASE_URL=your_base_url  # Optional
OUTPUT_DIR=./output             # Default output directory for parsed documents
PARSER=mineru                   # Parser selection: mineru or docling
PARSE_METHOD=auto              # Parse method: auto, ocr, or txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For backward compatibility, legacy environment variable names are still supported:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;MINERU_PARSE_METHOD&lt;/code&gt; is deprecated, please use &lt;code&gt;PARSE_METHOD&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: API keys are only required for full RAG processing with LLM integration. The parsing test files (&lt;code&gt;office_document_test.py&lt;/code&gt; and &lt;code&gt;image_format_test.py&lt;/code&gt;) only test parser functionality and do not require API keys.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Parser Configuration&lt;/h3&gt; 
&lt;p&gt;RAGAnything now supports multiple parsers, each with specific advantages:&lt;/p&gt; 
&lt;h4&gt;MinerU Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Supports PDF, images, Office documents, and more formats&lt;/li&gt; 
 &lt;li&gt;Powerful OCR and table extraction capabilities&lt;/li&gt; 
 &lt;li&gt;GPU acceleration support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Docling Parser&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Optimized for Office documents and HTML files&lt;/li&gt; 
 &lt;li&gt;Better document structure preservation&lt;/li&gt; 
 &lt;li&gt;Native support for multiple Office formats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;MinerU Configuration&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# MinerU 2.0 uses command-line parameters instead of config files
# Check available options:
mineru --help

# Common configurations:
mineru -p input.pdf -o output_dir -m auto    # Automatic parsing mode
mineru -p input.pdf -o output_dir -m ocr     # OCR-focused parsing
mineru -p input.pdf -o output_dir -b pipeline --device cuda  # GPU acceleration
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also configure parsing through RAGAnything parameters:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Basic parsing configuration with parser selection
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # or "ocr", "txt"
    parser="mineru"               # Optional: "mineru" or "docling"
)

# Advanced parsing configuration with special parameters
await rag.process_document_complete(
    file_path="document.pdf",
    output_dir="./output/",
    parse_method="auto",          # Parsing method: "auto", "ocr", "txt"
    parser="mineru",              # Parser selection: "mineru" or "docling"

    # MinerU special parameters - all supported kwargs:
    lang="ch",                   # Document language for OCR optimization (e.g., "ch", "en", "ja")
    device="cuda:0",             # Inference device: "cpu", "cuda", "cuda:0", "npu", "mps"
    start_page=0,                # Starting page number (0-based, for PDF)
    end_page=10,                 # Ending page number (0-based, for PDF)
    formula=True,                # Enable formula parsing
    table=True,                  # Enable table parsing
    backend="pipeline",          # Parsing backend: pipeline|vlm-transformers|vlm-sglang-engine|vlm-sglang-client.
    source="huggingface",        # Model source: "huggingface", "modelscope", "local"
    # vlm_url="http://127.0.0.1:3000" # Service address when using backend=vlm-sglang-client

    # Standard RAGAnything parameters
    display_stats=True,          # Display content statistics
    split_by_character=None,     # Optional character to split text by
    doc_id=None                  # Optional document ID
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: MinerU 2.0 no longer uses the &lt;code&gt;magic-pdf.json&lt;/code&gt; configuration file. All settings are now passed as command-line parameters or function arguments. RAG-Anything now supports multiple document parsers - you can choose between MinerU and Docling based on your needs.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Processing Requirements&lt;/h3&gt; 
&lt;p&gt;Different content types require specific optional dependencies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; (.doc, .docx, .ppt, .pptx, .xls, .xlsx): Install &lt;a href="https://www.libreoffice.org/download/download/"&gt;LibreOffice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extended Image Formats&lt;/strong&gt; (.bmp, .tiff, .gif, .webp): Install with &lt;code&gt;pip install raganything[image]&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; (.txt, .md): Install with &lt;code&gt;pip install raganything[text]&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ“‹ Quick Install&lt;/strong&gt;: Use &lt;code&gt;pip install raganything[all]&lt;/code&gt; to enable all format support (Python dependencies only - LibreOffice still needs separate installation)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ§ª Supported Content Types&lt;/h2&gt; 
&lt;h3&gt;Document Formats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PDFs&lt;/strong&gt; - Research papers, reports, presentations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Office Documents&lt;/strong&gt; - DOC, DOCX, PPT, PPTX, XLS, XLSX&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - JPG, PNG, BMP, TIFF, GIF, WebP&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Text Files&lt;/strong&gt; - TXT, MD&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Multimodal Elements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Images&lt;/strong&gt; - Photographs, diagrams, charts, screenshots&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tables&lt;/strong&gt; - Data tables, comparison charts, statistical summaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Equations&lt;/strong&gt; - Mathematical formulas in LaTeX format&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generic Content&lt;/strong&gt; - Custom content types via extensible processors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;em&gt;For installation of format-specific dependencies, see the &lt;a href="https://raw.githubusercontent.com/HKUDS/RAG-Anything/main/#-configuration"&gt;Configuration&lt;/a&gt; section.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“– Citation&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Academic Reference&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 60px; height: 60px; margin: 20px auto; position: relative;"&gt; 
  &lt;div style="width: 100%; height: 100%; border: 2px solid #00d9ff; border-radius: 50%; position: relative;"&gt; 
   &lt;div style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); font-size: 24px; color: #00d9ff;"&gt;
    ğŸ“–
   &lt;/div&gt; 
  &lt;/div&gt; 
  &lt;div style="position: absolute; bottom: -5px; left: 50%; transform: translateX(-50%); width: 20px; height: 20px; background: white; border-right: 2px solid #00d9ff; border-bottom: 2px solid #00d9ff; transform: rotate(45deg);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;p&gt;If you find RAG-Anything useful in your research, please cite our paper:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@article{guo2024lightrag,
  title={LightRAG: Simple and Fast Retrieval-Augmented Generation},
  author={Zirui Guo and Lianghao Xia and Yanhua Yu and Tu Ao and Chao Huang},
  year={2024},
  eprint={2410.05779},
  archivePrefix={arXiv},
  primaryClass={cs.IR}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ”— Related Projects&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Ecosystem &amp;amp; Extensions&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/LightRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;âš¡&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;LightRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Simple and Fast RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/VideoRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;ğŸ¥&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;VideoRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extreme Long-Context Video RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;td align="center"&gt; &lt;a href="https://github.com/HKUDS/MiniRAG"&gt; 
      &lt;div style="width: 100px; height: 100px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2); display: flex; align-items: center; justify-content: center; margin-bottom: 10px;"&gt; 
       &lt;span style="font-size: 32px;"&gt;âœ¨&lt;/span&gt; 
      &lt;/div&gt; &lt;b&gt;MiniRAG&lt;/b&gt;&lt;br /&gt; &lt;sub&gt;Extremely Simple RAG&lt;/sub&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â­ Star History&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://star-history.com/#HKUDS/RAG-Anything&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/RAG-Anything&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ¤ Contribution&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;Join the Innovation&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt;
  We thank all our contributors for their valuable contributions. 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/HKUDS/RAG-Anything/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=HKUDS/RAG-Anything" style="border-radius: 15px; box-shadow: 0 0 20px rgba(0, 217, 255, 0.3);" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 30px; margin: 30px 0;"&gt; 
 &lt;div&gt; 
  &lt;img src="https://user-images.githubusercontent.com/74038190/212284100-561aa473-3905-4a80-b561-0d28506553ee.gif" width="500" /&gt; 
 &lt;/div&gt; 
 &lt;div style="margin-top: 20px;"&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/â­%20Star%20us%20on%20GitHub-1a1a2e?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/issues" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/ğŸ›%20Report%20Issues-ff6b6b?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/HKUDS/RAG-Anything/discussions" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/ğŸ’¬%20Discussions-4ecdc4?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;div style="width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);"&gt; 
  &lt;div style="display: flex; justify-content: center; align-items: center; gap: 15px;"&gt; 
   &lt;span style="font-size: 24px;"&gt;â­&lt;/span&gt; 
   &lt;span style="color: #00d9ff; font-size: 18px;"&gt;Thank you for visiting RAG-Anything!&lt;/span&gt; 
   &lt;span style="font-size: 24px;"&gt;â­&lt;/span&gt; 
  &lt;/div&gt; 
  &lt;div style="margin-top: 10px; color: #00d9ff; font-size: 16px;"&gt;
   Building the Future of Multimodal AI
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>frappe/erpnext</title>
      <link>https://github.com/frappe/erpnext</link>
      <description>&lt;p&gt;Free and Open Source Enterprise Resource Planning (ERP)&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://frappe.io/erpnext"&gt; &lt;img src="https://raw.githubusercontent.com/frappe/erpnext/develop/erpnext/public/images/v16/erpnext.svg?sanitize=true" alt="ERPNext Logo" height="80px" width="80xp" /&gt; &lt;/a&gt; 
 &lt;h2&gt;ERPNext&lt;/h2&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;Powerful, Intuitive and Open-Source ERP&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://frappe.school"&gt;&lt;img src="https://img.shields.io/badge/Frappe%20School-Learn%20ERPNext-blue?style=flat-square" alt="Learn on Frappe School" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt; &lt;a href="https://github.com/frappe/erpnext/actions/workflows/server-tests-mariadb.yml"&gt;&lt;img src="https://github.com/frappe/erpnext/actions/workflows/server-tests-mariadb.yml/badge.svg?event=schedule" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/frappe/erpnext-worker"&gt;&lt;img src="https://img.shields.io/docker/pulls/frappe/erpnext-worker.svg?sanitize=true" alt="docker pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/frappe/erpnext/develop/erpnext/public/images/v16/hero_image.png" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://erpnext-demo.frappe.cloud/api/method/erpnext_demo.erpnext_demo.auth.login_demo"&gt;Live Demo&lt;/a&gt; - 
 &lt;a href="https://frappe.io/erpnext"&gt;Website&lt;/a&gt; - 
 &lt;a href="https://docs.frappe.io/erpnext/"&gt;Documentation&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;ERPNext&lt;/h2&gt; 
&lt;p&gt;100% Open-Source ERP system to help you run your business.&lt;/p&gt; 
&lt;h3&gt;Motivation&lt;/h3&gt; 
&lt;p&gt;Running a business is a complex task - handling invoices, tracking stock, managing personnel and even more ad-hoc activities. In a market where software is sold separately to manage each of these tasks, ERPNext does all of the above and more, for free.&lt;/p&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Accounting&lt;/strong&gt;: All the tools you need to manage cash flow in one place, right from recording transactions to summarizing and analyzing financial reports.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Order Management&lt;/strong&gt;: Track inventory levels, replenish stock, and manage sales orders, customers, suppliers, shipments, deliverables, and order fulfillment.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manufacturing&lt;/strong&gt;: Simplifies the production cycle, helps track material consumption, exhibits capacity planning, handles subcontracting, and more!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Asset Management&lt;/strong&gt;: From purchase to perishment, IT infrastructure to equipment. Cover every branch of your organization, all in one centralized system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Projects&lt;/strong&gt;: Delivery both internal and external Projects on time, budget and Profitability. Track tasks, timesheets, and issues by project.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details open&gt; 
 &lt;summary&gt;More&lt;/summary&gt; 
 &lt;img src="https://erpnext.com/files/v16_bom.png" /&gt; 
 &lt;img src="https://erpnext.com/files/v16_stock_summary.png" /&gt; 
 &lt;img src="https://erpnext.com/files/v16_job_card.png" /&gt; 
 &lt;img src="https://erpnext.com/files/v16_tasks.png" /&gt; 
&lt;/details&gt; 
&lt;h3&gt;Under the Hood&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe"&gt;&lt;strong&gt;Frappe Framework&lt;/strong&gt;&lt;/a&gt;: A full-stack web application framework written in Python and Javascript. The framework provides a robust foundation for building web applications, including a database abstraction layer, user authentication, and a REST API.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frappe/frappe-ui"&gt;&lt;strong&gt;Frappe UI&lt;/strong&gt;&lt;/a&gt;: A Vue-based UI library, to provide a modern user interface. The Frappe UI library provides a variety of components that can be used to build single-page applications on top of the Frappe Framework.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Production Setup&lt;/h2&gt; 
&lt;h3&gt;Managed Hosting&lt;/h3&gt; 
&lt;p&gt;You can try &lt;a href="https://frappecloud.com"&gt;Frappe Cloud&lt;/a&gt;, a simple, user-friendly and sophisticated &lt;a href="https://github.com/frappe/press"&gt;open-source&lt;/a&gt; platform to host Frappe applications with peace of mind.&lt;/p&gt; 
&lt;p&gt;It takes care of installation, setup, upgrades, monitoring, maintenance and support of your Frappe deployments. It is a fully featured developer platform with an ability to manage and control multiple Frappe deployments.&lt;/p&gt; 
&lt;div&gt; 
 &lt;a href="https://erpnext-demo.frappe.cloud/app/home" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/try-on-fc-white.png" /&gt; 
   &lt;img src="https://frappe.io/files/try-on-fc-black.png" alt="Try on Frappe Cloud" height="28" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Self-Hosted&lt;/h3&gt; 
&lt;h4&gt;Docker&lt;/h4&gt; 
&lt;p&gt;Prerequisites: docker, docker-compose, git. Refer &lt;a href="https://docs.docker.com"&gt;Docker Documentation&lt;/a&gt; for more details on Docker setup.&lt;/p&gt; 
&lt;p&gt;Run following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/frappe/frappe_docker
cd frappe_docker
docker compose -f pwd.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After a couple of minutes, site should be accessible on your localhost port: 8080. Use below default login credentials to access the site.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Username: Administrator&lt;/li&gt; 
 &lt;li&gt;Password: admin&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://github.com/frappe/frappe_docker?tab=readme-ov-file#to-run-on-arm64-architecture-follow-this-instructions"&gt;Frappe Docker&lt;/a&gt; for ARM based docker setup.&lt;/p&gt; 
&lt;h2&gt;Development Setup&lt;/h2&gt; 
&lt;h3&gt;Manual Install&lt;/h3&gt; 
&lt;p&gt;The Easy Way: our install script for bench will install all dependencies (e.g. MariaDB). See &lt;a href="https://github.com/frappe/bench"&gt;https://github.com/frappe/bench&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;New passwords will be created for the ERPNext "Administrator" user, the MariaDB root user, and the frappe user (the script displays the passwords and saves them to ~/frappe_passwords.txt).&lt;/p&gt; 
&lt;h3&gt;Local&lt;/h3&gt; 
&lt;p&gt;To setup the repository locally follow the steps mentioned below:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Setup bench by following the &lt;a href="https://frappeframework.com/docs/user/en/installation"&gt;Installation Steps&lt;/a&gt; and start the server&lt;/p&gt; &lt;pre&gt;&lt;code&gt;bench start
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;In a separate terminal window, run the following commands:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Create a new site
bench new-site erpnext.localhost
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Get the ERPNext app and install it&lt;/p&gt; &lt;pre&gt;&lt;code&gt;# Get the ERPNext app
bench get-app https://github.com/frappe/erpnext

# Install the app
bench --site erpnext.localhost install-app erpnext
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Open the URL &lt;code&gt;http://erpnext.localhost:8000/app&lt;/code&gt; in your browser, you should see the app running&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Learning and community&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://school.frappe.io"&gt;Frappe School&lt;/a&gt; - Learn Frappe Framework and ERPNext from the various courses by the maintainers or from the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.erpnext.com/"&gt;Official documentation&lt;/a&gt; - Extensive documentation for ERPNext.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discuss.erpnext.com/"&gt;Discussion Forum&lt;/a&gt; - Engage with community of ERPNext users and service providers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext_public.t.me"&gt;Telegram Group&lt;/a&gt; - Get instant help from huge community of users.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Issue-Guidelines"&gt;Issue Guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://erpnext.com/security"&gt;Report Security Vulnerabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/frappe/erpnext/wiki/Contribution-Guidelines"&gt;Pull Request Requirements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://crowdin.com/project/frappe"&gt;Translations&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Logo and Trademark Policy&lt;/h2&gt; 
&lt;p&gt;Please read our &lt;a href="https://raw.githubusercontent.com/frappe/erpnext/develop/TRADEMARK_POLICY.md"&gt;Logo and Trademark Policy&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;div align="center" style="padding-top: 0.75rem;"&gt; 
 &lt;a href="https://frappe.io" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://frappe.io/files/Frappe-white.png" /&gt; 
   &lt;img src="https://frappe.io/files/Frappe-black.png" alt="Frappe Technologies" height="28" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>jellyfin/jellyfin</title>
      <link>https://github.com/jellyfin/jellyfin</link>
      <description>&lt;p&gt;The Free Software Media System - Server Backend &amp; API&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Jellyfin&lt;/h1&gt; 
&lt;h3 align="center"&gt;The Free Software Media System&lt;/h3&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;img alt="Logo Banner" src="https://raw.githubusercontent.com/jellyfin/jellyfin-ux/master/branding/SVG/banner-logo-solid.svg?sanitize=true" /&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://github.com/jellyfin/jellyfin"&gt; &lt;img alt="GPL 2.0 License" src="https://img.shields.io/github/license/jellyfin/jellyfin.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://github.com/jellyfin/jellyfin/releases"&gt; &lt;img alt="Current Release" src="https://img.shields.io/github/release/jellyfin/jellyfin.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://translate.jellyfin.org/projects/jellyfin/jellyfin-core/?utm_source=widget"&gt; &lt;img alt="Translation Status" src="https://translate.jellyfin.org/widgets/jellyfin/-/jellyfin-core/svg-badge.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/jellyfin/jellyfin"&gt; &lt;img alt="Docker Pull Count" src="https://img.shields.io/docker/pulls/jellyfin/jellyfin.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://opencollective.com/jellyfin"&gt; &lt;img alt="Donate" src="https://img.shields.io/opencollective/all/jellyfin.svg?label=backers" /&gt; &lt;/a&gt; &lt;a href="https://features.jellyfin.org"&gt; &lt;img alt="Submit Feature Requests" src="https://img.shields.io/badge/fider-vote%20on%20features-success.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://matrix.to/#/#jellyfinorg:matrix.org"&gt; &lt;img alt="Chat on Matrix" src="https://img.shields.io/matrix/jellyfinorg:matrix.org.svg?logo=matrix" /&gt; &lt;/a&gt; &lt;a href="https://github.com/jellyfin/jellyfin/releases.atom"&gt; &lt;img alt="Release RSS Feed" src="https://img.shields.io/badge/rss-releases-ffa500?logo=rss" /&gt; &lt;/a&gt; &lt;a href="https://github.com/jellyfin/jellyfin/commits/master.atom"&gt; &lt;img alt="Master Commits RSS Feed" src="https://img.shields.io/badge/rss-commits-ffa500?logo=rss" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Jellyfin is a Free Software Media System that puts you in control of managing and streaming your media. It is an alternative to the proprietary Emby and Plex, to provide media from a dedicated server to end-user devices via multiple apps. Jellyfin is descended from Emby's 3.5.2 release and ported to the .NET platform to enable full cross-platform support.&lt;/p&gt; 
&lt;p&gt;There are no strings attached, no premium licenses or features, and no hidden agendas: just a team that wants to build something better and work together to achieve it. We welcome anyone who is interested in joining us in our quest!&lt;/p&gt; 
&lt;p&gt;For further details, please see &lt;a href="https://jellyfin.org/docs/"&gt;our documentation page&lt;/a&gt;. To receive the latest updates, get help with Jellyfin, and join the community, please visit &lt;a href="https://jellyfin.org/docs/general/getting-help"&gt;one of our communication channels&lt;/a&gt;. For more information about the project, please see our &lt;a href="https://jellyfin.org/docs/general/about"&gt;about page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Want to get started?&lt;/strong&gt;&lt;br /&gt; Check out our &lt;a href="https://jellyfin.org/downloads"&gt;downloads page&lt;/a&gt; or our &lt;a href="https://jellyfin.org/docs/general/installation/"&gt;installation guide&lt;/a&gt;, then see our &lt;a href="https://jellyfin.org/docs/general/quick-start"&gt;quick start guide&lt;/a&gt;. You can also &lt;a href="https://jellyfin.org/docs/general/installation/source"&gt;build from source&lt;/a&gt;.&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Something not working right?&lt;/strong&gt;&lt;br /&gt; Open an &lt;a href="https://jellyfin.org/docs/general/contributing/issues"&gt;Issue&lt;/a&gt; on GitHub.&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Want to contribute?&lt;/strong&gt;&lt;br /&gt; Check out our &lt;a href="https://jellyfin.org/contribute"&gt;contributing choose-your-own-adventure&lt;/a&gt; to see where you can help, then see our &lt;a href="https://jellyfin.org/docs/general/contributing/"&gt;contributing guide&lt;/a&gt; and our &lt;a href="https://jellyfin.org/docs/general/community-standards"&gt;community standards&lt;/a&gt;.&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;New idea or improvement?&lt;/strong&gt;&lt;br /&gt; Check out our &lt;a href="https://features.jellyfin.org/?view=most-wanted"&gt;feature request hub&lt;/a&gt;.&lt;br /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Don't see Jellyfin in your language?&lt;/strong&gt;&lt;br /&gt; Check out our &lt;a href="https://translate.jellyfin.org"&gt;Weblate instance&lt;/a&gt; to help translate Jellyfin and its subprojects.&lt;br /&gt;&lt;/p&gt; 
&lt;a href="https://translate.jellyfin.org/engage/jellyfin/?utm_source=widget"&gt; &lt;img src="https://translate.jellyfin.org/widgets/jellyfin/-/jellyfin-web/multi-auto.svg?sanitize=true" alt="Detailed Translation Status" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Jellyfin Server&lt;/h2&gt; 
&lt;p&gt;This repository contains the code for Jellyfin's backend server. Note that this is only one of many projects under the Jellyfin GitHub &lt;a href="https://github.com/jellyfin/"&gt;organization&lt;/a&gt; on GitHub. If you want to contribute, you can start by checking out our &lt;a href="https://jellyfin.org/docs/general/contributing/index.html"&gt;documentation&lt;/a&gt; to see what to work on.&lt;/p&gt; 
&lt;h2&gt;Server Development&lt;/h2&gt; 
&lt;p&gt;These instructions will help you get set up with a local development environment in order to contribute to this repository. Before you start, please be sure to completely read our &lt;a href="https://jellyfin.org/docs/general/contributing/development.html"&gt;guidelines on development contributions&lt;/a&gt;. Note that this project is supported on all major operating systems except FreeBSD, which is still incompatible.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;p&gt;Before the project can be built, you must first install the &lt;a href="https://dotnet.microsoft.com/download/dotnet"&gt;.NET 9.0 SDK&lt;/a&gt; on your system.&lt;/p&gt; 
&lt;p&gt;Instructions to run this project from the command line are included here, but you will also need to install an IDE if you want to debug the server while it is running. Any IDE that supports .NET 6 development will work, but two options are recent versions of &lt;a href="https://visualstudio.microsoft.com/downloads/"&gt;Visual Studio&lt;/a&gt; (at least 2022) and &lt;a href="https://code.visualstudio.com/Download"&gt;Visual Studio Code&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/jellyfin/jellyfin-ffmpeg"&gt;ffmpeg&lt;/a&gt; will also need to be installed.&lt;/p&gt; 
&lt;h3&gt;Cloning the Repository&lt;/h3&gt; 
&lt;p&gt;After dependencies have been installed you will need to clone a local copy of this repository. If you just want to run the server from source you can clone this repository directly, but if you are intending to contribute code changes to the project, you should &lt;a href="https://jellyfin.org/docs/general/contributing/development.html#set-up-your-copy-of-the-repo"&gt;set up your own fork&lt;/a&gt; of the repository. The following example shows how you can clone the repository directly over HTTPS.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/jellyfin/jellyfin.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Installing the Web Client&lt;/h3&gt; 
&lt;p&gt;The server is configured to host the static files required for the &lt;a href="https://github.com/jellyfin/jellyfin-web"&gt;web client&lt;/a&gt; in addition to serving the backend by default. Before you can run the server, you will need to get a copy of the web client since they are not included in this repository directly.&lt;/p&gt; 
&lt;p&gt;Note that it is also possible to &lt;a href="https://raw.githubusercontent.com/jellyfin/jellyfin/master/#hosting-the-web-client-separately"&gt;host the web client separately&lt;/a&gt; from the web server with some additional configuration, in which case you can skip this step.&lt;/p&gt; 
&lt;p&gt;There are three options to get the files for the web client.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download one of the finished builds from the &lt;a href="https://dev.azure.com/jellyfin-project/jellyfin/_build?definitionId=27"&gt;Azure DevOps pipeline&lt;/a&gt;. You can download the build for a specific release by looking at the &lt;a href="https://dev.azure.com/jellyfin-project/jellyfin/_build?definitionId=27&amp;amp;_a=summary&amp;amp;repositoryFilter=6&amp;amp;view=branches"&gt;branches tab&lt;/a&gt; of the pipelines page.&lt;/li&gt; 
 &lt;li&gt;Build them from source following the instructions on the &lt;a href="https://github.com/jellyfin/jellyfin-web"&gt;jellyfin-web repository&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Get the pre-built files from an existing installation of the server. For example, with a Windows server installation the client files are located at &lt;code&gt;C:\Program Files\Jellyfin\Server\jellyfin-web&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Running The Server&lt;/h3&gt; 
&lt;p&gt;The following instructions will help you get the project up and running via the command line, or your preferred IDE.&lt;/p&gt; 
&lt;h4&gt;Running With Visual Studio&lt;/h4&gt; 
&lt;p&gt;To run the project with Visual Studio you can open the Solution (&lt;code&gt;.sln&lt;/code&gt;) file and then press &lt;code&gt;F5&lt;/code&gt; to run the server.&lt;/p&gt; 
&lt;h4&gt;Running With Visual Studio Code&lt;/h4&gt; 
&lt;p&gt;To run the project with Visual Studio Code you will first need to open the repository directory with Visual Studio Code using the &lt;code&gt;Open Folder...&lt;/code&gt; option.&lt;/p&gt; 
&lt;p&gt;Second, you need to &lt;a href="https://code.visualstudio.com/docs/editor/extension-gallery#_recommended-extensions"&gt;install the recommended extensions for the workspace&lt;/a&gt;. Note that extension recommendations are classified as either "Workspace Recommendations" or "Other Recommendations", but only the "Workspace Recommendations" are required.&lt;/p&gt; 
&lt;p&gt;After the required extensions are installed, you can run the server by pressing &lt;code&gt;F5&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Running From the Command Line&lt;/h4&gt; 
&lt;p&gt;To run the server from the command line you can use the &lt;code&gt;dotnet run&lt;/code&gt; command. The example below shows how to do this if you have cloned the repository into a directory named &lt;code&gt;jellyfin&lt;/code&gt; (the default directory name) and should work on all operating systems.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd jellyfin                          # Move into the repository directory
dotnet run --project Jellyfin.Server --webdir /absolute/path/to/jellyfin-web/dist # Run the server startup project
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A second option is to build the project and then run the resulting executable file directly. When running the executable directly you can easily add command line options. Add the &lt;code&gt;--help&lt;/code&gt; flag to list details on all the supported command line options.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Build the project&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;dotnet build                       # Build the project
cd Jellyfin.Server/bin/Debug/net9.0 # Change into the build output directory
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Execute the build output. On Linux, Mac, etc. use &lt;code&gt;./jellyfin&lt;/code&gt; and on Windows use &lt;code&gt;jellyfin.exe&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Accessing the Hosted Web Client&lt;/h4&gt; 
&lt;p&gt;If the Server is configured to host the Web Client, and the Server is running, the Web Client can be accessed at &lt;code&gt;http://localhost:8096&lt;/code&gt; by default.&lt;/p&gt; 
&lt;p&gt;API documentation can be viewed at &lt;code&gt;http://localhost:8096/api-docs/swagger/index.html&lt;/code&gt;&lt;/p&gt; 
&lt;h3&gt;Running from GitHub Codespaces&lt;/h3&gt; 
&lt;p&gt;As Jellyfin will run on a container on a GitHub hosted server, JF needs to handle some things differently.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Depending on the selected configuration (if you just click 'create codespace' it will create a default configuration one) it might take 20-30 seconds to load all extensions and prepare the environment while VS Code is already open. Just give it some time and wait until you see &lt;code&gt;Downloading .NET version(s) 7.0.15~x64 ...... Done!&lt;/code&gt; in the output tab.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; If you want to access the JF instance from outside, like with a WebClient on another PC, remember to set the "ports" in the lower VS Code window to public.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; When first opening the server instance with any WebUI, you will be sent to the login instead of the setup page. Refresh the login page once and you should be redirected to the Setup.&lt;/p&gt; 
&lt;p&gt;There are two configurations for you to choose from.&lt;/p&gt; 
&lt;h4&gt;Default - Development Jellyfin Server&lt;/h4&gt; 
&lt;p&gt;This creates a container that has everything to run and debug the Jellyfin Media server but does not setup anything else. Each time you create a new container you have to run through the whole setup again. There is also no ffmpeg, webclient or media preloaded. Use the &lt;code&gt;.NET Launch (nowebclient)&lt;/code&gt; launch config to start the server.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Keep in mind that as this has no web client you have to connect to it via an external client. This can be just another codespace container running the WebUI. vuejs does not work from the get-go as it does not support the setup steps.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Development Jellyfin Server ffmpeg&lt;/h4&gt; 
&lt;p&gt;this extends the default server with a default installation of ffmpeg6 though the means described here: &lt;a href="https://jellyfin.org/docs/general/installation/linux#repository-manual"&gt;https://jellyfin.org/docs/general/installation/linux#repository-manual&lt;/a&gt; If you want to install a specific ffmpeg version, follow the comments embedded in the &lt;code&gt;.devcontainer/Dev - Server Ffmpeg/install.ffmpeg.sh&lt;/code&gt; file.&lt;/p&gt; 
&lt;p&gt;Use the &lt;code&gt;ghcs .NET Launch (nowebclient, ffmpeg)&lt;/code&gt; launch config to run with the jellyfin-ffmpeg enabled.&lt;/p&gt; 
&lt;h3&gt;Running The Tests&lt;/h3&gt; 
&lt;p&gt;This repository also includes unit tests that are used to validate functionality as part of a CI pipeline on Azure. There are several ways to run these tests.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run tests from the command line using &lt;code&gt;dotnet test&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run tests in Visual Studio using the &lt;a href="https://docs.microsoft.com/en-us/visualstudio/test/run-unit-tests-with-test-explorer"&gt;Test Explorer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Run individual tests in Visual Studio Code using the associated &lt;a href="https://github.com/OmniSharp/omnisharp-vscode/wiki/How-to-run-and-debug-unit-tests"&gt;CodeLens annotation&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Advanced Configuration&lt;/h3&gt; 
&lt;p&gt;The following sections describe some more advanced scenarios for running the server from source that build upon the standard instructions above.&lt;/p&gt; 
&lt;h4&gt;Hosting The Web Client Separately&lt;/h4&gt; 
&lt;p&gt;It is not necessary to host the frontend web client as part of the backend server. Hosting these two components separately may be useful for frontend developers who would prefer to host the client in a separate webpack development server for a tighter development loop. See the &lt;a href="https://github.com/jellyfin/jellyfin-web#getting-started"&gt;jellyfin-web&lt;/a&gt; repo for instructions on how to do this.&lt;/p&gt; 
&lt;p&gt;To instruct the server not to host the web content, there is a &lt;code&gt;nowebclient&lt;/code&gt; configuration flag that must be set. This can be specified using the command line switch &lt;code&gt;--nowebclient&lt;/code&gt; or the environment variable &lt;code&gt;JELLYFIN_NOWEBCONTENT=true&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Since this is a common scenario, there is also a separate launch profile defined for Visual Studio called &lt;code&gt;Jellyfin.Server (nowebcontent)&lt;/code&gt; that can be selected from the 'Start Debugging' dropdown in the main toolbar.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; The setup wizard cannot be run if the web client is hosted separately.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; This project is supported by: &lt;br /&gt; &lt;br /&gt; &lt;a href="https://www.digitalocean.com"&gt;&lt;img src="https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg?sanitize=true" height="50px" alt="DigitalOcean" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.jetbrains.com"&gt;&lt;img src="https://gist.githubusercontent.com/anthonylavado/e8b2403deee9581e0b4cb8cd675af7db/raw/fa104b7d73f759d7262794b94569f1b89df41c0b/jetbrains.svg?sanitize=true" height="50px" alt="JetBrains logo" /&gt;&lt;/a&gt; &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>humanlayer/humanlayer</title>
      <link>https://github.com/humanlayer/humanlayer</link>
      <description>&lt;p&gt;The best way to get AI coding agents to solve hard problems in complex codebases.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/humanlayer/humanlayer/main/docs/images/wordmark-light.svg?sanitize=true" alt="Wordmark Logo of HumanLayer" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;Close your editor forever.&lt;/h1&gt; 
 &lt;p&gt;&lt;strong&gt;CodeLayer is an open source IDE that lets you orchestrate AI coding agents.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;It comes with battle-tested workflows that enable AI to solve hard problems in large, complex codebases.&lt;/p&gt; 
 &lt;p&gt;Built on Claude Code. Open source. Scale from your laptop to your entire team.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;&lt;img src="https://img.shields.io/github/stars/humanlayer/humanlayer" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2"&gt;&lt;img src="https://img.shields.io/badge/License-Apache-green.svg?sanitize=true" alt="License: Apache-2" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt; &lt;p&gt;&lt;a href="https://humanlayer.dev/code"&gt;Join Waitlist&lt;/a&gt; | &lt;a href="https://humanlayer.dev/discord"&gt;Discord&lt;/a&gt;&lt;/p&gt; &lt;/h3&gt; 
 &lt;img referrerpolicy="no-referrer-when-downgrade" src="https://static.scarf.sh/a.png?x-pxid=fcfc0926-d841-47fb-b8a6-6aba3a6c3228" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Our entire company is using CodeLayer now. We're shipping one banger PR after the other. It is so f-ing good. Unbelievable dude."&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;â€“ RenÃ© Brandel, Founder @ Casco (YC X25)&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Superhuman for Claude Code&lt;/strong&gt; - Keyboard-first workflows designed for builders who value speed and control.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Advanced Context Engineering&lt;/strong&gt; - Scale AI-first dev to your entire team, without devolving into a chaotic slop-fest.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;M U L T I C L A U D E&lt;/strong&gt; - Run Claude Code sessions in parallel. Worktrees? Done. Remote cloud workers? You got it.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"This has improved my productivity (and token consumption) by at least 50%. Taking a superhuman style approach just makes soo much sense. Also, its so freaking cool to look back at all the work you've done in a day."&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;â€“ Tyler Brown, Founder @ Revlo.ai&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;From the team that brought you "Context Engineering"&lt;/h2&gt; 
&lt;p&gt;Leading experts on getting the most out of today's models.&lt;/p&gt; 
&lt;h4&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;Advanced Context Engineering for Coding Agents&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;This talk, given at YC on August 20th, 2025 lays out the groundwork for using AI to solve hard problems in complex codebases.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://humanlayer.dev/youtube"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;12 Factor Agents&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;A set of principles for building reliable and scalable LLM applications, inspired by the original 12-Factor App methodology.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://humanlayer.dev/youtube"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The original repo that coined the term "context engineering" back in April 2025.&lt;/p&gt; 
&lt;h4&gt;&lt;a href="https://humanlayer.dev/podcast"&gt;ğŸ¦„ AI That Works&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;A weekly conversation about how we can all get the most juice out of todays models with @hellovai &amp;amp; @dexhorthy&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/humanlayer/humanlayer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://humanlayer.dev/podcast"&gt;Podcast&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;For Teams&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Invest in outcomes, not tools.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Want to scale AI-first development to your entire org? Get tailored workflows, custom integrations, and cutting-edge advice.&lt;/p&gt; 
&lt;p&gt;HumanLayer's expert engineers will ship in the trenches with you and your team until everyone is a 100x engineer.&lt;/p&gt; 
&lt;p&gt;ğŸ“§ Shoot us an email at &lt;strong&gt;&lt;a href="mailto:contact@humanlayer.dev"&gt;contact@humanlayer.dev&lt;/a&gt;&lt;/strong&gt;, mention your team size and current AI development stack.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Coming soon - join the waitlist for early access
npx humanlayer join-waitlist --email ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Legacy Documentation&lt;/h2&gt; 
&lt;p&gt;Looking for the HumanLayer SDK documentation? See &lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/humanlayer.md"&gt;humanlayer.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;CodeLayer and the HumanLayer SDK are open-source and we welcome contributions in the form of issues, documentation, pull requests, and more. See &lt;a href="https://raw.githubusercontent.com/humanlayer/humanlayer/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The HumanLayer SDK and CodeLayer sources in this repo are licensed under the Apache 2 License.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#humanlayer/humanlayer&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=humanlayer/humanlayer&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>e2b-dev/awesome-ai-agents</title>
      <link>https://github.com/e2b-dev/awesome-ai-agents</link>
      <description>&lt;p&gt;A list of AI autonomous agents&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; ğŸ”® Awesome AI Agents &lt;p align="center"&gt; &lt;a href="https://discord.gg/U7KEcGErtQ" target="_blank"&gt; &lt;img src="https://img.shields.io/static/v1?label=Join&amp;amp;message=%20discord!&amp;amp;color=mediumslateblue" /&gt; &lt;/a&gt; &lt;a href="https://twitter.com/e2b" target="_blank"&gt; &lt;img src="https://img.shields.io/twitter/follow/e2b.svg?logo=twitter" /&gt; &lt;/a&gt; &lt;/p&gt; &lt;/h1&gt; 
&lt;h3 align="center"&gt; Add &lt;a href="https://e2b.dev/docs?ref=awesome-sdks"&gt;Code Interpreter&lt;/a&gt; to your AI App &lt;/h3&gt; 
&lt;h5 align="center"&gt;ğŸŒŸ &lt;a href="https://e2b.dev/ai-agents"&gt;See this list in web UI&lt;/a&gt;&lt;/h5&gt; 
&lt;h5 align="center"&gt;ğŸ‘‰ &lt;a href="https://forms.gle/UXQFCogLYrPFvfoUA"&gt;Submit new product here&lt;/a&gt;&lt;/h5&gt; 
&lt;img src="https://raw.githubusercontent.com/e2b-dev/awesome-ai-agents/main/assets/landscape-latest.png" width="100%" alt="Chart of AI Agents Landscape" /&gt; 
&lt;p&gt;Welcome to our list of AI agents. We structured the list into two parts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/e2b-dev/awesome-ai-agents/main/#open-source-projects"&gt;Open source projects&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/e2b-dev/awesome-ai-agents/main/#closed-source-projects-and-companies"&gt;Closed-source projects and companies&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To filter the products by categories and use-cases, see the ğŸŒŸ &lt;a href="https://e2b.dev/ai-agents"&gt;web version of this list&lt;/a&gt;. ğŸŒŸ&lt;/p&gt; 
&lt;p&gt;The list is done according to our best knowledge, although definitely not comprehensive. Check out also &lt;a href="https://github.com/e2b-dev/awesome-sdks-for-ai-agents"&gt;the Awesome List of SDKs for AI Agents&lt;/a&gt;. Discussion and feedback appreciated! &lt;span&gt;â¤ï¸&lt;/span&gt;&lt;/p&gt; 
&lt;h2&gt;Have anything to add?&lt;/h2&gt; 
&lt;p&gt;Create a pull request or fill in this &lt;a href="https://forms.gle/UXQFCogLYrPFvfoUA"&gt;form&lt;/a&gt;. Please keep the alphabetical order and in the correct category.&lt;/p&gt; 
&lt;p&gt;For adding AI agents'-related SDKs, frameworks and tools, please visit &lt;a href="https://github.com/e2b-dev/awesome-sdks-for-ai-agents"&gt;Awesome SDKs for AI Agents&lt;/a&gt;. This list is only for AI assistants and agents.&lt;/p&gt; 
&lt;!--
## Who's behind this?
This list is made by the team behind [e2b](https://github.com/e2b-dev/e2b). E2b is building AWS for AI agents. We help developers to deploy, test, and monitor AI agents. E2b is agnostic to your tech stack and aims to work with any tooling for building AI agents.
---&gt; 
&lt;h2&gt;Check out E2B - Code Interpreting for AI apps&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check out &lt;a href="https://e2b.dev/docs?ref=awesome-sdk"&gt;Code Interpreter SDK&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Explore examples in &lt;a href="https://github.com/e2b-dev/e2b-cookbook"&gt;E2B Cookbook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Read our &lt;a href="https://e2b.dev/docs?ref=awesome-sdks"&gt;docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Contact us at &lt;a href="mailto:hello@e2b.dev"&gt;hello@e2b.dev&lt;/a&gt; or &lt;a href="https://discord.gg/35NF4Y8WSE"&gt;on Discord&lt;/a&gt;. Follow us on &lt;a href="https://twitter.com/e2b"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Open-source projects&lt;/h1&gt; 
&lt;h2&gt;&lt;a href="https://github.com/HumanSignal/Adala"&gt;Adala&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Adala: Autonomous Data (Labeling) Agent framework&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/HumanSignal/Adala/raw/master/docs/src/img/logo-dark-mode.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Reliable agents&lt;/strong&gt;: Built on ground truth data for consistent, trustworthy results.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Controllable output&lt;/strong&gt;: Tailor output with flexible constraints to fit your needs.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Specialized in data processing&lt;/strong&gt;: Agents excel in custom data labeling and processing tasks.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Autonomous learning&lt;/strong&gt;: Agents evolve through observations and reflections, not just automation.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Flexible and extensible runtime&lt;/strong&gt;: Adaptable framework with community-driven evolution for diverse needs.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Easily customizable&lt;/strong&gt;: Develop agents swiftly for unique challenges, no steep learning curve.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://humansignal.github.io/Adala/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/QBtgTbXTgU"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/HumanSignal/Adala"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/LehengTHU/Agent4Rec"&gt;Agent4Rec&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Recommender system simulator with 1,000 agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/LehengTHU/Agent4Rec/raw/master/assets/sandbox.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Agent4Rec is a recommender system simulator that utilizes 1,000 LLM-empowered generative agents.&lt;/li&gt; 
  &lt;li&gt;These agents are initialized from the &lt;a href="https://grouplens.org/datasets/movielens/1m/"&gt;MovieLens-1M&lt;/a&gt; dataset, embodying varied social traits and preferences.&lt;/li&gt; 
  &lt;li&gt;Each agent interacts with personalized movie recommendations in a page-by-page manner and undertakes various actions such as watching, rating, evaluating, exiting, and interviewing.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.10108"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/DataBassGit/AgentForge"&gt;AgentForge&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;LLM-agnostic platform for agent building &amp;amp; testing&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1667167265060528129/l8S9vtP2_400x400.jpg" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A low-code framework designed for the swift creation, testing, and iteration of AI-powered autonomous agents and Cognitive Architectures, compatible with various LLM models.&lt;/li&gt; 
  &lt;li&gt;Facilitates building custom agents and cognitive architectures with ease.&lt;/li&gt; 
  &lt;li&gt;Supports multiple LLM models including OpenAI, Anthropic's Claude, and local Oobabooga, allowing flexibility in running different models for different agents based on specific requirements.&lt;/li&gt; 
  &lt;li&gt;Provides customizable agent memory management and on-the-fly prompt editing for rapid development and testing.&lt;/li&gt; 
  &lt;li&gt;Comes with a database-agnostic design ensuring seamless extensibility, with straightforward integration with different databases like ChromaDB for various AI projects.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/DataBassGit/AgentForge"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.agentforge.net/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/ttpXHUtCW6"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/AgentForge"&gt;X&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://agentgpt.reworkd.ai/"&gt;AgentGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Browser-based no-code version of AutoGPT&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/reworkd/AgentGPT/main/next/public/banner.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A no-code platform&lt;/li&gt; 
  &lt;li&gt;Process: 
   &lt;ul&gt; 
    &lt;li&gt;Assigning a goal to the agent&lt;/li&gt; 
    &lt;li&gt;Witnessing its thinking process&lt;/li&gt; 
    &lt;li&gt;Formulation of an execution plan&lt;/li&gt; 
    &lt;li&gt;Taking actions accordingly&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Uses OpenAI functions&lt;/li&gt; 
  &lt;li&gt;Supports gpt-3.5-16k, pinecone and pg_vector databases&lt;/li&gt; 
  &lt;li&gt;Stack 
   &lt;ul&gt; 
    &lt;li&gt;Frontend: NextJS + Typescript&lt;/li&gt; 
    &lt;li&gt;Backend: FastAPI + Python&lt;/li&gt; 
    &lt;li&gt;DB: MySQL through docker with the option of running SQLite locally&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!--
### Features
- Uses OpenAI **functions**
- Supports gpt-3.5-16k, pinecone and pg_vector databases

### Stack
- Frontend: NextJS + Typescript
- Backend: FastAPI + Python
	- DB: MySQL through docker with the option of running SQLite locally
	--&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.reworkd.ai/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://agentgpt.reworkd.ai/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/reworkd/AgentGPT"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;!-- This is a comment that appears only in the raw text --&gt; 
&lt;h2&gt;&lt;a href="https://github.com/jbexta/AgentPilot"&gt;AgentPilot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build, manage, and chat with agents in desktop app&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/jbexta/AgentPilot/raw/master/docs/demo.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Integrated into Open Interpreter and MemGPT&lt;/li&gt; 
  &lt;li&gt;Group chats feature&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jbexta/AgentPilot"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/AgentPilotAI"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/aiwaves-cn/agents"&gt;Agents&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Library/framework for building language agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/aiwaves-cn/agents/raw/master/assets/agents-logo.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Long-short Term Memory&lt;/strong&gt;: Language agents in the library are equipped with both long-term memory implemented via VectorDB + Semantic Search and short-term memory (working memory) maintained and updated by an LLM.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Tool Usage&lt;/strong&gt;: Language agents in the library can use any external tools via &lt;a href="https://platform.openai.com/docs/guides/gpt/function-calling"&gt;function-calling&lt;/a&gt; and developers can add customized tools/APIs &lt;a href="https://github.com/aiwaves-cn/agents/raw/master/src/agents/Component/ToolComponent.py"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Web Navigation&lt;/strong&gt;: Language agents in the library can use search engines to navigate the web and get useful information.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Multi-agent Communication&lt;/strong&gt;: In addition to single language agents, the library supports building multi-agent systems in which language agents can communicate with other language agents and the environment. Different from most existing frameworks for multi-agent systems that use pre-defined rules to control the order for agents' action, &lt;strong&gt;Agents&lt;/strong&gt; includes a &lt;em&gt;controller&lt;/em&gt; function that dynamically decides which agent will perform the next action using an LLM by considering the previous actions, the environment, and the target of the current states. This makes multi-agent communication more flexible.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Human-Agent interaction&lt;/strong&gt;: In addition to letting language agents communicate with each other in an environment, our framework seamlessly supports human users to play the role of the agent by himself/herself and input his/her own actions, and interact with other language agents in the environment.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Symbolic Control&lt;/strong&gt;: Different from existing frameworks for language agents that only use a simple task description to control the entire multi-agent system over the whole task completion process, &lt;strong&gt;Agents&lt;/strong&gt; allows users to use an &lt;strong&gt;SOP (Standard Operation Process)&lt;/strong&gt; that defines subgoals/subtasks for the overall task to customize fine-grained workflows for the language agents.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https:github.com/aiwaves-cn"&gt;AIWaves Inc.&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2309.07870.pdf"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/aiwaves-cn/agents"&gt;GitHub Repository&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://agents-readthedocsio.readthedocs.io/en/latest/index.html"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/wangchunshu/status/1702512370785100133"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/OpenBMB/AgentVerse"&gt;AgentVerse&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Platform for task-solving &amp;amp; simulation agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/card_img/1744672970822615040/m870GGf1?format=jpg&amp;amp;name=medium" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Assembles multiple agents to collaboratively accomplish tasks.&lt;/li&gt; 
  &lt;li&gt;Allows custom environments for observing or interacting with multiple agents.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Paper: &lt;a href="https://arxiv.org/abs/2308.10848"&gt;AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Agentverse71134"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/gDAXfjMw"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/spaces/AgentVerse/agentVerse"&gt;Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/eumemic/ai-legion"&gt;AI Legion&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multi-agent TS platform, similar to AutoGPT&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://res.cloudinary.com/apideck/image/upload/w_1500,f_auto/v1681330426/marketplaces/ckhg56iu1mkpc0b66vj7fsj3o/listings/ai-legion/screenshots/Screenshot_2023-04-12_at_22.13.24_d9kdoj.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Multi-agent, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An LLM-powered autonomous agent platform&lt;/li&gt; 
  &lt;li&gt;A framework for autonomous agents who can work together to accomplish tasks&lt;/li&gt; 
  &lt;li&gt;Interaction with agents done via console direct messages&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://github.com/eumemic"&gt;eumemic&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://gpt3demo.com/apps/ai-legion"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/eumemic/ai-legion"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/dysmemic"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/paul-gauthier/aider"&gt;Aider&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Use command line to edit code in your local repo&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://repository-images.githubusercontent.com/638629097/1d3d6251-f8be-4d11-bbb1-4e44b7364b74" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Aider is a command line tool that lets you pair program with GPT-3.5/GPT-4, to edit code stored in your local git repository&lt;/li&gt; 
  &lt;li&gt;You can start a new project or work with an existing repo. And you can fluidly switch back and forth between the aider chat where you ask GPT to edit the code and your own editor to make changes yourself&lt;/li&gt; 
  &lt;li&gt;Aider makes sure edits from you and GPT are committed to git with sensible commit messages. Aider is unique in that it works well with pre-existing, larger codebases&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://aider.chat/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://github.com/paul-gauthier"&gt;Paul Gauthier&lt;/a&gt; (Github)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/Tv2uQnR88V"&gt;Discord Invite&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/myshell-ai/AIlice"&gt;AIlice&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Create agents-calling tree to execute your tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/myshell-ai/AIlice/raw/master/AIlice.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Personal assistant, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"An Agent in the form of a chatbot independently plans tasks given in natural language and dynamically creates an agents calling tree to execute tasks.&lt;/li&gt; 
  &lt;li&gt;There is an interaction mechanism between agents to ensure fault tolerance.&lt;/li&gt; 
  &lt;li&gt;External interaction modules can be automatically built for self-expansion.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/myshell-ai/AIlice"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/microsoft/autogen"&gt;AutoGen&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multi-agent framework with diversity of agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/microsoft/autogen/raw/main/website/static/img/autogen_agentchat.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A framework for developing LLM (Large Language Model) applications with multiple conversational agents.&lt;/li&gt; 
  &lt;li&gt;These agents can collaborate to solve tasks and can interact seamlessly with humans.&lt;/li&gt; 
  &lt;li&gt;It simplifies complex LLM workflows, enhancing automation and optimization.&lt;/li&gt; 
  &lt;li&gt;It offers a range of working systems across various domains and complexities.&lt;/li&gt; 
  &lt;li&gt;It improves LLM inference with easy performance tuning and utility features like API unification and caching.&lt;/li&gt; 
  &lt;li&gt;It supports advanced usage patterns, including error handling, multi-config inference, and context programming.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Paper: &lt;a href="https://arxiv.org/pdf/2308.08155.pdf"&gt;AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/pAbnFJrkgZ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/pyautogen"&gt;Twitter thread describing the system&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://agpt.co/?utm_source=awesome-ai-agents"&gt;AutoGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Experimental attempt to make GPT4 fully autonomous&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://news.agpt.co/wp-content/uploads/2023/04/Logo_-_Auto_GPT-B-800x363.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An experimental open-source attempt to make GPT-4 fully autonomous, with &amp;gt;140k stars on GitHub&lt;/li&gt; 
  &lt;li&gt;Chains together LLM "thoughts", to autonomously achieve whatever goal you set&lt;/li&gt; 
  &lt;li&gt;Internet access for searches and information gathering&lt;/li&gt; 
  &lt;li&gt;Long-term and short-term memory management&lt;/li&gt; 
  &lt;li&gt;Can execute many commands such as Google Search, browse websites, write to files, and execute Python files and much more&lt;/li&gt; 
  &lt;li&gt;GPT-4 instances for text generation&lt;/li&gt; 
  &lt;li&gt;Access to popular websites and platforms&lt;/li&gt; 
  &lt;li&gt;File storage and summarization with GPT-3.5&lt;/li&gt; 
  &lt;li&gt;Extensibility with Plugins&lt;/li&gt; 
  &lt;li&gt;"A lot like BabyAGI combined with LangChain tools"&lt;/li&gt; 
  &lt;li&gt;Features added in release 0.4.0 
   &lt;ul&gt; 
    &lt;li&gt;File reading&lt;/li&gt; 
    &lt;li&gt;Commands customization&lt;/li&gt; 
    &lt;li&gt;Enhanced testing&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!--
### Features added in release 0.4.0
- File reading
- Commands customization
- Enhanced testing
--&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Auto_GPT/?utm_source=awesome-ai-agents"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Significant-Gravitas/Auto-GPT/?utm_source=awesome-ai-agents"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.facebook.com/groups/1330282574368178/?utm_source=awesome-ai-agents"&gt;Facebook&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/autogpt/?utm_source=awesome-ai-agents"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/autogpt/?utm_source=awesome-ai-agents"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/SigGravitas/?utm_source=awesome-ai-agents"&gt;Significant Gravitas&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/emrgnt-cmplxty/automata"&gt;Automata&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Generate code based on your project context&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/emrgnt-cmplxty/Automata/assets/68796651/61fe3c33-9b7a-4c1b-9726-a77140476b83" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Model: GPT 4&lt;/li&gt; 
  &lt;li&gt;Automata takes your project as a context, receives tasks, and executes the instructions seamlessly.&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Automata aims to evolve into a fully autonomous, self-programming Artificial Intelligence system.&lt;/li&gt; 
    &lt;li&gt;It's designed for seamless integration with all available agent platforms and LLM providers.&lt;/li&gt; 
    &lt;li&gt;Utilizes the novel code search algorithm, SymbolRank, and associated tools to build superior coding intelligence.&lt;/li&gt; 
    &lt;li&gt;Modular, fully configurable design with minimal reliance on external dependencies&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/emrgnt-cmplxty/automata"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://automata.readthedocs.io/en/latest/"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/ocolegro"&gt;Owen Colegrove&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!--

### Features
- Automata aims to evolve into a fully autonomous, self-programming Artificial Intelligence system.
- It's designed for seamless integration with all available agent platforms and LLM providers.
- Utilizes the novel code search algorithm, SymbolRank, and associated tools to build superior coding intelligence.
- Modular, fully configurable design with minimal reliance on external dependencies.

--&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/irgolic/AutoPR"&gt;AutoPR&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-generated pull requests agent that fixes issues&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/irgolic/AutoPR/raw/main/website/static/img/AutoPR_Mark_color.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Triggered by adding a label containing AutoPR to an issue, AutoPR will: 
   &lt;ul&gt; 
    &lt;li&gt;Plan a fix&lt;/li&gt; 
    &lt;li&gt;Write the code&lt;/li&gt; 
    &lt;li&gt;Push a branch&lt;/li&gt; 
    &lt;li&gt;Open a pull request&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/ykk7Znt3K6"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/stepanogil/autonomous-hr-chatbot"&gt;Autonomous HR Chatbot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that answers HR-related queries using tools&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/stepanogil/autonomous-hr-chatbot/raw/main/assets/sample_chat.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;HR, Business intelligence, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A prototype enterprise application - an Autonomous HR Assistant powered by GPT-3.5.&lt;/li&gt; 
  &lt;li&gt;An agent that can answer HR related queries autonomously using the tools it has on hand.&lt;/li&gt; 
  &lt;li&gt;Powered by GPT-3.5&lt;/li&gt; 
  &lt;li&gt;Current tools assigned to the agent (with more on the way): 
   &lt;ul&gt; 
    &lt;li&gt;Timekeeping Policy&lt;/li&gt; 
    &lt;li&gt;Employee Data&lt;/li&gt; 
    &lt;li&gt;Calculator&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Medium: &lt;a href="https://pub.towardsai.net/creating-a-mostly-autonomous-hr-assistant-with-chatgpt-and-langchains-agents-and-tools-1cdda0aa70ef"&gt;Creating a (mostly) Autonomous HR Assistant with ChatGPT and LangChainâ€™s Agents and Tools&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/stepanogil/autonomous-hr-chatbot"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/Stepanogil"&gt;Stephen Bonifacio&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=id7XRcEIBvg&amp;amp;ab_channel=StephenBonifacio"&gt;YouTube demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pub.towardsai.net/creating-a-mostly-autonomous-hr-assistant-with-chatgpt-and-langchains-agents-and-tools-1cdda0aa70ef"&gt;Blog post&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/yoheinakajima/babyagi"&gt;BabyAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A simple framework for managing tasks using AI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/21254008/235015461-543a897f-70cc-4b63-941a-2ae3c9172b11.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A pared-down version of the original &lt;a href="https://twitter.com/yoheinakajima/status/1640934493489070080?s=20"&gt;Task-Driven Autonomous Agent&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Creates tasks based on the result of previous tasks and a predefined objective.&lt;/li&gt; 
  &lt;li&gt;The script then uses OpenAI's NLP capabilities to create new tasks based on the objective&lt;/li&gt; 
  &lt;li&gt;Leverages OpenAI's GPT-4, pinecone vector search, and LangChainAI framework&lt;/li&gt; 
  &lt;li&gt;Default model is OpenAI GPT3-turbo&lt;/li&gt; 
  &lt;li&gt;The system maintains a task list for managing and prioritizing tasks&lt;/li&gt; 
  &lt;li&gt;It autonomously creates new tasks based on completed results and reprioritizes the task list accordingly, showcasing the adaptability of AI-powered language models&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Paper: &lt;a href="https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/"&gt;Task-driven Autonomous Agent Utilizing GPT-4, Pinecone, and LangChain for Diverse Applications&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/TMUw26XUcg"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima"&gt;Founder's Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1640934493489070080"&gt;Twitter thread describing the system&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://yoheinakajima.com/babybeeagi-task-management-and-functionality-expansion-on-top-of-babyagi/"&gt;BabyBeeAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Task management &amp;amp; functionality BabyAGI expansion&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://yoheinakajima.com/wp-content/uploads/2023/04/image.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A more advanced version of the original BabyAGI code&lt;/li&gt; 
  &lt;li&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Improves upon the original framework, by introducing a more complex task management prompt, allowing for more comprehensive analysis and synthesis of information&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Designed to handle multiple functions within one task management prompt&lt;/li&gt; 
  &lt;li&gt;Built on top of the GPT-4 architecture, resulting in slower processing speeds and occasional errors&lt;/li&gt; 
  &lt;li&gt;Provides a framework that can be further built upon and improved, paving the way for more sophisticated AI applications&lt;/li&gt; 
  &lt;li&gt;One of the significant differences between BabyAGI and BabyBeeAGI is the complexity of the task management prompt&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1652732735344246784"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yoheinakajima/babyagi/raw/main/classic/BabyBeeAGI.py"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://replit.com/@YoheiNakajima/BabyBeeAGI?v=1"&gt;Replit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/yoheinakajima"&gt;@yoheinakajima&lt;/a&gt; (Twitter)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://replit.com/@YoheiNakajima/BabyCatAGI"&gt;BabyCatAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;BabyCatAGI is a mod of BabyBeeAGI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/FwBwoRracAI99iP?format=jpg&amp;amp;name=medium" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Just 300 lines of code&lt;/li&gt; 
  &lt;li&gt;This was built as a d iteration on the original BabyAGI code in a lightweight way. Differences to BabyAGI include the following: 
   &lt;ul&gt; 
    &lt;li&gt;Task Creation Agent runs once&lt;/li&gt; 
    &lt;li&gt;Execution Agent loops through tasks&lt;/li&gt; 
    &lt;li&gt;Task dependencies for pulling relevant results&lt;/li&gt; 
    &lt;li&gt;Two tools: search tool and text completion&lt;/li&gt; 
    &lt;li&gt;â€œMini-agentâ€ as tool&lt;/li&gt; 
    &lt;li&gt;Search tool combines search, scrape, chunking, and extraction.&lt;/li&gt; 
    &lt;li&gt;Results combined to create summary report&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!--
### How to use
- Fork this into a private Repl
- Add your OpenAI API Key (required) and SerpAPI Key (optional)
- Update the OBJECTIVE variable
- Press "Run" at the top.
--&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1657448504112091136"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yoheinakajima/babyagi/raw/main/classic/BabyCatAGI.py"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://replit.com/@YoheiNakajima/BabyCatAGI"&gt;Replit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/yoheinakajima"&gt;@yoheinakajima&lt;/a&gt; (Twitter)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1666313838868992001"&gt;BabyDeerAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Mod of BabyAGI with only ~350 lines of code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/Fx_tr0yaUAYP1Q0?format=jpg&amp;amp;name=medium" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Parallel tasks (making it faster)&lt;/li&gt; 
    &lt;li&gt;3.5-turbo only (GPT-4 not required)&lt;/li&gt; 
    &lt;li&gt;User input tool&lt;/li&gt; 
    &lt;li&gt;Query rewrite in web search tool&lt;/li&gt; 
    &lt;li&gt;Saves results&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1666313838868992001"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yoheinakajima/babyagi/raw/main/classic/BabyDeerAGI.py"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://replit.com/@YoheiNakajima/BabyDeerAGI"&gt;Replit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/yoheinakajima"&gt;@yoheinakajima&lt;/a&gt; (Twitter)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1678443482866933760"&gt;BabyElfAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Mod of BabyDeerAGI, with ~895 lines of code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/F0sHc04aMAEVn3D?format=jpg&amp;amp;name=medium" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Skills class allows for creation of new skills&lt;/li&gt; 
    &lt;li&gt;'Dynamic task list' example with vector search&lt;/li&gt; 
    &lt;li&gt;Beta reflection agent&lt;/li&gt; 
    &lt;li&gt;Can read, write, and review its own code&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1678443482866933760"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yoheinakajima/babyagi/raw/main/classic/BabyElfAGI/main.py"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://replit.com/@YoheiNakajima/BabyElfAGI"&gt;Replit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/yoheinakajima"&gt;@yoheinakajima&lt;/a&gt; (Twitter)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/saten-private/BabyCommandAGI"&gt;BabyCommandAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Test what happens when you combine CLI and LLM&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/saten-private/BabyCommandAGI/raw/main/docs/Architecture.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;gent designed to test what happens when you combine CLI and LLM, which are more traditional interfaces than GUI (created by @saten-private)&lt;/li&gt; 
  &lt;li&gt;An AI agent based on @yoheinakajima's &lt;a href="https://github.com/yoheinakajima/babyagi"&gt;BabyAGI&lt;/a&gt; which executes shell commands&lt;/li&gt; 
  &lt;li&gt;Automatic Programming, Successfully created an app automatically just by providing feedback. The procedure can be found &lt;a href="https://twitter.com/saten_work/status/1674855573412810753"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;Automatic Environment Setup, Successfully installed a Flutter environment on Linux in a container, created the Flutter app, and launched it. The procedure can be found &lt;a href="https://twitter.com/saten_work/status/1667126272072491009"&gt;here&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;Aside from setting up the environment, it seems to be able to handle a bit of general tasks such as &lt;a href="https://anyaitools.com/babycommandagi/?utm_source=SocialAutoPoster&amp;amp;utm_medium=Social&amp;amp;utm_campaign=Twitter"&gt;Generating text, like poems, code, scripts, musical pieces, email, and letters, translating languages&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;There is a risk of breaking the environment. Please run in a virtual environment such as Docker.&lt;/li&gt; 
  &lt;li&gt;GPT-4 or higher is recommended&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/saten_work"&gt;Founder's Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/saten_work/status/1654571194111393793"&gt;Twitter thread describing the system&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/yoheinakajima/babyagi/tree/main/classic/babyfoxagi"&gt;BabyFoxAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Mod of BabyAGI with a new parallel UI panel&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/F2Vpt4EbIAAa326?format=jpg&amp;amp;name=medium" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A mod of BabyElfAGI, in a series of mods w the naming of Baby
   &lt;animal&gt;
    AGI in alphabetical order
   &lt;/animal&gt;&lt;/li&gt; 
  &lt;li&gt;Self-improving task lists (FOXY method) 
   &lt;ul&gt; 
    &lt;li&gt;By storing a final reflection at the end, and pulling the most relevant reflection to guide future runs, BabyAGI slowly generates better and better tasks lists&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Novel Chat UI w parallel tasks 
   &lt;ul&gt; 
    &lt;li&gt;You can chat w BabyAGI! It has an experimental UI where the chat is separate from the tasks/output panel, allowing you to request multiple tasks in parallel&lt;/li&gt; 
    &lt;li&gt;The Chat UI can use a single skill quickly, or chain multiple skills together using a tasklist&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;New skills 
   &lt;ul&gt; 
    &lt;li&gt;ğŸ¨ DALLE skill with prompt assist&lt;/li&gt; 
    &lt;li&gt;ğŸ¶ Music player w Deezer&lt;/li&gt; 
    &lt;li&gt;ğŸ“Š Airtable search (add your own table/base ID)&lt;/li&gt; 
    &lt;li&gt;ğŸ” Startup Analyst (example of beefy function call as a skill)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Itâ€™s own README&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima"&gt;Author's Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/yoheinakajima/status/1697539193768116449"&gt;Twitter thread describing the system&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://replit.com/@YoheiNakajima"&gt;Replit&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/pgalko/BambooAI"&gt;BambooAI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Data exploration and analysis for non-programmers&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/card_img/1745187734602313730/f-W5kbIU?format=jpg&amp;amp;name=medium" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;BambooAI runs in a loop (until user decides to end it).&lt;/li&gt; 
  &lt;li&gt;Allows mixing of different models with different capabilities, token costs and context windows for different tasks.&lt;/li&gt; 
  &lt;li&gt;Maintains the memory of previous conversations.&lt;/li&gt; 
  &lt;li&gt;Builds the prompts dynamically utilising relevant context from Pinecone vector DB.&lt;/li&gt; 
  &lt;li&gt;Offers a narrative or asks follow up questions if required.&lt;/li&gt; 
  &lt;li&gt;For codified responses, the task is broken down into a list of steps and a pseudo-code algorithm is built.&lt;/li&gt; 
  &lt;li&gt;Based on the algorithm, it ises the python code for dataset analysis, modeling or plotting.&lt;/li&gt; 
  &lt;li&gt;Debugs the code which then executes, auto-corrects if needs to, and displays the output to user.&lt;/li&gt; 
  &lt;li&gt;Ranks the final answers, and asks user for feedback.&lt;/li&gt; 
  &lt;li&gt;Builds a vector DB knowledge-base, based on the rank and the user feedback.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/pgalko/BambooAI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/pgalko"&gt;Creators's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/AutoPackAI/beebot"&gt;BeeBot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Early-stage project for wide range of tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://camo.githubusercontent.com/72231056f7393fa18ee2baa5cedf2688d1fc15478bb6131936e222e5d23ccbb6/68747470733a2f2f6572696b6c702e636f6d2f6d6173636f742e706e67" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"BeeBot is currently a work in progress and should be treated as an early stage research project. Its focus is not on production usage at this time."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/AutoPackAI/beebot"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Douglas_Schon/status/1681094815021187072?s=20"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/seahyinghang8/blinky"&gt;Blinky&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;An open-source AI debugging agent for VSCode&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/seahyinghang8/blinky/raw/master/media/banner.png" alt="Banner" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Debugging&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Blinky is an open-source AI debugging agent for VSCode that uses LLMs to help identify and fix backend code errors (inspired by SWE-agent).&lt;/li&gt; 
  &lt;li&gt;Blinky leverages the VSCode API, Language Server Protocol (LSP), and print statement debugging to triangulate and address bugs in real-world backend systems.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=blinky.blinky"&gt;VSCode Extension&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/d3AUNHDb"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/seahyinghang8/blinky"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://bloop.ai/"&gt;Bloop&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI code search, works for Rust and Typescript&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://bloop.ai/_next/static/media/logo_white.b3bdedc0.svg?sanitize=true" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A GPT-4 powered semantic code search engine that uses an AI agent&lt;/li&gt; 
  &lt;li&gt;Precise code navigation&lt;/li&gt; 
  &lt;li&gt;Built on stack graphs and scope queries&lt;/li&gt; 
  &lt;li&gt;Fast code search and regex matching engine written in Rust&lt;/li&gt; 
  &lt;li&gt;Allows to find Code on Rust and Typescript&lt;/li&gt; 
  &lt;li&gt;Allows to stage changes&lt;/li&gt; 
  &lt;li&gt;The agent searches both your local and remote repositories with natural language, regex and filtered queries&lt;/li&gt; 
  &lt;li&gt;Bloop can be run via app (easy to download via GitHub)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/BloopAI/bloop"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://bloop.ai/docs/getting-started"&gt;"Getting started" guide&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/BloopAI/bloop/releases"&gt;Bloop apps&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://bondai.dev/"&gt;BondAI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Code interpreter with CLI &amp;amp; RESTful/WebSocket API&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://bondai.dev/assets/images/bondai-logo-9bec7e27b93b804d375221ff8fb6d336.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A highly capable, autonomous AI Agent with an easy to use CLI, RESTful/WebSocket API, Pre-built Docker image and a robust suite of integrated tools.&lt;/li&gt; 
  &lt;li&gt;Support for all GPT-N, Embeddings and Dall-E OpenAI Models&lt;/li&gt; 
  &lt;li&gt;Support for Azure OpenAI Services&lt;/li&gt; 
  &lt;li&gt;Easy to use SDK for integration into any application&lt;/li&gt; 
  &lt;li&gt;Powerful &lt;strong&gt;Code Interpreter&lt;/strong&gt; capabilities&lt;/li&gt; 
  &lt;li&gt;Powerful data query capabilities via Postgres DB integration&lt;/li&gt; 
  &lt;li&gt;Pre-built Docker image provides safe execution environment for code generation/execution&lt;/li&gt; 
  &lt;li&gt;Support for telephony applications (via BlandAI)&lt;/li&gt; 
  &lt;li&gt;Support for stock trading (via Alpaca Markets)&lt;/li&gt; 
  &lt;li&gt;Integrates with Gmail and Google Search&lt;/li&gt; 
  &lt;li&gt;Easy to install &lt;code&gt;pip install bondai&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;To start the CLI just run &lt;code&gt;bondai&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;To start the RESTful/WebSocket API just run &lt;code&gt;bondai --server&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://bondai.dev"&gt;BondAI Homepage/Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/krohling/bondai"&gt;Github Repository&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://hub.docker.com/r/krohling/bondai"&gt;Docker Image&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/xeol-io/bumpgen"&gt;bumpgen&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent that keeps npm dependencies up-to-date&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/65af8f02f12662528cdc93d6/662e6061d42954630a191417_tanstack-ezgif.com-speed%20(1).gif" alt="demo" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Put dependency management and upgrades on autopilot&lt;/li&gt; 
  &lt;li&gt;bumpgen BUMPs an npm package's version up then GENerates the code fixes for breaking changes&lt;/li&gt; 
  &lt;li&gt;Supports gpt-4-turbo&lt;/li&gt; 
  &lt;li&gt;Easy install &amp;gt; &lt;code&gt;npm install -g bumpgen&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Easy start &amp;gt; &lt;code&gt;bumpgen @tanstack/react-query 5.28.14&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/xeol-io/bumpgen"&gt;Repo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.xeol.io/bumpgen/home"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://cal.ai"&gt;Cal.ai&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open-source scheduling assistant built on Cal.com&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://3620107743-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FpmUOqZjfGqNkiPmqgnMv%2Fuploads%2F9Qaq1hlaTcqKfrc9k4OG%2Fimage.png?alt=media&amp;amp;token=1ffe8530-19ff-4aea-b020-a99cdc224ce1" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Cal.ai can book meetings, summarize your week, and find time with others based on natural language.&lt;/li&gt; 
  &lt;li&gt;Responds flexibly to unseen tasks eg. "move my second-last meeting to tomorrow morning".&lt;/li&gt; 
  &lt;li&gt;Uses GPT-4 and LangChain Agent Executor under the hood.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/calcom/cal.com/tree/main/apps/ai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Authors: &lt;a href="https://github.com/calcom/cal.com/graphs/contributors"&gt;Cal.com core team&lt;/a&gt;, &lt;a href="https://github.com/dexterstorey"&gt;Dexter Storey&lt;/a&gt;, &lt;a href="https://github.com/tedspare"&gt;Ted Spare&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/camel-ai/camel"&gt;CAMEL&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Architecture for â€œMindâ€ Exploration of agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/logo.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CAMEL is an open-source library designed for the study of autonomous and communicative agents. 1)AI user agent: give instructions to the AI assistant with the goal of completing the task.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;ol start="2"&gt; 
  &lt;li&gt;AI assistant agent: follow AI userâ€™s instructions and respond with solutions to the task&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CAMEL also has an open-source community dedicated to the study of autonomous and communicative agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.camel-ai.org/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://ghli.org/camel.pdf"&gt;Paper - CAMEL: Communicative Agents for â€œMindâ€ Exploration of Large Scale Language Model Society&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://colab.research.google.com/drive/1AzP33O8rnMW__7ocWJhVBXjKziJXPtim?usp=sharing"&gt;Colab demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/camel-ai/camel"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/camel-ai"&gt;Hugging face datasets&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://camel-kwr1314.slack.com/join/shared_invite/zt-1vy8u9lbo-ZQmhIAyWSEfSwLCl2r2eKA#/shared-invite/email"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2F1508613885-atari-embeds.googleusercontent.com%2F&amp;amp;ref_src=twsrc%5Etfw%7Ctwcamp%5Ebuttonembed%7Ctwterm%5Efollow%7Ctwgr%5ECamelAIOrg&amp;amp;screen_name=CamelAIOrg"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Authors: Guohao Liâˆ— Hasan Abed Al Kader Hammoud* Hani Itani* Dmitrii Khizbullin, Bernard Ghanem&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.chatarena.org/"&gt;ChatArena&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A chat tool for multi agent interaction&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/Farama-Foundation/chatarena/raw/main/docs/images/chatarena_architecture.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Design, Build-your-own, SDK for AI apps, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ChatArena (or Chat Arena) is a Multi-Agent Language Game Environments for LLMs. The goal is to develop communication and collaboration capabilities of AIs. ChatArena provides:&lt;/li&gt; 
  &lt;li&gt;A general framework for building interactive environments for multiple large language models (LLMs).&lt;/li&gt; 
  &lt;li&gt;A collection of pre-built or community-created environments.&lt;/li&gt; 
  &lt;li&gt;User-friendly interfaces with both Web UI and commandline interfaces.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.chatarena.org/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Farama-Foundation/chatarena"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/_chatarena"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://chatarena.slack.com/join/shared_invite/zt-1t5fpbiep-CbKucEHdJ5YeDLEpKWxDOg#/shared-invite/email"&gt;Slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/OpenBMB/ChatDev"&gt;ChatDev&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Communicative agents for software development&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/OpenBMB/ChatDev/raw/main/misc/logo1.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ChatDev is a virtual software company driven by a multitude of intelligent agents assuming different roles such as CEO, CPO, CTO, programmer, reviewer, tester, and art designer, each represented by unique icons.&lt;/li&gt; 
  &lt;li&gt;These agents collaborate in a structured organizational environment, fulfilling the company's mission to "revolutionize the digital world through programming." They engage in functional seminars focusing on design, coding, testing, and documentation.&lt;/li&gt; 
  &lt;li&gt;ChatDev aims to provide an accessible, modular, and extensible platform based on large language models, facilitating the study of collective intelligence in a controlled setting.&lt;/li&gt; 
  &lt;li&gt;The framework allows for extensive customization, empowering users to tailor the software development process, define phases, and establish specific roles within the virtual company.&lt;/li&gt; 
  &lt;li&gt;ChatDev is committed to open-source principles, encouraging contributions from the community and sharing advancements transparently.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2307.07924"&gt;Paper - ChatDev: Communicative Agents for Software Development&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev/raw/main/wiki.md#local-demo"&gt;Local demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/OpenBMB/ChatDev"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/ur-whitelab/chemcrow-public"&gt;ChemCrow&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;LangChain agent for chemistry-related tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/ur-whitelab/chemcrow-public/raw/main/assets/chemcrow_dark_bold.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Science, Chemistry&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ChemCrow is an open source package for the accurate solution of reasoning-intensive chemical tasks&lt;/li&gt; 
  &lt;li&gt;It integrates 13 expert-design tools to augment LLM performance in chemistry and demonstrate effectiveness in automating chemical tasks&lt;/li&gt; 
  &lt;li&gt;Built with Langchain&lt;/li&gt; 
  &lt;li&gt;The LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output. It is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation. One interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results. (Source: &lt;a href="https://lilianweng.github.io/posts/2023-06-23-agent/"&gt;Weng, Lilian. (Jun 2023). LLM-powered Autonomous Agents". Lilâ€™Log. https://lilianweng.github.io/posts/2023-06-23-agent/.&lt;/a&gt;)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2304.05376"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ur-whitelab/chemcrow-public"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=35607616"&gt;HackerNews Discussion&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/ennucore/clippy/"&gt;Clippy&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that can plan, write, debug, and test code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://lev.la/images/clippy.jpg" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The purpose of Clippy is to elop code for or with the user.&lt;/li&gt; 
  &lt;li&gt;It can plan, write, debug, and test some projects autonomously.&lt;/li&gt; 
  &lt;li&gt;For harder tasks, the best way to use it is to look at its work and provide feedback to it.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ennucore/clippy/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="http://lev.la/"&gt;Lev Chizhov&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/codefuse-ai/codefuse-chatbot"&gt;CodeFuse-ChatBot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent serving entire SW development lifecycle&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/codefuse-ai/codefuse-chatbot/raw/main/sources/docs_imgs/objective_v4.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An intelligent assistant serving the entire software development lifecycle, powered by a Multi-Agent Framework, working with DevOps Toolkits, Code&amp;amp;Doc Repo RAG, etc.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/codefuse-ai/codefuse-chatbot"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/ajhous44/cody"&gt;Cody by ajhous44&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Query and navigate your codebase&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An AI assistant designed to let you interactively query your codebase using natural language.&lt;/li&gt; 
  &lt;li&gt;By utilizing vector embeddings, chunking, and OpenAI's language models, Cody can help you navigate through your code in an efficient and intuitive manner.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/ajhous44/cody"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://github.com/ajhous44/"&gt;@ajhous44&lt;/a&gt; (Github)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://docs.sourcegraph.com/cody"&gt;Cody by Sourcegraph&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that writes code and answers your questions&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://sourcegraph.com/.assets/img/sourcegraph-mark.svg?v2" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;An AI code assistant from Sourcegraph that writes code and answers questions for you by reading your entire codebase and the code graph.&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/sourcegraph/sourcegraph/tree/main/client/cody"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/sourcegraph"&gt;@sourcegraph&lt;/a&gt; (Twitter)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://continue.dev/"&gt;Continue&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open-source autopilot for software development&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://continue.dev/docs/assets/images/continue-cover-logo-aa135cc83fe8a14af480d1633ed74eb5.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An open-source autopilot for software developmentâ€”bring the power of ChatGPT to VS Code&lt;/li&gt; 
  &lt;li&gt;Features: 
   &lt;ul&gt; 
    &lt;li&gt;Answer coding questions&lt;/li&gt; 
    &lt;li&gt;Edit in natural language&lt;/li&gt; 
    &lt;li&gt;Generate files from scratch&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://continue.dev/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/continuedev/continue"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://continue.dev/docs/intro"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/continuedev"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/joaomdmoura/crewai"&gt;CrewAI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Framework for orchestrating role-playing agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/joaomdmoura/crewAI/raw/main/docs/crewai_logo.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, SDK for agents, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Cutting-edge framework for orchestrating role-playing, autonomous AI agents.&lt;/li&gt; 
  &lt;li&gt;By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.&lt;/li&gt; 
  &lt;li&gt;Crew AI is a multi-agent framework built on LangChain, aiming to empower engineers to harness the collective power of AI agents. In contrast to traditional automation methods, Crew AI introduces a new approach to collaborative decision-making, enhanced creativity, and solving complex problems.&lt;/li&gt; 
  &lt;li&gt;The design philosophy of Crew AI advocates simplicity through modularity. Its main components include agents, tools, tasks, processes, and crews. Each agent is akin to a team member, possessing specific roles, background stories, goals, and memories. Through modular design, we make the intricate world of AI agents accessible, manageable, and more engaging.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/joaomdmoura/crewai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/joaomdmoura"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://crewai.net/posts/how-to-use-crew-ai"&gt;Blog post: How to use Crew AI&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/joaomdmoura/CrewAI/wiki"&gt;Crew AI Wiki with examples and guides&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/joaomdmoura/CrewAI/wiki"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/X4JWnZnxPb"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/Technion-Kishony-lab/data-to-paper"&gt;data-to-paper&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-driven research from data to human-verifiable research papers&lt;/p&gt; 
&lt;details&gt; 
 &lt;br /&gt; 
 &lt;img src="https://github.com/Technion-Kishony-lab/data-to-paper/assets/65530510/e33bcb52-5f4e-4fd0-8be9-ebd64607c449" width="400" align="center" /&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Science, Research, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://arxiv.org/abs/2404.17605"&gt;&lt;em&gt;data-to-paper&lt;/em&gt;&lt;/a&gt; is a framework for systematically navigating the power of AI to perform complete end-to-end scientific research, starting from raw data and concluding with comprehensive, transparent, and human-verifiable scientific papers.&lt;/p&gt; 
 &lt;p&gt;Towards this goal, &lt;em&gt;data-to-paper&lt;/em&gt; systematically guides interacting LLM and rule-based agents through the conventional scientific path, from annotated data, through creating research hypotheses, conducting literature search, writing and debugging data analysis code, interpreting the results, and ultimately the step-by-step writing of a complete research paper.&lt;/p&gt; 
 &lt;p&gt;The &lt;em&gt;data-to-paper&lt;/em&gt; framework is created as a research project to understand the capacities and limitations of LLM-driven scientific research, and to develop ways of harnessing LLM to accelerate research while maintaining, and even enhancing, key scientific values, such as transparency, traceability and verifiability, and while allowing scientist to oversee and direct the process [see also: &lt;a href="https://www.nature.com/articles/d41586-023-03266-1"&gt;living guidelines&lt;/a&gt;].&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Technion-Kishony-lab/data-to-paper"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2404.17605"&gt;arXiv preprint&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=Nt_460MmM8k"&gt;Demo video&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.databerry.ai/"&gt;Databerry&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;(Pivoted to Chaindesk) No-code chatbot building&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.chaindesk.ai/_next/image?url=%2Fapp-logo-icon.png&amp;amp;w=256&amp;amp;q=75" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A super-easy no-code platform for creating AI chatbots trained on your own data&lt;/li&gt; 
  &lt;li&gt;After creating new agent, picking a model, data and other settings, they are ready to be deployed to website, Slack, Crisp, or Zapier&lt;/li&gt; 
  &lt;li&gt;Limit of agent in the free version&lt;/li&gt; 
  &lt;li&gt;Stack 
   &lt;ul&gt; 
    &lt;li&gt;Next.js&lt;/li&gt; 
    &lt;li&gt;Joy UI&lt;/li&gt; 
    &lt;li&gt;LangchainJS&lt;/li&gt; 
    &lt;li&gt;PostgreSQL&lt;/li&gt; 
    &lt;li&gt;Prisma&lt;/li&gt; 
    &lt;li&gt;Qdrant&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Streamline customer support, onboard new team members, and more&lt;/li&gt; 
    &lt;li&gt;Load data from anywhere&lt;/li&gt; 
    &lt;li&gt;No-code: User-friendly interface to manage your datastores and chat with your data&lt;/li&gt; 
    &lt;li&gt;Secured API endpoint for querying your data&lt;/li&gt; 
    &lt;li&gt;Auto sync data sources (coming soon)&lt;/li&gt; 
    &lt;li&gt;Auto generates a ChatGPT Plugin for each datastore&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.chaindesk.ai/introduction"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/FSWKj49ckX"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/gmpetrov/databerry"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/melih-unsal/DemoGPT"&gt;DemoGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Generates demo of a new app (of any purpose)&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/melih-unsal/DemoGPT/raw/main/assets/banner_small.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;DemoGPT leverages the power of Language Models (LLMs) to provide fast and effective demo creation for applications.&lt;/li&gt; 
  &lt;li&gt;Automates the prototyping process, making it more efficient and saving valuable time.&lt;/li&gt; 
  &lt;li&gt;Understands and processes the given prompts to generate relevant applications.&lt;/li&gt; 
  &lt;li&gt;Integrated with LangChain for generating application code through iterative parsing of LangChain's documentation with a "Tree of Transformations" (ToT) approach.&lt;/li&gt; 
  &lt;li&gt;The roadmap for DemoGPT includes constant updates and improvements based on user feedback and real-world application, working towards refining the technology and solving the hallucination problem.&lt;/li&gt; 
  &lt;li&gt;"We are planning to introduce features that will further enhance the application generation process, making it more user-friendly and efficient."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/melih-unsal/DemoGPT"&gt;Github&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.demogpt.io/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/demo_gpt"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://demogpt.streamlit.app/"&gt;Streamlit App&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/spaces/melihunsal/demogpt"&gt;Hugging Face Space&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/jina-ai/dev-gpt"&gt;DevGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Team of virtual developers&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1684472754597142529/tyM92sRA_400x400.jpg" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Tell your AI team what microservice you want to build, and they will do it for you. Your imagination is the limit!!&lt;/li&gt; 
  &lt;li&gt;Welcome to Dev-GPT, where we bring your ideas to life with the power of advanced artificial intelligence! Our automated development team is designed to create microservices tailored to your specific needs, making your software development process seamless and efficient. Comprised of a virtual Product Manager, Developer, and DevOps, our AI team ensures that every aspect of your project is covered, from concept to deployment.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/AWXCCC6G2P"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/stitionai/devika"&gt;Devika&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agentic AI Software Engineer&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/stitionai/devika/raw/main/.assets/devika-screenshot.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, general purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Devika is an Agentic AI Software Engineer that can understand high-level human instructions, break them down into steps, research relevant information, and write code to achieve the given objective.&lt;/li&gt; 
  &lt;li&gt;Devika aims to be a competitive open-source alternative to Devin by Cognition AI.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/stitionai/devika"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/entropy-research/Devon"&gt;Devon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open-source Devin alternative&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, general purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Open-source alternative to Devin by Entropy research&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/entropy-research/Devon"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/kuafuai/DevOpsGPT"&gt;DevOpsGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-Driven SW Development Automation Solution&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/kuafuai/DevOpsGPT/raw/master/docs/files/intro-flow-simple.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Welcome to the AI Driven Software Development Automation Solution, abbreviated as DevOpsGPT. We combine LLM (Large Language Model) with DevOps tools to convert natural language requirements into working software. This innovative feature greatly improves development efficiency, shortens development cycles, and reduces communication costs, resulting in higher-quality software delivery.&lt;/p&gt; 
 &lt;h3&gt;Features and Benefits&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Improved development efficiency: No need for tedious requirement document writing and explanations. Users can interact directly with DevOpsGPT to quickly convert requirements into functional software.&lt;/li&gt; 
  &lt;li&gt;Shortened development cycles: The automated software development process significantly reduces delivery time, accelerating software deployment and iterations.&lt;/li&gt; 
  &lt;li&gt;Reduced communication costs: By accurately understanding user requirements, DevOpsGPT minimizes the risk of communication errors and misunderstandings, enhancing collaboration efficiency between development and business teams.&lt;/li&gt; 
  &lt;li&gt;High-quality deliverables: DevOpsGPT generates code and performs validation, ensuring the quality and reliability of the delivered software.&lt;/li&gt; 
  &lt;li&gt;[Enterprise Edition] Existing project analysis: Through AI, automatic analysis of existing project information, accurate decomposition and development of required tasks on the basis of existing projects.&lt;/li&gt; 
  &lt;li&gt;[Enterprise Edition] Professional model selection: Support language model services stronger than GPT in the professional field to better complete requirements development tasks, and support private deployment.&lt;/li&gt; 
  &lt;li&gt;[Enterprise Edition] Support more DevOps platforms: can connect with more DevOps platforms to achieve the development and deployment of the whole process.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.kuafuai.net/"&gt;Creator Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://youtu.be/IWUPbGrJQOU"&gt;Demo Video&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/dot-agent/dotagent"&gt;dotagent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Deploy agents on cloud, PCs, or mobile devices&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/133483033?s=200&amp;amp;v=4" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An agent management system that facilitates the creation of robust AI applications and experimental autonomous agents through a rich suite of developer tools.&lt;/li&gt; 
  &lt;li&gt;Enables the deployment of agents across multiple platforms including cloud, PCs, or mobile devices, and extends functionality through Python or plain English integrations.&lt;/li&gt; 
  &lt;li&gt;Advances prompt engineering with a powerful prompt compiler, offering a higher degree of control over Language Models, significantly optimizing the response generation process.&lt;/li&gt; 
  &lt;li&gt;Allows seamless export of agents into portable files for execution in any environment, along with an optional Agentbox feature for optimized computing resource management within a sandboxed environment.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=uE_fykl8AVI&amp;amp;ab_channel=FahdMirza"&gt;YouTube video&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://eidolonai.com/"&gt;Eidolon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multi Agent SDK with pluggable, modular components&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.eidolonai.com/_astro/default.jKAYXmpI_ZWVg5E.webp" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own (agent-builing frameworks and platforms), SDK for AI apps&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Eidolon is an open source SDK for AI agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://eidolonai.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/eidolon-ai/eidolon"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/august-data/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/dave-brewster-first/"&gt;Dave Brewster - LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/ravi-nextlevelgtm/"&gt;Ravi Ramachandran - LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/lukehlalor/"&gt;Luke Lalor - LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/uilicious/english-compiler"&gt;English Compiler&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Converting markdown specs into functional code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/uilicious/english-compiler/raw/main/notes/imgs/EnglishCommand-CLI-help.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;OC AI based Compiler, for converting english based markdown specs, into functional code&lt;/li&gt; 
  &lt;li&gt;"We know that all greatâ„¢ projects start with awesomeâ„¢ detailed functional specifications. Which is typically written in English, or its many other spoken language alternatives.&lt;/li&gt; 
  &lt;li&gt;So what if, instead of writing code from functional specs, we simply compile it directly to code?&lt;/li&gt; 
  &lt;li&gt;Into a future, where we replace nearly everything, with just written text."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/picocreator"&gt;Creator's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://evo.ninja/"&gt;evo.ninja&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent that adapts its persona to achive tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://camo.githubusercontent.com/3333c49067bddef0b208e36e22cf6ec8066f5be1da1dc327532427a395ed8069/68747470733a2f2f6861636b6d642e696f2f5f75706c6f6164732f4279576a4c4b41686e2e706e67" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Research, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;What makes evo.ninja special is that it adapts itself in real-time, based on the tasks at hand.&lt;/li&gt; 
  &lt;li&gt;Evo utilizes pre-defined agent personas that are tailored to specific domains of tasks.&lt;/li&gt; 
  &lt;li&gt;Each iteration of evo's execution loop it will select and adopt the persona that fits the task at hand best.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://evo.ninja/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/polywrap/evo.ninja/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/r3rwh69cCa"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://fastagency.ai/latest/"&gt;FastAgency&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The fastest way to deploy multi-agent workflows&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://fastagency.ai/latest/assets/img/logo.svg?sanitize=true" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own (agent-builing frameworks and platforms), SDK for AI apps, Multi-agent, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"FastAgency is an open-source framework designed to accelerate the transition from prototype to production for multi-agent AI workflows.&lt;/li&gt; 
  &lt;li&gt;For developers who use the AutoGen framework, FastAgency enables you to seamlessly scale Jupyter notebook prototypes into fully functional, production-ready applications.&lt;/li&gt; 
  &lt;li&gt;With multi-framework support, a unified programming interface, and powerful API integration capabilities, FastAgency streamlines the deployment process, saving time and effort while maintaining flexibility and performance.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://fastagency.ai/latest/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/airtai/fastagency"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://flowiseai.com/"&gt;Flowise&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Low code Agent builder&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://flowiseai.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Flogo-color-high.e60de2f8.png&amp;amp;w=384&amp;amp;q=75" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own (agent-builing frameworks and platforms)&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Flowise is an open source low-code tool for developers to build customized LLM orchestration flow &amp;amp; AI agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://flowiseai.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/FlowiseAI/Flowise"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/FlowiseAI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/flowiseai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/amirrezasalimi/friday/"&gt;Friday&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI developer assistant for Node.js&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/amirrezasalimi/friday/raw/main/screenshot.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A developer assistant able to make whole nodejs project with unlimited prompts&lt;/li&gt; 
  &lt;li&gt;Provides a core prompt for building the foundation of your application&lt;/li&gt; 
  &lt;li&gt;Allows you to add unlimited sections, each of which is a prompt representing a specific part of your app&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Friday utilizes GPT-4 for AI assistance, but it has been tested and optimized with GPT-4-32k for improved speed and better results.&lt;/li&gt; 
    &lt;li&gt;It requires 2 small requests for your app's base and 1 request per section you provide.&lt;/li&gt; 
    &lt;li&gt;Friday employs esbuild behind the scenes for every app created by it.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Author:&lt;/strong&gt; &lt;a href="https://twitter.com/amirsalimiiii"&gt;Amirreza Salimi&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/genia-dev/GeniA"&gt;GeniA&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Engineering platform engineering AI team member&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/genia-dev/GeniA/raw/main/media/genia_title.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;GeniA is able to work along side you on your production enviroment, executing tasks on your behalf in your dev &amp;amp; cloud environments, AWS/k8s/Argo/GitHub etc.&lt;/li&gt; 
  &lt;li&gt;Allows you to enhance the platform by integrating your own tools and APIs.&lt;/li&gt; 
  &lt;li&gt;Slack App Bot integration.&lt;/li&gt; 
  &lt;li&gt;Supports GPT-3.5 &amp;amp; GPT-4.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Authors: &lt;a href="https://github.com/cmpxchg16"&gt;Uri Shamay&lt;/a&gt;, &lt;a href="https://github.com/shlomsh"&gt;Shlomi Shemesh&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://godmode.space/"&gt;Godmode&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Inspired by AutoGPT and BabyAGI, with nice UI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://toolpulse.ai/wp-content/uploads/2023/11/godmode-ai.jpg" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Godmode is a project inspired by Auto-GPT and BabyAGI, conducting various kinds of tasks via nice UI&lt;/li&gt; 
  &lt;li&gt;A web platform inspired by AutoGPT and BabyAGI&lt;/li&gt; 
  &lt;li&gt;What it can do: 
   &lt;ul&gt; 
    &lt;li&gt;Order your coffee at Starbucks&lt;/li&gt; 
    &lt;li&gt;Perform market analysis&lt;/li&gt; 
    &lt;li&gt;Find and negotiate a lease&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Supports GPT-3.5 &amp;amp; GPT-4&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/FOLLGAD/Godmode-GPT"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Authors: &lt;a href="https://twitter.com/emilahlback"&gt;Emil AhlbÃ¤ck&lt;/a&gt;, &lt;a href="https://twitter.com/_Lonis_"&gt;Lonis&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/vSzCcDDwz3"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/_Lonis_/status/1646641412182536196"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/Kav-K/GPTDiscord"&gt;GPT Discord&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The ultimate AI agent integration for Discord&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://camo.githubusercontent.com/c02e68bf20c853637e8cfb02c9406bd2b3b20637ea4ed95b7d68819e94a01dfe/68747470733a2f2f692e696d6775722e636f6d2f425a644f52544c2e706e67" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Content creation, Productivity, General purpose, Discord&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;GPT Discord is a robust, all-in-one GPT interface for Discord.&lt;/li&gt; 
  &lt;li&gt;GPT Discord supports everything from multi-modality image understanding, code interpretation, advanced data analysis, Q&amp;amp;A on your own documents, internet-connected chat with Wolfram Alpha and Google access, AI-moderation, image generation with DALL-E, and much more!&lt;/li&gt; 
  &lt;li&gt;Featuring code execution and environment manipulation by E2B&lt;/li&gt; 
  &lt;li&gt;&lt;img src="https://camo.githubusercontent.com/6806eb5cd7f4a14e693bc732a304f18c5413a493c92b4b73202ec3205017b9c8/68747470733a2f2f692e696d6775722e636f6d2f547366677455322e706e67" alt="image" /&gt;&lt;/li&gt; 
  &lt;li&gt;LLMs/model providers supported: 
   &lt;ul&gt; 
    &lt;li&gt;OpenAI models&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Kav-K/GPTDiscord"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://kaveenk.com/"&gt;Kaveen Kumarasinghe - founder of GPT Discord - website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/kaveenk/"&gt;Kaveen Kumarasinghe - founder of GPT Discord - LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://gptengineer.app/"&gt;GPT Engineer&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Generates entire codebase based on a prompt&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/GDA3bYrXYAE5XDQ?format=jpg&amp;amp;name=4096x4096" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;GPT Engineer is an AI agent that generates an entire codebase based on a prompt.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Model: GPT 4&lt;/li&gt; 
  &lt;li&gt;Specify your project, and the AI agent asks for clarification, and then constructs the entire code base&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Made to be easy to adapt, extend, and make your agent learn how you want your code to look. It generates an entire codebase based on a prompt&lt;/li&gt; 
    &lt;li&gt;You can specify the "identity" of the AI agent by editing the files in the identity folder&lt;/li&gt; 
    &lt;li&gt;Editing the identity and evolving the main prompt is currently how you make the agent remember things between projects&lt;/li&gt; 
    &lt;li&gt;Each step in steps.py will have its communication history with GPT4 stored in the logs folder, and can be rerun with scripts/rerun_edited_message_logs.py&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://gptengineer.app"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/AntonOsika/gpt-engineer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/8tcDQ89Ej2"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/antonosika"&gt;Anton Osika&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Attack/status/1671165869064609792"&gt;Twitter review by @Attack&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/0xpayne/gpt-migrate"&gt;GPT Migrate&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Migrate codebase between frameworks/languages&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://opengraph.githubassets.com/678543c5159118a70ea974db32bb95b310a3fbb6ad4296e97d54335031f8df82/joshpxyne/gpt-migrate" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;GOT Migrate easily migrates your codebase from one framework or language to another.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Pick from different LLMs&lt;/li&gt; 
  &lt;li&gt;Ability to allow GPT Migration to generate and run unit tests for the new codebase&lt;/li&gt; 
  &lt;li&gt;Ability to select source and target language of the migration&lt;/li&gt; 
  &lt;li&gt;Ability to customize the agent's workflow (setup -&amp;gt; migrate -&amp;gt; test)&lt;/li&gt; 
  &lt;li&gt;GPT Migrate team is working on adding &lt;a href="https://github.com/0xpayne/gpt-migrate#-benchmarks"&gt;benchmarks&lt;/a&gt; for the agent&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://gpt-migrate.com/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/joshpxyne"&gt;Josh Payne&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/joshpxyne/status/1675254164165910528"&gt;Announcement&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/Pythagora-io/gpt-pilot"&gt;GPT Pilot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Code the entire scalable app from scratch&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://techcrunch.com/wp-content/uploads/2023/08/gpt_pilot_logo.png?w=150" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;GPT Pilot is an AI agent that codes the entire app as you oversee the code being written&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dev tool that writes scalable apps from scratch while the developer oversees the implementation&lt;/li&gt; 
  &lt;li&gt;A research project to see how can GPT-4 be utilized to generate fully working, production-ready, apps&lt;/li&gt; 
  &lt;li&gt;The main idea is that AI can write most of the code for an app (maybe 95%) but for the rest 5%, a developer is and will be needed until we get full AGI&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Pythagora-io/gpt-pilot"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/HaqXugmxr9"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/assafelovic/gpt-researcher"&gt;GPT Researcher&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that researches entire internet on any topic&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://camo.githubusercontent.com/b3ab3e2b5612657816d64e174672498cd50027b75aa0a795833aee2ddab585b2/68747470733a2f2f636f7772697465722d696d616765732e73332e616d617a6f6e6177732e636f6d2f6172636869746563747572652e706e67" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Research, Science&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;GPT Researcher is a GPT-based autonomous agent that does online comprehensive research on any given topic&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Can produce detailed, factual and unbiased research reports&lt;/li&gt; 
  &lt;li&gt;Offers customization options for focusing on relevant resources, outlines, and lessons&lt;/li&gt; 
  &lt;li&gt;Addresses issues of speed and determinism, offering a more stable performance and increased speed through parallelized agent work, as opposed to synchronous operation&lt;/li&gt; 
  &lt;li&gt;Inspired by AutoGPT and the Plan-and-Solve paper&lt;/li&gt; 
  &lt;li&gt;The main idea is to run "planner" and "execution" agents, whereas the planner generates questions to research, and the execution agents seek the most related information based on each generated research question&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://tavily.com/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/2pFkc83fRq"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/assaf_elovic"&gt;Assaf Elovic&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/nicepkg/gpt-runner"&gt;GPT Runner&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that converses with your files&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://repository-images.githubusercontent.com/640476297/30741f73-caac-48bc-b500-1b7d6efde4c4" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Research, Science&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Conversation with your files which selected by you, no embedding, no vector database!&lt;/li&gt; 
  &lt;li&gt;It's also a AI Prompt Storybook. You can use it to manage some AI preset with your team. It support any IDE and language developer. We provide cli to run web and VSCode extension, Jetbrains plugin is coming soon.&lt;/li&gt; 
  &lt;li&gt;Private first, all data is local.&lt;/li&gt; 
  &lt;li&gt;We support both OpenAI and Anthropic (Claude-2)&lt;/li&gt; 
  &lt;li&gt;It support support for multiple languages.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/nicepkg/gpt-runner"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://github.com/2214962083"&gt;Jinming Yang&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://gptswarm.org/"&gt;GPTSwarm&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Language Agents as Optimizable Graphs&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://gptswarm.org/images/gptswarm.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own (agent-builing frameworks and platforms), General purpose, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ğŸ GPTSwarm is a graph-based framework for LLM-based agents, providing two high-level features: 
   &lt;ul&gt; 
    &lt;li&gt;It lets you build LLM-based agents from graphs.&lt;/li&gt; 
    &lt;li&gt;It enables the customized and automatic self-organization of agent swarms with self-improvement capabilities.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Various human-designed prompt engineering techniques have been proposed to improve problem solvers based on Large Language Models (LLMs), yielding many disparate code bases. We unify these approaches by describing LLM-based agents as computational graphs. Each node implements a function to process multimodal data or query other LLMs. Each edge describes the information flow between operations and agents. Graphs can be recursively combined into larger composite graphs representing hierarchies of inter-agent collaboration. Our novel automatic graph optimizers (1) refine node-level LLM prompts (node optimization) and (2) improve agent orchestration by changing graph connectivity (edge optimization). Experiments demonstrate that our framework can be used to efficiently develop, integrate, and automatically improve diverse LLM agents.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://gptswarm.org/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/metauto-ai/GPTSwarm"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/MingchenZhuge"&gt;Founder's X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/kreneskyp/ix"&gt;IX&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agents building, debugging, and deploying platform&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/kreneskyp/ix/raw/master/ix_350.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build your own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;IX is a platform for building, debugging, and deploying collaborative Agents and cognitive workflows. -IX is a LangChain-based agent platform that includes all the tools to build and deploy fleets of agents that collaborate to complete tasks. IX is both an editor and a runtime. The editor is a no-code graph style editor for the design of agents, chains, tools, retrieval functions, and collaborative workflows.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Intuitive graph style no-code editor.&lt;/li&gt; 
  &lt;li&gt;Horizontally scaling agent worker fleet.&lt;/li&gt; 
  &lt;li&gt;Multi-user, multi-agent chat interface.&lt;/li&gt; 
  &lt;li&gt;Smart input auto-completes &lt;code&gt;@mentions&lt;/code&gt; and &lt;code&gt;{file}&lt;/code&gt; references.&lt;/li&gt; 
  &lt;li&gt;Supports Chroma and other vector databases for document search.&lt;/li&gt; 
  &lt;li&gt;Supports OpenAI API, Anthropic, PaLM, and LLama based models.&lt;/li&gt; 
  &lt;li&gt;Component library is easily extended.&lt;/li&gt; 
  &lt;li&gt;Powered by LangChain&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=hAJ8ectypas&amp;amp;list=PLR8AMvFecu1hyMHFzaehbfFcMcECMafVs"&gt;Youtube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/jtrMKxzZZQ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/kreneskyp"&gt;Author's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/microsoft/JARVIS"&gt;JARVIS&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;System that connects LLMs with the ML community&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/microsoft/JARVIS/raw/main/hugginggpt/assets/intro.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;JARVIS is a system to connect LLMs with the ML community.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Task Planning: Using ChatGPT to analyze the requests of users to understand their intention, and disassemble them into possible solvable tasks.&lt;/li&gt; 
  &lt;li&gt;Model Selection: To solve the planned tasks, ChatGPT selects expert models hosted on Hugging Face based on their descriptions.&lt;/li&gt; 
  &lt;li&gt;Task Execution: Invokes and executes each selected model, and returns the results to ChatGPT.&lt;/li&gt; 
  &lt;li&gt;Response Generation: Use ChatGPT to integrate the prediction of all models, and generate responses.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2303.17580"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/langroid/langroid"&gt;Langroid&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multi-agent framework for building LLM apps&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/langroid/langroid/raw/main/docs/assets/langroid-card-lambda-ossem-rust-1200-630.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Build your own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;&lt;code&gt;Langroid&lt;/code&gt; is an intuitive, lightweight, extensible and principled Python framework to easily build LLM-powered applications. You set up Agents, equip them with optional components (LLM, vector-store and methods), assign them tasks, and have them collaboratively solve a problem by exchanging messages. This Multi-Agent paradigm is inspired by the &lt;a href="https://en.wikipedia.org/wiki/Actor_model"&gt;Actor Framework&lt;/a&gt; (but you do not need to know anything about this!).&lt;/p&gt; 
 &lt;p&gt;&lt;code&gt;Langroid&lt;/code&gt; is a fresh take on LLM app-development, where considerable thought has gone into simplifying the developer experience; it does not use &lt;code&gt;Langchain&lt;/code&gt;.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Works with most commercial/remote and open/local LLMs.&lt;/li&gt; 
  &lt;li&gt;Set up Multi-agent, multi-LLM system: use stronger LLMs for agents requiring strong reasoning and instruction-following, and delegate simpler tasks to weaker/local LLMs.&lt;/li&gt; 
  &lt;li&gt;Supports OpenAI function-calling as well as native equivalent called &lt;code&gt;ToolMessage&lt;/code&gt;, which works with LLMs that do not have built-in function-calling. Simply specify structure as a (nested) Pydantic object.&lt;/li&gt; 
  &lt;li&gt;Batteries-included: vector-databases for RAG (Retrieval-Augmented Generation), caching, logging/observability.&lt;/li&gt; 
  &lt;li&gt;Specialized agents available: &lt;code&gt;DocChatAgent&lt;/code&gt;, &lt;code&gt;SQLChatAgent&lt;/code&gt;, &lt;code&gt;TableChatAgent&lt;/code&gt; (for tabular data, e.g. csv/dataframes).&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;DocChatAgent&lt;/code&gt; handles text, PDF, Docx files/URLS, and has state-of-the art techniques for retrieval combining lexical and semantic search.&lt;/li&gt; 
  &lt;li&gt;Documentation: &lt;a href="https://langroid.github.io/langroid/"&gt;https://langroid.github.io/langroid/&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/felixbrock/lemon-agent"&gt;Lemon Agent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Plan-Validate-Solve agent for workflow automation&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/media/F3l2kEsXIAA0Gsm?format=jpg&amp;amp;name=large" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Lemon agent is a Plan-Validate-Solve (PVS) Agent for accurate, reliable and reproducable workflow automation&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A standalone supervised Plan and Solve Agent specialized on performing read and write operations on various tools like GitHub, HubSpot or Airtable &lt;em&gt;(ACL 2023 Paper "&lt;a href="https://arxiv.org/abs/2305.04091"&gt;Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models&lt;/a&gt;")&lt;/em&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Separation of tasks and human-in-the-loop interactions&lt;/strong&gt;: Lemon Agent is currently holding a Planner Agent and a Solver Agent to keep the agents focussed and increase accuracy. We are planning on adding additional agents real soon. In addition, Lemon Agent will ask for approval at relevant workflow steps to make sure the intended actions are executed.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Unlimited configuration options&lt;/strong&gt;: Lemon Agent gives you unlimited configuration options (see example here) when defining your workflow. For instance, you can tell Lemon Agent to ask for permission before executing a workflow step or to drop a ğŸ§”â€â™€ï¸ dad joke every time the model executes a workflow step.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;UI flexibility&lt;/strong&gt;: Build any UI on top or engage with Lemon Agent via the built-in CLI.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;[Soon] Model &amp;amp; framework agnostic operations&lt;/strong&gt;: Lemon Agent is a standalone agent, but can easily be integrated into frameworks like LangChain and be used with any model.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Bonus&lt;/strong&gt;: Identify weak spots in your agentâ€™s decision-making capabilities and move to a more deterministic behavior by further configuring your Lemon Agent workflows. &lt;strong&gt;(.html file that can be run without any additional installation)&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/fWU4rDYSxw"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/felixbrockm"&gt;Author's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/mpaepper/llm_agents"&gt;LLM Agents&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Library for building agents, using tools, planning&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;A minimalistic library for building agents that leverage large language models to automate tasks through a loop of commands and tool integrations.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Executing Python code in a REPL environment.&lt;/li&gt; 
  &lt;li&gt;Conducting searches on Google and Hacker News.&lt;/li&gt; 
  &lt;li&gt;Iterating through a cycle of Thought, Action, Observation, and New Thought based on the output of integrated tools.&lt;/li&gt; 
  &lt;li&gt;Dynamically appending new information to the prompt for informed decision-making by the agent.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/mpaepper/llm_agents"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.paepper.com/blog/posts/intelligent-agents-guided-by-llms/"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://llmstack.ai/"&gt;LLM Stack&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;No-code platform to build LLM Agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://llmstack.ai/img/logo-grayscale.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, no-code, web UI&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;LLM Stack is a no-code platform to build LLM Agents, workflows and applications with your data&lt;/li&gt; 
  &lt;li&gt;LLMStack supports all major model providers, like OpenAI, Cohere, Stability AI, Hugging Face, and more. Easily use these models to build powerful apps.&lt;/li&gt; 
  &lt;li&gt;With LLM Stack, you can build generative AI agents like AI SDRs, Research Analysts, RPA Automations etc., without writing any code. Connect agents to your internal or external tools, search the web or browse the internet with agents.&lt;/li&gt; 
  &lt;li&gt;LLMs/model providers supported 
   &lt;ul&gt; 
    &lt;li&gt;OpenAI&lt;/li&gt; 
    &lt;li&gt;Cohere&lt;/li&gt; 
    &lt;li&gt;Stability AI&lt;/li&gt; 
    &lt;li&gt;Hugging Face&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://llmstack.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/trypromptly/LLMStack"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://llmstack.ai/blog"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/PromtEngineer/localGPT"&gt;Local GPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Chat with documents without compromising privacy&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Research, Data analysis, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;LocalGPT is an open-source initiative that allows you to converse with your documents without compromising your privacy. Inspired by privateGPT, allows using your own documents as an information source&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Chat with your documents on your local device using GPT models. No data leaves your device and 100% private&lt;/li&gt; 
  &lt;li&gt;With everything running locally, you can be assured that no data ever leaves your computer&lt;/li&gt; 
  &lt;li&gt;Dive into the world of secure, local document interactions with LocalGPT&lt;/li&gt; 
  &lt;li&gt;Most of the description on readme is inspired by the original privateGPT&lt;/li&gt; 
  &lt;li&gt;Model: Vicuna-7B&lt;/li&gt; 
  &lt;li&gt;Using InstructorEmbeddings&lt;/li&gt; 
  &lt;li&gt;Both Embeddings as well as LLM will run on GPU. It also has CPU support if you do not have a GPU&lt;/li&gt; 
  &lt;li&gt;Built with Langchain&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/PromtEngineer/localGPT"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.reddit.com/r/LocalGPT/"&gt;Subreddit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=MlyoObdIHyo&amp;amp;ab_channel=PromptEngineering"&gt;YouTube - LocalGPT: OFFLINE CHAT FOR YOUR FILES [Installation &amp;amp; Code Walkthrough]&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/farizrahman4u/loopgpt/tree/main"&gt;Loop GPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Re-implementation of AutoGPT as a Python package&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/farizrahman4u/loopgpt/raw/main/docs/assets/imgs/loopgpt_demo_pic.png?raw=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Loop GPT is a re-implementation of the popular Auto-GPT project as a proper python package, written with modularity and extensibility in mind&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Languages: Python&lt;/li&gt; 
  &lt;li&gt;Default model: GPT-3.5-turbo (also possible with GPT-4)&lt;/li&gt; 
  &lt;li&gt;Modular Auto-GPT Framework&lt;/li&gt; 
  &lt;li&gt;Plug N Play" API - Extensible and modular "Pythonic" framework, not just a command line tool&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;"Easy to add new features, integrations and custom agent capabilities, all from python code, no nasty config files!"&lt;/li&gt; 
    &lt;li&gt;"Minimal prompt overhead - Every token counts. We are continuously working on getting the best results with the least possible number of tokens."&lt;/li&gt; 
    &lt;li&gt;"Human in the Loop - Ability to "course correct" agents who go astray via human feedback."&lt;/li&gt; 
    &lt;li&gt;"Full state serialization - can save the complete state of an agent, including memory and the states of its tools to a file or python object. No external databases or vector stores required (but they are still supported)!"&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;!--
### Features
- "Easy to add new features, integrations and custom agent capabilities, all from python code, no nasty config files!"
- "Minimal prompt overhead - Every token counts. We are continuously working on getting the best results with the least possible number of tokens."
- "Human in the Loop - Ability to "course correct" agents who go astray via human feedback."
- "Full state serialization - can save the complete state of an agent, including memory and the states of its tools to a file or python object. No external databases or vector stores required (but they are still supported)!"

--&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/samholt/l2mac"&gt;L2MAC&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent framework able to produce large complex codebases and entire books&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/samholt/L2MAC/master/docs/public/l2mac-icon-white.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Multi-agent, Coding, Build your own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;L2MAC is a multi-agent generation framework that, a single input prompt can generate an extensive unbounded output, such as an entire codebase or an entire book.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;L2MAC can create near unbounded outputs that align exactly with the user input prompt over very long generation tasks&lt;/li&gt; 
  &lt;li&gt;It achieves strong empirical performance of state-of-the-art generation for large codebase tasks and is in the top 3 for the HumanEval coding global benchmark. As L2MAC can detect invalid code and failing unit tests when generating code and automatically error corrects them.&lt;/li&gt; 
  &lt;li&gt;Internally persists a complete file-store memory that enables LLM agents to read files and write to files, creating a large output over many iterations&lt;/li&gt; 
  &lt;li&gt;It can be instructed to follow an exact prompt program&lt;/li&gt; 
  &lt;li&gt;As it generates the output one part at a time, it enables an LLM with a fixed context token limit to be bypassed&lt;/li&gt; 
  &lt;li&gt;The paper, peer-reviewed and recently accepted and published at ICLR 2024, introduces L2MAC.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/samholt/l2mac"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/z27CxnwdhY"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/samianholt"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.02003"&gt;Paper - L2MAC: Large Language Model Automatic Computer for Extensive Code Generation&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://maige.app"&gt;Maige&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Natural-language workflows for your GitHub repo.&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSNrQ3hXkHi0qTI-XThXwx7wA33LcAZZzLp5af6UjY0Vg&amp;amp;s" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Productivity, Debugging, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Maige is a codebase agent that runs when new issues and pull requests come up. Its core features are labelling, assigning, and answering questions.&lt;/li&gt; 
  &lt;li&gt;Maige can search the entire codebase, spin up a sandbox to run scripts, and even write basic code.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://maige.app"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/RubricLab/maige"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=YN-y-iweZTc&amp;amp;ab_channel=TerezaTizkova"&gt;Video - testing Maige&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/building-open-source-codebase-copilot-with-code-execution-layer"&gt;Interview - founder about building Maige&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/rubriclabs"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/tedspare"&gt;Founder's X - Ted Spare&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.magickml.com/"&gt;Magick&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AIDE for creating, deploying, monetizing agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/6507b4af22875d0b8abf95a7/6507bbdc3085cf26d1e8041e_white-wm-tiny.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, SDK for agents, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Magick is an AIDE for creating, deploying, scaling, and monetizing useful AI agents, and prompt chaining.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A full suite, model agnostic AIDE for creating, deploying, scaling, and monetizing useful AI agents, and prompt chaining.&lt;/li&gt; 
  &lt;li&gt;Magick allows to build things like BabyAGI within an hour. You can watch the graph executing in real time, watch the thought process as it executes, and understand the flow.&lt;/li&gt; 
  &lt;li&gt;"Visual development of autonomous agents is incoming. We have built Magick specifically for the rapid development of cognitive architecture and scalable event-driven autonomous agents."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.magickml.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Oneirocom/Magick"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/magickml"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/7Xx5DmbJCe"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/magickml/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/mrmetaverse/"&gt;Founder's LinkedIn - Jesse Alton&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/michaelpsharpe/"&gt;Founder's LinkedIn - Michael Sharpe&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/memfreeme/memfree"&gt;MemFree&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open Source Hybrid AI Search Engine&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/memfreeme/memfree/main/frontend/public/og.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Open Source, AI Search, Build your own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Open Source Hybrid AI Search Engine, Instantly Get Accurate Answers from the Internet, Bookmarks, Notes, and Docs.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;One-Click Chrome Bookmarks Sync and Index&lt;/li&gt; 
  &lt;li&gt;Support multiple traditional search engines as source&lt;/li&gt; 
  &lt;li&gt;Self-hosted Super Fast Serverless Vector Database&lt;/li&gt; 
  &lt;li&gt;Self-hosted Super Fast Local Embedding and Rerank Service&lt;/li&gt; 
  &lt;li&gt;Full Code Open Source&lt;/li&gt; 
  &lt;li&gt;One-Click Deployment On Production&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.memfree.me/docs"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/7QqyMSTaRq"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/ahaapple2023"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.memfree.me"&gt;Website&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/cpacker/MemGPT"&gt;MemGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Memory management system, providing context to LLM&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://files.readme.io/da7f719-small-memgpt_logo_circle_nuno.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Memory management, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A system that intelligently manages different memory tiers in LLMs to effectively provide the extended context within the LLM's limited context window.&lt;/li&gt; 
  &lt;li&gt;Chat with your data - talk to your local files or SQL database&lt;/li&gt; 
  &lt;li&gt;Create perpetual chatbots with self-editing memory&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.08560"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://memgpt.readthedocs.io/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/9GEQrxmVyE"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/MemGPT"&gt;Hugging Face&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/biobootloader/mentat"&gt;Mentat&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Assists you with coding task from command line&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/64bad175c3f1fe8957a06faf/64bef0d57ca34f97c26b2c63_abante-ai-icon_transparent_271.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Mentat is the AI tool that assists you with any coding task, right from your command line. Unlike Copilot, Mentat coordinates edits across multiple locations and files. And unlike ChatGPT, Mentat already has the context of your project - no copy and pasting required!&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.mentat.codes/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=lODjaWclwpY"&gt;Youtube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/bio_bootloader"&gt;Bio Bootloader&lt;/a&gt; (Twitter)&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/zbvd9qx9Pb"&gt;Discord Invite&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/geekan/MetaGPT"&gt;MetaGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent framework returning Design, Tasks, or Repo&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/geekan/MetaGPT/raw/main/docs/resources/MetaGPT-new-log.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Multi-agent, Coding, Build your own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;MetaGPT is a multi-agent framework that, given one line requirement, returns PRD, Design, Tasks, or Repo.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;MetaGPT allows to assign different roles to GPTs to form a collaborative software entity for complex tasks&lt;/li&gt; 
  &lt;li&gt;It takes a one line requirement as input and outputs user stories / competitive analysis / requirements / data structures / APIs / documents, etc.&lt;/li&gt; 
  &lt;li&gt;Internally, MetaGPT includes product managers / architects / project managers / engineers&lt;/li&gt; 
  &lt;li&gt;It provides the entire process of a software company along with carefully orchestrated SOPs. Code = SOP(Team) is the core philosophy&lt;/li&gt; 
  &lt;li&gt;The paper about LLM-based multi-agent work spushes forward the idea of autonomous agents collaborating with each other to do more than one can on its own.&lt;/li&gt; 
  &lt;li&gt;MetaGPT incorporates efficient human workflows as a meta programming approach into LLM-based multi-agent collaboration&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/geekan/MetaGPT"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/4WdszVjv"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/DeepWisdom2019"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2308.00352"&gt;Paper - MetaGPT: Meta Programming for Multi-Agent Collaborative Framework&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/muellerberndt/mini-agi"&gt;Mini AGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;General-purpose agent based on GPT-3.5 / GPT-4&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/muellerberndt/mini-agi/raw/main/static/mini-agi-cover.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;MiniAGI is a minimal general-purpose autonomous agent based on GPT-3.5 / GPT-4&lt;/li&gt; 
  &lt;li&gt;Can analyze stock prices, perform network security tests, create art, and order pizza&lt;/li&gt; 
  &lt;li&gt;MiniAGI is a simple autonomous agent compatible with GPT-3.5-Turbo and GPT-4&lt;/li&gt; 
  &lt;li&gt;It combines a robust prompt with a minimal set of tools, chain-of-thoughts, and short-term memory with summarization&lt;/li&gt; 
  &lt;li&gt;Capable of inner monologue and self-criticism&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/muellerberndt/mini-agi"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/composable-models/llm_multiagent_debate"&gt;Multiagent Debate&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Implementation of a paper on Multiagent Debate&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://composable-models.github.io/llm_debate/img/accuracy_small.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Multiagent Debate is an implementation of the paper "Improving Factuality and Reasoning in Language Models through Multiagent Debate".&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The paper illustrates how we may treat different instances of the same language models as a "multiagent society", where individual language model generate and critique the language generations of other instances of the language model&lt;/li&gt; 
  &lt;li&gt;The authors find that the final answer generated after such a procedure is both more factually accurate and solves reasoning questions more accurately&lt;/li&gt; 
  &lt;li&gt;Illustrating the quantitative difference between multiagent debate and single agent generation on different domains in reasoning and factual validity&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/composable-models/llm_multiagent_debate"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://composable-models.github.io/llm_debate/"&gt;Project page&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2305.14325"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/rumpfmax/Multi-GPT"&gt;Multi GPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Experimental multi-agent system&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An experimental open-source attempt to make GPT-4 fully autonomous&lt;/li&gt; 
  &lt;li&gt;Multiple "expertGPTs" collaborate to perform a task&lt;/li&gt; 
  &lt;li&gt;Each with their own short and long-term memory and the ability to communicate with each other&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Set a task and watch the experts get to work.&lt;/li&gt; 
    &lt;li&gt;Internet access for searches and information gathering&lt;/li&gt; 
    &lt;li&gt;Long-Term and Short-Term memory management&lt;/li&gt; 
    &lt;li&gt;GPT-4 instances for text generation&lt;/li&gt; 
    &lt;li&gt;Access to popular websites and platforms&lt;/li&gt; 
    &lt;li&gt;File storage and summarization with GPT-3.5&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.loom.com/share/b6bec93065794eb8a47e2109697afa39"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Authors: &lt;a href="https://twitter.com/md_rumpf"&gt;Max Rumpf&lt;/a&gt; and &lt;a href="https://twitter.com/SigGravitas"&gt;Significant Gravitas&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/codeintegrity-ai/mutahunter"&gt;MutahunterAI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;MutahunterAI: Accelerate developer productivity and code security with our open-source AI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/152569327?s=48&amp;amp;v=4" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Developer tools, Software security, Multi-agent, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Use Mutahunter to generate unit tests for your codebase, that specifically target the code vulnerabilities. By targeting the exact weaknesses in the code, we boost developer productivity.&lt;/li&gt; 
  &lt;li&gt;Unlike copilots which blindly generates test cases for your code, Mutahunter makes use of our mutation testing engine to generate unit tests that specifically target the vulnerabilities in your code&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Support all major languages.&lt;/li&gt; 
    &lt;li&gt;We can be used locally or can be integrated into any CI/CD runner as part of your existing workflow&lt;/li&gt; 
    &lt;li&gt;You can use Mutahunter with your own LLM APIs for privacy.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/codeintegrity-ai/mutahunter?tab=readme-ov-file#mutahunter"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/9P5V9qmKJn"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/codeintegrity-ai/mutahunter"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/mczhuge/NLSOM"&gt;NLSOM&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Natural Language-Based Societies of Mind&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/mczhuge/NLSOM/raw/main/assets/nlsom.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Science, Multimodal, Social, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Natural Language-Based Societies of Mind - concept with societies and communities of agents&lt;/li&gt; 
  &lt;li&gt;Concept, which contains societies and communities of agents&lt;/li&gt; 
  &lt;li&gt;Agents can be either LLMs, NN-based experts, APIs and role-players. They all communicate in natural language.&lt;/li&gt; 
  &lt;li&gt;To solve tasks, these agents use a collaborative "Mindstorm" process involving mutual interviews.&lt;/li&gt; 
  &lt;li&gt;Additional components for NLSOM can be easily added in a modular way.&lt;/li&gt; 
  &lt;li&gt;"What magical trick makes us intelligent? The trick is that there is no trick. The power of intelligence stems from our vast diversity, not from any single, perfect principle." â€” Marvin Minsky, The Society of Mind, p. 308&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/mczhuge/NLSOM"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2305.17066.pdf"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/SchmidhuberAI"&gt;Author's X - JÃ¼rgen Schmidhuber&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/MingchenZhuge"&gt;Author's X - Mingchen Zhuge&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/xlang-ai/OpenAgents"&gt;OpenAgents&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multi-agent general purpose platform&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/xlang-ai/OpenAgents/raw/main/pics/openagents_overview.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;OpenAgents is an Open Platform for Language Agents in the Wild, ChatGPT Plus Replica for Researchers, Developers, and General Users.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;User-centric 
   &lt;ul&gt; 
    &lt;li&gt;Chat Web UI&lt;/li&gt; 
    &lt;li&gt;Productive Agents&lt;/li&gt; 
    &lt;li&gt;Online Demo&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Fully open-sourced 
   &lt;ul&gt; 
    &lt;li&gt;Full-stack&lt;/li&gt; 
    &lt;li&gt;Easy deployment&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Extensible 
   &lt;ul&gt; 
    &lt;li&gt;LLMs&lt;/li&gt; 
    &lt;li&gt;Tools&lt;/li&gt; 
    &lt;li&gt;Agent methods&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/xlang-ai/OpenAgents"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2310.10634"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://chat.xlang.ai/"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/agiresearch/OpenAGI"&gt;OpenAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;R&amp;amp;D agents platform&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/agiresearch/OpenAGI/raw/main/images/illustration.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;OpenAGI is an open-source AGI R&amp;amp;D platform that enables agents for both benchmark tasks and open-ended tasks&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Powered by various language models such as GPT-4, Vicuna, LLaMA, and Flan-T5&lt;/li&gt; 
  &lt;li&gt;Supports multi-modality tool learning and task solving such as text, image, video and audio&lt;/li&gt; 
  &lt;li&gt;Supports task decomposition into both linear task-solving plans and non-linear task-solving plans&lt;/li&gt; 
  &lt;li&gt;Allows both benchmark task solving and open-ended task solving&lt;/li&gt; 
  &lt;li&gt;Provides easy-to-use evaluation protocols to evaluate task-solving ability&lt;/li&gt; 
  &lt;li&gt;Provide Reinforcement Learning from Task Feedback (RLTF) to allow continuously self-improving agent&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/agiresearch/OpenAGI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2304.04370"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=7RaXPPXi0-Y"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/OpenDevin/OpenDevin"&gt;OpenDevin&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;OpenDevin: Code Less, Make More&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/OpenDevin/OpenDevin/raw/main/logo.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, general purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The OpenDevin project is born out of a desire to replicate, enhance, and innovate beyond the original Devin model.&lt;/li&gt; 
  &lt;li&gt;By engaging the open-source community, we aim to tackle the challenges faced by Code LLMs in practical scenarios, producing works that significantly contribute to the community and pave the way for future advancements.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/OpenDevin/OpenDevin"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://openinterpreter.com/"&gt;Open Interpreter&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Code interpreter that lets LLMs execute code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://openinterpreter.com/assets/ncu_thumbnail.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Open Interpreter is an open-source interpreter that lets LLMs run code on your computer to complete tasks&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Runs locally&lt;/li&gt; 
  &lt;li&gt;Can for example summarize PDFs, visualize datasets, control your browser&lt;/li&gt; 
  &lt;li&gt;Works from a ChatGPT-like interface in your terminal.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://openinterpreter.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/KillianLucas/open-interpreter"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/hellokillian"&gt;Author's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.pezzo.ai/"&gt;Pezzo&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Development toolkit for prompt management &amp;amp; more&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.pezzo.ai/_next/static/media/Logo.b7e3878b.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Pezzo is a development toolkit designed to streamline prompt design, version management, publishing, collaboration, troubleshooting, observability and more&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Whether you are a technical person or a stakeholder, you can use Pezzo effectively. We don't believe that AI prompts should be designed in a developer's code editor. Aside from the technical issues with this approach, it blocks productivity."&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Centralized Prompt Management: Manage all AI prompts in one place for maximum visibility and efficiency.&lt;/li&gt; 
    &lt;li&gt;Streamlined Prompt Design, Publishing &amp;amp; Versioning: Create, edit, test and publish prompts with ease.&lt;/li&gt; 
    &lt;li&gt;Observability: Access detailed prompt execution history, stats and metrics (duration, prompt cost, completion cost, etc.) for better insights.&lt;/li&gt; 
    &lt;li&gt;Troubleshooting: Effortlessly resolve issues with your prompts. Time travel to retroactively fine-tune failed prompts and commit the fix instantly.&lt;/li&gt; 
    &lt;li&gt;Cost Transparency: Gain comprehensive cost transparency across all prompts and AI models.&lt;/li&gt; 
    &lt;li&gt;Simplified Integration: Reduce code overhead by 90% by consuming your AI prompts using the Pezzo Client, regardless of the model provider.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.pezzo.ai/docs/intro.html"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/pezzolabs/pezzo"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.privategpt.io/"&gt;Private GPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Tool for private interaction with your documents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/6408872e49e0944a088f17c1/640f3c6e8640895f2cbf95ba_logo%20full.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Research, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Private GPT is A tool for private interaction with documents, without a need for internet connection&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Built with LangChain, GPT4All, LlamaCpp, Chroma and SentenceTransformers&lt;/li&gt; 
  &lt;li&gt;A test project to validate the feasibility of a fully private solution for question answering using LLMs and Vector embeddings, not production ready&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/imartinez/privateGPT"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/topoteretes/PromethAI-Backend"&gt;PromethAI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent that helps with nutrition and other goals&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/125468716?s=280&amp;amp;v=4" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Personalized AI assistant that decomposes problems, offers solutions, and lets you use Agent actions to automate your flows"&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Helps users reach a solution by decomposing their requests into categories with a set of options (cuisine -&amp;gt; European)&lt;/li&gt; 
    &lt;li&gt;Has a dynamic UX/UI that helps avoid prompting&lt;/li&gt; 
    &lt;li&gt;Voice input supported&lt;/li&gt; 
    &lt;li&gt;Provides users with results of their queries and automates actions around them&lt;/li&gt; 
    &lt;li&gt;Remembers your past preferences and uses them to optimize your choices&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Tech 
   &lt;ul&gt; 
    &lt;li&gt;Powered by Langchain, decomposable async prompts + vector DB + Redis cache&lt;/li&gt; 
    &lt;li&gt;App built with Flutter + Dart 
     &lt;ul&gt; 
      &lt;li&gt;Connected to Zapier NLP&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/topoteretes/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://prometh.ai"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/tricalt"&gt;Vasilije M&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://reactagent.io/"&gt;React Agent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open-source React.js Autonomous LLM Agent&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://reactagent.io/logo-dark.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h2&gt;Description&lt;/h2&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An experimental autonomous agent&lt;/li&gt; 
  &lt;li&gt;Model: GPT-4&lt;/li&gt; 
  &lt;li&gt;Purpose: Gnerate and compose React components from user stories&lt;/li&gt; 
  &lt;li&gt;Stack 
   &lt;ul&gt; 
    &lt;li&gt;React&lt;/li&gt; 
    &lt;li&gt;TailwindCSS&lt;/li&gt; 
    &lt;li&gt;Typescript&lt;/li&gt; 
    &lt;li&gt;Radix UI&lt;/li&gt; 
    &lt;li&gt;Shandcn UI&lt;/li&gt; 
    &lt;li&gt;OpenAI API&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;The agent is taking a user story text and generating and composing multiple react components to generate the relevant screens, based on atomic design principles&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Generate React Components from user stories&lt;/li&gt; 
    &lt;li&gt;Compose React Components from existing components&lt;/li&gt; 
    &lt;li&gt;Use a local design system to generate React Components&lt;/li&gt; 
    &lt;li&gt;Use React, TailwindCSS, Typescript, Radix UI, Shandcn UI&lt;/li&gt; 
    &lt;li&gt;Built with Atomic Design Principles&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;It is still experimental but very interesting results, It is completely open-sourced, looking for contributors!&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h2&gt;Links&lt;/h2&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/eylonmiz/react-agent"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.reactagent.io/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Authors: &lt;a href="https://twitter.com/EylonMiz"&gt;Eylon Miz and&lt;/a&gt; and &lt;a href="https://twitter.com/LeeTwito"&gt;Lee Twito&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.hyperwriteai.com/self-operating-computer"&gt;Self-operating computer&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Let multimodal models operate a computer&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/63fcd79d410b22ddf397e1b8/654272554402410a71c84ab9_6405c1cabdf9c69f05b1080e_otherside_logo_symbol.webp" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Research&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Using the same inputs and outputs as a human operator, the model views the screen and decides on a series of mouse and keyboard actions to reach an objective.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.hyperwriteai.com/self-operating-computer"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/OthersideAI/self-operating-computer"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/smol-ai/developer"&gt;Smol developer&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Your own junior AI developer, deployed via E2B UI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://smol.ai/logo.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Smol is your own junior developer. &lt;a href="https://app.e2b.dev/agent/smol-developer/?utm_source=awesome-ai-agents"&gt;Deployed in few seconds via e2b&lt;/a&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Human-centric, coherent whole program synthesis&lt;/li&gt; 
  &lt;li&gt;Your own junior developer&lt;/li&gt; 
  &lt;li&gt;Allows to develop, debug, and decompile&lt;/li&gt; 
  &lt;li&gt;200 LOC, half english&lt;/li&gt; 
  &lt;li&gt;100k context can summarize both content and codebases&lt;/li&gt; 
  &lt;li&gt;Markdown is the best prompting DSL&lt;/li&gt; 
  &lt;li&gt;Copy and paste your errors as prompts&lt;/li&gt; 
  &lt;li&gt;Copy and paste curl output as prompts&lt;/li&gt; 
  &lt;li&gt;Write CSS animation by describing what u want&lt;/li&gt; 
  &lt;li&gt;GPT4 &amp;gt;&amp;gt;&amp;gt; GPT3.5/Anthropic Claude for codegen&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/swyx"&gt;Swyx&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=UCo7YeTy-aE"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/SmolModels"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://smol.ai/"&gt;Meme&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/stackwiseai/stackwise"&gt;Stackwise&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;VSCode extension that writes nodejs functions&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1723911660232945664/CtumfUuB_400x400.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Tool for agents, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Stackwise is a VS Code extension that writes and imports nodejs functions so that you can write code without context switching&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The open source function collection&lt;/li&gt; 
  &lt;li&gt;Explain what you want a function to do, and AI builds it.&lt;/li&gt; 
  &lt;li&gt;Stackwise is a VS Code extension that automatically writes and imports nodejs functions so that you can write code without context switching. No more hunting for documentation to integrate with APIs or back and forth with ChatGPT. Just pure functionality within your code!&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/stackwiseai/stackwise"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/stackwiseai"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/merwanehamadi"&gt;Founder's X - Wayne&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/silennai"&gt;Founder's X - Silen Naihin&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.superagent.sh/"&gt;Superagent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Tool that allows creating agents without coding&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://api.typedream.com/v0/document/public/b9d688ba-8f34-40e4-a24a-c62b403b402d/2YukgQsvbVkUp7u1HLsrBKCjfrO_superagent_logo_candidate_2_invisible_background_small.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, General purpose, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Superagent is not a single agent, but a tool that allows creating agents without coding&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Simplifies the configuration and deployment of LLM Agents to production&lt;/li&gt; 
  &lt;li&gt;"One of the core principals of SuperAgent is to build with any third-party dependencies to proprietary tech"&lt;/li&gt; 
  &lt;li&gt;It provides a range of features and functionalities to make it easier for developers to build, manage and deploy AI agents to production including features such as built in memory and document retrieval via vector dbs, powerful tools, webhooks, cron jobs etc.&lt;/li&gt; 
  &lt;li&gt;There are two main types of agents: action agents and plan-and-execute agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/homanp/superagent"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.superagent.sh/introduction"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/mhmJUTjW4b"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/pelaseyed"&gt;Ismail Pelaseyed&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/discussing-agents-challenges-with-ismail-pelaseyed-the-founder-of-superagent"&gt;Interview: Discussing agents' tracing, observability, and debugging with Ismail Pelaseyed, the founder of Superagent&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/ai-agents-in-2024"&gt;Blog post: What Ismail from Superagent and other developers predict for the future of AI Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://superagi.com/"&gt;SuperAGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Framework to develop and deploy AI agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1678659510041456640/rxUIfulT_400x400.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;SuperAGI is an open-source autonomous AI framework to enable development and deployment autonomous agents&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An AI agent framework&lt;/li&gt; 
  &lt;li&gt;Open source, but infrastructure is -source&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Provision, Spawn &amp;amp; Deploy Autonomous AI Agents&lt;/li&gt; 
    &lt;li&gt;Extend Agent Capabilities with Tools&lt;/li&gt; 
    &lt;li&gt;Run Concurrent Agents Seamlessly&lt;/li&gt; 
    &lt;li&gt;Graphical User Interface&lt;/li&gt; 
    &lt;li&gt;Action Console&lt;/li&gt; 
    &lt;li&gt;Multiple Vector DBs&lt;/li&gt; 
    &lt;li&gt;Multi-Modal Agents&lt;/li&gt; 
    &lt;li&gt;Agent Trajectory Fine-Tuning&lt;/li&gt; 
    &lt;li&gt;Performance Telemetry&lt;/li&gt; 
    &lt;li&gt;Optimized Token Usage&lt;/li&gt; 
    &lt;li&gt;Agent Memory Storage&lt;/li&gt; 
    &lt;li&gt;Looping Detection Heuristics&lt;/li&gt; 
    &lt;li&gt;Concurrent Agents&lt;/li&gt; 
    &lt;li&gt;Resource Manager&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@_superagi"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/dXbRe5BHJC"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.reddit.com/r/Super_AGI/"&gt;Subreddit&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/_superAGI"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/ishaanbhola"&gt;Ishaan Bhola&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/CR-Gjx/Suspicion-Agent"&gt;Suspicion Agent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Paper on imperfect information games&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/CR-Gjx/Suspicion-Agent/raw/main/figures/counterfactual.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Playing Imperfect Information Games with Theory of Mind Aware GPT-4&lt;/li&gt; 
  &lt;li&gt;The paper delves into the applicability of GPT-4's learned knowledge for imperfect information games&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/CR-Gjx/Suspicion-Agent"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2309.17277"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/spaces/cr7-gjx/Suspicion-Agent-Demo"&gt;Project demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://huggingface.co/spaces/cr7-gjx/Suspicion-Agent-Data-Visualization"&gt;Game data replay&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/princeton-nlp/SWE-agent"&gt;SWE Agent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Open-source Devin alternative&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/princeton-nlp/SWE-agent/raw/main/assets/swe-agent-banner.png" alt="Image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, general purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;This Devin alternative scores 12.3% on the FULL swe benchmark&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/danielhanchen/status/1775120334305607781"&gt;"An open source Devin getting 12.29% on 100% of the SWE Bench test set vs Devin's 13.84% on 25% of the test set!"&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;SWE-agent works by interacting with a specialized terminal, which allows it to: 
   &lt;ul&gt; 
    &lt;li&gt;ğŸ” Open, scroll and search through files&lt;/li&gt; 
    &lt;li&gt;âœï¸ Edit specific lines w/ automatic syntax check&lt;/li&gt; 
    &lt;li&gt;ğŸ§ª Write and execute tests&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;This custom-built interface is critical for good performance. Simply connecting an LM to a vanilla bash terminal does not work well.&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/jyangballin/status/1775114448513958134"&gt;"Our key insight is that LMs require carefully designed agent-computer interfaces (similar to how humans like good UI design). E.g. When the LM messes up indentation, our editor prevents it and gives feedback."&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;SWE-agent was released by the Princeton NLP team.&lt;/li&gt; 
  &lt;li&gt;What makes SWE-agent special is that it performs almost as well as Devin on the SWE-bench.&lt;/li&gt; 
  &lt;li&gt;It is important to say that the performance &lt;a href="https://www.swebench.com/"&gt;varies&lt;/a&gt; based on the model used by the agent.&lt;/li&gt; 
  &lt;li&gt;The changes and innovations in SWE-agent compared to Devin are: 
   &lt;ul&gt; 
    &lt;li&gt;The code in SWE Agent is executed locally via Docker.&lt;/li&gt; 
    &lt;li&gt;It uses â€œAgent-Computer Interfaceâ€ (ACI) - constraining the interface makes the agent easier to use for LMs. Only a few commants are allowed: run code, look for code, edit code and submit changes to GitHub.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Any code the agent writes goes through a syntax check (linter) before being submitted. If the syntax is incorrect, the agent gets feedback and is forced to redo the code.&lt;/li&gt; 
  &lt;li&gt;The agent can only read 100 lines of code at a time, rather than the entire file. This makes it easier for the language model to understand the code.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/princeton-nlp/SWE-agent"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://swe-agent.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://swe-agent.com/demo"&gt;Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/AVEFbBn2rH"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://sweep.dev/"&gt;Sweep&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Github assistant that fixes issues &amp;amp; writes code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/127925974?s=200&amp;amp;v=4" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Sweep is a Github assistant the helps fix small bugs and implement small features&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;To install, click the install button&lt;/li&gt; 
  &lt;li&gt;Then add the repository you want, make a quick ticket (e.g. writing tests)&lt;/li&gt; 
  &lt;li&gt;Prepend the ticket with "Sweep:" and let Sweep handle the rest&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/sweepai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/sweep-ai"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/sweep-founders-share-learnings-from-building-an-ai-coding-assistant"&gt;Interview: Sweep founders share learnings from building an AI coding assistant&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://sweep-ai.notion.site/Tricks-for-prompting-Sweep-3124d090f42e42a6a53618eaa88cdbf1"&gt;Tricks for prompting Sweep&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/TaxyAI/browser-extension"&gt;Taxy AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Taxy AI is a full browser automation&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/TaxyAI/browser-extension/raw/main/src/assets/img/icon-128.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Taxy uses GPT-4 to control your browser and perform repetitive actions on your behalf&lt;/li&gt; 
  &lt;li&gt;Currently it allows you to define ad-hoc instructions&lt;/li&gt; 
  &lt;li&gt;In the future it will also support saved and scheduled workflows&lt;/li&gt; 
  &lt;li&gt;Currently in an early stage with a waitlist&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/TaxyAI/browser-extension"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.google.com/forms/d/e/1FAIpQLScAFKI1fZ1cXhBmSp2HM93Jvuc8Jvrxh5iSbkKhtwKN-OHoTQ/viewform"&gt;Waitlist&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/seanpixel/Teenage-AGI/raw/main/README.md#experiments"&gt;Teenage AGI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;BabyAGI-inspired agent, can recall infinite memory&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;A BabyAGI-inspired agent that can recall infinite memory, "thinks" before making action, and doesn't lose memory after being shutting down&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Model: GPT-4&lt;/li&gt; 
  &lt;li&gt;Language: Python&lt;/li&gt; 
  &lt;li&gt;Uses OpenAI and Pinecone to give memory to an AI agent and also allows it to "think" before making an action (outputting text)&lt;/li&gt; 
  &lt;li&gt;Also, just by shutting down the AI, it doesn't forget its memories since it lives on Pinecone and its memory counter saves the index that it's on&lt;/li&gt; 
  &lt;li&gt;A process that happens every time the AI is queried by the user: 
   &lt;ul&gt; 
    &lt;li&gt;AI vectorizes the query and stores it in a Pinecone Vector Database&lt;/li&gt; 
    &lt;li&gt;AI looks inside its memory and finds memories and past queries that are relevant to the current query&lt;/li&gt; 
    &lt;li&gt;AI thinks about what action to take&lt;/li&gt; 
    &lt;li&gt;AI stores the thought from Step 3&lt;/li&gt; 
    &lt;li&gt;Based on the thought from Step 3 and relevant memories from Step 2, AI generates an output&lt;/li&gt; 
    &lt;li&gt;AI stores the current query and its answer in its Pinecone vector database memory&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Created by &lt;a href="https://twitter.com/sean_pixel"&gt;@sean_pixel&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Inspired by paper &lt;a href="https://arxiv.org/abs/2304.03442"&gt;"Generative Agents: Interactive Simulacra of Human Behavior"&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/microsoft/UFO"&gt;UFO&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A UI-Focused agent on Windows OS&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.com/microsoft/UFO/raw/main/assets/ufo_blue.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Multi-agent, GUI Agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Agent by Microsoft&lt;/li&gt; 
  &lt;li&gt;UFO is a UI-Focused dual-agent framework to fulfill user requests on Windows OS by seamlessly navigating and operating within individual or spanning multiple applications.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/microsoft/UFO"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href=""&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2402.07939"&gt;Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://vanna.ai/"&gt;Vanna.AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Python-based AI SQL agent trained on your schema&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://vanna.ai/img/vanna.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Debugging, Code migration, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Vanna is an Open-Source Python-based AI SQL agent trained on your schema that writes complex SQL in seconds&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI-driven business intelligence assistant&lt;/li&gt; 
  &lt;li&gt;Vanna helps you generate and run accurate SQL for your database using LLMs via Retrieval-Augmented Generation&lt;/li&gt; 
  &lt;li&gt;Vanna works in two easy steps - train a RAG "model" on your data, and then ask questions which will return SQL queries that can be set up to automatically run on your database&lt;/li&gt; 
  &lt;li&gt;The Vanna Python package and the various frontend integrations are all open-source&lt;/li&gt; 
  &lt;li&gt;Vannaâ€™s capabilities are tied to the training data you give it. More training data means better accuracy for large and complex datasets&lt;/li&gt; 
  &lt;li&gt;Your database contents are never sent to the LLM. The metadata storage layer only sees schemas, documentation, and queries&lt;/li&gt; 
  &lt;li&gt;As you use Vanna more, your model continuously improves as we augment your training data&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://vanna.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/vanna-ai/vanna"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/qUZYKHremx"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/vanna-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://vanna.ai/docs/"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://voyager.minedojo.org/"&gt;Voyager&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;LLM-powered lifelong learning agent in Minecraft&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://voyager.minedojo.org/assets/images/exploration_performance.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention&lt;/li&gt; 
  &lt;li&gt;Voyager consists of three key components: 
   &lt;ul&gt; 
    &lt;li&gt; 
     &lt;ol&gt; 
      &lt;li&gt;an automatic curriculum that maximizes exploration&lt;/li&gt; 
     &lt;/ol&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;ol start="2"&gt; 
      &lt;li&gt;an ever-growing skill library of executable code for storing and retrieving complex behaviors&lt;/li&gt; 
     &lt;/ol&gt; &lt;/li&gt; 
    &lt;li&gt; 
     &lt;ol start="3"&gt; 
      &lt;li&gt;a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement&lt;/li&gt; 
     &lt;/ol&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/MineDojo/Voyager"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2305.16291"&gt;Paper - Voyager: An Open-Ended Embodied Agent with Large Language Models&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=uTg39rNMojo"&gt;YouTube video&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/DrJimFan/status/1662115266933972993"&gt;Tweet&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://w3gpt.ai/"&gt;Web3 GPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Write &amp;amp; deploy smart contracts to EVM blockchains&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1701486001120567296/u84M3Ruo_400x400.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Blockchain, Coding, Generating apps, Smart contract&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Write and deploy smart contracts to EVM blockchains.&lt;/li&gt; 
  &lt;li&gt;Connect wallet to manually deploy contracts, even from you old chats.&lt;/li&gt; 
  &lt;li&gt;Enable Web2/3 users to interact with blockchains without a dedicated web3 wallet using account abstraction and a gas master account.&lt;/li&gt; 
  &lt;li&gt;Leverage Chat-GPT to interact with and control Web3-GPT functionalities.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://w3gpt.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/markeljan/web3gpt?tab=readme-ov-file"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/0xmarkeljan"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/markeljan/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://theolvs.github.io/westworld/"&gt;â€œWestworldâ€ simulation&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A multi-agent environment simulation library&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://theolvs.github.io/westworld/img/cover_hq_westworld1.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;A- multi-agent simulation library, with a goal to simulate and optimize systems and environments with multiple agents interacting&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Researchers from Stanford and Google created an interactive sandbox env with 25 Gen AI agents can simulate human behavior&lt;/li&gt; 
  &lt;li&gt;They walk in the park, join for coffee at a cafe, and share news with colleagues. They demonstrated surprisingly good social&lt;/li&gt; 
  &lt;li&gt;Westworld's inspiration is drawn from Unity software and Unity ML Agents, adapted in Python&lt;/li&gt; 
  &lt;li&gt;Languages 
   &lt;ul&gt; 
    &lt;li&gt;The library is available on PyPi via pip install westworld&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://github.com/TheoLvs/westworldjs"&gt;Javascript version (being developed)&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Easy creation of Grid and non-grid environments&lt;/li&gt; 
    &lt;li&gt;Objects (Agents, Obstacles, Collectibles, Triggers)&lt;/li&gt; 
    &lt;li&gt;Subclassing of different objects to create custom objects&lt;/li&gt; 
    &lt;li&gt;Spawner to generate objects randomly in the environment&lt;/li&gt; 
    &lt;li&gt;Basic rigid body system for all objects&lt;/li&gt; 
    &lt;li&gt;Simple agent behaviors (pathfinding, wandering, random walk, fleeing, vision range)&lt;/li&gt; 
    &lt;li&gt;Automatic maze generation&lt;/li&gt; 
    &lt;li&gt;Layer integration to convert image to obstacle and snap it to a grid&lt;/li&gt; 
    &lt;li&gt;Sample simulations and sample agents for classic simulations&lt;/li&gt; 
    &lt;li&gt;Simulation visualization, replay and export (gif or video)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/TheoLvs/westworld"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://theolvs.github.io/westworld/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2304.03442"&gt;Underlying paper - Generative Agents&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;A paper simulating interactions between tens of agents&lt;/li&gt; 
  &lt;li&gt;Presenting an architecture that extends a language model to store and synthesize the agent's experiences, enabling dynamic behavior planning in an interactive sandbox environment with generative agents&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/team-openpm/workgpt"&gt;WorkGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;GPT agent framework for invoking APIs&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/card_img/1744902310336118784/AVnD3MC-?format=jpg&amp;amp;name=medium" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;WorkGPT is an agent framework in a similar fashion to AutoGPT or LangChain. You give it a directive and an array of APIs and it will converse back and forth with the AI until its directive is complete.&lt;/li&gt; 
  &lt;li&gt;For example, a directive could be to research the web for something, to crawl a website, or to order you an Uber. We support any and all APIs that can be represented with an OpenAPI file.&lt;/li&gt; 
  &lt;li&gt;WorkGPT now has OpenAI's new function invocation feature baked into it 
   &lt;ul&gt; 
    &lt;li&gt;While chaining together APIs was possible before (see AutoGPT), it was slow, expensive, and error prone&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://twitter.com/maccaw/status/1669367224694607875"&gt;The tweet announcing this feature&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/maccaw"&gt;Alex MacCaw&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.getwren.ai/"&gt;Wren&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Natural Language Interface to Your Databases&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://cdn.prod.website-files.com/65e9b9dd95692faa9f5bb1c0/65f99924ac1b1f225c356d74_logo.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;"WrenAI is an AI-powered data assistant designed to help you retrieve results and insights quickly and effortlessly, without the need for SQL coding. It's also open-source, which means you can customize and use it to suit your specific needs.&lt;/p&gt; 
 &lt;p&gt;There are four key principles that we followed when developing WrenAI:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Explainability: We made sure that every SQL query generated by WrenAI is accurate, concise, and reliable, so you can trust the results it provides.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Interoperability: WrenAI lets you query data from multiple sources, regardless of different data formats and dialects. You can enjoy a standard interface across various sources, saving you time and hassle.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Interactive Experience: Our AI-powered assistant engages users in a dialogue, helping to clarify their queries, and refine results in real-time. You can interact with WrenAI in a natural and intuitive way.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Continuous Learning: WrenAI continually learns from its interactions with users, feedback, and query history. It incorporates new patterns, information, and data structures into its LLM knowledge base, ensuring that it gets better and more accurate over time."&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.getwren.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Canner/WrenAI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/getwrenai"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.getwren.ai/overview/introduction"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://blog.getwren.ai/"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/OpenBMB/XAgent"&gt;XAgent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Experimental LLM agent that solves various tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_banners/1713881934991093760/1697456782/1500x500" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;XAgent is an open-source experimental Large Language Model (LLM) driven autonomous agent that can automatically solve various tasks&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Emergence &amp;amp; Autonomy&lt;/strong&gt;: XAgent's autonomous operations transcend biases.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Safety &amp;amp; Operation&lt;/strong&gt;: Secure execution within docker environments.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Expert-Knowledge Free&lt;/strong&gt;: Effective operation without sole expert reliance.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Interface &amp;amp; Interaction&lt;/strong&gt;: Interact via a user-friendly GUI or command line, while it adapts and collaborates.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Dual-loop Mechanism&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Outer-Loop&lt;/strong&gt;: Manages plans and task refinements.&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Inner-Loop&lt;/strong&gt;: Dispatch, ReACT-based execution, feedback.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Universal Language - Function Calling&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;ToolAgent &amp;amp; ReACT&lt;/strong&gt;: Optimal action series for subtasks.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Tools&lt;/strong&gt;: 
   &lt;ul&gt; 
    &lt;li&gt;ğŸ“ File Editor&lt;/li&gt; 
    &lt;li&gt;ğŸ“˜ Python Notebook&lt;/li&gt; 
    &lt;li&gt;ğŸŒ Web Browser&lt;/li&gt; 
    &lt;li&gt;ğŸ–¥ï¸ Shell&lt;/li&gt; 
    &lt;li&gt;ğŸ§© Rapid API&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/XAgentTeam"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/OpenBMB/XAgent"&gt;GitHub Repository&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/zncs5aQkWZ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=QGkpd-tsFPA"&gt;Youtube Demo&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/yeagerai/yeagerai-agent"&gt;yAgents&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Capable of designing, coding and debugging tools&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;yAgents is an Agent-Builder Agent made by Yeager.ai capable of designing, coding and debugging its own tools.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Designed to help build, prototype, and deploy AI-powered tools and agents easily and efficiently.&lt;/li&gt; 
  &lt;li&gt;Built on the LangChain framework, allowing users of any technical background to create, improve, and deploy AI agents.&lt;/li&gt; 
  &lt;li&gt;Equipped with an interactive command line interface for real-time feedback and ease of navigation.&lt;/li&gt; 
  &lt;li&gt;Features session persistent memory to ensure data preservation across multiple sessions&lt;/li&gt; 
  &lt;li&gt;Quick and easy installation via pip.&lt;/li&gt; 
  &lt;li&gt;Contributions to expand and improve yAgents are highly encouraged.&lt;/li&gt; 
  &lt;li&gt;Warnings 
   &lt;ul&gt; 
    &lt;li&gt;Requires GPT-4 API access.&lt;/li&gt; 
    &lt;li&gt;Not tested for Windows systems&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yeagerai/yeagerai-agent/?utm_source=awesome-ai-agents"&gt;GitHub Repository&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/wKds24jdAX/?utm_source=awesome-ai-agents"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/yeagerai/yeagerai-agent/raw/main/LICENSE/?utm_source=awesome-ai-agents"&gt;License: MIT&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/pj4533/yourgoal/?utm_source=awesome-ai-agents"&gt;Yourgoal&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Swift implementation of BabyAGI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"This is a Swift port of BabyAGI, an example of an AI-powered task management system that uses OpenAI and Pinecone APIs to create, prioritize, and execute tasks. The main idea behind this system is that it creates tasks based on the result of previous tasks and a predefined objective."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/pj4533/?utm_source=awesome-ai-agents"&gt;PJ Gray&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;Closed-source projects and companies&lt;/h1&gt; 
&lt;h2&gt;&lt;a href="https://ability.ai/"&gt;Ability AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Secure, People-Centric Autonomous AI Agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://ability.ai/assets/images/image01.svg?v=e0c18927" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Empowering Businesses with Secure, People-Centric Autonomous AI Agents&lt;/li&gt; 
  &lt;li&gt;Still in early version&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://ability.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.adept.ai/?utm_source=awesome-ai-agents"&gt;Adept AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;ML research and product lab building intelligence&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/C4E0BAQHoZ-QBmwsa0g/company-logo_200_200/0/1677107534930/adeptailabs_logo?e=1713398400&amp;amp;v=beta&amp;amp;t=ykMLRWaek147bz9BpCaLCuYFrVorWWT3iaDsrWQa6Do" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A ML research and product lab building general intelligence by enabling humans and computers to work together creatively&lt;/li&gt; 
  &lt;li&gt;An AI teammate for everyone&lt;/li&gt; 
  &lt;li&gt;"Adept is building an entirely new way to get things done. It takes your goals, in plain language, and turns them into actions on the software you use every day."&lt;/li&gt; 
  &lt;li&gt;In early stage&lt;/li&gt; 
  &lt;li&gt;"Weâ€™re building a machine learning model that can interact with everything on your computer."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.adept.ai/?utm_source=awesome-ai-agents"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/adeptai/?utm_source=awesome-ai-agents"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.agents.inc/"&gt;AGENTS.inc&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agents for company/regulations, search&amp;amp;monitoring&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.agents.inc/wp-content/uploads/2023/08/AGENTS.inc-logo.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Science, Monitoring, General purpose, Business intelligence, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI agents for specific tasks: 
   &lt;ul&gt; 
    &lt;li&gt;Global News Radar AI Agent&lt;/li&gt; 
    &lt;li&gt;Company Identification AI Agent&lt;/li&gt; 
    &lt;li&gt;EU Policy Watch AI Agent&lt;/li&gt; 
    &lt;li&gt;Report AI Agent&lt;/li&gt; 
    &lt;li&gt;Scientific Knowledge Agent&lt;/li&gt; 
    &lt;li&gt;Patent Analysis Agent&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.agents.inc/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/agentsdotinc"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/agentsdotinc/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/c/agentsdotinc"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.facebook.com/agentsdotinc"&gt;Facebook&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/agentsinc"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://agentscale.ai/"&gt;AgentScale&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Your assistant, email writer, calendar scheduler&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/64e879914c784ca827df6d6d/6594ec15997b8276945f35a6_logo_side_white_cropped-p-500.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;AgentScale is your very own personal assistant, email writer, calendar scheduler, and internet surfer&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AgentScale is your very own AI personal assistant&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://agentscale.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/agentscale"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/agentscale-ai/about/"&gt;LInkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder's web: &lt;a href="https://jetnew.io/"&gt;Jet New&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://codestory.ai/"&gt;Aide by Codestory&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI code interpreter, AI-powered mod of VSCode&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/135339264?s=200&amp;amp;v=4" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Still in early stage, new features coming soon&lt;/li&gt; 
  &lt;li&gt;Now available for JS/TS&lt;/li&gt; 
  &lt;li&gt;Can the codebase, identify the root cause, make the fix and auto-generate tests to evaluate whether the bug was resolved&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://codestory.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.codestory.ai/"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/DNnh6tC9VA"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/codestoryai"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/codestory-ai/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://ailaflow.com"&gt;AilaFlow&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;No-code platform for building AI agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://yt3.googleusercontent.com/TkDmYBaXRvIegqkJoujtXpIlK9X5dMAjiDldAlqSHAUaekbvbYXlOaZq1DsV8neqBUZqlWAc5w=s900-c-k-c0x00ffffff-no-rj" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AilaFlow is no-code platform for building AI agents&lt;/li&gt; 
  &lt;li&gt;Use a template, adjust it using no-code editor to your needs&lt;/li&gt; 
  &lt;li&gt;Category: Productivity, Framework for building agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://ailaflow.com"&gt;AilaFlow - AI Agents No-code Platform&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder's X account: &lt;a href="https://twitter.com/b4rtaz"&gt;b4rtaz&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.airkit.ai"&gt;Airkit.ai&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Platform for building, testing, deploying Agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://airkit.ai/_gatsby/image/4d7db4337bbde82f2bf7ffb0e5046c81/a46b36f8203bc3f33cb41b43956d7bd2/IMG_1847.avif?u=https%3A%2F%2Flive-airkit-ai.pantheonsite.io%2Fapp%2Fuploads%2F2023%2F11%2FIMG_1847.png&amp;amp;a=w%3D480%26h%3D174%26fm%3Davif%26q%3D100&amp;amp;cd=c7e6c2e0828656c0553ba410f22d3684" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A browser based studio for managing prompts, building tools, and testing your agents.&lt;/li&gt; 
  &lt;li&gt;Built in short-term and long-term memory management&lt;/li&gt; 
  &lt;li&gt;1 click deployment. Embed anywhere with our Web SDK.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.airkit.ai"&gt;Profile of the company&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/AirkitAI"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.airplane.dev/autopilot/?utm_source=awesome-ai-agents/"&gt;Airplane Autopilot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Autopilot AI assistant of the Airplane company&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.airplane.dev/autopilot/hero/autopilot-logo.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A developer-centric approach to building internal UIs and workflows&lt;/li&gt; 
  &lt;li&gt;Turning APIs, SQL queries, and scripts into apps for the entire team&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Airplane lets you turn SQL queries, JavaScript/Python code, HTTP requests, etc into tasks&lt;/li&gt; 
    &lt;li&gt;Allows to run tasks through a no-code dashboard&lt;/li&gt; 
    &lt;li&gt;Tasks for customer support, on-call runbooks, and scheduled tasks&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.airplane.dev/?utm_source=awesome-ai-agents"&gt;Profile of the company&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.airplane.dev/?utm_source=awesome-ai-agents"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/AirplaneDev/?utm_source=awesome-ai-agents"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.airplane.dev/autopilot/?utm_source=awesome-ai-agents"&gt;They're building an AI assistant here&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.aomni.com/?utm_source=awesome-ai-agents"&gt;Aomni&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent designed for business intelligence&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.aomni.com/icons/aomni-logo-black.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Breaks down a high level research question into a step-by-step plan, and executes it&lt;/li&gt; 
  &lt;li&gt;Diverse tools, including a full web browser&lt;/li&gt; 
  &lt;li&gt;Can access internet information without the need for an API&lt;/li&gt; 
  &lt;li&gt;"We don't generate content using AI, as it can be unreliable. Instead, we extract relevant information from trusted sources, cluster and process it into a user-friendly format."&lt;/li&gt; 
  &lt;li&gt;AI-powered query planner intelligently routes and executes requests, ensuring correctness and diverse source selection&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/a367ncqEsm/?utm_source=awesome-ai-agents"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/david-zhang-from-aomni-gives-his-view-on-ai-agents"&gt;Interview: David Zhang from Aomni gives his view agents' reliability, debugging and orchestration&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://apidna.ai/"&gt;APIDNA&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multiple AI Agents for the integration of APIs.&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://apidna.ai/wp-content/uploads/2023/12/api-dna-logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Multi-agent, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"At APIDNA, we're connecting software companies to connect the world. And we're doing this with our proprietary no-code multiple Autonomous AI Agent platform, to address one of the major pain points in software development today â€“ the integration of API endpoints."&lt;/li&gt; 
  &lt;li&gt;"Our multiple Autonomous AI Agents instantly integrate API endpoints. This simplifies and accelerates the software integration process, typically taking only three steps - and completing within minutes. A task that traditionally could take hours, days, weeks, or even months."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://apidna.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/apidna/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/timdutta-ai/"&gt;Tim D. - LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/Artisan-AI"&gt;Artisian AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agents for sales, e-mails, book keeping &amp;amp; more&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1723059970609225728/WxC0wUQ-_400x400.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Multi-agent, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;YC company&lt;/li&gt; 
  &lt;li&gt;"Creating the first human-like digital workers, called Artisans"&lt;/li&gt; 
  &lt;li&gt;Artisans are advanced human-like digital workers trained to do specific roles, who integrate alongside human teams&lt;/li&gt; 
  &lt;li&gt;They have unique faces, names, memories &amp;amp; skills, and they continuously improve once they are employed, molding to each company's needs&lt;/li&gt; 
  &lt;li&gt;The first Artisan, Ava, automates the entire outbound sales process and can be set up with a 10-minute conversation. Ava creates TCPs, prospects with her database of over 270,000,000 contacts, crafts &amp;amp; sends highly bespoke email sequences, and books meetings into your calendar. And, you can manage all features &amp;amp; settings by talking to Ava via Slack.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Artisan-AI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/GetArtisanAI"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/artisanai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/jasparcjack"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/rupertdodkins/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://tech.eu/2023/11/17/ai-startup-artisan-raises-23m-to-develop-human-like-digital-workers/"&gt;Article&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://askpandi.com/ask"&gt;Ask Pandi&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Answer engine to search and generate knowledge&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://askpandi.com/logo.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Research, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Pandi compiles your search's final stretch into a concise, distraction-free webpage.&lt;/li&gt; 
  &lt;li&gt;It offers multi-modal answers with citations from top web creators, eliminating the need for link sifting, cookie consents, or ads.&lt;/li&gt; 
  &lt;li&gt;You can use the internet as a data source, create your own library, or do both.&lt;/li&gt; 
  &lt;li&gt;You can also use Pandi in creative mode for writing or coding.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://askpandi.com/ask"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/ask_pandi"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://asktosell.com/"&gt;AskToSell&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Meet autonomous AI sales agents that close deals&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/64dc76096a7dfdd761e62e16/64dc9b12f89067d1657f3103_asktosell%20transparent%20logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Sales, Build-your-own, Business intelligence, Marketing&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A web platform to deploy &amp;amp; manage autonomous AI sales agents that close small deals.&lt;/li&gt; 
  &lt;li&gt;Autonomous agents will contact your leads, qualify, prepare offers, handle objections, negotiate, and close the deal with superhuman-like performance&lt;/li&gt; 
  &lt;li&gt;AskToSell autonomously moves your leads through the pipeline. AI Sales Agents will learn about your product, contact your leads, qualify, prepare proposals, handle objections, negotiate, and close the deals.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://asktosell.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/asktosell/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/laimonasn/"&gt;Founder's LinkedIn - Laimonas Noreika&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.askyourdatabase.com/"&gt;AskYourDatabase&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Chat with SQL database, explore and visualize data&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.askyourdatabase.com/_next/image?url=%2Flogo-light.png&amp;amp;w=64&amp;amp;q=75" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Business intelligence, Productivity, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"ChatGPT for SQL"&lt;/li&gt; 
  &lt;li&gt;No SQL, Connect your database and chat with your data in ChatGPT&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.askyourdatabase.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/AZ2WnRxTD8"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/sheldon-niu-a174bb243/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.athenaintelligence.ai/"&gt;Athena Intelligence&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;24/7 Enterprise AI Data Analyst&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/6484b03566311009ccef7599/6602dcd93264ffed31406081_athena_logo_full%201.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Athena is an AI-native analytics platform designed to accelerate analytics workflows for enterprise teams.&lt;/li&gt; 
  &lt;li&gt;It offers both co-pilot and auto-pilot modes, learning users' workflows to allow for autonomous execution with confidence.&lt;/li&gt; 
  &lt;li&gt;Athena supports querying data, generating visualizations, analyzing enterprise data, and codifying workflows, making it a powerful tool for data-driven decision-making.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.athenaintelligence.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/brendongeils/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://avanz.ai/"&gt;Avanzai&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agents for portfolio risk and asset allocation&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/abZ2DpGylwpNlOcvhmiTEHLvU.png?scale-down-to=512" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis, Research, Build-your-own (agent-builing frameworks and platforms), Finance, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Avanzai helps users build autonomous AI agents that scrape news, fetch real time data and write Python code that helps them calculate risk exposures of their portfolio.&lt;/li&gt; 
  &lt;li&gt;Users can then deploy these agents to work around the clock, saving users time from doing this themselves.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://avanz.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/gmanmalena_"&gt;Founder's X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/avanzai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.bardeen.ai/"&gt;Bardeen&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Agent for automating repetitive tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/v2/D560BAQEzSXhSE2SQDg/company-logo_200_200/company-logo_200_200/0/1716353067827/bardeen_logo?e=1735776000&amp;amp;v=beta&amp;amp;t=ME3uHoIaMtWAPGQAyBiVFjA4U799mmBj5pjCTjrj5eM" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Sales&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI Agent for automating repetitive tasks&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.bardeen.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/bardeenai"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://beam.ai/"&gt;Beam&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A wide selection of AI agents automating workflows&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/frmJOXg5roLaxUZMpGF6efXw9A.png?scale-down-to=512" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Productivity, Build-your-own (agent-builing frameworks and platforms), Business intelligence, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;End-to-end process and workflow automation with intelligent AI agents.&lt;/li&gt; 
  &lt;li&gt;With multiple B2B2C use-cases among a myriad of industries - healthcare, insurance, logistics, customer service, etc. - Beam allows businesses to customise their own automations or choose from existing agent templates to minimize the time it takes to execute complex tasks, repetitive tasks, and 100% of back office tasks.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://beam.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/join__beam"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/beam-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@beam-ai"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.blackbox.ai/"&gt;Blackbox AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Software That Builds Software&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.blackbox.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FBlackbox-Logo-4x.85cc4976.png&amp;amp;w=384&amp;amp;q=75" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;General purpose, coding, data analysis&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;BLACKBOX.AI is a coding LLM designed to transform the way we build software.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;By building BLACKBOX.AI, our goal is to:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Accelerate the pace of innovation within companies by making engineers 10X faster in building and releasing products&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Accelerate the growth in software engineers around the world and 10X the number of engineers from ~100M to 1B&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.blackbox.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.runcode.ai/"&gt;Blackbox AI Code Interpreter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://pypi.org/project/blackboxai/"&gt;Blackbox AI Code Interpreter in terminal&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/aiblckbx?lang=cs"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.facebook.com/blckbxai/"&gt;Facebook&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://chromewebstore.google.com/detail/mcgbeeipkmelnpldkobichboakdfaeon"&gt;Chrome extension&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;Written about Blackbox:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://medium.com/@blackbox.ai/blackbox-ai-vs-codium-ai-7016abb93ec0"&gt;BLACKBOX AI vs Codium AI&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/pulse/blackbox-ai-supercharging-your-coding-workflow-swarup-mukharjee-5gqbe/"&gt;Blackbox AI: Supercharging Your Coding Workflow&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/pulse/unveiling-untold-story-blackboxai-revolution-software-yaqoot-kashif-em75f/"&gt;Unveiling the Untold Story of Blackbox.ai: A Revolution in Software Quality Assurance&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.blobr.io/"&gt;Blobr&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI business assistant connected to all your tools&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/5f1ace21b47b368069989680/65cdd7ab62643c6baa204181_logo-blobr-white.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Productivity, Marketig, Sales, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Blobr is an AI assistant making sense of your business data stored in all your siloed SaaS. Reveal insights, understand variations and customer patterns without technical effort.&lt;/li&gt; 
  &lt;li&gt;Blobr helps Sales Ops, Marketing Ops and growth people to make better decisions.&lt;/li&gt; 
  &lt;li&gt;Blobr adds an intelligence layer connected to all your SaaS (Hubspot, Google Analytics, Stripe, etc.).&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.blobr.io/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Blobr_io"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/alexandre-airvault-aabaa758/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;BrainSoup&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build an AI team that works for you, on your PC&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.nurgo-software.com/images/BrainSoup/BrainSoupCard512.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity, Data analysis, Multi-agent, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Custom AI agents that remember, learn and work together.&lt;/li&gt; 
  &lt;li&gt;Local native app, for privacy and responsiveness.&lt;/li&gt; 
  &lt;li&gt;Your data fuels your AI agents without leaving your PC.&lt;/li&gt; 
  &lt;li&gt;Multimodal: your AI agents understand text, voice, and images.&lt;/li&gt; 
  &lt;li&gt;Reactive: your agents can respond to user defined events and leverage real-time data.&lt;/li&gt; 
  &lt;li&gt;Autonomous: your agents can run in the background without user intervention.&lt;/li&gt; 
  &lt;li&gt;Collaborate safely: AIs can read, write execute and share files in a sandboxed environment.&lt;/li&gt; 
  &lt;li&gt;Multi-LLM: local and cloud-based AI models can be combined for best of both worlds.&lt;/li&gt; 
  &lt;li&gt;Tinkerable &amp;amp; extensible: empower your agents with custom tools and scripts.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.nurgo-software.com/products/brainsoup"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://help.nurgo-software.com/collection/148-brainsoup"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Nurgo"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/xt7PyCnH9S"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.broadn.io/?utm_source=awesome-ai-agents"&gt;broadn&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;No-code copilot that allows users to build AI apps&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://api.typedream.com/v0/document/public/9727d7a5-4819-4564-beac-0284be31fddc/2aOWIGcm82x5hyT6p1gN9X7cn62_broadn_logo_new.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;broadn is a no-code platform that helps non-technical people build AI products in minutes. We're faster and more flexible than traditional no-code tools through an LLM powered conversational interface and an agent architecture that automates complex backend/workflow operations&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Conversational interface&lt;/li&gt; 
    &lt;li&gt;LLM/AI model connectors (text, image models, etc)&lt;/li&gt; 
    &lt;li&gt;Create bespoke chatbots&lt;/li&gt; 
    &lt;li&gt;Render UI components&lt;/li&gt; 
    &lt;li&gt;Connect to external data via APIs&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Authors: &lt;a href="https://twitter.com/calindrimbau"&gt;Calin Drimbau&lt;/a&gt; and &lt;a href="https://twitter.com/vicpara"&gt;Victor Paraschiv&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/getbroadn"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://butternut.ai/"&gt;Butternut AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build fully-functioning, ready-to-launch website&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://butternut.ai/_next/image?url=%2Fimages%2Flogo%2Flogo-text.png&amp;amp;w=384&amp;amp;q=75" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Web design, Design, Coding, Marketing&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;A tool for creating a fully-functioning, ready-to-launch website in 20 seconds&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;No coding required thanks to user-friendly interface&lt;/li&gt; 
  &lt;li&gt;Full SEO optimization&lt;/li&gt; 
  &lt;li&gt;Picture Upload: Users can conveniently upload and regenerate their own pictures for unlimited customization of their profiles&lt;/li&gt; 
  &lt;li&gt;Profile Customization: Users have the flexibility to customize their profiles by hiding sections, adding social media links, and sharing contact details, allowing them to showcase their unique personality and brand&lt;/li&gt; 
  &lt;li&gt;Instant Preview: Users can instantly visualize their profile changes through a conveniently placed preview button, ensuring a quick assessment of the desired appearance&lt;/li&gt; 
  &lt;li&gt;30% Faster Speed: The app achieves an impressive 30% increase in website generation speed, providing users with a fast and efficient website building experience.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://butternut.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.b2.work/"&gt;B2 AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Autocomplete AI assistant for work&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://static.vecteezy.com/system/resources/previews/024/246/469/non_2x/advanced-ai-assistant-icon-in-illustration-vector.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Personal assistant, Business intelligence, Productivity, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;B2 is an autonomous AI assistant to help you get things done&lt;/li&gt; 
  &lt;li&gt;Share useful workflows with your team members or schedule AI-powered recurring workflows.&lt;/li&gt; 
  &lt;li&gt;Granular data-controls so your company's data doesn't end up in the wrong hands. Fully configurable role-based access.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.b2.work/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/amazng_wanderer"&gt;Founder's X - Ethan&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://chathelp.ai/"&gt;ChatHelp&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-powered Business, Work, Study Assistant&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://chathelp.ai/wp-content/uploads/chathelp_black.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Content creation, Productivity, Research, Marketig, Sales, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ğŸ‘‰ Chat with Private AI Knowledge Base - Increase daily work efficiency, by having an AI assistant, who knows everything about your business &amp;amp; competitors, your work or studies...&lt;/li&gt; 
  &lt;li&gt;ğŸ‘‰ Save time &amp;amp; money on customer support. Drive more sales, by letting AI interact with potential customers 24/7, via Website Chat Widget. Train AI with your Website data &amp;amp; other documentation!&lt;/li&gt; 
  &lt;li&gt;ğŸ‘‰ 100+ Unique AI Tools, for all your Business, Work &amp;amp; Study needs. Like, AI Writing Assistant &amp;amp; WordPress Auto Poster.&lt;/li&gt; 
  &lt;li&gt;ğŸ”œ Understand your customers better with AI-powered Feedback, Voting &amp;amp; Survey Widgets!&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;âœ”ï¸ Supported file formats: pdf, doc, docx, ppt, pptx, xls, xlsx, csv, json, epub, mp3, jpg, jpeg, png âœ”ï¸ WordPress Plugin âœ”ï¸ Youtube Transcripts âœ”ï¸ Analyze Yelp Reviews âœ”ï¸ +175 Languages âœ”ï¸ Create an AI-powered Website Chat Widget. âœ”ï¸ Create a Custom AI-powered Knowledge Base ğŸ”œ Zapier, Notion, ZenDesk, Hubspot, Trello, Monday.com, Slack, Gmail &amp;amp; Google Doc. support."&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://chathelp.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/ChatHelpAI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/chathelp/about/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/BK5QtfKxbB"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.facebook.com/ChatHelpAI"&gt;Facebook&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/chathelpai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.claros.so/"&gt;Claros AI Shopper&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI shopper that finds products for your taste&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.claros.so/logo-circle.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Personal assistant&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Claros is an AI personal shopper that finds you interesting products, and learns your taste over time&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI Shopping Assistants for Ecom + Everyone&lt;/li&gt; 
  &lt;li&gt;Claros is an AI personal shopper that finds you cool and interesting products. It can also learn your taste over time to give you the best results possible&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.claros.so/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/so_claros"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/clarosai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/thiteanish"&gt;Founder's X - Anish&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://twitter.com/asapdar"&gt;Founder's X - Ammar Safdari&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.clay.com/learn/claygent"&gt;Claygent&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Agent that scrapes and summarize data from the web&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/61477f2c24a826836f969afe/65b22bf376c1cc60a9e0de93_img-logo-clay.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Marketig, Sales, Finance, General purpose, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Claygent is an AI web scraper that can search and browse the web to find information for you and replace a huge amount of the manual work your SDRs are doing on account research!&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.clay.com/learn/claygent"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/adam-eldefrawy-8623a815a/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.codeautopilot.com/"&gt;Code Autopilot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Assistant for your project&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.codeautopilot.com/_next/static/media/logo_purple.fa331d81.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI Assistant for your GitHub issues and pull requests. Create entire features and fix bugs on complex GitHub projects at a distance of a text description.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.codeautopilot.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.codeautopilot.com/"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/code_autopilot"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Gsandec"&gt;Gustavo Silva - co-founder of Code Autopilot&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/fjrdomingues"&gt;FÃ¡bio ZÃ© Domingues - co-founder of Code Autopilot&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.codegen.com/"&gt;Codegen&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Solve tickets, write tests, level up your workflow&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/652ef464dd4ef344367c4fd1/652efb93dcbbba956ee773f2_Codegen%20-%20Logo%20-%20Primary%20-%20Dark%20Theme-p-500.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Codegen is an agent that allows automatically solve tickets, write tests and level up user's development workflow with the power of GPT-4.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Use-case: Coding, debugging, code migration etc.&lt;/li&gt; 
  &lt;li&gt;Models used: GPT-4&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.codegen.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Codegen"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/mathemagic1an"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://codewp.ai/"&gt;CodeWP&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Agent for WordPress websites&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://codewp.ai/wp-content/uploads/2023/09/New-Icon.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Faster WordPress Development with domain-specific AI modes, tools, and features.&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://codewp.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/wpai-inc/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/codewp_ai"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/wpai-inc/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/codewp_ai"&gt;James LePage - founder of CodeWP&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.codium.ai/"&gt;Codium AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Coding multipurpose AI assistant for developers&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.codium.ai/wp-content/uploads/2023/01/codium-logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Generating meaningful tests for busy devs&lt;/li&gt; 
  &lt;li&gt;Exploring and analyzing your code, docstrings, comments, and by interacting with you&lt;/li&gt; 
  &lt;li&gt;Non-trivial tests (and trivial, too!) suggested right inside your IDE 
   &lt;ul&gt; 
    &lt;li&gt;Generates tests&lt;/li&gt; 
    &lt;li&gt;Covers edge cases&lt;/li&gt; 
    &lt;li&gt;Best practice, readability code suggestions&lt;/li&gt; 
    &lt;li&gt;Gives you the code explanation&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;It is free&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/CodiumAI"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/codiumai"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@Codium-AI"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/SgSxuQ65GF"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Codium-ai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://commit.dev"&gt;Commit&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Career Copilot and AI Agent for SW Developers&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://commit.dev/wp-content/uploads/2021/05/commit-logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Comprehensive job search&lt;/li&gt; 
  &lt;li&gt;Accurate job recommendations based on your skills, experience, and preferences&lt;/li&gt; 
  &lt;li&gt;AI-powered auto-applications&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CEO: &lt;a href="https://www.linkedin.com/in/gunnr"&gt;Greg Gunn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;CTO: &lt;a href="https://www.linkedin.com/in/beiercai"&gt;Beier Cai&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://cognosys.ai"&gt;Cognosys&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Web-based version of AutoGPT or BabyAGI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_banners/1646414136811855873/1704327520/1500x500" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Research&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Friendly UI for building AI agents&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/SullyOmarr"&gt;Sully Omarr&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://e2b.dev/blog/about-deployment-evaluation-and-testing-of-agents-with-sully-omar-the-ceo-of-cognosys-ai"&gt;Interview: About deployment, evaluation, and testing of agents with Sully Omar, the CEO of Cognosys AI&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://contextqa.com/"&gt;ContextQA&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Agents for Software Testing&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://contextqa.com/wp-content/themes/contextQA/assets/images/cqa-logo-with-text.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Agentic AI for Complete Test Coverage&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://contextqa.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/ContextQa"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.cursor.so/"&gt;Cursor&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-powered Code Editor with VSCode-like UI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://cursor.sh/brand/logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Cursor is the AI-first Code Editor. Build software faster in an editor designed for pair-programming with AI.&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.cursor.so/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/getcursor/cursor"&gt;GitHub (Issue Only)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/PJEgRywgRy"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.cykel.ai/"&gt;Cykel&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Interact with any UI, website or API&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1704063452271058944/sZEVZIqG_400x400.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Cykel is an AI co-pilot model that can interact with any UI, website or API in response to natural language commands&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Use-case: General purpose, Personal assistant (helping with daily tasks)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.cykel.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/CykelAI"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/cykelai"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/EwanCollinge"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.cognition-labs.com/introducing-devin"&gt;Devin&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The first AI software engineer&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/65cf071d26e52092bc212f6e/65ed4622397bb038560f1ef3_cropped-p-500.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Devin is in early phase now, but according to demo, it has the following capabilities:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Can learn how to use unfamiliar technologies.&lt;/li&gt; 
  &lt;li&gt;Can build and deploy apps end to end.&lt;/li&gt; 
  &lt;li&gt;Can autonomously find and fix bugs in codebases.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.cognition-labs.com/introducing-devin"&gt;Blog post&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/cognition_labs"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://diagram.com/"&gt;Diagram&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI design tools for everyone, acquired by Figma&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://uploads-ssl.webflow.com/6408bea3de5aef58b7e197d4/6408c50680c7dae0a89901a1_logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Design, Content creation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI-powered design tools for everything from copywriting to generating unique icons from text&lt;/li&gt; 
  &lt;li&gt;Magic Copy writes, edits, and rewrites Figma text layers so you can design with real copy&lt;/li&gt; 
  &lt;li&gt;Generating images in Figma while designing&lt;/li&gt; 
  &lt;li&gt;Magic Rename intelligently names your layers so you can spend more time designing&lt;/li&gt; 
  &lt;li&gt;Magician works right inside your favorite design tool (e.g., Figma)&lt;/li&gt; 
  &lt;li&gt;Possible to get all the latest AI design advancements + future spells in one convenient plugin&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://diagram.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://docketai.net/"&gt;Docket AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Sales Engineer for somplex B2B sales&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://cdn.prod.website-files.com/64b81d5300b4d493cead41a3/66a0a76ea06f179159040503_Docket%20Logo%201.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Sales&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Docket AI is your personal AI Sales Engineer, empowers AEs to win more.&lt;/li&gt; 
  &lt;li&gt;It provides instant sales answers, automated RFP responses, and insights from top producers.&lt;/li&gt; 
  &lt;li&gt;Powered by the Sales Knowledge Lakeâ„¢, Docket unifies your companyâ€™s sales data with genAI. Transforming sales productivity and win rates.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docketai.net/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://dosu.dev/"&gt;Dosu&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;GitHub repo AI teammate helping also with docs&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/146474245?s=200&amp;amp;v=4" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dosu is an AI teammate that lives in your github repo, helping you respond to issues, triage bugs, and build better documentation.&lt;/li&gt; 
  &lt;li&gt;Dosu responds to issues within minutes in the user's native language.&lt;/li&gt; 
  &lt;li&gt;Dosu is a wizard when it comes to documentation, even when there is none. Not only will it remind you to update your documentation and help you write it, but Dosu can also ride shotgun as you code that next big feature, answering questions about external code as if youâ€™re sitting next to the author.&lt;/li&gt; 
  &lt;li&gt;Dosu keeps a watchful eye on open issues, resolving those that you might have missed and deprecating issues that no longer exist. Itâ€™ll even ask you if itâ€™s not sure.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://dosu.dev/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/dosu_ai"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/dosu-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/devstein/"&gt;Founder's LinkedIn - Devin Stein&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/devstein"&gt;Founder's GitHub - Devin Stein&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.getdot.ai/"&gt;Dot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Virtual assistant that help with data analytics&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/644a347ea803e322d9c0feb8/644a36f6d9f2d08386070b0d_fox_avatar_7.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dot allows to chat with your Data Warehouse (e.g. Snowflake, BigQuery, RedShift, Postgres ...) or Semantic Layer (e.g. Looker, dbt, dotML).&lt;/li&gt; 
  &lt;li&gt;Answer most business questions instantly 24/7, so data teams can focus on deep work, not on answering easy questions about dashboards&lt;/li&gt; 
  &lt;li&gt;Category: Research, Business intelligence, Data analysis&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.getdot.ai/"&gt;Website&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/sled-software/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder's linkedin - &lt;a href="https://www.linkedin.com/in/radewagen/"&gt;Rick Radewagen&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://duckie.ai/"&gt;Duckie AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Team of AI SW development companions (Ducklings)&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://duckie.ai/images/duckie_logo.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Duckie AI is a platform that lets engineers manage a team of AI software development companions (Ducklings) that get their dev work done&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Ducklings work with engineers to complete end-to-end feature development, from design to implementation Ducklings chat with users to define their goals, come up with engineering designs, and generate code&lt;/li&gt; 
  &lt;li&gt;Founded: 2023&lt;/li&gt; 
  &lt;li&gt;Location: San Francisco&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://duckie.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/duckie_ai"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/duckie-ai/about/"&gt;LInkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/JwQSRj9Wx2"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.ycombinator.com/companies/duckie-ai"&gt;YCombinator profile&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://ellipsis.dev/?utm_source=awesome-ai-agents"&gt;Ellipsis&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;(Previously BitBuilder) "Automated code reviews and bug fixes"&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://app.ellipsis.dev/images/ellipsis_github_logo_white_bg.png&amp;amp;w=640&amp;amp;q=75" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, GitHub, GitLab&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Create an Issue&lt;/li&gt; 
  &lt;li&gt;Approve the Implementation Plan&lt;/li&gt; 
  &lt;li&gt;Review the Pull Request&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Writing code&lt;/li&gt; 
    &lt;li&gt;Reviewing changes&lt;/li&gt; 
    &lt;li&gt;Addressing comments&lt;/li&gt; 
    &lt;li&gt;Answering questions&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.ellipsis.dev"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.ellipsis.dev/"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://encode.software"&gt;encode&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Fully autonomous AI SW engineer in early stage&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://encode.software/_next/image?url=%2Fslack2.png&amp;amp;w=1920&amp;amp;q=75" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;in alpha&lt;/li&gt; 
  &lt;li&gt;encode works with you and your team to get work done&lt;/li&gt; 
  &lt;li&gt;demo: &lt;a href="https://encode.software/demo"&gt;https://encode.software/demo&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.factory.ai/"&gt;Factory&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Coding Droids for building software end-to-end&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/644b0c1743a3f6abb4f7f149/659c69f2d6e5ba953d5aed58_t%20(1)-p-500.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;In aplha stage&lt;/li&gt; 
  &lt;li&gt;Itâ€™s not supposed to be just another coding copilots like GitHub Copilot or Codeium, but autonomous agents capable of autonomously building software from end to end&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/matangrinberg"&gt;CEO&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.fine.dev/"&gt;Fine&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build Software with AI Agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/6290be8d112ee934eeb6aaf2/64e2150d1d1c34380ec59254_logo%20white%20with%20name.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Deploy, manage, and run AI agents that serve as your virtual teammates.&lt;/li&gt; 
  &lt;li&gt;Built for teams, with organizational memory and collaboration in mind.&lt;/li&gt; 
  &lt;li&gt;Privacy oriented, we don't store your code, everything runs locally.&lt;/li&gt; 
  &lt;li&gt;Multiagent platform: Build your own custom agents.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/thisisfinedev"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/nxW8sA5yqe"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@thisisfinedev"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://fine-tuner.ai/"&gt;Fine Tuner&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;(Pivoted to Synthflow) No-code platform for agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://1a3c84454236f952546f01b263468144.cdn.bubble.io/f1704473650779x346108115281154240/gray%20logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, General purpose&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;With Fine-Tuner, you can build sophisticated, tailored AI agents at scale without any need for technical skills or coding. Just bring your data and ideas, and we'll provide the toolset you need to transform them into powerful AI solutions, capable of handling vast amounts of data and users. Take advantage of our scalable platform to meet your growing needs with ease and efficiency&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Connecting Your Chatbot to Your App&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;FineTuner.ai is a no-code AI platform that enables users to create and deploy custom AI agents and components without any coding. With an intuitive UI/UX and rapid API deployment, FineTuner.ai simplifies AI development, allowing users to focus on their unique use cases and ideas.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;4.1. Access the API tab for an overview of the required tokens and parameters to connect your chatbot to your app using REST API endpoints.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The Fine-Tuner REST API provides API endpoints for Fine-Tuner data types that allow to interact with your AI models remotely by sending and receiving JSON&lt;/li&gt; 
  &lt;li&gt;Authentication to the Fine-Tuner API is performed via HTTP Bearer Authentication&lt;/li&gt; 
  &lt;li&gt;Front end: Bubble&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/finetuner_ai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://fine-tuner.ai/resources?res=1682544317646x963647349155168300"&gt;Step-by-step guide&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/0xAlbert_S3"&gt;Author&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.fixie.ai/"&gt;Fixie&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Platform for creating LLM-powered AI apps&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1715406291349143552/-wRzF29t_400x400.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Building and managing LLM powered applications&lt;/li&gt; 
  &lt;li&gt;A cloud-based platform-as-a-service that allows developers to build smart agents that couple LLMs with back-end logic to interface to data, systems, and tools&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/fixie-ai"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.fixie.ai/"&gt;Fixie Developer Portal&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.ai-jsx.com/"&gt;AI.JSX&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/fixieai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/MsKAeKF8kU"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://floodehq.com/"&gt;Floode&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Executive agent automating communication busywork&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1670794260579270658/sLUFAGGs_400x400.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Works across all your communication and work tools: emails, social media DMs, calendar, Notion, etc.&lt;/li&gt; 
  &lt;li&gt;Adapted to your work habits.&lt;/li&gt; 
  &lt;li&gt;Ask your assistant to: 
   &lt;ul&gt; 
    &lt;li&gt;Craft messages&lt;/li&gt; 
    &lt;li&gt;Auto-sort&lt;/li&gt; 
    &lt;li&gt;Auto-schedule&lt;/li&gt; 
    &lt;li&gt;Summarize, extract tasks and information&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Authors: &lt;a href="https://twitter.com/SarahAllali7"&gt;Sarah Allali&lt;/a&gt; and &lt;a href="https://twitter.com/Nicowcbg"&gt;Nicolas Cabrignac&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/floodehq"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/features/preview/copilot-x"&gt;GitHub Copilot X&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-powered software developer&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://techcommunity.microsoft.com/t5/image/serverpage/image-id/439603i2263F871BE5D381D/image-size/original?v=v2&amp;amp;px=-1" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI pair programmer&lt;/li&gt; 
  &lt;li&gt;Chat and terminal interfaces&lt;/li&gt; 
  &lt;li&gt;Support for pull requests&lt;/li&gt; 
  &lt;li&gt;Early adoption of OpenAIâ€™s GPT-4&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/orgs/community/discussions/"&gt;Community&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.github.com/en"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/GitHubCopilot"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://about.gitlab.com/gitlab-duo/"&gt;GitLab Duo&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI for every step of SW development lifecycle&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://about.gitlab.com/nuxt-images/solutions/ai/duo-logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A suite of AI-powered capabilities for #DevSecOps workflows&lt;/li&gt; 
  &lt;li&gt;A toolbox of features integrated into the DevSecOps Platform to help teams across the entire software development environment become more efficient&lt;/li&gt; 
  &lt;li&gt;Examples of what GitLab Duo can do: 
   &lt;ul&gt; 
    &lt;li&gt;Planning refinement&lt;/li&gt; 
    &lt;li&gt;Security risk resolution&lt;/li&gt; 
    &lt;li&gt;CI/CD pipeline health&lt;/li&gt; 
    &lt;li&gt;Analytics charting.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/gitlab"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.gitwit.dev/"&gt;GitWit&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Automate code generation with AI. In beta version&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/SmLDF79Mns070VHglJVQyuQ1A.png?scale-down-to=512" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;GitWit uses a GPT-based agent to generate code and git to track changes made to files&lt;/li&gt; 
  &lt;li&gt;GitWit ties together large language models and modern developer tools&lt;/li&gt; 
  &lt;li&gt;It can spawn and modify codebases using just a single prompt&lt;/li&gt; 
  &lt;li&gt;GitWit is primarily aimed at full-stack developers, and is particularly loved by those with a learning mindsetâ€”such as those learning a new stack or technology&lt;/li&gt; 
  &lt;li&gt;It is in early beta and may require some experimentation with the prompts you enter&lt;/li&gt; 
  &lt;li&gt;You are offered to choose from code bases: 
   &lt;ul&gt; 
    &lt;li&gt;React + NextJS&lt;/li&gt; 
    &lt;li&gt;Python using pip&lt;/li&gt; 
    &lt;li&gt;A Chrome extension written in JavaScript&lt;/li&gt; 
    &lt;li&gt;An AngularJS using npm.&lt;/li&gt; 
    &lt;li&gt;Custom stack&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://gocharlie.ai/"&gt;GoCharlie&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Multimodal content creation autonomous agent&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://gocharlie.ai/wp-content/uploads/2023/08/gocharlie_logo_ai_2x-230x49@2x.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Content creation, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;GoCharlie is a multimodal content creation autonomous agent.&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/GocharlieAI"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/gocharlieai/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founders' X accounts: 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://twitter.com/kostashatalis"&gt;Kostas Hatalis&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://twitter.com/BrennanWoodruff"&gt;Brennan M. Woodruff&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.graphlit.com/"&gt;Graphlit&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;API-first data platform for building apps with AI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_banners/1651090820773335040/1687935300/1500x500" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Built on a serverless, cloud-native platform, Graphlit simplifies complex data workflows, including data ingestion, knowledge extraction, semantic search, alerting and application integrations.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.graphlit.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/graphlit"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/graphlit"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/WjxCHhV8Cz"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder's LInkedin: &lt;a href="https://www.linkedin.com/in/kirkmarple/"&gt;Kirk Marple&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder's X: &lt;a href="https://twitter.com/kirkmarple"&gt;Kirk Marple&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.graphlit.dev/getting-started/readme"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.grit.io/"&gt;Grit&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Automating code migrations and dependency upgrades&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/kBmTJBFuy8F87jwrhcMkN9SRI.png?scale-down-to=512" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Grit uses machine learning and static analysis to auto-generate pull requests for cleaning up technical debt&lt;/li&gt; 
  &lt;li&gt;Users can declare how they want their code to be structured and let Grit rewrite it for them&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/getgrit/0"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/gritdotio"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.gumloop.com/"&gt;Gumloop&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Automate any workflow with AI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.gumloop.com/images/gumloop_logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, data analysis, general purpose, marketing, legal, sales, HR, finance, education&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;(Previously called AgentHub)&lt;/li&gt; 
  &lt;li&gt;A platform to build and host LLM powered automations&lt;/li&gt; 
  &lt;li&gt;Fuel your workspace with our growing library of nodes.&lt;/li&gt; 
  &lt;li&gt;Pass data from A to Z with drag-and-click connections. No code required.&lt;/li&gt; 
  &lt;li&gt;Run your workflow. Test in our sandbox. See results. When you're ready, share it with anyone (or no one). You control that.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.gumloop.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/gumloop_ai"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/gumloop/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/xtbrafmzC7"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.gumloop.com/getting-started/introduction"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@AgentHub_Ai"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://medium.com/@max_82395"&gt;Medium blog&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.gumloop.com/templates"&gt;Templates&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.heightsplatform.com/"&gt;Heights Platform&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;For course creators, community builders &amp;amp; coaches&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://yt3.googleusercontent.com/ytc/AIf8zZRVnjibds6hCRgPhxIuFs2UA7E5wIr9a6Iq69-_sw=s900-c-k-c0x00ffffff-no-rj" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Heights AI Chat can make edits to your digital products, answer support questions, and provide advice on growing your business.&lt;/li&gt; 
  &lt;li&gt;Heights AI Coach is your personal autonomous coach, helping you accomplish your unique goals 
   &lt;ul&gt; 
    &lt;li&gt;Your AI coach will ask you questions and analyze the products you create to provide you with new tasks and recommendations every week.&lt;/li&gt; 
    &lt;li&gt;Information you share with your AI Coach will never be shared with another creator's AI Coach.&lt;/li&gt; 
    &lt;li&gt;Any information submitted will never be used for AI language model training data.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.heightsplatform.com/features/ai"&gt;AI Features&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/HeightsPlatform"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://hex.tech/product/magic-ai/"&gt;Hex Magic&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI tools for doing amazing things with data&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://images.ctfassets.net/mmgv7yhaaeds/4UFip8DgC0pJEOXeNppEQS/d97b0b1916c9b298f2480c1c28460015/social-sharing-magic.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"A suite of powerful AI features meant to augment data people"&lt;/li&gt; 
  &lt;li&gt;Hex can explain and document your code&lt;/li&gt; 
  &lt;li&gt;Hex Magic features know about database schemas, past operations, and the projectâ€™s execution graph, so they can make deeper, more insightful recommendations&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;You can see more â€“ and sign up for the waitlist â€“ over here.&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://hex.tech/blog/magic-private-beta/"&gt;Launch post&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://heymoon.ai/"&gt;Heymoon.ai&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Keep you on top of your calendar, tasks and info&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://heymoon.ai/assets/images/image04.png?v=a3b31dce" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Personal assistant for life: to keep you on top of your calendar, tasks and information&lt;/li&gt; 
  &lt;li&gt;Currently in a beta version&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://heymoon.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.imean.ai/"&gt;iMean.AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI personal assistant that automates browser task&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.imean.ai/icon.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Daily life, Build-your-own (agent-builing frameworks and platforms)&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;iMean is the first public product that automates browser task end to end deterministically.&lt;/li&gt; 
  &lt;li&gt;Unlike existing solutions that either stuck at middle steps or output only text instructions, iMean can automate the task for you and get you real results.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.imean.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/iMeanAI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/imean-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/zyonwu"&gt;Co-founder's X(Twitter) 1&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/zyonwu/"&gt;Co-founder's LinkedIn 1&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/yanni-shawn-a6222318b/"&gt;Co-founder's LinkedIn 2&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/zyonwu/status/1747801290368004424?s=20"&gt;Launch post&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://useinput.com/"&gt;Input&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-powered teammate that can collaborate on code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://useinput.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FlightLogo.196eccc1.png&amp;amp;w=640&amp;amp;q=75" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Multi-agent, GitHub&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI assistant (or team of assistants) for coding&lt;/li&gt; 
  &lt;li&gt;Allows to invite team members to collaborate with you and AI&lt;/li&gt; 
  &lt;li&gt;Agents do the work, and push it to GitHub autonomously&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://useinput.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/useinputai"&gt;X&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://github.com/blob42/Instrukt"&gt;Instrukt&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Terminal env for interacting with with AI agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Enables users to create and instruct modular AI agents, generate document indexes for question-answering, and attach tools to agents for enhanced functionalities.&lt;/li&gt; 
  &lt;li&gt;Facilitates coding assistance and conversational capabilities through predefined agents, along with the option to design custom agents, all within a keyboard and mouse-friendly terminal interface.&lt;/li&gt; 
  &lt;li&gt;Provides secure execution environments for agents through Docker containers, allowing for safe and private operations, along with an integrated developer console for debugging and introspection.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://github.com/blob42/Instrukt"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://invictai.io/"&gt;Invicta&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build your first team of Autonomous AI Agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://invictai.io/_next/image?url=%2Fimages%2Finvicta-text-black.svg&amp;amp;w=3840&amp;amp;q=75" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own (agent-builing frameworks and platforms), Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Your AI autopilot, not just a co-pilot.&lt;/li&gt; 
  &lt;li&gt;In-sync Knowledge Base: Notion, Google&amp;nbsp;Drive, URLs, all file types and&amp;nbsp;more&lt;/li&gt; 
  &lt;li&gt;Self-improving: They get better with each interaction and collaboration.&lt;/li&gt; 
  &lt;li&gt;LLM Agnostic. Use the best LLMs from OpenAI, Google, Mistral, and Anthropic, etc.&lt;/li&gt; 
  &lt;li&gt;Deploy agents where your team is: Zendesk, Slack, Discord, etc.&lt;/li&gt; 
  &lt;li&gt;Cooperative AI Teams: your agents can collaborate with each other as a team to complete complex workflows&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://invictai.io/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Invicta-AI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/InvictaAI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/invicta-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://julius.ai/"&gt;Julius&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI data processing, analysis, and visualization&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1704414144798261248/PN4b_sxH_400x400.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Chat-powered data analytics and AI agents, all in a notebook interface&lt;/li&gt; 
  &lt;li&gt;Allows to answer any question about users' data with a single prompt&lt;/li&gt; 
  &lt;li&gt;An intelligent data analyst tool that interprets, analyzes, and visualizes complex data in an intuitive, user-friendly manner&lt;/li&gt; 
  &lt;li&gt;"Jupyter Notebooks on steroids"&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://julius.ai/docs/chat-start-guide"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://julius.ai/use_cases"&gt;Use cases&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/JuliusAI_"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Team Twitter profiles: &lt;a href="https://twitter.com/badphilosopher"&gt;Matt Brockman&lt;/a&gt;, &lt;a href="https://twitter.com/0interestrates"&gt;rahul&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.kadoa.com/"&gt;Kadoa&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Web Scraping on Autopilot with AI&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.kadoa.com/images/kadoa.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Using LLMs to generate web scrapers and data processing steps on the fly that adapt to website changes.&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;No coding or browser extension required.&lt;/li&gt; 
    &lt;li&gt;The autonomous crawling agent efficiently locates the desired information on websites.&lt;/li&gt; 
    &lt;li&gt;Adaptability to website changes makes it maintenance-free&lt;/li&gt; 
    &lt;li&gt;Transforms data from multiple sources into the same structure&lt;/li&gt; 
    &lt;li&gt;Handles all clicking and scrolling automatically&lt;/li&gt; 
    &lt;li&gt;Handles proxies&lt;/li&gt; 
    &lt;li&gt;Powerful integrations&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.kadoa.com/playground"&gt;Playground&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/krebs_adrian"&gt;Adrian Krebs&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://heyjuno.co/"&gt;Juno&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-led user interviews for rich human insights&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/PobjUKj7qACciStbW7PAArGYXc.png?scale-down-to=512" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Research, Business intelligence, web UI&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Meet Juno! An AI-moderated research platform that conducts research and collects human insights. Itâ€™s unsupervised, multilingual and autonomous. Trained by veteran researchers, Juno empowers everyone to conduct in-depth qualitative research, without prior experience.&lt;/li&gt; 
  &lt;li&gt;LLMs/model providers supported 
   &lt;ul&gt; 
    &lt;li&gt;OpenAI&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://heyjuno.co/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/heyjunoco"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/heyjunoco/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/heyjunoco"&gt;Privacy overview&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://kompas.ai/"&gt;Kompas AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Pick your LLM &amp;amp; build custom conversational agent&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1712005262633271296/2c9Vdj2B_400x400.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Build-your-own, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Kompas AI is an advanced AI assistant for your team.&lt;/li&gt; 
  &lt;li&gt;It's designed to assist and enhance your productivity.&lt;/li&gt; 
  &lt;li&gt;It processes multiple tasks simultaneously.&lt;/li&gt; 
  &lt;li&gt;Kompas AI outperforms ChatGPT Pro in response speed, using Microsoft Azure's OpenAI Service.&lt;/li&gt; 
  &lt;li&gt;Kompas AI offers a free trial that allows you to use the Pro version for 10 days.&lt;/li&gt; 
  &lt;li&gt;Kompas AI primarily uses the gpt-4-turbo, gpt-4-vision and gpt-3.5-turbo models, but it also supports other models like Gemini, Claude 2, and open-source models. Notably, Kompas AI features a larger context window, through gpt-4-turbo utilizing a 128K tokens Context Window that allows it to remember up to 512,000 characters of past conversation for more complex tasks.&lt;/li&gt; 
  &lt;li&gt;Kompas AI prioritizes data security. Your files are protected with strong encryption, and data in transit is safeguarded. Unused data is regularly removed from the system.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://kompas.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Kompas_AI"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/KompasAI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/kompas-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://medium.com/@Kompas.ai"&gt;Medium&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.kompas.ai/docs/kompas-ai-intro/service-introduction"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://kusho.ai/"&gt;Kusho&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent for API testing&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D560BAQFE0UatBCw0_w/company-logo_200_200/0/1702642519517/kusho_logo?e=1714003200&amp;amp;v=beta&amp;amp;t=mihS31C5JOQPva4d17sJvNj_QOS1TS9slFp4VAH16u8" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Productivity, Debugging&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;KushoAI instantly generates and runs test suites for your APIs so you can push code effortlessly.&lt;/li&gt; 
  &lt;li&gt;Save hours of manual effort by delegating API testing to KushoAI. Unlock crash-free releases starting today.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;Add a link to your Postman collection to instantly generate exhaustive test suites for each API and save hours of manual effort.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Get AI-analysed test results in a single click.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Auto-run relevant test suites at any stage of your CI/CD pipeline."&lt;/p&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Works on your Postman collections&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;"At KushoAI, we believe that the job of technology is to empower people. Weâ€™re building AI agents trained for specific problems to unlock value at a pace faster than ever before."&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://kusho.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/kushoai"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/kusho/?originalSubdomain=in"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://blog.kusho.ai/"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@KushoAI"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/sourabhgawande/"&gt;Sourabh Gawande - cofounder at Kusho&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/abhishek1315/"&gt;Abhishek Saikia - cofounder at Kusho&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.kwal.ai/"&gt;Kwal&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Voice Agents for Recruiting&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://static.wixstatic.com/media/d84692_0e36f4d5a7974924a68d537a0c8184f9~mv2.png/v1/fill/w_302,h_166,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/d84692_0e36f4d5a7974924a68d537a0c8184f9~mv2.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.kwal.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/Kwal_AI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/kwal/about/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.lindy.ai/"&gt;Lindy&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI assistant that can help with daily tasks&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/63e15df811f9df22b231e58f/65473d5a31149f709f0d6c39_Group%201266.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Lindy is still in a beta version&lt;/li&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;Lindy triages your email&lt;/li&gt; 
    &lt;li&gt;She learns from your inbox and automatically surfaces the highest-priority emails for you&lt;/li&gt; 
    &lt;li&gt;Automatic conflict handling&lt;/li&gt; 
    &lt;li&gt;Daily briefing&lt;/li&gt; 
    &lt;li&gt;Contract management&lt;/li&gt; 
    &lt;li&gt;Meeting note taking&lt;/li&gt; 
    &lt;li&gt;Summarization&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/Altimor"&gt;Flo Crivello&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://lutra.ai/"&gt;Lutra AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Platform for creating AI workflows and apps&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D4D0BAQE_KlQYa63Cbg/company-logo_200_200/0/1701917707502/lutra_ai_logo?e=1713398400&amp;amp;v=beta&amp;amp;t=-c8RMYvjM4j06XsJVx1DUJAJ336S80bWO4CSD_IHQao" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Business intelligence, Productivity, Content creation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A platform for creating your personal AI workflows and apps. Lutra first converses with you to understand your goals, and then writes code to produce AI workflows.&lt;/li&gt; 
  &lt;li&gt;These AI workflows are akin to specialized agents that help you with all kinds of tasks. Because these workflows are based in code, Lutra is able to securely and reliably execute them, ensuring that your data is always protected.&lt;/li&gt; 
  &lt;li&gt;Get a personalized newsletter everyday with concise summaries of news tailored to your interests.&lt;/li&gt; 
  &lt;li&gt;Have AI automatically label your incoming emails into categories you choose. Get things done!&lt;/li&gt; 
  &lt;li&gt;Collect public information about a person and the company they work for, so that you can be ready when you meet them.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://lutra.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/lutra-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Lutra_AI"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/9ZDFvRXe8V"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/vijay-vasudevan-a5062434/"&gt;Founder's LinkedIn - Vijay Vasudevan&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/jngiam/"&gt;Founder's LinkedIn - Jiquan Ngiam&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://magicloops.dev/"&gt;Magic Loops&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Personal automations made easy&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://avatars.githubusercontent.com/u/134019091?s=200&amp;amp;v=4" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Content creation, Productivity, Build-your-own (agent-builing frameworks and platforms), SDK for AI apps, Art, Marketig, Sales, Finance, General purpose, Personal computing&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Magic Loops are the fastest way to automate (almost) anything. By combining generative AI with code, we make it easy for anyone (yes, even non-programmers!) to setup repeatable tasks and automated workflows.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://magicloops.dev/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/magicloops"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/magicloops/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/magicloopsdev"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/adam-williams-0995a949/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/jumploops"&gt;Founder's X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://makedraft.com/"&gt;Makedraft&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Generate + edit HTML components with text prompts&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1719412088492445696/qoVdGYth_400x400.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Productivity, Generating apps, Design, Content creation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Makedraft is an AI that generates frontend code based on your instructions. You can then copy the HTML to any project&lt;/li&gt; 
  &lt;li&gt;You can generate HTML templates with text prompts or highlight the code you want changed and instruct the AI on what to change&lt;/li&gt; 
  &lt;li&gt;Makedraft also generates Javascript, as well as Alpine.js. Vue.js is coming soon&lt;/li&gt; 
  &lt;li&gt;Makedraft will be introducing a Showcase for people to see Showcase projects. Makedraft is currently in open beta and is free to use. A Pro plan will be available soon. Users who subscribe to the Pro plan will have have their generated projects set to private by default&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://makedraft.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.makedraft.com/"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/makedraft"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@makedraft"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/realdavidma"&gt;Founder's X: David Ma&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/makedraft"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://manaflow.ai/"&gt;Manaflow&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Automate technical business workflows&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://bookface-images.s3.amazonaws.com/logos/5e452772f87fd93353d19538fd8f1c9f3ab9b6eb.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Coding, Workflow automation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Manaflow empowers non-technical teams to automate recurring workflows that require analyzing data, connecting APIs, and taking actions.&lt;/li&gt; 
  &lt;li&gt;Using English, you can train Manaflow agents to interface with multiple third-party apps concurrently, host custom-built APIs, conduct customer interviews, build persistent data dashboards, run custom ML models, and execute actions for your business.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://manaflow.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/manaflowai"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/manaflow-ai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.ycombinator.com/companies/manaflow"&gt;YCombinator&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://minion.ai/"&gt;Minion AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;By creator of GitHub Copilot, in waitlist stage&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://minion.ai/img/minion-1.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;By creator of GitHub Copilot, in waitlist stage&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/ai_minion"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/alexgraveley"&gt;Alex Graveley&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://multion.ai/"&gt;MultiOn&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Book a flight or order a burger with MultiOn&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1735699647744864256/jrKJWM78_400x400.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The agent runs and controls the local Google Chrome, which allows it to interact with the world/services/web apps, just like people interact with the world/services/web apps using Google Chrome&lt;/li&gt; 
  &lt;li&gt;The agent itself probably also runs locally and currently, it needs the local Google Chrome to function&lt;/li&gt; 
  &lt;li&gt;Our understanding from the demo video is that they use local code and a custom plugin in ChatGPT to control a web browser (e.g., Google Chrome). This setup enables MultiOn to perform tasks like ordering plane tickets as if a human were interacting with the browser directly&lt;/li&gt; 
  &lt;li&gt;Use cases 
   &lt;ul&gt; 
    &lt;li&gt;A lot of cool real use cases, e.g., -Sending an email fully autonomously -Posting a tweet -Sending a tweet reply to a specific person with a specific message -Sending a Facebook message to a friend -Searching for vacation rentals and check pricing for an upcoming trip -Searching for a wedding venue and starting the wedding planning process -Scheduling a car wash&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;After introducing the GPT function calling, MultiOn can call itself recursively to spawn more sub-agents&lt;/li&gt; 
  &lt;li&gt;Instead of calling multiple functions or APIs you just need one Universal Function that can interact with all services and have it call itself to accomplish more complex tasks in parallel&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/MultiON_AI"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Author: &lt;a href="https://twitter.com/DivGarg9"&gt;Div Garg&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://mutable.ai/"&gt;Mutable AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI-Accelerated Software Development&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://mutable.ai/Reverse-noMargin1000w-p-500.acf1588e.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Features 
   &lt;ul&gt; 
    &lt;li&gt;AI Autocomplete&lt;/li&gt; 
    &lt;li&gt;Production Quality Code with One Click&lt;/li&gt; 
    &lt;li&gt;Prompt driven development&lt;/li&gt; 
    &lt;li&gt;Test Generation (coming soon)&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/zAwadbmuVk"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/mutableai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/mutableai/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.naut.ai/"&gt;Naut&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build your own agents. In early stage&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1643093020097609730/XmHqIOhJ_400x400.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, Multi-agent&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;"Build your team of AI agents that work for you. Early access now live. Join waitlist."&lt;/p&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/naut_ai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://gpt.nexus/"&gt;NexusGPT&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build AI agents in minutes, without coding&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1784129822320467968/n_9UYcHR_400x400.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Technical challenges of building AI products, Business/marketing challenges of building AI products&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;NexusGPT enables anyone to build, finetune, and integrate autonomous AI agents without touching a single line of code.&lt;/li&gt; 
  &lt;li&gt;On Nexus, you can create agents able to perform about any task you can imagine and integrate them where it matters the most for you (from your website all the way to your internal Slack channel).&lt;/li&gt; 
  &lt;li&gt;To do that, nexus provides an existing marketplace of over 1000 ready-made agents as well as over 1500 tools ready to add to your agent.&lt;/li&gt; 
  &lt;li&gt;You can also add custom knowledge (from pdf, pptx, docx, website, notion, etc.) and add it as well to your own agent to make it relevant for your own use case and business.&lt;/li&gt; 
  &lt;li&gt;Finally, once you want to deploy your agent, you can do it simply directly on your website, WhatsApp, Slack, Teams, etc. in one click."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://gpt.nexus/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/nexus_gpt"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/nexusgpt/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.hyperwriteai.com/"&gt;Otherside's AI Assistant - Hyperwrite&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Chrome extension - general purpose AI agent&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/63fcd79d410b22ddf397e1b8/654272554402410a71c84ab9_6405c1cabdf9c69f05b1080e_otherside_logo_symbol.webp" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Hyperwrite is a chrome app that can take control of your browser and complete high level tasks for you.&lt;/li&gt; 
  &lt;li&gt;AI agent that can use a web browser like a human&lt;/li&gt; 
  &lt;li&gt;"Just describe what you want it to do, and it will automatically operate Chrome to achieve your task."&lt;/li&gt; 
  &lt;li&gt;Examples of use cases: Booking flights, ordering food, researching complex topics, managing your email&lt;/li&gt; 
  &lt;li&gt;Designed to handle tasks from booking flights to conducting in-depth research, and everything in between.&lt;/li&gt; 
  &lt;li&gt;Examples of usage: 
   &lt;ul&gt; 
    &lt;li&gt;Organize Gmail inbox&lt;/li&gt; 
    &lt;li&gt;Booking a flight&lt;/li&gt; 
    &lt;li&gt;Ordering online&lt;/li&gt; 
    &lt;li&gt;Finding hire candidates&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/mattshumer_/status/1673730806865358848"&gt;Launch announcement&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://chrome.google.com/webstore/detail/hyperwrite-ai-writing-com/kljjoeapehcmaphfcjkmbhkinoaopdnd"&gt;Google Chrome Extension&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://venturebeat.com/ai/hyperwrite-unveils-breakthrough-ai-agent-that-can-surf-the-web-like-a-human/"&gt;Article&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.phind.com/"&gt;Phind&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Personal programming and research AI assistant&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.phind.com/images/phind_v2.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, research&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Phind is an AI search engine and pair programmer&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.phind.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/S25yW8TebZ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/phindsearch"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;CEO's Twitter: &lt;a href="https://twitter.com/MichaelRoyzen"&gt;Michael Royzen&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://powerdrill.ai/"&gt;Powerdrill AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent that completes your data job 10x faster&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D4E0BAQGwWRCWd6izLg/company-logo_200_200/0/1686636701294?e=1726099200&amp;amp;v=beta&amp;amp;t=oFa1Z8ulQzNuasFcQBdrzZD8L1RJ_vjPhbbl4KXkN7g" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Data analysis, Productivity, Research, Marketig, Sales, Finance&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Powerdrill is an AI SaaS service centered around personal and enterprise datasets.&lt;/li&gt; 
  &lt;li&gt;Designed to unlock the full potential of your data, Powerdrill enables you to use natural language to effortlessly interact with your datasets for tasks ranging from simple Q&amp;amp;As to insightful BI analysis.&lt;/li&gt; 
  &lt;li&gt;By breaking down barriers to knowledge acquisition and data analysis, Powerdrill boosts data processing efficiency exponentially.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://powerdrill.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/powerdrillai"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://docs.powerdrill.ai/introduction"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://proficientai.com"&gt;Proficient AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Interaction APIs and SDKs for building AI agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.phind.com/images/phind_v2.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;An end-to-end solution, with which it takes 3 minutes not weeks to get a user-facing agent up and running in your app (currently 3 SDKs including React)&lt;/li&gt; 
  &lt;li&gt;Powerful tools built into the admin dashboard and Admin API including analytics, monitoring, rate-limiting, content moderation, etc.&lt;/li&gt; 
  &lt;li&gt;minimizes or eliminates the need for custom backend infrastructure so you can focus on implementing the business logic&lt;/li&gt; 
  &lt;li&gt;Technology-agnostic solution that supports multiple LLM providers (currently 7 models from OpenAI and Anthropic) allowing you to easily switch between models with 1 click&lt;/li&gt; 
  &lt;li&gt;Ready-to-use, highly customizable and beautiful UI components rendering complex interaction trees with support for advanced features like streaming&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://docs.proficientai.com"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/proficientai/js"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.gg/DVbwTM8erb"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.trypromptly.com/"&gt;Promptly&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Generative AI for Your Enterprise&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/64627565e0cbc380d04ed8ae/6488f9eb9992aa1dc3bc1a63_logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, no-code, web UI&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Build tailor-made generative AI agents, applications and chatbots that cater to your users' unique needs.&lt;/li&gt; 
  &lt;li&gt;Seamlessly integrate your own data and GPT-powered models without any coding experience.&lt;/li&gt; 
  &lt;li&gt;Promptly supports all major model providers, like OpenAI, Cohere, Stability AI, Hugging Face, and more. Easily use these models to build powerful apps.&lt;/li&gt; 
  &lt;li&gt;Promptly provides embeddable widgets that you can easily integrate into your website. Use these widgets to build conversational AI applications or to add a chatbot to your website.&lt;/li&gt; 
  &lt;li&gt;Import your own data and connect it to LLM models to supercharge your generative AI applications and chatbots. Promptly supports a wide variety of data sources, including Web URLs, Sitemaps, PDFs, Audio, PPTs, Google Drive, Notion imports etc&lt;/li&gt; 
  &lt;li&gt;LLMs/model providers supported 
   &lt;ul&gt; 
    &lt;li&gt;OpenAI&lt;/li&gt; 
    &lt;li&gt;Cohere&lt;/li&gt; 
    &lt;li&gt;Stability AI&lt;/li&gt; 
    &lt;li&gt;Hugging Face&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.trypromptly.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/trypromptly"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/trypromptly"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/3JsEzSXspJ"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/trypromptly/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@trypromptly"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://q-bot.suchica.com/"&gt;Q, ChatGPT for Slack&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI workforce on Slack for under-resourced SMEs&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://q-bot.suchica.com/_next/image?url=%2F_next%2Fstatic%2Fmedia%2FDALLE_2023-01-10_QRobot.86c0521b.png&amp;amp;w=256&amp;amp;q=75" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Personal assistant, Business intelligence, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Q functions like ChatGPT, but within your workspace.&lt;/li&gt; 
  &lt;li&gt;Secure and shareable, Q won't store or learn your data.&lt;/li&gt; 
  &lt;li&gt;Unlike ChatGPT, Q can read various types of URLs and files on-demand with your input.&lt;/li&gt; 
  &lt;li&gt;Ideal for summarizing, evaluating, brainstorming ideas, self-reviewing, Q&amp;amp;A, and more.&lt;/li&gt; 
  &lt;li&gt;We also support URLs that require authentication, such as Google Workspace Apps.&lt;/li&gt; 
  &lt;li&gt;Itemize your team-specific rules, guidelines, and templates.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://q-bot.suchica.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/hiroshinishio"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/suchica/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/QBotGPT"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/@q-aibot-2182/videos"&gt;YouTube&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/hiroshi-nishio-084595216/"&gt;Founder's LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/hnishio0105"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://questflow.ai"&gt;Questflow&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Marketplace for autonomous AI workers with no-code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.aitoolsclub.com/content/images/2023/07/Screenshot-2023-07-26-184451.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Questflow is a marketplace designed for SMBs to connect with autonomous AI workers.&lt;/li&gt; 
  &lt;li&gt;Our platform enables digital workers to discover and deploy AI agents for seamless workflow automation.&lt;/li&gt; 
  &lt;li&gt;With a no-code editor, we empower digital knowledge providers to create, distribute, and monetize AI workers.&lt;/li&gt; 
  &lt;li&gt;Similar to Upwork, Questflow offers a marketplace where users can utilize AI agents to accomplish tasks across various digital workspaces.&lt;/li&gt; 
  &lt;li&gt;Creators have the opportunity to transform their specialized knowledge into AI agents, expanding their reach and generating revenue.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/questflow"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://t.me/+lAFNg26e5aA5NGNl"&gt;Telegram&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/questflow"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://rebyte.ai/"&gt;Rebyte&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;A Multi ai agents builder platform&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1700140660702257152/xTLqugBI_400x400.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Generating apps, Build-your-own&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;A Multi ai agents builder platform built for GenAI applications.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://rebyte.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/ReByteAI"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/e4AYNnFg2F"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/realchar/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/jian-cai-8611094/"&gt;Founder's LinkedIn - Jian cai&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://www.linkedin.com/in/shaunwei/"&gt;Founder's LinkedIn - Xiao(Shaun) W.&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://relevanceai.com/"&gt;Relevance AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build your AI Workforce&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://mintlify.s3-us-west-1.amazonaws.com/relevanceai/images/logo/dark.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Content creation, Productivity, Research, Build-your-own (agent-builing frameworks and platforms), Marketig, Sales, General purpose, Multi-agent, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Relevance AI is a fast platform to build and deploy AI apps &amp;amp; agents. It's the home of the AI Workforce.&lt;/li&gt; 
  &lt;li&gt;AI Workforce is a digital team you can hire to assist you in completing mundane and repetitive tasks.&lt;/li&gt; 
  &lt;li&gt;An AI Workforce consists of Agents equipped with Tools specific to your business operations crafted by domain experts.&lt;/li&gt; 
  &lt;li&gt;With Relevance, you will have the home of the AI Workforce with a single platform to create your Tools, equip them to Agents and deploy it to your organisation as a Multi-Agent System (MAS).&lt;/li&gt; 
  &lt;li&gt;Relevance supports OpenAI, Anthropic, Cohere, PaLM, and more.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://relevanceai.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/RelevanceAI"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/RelevanceAI_"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/relevanceai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/JackyGKoh"&gt;Jacky Koh - X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/thedanvass"&gt;Daniel Vassilev - X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://saga.so/ai"&gt;Saga&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Digital AI assistant for notes, tasks, and tools&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://uploads-ssl.webflow.com/600abb9dfd0530004ee876c0/62bd6a08f11f1f89bb1d1170_saga-logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Content creation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Generating content&lt;/li&gt; 
  &lt;li&gt;Brainstorming ideas&lt;/li&gt; 
  &lt;li&gt;Translation&lt;/li&gt; 
  &lt;li&gt;Grammer check&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://sagahq.canny.io/"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/saga_hq"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://sagacommunity.slack.com/join/shared_invite/zt-13m3lrrdt-1x6~l6sLuR8CX~4c3fWwHA#/shared-invite/email"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/cgz2mUEq7P"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.second.dev/"&gt;Second&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Automated migrations and upgrades for your code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/63717dfd25366f06c3ed64cc/645dcdc2d70f00fded6f6c0b_second-logo-white.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Migrate frameworks such as Angular to React, libraries such as Redux to React Context, or languages such as JavaScript to TypeScript&lt;/li&gt; 
  &lt;li&gt;Perform major version upgrades on any number of applications, of any size&lt;/li&gt; 
  &lt;li&gt;Upgrade frameworks such as Next.js 12 to 13, libraries such as MUI 4 to 5, or languages such as Python 2 to 3&lt;/li&gt; 
  &lt;li&gt;Target users: enterprise codebases&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://second.canny.io/"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.ycombinator.com/companies/second"&gt;YCombinator&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/SecondDevHQ"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/secondhq/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://discord.com/invite/ZhYUEjsW3Z"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder: &lt;a href="https://twitter.com/ericdrowell"&gt;Eric Rowell&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.sentius.ai/"&gt;Sentius&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Agent operates browser to do your tasks for you&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://assets-global.website-files.com/65322c702cb29c000a4d7f49/65323973bde43d64e5b01d0f_logo.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose, Multi-agent, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Autonomous Agents for the Enterprise&lt;/li&gt; 
  &lt;li&gt;Sentius's high-load Autonomous Agents platform runs inside the company's secure perimeter, either in cloud or on-premises, and enables safe creation, deployment, and management of Enterprise Autonomous Agents&lt;/li&gt; 
  &lt;li&gt;Sentius provides an integrated suite of no-code development tools to build, test, deploy, and manage Autonomous Agents inside your organization&lt;/li&gt; 
  &lt;li&gt;Sentius offers robust and efficient Autonomous Agents for critical use cases tailored to your organization's specific needs&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.sentius.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Generative-Assistants/"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/sentiusai/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=amjFOO_v28Q&amp;amp;ab_channel=DanielKornev"&gt;YouTube Demo&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/sentiusai"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Team LinkedIn profiles: &lt;a href="https://www.linkedin.com/in/eugene-izhikevich/"&gt;1&lt;/a&gt;, &lt;a href="https://www.linkedin.com/in/dilyara-zharikova/"&gt;2&lt;/a&gt;, &lt;a href="https://www.linkedin.com/in/mikhail-burtsev-85a47b9/"&gt;3&lt;/a&gt;, &lt;a href="https://www.linkedin.com/in/danielkornev/"&gt;4&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://shoppal.ai"&gt;ShopPal&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI assistant, enhance shopping experience.&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://pbs.twimg.com/profile_images/1777239533094150144/a28xyvug_400x400.jpg" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Research, Ecommerce&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"ğŸ›ï¸ShopPal: Your Curated AI Shopping AssistantğŸ¥‚ğŸ’°ğŸ’³&lt;/li&gt; 
  &lt;li&gt;Curated AI shopping assistant, aiming to enhance and accompany your shopping experience.&lt;/li&gt; 
  &lt;li&gt;To enhance and accompany your shopping experience, ShopPal delivers summary insights, tailored recommendations, visual comparisons, and the best deals, which are all personalized just for you! "&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://shoppal.ai"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://spell.so/"&gt;Spell&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AutoGPT agents with plugins&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://spell.so/_next/static/media/logo.32731dee.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"Delegate your tasks to autonomous AI agents. Transform your daily work with revolutionary and intuitive AI tools powered by GPT4"&lt;/li&gt; 
  &lt;li&gt;Access APIs like Zapier, Wolfram, etc.&lt;/li&gt; 
  &lt;li&gt;Open links&lt;/li&gt; 
  &lt;li&gt;Manipulate files&lt;/li&gt; 
  &lt;li&gt;Search web&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/rafal_makes"&gt;Author's Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://superluminal.dev"&gt;Superluminal&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI copilot to your product's data dashboard&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://superluminal.dev/176fae26858de1966f98.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Get set up in minutes with the Superluminal React component, or use the API directly for custom solutions.&lt;/li&gt; 
  &lt;li&gt;Writes Python code to answer questions and perform tasks, similar to ChatGPT + CodeInterpreter.&lt;/li&gt; 
  &lt;li&gt;Fully managed compute infrastructure for the secure execution of generated code.&lt;/li&gt; 
  &lt;li&gt;Customize the look and feel to fit your product.&lt;/li&gt; 
  &lt;li&gt;Full support for graphs, pivots and filters in addition to textual answers.&lt;/li&gt; 
  &lt;li&gt;Enable your customers to extract more value from the data already on their dashboard with meaningful answers to high-level questions.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/getluminal/"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/74930600/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://talktodata.ai/"&gt;TalktoData&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Data discovery, cleaing, analysis &amp;amp; visualization&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://talktodata.ai/hubfs/logo-transparant-04-1.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI Data Analyst that works with your CSV, Excel, Goolge Sheets and SQL Databases&lt;/li&gt; 
  &lt;li&gt;AI Agent for all the data analytics needs&lt;/li&gt; 
  &lt;li&gt;Allows users to generate beautiful visualizations, followup question and refine requirements&lt;/li&gt; 
  &lt;li&gt;"ChatGPT for Data Analysis"&lt;/li&gt; 
  &lt;li&gt;A Data Analyst the never sleeps and always available(A chat away)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://talktodata.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/TalktoData"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/talktodata/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Team Twitter profiles: &lt;a href="https://twitter.com/vinodvarma24"&gt;Vinod Varma&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.taskade.com/"&gt;Taskade&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Create, train, and run custom AI agents&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://www.taskade.com/static_images/taskade-circle-logo-full-black.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, General purpose, Productivity&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;AI Agent for custom tasks, automation, and workflows&lt;/li&gt; 
  &lt;li&gt;AI Generator for flowcharts, mind mapping, task management&lt;/li&gt; 
  &lt;li&gt;AI Chat Assistant and Media Q&amp;amp;A with projects, docs, and more&lt;/li&gt; 
  &lt;li&gt;Custom AI Agents: Craft AI agents with custom commands, tools, and knowledge to automate tasks&lt;/li&gt; 
  &lt;li&gt;Engage with projects and documents through a dynamic AI Chat Assistant, providing media Q&amp;amp;A and contextual support.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://taskade.com/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/taskade"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/taskade/"&gt;Linkedin&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Team Twitter profiles: &lt;a href="https://twitter.com/johnxie"&gt;John Xie&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.thinkchain.ai/"&gt;ThinkChain AI&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Financial AI agent platform&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D4E0BAQGc0T7tqN-IZQ/company-logo_200_200/0/1688338143903?e=2147483647&amp;amp;v=beta&amp;amp;t=bwM2YckiHgvHaMtmYQjB6XGUT5FNtUbvFNHJvepsGu4" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Finance, Data analysis&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ThinkChain provides a large and growing set of advanced AI agents, e.g. 
   &lt;ul&gt; 
    &lt;li&gt;Discover agent - can access search and your Knowledge base for informed answers&lt;/li&gt; 
    &lt;li&gt;Chain of Thought agent - breaks questions into parts to be addressed independently&lt;/li&gt; 
    &lt;li&gt;Analyst agent - creates realtime financial analysis, from DCF to LBO and everything in between&lt;/li&gt; 
    &lt;li&gt;Auto Agent - can create an entire workflow from scratch&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Currently in an early access version&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.thinkchain.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;Founder: &lt;a href="https://twitter.com/_tony_lewis"&gt;Tony Lewis&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://testdriver.ai/"&gt;Test Driver&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI Agent for QA in GitHub&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://framerusercontent.com/images/in0q3dhCrmymGzApkC4KBzdpcE.png?scale-down-to=512" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding, Productivity, Debugging, Testing&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"No more writing automated tests or waiting on manual testing.&lt;/li&gt; 
  &lt;li&gt;Instruct @testdriverai to test any PR with natural language.&lt;/li&gt; 
  &lt;li&gt;TestDriver will perform a test on your PR and send back video and log recording of what occurred."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://testdriver.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/sunglassesface"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/adam-eldefrawy-8623a815a/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://usetusk.ai/"&gt;Tusk&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI engineer that pushes and tests code&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://usetusk.ai/tusk-logo.eed7968a.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Tusk is an AI engineer that helps product managers ship simple front-end changes fast, letting their software engineers focus on more important work&lt;/li&gt; 
  &lt;li&gt;Assign a product ticket to Tusk, and let our AI write, push, and test the code for you&lt;/li&gt; 
  &lt;li&gt;Use-cases: Coding, debugging, code migration etc.&lt;/li&gt; 
  &lt;li&gt;Tusk is a &lt;a href="https://www.ycombinator.com/companies/tusk"&gt;Y-combinator company&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://usetusk.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/apps/use-tusk"&gt;GitHub&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/usetusk"&gt;X &lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/usetusk/about/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/sohilkshirsagar"&gt;Founder's X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/Marcel7an"&gt;Founder's X 2&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.vortic.ai/"&gt;Vortic&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;AI agent helping Insurance Sales and Claims&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D560BAQEG1EZ0w5b_pw/company-logo_200_200/0/1710090819045/vortic_ai_logo?e=2147483647&amp;amp;v=beta&amp;amp;t=cNHAuR0hBAAO_LAhV9iNj0Ha3s8gkQkl1esp3i1RGD4" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Productivity, Build-your-own (agent-builing frameworks and platforms), Sales, General purpose, Multi-agent, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Vortic wants to make it easy for the enterprises to embed the agents with the real purpose business outcomes.&lt;/li&gt; 
  &lt;li&gt;Vortic aims to provide the real time value realisation with the pre built agents embedding with their ecosystem providing customised toolkits.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.vortic.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/harshnagalla/"&gt;Co-founder's LinkedIn 1&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/divyajot-singh-06b78559/"&gt;Co-founder's LinkedIn 2&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://v0.dev/"&gt;v0 by Vercel&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Get React code based on Shadcn UI &amp;amp; Tailwind CSS&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://ph-files.imgix.net/2c7b17e3-7a6d-4872-ab81-471803a924ce.png?auto=format" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Coding&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;v0 is a generative user interface system by Vercel Labs powered by AI. It generates copy-and-paste friendly React code based on Shadcn UI and Tailwind CSS.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Currently in waitlist stage&lt;/li&gt; 
  &lt;li&gt;v0 generates custom components on the fly that you can copy and paste into your existing codebase&lt;/li&gt; 
  &lt;li&gt;Built on NextJS App Router&lt;/li&gt; 
  &lt;li&gt;AI by the Vercel &lt;code&gt;ai&lt;/code&gt; SDK&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://v0.dev/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/rauchg/status/1702353417375826303?s=20"&gt;X post&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://wispy.technicalmagic.ai/"&gt;Wispy&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Summarize content, compose content, create quizzes&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://wispy.technicalmagic.ai/assets/icon-white.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Research, content creation&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;p&gt;Wispy is a web-browsing AI assistant that can summarize content, compose content, explain things or create quizzes for topics you are learning&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Wispy is stil in Beta version&lt;/li&gt; 
  &lt;li&gt;With Wispy, you can effortlessly transform web content to perfectly suit your unique needs, all without leaving the comfort of your browser&lt;/li&gt; 
  &lt;li&gt;Chat-based AI like Llama and GPT-4 are not the only ways to incorporate AI into your life&lt;/li&gt; 
  &lt;li&gt;With Wispy, go beyond chatbots with a browser-native AI companion that makes your browsing more delightful, productive, and streamlined!&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://wispy.technicalmagic.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://chrome.google.com/webstore/detail/wispy-your-personalized-a/nbljfchpacfegmmmajcneihieeglpofc"&gt;Chrome extension&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://www.wordware.ai/"&gt;Wordware&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Build better language model apps, fast.&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://media.licdn.com/dms/image/D4D0BAQFwJFfvXQ7j4A/company-logo_200_200/0/1693909474889/wordware_logo?e=1714003200&amp;amp;v=beta&amp;amp;t=65DGJQN1bRfjKhVmkWwH393y1_1L7ej8qd6yGYtmdpM" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, Supports open-source models&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Wordware is your all-in-one platform for deploying LLM applications.&lt;/li&gt; 
  &lt;li&gt;LLMs/model providers supported 
   &lt;ul&gt; 
    &lt;li&gt;GPT-3.5&lt;/li&gt; 
    &lt;li&gt;GPT-4 Turbo&lt;/li&gt; 
    &lt;li&gt;GPT-4&lt;/li&gt; 
    &lt;li&gt;GPT-4 Vision&lt;/li&gt; 
    &lt;li&gt;MISTRAL&lt;/li&gt; 
    &lt;li&gt;MIXTRAL&lt;/li&gt; 
    &lt;li&gt;Claude instant&lt;/li&gt; 
    &lt;li&gt;Claude 2&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://x.com/bertie_ai/status/1734539295187214423?s=20"&gt;Post on X about supported models&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://www.wordware.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://twitter.com/wordware_ai"&gt;X&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/wordware/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/filipkozera/"&gt;Filip Kozera - founder at Wordware&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://workhub.ai/"&gt;WorkBot&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;The Only AI Platform you will ever need!&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://workhub.ai/wp-content/uploads/2023/05/workhub-logo-horizontal.png" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Science, Productivity, Business intelligence&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;"A privacy-centric Conversational AI platform leveraging AI Agents, Commercial and Opensource LLM support to centralize knowledge, thereby enriching collaboration and facilitating streamlined automation.&lt;/li&gt; 
  &lt;li&gt;WorkHub empowers users with versatile conversational bots and tools that provide insights, knowledge, and data-driven actions.&lt;/li&gt; 
  &lt;li&gt;With seamless integration capabilities, Workhub can be connected to any database and applications, ensuring comprehensive access to information."&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://workhub.ai/"&gt;Web&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.linkedin.com/company/workhub-official/"&gt;LinkedIn&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://x.com/WorkHubOfficiaI"&gt;X (Twitter)&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;a href="https://zapier.com/central"&gt;Zapier Central&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Work hand in hand with AI bots&lt;/p&gt; 
&lt;details&gt; 
 &lt;p&gt;&lt;img src="https://bot-templates-dbuh9gyx1.vercel.zapier-deployment.com/_next/static/media/logo-color.9fac53e4.svg?sanitize=true" alt="image" /&gt;&lt;/p&gt; 
 &lt;h3&gt;Category&lt;/h3&gt; 
 &lt;p&gt;Build-your-own, Productivity, General purpose&lt;/p&gt; 
 &lt;h3&gt;Description&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Zapier Central is an experimental AI workspace where you can teach bots to work across 6,000+ apps.&lt;/li&gt; 
  &lt;li&gt;Features: 
   &lt;ul&gt; 
    &lt;li&gt;Give your bot access to your company's source of truth to get instant answers.&lt;/li&gt; 
    &lt;li&gt;Ask bots to act in 6,000+ apps&lt;/li&gt; 
    &lt;li&gt;Central runs on Zapier's ecosystem to help you automate the tools you already use.&lt;/li&gt; 
    &lt;li&gt;Teach your bot once, then watch it workâ€”even when you're not around.&lt;/li&gt; 
    &lt;li&gt;Everything in one workspace&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;Links&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://zapier.com/central"&gt;Web&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;span&gt;âœ´&lt;/span&gt; AI apps &amp;amp; agents with sandbox integration or native support&lt;/h2&gt; 
&lt;h3&gt;&lt;span&gt;âœ´&lt;/span&gt; &lt;a href="https://www.superagent.sh/"&gt;Superagent&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;p&gt;Superagent uses E2B as a &lt;a href="https://x.com/pelaseyed/status/1709592941226831916?s=20"&gt;code execution tool&lt;/a&gt;. To try Superagent with E2B, create a Code interpreter API and then select it for your agent to use.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;span&gt;âœ´&lt;/span&gt; &lt;a href="https://e2b.dev/docs/llm-platforms/openai/"&gt;OpenAI's Assistants&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;p&gt;You can define actions for your AI assistant and E2B will automatically execute them inside a sandbox. This allows you to create powerful AI assistants with custom tools completely predefined by you. To &lt;a href="https://e2b.dev/docs/llm-platforms/openai"&gt;try the OpenAI Assistants with E2B&lt;/a&gt;, you can follow our guide in &lt;a href="https://e2b.dev/docs/llm-platforms/openai#python"&gt;Python&lt;/a&gt; or &lt;a href="https://e2b.dev/docs/llm-platforms/openai#java-script"&gt;JavaScript&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;span&gt;âœ´&lt;/span&gt; &lt;a href="https://python.langchain.com/docs/integrations/tools/e2b_data_analysis"&gt;Langchain Data Analyst&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;p&gt;E2B Data Analysis sandbox &lt;a href="https://python.langchain.com/docs/integrations/tools/e2b_data_analysis"&gt;integrated into Langchain&lt;/a&gt; allows you to:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Run Python code&lt;/li&gt; 
  &lt;li&gt;Generate charts via matplotlib&lt;/li&gt; 
  &lt;li&gt;Install Python packages dynamically during runtime&lt;/li&gt; 
  &lt;li&gt;Install system packages dynamically during runtime&lt;/li&gt; 
  &lt;li&gt;Run shell commands&lt;/li&gt; 
  &lt;li&gt;Upload and download files. See also a guide &lt;a href="https://e2b.dev/blog/build-ai-data-analyst-with-langchain-and-e2b"&gt;here&lt;/a&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Want to use E2B with your AI product?&lt;/h2&gt; 
&lt;p&gt;Contact us at &lt;a href="mailto:hello@e2b.dev"&gt;hello@e2b.dev&lt;/a&gt; or &lt;a href="https://discord.gg/35NF4Y8WSE"&gt;on discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We are open-source and you can get started with E2B &lt;a href="https://e2b.dev/docs?ref=awesome-sdks"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;!-- 
&lt;img src="/assets/footer.png" width="100%" alt="SDKs Repo Visual" /&gt;
--&gt; 
&lt;h2&gt;Join the community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow us on &lt;a href="https://twitter.com/e2b"&gt;X &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/35NF4Y8WSE"&gt;Hit us up on discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Feel free to reach out to us at &lt;a href="mailto:hello@e2b.dev"&gt;hello@e2b.dev&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- 
&lt;a href="https://discord.gg/U7KEcGErtQ" target="_blank"&gt;
	&lt;img src="https://img.shields.io/static/v1?label=Join&amp;message=%20discord!&amp;color=mediumslateblue"&gt;
&lt;/a&gt;
&lt;a href="https://twitter.com/e2b" target="_blank"&gt;
	&lt;img src="https://img.shields.io/twitter/follow/e2b.svg?logo=twitter"&gt;
&lt;/a&gt;
--&gt; 
&lt;!-- More agents to add in the future

- GPTeam https://twitter.com/itstimconnors/status/1672278464362336256
- https://github.com/101dotxyz/GPTeam

- Neurite https://github.com/satellitecomponent/Neurite

- AutoGPT.js https://github.com/zabirauf/AutoGPT.js

- Street Fighter https://github.com/linyiLYi/street-fighter-ai

- GPT RPG https://github.com/dzoba/gptrpg

- Autopilot https://github.com/fjrdomingues/autopilot

- WinGPT - AI assistant for Windows https://news.ycombinator.com/item?id=36472854



--&gt;</description>
    </item>
    
  </channel>
</rss>