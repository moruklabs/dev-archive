<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Mon, 05 Jan 2026 01:39:36 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>usememos/memos</title>
      <link>https://github.com/usememos/memos</link>
      <description>&lt;p&gt;An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Memos&lt;/h1&gt; 
&lt;img align="right" height="96px" src="https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/logo-rounded.png" alt="Memos" /&gt; 
&lt;p&gt;An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://usememos.com"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%8F%A0-usememos.com-blue?style=flat-square" alt="Home" /&gt;&lt;/a&gt; &lt;a href="https://demo.usememos.com/"&gt;&lt;img src="https://img.shields.io/badge/%E2%9C%A8-Try%20Demo-orange?style=flat-square" alt="Live Demo" /&gt;&lt;/a&gt; &lt;a href="https://usememos.com/docs"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%93%9A-Documentation-green?style=flat-square" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/tfPJa4UmAv"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%92%AC-Discord-5865f2?style=flat-square&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/neosmemo/memos"&gt;&lt;img src="https://img.shields.io/docker/pulls/neosmemo/memos?style=flat-square&amp;amp;logo=docker" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/demo.png" alt="Memos Demo Screenshot" height="512" /&gt; 
&lt;h3&gt;üíé Featured Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://go.warp.dev/memos"&gt;&lt;strong&gt;Warp&lt;/strong&gt; ‚Äî The AI-powered terminal built for speed and collaboration&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://go.warp.dev/memos" target="_blank" rel="noopener"&gt; &lt;img src="https://raw.githubusercontent.com/warpdotdev/brand-assets/main/Github/Sponsor/Warp-Github-LG-02.png" alt="Warp - The AI-powered terminal built for speed and collaboration" width="512" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://www.lambdatest.com/?utm_source=memos&amp;amp;utm_medium=sponsor"&gt;&lt;strong&gt;LambdaTest&lt;/strong&gt; - Cross-browser testing cloud&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://www.lambdatest.com/?utm_source=memos&amp;amp;utm_medium=sponsor" target="_blank" rel="noopener"&gt; &lt;img src="https://www.lambdatest.com/blue-logo.png" alt="LambdaTest - Cross-browser testing cloud" height="50" /&gt; &lt;/a&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Memos is a privacy-first, self-hosted knowledge base that works seamlessly for personal notes, team wikis, and knowledge management. Built with Go and React, it offers lightning-fast performance without compromising on features or usability.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why choose Memos over cloud services?&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Memos&lt;/th&gt; 
   &lt;th&gt;Cloud Services&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Privacy&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Self-hosted, zero telemetry&lt;/td&gt; 
   &lt;td&gt;‚ùå Your data on their servers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Free forever, MIT license&lt;/td&gt; 
   &lt;td&gt;‚ùå Subscription fees&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Performance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Instant load, no latency&lt;/td&gt; 
   &lt;td&gt;‚ö†Ô∏è Depends on internet&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ownership&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Full control &amp;amp; export&lt;/td&gt; 
   &lt;td&gt;‚ùå Vendor lock-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Access&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Full REST + gRPC APIs&lt;/td&gt; 
   &lt;td&gt;‚ö†Ô∏è Limited or paid&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Open source, forkable&lt;/td&gt; 
   &lt;td&gt;‚ùå Closed ecosystem&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîí Privacy-First Architecture&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Self-hosted on your infrastructure with zero telemetry&lt;/li&gt; 
   &lt;li&gt;Complete data ownership and export capabilities&lt;/li&gt; 
   &lt;li&gt;No tracking, no ads, no vendor lock-in&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìù Markdown Native&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full markdown support&lt;/li&gt; 
   &lt;li&gt;Plain text storage ‚Äî take your data anywhere&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° Blazing Fast&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Built with Go backend and React frontend&lt;/li&gt; 
   &lt;li&gt;Optimized for performance at any scale&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üê≥ Simple Deployment&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;One-line Docker installation&lt;/li&gt; 
   &lt;li&gt;Supports SQLite, MySQL, and PostgreSQL&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Developer-Friendly&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full REST and gRPC APIs&lt;/li&gt; 
   &lt;li&gt;Easy integration with existing workflows&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üé® Beautiful Interface&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Clean, minimal design and dark mode support&lt;/li&gt; 
   &lt;li&gt;Mobile-responsive layout&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Docker (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name memos \
  -p 5230:5230 \
  -v ~/.memos:/var/opt/memos \
  neosmemo/memos:stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;code&gt;http://localhost:5230&lt;/code&gt; and start writing!&lt;/p&gt; 
&lt;h3&gt;Try the Live Demo&lt;/h3&gt; 
&lt;p&gt;Don't want to install yet? Try our &lt;a href="https://demo.usememos.com/"&gt;live demo&lt;/a&gt; first!&lt;/p&gt; 
&lt;h3&gt;Other Installation Methods&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt; - Recommended for production deployments&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-built Binaries&lt;/strong&gt; - Available for Linux, macOS, and Windows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt; - Helm charts and manifests available&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build from Source&lt;/strong&gt; - For development and customization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See our &lt;a href="https://usememos.com/docs/installation"&gt;installation guide&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of all kinds! Whether you're fixing bugs, adding features, improving documentation, or helping with translations ‚Äî every contribution matters.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Ways to contribute:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/usememos/memos/issues/new?template=bug_report.md"&gt;Report bugs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° &lt;a href="https://github.com/usememos/memos/issues/new?template=feature_request.md"&gt;Suggest features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîß &lt;a href="https://github.com/usememos/memos/pulls"&gt;Submit pull requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://github.com/usememos/memos/tree/main/docs"&gt;Improve documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üåç &lt;a href="https://github.com/usememos/memos/tree/main/web/src/locales"&gt;Help with translations&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Love Memos? &lt;a href="https://github.com/sponsors/usememos"&gt;Sponsor us on GitHub&lt;/a&gt; to help keep the project growing!&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#usememos/memos&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=usememos/memos&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Memos is open-source software licensed under the &lt;a href="https://raw.githubusercontent.com/usememos/memos/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Privacy Policy&lt;/h2&gt; 
&lt;p&gt;Memos is built with privacy as a core principle. As a self-hosted application, all your data stays on your infrastructure. There is no telemetry, no tracking, and no data collection. See our &lt;a href="https://usememos.com/privacy"&gt;Privacy Policy&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://usememos.com"&gt;Website&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://usememos.com/docs"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://demo.usememos.com/"&gt;Demo&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://discord.gg/tfPJa4UmAv"&gt;Discord&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://x.com/usememos"&gt;X/Twitter&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;a href="https://vercel.com/oss"&gt; &lt;img alt="Vercel OSS Program" src="https://vercel.com/oss/program-badge.svg?sanitize=true" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>resemble-ai/chatterbox</title>
      <link>https://github.com/resemble-ai/chatterbox</link>
      <description>&lt;p&gt;SoTA open-source TTS&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/Chatterbox-Turbo.jpg" alt="Chatterbox Turbo Image" /&gt;&lt;/p&gt; 
&lt;h1&gt;Chatterbox TTS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_turbo_demopage/"&gt;&lt;img src="https://img.shields.io/badge/listen-demo_samples-blue" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo"&gt;&lt;img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm.svg?sanitize=true" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://podonos.com/resembleai/chatterbox"&gt;&lt;img src="https://static-public.podonos.com/badges/insight-on-pdns-sm-dark.svg?sanitize=true" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;&lt;img src="https://img.shields.io/discord/1377773249798344776?label=join%20discord&amp;amp;logo=discord&amp;amp;style=flat" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;_Made with ‚ô•Ô∏è by &lt;a href="https://resemble.ai" target="_blank"&gt;&lt;img width="100" alt="resemble-logo-horizontal" src="https://github.com/user-attachments/assets/35cf756b-3506-4943-9c72-c05ddfa4e525" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Chatterbox&lt;/strong&gt; is a family of three state-of-the-art, open-source text-to-speech models by Resemble AI.&lt;/p&gt; 
&lt;p&gt;We are excited to introduce &lt;strong&gt;Chatterbox-Turbo&lt;/strong&gt;, our most efficient model yet. Built on a streamlined 350M parameter architecture, &lt;strong&gt;Turbo&lt;/strong&gt; delivers high-quality speech with less compute and VRAM than our previous models. We have also distilled the speech-token-to-mel decoder, previously a bottleneck, reducing generation from 10 steps to just &lt;strong&gt;one&lt;/strong&gt;, while retaining high-fidelity audio output.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Paralinguistic tags&lt;/strong&gt; are now native to the Turbo model, allowing you to use &lt;code&gt;[cough]&lt;/code&gt;, &lt;code&gt;[laugh]&lt;/code&gt;, &lt;code&gt;[chuckle]&lt;/code&gt;, and more to add distinct realism. While Turbo was built primarily for low-latency voice agents, it excels at narration and creative workflows.&lt;/p&gt; 
&lt;p&gt;If you like the model but need to scale or tune it for higher accuracy, check out our competitively priced TTS service (&lt;a href="https://resemble.ai"&gt;link&lt;/a&gt;). It delivers reliable performance with ultra-low latency of sub 200ms‚Äîideal for production use in agents, applications, or interactive media.&lt;/p&gt; 
&lt;img width="1200" height="600" alt="Podonos Turbo Eval" src="https://storage.googleapis.com/chatterbox-demo-samples/turbo/podonos_turbo.png" /&gt; 
&lt;h3&gt;‚ö° Model Zoo&lt;/h3&gt; 
&lt;p&gt;Choose the right model for your application.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Model&lt;/th&gt; 
   &lt;th align="left"&gt;Size&lt;/th&gt; 
   &lt;th align="left"&gt;Languages&lt;/th&gt; 
   &lt;th align="left"&gt;Key Features&lt;/th&gt; 
   &lt;th align="left"&gt;Best For&lt;/th&gt; 
   &lt;th align="left"&gt;ü§ó&lt;/th&gt; 
   &lt;th align="left"&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Chatterbox-Turbo&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;350M&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Paralinguistic Tags (&lt;code&gt;[laugh]&lt;/code&gt;), Lower Compute and VRAM&lt;/td&gt; 
   &lt;td align="left"&gt;Zero-shot voice agents, Production&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_turbo_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Chatterbox-Multilingual &lt;a href="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/#supported-languages"&gt;(Language list)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;500M&lt;/td&gt; 
   &lt;td align="left"&gt;23+&lt;/td&gt; 
   &lt;td align="left"&gt;Zero-shot cloning, Multiple Languages&lt;/td&gt; 
   &lt;td align="left"&gt;Global applications, Localization&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox-Multilingual-TTS"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Chatterbox &lt;a href="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/#original-chatterbox-tips"&gt;(Tips and Tricks)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;500M&lt;/td&gt; 
   &lt;td align="left"&gt;English&lt;/td&gt; 
   &lt;td align="left"&gt;CFG &amp;amp; Exaggeration tuning&lt;/td&gt; 
   &lt;td align="left"&gt;General zero-shot TTS with creative controls&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install chatterbox-tts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can install from source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# conda create -yn chatterbox python=3.11
# conda activate chatterbox

git clone https://github.com/resemble-ai/chatterbox.git
cd chatterbox
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We developed and tested Chatterbox on Python 3.11 on Debian 11 OS; the versions of the dependencies are pinned in &lt;code&gt;pyproject.toml&lt;/code&gt; to ensure consistency. You can modify the code or dependencies in this installation mode.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h5&gt;Chatterbox-Turbo&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torchaudio as ta
import torch
from chatterbox.tts_turbo import ChatterboxTurboTTS

# Load the Turbo model
model = ChatterboxTurboTTS.from_pretrained(device="cuda")

# Generate with Paralinguistic Tags
text = "Hi there, Sarah here from MochaFone calling you back [chuckle], have you got one minute to chat about the billing issue?"

# Generate audio (requires a reference clip for voice cloning)
wav = model.generate(text, audio_prompt_path="your_10s_ref_clip.wav")

ta.save("test-turbo.wav", wav, model.sr)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Chatterbox and Chatterbox-Multilingual&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
from chatterbox.mtl_tts import ChatterboxMultilingualTTS

# English example
model = ChatterboxTTS.from_pretrained(device="cuda")

text = "Ezreal and Jinx teamed up with Ahri, Yasuo, and Teemo to take down the enemy's Nexus in an epic late-game pentakill."
wav = model.generate(text)
ta.save("test-english.wav", wav, model.sr)

# Multilingual examples
multilingual_model = ChatterboxMultilingualTTS.from_pretrained(device=device)

french_text = "Bonjour, comment √ßa va? Ceci est le mod√®le de synth√®se vocale multilingue Chatterbox, il prend en charge 23 langues."
wav_french = multilingual_model.generate(spanish_text, language_id="fr")
ta.save("test-french.wav", wav_french, model.sr)

chinese_text = "‰Ω†Â•ΩÔºå‰ªäÂ§©Â§©Ê∞îÁúü‰∏çÈîôÔºåÂ∏åÊúõ‰Ω†Êúâ‰∏Ä‰∏™ÊÑâÂø´ÁöÑÂë®Êú´„ÄÇ"
wav_chinese = multilingual_model.generate(chinese_text, language_id="zh")
ta.save("test-chinese.wav", wav_chinese, model.sr)

# If you want to synthesize with a different voice, specify the audio prompt
AUDIO_PROMPT_PATH = "YOUR_FILE.wav"
wav = model.generate(text, audio_prompt_path=AUDIO_PROMPT_PATH)
ta.save("test-2.wav", wav, model.sr)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;code&gt;example_tts.py&lt;/code&gt; and &lt;code&gt;example_vc.py&lt;/code&gt; for more examples.&lt;/p&gt; 
&lt;h2&gt;Supported Languages&lt;/h2&gt; 
&lt;p&gt;Arabic (ar) ‚Ä¢ Danish (da) ‚Ä¢ German (de) ‚Ä¢ Greek (el) ‚Ä¢ English (en) ‚Ä¢ Spanish (es) ‚Ä¢ Finnish (fi) ‚Ä¢ French (fr) ‚Ä¢ Hebrew (he) ‚Ä¢ Hindi (hi) ‚Ä¢ Italian (it) ‚Ä¢ Japanese (ja) ‚Ä¢ Korean (ko) ‚Ä¢ Malay (ms) ‚Ä¢ Dutch (nl) ‚Ä¢ Norwegian (no) ‚Ä¢ Polish (pl) ‚Ä¢ Portuguese (pt) ‚Ä¢ Russian (ru) ‚Ä¢ Swedish (sv) ‚Ä¢ Swahili (sw) ‚Ä¢ Turkish (tr) ‚Ä¢ Chinese (zh)&lt;/p&gt; 
&lt;h2&gt;Original Chatterbox Tips&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;General Use (TTS and Voice Agents):&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Ensure that the reference clip matches the specified language tag. Otherwise, language transfer outputs may inherit the accent of the reference clip‚Äôs language. To mitigate this, set &lt;code&gt;cfg_weight&lt;/code&gt; to &lt;code&gt;0&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;The default settings (&lt;code&gt;exaggeration=0.5&lt;/code&gt;, &lt;code&gt;cfg_weight=0.5&lt;/code&gt;) work well for most prompts across all languages.&lt;/li&gt; 
   &lt;li&gt;If the reference speaker has a fast speaking style, lowering &lt;code&gt;cfg_weight&lt;/code&gt; to around &lt;code&gt;0.3&lt;/code&gt; can improve pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Expressive or Dramatic Speech:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Try lower &lt;code&gt;cfg_weight&lt;/code&gt; values (e.g. &lt;code&gt;~0.3&lt;/code&gt;) and increase &lt;code&gt;exaggeration&lt;/code&gt; to around &lt;code&gt;0.7&lt;/code&gt; or higher.&lt;/li&gt; 
   &lt;li&gt;Higher &lt;code&gt;exaggeration&lt;/code&gt; tends to speed up speech; reducing &lt;code&gt;cfg_weight&lt;/code&gt; helps compensate with slower, more deliberate pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Built-in PerTh Watermarking for Responsible AI&lt;/h2&gt; 
&lt;p&gt;Every audio file generated by Chatterbox includes &lt;a href="https://github.com/resemble-ai/perth"&gt;Resemble AI's Perth (Perceptual Threshold) Watermarker&lt;/a&gt; - imperceptible neural watermarks that survive MP3 compression, audio editing, and common manipulations while maintaining nearly 100% detection accuracy.&lt;/p&gt; 
&lt;h2&gt;Watermark extraction&lt;/h2&gt; 
&lt;p&gt;You can look for the watermark using the following script.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import perth
import librosa

AUDIO_PATH = "YOUR_FILE.wav"

# Load the watermarked audio
watermarked_audio, sr = librosa.load(AUDIO_PATH, sr=None)

# Initialize watermarker (same as used for embedding)
watermarker = perth.PerthImplicitWatermarker()

# Extract watermark
watermark = watermarker.get_watermark(watermarked_audio, sample_rate=sr)
print(f"Extracted watermark: {watermark}")
# Output: 0.0 (no watermark) or 1.0 (watermarked)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Official Discord&lt;/h2&gt; 
&lt;p&gt;üëã Join us on &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;Discord&lt;/a&gt; and let's build something awesome together!&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FunAudioLLM/CosyVoice"&gt;Cosyvoice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning"&gt;Real-Time-Voice-Cloning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yl4579/HiFTNet"&gt;HiFT-GAN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/meta-llama/llama3"&gt;Llama 3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xingchensong/S3Tokenizer"&gt;S3Tokenizer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find this model useful, please consider citing.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{chatterboxtts2025,
  author       = {{Resemble AI}},
  title        = {{Chatterbox-TTS}},
  year         = {2025},
  howpublished = {\url{https://github.com/resemble-ai/chatterbox}},
  note         = {GitHub repository}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;Don't use this model to do bad things. Prompts are sourced from freely available data on the internet.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>antiwork/gumroad</title>
      <link>https://github.com/antiwork/gumroad</link>
      <description>&lt;p&gt;Sell stuff and see what sticks&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source srcset="https://public-files.gumroad.com/logo/gumroad-dark.svg" media="(prefers-color-scheme: dark)" /&gt; 
  &lt;source srcset="https://public-files.gumroad.com/logo/gumroad.svg" media="(prefers-color-scheme: light)" /&gt; 
  &lt;img src="https://public-files.gumroad.com/logo/gumroad.svg?sanitize=true" height="100" alt="Gumroad logo" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;Sell your stuff. See what sticks.&lt;/strong&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://gumroad.com"&gt;Gumroad&lt;/a&gt; is an e-commerce platform that enables creators to sell products directly to consumers. This repository contains the source code for the Gumroad web application. &lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/#running-locally"&gt;Running Locally&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/#development"&gt;Development&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/#logging-in"&gt;Logging in&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/#resetting-elasticsearch-indices"&gt;Resetting Elasticsearch indices&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/#push-notifications"&gt;Push Notifications&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/#common-development-tasks"&gt;Common Development Tasks&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/#linting"&gt;Linting&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üí° If you're on Windows, follow our &lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/docs/development/windows.md"&gt;Windows setup guide&lt;/a&gt; instead.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Before you begin, ensure you have the following installed:&lt;/p&gt; 
&lt;h4&gt;Ruby&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.ruby-lang.org/en/documentation/installation/"&gt;https://www.ruby-lang.org/en/documentation/installation/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install the version listed in &lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/.ruby-version"&gt;the .ruby-version file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Node.js&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/en/download"&gt;https://nodejs.org/en/download&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install the version listed in &lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/.node-version"&gt;the .node-version file&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Docker&lt;/h4&gt; 
&lt;p&gt;We use Docker to setup the services for development environment.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For MacOS: Download the Docker app from the &lt;a href="https://www.docker.com/products/docker-desktop"&gt;Docker website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For Linux:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo wget -qO- https://get.docker.com/ | sh
sudo usermod -aG docker $(whoami)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;MySQL &amp;amp; Percona Toolkit&lt;/h4&gt; 
&lt;p&gt;Install a local version of MySQL 8.0.x to match the version running in production.&lt;/p&gt; 
&lt;p&gt;The local version of MySQL is a dependency of the Ruby &lt;code&gt;mysql2&lt;/code&gt; gem. You do not need to start an instance of the MySQL service locally. The app will connect to a MySQL instance running in the Docker container.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For MacOS:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install mysql@8.0 percona-toolkit
brew link --force mysql@8.0

# to use Homebrew's `openssl`:
brew install openssl
bundle config --global build.mysql2 --with-opt-dir="$(brew --prefix openssl)"

# ensure MySQL is not running as a service
brew services stop mysql@8.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;For Linux: 
  &lt;ul&gt; 
   &lt;li&gt;MySQL: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://dev.mysql.com/doc/refman/8.0/en/linux-installation.html"&gt;https://dev.mysql.com/doc/refman/8.0/en/linux-installation.html&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;apt install libmysqlclient-dev&lt;/code&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Percona Toolkit: &lt;a href="https://www.percona.com/doc/percona-toolkit/LATEST/installation.html"&gt;https://www.percona.com/doc/percona-toolkit/LATEST/installation.html&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Image Processing Libraries&lt;/h4&gt; 
&lt;h5&gt;ImageMagick&lt;/h5&gt; 
&lt;p&gt;We use &lt;code&gt;imagemagick&lt;/code&gt; for preview editing.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For MacOS: &lt;code&gt;brew install imagemagick&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;For Linux: &lt;code&gt;sudo apt-get install imagemagick&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h5&gt;libvips&lt;/h5&gt; 
&lt;p&gt;For newer image formats we use &lt;code&gt;libvips&lt;/code&gt; for image processing with ActiveStorage.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For MacOS: &lt;code&gt;brew install libvips&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;For Linux: &lt;code&gt;sudo apt-get install libvips-dev&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;FFmpeg&lt;/h4&gt; 
&lt;p&gt;We use &lt;code&gt;ffprobe&lt;/code&gt; that comes with &lt;code&gt;FFmpeg&lt;/code&gt; package to fetch metadata from video files.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For MacOS: &lt;code&gt;brew install ffmpeg&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;For Linux: &lt;code&gt;sudo apt-get install ffmpeg&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;PDFtk&lt;/h4&gt; 
&lt;p&gt;We use &lt;a href="https://www.pdflabs.com/tools/pdftk-server/"&gt;pdftk&lt;/a&gt; to stamp PDF files with the Gumroad logo and the buyers' emails.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For MacOS: Download from &lt;a href="https://www.pdflabs.com/tools/pdftk-the-pdf-toolkit/pdftk_server-2.02-mac_osx-10.11-setup.pkg"&gt;here&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; pdftk may be blocked by Apple's firewall. If this happens, go to Settings &amp;gt; Privacy &amp;amp; Security and click "Open Anyways" to allow the installation.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;For Linux: &lt;code&gt;sudo apt-get install pdftk&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;wkhtmltopdf&lt;/h4&gt; 
&lt;p&gt;While generating invoices, to convert HTML to PDF, PDFKit expects &lt;a href="https://wkhtmltopdf.org/"&gt;wkhtmltopdf&lt;/a&gt; to be installed on your system. &lt;a href="https://wkhtmltopdf.org/downloads.html"&gt;Download&lt;/a&gt; and install the version 0.12.6 for your platform.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt; similar to pdftk, this may also be blocked by Apple's firewall on MacOS. Follow a similar process as above.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;h4&gt;Bundler and gems&lt;/h4&gt; 
&lt;p&gt;We use Bundler to install Ruby gems.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;gem install bundler
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install gems:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;bundle install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Also make sure to install &lt;code&gt;dotenv&lt;/code&gt; as it is required for some console commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;gem install dotenv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;npm and Node.js dependencies&lt;/h4&gt; 
&lt;p&gt;Make sure the correct version of &lt;code&gt;npm&lt;/code&gt; is enabled:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;corepack enable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;h4&gt;Set up Custom credentials&lt;/h4&gt; 
&lt;p&gt;App can be booted without any custom credentials. But if you would like to use services that require custom credentials (e.g. S3, Stripe, Resend, etc.), you can copy the &lt;code&gt;.env.example&lt;/code&gt; file to &lt;code&gt;.env&lt;/code&gt; and fill in the values.&lt;/p&gt; 
&lt;h4&gt;Local SSL Certificates&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install mkcert on macOS:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;brew install mkcert
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For other operating systems, see &lt;a href="https://github.com/FiloSottile/mkcert?tab=readme-ov-file#installation"&gt;mkcert installation instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Generate certificates by running:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;bin/generate_ssl_certificates
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running Locally&lt;/h3&gt; 
&lt;h4&gt;Start Docker services&lt;/h4&gt; 
&lt;p&gt;If you installed Docker Desktop (on a Mac or Windows machine), you can run the following command to start the Docker services:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are on Linux, or installed Docker via a package manager on a mac, you may have to manually give docker superuser access to open ports 80 and 443. To do that, use &lt;code&gt;sudo make local&lt;/code&gt; instead.&lt;/p&gt; 
&lt;p&gt;This command will not terminate. You run this in one tab and start the application in another tab. If you want to run Docker services in the background, use &lt;code&gt;LOCAL_DETACHED=true make local&lt;/code&gt; instead.&lt;/p&gt; 
&lt;h4&gt;Set up the database&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;bin/rails db:prepare
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Linux (Debian / Ubuntu) you might need the following:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;apt install libxslt-dev libxml2-dev&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Start the application&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;bin/dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts the Rails server, the JavaScript build system, and a Sidekiq worker.&lt;/p&gt; 
&lt;p&gt;You can now access the application at &lt;code&gt;https://gumroad.dev&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Logging in&lt;/h3&gt; 
&lt;p&gt;You can log in with the username &lt;code&gt;seller@gumroad.com&lt;/code&gt; and the password &lt;code&gt;password&lt;/code&gt;. The two-factor authentication code is &lt;code&gt;000000&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Read more about logging in as a user with a different team role at &lt;a href="https://raw.githubusercontent.com/antiwork/gumroad/main/docs/users.md"&gt;Users &amp;amp; authentication&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Resetting Elasticsearch indices&lt;/h3&gt; 
&lt;p&gt;You will need to explicitly reindex Elasticsearch to populate the indices after setup, otherwise you will see &lt;code&gt;index_not_found_exception&lt;/code&gt; errors when you visit the dev application. You can reset them using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ruby"&gt;# Run this in a rails console:
DevTools.delete_all_indices_and_reindex_all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Push Notifications&lt;/h3&gt; 
&lt;p&gt;To send push notifications:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;INITIALIZE_RPUSH_APPS=true bundle exec rpush start -e development -f
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Common Development Tasks&lt;/h3&gt; 
&lt;h4&gt;Rails console:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;bin/rails c
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Rake tasks:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;bin/rake task_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Linting&lt;/h3&gt; 
&lt;p&gt;We use ESLint for JS, and Rubocop for Ruby. Your editor should support displaying and fixing issues reported by these inline, and CI will automatically check and fix (if possible) these.&lt;/p&gt; 
&lt;p&gt;If you'd like, you can run &lt;code&gt;git config --local core.hooksPath .githooks&lt;/code&gt; to check for these locally when committing.&lt;/p&gt; 
&lt;h2&gt;Common Issues&lt;/h2&gt; 
&lt;h3&gt;macOS Error When Running Tests (Related to &lt;code&gt;fork()&lt;/code&gt;)&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;objc[11912]: +[__NSCFConstantString initialize] may have been in progress in another thread when fork() was called.
objc[11912]: +[__NSCFConstantString initialize] may have been in progress in another thread when fork() was called. We cannot safely call it or ignore it in the fork() child process. Crashing instead. Set a breakpoint on objc_initializeAfterForkError to debug.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This issue occurs on macOS due to how the &lt;code&gt;fork()&lt;/code&gt; system call interacts with multithreaded Objective-C applications‚Äîcommonly triggered when Spring is enabled during testing.&lt;/p&gt; 
&lt;h4&gt;How to Fix:&lt;/h4&gt; 
&lt;p&gt;Temporarily disable Spring before running your tests to avoid this error.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export DISABLE_SPRING=1
bin/rspec spec/requests/balance_pages_spec.rb
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will disable Spring for the current session, allowing the tests to run without triggering the &lt;code&gt;fork()&lt;/code&gt;-related crash.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>google-gemini/computer-use-preview</title>
      <link>https://github.com/google-gemini/computer-use-preview</link>
      <description>&lt;p&gt;&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Computer Use Preview&lt;/h1&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;This section will guide you through setting up and running the Computer Use Preview model, either the Gemini Developer API or Vertex AI. Follow these steps to get started.&lt;/p&gt; 
&lt;h3&gt;1. Installation&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Clone the Repository&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/google/computer-use-preview.git
cd computer-use-preview
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Set up Python Virtual Environment and Install Dependencies&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Install Playwright and Browser Dependencies&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install system dependencies required by Playwright for Chrome
playwright install-deps chrome

# Install the Chrome browser for Playwright
playwright install chrome
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Configuration&lt;/h3&gt; 
&lt;p&gt;You can get started using either the Gemini Developer API or Vertex AI.&lt;/p&gt; 
&lt;h4&gt;A. If using the Gemini Developer API:&lt;/h4&gt; 
&lt;p&gt;You need a Gemini API key to use the agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export GEMINI_API_KEY="YOUR_GEMINI_API_KEY"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or to add this to your virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;echo 'export GEMINI_API_KEY="YOUR_GEMINI_API_KEY"' &amp;gt;&amp;gt; .venv/bin/activate
# After editing, you'll need to deactivate and reactivate your virtual
# environment if it's already active:
deactivate
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace &lt;code&gt;YOUR_GEMINI_API_KEY&lt;/code&gt; with your actual key.&lt;/p&gt; 
&lt;h4&gt;B. If using the Vertex AI Client:&lt;/h4&gt; 
&lt;p&gt;You need to explicitly use Vertex AI, then provide project and location to use the agent:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export USE_VERTEXAI=true
export VERTEXAI_PROJECT="YOUR_PROJECT_ID"
export VERTEXAI_LOCATION="YOUR_LOCATION"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or to add this to your virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;echo 'export USE_VERTEXAI=true' &amp;gt;&amp;gt; .venv/bin/activate
echo 'export VERTEXAI_PROJECT="your-project-id"' &amp;gt;&amp;gt; .venv/bin/activate
echo 'export VERTEXAI_LOCATION="your-location"' &amp;gt;&amp;gt; .venv/bin/activate
# After editing, you'll need to deactivate and reactivate your virtual
# environment if it's already active:
deactivate
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace &lt;code&gt;YOUR_PROJECT_ID&lt;/code&gt; and &lt;code&gt;YOUR_LOCATION&lt;/code&gt; with your actual project and location.&lt;/p&gt; 
&lt;h3&gt;3. Running the Tool&lt;/h3&gt; 
&lt;p&gt;The primary way to use the tool is via the &lt;code&gt;main.py&lt;/code&gt; script.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;General Command Structure:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py --query "Go to Google and type 'Hello World' into the search bar"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Environments:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can specify a particular environment with the &lt;code&gt;--env &amp;lt;environment&amp;gt;&lt;/code&gt; flag. Available options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;playwright&lt;/code&gt;: Runs the browser locally using Playwright.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;browserbase&lt;/code&gt;: Connects to a Browserbase instance.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Local Playwright&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Runs the agent using a Chrome browser instance controlled locally by Playwright.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py --query="Go to Google and type 'Hello World' into the search bar" --env="playwright"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also specify an initial URL for the Playwright environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py --query="Go to Google and type 'Hello World' into the search bar" --env="playwright" --initial_url="https://www.google.com/search?q=latest+AI+news"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Browserbase&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Runs the agent using Browserbase as the browser backend. Ensure the proper Browserbase environment variables are set:&lt;code&gt;BROWSERBASE_API_KEY&lt;/code&gt; and &lt;code&gt;BROWSERBASE_PROJECT_ID&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py --query="Go to Google and type 'Hello World' into the search bar" --env="browserbase"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Agent CLI&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;main.py&lt;/code&gt; script is the command-line interface (CLI) for running the browser agent.&lt;/p&gt; 
&lt;h3&gt;Command-Line Arguments&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Argument&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Required&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Supported Environment(s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--query&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The natural language query for the browser agent to execute.&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;All&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--env&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The computer use environment to use. Must be one of the following: &lt;code&gt;playwright&lt;/code&gt;, or &lt;code&gt;browserbase&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;All&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--initial_url&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The initial URL to load when the browser starts.&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.google.com"&gt;https://www.google.com&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;All&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--highlight_mouse&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;If specified, the agent will attempt to highlight the mouse cursor's position in the screenshots. This is useful for visual debugging.&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;False (not highlighted)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;playwright&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Required&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GEMINI_API_KEY&lt;/td&gt; 
   &lt;td&gt;Your API key for the Gemini model.&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BROWSERBASE_API_KEY&lt;/td&gt; 
   &lt;td&gt;Your API key for Browserbase.&lt;/td&gt; 
   &lt;td&gt;Yes (when using the browserbase environment)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;BROWSERBASE_PROJECT_ID&lt;/td&gt; 
   &lt;td&gt;Your Project ID for Browserbase.&lt;/td&gt; 
   &lt;td&gt;Yes (when using the browserbase environment)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Known Issues&lt;/h2&gt; 
&lt;h3&gt;Playwright Dropdown Menu&lt;/h3&gt; 
&lt;p&gt;On certain operating systems, the Playwright browser is unable to capture &lt;code&gt;&amp;lt;select&amp;gt;&lt;/code&gt; elements because they are rendered by the operating system. As a result, the agent is unable to send the correct screenshot to the model.&lt;/p&gt; 
&lt;p&gt;There are several ways to mitigate this.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Use the Browserbase option instead of Playwright.&lt;/li&gt; 
 &lt;li&gt;Inject a script like &lt;a href="https://github.com/amitamb/proxy-select"&gt;proxy-select&lt;/a&gt; to render a custom &lt;code&gt;&amp;lt;select&amp;gt;&lt;/code&gt; element. You must inject &lt;code&gt;proxy-select.css&lt;/code&gt; and &lt;code&gt;proxy-select.js&lt;/code&gt; into each page that has a non-custom &lt;code&gt;&amp;lt;select&amp;gt;&lt;/code&gt; element. You can do this in the &lt;a href="https://github.com/google-gemini/computer-use-preview/raw/main/computers/playwright/playwright.py#L100"&gt;&lt;code&gt;Playwright.__enter__&lt;/code&gt;&lt;/a&gt; method by adding a few lines of code, like the following (replacing &lt;code&gt;PROXY_SELECT_JS&lt;/code&gt; and &lt;code&gt;PROXY_SELECT_CSS&lt;/code&gt; with the appropriate variables):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;self._page.add_init_script(PROXY_SELECT_JS)
def inject_style(page):
    try:
        page.add_style_tag(content=PROXY_SELECT_CSS)
    except Exception as e:
        print(f"Error injecting style: {e}")

self._page.on('domcontentloaded', inject_style)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note, option 2 does not work 100% of the time, but is a temporary workaround for certain websites. The better option is to use Browserbase.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>BloopAI/vibe-kanban</title>
      <link>https://github.com/BloopAI/vibe-kanban</link>
      <description>&lt;p&gt;Get 10X more out of Claude Code, Codex or any coding agent&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://vibekanban.com"&gt; 
  &lt;picture&gt; 
   &lt;source srcset="frontend/public/vibe-kanban-logo-dark.svg" media="(prefers-color-scheme: dark)" /&gt; 
   &lt;source srcset="frontend/public/vibe-kanban-logo.svg" media="(prefers-color-scheme: light)" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/BloopAI/vibe-kanban/main/frontend/public/vibe-kanban-logo.svg?sanitize=true" alt="Vibe Kanban Logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Get 10X more out of Claude Code, Gemini CLI, Codex, Amp and other coding agents...&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.npmjs.com/package/vibe-kanban"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/vibe-kanban?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/BloopAI/vibe-kanban/raw/main/.github/workflows/publish.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/BloopAI/vibe-kanban/.github%2Fworkflows%2Fpublish.yml" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/BloopAI/vibe-kanban"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; &lt;a href="https://jobs.polymer.co/vibe-kanban?source=github"&gt;&lt;strong&gt;We're hiring!&lt;/strong&gt;&lt;/a&gt; &lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/BloopAI/vibe-kanban/main/frontend/public/vibe-kanban-screenshot-overview.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;AI coding agents are increasingly writing the world's code and human engineers now spend the majority of their time planning, reviewing, and orchestrating tasks. Vibe Kanban streamlines this process, enabling you to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Easily switch between different coding agents&lt;/li&gt; 
 &lt;li&gt;Orchestrate the execution of multiple coding agents in parallel or in sequence&lt;/li&gt; 
 &lt;li&gt;Quickly review work and start dev servers&lt;/li&gt; 
 &lt;li&gt;Track the status of tasks that your coding agents are working on&lt;/li&gt; 
 &lt;li&gt;Centralise configuration of coding agent MCP configs&lt;/li&gt; 
 &lt;li&gt;Open projects remotely via SSH when running Vibe Kanban on a remote server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can watch a video overview &lt;a href="https://youtu.be/TFT3KnZOOAk"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Make sure you have authenticated with your favourite coding agent. A full list of supported coding agents can be found in the &lt;a href="https://vibekanban.com/docs"&gt;docs&lt;/a&gt;. Then in your terminal run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx vibe-kanban
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Please head to the &lt;a href="https://vibekanban.com/docs"&gt;website&lt;/a&gt; for the latest documentation and user guides.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://github.com/BloopAI/vibe-kanban/discussions"&gt;GitHub Discussions&lt;/a&gt; for feature requests. Please open a discussion to create a feature request. For bugs please open an issue on this repo.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We would prefer that ideas and changes are first raised with the core team via &lt;a href="https://github.com/BloopAI/vibe-kanban/discussions"&gt;GitHub Discussions&lt;/a&gt; or &lt;a href="https://discord.gg/AC4nwVtJM3"&gt;Discord&lt;/a&gt;, where we can discuss implementation details and alignment with the existing roadmap. Please do not open PRs without first discussing your proposal with the team.&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt; (latest stable)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; (&amp;gt;=18)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pnpm.io/"&gt;pnpm&lt;/a&gt; (&amp;gt;=8)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additional development tools:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cargo install cargo-watch
cargo install sqlx-cli
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm i
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Running the dev server&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pnpm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will start the backend. A blank DB will be copied from the &lt;code&gt;dev_assets_seed&lt;/code&gt; folder.&lt;/p&gt; 
&lt;h3&gt;Building the frontend&lt;/h3&gt; 
&lt;p&gt;To build just the frontend:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd frontend
pnpm build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build from source (macOS)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run &lt;code&gt;./local-build.sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Test with &lt;code&gt;cd npx-cli &amp;amp;&amp;amp; node bin/cli.js&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Environment Variables&lt;/h3&gt; 
&lt;p&gt;The following environment variables can be configured at build time or runtime:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Default&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POSTHOG_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Build-time&lt;/td&gt; 
   &lt;td&gt;Empty&lt;/td&gt; 
   &lt;td&gt;PostHog analytics API key (disables analytics if empty)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;POSTHOG_API_ENDPOINT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Build-time&lt;/td&gt; 
   &lt;td&gt;Empty&lt;/td&gt; 
   &lt;td&gt;PostHog analytics endpoint (disables analytics if empty)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;Auto-assign&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Production&lt;/strong&gt;: Server port. &lt;strong&gt;Dev&lt;/strong&gt;: Frontend port (backend uses PORT+1)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BACKEND_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0&lt;/code&gt; (auto-assign)&lt;/td&gt; 
   &lt;td&gt;Backend server port (dev mode only, overrides PORT+1)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;FRONTEND_PORT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;3000&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Frontend dev server port (dev mode only, overrides PORT)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;HOST&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;127.0.0.1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Backend server host&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DISABLE_WORKTREE_ORPHAN_CLEANUP&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Runtime&lt;/td&gt; 
   &lt;td&gt;Not set&lt;/td&gt; 
   &lt;td&gt;Disable git worktree cleanup (for debugging)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Build-time variables&lt;/strong&gt; must be set when running &lt;code&gt;pnpm run build&lt;/code&gt;. &lt;strong&gt;Runtime variables&lt;/strong&gt; are read when the application starts.&lt;/p&gt; 
&lt;h3&gt;Remote Deployment&lt;/h3&gt; 
&lt;p&gt;When running Vibe Kanban on a remote server (e.g., via systemctl, Docker, or cloud hosting), you can configure your editor to open projects via SSH:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Access via tunnel&lt;/strong&gt;: Use Cloudflare Tunnel, ngrok, or similar to expose the web UI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configure remote SSH&lt;/strong&gt; in Settings ‚Üí Editor Integration: 
  &lt;ul&gt; 
   &lt;li&gt;Set &lt;strong&gt;Remote SSH Host&lt;/strong&gt; to your server hostname or IP&lt;/li&gt; 
   &lt;li&gt;Set &lt;strong&gt;Remote SSH User&lt;/strong&gt; to your SSH username (optional)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;SSH access from your local machine to the remote server&lt;/li&gt; 
   &lt;li&gt;SSH keys configured (passwordless authentication)&lt;/li&gt; 
   &lt;li&gt;VSCode Remote-SSH extension&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;When configured, the "Open in VSCode" buttons will generate URLs like &lt;code&gt;vscode://vscode-remote/ssh-remote+user@host/path&lt;/code&gt; that open your local editor and connect to the remote server.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://vibekanban.com/docs/configuration-customisation/global-settings#remote-ssh-configuration"&gt;documentation&lt;/a&gt; for detailed setup instructions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>alexta69/metube</title>
      <link>https://github.com/alexta69/metube</link>
      <description>&lt;p&gt;Self-hosted YouTube downloader (web UI for youtube-dl / yt-dlp)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MeTube&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/alexta69/metube/actions/workflows/main.yml/badge.svg?sanitize=true" alt="Build Status" /&gt; &lt;img src="https://img.shields.io/docker/pulls/alexta69/metube.svg?sanitize=true" alt="Docker Pulls" /&gt;&lt;/p&gt; 
&lt;p&gt;Web GUI for youtube-dl (using the &lt;a href="https://github.com/yt-dlp/yt-dlp"&gt;yt-dlp&lt;/a&gt; fork) with playlist support. Allows you to download videos from YouTube and &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/supportedsites.md"&gt;dozens of other sites&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/alexta69/metube/raw/master/screenshot.gif" alt="screenshot1" /&gt;&lt;/p&gt; 
&lt;h2&gt;üê≥ Run using Docker&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -p 8081:8081 -v /path/to/downloads:/downloads ghcr.io/alexta69/metube
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üê≥ Run using docker-compose&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  metube:
    image: ghcr.io/alexta69/metube
    container_name: metube
    restart: unless-stopped
    ports:
      - "8081:8081"
    volumes:
      - /path/to/downloads:/downloads
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚öôÔ∏è Configuration via environment variables&lt;/h2&gt; 
&lt;p&gt;Certain values can be set via environment variables, using the &lt;code&gt;-e&lt;/code&gt; parameter on the docker command line, or the &lt;code&gt;environment:&lt;/code&gt; section in docker-compose.&lt;/p&gt; 
&lt;h3&gt;‚¨áÔ∏è Download Behavior&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;DOWNLOAD_MODE&lt;/strong&gt;: This flag controls how downloads are scheduled and executed. Options are &lt;code&gt;sequential&lt;/code&gt;, &lt;code&gt;concurrent&lt;/code&gt;, and &lt;code&gt;limited&lt;/code&gt;. Defaults to &lt;code&gt;limited&lt;/code&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;sequential&lt;/code&gt;: Downloads are processed one at a time. A new download won't start until the previous one has finished. This mode is useful for conserving system resources or ensuring downloads occur in strict order.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;concurrent&lt;/code&gt;: Downloads are started immediately as they are added, with no built-in limit on how many run simultaneously. This mode may overwhelm your system if too many downloads start at once.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;limited&lt;/code&gt;: Downloads are started concurrently but are capped by a concurrency limit. In this mode, a semaphore is used so that at most a fixed number of downloads run at any given time.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MAX_CONCURRENT_DOWNLOADS&lt;/strong&gt;: This flag is used only when &lt;code&gt;DOWNLOAD_MODE&lt;/code&gt; is set to &lt;code&gt;limited&lt;/code&gt;.&lt;br /&gt; It specifies the maximum number of simultaneous downloads allowed. For example, if set to &lt;code&gt;5&lt;/code&gt;, then at most five downloads will run concurrently, and any additional downloads will wait until one of the active downloads completes. Defaults to &lt;code&gt;3&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DELETE_FILE_ON_TRASHCAN&lt;/strong&gt;: if &lt;code&gt;true&lt;/code&gt;, downloaded files are deleted on the server, when they are trashed from the "Completed" section of the UI. Defaults to &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DEFAULT_OPTION_PLAYLIST_STRICT_MODE&lt;/strong&gt;: if &lt;code&gt;true&lt;/code&gt;, the "Strict Playlist mode" switch will be enabled by default. In this mode the playlists will be downloaded only if the URL strictly points to a playlist. URLs to videos inside a playlist will be treated same as direct video URL. Defaults to &lt;code&gt;false&lt;/code&gt; .&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DEFAULT_OPTION_PLAYLIST_ITEM_LIMIT&lt;/strong&gt;: Maximum number of playlist items that can be downloaded. Defaults to &lt;code&gt;0&lt;/code&gt; (no limit).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìÅ Storage &amp;amp; Directories&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;DOWNLOAD_DIR&lt;/strong&gt;: Path to where the downloads will be saved. Defaults to &lt;code&gt;/downloads&lt;/code&gt; in the Docker image, and &lt;code&gt;.&lt;/code&gt; otherwise.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AUDIO_DOWNLOAD_DIR&lt;/strong&gt;: Path to where audio-only downloads will be saved, if you wish to separate them from the video downloads. Defaults to the value of &lt;code&gt;DOWNLOAD_DIR&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CUSTOM_DIRS&lt;/strong&gt;: Whether to enable downloading videos into custom directories within the &lt;strong&gt;DOWNLOAD_DIR&lt;/strong&gt; (or &lt;strong&gt;AUDIO_DOWNLOAD_DIR&lt;/strong&gt;). When enabled, a dropdown appears next to the Add button to specify the download directory. Defaults to &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CREATE_CUSTOM_DIRS&lt;/strong&gt;: Whether to support automatically creating directories within the &lt;strong&gt;DOWNLOAD_DIR&lt;/strong&gt; (or &lt;strong&gt;AUDIO_DOWNLOAD_DIR&lt;/strong&gt;) if they do not exist. When enabled, the download directory selector supports free-text input, and the specified directory will be created recursively. Defaults to &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CUSTOM_DIRS_EXCLUDE_REGEX&lt;/strong&gt;: Regular expression to exclude some custom directories from the dropdown. Empty regex disables exclusion. Defaults to &lt;code&gt;(^|/)[.@].*$&lt;/code&gt;, which means directories starting with &lt;code&gt;.&lt;/code&gt; or &lt;code&gt;@&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DOWNLOAD_DIRS_INDEXABLE&lt;/strong&gt;: If &lt;code&gt;true&lt;/code&gt;, the download directories (&lt;strong&gt;DOWNLOAD_DIR&lt;/strong&gt; and &lt;strong&gt;AUDIO_DOWNLOAD_DIR&lt;/strong&gt;) are indexable on the web server. Defaults to &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;STATE_DIR&lt;/strong&gt;: Path to where the queue persistence files will be saved. Defaults to &lt;code&gt;/downloads/.metube&lt;/code&gt; in the Docker image, and &lt;code&gt;.&lt;/code&gt; otherwise.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;TEMP_DIR&lt;/strong&gt;: Path where intermediary download files will be saved. Defaults to &lt;code&gt;/downloads&lt;/code&gt; in the Docker image, and &lt;code&gt;.&lt;/code&gt; otherwise. 
  &lt;ul&gt; 
   &lt;li&gt;Set this to an SSD or RAM filesystem (e.g., &lt;code&gt;tmpfs&lt;/code&gt;) for better performance.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: Using a RAM filesystem may prevent downloads from being resumed.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìù File Naming &amp;amp; yt-dlp&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OUTPUT_TEMPLATE&lt;/strong&gt;: The template for the filenames of the downloaded videos, formatted according to &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/README.md#output-template"&gt;this spec&lt;/a&gt;. Defaults to &lt;code&gt;%(title)s.%(ext)s&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OUTPUT_TEMPLATE_CHAPTER&lt;/strong&gt;: The template for the filenames of the downloaded videos when split into chapters via postprocessors. Defaults to &lt;code&gt;%(title)s - %(section_number)s %(section_title)s.%(ext)s&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OUTPUT_TEMPLATE_PLAYLIST&lt;/strong&gt;: The template for the filenames of the downloaded videos when downloaded as a playlist. Defaults to &lt;code&gt;%(playlist_title)s/%(title)s.%(ext)s&lt;/code&gt;. When empty, then &lt;code&gt;OUTPUT_TEMPLATE&lt;/code&gt; is used.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;YTDL_OPTIONS&lt;/strong&gt;: Additional options to pass to yt-dlp in JSON format. &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/yt_dlp/YoutubeDL.py#L222"&gt;See available options here&lt;/a&gt;. They roughly correspond to command-line options, though some do not have exact equivalents here. For example, &lt;code&gt;--recode-video&lt;/code&gt; has to be specified via &lt;code&gt;postprocessors&lt;/code&gt;. Also note that dashes are replaced with underscores. You may find &lt;a href="https://github.com/yt-dlp/yt-dlp/raw/master/devscripts/cli_to_api.py"&gt;this script&lt;/a&gt; helpful for converting from command-line options to &lt;code&gt;YTDL_OPTIONS&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;YTDL_OPTIONS_FILE&lt;/strong&gt;: A path to a JSON file that will be loaded and used for populating &lt;code&gt;YTDL_OPTIONS&lt;/code&gt; above. Please note that if both &lt;code&gt;YTDL_OPTIONS_FILE&lt;/code&gt; and &lt;code&gt;YTDL_OPTIONS&lt;/code&gt; are specified, the options in &lt;code&gt;YTDL_OPTIONS&lt;/code&gt; take precedence. The file will be monitored for changes and reloaded automatically when changes are detected.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üåê Web Server &amp;amp; URLs&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;URL_PREFIX&lt;/strong&gt;: Base path for the web server (for use when hosting behind a reverse proxy). Defaults to &lt;code&gt;/&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PUBLIC_HOST_URL&lt;/strong&gt;: Base URL for the download links shown in the UI for completed files. By default, MeTube serves them under its own URL. If your download directory is accessible on another URL and you want the download links to be based there, use this variable to set it.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PUBLIC_HOST_AUDIO_URL&lt;/strong&gt;: Same as PUBLIC_HOST_URL but for audio downloads.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTPS&lt;/strong&gt;: Use &lt;code&gt;https&lt;/code&gt; instead of &lt;code&gt;http&lt;/code&gt; (&lt;strong&gt;CERTFILE&lt;/strong&gt; and &lt;strong&gt;KEYFILE&lt;/strong&gt; required). Defaults to &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CERTFILE&lt;/strong&gt;: HTTPS certificate file path.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;KEYFILE&lt;/strong&gt;: HTTPS key file path.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ROBOTS_TXT&lt;/strong&gt;: A path to a &lt;code&gt;robots.txt&lt;/code&gt; file mounted in the container.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üè† Basic Setup&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;UID&lt;/strong&gt;: User under which MeTube will run. Defaults to &lt;code&gt;1000&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GID&lt;/strong&gt;: Group under which MeTube will run. Defaults to &lt;code&gt;1000&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UMASK&lt;/strong&gt;: Umask value used by MeTube. Defaults to &lt;code&gt;022&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DEFAULT_THEME&lt;/strong&gt;: Default theme to use for the UI, can be set to &lt;code&gt;light&lt;/code&gt;, &lt;code&gt;dark&lt;/code&gt;, or &lt;code&gt;auto&lt;/code&gt;. Defaults to &lt;code&gt;auto&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LOGLEVEL&lt;/strong&gt;: Log level, can be set to &lt;code&gt;DEBUG&lt;/code&gt;, &lt;code&gt;INFO&lt;/code&gt;, &lt;code&gt;WARNING&lt;/code&gt;, &lt;code&gt;ERROR&lt;/code&gt;, &lt;code&gt;CRITICAL&lt;/code&gt;, or &lt;code&gt;NONE&lt;/code&gt;. Defaults to &lt;code&gt;INFO&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ENABLE_ACCESSLOG&lt;/strong&gt;: Whether to enable access log. Defaults to &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The project's Wiki contains examples of useful configurations contributed by users of MeTube:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alexta69/metube/wiki/YTDL_OPTIONS-Cookbook"&gt;YTDL_OPTIONS Cookbook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/alexta69/metube/wiki/OUTPUT_TEMPLATE-Cookbook"&gt;OUTPUT_TEMPLATE Cookbook&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üç™ Using browser cookies&lt;/h2&gt; 
&lt;p&gt;In case you need to use your browser's cookies with MeTube, for example to download restricted or private videos:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add the following to your docker-compose.yml:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;    volumes:
      - /path/to/cookies:/cookies
    environment:
      - YTDL_OPTIONS={"cookiefile":"/cookies/cookies.txt"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install in your browser an extension to extract cookies: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://addons.mozilla.org/en-US/firefox/addon/export-cookies-txt/"&gt;Firefox&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://chrome.google.com/webstore/detail/get-cookiestxt-locally/cclelndahbckbenkjhflpdbgdldlbecc"&gt;Chrome&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Extract the cookies you need with the extension and rename the file &lt;code&gt;cookies.txt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Drop the file in the folder you configured in the docker-compose.yml above&lt;/li&gt; 
 &lt;li&gt;Restart the container&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîå Browser extensions&lt;/h2&gt; 
&lt;p&gt;Browser extensions allow right-clicking videos and sending them directly to MeTube. Please note that if you're on an HTTPS page, your MeTube instance must be behind an HTTPS reverse proxy (see below) for the extensions to work.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Chrome:&lt;/strong&gt; contributed by &lt;a href="https://github.com/rpsl"&gt;Rpsl&lt;/a&gt;. You can install it from &lt;a href="https://chrome.google.com/webstore/detail/metube-downloader/fbmkmdnlhacefjljljlbhkodfmfkijdh"&gt;Google Chrome Webstore&lt;/a&gt; or use developer mode and install &lt;a href="https://github.com/Rpsl/metube-browser-extension"&gt;from sources&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Firefox:&lt;/strong&gt; contributed by &lt;a href="https://github.com/nanocortex"&gt;nanocortex&lt;/a&gt;. You can install it from &lt;a href="https://addons.mozilla.org/en-US/firefox/addon/metube-downloader"&gt;Firefox Addons&lt;/a&gt; or get sources from &lt;a href="https://github.com/nanocortex/metube-firefox-addon"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üì± iOS Shortcut&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/rithask"&gt;rithask&lt;/a&gt; created an iOS shortcut to send URLs to MeTube from Safari. Enter the MeTube instance address when prompted which will be saved for later use. You can run the shortcut from Safari‚Äôs share menu. The shortcut can be downloaded from &lt;a href="https://www.icloud.com/shortcuts/66627a9f334c467baabdb2769763a1a6"&gt;this iCloud link&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üì± iOS Compatibility&lt;/h2&gt; 
&lt;p&gt;iOS has strict requirements for video files, requiring h264 or h265 video codec and aac audio codec in MP4 container. This can sometimes be a lower quality than the best quality available. To accommodate iOS requirements, when downloading a MP4 format you can choose "Best (iOS)" to get the best quality formats as compatible as possible with iOS requirements.&lt;/p&gt; 
&lt;p&gt;To force all downloads to be converted to an iOS-compatible codec, insert this as an environment variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;  environment:
    - 'YTDL_OPTIONS={"format": "best", "exec": "ffmpeg -i %(filepath)q -c:v libx264 -c:a aac %(filepath)q.h264.mp4"}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîñ Bookmarklet&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/kushfest"&gt;kushfest&lt;/a&gt; has created a Chrome bookmarklet for sending the currently open webpage to MeTube. Please note that if you're on an HTTPS page, your MeTube instance must be configured with &lt;code&gt;HTTPS&lt;/code&gt; as &lt;code&gt;true&lt;/code&gt; in the environment, or be behind an HTTPS reverse proxy (see below) for the bookmarklet to work.&lt;/p&gt; 
&lt;p&gt;GitHub doesn't allow embedding JavaScript as a link, so the bookmarklet has to be created manually by copying the following code to a new bookmark you create on your bookmarks bar. Change the hostname in the URL below to point to your MeTube instance.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;javascript:!function(){xhr=new XMLHttpRequest();xhr.open("POST","https://metube.domain.com/add");xhr.withCredentials=true;xhr.send(JSON.stringify({"url":document.location.href,"quality":"best"}));xhr.onload=function(){if(xhr.status==200){alert("Sent to metube!")}else{alert("Send to metube failed. Check the javascript console for clues.")}}}();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/shoonya75"&gt;shoonya75&lt;/a&gt; has contributed a Firefox version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;javascript:(function(){xhr=new XMLHttpRequest();xhr.open("POST","https://metube.domain.com/add");xhr.send(JSON.stringify({"url":document.location.href,"quality":"best"}));xhr.onload=function(){if(xhr.status==200){alert("Sent to metube!")}else{alert("Send to metube failed. Check the javascript console for clues.")}}})();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above bookmarklets use &lt;code&gt;alert()&lt;/code&gt; as a success/failure notification. The following will show a toast message instead:&lt;/p&gt; 
&lt;p&gt;Chrome:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;javascript:!function(){function notify(msg) {var sc = document.scrollingElement.scrollTop; var text = document.createElement('span');text.innerHTML=msg;var ts = text.style;ts.all = 'revert';ts.color = '#000';ts.fontFamily = 'Verdana, sans-serif';ts.fontSize = '15px';ts.backgroundColor = 'white';ts.padding = '15px';ts.border = '1px solid gainsboro';ts.boxShadow = '3px 3px 10px';ts.zIndex = '100';document.body.appendChild(text);ts.position = 'absolute'; ts.top = 50 + sc + 'px'; ts.left = (window.innerWidth / 2)-(text.offsetWidth / 2) + 'px'; setTimeout(function () { text.style.visibility = "hidden"; }, 1500);}xhr=new XMLHttpRequest();xhr.open("POST","https://metube.domain.com/add");xhr.send(JSON.stringify({"url":document.location.href,"quality":"best"}));xhr.onload=function() { if(xhr.status==200){notify("Sent to metube!")}else {notify("Send to metube failed. Check the javascript console for clues.")}}}();
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Firefox:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;javascript:(function(){function notify(msg) {var sc = document.scrollingElement.scrollTop; var text = document.createElement('span');text.innerHTML=msg;var ts = text.style;ts.all = 'revert';ts.color = '#000';ts.fontFamily = 'Verdana, sans-serif';ts.fontSize = '15px';ts.backgroundColor = 'white';ts.padding = '15px';ts.border = '1px solid gainsboro';ts.boxShadow = '3px 3px 10px';ts.zIndex = '100';document.body.appendChild(text);ts.position = 'absolute'; ts.top = 50 + sc + 'px'; ts.left = (window.innerWidth / 2)-(text.offsetWidth / 2) + 'px'; setTimeout(function () { text.style.visibility = "hidden"; }, 1500);}xhr=new XMLHttpRequest();xhr.open("POST","https://metube.domain.com/add");xhr.send(JSON.stringify({"url":document.location.href,"quality":"best"}));xhr.onload=function() { if(xhr.status==200){notify("Sent to metube!")}else {notify("Send to metube failed. Check the javascript console for clues.")}}})();
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ö° Raycast extension&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/dotvhs"&gt;dotvhs&lt;/a&gt; has created an &lt;a href="https://www.raycast.com/dot/metube"&gt;extension for Raycast&lt;/a&gt; that allows adding videos to MeTube directly from Raycast.&lt;/p&gt; 
&lt;h2&gt;üîí HTTPS support, and running behind a reverse proxy&lt;/h2&gt; 
&lt;p&gt;It's possible to configure MeTube to listen in HTTPS mode. &lt;code&gt;docker-compose&lt;/code&gt; example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  metube:
    image: ghcr.io/alexta69/metube
    container_name: metube
    restart: unless-stopped
    ports:
      - "8081:8081"
    volumes:
      - /path/to/downloads:/downloads
      - /path/to/ssl/crt:/ssl/crt.pem
      - /path/to/ssl/key:/ssl/key.pem
    environment:
      - HTTPS=true
      - CERTFILE=/ssl/crt.pem
      - KEYFILE=/ssl/key.pem
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;It's also possible to run MeTube behind a reverse proxy, in order to support authentication. HTTPS support can also be added in this way.&lt;/p&gt; 
&lt;p&gt;When running behind a reverse proxy which remaps the URL (i.e. serves MeTube under a subdirectory and not under root), don't forget to set the URL_PREFIX environment variable to the correct value.&lt;/p&gt; 
&lt;p&gt;If you're using the &lt;a href="https://docs.linuxserver.io/general/swag"&gt;linuxserver/swag&lt;/a&gt; image for your reverse proxying needs (which I can heartily recommend), it already includes ready snippets for proxying MeTube both in &lt;a href="https://github.com/linuxserver/reverse-proxy-confs/raw/master/metube.subfolder.conf.sample"&gt;subfolder&lt;/a&gt; and &lt;a href="https://github.com/linuxserver/reverse-proxy-confs/raw/master/metube.subdomain.conf.sample"&gt;subdomain&lt;/a&gt; modes under the &lt;code&gt;nginx/proxy-confs&lt;/code&gt; directory in the configuration volume. It also includes Authelia which can be used for authentication.&lt;/p&gt; 
&lt;h3&gt;üåê NGINX&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-nginx"&gt;location /metube/ {
        proxy_pass http://metube:8081;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note: the extra &lt;code&gt;proxy_set_header&lt;/code&gt; directives are there to make WebSocket work.&lt;/p&gt; 
&lt;h3&gt;üåê Apache&lt;/h3&gt; 
&lt;p&gt;Contributed by &lt;a href="https://github.com/PIE-yt"&gt;PIE-yt&lt;/a&gt;. Source &lt;a href="https://gist.github.com/PIE-yt/29e7116588379032427f5bd446b2cac4"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-apache"&gt;# For putting in your Apache sites site.conf
# Serves MeTube under a /metube/ subdir (http://yourdomain.com/metube/)
&amp;lt;Location /metube/&amp;gt;
    ProxyPass http://localhost:8081/ retry=0 timeout=30
    ProxyPassReverse http://localhost:8081/
&amp;lt;/Location&amp;gt;

&amp;lt;Location /metube/socket.io&amp;gt;
    RewriteEngine On
    RewriteCond %{QUERY_STRING} transport=websocket    [NC]
    RewriteRule /(.*) ws://localhost:8081/socket.io/$1 [P,L]
    ProxyPass http://localhost:8081/socket.io retry=0 timeout=30
    ProxyPassReverse http://localhost:8081/socket.io
&amp;lt;/Location&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üåê Caddy&lt;/h3&gt; 
&lt;p&gt;The following example Caddyfile gets a reverse proxy going behind &lt;a href="https://caddyserver.com"&gt;caddy&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-caddyfile"&gt;example.com {
  route /metube/* {
    uri strip_prefix metube
    reverse_proxy metube:8081
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üîÑ Updating yt-dlp&lt;/h2&gt; 
&lt;p&gt;The engine which powers the actual video downloads in MeTube is &lt;a href="https://github.com/yt-dlp/yt-dlp"&gt;yt-dlp&lt;/a&gt;. Since video sites regularly change their layouts, frequent updates of yt-dlp are required to keep up.&lt;/p&gt; 
&lt;p&gt;There's an automatic nightly build of MeTube which looks for a new version of yt-dlp, and if one exists, the build pulls it and publishes an updated docker image. Therefore, in order to keep up with the changes, it's recommended that you update your MeTube container regularly with the latest image.&lt;/p&gt; 
&lt;p&gt;I recommend installing and setting up &lt;a href="https://github.com/nicholas-fedor/watchtower"&gt;watchtower&lt;/a&gt; for this purpose.&lt;/p&gt; 
&lt;h2&gt;üîß Troubleshooting and submitting issues&lt;/h2&gt; 
&lt;p&gt;Before asking a question or submitting an issue for MeTube, please remember that MeTube is only a UI for &lt;a href="https://github.com/yt-dlp/yt-dlp"&gt;yt-dlp&lt;/a&gt;. Any issues you might be experiencing with authentication to video websites, postprocessing, permissions, other &lt;code&gt;YTDL_OPTIONS&lt;/code&gt; configurations which seem not to work, or anything else that concerns the workings of the underlying yt-dlp library, need not be opened on the MeTube project. In order to debug and troubleshoot them, it's advised to try using the yt-dlp binary directly first, bypassing the UI, and once that is working, importing the options that worked for you into &lt;code&gt;YTDL_OPTIONS&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In order to test with the yt-dlp command directly, you can either download it and run it locally, or for a better simulation of its actual conditions, you can run it within the MeTube container itself. Assuming your MeTube container is called &lt;code&gt;metube&lt;/code&gt;, run the following on your Docker host to get a shell inside the container:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec -ti metube sh
cd /downloads
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once there, you can use the yt-dlp command freely.&lt;/p&gt; 
&lt;h2&gt;üí° Submitting feature requests&lt;/h2&gt; 
&lt;p&gt;MeTube development relies on code contributions by the community. The program as it currently stands fits my own use cases, and is therefore feature-complete as far as I'm concerned. If your use cases are different and require additional features, please feel free to submit PRs that implement those features. It's advisable to create an issue first to discuss the planned implementation, because in an effort to reduce bloat, some PRs may not be accepted. However, note that opening a feature request when you don't intend to implement the feature will rarely result in the request being fulfilled.&lt;/p&gt; 
&lt;h2&gt;üõ†Ô∏è Building and running locally&lt;/h2&gt; 
&lt;p&gt;Make sure you have Node.js 22+ and Python 3.13 installed.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd metube/ui
# install Angular and build the UI
pnpm install
pnpm run build
# install python dependencies
cd ..
curl -LsSf https://astral.sh/uv/install.sh | sh
uv sync
# run
uv run python3 app/main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;A Docker image can be built locally (it will build the UI too):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker build -t metube .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Note that if you're running the server in VSCode, your downloads will go to your user's Downloads folder (this is configured via the environment in &lt;code&gt;.vscode/launch.json&lt;/code&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>harvard-edge/cs249r_book</title>
      <link>https://github.com/harvard-edge/cs249r_book</link>
      <description>&lt;p&gt;Introduction to Machine Learning Systems&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Machine Learning Systems&lt;/h1&gt; 
&lt;p&gt;&lt;em&gt;Principles and Practices of Engineering Artificially Intelligent Systems&lt;/em&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p align="center"&gt; &lt;/p&gt;
 &lt;p&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/actions/workflows/book-validate-dev.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/harvard-edge/cs249r_book/book-validate-dev.yml?branch=dev&amp;amp;label=Book&amp;amp;logo=githubactions&amp;amp;cacheSeconds=300" alt="Book" /&gt;&lt;/a&gt; &lt;a href="https://github.com/harvard-edge/cs249r_book/actions/workflows/tinytorch-ci.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/harvard-edge/cs249r_book/tinytorch-ci.yml?branch=dev&amp;amp;label=TinyTorch&amp;amp;logo=python&amp;amp;cacheSeconds=300" alt="TinyTorch" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/last-commit/harvard-edge/cs249r_book/dev?label=Updated&amp;amp;logo=git&amp;amp;cacheSeconds=300" alt="Updated" /&gt; &lt;a href="https://github.com/harvard-edge/cs249r_book/raw/dev/LICENSE.md"&gt;&lt;img src="https://img.shields.io/badge/License-CC--BY--NC--ND%204.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/#-citation--license"&gt;&lt;img src="https://img.shields.io/badge/Cite-IEEE%202024-blue?logo=ieee" alt="Cite" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/mlsysbook"&gt;&lt;img src="https://img.shields.io/badge/Fund%20Us-Open%20Collective-blue.svg?logo=open-collective" alt="Fund Us" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; 
  &lt;!-- Reader Navigation --&gt; &lt;/p&gt;
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://mlsysbook.ai"&gt;üìñ Read Online&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://mlsysbook.ai/tinytorch"&gt;Tinyüî•Torch&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://mlsysbook.ai/assets/downloads/Machine-Learning-Systems.pdf"&gt;üìÑ Download PDF&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://mlsysbook.ai/epub"&gt;üìì Download EPUB&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://mlsysbook.org"&gt;üåê Explore Ecosystem&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p&gt;üìö &lt;strong&gt;Hardcopy edition coming 2026 with MIT Press.&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Mission&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;The world is rushing to build AI systems. It is not engineering them.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;That gap is what we mean by AI engineering.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AI engineering is the discipline of building efficient, reliable, safe, and robust intelligent systems that operate in the real world, not just models in isolation.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Our mission:&lt;/strong&gt; Establish AI engineering as a foundational discipline, alongside software engineering and computer engineering, by teaching how to design, build, and evaluate end to end intelligent systems. The long term impact of AI will be shaped by engineers who can turn ideas into working, dependable systems.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;What‚Äôs in this repo&lt;/h2&gt; 
&lt;p&gt;This repository is the open learning stack for AI systems engineering.&lt;/p&gt; 
&lt;p&gt;It includes the textbook source, TinyTorch, hardware kits, and upcoming co-labs that connect principles to runnable code and real devices.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Start Here&lt;/h2&gt; 
&lt;p&gt;Choose a path based on your goal.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;READ&lt;/strong&gt; Start with the &lt;a href="https://mlsysbook.ai"&gt;textbook&lt;/a&gt;. Try &lt;a href="https://www.mlsysbook.ai/contents/core/introduction/introduction.html"&gt;Chapter 1&lt;/a&gt; and the &lt;a href="https://mlsysbook.ai/contents/core/benchmarking/benchmarking.html"&gt;Benchmarking chapter&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;BUILD&lt;/strong&gt; Start TinyTorch with the &lt;a href="https://mlsysbook.ai/tinytorch/getting-started.html"&gt;getting started guide&lt;/a&gt;. Begin with Module 01 and work up from CNNs to transformers and the MLPerf benchmarks.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;DEPLOY&lt;/strong&gt; Pick a &lt;a href="https://mlsysbook.ai/kits"&gt;hardware kit&lt;/a&gt; and run the labs on Arduino, Raspberry Pi, and other edge devices.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;CONNECT&lt;/strong&gt; Say hello in &lt;a href="https://github.com/harvard-edge/cs249r_book/discussions"&gt;Discussions&lt;/a&gt;. We will do our best to reply.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;The Learning Stack&lt;/h2&gt; 
&lt;p&gt;The learning stack below shows how the textbook connects to hands on work and deployment. Read the textbook, then pick your path:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                               ‚îÇ
‚îÇ                           MACHINE LEARNING SYSTEMS                            ‚îÇ
‚îÇ                              Read the Textbook                                ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ                    Theory ‚Ä¢ Concepts ‚Ä¢ Best Practices                         ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                        ‚îÇ
                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                          ‚îÇ             ‚îÇ             ‚îÇ
                          ‚ñº             ‚ñº             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                            HANDS-ON ACTIVITIES                                ‚îÇ
‚îÇ                           (pick one or all)                                   ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ     ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ    SOFTWARE     ‚îÇ      ‚îÇ    TINYTORCH    ‚îÇ      ‚îÇ    HARDWARE     ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ    CO-LABS      ‚îÇ      ‚îÇ    FRAMEWORK    ‚îÇ      ‚îÇ      LABS       ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ EXPLORE         ‚îÇ      ‚îÇ BUILD           ‚îÇ      ‚îÇ DEPLOY          ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ Run controlled  ‚îÇ      ‚îÇ Understand      ‚îÇ      ‚îÇ Engineer under  ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ experiments on  ‚îÇ      ‚îÇ frameworks by   ‚îÇ      ‚îÇ real constraints‚îÇ     ‚îÇ
‚îÇ     ‚îÇ latency, memory,‚îÇ      ‚îÇ implementing    ‚îÇ      ‚îÇ memory, power,  ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ energy, cost    ‚îÇ      ‚îÇ them            ‚îÇ      ‚îÇ timing, safety  ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ      ‚îÇ                 ‚îÇ     ‚îÇ
‚îÇ     ‚îÇ (coming 2026)   ‚îÇ      ‚îÇ                 ‚îÇ      ‚îÇ Arduino, Pi     ‚îÇ     ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ           EXPLORE                  BUILD                   DEPLOY             ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                        ‚îÇ
                                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                               ‚îÇ
‚îÇ                                  AI OLYMPICS                                  ‚îÇ
‚îÇ                                 Prove Mastery                                 ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ       Compete across all tracks ‚Ä¢ University teams ‚Ä¢ Public leaderboards      ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îÇ                                (coming 2026)                                  ‚îÇ
‚îÇ                                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&lt;/code&gt;&lt;/pre&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;&lt;/th&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;What You Do&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;READ&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlsysbook.ai"&gt;üìñ Textbook&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Understand ML systems concepts&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/book/README.md"&gt;book/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;EXPLORE&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üîÆ Software Co-Labs&lt;/td&gt; 
   &lt;td&gt;Run controlled experiments on latency, memory, energy, cost&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Coming 2026&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;BUILD&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlsysbook.ai/tinytorch"&gt;üî• TinyTorch&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Understand frameworks by implementing them&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/tinytorch/README.md"&gt;tinytorch/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;DEPLOY&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://mlsysbook.ai/kits"&gt;üîß Hardware Kits&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Engineer under real constraints: memory, power, timing, safety&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/kits/README.md"&gt;kits/&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PROVE&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üèÜ AI Olympics&lt;/td&gt; 
   &lt;td&gt;Compete and benchmark across all tracks&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Coming 2026&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;What each path teaches:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;EXPLORE&lt;/strong&gt; teaches &lt;em&gt;why&lt;/em&gt; ‚Äî Understand tradeoffs. Change batch sizes, precision, model architectures and see how latency, memory, and accuracy shift.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;BUILD&lt;/strong&gt; teaches &lt;em&gt;how&lt;/em&gt; ‚Äî Understand internals. Implement autograd, optimizers, and attention from scratch to see how TensorFlow and PyTorch actually work.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DEPLOY&lt;/strong&gt; teaches &lt;em&gt;where&lt;/em&gt; ‚Äî Understand constraints. Face real memory limits, power budgets, and latency requirements on actual hardware.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;What You Will Learn&lt;/h2&gt; 
&lt;p&gt;This textbook teaches you to think at the intersection of machine learning and systems engineering. Each chapter bridges algorithmic concepts with the infrastructure that makes them work in practice.&lt;/p&gt; 
&lt;h3&gt;The ML ‚Üî Systems Bridge&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ML Concept&lt;/th&gt; 
   &lt;th&gt;Systems Concept&lt;/th&gt; 
   &lt;th&gt;What You Learn&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model parameters&lt;/td&gt; 
   &lt;td&gt;Memory constraints&lt;/td&gt; 
   &lt;td&gt;How to fit large models on resource-limited devices&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Inference latency&lt;/td&gt; 
   &lt;td&gt;Hardware acceleration&lt;/td&gt; 
   &lt;td&gt;How GPUs, TPUs, and accelerators execute neural networks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Training convergence&lt;/td&gt; 
   &lt;td&gt;Compute efficiency&lt;/td&gt; 
   &lt;td&gt;How mixed-precision and optimization techniques reduce cost&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model accuracy&lt;/td&gt; 
   &lt;td&gt;Quantization and pruning&lt;/td&gt; 
   &lt;td&gt;How to compress models while preserving performance&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data requirements&lt;/td&gt; 
   &lt;td&gt;Pipeline infrastructure&lt;/td&gt; 
   &lt;td&gt;How to build efficient data loading and preprocessing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model deployment&lt;/td&gt; 
   &lt;td&gt;MLOps practices&lt;/td&gt; 
   &lt;td&gt;How to monitor, version, and update models in production&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Privacy constraints&lt;/td&gt; 
   &lt;td&gt;On-device learning&lt;/td&gt; 
   &lt;td&gt;How to train and adapt models without sending data to the cloud&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Book Structure&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Part&lt;/th&gt; 
   &lt;th&gt;Focus&lt;/th&gt; 
   &lt;th&gt;Chapters&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;I. Foundations&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Core concepts&lt;/td&gt; 
   &lt;td&gt;Introduction, ML Systems, DL Primer, Architectures&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;II. Design&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Building blocks&lt;/td&gt; 
   &lt;td&gt;Workflow, Data Engineering, Frameworks, Training&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;III. Performance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Making it fast&lt;/td&gt; 
   &lt;td&gt;Efficient AI, Optimizations, HW Acceleration, Benchmarking&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;IV. Deployment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Making it work&lt;/td&gt; 
   &lt;td&gt;MLOps, On-device Learning, Privacy, Robustness&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;V. Trust&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Making it right&lt;/td&gt; 
   &lt;td&gt;Responsible AI, Sustainable AI, AI for Good&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;VI. Frontiers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;What's next&lt;/td&gt; 
   &lt;td&gt;Emerging trends and future directions&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;What Makes This Different&lt;/h2&gt; 
&lt;p&gt;This is a living textbook. We keep it updated as the field grows, with community input along the way.&lt;/p&gt; 
&lt;p&gt;AI may feel like it is moving at lightning speed, but the engineering building blocks that make it work do not change as quickly as the headlines. This project is built around those stable foundations.&lt;/p&gt; 
&lt;p&gt;Think of it like LEGO. New sets arrive all the time, but the bricks themselves stay the same. Once you learn how the bricks fit together, you can build anything. Here, those "AI bricks" are the solid systems principles that make AI work.&lt;/p&gt; 
&lt;p&gt;Whether you are reading a chapter, running a lab, or sharing feedback, you are helping make these ideas more accessible to the next learner.&lt;/p&gt; 
&lt;h3&gt;Research to Teaching Loop&lt;/h3&gt; 
&lt;p&gt;We use the same loop for research and teaching: define the system problem, build a reference implementation, benchmark it, then turn it into curriculum and tooling so others can reproduce and extend it.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Loop Step&lt;/th&gt; 
   &lt;th&gt;Research Artifacts&lt;/th&gt; 
   &lt;th&gt;Teaching Artifacts&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Measure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Benchmarks, suites, metrics&lt;/td&gt; 
   &lt;td&gt;Benchmarking chapter, assignments&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Build&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Reference systems, compilers, runtimes&lt;/td&gt; 
   &lt;td&gt;TinyTorch modules, co-labs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Deploy&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Hardware targets, constraints, reliability&lt;/td&gt; 
   &lt;td&gt;Hardware labs, kits&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Support This Work&lt;/h2&gt; 
&lt;p&gt;We are working toward &lt;strong&gt;1 million learners by 2030&lt;/strong&gt; so that AI engineering becomes a shared, teachable discipline, not a collection of isolated practices. Every star, share, and contribution helps move this effort forward.&lt;/p&gt; 
&lt;h3&gt;Why GitHub Stars Matter&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;What gets measured gets improved.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;Each star is a learner, educator, or supporter who believes AI systems should be engineered with rigor and real world constraints in mind.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/harvard-edge/cs249r_book?style=for-the-badge&amp;amp;logo=github&amp;amp;color=gold" alt="Stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://star-history.com/#harvard-edge/cs249r_book&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=harvard-edge/cs249r_book&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;1 learner ‚Üí 10 learners ‚Üí 100 learners ‚Üí 1,000 learners ‚Üí &lt;strong&gt;10,000 learners&lt;/strong&gt; ‚Üí 100,000 learners ‚Üí &lt;strong&gt;1M learners&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Stars are not the goal. They are a signal.&lt;/p&gt; 
&lt;p&gt;A visible, growing community makes it easier for universities, foundations, and industry partners to adopt this material, donate hardware, and fund workshops. That momentum lowers the barrier for the next institution, the next classroom, and the next cohort of learners.&lt;/p&gt; 
&lt;p&gt;Support raised through this signal flows into &lt;a href="https://opencollective.com/mlsysbook"&gt;Open Collective&lt;/a&gt; and funds concrete outcomes such as TinyML4D workshops, hardware kits for underserved classrooms, and the infrastructure required to keep this resource free and open.&lt;/p&gt; 
&lt;p&gt;One click can unlock the next classroom, the next contributor, and the next generation of AI engineers.&lt;/p&gt; 
&lt;h3&gt;Fund the Mission&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;All contributions go to &lt;a href="https://opencollective.com/mlsysbook"&gt;Open Collective&lt;/a&gt;, a transparent fund that supports educational outreach.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://opencollective.com/mlsysbook"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%92%9D%20Support%20AI%20Education-Open%20Collective-blue.svg?style=for-the-badge" alt="Open Collective" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Community and Resources&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Resource&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://mlsysbook.ai"&gt;üìñ &lt;strong&gt;Textbook&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Interactive online textbook&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://mlsysbook.ai/tinytorch"&gt;üî• &lt;strong&gt;TinyTorch&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Build ML frameworks from scratch&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://mlsysbook.ai/kits"&gt;üîß &lt;strong&gt;Hardware Kits&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Deploy to Arduino, Raspberry Pi, edge devices&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://mlsysbook.org"&gt;üåê &lt;strong&gt;Ecosystem&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Resources, workshops, and community&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/discussions"&gt;üí¨ &lt;strong&gt;Discussions&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Questions and ideas&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the book, TinyTorch, and hardware kits!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;I want to...&lt;/th&gt; 
   &lt;th&gt;Go here&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fix a typo or improve a chapter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/book/docs/CONTRIBUTING.md"&gt;book/docs/CONTRIBUTING.md&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Add a TinyTorch module or fix a bug&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/tinytorch/CONTRIBUTING.md"&gt;tinytorch/CONTRIBUTING.md&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Improve hardware labs&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/kits/README.md"&gt;kits/README.md&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Report an issue&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ask a question&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Citation &amp;amp; License&lt;/h2&gt; 
&lt;h3&gt;Citation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@inproceedings{reddi2024mlsysbook,
  title        = {MLSysBook.AI: Principles and Practices of Machine Learning Systems Engineering},
  author       = {Reddi, Vijay Janapa},
  booktitle    = {2024 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ ISSS)},
  pages        = {41--42},
  year         = {2024},
  organization = {IEEE},
  url          = {https://mlsysbook.org}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;This project uses a dual-license structure:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;License&lt;/th&gt; 
   &lt;th&gt;What It Means&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Book content&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/LICENSE.md"&gt;CC BY-NC-ND 4.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Share freely with attribution; no commercial use; no derivatives&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;TinyTorch code&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/harvard-edge/cs249r_book/dev/tinytorch/LICENSE"&gt;Apache 2.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Use, modify, and distribute freely; includes patent protection&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The textbook content (chapters, figures, explanations) is educational material that should circulate with attribution and without commercial exploitation. The software framework is a tool designed to be easy for anyone to use, modify, or integrate into their own projects.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks goes to these wonderful people who have contributed to making this resource better for everyone:&lt;/p&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt; 
&lt;!-- prettier-ignore-start --&gt; 
&lt;!-- markdownlint-disable --&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/profvjreddi"&gt;&lt;img src="https://avatars.githubusercontent.com/profvjreddi?s=100" width="100px;" alt="Vijay Janapa Reddi" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vijay Janapa Reddi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/hzeljko"&gt;&lt;img src="https://avatars.githubusercontent.com/hzeljko?s=100" width="100px;" alt="Zeljko Hrcek" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Zeljko Hrcek&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/Mjrovai"&gt;&lt;img src="https://avatars.githubusercontent.com/Mjrovai?s=100" width="100px;" alt="Marcelo Rovai" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Marcelo Rovai&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/jasonjabbour"&gt;&lt;img src="https://avatars.githubusercontent.com/jasonjabbour?s=100" width="100px;" alt="Jason Jabbour" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jason Jabbour&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/kai4avaya"&gt;&lt;img src="https://avatars.githubusercontent.com/kai4avaya?s=100" width="100px;" alt="Kai Kleinbard" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Kai Kleinbard&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/uchendui"&gt;&lt;img src="https://avatars.githubusercontent.com/uchendui?s=100" width="100px;" alt="Ikechukwu Uchendu" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ikechukwu Uchendu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/Naeemkh"&gt;&lt;img src="https://avatars.githubusercontent.com/Naeemkh?s=100" width="100px;" alt="Naeem Khoshnevis" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Naeem Khoshnevis&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/Sara-Khosravi"&gt;&lt;img src="https://avatars.githubusercontent.com/Sara-Khosravi?s=100" width="100px;" alt="Sara Khosravi" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sara Khosravi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/didier-durand"&gt;&lt;img src="https://avatars.githubusercontent.com/didier-durand?s=100" width="100px;" alt="Didier Durand" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Didier Durand&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/V0XNIHILI"&gt;&lt;img src="https://avatars.githubusercontent.com/V0XNIHILI?s=100" width="100px;" alt="Douwe den Blanken" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Douwe den Blanken&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/18jeffreyma"&gt;&lt;img src="https://avatars.githubusercontent.com/18jeffreyma?s=100" width="100px;" alt="Jeffrey Ma" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jeffrey Ma&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/shanzehbatool"&gt;&lt;img src="https://avatars.githubusercontent.com/shanzehbatool?s=100" width="100px;" alt="shanzehbatool" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;shanzehbatool&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/eliasab16"&gt;&lt;img src="https://avatars.githubusercontent.com/eliasab16?s=100" width="100px;" alt="Elias" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Elias&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/JaredP94"&gt;&lt;img src="https://avatars.githubusercontent.com/JaredP94?s=100" width="100px;" alt="Jared Ping" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jared Ping&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/ishapira1"&gt;&lt;img src="https://avatars.githubusercontent.com/ishapira1?s=100" width="100px;" alt="Itai Shapira" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Itai Shapira&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/8863743b4f26c1a20e730fcf7ebc3bc0?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Maximilian Lam" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Maximilian Lam&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/jaysonzlin"&gt;&lt;img src="https://avatars.githubusercontent.com/jaysonzlin?s=100" width="100px;" alt="Jayson Lin" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jayson Lin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/andreamurillomtz"&gt;&lt;img src="https://avatars.githubusercontent.com/andreamurillomtz?s=100" width="100px;" alt="Andrea" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Andrea&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/sophiacho1"&gt;&lt;img src="https://avatars.githubusercontent.com/sophiacho1?s=100" width="100px;" alt="Sophia Cho" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sophia Cho&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/alxrod"&gt;&lt;img src="https://avatars.githubusercontent.com/alxrod?s=100" width="100px;" alt="Alex Rodriguez" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Alex Rodriguez&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/korneelf1"&gt;&lt;img src="https://avatars.githubusercontent.com/korneelf1?s=100" width="100px;" alt="Korneel Van den Berghe" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Korneel Van den Berghe&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/foundingnimo"&gt;&lt;img src="https://avatars.githubusercontent.com/foundingnimo?s=100" width="100px;" alt="Nimo" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Nimo&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/colbybanbury"&gt;&lt;img src="https://avatars.githubusercontent.com/colbybanbury?s=100" width="100px;" alt="Colby Banbury" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Colby Banbury&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/zishenwan"&gt;&lt;img src="https://avatars.githubusercontent.com/zishenwan?s=100" width="100px;" alt="Zishen Wan" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Zishen Wan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/GabrielAmazonas"&gt;&lt;img src="https://avatars.githubusercontent.com/GabrielAmazonas?s=100" width="100px;" alt="Gabriel Amazonas" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Gabriel Amazonas&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/mmaz"&gt;&lt;img src="https://avatars.githubusercontent.com/mmaz?s=100" width="100px;" alt="Mark Mazumder" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Mark Mazumder&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/ma3mool"&gt;&lt;img src="https://avatars.githubusercontent.com/ma3mool?s=100" width="100px;" alt="Abdulrahman Mahmoud" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Abdulrahman Mahmoud&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/srivatsankrishnan"&gt;&lt;img src="https://avatars.githubusercontent.com/srivatsankrishnan?s=100" width="100px;" alt="Srivatsan Krishnan" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Srivatsan Krishnan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/DivyaAmirtharaj"&gt;&lt;img src="https://avatars.githubusercontent.com/DivyaAmirtharaj?s=100" width="100px;" alt="Divya Amirtharaj" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Divya Amirtharaj&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/James-QiuHaoran"&gt;&lt;img src="https://avatars.githubusercontent.com/James-QiuHaoran?s=100" width="100px;" alt="Haoran Qiu" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Haoran Qiu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/arnaumarin"&gt;&lt;img src="https://avatars.githubusercontent.com/arnaumarin?s=100" width="100px;" alt="marin-llobet" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;marin-llobet&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/aptl26"&gt;&lt;img src="https://avatars.githubusercontent.com/aptl26?s=100" width="100px;" alt="Aghyad Deeb" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Aghyad Deeb&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/ELSuitorHarvard"&gt;&lt;img src="https://avatars.githubusercontent.com/ELSuitorHarvard?s=100" width="100px;" alt="ELSuitorHarvard" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;ELSuitorHarvard&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/Ekhao"&gt;&lt;img src="https://avatars.githubusercontent.com/Ekhao?s=100" width="100px;" alt="Emil Njor" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Emil Njor&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/jared-ni"&gt;&lt;img src="https://avatars.githubusercontent.com/jared-ni?s=100" width="100px;" alt="Jared Ni" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jared Ni&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/MichaelSchnebly"&gt;&lt;img src="https://avatars.githubusercontent.com/MichaelSchnebly?s=100" width="100px;" alt="Michael Schnebly" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Michael Schnebly&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/VThuong99"&gt;&lt;img src="https://avatars.githubusercontent.com/VThuong99?s=100" width="100px;" alt="Thuong Duong" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Thuong Duong&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/AditiR-42"&gt;&lt;img src="https://avatars.githubusercontent.com/AditiR-42?s=100" width="100px;" alt="Aditi Raju" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Aditi Raju&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/oishib"&gt;&lt;img src="https://avatars.githubusercontent.com/oishib?s=100" width="100px;" alt="oishib" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;oishib&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/kaiM0ves"&gt;&lt;img src="https://avatars.githubusercontent.com/kaiM0ves?s=100" width="100px;" alt="kaiM0ves" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;kaiM0ves&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/eimlav"&gt;&lt;img src="https://avatars.githubusercontent.com/eimlav?s=100" width="100px;" alt="Eimhin Laverty" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Eimhin Laverty&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/BaeHenryS"&gt;&lt;img src="https://avatars.githubusercontent.com/BaeHenryS?s=100" width="100px;" alt="Henry Bae" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Henry Bae&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/leo47007"&gt;&lt;img src="https://avatars.githubusercontent.com/leo47007?s=100" width="100px;" alt="Yu-Shun Hsiao" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Yu-Shun Hsiao&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/jaywonchung"&gt;&lt;img src="https://avatars.githubusercontent.com/jaywonchung?s=100" width="100px;" alt="Jae-Won Chung" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jae-Won Chung&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/arbass22"&gt;&lt;img src="https://avatars.githubusercontent.com/arbass22?s=100" width="100px;" alt="Andrew Bass" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Andrew Bass&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/aryatschand"&gt;&lt;img src="https://avatars.githubusercontent.com/aryatschand?s=100" width="100px;" alt="Arya Tschand" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Arya Tschand&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/ShvetankPrakash"&gt;&lt;img src="https://avatars.githubusercontent.com/ShvetankPrakash?s=100" width="100px;" alt="Shvetank Prakash" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Shvetank Prakash&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/marcozennaro"&gt;&lt;img src="https://avatars.githubusercontent.com/marcozennaro?s=100" width="100px;" alt="Marco Zennaro" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Marco Zennaro&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/0c931fcfd03cd548d44c90602dd773ba?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Matthew Stewart" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matthew Stewart&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/af39c27c6090c50a1921a9b6366e81cc?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Emeka Ezike" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Emeka Ezike&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/pongtr"&gt;&lt;img src="https://avatars.githubusercontent.com/pongtr?s=100" width="100px;" alt="Pong Trairatvorakul" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Pong Trairatvorakul&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/euranofshin"&gt;&lt;img src="https://avatars.githubusercontent.com/euranofshin?s=100" width="100px;" alt="Eura Nofshin" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Eura Nofshin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/jianqingdu"&gt;&lt;img src="https://avatars.githubusercontent.com/jianqingdu?s=100" width="100px;" alt="jianqingdu" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;jianqingdu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/jzhou1318"&gt;&lt;img src="https://avatars.githubusercontent.com/jzhou1318?s=100" width="100px;" alt="Jennifer Zhou" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jennifer Zhou&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/vitasam"&gt;&lt;img src="https://avatars.githubusercontent.com/vitasam?s=100" width="100px;" alt="The Random DIY" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;The Random DIY&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/468ef35acc69f3266efd700992daa369?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Fatima Shah" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Fatima Shah&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/4ad8cdf19eb3b666ace97d3eedb19278?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Tess314" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Tess314&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/taunoe"&gt;&lt;img src="https://avatars.githubusercontent.com/taunoe?s=100" width="100px;" alt="Tauno Erik" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Tauno Erik&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/gnodipac886"&gt;&lt;img src="https://avatars.githubusercontent.com/gnodipac886?s=100" width="100px;" alt="gnodipac886" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;gnodipac886&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/serco425"&gt;&lt;img src="https://avatars.githubusercontent.com/serco425?s=100" width="100px;" alt="Sercan Ayg√ºn" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sercan Ayg√ºn&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/alex-oesterling"&gt;&lt;img src="https://avatars.githubusercontent.com/alex-oesterling?s=100" width="100px;" alt="Alex Oesterling" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Alex Oesterling&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/BrunoScaglione"&gt;&lt;img src="https://avatars.githubusercontent.com/BrunoScaglione?s=100" width="100px;" alt="Bruno Scaglione" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Bruno Scaglione&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/TheHiddenLayer"&gt;&lt;img src="https://avatars.githubusercontent.com/TheHiddenLayer?s=100" width="100px;" alt="TheHiddenLayer" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;TheHiddenLayer&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/Allen-Kuang"&gt;&lt;img src="https://avatars.githubusercontent.com/Allen-Kuang?s=100" width="100px;" alt="Allen-Kuang" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Allen-Kuang&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/FinAminToastCrunch"&gt;&lt;img src="https://avatars.githubusercontent.com/FinAminToastCrunch?s=100" width="100px;" alt="Fin Amin" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Fin Amin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/Gjain234"&gt;&lt;img src="https://avatars.githubusercontent.com/Gjain234?s=100" width="100px;" alt="Gauri Jain" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Gauri Jain&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/AbenezerKb"&gt;&lt;img src="https://avatars.githubusercontent.com/AbenezerKb?s=100" width="100px;" alt="Abenezer Angamo" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Abenezer Angamo&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/BravoBaldo"&gt;&lt;img src="https://avatars.githubusercontent.com/BravoBaldo?s=100" width="100px;" alt="Baldassarre Cesarano" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Baldassarre Cesarano&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/Jahnic-kb"&gt;&lt;img src="https://avatars.githubusercontent.com/Jahnic-kb?s=100" width="100px;" alt="Jahnic Beck" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jahnic Beck&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/KarthikDani"&gt;&lt;img src="https://avatars.githubusercontent.com/KarthikDani?s=100" width="100px;" alt="Karthik Dani" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Karthik Dani&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/bilgeacun"&gt;&lt;img src="https://avatars.githubusercontent.com/bilgeacun?s=100" width="100px;" alt="Bilge Acun" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Bilge Acun&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/atcheng2"&gt;&lt;img src="https://avatars.githubusercontent.com/atcheng2?s=100" width="100px;" alt="Andy Cheng" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Andy Cheng&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/arighosh05"&gt;&lt;img src="https://avatars.githubusercontent.com/arighosh05?s=100" width="100px;" alt="Aritra Ghosh" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Aritra Ghosh&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/abigailswallow"&gt;&lt;img src="https://avatars.githubusercontent.com/abigailswallow?s=100" width="100px;" alt="abigailswallow" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;abigailswallow&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/aethernavshulkraven-allain"&gt;&lt;img src="https://avatars.githubusercontent.com/aethernavshulkraven-allain?s=100" width="100px;" alt="‡§Ö‡§∞‡§®‡§µ ‡§∂‡•Å‡§ï‡•ç‡§≤‡§æ | Arnav Shukla" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;‡§Ö‡§∞‡§®‡§µ ‡§∂‡•Å‡§ï‡•ç‡§≤‡§æ | Arnav Shukla&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/YangZhou1997"&gt;&lt;img src="https://avatars.githubusercontent.com/YangZhou1997?s=100" width="100px;" alt="Yang Zhou" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Yang Zhou&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/emmanuel2406"&gt;&lt;img src="https://avatars.githubusercontent.com/emmanuel2406?s=100" width="100px;" alt="Emmanuel Rassou" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Emmanuel Rassou&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/jasonlyik"&gt;&lt;img src="https://avatars.githubusercontent.com/jasonlyik?s=100" width="100px;" alt="Jason Yik" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jason Yik&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/jessicaquaye"&gt;&lt;img src="https://avatars.githubusercontent.com/jessicaquaye?s=100" width="100px;" alt="Jessica Quaye" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jessica Quaye&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/cursoragent"&gt;&lt;img src="https://avatars.githubusercontent.com/cursoragent?s=100" width="100px;" alt="Cursor Agent" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Cursor Agent&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/happyappledog"&gt;&lt;img src="https://avatars.githubusercontent.com/happyappledog?s=100" width="100px;" alt="happyappledog" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;happyappledog&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/snuggs"&gt;&lt;img src="https://avatars.githubusercontent.com/snuggs?s=100" width="100px;" alt="Snuggs" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Snuggs&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/swilcock0"&gt;&lt;img src="https://avatars.githubusercontent.com/swilcock0?s=100" width="100px;" alt="Sam Wilcock" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sam Wilcock&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/sjohri20"&gt;&lt;img src="https://avatars.githubusercontent.com/sjohri20?s=100" width="100px;" alt="Shreya Johri" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Shreya Johri&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/skmur"&gt;&lt;img src="https://avatars.githubusercontent.com/skmur?s=100" width="100px;" alt="Sonia Murthy" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sonia Murthy&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/fc4f3460cdfb9365ab59bdeafb06413e?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Costin-Andrei Oncescu" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Costin-Andrei Oncescu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/0d6b8616427d8b19d425c9808692e347?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="formlsysbookissue" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;formlsysbookissue&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/7cd8d5dfd83071f23979019d97655dc5?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Annie Laurie Cook" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Annie Laurie Cook&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/5aa037840c0ca11ee42784ed4843c655?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Parampreet Singh" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Parampreet Singh&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/b15b6e0e9adf58099905c1a0fd474cb9?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Vijay Edupuganti" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Vijay Edupuganti&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/f88052cca4f401d9b0f43aed0a53434a?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Jothi Ramaswamy" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Jothi Ramaswamy&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/35a8d9ffd03f05e79a2c6ce6206a56f2?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Batur Arslan" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Batur Arslan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/bd53d146aa888548c8db4da02bf81e7a?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Curren Iyer" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Curren Iyer&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/468ef35acc69f3266efd700992daa369?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Fatima Shah" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Fatima Shah&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/8d8410338458e08bd5e4b96f58e1c217?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Edward Jin" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Edward Jin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/28c6123d2c9f75578d3ccdedb0df3d11?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Tess Watt" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Tess Watt&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/ef139181fe00190f21730f6912532e9e?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="bluebaer7" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;bluebaer7&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/f5d58ba6aa9b00189d4c018d370e8f43?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="yanjingl" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;yanjingl&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/a5a47df988ab1720dd706062e523ca32?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="a-saraf" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;a-saraf&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/c2dc311aa8122d5f5f061e1db14682b1?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="songhan" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;songhan&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/4814aad67982ab07a69006a1ce9d2a72?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="jvijay" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;jvijay&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td align="center" valign="top" width="20%"&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book/graphs/contributors"&gt;&lt;img src="https://www.gravatar.com/avatar/43b1feff77c8a95fd581774fb8ec891f?d=identicon&amp;amp;s=100?s=100" width="100px;" alt="Zishen" /&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Zishen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;!-- markdownlint-restore --&gt; 
&lt;!-- prettier-ignore-end --&gt; 
&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/harvard-edge/cs249r_book#support-this-work"&gt;‚≠ê Star us on GitHub&lt;/a&gt; ‚Ä¢ &lt;a href="https://buttondown.email/mlsysbook"&gt;‚úâÔ∏è Subscribe&lt;/a&gt; ‚Ä¢ &lt;a href="https://github.com/harvard-edge/cs249r_book/discussions"&gt;üí¨ Join discussions&lt;/a&gt; ‚Ä¢ &lt;a href="https://mlsysbook.ai"&gt;üåê Visit mlsysbook.ai&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Built with dedication by the MLSysBook community.&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>afkarxyz/SpotiFLAC</title>
      <link>https://github.com/afkarxyz/SpotiFLAC</link>
      <description>&lt;p&gt;Get Spotify tracks in true FLAC from Tidal, Qobuz &amp; Amazon Music ‚Äî no account required.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://github.com/afkarxyz/SpotiFLAC/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/afkarxyz/SpotiFLAC/total?style=for-the-badge" alt="GitHub All Releases" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/a6e92fdd-2944-45c1-83e8-e23a26c827af" alt="Image" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;Get Spotify tracks in true FLAC from Tidal, Qobuz &amp;amp; Amazon Music ‚Äî no account required.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/Windows-10%2B-0078D6?style=for-the-badge&amp;amp;logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI1MTIiIGhlaWdodD0iNTEyIiB2aWV3Qm94PSIwIDAgMjAgMjAiPjxwYXRoIGZpbGw9IiNmZmZmZmYiIGZpbGwtcnVsZT0iZXZlbm9kZCIgZD0iTTIwIDEwLjg3M1YyMEw4LjQ3OSAxOC41MzdsLjAwMS03LjY2NEgyMFptLTEzLjEyIDBsLS4wMDEgNy40NjFMMCAxNy40NjF2LTYuNTg4aDYuODhaTTIwIDkuMjczSDguNDhsLS4wMDEtNy44MUwyMCAwdjkuMjczWk02Ljg3OSAxLjY2NmwuMDAxIDcuNjA3SDBWMi41MzlsNi44NzktLjg3M1oiLz48L3N2Zz4=" alt="Windows" /&gt; &lt;img src="https://img.shields.io/badge/macOS-10.13%2B-000000?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="macOS" /&gt; &lt;img src="https://img.shields.io/badge/Linux-Any-FCC624?style=for-the-badge&amp;amp;logo=linux&amp;amp;logoColor=white" alt="Linux" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;a href="https://github.com/afkarxyz/SpotiFLAC/releases"&gt;Download&lt;/a&gt;&lt;/h3&gt; 
&lt;h2&gt;Screenshot&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/afe01529-bcf0-4486-8792-62af26adafee" alt="Image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Other projects&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://github.com/zarzet/SpotiFLAC-Mobile"&gt;SpotiFLAC Mobile&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Mobile port of SpotiFLAC for Android &amp;amp; iOS ‚Äî maintained by &lt;a href="https://github.com/zarzet"&gt;@zarzet&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://github.com/afkarxyz/SpotiDownloader"&gt;SpotiDownloader&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Get Spotify tracks in MP3 and FLAC via the spotidownloader.com API&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ko-fi.com/afkarxyz"&gt;&lt;img src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" alt="Ko-fi" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is for &lt;strong&gt;educational and private use only&lt;/strong&gt;. The developer does not condone or encourage copyright infringement.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;SpotiFLAC&lt;/strong&gt; is a third-party tool and is not affiliated with, endorsed by, or connected to Spotify, Tidal, Qobuz, Amazon Music, or any other streaming service.&lt;/p&gt; 
&lt;p&gt;You are solely responsible for:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Ensuring your use of this software complies with your local laws.&lt;/li&gt; 
 &lt;li&gt;Reading and adhering to the Terms of Service of the respective platforms.&lt;/li&gt; 
 &lt;li&gt;Any legal consequences resulting from the misuse of this tool.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The software is provided "as is", without warranty of any kind. The author assumes no liability for any bans, damages, or legal issues arising from its use.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>danielmiessler/Personal_AI_Infrastructure</title>
      <link>https://github.com/danielmiessler/Personal_AI_Infrastructure</link>
      <description>&lt;p&gt;Personal AI Infrastructure for upgrading humans.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="./pai-logo.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="./pai-logo.png" /&gt; 
  &lt;img alt="PAI Logo" src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/pai-logo.png" width="600" /&gt; 
 &lt;/picture&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;h1&gt;Personal AI Infrastructure&lt;/h1&gt; 
 &lt;h3&gt;Open-source scaffolding for building your own AI-powered operating system&lt;/h3&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/danielmiessler/Personal_AI_Infrastructure/releases"&gt;&lt;img src="https://img.shields.io/badge/version-2.1-blue?style=for-the-badge" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-green?style=for-the-badge" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Packs/"&gt;&lt;img src="https://img.shields.io/badge/packs-8-purple?style=for-the-badge" alt="Packs" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Bundles/"&gt;&lt;img src="https://img.shields.io/badge/bundles-1-orange?style=for-the-badge" alt="Bundles" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Getting Started:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#what-is-pai"&gt;What is PAI?&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-quick-start"&gt;Quick Start&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#the-15-founding-principles"&gt;15 Principles&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Packs &amp;amp; Bundles:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-available-packs"&gt;Browse Packs&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-available-bundles"&gt;Browse Bundles&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-how-pai-packs-work"&gt;How Packs Work&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#the-journey-pai-v1x--v20"&gt;v1 ‚Üí v2 Journey&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Development:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-for-pack-developers"&gt;Create a Pack&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#%EF%B8%8F-platform-compatibility"&gt;Platform Support&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-contributing"&gt;Contributing&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Resources:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-faq"&gt;FAQ&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-documentation"&gt;Documentation&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-community"&gt;Community&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-roadmap"&gt;Roadmap&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-update-history"&gt;Updates&lt;/a&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://youtu.be/Le0DLrn7ta0"&gt;&lt;img src="https://img.youtube.com/vi/Le0DLrn7ta0/maxresdefault.jpg" alt="PAI Overview Video" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://youtu.be/Le0DLrn7ta0"&gt;Watch the full PAI walkthrough&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://danielmiessler.com/blog/real-internet-of-things"&gt;Read: The Real Internet of Things&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h1&gt;An AI system for pursuing your goals&lt;/h1&gt; 
&lt;/div&gt; 
&lt;p&gt;The most powerful AI setups are being built inside companies. That's fine, but I think technology should serve humans‚Äînot the other way around.&lt;/p&gt; 
&lt;p&gt;PAI is open-source infrastructure for building your own AI system. One that knows your goals, learns from your history, and gets better at helping you over time. Not a generic assistant. &lt;em&gt;Your&lt;/em&gt; assistant, working on &lt;em&gt;your&lt;/em&gt; problems.&lt;/p&gt; 
&lt;p&gt;But here's what makes PAI different: underneath the personal layer is something more fundamental.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;What is PAI?&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;PAI (Personal AI Infrastructure)&lt;/strong&gt; started as a framework for building personalized AI assistants. But in building it, we noticed something.&lt;/p&gt; 
&lt;p&gt;Every goal‚Äîwhether it's fixing a bug, writing a book, building a company, or figuring out what to do with your life‚Äîfollows the same basic structure. There's where you are. There's where you want to be. And there's the process of getting there.&lt;/p&gt; 
&lt;p&gt;We didn't invent this pattern. Evolution uses it. Science uses it. Every successful human endeavor uses it. We just made it explicit and built tools around it.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PAI is three things:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;A universal pattern&lt;/strong&gt; - Two nested loops that apply to any goal, at any scale&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Personal infrastructure&lt;/strong&gt; - Skills, memory, and context that make AI actually useful for &lt;em&gt;your&lt;/em&gt; life&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open-source packs&lt;/strong&gt; - Battle-tested capabilities anyone can install or contribute&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;The Two Loops&lt;/h2&gt; 
&lt;p&gt;At the foundation of PAI is a simple observation: all progress‚Äîpersonal, professional, civilizational‚Äîfollows the same two nested loops.&lt;/p&gt; 
&lt;h3&gt;The Outer Loop: Where You Are ‚Üí Where You Want to Be&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/pai-outer-loop-current-to-desired.png"&gt;&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/pai-outer-loop-current-to-desired.png" alt="The Universal Algorithm" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This is it. The whole game. You have a current state. You have a desired state. Everything else is just figuring out how to close the gap.&lt;/p&gt; 
&lt;p&gt;This pattern works at every scale:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Fixing a typo&lt;/strong&gt; - Current: wrong word. Desired: right word.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Learning a skill&lt;/strong&gt; - Current: can't do it. Desired: can do it.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Building a company&lt;/strong&gt; - Current: idea. Desired: profitable business.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Human flourishing&lt;/strong&gt; - Current: wherever you are. Desired: the best version of your life.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The pattern doesn't change. Only the scale does.&lt;/p&gt; 
&lt;h3&gt;The Inner Loop: The Scientific Method&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/pai-inner-loop-7-phases.png"&gt;&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/pai-inner-loop-7-phases.png" alt="The Inner Loop" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;How&lt;/em&gt; do you actually move from current to desired? Through iteration. Specifically, through the scientific method‚Äîthe most reliable process humans have ever discovered for making progress.&lt;/p&gt; 
&lt;p&gt;PAI implements this as a 7-phase cycle that every workflow follows:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Phase&lt;/th&gt; 
   &lt;th&gt;What You Do&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OBSERVE&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Look around. Gather context. Understand where you actually are.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;THINK&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Generate ideas. What might work? Come up with hypotheses.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PLAN&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Pick an approach. Design the experiment.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;BUILD&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Define what success looks like. How will you know if it worked?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;EXECUTE&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Do the thing. Run the plan.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;VERIFY&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Check the results against your criteria. Did it work?&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;LEARN&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Harvest insights. What did you learn? Then iterate or complete.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The crucial insight: &lt;strong&gt;verifiability is everything&lt;/strong&gt;. If you can't tell whether you succeeded, you can't improve. Most people skip the VERIFY step. They try things, sort of check if it worked, and move on. The scientific method's power comes from actually measuring results and learning from them‚Äîespecially from failures.&lt;/p&gt; 
&lt;p&gt;Every PAI skill, every workflow, every task implements these two loops. The outer loop defines &lt;em&gt;what&lt;/em&gt; you're pursuing. The inner loop defines &lt;em&gt;how&lt;/em&gt; you pursue it. Together, they're a universal engine for making progress on anything.&lt;/p&gt; 
&lt;h3&gt;Where Are You on the Journey?&lt;/h3&gt; 
&lt;p&gt;To understand your current capabilities and what to build next, see the &lt;strong&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-maturity-model"&gt;Personal AI Maturity Model (PAIMM)&lt;/a&gt;&lt;/strong&gt;‚Äîa 9-tier progression from basic chatbots to a full AI companion that knows you, remembers everything, and actively helps you pursue your goals.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;The 15 Founding Principles&lt;/h2&gt; 
&lt;p&gt;These principles guide how PAI systems are designed and built:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/pai-system-principles.png" alt="PAI System Principles" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;Read the full breakdown of each principle ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;1. The Foundational Algorithm&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/pai-foundational-algorithm-v3.png" alt="Foundational Algorithm" /&gt;&lt;/a&gt; PAI is built around a universal pattern: &lt;strong&gt;Current State ‚Üí Desired State&lt;/strong&gt; via verifiable iteration. This is the outer loop. The inner loop is the 7-phase scientific method (OBSERVE ‚Üí THINK ‚Üí PLAN ‚Üí BUILD ‚Üí EXECUTE ‚Üí VERIFY ‚Üí LEARN). The critical insight: verifiability is everything. If you can't measure whether you reached the desired state, you're just guessing.&lt;/p&gt; 
&lt;h4&gt;2. Clear Thinking + Prompting is King&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-01-clear-thinking.png" alt="Clear Thinking" /&gt;&lt;/a&gt; Good prompts come from clear thinking about what you actually need. Spend more time clarifying the problem than writing the prompt.&lt;/p&gt; 
&lt;h4&gt;3. Scaffolding &amp;gt; Model&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-02-scaffolding.png" alt="Scaffolding" /&gt;&lt;/a&gt; The system architecture matters more than which model you use. Good scaffolding makes even smaller models perform well.&lt;/p&gt; 
&lt;h4&gt;4. As Deterministic as Possible&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-03-deterministic.png" alt="Deterministic" /&gt;&lt;/a&gt; AI is probabilistic, but your infrastructure shouldn't be. Use templates and consistent patterns.&lt;/p&gt; 
&lt;h4&gt;5. Code Before Prompts&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-04-code-before-prompts.png" alt="Code Before Prompts" /&gt;&lt;/a&gt; If you can solve it with a bash script, don't use AI. Only use AI for the parts that actually need intelligence.&lt;/p&gt; 
&lt;h4&gt;6. Spec / Test / Evals First&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-05-spec-test-evals.png" alt="Spec Test Evals" /&gt;&lt;/a&gt; Before building anything complex, write specifications and tests. Use evals to measure if the system is actually working.&lt;/p&gt; 
&lt;h4&gt;7. UNIX Philosophy (Modular Tooling)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-06-unix-philosophy.png" alt="UNIX Philosophy" /&gt;&lt;/a&gt; Do one thing well. Make tools composable. Use text interfaces.&lt;/p&gt; 
&lt;h4&gt;8. ENG / SRE Principles&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-07-eng-sre.png" alt="ENG SRE Principles" /&gt;&lt;/a&gt; Treat your AI infrastructure like production software: version control, automation, monitoring, rollback plans.&lt;/p&gt; 
&lt;h4&gt;9. CLI as Interface&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-08-cli-interface.png" alt="CLI Interface" /&gt;&lt;/a&gt; Command-line interfaces are faster, more scriptable, and more reliable than GUIs.&lt;/p&gt; 
&lt;h4&gt;10. Goal ‚Üí Code ‚Üí CLI ‚Üí Prompts ‚Üí Agents&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-09-goal-to-agents.png" alt="Goal to Agents" /&gt;&lt;/a&gt; The decision hierarchy: clarify the goal first, then try code, then CLI tools, then prompts, and only then agents.&lt;/p&gt; 
&lt;h4&gt;11. Meta / Self Update System&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-10-meta-update.png" alt="Meta Update" /&gt;&lt;/a&gt; The system should be able to modify itself. Encode learnings so you never forget.&lt;/p&gt; 
&lt;h4&gt;12. Custom Skill Management&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-11-skill-management.png" alt="Skill Management" /&gt;&lt;/a&gt; Skills are the foundation of personalization - modular capabilities that route intelligently.&lt;/p&gt; 
&lt;h4&gt;13. Custom History System&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-12-history-system.png" alt="History System" /&gt;&lt;/a&gt; Everything worth knowing gets captured. History feeds back into context for future sessions.&lt;/p&gt; 
&lt;h4&gt;14. Custom Agent Personalities / Voices&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;&lt;img src="https://danielmiessler.com/images/pai-principle-13-agent-personalities.png" alt="Agent Personalities" /&gt;&lt;/a&gt; Different work needs different approaches. Specialized agents with unique personalities and voices.&lt;/p&gt; 
&lt;h4&gt;15. Science as Cognitive Loop&lt;/h4&gt; 
&lt;p&gt;The meta-principle: Hypothesis ‚Üí Experiment ‚Üí Measure ‚Üí Iterate. Every decision follows this pattern.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;The Journey: PAI v1.x ‚Üí v2.0&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;PAI v1.x&lt;/strong&gt; attempted to mirror my entire personal AI system (Kai) as an installable template. The idea was simple: "Here's everything I built - clone it and customize."&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The problem:&lt;/strong&gt; It didn't work. The system was a Jenga tower of interconnected dependencies. Change one piece, and three others broke. Users couldn't easily adopt parts without understanding the whole. Updates were a nightmare because everything was coupled.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PAI v2.0&lt;/strong&gt; takes a fundamentally different approach: &lt;strong&gt;modular packs&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Instead of "here's my whole system," it's "here are battle-tested capabilities you can install independently." Each pack is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Self-contained&lt;/strong&gt; - Works without understanding the rest of the system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Independently installable&lt;/strong&gt; - Add what you need, skip what you don't&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Platform-agnostic&lt;/strong&gt; - Works with Claude Code, OpenCode, or custom systems&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI-installable&lt;/strong&gt; - Your AI can read the pack and set it up for you&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The packs are extracted from Kai - real capabilities that have been running in production. They're not theoretical examples. They're the actual tools and systems I use daily, packaged for others to adopt.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;PAI v2.0: PAI Packs&lt;/h1&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;PAI Packs&lt;/strong&gt; are modular upgrade packages for AI agent systems. Think of them like learning kung-fu in The Matrix - each pack is a complete, tested capability that you can download into your system.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PAI Packs provide&lt;/strong&gt; self-contained bundles with everything your AI needs to implement a specific capability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;The problem&lt;/strong&gt; being solved&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The solution&lt;/strong&gt; and how it works&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;All code&lt;/strong&gt; (tools, CLIs, scripts)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workflows&lt;/strong&gt; (step-by-step processes)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Context files&lt;/strong&gt; (guidelines, aesthetics, specifications)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Examples&lt;/strong&gt; and usage patterns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Installation instructions&lt;/strong&gt; (for both AI and manual)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing procedures&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Troubleshooting guides&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;The key insight:&lt;/strong&gt; Give your AI the complete context it needs, and it can integrate the pack into &lt;em&gt;your&lt;/em&gt; system, whether that's Claude Code, OpenCode, Gemini Code, GPT-Codex, or a homebrew setup.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;How PAI Works&lt;/h2&gt; 
&lt;p&gt;This section explains the technical architecture, installation process, and runtime mechanics of the Personal AI Infrastructure (PAI) system.&lt;/p&gt; 
&lt;h3&gt;1. High-Level Architecture&lt;/h3&gt; 
&lt;p&gt;PAI is not a standalone application but a &lt;strong&gt;configuration and automation layer&lt;/strong&gt; that sits on top of &lt;strong&gt;Claude Code&lt;/strong&gt; (Anthropic's CLI agent). It transforms a generic AI agent into a personalized system with persistent memory, security controls, and defined skills.&lt;/p&gt; 
&lt;p&gt;The architecture consists of three main layers:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;The Engine (Claude Code)&lt;/strong&gt;: The underlying AI agent that executes commands and processes prompts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The Middleware (Hooks)&lt;/strong&gt;: A system of event listeners that intercept Claude Code's operations (like tool use, session start) to enforce security, inject context, and log activity.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The Content (Packs)&lt;/strong&gt;: Modular bundles of markdown files and scripts that define "Skills" (workflows), "Tools" (executable code), and "Identity" (system prompts).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;2. The Hook System (The "Magic")&lt;/h3&gt; 
&lt;p&gt;The core mechanism that makes PAI work is the &lt;strong&gt;Hook System&lt;/strong&gt;. Claude Code has a native capability to run scripts when certain events occur. PAI leverages this to inject its logic.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How Hooks Work:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Configuration&lt;/strong&gt;: Hooks are registered in &lt;code&gt;~/.claude/settings.json&lt;/code&gt;. This file maps events (like &lt;code&gt;PreToolUse&lt;/code&gt;) to specific scripts.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Events&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;SessionStart&lt;/code&gt;: Fires when you open Claude Code. PAI uses this to load your "CORE" skill and context.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;PreToolUse&lt;/code&gt;: Fires before the AI runs a command (e.g., &lt;code&gt;bash&lt;/code&gt;, &lt;code&gt;edit&lt;/code&gt;). PAI uses this for &lt;strong&gt;Security Validation&lt;/strong&gt; (blocking &lt;code&gt;rm -rf&lt;/code&gt;, etc.).&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;PostToolUse&lt;/code&gt;: Fires after a command. Used for logging and observability.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;UserPromptSubmit&lt;/code&gt;: Fires when you type a message. Used to update terminal tab titles.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Execution&lt;/strong&gt;: When an event fires, Claude Code runs the corresponding TypeScript script (using &lt;code&gt;bun&lt;/code&gt;) located in &lt;code&gt;~/.claude/hooks/&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Communication&lt;/strong&gt;: The script receives event data via &lt;code&gt;stdin&lt;/code&gt; (JSON) and can control the outcome (e.g., allow or block a command) via exit codes or &lt;code&gt;stdout&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;3. Installation Process&lt;/h3&gt; 
&lt;p&gt;The installation is a two-phase process: &lt;strong&gt;Bootstrapping&lt;/strong&gt; (Manual) and &lt;strong&gt;Pack Installation&lt;/strong&gt; (AI-Driven).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Phase 1: Bootstrapping (The &lt;code&gt;install.ts&lt;/code&gt; script)&lt;/strong&gt; The user runs &lt;code&gt;bun run Bundles/Kai/install.ts&lt;/code&gt;. This script &lt;strong&gt;does not&lt;/strong&gt; install the full system. Instead, it:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Creates Directory Structure&lt;/strong&gt;: Sets up &lt;code&gt;~/.claude/&lt;/code&gt; (or &lt;code&gt;$PAI_DIR&lt;/code&gt;) with folders for &lt;code&gt;skills&lt;/code&gt;, &lt;code&gt;hooks&lt;/code&gt;, &lt;code&gt;history&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Generates Config Files&lt;/strong&gt;: Creates &lt;code&gt;SKILL.md&lt;/code&gt;, &lt;code&gt;Contacts.md&lt;/code&gt;, and &lt;code&gt;CoreStack.md&lt;/code&gt; with user preferences (name, timezone).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sets Environment Variables&lt;/strong&gt;: Updates &lt;code&gt;.zshrc&lt;/code&gt; or &lt;code&gt;.bashrc&lt;/code&gt; with &lt;code&gt;DA&lt;/code&gt; (Assistant Name), &lt;code&gt;PAI_DIR&lt;/code&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Updates &lt;code&gt;settings.json&lt;/code&gt;&lt;/strong&gt;: Injects environment variables into Claude Code's settings.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Crucially, this phase does not install the hooks or skills.&lt;/strong&gt; It prepares the environment for the AI to do it.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Phase 2: Pack Installation (AI-Driven)&lt;/strong&gt; The user is instructed to "give each pack file to your AI". This is where the actual installation happens.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;User Action&lt;/strong&gt;: The user pastes the content of a pack file (e.g., &lt;code&gt;Packs/kai-hook-system.md&lt;/code&gt;) into Claude Code.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Execution&lt;/strong&gt;: The pack file contains natural language instructions and code blocks. The AI reads these instructions and: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Writes Files&lt;/strong&gt;: Creates the TypeScript hook files (e.g., &lt;code&gt;hooks/security-validator.ts&lt;/code&gt;) and skill definitions.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Configures System&lt;/strong&gt;: Updates &lt;code&gt;settings.json&lt;/code&gt; to register the new hooks.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Verifies&lt;/strong&gt;: Runs verification commands to ensure the pack is working.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This "Inception-style" installation (using the AI to build the AI's infrastructure) ensures that the system is self-documenting and the AI "knows" about its own components.&lt;/p&gt; 
&lt;h3&gt;4. Runtime Flow&lt;/h3&gt; 
&lt;p&gt;Here is what happens when you use PAI:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Start&lt;/strong&gt;: You run &lt;code&gt;claude&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Initialization (&lt;code&gt;SessionStart&lt;/code&gt;)&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Claude Code fires &lt;code&gt;SessionStart&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;hooks/initialize-session.ts&lt;/code&gt; runs.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;hooks/load-core-context.ts&lt;/code&gt; runs. It reads &lt;code&gt;skills/CORE/SKILL.md&lt;/code&gt; and injects it into the context. Now the AI knows who it is and what skills it has.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User Interaction&lt;/strong&gt;: You ask "Create a new blog post".&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Routing&lt;/strong&gt;: The AI (guided by the injected &lt;code&gt;SKILL.md&lt;/code&gt;) recognizes this matches a skill (e.g., &lt;code&gt;CreateContent&lt;/code&gt;). It loads the specific workflow for that skill.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Execution (&lt;code&gt;PreToolUse&lt;/code&gt;)&lt;/strong&gt;: The AI decides to run a command (e.g., &lt;code&gt;touch blog.md&lt;/code&gt;). 
  &lt;ul&gt; 
   &lt;li&gt;Claude Code fires &lt;code&gt;PreToolUse&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;hooks/security-validator.ts&lt;/code&gt; runs. It checks if &lt;code&gt;touch blog.md&lt;/code&gt; is safe.&lt;/li&gt; 
   &lt;li&gt;If safe (Exit Code 0), the command runs.&lt;/li&gt; 
   &lt;li&gt;If unsafe (Exit Code 1+), the command is blocked.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Completion&lt;/strong&gt;: The AI finishes the task and updates its memory (via &lt;code&gt;kai-history-system&lt;/code&gt; hooks).&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;5. Key Components&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;kai-hook-system&lt;/code&gt;&lt;/strong&gt;: The engine room. Provides the event bus and security layer.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;kai-core-install&lt;/code&gt;&lt;/strong&gt;: The brain. Defines the "CORE" skill, identity, and routing logic.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;kai-history-system&lt;/code&gt;&lt;/strong&gt;: The memory. Captures session data and learnings.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;kai-voice-system&lt;/code&gt;&lt;/strong&gt;: (Optional) Adds voice capabilities via ElevenLabs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üì¶ Available Packs&lt;/h2&gt; 
&lt;h3&gt;Features (Architectural Systems)&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Pack&lt;/th&gt; 
   &lt;th&gt;Version&lt;/th&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Packs/kai-history-system.md"&gt;&lt;strong&gt;Kai History System&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;1.0.0&lt;/td&gt; 
   &lt;td&gt;Infrastructure&lt;/td&gt; 
   &lt;td&gt;Automatic context-tracking system that captures all work, decisions, and learnings with zero manual effort&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Skills (Action-Oriented Capabilities)&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Pack&lt;/th&gt; 
   &lt;th&gt;Version&lt;/th&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Coming soon&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;Skills being extracted and packaged&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Coming Soon&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Features being packaged:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Skill System&lt;/strong&gt; - Skill routing and workflow management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agent Factory&lt;/strong&gt; - Custom agent creation and orchestration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompting System&lt;/strong&gt; - Meta-prompting and template framework&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Skills being packaged:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Art&lt;/strong&gt; - Visual content generation system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Research&lt;/strong&gt; - Multi-source research orchestration with parallel agents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OSINT&lt;/strong&gt; - Open-source intelligence gathering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-contributing"&gt;&lt;strong&gt;Submit your own pack&lt;/strong&gt;&lt;/a&gt; ‚Üí&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üì¶ Available Bundles&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Bundles&lt;/strong&gt; are curated collections of packs designed to work together. Instead of installing packs one-by-one, install a bundle to get a complete, tested experience.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Bundle&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Packs&lt;/th&gt; 
   &lt;th&gt;Tier&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Bundles/Kai/"&gt;&lt;strong&gt;Kai Bundle&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;The official PAI bundle - complete personal AI infrastructure extracted from Daniel Miessler's production system&lt;/td&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;Complete&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Why Bundles?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Curated combinations&lt;/strong&gt; - Tested packs that work well together&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Proper installation order&lt;/strong&gt; - Dependencies handled correctly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Emergent capabilities&lt;/strong&gt; - The whole is greater than the sum of parts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complete experience&lt;/strong&gt; - Everything needed for a specific goal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive wizard&lt;/strong&gt; - Guided setup with conflict detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;The Kai Bundle&lt;/strong&gt; is the flagship bundle. Installing all its packs recreates the PAI v1.0 "mirrored system" experience - but through modular, maintainable packs instead of a monolithic copy.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Quick install:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repo and run the interactive wizard
git clone https://github.com/danielmiessler/PAI.git
cd PAI/Bundles/Kai &amp;amp;&amp;amp; bun run install.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Bundles/"&gt;&lt;strong&gt;Learn more about bundles ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;FOR AI AGENTS:&lt;/strong&gt; The entire PAI system is designed to be used by AI. You can read this README to understand how PAI works with its Packs and Bundles. A recommended approach: evaluate the entire system, then interact with your principal and ask them which Bundles or Packs they'd like to install‚Äîgive them options based on their needs. From there, you should be able to read any Bundle or Pack file (including new ones as they're released) and guide your principal on whether they want to install it.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Option 1: Install the Complete Kai Bundle (Recommended)&lt;/h3&gt; 
&lt;p&gt;The fastest way to get started is with the interactive bundle wizard:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repo
git clone https://github.com/danielmiessler/PAI.git
cd PAI/Bundles/Kai

# Run the interactive wizard
bun run install.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;The wizard will:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ask for your preferences (AI name, install location, timezone)&lt;/li&gt; 
 &lt;li&gt;Detect any existing installations and offer to merge or replace&lt;/li&gt; 
 &lt;li&gt;Create the required directory structure&lt;/li&gt; 
 &lt;li&gt;Configure environment variables&lt;/li&gt; 
 &lt;li&gt;Guide you through installing each pack in order&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Option 2: AI-Assisted Pack Installation&lt;/h3&gt; 
&lt;p&gt;Install individual packs by giving them to your AI:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Browse packs&lt;/strong&gt; - Find a pack you want in &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Packs/"&gt;Packs/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Give it to your AI&lt;/strong&gt; - Provide the entire pack markdown file&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ask your AI to install it:&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code&gt;Install this pack into my system. Use PAI_DIR="~/.config/pai"
and DA="MyAI". Set up the hooks, save the code, and verify it works.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Your AI will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check for required dependencies&lt;/li&gt; 
 &lt;li&gt;Save code to appropriate directories&lt;/li&gt; 
 &lt;li&gt;Set up routing/hooks (if applicable)&lt;/li&gt; 
 &lt;li&gt;Validate the installation&lt;/li&gt; 
 &lt;li&gt;Run a test to ensure it works&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Option 3: Manual Installation&lt;/h3&gt; 
&lt;p&gt;Each pack includes detailed manual installation instructions. Open the pack file and follow the "Installation ‚Üí Manual" section.&lt;/p&gt; 
&lt;h3&gt;Option 4: Browse and Cherry-Pick&lt;/h3&gt; 
&lt;p&gt;Packs are self-contained markdown files. You can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read the code directly in the pack&lt;/li&gt; 
 &lt;li&gt;Copy specific functions or workflows&lt;/li&gt; 
 &lt;li&gt;Adapt the approach to your own system&lt;/li&gt; 
 &lt;li&gt;Use it as reference documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;No forced structure. No mandatory setup. Take what's useful, leave the rest.&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìÇ Understanding PAI_DIR&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;PAI_DIR&lt;/code&gt; environment variable is the &lt;strong&gt;single source of truth&lt;/strong&gt; for where your PAI installation lives.&lt;/p&gt; 
&lt;h3&gt;What is PAI_DIR?&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;PAI_DIR&lt;/code&gt; points to the directory where your personal AI infrastructure is installed - this is where skills, hooks, history, and configuration files live.&lt;/p&gt; 
&lt;h3&gt;Two Different Things&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Concept&lt;/th&gt; 
   &lt;th&gt;Path&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PAI Repository&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Where you cloned &lt;code&gt;git clone https://github.com/danielmiessler/PAI.git&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Source code, packs, templates - read-only reference&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;PAI Installation&lt;/strong&gt; (&lt;code&gt;PAI_DIR&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;~/.claude&lt;/code&gt; (default) or your custom location&lt;/td&gt; 
   &lt;td&gt;Your active installation - skills, hooks, history, config&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The repository is like a cookbook. Your installation is your actual kitchen.&lt;/p&gt; 
&lt;h3&gt;Default Behavior&lt;/h3&gt; 
&lt;p&gt;If &lt;code&gt;PAI_DIR&lt;/code&gt; is not set, PAI tools and packs default to &lt;code&gt;~/.claude&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;This is the standard Claude Code configuration directory&lt;/li&gt; 
 &lt;li&gt;Works seamlessly with Claude Code out of the box&lt;/li&gt; 
 &lt;li&gt;Recommended for most users&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;When to Use a Custom PAI_DIR&lt;/h3&gt; 
&lt;p&gt;Set a custom &lt;code&gt;PAI_DIR&lt;/code&gt; if you:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use a different AI coding assistant (Cursor, Windsurf, OpenCode)&lt;/li&gt; 
 &lt;li&gt;Want to keep PAI separate from Claude Code's config&lt;/li&gt; 
 &lt;li&gt;Are testing or developing packs&lt;/li&gt; 
 &lt;li&gt;Have multiple PAI installations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Setting PAI_DIR&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;In your shell profile&lt;/strong&gt; (&lt;code&gt;~/.zshrc&lt;/code&gt; or &lt;code&gt;~/.bashrc&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export PAI_DIR="$HOME/.claude"  # Default - Claude Code location
# OR
export PAI_DIR="$HOME/.config/pai"  # Custom location
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;How Tools Resolve PAI_DIR&lt;/h3&gt; 
&lt;p&gt;PAI tools use this resolution order:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;process.env.PAI_DIR&lt;/code&gt; - Explicit setting (highest priority)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;process.env.PAI_HOME&lt;/code&gt; - Legacy/alternate variable&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;~/.claude&lt;/code&gt; - Default fallback&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This means: if you set &lt;code&gt;PAI_DIR&lt;/code&gt;, it takes precedence. If not, it defaults to Claude Code's standard location.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üîê Authentication Setup&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;All API keys live in ONE place: &lt;code&gt;$PAI_DIR/.env&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This is a core principle of PAI: &lt;strong&gt;no keys stored anywhere else in the system&lt;/strong&gt;. Every pack, every tool, every workflow reads from this single file.&lt;/p&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Copy the example file to your PAI directory
cp .env.example $PAI_DIR/.env

# 2. Edit and add your API keys
nano $PAI_DIR/.env

# 3. Restart Claude Code to load the new environment
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;What Goes in .env&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Core variables:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;DA&lt;/code&gt; - Your AI assistant's name&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;TIME_ZONE&lt;/code&gt; - Your timezone&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Pack-specific keys:&lt;/strong&gt; Each pack documents its required API keys in its installation section. Add them to &lt;code&gt;.env&lt;/code&gt; as you install packs.&lt;/p&gt; 
&lt;h3&gt;Security Rules&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;NEVER commit &lt;code&gt;.env&lt;/code&gt; files to git&lt;/strong&gt; - The &lt;code&gt;.gitignore&lt;/code&gt; already excludes them&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;NEVER store API keys in pack files, configs, or code&lt;/strong&gt; - Always use environment variables&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ALL authentication flows through &lt;code&gt;$PAI_DIR/.env&lt;/code&gt;&lt;/strong&gt; - One file, one location, no exceptions&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/.env.example"&gt;.env.example&lt;/a&gt; for the complete template with documentation.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìñ How PAI Packs Work&lt;/h2&gt; 
&lt;p&gt;PAI offers &lt;strong&gt;two types of packs&lt;/strong&gt;, each with its own structure and purpose:&lt;/p&gt; 
&lt;h3&gt;Pack Type 1: Skills&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Skills&lt;/strong&gt; are action-oriented capabilities that your AI can invoke - things like generating visual content, conducting research, or processing data.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt; Art (visual content generation), Research (multi-source investigation), OSINT (intelligence gathering)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Structure:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Assistant Install Prompt&lt;/strong&gt; - Step-by-step instructions for AI to autonomously install&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pack Metadata&lt;/strong&gt; - Version, dependencies, API keys, platform support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The Problem&lt;/strong&gt; - What's broken/missing?&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The Solution&lt;/strong&gt; - How this skill fixes it&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quick Start&lt;/strong&gt; - Get running in 60 seconds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pack Contents&lt;/strong&gt; - Workflows, tools, context files (complete source code)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Examples&lt;/strong&gt; - Real usage scenarios&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Installation&lt;/strong&gt; - AI-assisted + manual steps&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing&lt;/strong&gt; - Smoke tests and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt; - Common issues and fixes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Credits&lt;/strong&gt; - Attribution for ideas, influences, collaborators&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Resources&lt;/strong&gt; - Additional reading, related projects, external docs&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Pack Type 2: Features&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Features&lt;/strong&gt; are architectural patterns and systems - infrastructure pieces like custom history systems, skill routing, agent orchestration, or prompting frameworks.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt; History System (automatic context-tracking), Skill System (routing and management), Agent Factory (custom agent creation), Prompting System (meta-prompting and templates)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Structure:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Assistant Install Prompt&lt;/strong&gt; - Step-by-step instructions for AI to autonomously install&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pack Metadata&lt;/strong&gt; - Version, dependencies, platform support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The Problem&lt;/strong&gt; - What architectural challenge exists?&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;The Solution&lt;/strong&gt; - The design pattern and approach&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Implementation&lt;/strong&gt; - Complete code, configuration files, integration guides&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Examples&lt;/strong&gt; - Real-world usage patterns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Installation&lt;/strong&gt; - AI-assisted + manual steps&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing&lt;/strong&gt; - Validation procedures&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt; - Common integration issues&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Credits&lt;/strong&gt; - Attribution for architectural ideas, influences&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Resources&lt;/strong&gt; - Additional reading, similar systems, theoretical background&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Universal Elements&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;All packs include:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;pack:
  name: PackName
  version: 1.0.0
  category: visual-content | infrastructure | research | automation
  type: skill | feature
  author: Contributor Name
  license: MIT
  requires:
    - Other-Pack &amp;gt;= 1.0.0 (optional dependencies)
  platforms: [macos, linux, windows]
  dependencies:
    tools: [bun, ImageMagick]
    api_keys: [REPLICATE_API_TOKEN]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;ü§ñ Assistant Install Prompt&lt;/strong&gt; - Every pack starts with instructions for AI assistants to autonomously install it. Your AI reads the pack, understands what it does, verifies dependencies, sets up the code, and validates it works - all without manual intervention.&lt;/p&gt; 
&lt;h3&gt;Why Single Files?&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Portability&lt;/strong&gt; - One file contains everything. Email it, share it, version control it.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AI-Friendly&lt;/strong&gt; - Your AI can read the entire context at once. No navigation, no missing pieces.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;No Dependencies&lt;/strong&gt; - Packs are self-contained. They may &lt;em&gt;call&lt;/em&gt; external tools, but the pack itself is complete.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Easy Review&lt;/strong&gt; - See exactly what you're installing. No hidden files, no surprises.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Version Control&lt;/strong&gt; - Simple to track changes, fork, and merge improvements.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üõ†Ô∏è For Pack Developers&lt;/h2&gt; 
&lt;h3&gt;Creating a PAI Pack&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;1. Get the pack template:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -O https://raw.githubusercontent.com/danielmiessler/PAI/main/Tools/PAIPackTemplate.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;2. Fill in each section:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Assistant Install Prompt&lt;/strong&gt; - Instructions for AI to install autonomously&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Problem statement&lt;/strong&gt; - What's broken or missing?&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Solution&lt;/strong&gt; - How your pack fixes it&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Implementation/Contents&lt;/strong&gt; - All code (embedded in markdown code blocks)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Examples&lt;/strong&gt; - Real usage scenarios&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Installation steps&lt;/strong&gt; - Both AI-assisted and manual&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing procedures&lt;/strong&gt; - Smoke tests and validation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Credits&lt;/strong&gt; - Attribution for ideas and influences&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Resources&lt;/strong&gt; - Additional reading and related projects&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;3. Validate it:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Test with your own AI:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Here's my pack. Install it into a fresh system and verify it works.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;4. Submit a PR:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git checkout -b add-pack-name
cp MyPack.md Packs/
git add Packs/MyPack.md
git commit -m "Add MyPack - one-line description"
git push origin add-pack-name
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open a PR with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Pack description&lt;/li&gt; 
 &lt;li&gt;What problem it solves&lt;/li&gt; 
 &lt;li&gt;Testing you've done&lt;/li&gt; 
 &lt;li&gt;Screenshots/examples (if applicable)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Pack Quality Standards&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Must have:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ Clear problem statement&lt;/li&gt; 
 &lt;li&gt;‚úÖ Complete working code (tested)&lt;/li&gt; 
 &lt;li&gt;‚úÖ Real examples (not placeholders)&lt;/li&gt; 
 &lt;li&gt;‚úÖ Both AI and manual installation instructions&lt;/li&gt; 
 &lt;li&gt;‚úÖ Troubleshooting section&lt;/li&gt; 
 &lt;li&gt;‚úÖ No hardcoded personal data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Nice to have:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Screenshots of output&lt;/li&gt; 
 &lt;li&gt;Video demo&lt;/li&gt; 
 &lt;li&gt;Multiple examples for different use cases&lt;/li&gt; 
 &lt;li&gt;Integration with other packs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üèóÔ∏è Platform Compatibility&lt;/h2&gt; 
&lt;p&gt;PAI packs are designed to be &lt;strong&gt;platform-agnostic&lt;/strong&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
   &lt;th&gt;Notes&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Claude Code&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Full support&lt;/td&gt; 
   &lt;td&gt;Native integration, all features work&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;OpenCode&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Compatible&lt;/td&gt; 
   &lt;td&gt;Skills/hooks may need adaptation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Custom systems&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Compatible&lt;/td&gt; 
   &lt;td&gt;Extract code, adapt to your structure&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Gemini Code / Codex&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;üîÑ Testing&lt;/td&gt; 
   &lt;td&gt;Should work with minor tweaks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Manual use&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Always works&lt;/td&gt; 
   &lt;td&gt;Packs are documentation + code&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The code itself is platform-independent (TypeScript, Python, Bash). Integration points (skills, hooks) may vary by platform.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üí° Why Packs?&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Text is the interface.&lt;/strong&gt; Everything your AI needs to implement a capability should be in one readable file.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Composability over monoliths.&lt;/strong&gt; Mix and match packs. Build your own stack.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;AI-first design.&lt;/strong&gt; Optimized for AI agents to read, understand, and implement - not just humans.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Open contribution.&lt;/strong&gt; Anyone can submit a pack. The best ideas win.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;No vendor lock-in.&lt;/strong&gt; Packs describe &lt;em&gt;how to solve a problem&lt;/em&gt;, not just "here's the code for our platform."&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;h3&gt;Submit a Pack&lt;/h3&gt; 
&lt;p&gt;We welcome packs that solve real problems:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the repository&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create your pack&lt;/strong&gt; - Follow &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Tools/PAIPackTemplate.md"&gt;PAIPackTemplate.md&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test it thoroughly&lt;/strong&gt; - Install in a fresh system with AI assistance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Submit a PR&lt;/strong&gt; - Include examples and testing evidence&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Pack Review Process&lt;/h3&gt; 
&lt;p&gt;Submitted packs are reviewed for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Completeness&lt;/strong&gt; - All required sections present&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code quality&lt;/strong&gt; - Works as described, no obvious bugs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt; - No hardcoded secrets, follows best practices&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Usefulness&lt;/strong&gt; - Solves a real problem for users&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Review timeline:&lt;/strong&gt; Most packs reviewed within 7 days.&lt;/p&gt; 
&lt;h3&gt;Pack Maintenance&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Authors maintain their packs.&lt;/strong&gt; When you submit a pack, you're committing to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Respond to issues about your pack&lt;/li&gt; 
 &lt;li&gt;Fix bugs that are reported&lt;/li&gt; 
 &lt;li&gt;Consider feature requests&lt;/li&gt; 
 &lt;li&gt;Update for breaking changes in dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If a pack becomes unmaintained, the community can fork and maintain a new version.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Document&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/PACKS.md"&gt;PACKS.md&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Complete pack system documentation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Bundles/"&gt;Bundles/&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Bundle system documentation and available bundles&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/SECURITY.md"&gt;SECURITY.md&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Security policies and best practices&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéØ Roadmap&lt;/h2&gt; 
&lt;h3&gt;v1.0 (Current)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Pack format specification&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; History System pack (context-tracking)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Pack template&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Installation documentation&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Pack discovery website&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 5+ core packs released&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;v1.1 (Q1 2026)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Pack dependency system&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Automated testing framework&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Pack marketplace&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Cross-pack integration examples&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 20+ packs available&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;v1.2 (Q2 2026)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Pack composition tools&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Version compatibility checker&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Community pack ratings&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Pack search/filter by category&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 50+ packs available&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üåê Community&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;GitHub Discussions:&lt;/strong&gt; &lt;a href="https://github.com/danielmiessler/Personal_AI_Infrastructure/discussions"&gt;Join the conversation&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Discord:&lt;/strong&gt; &lt;a href="https://discord.gg/danielmiessler"&gt;PAI Community&lt;/a&gt; (coming soon)&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Twitter/X:&lt;/strong&gt; &lt;a href="https://twitter.com/danielmiessler"&gt;@danielmiessler&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Blog:&lt;/strong&gt; &lt;a href="https://danielmiessler.com"&gt;danielmiessler.com&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Recognition&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Top pack contributors&lt;/strong&gt; (packs submitted/maintained):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;(List will be populated as packs are submitted)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Special thanks:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;All early PAI users who provided feedback&lt;/li&gt; 
 &lt;li&gt;The Claude Code team for building an incredible platform&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚ùì FAQ&lt;/h2&gt; 
&lt;h3&gt;Isn't Claude Code and other agentic systems already pretty good? What makes this an upgrade over them?&lt;/h3&gt; 
&lt;p&gt;PAI isn't a replacement for Claude Code‚Äîit's what you build &lt;em&gt;on top of it&lt;/em&gt;. Claude Code (and systems like Cursor, Windsurf, OpenCode) gives you an AI that can read files, write code, and execute commands. But they're generic. They don't know your goals, your preferred workflows, your history, or your specific context.&lt;/p&gt; 
&lt;p&gt;PAI provides the scaffolding to make that generic AI &lt;em&gt;yours&lt;/em&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Persistent memory&lt;/strong&gt; ‚Äî Your AI remembers past sessions, decisions, and learnings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom skills&lt;/strong&gt; ‚Äî Specialized capabilities for the things you do most (research, content creation, security analysis, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Your context&lt;/strong&gt; ‚Äî Goals, contacts, preferences, definitions‚Äîall available to your AI without re-explaining&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent routing&lt;/strong&gt; ‚Äî Say "research this" and the right workflow triggers automatically&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-improvement&lt;/strong&gt; ‚Äî The system can modify itself based on what it learns&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Think of it this way: Claude Code is the engine. PAI is everything else that makes it &lt;em&gt;your&lt;/em&gt; car‚Äîthe custom seat position, the saved radio stations, the GPS with your home address, the toolbox in the trunk.&lt;/p&gt; 
&lt;h3&gt;Do I need to install everything?&lt;/h3&gt; 
&lt;p&gt;No‚Äîand that's the point. The mistake of PAI v1 (and many other agentic systems) was trying to install everything all at once in an all-or-nothing fashion. That creates fragile systems where one broken piece takes down the whole thing.&lt;/p&gt; 
&lt;p&gt;PAI v2 is modular by design:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Packs are independent&lt;/strong&gt; ‚Äî Install one, install ten, install none. Each pack is self-contained.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Start small&lt;/strong&gt; ‚Äî Begin with the Hook System, add History when you want persistence, add Skills when you need routing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No dependencies on the whole&lt;/strong&gt; ‚Äî Each pack declares its dependencies explicitly. You install exactly what you need.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Incremental adoption&lt;/strong&gt; ‚Äî Use PAI alongside your existing setup. Migrate at your own pace.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The best way to start: pick ONE pack that solves a problem you have today. Install it. Use it. Then decide if you want more.&lt;/p&gt; 
&lt;h3&gt;What's the difference between PAI and Anthropic's plugin system?&lt;/h3&gt; 
&lt;p&gt;Anthropic's plugin system (Skills, slash commands, MCP servers) provides discrete functionality‚Äîindividual tools your AI can use. It's powerful, and you're free to use plugins as part of PAI as well.&lt;/p&gt; 
&lt;p&gt;The difference is scope and integration:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Anthropic's plugins&lt;/strong&gt; = Individual pieces of functionality that don't understand overall context‚Äîthey don't know how they work with other pieces of functionality, and most importantly, they don't integrate with your actual system and your actual goals.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;PAI&lt;/strong&gt; = A complete system where everything understands the context‚Äîyour goals, your workflows, how pieces work together, and what you're actually trying to accomplish.&lt;/p&gt; 
&lt;p&gt;PAI is:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;An implemented, full-setup system&lt;/strong&gt; ‚Äî Not just tools, but a complete personal AI infrastructure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamically adaptive&lt;/strong&gt; ‚Äî Adjusts to your existing environment and workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Context-aware&lt;/strong&gt; ‚Äî Understands what you're trying to accomplish in your life and work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Customized to you&lt;/strong&gt; ‚Äî Picks and chooses functionality from different sources&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-managing&lt;/strong&gt; ‚Äî Your AI installs, configures, and maintains the system itself&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The plugin system offers building blocks. PAI offers a blueprint for a mansion‚Äîplus the AI architect to build it.&lt;/p&gt; 
&lt;h3&gt;Is PAI only for Claude Code?&lt;/h3&gt; 
&lt;p&gt;No. PAI packs are designed to be &lt;strong&gt;platform-agnostic&lt;/strong&gt;. While the examples use Claude Code (because that's what the author uses), the packs work with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Claude Code&lt;/strong&gt; ‚Äî Full native support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OpenCode&lt;/strong&gt; ‚Äî Compatible with minor adaptations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cursor / Windsurf&lt;/strong&gt; ‚Äî Works with configuration adjustments&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Gemini Code / GPT-Codex&lt;/strong&gt; ‚Äî Should work with tweaks (community testing welcome)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom systems&lt;/strong&gt; ‚Äî Extract the code and concepts, adapt to your setup&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The code is TypeScript, Python, and Bash. The concepts are universal. The integration points vary by platform, but the core value transfers.&lt;/p&gt; 
&lt;h3&gt;Do I need to install everything?&lt;/h3&gt; 
&lt;p&gt;No. That was the mistake of PAI v1.x‚Äîtrying to install everything at once.&lt;/p&gt; 
&lt;p&gt;PAI v2.0 is modular by design:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Start with one pack&lt;/strong&gt; ‚Äî History System is a good first choice&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add more as needed&lt;/strong&gt; ‚Äî Each pack is independent&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use the Kai Bundle&lt;/strong&gt; if you want the full experience (but even that installs one pack at a time)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cherry-pick&lt;/strong&gt; ‚Äî Read a pack, extract the ideas, adapt them yourself&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There's no "all or nothing." Take what's useful, leave the rest.&lt;/p&gt; 
&lt;h3&gt;How do I contribute a pack?&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Solve a real problem&lt;/strong&gt; ‚Äî Packs should come from actual use, not theoretical ideas&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use the template&lt;/strong&gt; ‚Äî Download &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/Tools/PAIPackTemplate.md"&gt;PAIPackTemplate.md&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test it&lt;/strong&gt; ‚Äî Have your AI install it in a fresh environment&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Submit a PR&lt;/strong&gt; ‚Äî Include examples and evidence it works&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-contributing"&gt;Contributing&lt;/a&gt; for full details.&lt;/p&gt; 
&lt;h3&gt;How is this different from fabric?&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/danielmiessler/fabric"&gt;Fabric&lt;/a&gt; is a collection of AI prompts (patterns) for specific tasks‚Äîextract wisdom, analyze arguments, summarize content. It's focused on &lt;em&gt;what to ask AI&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;PAI is infrastructure for &lt;em&gt;how your AI operates&lt;/em&gt;‚Äîmemory, skills, routing, context, self-improvement. They're complementary:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Fabric&lt;/strong&gt; = A library of expert prompts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PAI&lt;/strong&gt; = The system that knows when to use which prompt, remembers your preferences, and learns from results&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Many PAI users integrate Fabric patterns into their skills. They work great together.&lt;/p&gt; 
&lt;h3&gt;What if I break something?&lt;/h3&gt; 
&lt;p&gt;The modular design makes recovery easy:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Packs are isolated&lt;/strong&gt; ‚Äî Breaking one doesn't affect others&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;History is preserved&lt;/strong&gt; ‚Äî Your AI's memory survives mistakes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Git-backed&lt;/strong&gt; ‚Äî Version control everything, roll back when needed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI can fix it&lt;/strong&gt; ‚Äî Your AI helped build it, it can help repair it&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Start small, experiment, iterate. The system is designed for safe exploration.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìú License&lt;/h2&gt; 
&lt;p&gt;MIT License - see &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; Do whatever you want with this. Build on it, sell it, modify it. Just don't blame us if something breaks. Attribution appreciated but not required.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üéÅ Support PAI&lt;/h2&gt; 
&lt;p&gt;PAI is &lt;strong&gt;free and open-source forever.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you find it valuable:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚≠ê &lt;strong&gt;Star the repo&lt;/strong&gt; - Helps others discover it&lt;/li&gt; 
 &lt;li&gt;üì¢ &lt;strong&gt;Share your packs&lt;/strong&gt; - The more packs, the better PAI gets&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;strong&gt;Engage in discussions&lt;/strong&gt; - Help answer questions, share ideas&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;Report issues&lt;/strong&gt; - Make PAI better for everyone&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;strong&gt;Write about it&lt;/strong&gt; - Blog posts, videos, tutorials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Premium support&lt;/strong&gt; coming soon for organizations.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìö Related Reading&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://danielmiessler.com/blog/real-internet-of-things"&gt;The Real Internet of Things&lt;/a&gt; ‚Äî The vision behind PAI&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://danielmiessler.com/blog/ai-predictable-path-7-components-2024"&gt;AI's Predictable Path: 7 Components&lt;/a&gt; ‚Äî Visual walkthrough of where AI is heading&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://danielmiessler.com/blog/personal-ai-infrastructure"&gt;Building a Personal AI Infrastructure&lt;/a&gt; ‚Äî Full PAI walkthrough with examples&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üìú Update History&lt;/h2&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;strong&gt;v2.1.0 (2025-12-31) ‚Äî Directory-Based Pack Structure&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Major Pack Format Change&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;All 8 packs migrated from single markdown files to directory-based structure&lt;/li&gt; 
  &lt;li&gt;New pack format: &lt;code&gt;README.md&lt;/code&gt;, &lt;code&gt;INSTALL.md&lt;/code&gt;, &lt;code&gt;VERIFY.md&lt;/code&gt;, and &lt;code&gt;src/&lt;/code&gt; directory&lt;/li&gt; 
  &lt;li&gt;Source code now lives in real files (.ts, .yaml, .hbs) instead of embedded in markdown&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Why This Matters&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Solves token limit issues (single files exceeded 28k tokens vs 25k limit)&lt;/li&gt; 
  &lt;li&gt;Real code files can be linted, tested, and validated&lt;/li&gt; 
  &lt;li&gt;AI agents copy actual files instead of extracting from markdown blocks&lt;/li&gt; 
  &lt;li&gt;Eliminates "helpful simplification" where AI would reduce code complexity&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Updated Documentation&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Packs/README.md updated with v2.0 structure documentation&lt;/li&gt; 
  &lt;li&gt;Bundles/README.md updated with new pack format description&lt;/li&gt; 
  &lt;li&gt;Bundles/Kai/README.md bumped to v2.0.0 with directory references&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;What Changed Per Pack&lt;/strong&gt; Each pack directory now contains:&lt;/p&gt; 
 &lt;pre&gt;&lt;code&gt;pack-name/
‚îú‚îÄ‚îÄ README.md      # Overview, architecture, what it solves
‚îú‚îÄ‚îÄ INSTALL.md     # Step-by-step installation instructions
‚îú‚îÄ‚îÄ VERIFY.md      # Mandatory verification checklist
‚îî‚îÄ‚îÄ src/           # Actual source code files
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v2.0.1 (2025-12-30) ‚Äî Pack Expansion &amp;amp; Polish&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;New Packs Released&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Kai Prompting Skill&lt;/strong&gt; (v1.0.0) - Meta-prompting system with templates, standards, and dynamic prompt generation&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Kai Agents Skill&lt;/strong&gt; (v1.0.0) - Dynamic agent composition with personality mapping and parallel orchestration&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Pack Updates&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Kai Voice System&lt;/strong&gt; - New pack icon with refined design (cache-busted for immediate updates)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Kai Art Pack&lt;/strong&gt; (v1.1.0) - Multi-reference image support for complex visual compositions&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Documentation &amp;amp; Quality&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Standardized authentication to single &lt;code&gt;$PAI_DIR/.env&lt;/code&gt; location across all packs&lt;/li&gt; 
  &lt;li&gt;Enhanced wizard clarity for installation flows (addressing #259, #260, #261)&lt;/li&gt; 
  &lt;li&gt;Safer verification patterns for security hooks&lt;/li&gt; 
  &lt;li&gt;Consistency pass across all pack documentation&lt;/li&gt; 
  &lt;li&gt;Updated pack manifests with accurate dependencies&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Reorganized Tools directory with AI usage guide&lt;/li&gt; 
  &lt;li&gt;Added Tools README with icons and descriptions&lt;/li&gt; 
  &lt;li&gt;Moved templates and diagnostic tools to centralized location&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;What's New Since v2.0.0?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;v2.0.0 launched the Packs system. v2.0.1 adds:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;8 feature packs now available with improved documentation&lt;/li&gt; 
  &lt;li&gt;Better installation experience with clearer wizards&lt;/li&gt; 
  &lt;li&gt;Unified authentication pattern (no more scattered .env files)&lt;/li&gt; 
  &lt;li&gt;Professional pack icons for visual consistency&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v2.0.0 (2025-12-28) ‚Äî PAI Packs System Launch&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Major Architecture Shift&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Transitioned from "mirrored system" approach to modular &lt;strong&gt;PAI Packs&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Packs are self-contained, AI-installable capability bundles&lt;/li&gt; 
  &lt;li&gt;Platform-agnostic design: works with Claude Code, OpenCode, Gemini Code, GPT-Codex, or custom systems&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;First Pack Released&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Kai History System&lt;/strong&gt; (v1.0.0) - Automatic context-tracking for entire AI infrastructure&lt;/li&gt; 
  &lt;li&gt;Complete implementation: 4 hooks, 3 library files, settings.json configuration&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;New Documentation&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;Tools/PAIPackTemplate.md&lt;/code&gt; - Full pack template specification&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;PACKS.md&lt;/code&gt; - Complete pack system documentation&lt;/li&gt; 
  &lt;li&gt;Updated README with 14 Founding Principles and full pack installation guide&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Why the Change?&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;v1.x tried to mirror the entire Kai system - too fragile, too many interdependencies&lt;/li&gt; 
  &lt;li&gt;v2.0 extracts battle-tested features as independent, installable modules&lt;/li&gt; 
  &lt;li&gt;Each pack is like learning kung-fu in The Matrix - a complete capability download&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.9.1 (2025-12-01) ‚Äî Patch Release&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Fixes&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;PAI_DIR&lt;/code&gt; now auto-configures in settings.json during setup&lt;/li&gt; 
  &lt;li&gt;Platform-agnostic paths work across macOS, Linux, Windows&lt;/li&gt; 
  &lt;li&gt;Fixed timezone configuration in hooks&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.9.0 (2025-11-28) ‚Äî Observability &amp;amp; Identity&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Observability Dashboard&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Real-time agent monitoring with live charts&lt;/li&gt; 
  &lt;li&gt;Bun + Vue architecture for performance&lt;/li&gt; 
  &lt;li&gt;Multiple themes (Tokyo Night, Nord, Catppuccin, etc.)&lt;/li&gt; 
  &lt;li&gt;Security obfuscation for sensitive data&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Genericized Agent Identity&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;All agent references now use &lt;code&gt;process.env.DA || 'main'&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;No more hardcoded names ‚Äî your DA name flows through the entire system&lt;/li&gt; 
  &lt;li&gt;Observability dashboard shows your configured identity&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Platform-Agnostic Configuration&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Clear separation: &lt;code&gt;settings.json&lt;/code&gt; for identity/paths, &lt;code&gt;.env&lt;/code&gt; for API keys&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;DA&lt;/code&gt; (Digital Assistant name) ‚Äî your AI's identity&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;PAI_DIR&lt;/code&gt; ‚Äî root directory for all configuration&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;TIME_ZONE&lt;/code&gt; ‚Äî configurable timezone for timestamps&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Skill System Improvements&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Canonical TitleCase file naming throughout&lt;/li&gt; 
  &lt;li&gt;Standardized skill-workflow-notification script for dashboard detection&lt;/li&gt; 
  &lt;li&gt;All paths use &lt;code&gt;${PAI_DIR}/&lt;/code&gt; for location-agnostic installation&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.8.0 (2025-11-25) ‚Äî Research &amp;amp; Documentation&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Research Skill&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Comprehensive research skill with 10 specialized workflows&lt;/li&gt; 
  &lt;li&gt;Multi-source research with parallel agent execution&lt;/li&gt; 
  &lt;li&gt;Fabric pattern integration (242+ AI patterns)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Path standardization using &lt;code&gt;${PAI_DIR}/&lt;/code&gt; throughout&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;PAI_CONTRACT.md&lt;/code&gt; defining core guarantees&lt;/li&gt; 
  &lt;li&gt;Self-test validation system for health checks&lt;/li&gt; 
  &lt;li&gt;Protection system for PAI-specific files&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.7.0 (2025-11-20) ‚Äî Protection &amp;amp; Clarity&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;PAI Path Resolution System&lt;/strong&gt; (#112)&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Centralized &lt;code&gt;pai-paths.ts&lt;/code&gt; library ‚Äî single source of truth&lt;/li&gt; 
  &lt;li&gt;Smart detection with fallback to &lt;code&gt;~/.claude&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Updated 7 hooks to use centralized paths&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;PAI vs Kai Clarity&lt;/strong&gt; (#113)&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;PAI_CONTRACT.md&lt;/code&gt; ‚Äî official contract defining boundaries&lt;/li&gt; 
  &lt;li&gt;Self-test system (&lt;code&gt;bun ${PAI_DIR}/hooks/self-test.ts&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;Clear README section distinguishing PAI from Kai&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Protection System&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;.pai-protected.json&lt;/code&gt; manifest of protected files&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;validate-protected.ts&lt;/code&gt; script for pre-commit validation&lt;/li&gt; 
  &lt;li&gt;Pre-commit hook template for automated checks&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.6.5 (2025-11-18) ‚Äî BrightData Integration&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Four-Tier Progressive Web Scraping&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Tier 1: WebFetch (free, built-in)&lt;/li&gt; 
  &lt;li&gt;Tier 2: cURL with headers (free, more reliable)&lt;/li&gt; 
  &lt;li&gt;Tier 3: Playwright (free, JavaScript rendering)&lt;/li&gt; 
  &lt;li&gt;Tier 4: Bright Data MCP (paid, anti-bot bypass)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.6.0 (2025-11-15) ‚Äî Major Architecture Update&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Repository Restructure&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Moved all configuration to &lt;code&gt;.claude/&lt;/code&gt; directory&lt;/li&gt; 
  &lt;li&gt;Skills-as-containers architecture&lt;/li&gt; 
  &lt;li&gt;Three-tier progressive disclosure&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Skills System&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Art skill with visual content generation&lt;/li&gt; 
  &lt;li&gt;Story-explanation skill for narrative summaries&lt;/li&gt; 
  &lt;li&gt;Create-skill and create-cli meta-skills&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Hook System&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Comprehensive event capture system&lt;/li&gt; 
  &lt;li&gt;Session summary and tool output capture&lt;/li&gt; 
  &lt;li&gt;Tab title updates&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Voice Integration&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Voice server with ElevenLabs TTS&lt;/li&gt; 
  &lt;li&gt;Session start notifications&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.5.0 and Earlier&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;v0.5.0 ‚Äî Foundation&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CORE skill as central context loader&lt;/li&gt; 
  &lt;li&gt;Constitution defining system principles&lt;/li&gt; 
  &lt;li&gt;CLI-First Architecture pattern&lt;/li&gt; 
  &lt;li&gt;Initial skills: Fabric, FFUF, Alex Hormozi pitch&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Pre-v0.5.0 ‚Äî Early Development&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Initial repository setup&lt;/li&gt; 
  &lt;li&gt;Basic settings.json structure&lt;/li&gt; 
  &lt;li&gt;Agent personality definitions&lt;/li&gt; 
  &lt;li&gt;Foundational hook experiments&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üôè Credits&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Anthropic and the Claude Code team&lt;/strong&gt; ‚Äî First and foremost. You are moving AI further and faster than anyone right now. Claude Code is the foundation that makes all of this possible.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/@indydevdan"&gt;IndyDevDan&lt;/a&gt;&lt;/strong&gt; ‚Äî For great videos on meta-prompting and custom agents that have inspired parts of PAI.&lt;/p&gt; 
&lt;h3&gt;Contributors&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/fayerman-source"&gt;fayerman-source&lt;/a&gt;&lt;/strong&gt; ‚Äî Google Cloud TTS provider integration and Linux audio support for the voice system.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Built with ‚ù§Ô∏è by &lt;a href="https://danielmiessler.com"&gt;Daniel Miessler&lt;/a&gt; and the PAI community&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Augment yourself.&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>