<rss version="2.0">
  <channel>
    <title>GitHub Rust Weekly Trending</title>
    <description>Weekly Trending of Rust in GitHub</description>
    <pubDate>Sat, 06 Dec 2025 01:51:04 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>huggingface/tokenizers</title>
      <link>https://github.com/huggingface/tokenizers</link>
      <description>&lt;p&gt;üí• Fast State-of-the-Art Tokenizers optimized for Research and Production&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;br /&gt; &lt;img src="https://huggingface.co/landing/assets/tokenizers/tokenizers-logo.png" width="600" /&gt; &lt;br /&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;img alt="Build" src="https://github.com/huggingface/tokenizers/workflows/Rust/badge.svg?sanitize=true" /&gt; &lt;a href="https://github.com/huggingface/tokenizers/raw/main/LICENSE"&gt; &lt;img alt="GitHub" src="https://img.shields.io/github/license/huggingface/tokenizers.svg?color=blue&amp;amp;cachedrop" /&gt; &lt;/a&gt; &lt;a href="https://pepy.tech/project/tokenizers"&gt; &lt;img src="https://pepy.tech/badge/tokenizers/week" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Provides an implementation of today's most used tokenizers, with a focus on performance and versatility.&lt;/p&gt; 
&lt;h2&gt;Main features:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Train new vocabularies and tokenize, using today's most used tokenizers.&lt;/li&gt; 
 &lt;li&gt;Extremely fast (both training and tokenization), thanks to the Rust implementation. Takes less than 20 seconds to tokenize a GB of text on a server's CPU.&lt;/li&gt; 
 &lt;li&gt;Easy to use, but also extremely versatile.&lt;/li&gt; 
 &lt;li&gt;Designed for research and production.&lt;/li&gt; 
 &lt;li&gt;Normalization comes with alignments tracking. It's always possible to get the part of the original sentence that corresponds to a given token.&lt;/li&gt; 
 &lt;li&gt;Does all the pre-processing: Truncate, Pad, add the special tokens your model needs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performances&lt;/h2&gt; 
&lt;p&gt;Performances can vary depending on hardware, but running the &lt;a href="https://raw.githubusercontent.com/huggingface/tokenizers/main/bindings/python/benches/test_tiktoken.py"&gt;~/bindings/python/benches/test_tiktoken.py&lt;/a&gt; should give the following on a g6 aws instance: &lt;img src="https://github.com/user-attachments/assets/2b913d4b-e488-4cbc-b542-f90a6c40643d" alt="image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Bindings&lt;/h2&gt; 
&lt;p&gt;We provide bindings to the following languages (more to come!):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/tokenizers/tree/main/tokenizers"&gt;Rust&lt;/a&gt; (Original implementation)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/tokenizers/tree/main/bindings/python"&gt;Python&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/tokenizers/tree/main/bindings/node"&gt;Node.js&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ankane/tokenizers-ruby"&gt;Ruby&lt;/a&gt; (Contributed by @ankane, external repo)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;You can install from source using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/huggingface/tokenizers.git#subdirectory=bindings/python
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or install the released versions with&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install tokenizers
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick example using Python:&lt;/h2&gt; 
&lt;p&gt;Choose your model between Byte-Pair Encoding, WordPiece or Unigram and instantiate a tokenizer:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tokenizers import Tokenizer
from tokenizers.models import BPE

tokenizer = Tokenizer(BPE())
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can customize how pre-tokenization (e.g., splitting into words) is done:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tokenizers.pre_tokenizers import Whitespace

tokenizer.pre_tokenizer = Whitespace()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then training your tokenizer on a set of files just takes two lines of codes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from tokenizers.trainers import BpeTrainer

trainer = BpeTrainer(special_tokens=["[UNK]", "[CLS]", "[SEP]", "[PAD]", "[MASK]"])
tokenizer.train(files=["wiki.train.raw", "wiki.valid.raw", "wiki.test.raw"], trainer=trainer)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once your tokenizer is trained, encode any text with just one line:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;output = tokenizer.encode("Hello, y'all! How are you üòÅ ?")
print(output.tokens)
# ["Hello", ",", "y", "'", "all", "!", "How", "are", "you", "[UNK]", "?"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check the &lt;a href="https://huggingface.co/docs/tokenizers/index"&gt;documentation&lt;/a&gt; or the &lt;a href="https://huggingface.co/docs/tokenizers/quicktour"&gt;quicktour&lt;/a&gt; to learn more!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pola-rs/polars</title>
      <link>https://github.com/pola-rs/polars</link>
      <description>&lt;p&gt;Extremely fast Query Engine for DataFrames, written in Rust&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://pola.rs"&gt; &lt;img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/banner/polars_github_banner.svg?sanitize=true" alt="Polars logo" /&gt; &lt;/a&gt; &lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://crates.io/crates/polars"&gt; &lt;img src="https://img.shields.io/crates/v/polars.svg?sanitize=true" alt="crates.io Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://pypi.org/project/polars/"&gt; &lt;img src="https://img.shields.io/pypi/v/polars.svg?sanitize=true" alt="PyPi Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://www.npmjs.com/package/nodejs-polars"&gt; &lt;img src="https://img.shields.io/npm/v/nodejs-polars.svg?sanitize=true" alt="NPM Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://community.r-multiverse.org/polars"&gt; &lt;img src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fcommunity.r-multiverse.org%2Fapi%2Fpackages%2Fpolars&amp;amp;query=%24.Version&amp;amp;label=r-multiverse" alt="R-multiverse Latest Release" /&gt; &lt;/a&gt; 
 &lt;a href="https://doi.org/10.5281/zenodo.7697217"&gt; &lt;img src="https://zenodo.org/badge/DOI/10.5281/zenodo.7697217.svg?sanitize=true" alt="DOI Latest Release" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;b&gt;Documentation&lt;/b&gt;: &lt;a href="https://docs.pola.rs/api/python/stable/reference/index.html"&gt;Python&lt;/a&gt; - &lt;a href="https://docs.rs/polars/latest/polars/"&gt;Rust&lt;/a&gt; - &lt;a href="https://pola-rs.github.io/nodejs-polars/index.html"&gt;Node.js&lt;/a&gt; - &lt;a href="https://pola-rs.github.io/r-polars/index.html"&gt;R&lt;/a&gt; | &lt;b&gt;StackOverflow&lt;/b&gt;: &lt;a href="https://stackoverflow.com/questions/tagged/python-polars"&gt;Python&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/rust-polars"&gt;Rust&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/nodejs-polars"&gt;Node.js&lt;/a&gt; - &lt;a href="https://stackoverflow.com/questions/tagged/r-polars"&gt;R&lt;/a&gt; | &lt;a href="https://docs.pola.rs/"&gt;User guide&lt;/a&gt; | &lt;a href="https://discord.gg/4UfP5cfBE7"&gt;Discord&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Polars: Extremely fast Query Engine for DataFrames, written in Rust&lt;/h2&gt; 
&lt;p&gt;Polars is an analytical query engine written for DataFrames. It is designed to be fast, easy to use and expressive. Key features are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Lazy | Eager execution&lt;/li&gt; 
 &lt;li&gt;Streaming (larger-than-RAM datasets)&lt;/li&gt; 
 &lt;li&gt;Query optimization&lt;/li&gt; 
 &lt;li&gt;Multi-threaded&lt;/li&gt; 
 &lt;li&gt;Written in Rust&lt;/li&gt; 
 &lt;li&gt;SIMD&lt;/li&gt; 
 &lt;li&gt;Powerful expression API&lt;/li&gt; 
 &lt;li&gt;Front end in Python | Rust | NodeJS | R | SQL&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arrow.apache.org/docs/format/Columnar.html"&gt;Apache Arrow Columnar Format&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To learn more, read the &lt;a href="https://docs.pola.rs/"&gt;user guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Performance üöÄüöÄ&lt;/h2&gt; 
&lt;h3&gt;Blazingly fast&lt;/h3&gt; 
&lt;p&gt;Polars is very fast. In fact, it is one of the best performing solutions available. See the &lt;a href="https://www.pola.rs/benchmarks.html"&gt;PDS-H benchmarks&lt;/a&gt; results.&lt;/p&gt; 
&lt;h3&gt;Lightweight&lt;/h3&gt; 
&lt;p&gt;Polars is also very lightweight. It comes with zero required dependencies, and this shows in the import times:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;polars: 70ms&lt;/li&gt; 
 &lt;li&gt;numpy: 104ms&lt;/li&gt; 
 &lt;li&gt;pandas: 520ms&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Handles larger-than-RAM data&lt;/h3&gt; 
&lt;p&gt;If you have data that does not fit into memory, Polars' query engine is able to process your query (or parts of your query) in a streaming fashion. This drastically reduces memory requirements, so you might be able to process your 250GB dataset on your laptop. Collect with &lt;code&gt;collect(engine='streaming')&lt;/code&gt; to run the query streaming.&lt;/p&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;p&gt;Install the latest Polars version with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install polars
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.pola.rs/user-guide/installation/#feature-flags"&gt;User Guide&lt;/a&gt; for more details on optional dependencies&lt;/p&gt; 
&lt;p&gt;To see the current Polars version and a full list of its optional dependencies, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;pl.show_versions()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Want to contribute? Read our &lt;a href="https://docs.pola.rs/development/contributing/"&gt;contributing guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Managed/Distributed Polars&lt;/h2&gt; 
&lt;p&gt;Do you want a managed solution or scale out to distributed clusters? Consider our &lt;a href="https://cloud.pola.rs/"&gt;offering&lt;/a&gt; and help the project!&lt;/p&gt; 
&lt;h2&gt;Python: compile Polars from source&lt;/h2&gt; 
&lt;p&gt;If you want a bleeding edge release or maximal performance you should compile Polars from source.&lt;/p&gt; 
&lt;p&gt;This can be done by going through the following steps in sequence:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the latest &lt;a href="https://www.rust-lang.org/tools/install"&gt;Rust compiler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://maturin.rs/"&gt;maturin&lt;/a&gt;: &lt;code&gt;pip install maturin&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cd py-polars&lt;/code&gt; and choose one of the following: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;make build&lt;/code&gt;, slow binary with debug assertions and symbols, fast compile times&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-release&lt;/code&gt;, fast binary without debug assertions, minimal debug symbols, long compile times&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-nodebug-release&lt;/code&gt;, same as build-release but without any debug symbols, slightly faster to compile&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-debug-release&lt;/code&gt;, same as build-release but with full debug symbols, slightly slower to compile&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;make build-dist-release&lt;/code&gt;, fastest binary, extreme compile times&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;By default the binary is compiled with optimizations turned on for a modern CPU. Specify &lt;code&gt;LTS_CPU=1&lt;/code&gt; with the command if your CPU is older and does not support e.g. AVX2.&lt;/p&gt; 
&lt;p&gt;Note that the Rust crate implementing the Python bindings is called &lt;code&gt;py-polars&lt;/code&gt; to distinguish from the wrapped Rust crate &lt;code&gt;polars&lt;/code&gt; itself. However, both the Python package and the Python module are named &lt;code&gt;polars&lt;/code&gt;, so you can &lt;code&gt;pip install polars&lt;/code&gt; and &lt;code&gt;import polars&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Using custom Rust functions in Python&lt;/h2&gt; 
&lt;p&gt;Extending Polars with UDFs compiled in Rust is easy. We expose PyO3 extensions for &lt;code&gt;DataFrame&lt;/code&gt; and &lt;code&gt;Series&lt;/code&gt; data structures. See more in &lt;a href="https://github.com/pola-rs/polars/tree/main/pyo3-polars"&gt;https://github.com/pola-rs/polars/tree/main/pyo3-polars&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Going big...&lt;/h2&gt; 
&lt;p&gt;Do you expect more than 2^32 (~4.2 billion) rows? Compile Polars with the &lt;code&gt;bigidx&lt;/code&gt; feature flag or, for Python users, install &lt;code&gt;pip install polars[rt64]&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Don't use this unless you hit the row boundary as the default build of Polars is faster and consumes less memory.&lt;/p&gt; 
&lt;h2&gt;Legacy&lt;/h2&gt; 
&lt;p&gt;Do you want Polars to run on an old CPU (e.g. dating from before 2011), or on an &lt;code&gt;x86-64&lt;/code&gt; build of Python on Apple Silicon under Rosetta? Install &lt;code&gt;pip install polars[rtcompat]&lt;/code&gt;. This version of Polars is compiled without &lt;a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions"&gt;AVX&lt;/a&gt; target features.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>eythaann/Seelen-UI</title>
      <link>https://github.com/eythaann/Seelen-UI</link>
      <description>&lt;p&gt;The Fully Customizable Desktop Environment for Windows 10/11.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/logo.svg?sanitize=true" width="44" align="top" alt="Seelen UI Logo" /&gt; Seelen UI &lt;/h1&gt; 
&lt;h2 align="center"&gt; Fully Customizable Desktop Environment for Windows &lt;br /&gt; Available in 70+ Languages &lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/eythaann/seelen-ui/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/eythaann/seelen-ui.svg?sanitize=true" alt="Contributors" /&gt;&lt;/a&gt; &lt;a href="https://github.com/eythaann/seelen-ui/commits/main"&gt;&lt;img src="https://img.shields.io/github/last-commit/eythaann/seelen-ui.svg?sanitize=true" alt="Last Commit" /&gt;&lt;/a&gt; &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/eythaann/seelen-ui.svg?sanitize=true" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;&lt;img src="https://img.shields.io/github/downloads/eythaann/seelen-ui/total.svg?sanitize=true" alt="Downloads" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/preview.png" width="100%" alt="Screenshot of Seelen UI desktop showing a customized desktop environment" /&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center" width="33%"&gt; &lt;a href="https://apps.microsoft.com/detail/Seelen%20UI/9p67c2d4t9fb?mode=full" target="_blank" rel="noopener noreferrer" aria-label="Download Seelen UI from Microsoft Store"&gt; &lt;img src="https://get.microsoft.com/images/en-us%20dark.svg?sanitize=true" width="100%" alt="Download Seelen UI from Microsoft Store" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" width="33%"&gt; &lt;a href="https://discord.gg/ABfASx5ZAJ" target="_blank" rel="noopener noreferrer" aria-label="Join the Seelen UI Discord community"&gt; &lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/discord-alt.png" width="100%" alt="Join the Seelen UI Discord community" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" width="33%"&gt; &lt;a href="https://www.digitalocean.com/?refcode=955c7335abf5&amp;amp;utm_campaign=Referral_Invite&amp;amp;utm_medium=Referral_Program&amp;amp;utm_source=badge" target="_blank" rel="noopener noreferrer" aria-label="DigitalOcean Referral Badge"&gt; &lt;img src="https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%201.svg?sanitize=true" width="100%" alt="DigitalOcean Referral Badge" /&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://seelen.io/apps/seelen-ui"&gt;Seelen UI&lt;/a&gt; is a tool designed to enhance your Windows desktop experience with a focus on customization and productivity. It integrates smoothly into your system, providing a range of features that allow you to personalize your desktop and optimize your workflow.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Be Creative&lt;/strong&gt;: Seelen UI lets you tailor your desktop to fit your style and needs. You can adjust menus, widgets, icons, and other elements to create a personalized and visually appealing desktop environment.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/theme_preview.png" alt="Seelen UI Custom Theme" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enhance Your Productivity&lt;/strong&gt;: Seelen UI helps you organize your desktop efficiently. With a Tiling Windows Manager, windows automatically arrange themselves to support multitasking, making your work more streamlined.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/twm_preview.png" alt="Seelen UI Tiling Window Manager" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Enjoy your music&lt;/strong&gt;: With an integrated media module that's compatible with most music players, Seelen UI allows you to enjoy your music seamlessly. You can pause, resume, and skip tracks at any time without the need to open additional windows.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/media_module_preview.png" alt="Seelen UI Media Module" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Be faster!&lt;/strong&gt;: With an app launcher inspired by Rofi, Seelen UI provides a simple and intuitive way to quickly access your applications and execute commands.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/app_launcher_preview.png" alt="Seelen UI App Launcher" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;User-Friendly Configuration&lt;/strong&gt;: Seelen UI offers an intuitive interface for easy customization. Adjust settings such as themes, taskbar layouts, icons, etc. With just a few clicks.&lt;/p&gt; &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/images/settings_preview.png" alt="Seelen UI Settings" /&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!CAUTION] Seelen UI requires the WebView runtime to be installed. On Windows 11, it comes pre-installed with the system. However, on Windows 10, the WebView runtime is included with the &lt;code&gt;setup.exe&lt;/code&gt; installer. Additionally, Microsoft Edge is necessary to function correctly. Some users may have modified their system and removed Edge, so please ensure both Edge and the WebView runtime are installed on your system.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] On fresh installations of Windows, the app might show a white or dark screen. You only need to update your Windows through Windows Update and restart your PC.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;You can choose from different installation options based on your preference:&lt;/p&gt; 
&lt;h3&gt;Microsoft Store &lt;em&gt;(recommended)&lt;/em&gt;&lt;/h3&gt; 
&lt;p&gt;Download the latest version from the &lt;a href="https://www.microsoft.com/store/productId/9P67C2D4T9FB?ocid=pdpshare"&gt;Store&lt;/a&gt; page. This is the recommended option because you will receive updates and a secure version of the program.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/em&gt;: It may take around 1 to 3 business days for changes to be reflected in the Microsoft Store, as updates are approved by real people in the store.&lt;/p&gt; 
&lt;h3&gt;Winget&lt;/h3&gt; 
&lt;p&gt;Install the latest version using:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-pwsh"&gt;winget install --id Seelen.SeelenUI
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This option also uses the signed &lt;code&gt;.msix&lt;/code&gt; package and ensures you have the latest secure version. Similar to the Microsoft Store, it may take around 1 to 3 business days for changes to be reflected in Winget, as updates are approved by real people in the &lt;code&gt;winget-pkg&lt;/code&gt; project.&lt;/p&gt; 
&lt;h3&gt;.msix Installer&lt;/h3&gt; 
&lt;p&gt;Download the &lt;code&gt;.msix&lt;/code&gt; installer from the &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;Releases&lt;/a&gt; page. This package is signed, ensuring a secure installation. This is the same option as the Microsoft Store but is a portable installer.&lt;/p&gt; 
&lt;h3&gt;.exe Installer&lt;/h3&gt; 
&lt;p&gt;Download the latest version from the &lt;a href="https://github.com/eythaann/seelen-ui/releases"&gt;Releases&lt;/a&gt; page and run the &lt;code&gt;setup.exe&lt;/code&gt; installer. This option is less recommended as the installer is not signed, which may cause it to be flagged as a potential threat by some antivirus programs. The &lt;code&gt;setup.exe&lt;/code&gt; is updated more quickly than the Microsoft Store or Winget versions and also it receives notifications updates on new release.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Once installed or extracted, simply open the program. The easy-to-use and intuitive GUI will guide you through the configuration process. Customize your desktop environment effortlessly.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For in-depth details on various aspects of Seelen UI, explore the following documents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/languages.md"&gt;Languages&lt;/a&gt; - Information regarding translations.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/toolbar.md"&gt;Toolbar&lt;/a&gt; - Details about customizing and using the toolbar.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://seelen.io/blog/seelen-ui-theme-tutorial"&gt;Themes&lt;/a&gt; - Guidance on creating and applying themes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/window_manager.md"&gt;Window Manager&lt;/a&gt; - Instructions on configuring the window manager.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/project.md"&gt;Project&lt;/a&gt; - General information about the project and its structure.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Upcoming Features&lt;/h2&gt; 
&lt;p&gt;I‚Äôm excited to share some upcoming features for Seelen UI! Here‚Äôs a glimpse of what‚Äôs planned for the future:&lt;/p&gt; 
&lt;h3&gt;&lt;del&gt;App Launcher&lt;/del&gt; ‚úÖ&lt;/h3&gt; 
&lt;p&gt;I‚Äôm planning to develop an app launcher inspired by &lt;a href="https://github.com/davatorium/rofi"&gt;Rofi&lt;/a&gt; on Linux. This feature will provide a sleek and highly customizable way to quickly access your applications.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/adi1090x/files/master/rofi/previews/colorful/main.gif" alt="App Launcher Preview" /&gt; &lt;em&gt;Image courtesy of &lt;a href="https://github.com/dctxmei/rofi-themes"&gt;rofi-themes&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Customizable Popup Widgets&lt;/h3&gt; 
&lt;p&gt;I aim to introduce a set of fully customizable popup widgets, similar to the features available in &lt;a href="https://github.com/elkowar/eww"&gt;EWW&lt;/a&gt;. These widgets will be highly configurable and adaptable to your needs, providing an enhanced and interactive way to manage your desktop environment.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/adi1090x/widgets/main/previews/dashboard.png" alt="Customizable Widgets Preview" /&gt; &lt;em&gt;Image courtesy of &lt;a href="https://github.com/adi1090x/widgets"&gt;adi1090x&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Custom Alt + Tab (Task Switching)&lt;/h3&gt; 
&lt;p&gt;An upgraded Alt + Tab system for task switching is on the horizon. This will offer a more visually appealing and functional experience, allowing for smoother transitions between open applications and windows.&lt;/p&gt; 
&lt;h3&gt;Custom Virtual Desktops Viewer and Animations&lt;/h3&gt; 
&lt;p&gt;I‚Äôm also working on a custom virtual desktops viewer and dynamic animations to improve navigation between different workspaces. This will provide a more intuitive and immersive multitasking experience.&lt;/p&gt; 
&lt;p&gt;Stay tuned for more updates as I develop these features. I appreciate your support and enthusiasm!&lt;/p&gt; 
&lt;p&gt;Happy customizing!&lt;/p&gt; 
&lt;p&gt;The Seelen UI Team&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read the &lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/CONTRIBUTING"&gt;Contribution Guidelines&lt;/a&gt; to get started with terms.&lt;/li&gt; 
 &lt;li&gt;Read the &lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/documentation/project.md"&gt;Project Documentation&lt;/a&gt; to understand the project structure and how to use it.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/eythaann/Seelen-UI/master/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;For inquiries and support, please contact me on &lt;a href="https://discord.gg/ABfASx5ZAJ"&gt;Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;We're grateful for the support of our sponsors who help make Seelen UI possible.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Sponsor&lt;/th&gt; 
   &lt;th align="left"&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://www.digitalocean.com/?refcode=955c7335abf5&amp;amp;utm_campaign=Referral_Invite&amp;amp;utm_medium=Referral_Program&amp;amp;utm_source=badge"&gt;&lt;img src="https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%201.svg?sanitize=true" alt="DigitalOcean" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;DigitalOcean&lt;/strong&gt; provides cloud infrastructure services that power our development and testing environments.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;a href="https://signpath.io/"&gt;&lt;img src="https://avatars.githubusercontent.com/u/34448643?s=60" alt="SignPath" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;SignPath&lt;/strong&gt; provides free code signing certificates, ensuring secure and trusted releases for our users.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;See you later&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;                 .      .&amp;amp;     _,x&amp;amp;"``
                  &amp;amp; .   &amp;amp;'  ;.&amp;amp;&amp;amp;'
            &amp;amp;.  . &amp;amp;.&amp;amp;     .0&amp;amp;&amp;amp;&amp;amp;;&amp;amp;""`
       .    '&amp;amp;  &amp;amp;.&amp;amp;&amp;amp;&amp;amp;  .&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;'
     .&amp;amp;         ;&amp;amp;&amp;amp;&amp;amp; &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;'
    &amp;amp;&amp;amp;          &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;     &amp;amp;&amp;amp;&amp;amp;
   0&amp;amp;    .     &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;""
  &amp;amp;&amp;amp;   .0     &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;
 0&amp;amp;&amp;amp; .&amp;amp;'     &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;
:&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;    . &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp; 
0&amp;amp;&amp;amp;&amp;amp;&amp;amp;    &amp;amp; &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;
&amp;amp;&amp;amp;&amp;amp;&amp;amp;'   &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;               .&amp;amp;&amp;amp;&amp;amp;x&amp;amp;
&amp;amp;&amp;amp;&amp;amp;&amp;amp;   :&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0.&amp;amp;'        , .&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;;.
&amp;amp;&amp;amp;&amp;amp;&amp;amp;.  &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;        .&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;'               .
0&amp;amp;&amp;amp;&amp;amp;&amp;amp;  &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;       ,&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;                &amp;amp;
:&amp;amp;&amp;amp;&amp;amp;&amp;amp;; &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0       ,;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;             ;  .0
 0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0     ,;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;             &amp;amp;  &amp;amp;;
  0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0   :',;".&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;".&amp;amp;             &amp;amp;&amp;amp; &amp;amp;0
   0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0  ',;',&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;" ,&amp;amp;'             &amp;amp;&amp;amp;&amp;amp;&amp;amp;0
    0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0 ,x&amp;amp;&amp;amp;&amp;amp;&amp;amp;" .&amp;amp;&amp;amp;&amp;amp;              &amp;amp;&amp;amp;&amp;amp;&amp;amp;0
      0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp; .&amp;amp;&amp;amp;&amp;amp;&amp;amp;"'''"&amp;amp;&amp;amp;"&amp;amp;&amp;amp;            &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
       0&amp;amp;&amp;amp; .&amp;amp;&amp;amp;;``       `&amp;amp;: :&amp;amp;         &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
          &amp;amp;"' &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;   &amp;amp;"&amp;amp; &amp;amp;"&amp;amp;   &amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
            0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
               0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0         Seelen
                    0&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;&amp;amp;0
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;üìå &lt;strong&gt;Official Website&lt;/strong&gt;: &lt;a href="https://seelen.io"&gt;https://seelen.io&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Seelen Inc ¬© 2025 - All rights reserved&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>katanemo/archgw</title>
      <link>https://github.com/katanemo/archgw</link>
      <description>&lt;p&gt;Delivery infrastructure for agents. Arch is a models-native proxy server that handles the plumbing work in AI: agent routing &amp; orchestration, guardrails, zero-code logs and traces, unified access to LLMs from OpenAI, Anthropic, Ollama, etc. Build agents faster, and deliver them reliably to production.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/arch-logo.png" alt="Arch Logo" width="75%" height="auto" /&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Arch is a models-native (edge and service) proxy server for agents.&lt;/em&gt;&lt;br /&gt;&lt;br /&gt; Arch handles the &lt;em&gt;pesky plumbing work&lt;/em&gt; in building AI agents ‚Äî like applying guardrails, routing prompts to the right agent, generating hyper-rich information traces for RL, and unifying access to any LLM. It‚Äôs a language and framework friendly infrastructure layer designed to help you build and ship agentic apps faster.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Quickstart"&gt;Quickstart&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Demos"&gt;Demos&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#use-arch-as-a-llm-router"&gt;Route LLMs&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Build-Agentic-Apps-with-Arch"&gt;Build agentic apps with Arch&lt;/a&gt; ‚Ä¢ &lt;a href="https://docs.archgw.com"&gt;Documentation&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#Contact"&gt;Contact&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/katanemo/arch/actions/workflows/pre-commit.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/pre-commit.yml/badge.svg?sanitize=true" alt="pre-commit" /&gt;&lt;/a&gt; &lt;a href="https://github.com/katanemo/arch/actions/workflows/rust_tests.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/rust_tests.yml/badge.svg?sanitize=true" alt="rust tests (prompt and llm gateway)" /&gt;&lt;/a&gt; &lt;a href="https://github.com/katanemo/arch/actions/workflows/e2e_tests.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/e2e_tests.yml/badge.svg?sanitize=true" alt="e2e tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/katanemo/arch/actions/workflows/static.yml"&gt;&lt;img src="https://github.com/katanemo/arch/actions/workflows/static.yml/badge.svg?sanitize=true" alt="Build and Deploy Documentation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;About The Latest Release:&lt;/h1&gt; 
&lt;p&gt;[0.3.20] &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/use_cases/claude_code_router/README.md"&gt;Preference-aware multi LLM routing for Claude Code 2.0&lt;/a&gt; &lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/claude_code_router.png" alt="high-level network architecture for ArchGW" width="50%" /&gt;&lt;/p&gt; 
&lt;h1&gt;Overview&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.producthunt.com/posts/arch-3?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-arch-3" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=565761&amp;amp;theme=dark&amp;amp;period=daily&amp;amp;t=1742359429995" alt="Arch - Build fast, hyper-personalized agents with intelligent infra | Product Hunt" style="width: 188px; height: 41px;" width="188" height="41" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;AI demos are easy to hack. But once you move past a prototype, you‚Äôre stuck building and maintaining low-level plumbing code that slows down real innovation. For example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Routing &amp;amp; orchestration.&lt;/strong&gt; Put routing in code and you‚Äôve got two choices: maintain it yourself or live with a framework‚Äôs baked-in logic. Either way, keeping routing consistent means pushing code changes across all your agents, slowing iteration and turning every policy tweak into a refactor instead of a config flip.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Model integration churn.&lt;/strong&gt; Frameworks wire LLM integrations directly into code abstractions, making it hard to add or swap models without touching application code ‚Äî meaning you‚Äôll have to do codewide search/replace every time you want to experiment with a new model or version.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability &amp;amp; governance.&lt;/strong&gt; Logging, tracing, and guardrails are baked in as tightly coupled features, so bringing in best-of-breed solutions is painful and often requires digging through the guts of a framework.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Prompt engineering overhead&lt;/strong&gt;. Input validation, clarifying vague user input, and coercing outputs into the right schema all pile up, turning what should be design work into low-level plumbing work.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Brittle upgrades&lt;/strong&gt;. Every change (new model, new guardrail, new trace format) means patching and redeploying application servers. Contrast that with bouncing a central proxy‚Äîone upgrade, instantly consistent everywhere.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;With Arch, you can move faster by focusing on higher-level objectives in a language and framework agnostic way. &lt;strong&gt;Arch&lt;/strong&gt; was built by the contributors of &lt;a href="https://www.envoyproxy.io/"&gt;Envoy Proxy&lt;/a&gt; with the belief that:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Prompts are nuanced and opaque user requests, which require the same capabilities as traditional HTTP requests including secure handling, intelligent routing, robust observability, and integration with backend (API) systems to improve speed and accuracy for common agentic scenarios ‚Äì all outside core application logic.*&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Core Features&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;üö¶ Route to Agents&lt;/code&gt;: Engineered with purpose-built &lt;a href="https://huggingface.co/collections/katanemo/arch-function-66f209a693ea8df14317ad68"&gt;LLMs&lt;/a&gt; for fast (&amp;lt;100ms) agent routing and hand-off&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;üîó Route to LLMs&lt;/code&gt;: Unify access to LLMs with support for &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/#use-arch-as-a-llm-router"&gt;three routing strategies&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;‚õ® Guardrails&lt;/code&gt;: Centrally configure and prevent harmful outcomes and ensure safe user interactions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;‚ö° Tools Use&lt;/code&gt;: For common agentic scenarios let Arch instantly clarify and convert prompts to tools/API calls&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;üïµ Observability&lt;/code&gt;: W3C compatible request tracing and LLM metrics that instantly plugin with popular tools&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;üß± Built on Envoy&lt;/code&gt;: Arch runs alongside app servers as a containerized process, and builds on top of &lt;a href="https://envoyproxy.io"&gt;Envoy's&lt;/a&gt; proven HTTP management and scalability features to handle ingress and egress traffic related to prompts and LLMs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;High-Level Sequence Diagram&lt;/strong&gt;: &lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/arch_network_diagram_high_level.png" alt="high-level network architecture for ArchGW" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Jump to our &lt;a href="https://docs.archgw.com"&gt;docs&lt;/a&gt;&lt;/strong&gt; to learn how you can use Arch to improve the speed, security and personalization of your GenAI apps.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Today, the function calling LLM (Arch-Function) designed for the agentic and RAG scenarios is hosted free of charge in the US-central region. To offer consistent latencies and throughput, and to manage our expenses, we will enable access to the hosted version via developers keys soon, and give you the option to run that LLM locally. For more details see this issue &lt;a href="https://github.com/katanemo/archgw/issues/258"&gt;#258&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;To get in touch with us, please join our &lt;a href="https://discord.gg/pGZf2gcwEc"&gt;discord server&lt;/a&gt;. We will be monitoring that actively and offering support there.&lt;/p&gt; 
&lt;h2&gt;Demos&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/samples_python/weather_forecast/README.md"&gt;Sample App: Weather Forecast Agent&lt;/a&gt; - A sample agentic weather forecasting app that highlights core function calling capabilities of Arch.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/samples_python/network_switch_operator_agent/README.md"&gt;Sample App: Network Operator Agent&lt;/a&gt; - A simple network device switch operator agent that can retrieve device statistics and reboot them.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/demos/use_cases/spotify_bearer_auth"&gt;Use Case: Connecting to SaaS APIs&lt;/a&gt; - Connect 3rd party SaaS APIs to your agentic chat experience.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Follow this quickstart guide to use Arch as a router for local or hosted LLMs, including dynamic routing. Later in the section we will see how you can Arch to build highly capable agentic applications, and to provide e2e observability.&lt;/p&gt; 
&lt;h3&gt;Prerequisites&lt;/h3&gt; 
&lt;p&gt;Before you begin, ensure you have the following:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/get-started/get-docker/"&gt;Docker System&lt;/a&gt; (v24)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/install/"&gt;Docker compose&lt;/a&gt; (v2.29)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python&lt;/a&gt; (v3.13)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Arch's CLI allows you to manage and interact with the Arch gateway efficiently. To install the CLI, simply run the following command:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] We recommend that developers create a new Python virtual environment to isolate dependencies before installing Arch. This ensures that archgw and its dependencies do not interfere with other packages on your system.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ python3.12 -m venv venv
$ source venv/bin/activate   # On Windows, use: venv\Scripts\activate
$ pip install archgw==0.3.21
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Use Arch as a LLM Router&lt;/h3&gt; 
&lt;p&gt;Arch supports three powerful routing strategies for LLMs: model-based routing, alias-based routing, and preference-based routing. Each strategy offers different levels of abstraction and control for managing your LLM infrastructure.&lt;/p&gt; 
&lt;h4&gt;Model-based Routing&lt;/h4&gt; 
&lt;p&gt;Model-based routing allows you to configure specific models with static routing. This is ideal when you need direct control over which models handle specific requests. Arch supports 11+ LLM providers including OpenAI, Anthropic, DeepSeek, Mistral, Groq, and more.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - model: openai/gpt-4o
    access_key: $OPENAI_API_KEY
    default: true

  - model: anthropic/claude-3-5-sonnet-20241022
    access_key: $ANTHROPIC_API_KEY

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can then route to specific models using any OpenAI-compatible client:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI

client = OpenAI(base_url="http://127.0.0.1:12000/v1", api_key="test")

# Route to specific model
response = client.chat.completions.create(
    model="anthropic/claude-3-5-sonnet-20241022",
    messages=[{"role": "user", "content": "Explain quantum computing"}]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Alias-based Routing&lt;/h4&gt; 
&lt;p&gt;Alias-based routing lets you create semantic model names that map to underlying providers. This approach decouples your application code from specific model names, making it easy to experiment with different models or handle provider changes.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - model: openai/gpt-4o
    access_key: $OPENAI_API_KEY

  - model: anthropic/claude-3-5-sonnet-20241022
    access_key: $ANTHROPIC_API_KEY

model_aliases:
  # Model aliases - friendly names that map to actual model names
  fast-model:
    target: gpt-4o-mini

  reasoning-model:
    target: gpt-4o

  creative-model:
    target: claude-3-5-sonnet-20241022
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use semantic aliases in your application code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Your code uses semantic names instead of provider-specific ones
response = client.chat.completions.create(
    model="reasoning-model",  # Routes to best available reasoning model
    messages=[{"role": "user", "content": "Solve this complex problem..."}]
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Preference-aligned Routing&lt;/h4&gt; 
&lt;p&gt;Preference-aligned routing provides intelligent, dynamic model selection based on natural language descriptions of tasks and preferences. Instead of hardcoded routing logic, you describe what each model is good at using plain English.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - model: openai/gpt-4o
    access_key: $OPENAI_API_KEY
    routing_preferences:
      - name: complex_reasoning
        description: deep analysis, mathematical problem solving, and logical reasoning
      - name: creative_writing
        description: storytelling, creative content, and artistic writing

  - model: deepseek/deepseek-coder
    access_key: $DEEPSEEK_API_KEY
    routing_preferences:
      - name: code_generation
        description: generating new code, writing functions, and creating scripts
      - name: code_review
        description: analyzing existing code for bugs, improvements, and optimization
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Arch uses a lightweight 1.5B autoregressive model to intelligently map user prompts to these preferences, automatically selecting the best model for each request. This approach adapts to intent drift, supports multi-turn conversations, and avoids brittle embedding-based classifiers or manual if/else chains. No retraining required when adding models or updating policies ‚Äî routing is governed entirely by human-readable rules.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn More&lt;/strong&gt;: Check our &lt;a href="https://docs.archgw.com/concepts/llm_providers/llm_providers.html"&gt;documentation&lt;/a&gt; for comprehensive provider setup guides and routing strategies. You can learn more about the design, benchmarks, and methodology behind preference-based routing in our paper:&lt;/p&gt; 
&lt;div align="left"&gt; 
 &lt;a href="https://arxiv.org/abs/2506.16655" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/arch_router_paper_preview.png" alt="Arch Router Paper Preview" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h3&gt;Build Agentic Apps with Arch&lt;/h3&gt; 
&lt;p&gt;In following quickstart we will show you how easy it is to build AI agent with Arch gateway. We will build a currency exchange agent using following simple steps. For this demo we will use &lt;code&gt;https://api.frankfurter.dev/&lt;/code&gt; to fetch latest price for currencies and assume USD as base currency.&lt;/p&gt; 
&lt;h4&gt;Step 1. Create arch config file&lt;/h4&gt; 
&lt;p&gt;Create &lt;code&gt;arch_config.yaml&lt;/code&gt; file with following content,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;version: v0.1.0

listeners:
  ingress_traffic:
    address: 0.0.0.0
    port: 10000
    message_format: openai
    timeout: 30s

llm_providers:
  - access_key: $OPENAI_API_KEY
    model: openai/gpt-4o

system_prompt: |
  You are a helpful assistant.

prompt_guards:
  input_guards:
    jailbreak:
      on_exception:
        message: Looks like you're curious about my abilities, but I can only provide assistance for currency exchange.

prompt_targets:
  - name: currency_exchange
    description: Get currency exchange rate from USD to other currencies
    parameters:
      - name: currency_symbol
        description: the currency that needs conversion
        required: true
        type: str
        in_path: true
    endpoint:
      name: frankfurter_api
      path: /v1/latest?base=USD&amp;amp;symbols={currency_symbol}
    system_prompt: |
      You are a helpful assistant. Show me the currency symbol you want to convert from USD.

  - name: get_supported_currencies
    description: Get list of supported currencies for conversion
    endpoint:
      name: frankfurter_api
      path: /v1/currencies

endpoints:
  frankfurter_api:
    endpoint: api.frankfurter.dev:443
    protocol: https
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 2. Start arch gateway with currency conversion config&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;
$ archgw up arch_config.yaml
2024-12-05 16:56:27,979 - cli.main - INFO - Starting archgw cli version: 0.3.21
2024-12-05 16:56:28,485 - cli.utils - INFO - Schema validation successful!
2024-12-05 16:56:28,485 - cli.main - INFO - Starting arch model server and arch gateway
2024-12-05 16:56:51,647 - cli.core - INFO - Container is healthy!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once the gateway is up you can start interacting with at port 10000 using openai chat completion API.&lt;/p&gt; 
&lt;p&gt;Some of the sample queries you can ask could be &lt;code&gt;what is currency rate for gbp?&lt;/code&gt; or &lt;code&gt;show me list of currencies for conversion&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Step 3. Interacting with gateway using curl command&lt;/h4&gt; 
&lt;p&gt;Here is a sample curl command you can use to interact,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ curl --header 'Content-Type: application/json' \
  --data '{"messages": [{"role": "user","content": "what is exchange rate for gbp"}], "model": "none"}' \
  http://localhost:10000/v1/chat/completions | jq ".choices[0].message.content"

"As of the date provided in your context, December 5, 2024, the exchange rate for GBP (British Pound) from USD (United States Dollar) is 0.78558. This means that 1 USD is equivalent to 0.78558 GBP."

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And to get list of supported currencies,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ curl --header 'Content-Type: application/json' \
  --data '{"messages": [{"role": "user","content": "show me list of currencies that are supported for conversion"}], "model": "none"}' \
  http://localhost:10000/v1/chat/completions | jq ".choices[0].message.content"

"Here is a list of the currencies that are supported for conversion from USD, along with their symbols:\n\n1. AUD - Australian Dollar\n2. BGN - Bulgarian Lev\n3. BRL - Brazilian Real\n4. CAD - Canadian Dollar\n5. CHF - Swiss Franc\n6. CNY - Chinese Renminbi Yuan\n7. CZK - Czech Koruna\n8. DKK - Danish Krone\n9. EUR - Euro\n10. GBP - British Pound\n11. HKD - Hong Kong Dollar\n12. HUF - Hungarian Forint\n13. IDR - Indonesian Rupiah\n14. ILS - Israeli New Sheqel\n15. INR - Indian Rupee\n16. ISK - Icelandic Kr√≥na\n17. JPY - Japanese Yen\n18. KRW - South Korean Won\n19. MXN - Mexican Peso\n20. MYR - Malaysian Ringgit\n21. NOK - Norwegian Krone\n22. NZD - New Zealand Dollar\n23. PHP - Philippine Peso\n24. PLN - Polish Z≈Çoty\n25. RON - Romanian Leu\n26. SEK - Swedish Krona\n27. SGD - Singapore Dollar\n28. THB - Thai Baht\n29. TRY - Turkish Lira\n30. USD - United States Dollar\n31. ZAR - South African Rand\n\nIf you want to convert USD to any of these currencies, you can select the one you are interested in."

&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;&lt;a href="https://docs.archgw.com/guides/observability/observability.html"&gt;Observability&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Arch is designed to support best-in class observability by supporting open standards. Please read our &lt;a href="https://docs.archgw.com/guides/observability/observability.html"&gt;docs&lt;/a&gt; on observability for more details on tracing, metrics, and logs. The screenshot below is from our integration with Signoz (among others)&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/katanemo/archgw/main/docs/source/_static/img/tracing.png" alt="alt text" /&gt;&lt;/p&gt; 
&lt;h2&gt;Debugging&lt;/h2&gt; 
&lt;p&gt;When debugging issues / errors application logs and access logs provide key information to give you more context on whats going on with the system. Arch gateway runs in info log level and following is a typical output you could see in a typical interaction between developer and arch gateway,&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ archgw up --service archgw --foreground
...
[2025-03-26 18:32:01.350][26][info] prompt_gateway: on_http_request_body: sending request to model server
[2025-03-26 18:32:01.851][26][info] prompt_gateway: on_http_call_response: model server response received
[2025-03-26 18:32:01.852][26][info] prompt_gateway: on_http_call_response: dispatching api call to developer endpoint: weather_forecast_service, path: /weather, method: POST
[2025-03-26 18:32:01.882][26][info] prompt_gateway: on_http_call_response: developer api call response received: status code: 200
[2025-03-26 18:32:01.882][26][info] prompt_gateway: on_http_call_response: sending request to upstream llm
[2025-03-26 18:32:01.883][26][info] llm_gateway: on_http_request_body: provider: gpt-4o-mini, model requested: None, model selected: gpt-4o-mini
[2025-03-26 18:32:02.818][26][info] llm_gateway: on_http_response_body: time to first token: 1468ms
[2025-03-26 18:32:04.532][26][info] llm_gateway: on_http_response_body: request latency: 3183ms
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Log level can be changed to debug to get more details. To enable debug logs edit (supervisord.conf)[arch/supervisord.conf], change the log level &lt;code&gt;--component-log-level wasm:info&lt;/code&gt; to &lt;code&gt;--component-log-level wasm:debug&lt;/code&gt;. And after that you need to rebuild docker image and restart the arch gateway using following set of commands,&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# make sure you are at the root of the repo
$ archgw build
# go to your service that has arch_config.yaml file and issue following command,
$ archgw up --service archgw --foreground
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;We would love feedback on our &lt;a href="https://github.com/orgs/katanemo/projects/1"&gt;Roadmap&lt;/a&gt; and we welcome contributions to &lt;strong&gt;Arch&lt;/strong&gt;! Whether you're fixing bugs, adding new features, improving documentation, or creating tutorials, your help is much appreciated. Please visit our &lt;a href="https://raw.githubusercontent.com/katanemo/archgw/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; for more details&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ArthurBrussee/brush</title>
      <link>https://github.com/ArthurBrussee/brush</link>
      <description>&lt;p&gt;3D Reconstruction for all&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Brush&lt;/h1&gt; 
&lt;p&gt;
 &lt;video src="https://github.com/user-attachments/assets/5756967a-846c-44cf-bde9-3ca4c86f1a4d"&gt;
  A video showing various Brush features and scenes
 &lt;/video&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt; Massive thanks to &lt;a href="https://www.youtube.com/@gradeeterna"&gt;@GradeEterna&lt;/a&gt; for the beautiful scenes &lt;/i&gt; &lt;/p&gt; 
&lt;p&gt;Brush is a 3D reconstruction engine using &lt;a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/"&gt;Gaussian splatting&lt;/a&gt;. It works on a wide range of systems: &lt;strong&gt;macOS/windows/linux&lt;/strong&gt;, &lt;strong&gt;AMD/Nvidia/Intel&lt;/strong&gt; cards, &lt;strong&gt;Android&lt;/strong&gt;, and in a &lt;strong&gt;browser&lt;/strong&gt;. To achieve this, it uses WebGPU compatible tech and the &lt;a href="https://github.com/tracel-ai/burn"&gt;Burn&lt;/a&gt; machine learning framework.&lt;/p&gt; 
&lt;p&gt;Machine learning for real time rendering has tons of potential, but most ML tools don't work well with it: Rendering requires realtime interactivity, usually involve dynamic shapes &amp;amp; computations, don't run on most platforms, and it can be cumbersome to ship apps with large CUDA deps. Brush on the other hand produces simple dependency free binaries, runs on nearly all devices, without any setup.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://arthurbrussee.github.io/brush-demo"&gt;&lt;strong&gt;Try the web demo&lt;/strong&gt; &lt;img src="https://cdn-icons-png.flaticon.com/256/888/888846.png" alt="chrome logo" width="24" /&gt; &lt;/a&gt; &lt;em&gt;NOTE: Only works on Chrome and Edge. Firefox and Safari are hopefully supported soon)&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/TbxJST2BbC"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/https://discord.gg/TbxJST2BbC" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Training&lt;/h2&gt; 
&lt;p&gt;Brush takes in COLMAP data or datasets in the Nerfstudio format. Training is fully supported natively, on mobile, and in a browser. While training you can interact with the scene and see the training dynamics live, and compare the current rendering to input views as the training progresses.&lt;/p&gt; 
&lt;p&gt;It also supports masking images:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Images with transparency. This will force the final splat to match the transparency of the input.&lt;/li&gt; 
 &lt;li&gt;A folder of images called 'masks'. This ignores parts of the image that are masked out.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Viewer&lt;/h2&gt; 
&lt;p&gt;Brush also works well as a splat viewer, including on the web. It can load .ply &amp;amp; .compressed.ply files. You can stream in data from a URL (for a web app, simply append &lt;code&gt;?url=&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;Brush also can load .zip of splat files to display them as an animation, or a special ply that includes delta frames (see &lt;a href="https://cat-4d.github.io/"&gt;cat-4D&lt;/a&gt; and &lt;a href="https://felixtaubner.github.io/cap4d/"&gt;Cap4D&lt;/a&gt;!).&lt;/p&gt; 
&lt;h2&gt;CLI&lt;/h2&gt; 
&lt;p&gt;Brush can be used as a CLI. Run &lt;code&gt;brush --help&lt;/code&gt; to get an overview. Every CLI command can work with &lt;code&gt;--with-viewer&lt;/code&gt; which also opens the UI, for easy debugging.&lt;/p&gt; 
&lt;h2&gt;Rerun&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/f679fec0-935d-4dd2-87e1-c301db9cdc2c"&gt;https://github.com/user-attachments/assets/f679fec0-935d-4dd2-87e1-c301db9cdc2c&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;While training, additional data can be visualized with the excellent &lt;a href="https://rerun.io/"&gt;rerun&lt;/a&gt;. To install rerun on your machine, please follow their &lt;a href="https://rerun.io/docs/getting-started/installing-viewer"&gt;instructions&lt;/a&gt;. Open the ./brush_blueprint.rbl in the viewer for best results.&lt;/p&gt; 
&lt;h2&gt;Building Brush&lt;/h2&gt; 
&lt;p&gt;First install rust 1.88+. You can run tests with &lt;code&gt;cargo test --all&lt;/code&gt;. Brush uses the wonderful &lt;a href="https://rerun.io/"&gt;rerun&lt;/a&gt; for additional visualizations while training, run &lt;code&gt;cargo install rerun-cli&lt;/code&gt; if you want to use it.&lt;/p&gt; 
&lt;h3&gt;Windows/macOS/Linux&lt;/h3&gt; 
&lt;p&gt;Simply &lt;code&gt;cargo run&lt;/code&gt; or &lt;code&gt;cargo run --release&lt;/code&gt; from the workspace root. Brush can also be used as a CLI, run &lt;code&gt;cargo run --release -- --help&lt;/code&gt; to use the CLI directly from source. See the notes about the CLI in the features section.&lt;/p&gt; 
&lt;h3&gt;Web&lt;/h3&gt; 
&lt;p&gt;Brush can be compiled to WASM. Run &lt;code&gt;npm run dev&lt;/code&gt; to start the demo website using Next.js, see the brush_nextjs directory.&lt;/p&gt; 
&lt;p&gt;Brush uses &lt;a href="https://rustwasm.github.io/wasm-bindgen/introduction.html"&gt;&lt;code&gt;wasm-pack&lt;/code&gt;&lt;/a&gt; to build the WASM bundle. You can also use it without a bundler, see &lt;a href="hhttps://rustwasm.github.io/wasm-bindgen/examples/without-a-bundler.html"&gt;wasm-pack's documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;WebGPU is still an upcoming standard, and as such, only Chrome 134+ on Windows and macOS is currently supported.&lt;/p&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;p&gt;As a one time setup, make sure you have the Android SDK &amp;amp; NDK installed.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check if ANDROID_NDK_HOME and ANDROID_HOME are set&lt;/li&gt; 
 &lt;li&gt;Add the Android target to rust &lt;code&gt;rustup target add aarch64-linux-android&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install cargo-ndk to manage building a lib &lt;code&gt;cargo install cargo-ndk&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each time you change the rust code, run&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;cargo ndk -t arm64-v8a -o crates/brush-app/app/src/main/jniLibs/ build&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Nb: Nb, for best performance, build in release mode. This is separate from the Android Studio app build configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cargo ndk -t arm64-v8a -o crates/brush-app/app/src/main/jniLibs/ build --release&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can now either run the project from Android Studio (Android Studio does NOT build the rust code), or run it from the command line:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./gradlew build
./gradlew installDebug
adb shell am start -n com.splats.app/.MainActivity
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also open this folder as a project in Android Studio and run things from there. Nb: Running in Android Studio does &lt;em&gt;not&lt;/em&gt; rebuild the rust code automatically.&lt;/p&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;Rendering and training are generally faster than gsplat. You can run benchmarks of some of the kernels using &lt;code&gt;cargo bench&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Acknowledgements&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/nerfstudio-project/gsplat"&gt;&lt;strong&gt;gSplat&lt;/strong&gt;&lt;/a&gt;, for their reference version of the kernels&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Peter Hedman, George Kopanas &amp;amp; Bernhard Kerbl&lt;/strong&gt;, for the many discussions &amp;amp; pointers.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The Burn team&lt;/strong&gt;, for help &amp;amp; improvements to Burn along the way&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Raph Levien&lt;/strong&gt;, for the &lt;a href="https://github.com/googlefonts/compute-shader-101/pull/31"&gt;original version&lt;/a&gt; of the GPU radix sort.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;GradeEterna&lt;/strong&gt;, for feedback and their scenes.&lt;/p&gt; 
&lt;h1&gt;Disclaimer&lt;/h1&gt; 
&lt;p&gt;This is &lt;em&gt;not&lt;/em&gt; an official Google product. This repository is a forked public version of &lt;a href="https://github.com/google-research/google-research/tree/master/brush_splat"&gt;the google-research repository&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automattic/harper</title>
      <link>https://github.com/Automattic/harper</link>
      <description>&lt;p&gt;Offline, privacy-first grammar checker. Fast, open-source, Rust-powered&lt;/p&gt;&lt;hr&gt;&lt;div id="header" align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/Automattic/harper/master/logo.svg?sanitize=true" width="400px" /&gt; 
 &lt;h1&gt;Harper&lt;/h1&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;a href="https://github.com/automattic/harper/actions/workflows/binaries.yml"&gt;&lt;img src="https://github.com/automattic/harper/actions/workflows/binaries.yml/badge.svg?sanitize=true" alt="Harper Binaries" /&gt;&lt;/a&gt; &lt;a href="https://github.com/automattic/harper/actions/workflows/build_web.yml"&gt;&lt;img src="https://github.com/automattic/harper/actions/workflows/build_web.yml/badge.svg?sanitize=true" alt="Website" /&gt;&lt;/a&gt; &lt;a href="https://github.com/automattic/harper/actions/workflows/just_checks.yml"&gt;&lt;img src="https://github.com/automattic/harper/actions/workflows/just_checks.yml/badge.svg?sanitize=true" alt="Checks" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/harper-ls"&gt;&lt;img src="https://img.shields.io/crates/v/harper-ls" alt="Crates.io" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/npm/v/harper.js" alt="NPM Version" /&gt; &lt;img src="https://img.shields.io/github/downloads/automattic/harper/total?label=Binary+Downloads" alt="Downloads" /&gt; &lt;img src="https://img.shields.io/github/downloads/automattic/harper-obsidian-plugin/total?label=Obsidian+Plugin+Downloads" alt="Obsidian Plugin Downloads" /&gt;&lt;/p&gt; 
&lt;p&gt;Harper is an English grammar checker designed to be &lt;em&gt;just right.&lt;/em&gt; I created it after years of dealing with the shortcomings of the competition.&lt;/p&gt; 
&lt;p&gt;Grammarly was too expensive and too overbearing. Its suggestions lacked context, and were often just plain &lt;em&gt;wrong&lt;/em&gt;. Not to mention: it's a privacy nightmare. Everything you write with Grammarly is sent to their servers. Their privacy policy claims they don't sell the data, but that doesn't mean they don't use it to train large language models and god knows what else. Not only that, but the round-trip-time of the network request makes revising your work all the more tedious.&lt;/p&gt; 
&lt;p&gt;LanguageTool is great, if you have gigabytes of RAM to spare and are willing to download the ~16GB n-gram dataset. Besides the memory requirements, I found LanguageTool too slow: it would take several seconds to lint even a moderate-size document.&lt;/p&gt; 
&lt;p&gt;That's why I created Harper: it is the grammar checker that fits my needs. Not only does it take milliseconds to lint a document, take less than 1/50th of LanguageTool's memory footprint, but it is also completely private.&lt;/p&gt; 
&lt;p&gt;Harper is even small enough to load via &lt;a href="https://writewithharper.com"&gt;WebAssembly.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Language Support&lt;/h2&gt; 
&lt;p&gt;Harper currently only supports English, but the core is extensible to support other languages, so we welcome contributions that allow for other language support.&lt;/p&gt; 
&lt;h2&gt;Performance Issues&lt;/h2&gt; 
&lt;p&gt;We consider long lint times bugs. If you encounter any significant performance issues, please create an issue on the topic.&lt;/p&gt; 
&lt;p&gt;If you find a fix to any performance issue, we would appreciate the contribution. Just please make sure to read &lt;a href="https://github.com/automattic/harper/raw/master/CONTRIBUTING.md"&gt;our contribution guidelines first.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://writewithharper.com/#faqs"&gt;Frequently Asked Questions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://writewithharper.com/docs/integrations/obsidian"&gt;Obsidian Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://writewithharper.com/docs/integrations/language-server"&gt;&lt;code&gt;harper-ls&lt;/code&gt; Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Supported Editors' Documentation 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://writewithharper.com/docs/integrations/visual-studio-code"&gt;Visual Studio Code&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://writewithharper.com/docs/integrations/neovim"&gt;Neovim&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://writewithharper.com/docs/integrations/helix"&gt;Helix&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://writewithharper.com/docs/integrations/emacs"&gt;Emacs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://writewithharper.com/docs/integrations/zed"&gt;Zed&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://writewithharper.com/docs/harperjs/introduction"&gt;&lt;code&gt;harper.js&lt;/code&gt; Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.com/invite/JBqcAaKrzQ"&gt;Official Discord Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Huge Thanks&lt;/h2&gt; 
&lt;p&gt;This project would not be possible without the hard work from those who &lt;a href="https://writewithharper.com/docs/contributors/introduction"&gt;contribute&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://github.com/automattic/harper/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=automattic/harper" /&gt; &lt;/a&gt; 
&lt;p&gt;Harper's logo was designed by &lt;a href="https://lukaswerner.com/"&gt;Lukas Werner&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>typst/typst</title>
      <link>https://github.com/typst/typst</link>
      <description>&lt;p&gt;A markup-based typesetting system that is powerful and easy to learn.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img alt="Typst" src="https://user-images.githubusercontent.com/17899797/226108480-722b770e-6313-40d7-84f2-26bebb55a281.png" /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://typst.app/docs/"&gt; &lt;img alt="Documentation" src="https://img.shields.io/website?down_message=offline&amp;amp;label=docs&amp;amp;up_color=007aff&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Ftypst.app%2Fdocs" /&gt;&lt;/a&gt; &lt;a href="https://typst.app/"&gt; &lt;img alt="Typst App" src="https://img.shields.io/website?down_message=offline&amp;amp;label=typst.app&amp;amp;up_color=239dad&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Ftypst.app" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/2uDybryKPe"&gt; &lt;img alt="Discord Server" src="https://img.shields.io/discord/1054443721975922748?color=5865F2&amp;amp;label=discord&amp;amp;labelColor=555" /&gt;&lt;/a&gt; &lt;a href="https://github.com/typst/typst/raw/main/LICENSE"&gt; &lt;img alt="Apache-2 License" src="https://img.shields.io/badge/license-Apache%202-brightgreen" /&gt;&lt;/a&gt; &lt;a href="https://typst.app/jobs/"&gt; &lt;img alt="Jobs at Typst" src="https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Ftypst.app%2Fassets%2Fdata%2Fshields.json&amp;amp;query=%24.jobs.text&amp;amp;label=jobs&amp;amp;color=%23A561FF&amp;amp;cacheSeconds=1800" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Typst is a new markup-based typesetting system that is designed to be as powerful as LaTeX while being much easier to learn and use. Typst has:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Built-in markup for the most common formatting tasks&lt;/li&gt; 
 &lt;li&gt;Flexible functions for everything else&lt;/li&gt; 
 &lt;li&gt;A tightly integrated scripting system&lt;/li&gt; 
 &lt;li&gt;Math typesetting, bibliography management, and more&lt;/li&gt; 
 &lt;li&gt;Fast compile times thanks to incremental compilation&lt;/li&gt; 
 &lt;li&gt;Friendly error messages in case something goes wrong&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This repository contains the Typst compiler and its CLI, which is everything you need to compile Typst documents locally. For the best writing experience, consider signing up to our &lt;a href="https://typst.app/"&gt;collaborative online editor&lt;/a&gt; for free.&lt;/p&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;A &lt;a href="https://typst.app/docs/tutorial/"&gt;gentle introduction&lt;/a&gt; to Typst is available in our documentation. However, if you want to see the power of Typst encapsulated in one image, here it is:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img alt="Example" width="900" src="https://user-images.githubusercontent.com/17899797/228031796-ced0e452-fcee-4ae9-92da-b9287764ff25.png" /&gt; &lt;/p&gt; 
&lt;p&gt;Let's dissect what's going on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;We use &lt;em&gt;set rules&lt;/em&gt; to configure element properties like the size of pages or the numbering of headings. By setting the page height to &lt;code&gt;auto&lt;/code&gt;, it scales to fit the content. Set rules accommodate the most common configurations. If you need full control, you can also use &lt;a href="https://typst.app/docs/reference/styling/#show-rules"&gt;show rules&lt;/a&gt; to completely redefine the appearance of an element.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;We insert a heading with the &lt;code&gt;= Heading&lt;/code&gt; syntax. One equals sign creates a top level heading, two create a subheading and so on. Typst has more lightweight markup like this, see the &lt;a href="https://typst.app/docs/reference/syntax/"&gt;syntax&lt;/a&gt; reference for a full list.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://typst.app/docs/reference/math/"&gt;Mathematical equations&lt;/a&gt; are enclosed in dollar signs. By adding extra spaces around the contents of an equation, we can put it into a separate block. Multi-letter identifiers are interpreted as Typst definitions and functions unless put into quotes. This way, we don't need backslashes for things like &lt;code&gt;floor&lt;/code&gt; and &lt;code&gt;sqrt&lt;/code&gt;. And &lt;code&gt;phi.alt&lt;/code&gt; applies the &lt;code&gt;alt&lt;/code&gt; modifier to the &lt;code&gt;phi&lt;/code&gt; to select a particular symbol variant.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Now, we get to some &lt;a href="https://typst.app/docs/reference/scripting/"&gt;scripting&lt;/a&gt;. To input code into a Typst document, we can write a hash followed by an expression. We define two variables and a recursive function to compute the n-th fibonacci number. Then, we display the results in a center-aligned table. The table function takes its cells row-by-row. Therefore, we first pass the formulas &lt;code&gt;$F_1$&lt;/code&gt; to &lt;code&gt;$F_8$&lt;/code&gt; and then the computed fibonacci numbers. We apply the spreading operator (&lt;code&gt;..&lt;/code&gt;) to both because they are arrays and we want to pass the arrays' items as individual arguments.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;Text version of the code example.&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-typst"&gt;#set page(width: 10cm, height: auto)
#set heading(numbering: "1.")

= Fibonacci sequence
The Fibonacci sequence is defined through the
recurrence relation $F_n = F_(n-1) + F_(n-2)$.
It can also be expressed in _closed form:_

$ F_n = round(1 / sqrt(5) phi.alt^n), quad
  phi.alt = (1 + sqrt(5)) / 2 $

#let count = 8
#let nums = range(1, count + 1)
#let fib(n) = (
  if n &amp;lt;= 2 { 1 }
  else { fib(n - 1) + fib(n - 2) }
)

The first #count numbers of the sequence are:

#align(center, table(
  columns: count,
  ..nums.map(n =&amp;gt; $F_#n$),
  ..nums.map(n =&amp;gt; str(fib(n))),
))
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Typst's CLI is available from different sources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;You can get sources and pre-built binaries for the latest release of Typst from the &lt;a href="https://github.com/typst/typst/releases/"&gt;releases page&lt;/a&gt;. Download the archive for your platform and place it in a directory that is in your &lt;code&gt;PATH&lt;/code&gt;. To stay up to date with future releases, you can simply run &lt;code&gt;typst update&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;You can install Typst through different package managers. Note that the versions in the package managers might lag behind the latest release.&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Linux: 
    &lt;ul&gt; 
     &lt;li&gt;View &lt;a href="https://repology.org/project/typst/versions"&gt;Typst on Repology&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;View &lt;a href="https://snapcraft.io/typst"&gt;Typst's Snap&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;macOS: &lt;code&gt;brew install typst&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Windows: &lt;code&gt;winget install --id Typst.Typst&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;If you have a &lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt; toolchain installed, you can install&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;the latest released Typst version with &lt;code&gt;cargo install --locked typst-cli&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;a development version with &lt;code&gt;cargo install --git https://github.com/typst/typst --locked typst-cli&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Nix users can&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;use the &lt;code&gt;typst&lt;/code&gt; package with &lt;code&gt;nix-shell -p typst&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;build and run a development version with &lt;code&gt;nix run github:typst/typst -- --version&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Docker users can run a prebuilt image with &lt;code&gt;docker run ghcr.io/typst/typst:latest --help&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;p&gt;Once you have installed Typst, you can use it like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Creates `file.pdf` in working directory.
typst compile file.typ

# Creates PDF file at the desired path.
typst compile path/to/source.typ path/to/output.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also watch source files and automatically recompile on changes. This is faster than compiling from scratch each time because Typst has incremental compilation.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Watches source files and recompiles on changes.
typst watch file.typ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Typst further allows you to add custom font paths for your project and list all of the fonts it discovered:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Adds additional directories to search for fonts.
typst compile --font-path path/to/fonts file.typ

# Lists all of the discovered fonts in the system and the given directory.
typst fonts --font-path path/to/fonts

# Or via environment variable (Linux syntax).
TYPST_FONT_PATHS=path/to/fonts typst fonts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For other CLI subcommands and options, see below:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# Prints available subcommands and options.
typst help

# Prints detailed usage of a subcommand.
typst help watch
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you prefer an integrated IDE-like experience with autocompletion and instant preview, you can also check out our &lt;a href="https://typst.app/"&gt;free web app&lt;/a&gt;. Alternatively, there is a community-created language server called &lt;a href="https://myriad-dreamin.github.io/tinymist/"&gt;Tinymist&lt;/a&gt; which is integrated into various editor extensions.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The main places where the community gathers are our &lt;a href="https://forum.typst.app/"&gt;Forum&lt;/a&gt; and our &lt;a href="https://discord.gg/2uDybryKPe"&gt;Discord server&lt;/a&gt;. The Forum is a great place to ask questions, help others, and share cool things you created with Typst. The Discord server is more suitable for quicker questions, discussions about contributing, or just to chat. We'd be happy to see you there!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://typst.app/universe/"&gt;Typst Universe&lt;/a&gt; is where the community shares templates and packages. If you want to share your own creations, you can submit them to our &lt;a href="https://github.com/typst/packages/"&gt;package repository&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you had a bad experience in our community, please &lt;a href="https://typst.app/contact"&gt;reach out to us&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We love to see contributions from the community. If you experience bugs, feel free to open an issue. If you would like to implement a new feature or bug fix, please follow the steps outlined in the &lt;a href="https://github.com/typst/typst/raw/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To build Typst yourself, first ensure that you have the &lt;a href="https://rustup.rs/"&gt;latest stable Rust&lt;/a&gt; installed. Then, clone this repository and build the CLI with the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/typst/typst
cd typst
cargo build --release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The optimized binary will be stored in &lt;code&gt;target/release/&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Another good way to contribute is by &lt;a href="https://github.com/typst/packages/"&gt;sharing packages&lt;/a&gt; with the community.&lt;/p&gt; 
&lt;h2&gt;Pronunciation and Spelling&lt;/h2&gt; 
&lt;p&gt;IPA: /ta…™pst/. "Ty" like in &lt;strong&gt;Ty&lt;/strong&gt;pesetting and "pst" like in Hi&lt;strong&gt;pst&lt;/strong&gt;er. When writing about Typst, capitalize its name as a proper noun, with a capital "T".&lt;/p&gt; 
&lt;h2&gt;Design Principles&lt;/h2&gt; 
&lt;p&gt;All of Typst has been designed with three key goals in mind: Power, simplicity, and performance. We think it's time for a system that matches the power of LaTeX, is easy to learn and use, all while being fast enough to realize instant preview. To achieve these goals, we follow three core design principles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Simplicity through Consistency:&lt;/strong&gt; If you know how to do one thing in Typst, you should be able to transfer that knowledge to other things. If there are multiple ways to do the same thing, one of them should be at a different level of abstraction than the other. E.g. it's okay that &lt;code&gt;= Introduction&lt;/code&gt; and &lt;code&gt;#heading[Introduction]&lt;/code&gt; do the same thing because the former is just syntax sugar for the latter.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Power through Composability:&lt;/strong&gt; There are two ways to make something flexible: Have a knob for everything or have a few knobs that you can combine in many ways. Typst is designed with the second way in mind. We provide systems that you can compose in ways we've never even thought of. TeX is also in the second category, but it's a bit low-level and therefore people use LaTeX instead. But there, we don't really have that much composability. Instead, there's a package for everything (&lt;code&gt;\usepackage{knob}&lt;/code&gt;).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Performance through Incrementality:&lt;/strong&gt; All Typst language features must accommodate for incremental compilation. Luckily we have &lt;a href="https://github.com/typst/comemo/"&gt;&lt;code&gt;comemo&lt;/code&gt;&lt;/a&gt;, a system for incremental compilation which does most of the hard work in the background.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;We'd like to thank everyone who is supporting Typst's development, be it via &lt;a href="https://github.com/sponsors/typst/"&gt;GitHub sponsors&lt;/a&gt; or elsewhere. In particular, special thanks[^1] go to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://posit.co/blog/posit-and-typst/"&gt;Posit&lt;/a&gt; for financing a full-time compiler engineer&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nlnet.nl/"&gt;NLnet&lt;/a&gt; for supporting work on Typst via multiple grants through the &lt;a href="https://nlnet.nl/core"&gt;NGI Zero Core&lt;/a&gt; fund: 
  &lt;ul&gt; 
   &lt;li&gt;Work on &lt;a href="https://nlnet.nl/project/Typst-HTML/"&gt;HTML export&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Work on &lt;a href="https://nlnet.nl/project/Typst-Accessibility/"&gt;PDF accessibility&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.science-startups.berlin/"&gt;Science &amp;amp; Startups&lt;/a&gt; for having financed Typst development from January through June 2023 via the Berlin Startup Scholarship&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://zerodha.tech/blog/1-5-million-pdfs-in-25-minutes/"&gt;Zerodha&lt;/a&gt; for their generous one-time sponsorship&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;[^1]: This list only includes contributions for our open-source work that exceed or are expected to exceed ‚Ç¨10K.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>witnessmenow/ESP32-Cheap-Yellow-Display</title>
      <link>https://github.com/witnessmenow/ESP32-Cheap-Yellow-Display</link>
      <description>&lt;p&gt;Building a community around a cheap ESP32 Display with a touch screen&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ESP32-Cheap-Yellow-Display&lt;/h1&gt; 
&lt;p&gt;There is an ESP32 with a built in 320 x 240 2.8" LCD display with a touch screen called the "ESP32-2432S028R", since this doesn't roll of the tongue, I propose it should be renamed the "Cheap Yellow Display" or CYD for short. This display is only about $15 delivered so I think it's really good value.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/witnessmenow/ESP32-Cheap-Yellow-Display/assets/1562562/76c3d481-2523-4b6f-881c-2e29f9368cd0" alt="image" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;The CYD has the following features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ESP32 (With Wifi and Bluetooth)&lt;/li&gt; 
 &lt;li&gt;320 x 240 LCD Display (2.8")&lt;/li&gt; 
 &lt;li&gt;Touch Screen (Resistive)&lt;/li&gt; 
 &lt;li&gt;USB for powering and programming&lt;/li&gt; 
 &lt;li&gt;SD Card Slot, LED and some additional pins broken out&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Who is it good for?&lt;/h2&gt; 
&lt;p&gt;I think it's useful for the following types of people:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;People just getting started with working hardware&lt;/strong&gt; - as everything is already connected, there is no soldering or additional components required&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;People who are familiar with working with hardware, but are lazy&lt;/strong&gt; - (like me) Sometimes you just want to build a project without having to assemble any hardware&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;People who aren't really looking to learn anything, but just want to build some cool things&lt;/strong&gt; - More about this later.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What is the purpose of this page?&lt;/h2&gt; 
&lt;p&gt;So this is pretty nice hardware and a cheap price, but the software instructions/support around it is pretty poor. Just a single link to a zip file on a random website.&lt;/p&gt; 
&lt;p&gt;A couple of years ago I released the &lt;a href="https://github.com/witnessmenow/ESP32-Trinity"&gt;ESP32 Trinity&lt;/a&gt;, which is an open source ESP32 board for controlling Matrix panels. I think the main benefit people get out of the work I did on the Trinty is not the hardware, but the documentation, example code and ready to go projects.&lt;/p&gt; 
&lt;p&gt;I'm no longer creating hardware products, but I think it would be interesting if we could create the same kind of community around this display, where people can share examples and projects made for this display.&lt;/p&gt; 
&lt;h2&gt;How do I know if a display is a CYD?&lt;/h2&gt; 
&lt;p&gt;&lt;img src="http://www.plantuml.com/plantuml/png/RP0nJyCm48Nt_8gZNIb3fge3LD2b2q92235UamDRE7PaNuhyxxda7DGgJBs-zxtSE-yJO-IXSzKD6-e8UeVMLyQs1DJrdA6br4JRims-4fW9LiS4bY6JS-47qBTWC052QvEayyCAvA-wS-8vi01F7mS8SVevOxJeUK9zu55QzzP_Nw-exxPmz8tHJzRRsJq4cdo3Pu98oIQsCd4O6WDIbyXF4LN-JNMsYG7UNXyXUAUTLHDfqVeMJWClUfSPrY_OOyPtO_ivUPcfnoMV3iyXJh4cj_MGJd8lEleQkvQKi9TYUT_DvbukXnraIfTQURMT39Nu8kcrXInIwQYO-gCyNwgm6al-ZneTNIRqjLokqS2UV3jqxXS0" alt="CYD decision tree" /&gt;&lt;/p&gt; 
&lt;h2&gt;Where to buy?&lt;/h2&gt; 
&lt;p&gt;Buy from wherever works out cheapest for you:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://s.click.aliexpress.com/e/_DkSpIjB"&gt;Aliexpress*&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://s.click.aliexpress.com/e/_DkcmuCh"&gt;Aliexpress*&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.aliexpress.com/item/1005004502250619.html"&gt;Aliexpress&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.makerfabs.com/sunton-esp32-2-8-inch-tft-with-touch.html"&gt;Makerfabs&lt;/a&gt; - Seems to come with a 16GB SD card. Makerfabs also stock my &lt;a href="https://github.com/witnessmenow/ESP32-Trinity"&gt;ESP32 Trinity&lt;/a&gt; (NOTE there will be import due in the EU from makerfabs)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;* = Affiliate Link&lt;/p&gt; 
&lt;h2&gt;Getting Started With Your CYD&lt;/h2&gt; 
&lt;p&gt;For details on how to get started with your CYD, please check out the &lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/SETUP.md"&gt;Setup and Configuration&lt;/a&gt; page&lt;/p&gt; 
&lt;h2&gt;Code Examples&lt;/h2&gt; 
&lt;h3&gt;The Basics&lt;/h3&gt; 
&lt;p&gt;A collection of examples demonstrating how to use the different features of the CYD, this is a good place to get started. &lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/Examples/Basics"&gt;Check them out here.&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Alternative Display Libraries&lt;/h3&gt; 
&lt;p&gt;The basics examples are based on the TFT_eSPI display library, but the CYD also works with other display libraries too. Here is some example code if you prefer to use an alternative Arduino library. &lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/Examples/AlternativeLibraries"&gt;Check them out here.&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;ESPHome&lt;/h3&gt; 
&lt;p&gt;Some examples for using the CYD in ESPHome. &lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/Examples/ESPHome"&gt;Check them out here.&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Additional Info and Links&lt;/h2&gt; 
&lt;h3&gt;Discord&lt;/h3&gt; 
&lt;p&gt;Join the CYD discussion on &lt;a href="https://discord.gg/nnezpvq"&gt;my Discord channel&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;3DPrinting&lt;/h3&gt; 
&lt;p&gt;Some examples of 3D printed stands and cases. &lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/3dModels"&gt;Check them out here.&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Pin Information&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/PINS.md"&gt;This page&lt;/a&gt; contains information about what pins are used where, and what ones are free to use.&lt;/p&gt; 
&lt;h3&gt;Add-ons&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/ADDONS.md"&gt;This page&lt;/a&gt; contains information about additional hardware add-ons that can add functionality to your CYD&lt;/p&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/TROUBLESHOOTING.md"&gt;This page&lt;/a&gt; contains information about how to troubleshoot your CYD device&lt;/p&gt; 
&lt;h3&gt;Hardware Mods&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/Mods/README.md"&gt;This page&lt;/a&gt; contains information about some hardware mods that can be performed on the CYD to improve or change some of its functionality&lt;/p&gt; 
&lt;h3&gt;Media and Video Mentions&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/MEDIA.md"&gt;This page&lt;/a&gt; lists any times the CYD project was mentioned somewhere!&lt;/p&gt; 
&lt;h2&gt;License Info&lt;/h2&gt; 
&lt;p&gt;This project is licensed as MIT as per the &lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/LICENSE"&gt;license file&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The one exception to this is the &lt;a href="https://raw.githubusercontent.com/witnessmenow/ESP32-Cheap-Yellow-Display/main/OriginalDocumentation/"&gt;OriginalDocumentation&lt;/a&gt; folder, that I do not have the right to license&lt;/p&gt; 
&lt;h2&gt;Other Languages&lt;/h2&gt; 
&lt;p&gt;Some members of the community have ported some of this information to other languages!&lt;/p&gt; 
&lt;p&gt;Please note: I can't gaurantee the accuracy of the translation, how up to date they are or the content on them in general.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/usini/ESP32-Cheap-Yellow-Display-Documentation-FR"&gt;French / Fran√ßaise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/paelzer/ESP32-Cheap-Yellow-Display-Documentation-DE"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you would like to contribure a translation, please name the repo with the language name or code in the repo name and you can link it here.&lt;/p&gt; 
&lt;h2&gt;Help Support what I do!&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/witnessmenow/"&gt;If you enjoy my work, please consider becoming a Github sponsor!&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>oxc-project/oxc</title>
      <link>https://github.com/oxc-project/oxc</link>
      <description>&lt;p&gt;‚öì A collection of JavaScript tools written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img alt="OXC Logo" src="https://cdn.jsdelivr.net/gh/oxc-project/oxc-assets/preview-universal.png" width="700" /&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/oxc-project/oxc/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-blue.svg?sanitize=true" alt="MIT licensed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/oxc-project/oxc/actions/workflows/ci.yml?query=event%3Apush+branch%3Amain"&gt;&lt;img src="https://github.com/oxc-project/oxc/actions/workflows/ci.yml/badge.svg?event=push&amp;amp;branch=main" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/oxc-project/oxc"&gt;&lt;img src="https://codecov.io/gh/oxc-project/oxc/graph/badge.svg?token=FVHEH0BQLJ" alt="Code Coverage" /&gt;&lt;/a&gt; &lt;a href="https://codspeed.io/oxc-project/oxc"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://codspeed.io/badge.json" alt="CodSpeed Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/Boshen"&gt;&lt;img src="https://img.shields.io/github/sponsors/Boshen" alt="Sponsors" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/9uXCAwqQZW"&gt;&lt;img src="https://img.shields.io/discord/1079625926024900739?logo=discord&amp;amp;label=Discord" alt="Discord chat" /&gt;&lt;/a&gt; &lt;a href="https://playground.oxc.rs/"&gt;&lt;img src="https://img.shields.io/badge/Playground-blue?color=9BE4E0" alt="Playground" /&gt;&lt;/a&gt; &lt;a href="https://oxc.rs"&gt;&lt;img src="https://img.shields.io/badge/Website-blue" alt="Website" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚öì Oxc&lt;/h2&gt; 
&lt;p&gt;&lt;em&gt;/o ä …õks siÀê/&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;The Oxidation Compiler is a collection of high-performance tools for JavaScript and TypeScript written in Rust.&lt;/p&gt; 
&lt;p&gt;Oxc is part of &lt;a href="https://voidzero.dev/"&gt;VoidZero&lt;/a&gt;'s vision for a unified, high-performance toolchain for JavaScript. It powers &lt;a href="https://rolldown.rs"&gt;Rolldown&lt;/a&gt; (&lt;a href="https://vitejs.dev/"&gt;Vite&lt;/a&gt;'s future bundler) and enables the next generation of ultra-fast development tools that work seamlessly together.&lt;/p&gt; 
&lt;p&gt;For more information, check out our website at &lt;a href="https://oxc.rs"&gt;oxc.rs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;sub&gt;* Oxidation is the chemical process that creates rust&lt;/sub&gt;&lt;/p&gt; 
&lt;h2&gt;üèóÔ∏è Design Principles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt;: Through rigorous performance engineering.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Correctness&lt;/strong&gt;: Through conformance testing to standards and similar projects.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Developer Experience&lt;/strong&gt;: Clear APIs, comprehensive documentation, and sensible configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modular composability&lt;/strong&gt;: Use individual components independently or compose them into complete toolchains.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more about our &lt;a href="https://oxc.rs/docs/learn/architecture/parser.html"&gt;architecture&lt;/a&gt; and &lt;a href="https://oxc.rs/docs/learn/performance"&gt;performance philosophy&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üì¶ Tools &amp;amp; Packages&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Tool&lt;/th&gt; 
   &lt;th&gt;npm&lt;/th&gt; 
   &lt;th&gt;crates.io&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/oxlint"&gt;oxlint&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Formatter&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/oxfmt"&gt;oxfmt&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Parser&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/oxc-parser"&gt;oxc-parser&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://crates.io/crates/oxc_parser"&gt;oxc_parser&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Transformer&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/oxc-transform"&gt;oxc-transform&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://crates.io/crates/oxc_transformer"&gt;oxc_transformer&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Minifier&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/oxc-minify"&gt;oxc-minify&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://crates.io/crates/oxc_minifier"&gt;oxc_minifier&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Resolver&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/oxc-resolver"&gt;oxc-resolver&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://crates.io/crates/oxc_resolver"&gt;oxc_resolver&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;See &lt;a href="https://oxc.rs/"&gt;documentation&lt;/a&gt; for detailed usage guides for each tool.&lt;/p&gt; 
&lt;h2&gt;‚ö°Ô∏è Quick Start&lt;/h2&gt; 
&lt;h3&gt;Linter&lt;/h3&gt; 
&lt;p&gt;The production-ready linter catches mistakes for you with sensible defaults and optional configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx oxlint@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To give you an idea of its capabilities, here is an example from the &lt;a href="https://github.com/microsoft/vscode"&gt;vscode&lt;/a&gt; repository, which finishes linting 4800+ files in 0.7 seconds:&lt;/p&gt; 
&lt;p float="left" align="left"&gt; &lt;img src="https://cdn.jsdelivr.net/gh/oxc-project/oxc-assets/linter-screenshot.png" width="60%" /&gt; &lt;/p&gt; 
&lt;p&gt;‚Üí &lt;a href="https://oxc.rs/docs/guide/usage/linter/cli.html"&gt;oxlint documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Formatter&lt;/h3&gt; 
&lt;p&gt;Fast, opinionated code formatter compatible with &lt;a href="https://prettier.io/"&gt;Prettier&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx oxfmt@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí &lt;a href="https://oxc.rs/docs/guide/usage/formatter"&gt;Formatter documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Parser (Node.js)&lt;/h3&gt; 
&lt;p&gt;The fastest JavaScript/TypeScript parser written in Rust:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install oxc-parser
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;import { parseSync } from 'oxc-parser';
const result = parseSync('const x = 1;');
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí &lt;a href="https://oxc.rs/docs/guide/usage/parser"&gt;Parser documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Transformer (Node.js)&lt;/h3&gt; 
&lt;p&gt;TypeScript, React, and modern JavaScript transformation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install oxc-transform
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;import { transform } from 'oxc-transform';
const result = transform('source.tsx', code, { typescript: true });
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí &lt;a href="https://oxc.rs/docs/guide/usage/transformer"&gt;Transformer documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Minifier (Node.js)&lt;/h3&gt; 
&lt;p&gt;High-performance JavaScript minifier:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install oxc-minify
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-js"&gt;import { minify } from 'oxc-minify';
const result = minify(code, { mangle: true });
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí &lt;a href="https://oxc.rs/docs/guide/usage/minifier"&gt;Minifier documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Rust&lt;/h3&gt; 
&lt;p&gt;Individual crates are published for building your own JavaScript tools:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[dependencies]
oxc = "0.x"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;‚Üí &lt;a href="https://docs.rs/oxc"&gt;Rust documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;VoidZero Inc.&lt;/h2&gt; 
&lt;p&gt;Oxc is a project of &lt;a href="https://voidzero.dev/"&gt;VoidZero&lt;/a&gt;, see our announcement &lt;a href="https://voidzero.dev/blog"&gt;Announcing VoidZero - Next Generation Toolchain for JavaScript&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have requirements for JavaScript tools at scale, please &lt;a href="https://forms.gle/WQgjyzYJpwurpxWKA"&gt;get in touch&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;üôã Who's using Oxc?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://rolldown.rs"&gt;Rolldown&lt;/a&gt; and &lt;a href="https://nuxt.com/"&gt;Nuxt&lt;/a&gt; use Oxc for parsing. &lt;a href="https://rolldown.rs"&gt;Rolldown&lt;/a&gt; also uses Oxc for transformation and minification. &lt;a href="https://trynova.dev/"&gt;Nova&lt;/a&gt;, &lt;a href="https://github.com/swc-project/swc-node"&gt;swc-node&lt;/a&gt;, and &lt;a href="https://github.com/webpro/knip"&gt;knip&lt;/a&gt; use &lt;a href="https://docs.rs/oxc_resolver"&gt;oxc_resolver&lt;/a&gt; for module resolution. &lt;a href="https://preactjs.com/"&gt;Preact&lt;/a&gt;, &lt;a href="https://shopify.com/"&gt;Shopify&lt;/a&gt;, &lt;a href="https://www.bytedance.com/"&gt;ByteDance&lt;/a&gt;, and &lt;a href="https://shopee.com/"&gt;Shopee&lt;/a&gt; use oxlint for linting.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://oxc.rs/docs/guide/projects.html"&gt;See more projects using Oxc ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;‚úçÔ∏è Contribute&lt;/h2&gt; 
&lt;p&gt;Check out some of the &lt;a href="https://github.com/oxc-project/oxc/contribute"&gt;good first issues&lt;/a&gt; or ask us on &lt;a href="https://discord.gg/9uXCAwqQZW"&gt;Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/oxc-project/oxc/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidance, or read the complete &lt;a href="https://oxc.rs/docs/contribute/introduction.html"&gt;contributing guide on our website ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you are unable to contribute by code, you can still participate by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add a &lt;a href="https://github.com/oxc-project/oxc/stargazers"&gt;GitHub Star&lt;/a&gt; to the project&lt;/li&gt; 
 &lt;li&gt;Join us on &lt;a href="https://discord.gg/9uXCAwqQZW"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/boshen_c"&gt;Follow me on X&lt;/a&gt; and post about this project&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Credits&lt;/h2&gt; 
&lt;p&gt;This project was incubated with the assistance of these exceptional mentors and their projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://biomejs.dev/"&gt;Biome&lt;/a&gt; - &lt;a href="https://github.com/ematipico"&gt;@ematipico&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://beta.ruff.rs"&gt;Ruff&lt;/a&gt; - &lt;a href="https://github.com/charliermarsh"&gt;@charliermarsh&lt;/a&gt;, &lt;a href="https://github.com/MichaReiser"&gt;@MichaReiser&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/quick-lint/quick-lint-js"&gt;quick-lint-js&lt;/a&gt; - &lt;a href="https://github.com/strager"&gt;@strager&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://package.elm-lang.org/packages/jfmengels/elm-review/latest"&gt;elm-review&lt;/a&gt; - &lt;a href="https://github.com/jfmengels"&gt;@jfmengels&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Special thanks go to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/domonji"&gt;@domonji&lt;/a&gt; for bootstrapping this project together and also completing the TypeScript parser&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tongtong-lu"&gt;@tongtong-lu&lt;/a&gt; and &lt;a href="https://github.com/guan-wy"&gt;@guan-wy&lt;/a&gt; for designing the &lt;a href="https://github.com/oxc-project/oxc-assets"&gt;project logo&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚ù§ Who's &lt;a href="https://github.com/sponsors/Boshen"&gt;Sponsoring Oxc&lt;/a&gt;?&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/sponsors/Boshen"&gt; &lt;img src="https://raw.githubusercontent.com/Boshen/sponsors/main/sponsors.svg?sanitize=true" alt="My sponsors" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;üìñ License&lt;/h2&gt; 
&lt;p&gt;Oxc is free and open-source software licensed under the &lt;a href="https://raw.githubusercontent.com/oxc-project/oxc/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Oxc ports or copies code from other open source projects, their licenses are listed in &lt;a href="https://raw.githubusercontent.com/oxc-project/oxc/main/THIRD-PARTY-LICENSE"&gt;&lt;strong&gt;Third-party library licenses&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>stalwartlabs/stalwart</title>
      <link>https://github.com/stalwartlabs/stalwart</link>
      <description>&lt;p&gt;All-in-one Mail &amp; Collaboration server. Secure, scalable and fluent in every protocol (IMAP, JMAP, SMTP, CalDAV, CardDAV, WebDAV).&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://stalw.art"&gt; &lt;img src="https://raw.githubusercontent.com/stalwartlabs/stalwart/main/img/logo-red.svg?sanitize=true" height="150" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; Secure, scalable mail &amp;amp; collaboration server with comprehensive protocol support üõ°Ô∏è &lt;br /&gt;(IMAP, JMAP, SMTP, CalDAV, CardDAV, WebDAV) &lt;/h3&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/stalwartlabs/stalwart/actions/workflows/ci.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/stalwartlabs/stalwart/ci.yml?style=flat-square" alt="continuous integration" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.gnu.org/licenses/agpl-3.0"&gt;&lt;img src="https://img.shields.io/badge/License-AGPL_v3-blue.svg?label=license&amp;amp;style=flat-square" alt="License: AGPL v3" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://stalw.art/docs/install/get-started"&gt;&lt;img src="https://img.shields.io/badge/read_the-docs-red?style=flat-square" alt="Documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://mastodon.social/@stalwartlabs"&gt;&lt;img src="https://img.shields.io/mastodon/follow/109929667531941122?style=flat-square&amp;amp;logo=mastodon&amp;amp;color=%236364ff&amp;amp;label=Follow%20on%20Mastodon" alt="Mastodon" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://twitter.com/stalwartlabs"&gt;&lt;img src="https://img.shields.io/twitter/follow/stalwartlabs?style=flat-square&amp;amp;logo=x&amp;amp;label=Follow%20on%20Twitter" alt="Twitter" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.com/servers/stalwart-923615863037390889"&gt;&lt;img src="https://img.shields.io/discord/923615863037390889?label=Join%20Discord&amp;amp;logo=discord&amp;amp;style=flat-square" alt="Discord" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.reddit.com/r/stalwartlabs/"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/stalwartlabs?label=Join%20%2Fr%2Fstalwartlabs&amp;amp;logo=reddit&amp;amp;style=flat-square" alt="Reddit" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Stalwart&lt;/strong&gt; is an open-source mail &amp;amp; collaboration server with JMAP, IMAP4, POP3, SMTP, CalDAV, CardDAV and WebDAV support and a wide range of modern features. It is written in Rust and designed to be secure, fast, robust and scalable.&lt;/p&gt; 
&lt;p&gt;Key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Email&lt;/strong&gt; server with complete protocol support: 
  &lt;ul&gt; 
   &lt;li&gt;JMAP: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc8621"&gt;JMAP for Mail&lt;/a&gt; server.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.ietf.org/archive/id/draft-ietf-jmap-sieve-22.html"&gt;JMAP for Sieve Scripts&lt;/a&gt;.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc8887"&gt;WebSocket&lt;/a&gt;, &lt;a href="https://www.rfc-editor.org/rfc/rfc9404.html"&gt;Blob Management&lt;/a&gt; and &lt;a href="https://www.rfc-editor.org/rfc/rfc9425.html"&gt;Quotas&lt;/a&gt; extensions.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;IMAP: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc9051"&gt;IMAP4rev2&lt;/a&gt; and &lt;a href="https://datatracker.ietf.org/doc/html/rfc3501"&gt;IMAP4rev1&lt;/a&gt; server.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc5804"&gt;ManageSieve&lt;/a&gt; server.&lt;/li&gt; 
     &lt;li&gt;Numerous &lt;a href="https://stalw.art/docs/development/rfcs#imap4-and-extensions"&gt;extensions&lt;/a&gt; supported.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;POP3: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc1939"&gt;POP3&lt;/a&gt; server.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc2595"&gt;STLS&lt;/a&gt; and &lt;a href="https://datatracker.ietf.org/doc/html/rfc5034"&gt;SASL&lt;/a&gt; support as well as other &lt;a href="https://datatracker.ietf.org/doc/html/rfc2449"&gt;extensions&lt;/a&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;SMTP: 
    &lt;ul&gt; 
     &lt;li&gt;SMTP server with built-in &lt;a href="https://datatracker.ietf.org/doc/html/rfc7489"&gt;DMARC&lt;/a&gt;, &lt;a href="https://datatracker.ietf.org/doc/html/rfc6376"&gt;DKIM&lt;/a&gt;, &lt;a href="https://datatracker.ietf.org/doc/html/rfc7208"&gt;SPF&lt;/a&gt; and &lt;a href="https://datatracker.ietf.org/doc/html/rfc8617"&gt;ARC&lt;/a&gt; support for message authentication.&lt;/li&gt; 
     &lt;li&gt;Strong transport security through &lt;a href="https://datatracker.ietf.org/doc/html/rfc6698"&gt;DANE&lt;/a&gt;, &lt;a href="https://datatracker.ietf.org/doc/html/rfc8461"&gt;MTA-STS&lt;/a&gt; and &lt;a href="https://datatracker.ietf.org/doc/html/rfc8460"&gt;SMTP TLS&lt;/a&gt; reporting.&lt;/li&gt; 
     &lt;li&gt;Inbound throttling and filtering with granular configuration rules, sieve scripting, MTA hooks and milter integration.&lt;/li&gt; 
     &lt;li&gt;Distributed virtual queues with delayed delivery, priority delivery, quotas, routing rules and throttling support.&lt;/li&gt; 
     &lt;li&gt;Envelope rewriting and message modification.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Collaboration&lt;/strong&gt; server: 
  &lt;ul&gt; 
   &lt;li&gt;Calendaring and scheduling: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc4791"&gt;CalDAV&lt;/a&gt; and &lt;a href="https://datatracker.ietf.org/doc/html/rfc6638"&gt;CalDAV Scheduling&lt;/a&gt; support.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/draft-ietf-jmap-calendars-24"&gt;JMAP for Calendars&lt;/a&gt; support.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Contact management: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc6352"&gt;CardDAV&lt;/a&gt; support.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc9610"&gt;JMAP for Contacts&lt;/a&gt; support.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;File storage: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc4918"&gt;WebDAV&lt;/a&gt; support.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/draft-ietf-jmap-filenode-03"&gt;JMAP for File Storage&lt;/a&gt; support.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Sharing with fine-grained access controls: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc3744"&gt;WebDAV ACL&lt;/a&gt; support.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc9670"&gt;JMAP Sharing&lt;/a&gt; support.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Spam&lt;/strong&gt; and &lt;strong&gt;Phishing&lt;/strong&gt; built-in filter: 
  &lt;ul&gt; 
   &lt;li&gt;Comprehensive set of filtering &lt;strong&gt;rules&lt;/strong&gt; on par with popular solutions.&lt;/li&gt; 
   &lt;li&gt;LLM-driven spam filtering and message analysis.&lt;/li&gt; 
   &lt;li&gt;Statistical &lt;strong&gt;spam classifier&lt;/strong&gt; with automatic training capabilities and address book integration.&lt;/li&gt; 
   &lt;li&gt;DNS Blocklists (&lt;strong&gt;DNSBLs&lt;/strong&gt;) checking of IP addresses, domains, and hashes.&lt;/li&gt; 
   &lt;li&gt;Collaborative digest-based spam filtering with &lt;strong&gt;Pyzor&lt;/strong&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Phishing&lt;/strong&gt; protection against homographic URL attacks, sender spoofing and other techniques.&lt;/li&gt; 
   &lt;li&gt;Trusted &lt;strong&gt;reply&lt;/strong&gt; tracking to recognize and prioritize genuine e-mail replies.&lt;/li&gt; 
   &lt;li&gt;Sender &lt;strong&gt;reputation&lt;/strong&gt; monitoring by IP address, ASN, domain and email address.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Greylisting&lt;/strong&gt; to temporarily defer unknown senders.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Spam traps&lt;/strong&gt; to set up decoy email addresses that catch and analyze spam.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Pluggable storage backends with &lt;strong&gt;RocksDB&lt;/strong&gt;, &lt;strong&gt;FoundationDB&lt;/strong&gt;, &lt;strong&gt;PostgreSQL&lt;/strong&gt;, &lt;strong&gt;mySQL&lt;/strong&gt;, &lt;strong&gt;SQLite&lt;/strong&gt;, &lt;strong&gt;S3-Compatible&lt;/strong&gt;, &lt;strong&gt;Azure&lt;/strong&gt;, &lt;strong&gt;Redis&lt;/strong&gt; and &lt;strong&gt;ElasticSearch&lt;/strong&gt; support.&lt;/li&gt; 
   &lt;li&gt;Full-text search available in 17 languages.&lt;/li&gt; 
   &lt;li&gt;Sieve scripting language with support for all &lt;a href="https://www.iana.org/assignments/sieve-extensions/sieve-extensions.xhtml"&gt;registered extensions&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Email aliases, mailing lists, subaddressing and catch-all addresses support.&lt;/li&gt; 
   &lt;li&gt;Automatic account configuration and discovery with &lt;a href="https://www.ietf.org/id/draft-bucksch-autoconfig-02.html"&gt;autoconfig&lt;/a&gt; and &lt;a href="https://learn.microsoft.com/en-us/exchange/architecture/client-access/autodiscover?view=exchserver-2019"&gt;autodiscover&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Multi-tenancy support with domain and tenant isolation.&lt;/li&gt; 
   &lt;li&gt;Disk quotas per user and tenant.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Secure and robust&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Encryption at rest with &lt;strong&gt;S/MIME&lt;/strong&gt; or &lt;strong&gt;OpenPGP&lt;/strong&gt;.&lt;/li&gt; 
   &lt;li&gt;Automatic TLS certificate provisioning with &lt;a href="https://datatracker.ietf.org/doc/html/rfc8555"&gt;ACME&lt;/a&gt; using &lt;code&gt;TLS-ALPN-01&lt;/code&gt;, &lt;code&gt;DNS-01&lt;/code&gt; or &lt;code&gt;HTTP-01&lt;/code&gt; challenges.&lt;/li&gt; 
   &lt;li&gt;Automated blocking of IP addresses that attack, abuse or scan the server for exploits.&lt;/li&gt; 
   &lt;li&gt;Rate limiting.&lt;/li&gt; 
   &lt;li&gt;Security audited (read the &lt;a href="https://stalw.art/blog/security-audit"&gt;report&lt;/a&gt;).&lt;/li&gt; 
   &lt;li&gt;Memory safe (thanks to Rust).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable and fault-tolerant&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Designed to handle growth seamlessly, from small setups to large-scale deployments of thousands of nodes.&lt;/li&gt; 
   &lt;li&gt;Built with &lt;strong&gt;fault tolerance&lt;/strong&gt; and &lt;strong&gt;high availability&lt;/strong&gt; in mind, recovers from hardware or software failures with minimal operational impact.&lt;/li&gt; 
   &lt;li&gt;Peer-to-peer cluster coordination or with &lt;strong&gt;Kafka&lt;/strong&gt;, &lt;strong&gt;Redpanda&lt;/strong&gt;, &lt;strong&gt;NATS&lt;/strong&gt; or &lt;strong&gt;Redis&lt;/strong&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;, &lt;strong&gt;Apache Mesos&lt;/strong&gt; and &lt;strong&gt;Docker Swarm&lt;/strong&gt; support for automated scaling and container orchestration.&lt;/li&gt; 
   &lt;li&gt;Read replicas, sharded blob storage and in-memory data stores for high performance and low latency.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication and Authorization&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;OpenID Connect&lt;/strong&gt; authentication.&lt;/li&gt; 
   &lt;li&gt;OAuth 2.0 authorization with &lt;a href="https://www.rfc-editor.org/rfc/rfc8628"&gt;authorization code&lt;/a&gt; and &lt;a href="https://www.rfc-editor.org/rfc/rfc8628"&gt;device authorization&lt;/a&gt; flows.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;LDAP&lt;/strong&gt;, &lt;strong&gt;OIDC&lt;/strong&gt;, &lt;strong&gt;SQL&lt;/strong&gt; or built-in authentication backend support.&lt;/li&gt; 
   &lt;li&gt;Two-factor authentication with Time-based One-Time Passwords (&lt;code&gt;2FA-TOTP&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Application passwords (App Passwords).&lt;/li&gt; 
   &lt;li&gt;Roles and permissions.&lt;/li&gt; 
   &lt;li&gt;Access Control Lists (ACLs).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Logging and tracing with &lt;strong&gt;OpenTelemetry&lt;/strong&gt;, journald, log files and console support.&lt;/li&gt; 
   &lt;li&gt;Metrics with &lt;strong&gt;OpenTelemetry&lt;/strong&gt; and &lt;strong&gt;Prometheus&lt;/strong&gt; integration.&lt;/li&gt; 
   &lt;li&gt;Webhooks for event-driven automation.&lt;/li&gt; 
   &lt;li&gt;Alerts with email and webhook notifications.&lt;/li&gt; 
   &lt;li&gt;Live tracing and metrics.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web-based administration&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Dashboard with real-time statistics and monitoring.&lt;/li&gt; 
   &lt;li&gt;Account, domain, group and mailing list management.&lt;/li&gt; 
   &lt;li&gt;SMTP queue management for messages and outbound DMARC and TLS reports.&lt;/li&gt; 
   &lt;li&gt;Report visualization interface for received DMARC, TLS-RPT and Failure (ARF) reports.&lt;/li&gt; 
   &lt;li&gt;Configuration of every aspect of the mail server.&lt;/li&gt; 
   &lt;li&gt;Log viewer with search and filtering capabilities.&lt;/li&gt; 
   &lt;li&gt;Self-service portal for password reset and encryption-at-rest key management.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;img src="https://raw.githubusercontent.com/stalwartlabs/stalwart/main/img/screencast-setup.gif" /&gt; 
&lt;h2&gt;Presentation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Want a deeper dive?&lt;/strong&gt; Need to explain to your boss why Stalwart is the perfect fit? Whether you're evaluating options, making a case to your team, or simply curious about how it all works under the hood, these slides walk you through the key features, architecture, and benefits of Stalwart. Browse the &lt;a href="https://stalw.art/slides"&gt;slides&lt;/a&gt; to see what makes it stand out.&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;Install Stalwart on your server by following the instructions for your platform:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://stalw.art/docs/install/platform/linux"&gt;Linux / MacOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://stalw.art/docs/install/platform/windows"&gt;Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://stalw.art/docs/install/platform/docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All documentation is available at &lt;a href="https://stalw.art/docs/install/get-started"&gt;stalw.art/docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;If you are having problems running Stalwart, you found a bug or just have a question, do not hesitate to reach us on &lt;a href="https://github.com/stalwartlabs/stalwart/discussions"&gt;GitHub Discussions&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/stalwartlabs"&gt;Reddit&lt;/a&gt; or &lt;a href="https://discord.com/servers/stalwart-923615863037390889"&gt;Discord&lt;/a&gt;. Additionally you may purchase an &lt;a href="https://stalw.art/enterprise"&gt;Enterprise License&lt;/a&gt; to obtain priority support from Stalwart Labs LLC.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Stalwart has reached an exciting point in its journey, it‚Äôs now &lt;strong&gt;feature complete&lt;/strong&gt;. All the core functionality and open standard email and collaboration protocols that we set out to support are in place. In other words, Stalwart already does everything you‚Äôd expect from a modern, standards-compliant mail and collaboration platform.&lt;/p&gt; 
&lt;p&gt;The next major milestone is all about refinement: finalizing the database schema and focusing on performance optimizations to ensure everything runs as efficiently and reliably as possible. Once that‚Äôs done, we‚Äôll be ready to roll out version &lt;strong&gt;1.0&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Of course, development doesn‚Äôt stop there. The community has contributed hundreds of great ideas for improvements and new features, everything from subtle usability tweaks to entirely new integrations. You can see the full list of proposals over on our &lt;a href="https://github.com/stalwartlabs/stalwart/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3Aenhancement"&gt;GitHub issues&lt;/a&gt;. If there‚Äôs something you‚Äôd like to see prioritized, just give it a thumbs up as we plan to implement enhancements based on the community‚Äôs votes.&lt;/p&gt; 
&lt;h2&gt;Sponsorship&lt;/h2&gt; 
&lt;p&gt;Your support is crucial in helping us continue to improve the project, add new features, and maintain the highest level of quality. By &lt;a href="https://opencollective.com/stalwart"&gt;becoming a sponsor&lt;/a&gt;, you help fund the development and future of Stalwart. As a thank-you, sponsors who contribute $5 per month or more will automatically receive a &lt;a href="https://stalw.art/enterprise/"&gt;Enterprise edition&lt;/a&gt; license. And, sponsors who contribute $30 per month or more, also have access to &lt;a href="https://stalw.art/support"&gt;Premium Support&lt;/a&gt; from Stalwart Labs.&lt;/p&gt; 
&lt;p&gt;These are some of our open-source sponsors:&lt;/p&gt; 
&lt;!-- sponsors --&gt;
&lt;a href="https://github.com/kbjr"&gt;&lt;img src="https://github.com/kbjr.png" width="60px" alt="User avatar: James Brumond" /&gt;&lt;/a&gt;
&lt;a href="https://github.com/MailRoute"&gt;&lt;img src="https://github.com/MailRoute.png" width="60px" alt="User avatar: MailRoute, Inc." /&gt;&lt;/a&gt;
&lt;a href="https://github.com/starsong-consulting"&gt;&lt;img src="https://github.com/starsong-consulting.png" width="60px" alt="User avatar: Starsong GmbH" /&gt;&lt;/a&gt;
&lt;a href="https://github.com/mingfu-design"&gt;&lt;img src="https://github.com/mingfu-design.png" width="60px" alt="User avatar: Ming Fu Design Ltd. ÊòéÂ≠öË®≠Ë®àÊúâÈôêÂÖ¨Âè∏" /&gt;&lt;/a&gt;
&lt;a href="https://github.com/tamwuff"&gt;&lt;img src="https://github.com/tamwuff.png" width="60px" alt="User avatar: Tamino" /&gt;&lt;/a&gt;
&lt;a href="https://github.com/panascais"&gt;&lt;img src="https://github.com/panascais.png" width="60px" alt="User avatar: panascais" /&gt;&lt;/a&gt;
&lt;a href="https://github.com/JanAxelJonsson"&gt;&lt;img src="https://github.com/JanAxelJonsson.png" width="60px" alt="User avatar: Jan Jonsson" /&gt;&lt;/a&gt;
&lt;!-- sponsors --&gt; 
&lt;p&gt;&lt;br /&gt;If you would like to support our work, please consider &lt;a href="https://opencollective.com/stalwart"&gt;becoming a sponsor&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Funding&lt;/h2&gt; 
&lt;p&gt;Part of the development of this project was funded through:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://nlnet.nl/entrust"&gt;NGI0 Entrust Fund&lt;/a&gt;, a fund established by &lt;a href="https://nlnet.nl/"&gt;NLnet&lt;/a&gt; with financial support from the European Commission's &lt;a href="https://ngi.eu/"&gt;Next Generation Internet&lt;/a&gt; programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No 101069594.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nlnet.nl/NGI0/"&gt;NGI Zero Core&lt;/a&gt;, a fund established by &lt;a href="https://nlnet.nl/"&gt;NLnet&lt;/a&gt; with financial support from the European Commission's programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No 101092990.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you find the project useful you can help by &lt;a href="https://opencollective.com/stalwart"&gt;becoming a sponsor&lt;/a&gt;. Thank you!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is dual-licensed under the &lt;strong&gt;GNU Affero General Public License v3.0&lt;/strong&gt; (AGPL-3.0; as published by the Free Software Foundation) and the &lt;strong&gt;Stalwart Enterprise License v1 (SELv1)&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://raw.githubusercontent.com/stalwartlabs/stalwart/main/LICENSES/AGPL-3.0-only.txt"&gt;GNU Affero General Public License v3.0&lt;/a&gt; is a free software license that ensures your freedom to use, modify, and distribute the software, with the condition that any modified versions of the software must also be distributed under the same license.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://raw.githubusercontent.com/stalwartlabs/stalwart/main/LICENSES/LicenseRef-SEL.txt"&gt;Stalwart Enterprise License v1 (SELv1)&lt;/a&gt; is a proprietary license designed for commercial use. It offers additional features and greater flexibility for businesses that do not wish to comply with the AGPL-3.0 license requirements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each file in this project contains a license notice at the top, indicating the applicable license(s). The license notice follows the &lt;a href="https://reuse.software/"&gt;REUSE guidelines&lt;/a&gt; to ensure clarity and consistency. The full text of each license is available in the &lt;a href="https://raw.githubusercontent.com/stalwartlabs/stalwart/main/LICENSES/"&gt;LICENSES&lt;/a&gt; directory.&lt;/p&gt; 
&lt;h2&gt;Copyright&lt;/h2&gt; 
&lt;p&gt;Copyright (C) 2020, Stalwart Labs LLC&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>topjohnwu/Magisk</title>
      <link>https://github.com/topjohnwu/Magisk</link>
      <description>&lt;p&gt;The Magic Mask for Android&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/topjohnwu/Magisk/master/docs/images/logo.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/topjohnwu/magisk-files/count/count.json"&gt;&lt;img src="https://img.shields.io/badge/dynamic/json?color=green&amp;amp;label=Downloads&amp;amp;query=totalString&amp;amp;url=https%3A%2F%2Fraw.githubusercontent.com%2Ftopjohnwu%2Fmagisk-files%2Fcount%2Fcount.json&amp;amp;cacheSeconds=1800" alt="Downloads" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;This is not an officially supported Google product&lt;/h4&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Magisk is a suite of open source software for customizing Android, supporting devices higher than Android 6.0.&lt;br /&gt; Some highlight features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MagiskSU&lt;/strong&gt;: Provide root access for applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Magisk Modules&lt;/strong&gt;: Modify read-only partitions by installing modules&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MagiskBoot&lt;/strong&gt;: The most complete tool for unpacking and repacking Android boot images&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zygisk&lt;/strong&gt;: Run code in every Android applications' processes&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Downloads&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/topjohnwu/Magisk/releases"&gt;Github&lt;/a&gt; is the only source where you can get official Magisk information and downloads.&lt;/p&gt; 
&lt;h2&gt;Useful Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://topjohnwu.github.io/Magisk/install.html"&gt;Installation Instruction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://topjohnwu.github.io/Magisk/build.html"&gt;Building and Development&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://topjohnwu.github.io/Magisk/"&gt;Magisk Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/topjohnwu/zygisk-module-sample"&gt;Zygisk module sample&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Bug Reports&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Only bug reports from Debug builds will be accepted.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;For installation issues, upload both boot image and install logs.&lt;br /&gt; For Magisk issues, upload boot logcat or dmesg.&lt;br /&gt; For Magisk app crashes, record and upload the logcat when the crash occurs.&lt;/p&gt; 
&lt;h2&gt;Translation Contributions&lt;/h2&gt; 
&lt;p&gt;Default string resources for the Magisk app and its stub APK are located here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;app/core/src/main/res/values/strings.xml&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;app/stub/src/main/res/values/strings.xml&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Translate each and place them in the respective locations (&lt;code&gt;[module]/src/main/res/values-[lang]/strings.xml&lt;/code&gt;).&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Magisk, including all git submodules are free software:
you can redistribute it and/or modify it under the terms of the
GNU General Public License as published by the Free Software Foundation,
either version 3 of the License, or (at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see &amp;lt;http://www.gnu.org/licenses/&amp;gt;.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>tensorzero/tensorzero</title>
      <link>https://github.com/tensorzero/tensorzero</link>
      <description>&lt;p&gt;TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;
 &lt;picture&gt;
  &lt;img src="https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9" alt="TensorZero Logo" width="128" height="128" /&gt;
 &lt;/picture&gt;&lt;/p&gt; 
&lt;h1&gt;TensorZero&lt;/h1&gt; 
&lt;p&gt;
 &lt;picture&gt;
  &lt;img src="https://www.tensorzero.com/github-trending-badge.svg?sanitize=true" alt="#1 Repository Of The Day" /&gt;
 &lt;/picture&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;TensorZero is an open-source stack for &lt;em&gt;industrial-grade LLM applications&lt;/em&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gateway:&lt;/strong&gt; access every LLM provider through a unified API, built for performance (&amp;lt;1ms p99 latency)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability:&lt;/strong&gt; store inferences and feedback in your database, available programmatically or in the UI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimization:&lt;/strong&gt; collect metrics and human feedback to optimize prompts, models, and inference strategies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evaluation:&lt;/strong&gt; benchmark individual inferences or end-to-end workflows using heuristics, LLM judges, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Experimentation:&lt;/strong&gt; ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Take what you need, adopt incrementally, and complement with other tools.&lt;/p&gt; 
&lt;p&gt;
 &lt;video src="https://github.com/user-attachments/assets/04a8466e-27d8-4189-b305-e7cecb6881ee"&gt;&lt;/video&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;b&gt;&lt;a href="https://www.tensorzero.com/" target="_blank"&gt;Website&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs" target="_blank"&gt;Docs&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.x.com/tensorzero" target="_blank"&gt;Twitter&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/slack" target="_blank"&gt;Slack&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/discord" target="_blank"&gt;Discord&lt;/a&gt;&lt;/b&gt; &lt;br /&gt; &lt;br /&gt; &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart" target="_blank"&gt;Quick Start (5min)&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank"&gt;Deployment Guide&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/api-reference" target="_blank"&gt;API Reference&lt;/a&gt;&lt;/b&gt; ¬∑ &lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment" target="_blank"&gt;Configuration Reference&lt;/a&gt;&lt;/b&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;üåê LLM Gateway&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Integrate with TensorZero once and access every major LLM provider.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/call-any-llm"&gt;Call any LLM&lt;/a&gt;&lt;/strong&gt; (API or self-hosted) through a single unified API&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Infer with &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/streaming-inference"&gt;streaming&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/tool-use"&gt;tool use&lt;/a&gt;&lt;/strong&gt;, structured generation, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/batch-inference"&gt;batch&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/generate-embeddings"&gt;embeddings&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/multimodal-inference"&gt;multimodal (images, files)&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-caching"&gt;caching&lt;/a&gt;&lt;/strong&gt;, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/create-a-prompt-template"&gt;Create prompt templates and schemas&lt;/a&gt;&lt;/strong&gt; to enforce a consistent, typed interface between your application and the LLMs&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Satisfy extreme throughput and latency needs, thanks to ü¶Ä Rust: &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/benchmarks"&gt;&amp;lt;1ms p99 latency overhead at 10k+ QPS&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Use any programming language: &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/clients"&gt;integrate via our Python client, any OpenAI SDK, or our HTTP API&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks"&gt;Ensure high availability&lt;/a&gt;&lt;/strong&gt; with routing, retries, fallbacks, load balancing, granular timeouts, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/operations/enforce-custom-rate-limits"&gt;Enforce custom rate limits&lt;/a&gt;&lt;/strong&gt; with granular scopes (e.g. user-defined tags) to keep usage under control&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/operations/set-up-auth-for-tensorzero"&gt;Set up auth for TensorZero&lt;/a&gt;&lt;/strong&gt; to allow clients to access models without sharing provider API keys&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: spend tracking and budgeting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;strong&gt;Supported Model Providers:&lt;/strong&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/anthropic"&gt;Anthropic&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock"&gt;AWS Bedrock&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker"&gt;AWS SageMaker&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/azure"&gt;Azure OpenAI Service&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/deepseek"&gt;DeepSeek&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/fireworks"&gt;Fireworks&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic"&gt;GCP Vertex AI Anthropic&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini"&gt;GCP Vertex AI Gemini&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini"&gt;Google AI Studio (Gemini API)&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/groq"&gt;Groq&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic"&gt;Hyperbolic&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/mistral"&gt;Mistral&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai"&gt;OpenAI&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openrouter"&gt;OpenRouter&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/sglang"&gt;SGLang&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/tgi"&gt;TGI&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/together"&gt;Together AI&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/vllm"&gt;vLLM&lt;/a&gt;&lt;/strong&gt;, and &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/xai"&gt;xAI (Grok)&lt;/a&gt;&lt;/strong&gt;. Need something else? TensorZero also supports &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible"&gt;any OpenAI-compatible API (e.g. Ollama)&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Python ‚Äî TensorZero Client (Recommended)&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the TensorZero Python client.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from tensorzero import TensorZeroGateway  # or AsyncTensorZeroGateway


with TensorZeroGateway.build_embedded(clickhouse_url="...", config_file="...") as client:
    response = client.inference(
        model_name="openai::gpt-4o-mini",
        # Try other providers easily: "anthropic::claude-3-7-sonnet-20250219"
        input={
            "messages": [
                {
                    "role": "user",
                    "content": "Write a haiku about artificial intelligence.",
                }
            ]
        },
    )
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Python ‚Äî OpenAI SDK&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the OpenAI Python SDK with TensorZero.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;code&gt;pip install tensorzero&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from openai import OpenAI  # or AsyncOpenAI
from tensorzero import patch_openai_client

client = OpenAI()

patch_openai_client(
    client,
    clickhouse_url="http://chuser:chpassword@localhost:8123/tensorzero",
    config_file="config/tensorzero.toml",
    async_setup=False,
)

response = client.chat.completions.create(
    model="tensorzero::model_name::openai::gpt-4o-mini",
    # Try other providers easily: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
    messages=[
        {
            "role": "user",
            "content": "Write a haiku about artificial intelligence.",
        }
    ],
)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: JavaScript / TypeScript (Node) ‚Äî OpenAI SDK&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;You can access any provider using the OpenAI Node SDK with TensorZero.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment"&gt;Detailed instructions ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-ts"&gt;import OpenAI from "openai";

const client = new OpenAI({
  baseURL: "http://localhost:3000/openai/v1",
});

const response = await client.chat.completions.create({
  model: "tensorzero::model_name::openai::gpt-4o-mini",
  // Try other providers easily: "tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219"
  messages: [
    {
      role: "user",
      content: "Write a haiku about artificial intelligence.",
    },
  ],
});
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;b&gt;Usage: Other Languages &amp;amp; Platforms ‚Äî HTTP API&lt;/b&gt;&lt;/summary&gt; 
 &lt;p&gt;TensorZero supports virtually any programming language or platform via its HTTP API.&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Deploy &lt;code&gt;tensorzero/gateway&lt;/code&gt; using Docker. &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/deployment"&gt;Detailed instructions ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
  &lt;li&gt;Optional: Set up the TensorZero configuration.&lt;/li&gt; 
  &lt;li&gt;Run inference:&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST "http://localhost:3000/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "openai::gpt-4o-mini",
    "input": {
      "messages": [
        {
          "role": "user",
          "content": "Write a haiku about artificial intelligence."
        }
      ]
    }
  }'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;See &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; for more information.&lt;/p&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h3&gt;üîç LLM Observability&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Zoom in to debug individual API calls, or zoom out to monitor metrics across models and prompts over time ‚Äî all using the open-source TensorZero UI.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Store inferences and &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/metrics-feedback"&gt;feedback (metrics, human edits, etc.)&lt;/a&gt;&lt;/strong&gt; in your own database&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Dive into individual inferences or high-level aggregate patterns using the TensorZero UI or programmatically&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/api-reference/datasets-datapoints"&gt;Build datasets&lt;/a&gt;&lt;/strong&gt; for optimization, evaluation, and other workflows&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Replay historical inferences with new prompts, models, inference strategies, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/operations/export-opentelemetry-traces"&gt;Export OpenTelemetry traces (OTLP)&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/observability/export-prometheus-metrics"&gt;export Prometheus metrics&lt;/a&gt;&lt;/strong&gt; to your favorite application observability tools&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: AI-assisted debugging and root cause analysis; AI-assisted data labeling&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Observability ¬ª UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Observability ¬ª Programmatic&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;
    &lt;video src="https://github.com/user-attachments/assets/a23e4c95-18fa-482c-8423-6078fb4cf285"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td width="50%" align="left" valign="middle"&gt; &lt;pre&gt;&lt;code class="language-python"&gt;t0.experimental_list_inferences(
  function_name="sales_agent",
  variant_name="qwen3-promptv2",
  filters=BooleanMetricFilter(
      metric_name="converted_sale",
      value=True,
  ),
  order_by=[OrderBy(by="timestamp", direction="descending")],
  limit=100_000,
  # ... and more ...
)
&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h3&gt;üìà LLM Optimization&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Send production metrics and human feedback to easily optimize your prompts, models, and inference strategies ‚Äî using the UI or programmatically.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize your models with supervised fine-tuning, RLHF, and other techniques&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize your prompts with automated prompt engineering algorithms like MIPROv2&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize your inference strategy with dynamic in-context learning, chain of thought, best/mixture-of-N sampling, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Enable a feedback loop for your LLMs: a data &amp;amp; learning flywheel turning production data into smarter, faster, and cheaper models&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: synthetic data generation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Model Optimization&lt;/h4&gt; 
&lt;p&gt;Optimize closed-source and open-source models using supervised fine-tuning (SFT) and preference fine-tuning (DPO).&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Supervised Fine-tuning ‚Äî UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Preference Fine-tuning (DPO) ‚Äî Jupyter Notebook&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;
    &lt;video src="https://github.com/user-attachments/assets/82f76be7-5e02-4ada-b503-69dfa209a442"&gt;&lt;/video&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h4&gt;Inference-Time Optimization&lt;/h4&gt; 
&lt;p&gt;Boost performance by dynamically updating your prompts with relevant examples, combining responses from multiple inferences, and more.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling"&gt;Best-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling"&gt;Mixture-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl"&gt;Dynamic In-Context Learning (DICL)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot"&gt;Chain-of-Thought (CoT)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311" height="320" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h4&gt;Prompt Optimization&lt;/h4&gt; 
&lt;p&gt;Optimize your prompts programmatically using research-driven optimization techniques.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling"&gt;MIPROv2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy"&gt;DSPy Integration&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db" alt="MIPROv2 diagram" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt; TensorZero comes with several optimization recipes, but you can also easily create your own. This example shows how to optimize a TensorZero function using an arbitrary tool ‚Äî here, DSPy, a popular library for automated prompt engineering. &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;More coming soon...&lt;/em&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;üìä LLM Evaluation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Compare prompts, models, and inference strategies using evaluations powered by heuristics and LLM judges.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/evaluations/inference-evaluations/tutorial"&gt;Evaluate individual inferences&lt;/a&gt;&lt;/strong&gt; with &lt;em&gt;inference evaluations&lt;/em&gt; powered by heuristics or LLM judges (‚âà unit tests for LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/evaluations/workflow-evaluations/tutorial"&gt;Evaluate end-to-end workflows&lt;/a&gt;&lt;/strong&gt; with &lt;em&gt;workflow evaluations&lt;/em&gt; with complete flexibility (‚âà integration tests for LLMs)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Optimize LLM judges just like any other TensorZero function to align them to human preferences&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Soon: more built-in evaluators; headless evaluations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt;&lt;/tr&gt; 
  &lt;!-- flip highlight order --&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Evaluation ¬ª UI&lt;/b&gt;&lt;/td&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;b&gt;Evaluation ¬ª CLI&lt;/b&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" align="center" valign="middle"&gt;&lt;img src="https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699" /&gt;&lt;/td&gt; 
   &lt;td width="50%" align="left" valign="middle"&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5&lt;/code&gt;&lt;/pre&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100
exact_match: 0.83 ¬± 0.03 (n=100)
semantic_match: 0.98 ¬± 0.01 (n=100)
item_count: 7.15 ¬± 0.39 (n=100)&lt;/code&gt;&lt;/pre&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;üß™ LLM Experimentation&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/experimentation/run-adaptive-ab-tests"&gt;Run adaptive A/B tests&lt;/a&gt;&lt;/strong&gt; to ship with confidence and identify the best prompts and models for your use cases.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Enforce principled experiments in complex workflows, including support for multi-turn LLM systems, sequential testing, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&amp;amp; more!&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Build with an open-source stack well-suited for prototypes but designed from the ground up to support the most complex LLM applications and deployments.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Build simple applications or massive deployments with GitOps-friendly orchestration&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/operations/extend-tensorzero"&gt;Extend TensorZero&lt;/a&gt;&lt;/strong&gt; with built-in escape hatches, programmatic-first usage, direct database access, and more&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Integrate with third-party tools: specialized observability and evaluations, model providers, agent orchestration frameworks, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Iterate quickly by experimenting with prompts interactively using the Playground UI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Frequently Asked Questions&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;What is TensorZero?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How is TensorZero different from other LLM frameworks?&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;TensorZero enables you to optimize complex LLM applications based on production metrics and human feedback.&lt;/li&gt; 
 &lt;li&gt;TensorZero supports the needs of industrial-grade LLM applications: low latency, high throughput, type safety, self-hosted, GitOps, customizability, etc.&lt;/li&gt; 
 &lt;li&gt;TensorZero unifies the entire LLMOps stack, creating compounding benefits. For example, LLM evaluations can be used for fine-tuning models alongside AI judges.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Can I use TensorZero with ___?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Yes. Every major programming language is supported. You can use TensorZero with our Python client, any OpenAI SDK or OpenAI-compatible client, or our HTTP API.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Is TensorZero production-ready?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Yes. Here's a case study: &lt;strong&gt;&lt;a href="https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms"&gt;Automating Code Changelogs at a Large Bank with LLMs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How much does TensorZero cost?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Nothing. TensorZero is 100% self-hosted and open-source. There are no paid features.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Who is building TensorZero?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Our technical team includes a former Rust compiler maintainer, machine learning researchers (Stanford, CMU, Oxford, Columbia) with thousands of citations, and the chief product officer of a decacorn startup. We're backed by the same investors as leading open-source projects (e.g. ClickHouse, CockroachDB) and AI labs (e.g. OpenAI, Anthropic). See our &lt;strong&gt;&lt;a href="https://www.tensorzero.com/blog/tensorzero-raises-7-3m-seed-round-to-build-an-open-source-stack-for-industrial-grade-llm-applications/"&gt;$7.3M seed round announcement&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href="https://venturebeat.com/ai/tensorzero-nabs-7-3m-seed-to-solve-the-messy-world-of-enterprise-llm-development/"&gt;coverage from VentureBeat&lt;/a&gt;&lt;/strong&gt;. We're &lt;strong&gt;&lt;a href="https://www.tensorzero.com/jobs"&gt;hiring in NYC&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How do I get started?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can adopt TensorZero incrementally. Our &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; goes from a vanilla OpenAI wrapper to a production-ready LLM application with observability and fine-tuning in just 5 minutes.&lt;/p&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Watch LLMs get better at data extraction in real-time with TensorZero!&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl"&gt;Dynamic in-context learning (DICL)&lt;/a&gt;&lt;/strong&gt; is a powerful inference-time optimization available out of the box with TensorZero. It enhances LLM performance by automatically incorporating relevant historical examples into the prompt, without the need for model fine-tuning.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb"&gt;https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Start building today.&lt;/strong&gt; The &lt;strong&gt;&lt;a href="https://www.tensorzero.com/docs/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/strong&gt; shows it's easy to set up an LLM application with TensorZero.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Questions?&lt;/strong&gt; Ask us on &lt;strong&gt;&lt;a href="https://www.tensorzero.com/slack"&gt;Slack&lt;/a&gt;&lt;/strong&gt; or &lt;strong&gt;&lt;a href="https://www.tensorzero.com/discord"&gt;Discord&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Using TensorZero at work?&lt;/strong&gt; Email us at &lt;strong&gt;&lt;a href="mailto:hello@tensorzero.com"&gt;hello@tensorzero.com&lt;/a&gt;&lt;/strong&gt; to set up a Slack or Teams channel with your team (free).&lt;/p&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;We are working on a series of &lt;strong&gt;complete runnable examples&lt;/strong&gt; illustrating TensorZero's data &amp;amp; learning flywheel.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner"&gt;Optimizing Data Extraction (NER) with TensorZero&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to use TensorZero to optimize a data extraction pipeline. We demonstrate techniques like fine-tuning and dynamic in-context learning (DICL). In the end, an optimized GPT-4o Mini model outperforms GPT-4o on this task ‚Äî at a fraction of the cost and latency ‚Äî using a small amount of training data.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/"&gt;Agentic RAG ‚Äî Multi-Hop Question Answering with LLMs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to build a multi-hop retrieval agent using TensorZero. The agent iteratively searches Wikipedia to gather information, and decides when it has enough context to answer a complex question.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences"&gt;Writing Haikus to Satisfy a Judge with Hidden Preferences&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example fine-tunes GPT-4o Mini to generate haikus tailored to a specific taste. You'll see TensorZero's "data flywheel in a box" in action: better variants leads to better data, and better data leads to better variants. You'll see progress by fine-tuning the LLM multiple times.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/multimodal-vision-finetuning"&gt;Image Data Extraction ‚Äî Multimodal (Vision) Fine-tuning&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example shows how to fine-tune multimodal models (VLMs) like GPT-4o to improve their performance on vision-language tasks. Specifically, we'll build a system that categorizes document images (screenshots of computer science research papers).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/chess-puzzles/"&gt;Improving LLM Chess Ability with Best-of-N Sampling&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This example showcases how best-of-N sampling can significantly enhance an LLM's chess-playing abilities by selecting the most promising moves from multiple generated options.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy"&gt;Improving Math Reasoning with a Custom Recipe for Automated Prompt Engineering (DSPy)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;TensorZero provides a number of pre-built optimization recipes covering common LLM engineering workflows. But you can also easily create your own recipes and workflows! This example shows how to optimize a TensorZero function using an arbitrary tool ‚Äî here, DSPy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;em&gt;&amp;amp; many more on the way!&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Blog Posts&lt;/h2&gt; 
&lt;p&gt;We write about LLM engineering on the &lt;strong&gt;&lt;a href="https://www.tensorzero.com/blog"&gt;TensorZero Blog&lt;/a&gt;&lt;/strong&gt;. Here are some of our favorite posts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.tensorzero.com/blog/bandits-in-your-llm-gateway/"&gt;Bandits in your LLM Gateway: Improve LLM Applications Faster with Adaptive Experimentation (A/B Testing)&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.tensorzero.com/blog/is-openai-reinforcement-fine-tuning-rft-worth-it/"&gt;Is OpenAI's Reinforcement Fine-Tuning (RFT) Worth It?&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.tensorzero.com/blog/distillation-programmatic-data-curation-smarter-llms-5-30x-cheaper-inference/"&gt;Distillation with Programmatic Data Curation: Smarter LLMs, 5-30x Cheaper Inference&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.tensorzero.com/blog/from-ner-to-agents-does-automated-prompt-engineering-scale-to-complex-tasks/"&gt;From NER to Agents: Does Automated Prompt Engineering Scale to Complex Tasks?&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>rustfs/rustfs</title>
      <link>https://github.com/rustfs/rustfs</link>
      <description>&lt;p&gt;üöÄ2.3x faster than MinIO for 4KB object payloads. RustFS is an open-source, S3-compatible high-performance object storage system supporting migration and coexistence with other S3-compatible platforms such as MinIO and Ceph.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://rustfs.com"&gt;&lt;img src="https://rustfs.com/images/rustfs-github.png" alt="RustFS" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt;RustFS is a high-performance, distributed object storage system built in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/rustfs/rustfs/actions/workflows/ci.yml"&gt;&lt;img alt="CI" src="https://github.com/rustfs/rustfs/actions/workflows/ci.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/rustfs/rustfs/actions/workflows/docker.yml"&gt;&lt;img alt="Build and Push Docker Images" src="https://github.com/rustfs/rustfs/actions/workflows/docker.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;img alt="GitHub commit activity" src="https://img.shields.io/github/commit-activity/m/rustfs/rustfs" /&gt; &lt;img alt="Github Last Commit" src="https://img.shields.io/github/last-commit/rustfs/rustfs" /&gt; &lt;a href="https://hellogithub.com/repository/rustfs/rustfs" target="_blank"&gt;&lt;img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=b95bcb72bdc340b68f16fdf6790b7d5b&amp;amp;claim_uid=MsbvjYeLDKAH457&amp;amp;theme=small" alt="FeaturedÔΩúHelloGitHub" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://docs.rustfs.com/installation/"&gt;Getting Started&lt;/a&gt; ¬∑ &lt;a href="https://docs.rustfs.com/"&gt;Docs&lt;/a&gt; ¬∑ &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;Bug reports&lt;/a&gt; ¬∑ &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;Discussions&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; English | &lt;a href="https://github.com/rustfs/rustfs/raw/main/README_ZH.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=fr"&gt;fran√ßais&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ja"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ko"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=pt"&gt;Portuguese&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ru"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;RustFS is a high-performance, distributed object storage system built in Rust‚Äîone of the most loved programming languages worldwide. RustFS combines the simplicity of MinIO with the memory safety and raw performance of Rust. It offers full S3 compatibility, is completely open-source, and is optimized for data lakes, AI, and big data workloads.&lt;/p&gt; 
&lt;p&gt;Unlike other storage systems, RustFS is released under the permissible Apache 2.0 license, avoiding the restrictions of AGPL. With Rust as its foundation, RustFS delivers superior speed and secure distributed features for next-generation object storage.&lt;/p&gt; 
&lt;h2&gt;Feature &amp;amp; Status&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High Performance&lt;/strong&gt;: Built with Rust to ensure maximum speed and resource efficiency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Architecture&lt;/strong&gt;: Scalable and fault-tolerant design suitable for large-scale deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3 Compatibility&lt;/strong&gt;: Seamless integration with existing S3-compatible applications and tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Lake Support&lt;/strong&gt;: Optimized for high-throughput big data and AI workloads.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source&lt;/strong&gt;: Licensed under Apache 2.0, encouraging unrestricted community contributions and commercial usage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User-Friendly&lt;/strong&gt;: Designed with simplicity in mind for easy deployment and management.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Feature&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
   &lt;th align="left"&gt;Feature&lt;/th&gt; 
   &lt;th align="left"&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;S3 Core Features&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Bitrot Protection&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Upload / Download&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Single Node Mode&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Versioning&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Bucket Replication&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚ö†Ô∏è Partial Support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Logging&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Lifecycle Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;üöß Under Testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Event Notifications&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Distributed Mode&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;üöß Under Testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;K8s Helm Charts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;‚úÖ Available&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;OPA (Open Policy Agent)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;üöß Under Testing&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;RustFS vs MinIO Performance&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Stress Test Environment:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Parameter&lt;/th&gt; 
   &lt;th&gt;Remark&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
   &lt;td&gt;2 Core&lt;/td&gt; 
   &lt;td&gt;Intel Xeon (Sapphire Rapids) Platinum 8475B, 2.7/3.2 GHz&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Memory&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Network&lt;/td&gt; 
   &lt;td&gt;15Gbps&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Drive&lt;/td&gt; 
   &lt;td&gt;40GB x 4&lt;/td&gt; 
   &lt;td&gt;IOPS 3800 / Drive&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a"&gt;https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;RustFS vs Other Object Storage&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Feature&lt;/th&gt; 
   &lt;th align="left"&gt;RustFS&lt;/th&gt; 
   &lt;th align="left"&gt;Other Object Storage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Console Experience&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Powerful Console&lt;/strong&gt;&lt;br /&gt;Comprehensive management interface.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Basic / Limited Console&lt;/strong&gt;&lt;br /&gt;Often overly simple or lacking critical features.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Language &amp;amp; Safety&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Rust-based&lt;/strong&gt;&lt;br /&gt;Memory safety by design.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Go or C-based&lt;/strong&gt;&lt;br /&gt;Potential for memory GC pauses or leaks.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Data Sovereignty&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;No Telemetry / Full Compliance&lt;/strong&gt;&lt;br /&gt;Guards against unauthorized cross-border data egress. Compliant with GDPR (EU/UK), CCPA (US), and APPI (Japan).&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Potential Risk&lt;/strong&gt;&lt;br /&gt;Possible legal exposure and unwanted data telemetry.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Licensing&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Permissive Apache 2.0&lt;/strong&gt;&lt;br /&gt;Business-friendly, no "poison pill" clauses.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Restrictive AGPL v3&lt;/strong&gt;&lt;br /&gt;Risk of license traps and intellectual property pollution.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Compatibility&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;100% S3 Compatible&lt;/strong&gt;&lt;br /&gt;Works with any cloud provider or client, anywhere.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Variable Compatibility&lt;/strong&gt;&lt;br /&gt;May lack support for local cloud vendors or specific APIs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Edge &amp;amp; IoT&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Strong Edge Support&lt;/strong&gt;&lt;br /&gt;Ideal for secure, innovative edge devices.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Weak Edge Support&lt;/strong&gt;&lt;br /&gt;Often too heavy for edge gateways.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Risk Profile&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Enterprise Risk Mitigation&lt;/strong&gt;&lt;br /&gt;Clear IP rights and safe for commercial use.&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Legal Risks&lt;/strong&gt;&lt;br /&gt;Intellectual property ambiguity and usage restrictions.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To get started with RustFS, follow these steps:&lt;/p&gt; 
&lt;h3&gt;1. One-click Installation (Option 1)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -O https://rustfs.com/install_rustfs.sh &amp;amp;&amp;amp; bash install_rustfs.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Docker Quick Start (Option 2)&lt;/h3&gt; 
&lt;p&gt;The RustFS container runs as a non-root user &lt;code&gt;rustfs&lt;/code&gt; (UID &lt;code&gt;10001&lt;/code&gt;). If you run Docker with &lt;code&gt;-v&lt;/code&gt; to mount a host directory, please ensure the host directory owner is set to &lt;code&gt;10001&lt;/code&gt;, otherwise you will encounter permission denied errors.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; # Create data and logs directories
 mkdir -p data logs

 # Change the owner of these directories
 chown -R 10001:10001 data logs

 # Using latest version
 docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:latest

 # Using specific version
 docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:1.0.0.alpha.68
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use Docker Compose. Using the &lt;code&gt;docker-compose.yml&lt;/code&gt; file in the root directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose --profile observability up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: We recommend reviewing the &lt;code&gt;docker-compose.yaml&lt;/code&gt; file before running. It defines several services including Grafana, Prometheus, and Jaeger, which are helpful for RustFS observability. If you wish to start Redis or Nginx containers, you can specify the corresponding profiles.&lt;/p&gt; 
&lt;h3&gt;3. Build from Source (Option 3) - Advanced Users&lt;/h3&gt; 
&lt;p&gt;For developers who want to build RustFS Docker images from source with multi-architecture support:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build multi-architecture images locally
./docker-buildx.sh --build-arg RELEASE=latest

# Build and push to registry
./docker-buildx.sh --push

# Build specific version
./docker-buildx.sh --release v1.0.0 --push

# Build for custom registry
./docker-buildx.sh --registry your-registry.com --namespace yourname --push
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;docker-buildx.sh&lt;/code&gt; script supports: - &lt;strong&gt;Multi-architecture builds&lt;/strong&gt;: &lt;code&gt;linux/amd64&lt;/code&gt;, &lt;code&gt;linux/arm64&lt;/code&gt; - &lt;strong&gt;Automatic version detection&lt;/strong&gt;: Uses git tags or commit hashes - &lt;strong&gt;Registry flexibility&lt;/strong&gt;: Supports Docker Hub, GitHub Container Registry, etc. - &lt;strong&gt;Build optimization&lt;/strong&gt;: Includes caching and parallel builds&lt;/p&gt; 
&lt;p&gt;You can also use Make targets for convenience:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make docker-buildx                    # Build locally
make docker-buildx-push               # Build and push
make docker-buildx-version VERSION=v1.0.0  # Build specific version
make help-docker                      # Show all Docker-related commands
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Heads-up (macOS cross-compilation)&lt;/strong&gt;: macOS keeps the default &lt;code&gt;ulimit -n&lt;/code&gt; at 256, so &lt;code&gt;cargo zigbuild&lt;/code&gt; or &lt;code&gt;./build-rustfs.sh --platform ...&lt;/code&gt; may fail with &lt;code&gt;ProcessFdQuotaExceeded&lt;/code&gt; when targeting Linux. The build script attempts to raise the limit automatically, but if you still see the warning, run &lt;code&gt;ulimit -n 4096&lt;/code&gt; (or higher) in your shell before building.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;4. Build with Helm Chart (Option 4) - Cloud Native&lt;/h3&gt; 
&lt;p&gt;Follow the instructions in the &lt;a href="https://charts.rustfs.com/"&gt;Helm Chart README&lt;/a&gt; to install RustFS on a Kubernetes cluster.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Accessing RustFS&lt;/h3&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;&lt;strong&gt;Access the Console&lt;/strong&gt;: Open your web browser and navigate to &lt;code&gt;http://localhost:9000&lt;/code&gt; to access the RustFS console. 
  &lt;ul&gt; 
   &lt;li&gt;Default credentials: &lt;code&gt;rustfsadmin&lt;/code&gt; / &lt;code&gt;rustfsadmin&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Bucket&lt;/strong&gt;: Use the console to create a new bucket for your objects.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Upload Objects&lt;/strong&gt;: You can upload files directly through the console or use S3-compatible APIs/clients to interact with your RustFS instance.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: To access the RustFS instance via &lt;code&gt;https&lt;/code&gt;, please refer to the &lt;a href="https://docs.rustfs.com/integration/tls-configured.html"&gt;TLS Configuration Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, including configuration options, API references, and advanced usage, please visit our &lt;a href="https://docs.rustfs.com"&gt;Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;p&gt;If you have any questions or need assistance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check the &lt;a href="https://github.com/rustfs/rustfs/discussions/categories/q-a"&gt;FAQ&lt;/a&gt; for common issues and solutions.&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt; to ask questions and share your experiences.&lt;/li&gt; 
 &lt;li&gt;Open an issue on our &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;GitHub Issues&lt;/a&gt; page for bug reports or feature requests.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.rustfs.com"&gt;Documentation&lt;/a&gt; - The manual you should read&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/releases"&gt;Changelog&lt;/a&gt; - What we broke and fixed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt; - Where the community lives&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Bugs&lt;/strong&gt;: &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business&lt;/strong&gt;: &lt;a href="mailto:hello@rustfs.com"&gt;hello@rustfs.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jobs&lt;/strong&gt;: &lt;a href="mailto:jobs@rustfs.com"&gt;jobs@rustfs.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;General Discussion&lt;/strong&gt;: &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contributing&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/rustfs/rustfs/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;RustFS is a community-driven project, and we appreciate all contributions. Check out the &lt;a href="https://github.com/rustfs/rustfs/graphs/contributors"&gt;Contributors&lt;/a&gt; page to see the amazing people who have helped make RustFS better.&lt;/p&gt; 
&lt;a href="https://github.com/rustfs/rustfs/graphs/contributors"&gt; &lt;img src="https://opencollective.com/rustfs/contributors.svg?width=890&amp;amp;limit=500&amp;amp;button=false" alt="Contributors" /&gt; &lt;/a&gt; 
&lt;h2&gt;Github Trending Top&lt;/h2&gt; 
&lt;p&gt;üöÄ RustFS is beloved by open-source enthusiasts and enterprise users worldwide, often appearing on the GitHub Trending top charts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/14181" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/rustfs/rustfs/refs/heads/main/docs/rustfs-trending.jpg" alt="rustfs%2Frustfs | Trendshift" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#rustfs/rustfs&amp;amp;type=date&amp;amp;legend=top-left"&gt;&lt;img src="https://api.star-history.com/svg?repos=rustfs/rustfs&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;Apache 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RustFS&lt;/strong&gt; is a trademark of RustFS, Inc. All other trademarks are the property of their respective owners.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>EFForg/rayhunter</title>
      <link>https://github.com/EFForg/rayhunter</link>
      <description>&lt;p&gt;Rust tool to detect cell site simulators on an orbic mobile hotspot&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Rayhunter&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/EFForg/rayhunter/actions/workflows/main.yml/badge.svg?sanitize=true" alt="Tests" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://www.eff.org/files/styles/media_browser_preview/public/banner_library/rayhunter-banner.png" alt="Rayhunter Logo - An Orca taking a bite out of a cellular signal bar" /&gt;&lt;/p&gt; 
&lt;p&gt;Rayhunter is a project for detecting IMSI catchers, also known as cell-site simulators or stingrays. It was first designed to run on a cheap mobile hotspot called the Orbic RC400L, but thanks to community efforts, it can &lt;a href="https://efforg.github.io/rayhunter/supported-devices.html"&gt;support some other devices as well&lt;/a&gt;. It's also designed to be as easy to install and use as possible, regardless of your level of technical skills, and to minimize false positives.&lt;/p&gt; 
&lt;p&gt;‚Üí Check out the &lt;a href="https://efforg.github.io/rayhunter/installation.html"&gt;installation guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;‚Üí To learn more about the aim of the project, and about IMSI catchers in general, please check out our &lt;a href="https://www.eff.org/deeplinks/2025/03/meet-rayhunter-new-open-source-tool-eff-detect-cellular-spying"&gt;introductory blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;‚Üí For discussion, help, or to join the mattermost channel and get involved with the project and community check out the &lt;a href="https://efforg.github.io/rayhunter/support-feedback-community.html"&gt;many ways listed here&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;‚Üí To learn more about the project in general check out the &lt;a href="https://efforg.github.io/rayhunter/"&gt;Rayhunter Book&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;LEGAL DISCLAIMER:&lt;/strong&gt; Use this program at your own risk. We believe running this program does not currently violate any laws or regulations in the United States. However, we are not responsible for civil or criminal liability resulting from the use of this software. If you are located outside of the US please consult with an attorney in your country to help you assess the legal risks of running this program.&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Good Hunting!&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TheAlgorithms/Rust</title>
      <link>https://github.com/TheAlgorithms/Rust</link>
      <description>&lt;p&gt;All Algorithms implemented in Rust&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;!-- Title: --&gt; 
 &lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Rust_programming_language_black_logo.svg/1024px-Rust_programming_language_black_logo.svg.png" width="100" height="100" /&gt; 
 &lt;h1&gt;&lt;a href="https://github.com/TheAlgorithms/"&gt;The Algorithms&lt;/a&gt; - Rust&lt;/h1&gt; 
 &lt;!-- Labels: --&gt; 
 &lt;a href="https://gitpod.io/#https://github.com/TheAlgorithms/Rust"&gt; &lt;img src="https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod&amp;amp;style=flat-square" height="20" alt="Gitpod Ready-to-Code" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Rust/actions/workflows/build.yml"&gt; &lt;img src="https://github.com/TheAlgorithms/Rust/actions/workflows/build.yml/badge.svg?sanitize=true" height="20" alt="Build workflow" /&gt; &lt;/a&gt; 
 &lt;a href="https://codecov.io/gh/TheAlgorithms/Rust"&gt; &lt;img src="https://codecov.io/gh/TheAlgorithms/Rust/graph/badge.svg?token=nRkPKfbs42" /&gt; &lt;/a&gt; 
 &lt;a href="https://the-algorithms.com/discord"&gt; &lt;img src="https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;amp;colorB=00d37d" height="20" alt="Discord community" /&gt; &lt;/a&gt; 
 &lt;a href="https://matrix.to/#/#TheAlgorithms_community:gitter.im"&gt; &lt;img src="https://img.shields.io/gitter/room/TheAlgorithms/community.svg?style=flat-square" height="20" alt="Gitter chat" /&gt; &lt;/a&gt; 
 &lt;!-- Short description: --&gt; 
 &lt;h3&gt;All algorithms implemented in Rust - for education&lt;/h3&gt; 
&lt;/div&gt; 
&lt;h3&gt;List of Algorithms&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Rust/master/DIRECTORY.md"&gt;directory&lt;/a&gt; for easier navigation and a better overview of the project.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Read through our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Rust/master/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; before you contribute.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>astral-sh/uv</title>
      <link>https://github.com/astral-sh/uv</link>
      <description>&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;uv&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json" alt="uv" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/v/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/l/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv/actions"&gt;&lt;img src="https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Actions status" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/astral-sh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d" /&gt; 
  &lt;img alt="Shows a bar chart with benchmark results." src="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Installing &lt;a href="https://trio.readthedocs.io/"&gt;Trio&lt;/a&gt;'s dependencies with a warm cache.&lt;/i&gt; &lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üöÄ A single tool to replace &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, &lt;code&gt;pipx&lt;/code&gt;, &lt;code&gt;poetry&lt;/code&gt;, &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;twine&lt;/code&gt;, &lt;code&gt;virtualenv&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;‚ö°Ô∏è &lt;a href="https://github.com/astral-sh/uv/raw/main/BENCHMARKS.md"&gt;10-100x faster&lt;/a&gt; than &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;üóÇÔ∏è Provides &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#projects"&gt;comprehensive project management&lt;/a&gt;, with a &lt;a href="https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile"&gt;universal lockfile&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;‚ùáÔ∏è &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#scripts"&gt;Runs scripts&lt;/a&gt;, with support for &lt;a href="https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies"&gt;inline dependency metadata&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;üêç &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#python-versions"&gt;Installs and manages&lt;/a&gt; Python versions.&lt;/li&gt; 
 &lt;li&gt;üõ†Ô∏è &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#tools"&gt;Runs and installs&lt;/a&gt; tools published as Python packages.&lt;/li&gt; 
 &lt;li&gt;üî© Includes a &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#the-pip-interface"&gt;pip-compatible interface&lt;/a&gt; for a performance boost with a familiar CLI.&lt;/li&gt; 
 &lt;li&gt;üè¢ Supports Cargo-style &lt;a href="https://docs.astral.sh/uv/concepts/projects/workspaces"&gt;workspaces&lt;/a&gt; for scalable projects.&lt;/li&gt; 
 &lt;li&gt;üíæ Disk-space efficient, with a &lt;a href="https://docs.astral.sh/uv/concepts/cache"&gt;global cache&lt;/a&gt; for dependency deduplication.&lt;/li&gt; 
 &lt;li&gt;‚è¨ Installable without Rust or Python via &lt;code&gt;curl&lt;/code&gt; or &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è Supports macOS, Linux, and Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;uv is backed by &lt;a href="https://astral.sh"&gt;Astral&lt;/a&gt;, the creators of &lt;a href="https://github.com/astral-sh/ruff"&gt;Ruff&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install uv with our standalone installers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On Windows.
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, from &lt;a href="https://pypi.org/project/uv/"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# With pip.
pip install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Or pipx.
pipx install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If installed via the standalone installer, uv can update itself to the latest version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv self update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;installation documentation&lt;/a&gt; for details and alternative installation methods.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;uv's documentation is available at &lt;a href="https://docs.astral.sh/uv"&gt;docs.astral.sh/uv&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, the command line reference documentation can be viewed with &lt;code&gt;uv help&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Projects&lt;/h3&gt; 
&lt;p&gt;uv manages project dependencies and environments, with support for lockfiles, workspaces, and more, similar to &lt;code&gt;rye&lt;/code&gt; or &lt;code&gt;poetry&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/projects/"&gt;project documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;uv also supports building and publishing projects, even if they're not managed with uv. See the &lt;a href="https://docs.astral.sh/uv/guides/publish/"&gt;publish guide&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h3&gt;Scripts&lt;/h3&gt; 
&lt;p&gt;uv manages dependencies and environments for single-file scripts.&lt;/p&gt; 
&lt;p&gt;Create a new script and add inline metadata declaring its dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ echo 'import requests; print(requests.get("https://astral.sh"))' &amp;gt; example.py

$ uv add --script example.py requests
Updated `example.py`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, run the script in an isolated virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&amp;lt;Response [200]&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/scripts/"&gt;scripts documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;uv executes and installs command-line tools provided by Python packages, similar to &lt;code&gt;pipx&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Run a tool in an ephemeral environment using &lt;code&gt;uvx&lt;/code&gt; (an alias for &lt;code&gt;uv tool run&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uvx pycowsay 'hello world!'
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  """

  ------------
&amp;lt; hello world! &amp;gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install a tool with &lt;code&gt;uv tool install&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/tools/"&gt;tools documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Python versions&lt;/h3&gt; 
&lt;p&gt;uv installs Python and allows quickly switching between versions.&lt;/p&gt; 
&lt;p&gt;Install multiple Python versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download Python versions as needed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&amp;gt;&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use a specific Python version in the current directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python pin 3.11
Pinned `.python-version` to `3.11`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/install-python/"&gt;Python installation documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;The pip interface&lt;/h3&gt; 
&lt;p&gt;uv provides a drop-in replacement for common &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, and &lt;code&gt;virtualenv&lt;/code&gt; commands.&lt;/p&gt; 
&lt;p&gt;uv extends their interfaces with advanced features, such as dependency version overrides, platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and more.&lt;/p&gt; 
&lt;p&gt;Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the &lt;code&gt;uv pip&lt;/code&gt; interface.&lt;/p&gt; 
&lt;p&gt;Compile requirements into a platform-independent requirements file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the locked requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/pip/index/"&gt;pip interface documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/platforms/"&gt;platform support&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Versioning policy&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/versioning/"&gt;versioning policy&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We are passionate about supporting contributors of all levels of experience and would love to see you get involved in the project. See the &lt;a href="https://github.com/astral-sh/uv/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h4&gt;How do you pronounce uv?&lt;/h4&gt; 
&lt;p&gt;It's pronounced as "you - vee" (&lt;a href="https://en.wikipedia.org/wiki/Help:IPA/English#Key"&gt;&lt;code&gt;/juÀê viÀê/&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; 
&lt;h4&gt;How should I stylize uv?&lt;/h4&gt; 
&lt;p&gt;Just "uv", please. See the &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/STYLE.md#styling-uv"&gt;style guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;uv's dependency resolver uses &lt;a href="https://github.com/pubgrub-rs/pubgrub"&gt;PubGrub&lt;/a&gt; under the hood. We're grateful to the PubGrub maintainers, especially &lt;a href="https://github.com/Eh2406"&gt;Jacob Finkelman&lt;/a&gt;, for their support.&lt;/p&gt; 
&lt;p&gt;uv's Git implementation is based on &lt;a href="https://github.com/rust-lang/cargo"&gt;Cargo&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some of uv's optimizations are inspired by the great work we've seen in &lt;a href="https://pnpm.io/"&gt;pnpm&lt;/a&gt;, &lt;a href="https://github.com/orogene/orogene"&gt;Orogene&lt;/a&gt;, and &lt;a href="https://github.com/oven-sh/bun"&gt;Bun&lt;/a&gt;. We've also learned a lot from Nathaniel J. Smith's &lt;a href="https://github.com/njsmith/posy"&gt;Posy&lt;/a&gt; and adapted its &lt;a href="https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline"&gt;trampoline&lt;/a&gt; for Windows support.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;uv is licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0, (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="https://opensource.org/licenses/MIT"&gt;https://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://astral.sh" style="background:none"&gt; &lt;img src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg?sanitize=true" alt="Made by Astral" /&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>qdrant/qdrant</title>
      <link>https://github.com/qdrant/qdrant</link>
      <description>&lt;p&gt;Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/qdrant/qdrant/raw/master/docs/logo-dark.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/qdrant/qdrant/raw/master/docs/logo-light.svg" /&gt; 
  &lt;img height="100" alt="Qdrant" src="https://github.com/qdrant/qdrant/raw/master/docs/logo.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;b&gt;Vector Search Engine for the next generation of AI applications&lt;/b&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/qdrant/qdrant/actions/workflows/rust.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/qdrant/qdrant/rust.yml?style=flat-square" alt="Tests status" /&gt;&lt;/a&gt; &lt;a href="https://api.qdrant.tech/"&gt;&lt;img src="https://img.shields.io/badge/Docs-OpenAPI%203.0-success?style=flat-square" alt="OpenAPI Docs" /&gt;&lt;/a&gt; &lt;a href="https://github.com/qdrant/qdrant/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/qdrant/qdrant?style=flat-square" alt="Apache 2.0 License" /&gt;&lt;/a&gt; &lt;a href="https://qdrant.to/discord"&gt;&lt;img src="https://img.shields.io/discord/907569970500743200?logo=Discord&amp;amp;style=flat-square&amp;amp;color=7289da" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://qdrant.to/roadmap"&gt;&lt;img src="https://img.shields.io/badge/Roadmap-2025-bc1439.svg?style=flat-square" alt="Roadmap 2025" /&gt;&lt;/a&gt; &lt;a href="https://cloud.qdrant.io/"&gt;&lt;img src="https://img.shields.io/badge/Qdrant-Cloud-24386C.svg?logo=cloud&amp;amp;style=flat-square" alt="Qdrant Cloud" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Qdrant&lt;/strong&gt; (read: &lt;em&gt;quadrant&lt;/em&gt;) is a vector similarity search engine and vector database. It provides a production-ready service with a convenient API to store, search, and manage points‚Äîvectors with an additional payload Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications.&lt;/p&gt; 
&lt;p&gt;Qdrant is written in Rust ü¶Ä, which makes it fast and reliable even under high load. See &lt;a href="https://qdrant.tech/benchmarks/"&gt;benchmarks&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!&lt;/p&gt; 
&lt;p&gt;Qdrant is also available as a fully managed &lt;strong&gt;&lt;a href="https://cloud.qdrant.io/"&gt;Qdrant Cloud&lt;/a&gt;&lt;/strong&gt; ‚õÖ including a &lt;strong&gt;free tier&lt;/strong&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/docs/QUICK_START.md"&gt;Quick Start&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/#clients"&gt;Client Libraries&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/#demo-projects"&gt;Demo Projects&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/#integrations"&gt;Integrations&lt;/a&gt; ‚Ä¢ &lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/#contacts"&gt;Contact&lt;/a&gt; &lt;/strong&gt; &lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Python&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;pip install qdrant-client
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The python client offers a convenient way to start with Qdrant locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from qdrant_client import QdrantClient
qdrant = QdrantClient(":memory:") # Create in-memory Qdrant instance, for testing, CI/CD
# OR
client = QdrantClient(path="path/to/db")  # Persists changes to disk, fast prototyping
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Client-Server&lt;/h3&gt; 
&lt;p&gt;To experience the full power of Qdrant locally, run the container with this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -p 6333:6333 qdrant/qdrant
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now you can connect to this with any client, including Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;qdrant = QdrantClient("http://localhost:6333") # Connect to existing Qdrant instance
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Before deploying Qdrant to production, be sure to read our &lt;a href="https://qdrant.tech/documentation/guides/installation/"&gt;installation&lt;/a&gt; and &lt;a href="https://qdrant.tech/documentation/guides/security/"&gt;security&lt;/a&gt; guides.&lt;/p&gt; 
&lt;h3&gt;Clients&lt;/h3&gt; 
&lt;p&gt;Qdrant offers the following client libraries to help you integrate it into your application stack with ease:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Official: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/go-client"&gt;Go client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/rust-client"&gt;Rust client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/qdrant-js"&gt;JavaScript/TypeScript client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/qdrant-client"&gt;Python client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/qdrant-dotnet"&gt;.NET/C# client&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/qdrant/java-client"&gt;Java client&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Community: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://hexdocs.pm/qdrant/readme.html"&gt;Elixir&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/hkulekci/qdrant-php"&gt;PHP&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/andreibondarev/qdrant-ruby"&gt;Ruby&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/metaloom/qdrant-java-client"&gt;Java&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Where do I go from here?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/qdrant/qdrant/master/docs/QUICK_START.md"&gt;Quick Start Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;End to End &lt;a href="https://colab.research.google.com/drive/1Bz8RSVHwnNDaNtDwotfPj0w7AYzsdXZ-?usp=sharing"&gt;Colab Notebook&lt;/a&gt; demo with SentenceBERT and Qdrant&lt;/li&gt; 
 &lt;li&gt;Detailed &lt;a href="https://qdrant.tech/documentation/"&gt;Documentation&lt;/a&gt; are great starting points&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://qdrant.to/qdrant-tutorial"&gt;Step-by-Step Tutorial&lt;/a&gt; to create your first neural network project with Qdrant&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo Projects&lt;a href="https://replit.com/@qdrant"&gt;&lt;img align="right" src="https://replit.com/badge/github/qdrant/qdrant" alt="Run on Repl.it" /&gt;&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;Discover Semantic Text Search üîç&lt;/h3&gt; 
&lt;p&gt;Unlock the power of semantic embeddings with Qdrant, transcending keyword-based search to find meaningful connections in short texts. Deploy a neural search in minutes using a pre-trained neural network, and experience the future of text search. &lt;a href="https://qdrant.to/semantic-search-demo"&gt;Try it online!&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Explore Similar Image Search - Food Discovery üçï&lt;/h3&gt; 
&lt;p&gt;There's more to discovery than text search, especially when it comes to food. People often choose meals based on appearance rather than descriptions and ingredients. Let Qdrant help your users find their next delicious meal using visual search, even if they don't know the dish's name. &lt;a href="https://qdrant.to/food-discovery"&gt;Check it out!&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Master Extreme Classification - E-commerce Product Categorization üì∫&lt;/h3&gt; 
&lt;p&gt;Enter the cutting-edge realm of extreme classification, an emerging machine learning field tackling multi-class and multi-label problems with millions of labels. Harness the potential of similarity learning models, and see how a pre-trained transformer model and Qdrant can revolutionize e-commerce product categorization. &lt;a href="https://qdrant.to/extreme-classification-demo"&gt;Play with it online!&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt; More solutions &lt;/summary&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="30%"&gt; &lt;img src="https://qdrant.tech/content/images/text_search.png" /&gt; &lt;/td&gt; 
    &lt;td width="30%"&gt; &lt;img src="https://qdrant.tech/content/images/image_search.png" /&gt; &lt;/td&gt; 
    &lt;td width="30%"&gt; &lt;img src="https://qdrant.tech/content/images/recommendations.png" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; Semantic Text Search &lt;/td&gt; 
    &lt;td&gt; Similar Image Search &lt;/td&gt; 
    &lt;td&gt; Recommendations &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt; &lt;img width="300px" src="https://qdrant.tech/content/images/chat_bots.png" /&gt; &lt;/td&gt; 
    &lt;td&gt; &lt;img width="300px" src="https://qdrant.tech/content/images/matching_engines.png" /&gt; &lt;/td&gt; 
    &lt;td&gt; &lt;img width="300px" src="https://qdrant.tech/content/images/anomalies_detection.png" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; Chat Bots &lt;/td&gt; 
    &lt;td&gt; Matching Engines &lt;/td&gt; 
    &lt;td&gt; Anomaly Detection &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;h3&gt;REST&lt;/h3&gt; 
&lt;p&gt;Online OpenAPI 3.0 documentation is available &lt;a href="https://api.qdrant.tech/"&gt;here&lt;/a&gt;. OpenAPI makes it easy to generate a client for virtually any framework or programming language.&lt;/p&gt; 
&lt;p&gt;You can also download raw OpenAPI &lt;a href="https://github.com/qdrant/qdrant/raw/master/docs/redoc/master/openapi.json"&gt;definitions&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;gRPC&lt;/h3&gt; 
&lt;p&gt;For faster production-tier searches, Qdrant also provides a gRPC interface. You can find gRPC documentation &lt;a href="https://qdrant.tech/documentation/interfaces/#grpc-interface"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Filtering and Payload&lt;/h3&gt; 
&lt;p&gt;Qdrant can attach any JSON payloads to vectors, allowing for both the storage and filtering of data based on the values in these payloads. Payload supports a wide range of data types and query conditions, including keyword matching, full-text filtering, numerical ranges, geo-locations, and more.&lt;/p&gt; 
&lt;p&gt;Filtering conditions can be combined in various ways, including &lt;code&gt;should&lt;/code&gt;, &lt;code&gt;must&lt;/code&gt;, and &lt;code&gt;must_not&lt;/code&gt; clauses, ensuring that you can implement any desired business logic on top of similarity matching.&lt;/p&gt; 
&lt;h3&gt;Hybrid Search with Sparse Vectors&lt;/h3&gt; 
&lt;p&gt;To address the limitations of vector embeddings when searching for specific keywords, Qdrant introduces support for sparse vectors in addition to the regular dense ones.&lt;/p&gt; 
&lt;p&gt;Sparse vectors can be viewed as an generalization of BM25 or TF-IDF ranking. They enable you to harness the capabilities of transformer-based neural networks to weigh individual tokens effectively.&lt;/p&gt; 
&lt;h3&gt;Vector Quantization and On-Disk Storage&lt;/h3&gt; 
&lt;p&gt;Qdrant provides multiple options to make vector search cheaper and more resource-efficient. Built-in vector quantization reduces RAM usage by up to 97% and dynamically manages the trade-off between search speed and precision.&lt;/p&gt; 
&lt;h3&gt;Distributed Deployment&lt;/h3&gt; 
&lt;p&gt;Qdrant offers comprehensive horizontal scaling support through two key mechanisms:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Size expansion via sharding and throughput enhancement via replication&lt;/li&gt; 
 &lt;li&gt;Zero-downtime rolling updates and seamless dynamic scaling of the collections&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Highlighted Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Query Planning and Payload Indexes&lt;/strong&gt; - leverages stored payload information to optimize query execution strategy.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SIMD Hardware Acceleration&lt;/strong&gt; - utilizes modern CPU x86-x64 and Neon architectures to deliver better performance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Async I/O&lt;/strong&gt; - uses &lt;code&gt;io_uring&lt;/code&gt; to maximize disk throughput utilization even on a network-attached storage.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Write-Ahead Logging&lt;/strong&gt; - ensures data persistence with update confirmation, even during power outages.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Integrations&lt;/h1&gt; 
&lt;p&gt;Examples and/or documentation of Qdrant integrations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.cohere.com/docs/qdrant-and-cohere"&gt;Cohere&lt;/a&gt; (&lt;a href="https://qdrant.tech/articles/qa-with-cohere-and-qdrant/"&gt;blogpost on building a QA app with Cohere and Qdrant&lt;/a&gt;) - Use Cohere embeddings with Qdrant&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docarray.org/user_guide/storing/index_qdrant/"&gt;DocArray&lt;/a&gt; - Use Qdrant as a document store in DocArray&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://haystack.deepset.ai/integrations/qdrant-document-store"&gt;Haystack&lt;/a&gt; - Use Qdrant as a document store with Haystack (&lt;a href="https://haystack.deepset.ai/blog/qdrant-integration"&gt;blogpost&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://python.langchain.com/docs/integrations/providers/qdrant/"&gt;LangChain&lt;/a&gt; (&lt;a href="https://qdrant.tech/articles/langchain-integration/"&gt;blogpost&lt;/a&gt;) - Use Qdrant as a memory backend for LangChain.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/QdrantIndexDemo.html"&gt;LlamaIndex&lt;/a&gt; - Use Qdrant as a Vector Store with LlamaIndex.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openai/chatgpt-retrieval-plugin/raw/main/docs/providers/qdrant/setup.md"&gt;OpenAI - ChatGPT retrieval plugin&lt;/a&gt; - Use Qdrant as a memory backend for ChatGPT&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://devblogs.microsoft.com/semantic-kernel/the-power-of-persistent-memory-with-semantic-kernel-and-qdrant-vector-database/"&gt;Microsoft Semantic Kernel&lt;/a&gt; - Use Qdrant as persistent memory with Semantic Kernel&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contacts&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Have questions? Join our &lt;a href="https://qdrant.to/discord"&gt;Discord channel&lt;/a&gt; or mention &lt;a href="https://qdrant.to/twitter"&gt;@qdrant_engine on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Want to stay in touch with latest releases? Subscribe to our &lt;a href="https://qdrant.tech/subscribe/"&gt;Newsletters&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Looking for a managed cloud? Check &lt;a href="https://qdrant.tech/pricing/"&gt;pricing&lt;/a&gt;, need something personalised? We're at &lt;a href="mailto:info@qdrant.tech"&gt;info@qdrant.tech&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Qdrant is licensed under the Apache License, Version 2.0. View a copy of the &lt;a href="https://github.com/qdrant/qdrant/raw/master/LICENSE"&gt;License file&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ankitects/anki</title>
      <link>https://github.com/ankitects/anki</link>
      <description>&lt;p&gt;Anki is a smart spaced repetition flashcard program&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Anki¬Æ&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://buildkite.com/ankitects/anki-ci"&gt;&lt;img src="https://badge.buildkite.com/c9edf020a4aec976f9835e54751cc5409d843adbb66d043bd3.svg?branch=main" alt="Build status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repo contains the source code for the computer version of &lt;a href="https://apps.ankiweb.net"&gt;Anki&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;About&lt;/h1&gt; 
&lt;p&gt;Anki is a spaced repetition program. Please see the &lt;a href="https://apps.ankiweb.net"&gt;website&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h1&gt;Getting Started&lt;/h1&gt; 
&lt;h3&gt;Anki Betas&lt;/h3&gt; 
&lt;p&gt;If you'd like to try development builds of Anki but don't feel comfortable building the code, please see &lt;a href="https://betas.ankiweb.net/"&gt;Anki betas&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Developing&lt;/h3&gt; 
&lt;p&gt;For more information on building and developing, please see &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/docs/development.md"&gt;Development&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;Want to contribute to Anki? Check out the &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/docs/contributing.md"&gt;Contribution Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Anki Contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/CONTRIBUTORS"&gt;CONTRIBUTORS&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Anki's license: &lt;a href="https://raw.githubusercontent.com/ankitects/anki/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>firecracker-microvm/firecracker</title>
      <link>https://github.com/firecracker-microvm/firecracker</link>
      <description>&lt;p&gt;Secure and fast microVMs for serverless computing.&lt;/p&gt;&lt;hr&gt;&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="docs/images/fc_logo_full_transparent-bg_white-fg.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="docs/images/fc_logo_full_transparent-bg.png" /&gt; 
 &lt;img alt="Firecracker Logo Title" width="750" src="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/images/fc_logo_full_transparent-bg.png" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;Our mission is to enable secure, multi-tenant, minimal-overhead execution of container and function workloads.&lt;/p&gt; 
&lt;p&gt;Read more about the Firecracker Charter &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/CHARTER.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;What is Firecracker?&lt;/h2&gt; 
&lt;p&gt;Firecracker is an open source virtualization technology that is purpose-built for creating and managing secure, multi-tenant container and function-based services that provide serverless operational models. Firecracker runs workloads in lightweight virtual machines, called microVMs, which combine the security and isolation properties provided by hardware virtualization technology with the speed and flexibility of containers.&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;The main component of Firecracker is a virtual machine monitor (VMM) that uses the Linux Kernel Virtual Machine (KVM) to create and run microVMs. Firecracker has a minimalist design. It excludes unnecessary devices and guest-facing functionality to reduce the memory footprint and attack surface area of each microVM. This improves security, decreases the startup time, and increases hardware utilization. Firecracker has also been integrated in container runtimes, for example &lt;a href="https://github.com/kata-containers/kata-containers"&gt;Kata Containers&lt;/a&gt; and &lt;a href="https://github.com/liquidmetal-dev/flintlock"&gt;Flintlock&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Firecracker was developed at Amazon Web Services to accelerate the speed and efficiency of services like &lt;a href="https://aws.amazon.com/lambda/"&gt;AWS Lambda&lt;/a&gt; and &lt;a href="https://aws.amazon.com/fargate/"&gt;AWS Fargate&lt;/a&gt;. Firecracker is open sourced under &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/LICENSE"&gt;Apache version 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To read more about Firecracker, check out &lt;a href="https://firecracker-microvm.github.io"&gt;firecracker-microvm.io&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;To get started with Firecracker, download the latest &lt;a href="https://github.com/firecracker-microvm/firecracker/releases"&gt;release&lt;/a&gt; binaries or build it from source.&lt;/p&gt; 
&lt;p&gt;You can build Firecracker on any Unix/Linux system that has Docker running (we use a development container) and &lt;code&gt;bash&lt;/code&gt; installed, as follows:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/firecracker-microvm/firecracker
cd firecracker
tools/devtool build
toolchain="$(uname -m)-unknown-linux-musl"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The Firecracker binary will be placed at &lt;code&gt;build/cargo_target/${toolchain}/debug/firecracker&lt;/code&gt;. For more information on building, testing, and running Firecracker, go to the &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/getting-started.md"&gt;quickstart guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The overall security of Firecracker microVMs, including the ability to meet the criteria for safe multi-tenant computing, depends on a well configured Linux host operating system. A configuration that we believe meets this bar is included in &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/prod-host-setup.md"&gt;the production host setup document&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Firecracker is already running production workloads within AWS, but it's still Day 1 on the journey guided by our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/CHARTER.md"&gt;mission&lt;/a&gt;. There's a lot more to build and we welcome all contributions.&lt;/p&gt; 
&lt;p&gt;To contribute to Firecracker, check out the development setup section in the &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/getting-started.md"&gt;getting started guide&lt;/a&gt; and then the Firecracker &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Releases&lt;/h2&gt; 
&lt;p&gt;New Firecracker versions are released via the GitHub repository &lt;a href="https://github.com/firecracker-microvm/firecracker/releases"&gt;releases&lt;/a&gt; page, typically every two or three months. A history of changes is recorded in our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/CHANGELOG.md"&gt;changelog&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The Firecracker release policy is detailed &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/RELEASE_POLICY.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Design&lt;/h2&gt; 
&lt;p&gt;Firecracker's overall architecture is described in &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/design.md"&gt;the design document&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features &amp;amp; Capabilities&lt;/h2&gt; 
&lt;p&gt;Firecracker consists of a single micro Virtual Machine Manager process that exposes an API endpoint to the host once started. The API is &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/src/firecracker/swagger/firecracker.yaml"&gt;specified in OpenAPI format&lt;/a&gt;. Read more about it in the &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/api_requests"&gt;API docs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;strong&gt;API endpoint&lt;/strong&gt; can be used to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Configure the microvm by: 
  &lt;ul&gt; 
   &lt;li&gt;Setting the number of vCPUs (the default is 1).&lt;/li&gt; 
   &lt;li&gt;Setting the memory size (the default is 128 MiB).&lt;/li&gt; 
   &lt;li&gt;Configuring a &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/cpu_templates/cpu-templates.md"&gt;CPU template&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Add one or more network interfaces to the microVM.&lt;/li&gt; 
 &lt;li&gt;Add one or more read-write or read-only disks to the microVM, each represented by a file-backed block device.&lt;/li&gt; 
 &lt;li&gt;Trigger a block device re-scan while the guest is running. This enables the guest OS to pick up size changes to the block device's backing file.&lt;/li&gt; 
 &lt;li&gt;Change the backing file for a block device, before or after the guest boots.&lt;/li&gt; 
 &lt;li&gt;Configure rate limiters for virtio devices which can limit the bandwidth, operations per second, or both.&lt;/li&gt; 
 &lt;li&gt;Configure the logging and metric system.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[BETA]&lt;/code&gt; Configure the data tree of the guest-facing metadata service. The service is only available to the guest if this resource is configured.&lt;/li&gt; 
 &lt;li&gt;Add a &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/vsock.md"&gt;vsock socket&lt;/a&gt; to the microVM.&lt;/li&gt; 
 &lt;li&gt;Add a &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/entropy.md"&gt;entropy device&lt;/a&gt; to the microVM.&lt;/li&gt; 
 &lt;li&gt;Add a &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/pmem.md"&gt;pmem device&lt;/a&gt; to the microVM.&lt;/li&gt; 
 &lt;li&gt;Configure and manage &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/memory-hotplug.md"&gt;memory hotplugging&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Start the microVM using a given kernel image, root file system, and boot arguments.&lt;/li&gt; 
 &lt;li&gt;[x86_64 only] Stop the microVM.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Built-in Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Demand fault paging and CPU oversubscription enabled by default.&lt;/li&gt; 
 &lt;li&gt;Advanced, thread-specific seccomp filters for enhanced security.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/docs/jailer.md"&gt;Jailer&lt;/a&gt; process for starting Firecracker in production scenarios; applies a cgroup/namespace isolation barrier and then drops privileges.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Tested platforms&lt;/h2&gt; 
&lt;p&gt;We test all combinations of:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Instance&lt;/th&gt; 
   &lt;th align="left"&gt;Host OS &amp;amp; Kernel&lt;/th&gt; 
   &lt;th align="left"&gt;Guest Rootfs&lt;/th&gt; 
   &lt;th align="left"&gt;Guest Kernel&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m5n.metal (Intel Cascade Lake)&lt;/td&gt; 
   &lt;td align="left"&gt;al2 linux_5.10&lt;/td&gt; 
   &lt;td align="left"&gt;ubuntu 24.04&lt;/td&gt; 
   &lt;td align="left"&gt;linux_5.10&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m6i.metal (Intel Ice Lake)&lt;/td&gt; 
   &lt;td align="left"&gt;al2023 linux_6.1&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;linux_6.1&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m7i.metal-24xl (Intel Sapphire Rapids)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m7i.metal-48xl (Intel Sapphire Rapids)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m6a.metal (AMD Milan)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m7a.metal-48xl (AMD Genoa)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m6g.metal (Graviton 2)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m7g.metal (Graviton 3)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m8g.metal-24xl (Graviton 4)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;m8g.metal-48xl (Graviton 4)&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Known issues and Limitations&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;code&gt;pl031&lt;/code&gt; RTC device on aarch64 does not support interrupts, so guest programs which use an RTC alarm (e.g. &lt;code&gt;hwclock&lt;/code&gt;) will not work.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;Firecracker's performance characteristics are listed as part of the &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/SPECIFICATION.md"&gt;specification documentation&lt;/a&gt;. All specifications are a part of our commitment to supporting container and function workloads in serverless operational models, and are therefore enforced via continuous integration testing.&lt;/p&gt; 
&lt;h2&gt;Policy for Security Disclosures&lt;/h2&gt; 
&lt;p&gt;The security of Firecracker is our top priority. If you suspect you have uncovered a vulnerability, contact us privately, as outlined in our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/SECURITY.md"&gt;security policy document&lt;/a&gt;; we will immediately prioritize your disclosure.&lt;/p&gt; 
&lt;h2&gt;FAQ &amp;amp; Contact&lt;/h2&gt; 
&lt;p&gt;Frequently asked questions are collected in our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/FAQ.md"&gt;FAQ doc&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can get in touch with the Firecracker community in the following ways:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Security-related issues, see our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/SECURITY.md"&gt;security policy document&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Chat with us on our &lt;a href="https://join.slack.com/t/firecracker-microvm/shared_invite/zt-2tc0mfxpc-tU~HYAYSzLDl5XGGJU3YIg"&gt;Slack workspace&lt;/a&gt; &lt;em&gt;Note: most of the maintainers are on a European time zone.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Open a GitHub issue in this repository.&lt;/li&gt; 
 &lt;li&gt;Email the maintainers at &lt;a href="mailto:firecracker-maintainers@amazon.com"&gt;firecracker-maintainers@amazon.com&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When communicating within the Firecracker community, please mind our &lt;a href="https://raw.githubusercontent.com/firecracker-microvm/firecracker/main/CODE_OF_CONDUCT.md"&gt;code of conduct&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>