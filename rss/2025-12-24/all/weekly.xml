<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Tue, 23 Dec 2025 01:42:37 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>anthropics/claude-code</title>
      <link>https://github.com/anthropics/claude-code</link>
      <description>&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Code&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square" alt="" /&gt; &lt;a href="https://www.npmjs.com/package/@anthropic-ai/claude-code"&gt;&lt;img src="https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square" alt="npm" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your terminal, IDE, or tag @claude on Github.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn more in the &lt;a href="https://docs.anthropic.com/en/docs/claude-code/overview"&gt;official documentation&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/anthropics/claude-code/main/demo.gif" /&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Claude Code:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;MacOS/Linux:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://claude.ai/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Homebrew (MacOS):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install --cask claude-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Windows:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://claude.ai/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;NPM:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install -g @anthropic-ai/claude-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;NOTE: If installing with NPM, you also need to install &lt;a href="https://nodejs.org/en/download/"&gt;Node.js 18+&lt;/a&gt;&lt;/p&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Navigate to your project directory and run &lt;code&gt;claude&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Plugins&lt;/h2&gt; 
&lt;p&gt;This repository includes several Claude Code plugins that extend functionality with custom commands and agents. See the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-code/main/plugins/README.md"&gt;plugins directory&lt;/a&gt; for detailed documentation on available plugins.&lt;/p&gt; 
&lt;h2&gt;Reporting Bugs&lt;/h2&gt; 
&lt;p&gt;We welcome your feedback. Use the &lt;code&gt;/bug&lt;/code&gt; command to report issues directly within Claude Code, or file a &lt;a href="https://github.com/anthropics/claude-code/issues"&gt;GitHub issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Connect on Discord&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href="https://anthropic.com/discord"&gt;Claude Developers Discord&lt;/a&gt; to connect with other developers using Claude Code. Get help, share feedback, and discuss your projects with the community.&lt;/p&gt; 
&lt;h2&gt;Data collection, usage, and retention&lt;/h2&gt; 
&lt;p&gt;When you use Claude Code, we collect feedback, which includes usage data (such as code acceptance or rejections), associated conversation data, and user feedback submitted via the &lt;code&gt;/bug&lt;/code&gt; command.&lt;/p&gt; 
&lt;h3&gt;How we use your data&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://docs.anthropic.com/en/docs/claude-code/data-usage"&gt;data usage policies&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Privacy safeguards&lt;/h3&gt; 
&lt;p&gt;We have implemented several safeguards to protect your data, including limited retention periods for sensitive information, restricted access to user session data, and clear policies against using feedback for model training.&lt;/p&gt; 
&lt;p&gt;For full details, please review our &lt;a href="https://www.anthropic.com/legal/commercial-terms"&gt;Commercial Terms of Service&lt;/a&gt; and &lt;a href="https://www.anthropic.com/legal/privacy"&gt;Privacy Policy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Morganamilo/paru</title>
      <link>https://github.com/Morganamilo/paru</link>
      <description>&lt;p&gt;Feature packed AUR helper&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Paru&lt;/h1&gt; 
&lt;p&gt;Feature packed AUR helper&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aur.archlinux.org/packages/paru/"&gt;&lt;img src="https://img.shields.io/aur/version/paru?color=1793d1&amp;amp;label=paru&amp;amp;logo=arch-linux&amp;amp;style=for-the-badge" alt="paru" /&gt;&lt;/a&gt; &lt;a href="https://aur.archlinux.org/packages/paru-bin/"&gt;&lt;img src="https://img.shields.io/aur/version/paru-bin?color=1793d1&amp;amp;label=paru-bin&amp;amp;logo=arch-linux&amp;amp;style=for-the-badge" alt="paru-bin" /&gt;&lt;/a&gt; &lt;a href="https://aur.archlinux.org/packages/paru-git/"&gt;&lt;img src="https://img.shields.io/aur/version/paru-git?color=1793d1&amp;amp;label=paru-git&amp;amp;logo=arch-linux&amp;amp;style=for-the-badge" alt="paru-git" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Description&lt;/h2&gt; 
&lt;p&gt;Paru is your standard pacman wrapping AUR helper with lots of features and minimal interaction.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://asciinema.org/a/sEh1ZpZZUgXUsgqKxuDdhpdEE"&gt;&lt;img src="https://asciinema.org/a/sEh1ZpZZUgXUsgqKxuDdhpdEE.svg?sanitize=true" alt="asciicast" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;sudo pacman -S --needed base-devel
git clone https://aur.archlinux.org/paru.git
cd paru
makepkg -si
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/Morganamilo/paru/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;General Tips&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Man pages&lt;/strong&gt;: For documentation on paru's options and config file see &lt;code&gt;paru(8)&lt;/code&gt; and &lt;code&gt;paru.conf(5)&lt;/code&gt; respectively.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Color&lt;/strong&gt;: Paru only enables color if color is enabled in pacman. Enable &lt;code&gt;color&lt;/code&gt; in your &lt;code&gt;pacman.conf&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;File based review&lt;/strong&gt;: To get a more advanced review process enable &lt;code&gt;FileManager&lt;/code&gt; with your file manager of choice in &lt;code&gt;paru.conf&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flip search order&lt;/strong&gt;: To get search results to start at the bottom and go upwards, enable &lt;code&gt;BottomUp&lt;/code&gt; in &lt;code&gt;paru.conf&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Editing PKGBUILDs&lt;/strong&gt;: When editing PKGBUILDs, you can commit your changes to make them permanent. When the package is upgraded, &lt;code&gt;git&lt;/code&gt; will try to merge your changes with upstream's.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PKGBUILD syntax highlighting&lt;/strong&gt;: You can install &lt;a href="https://github.com/sharkdp/bat"&gt;&lt;code&gt;bat&lt;/code&gt;&lt;/a&gt; to enable syntax highlighting during PKGBUILD review.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Tracking -git packages&lt;/strong&gt;: Paru tracks -git package by monitoring the upstream repository. Paru can only do this for packages that paru itself installed. &lt;code&gt;paru --gendb&lt;/code&gt; will make paru aware of packages it did not install.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;paru &amp;lt;target&amp;gt;&lt;/code&gt; -- Interactively search and install &lt;code&gt;&amp;lt;target&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;paru&lt;/code&gt; -- Alias for &lt;code&gt;paru -Syu&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;paru -S &amp;lt;target&amp;gt;&lt;/code&gt; -- Install a specific package.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;paru -Sua&lt;/code&gt; -- Upgrade AUR packages.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;paru -Qua&lt;/code&gt; -- Print available AUR updates.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;paru -G &amp;lt;target&amp;gt;&lt;/code&gt; -- Download the PKGBUILD and related files of &lt;code&gt;&amp;lt;target&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;paru -Gp &amp;lt;target&amp;gt;&lt;/code&gt; -- Print the PKGBUILD of &lt;code&gt;&amp;lt;target&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;paru -Gc &amp;lt;target&amp;gt;&lt;/code&gt; -- Print the AUR comments of &lt;code&gt;&amp;lt;target&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;paru --gendb&lt;/code&gt; -- Generate the devel database for tracking &lt;code&gt;*-git&lt;/code&gt; packages. This is only needed when you initially start using paru.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;paru -Bi .&lt;/code&gt; -- Build and install a PKGBUILD in the current directory.&lt;/p&gt; 
&lt;h2&gt;IRC&lt;/h2&gt; 
&lt;p&gt;Paru now has an IRC. #paru on &lt;a href="https://libera.chat/"&gt;Libera Chat&lt;/a&gt;. Feel free to join for discussion and help with paru.&lt;/p&gt; 
&lt;h2&gt;Debugging&lt;/h2&gt; 
&lt;p&gt;Paru is not an official tool. If paru can't build a package, you should first check if makepkg can successfully build the package. If it can't, then you should report the issue to the maintainer. Otherwise, it is likely an issue with paru and should be reported here.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ZJU-LLMs/Foundations-of-LLMs</title>
      <link>https://github.com/ZJU-LLMs/Foundations-of-LLMs</link>
      <description>&lt;p&gt;A book for Learning the Foundations of LLMs&lt;/p&gt;&lt;hr&gt;&lt;p&gt;âœ¨ News: æˆ‘ä»¬å¼€æºäº†ä¸€æ¬¾å¤šæ™ºèƒ½ä½“å¼€å‘æ¡†æ¶Agent-Kernelï¼Œè®©å¤§å®¶è½»æ¾ç©è½¬å¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ä¸€ç™¾ä¸ªæ™ºèƒ½ä½“åœ¨è‡ªå·±çš„ç¬”è®°æœ¬ç”µè„‘ä¸Šå°±èƒ½è·‘èµ·æ¥å“¦~ ç§‘ç ”ã€æ¯•è®¾ã€å¤§åˆ›ã€SRTPéƒ½æ˜¯è®©äººçœ¼å‰ä¸€äº®çš„åˆ›æ–°ç¥å™¨ï¼ Github åœ°å€: &lt;a href="https://github.com/ZJU-LLMs/Agent-Kernel"&gt;https://github.com/ZJU-LLMs/Agent-Kernel&lt;/a&gt; å¿«æ¥çœ‹çœ‹å§ï¼&lt;/p&gt; 
&lt;h1 align="center"&gt;å¤§æ¨¡å‹åŸºç¡€&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;img src=".\figure\cover.png" style="width: 50%" /&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;img src="https://img.shields.io/badge/version-1.0.0-blue" /&gt; &lt;img src="https://img.shields.io/github/stars/ZJU-LLMs/Foundations-of-LLMs?style=social" /&gt; &lt;img src="https://img.shields.io/github/forks/ZJU-LLMs/Foundations-of-LLMs?style=social" /&gt; 
 &lt;!--   &lt;img src="https://img.shields.io/github/license/ZJU-LLMs/Foundations-of-LLMs"&gt; --&gt; &lt;/p&gt; 
&lt;p&gt;æœ¬ä¹¦æ—¨åœ¨ä¸ºå¯¹å¤§è¯­è¨€æ¨¡å‹æ„Ÿå…´è¶£çš„è¯»è€…ç³»ç»Ÿåœ°è®²è§£ç›¸å…³åŸºç¡€çŸ¥è¯†ã€ä»‹ç»å‰æ²¿æŠ€æœ¯ã€‚ä½œè€…å›¢é˜Ÿå°†è®¤çœŸå¬å–å¼€æºç¤¾åŒºä»¥åŠå¹¿å¤§ä¸“å®¶å­¦è€…çš„å»ºè®®ï¼ŒæŒç»­è¿›è¡Œ&lt;strong&gt;æœˆåº¦æ›´æ–°&lt;/strong&gt;ï¼Œè‡´åŠ›æ‰“é€ &lt;strong&gt;æ˜“è¯»ã€ä¸¥è°¨ã€æœ‰æ·±åº¦&lt;/strong&gt;çš„å¤§æ¨¡å‹æ•™æã€‚å¹¶ä¸”ï¼Œæœ¬ä¹¦è¿˜å°†é’ˆå¯¹æ¯ç« å†…å®¹é…å¤‡ç›¸å…³çš„&lt;strong&gt;Paper List&lt;/strong&gt;ï¼Œä»¥è·Ÿè¸ªç›¸å…³æŠ€æœ¯çš„&lt;strong&gt;æœ€æ–°è¿›å±•&lt;/strong&gt;ã€‚&lt;/p&gt; 
&lt;p&gt;æœ¬ä¹¦ç¬¬ä¸€ç‰ˆåŒ…æ‹¬&lt;strong&gt;ä¼ ç»Ÿè¯­è¨€æ¨¡å‹&lt;/strong&gt;ã€&lt;strong&gt;å¤§è¯­è¨€æ¨¡å‹æ¶æ„æ¼”åŒ–&lt;/strong&gt;ã€&lt;strong&gt;Promptå·¥ç¨‹&lt;/strong&gt;ã€&lt;strong&gt;å‚æ•°é«˜æ•ˆå¾®è°ƒ&lt;/strong&gt;ã€&lt;strong&gt;æ¨¡å‹ç¼–è¾‘&lt;/strong&gt;ã€&lt;strong&gt;æ£€ç´¢å¢å¼ºç”Ÿæˆ&lt;/strong&gt;ç­‰å…­ç« å†…å®¹ã€‚ä¸ºå¢åŠ æœ¬ä¹¦çš„æ˜“è¯»æ€§ï¼Œæ¯ç« åˆ†åˆ«ä»¥&lt;strong&gt;ä¸€ç§åŠ¨ç‰©&lt;/strong&gt;ä¸ºèƒŒæ™¯ï¼Œå¯¹å…·ä½“æŠ€æœ¯è¿›è¡Œä¸¾ä¾‹è¯´æ˜ï¼Œæ•…æ­¤æœ¬ä¹¦ä»¥å…­ç§åŠ¨ç‰©ä½œä¸ºå°é¢ã€‚å½“å‰ç‰ˆæœ¬æ‰€å«å†…å®¹å‡æ¥æºäºä½œè€…å›¢é˜Ÿå¯¹ç›¸å…³æ–¹å‘çš„æ¢ç´¢ä¸ç†è§£ï¼Œå¦‚æœ‰è°¬è¯¯ï¼Œæ³è¯·å¤§å®¶å¤šæissueï¼Œå¤šå¤šèµæ•™ã€‚åç»­ï¼Œä½œè€…å›¢é˜Ÿè¿˜å°†ç»§ç»­æ¢ç´¢å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿã€å¤§æ¨¡å‹æ™ºèƒ½ä½“ç­‰æ–¹å‘ã€‚ç›¸å…³å†…å®¹ä¹Ÿå°†é™†ç»­è¡¥å……åˆ°æœ¬ä¹¦çš„åç»­ç‰ˆæœ¬ä¸­ï¼ŒæœŸå¾…å°é¢ä¸Šçš„åŠ¨ç‰©è¶Šæ¥è¶Šå¤šã€‚&lt;/p&gt; 
&lt;p&gt;å½“å‰å®Œæ•´çš„æœ¬ä¹¦PDFç‰ˆæœ¬è·¯å¾„ä¸º&lt;a href="https://github.com/ZJU-LLMs/Foundations-of-LLMs/raw/main/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E6%95%99%E6%9D%90/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%20%E5%AE%8C%E6%95%B4%E7%89%88.pdf"&gt;å¤§æ¨¡å‹åŸºç¡€.pdf&lt;/a&gt;ã€‚å¦å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸¤ä¸ªæ–‡ä»¶å¤¹ï¼Œ&lt;a href="https://github.com/ZJU-LLMs/Foundations-of-LLMs/tree/main/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E6%95%99%E6%9D%90/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E5%88%86%E7%AB%A0%E8%8A%82%E5%86%85%E5%AE%B9"&gt;å¤§è¯­è¨€æ¨¡å‹åˆ†ç« èŠ‚å†…å®¹&lt;/a&gt;æ–‡ä»¶å¤¹ä¸­åŒ…å«äº†å„ç« èŠ‚çš„PDFç‰ˆæœ¬ã€‚è€Œ&lt;a href="https://github.com/ZJU-LLMs/Foundations-of-LLMs/tree/main/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E5%88%97%E8%A1%A8"&gt;å¤§è¯­è¨€æ¨¡å‹ç›¸å…³è®ºæ–‡&lt;/a&gt;æ–‡ä»¶å¤¹ä¸­åŒ…å«äº†å„ç« èŠ‚çš„ç›¸å…³è®ºæ–‡ï¼Œå½“å‰æ­£å¤„äºä¸æ–­æ›´æ–°ä¸­ã€‚&lt;/p&gt; 
&lt;p&gt;å…¶ä¸­æ¯ä¸ªç« èŠ‚çš„å†…å®¹ç›®å½•å¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚&lt;/p&gt; 
&lt;h2&gt;æœ¬ä¹¦ç›®å½•&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;th style="text-align:center; width: 25%;"&gt;ç« èŠ‚&lt;/th&gt; 
   &lt;th style="text-align:center; width: 75%;" colspan="3"&gt;æ‰€å«å†…å®¹&lt;/th&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;b&gt;&lt;a href="https://github.com/ZJU-LLMs/Foundations-of-LLMs/raw/main/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E6%95%99%E6%9D%90/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E5%88%86%E7%AB%A0%E8%8A%82%E5%86%85%E5%AE%B9/%E7%AC%AC1%E7%AB%A0%20%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.pdf"&gt;ç¬¬ 1 ç« ï¼šè¯­è¨€æ¨¡å‹åŸºç¡€&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td style="width: 25%;"&gt;1.1 åŸºäºç»Ÿè®¡æ–¹æ³•çš„è¯­è¨€æ¨¡å‹&lt;/td&gt; 
   &lt;td style="width: 25%;"&gt;1.2 åŸºäº RNN çš„è¯­è¨€æ¨¡å‹&lt;/td&gt; 
   &lt;td style="width: 25%;"&gt;1.3 åŸºäº Transformer çš„è¯­è¨€æ¨¡å‹&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1.4 è¯­è¨€æ¨¡å‹çš„é‡‡æ ·æ–¹æ³•&lt;/td&gt; 
   &lt;td&gt;1.5 è¯­è¨€æ¨¡å‹çš„è¯„æµ‹&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;b&gt;&lt;a href="https://github.com/ZJU-LLMs/Foundations-of-LLMs/raw/main/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E6%95%99%E6%9D%90/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E5%88%86%E7%AB%A0%E8%8A%82%E5%86%85%E5%AE%B9/%E7%AC%AC2%E7%AB%A0%20%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84.pdf"&gt;ç¬¬ 2 ç« ï¼šå¤§è¯­è¨€æ¨¡å‹&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td&gt;2.1 å¤§æ•°æ® + å¤§æ¨¡å‹ â†’ æ–°æ™ºèƒ½&lt;/td&gt; 
   &lt;td&gt;2.2 å¤§è¯­è¨€æ¨¡å‹æ¶æ„æ¦‚è§ˆ&lt;/td&gt; 
   &lt;td&gt;2.3 åŸºäº Encoder-only æ¶æ„çš„å¤§è¯­è¨€æ¨¡å‹&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2.4 åŸºäº Encoder-Decoder æ¶æ„çš„å¤§è¯­è¨€æ¨¡å‹&lt;/td&gt; 
   &lt;td&gt;2.5 åŸºäº Decoder-only æ¶æ„çš„å¤§è¯­è¨€æ¨¡å‹&lt;/td&gt; 
   &lt;td&gt;2.6 é Transformer æ¶æ„&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;b&gt;&lt;a href="https://github.com/ZJU-LLMs/Foundations-of-LLMs/raw/main/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E6%95%99%E6%9D%90/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E5%88%86%E7%AB%A0%E8%8A%82%E5%86%85%E5%AE%B9/%E7%AC%AC3%E7%AB%A0%20Prompt%20%E5%B7%A5%E7%A8%8B.pdf"&gt;ç¬¬ 3 ç« ï¼šPrompt å·¥ç¨‹&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td&gt;3.1 Prompt å·¥ç¨‹ç®€ä»‹&lt;/td&gt; 
   &lt;td&gt;3.2 ä¸Šä¸‹æ–‡å­¦ä¹ &lt;/td&gt; 
   &lt;td&gt;3.3 æ€ç»´é“¾&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3.4 Prompt æŠ€å·§&lt;/td&gt; 
   &lt;td&gt;3.5 ç›¸å…³åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;b&gt;&lt;a href="https://github.com/ZJU-LLMs/Foundations-of-LLMs/raw/main/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E6%95%99%E6%9D%90/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E5%88%86%E7%AB%A0%E8%8A%82%E5%86%85%E5%AE%B9/%E7%AC%AC4%E7%AB%A0%20%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83.pdf"&gt;ç¬¬ 4 ç« ï¼šå‚æ•°é«˜æ•ˆå¾®è°ƒ&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td&gt;4.1 å‚æ•°é«˜æ•ˆå¾®è°ƒç®€ä»‹&lt;/td&gt; 
   &lt;td&gt;4.2 å‚æ•°é™„åŠ æ–¹æ³•&lt;/td&gt; 
   &lt;td&gt;4.3 å‚æ•°é€‰æ‹©æ–¹æ³•&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4.4 ä½ç§©é€‚é…æ–¹æ³•&lt;/td&gt; 
   &lt;td&gt;4.5 å®è·µä¸åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;b&gt;&lt;a href="https://github.com/ZJU-LLMs/Foundations-of-LLMs/raw/main/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E6%95%99%E6%9D%90/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E5%88%86%E7%AB%A0%E8%8A%82%E5%86%85%E5%AE%B9/%E7%AC%AC5%E7%AB%A0%20%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%BE%91.pdf"&gt;ç¬¬ 5 ç« ï¼šæ¨¡å‹ç¼–è¾‘&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td&gt;5.1 æ¨¡å‹ç¼–è¾‘ç®€ä»‹&lt;/td&gt; 
   &lt;td&gt;5.2 æ¨¡å‹ç¼–è¾‘ç»å…¸æ–¹æ³•&lt;/td&gt; 
   &lt;td&gt;5.3 é™„åŠ å‚æ•°æ³•ï¼šT-Patcher&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5.4 å®šä½ç¼–è¾‘æ³•ï¼šROME&lt;/td&gt; 
   &lt;td&gt;5.5 æ¨¡å‹ç¼–è¾‘åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td rowspan="2"&gt;&lt;b&gt;&lt;a href="https://github.com/ZJU-LLMs/Foundations-of-LLMs/raw/main/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E6%95%99%E6%9D%90/%E3%80%8A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E3%80%8B%E5%88%86%E7%AB%A0%E8%8A%82%E5%86%85%E5%AE%B9/%E7%AC%AC6%E7%AB%A0%20%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90.pdf"&gt;ç¬¬ 6 ç« ï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆ&lt;/a&gt;&lt;/b&gt;&lt;/td&gt; 
   &lt;td&gt;6.1 æ£€ç´¢å¢å¼ºç”Ÿæˆç®€ä»‹&lt;/td&gt; 
   &lt;td&gt;6.2 æ£€ç´¢å¢å¼ºç”Ÿæˆæ¶æ„&lt;/td&gt; 
   &lt;td&gt;6.3 çŸ¥è¯†æ£€ç´¢&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6.4 ç”Ÿæˆå¢å¼º&lt;/td&gt; 
   &lt;td&gt;6.5 å®è·µä¸åº”ç”¨&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;è‡´è°¢&lt;/h2&gt; 
&lt;p&gt;æœ¬ä¹¦çš„ä¸æ–­ä¼˜åŒ–ï¼Œå°†ä»°ä»—å„ä½è¯»è€…çš„å¸®åŠ©ä¸æ”¯æŒã€‚æ‚¨çš„å»ºè®®å°†æˆä¸ºæˆ‘ä»¬æŒç»­å‘å‰çš„åŠ¨åŠ›ï¼&lt;/p&gt; 
&lt;p&gt;æ‰€æœ‰æå‡ºissueçš„äººï¼Œæˆ‘ä»¬éƒ½åˆ—ä¸¾åœ¨æ­¤ï¼Œä»¥è¡¨è¾¾æˆ‘ä»¬æ·±æ·±çš„è°¢æ„ã€‚&lt;/p&gt; 
&lt;p&gt;å¦‚æœæœ‰æ­¤ä¹¦ç›¸å…³çš„å…¶ä»–é—®é¢˜ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ä»¬ï¼Œå¯å‘é€é‚®ä»¶è‡³ï¼š&lt;a href="mailto:xuwenyi@zju.edu.cn"&gt;xuwenyi@zju.edu.cn&lt;/a&gt;ã€‚&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src=".\figure\wechat_QR_code.jpg" style="width: 90%" /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>resemble-ai/chatterbox</title>
      <link>https://github.com/resemble-ai/chatterbox</link>
      <description>&lt;p&gt;SoTA open-source TTS&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/Chatterbox-Turbo.jpg" alt="Chatterbox Turbo Image" /&gt;&lt;/p&gt; 
&lt;h1&gt;Chatterbox TTS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_turbo_demopage/"&gt;&lt;img src="https://img.shields.io/badge/listen-demo_samples-blue" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo"&gt;&lt;img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm.svg?sanitize=true" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://podonos.com/resembleai/chatterbox"&gt;&lt;img src="https://static-public.podonos.com/badges/insight-on-pdns-sm-dark.svg?sanitize=true" alt="Alt Text" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;&lt;img src="https://img.shields.io/discord/1377773249798344776?label=join%20discord&amp;amp;logo=discord&amp;amp;style=flat" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;_Made with â™¥ï¸ by &lt;a href="https://resemble.ai" target="_blank"&gt;&lt;img width="100" alt="resemble-logo-horizontal" src="https://github.com/user-attachments/assets/35cf756b-3506-4943-9c72-c05ddfa4e525" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Chatterbox&lt;/strong&gt; is a family of three state-of-the-art, open-source text-to-speech models by Resemble AI.&lt;/p&gt; 
&lt;p&gt;We are excited to introduce &lt;strong&gt;Chatterbox-Turbo&lt;/strong&gt;, our most efficient model yet. Built on a streamlined 350M parameter architecture, &lt;strong&gt;Turbo&lt;/strong&gt; delivers high-quality speech with less compute and VRAM than our previous models. We have also distilled the speech-token-to-mel decoder, previously a bottleneck, reducing generation from 10 steps to just &lt;strong&gt;one&lt;/strong&gt;, while retaining high-fidelity audio output.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Paralinguistic tags&lt;/strong&gt; are now native to the Turbo model, allowing you to use &lt;code&gt;[cough]&lt;/code&gt;, &lt;code&gt;[laugh]&lt;/code&gt;, &lt;code&gt;[chuckle]&lt;/code&gt;, and more to add distinct realism. While Turbo was built primarily for low-latency voice agents, it excels at narration and creative workflows.&lt;/p&gt; 
&lt;p&gt;If you like the model but need to scale or tune it for higher accuracy, check out our competitively priced TTS service (&lt;a href="https://resemble.ai"&gt;link&lt;/a&gt;). It delivers reliable performance with ultra-low latency of sub 200msâ€”ideal for production use in agents, applications, or interactive media.&lt;/p&gt; 
&lt;img width="1200" height="600" alt="Podonos Turbo Eval" src="https://storage.googleapis.com/chatterbox-demo-samples/turbo/podonos_turbo.png" /&gt; 
&lt;h3&gt;âš¡ Model Zoo&lt;/h3&gt; 
&lt;p&gt;Choose the right model for your application.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Model&lt;/th&gt; 
   &lt;th align="left"&gt;Size&lt;/th&gt; 
   &lt;th align="left"&gt;Languages&lt;/th&gt; 
   &lt;th align="left"&gt;Key Features&lt;/th&gt; 
   &lt;th align="left"&gt;Best For&lt;/th&gt; 
   &lt;th align="left"&gt;ğŸ¤—&lt;/th&gt; 
   &lt;th align="left"&gt;Examples&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;Chatterbox-Turbo&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;350M&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;strong&gt;English&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Paralinguistic Tags (&lt;code&gt;[laugh]&lt;/code&gt;), Lower Compute and VRAM&lt;/td&gt; 
   &lt;td align="left"&gt;Zero-shot voice agents, Production&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_turbo_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Chatterbox-Multilingual &lt;a href="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/#supported-languages"&gt;(Language list)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;500M&lt;/td&gt; 
   &lt;td align="left"&gt;23+&lt;/td&gt; 
   &lt;td align="left"&gt;Zero-shot cloning, Multiple Languages&lt;/td&gt; 
   &lt;td align="left"&gt;Global applications, Localization&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox-Multilingual-TTS"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Chatterbox &lt;a href="https://raw.githubusercontent.com/resemble-ai/chatterbox/master/#original-chatterbox-tips"&gt;(Tips and Tricks)&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;500M&lt;/td&gt; 
   &lt;td align="left"&gt;English&lt;/td&gt; 
   &lt;td align="left"&gt;CFG &amp;amp; Exaggeration tuning&lt;/td&gt; 
   &lt;td align="left"&gt;General zero-shot TTS with creative controls&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://huggingface.co/spaces/ResembleAI/Chatterbox"&gt;Demo&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://resemble-ai.github.io/chatterbox_demopage/"&gt;Listen&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pip install chatterbox-tts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively, you can install from source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# conda create -yn chatterbox python=3.11
# conda activate chatterbox

git clone https://github.com/resemble-ai/chatterbox.git
cd chatterbox
pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We developed and tested Chatterbox on Python 3.11 on Debian 11 OS; the versions of the dependencies are pinned in &lt;code&gt;pyproject.toml&lt;/code&gt; to ensure consistency. You can modify the code or dependencies in this installation mode.&lt;/p&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h5&gt;Chatterbox-Turbo&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import torchaudio as ta
import torch
from chatterbox.tts_turbo import ChatterboxTurboTTS

# Load the Turbo model
model = ChatterboxTurboTTS.from_pretrained(device="cuda")

# Generate with Paralinguistic Tags
text = "Hi there, Sarah here from MochaFone calling you back [chuckle], have you got one minute to chat about the billing issue?"

# Generate audio (requires a reference clip for voice cloning)
wav = model.generate(text, audio_prompt_path="your_10s_ref_clip.wav")

ta.save("test-turbo.wav", wav, model.sr)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Chatterbox and Chatterbox-Multilingual&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
from chatterbox.mtl_tts import ChatterboxMultilingualTTS

# English example
model = ChatterboxTTS.from_pretrained(device="cuda")

text = "Ezreal and Jinx teamed up with Ahri, Yasuo, and Teemo to take down the enemy's Nexus in an epic late-game pentakill."
wav = model.generate(text)
ta.save("test-english.wav", wav, model.sr)

# Multilingual examples
multilingual_model = ChatterboxMultilingualTTS.from_pretrained(device=device)

french_text = "Bonjour, comment Ã§a va? Ceci est le modÃ¨le de synthÃ¨se vocale multilingue Chatterbox, il prend en charge 23 langues."
wav_french = multilingual_model.generate(spanish_text, language_id="fr")
ta.save("test-french.wav", wav_french, model.sr)

chinese_text = "ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œå¸Œæœ›ä½ æœ‰ä¸€ä¸ªæ„‰å¿«çš„å‘¨æœ«ã€‚"
wav_chinese = multilingual_model.generate(chinese_text, language_id="zh")
ta.save("test-chinese.wav", wav_chinese, model.sr)

# If you want to synthesize with a different voice, specify the audio prompt
AUDIO_PROMPT_PATH = "YOUR_FILE.wav"
wav = model.generate(text, audio_prompt_path=AUDIO_PROMPT_PATH)
ta.save("test-2.wav", wav, model.sr)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;code&gt;example_tts.py&lt;/code&gt; and &lt;code&gt;example_vc.py&lt;/code&gt; for more examples.&lt;/p&gt; 
&lt;h2&gt;Supported Languages&lt;/h2&gt; 
&lt;p&gt;Arabic (ar) â€¢ Danish (da) â€¢ German (de) â€¢ Greek (el) â€¢ English (en) â€¢ Spanish (es) â€¢ Finnish (fi) â€¢ French (fr) â€¢ Hebrew (he) â€¢ Hindi (hi) â€¢ Italian (it) â€¢ Japanese (ja) â€¢ Korean (ko) â€¢ Malay (ms) â€¢ Dutch (nl) â€¢ Norwegian (no) â€¢ Polish (pl) â€¢ Portuguese (pt) â€¢ Russian (ru) â€¢ Swedish (sv) â€¢ Swahili (sw) â€¢ Turkish (tr) â€¢ Chinese (zh)&lt;/p&gt; 
&lt;h2&gt;Original Chatterbox Tips&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;General Use (TTS and Voice Agents):&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Ensure that the reference clip matches the specified language tag. Otherwise, language transfer outputs may inherit the accent of the reference clipâ€™s language. To mitigate this, set &lt;code&gt;cfg_weight&lt;/code&gt; to &lt;code&gt;0&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;The default settings (&lt;code&gt;exaggeration=0.5&lt;/code&gt;, &lt;code&gt;cfg_weight=0.5&lt;/code&gt;) work well for most prompts across all languages.&lt;/li&gt; 
   &lt;li&gt;If the reference speaker has a fast speaking style, lowering &lt;code&gt;cfg_weight&lt;/code&gt; to around &lt;code&gt;0.3&lt;/code&gt; can improve pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Expressive or Dramatic Speech:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Try lower &lt;code&gt;cfg_weight&lt;/code&gt; values (e.g. &lt;code&gt;~0.3&lt;/code&gt;) and increase &lt;code&gt;exaggeration&lt;/code&gt; to around &lt;code&gt;0.7&lt;/code&gt; or higher.&lt;/li&gt; 
   &lt;li&gt;Higher &lt;code&gt;exaggeration&lt;/code&gt; tends to speed up speech; reducing &lt;code&gt;cfg_weight&lt;/code&gt; helps compensate with slower, more deliberate pacing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Built-in PerTh Watermarking for Responsible AI&lt;/h2&gt; 
&lt;p&gt;Every audio file generated by Chatterbox includes &lt;a href="https://github.com/resemble-ai/perth"&gt;Resemble AI's Perth (Perceptual Threshold) Watermarker&lt;/a&gt; - imperceptible neural watermarks that survive MP3 compression, audio editing, and common manipulations while maintaining nearly 100% detection accuracy.&lt;/p&gt; 
&lt;h2&gt;Watermark extraction&lt;/h2&gt; 
&lt;p&gt;You can look for the watermark using the following script.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import perth
import librosa

AUDIO_PATH = "YOUR_FILE.wav"

# Load the watermarked audio
watermarked_audio, sr = librosa.load(AUDIO_PATH, sr=None)

# Initialize watermarker (same as used for embedding)
watermarker = perth.PerthImplicitWatermarker()

# Extract watermark
watermark = watermarker.get_watermark(watermarked_audio, sample_rate=sr)
print(f"Extracted watermark: {watermark}")
# Output: 0.0 (no watermark) or 1.0 (watermarked)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Official Discord&lt;/h2&gt; 
&lt;p&gt;ğŸ‘‹ Join us on &lt;a href="https://discord.gg/rJq9cRJBJ6"&gt;Discord&lt;/a&gt; and let's build something awesome together!&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/FunAudioLLM/CosyVoice"&gt;Cosyvoice&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning"&gt;Real-Time-Voice-Cloning&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yl4579/HiFTNet"&gt;HiFT-GAN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/meta-llama/llama3"&gt;Llama 3&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/xingchensong/S3Tokenizer"&gt;S3Tokenizer&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you find this model useful, please consider citing.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{chatterboxtts2025,
  author       = {{Resemble AI}},
  title        = {{Chatterbox-TTS}},
  year         = {2025},
  howpublished = {\url{https://github.com/resemble-ai/chatterbox}},
  note         = {GitHub repository}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;Don't use this model to do bad things. Prompts are sourced from freely available data on the internet.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>v2fly/domain-list-community</title>
      <link>https://github.com/v2fly/domain-list-community</link>
      <description>&lt;p&gt;Community managed domain list. Generate geosite.dat for V2Ray.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Domain list community&lt;/h1&gt; 
&lt;p&gt;This project manages a list of domains, to be used as geosites for routing purpose in Project V.&lt;/p&gt; 
&lt;h2&gt;Purpose of this project&lt;/h2&gt; 
&lt;p&gt;This project is not opinionated. In other words, it does NOT endorse, claim or imply that a domain should be blocked or proxied. It can be used to generate routing rules on demand.&lt;/p&gt; 
&lt;h2&gt;Download links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;dlc.dat&lt;/strong&gt;ï¼š&lt;a href="https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat"&gt;https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;dlc.dat.sha256sum&lt;/strong&gt;ï¼š&lt;a href="https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum"&gt;https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage example&lt;/h2&gt; 
&lt;p&gt;Each file in the &lt;code&gt;data&lt;/code&gt; directory can be used as a rule in this format: &lt;code&gt;geosite:filename&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"routing": {
  "domainStrategy": "IPIfNonMatch",
  "rules": [
    {
      "type": "field",
      "outboundTag": "Reject",
      "domain": [
        "geosite:category-ads-all",
        "geosite:category-porn"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Direct",
      "domain": [
        "domain:icloud.com",
        "domain:icloud-content.com",
        "domain:cdn-apple.com",
        "geosite:cn",
        "geosite:private"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-1",
      "domain": [
        "geosite:category-anticensorship",
        "geosite:category-media",
        "geosite:category-vpnservices"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-2",
      "domain": [
        "geosite:category-dev"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-3",
      "domain": [
        "geosite:geolocation-!cn"
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Generate &lt;code&gt;dlc.dat&lt;/code&gt; manually&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;golang&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Clone project code: &lt;code&gt;git clone https://github.com/v2fly/domain-list-community.git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Navigate to project root directory: &lt;code&gt;cd domain-list-community&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install project dependencies: &lt;code&gt;go mod download&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Generate &lt;code&gt;dlc.dat&lt;/code&gt; (without &lt;code&gt;datapath&lt;/code&gt; option means to use domain lists in &lt;code&gt;data&lt;/code&gt; directory of current working directory): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;go run ./&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;go run ./ --datapath=/path/to/your/custom/data/directory&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run &lt;code&gt;go run ./ --help&lt;/code&gt; for more usage information.&lt;/p&gt; 
&lt;h2&gt;Structure of data&lt;/h2&gt; 
&lt;p&gt;All data are under &lt;code&gt;data&lt;/code&gt; directory. Each file in the directory represents a sub-list of domains, named by the file name. File content is in the following format.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# comments
include:another-file
domain:google.com @attr1 @attr2
keyword:google
regexp:www\.google\.com$
full:www.google.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Syntax:&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The following types of rules are &lt;strong&gt;NOT&lt;/strong&gt; fully compatible with the ones that defined by user in V2Ray config file. Do &lt;strong&gt;Not&lt;/strong&gt; copy and paste directly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Comment begins with &lt;code&gt;#&lt;/code&gt;. It may begin anywhere in the file. The content in the line after &lt;code&gt;#&lt;/code&gt; is treated as comment and ignored in production.&lt;/li&gt; 
 &lt;li&gt;Inclusion begins with &lt;code&gt;include:&lt;/code&gt;, followed by the file name of an existing file in the same directory.&lt;/li&gt; 
 &lt;li&gt;Subdomain begins with &lt;code&gt;domain:&lt;/code&gt;, followed by a valid domain name. The prefix &lt;code&gt;domain:&lt;/code&gt; may be omitted.&lt;/li&gt; 
 &lt;li&gt;Keyword begins with &lt;code&gt;keyword:&lt;/code&gt;, followed by a string.&lt;/li&gt; 
 &lt;li&gt;Regular expression begins with &lt;code&gt;regexp:&lt;/code&gt;, followed by a valid regular expression (per Golang's standard).&lt;/li&gt; 
 &lt;li&gt;Full domain begins with &lt;code&gt;full:&lt;/code&gt;, followed by a complete and valid domain name.&lt;/li&gt; 
 &lt;li&gt;Domains (including &lt;code&gt;domain&lt;/code&gt;, &lt;code&gt;keyword&lt;/code&gt;, &lt;code&gt;regexp&lt;/code&gt; and &lt;code&gt;full&lt;/code&gt;) may have one or more attributes. Each attribute begins with &lt;code&gt;@&lt;/code&gt; and followed by the name of the attribute.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Adding new &lt;code&gt;regexp&lt;/code&gt; and &lt;code&gt;keyword&lt;/code&gt; rules is discouraged because it is easy to use them incorrectly, and proxy software cannot efficiently match these types of rules.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;How it works&lt;/h2&gt; 
&lt;p&gt;The entire &lt;code&gt;data&lt;/code&gt; directory will be built into an external &lt;code&gt;geosite&lt;/code&gt; file for Project V. Each file in the directory represents a section in the generated file.&lt;/p&gt; 
&lt;p&gt;To generate a section:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Remove all the comments in the file.&lt;/li&gt; 
 &lt;li&gt;Replace &lt;code&gt;include:&lt;/code&gt; lines with the actual content of the file.&lt;/li&gt; 
 &lt;li&gt;Omit all empty lines.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;domain:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L21"&gt;sub-domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;full:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L23"&gt;full domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;keyword:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L17"&gt;plain domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;regexp:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/routercommon/common.proto#L19"&gt;regex domain routing rule&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;How to organize domains&lt;/h2&gt; 
&lt;h3&gt;File name&lt;/h3&gt; 
&lt;p&gt;Theoretically any string can be used as the name, as long as it is a valid file name. In practice, we prefer names for determinic group of domains, such as the owner (usually a company name) of the domains, e.g., "google", "netflix". Names with unclear scope are generally unrecommended, such as "evil", or "local".&lt;/p&gt; 
&lt;h3&gt;Attributes&lt;/h3&gt; 
&lt;p&gt;Attribute is useful for sub-group of domains, especially for filtering purpose. For example, the list of &lt;code&gt;google&lt;/code&gt; domains may contains its main domains, as well as domains that serve ads. The ads domains may be marked by attribute &lt;code&gt;@ads&lt;/code&gt;, and can be used as &lt;code&gt;geosite:google@ads&lt;/code&gt; in V2Ray routing.&lt;/p&gt; 
&lt;h2&gt;Contribution guideline&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fork this repo, make modifications to your own repo, file a PR.&lt;/li&gt; 
 &lt;li&gt;Please begin with small size PRs, say modification in a single file.&lt;/li&gt; 
 &lt;li&gt;A PR must be reviewed and approved by another member.&lt;/li&gt; 
 &lt;li&gt;A script will verify your pull request to test whether your PR is correct or not every time you update the PR. Only the PR which passes the test will be merged. Please go to the Action label to get detailed information if you didn't pass it. We also provide the file which has been generated to make you test.&lt;/li&gt; 
 &lt;li&gt;After a few successful PRs, you may apply for manager access to this repository.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>anthropics/skills</title>
      <link>https://github.com/anthropics/skills</link>
      <description>&lt;p&gt;Public repository for Agent Skills&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This repository contains Anthropic's implementation of skills for Claude. For information about the Agent Skills standard, see &lt;a href="http://agentskills.io"&gt;agentskills.io&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;Skills&lt;/h1&gt; 
&lt;p&gt;Skills are folders of instructions, scripts, and resources that Claude loads dynamically to improve performance on specialized tasks. Skills teach Claude how to complete specific tasks in a repeatable way, whether that's creating documents with your company's brand guidelines, analyzing data using your organization's specific workflows, or automating personal tasks.&lt;/p&gt; 
&lt;p&gt;For more information, check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512176-what-are-skills"&gt;What are skills?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512180-using-skills-in-claude"&gt;Using skills in Claude&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.claude.com/en/articles/12512198-creating-custom-skills"&gt;How to create custom skills&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills"&gt;Equipping agents for the real world with Agent Skills&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;About This Repository&lt;/h1&gt; 
&lt;p&gt;This repository contains skills that demonstrate what's possible with Claude's skills system. These skills range from creative applications (art, music, design) to technical tasks (testing web apps, MCP server generation) to enterprise workflows (communications, branding, etc.).&lt;/p&gt; 
&lt;p&gt;Each skill is self-contained in its own folder with a &lt;code&gt;SKILL.md&lt;/code&gt; file containing the instructions and metadata that Claude uses. Browse through these skills to get inspiration for your own skills or to understand different patterns and approaches.&lt;/p&gt; 
&lt;p&gt;Many skills in this repo are open source (Apache 2.0). We've also included the document creation &amp;amp; editing skills that power &lt;a href="https://www.anthropic.com/news/create-files"&gt;Claude's document capabilities&lt;/a&gt; under the hood in the &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/docx"&gt;&lt;code&gt;skills/docx&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/pdf"&gt;&lt;code&gt;skills/pdf&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/pptx"&gt;&lt;code&gt;skills/pptx&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills/xlsx"&gt;&lt;code&gt;skills/xlsx&lt;/code&gt;&lt;/a&gt; subfolders. These are source-available, not open source, but we wanted to share these with developers as a reference for more complex skills that are actively used in a production AI application.&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;These skills are provided for demonstration and educational purposes only.&lt;/strong&gt; While some of these capabilities may be available in Claude, the implementations and behaviors you receive from Claude may differ from what is shown in these skills. These skills are meant to illustrate patterns and possibilities. Always test skills thoroughly in your own environment before relying on them for critical tasks.&lt;/p&gt; 
&lt;h1&gt;Skill Sets&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/skills"&gt;./skills&lt;/a&gt;: Skill examples for Creative &amp;amp; Design, Development &amp;amp; Technical, Enterprise &amp;amp; Communication, and Document Skills&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/spec"&gt;./spec&lt;/a&gt;: The Agent Skills specification&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/anthropics/skills/main/template"&gt;./template&lt;/a&gt;: Skill template&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Try in Claude Code, Claude.ai, and the API&lt;/h1&gt; 
&lt;h2&gt;Claude Code&lt;/h2&gt; 
&lt;p&gt;You can register this repository as a Claude Code Plugin marketplace by running the following command in Claude Code:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/plugin marketplace add anthropics/skills
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, to install a specific set of skills:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Select &lt;code&gt;Browse and install plugins&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;anthropic-agent-skills&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;document-skills&lt;/code&gt; or &lt;code&gt;example-skills&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Select &lt;code&gt;Install now&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Alternatively, directly install either Plugin via:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;/plugin install document-skills@anthropic-agent-skills
/plugin install example-skills@anthropic-agent-skills
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;After installing the plugin, you can use the skill by just mentioning it. For instance, if you install the &lt;code&gt;document-skills&lt;/code&gt; plugin from the marketplace, you can ask Claude Code to do something like: "Use the PDF skill to extract the form fields from &lt;code&gt;path/to/some-file.pdf&lt;/code&gt;"&lt;/p&gt; 
&lt;h2&gt;Claude.ai&lt;/h2&gt; 
&lt;p&gt;These example skills are all already available to paid plans in Claude.ai.&lt;/p&gt; 
&lt;p&gt;To use any skill from this repository or upload custom skills, follow the instructions in &lt;a href="https://support.claude.com/en/articles/12512180-using-skills-in-claude#h_a4222fa77b"&gt;Using skills in Claude&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Claude API&lt;/h2&gt; 
&lt;p&gt;You can use Anthropic's pre-built skills, and upload custom skills, via the Claude API. See the &lt;a href="https://docs.claude.com/en/api/skills-guide#creating-a-skill"&gt;Skills API Quickstart&lt;/a&gt; for more.&lt;/p&gt; 
&lt;h1&gt;Creating a Basic Skill&lt;/h1&gt; 
&lt;p&gt;Skills are simple to create - just a folder with a &lt;code&gt;SKILL.md&lt;/code&gt; file containing YAML frontmatter and instructions. You can use the &lt;strong&gt;template-skill&lt;/strong&gt; in this repository as a starting point:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;---
name: my-skill-name
description: A clear description of what this skill does and when to use it
---

# My Skill Name

[Add your instructions here that Claude will follow when this skill is active]

## Examples
- Example usage 1
- Example usage 2

## Guidelines
- Guideline 1
- Guideline 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The frontmatter requires only two fields:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;name&lt;/code&gt; - A unique identifier for your skill (lowercase, hyphens for spaces)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;description&lt;/code&gt; - A complete description of what the skill does and when to use it&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The markdown content below contains the instructions, examples, and guidelines that Claude will follow. For more details, see &lt;a href="https://support.claude.com/en/articles/12512198-creating-custom-skills"&gt;How to create custom skills&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Partner Skills&lt;/h1&gt; 
&lt;p&gt;Skills are a great way to teach Claude how to get better at using specific pieces of software. As we see awesome example skills from partners, we may highlight some of them here:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Notion&lt;/strong&gt; - &lt;a href="https://www.notion.so/notiondevs/Notion-Skills-for-Claude-28da4445d27180c7af1df7d8615723d0"&gt;Notion Skills for Claude&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>AUTOMATIC1111/stable-diffusion-webui</title>
      <link>https://github.com/AUTOMATIC1111/stable-diffusion-webui</link>
      <description>&lt;p&gt;Stable Diffusion web UI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Stable Diffusion web UI&lt;/h1&gt; 
&lt;p&gt;A web interface for Stable Diffusion, implemented using Gradio library.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/screenshot.png" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features"&gt;Detailed feature showcase with images&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Original txt2img and img2img modes&lt;/li&gt; 
 &lt;li&gt;One click install and run script (but you still must install python and git)&lt;/li&gt; 
 &lt;li&gt;Outpainting&lt;/li&gt; 
 &lt;li&gt;Inpainting&lt;/li&gt; 
 &lt;li&gt;Color Sketch&lt;/li&gt; 
 &lt;li&gt;Prompt Matrix&lt;/li&gt; 
 &lt;li&gt;Stable Diffusion Upscale&lt;/li&gt; 
 &lt;li&gt;Attention, specify parts of text that the model should pay more attention to 
  &lt;ul&gt; 
   &lt;li&gt;a man in a &lt;code&gt;((tuxedo))&lt;/code&gt; - will pay more attention to tuxedo&lt;/li&gt; 
   &lt;li&gt;a man in a &lt;code&gt;(tuxedo:1.21)&lt;/code&gt; - alternative syntax&lt;/li&gt; 
   &lt;li&gt;select text and press &lt;code&gt;Ctrl+Up&lt;/code&gt; or &lt;code&gt;Ctrl+Down&lt;/code&gt; (or &lt;code&gt;Command+Up&lt;/code&gt; or &lt;code&gt;Command+Down&lt;/code&gt; if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Loopback, run img2img processing multiple times&lt;/li&gt; 
 &lt;li&gt;X/Y/Z plot, a way to draw a 3 dimensional plot of images with different parameters&lt;/li&gt; 
 &lt;li&gt;Textual Inversion 
  &lt;ul&gt; 
   &lt;li&gt;have as many embeddings as you want and use any names you like for them&lt;/li&gt; 
   &lt;li&gt;use multiple embeddings with different numbers of vectors per token&lt;/li&gt; 
   &lt;li&gt;works with half precision floating point numbers&lt;/li&gt; 
   &lt;li&gt;train embeddings on 8GB (also reports of 6GB working)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Extras tab with: 
  &lt;ul&gt; 
   &lt;li&gt;GFPGAN, neural network that fixes faces&lt;/li&gt; 
   &lt;li&gt;CodeFormer, face restoration tool as an alternative to GFPGAN&lt;/li&gt; 
   &lt;li&gt;RealESRGAN, neural network upscaler&lt;/li&gt; 
   &lt;li&gt;ESRGAN, neural network upscaler with a lot of third party models&lt;/li&gt; 
   &lt;li&gt;SwinIR and Swin2SR (&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092"&gt;see here&lt;/a&gt;), neural network upscalers&lt;/li&gt; 
   &lt;li&gt;LDSR, Latent diffusion super resolution upscaling&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Resizing aspect ratio options&lt;/li&gt; 
 &lt;li&gt;Sampling method selection 
  &lt;ul&gt; 
   &lt;li&gt;Adjust sampler eta values (noise multiplier)&lt;/li&gt; 
   &lt;li&gt;More advanced noise setting options&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Interrupt processing at any time&lt;/li&gt; 
 &lt;li&gt;4GB video card support (also reports of 2GB working)&lt;/li&gt; 
 &lt;li&gt;Correct seeds for batches&lt;/li&gt; 
 &lt;li&gt;Live prompt token length validation&lt;/li&gt; 
 &lt;li&gt;Generation parameters 
  &lt;ul&gt; 
   &lt;li&gt;parameters you used to generate images are saved with that image&lt;/li&gt; 
   &lt;li&gt;in PNG chunks for PNG, in EXIF for JPEG&lt;/li&gt; 
   &lt;li&gt;can drag the image to PNG info tab to restore generation parameters and automatically copy them into UI&lt;/li&gt; 
   &lt;li&gt;can be disabled in settings&lt;/li&gt; 
   &lt;li&gt;drag and drop an image/text-parameters to promptbox&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Read Generation Parameters Button, loads parameters in promptbox to UI&lt;/li&gt; 
 &lt;li&gt;Settings page&lt;/li&gt; 
 &lt;li&gt;Running arbitrary python code from UI (must run with &lt;code&gt;--allow-code&lt;/code&gt; to enable)&lt;/li&gt; 
 &lt;li&gt;Mouseover hints for most UI elements&lt;/li&gt; 
 &lt;li&gt;Possible to change defaults/mix/max/step values for UI elements via text config&lt;/li&gt; 
 &lt;li&gt;Tiling support, a checkbox to create images that can be tiled like textures&lt;/li&gt; 
 &lt;li&gt;Progress bar and live image generation preview 
  &lt;ul&gt; 
   &lt;li&gt;Can use a separate neural network to produce previews with almost none VRAM or compute requirement&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Negative prompt, an extra text field that allows you to list what you don't want to see in generated image&lt;/li&gt; 
 &lt;li&gt;Styles, a way to save part of prompt and easily apply them via dropdown later&lt;/li&gt; 
 &lt;li&gt;Variations, a way to generate same image but with tiny differences&lt;/li&gt; 
 &lt;li&gt;Seed resizing, a way to generate same image but at slightly different resolution&lt;/li&gt; 
 &lt;li&gt;CLIP interrogator, a button that tries to guess prompt from an image&lt;/li&gt; 
 &lt;li&gt;Prompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midway&lt;/li&gt; 
 &lt;li&gt;Batch Processing, process a group of files using img2img&lt;/li&gt; 
 &lt;li&gt;Img2img Alternative, reverse Euler method of cross attention control&lt;/li&gt; 
 &lt;li&gt;Highres Fix, a convenience option to produce high resolution pictures in one click without usual distortions&lt;/li&gt; 
 &lt;li&gt;Reloading checkpoints on the fly&lt;/li&gt; 
 &lt;li&gt;Checkpoint Merger, a tab that allows you to merge up to 3 checkpoints into one&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts"&gt;Custom scripts&lt;/a&gt; with many extensions from community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/"&gt;Composable-Diffusion&lt;/a&gt;, a way to use multiple prompts at once 
  &lt;ul&gt; 
   &lt;li&gt;separate prompts using uppercase &lt;code&gt;AND&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;also supports weights for prompts: &lt;code&gt;a cat :1.2 AND a dog AND a penguin :2.2&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;No token limit for prompts (original stable diffusion lets you use up to 75 tokens)&lt;/li&gt; 
 &lt;li&gt;DeepDanbooru integration, creates danbooru style tags for anime prompts&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers"&gt;xformers&lt;/a&gt;, major speed increase for select cards: (add &lt;code&gt;--xformers&lt;/code&gt; to commandline args)&lt;/li&gt; 
 &lt;li&gt;via extension: &lt;a href="https://github.com/yfszzx/stable-diffusion-webui-images-browser"&gt;History tab&lt;/a&gt;: view, direct and delete images conveniently within the UI&lt;/li&gt; 
 &lt;li&gt;Generate forever option&lt;/li&gt; 
 &lt;li&gt;Training tab 
  &lt;ul&gt; 
   &lt;li&gt;hypernetworks and embeddings options&lt;/li&gt; 
   &lt;li&gt;Preprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Clip skip&lt;/li&gt; 
 &lt;li&gt;Hypernetworks&lt;/li&gt; 
 &lt;li&gt;Loras (same as Hypernetworks but more pretty)&lt;/li&gt; 
 &lt;li&gt;A separate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your prompt&lt;/li&gt; 
 &lt;li&gt;Can select to load a different VAE from settings screen&lt;/li&gt; 
 &lt;li&gt;Estimated completion time in progress bar&lt;/li&gt; 
 &lt;li&gt;API&lt;/li&gt; 
 &lt;li&gt;Support for dedicated &lt;a href="https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion"&gt;inpainting model&lt;/a&gt; by RunwayML&lt;/li&gt; 
 &lt;li&gt;via extension: &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients"&gt;Aesthetic Gradients&lt;/a&gt;, a way to generate images with a specific aesthetic by using clip images embeds (implementation of &lt;a href="https://github.com/vicgalle/stable-diffusion-aesthetic-gradients"&gt;https://github.com/vicgalle/stable-diffusion-aesthetic-gradients&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Stability-AI/stablediffusion"&gt;Stable Diffusion 2.0&lt;/a&gt; support - see &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20"&gt;wiki&lt;/a&gt; for instructions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/2211.06679"&gt;Alt-Diffusion&lt;/a&gt; support - see &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion"&gt;wiki&lt;/a&gt; for instructions&lt;/li&gt; 
 &lt;li&gt;Now without any bad letters!&lt;/li&gt; 
 &lt;li&gt;Load checkpoints in safetensors format&lt;/li&gt; 
 &lt;li&gt;Eased resolution restriction: generated image's dimensions must be a multiple of 8 rather than 64&lt;/li&gt; 
 &lt;li&gt;Now with a license!&lt;/li&gt; 
 &lt;li&gt;Reorder elements in the UI from settings screen&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/segmind/SSD-1B"&gt;Segmind Stable Diffusion&lt;/a&gt; support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation and Running&lt;/h2&gt; 
&lt;p&gt;Make sure the required &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies"&gt;dependencies&lt;/a&gt; are met and follow the instructions available for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs"&gt;NVidia&lt;/a&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs"&gt;AMD&lt;/a&gt; GPUs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon"&gt;Intel CPUs, Intel GPUs (both integrated and discrete)&lt;/a&gt; (external wiki page)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs"&gt;Ascend NPUs&lt;/a&gt; (external wiki page)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Alternatively, use online services (like Google Colab):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services"&gt;List of Online Services&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation on Windows 10/11 with NVidia-GPUs using release package&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download &lt;code&gt;sd.webui.zip&lt;/code&gt; from &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre"&gt;v1.0.0-pre&lt;/a&gt; and extract its contents.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;update.bat&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;run.bat&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;For more details see &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs"&gt;Install-and-Run-on-NVidia-GPUs&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Automatic Installation on Windows&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install &lt;a href="https://www.python.org/downloads/release/python-3106/"&gt;Python 3.10.6&lt;/a&gt; (Newer version of Python does not support torch), checking "Add Python to PATH".&lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://git-scm.com/download/win"&gt;git&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Download the stable-diffusion-webui repository, for example by running &lt;code&gt;git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;webui-user.bat&lt;/code&gt; from Windows Explorer as normal, non-administrator, user.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Automatic Installation on Linux&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Debian-based:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Red Hat-based:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# openSUSE-based:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Arch-based:
sudo pacman -S wget git python3
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your system is very new, you need to install python3.11 or python3.10:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # do not confuse with python3.11 package

# Only for 3.11
# Then set up env variable in launch script
export python_cmd="python3.11"
# or in webui-user.sh
python_cmd="python3.11"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Navigate to the directory you would like the webui to be installed and execute the following command:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or just clone the repo wherever you want:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Run &lt;code&gt;webui.sh&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Check &lt;code&gt;webui-user.sh&lt;/code&gt; for options.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Installation on Apple Silicon&lt;/h3&gt; 
&lt;p&gt;Find the instructions &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Here's how to add code to this repo: &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing"&gt;Contributing&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The documentation was moved from this README over to the project's &lt;a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki"&gt;wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) &lt;a href="https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki"&gt;crawlable wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;Licenses for borrowed code can be found in &lt;code&gt;Settings -&amp;gt; Licenses&lt;/code&gt; screen, and also in &lt;code&gt;html/licenses.html&lt;/code&gt; file.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Stable Diffusion - &lt;a href="https://github.com/Stability-AI/stablediffusion"&gt;https://github.com/Stability-AI/stablediffusion&lt;/a&gt;, &lt;a href="https://github.com/CompVis/taming-transformers"&gt;https://github.com/CompVis/taming-transformers&lt;/a&gt;, &lt;a href="https://github.com/mcmonkey4eva/sd3-ref"&gt;https://github.com/mcmonkey4eva/sd3-ref&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;k-diffusion - &lt;a href="https://github.com/crowsonkb/k-diffusion.git"&gt;https://github.com/crowsonkb/k-diffusion.git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Spandrel - &lt;a href="https://github.com/chaiNNer-org/spandrel"&gt;https://github.com/chaiNNer-org/spandrel&lt;/a&gt; implementing 
  &lt;ul&gt; 
   &lt;li&gt;GFPGAN - &lt;a href="https://github.com/TencentARC/GFPGAN.git"&gt;https://github.com/TencentARC/GFPGAN.git&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;CodeFormer - &lt;a href="https://github.com/sczhou/CodeFormer"&gt;https://github.com/sczhou/CodeFormer&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;ESRGAN - &lt;a href="https://github.com/xinntao/ESRGAN"&gt;https://github.com/xinntao/ESRGAN&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;SwinIR - &lt;a href="https://github.com/JingyunLiang/SwinIR"&gt;https://github.com/JingyunLiang/SwinIR&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Swin2SR - &lt;a href="https://github.com/mv-lab/swin2sr"&gt;https://github.com/mv-lab/swin2sr&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;LDSR - &lt;a href="https://github.com/Hafiidz/latent-diffusion"&gt;https://github.com/Hafiidz/latent-diffusion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;MiDaS - &lt;a href="https://github.com/isl-org/MiDaS"&gt;https://github.com/isl-org/MiDaS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Ideas for optimizations - &lt;a href="https://github.com/basujindal/stable-diffusion"&gt;https://github.com/basujindal/stable-diffusion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Cross Attention layer optimization - Doggettx - &lt;a href="https://github.com/Doggettx/stable-diffusion"&gt;https://github.com/Doggettx/stable-diffusion&lt;/a&gt;, original idea for prompt editing.&lt;/li&gt; 
 &lt;li&gt;Cross Attention layer optimization - InvokeAI, lstein - &lt;a href="https://github.com/invoke-ai/InvokeAI"&gt;https://github.com/invoke-ai/InvokeAI&lt;/a&gt; (originally &lt;a href="http://github.com/lstein/stable-diffusion"&gt;http://github.com/lstein/stable-diffusion&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Sub-quadratic Cross Attention layer optimization - Alex Birch (&lt;a href="https://github.com/Birch-san/diffusers/pull/1"&gt;https://github.com/Birch-san/diffusers/pull/1&lt;/a&gt;), Amin Rezaei (&lt;a href="https://github.com/AminRezaei0x443/memory-efficient-attention"&gt;https://github.com/AminRezaei0x443/memory-efficient-attention&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Textual Inversion - Rinon Gal - &lt;a href="https://github.com/rinongal/textual_inversion"&gt;https://github.com/rinongal/textual_inversion&lt;/a&gt; (we're not using his code, but we are using his ideas).&lt;/li&gt; 
 &lt;li&gt;Idea for SD upscale - &lt;a href="https://github.com/jquesnelle/txt2imghd"&gt;https://github.com/jquesnelle/txt2imghd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Noise generation for outpainting mk2 - &lt;a href="https://github.com/parlance-zz/g-diffuser-bot"&gt;https://github.com/parlance-zz/g-diffuser-bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;CLIP interrogator idea and borrowing some code - &lt;a href="https://github.com/pharmapsychotic/clip-interrogator"&gt;https://github.com/pharmapsychotic/clip-interrogator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Idea for Composable Diffusion - &lt;a href="https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch"&gt;https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;xformers - &lt;a href="https://github.com/facebookresearch/xformers"&gt;https://github.com/facebookresearch/xformers&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DeepDanbooru - interrogator for anime diffusers &lt;a href="https://github.com/KichangKim/DeepDanbooru"&gt;https://github.com/KichangKim/DeepDanbooru&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Sampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (&lt;a href="https://github.com/Birch-san/diffusers-play/tree/92feee6"&gt;https://github.com/Birch-san/diffusers-play/tree/92feee6&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - &lt;a href="https://github.com/timothybrooks/instruct-pix2pix"&gt;https://github.com/timothybrooks/instruct-pix2pix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Security advice - RyotaK&lt;/li&gt; 
 &lt;li&gt;UniPC sampler - Wenliang Zhao - &lt;a href="https://github.com/wl-zhao/UniPC"&gt;https://github.com/wl-zhao/UniPC&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;TAESD - Ollin Boer Bohan - &lt;a href="https://github.com/madebyollin/taesd"&gt;https://github.com/madebyollin/taesd&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;LyCORIS - KohakuBlueleaf&lt;/li&gt; 
 &lt;li&gt;Restart sampling - lambertae - &lt;a href="https://github.com/Newbeeer/diffusion_restart_sampling"&gt;https://github.com/Newbeeer/diffusion_restart_sampling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hypertile - tfernd - &lt;a href="https://github.com/tfernd/HyperTile"&gt;https://github.com/tfernd/HyperTile&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Initial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.&lt;/li&gt; 
 &lt;li&gt;(You)&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>DayuanJiang/next-ai-draw-io</title>
      <link>https://github.com/DayuanJiang/next-ai-draw-io</link>
      <description>&lt;p&gt;A next.js web application that integrates AI capabilities with draw.io diagrams. This app allows you to create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Next AI Draw.io&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;AI-Powered Diagram Creation Tool - Chat, Draw, Visualize&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/README_CN.md"&gt;ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/README_JA.md"&gt;æ—¥æœ¬èª&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://next-ai-drawio.jiang.jp/"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15449" alt="TrendShift" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License: Apache 2.0" /&gt;&lt;/a&gt; &lt;a href="https://nextjs.org/"&gt;&lt;img src="https://img.shields.io/badge/Next.js-16.x-black" alt="Next.js" /&gt;&lt;/a&gt; &lt;a href="https://react.dev/"&gt;&lt;img src="https://img.shields.io/badge/React-19.x-61dafb" alt="React" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/DayuanJiang"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-%E2%9D%A4-ea4aaa" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://next-ai-drawio.jiang.jp/"&gt;&lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/live-demo-button.svg?sanitize=true" alt="Live Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;A Next.js web application that integrates AI capabilities with draw.io diagrams. Create, modify, and enhance diagrams through natural language commands and AI-assisted visualization.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/9d60a3e8-4a1c-4b5e-acbb-26af2d3eabd1"&gt;https://github.com/user-attachments/assets/9d60a3e8-4a1c-4b5e-acbb-26af2d3eabd1&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#next-ai-drawio-"&gt;Next AI Draw.io &lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#mcp-server-preview"&gt;MCP Server (Preview)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#getting-started"&gt;Getting Started&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#try-it-online"&gt;Try it Online&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#desktop-application"&gt;Desktop Application&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#run-with-docker-recommended"&gt;Run with Docker (Recommended)&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#deployment"&gt;Deployment&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#multi-provider-support"&gt;Multi-Provider Support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#how-it-works"&gt;How It Works&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#project-structure"&gt;Project Structure&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#support--contact"&gt;Support &amp;amp; Contact&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#star-history"&gt;Star History&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;Here are some example prompts and their generated diagrams:&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table width="100%"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="2" valign="top" align="center"&gt; &lt;strong&gt;Animated transformer connectors&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Give me a **animated connector** diagram of transformer's architecture.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/animated_connectors.svg?sanitize=true" alt="Transformer Architecture with Animated Connectors" width="480" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;GCP architecture diagram&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a GCP architecture diagram with **GCP icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/gcp_demo.svg?sanitize=true" alt="GCP Architecture Diagram" width="480" /&gt; &lt;/td&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;AWS architecture diagram&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a AWS architecture diagram with **AWS icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/aws_demo.svg?sanitize=true" alt="AWS Architecture Diagram" width="480" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;Azure architecture diagram&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Generate a Azure architecture diagram with **Azure icons**. In this diagram, users connect to a frontend hosted on an instance.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/azure_demo.svg?sanitize=true" alt="Azure Architecture Diagram" width="480" /&gt; &lt;/td&gt; 
    &lt;td width="50%" valign="top"&gt; &lt;strong&gt;Cat sketch prompt&lt;/strong&gt;&lt;br /&gt; &lt;p&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; Draw a cute cat for me.&lt;/p&gt; &lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/cat_demo.svg?sanitize=true" alt="Cat Drawing" width="240" /&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-Powered Diagram Creation&lt;/strong&gt;: Leverage Large Language Models to create and manipulate draw.io diagrams directly through natural language commands&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Image-Based Diagram Replication&lt;/strong&gt;: Upload existing diagrams or images and have the AI replicate and enhance them automatically&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PDF &amp;amp; Text File Upload&lt;/strong&gt;: Upload PDF documents and text files to extract content and generate diagrams from existing documents&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI Reasoning Display&lt;/strong&gt;: View the AI's thinking process for supported models (OpenAI o1/o3, Gemini, Claude, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Diagram History&lt;/strong&gt;: Comprehensive version control that tracks all changes, allowing you to view and restore previous versions of your diagrams before the AI editing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Chat Interface&lt;/strong&gt;: Communicate with AI to refine your diagrams in real-time&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Architecture Diagram Support&lt;/strong&gt;: Specialized support for generating cloud architecture diagrams (AWS, GCP, Azure)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Animated Connectors&lt;/strong&gt;: Create dynamic and animated connectors between diagram elements for better visualization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;MCP Server (Preview)&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Preview Feature&lt;/strong&gt;: This feature is experimental and may not stable.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Use Next AI Draw.io with AI agents like Claude Desktop, Cursor, and VS Code via MCP (Model Context Protocol).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "drawio": {
      "command": "npx",
      "args": ["@next-ai-drawio/mcp-server@latest"]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Claude Code CLI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add drawio -- npx @next-ai-drawio/mcp-server@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then ask Claude to create diagrams:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;"Create a flowchart showing user authentication with login, MFA, and session management"&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The diagram appears in your browser in real-time!&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/packages/mcp-server/README.md"&gt;MCP Server README&lt;/a&gt; for VS Code, Cursor, and other client configurations.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;h3&gt;Try it Online&lt;/h3&gt; 
&lt;p&gt;No installation needed! Try the app directly on our demo site:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://next-ai-drawio.jiang.jp/"&gt;&lt;img src="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/public/live-demo-button.svg?sanitize=true" alt="Live Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: Due to high traffic, the demo site currently uses minimax-m2. For best results, we recommend self-hosting with Claude Sonnet 4.5 or Claude Opus 4.5.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Bring Your Own API Key&lt;/strong&gt;: You can use your own API key to bypass usage limits on the demo site. Click the Settings icon in the chat panel to configure your provider and API key. Your key is stored locally in your browser and is never stored on the server.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Desktop Application&lt;/h3&gt; 
&lt;p&gt;Download the native desktop app for your platform from the &lt;a href="https://github.com/DayuanJiang/next-ai-draw-io/releases"&gt;Releases page&lt;/a&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.dmg&lt;/code&gt; (Intel &amp;amp; Apple Silicon)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.exe&lt;/code&gt; installer (x64 &amp;amp; ARM64)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.AppImage&lt;/code&gt; or &lt;code&gt;.deb&lt;/code&gt; (x64 &amp;amp; ARM64)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Secure API key storage&lt;/strong&gt;: Credentials encrypted using OS keychain&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configuration presets&lt;/strong&gt;: Save and switch between AI providers via menu&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Native file dialogs&lt;/strong&gt;: Open/save &lt;code&gt;.drawio&lt;/code&gt; files directly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Offline capable&lt;/strong&gt;: Works without internet after first launch&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick Setup:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download and install for your platform&lt;/li&gt; 
 &lt;li&gt;Open the app â†’ &lt;strong&gt;Menu â†’ Configuration â†’ Manage Presets&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Add your AI provider credentials&lt;/li&gt; 
 &lt;li&gt;Start creating diagrams!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Run with Docker (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you just want to run it locally, the best way is to use Docker.&lt;/p&gt; 
&lt;p&gt;First, install Docker if you haven't already: &lt;a href="https://docs.docker.com/get-docker/"&gt;Get Docker&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -p 3000:3000 \
  -e AI_PROVIDER=openai \
  -e AI_MODEL=gpt-4o \
  -e OPENAI_API_KEY=your_api_key \
  ghcr.io/dayuanjiang/next-ai-draw-io:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use an env file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp env.example .env
# Edit .env with your configuration
docker run -d -p 3000:3000 --env-file .env ghcr.io/dayuanjiang/next-ai-draw-io:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt; in your browser.&lt;/p&gt; 
&lt;p&gt;Replace the environment variables with your preferred AI provider configuration. See &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/#multi-provider-support"&gt;Multi-Provider Support&lt;/a&gt; for available options.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Offline Deployment:&lt;/strong&gt; If &lt;code&gt;embed.diagrams.net&lt;/code&gt; is blocked, see &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/offline-deployment.md"&gt;Offline Deployment&lt;/a&gt; for configuration options.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/DayuanJiang/next-ai-draw-io
cd next-ai-draw-io
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Configure your AI provider:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Create a &lt;code&gt;.env.local&lt;/code&gt; file in the root directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cp env.example .env.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Edit &lt;code&gt;.env.local&lt;/code&gt; and configure your chosen provider:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Set &lt;code&gt;AI_PROVIDER&lt;/code&gt; to your chosen provider (bedrock, openai, anthropic, google, azure, ollama, openrouter, deepseek, siliconflow)&lt;/li&gt; 
 &lt;li&gt;Set &lt;code&gt;AI_MODEL&lt;/code&gt; to the specific model you want to use&lt;/li&gt; 
 &lt;li&gt;Add the required API keys for your provider&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;TEMPERATURE&lt;/code&gt;: Optional temperature setting (e.g., &lt;code&gt;0&lt;/code&gt; for deterministic output). Leave unset for models that don't support it (e.g., reasoning models).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;ACCESS_CODE_LIST&lt;/code&gt;: Optional access password(s), can be comma-separated for multiple passwords.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Warning: If you do not set &lt;code&gt;ACCESS_CODE_LIST&lt;/code&gt;, anyone can access your deployed site directly, which may lead to rapid depletion of your token. It is recommended to set this option.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/ai-providers.md"&gt;Provider Configuration Guide&lt;/a&gt; for detailed setup instructions for each provider.&lt;/p&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Run the development server:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt; in your browser to see the application.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Deployment&lt;/h2&gt; 
&lt;p&gt;The easiest way to deploy your Next.js app is to use the &lt;a href="https://vercel.com/new"&gt;Vercel Platform&lt;/a&gt; from the creators of Next.js.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://nextjs.org/docs/app/building-your-application/deploying"&gt;Next.js deployment documentation&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;Or you can deploy by this button. &lt;a href="https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FDayuanJiang%2Fnext-ai-draw-io"&gt;&lt;img src="https://vercel.com/button" alt="Deploy with Vercel" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Be sure to &lt;strong&gt;set the environment variables&lt;/strong&gt; in the Vercel dashboard as you did in your local &lt;code&gt;.env.local&lt;/code&gt; file.&lt;/p&gt; 
&lt;h2&gt;Multi-Provider Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;AWS Bedrock (default)&lt;/li&gt; 
 &lt;li&gt;OpenAI&lt;/li&gt; 
 &lt;li&gt;Anthropic&lt;/li&gt; 
 &lt;li&gt;Google AI&lt;/li&gt; 
 &lt;li&gt;Azure OpenAI&lt;/li&gt; 
 &lt;li&gt;Ollama&lt;/li&gt; 
 &lt;li&gt;OpenRouter&lt;/li&gt; 
 &lt;li&gt;DeepSeek&lt;/li&gt; 
 &lt;li&gt;SiliconFlow&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All providers except AWS Bedrock and OpenRouter support custom endpoints.&lt;/p&gt; 
&lt;p&gt;ğŸ“– &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/DayuanJiang/next-ai-draw-io/main/docs/ai-providers.md"&gt;Detailed Provider Configuration Guide&lt;/a&gt;&lt;/strong&gt; - See setup instructions for each provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Model Requirements&lt;/strong&gt;: This task requires strong model capabilities for generating long-form text with strict formatting constraints (draw.io XML). Recommended models include Claude Sonnet 4.5, GPT-5.1, Gemini 3 Pro, and DeepSeek V3.2/R1.&lt;/p&gt; 
&lt;p&gt;Note that &lt;code&gt;claude&lt;/code&gt; series has trained on draw.io diagrams with cloud architecture logos like AWS, Azure, GCP. So if you want to create cloud architecture diagrams, this is the best choice.&lt;/p&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;p&gt;The application uses the following technologies:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Next.js&lt;/strong&gt;: For the frontend framework and routing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vercel AI SDK&lt;/strong&gt; (&lt;code&gt;ai&lt;/code&gt; + &lt;code&gt;@ai-sdk/*&lt;/code&gt;): For streaming AI responses and multi-provider support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;react-drawio&lt;/strong&gt;: For diagram representation and manipulation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Diagrams are represented as XML that can be rendered in draw.io. The AI processes your commands and generates or modifies this XML accordingly.&lt;/p&gt; 
&lt;h2&gt;Project Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;app/                  # Next.js App Router
  api/chat/           # Chat API endpoint with AI tools
  page.tsx            # Main page with DrawIO embed
components/           # React components
  chat-panel.tsx      # Chat interface with diagram control
  chat-input.tsx      # User input component with file upload
  history-dialog.tsx  # Diagram version history viewer
  ui/                 # UI components (buttons, cards, etc.)
contexts/             # React context providers
  diagram-context.tsx # Global diagram state management
lib/                  # Utility functions and helpers
  ai-providers.ts     # Multi-provider AI configuration
  utils.ts            # XML processing and conversion utilities
public/               # Static assets including example images
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Support &amp;amp; Contact&lt;/h2&gt; 
&lt;p&gt;If you find this project useful, please consider &lt;a href="https://github.com/sponsors/DayuanJiang"&gt;sponsoring&lt;/a&gt; to help me host the live demo site!&lt;/p&gt; 
&lt;p&gt;For support or inquiries, please open an issue on the GitHub repository or contact the maintainer at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Email: me[at]jiang.jp&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#DayuanJiang/next-ai-draw-io&amp;amp;type=date&amp;amp;legend=top-left"&gt;&lt;img src="https://api.star-history.com/svg?repos=DayuanJiang/next-ai-draw-io&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt;</description>
    </item>
    
    <item>
      <title>exo-explore/exo</title>
      <link>https://github.com/exo-explore/exo</link>
      <description>&lt;p&gt;Run your own AI cluster at home with everyday devices ğŸ“±ğŸ’» ğŸ–¥ï¸âŒš&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="/docs/imgs/exo-logo-black-bg.jpg" /&gt; 
  &lt;img alt="exo logo" src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/imgs/exo-logo-transparent.png" width="50%" height="50%" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;exo: Run your own AI cluster at home with everyday devices. Maintained by &lt;a href="https://x.com/exolabs"&gt;exo labs&lt;/a&gt;.&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://discord.gg/72NsF6ux" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/exolabs" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/exolabs?style=social" alt="X" /&gt;&lt;/a&gt; &lt;a href="https://www.apache.org/licenses/LICENSE-2.0.html" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/License-Apache2.0-blue.svg?sanitize=true" alt="License: Apache-2.0" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;exo connects all your devices into an AI cluster. Not only does exo enable running models larger than would fit on a single device, but with &lt;a href="https://x.com/exolabs/status/2001817749744476256?s=20"&gt;day-0 support for RDMA over Thunderbolt&lt;/a&gt;, makes models run faster as you add more devices.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic Device Discovery&lt;/strong&gt;: Devices running exo automatically discover each other - no manual configuration.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;RDMA over Thunderbolt&lt;/strong&gt;: exo ships with &lt;a href="https://x.com/exolabs/status/2001817749744476256?s=20"&gt;day-0 support for RDMA over Thunderbolt 5&lt;/a&gt;, enabling 99% reduction in latency between devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Topology-Aware Auto Parallel&lt;/strong&gt;: exo figures out the best way to split your model across all available devices based on a realtime view of your device topology. It takes into account device resources and network latency/bandwidth between each link.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tensor Parallelism&lt;/strong&gt;: exo supports sharding models, for up to 1.8x speedup on 2 devices and 3.2x speedup on 4 devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MLX Support&lt;/strong&gt;: exo uses &lt;a href="https://github.com/ml-explore/mlx"&gt;MLX&lt;/a&gt; as an inference backend and &lt;a href="https://ml-explore.github.io/mlx/build/html/usage/distributed.html"&gt;MLX distributed&lt;/a&gt; for distributed communication.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;details&gt; 
 &lt;summary&gt;Qwen3-235B (8-bit) on 4 Ã— M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-1-qwen3-235b.jpeg" alt="Benchmark - Qwen3-235B (8-bit) on 4 Ã— M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio â€“ RDMA over Thunderboltâ€¯5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;DeepSeek v3.1 671B (8-bit) on 4 Ã— M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-2-deepseek-3.1-671b.jpeg" alt="Benchmark - DeepSeek v3.1 671B (8-bit) on 4 Ã— M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio â€“ RDMA over Thunderboltâ€¯5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Kimi K2 Thinking (native 4-bit) on 4 Ã— M3 Ultra Mac Studio with Tensor Parallel RDMA&lt;/summary&gt; 
 &lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/benchmarks/jeffgeerling/mac-studio-cluster-ai-full-3-kimi-k2-thinking.jpeg" alt="Benchmark - Kimi K2 Thinking (native 4-bit) on 4 Ã— M3 Ultra Mac Studio with Tensor Parallel RDMA" width="80%" /&gt; 
 &lt;p&gt; &lt;strong&gt;Source:&lt;/strong&gt; &lt;a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5"&gt;Jeff Geerling: 15 TB VRAM on Mac Studio â€“ RDMA over Thunderboltâ€¯5&lt;/a&gt; &lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Devices running exo automatically discover each other, without needing any manual configuration. Each device provides an API and a dashboard for interacting with your cluster (runs at &lt;code&gt;http://localhost:52415&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;There are two ways to run exo:&lt;/p&gt; 
&lt;h3&gt;Run from Source (Mac &amp;amp; Linux)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/Homebrew/brew"&gt;brew&lt;/a&gt; (for simple package management on MacOS)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;uv&lt;/a&gt; (for Python dependency management)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/vladkens/macmon"&gt;macmon&lt;/a&gt; (for hardware monitoring on Apple Silicon)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/nodejs/node"&gt;node&lt;/a&gt; (for building the dashboard)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;brew install uv macmon node
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/rust-lang/rustup"&gt;rust&lt;/a&gt; (to build Rust bindings, nightly for now)&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup toolchain install nightly
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Clone the repo, build the dashboard, and run exo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone exo
git clone https://github.com/exo-explore/exo

# Build dashboard
cd exo/dashboard &amp;amp;&amp;amp; npm install &amp;amp;&amp;amp; npm run build &amp;amp;&amp;amp; cd ..

# Run exo
uv run exo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts the exo dashboard and API at &lt;a href="http://localhost:52415/"&gt;http://localhost:52415/&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;macOS App&lt;/h3&gt; 
&lt;p&gt;exo ships a macOS app that runs in the background on your Mac.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/exo-explore/exo/main/docs/imgs/macos-app-one-macbook.png" alt="exo macOS App - running on a MacBook" width="35%" /&gt; 
&lt;p&gt;The macOS app requires macOS Tahoe 26.2 or later.&lt;/p&gt; 
&lt;p&gt;Download the latest build here: &lt;a href="https://assets.exolabs.net/EXO-latest.dmg"&gt;EXO-latest.dmg&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The app will ask for permission to modify system settings and install a new Network profile. Improvements to this are being worked on.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Using the API&lt;/h3&gt; 
&lt;p&gt;If you prefer to interact with exo via the API, here is an example creating an instance of a small model (&lt;code&gt;mlx-community/Llama-3.2-1B-Instruct-4bit&lt;/code&gt;), sending a chat completions request and deleting the instance.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;1. Preview instance placements&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;/instance/previews&lt;/code&gt; endpoint will preview all valid placements for your model.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl "http://localhost:52415/instance/previews?model_id=llama-3.2-1b"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sample response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "previews": [
    {
      "model_id": "mlx-community/Llama-3.2-1B-Instruct-4bit",
      "sharding": "Pipeline",
      "instance_meta": "MlxRing",
      "instance": {...},
      "memory_delta_by_node": {"local": 729808896},
      "error": null
    }
    // ...possibly more placements...
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will return all valid placements for this model. Pick a placement that you like. To pick the first one, pipe into &lt;code&gt;jq&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl "http://localhost:52415/instance/previews?model_id=llama-3.2-1b" | jq -c '.previews[] | select(.error == null) | .instance' | head -n1
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;2. Create a model instance&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Send a POST to &lt;code&gt;/instance&lt;/code&gt; with your desired placement in the &lt;code&gt;instance&lt;/code&gt; field (the full payload must match types as in &lt;code&gt;CreateInstanceParams&lt;/code&gt;), which you can copy from step 1:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X POST http://localhost:52415/instance \
  -H 'Content-Type: application/json' \
  -d '{
    "instance": {...}
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Sample response:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "message": "Command received.",
  "command_id": "e9d1a8ab-...."
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;3. Send a chat completion&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Now, make a POST to &lt;code&gt;/v1/chat/completions&lt;/code&gt; (the same format as OpenAI's API):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -N -X POST http://localhost:52415/v1/chat/completions \
  -H 'Content-Type: application/json' \
  -d '{
    "model": "mlx-community/Llama-3.2-1B-Instruct-4bit",
    "messages": [
      {"role": "user", "content": "What is Llama 3.2 1B?"}
    ],
    "stream": true
  }'
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;4. Delete the instance&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;When you're done, delete the instance by its ID (find it via &lt;code&gt;/state&lt;/code&gt; or &lt;code&gt;/instance&lt;/code&gt; endpoints):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -X DELETE http://localhost:52415/instance/YOUR_INSTANCE_ID
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;em&gt;&lt;em&gt;Other useful API endpoints&lt;/em&gt;:&lt;/em&gt;*&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;List all models: &lt;code&gt;curl http://localhost:52415/models&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Inspect instance IDs and deployment state: &lt;code&gt;curl http://localhost:52415/state&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For further details, see API types and endpoints in &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/src/exo/master/api.py"&gt;src/exo/master/api.py&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Hardware Accelerator Support&lt;/h2&gt; 
&lt;p&gt;On macOS, exo uses the GPU. On Linux, exo currently runs on CPU. We are working on extending hardware accelerator support. If you'd like support for a new hardware platform, please &lt;a href="https://github.com/exo-explore/exo/issues"&gt;search for an existing feature request&lt;/a&gt; and add a thumbs up so we know what hardware is important to the community.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/exo-explore/exo/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidelines on how to contribute to exo.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sst/opencode</title>
      <link>https://github.com/sst/opencode</link>
      <description>&lt;p&gt;The open source coding agent.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://opencode.ai"&gt; 
  &lt;picture&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-dark.svg" media="(prefers-color-scheme: dark)" /&gt; 
   &lt;source srcset="packages/console/app/src/asset/logo-ornate-light.svg" media="(prefers-color-scheme: light)" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/sst/opencode/dev/packages/console/app/src/asset/logo-ornate-light.svg?sanitize=true" alt="OpenCode logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;The open source AI coding agent.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://opencode.ai/discord"&gt;&lt;img alt="Discord" src="https://img.shields.io/discord/1391832426048651334?style=flat-square&amp;amp;label=discord" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/opencode-ai"&gt;&lt;img alt="npm" src="https://img.shields.io/npm/v/opencode-ai?style=flat-square" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sst/opencode/actions/workflows/publish.yml"&gt;&lt;img alt="Build status" src="https://img.shields.io/github/actions/workflow/status/sst/opencode/publish.yml?style=flat-square&amp;amp;branch=dev" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opencode.ai"&gt;&lt;img src="https://raw.githubusercontent.com/sst/opencode/dev/packages/web/src/assets/lander/screenshot.png" alt="OpenCode Terminal UI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# YOLO
curl -fsSL https://opencode.ai/install | bash

# Package managers
npm i -g opencode-ai@latest        # or bun/pnpm/yarn
scoop bucket add extras; scoop install extras/opencode  # Windows
choco install opencode             # Windows
brew install opencode              # macOS and Linux
paru -S opencode-bin               # Arch Linux
mise use -g github:sst/opencode # Any OS
nix run nixpkgs#opencode           # or github:sst/opencode for latest dev branch
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] Remove versions older than 0.1.x before installing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Desktop App (BETA)&lt;/h3&gt; 
&lt;p&gt;OpenCode is also available as a desktop application. Download directly from the &lt;a href="https://github.com/sst/opencode/releases"&gt;releases page&lt;/a&gt; or &lt;a href="https://opencode.ai/download"&gt;opencode.ai/download&lt;/a&gt;.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Download&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Apple Silicon)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-aarch64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;macOS (Intel)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-darwin-x64.dmg&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Windows&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;opencode-desktop-windows-x64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;.deb&lt;/code&gt;, &lt;code&gt;.rpm&lt;/code&gt;, or AppImage&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS (Homebrew)
brew install --cask opencode-desktop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Installation Directory&lt;/h4&gt; 
&lt;p&gt;The install script respects the following priority order for the installation path:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;$OPENCODE_INSTALL_DIR&lt;/code&gt; - Custom installation directory&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$XDG_BIN_DIR&lt;/code&gt; - XDG Base Directory Specification compliant path&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/bin&lt;/code&gt; - Standard user binary directory (if exists or can be created)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;$HOME/.opencode/bin&lt;/code&gt; - Default fallback&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Examples
OPENCODE_INSTALL_DIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash
XDG_BIN_DIR=$HOME/.local/bin curl -fsSL https://opencode.ai/install | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Agents&lt;/h3&gt; 
&lt;p&gt;OpenCode includes two built-in agents you can switch between, you can switch between these using the &lt;code&gt;Tab&lt;/code&gt; key.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;build&lt;/strong&gt; - Default, full access agent for development work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;plan&lt;/strong&gt; - Read-only agent for analysis and code exploration 
  &lt;ul&gt; 
   &lt;li&gt;Denies file edits by default&lt;/li&gt; 
   &lt;li&gt;Asks permission before running bash commands&lt;/li&gt; 
   &lt;li&gt;Ideal for exploring unfamiliar codebases or planning changes&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, included is a &lt;strong&gt;general&lt;/strong&gt; subagent for complex searches and multi-step tasks. This is used internally and can be invoked using &lt;code&gt;@general&lt;/code&gt; in messages.&lt;/p&gt; 
&lt;p&gt;Learn more about &lt;a href="https://opencode.ai/docs/agents"&gt;agents&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;For more info on how to configure OpenCode &lt;a href="https://opencode.ai/docs"&gt;&lt;strong&gt;head over to our docs&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;If you're interested in contributing to OpenCode, please read our &lt;a href="https://raw.githubusercontent.com/sst/opencode/dev/CONTRIBUTING.md"&gt;contributing docs&lt;/a&gt; before submitting a pull request.&lt;/p&gt; 
&lt;h3&gt;Building on OpenCode&lt;/h3&gt; 
&lt;p&gt;If you are working on a project that's related to OpenCode and is using "opencode" as a part of its name; for example, "opencode-dashboard" or "opencode-mobile", please add a note to your README to clarify that it is not built by the OpenCode team and is not affiliated with us in any way.&lt;/p&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;h4&gt;How is this different than Claude Code?&lt;/h4&gt; 
&lt;p&gt;It's very similar to Claude Code in terms of capability. Here are the key differences:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;100% open source&lt;/li&gt; 
 &lt;li&gt;Not coupled to any provider. Although we recommend the models we provide through &lt;a href="https://opencode.ai/zen"&gt;OpenCode Zen&lt;/a&gt;; OpenCode can be used with Claude, OpenAI, Google or even local models. As models evolve the gaps between them will close and pricing will drop so being provider-agnostic is important.&lt;/li&gt; 
 &lt;li&gt;Out of the box LSP support&lt;/li&gt; 
 &lt;li&gt;A focus on TUI. OpenCode is built by neovim users and the creators of &lt;a href="https://terminal.shop"&gt;terminal.shop&lt;/a&gt;; we are going to push the limits of what's possible in the terminal.&lt;/li&gt; 
 &lt;li&gt;A client/server architecture. This for example can allow OpenCode to run on your computer, while you can drive it remotely from a mobile app. Meaning that the TUI frontend is just one of the possible clients.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;What's the other repo?&lt;/h4&gt; 
&lt;p&gt;The other confusingly named repo has no relation to this one. You can &lt;a href="https://x.com/thdxr/status/1933561254481666466"&gt;read the story behind it here&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Join our community&lt;/strong&gt; &lt;a href="https://discord.gg/opencode"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/opencode"&gt;X.com&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>simstudioai/sim</title>
      <link>https://github.com/simstudioai/sim</link>
      <description>&lt;p&gt;Open-source platform to build and deploy AI agent workflows.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/logo/reverse/text/large.png" alt="Sim Logo" width="500" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;Build and deploy AI agent workflows in minutes.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA" alt="Sim.ai" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/Hr4UWYEcTT" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20Server-5865F2?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/simdotai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/twitter/follow/simstudioai?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://docs.sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/Docs-6F3DFA.svg?sanitize=true" alt="Documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h3&gt;Build Workflows with Ease&lt;/h3&gt; 
&lt;p&gt;Design agent workflows visually on a canvasâ€”connect agents, tools, and blocks, then run them instantly.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/workflow.gif" alt="Workflow Builder Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h3&gt;Supercharge with Copilot&lt;/h3&gt; 
&lt;p&gt;Leverage Copilot to generate nodes, fix errors, and iterate on flows directly from natural language.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/copilot.gif" alt="Copilot Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h3&gt;Integrate Vector Databases&lt;/h3&gt; 
&lt;p&gt;Upload documents to a vector store and let agents answer questions grounded in your specific content.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/simstudioai/sim/main/apps/sim/public/static/knowledge.gif" alt="Knowledge Uploads and Retrieval Demo" width="800" /&gt; &lt;/p&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt;Cloud-hosted: &lt;a href="https://sim.ai"&gt;sim.ai&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://sim.ai" target="_blank" rel="noopener noreferrer"&gt;&lt;img src="https://img.shields.io/badge/sim.ai-6F3DFA?logo=data:image/svg%2bxml;base64,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&amp;amp;logoColor=white" alt="Sim.ai" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Self-hosted: NPM Package&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx simstudio
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;â†’ &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Note&lt;/h4&gt; 
&lt;p&gt;Docker must be installed and running on your machine.&lt;/p&gt; 
&lt;h4&gt;Options&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Flag&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-p, --port &amp;lt;port&amp;gt;&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Port to run Sim on (default &lt;code&gt;3000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--no-pull&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Skip pulling latest Docker images&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Self-hosted: Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/simstudioai/sim.git

# Navigate to the project directory
cd sim

# Start Sim
docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access the application at &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Using Local Models with Ollama&lt;/h4&gt; 
&lt;p&gt;Run Sim with local AI models using &lt;a href="https://ollama.ai"&gt;Ollama&lt;/a&gt; - no external APIs required:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with GPU support (automatically downloads gemma3:4b model)
docker compose -f docker-compose.ollama.yml --profile setup up -d

# For CPU-only systems:
docker compose -f docker-compose.ollama.yml --profile cpu --profile setup up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Wait for the model to download, then visit &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;. Add more models with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose -f docker-compose.ollama.yml exec ollama ollama pull llama3.1:8b
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Using an External Ollama Instance&lt;/h4&gt; 
&lt;p&gt;If you already have Ollama running on your host machine (outside Docker), you need to configure the &lt;code&gt;OLLAMA_URL&lt;/code&gt; to use &lt;code&gt;host.docker.internal&lt;/code&gt; instead of &lt;code&gt;localhost&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Docker Desktop (macOS/Windows)
OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d

# Linux (add extra_hosts or use host IP)
docker compose -f docker-compose.prod.yml up -d  # Then set OLLAMA_URL to your host's IP
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt; When running inside Docker, &lt;code&gt;localhost&lt;/code&gt; refers to the container itself, not your host machine. &lt;code&gt;host.docker.internal&lt;/code&gt; is a special DNS name that resolves to the host.&lt;/p&gt; 
&lt;p&gt;For Linux users, you can either:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use your host machine's actual IP address (e.g., &lt;code&gt;http://192.168.1.100:11434&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Add &lt;code&gt;extra_hosts: ["host.docker.internal:host-gateway"]&lt;/code&gt; to the simstudio service in your compose file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Using vLLM&lt;/h4&gt; 
&lt;p&gt;Sim also supports &lt;a href="https://docs.vllm.ai/"&gt;vLLM&lt;/a&gt; for self-hosted models with OpenAI-compatible API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Set these environment variables
VLLM_BASE_URL=http://your-vllm-server:8000
VLLM_API_KEY=your_optional_api_key  # Only if your vLLM instance requires auth
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When running with Docker, use &lt;code&gt;host.docker.internal&lt;/code&gt; if vLLM is on your host machine (same as Ollama above).&lt;/p&gt; 
&lt;h3&gt;Self-hosted: Dev Containers&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open VS Code with the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers"&gt;Remote - Containers extension&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Open the project and click "Reopen in Container" when prompted&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;bun run dev:full&lt;/code&gt; in the terminal or use the &lt;code&gt;sim-start&lt;/code&gt; alias 
  &lt;ul&gt; 
   &lt;li&gt;This starts both the main application and the realtime socket server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Self-hosted: Manual Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Requirements:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt; runtime&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; v20+ (required for sandboxed code execution)&lt;/li&gt; 
 &lt;li&gt;PostgreSQL 12+ with &lt;a href="https://github.com/pgvector/pgvector"&gt;pgvector extension&lt;/a&gt; (required for AI embeddings)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Sim uses vector embeddings for AI features like knowledge bases and semantic search, which requires the &lt;code&gt;pgvector&lt;/code&gt; PostgreSQL extension.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone and install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/simstudioai/sim.git
cd sim
bun install
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Set up PostgreSQL with pgvector:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You need PostgreSQL with the &lt;code&gt;vector&lt;/code&gt; extension for embedding support. Choose one option:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Using Docker (Recommended)&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start PostgreSQL with pgvector extension
docker run --name simstudio-db \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=simstudio \
  -p 5432:5432 -d \
  pgvector/pgvector:pg17
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Manual Installation&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install PostgreSQL 12+ and the pgvector extension&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/pgvector/pgvector#installation"&gt;pgvector installation guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Set up environment:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
cp .env.example .env  # Configure with required variables (DATABASE_URL, BETTER_AUTH_SECRET, BETTER_AUTH_URL)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Set up the database:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;First, configure the database package environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd packages/db
cp .env.example .env 
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update your &lt;code&gt;packages/db/.env&lt;/code&gt; file with the database URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;DATABASE_URL="postgresql://postgres:your_password@localhost:5432/simstudio"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run the migrations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd packages/db # Required so drizzle picks correct .env file
bunx drizzle-kit migrate --config=./drizzle.config.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="5"&gt; 
 &lt;li&gt;Start the development servers:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Recommended approach - run both servers together (from project root):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev:full
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts both the main Next.js application and the realtime socket server required for full functionality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Alternative - run servers separately:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Next.js app (from project root):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bun run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Realtime socket server (from &lt;code&gt;apps/sim&lt;/code&gt; directory in a separate terminal):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd apps/sim
bun run dev:sockets
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Copilot API Keys&lt;/h2&gt; 
&lt;p&gt;Copilot is a Sim-managed service. To use Copilot on a self-hosted instance:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Go to &lt;a href="https://sim.ai"&gt;https://sim.ai&lt;/a&gt; â†’ Settings â†’ Copilot and generate a Copilot API key&lt;/li&gt; 
 &lt;li&gt;Set &lt;code&gt;COPILOT_API_KEY&lt;/code&gt; environment variable in your self-hosted apps/sim/.env file to that value&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Environment Variables&lt;/h2&gt; 
&lt;p&gt;Key environment variables for self-hosted deployments (see &lt;code&gt;apps/sim/.env.example&lt;/code&gt; for full list):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Required&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;DATABASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;PostgreSQL connection string with pgvector&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BETTER_AUTH_SECRET&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Auth secret (&lt;code&gt;openssl rand -hex 32&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;BETTER_AUTH_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Your app URL (e.g., &lt;code&gt;http://localhost:3000&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;NEXT_PUBLIC_APP_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Public app URL (same as above)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENCRYPTION_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Encryption key (&lt;code&gt;openssl rand -hex 32&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;Ollama server URL (default: &lt;code&gt;http://localhost:11434&lt;/code&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;VLLM_BASE_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;vLLM server URL for self-hosted models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;COPILOT_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
   &lt;td&gt;API key from sim.ai for Copilot features&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Ollama models not showing in dropdown (Docker)&lt;/h3&gt; 
&lt;p&gt;If you're running Ollama on your host machine and Sim in Docker, change &lt;code&gt;OLLAMA_URL&lt;/code&gt; from &lt;code&gt;localhost&lt;/code&gt; to &lt;code&gt;host.docker.internal&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;OLLAMA_URL=http://host.docker.internal:11434 docker compose -f docker-compose.prod.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/#using-an-external-ollama-instance"&gt;Using an External Ollama Instance&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Database connection issues&lt;/h3&gt; 
&lt;p&gt;Ensure PostgreSQL has the pgvector extension installed. When using Docker, wait for the database to be healthy before running migrations.&lt;/p&gt; 
&lt;h3&gt;Port conflicts&lt;/h3&gt; 
&lt;p&gt;If ports 3000, 3002, or 5432 are in use, configure alternatives:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Custom ports
NEXT_PUBLIC_APP_URL=http://localhost:3100 POSTGRES_PORT=5433 docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Tech Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: &lt;a href="https://nextjs.org/"&gt;Next.js&lt;/a&gt; (App Router)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Runtime&lt;/strong&gt;: &lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: PostgreSQL with &lt;a href="https://orm.drizzle.team"&gt;Drizzle ORM&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: &lt;a href="https://better-auth.com"&gt;Better Auth&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: &lt;a href="https://ui.shadcn.com/"&gt;Shadcn&lt;/a&gt;, &lt;a href="https://tailwindcss.com"&gt;Tailwind CSS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;State Management&lt;/strong&gt;: &lt;a href="https://zustand-demo.pmnd.rs/"&gt;Zustand&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flow Editor&lt;/strong&gt;: &lt;a href="https://reactflow.dev/"&gt;ReactFlow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docs&lt;/strong&gt;: &lt;a href="https://fumadocs.vercel.app/"&gt;Fumadocs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monorepo&lt;/strong&gt;: &lt;a href="https://turborepo.org/"&gt;Turborepo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Realtime&lt;/strong&gt;: &lt;a href="https://socket.io/"&gt;Socket.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Jobs&lt;/strong&gt;: &lt;a href="https://trigger.dev/"&gt;Trigger.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remote Code Execution&lt;/strong&gt;: &lt;a href="https://www.e2b.dev/"&gt;E2B&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! Please see our &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/simstudioai/sim/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p align="center"&gt;Made with â¤ï¸ by the Sim Team&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>thedotmack/claude-mem</title>
      <link>https://github.com/thedotmack/claude-mem</link>
      <description>&lt;p&gt;A Claude Code plugin that automatically captures everything Claude does during your coding sessions, compresses it with AI (using Claude's agent-sdk), and injects relevant context back into future sessions.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;a href="https://github.com/thedotmack/claude-mem"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-dark-mode.webp" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-light-mode.webp" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/claude-mem-logo-for-light-mode.webp" alt="Claude-Mem" width="400" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.zh.md"&gt;ğŸ‡¨ğŸ‡³ ä¸­æ–‡&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ja.md"&gt;ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.pt-br.md"&gt;ğŸ‡§ğŸ‡· PortuguÃªs&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ko.md"&gt;ğŸ‡°ğŸ‡· í•œêµ­ì–´&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.es.md"&gt;ğŸ‡ªğŸ‡¸ EspaÃ±ol&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.de.md"&gt;ğŸ‡©ğŸ‡ª Deutsch&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.fr.md"&gt;ğŸ‡«ğŸ‡· FranÃ§ais&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.he.md"&gt;ğŸ‡®ğŸ‡± ×¢×‘×¨×™×ª&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ar.md"&gt;ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ru.md"&gt;ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.pl.md"&gt;ğŸ‡µğŸ‡± Polski&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.cs.md"&gt;ğŸ‡¨ğŸ‡¿ ÄŒeÅ¡tina&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.nl.md"&gt;ğŸ‡³ğŸ‡± Nederlands&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.tr.md"&gt;ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.uk.md"&gt;ğŸ‡ºğŸ‡¦ Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.vi.md"&gt;ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.id.md"&gt;ğŸ‡®ğŸ‡© Indonesia&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.th.md"&gt;ğŸ‡¹ğŸ‡­ à¹„à¸—à¸¢&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.hi.md"&gt;ğŸ‡®ğŸ‡³ à¤¹à¤¿à¤¨à¥à¤¦à¥€&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.bn.md"&gt;ğŸ‡§ğŸ‡© à¦¬à¦¾à¦‚à¦²à¦¾&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.ro.md"&gt;ğŸ‡·ğŸ‡´ RomÃ¢nÄƒ&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.sv.md"&gt;ğŸ‡¸ğŸ‡ª Svenska&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.it.md"&gt;ğŸ‡®ğŸ‡¹ Italiano&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.el.md"&gt;ğŸ‡¬ğŸ‡· Î•Î»Î»Î·Î½Î¹ÎºÎ¬&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.hu.md"&gt;ğŸ‡­ğŸ‡º Magyar&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.fi.md"&gt;ğŸ‡«ğŸ‡® Suomi&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.da.md"&gt;ğŸ‡©ğŸ‡° Dansk&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/i18n/README.no.md"&gt;ğŸ‡³ğŸ‡´ Norsk&lt;/a&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt;Persistent memory compression system built for &lt;a href="https://claude.com/claude-code" target="_blank"&gt;Claude Code&lt;/a&gt;.&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-AGPL%203.0-blue.svg?sanitize=true" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/package.json"&gt; &lt;img src="https://img.shields.io/badge/version-6.5.0-green.svg?sanitize=true" alt="Version" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/package.json"&gt; &lt;img src="https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg?sanitize=true" alt="Node" /&gt; &lt;/a&gt; &lt;a href="https://github.com/thedotmack/awesome-claude-code"&gt; &lt;img src="https://awesome.re/mentioned-badge.svg?sanitize=true" alt="Mentioned in Awesome Claude Code" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15496" target="_blank"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge-dark.svg" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge.svg" /&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/trendshift-badge.svg?sanitize=true" alt="thedotmack/claude-mem | Trendshift" width="250" height="55" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/thedotmack/claude-mem"&gt; 
  &lt;picture&gt; 
   &lt;img src="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/public/cm-preview.gif" alt="Claude-Mem Preview" width="800" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#quick-start"&gt;Quick Start&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#how-it-works"&gt;How It Works&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#mcp-search-tools"&gt;Search Tools&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#documentation"&gt;Documentation&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#configuration"&gt;Configuration&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#troubleshooting"&gt;Troubleshooting&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/#license"&gt;License&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; Claude-Mem seamlessly preserves context across sessions by automatically capturing tool usage observations, generating semantic summaries, and making them available to future sessions. This enables Claude to maintain continuity of knowledge about projects even after sessions end or reconnect. &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;Start a new Claude Code session in the terminal and enter the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; /plugin marketplace add thedotmack/claude-mem

&amp;gt; /plugin install claude-mem
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Restart Claude Code. Context from previous sessions will automatically appear in new sessions.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ§  &lt;strong&gt;Persistent Memory&lt;/strong&gt; - Context survives across sessions&lt;/li&gt; 
 &lt;li&gt;ğŸ“Š &lt;strong&gt;Progressive Disclosure&lt;/strong&gt; - Layered memory retrieval with token cost visibility&lt;/li&gt; 
 &lt;li&gt;ğŸ” &lt;strong&gt;Skill-Based Search&lt;/strong&gt; - Query your project history with mem-search skill&lt;/li&gt; 
 &lt;li&gt;ğŸ–¥ï¸ &lt;strong&gt;Web Viewer UI&lt;/strong&gt; - Real-time memory stream at &lt;a href="http://localhost:37777"&gt;http://localhost:37777&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ’» &lt;strong&gt;Claude Desktop Skill&lt;/strong&gt; - Search memory from Claude Desktop conversations&lt;/li&gt; 
 &lt;li&gt;ğŸ”’ &lt;strong&gt;Privacy Control&lt;/strong&gt; - Use &lt;code&gt;&amp;lt;private&amp;gt;&lt;/code&gt; tags to exclude sensitive content from storage&lt;/li&gt; 
 &lt;li&gt;âš™ï¸ &lt;strong&gt;Context Configuration&lt;/strong&gt; - Fine-grained control over what context gets injected&lt;/li&gt; 
 &lt;li&gt;ğŸ¤– &lt;strong&gt;Automatic Operation&lt;/strong&gt; - No manual intervention required&lt;/li&gt; 
 &lt;li&gt;ğŸ”— &lt;strong&gt;Citations&lt;/strong&gt; - Reference past observations with IDs (access via &lt;a href="http://localhost:37777/api/observation/%7Bid%7D"&gt;http://localhost:37777/api/observation/{id}&lt;/a&gt; or view all in the web viewer at &lt;a href="http://localhost:37777"&gt;http://localhost:37777&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;ğŸ§ª &lt;strong&gt;Beta Channel&lt;/strong&gt; - Try experimental features like Endless Mode via version switching&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;ğŸ“š &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/"&gt;View Full Documentation&lt;/a&gt;&lt;/strong&gt; - Browse markdown docs on GitHub&lt;/p&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/installation"&gt;Installation Guide&lt;/a&gt;&lt;/strong&gt; - Quick start &amp;amp; advanced installation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/usage/getting-started"&gt;Usage Guide&lt;/a&gt;&lt;/strong&gt; - How Claude-Mem works automatically&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/usage/search-tools"&gt;Search Tools&lt;/a&gt;&lt;/strong&gt; - Query your project history with natural language&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/beta-features"&gt;Beta Features&lt;/a&gt;&lt;/strong&gt; - Try experimental features like Endless Mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Best Practices&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/context-engineering"&gt;Context Engineering&lt;/a&gt;&lt;/strong&gt; - AI agent context optimization principles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/progressive-disclosure"&gt;Progressive Disclosure&lt;/a&gt;&lt;/strong&gt; - Philosophy behind Claude-Mem's context priming strategy&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Architecture&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/overview"&gt;Overview&lt;/a&gt;&lt;/strong&gt; - System components &amp;amp; data flow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture-evolution"&gt;Architecture Evolution&lt;/a&gt;&lt;/strong&gt; - The journey from v3 to v5&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/hooks-architecture"&gt;Hooks Architecture&lt;/a&gt;&lt;/strong&gt; - How Claude-Mem uses lifecycle hooks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/hooks"&gt;Hooks Reference&lt;/a&gt;&lt;/strong&gt; - 7 hook scripts explained&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/worker-service"&gt;Worker Service&lt;/a&gt;&lt;/strong&gt; - HTTP API &amp;amp; Bun management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/database"&gt;Database&lt;/a&gt;&lt;/strong&gt; - SQLite schema &amp;amp; FTS5 search&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/architecture/search-architecture"&gt;Search Architecture&lt;/a&gt;&lt;/strong&gt; - Hybrid search with Chroma vector database&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Configuration &amp;amp; Development&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/configuration"&gt;Configuration&lt;/a&gt;&lt;/strong&gt; - Environment variables &amp;amp; settings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/development"&gt;Development&lt;/a&gt;&lt;/strong&gt; - Building, testing, contributing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/troubleshooting"&gt;Troubleshooting&lt;/a&gt;&lt;/strong&gt; - Common issues &amp;amp; solutions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;How It Works&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Core Components:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;5 Lifecycle Hooks&lt;/strong&gt; - SessionStart, UserPromptSubmit, PostToolUse, Stop, SessionEnd (6 hook scripts)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Install&lt;/strong&gt; - Cached dependency checker (pre-hook script, not a lifecycle hook)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Worker Service&lt;/strong&gt; - HTTP API on port 37777 with web viewer UI and 10 search endpoints, managed by Bun&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite Database&lt;/strong&gt; - Stores sessions, observations, summaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;mem-search Skill&lt;/strong&gt; - Natural language queries with progressive disclosure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chroma Vector Database&lt;/strong&gt; - Hybrid semantic + keyword search for intelligent context retrieval&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/architecture/overview"&gt;Architecture Overview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;mem-search Skill&lt;/h2&gt; 
&lt;p&gt;Claude-Mem provides intelligent search through the mem-search skill that auto-invokes when you ask about past work:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;How It Works:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Just ask naturally: &lt;em&gt;"What did we do last session?"&lt;/em&gt; or &lt;em&gt;"Did we fix this bug before?"&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Claude automatically invokes the mem-search skill to find relevant context&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Available Search Operations:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Search Observations&lt;/strong&gt; - Full-text search across observations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search Sessions&lt;/strong&gt; - Full-text search across session summaries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search Prompts&lt;/strong&gt; - Search raw user requests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;By Concept&lt;/strong&gt; - Find by concept tags (discovery, problem-solution, pattern, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;By File&lt;/strong&gt; - Find observations referencing specific files&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;By Type&lt;/strong&gt; - Find by type (decision, bugfix, feature, refactor, discovery, change)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Recent Context&lt;/strong&gt; - Get recent session context for a project&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Timeline&lt;/strong&gt; - Get unified timeline of context around a specific point in time&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Timeline by Query&lt;/strong&gt; - Search for observations and get timeline context around best match&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Help&lt;/strong&gt; - Get search API documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example Natural Language Queries:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;"What bugs did we fix last session?"
"How did we implement authentication?"
"What changes were made to worker-service.ts?"
"Show me recent work on this project"
"What was happening when we added the viewer UI?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/usage/search-tools"&gt;Search Tools Guide&lt;/a&gt; for detailed examples.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Beta Features&lt;/h2&gt; 
&lt;p&gt;Claude-Mem offers a &lt;strong&gt;beta channel&lt;/strong&gt; with experimental features like &lt;strong&gt;Endless Mode&lt;/strong&gt; (biomimetic memory architecture for extended sessions). Switch between stable and beta versions from the web viewer UI at &lt;a href="http://localhost:37777"&gt;http://localhost:37777&lt;/a&gt; â†’ Settings.&lt;/p&gt; 
&lt;p&gt;See &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/beta-features"&gt;Beta Features Documentation&lt;/a&gt;&lt;/strong&gt; for details on Endless Mode and how to try it.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;System Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: 18.0.0 or higher&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Claude Code&lt;/strong&gt;: Latest version with plugin support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bun&lt;/strong&gt;: JavaScript runtime and process manager (auto-installed if missing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;uv&lt;/strong&gt;: Python package manager for vector search (auto-installed if missing)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite 3&lt;/strong&gt;: For persistent storage (bundled)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Settings are managed in &lt;code&gt;~/.claude-mem/settings.json&lt;/code&gt; (auto-created with defaults on first run). Configure AI model, worker port, data directory, log level, and context injection settings.&lt;/p&gt; 
&lt;p&gt;See the &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/configuration"&gt;Configuration Guide&lt;/a&gt;&lt;/strong&gt; for all available settings and examples.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;See the &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/development"&gt;Development Guide&lt;/a&gt;&lt;/strong&gt; for build instructions, testing, and contribution workflow.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;If experiencing issues, describe the problem to Claude and the troubleshoot skill will automatically diagnose and provide fixes.&lt;/p&gt; 
&lt;p&gt;See the &lt;strong&gt;&lt;a href="https://docs.claude-mem.ai/troubleshooting"&gt;Troubleshooting Guide&lt;/a&gt;&lt;/strong&gt; for common issues and solutions.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Bug Reports&lt;/h2&gt; 
&lt;p&gt;Create comprehensive bug reports with the automated generator:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ~/.claude/plugins/marketplaces/thedotmack
npm run bug-report
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Make your changes with tests&lt;/li&gt; 
 &lt;li&gt;Update documentation&lt;/li&gt; 
 &lt;li&gt;Submit a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;a href="https://docs.claude-mem.ai/development"&gt;Development Guide&lt;/a&gt; for contribution workflow.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;strong&gt;GNU Affero General Public License v3.0&lt;/strong&gt; (AGPL-3.0).&lt;/p&gt; 
&lt;p&gt;Copyright (C) 2025 Alex Newman (@thedotmack). All rights reserved.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for full details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;What This Means:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can use, modify, and distribute this software freely&lt;/li&gt; 
 &lt;li&gt;If you modify and deploy on a network server, you must make your source code available&lt;/li&gt; 
 &lt;li&gt;Derivative works must also be licensed under AGPL-3.0&lt;/li&gt; 
 &lt;li&gt;There is NO WARRANTY for this software&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note on Ragtime&lt;/strong&gt;: The &lt;code&gt;ragtime/&lt;/code&gt; directory is licensed separately under the &lt;strong&gt;PolyForm Noncommercial License 1.0.0&lt;/strong&gt;. See &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/ragtime/LICENSE"&gt;ragtime/LICENSE&lt;/a&gt; for details.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/thedotmack/claude-mem/main/docs/"&gt;docs/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: &lt;a href="https://github.com/thedotmack/claude-mem/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repository&lt;/strong&gt;: &lt;a href="https://github.com/thedotmack/claude-mem"&gt;github.com/thedotmack/claude-mem&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Author&lt;/strong&gt;: Alex Newman (&lt;a href="https://github.com/thedotmack"&gt;@thedotmack&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Built with Claude Agent SDK&lt;/strong&gt; | &lt;strong&gt;Powered by Claude Code&lt;/strong&gt; | &lt;strong&gt;Made with TypeScript&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GeeeekExplorer/nano-vllm</title>
      <link>https://github.com/GeeeekExplorer/nano-vllm</link>
      <description>&lt;p&gt;Nano vLLM&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img width="300" src="https://raw.githubusercontent.com/GeeeekExplorer/nano-vllm/main/assets/logo.png" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/15323" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/15323" alt="GeeeekExplorer%2Fnano-vllm | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Nano-vLLM&lt;/h1&gt; 
&lt;p&gt;A lightweight vLLM implementation built from scratch.&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;Fast offline inference&lt;/strong&gt; - Comparable inference speeds to vLLM&lt;/li&gt; 
 &lt;li&gt;ğŸ“– &lt;strong&gt;Readable codebase&lt;/strong&gt; - Clean implementation in ~ 1,200 lines of Python code&lt;/li&gt; 
 &lt;li&gt;âš¡ &lt;strong&gt;Optimization Suite&lt;/strong&gt; - Prefix caching, Tensor Parallelism, Torch compilation, CUDA graph, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install git+https://github.com/GeeeekExplorer/nano-vllm.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Model Download&lt;/h2&gt; 
&lt;p&gt;To download the model weights manually, use the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;huggingface-cli download --resume-download Qwen/Qwen3-0.6B \
  --local-dir ~/huggingface/Qwen3-0.6B/ \
  --local-dir-use-symlinks False
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;example.py&lt;/code&gt; for usage. The API mirrors vLLM's interface with minor differences in the &lt;code&gt;LLM.generate&lt;/code&gt; method:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from nanovllm import LLM, SamplingParams
llm = LLM("/YOUR/MODEL/PATH", enforce_eager=True, tensor_parallel_size=1)
sampling_params = SamplingParams(temperature=0.6, max_tokens=256)
prompts = ["Hello, Nano-vLLM."]
outputs = llm.generate(prompts, sampling_params)
outputs[0]["text"]
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;bench.py&lt;/code&gt; for benchmark.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Test Configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hardware: RTX 4070 Laptop (8GB)&lt;/li&gt; 
 &lt;li&gt;Model: Qwen3-0.6B&lt;/li&gt; 
 &lt;li&gt;Total Requests: 256 sequences&lt;/li&gt; 
 &lt;li&gt;Input Length: Randomly sampled between 100â€“1024 tokens&lt;/li&gt; 
 &lt;li&gt;Output Length: Randomly sampled between 100â€“1024 tokens&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Performance Results:&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Inference Engine&lt;/th&gt; 
   &lt;th&gt;Output Tokens&lt;/th&gt; 
   &lt;th&gt;Time (s)&lt;/th&gt; 
   &lt;th&gt;Throughput (tokens/s)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vLLM&lt;/td&gt; 
   &lt;td&gt;133,966&lt;/td&gt; 
   &lt;td&gt;98.37&lt;/td&gt; 
   &lt;td&gt;1361.84&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Nano-vLLM&lt;/td&gt; 
   &lt;td&gt;133,966&lt;/td&gt; 
   &lt;td&gt;93.41&lt;/td&gt; 
   &lt;td&gt;1434.13&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#GeeeekExplorer/nano-vllm&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=GeeeekExplorer/nano-vllm&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>refly-ai/refly</title>
      <link>https://github.com/refly-ai/refly</link>
      <description>&lt;p&gt;Vibe Workflow Platform for Non-technical Creators.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://static.refly.ai/landing/refly-cover-new.webp" alt="refly-cover" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1 align="center" style="border-bottom: none"&gt; &lt;b&gt; &lt;a href="https://refly.ai"&gt;Refly.AI&lt;/a&gt;&lt;br /&gt; &lt;/b&gt; â­ï¸ The World's First Vibe Workflow Platform for Non-technical Creators â­ï¸ &lt;br /&gt; &lt;/h1&gt; 
&lt;/div&gt; 
&lt;p&gt;Refly.AI is the world's first vibe workflow platform that empowers non-technical creators to build, share and monetize powerful AI automation workflows through simple prompts and a visual canvas - no coding required.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;N8N for non-technical: Build workflows as easily as assembling Lego bricks. Refly.ai empowers non-technical creators to eliminate repetitive tasks without technical barriers.&lt;/li&gt; 
 &lt;li&gt;Canva for workflow: Just as Canva democratized design, Refly.ai democratizes workflow creationâ€”making it simple for everyone to build and share automations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://refly.ai/"&gt;ğŸš€ Refly.ai v1.0.0 Released! A milestone launch bringing the first full Vibe Workflow experience. ğŸš€&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://refly.ai/"&gt;Refly Cloud&lt;/a&gt; Â· &lt;a href="https://docs.refly.ai/community-version/self-deploy"&gt;Self-hosting&lt;/a&gt; Â· &lt;a href="https://github.com/refly-ai/refly/discussions"&gt;Forum&lt;/a&gt; Â· &lt;a href="https://discord.gg/YVuYFjFvRC"&gt;Discord&lt;/a&gt; Â· &lt;a href="https://x.com/reflyai"&gt;Twitter&lt;/a&gt; Â· &lt;a href="https://docs.refly.ai/"&gt;Documentation&lt;/a&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://refly.ai" target="_blank"&gt; &lt;img alt="Static Badge" src="https://img.shields.io/badge/Product-F04438" /&gt;&lt;/a&gt; &lt;a href="https://refly.ai/pricing" target="_blank"&gt; &lt;img alt="Static Badge" src="https://img.shields.io/badge/free-pricing?logo=free&amp;amp;color=%20%23155EEF&amp;amp;label=pricing&amp;amp;labelColor=%20%23528bff" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/YVuYFjFvRC" target="_blank"&gt; &lt;img alt="Discord Chat" src="https://img.shields.io/discord/1323513432686989362?label=chat&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;style=flat&amp;amp;color=5865F2" /&gt;&lt;/a&gt; &lt;a href="https://x.com/reflyai" target="_blank"&gt; &lt;img alt="Static Badge" src="https://img.shields.io/twitter/follow/reflyai" /&gt;&lt;/a&gt; &lt;a href="https://www.typescriptlang.org/" target="_blank"&gt; &lt;img alt="TypeScript-version-icon" src="https://img.shields.io/badge/TypeScript-^5.3.3-blue" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://template.run.claw.cloud/?openapp=system-fastdeploy%3FtemplateName%3Drefly"&gt;&lt;img src="https://raw.githubusercontent.com/ClawCloud/Run-Template/refs/heads/main/Run-on-ClawCloud.svg?sanitize=true" alt="SVG" style="height:45px; vertical-align:middle;" /&gt;&lt;/a&gt; &lt;a href="https://template.sealos.io/deploy?templateName=refly"&gt;&lt;img src="https://sealos.io/Deploy-on-Sealos.svg?sanitize=true" alt="Deploy on Sealos" /&gt;&lt;/a&gt; &lt;a href="https://gitpod.io/#https://github.com/refly-ai/refly"&gt;&lt;img src="https://gitpod.io/button/open-in-gitpod.svg?sanitize=true" alt="Open in Gitpod" /&gt;&lt;/a&gt; &lt;a href="https://www.hostinger.com/vps/docker-hosting?compose_url=https://github.com/refly-ai/refly"&gt;&lt;img src="https://assets.hostinger.com/vps/deploy.svg?sanitize=true" alt="Deploy on Hostinger" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;âœ¨ Key Features&lt;/h2&gt; 
&lt;h3&gt;Intervenable Agent: Eliminates unpredictable "black box" executions&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Visualized Execution&lt;/strong&gt;: Every step of the workflow is clearly visible on the canvas. Allows for easy review, understanding, and debugging of the automation process.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time Intervention&lt;/strong&gt;: Users can pause, review, modify, or restart the Agent at any point during execution. Eliminates the frustration of unstable, irreversible, or unoptimizable "black box" executions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Minimalist Workflow Tool: Orchestrate not nodes, but pre-packaged &amp;amp; powerful Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Forget tedious configuration. In Refly.ai, every node is a powerful, ready-to-use Agent. All you need to do is assign tasks and connect. Refly.ai does in minutes with two nodes what n8n takes hours and ten or more nodes to complete.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Workflow Copilot: Turn your words into complex automations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Describe a task, and the Refly copilot instantly crafts, modifies, and debugs complex automations directly in your canvas. Even multi-step workflows can be built in seconds.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Workflow Marketplace: One-Click Publishing,Monetize your expertise&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;One-click publishing&lt;/strong&gt;: Users can easily turn their workflows into shareable AI Apps and publish them to the workflow marketplace.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Monetize your expertise&lt;/strong&gt;: Creators get paid every time users run their workflows, making your experience and creations more valuable than ever.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Use?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;We've deployed a Refly Cloud version that allows zero-configuration usage, offering all capabilities of the self-hosted version, including free access to the latest models. Visit &lt;a href="https://refly.ai/"&gt;https://refly.ai/&lt;/a&gt; to get started.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Self-hosting Refly Community Edition&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Get started quickly with our &lt;a href="https://raw.githubusercontent.com/refly-ai/refly/main/CONTRIBUTING.md"&gt;Getting Started Guide&lt;/a&gt; to run Refly in your environment. For more detailed references and in-depth instructions, please refer to our documentation.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Refly for enterprise / organizations&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Please contact us at &lt;a href="mailto:support@refly.ai"&gt;support@refly.ai&lt;/a&gt; for private deployment solutions.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Stay Updated&lt;/h2&gt; 
&lt;p&gt;Star Refly on GitHub to receive instant notifications about new version releases.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/877dfeb7-1088-41f1-9176-468d877ded0a" alt="stay-tuned" /&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing Guidelines&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Bug Reports&lt;/th&gt; 
   &lt;th&gt;Feature Requests&lt;/th&gt; 
   &lt;th&gt;Issues/Discussions&lt;/th&gt; 
   &lt;th&gt;ReflyAI Community&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/refly-ai/refly/issues/new/choose"&gt;Create Bug Report&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/refly-ai/refly/pulls"&gt;Submit Feature Request&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/refly-ai/refly/discussions"&gt;View GitHub Discussions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.refly.ai/community/contact-us"&gt;Visit ReflyAI Community&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Something isn't working as expected&lt;/td&gt; 
   &lt;td&gt;Ideas for new features or improvements&lt;/td&gt; 
   &lt;td&gt;Discuss and raise questions&lt;/td&gt; 
   &lt;td&gt;A place to ask questions, learn, and connect with others&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Calling all developers, testers, tech writers and more! Contributions of all types are more than welcome, please check our &lt;a href="https://raw.githubusercontent.com/refly-ai/refly/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; and feel free to browse our &lt;a href="https://github.com/refly-ai/refly/issues"&gt;GitHub issues&lt;/a&gt; to show us what you can do.&lt;/p&gt; 
&lt;p&gt;For bug reports, feature requests, and other suggestions, you can also &lt;a href="https://github.com/refly-ai/refly/issues/new/choose"&gt;create a new issue&lt;/a&gt; and choose the most appropriate template to provide feedback.&lt;/p&gt; 
&lt;p&gt;If you have any questions, feel free to reach out to us. One of the best places to get more information and learn is the &lt;a href="https://docs.refly.ai/community/contact-us"&gt;ReflyAI Community&lt;/a&gt;, where you can connect with other like-minded individuals.&lt;/p&gt; 
&lt;h2&gt;Community and Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/refly-ai/refly/discussions"&gt;GitHub Discussion&lt;/a&gt;: Best for sharing feedback and asking questions.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/refly-ai/refly/issues"&gt;GitHub Issues&lt;/a&gt;: Best for reporting bugs and suggesting features when using ReflyAI. Please refer to our contribution guidelines.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/YVuYFjFvRC"&gt;Discord&lt;/a&gt;: Best for sharing your applications and interacting with the community.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/reflyai"&gt;X(Twitter)&lt;/a&gt;: Best for sharing your applications and staying connected with the community.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security Issues&lt;/h2&gt; 
&lt;p&gt;To protect your privacy, please avoid posting security-related issues on GitHub. Instead, send your questions to &lt;a href="mailto:support@refly.ai"&gt;support@refly.ai&lt;/a&gt;, and we will provide you with a more detailed response.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/refly-ai/refly/main/LICENSE"&gt;ReflyAI Open Source License&lt;/a&gt;, which is essentially the Apache 2.0 License with some additional restrictions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>danielmiessler/Personal_AI_Infrastructure</title>
      <link>https://github.com/danielmiessler/Personal_AI_Infrastructure</link>
      <description>&lt;p&gt;Personal AI Infrastructure for upgrading humans.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="./pai-logo.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="./pai-logo.png" /&gt; 
  &lt;img alt="PAI Logo" src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/pai-logo.png" width="600" /&gt; 
 &lt;/picture&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;h1&gt;Personal AI Infrastructure&lt;/h1&gt; 
 &lt;h3&gt;Open-source scaffolding for building your own AI-powered operating system&lt;/h3&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/danielmiessler/Personal_AI_Infrastructure/releases"&gt;&lt;img src="https://img.shields.io/badge/version-0.9.1-blue?style=for-the-badge" alt="Version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-green?style=for-the-badge" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://claude.ai/code"&gt;&lt;img src="https://img.shields.io/badge/Claude_Code-Powered-8B5CF6?style=for-the-badge" alt="Claude Code" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-quick-start"&gt;&lt;strong&gt;Quick Start&lt;/strong&gt;&lt;/a&gt; Â· &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-documentation"&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt; Â· &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-examples"&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/a&gt; Â· &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-updating-pai"&gt;&lt;strong&gt;Updating&lt;/strong&gt;&lt;/a&gt; Â· &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-community"&gt;&lt;strong&gt;Community&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://youtu.be/iKwRWwabkEc"&gt;&lt;img src="https://img.youtube.com/vi/iKwRWwabkEc/maxresdefault.jpg" alt="PAI Overview Video" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;&lt;a href="https://youtu.be/iKwRWwabkEc"&gt;Watch the full PAI walkthrough&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://danielmiessler.com/blog/real-internet-of-things"&gt;Read: The Real Internet of Things&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;h1&gt;The best AI in the world should be available to everyone&lt;/h1&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="docs/images/pai-overview.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="docs/images/pai-overview.png" /&gt; 
  &lt;img alt="PAI Architecture Overview" src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/pai-overview.png" width="800" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;p&gt;Right now the most powerful AI setups are being built inside companies for efficiency and profits.&lt;/p&gt; 
&lt;p&gt;That's all good, but I think the purpose of technology is to serve humansâ€”not the other way around. These new AI frameworks should be available to everyone, including people not in technology, so that regular people can use it to help them flourish.&lt;/p&gt; 
&lt;p&gt;That's what PAI is. It's the foundation for building a Personal AI System that understands your larger goals and context, gets better over time, and that works for &lt;em&gt;you&lt;/em&gt; because it's &lt;em&gt;yours&lt;/em&gt;. Not some generic chatbot. Not some common assistant. A full platform for magnifying yourself and your impact on the world.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Related reading:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://danielmiessler.com/blog/real-internet-of-things"&gt;The Real Internet of Things&lt;/a&gt; â€” The vision behind PAI (full book)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://danielmiessler.com/blog/ai-predictable-path-7-components-2024"&gt;AI's Predictable Path: 7 Components&lt;/a&gt; â€” Visual walkthrough of where AI is heading&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;h2&gt;What is PAI?&lt;/h2&gt; 
&lt;p&gt;PAI (Personal AI Infrastructure) is an open-source template for building your own AI-powered operating system. It's currently built on &lt;a href="https://claude.ai/code"&gt;Claude Code&lt;/a&gt;, but designed to be platform-independent â€” the architecture, skills, and workflows are structured so future migrations to other AI platforms are straightforward.&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="docs/images/pai-infrastructure.png" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="docs/images/pai-infrastructure.png" /&gt; 
 &lt;img alt="PAI Infrastructure Architecture" src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/pai-infrastructure.png" width="800" /&gt; 
&lt;/picture&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Skills&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Self-contained AI capabilities with routing, workflows, and documentation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Agents&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Specialized AI personalities for different tasks (engineer, researcher, designer)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Hooks&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Event-driven automation that captures work and manages state&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;History&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Automatic documentation system (UOCS) that captures everything&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;Start clean, small, and simple.&lt;/strong&gt; Build the scaffolding that makes AI reliable.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h2&gt;What's New in v0.9.0&lt;/h2&gt; 
&lt;p&gt;Big updates! PAI is now fully &lt;strong&gt;platform-agnostic&lt;/strong&gt; â€” your AI identity, your system.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ“Š &lt;strong&gt;Observability Dashboard&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time agent monitoring with live charts&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ­ &lt;strong&gt;Genericized Identity&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Configure your DA name, it flows everywhere&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;âš™ï¸ &lt;strong&gt;Better Configuration&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Clear docs for all environment variables&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;ğŸ‘‰ &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#-updates"&gt;&lt;strong&gt;See full changelog&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;p&gt;Choose your platform:&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ macOS&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;1. Clone PAI&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/danielmiessler/PAI.git ~/PAI
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;2. Create Symlink&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Remove existing ~/.claude if present (backup first if needed)
[ -d ~/.claude ] &amp;amp;&amp;amp; mv ~/.claude ~/.claude.backup
ln -s ~/PAI/.claude ~/.claude
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;3. Run the Setup Wizard&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;~/.claude/Tools/setup/bootstrap.sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;4. Add Your API Keys&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cp ~/.claude/.env.example ~/.claude/.env
nano ~/.claude/.env
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;5. Start Claude Code&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;source ~/.zshrc  # Load PAI environment
claude
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ§ Linux&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;1. Clone PAI&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/danielmiessler/PAI.git ~/PAI
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;2. Create Symlink&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Remove existing ~/.claude if present (backup first if needed)
[ -d ~/.claude ] &amp;amp;&amp;amp; mv ~/.claude ~/.claude.backup
ln -s ~/PAI/.claude ~/.claude
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;3. Run the Setup Wizard&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;~/.claude/Tools/setup/bootstrap.sh
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;4. Add Your API Keys&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;cp ~/.claude/.env.example ~/.claude/.env
nano ~/.claude/.env
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;5. Start Claude Code&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;source ~/.bashrc  # Load PAI environment
claude
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸªŸ Windows&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;1. Clone PAI&lt;/strong&gt; (PowerShell)&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-powershell"&gt;git clone https://github.com/danielmiessler/PAI.git $env:USERPROFILE\PAI
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;2. Create Symlink&lt;/strong&gt; (Run PowerShell as Administrator)&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-powershell"&gt;# Remove existing .claude if present (backup first if needed)
if (Test-Path "$env:USERPROFILE\.claude") { Rename-Item "$env:USERPROFILE\.claude" "$env:USERPROFILE\.claude.backup" }
New-Item -ItemType SymbolicLink -Path "$env:USERPROFILE\.claude" -Target "$env:USERPROFILE\PAI\.claude"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;3. Run the Setup Wizard&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-powershell"&gt;&amp;amp; "$env:USERPROFILE\.claude\tools\setup\bootstrap.ps1"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;4. Add Your API Keys&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-powershell"&gt;Copy-Item "$env:USERPROFILE\.claude\.env.example" "$env:USERPROFILE\.claude\.env"
notepad "$env:USERPROFILE\.claude\.env"
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;5. Start Claude Code&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-powershell"&gt;# Restart PowerShell to load environment, then:
claude
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] The setup wizard will configure your name, email, AI assistant name, and environment variables to customize to your environment.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ğŸ“š For detailed setup, see &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/QUICKSTART.md"&gt;&lt;code&gt;docs/QUICKSTART.md&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ“š Documentation&lt;/h2&gt; 
&lt;p&gt;All documentation lives in the CORE skill (&lt;code&gt;.claude/Skills/CORE/&lt;/code&gt;):&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Document&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/.claude/Skills/CORE/CONSTITUTION.md"&gt;&lt;strong&gt;CONSTITUTION.md&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;System philosophy, architecture, operating principles&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/.claude/Skills/CORE/SkillSystem.md"&gt;&lt;strong&gt;SkillSystem.md&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;How to create your own skills&lt;/strong&gt; â€” the canonical skill structure guide&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/.claude/Skills/CORE/SKILL.md"&gt;&lt;strong&gt;SKILL.md&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Main PAI skill with identity, preferences, quick reference&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/.claude/Skills/CORE/HookSystem.md"&gt;HookSystem.md&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Event-driven automation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/.claude/Skills/CORE/HistorySystem.md"&gt;HistorySystem.md&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Automatic work documentation (UOCS)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Additional Reference&lt;/strong&gt;&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Document&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/.claude/Skills/CORE/Prompting.md"&gt;Prompting.md&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Prompt engineering patterns&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/.claude/Skills/CORE/Aesthetic.md"&gt;Aesthetic.md&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Visual design system&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/.claude/voice-server/README.md"&gt;voice-server/README.md&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Text-to-speech feedback&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ¨ Examples&lt;/h2&gt; 
&lt;p&gt;Explore example skills in &lt;code&gt;.claude/Skills/&lt;/code&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Skill&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Observability/&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time agent monitoring dashboard with WebSocket streaming&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;BrightData/&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Four-tier progressive web scraping with automatic fallback&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Fabric/&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Native Fabric patterns&lt;/strong&gt; â€” 248 patterns run directly in Claude's context (no CLI needed)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Research/&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Multi-source research workflows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Createskill/&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Templates for creating new skills&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Each skill demonstrates the skills-as-containers pattern with routing, workflows, and self-contained documentation.&lt;/p&gt; 
&lt;h3&gt;Native Fabric Patterns&lt;/h3&gt; 
&lt;p&gt;The Fabric skill now executes patterns &lt;strong&gt;natively&lt;/strong&gt; within Claude Code â€” no CLI spawning required:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Your subscription's power&lt;/strong&gt; â€” Patterns run with your Opus/Sonnet model, not Fabric's configured model&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full context&lt;/strong&gt; â€” Patterns have access to your entire conversation history&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Faster execution&lt;/strong&gt; â€” No process spawning overhead&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;248 patterns included&lt;/strong&gt; â€” extract_wisdom, summarize, threat modeling, and more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Update patterns from upstream
.claude/Skills/Fabric/tools/update-patterns.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Only use &lt;code&gt;fabric&lt;/code&gt; CLI for YouTube transcripts (&lt;code&gt;-y&lt;/code&gt;) or pattern updates (&lt;code&gt;-U&lt;/code&gt;).&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ—ï¸ The Thirteen Founding Principles&lt;/h2&gt; 
&lt;p&gt;PAI is built on 13 foundational principles that define how to build reliable AI infrastructure.&lt;/p&gt; 
&lt;p&gt;Complete architecture documentation: &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/.claude/Skills/CORE/Architecture.md"&gt;&lt;code&gt;.claude/Skills/CORE/Architecture.md&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;1. Clear Thinking + Prompting is King&lt;/h3&gt; 
&lt;p&gt;The quality of outcomes depends on the quality of thinking and prompts. Before any code, before any architectureâ€”there must be clear thinking.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-01-clear-thinking.png" alt="Clear Thinking + Prompting" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;2. Scaffolding &amp;gt; Model&lt;/h3&gt; 
&lt;p&gt;The system architecture matters more than the underlying AI model. A well-structured system with good scaffolding will outperform a more powerful model with poor structure.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-02-scaffolding.png" alt="Scaffolding &gt; Model" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;3. As Deterministic as Possible&lt;/h3&gt; 
&lt;p&gt;Favor predictable, repeatable outcomes over flexibility. Same input â†’ Same output. Always.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-03-deterministic.png" alt="Deterministic Systems" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;4. Code Before Prompts&lt;/h3&gt; 
&lt;p&gt;Write code to solve problems, use prompts to orchestrate code. Prompts should never replicate functionality that code can provide.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-04-code-before-prompts.png" alt="Code Before Prompts" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;5. Spec / Test / Evals First&lt;/h3&gt; 
&lt;p&gt;Define expected behavior before writing implementation. If you can't specify it, you can't test it. If you can't test it, you can't trust it.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-05-spec-test-evals.png" alt="Spec / Test / Evals First" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;6. UNIX Philosophy&lt;/h3&gt; 
&lt;p&gt;Do one thing well. Compose tools through standard interfaces. Build small, focused toolsâ€”compose them for complex operations.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-06-unix-philosophy.png" alt="UNIX Philosophy" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;7. ENG / SRE Principles&lt;/h3&gt; 
&lt;p&gt;Apply software engineering and site reliability practices to AI systems. AI infrastructure is infrastructureâ€”treat it with the same rigor.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-07-eng-sre.png" alt="ENG / SRE Principles" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;8. CLI as Interface&lt;/h3&gt; 
&lt;p&gt;Every operation should be accessible via command line. If there's no CLI command for it, you can't script it or test it reliably.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-08-cli-interface.png" alt="CLI as Interface" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;9. Goal â†’ Code â†’ CLI â†’ Prompts â†’ Agents&lt;/h3&gt; 
&lt;p&gt;The proper development pipeline for any new feature. Each layer builds on the previousâ€”skip a layer, get a shaky system.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-09-implementation-pipeline.png" alt="Implementation Pipeline" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;10. Meta / Self Update System&lt;/h3&gt; 
&lt;p&gt;The system should be able to improve itself. A system that can't update itself will stagnate.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-10-self-update.png" alt="Self-Improving System" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;11. Custom Skill Management&lt;/h3&gt; 
&lt;p&gt;Skills are the organizational unit for all domain expertise. Skills are how PAI scalesâ€”each new domain gets its own skill, maintaining organization as the system grows.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-11-skill-management.png" alt="Skill Architecture" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;12. Custom History System&lt;/h3&gt; 
&lt;p&gt;Automatic capture and preservation of valuable work. Memory makes intelligence compound. Without history, every session starts from zero.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-12-history-system.png" alt="History System" width="100%" /&gt; 
&lt;hr /&gt; 
&lt;h3&gt;13. Custom Agent Personalities / Voices&lt;/h3&gt; 
&lt;p&gt;Specialized agents with distinct personalities for different tasks. Personality isn't decorationâ€”it's functional.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/docs/images/principle-13-agent-personalities.png" alt="Agent Personalities" width="100%" /&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ› ï¸ Technology Stack&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Choice&lt;/th&gt; 
   &lt;th&gt;Note&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Runtime&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Bun&lt;/td&gt; 
   &lt;td&gt;NOT Node.js&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Language&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;TypeScript&lt;/td&gt; 
   &lt;td&gt;NOT Python&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Package Manager&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Bun&lt;/td&gt; 
   &lt;td&gt;NOT npm/yarn/pnpm&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Format&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Markdown&lt;/td&gt; 
   &lt;td&gt;NOT HTML for basic content&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Testing&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Vitest&lt;/td&gt; 
   &lt;td&gt;When needed&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Voice&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;ElevenLabs&lt;/td&gt; 
   &lt;td&gt;TTS integration&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ”„ Updating PAI&lt;/h2&gt; 
&lt;p&gt;PAI includes an intelligent sideloading system that helps you update while preserving your customizations.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# In Claude Code, run:
/paiupdate    # or just /pa
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What happens:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Your DA fetches the latest PAI to a staging area (doesn't touch your files)&lt;/li&gt; 
 &lt;li&gt;Analyzes differences between upstream and your customizations&lt;/li&gt; 
 &lt;li&gt;Generates a personalized report showing conflicts vs. safe updates&lt;/li&gt; 
 &lt;li&gt;You choose what to adopt â€” your DA handles the merge&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Your custom skills, modified hooks, and personalized settings are &lt;strong&gt;never blindly overwritten&lt;/strong&gt;. The system understands that your &lt;code&gt;env.DA&lt;/code&gt;, custom environment variables, and personal tweaks are intentional.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ’¬ Community&lt;/h2&gt; 
&lt;p&gt;Kai and I work hard to address issues and PRs throughout the week â€” we try not to get too far behind!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Channel&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ› &lt;strong&gt;Issues&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/danielmiessler/Personal_AI_Infrastructure/issues"&gt;Report bugs or request features&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ’¬ &lt;strong&gt;Discussions&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/danielmiessler/Personal_AI_Infrastructure/discussions"&gt;Ask questions and share ideas&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ¥ &lt;strong&gt;Video&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/iKwRWwabkEc"&gt;Watch the full PAI walkthrough&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ“ &lt;strong&gt;Blog&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://danielmiessler.com/blog/real-internet-of-things"&gt;The Real Internet of Things&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ“ Updates&lt;/h2&gt; 
&lt;details open&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.9.1 (2025-12-04) â€” Setup Script Fix&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;PAI_DIR Auto-Configuration&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;setup.sh&lt;/code&gt; now automatically configures &lt;code&gt;PAI_DIR&lt;/code&gt; in &lt;code&gt;settings.json&lt;/code&gt; with your actual home directory path&lt;/li&gt; 
  &lt;li&gt;No more manual editing of &lt;code&gt;__HOME__/.claude&lt;/code&gt; placeholder&lt;/li&gt; 
  &lt;li&gt;Clear error messaging if hooks fail due to misconfigured paths&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Improved Documentation&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Added &lt;code&gt;_setupNote&lt;/code&gt; in &lt;code&gt;settings.json&lt;/code&gt; explaining the fix&lt;/li&gt; 
  &lt;li&gt;Updated &lt;code&gt;_envDocs&lt;/code&gt; with troubleshooting guidance&lt;/li&gt; 
  &lt;li&gt;QUICKSTART.md troubleshooting section for PAI_DIR issues&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Bug Fix&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Fixes #110 â€” Hook failures caused by unexpanded PAI_DIR placeholder&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.9.0 (2025-12-01) â€” Platform Agnostic Release&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;This release focuses on making PAI fully portable and fork-friendly. Your AI, your identity, your system.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Observability Dashboard&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Complete real-time agent monitoring at &lt;code&gt;.claude/Skills/Observability/&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;WebSocket streaming of all agent activity&lt;/li&gt; 
  &lt;li&gt;Live pulse charts, event timelines, and swim lanes&lt;/li&gt; 
  &lt;li&gt;Multiple themes (Tokyo Night, Nord, Catppuccin, etc.)&lt;/li&gt; 
  &lt;li&gt;Security obfuscation for sensitive data&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Genericized Agent Identity&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;All agent references now use &lt;code&gt;process.env.DA || 'main'&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;No more hardcoded names â€” your DA name flows through the entire system&lt;/li&gt; 
  &lt;li&gt;Observability dashboard shows your configured identity&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Platform-Agnostic Configuration&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Clear separation: &lt;code&gt;settings.json&lt;/code&gt; for identity/paths, &lt;code&gt;.env&lt;/code&gt; for API keys&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;DA&lt;/code&gt; (Digital Assistant name) â€” your AI's identity&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;PAI_DIR&lt;/code&gt; â€” root directory for all configuration&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;TIME_ZONE&lt;/code&gt; â€” configurable timezone for timestamps&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Skill System Improvements&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Canonical TitleCase file naming throughout&lt;/li&gt; 
  &lt;li&gt;Standardized skill-workflow-notification script for dashboard detection&lt;/li&gt; 
  &lt;li&gt;All paths use &lt;code&gt;${PAI_DIR}/&lt;/code&gt; for location-agnostic installation&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.8.0 (2025-11-25) â€” Research &amp;amp; Documentation&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Research Skill&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Comprehensive research skill with 10 specialized workflows&lt;/li&gt; 
  &lt;li&gt;Multi-source research with parallel agent execution&lt;/li&gt; 
  &lt;li&gt;Fabric pattern integration (242+ AI patterns)&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Infrastructure&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Path standardization using &lt;code&gt;${PAI_DIR}/&lt;/code&gt; throughout&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;PAI_CONTRACT.md&lt;/code&gt; defining core guarantees&lt;/li&gt; 
  &lt;li&gt;Self-test validation system for health checks&lt;/li&gt; 
  &lt;li&gt;Protection system for PAI-specific files&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.7.0 (2025-11-20) â€” Protection &amp;amp; Clarity&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;PAI Path Resolution System&lt;/strong&gt; (#112)&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Centralized &lt;code&gt;pai-paths.ts&lt;/code&gt; library â€” single source of truth&lt;/li&gt; 
  &lt;li&gt;Smart detection with fallback to &lt;code&gt;~/.claude&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;Updated 7 hooks to use centralized paths&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;PAI vs Kai Clarity&lt;/strong&gt; (#113)&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;PAI_CONTRACT.md&lt;/code&gt; â€” official contract defining boundaries&lt;/li&gt; 
  &lt;li&gt;Self-test system (&lt;code&gt;bun ${PAI_DIR}/hooks/self-test.ts&lt;/code&gt;)&lt;/li&gt; 
  &lt;li&gt;Clear README section distinguishing PAI from Kai&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Protection System&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;.pai-protected.json&lt;/code&gt; manifest of protected files&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;validate-protected.ts&lt;/code&gt; script for pre-commit validation&lt;/li&gt; 
  &lt;li&gt;Pre-commit hook template for automated checks&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.6.5 (2025-11-18) â€” BrightData Integration&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Four-Tier Progressive Web Scraping&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Tier 1: WebFetch (free, built-in)&lt;/li&gt; 
  &lt;li&gt;Tier 2: cURL with headers (free, more reliable)&lt;/li&gt; 
  &lt;li&gt;Tier 3: Playwright (free, JavaScript rendering)&lt;/li&gt; 
  &lt;li&gt;Tier 4: Bright Data MCP (paid, anti-bot bypass)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.6.0 (2025-11-15) â€” Major Architecture Update&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Repository Restructure&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Moved all configuration to &lt;code&gt;.claude/&lt;/code&gt; directory&lt;/li&gt; 
  &lt;li&gt;Skills-as-containers architecture&lt;/li&gt; 
  &lt;li&gt;Three-tier progressive disclosure&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Skills System&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Art skill with visual content generation&lt;/li&gt; 
  &lt;li&gt;Story-explanation skill for narrative summaries&lt;/li&gt; 
  &lt;li&gt;Create-skill and create-cli meta-skills&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Hook System&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Comprehensive event capture system&lt;/li&gt; 
  &lt;li&gt;Session summary and tool output capture&lt;/li&gt; 
  &lt;li&gt;Tab title updates&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Voice Integration&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Voice server with ElevenLabs TTS&lt;/li&gt; 
  &lt;li&gt;Session start notifications&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;v0.5.0 and Earlier&lt;/strong&gt;&lt;/summary&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;v0.5.0 â€” Foundation&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CORE skill as central context loader&lt;/li&gt; 
  &lt;li&gt;Constitution defining system principles&lt;/li&gt; 
  &lt;li&gt;CLI-First Architecture pattern&lt;/li&gt; 
  &lt;li&gt;Initial skills: Fabric, FFUF, Alex Hormozi pitch&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;strong&gt;Pre-v0.5.0 â€” Early Development&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Initial repository setup&lt;/li&gt; 
  &lt;li&gt;Basic settings.json structure&lt;/li&gt; 
  &lt;li&gt;Agent personality definitions&lt;/li&gt; 
  &lt;li&gt;Foundational hook experiments&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ“œ License&lt;/h2&gt; 
&lt;p&gt;MIT License â€” see &lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/LICENSE"&gt;&lt;code&gt;LICENSE&lt;/code&gt;&lt;/a&gt; for details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ™ Acknowledgments&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Built on &lt;a href="https://code.claude.com"&gt;Claude Code&lt;/a&gt; by Anthropic.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;PAI is the technical foundation for &lt;a href="https://human3.unsupervised-learning.com"&gt;Human 3.0&lt;/a&gt; â€” a program I created to help people transform into a version of themselves that can thrive in the post-corporate world that's coming. Human 3.0 means AI-augmented humans who build and control their own AI systems.&lt;/p&gt; 
&lt;p&gt;Right now, the most sophisticated AI infrastructure exists inside corporations with massive engineering teams. PAI exists to change that. To give individuals the same scaffolding that companies spend millions building.&lt;/p&gt; 
&lt;p&gt;Your AI, knowing how you work, learning from your patterns, serving your goals â€” not some corporation's engagement metrics. That's what this enables.&lt;/p&gt; 
&lt;br /&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;Start clean. Start small. Build the AI infrastructure you need.&lt;/strong&gt;&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/danielmiessler/Personal_AI_Infrastructure/main/#personal-ai-infrastructure"&gt;â¬† Back to Top&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>HKUDS/DeepCode</title>
      <link>https://github.com/HKUDS/DeepCode</link>
      <description>&lt;p&gt;"DeepCode: Open Agentic Coding (Paper2Code &amp; Text2Web &amp; Text2Backend)"&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;table style="border: none; margin: 0 auto; padding: 0; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" style="vertical-align: middle; padding: 10px; border: none; width: 250px;"&gt; &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/logo.png" alt="DeepCode Logo" width="200" style="margin: 0; padding: 0; display: block;" /&gt; &lt;/td&gt; 
    &lt;td align="left" style="vertical-align: middle; padding: 10px 0 10px 30px; border: none;"&gt; &lt;pre style="font-family: 'Courier New', monospace; font-size: 16px; color: #0EA5E9; margin: 0; padding: 0; text-shadow: 0 0 10px #0EA5E9, 0 0 20px rgba(14,165,233,0.5); line-height: 1.2; transform: skew(-1deg, 0deg); display: block;"&gt;    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•      â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•&lt;/pre&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://trendshift.io/repositories/14665" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14665" alt="HKUDS%2FDeepCode | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
 &lt;!-- &lt;img src="https://readme-typing-svg.herokuapp.com?font=Russo+One&amp;size=28&amp;duration=2000&amp;pause=800&amp;color=06B6D4&amp;background=00000000&amp;center=true&amp;vCenter=true&amp;width=800&amp;height=50&amp;lines=%E2%9A%A1+OPEN+AGENTIC+CODING+%E2%9A%A1" alt="DeepCode Tech Subtitle" style="margin-top: 5px; filter: drop-shadow(0 0 12px #06B6D4) drop-shadow(0 0 24px rgba(6,182,212,0.4));"/&gt; --&gt; 
 &lt;h1&gt;&lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/43c585dca3d21b8e4b6390d835cdd34dc4b4b23d/DeepCode_images/title_logo.svg?sanitize=true" alt="DeepCode Logo" width="32" height="32" style="vertical-align: middle; margin-right: 8px;" /&gt; DeepCode: Open Agentic Coding&lt;/h1&gt; 
 &lt;h3&gt;&lt;em&gt;Advancing Code Generation with Multi-Agent Systems&lt;/em&gt;&lt;/h3&gt; 
 &lt;!-- &lt;p align="center"&gt;
  &lt;img src="https://img.shields.io/badge/Version-1.0.0-00d4ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white" alt="Version"&gt;

  &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;logo=opensourceinitiative&amp;logoColor=white" alt="License"&gt;
  &lt;img src="https://img.shields.io/badge/AI-Multi--Agent-9b59b6?style=for-the-badge&amp;logo=brain&amp;logoColor=white" alt="AI"&gt;
  &lt;img src="https://img.shields.io/badge/HKU-Data_Intelligence_Lab-f39c12?style=for-the-badge&amp;logo=university&amp;logoColor=white" alt="HKU"&gt;
&lt;/p&gt; --&gt; 
 &lt;p&gt; &lt;a href="https://github.com/HKUDS/DeepCode/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/HKUDS/DeepCode?color=00d9ff&amp;amp;style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2512.07921"&gt;&lt;img src="https://img.shields.io/badge/Paper-arXiv-orange?style=for-the-badge&amp;amp;logo=arxiv&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/ğŸPython-3.13-4ecdc4?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; 
  &lt;!-- &lt;a href="https://pypi.org/project/deepcode-hku/"&gt;&lt;img src="https://img.shields.io/pypi/v/deepcode-hku.svg?style=for-the-badge&amp;logo=pypi&amp;logoColor=white&amp;labelColor=1a1a2e&amp;color=ff6b6b"&gt;&lt;/a&gt; --&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;a href="https://discord.gg/yF2MmDJyGJ"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬Discord-Community-7289da?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/DeepCode/issues/11"&gt;&lt;img src="https://img.shields.io/badge/ğŸ’¬WeChat-Group-07c160?style=for-the-badge&amp;amp;logo=wechat&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;div style="width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);"&gt;&lt;/div&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start" style="text-decoration: none;"&gt; &lt;img src="https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;div align="center" style="margin-top: 10px;"&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README.md"&gt; &lt;img src="https://img.shields.io/badge/English-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="English" /&gt; &lt;/a&gt; 
  &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/README_ZH.md"&gt; &lt;img src="https://img.shields.io/badge/ä¸­æ–‡-00d4ff?style=for-the-badge&amp;amp;logo=readme&amp;amp;logoColor=white&amp;amp;labelColor=1a1a2e" alt="ä¸­æ–‡" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;ğŸ–¥ï¸ &lt;strong&gt;Interface Showcase&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse; margin: 30px 0;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;ğŸ–¥ï¸ &lt;strong&gt;CLI Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Terminal-Based Development&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/CLI.gif" alt="CLI Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(45,55,72,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;ğŸš€ Advanced Terminal Experience&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;âš¡ Fast command-line workflow&lt;br /&gt;ğŸ”§ Developer-friendly interface&lt;br /&gt;ğŸ“Š Real-time progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Professional terminal interface for advanced users and CI/CD integration&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td width="50%" align="center" style="vertical-align: top; padding: 20px;"&gt; &lt;h4&gt;ğŸŒ &lt;strong&gt;Web Interface&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Visual Interactive Experience&lt;/strong&gt;&lt;/p&gt; 
     &lt;div align="center"&gt; 
      &lt;img src="https://github.com/Zongwei9888/Experiment_Images/raw/8882a7313c504ca97ead6e7b36c51aa761b6a4f3/DeepCode_images/UI.gif" alt="Web Interface Demo" width="100%" style="border-radius: 10px; box-shadow: 0 8px 20px rgba(14,165,233,0.3); margin: 15px 0;" /&gt; 
      &lt;div style="background: linear-gradient(135deg, #0EA5E9 0%, #00D4FF 100%); border-radius: 12px; padding: 15px; margin: 15px 0; color: white;"&gt; 
       &lt;strong&gt;ğŸ¨ Modern Web Dashboard&lt;/strong&gt;
       &lt;br /&gt; 
       &lt;small&gt;ğŸ–±ï¸ Intuitive drag-and-drop&lt;br /&gt;ğŸ“± Responsive design&lt;br /&gt;ğŸ¯ Visual progress tracking&lt;/small&gt; 
      &lt;/div&gt; 
      &lt;p&gt;&lt;em&gt;Beautiful web interface with streamlined workflow for all skill levels&lt;/em&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;hr /&gt; 
 &lt;div align="center"&gt; 
  &lt;h3&gt;ğŸ¬ &lt;strong&gt;Introduction Video&lt;/strong&gt;&lt;/h3&gt; 
  &lt;div style="margin: 20px 0;"&gt; 
   &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.youtube.com/vi/PRgmP8pOI08/maxresdefault.jpg" alt="DeepCode Introduction Video" width="75%" style="border-radius: 12px; box-shadow: 0 8px 25px rgba(0,0,0,0.15); transition: transform 0.3s ease;" /&gt; &lt;/a&gt; 
  &lt;/div&gt; 
  &lt;p&gt;&lt;em&gt;ğŸ¯ &lt;strong&gt;Watch our complete introduction&lt;/strong&gt; - See how DeepCode transforms research papers and natural language into production-ready code&lt;/em&gt;&lt;/p&gt; 
  &lt;p&gt; &lt;a href="https://youtu.be/PRgmP8pOI08" target="_blank"&gt; &lt;img src="https://img.shields.io/badge/â–¶ï¸_Watch_Video-FF0000?style=for-the-badge&amp;amp;logo=youtube&amp;amp;logoColor=white" alt="Watch Video" /&gt; &lt;/a&gt; &lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;em&gt;"Where AI Agents Transform Ideas into Production-Ready Code"&lt;/em&gt;&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“‘ Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-news"&gt;ğŸ“° News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-key-features"&gt;ğŸš€ Key Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#%EF%B8%8F-architecture"&gt;ğŸ—ï¸ Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-experimental-results"&gt;ğŸ“Š Experimental Results&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;ğŸš€ Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-examples"&gt;ğŸ’¡ Examples&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-live-demonstrations"&gt;ğŸ¬ Live Demonstrations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-star-history"&gt;â­ Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-license"&gt;ğŸ“„ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“° News&lt;/h2&gt; 
&lt;p&gt;ğŸ‰ &lt;strong&gt;[2025-10] ğŸ‰ [2025-10-28] DeepCode Achieves SOTA on PaperBench!&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode sets new benchmarks on OpenAI's PaperBench Code-Dev across all categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ† &lt;strong&gt;Surpasses Human Experts&lt;/strong&gt;: &lt;strong&gt;75.9%&lt;/strong&gt; (DeepCode) vs Top Machine Learning PhDs 72.4% (+3.5%).&lt;/li&gt; 
 &lt;li&gt;ğŸ¥‡ &lt;strong&gt;Outperforms SOTA Commercial Code Agents&lt;/strong&gt;: &lt;strong&gt;84.8%&lt;/strong&gt; (DeepCode) vs Leading Commercial Code Agents (+26.1%) (Cursor, Claude Code, and Codex).&lt;/li&gt; 
 &lt;li&gt;ğŸ”¬ &lt;strong&gt;Advances Scientific Coding&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs PaperCoder 51.1% (+22.4%).&lt;/li&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;Beats LLM Agents&lt;/strong&gt;: &lt;strong&gt;73.5%&lt;/strong&gt; (DeepCode) vs best LLM frameworks 43.3% (+30.2%).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Key Features&lt;/h2&gt; 
&lt;br /&gt; 
&lt;table align="center" width="100%" style="border: none; table-layout: fixed;"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;ğŸš€ &lt;strong&gt;Paper2Code&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/ALGORITHM-IMPLEMENTATION-ff6b6b?style=for-the-badge&amp;amp;logo=algorithm&amp;amp;logoColor=white" alt="Algorithm Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Implementation of Complex Algorithms&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Effortlessly converts complex algorithms from research papers into &lt;strong&gt;high-quality&lt;/strong&gt;, &lt;strong&gt;production-ready&lt;/strong&gt; code, accelerating algorithm reproduction.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;ğŸ¨ &lt;strong&gt;Text2Web&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/FRONTEND-DEVELOPMENT-4ecdc4?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=white" alt="Frontend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Front-End Web Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Translates plain textual descriptions into &lt;strong&gt;fully functional&lt;/strong&gt;, &lt;strong&gt;visually appealing&lt;/strong&gt; front-end web code for rapid interface creation.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="30%" align="center" style="vertical-align: top; padding: 20px;"&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;h3 style="margin: 0; padding: 0;"&gt;âš™ï¸ &lt;strong&gt;Text2Backend&lt;/strong&gt;&lt;/h3&gt; 
    &lt;/div&gt; 
    &lt;div align="center" style="margin: 15px 0;"&gt; 
     &lt;img src="https://img.shields.io/badge/BACKEND-DEVELOPMENT-9b59b6?style=for-the-badge&amp;amp;logo=server&amp;amp;logoColor=white" alt="Backend Badge" /&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 80px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;&lt;strong&gt;Automated Back-End Development&lt;/strong&gt;&lt;/p&gt; 
    &lt;/div&gt; 
    &lt;div style="height: 60px; display: flex; align-items: center; justify-content: center;"&gt; 
     &lt;p align="center"&gt;Generates &lt;strong&gt;efficient&lt;/strong&gt;, &lt;strong&gt;scalable&lt;/strong&gt;, and &lt;strong&gt;feature-rich&lt;/strong&gt; back-end code from simple text inputs, streamlining server-side development.&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;br /&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“Š Experimental Results&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/HKUDS/DeepCode/main/assets/result_main02.jpg" /&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;We evaluate &lt;strong&gt;DeepCode&lt;/strong&gt; on the &lt;a href="https://openai.com/index/paperbench/"&gt;&lt;em&gt;PaperBench&lt;/em&gt;&lt;/a&gt; benchmark (released by OpenAI), a rigorous testbed requiring AI agents to independently reproduce 20 ICML 2024 papers from scratch. The benchmark comprises 8,316 gradable components assessed using SimpleJudge with hierarchical weighting.&lt;/p&gt; 
&lt;p&gt;Our experiments compare DeepCode against four baseline categories: &lt;strong&gt;(1) Human Experts&lt;/strong&gt;, &lt;strong&gt;(2) State-of-the-Art Commercial Code Agents&lt;/strong&gt;, &lt;strong&gt;(3) Scientific Code Agents&lt;/strong&gt;, and &lt;strong&gt;(4) LLM-Based Agents&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;â‘  ğŸ§  Human Expert Performance (Top Machine Learning PhD)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 75.9% vs. Top Machine Learning PhD: 72.4% (+3.5%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode achieves &lt;strong&gt;75.9%&lt;/strong&gt; on the 3-paper human evaluation subset, &lt;strong&gt;surpassing the best-of-3 human expert baseline (72.4%) by +3.5 percentage points&lt;/strong&gt;. This demonstrates that our framework not only matches but exceeds expert-level code reproduction capabilities, representing a significant milestone in autonomous scientific software engineering.&lt;/p&gt; 
&lt;h3&gt;â‘¡ ğŸ’¼ State-of-the-Art Commercial Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 84.8% vs. Best Commercial Agent: 58.7% (+26.1%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;On the 5-paper subset, DeepCode substantially outperforms leading commercial coding tools:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cursor: 58.4%&lt;/li&gt; 
 &lt;li&gt;Claude Code: 58.7%&lt;/li&gt; 
 &lt;li&gt;Codex: 40.0%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 84.8%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This represents a &lt;strong&gt;+26.1% improvement&lt;/strong&gt; over the leading commercial code agent. All commercial agents utilize Claude Sonnet 4.5 or GPT-5 Codex-high, highlighting that &lt;strong&gt;DeepCode's superior architecture&lt;/strong&gt;â€”rather than base model capabilityâ€”drives this performance gap.&lt;/p&gt; 
&lt;h3&gt;â‘¢ ğŸ”¬ Scientific Code Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. PaperCoder: 51.1% (+22.4%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Compared to PaperCoder (&lt;strong&gt;51.1%&lt;/strong&gt;), the state-of-the-art scientific code reproduction framework, DeepCode achieves &lt;strong&gt;73.5%&lt;/strong&gt;, demonstrating a &lt;strong&gt;+22.4% relative improvement&lt;/strong&gt;. This substantial margin validates our multi-module architecture combining planning, hierarchical task decomposition, code generation, and iterative debugging over simpler pipeline-based approaches.&lt;/p&gt; 
&lt;h3&gt;â‘£ ğŸ¤– LLM-Based Agents&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode: 73.5% vs. Best LLM Agent: 43.3% (+30.2%)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode significantly outperforms all tested LLM agents:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Claude 3.5 Sonnet + IterativeAgent: 27.5%&lt;/li&gt; 
 &lt;li&gt;o1 + IterativeAgent (36 hours): 42.4%&lt;/li&gt; 
 &lt;li&gt;o1 BasicAgent: 43.3%&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeepCode: 73.5%&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The &lt;strong&gt;+30.2% improvement&lt;/strong&gt; over the best-performing LLM agent demonstrates that sophisticated agent scaffolding, rather than extended inference time or larger models, is critical for complex code reproduction tasks.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ¯ &lt;strong&gt;Autonomous Self-Orchestrating Multi-Agent Architecture&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;The Challenges&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ“„ &lt;strong&gt;Implementation Complexity&lt;/strong&gt;: Converting academic papers and complex algorithms into working code requires significant technical effort and domain expertise&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”¬ &lt;strong&gt;Research Bottleneck&lt;/strong&gt;: Researchers spend valuable time implementing algorithms instead of focusing on their core research and discovery work&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;â±ï¸ &lt;strong&gt;Development Delays&lt;/strong&gt;: Product teams experience long wait times between concept and testable prototypes, slowing down innovation cycles&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ”„ &lt;strong&gt;Repetitive Coding&lt;/strong&gt;: Developers repeatedly implement similar patterns and functionality instead of building on existing solutions&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; addresses these workflow inefficiencies by providing reliable automation for common development tasks, streamlining your development workflow from concept to code.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart LR
    A["ğŸ“„ Research Papers&amp;lt;br/&amp;gt;ğŸ’¬ Text Prompts&amp;lt;br/&amp;gt;ğŸŒ URLs &amp;amp; Document&amp;lt;br/&amp;gt;ğŸ“ Files: PDF, DOC, PPTX, TXT, HTML"] --&amp;gt; B["ğŸ§  DeepCode&amp;lt;br/&amp;gt;Multi-Agent Engine"]
    B --&amp;gt; C["ğŸš€ Algorithm Implementation &amp;lt;br/&amp;gt;ğŸ¨ Frontend Development &amp;lt;br/&amp;gt;âš™ï¸ Backend Development"]

    style A fill:#ff6b6b,stroke:#c0392b,stroke-width:2px,color:#000
    style B fill:#00d4ff,stroke:#0984e3,stroke-width:3px,color:#000
    style C fill:#00b894,stroke:#00a085,stroke-width:2px,color:#000
&lt;/code&gt;&lt;/pre&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ—ï¸ Architecture&lt;/h2&gt; 
&lt;h3&gt;ğŸ“Š &lt;strong&gt;System Overview&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;DeepCode&lt;/strong&gt; is an AI-powered development platform that automates code generation and implementation tasks. Our multi-agent system handles the complexity of translating requirements into functional, well-structured code, allowing you to focus on innovation rather than implementation details.&lt;/p&gt; 
&lt;p&gt;ğŸ¯ &lt;strong&gt;Technical Capabilities&lt;/strong&gt;:&lt;/p&gt; 
&lt;p&gt;ğŸ§¬ &lt;strong&gt;Research-to-Production Pipeline&lt;/strong&gt;&lt;br /&gt; Multi-modal document analysis engine that extracts algorithmic logic and mathematical models from academic papers. Generates optimized implementations with proper data structures while preserving computational complexity characteristics.&lt;/p&gt; 
&lt;p&gt;ğŸª„ &lt;strong&gt;Natural Language Code Synthesis&lt;/strong&gt;&lt;br /&gt; Context-aware code generation using fine-tuned language models trained on curated code repositories. Maintains architectural consistency across modules while supporting multiple programming languages and frameworks.&lt;/p&gt; 
&lt;p&gt;âš¡ &lt;strong&gt;Automated Prototyping Engine&lt;/strong&gt;&lt;br /&gt; Intelligent scaffolding system generating complete application structures including database schemas, API endpoints, and frontend components. Uses dependency analysis to ensure scalable architecture from initial generation.&lt;/p&gt; 
&lt;p&gt;ğŸ’ &lt;strong&gt;Quality Assurance Automation&lt;/strong&gt;&lt;br /&gt; Integrated static analysis with automated unit test generation and documentation synthesis. Employs AST analysis for code correctness and property-based testing for comprehensive coverage.&lt;/p&gt; 
&lt;p&gt;ğŸ”® &lt;strong&gt;CodeRAG Integration System&lt;/strong&gt;&lt;br /&gt; Advanced retrieval-augmented generation combining semantic vector embeddings with graph-based dependency analysis. Automatically discovers optimal libraries and implementation patterns from large-scale code corpus.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ”§ &lt;strong&gt;Core Techniques&lt;/strong&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ§  &lt;strong&gt;Intelligent Orchestration Agent&lt;/strong&gt;: Central decision-making system that coordinates workflow phases and analyzes requirements. Employs dynamic planning algorithms to adapt execution strategies in real-time based on evolving project complexity. Dynamically selects optimal processing strategies for each implementation step. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ’¾ &lt;strong&gt;Efficient Memory Mechanism&lt;/strong&gt;: Advanced context engineering system that manages large-scale code contexts efficiently. Implements hierarchical memory structures with intelligent compression for handling complex codebases. This component enables instant retrieval of implementation patterns and maintains semantic coherence across extended development sessions. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ğŸ” &lt;strong&gt;Advanced CodeRAG System&lt;/strong&gt;: Global code comprehension engine that analyzes complex inter-dependencies across repositories. Performs cross-codebase relationship mapping to understand architectural patterns from a holistic perspective. This module leverages dependency graphs and semantic analysis to provide globally-aware code recommendations during implementation.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ¤– &lt;strong&gt;Multi-Agent Architecture of DeepCode&lt;/strong&gt;:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ¯ Central Orchestrating Agent&lt;/strong&gt;: Orchestrates entire workflow execution and makes strategic decisions. Coordinates specialized agents based on input complexity analysis. Implements dynamic task planning and resource allocation algorithms. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“ Intent Understanding Agent&lt;/strong&gt;: Performs deep semantic analysis of user requirements to decode complex intentions. Extracts functional specifications and technical constraints through advanced NLP processing. Transforms ambiguous human descriptions into precise, actionable development specifications with structured task decomposition. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“„ Document Parsing Agent&lt;/strong&gt;: Processes complex technical documents and research papers with advanced parsing capabilities. Extracts algorithms and methodologies using document understanding models. Converts academic concepts into practical implementation specifications through intelligent content analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ—ï¸ Code Planning Agent&lt;/strong&gt;: Performs architectural design and technology stack optimization. Dynamic planning for adaptive development roadmaps. Enforces coding standards and generates modular structures through automated design pattern selection.&lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Code Reference Mining Agent&lt;/strong&gt;: Discovers relevant repositories and frameworks through intelligent search algorithms. Analyzes codebases for compatibility and integration potential. Provides recommendations based on similarity metrics and automated dependency analysis. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ“š Code Indexing Agent&lt;/strong&gt;: Builds comprehensive knowledge graphs of discovered codebases. Maintains semantic relationships between code components. Enables intelligent retrieval and cross-reference capabilities. &lt;br /&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ§¬ Code Generation Agent&lt;/strong&gt;: Synthesizes gathered information into executable code implementations. Creates functional interfaces and integrates discovered components. Generates comprehensive test suites and documentation for reproducibility.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h4&gt;ğŸ› ï¸ &lt;strong&gt;Implementation Tools Matrix&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ”§ Powered by MCP (Model Context Protocol)&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;DeepCode leverages the &lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt; standard to seamlessly integrate with various tools and services. This standardized approach ensures reliable communication between AI agents and external systems, enabling powerful automation capabilities.&lt;/p&gt; 
&lt;h5&gt;ğŸ“¡ &lt;strong&gt;MCP Servers &amp;amp; Tools&lt;/strong&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ğŸ› ï¸ &lt;strong&gt;MCP Server&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ”§ &lt;strong&gt;Primary Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ’¡ &lt;strong&gt;Purpose &amp;amp; Capabilities&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ” brave&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Search Engine&lt;/td&gt; 
   &lt;td&gt;Real-time information retrieval via Brave Search API&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸŒ bocha-mcp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Alternative Search&lt;/td&gt; 
   &lt;td&gt;Secondary search option with independent API access&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“‚ filesystem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;File System Operations&lt;/td&gt; 
   &lt;td&gt;Local file and directory management, read/write operations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸŒ fetch&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Web Content Retrieval&lt;/td&gt; 
   &lt;td&gt;Fetch and extract content from URLs and web resources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“¥ github-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Repository Management&lt;/td&gt; 
   &lt;td&gt;Clone and download GitHub repositories for analysis&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“‹ file-downloader&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document Processing&lt;/td&gt; 
   &lt;td&gt;Download and convert files (PDF, DOCX, etc.) to Markdown&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âš¡ command-executor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;System Commands&lt;/td&gt; 
   &lt;td&gt;Execute bash/shell commands for environment management&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ§¬ code-implementation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Code Generation Hub&lt;/td&gt; 
   &lt;td&gt;Comprehensive code reproduction with execution and testing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“š code-reference-indexer&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Code Search&lt;/td&gt; 
   &lt;td&gt;Intelligent indexing and search of code repositories&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“„ document-segmentation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Smart Document Analysis&lt;/td&gt; 
   &lt;td&gt;Intelligent document segmentation for large papers and technical documents&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h5&gt;ğŸ”§ &lt;strong&gt;Legacy Tool Functions&lt;/strong&gt; &lt;em&gt;(for reference)&lt;/em&gt;&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ğŸ› ï¸ &lt;strong&gt;Function&lt;/strong&gt;&lt;/th&gt; 
   &lt;th&gt;ğŸ¯ &lt;strong&gt;Usage Context&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“„ read_code_mem&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Efficient code context retrieval from memory&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âœï¸ write_file&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Direct file content generation and modification&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ execute_python&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Python code testing and validation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“ get_file_structure&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Project structure analysis and organization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;âš™ï¸ set_workspace&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Dynamic workspace and environment configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;ğŸ“Š get_operation_history&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Process monitoring and operation tracking&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;p&gt;ğŸ›ï¸ &lt;strong&gt;Multi-Interface Framework&lt;/strong&gt;&lt;br /&gt; RESTful API with CLI and web frontends featuring real-time code streaming, interactive debugging, and extensible plugin architecture for CI/CD integration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ğŸš€ Multi-Agent Intelligent Pipeline:&lt;/strong&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;ğŸŒŸ &lt;strong&gt;Intelligence Processing Flow&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" width="100%" style="border: none; border-collapse: collapse;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; ğŸ’¡ &lt;strong&gt;INPUT LAYER&lt;/strong&gt;&lt;br /&gt; ğŸ“„ Research Papers â€¢ ğŸ’¬ Natural Language â€¢ ğŸŒ URLs â€¢ ğŸ“‹ Requirements &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="20"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ¯ &lt;strong&gt;CENTRAL ORCHESTRATION&lt;/strong&gt;&lt;br /&gt; Strategic Decision Making â€¢ Workflow Coordination â€¢ Agent Management &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #3742fa 0%, #2f3542 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“ &lt;strong&gt;TEXT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Requirement Processing&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #8c7ae6 0%, #9c88ff 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“„ &lt;strong&gt;DOCUMENT ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Paper &amp;amp; Spec Processing&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #00d2d3 0%, #54a0ff 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ“‹ &lt;strong&gt;REPRODUCTION PLANNING&lt;/strong&gt;&lt;br /&gt; Deep Paper Analysis â€¢ Code Requirements Parsing â€¢ Reproduction Strategy Development &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #ffa726 0%, #ff7043 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ” &lt;strong&gt;REFERENCE ANALYSIS&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Repository Discovery&lt;/small&gt; &lt;/td&gt; 
    &lt;td width="10"&gt;&lt;/td&gt; 
    &lt;td align="center" style="padding: 12px; background: linear-gradient(135deg, #e056fd 0%, #f368e0 100%); border-radius: 10px; color: white; width: 50%;"&gt; ğŸ“š &lt;strong&gt;CODE INDEXING&lt;/strong&gt;&lt;br /&gt; &lt;small&gt;Knowledge Graph Building&lt;/small&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 15px; background: linear-gradient(135deg, #26de81 0%, #20bf6b 100%); border-radius: 12px; color: white; font-weight: bold;"&gt; ğŸ§¬ &lt;strong&gt;CODE IMPLEMENTATION&lt;/strong&gt;&lt;br /&gt; Implementation Generation â€¢ Testing â€¢ Documentation &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td colspan="3" height="15"&gt;&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td colspan="3" align="center" style="padding: 20px; background: linear-gradient(135deg, #045de9 0%, #09c6f9 100%); border-radius: 15px; color: white; font-weight: bold;"&gt; âš¡ &lt;strong&gt;OUTPUT DELIVERY&lt;/strong&gt;&lt;br /&gt; ğŸ“¦ Complete Codebase â€¢ ğŸ§ª Test Suite â€¢ ğŸ“š Documentation â€¢ ğŸš€ Deployment Ready &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;ğŸ”„ &lt;strong&gt;Process Intelligence Features&lt;/strong&gt;&lt;/h3&gt; 
 &lt;table align="center" style="border: none;"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #ff6b6b;"&gt; 
      &lt;h4&gt;ğŸ¯ Adaptive Flow&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Dynamic agent selection based on input complexity&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #4ecdc4;"&gt; 
      &lt;h4&gt;ğŸ§  Smart Coordination&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Intelligent task distribution and parallel processing&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #45b7d1;"&gt; 
      &lt;h4&gt;ğŸ” Context Awareness&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Deep understanding through CodeRAG integration&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
    &lt;td align="center" width="25%" style="padding: 15px;"&gt; 
     &lt;div style="background: #f8f9fa; border-radius: 10px; padding: 15px; border-left: 4px solid #96ceb4;"&gt; 
      &lt;h4&gt;âš¡ Quality Assurance&lt;/h4&gt; 
      &lt;p&gt;&lt;small&gt;Automated testing and validation throughout&lt;/small&gt;&lt;/p&gt; 
     &lt;/div&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;h3&gt;ğŸ“¦ &lt;strong&gt;Step 1: Installation&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;âš¡ &lt;strong&gt;Direct Installation (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸš€ Install DeepCode package directly
pip install deepcode-hku

# ğŸ”‘ Download configuration files
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.config.yaml
curl -O https://raw.githubusercontent.com/HKUDS/DeepCode/main/mcp_agent.secrets.yaml

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)
# - google: api_key (for Gemini models)

# ğŸ¤– Select your preferred LLM provider (optional)
# Edit mcp_agent.config.yaml to choose your LLM (line ~106):
# - llm_provider: "google"    # Use Google Gemini models
# - llm_provider: "anthropic" # Use Anthropic Claude models
# - llm_provider: "openai"    # Use OpenAI/compatible models
# Note: If not set or unavailable, will automatically fallback to first available provider

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ğŸ”§ &lt;strong&gt;Development Installation (From Source)&lt;/strong&gt;&lt;/h4&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“‚ Click to expand development installation options&lt;/strong&gt;&lt;/summary&gt; 
 &lt;h5&gt;ğŸ”¥ &lt;strong&gt;Using UV (Recommended for Development)&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸ”½ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# ğŸ“¦ Install UV package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# ğŸ”§ Install dependencies with UV
uv venv --python=3.13
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -r requirements.txt

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)
# - google: api_key (for Gemini models)

# ğŸ¤– Select your preferred LLM provider (optional)
# Edit mcp_agent.config.yaml to choose your LLM (line ~106):
# - llm_provider: "google"    # Use Google Gemini models
# - llm_provider: "anthropic" # Use Anthropic Claude models
# - llm_provider: "openai"    # Use OpenAI/compatible models
# Note: If not set or unavailable, will automatically fallback to first available provider

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h5&gt;ğŸ &lt;strong&gt;Using Traditional pip&lt;/strong&gt;&lt;/h5&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸ”½ Clone the repository
git clone https://github.com/HKUDS/DeepCode.git
cd DeepCode/

# ğŸ“¦ Install dependencies
pip install -r requirements.txt

# ğŸ”‘ Configure API keys (required)
# Edit mcp_agent.secrets.yaml with your API keys and base_url:
# - openai: api_key, base_url (for OpenAI/custom endpoints)
# - anthropic: api_key (for Claude models)
# - google: api_key (for Gemini models)

# ğŸ¤– Select your preferred LLM provider (optional)
# Edit mcp_agent.config.yaml to choose your LLM (line ~106):
# - llm_provider: "google"    # Use Google Gemini models
# - llm_provider: "anthropic" # Use Anthropic Claude models
# - llm_provider: "openai"    # Use OpenAI/compatible models
# Note: If not set or unavailable, will automatically fallback to first available provider

# ğŸ”‘ Configure search API keys for web search (optional)
# Edit mcp_agent.config.yaml to set your API keys:
# - For Brave Search: Set BRAVE_API_KEY: "your_key_here" in brave.env section (line ~28)
# - For Bocha-MCP: Set BOCHA_API_KEY: "your_key_here" in bocha-mcp.env section (line ~74)

# ğŸ“„ Configure document segmentation (optional)
# Edit mcp_agent.config.yaml to control document processing:
# - enabled: true/false (whether to use intelligent document segmentation)
# - size_threshold_chars: 50000 (document size threshold to trigger segmentation)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h4&gt;ğŸªŸ &lt;strong&gt;Windows Users: Additional MCP Server Configuration&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;If you're using Windows, you may need to configure MCP servers manually in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Install MCP servers globally
npm i -g @modelcontextprotocol/server-brave-search
npm i -g @modelcontextprotocol/server-filesystem

# 2. Find your global node_modules path
npm -g root
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then update your &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt; to use absolute paths:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;mcp:
  servers:
    brave:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-brave-search/dist/index.js"]
    filesystem:
      command: "node"
      args: ["C:/Program Files/nodejs/node_modules/@modelcontextprotocol/server-filesystem/dist/index.js", "."]
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Replace the path with your actual global node_modules path from step 2.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;ğŸ” &lt;strong&gt;Search Server Configuration (Optional)&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;DeepCode supports multiple search servers for web search functionality. You can configure your preferred option in &lt;code&gt;mcp_agent.config.yaml&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# Default search server configuration
# Options: "brave" or "bocha-mcp"
default_search_server: "brave"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Available Options:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸ” Brave Search&lt;/strong&gt; (&lt;code&gt;"brave"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Default option with high-quality search results&lt;/li&gt; 
   &lt;li&gt;Requires BRAVE_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Recommended for most users&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ğŸŒ Bocha-MCP&lt;/strong&gt; (&lt;code&gt;"bocha-mcp"&lt;/code&gt;):&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Alternative search server option&lt;/li&gt; 
   &lt;li&gt;Requires BOCHA_API_KEY configuration&lt;/li&gt; 
   &lt;li&gt;Uses local Python server implementation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;API Key Configuration in mcp_agent.config.yaml:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# For Brave Search (default) - around line 28
brave:
  command: "npx"
  args: ["-y", "@modelcontextprotocol/server-brave-search"]
  env:
    BRAVE_API_KEY: "your_brave_api_key_here"

# For Bocha-MCP (alternative) - around line 74
bocha-mcp:
  command: "python"
  args: ["tools/bocha_search_server.py"]
  env:
    PYTHONPATH: "."
    BOCHA_API_KEY: "your_bocha_api_key_here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;ğŸ’¡ Tip&lt;/strong&gt;: Both search servers require API key configuration. Choose the one that best fits your API access and requirements.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;âš¡ &lt;strong&gt;Step 2: Launch Application&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;ğŸš€ &lt;strong&gt;Using Installed Package (Recommended)&lt;/strong&gt;&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ğŸŒ Launch web interface directly
deepcode

# The application will automatically start at http://localhost:8501
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;ğŸ› ï¸ &lt;strong&gt;Using Source Code&lt;/strong&gt;&lt;/h4&gt; 
&lt;p&gt;Choose your preferred interface:&lt;/p&gt; 
&lt;h5&gt;ğŸŒ &lt;strong&gt;Web Interface&lt;/strong&gt; (Recommended)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run streamlit run ui/streamlit_app.py
# Or using traditional Python
streamlit run ui/streamlit_app.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Access-localhost:8501-00d4ff?style=flat-square&amp;amp;logo=streamlit&amp;amp;logoColor=white" alt="Web Access" /&gt; 
&lt;/div&gt; 
&lt;h5&gt;ğŸ–¥ï¸ &lt;strong&gt;CLI Interface&lt;/strong&gt; (Advanced Users)&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Using UV
uv run python cli/main_cli.py
# Or using traditional Python
python cli/main_cli.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://img.shields.io/badge/Mode-Interactive_Terminal-9b59b6?style=flat-square&amp;amp;logo=terminal&amp;amp;logoColor=white" alt="CLI Mode" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;ğŸ¯ &lt;strong&gt;Step 3: Generate Code&lt;/strong&gt;&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“„ Input&lt;/strong&gt;: Upload your research paper, provide requirements, or paste a URL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– Processing&lt;/strong&gt;: Watch the multi-agent system analyze and plan&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Output&lt;/strong&gt;: Receive production-ready code with tests and documentation&lt;/li&gt; 
&lt;/ol&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ’¡ Examples&lt;/h2&gt; 
&lt;h3&gt;ğŸ¬ &lt;strong&gt;Live Demonstrations&lt;/strong&gt;&lt;/h3&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸ“„ &lt;strong&gt;Paper2Code Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Research to Implementation&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt; &lt;img src="https://img.youtube.com/vi/MQZYpLkzsbw/maxresdefault.jpg" alt="Paper2Code Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=MQZYpLkzsbw"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Transform academic papers into production-ready code automatically&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸ–¼ï¸ &lt;strong&gt;Image Processing Demo&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;AI-Powered Image Tools&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt; &lt;img src="https://img.youtube.com/vi/nFt5mLaMEac/maxresdefault.jpg" alt="Image Processing Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=nFt5mLaMEac"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Intelligent image processing with background removal and enhancement&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
   &lt;td width="33%" align="center"&gt; &lt;h4&gt;ğŸŒ &lt;strong&gt;Frontend Implementation&lt;/strong&gt;&lt;/h4&gt; &lt;p&gt;&lt;strong&gt;Complete Web Application&lt;/strong&gt;&lt;/p&gt; 
    &lt;div align="center"&gt; 
     &lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt; &lt;img src="https://img.youtube.com/vi/78wx3dkTaAU/maxresdefault.jpg" alt="Frontend Demo" width="100%" style="border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);" /&gt; &lt;/a&gt; 
     &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.youtube.com/watch?v=78wx3dkTaAU"&gt;â–¶ï¸ Watch Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
     &lt;p&gt;&lt;em&gt;Full-stack web development from concept to deployment&lt;/em&gt;&lt;/p&gt; 
    &lt;/div&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;ğŸ†• &lt;strong&gt;Recent Updates&lt;/strong&gt;&lt;/h3&gt; 
&lt;h4&gt;ğŸ“„ &lt;strong&gt;Smart Document Segmentation (v1.2.0)&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Processing&lt;/strong&gt;: Automatically handles large research papers and technical documents that exceed LLM token limits&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configurable Control&lt;/strong&gt;: Toggle segmentation via configuration with size-based thresholds&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Semantic Analysis&lt;/strong&gt;: Advanced content understanding with algorithm, concept, and formula preservation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backward Compatibility&lt;/strong&gt;: Seamlessly falls back to traditional processing for smaller documents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸš€ &lt;strong&gt;Coming Soon&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;We're continuously enhancing DeepCode with exciting new features:&lt;/p&gt; 
&lt;h4&gt;ğŸ”§ &lt;strong&gt;Enhanced Code Reliability &amp;amp; Validation&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Automated Testing&lt;/strong&gt;: Comprehensive functionality testing with execution verification and error detection.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Quality Assurance&lt;/strong&gt;: Multi-level validation through static analysis, dynamic testing, and performance benchmarking.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Debugging&lt;/strong&gt;: AI-powered error detection with automatic correction suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ğŸ“Š &lt;strong&gt;PaperBench Performance Showcase&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Benchmark Dashboard&lt;/strong&gt;: Comprehensive performance metrics on the PaperBench evaluation suite.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accuracy Metrics&lt;/strong&gt;: Detailed comparison with state-of-the-art paper reproduction systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Success Analytics&lt;/strong&gt;: Statistical analysis across paper categories and complexity levels.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;âš¡ &lt;strong&gt;System-wide Optimizations&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Performance Boost&lt;/strong&gt;: Multi-threaded processing and optimized agent coordination for faster generation.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Reasoning&lt;/strong&gt;: Advanced reasoning capabilities with improved context understanding.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Expanded Support&lt;/strong&gt;: Extended compatibility with additional programming languages and frameworks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;â­ Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;em&gt;Community Growth Trajectory&lt;/em&gt;&lt;/p&gt; 
 &lt;a href="https://star-history.com/#HKUDS/DeepCode&amp;amp;Date"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" /&gt; 
   &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=HKUDS/DeepCode&amp;amp;type=Date" style="border-radius: 15px; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸš€ &lt;strong&gt;Ready to Transform Development?&lt;/strong&gt;&lt;/h3&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://raw.githubusercontent.com/HKUDS/DeepCode/main/#-quick-start"&gt;&lt;img src="https://img.shields.io/badge/ğŸš€_Get_Started-00d4ff?style=for-the-badge&amp;amp;logo=rocket&amp;amp;logoColor=white" alt="Get Started" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS"&gt;&lt;img src="https://img.shields.io/badge/ğŸ›ï¸_View_on_GitHub-00d4ff?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="View on GitHub" /&gt;&lt;/a&gt; &lt;a href="https://github.com/HKUDS/deepcode-agent"&gt;&lt;img src="https://img.shields.io/badge/â­_Star_Project-00d4ff?style=for-the-badge&amp;amp;logo=star&amp;amp;logoColor=white" alt="Star Project" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;div align="left"&gt; 
  &lt;h3&gt;ğŸ“– &lt;strong&gt;Citation&lt;/strong&gt;&lt;/h3&gt; 
  &lt;p&gt;If you find DeepCode useful in your research or applications, please kindly cite:&lt;/p&gt; 
  &lt;pre&gt;&lt;code&gt;@misc{li2025deepcodeopenagenticcoding,
      title={DeepCode: Open Agentic Coding}, 
      author={Zongwei Li and Zhonghang Li and Zirui Guo and Xubin Ren and Chao Huang},
      year={2025},
      eprint={2512.07921},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2512.07921}, 
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;hr /&gt; 
  &lt;h3&gt;ğŸ“„ &lt;strong&gt;License&lt;/strong&gt;&lt;/h3&gt; 
  &lt;div align="center"&gt; 
   &lt;img src="https://img.shields.io/badge/License-MIT-4ecdc4?style=for-the-badge&amp;amp;logo=opensourceinitiative&amp;amp;logoColor=white" alt="MIT License" /&gt; 
   &lt;p&gt;&lt;strong&gt;MIT License&lt;/strong&gt; - Copyright (c) 2025 Data Intelligence Lab, The University of Hong Kong&lt;/p&gt; 
   &lt;hr /&gt; 
   &lt;img src="https://visitor-badge.laobi.icu/badge?page_id=deepcode.readme&amp;amp;style=for-the-badge&amp;amp;color=00d4ff" alt="Visitors" /&gt; 
  &lt;/div&gt; 
 &lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Tencent/WeKnora</title>
      <link>https://github.com/Tencent/WeKnora</link>
      <description>&lt;p&gt;LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/logo.png" alt="WeKnora Logo" height="120" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;a href="https://trendshift.io/repositories/15289" target="_blank"&gt; &lt;img src="https://trendshift.io/api/badge/repositories/15289" alt="Tencent%2FWeKnora | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt; &lt;/a&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://weknora.weixin.qq.com" target="_blank"&gt; &lt;img alt="å®˜æ–¹ç½‘ç«™" src="https://img.shields.io/badge/å®˜æ–¹ç½‘ç«™-WeKnora-4e6b99" /&gt; &lt;/a&gt; &lt;a href="https://chatbot.weixin.qq.com" target="_blank"&gt; &lt;img alt="å¾®ä¿¡å¯¹è¯å¼€æ”¾å¹³å°" src="https://img.shields.io/badge/å¾®ä¿¡å¯¹è¯å¼€æ”¾å¹³å°-5ac725" /&gt; &lt;/a&gt; &lt;a href="https://github.com/Tencent/WeKnora/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;amp;color=2e6cc4" alt="License" /&gt; &lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/CHANGELOG.md"&gt; &lt;img alt="Version" src="https://img.shields.io/badge/version-0.2.5-2e6cc4?labelColor=d4eaf7" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; | &lt;b&gt;English&lt;/b&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_CN.md"&gt;&lt;b&gt;ç®€ä½“ä¸­æ–‡&lt;/b&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/README_JA.md"&gt;&lt;b&gt;æ—¥æœ¬èª&lt;/b&gt;&lt;/a&gt; | &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h4 align="center"&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-overview"&gt;Overview&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-architecture"&gt;Architecture&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-key-features"&gt;Key Features&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-getting-started"&gt;Getting Started&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-api-reference"&gt;API Reference&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/#-developer-guide"&gt;Developer Guide&lt;/a&gt;&lt;/p&gt; &lt;/h4&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h1&gt;ğŸ’¡ WeKnora - LLM-Powered Document Understanding &amp;amp; Retrieval Framework&lt;/h1&gt; 
&lt;h2&gt;ğŸ“Œ Overview&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://weknora.weixin.qq.com"&gt;&lt;strong&gt;WeKnora&lt;/strong&gt;&lt;/a&gt; is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents.&lt;/p&gt; 
&lt;p&gt;It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the &lt;strong&gt;RAG (Retrieval-Augmented Generation)&lt;/strong&gt; paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Website:&lt;/strong&gt; &lt;a href="https://weknora.weixin.qq.com"&gt;https://weknora.weixin.qq.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;âœ¨ Latest Updates&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;v0.2.0 Highlights:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ¤– &lt;strong&gt;Agent Mode&lt;/strong&gt;: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;ğŸ“š &lt;strong&gt;Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry&lt;/li&gt; 
 &lt;li&gt;âš™ï¸ &lt;strong&gt;Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;ğŸŒ &lt;strong&gt;Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;ğŸ”Œ &lt;strong&gt;MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;ğŸ¨ &lt;strong&gt;New UI&lt;/strong&gt;: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade&lt;/li&gt; 
 &lt;li&gt;âš¡ &lt;strong&gt;Infrastructure Upgrade&lt;/strong&gt;: Introduced MQ async task management, support for automatic database migration, and fast development mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ”’ Security Notice&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Deploy WeKnora services in internal/private network environments rather than public internet&lt;/li&gt; 
 &lt;li&gt;Avoid exposing the service directly to public networks to prevent potential information leakage&lt;/li&gt; 
 &lt;li&gt;Configure proper firewall rules and access controls for your deployment environment&lt;/li&gt; 
 &lt;li&gt;Regularly update to the latest version for security patches and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ—ï¸ Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/architecture.png" alt="weknora-architecture.png" /&gt;&lt;/p&gt; 
&lt;p&gt;WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.&lt;/p&gt; 
&lt;h2&gt;ğŸ¯ Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– Agent Mode&lt;/strong&gt;: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ” Precise Understanding&lt;/strong&gt;: Structured content extraction from PDFs, Word documents, images and more into unified semantic views&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ§  Intelligent Reasoning&lt;/strong&gt;: Leverages LLMs to understand document context and user intent for accurate Q&amp;amp;A and multi-turn conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“š Multi-Type Knowledge Bases&lt;/strong&gt;: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Flexible Extension&lt;/strong&gt;: All components from parsing and embedding to retrieval and generation are decoupled for easy customization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Efficient Retrieval&lt;/strong&gt;: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸŒ Web Search&lt;/strong&gt;: Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”Œ MCP Tool Integration&lt;/strong&gt;: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš™ï¸ Conversation Strategy&lt;/strong&gt;: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¯ User-Friendly&lt;/strong&gt;: Intuitive web interface and standardized APIs for zero technical barriers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”’ Secure &amp;amp; Controlled&lt;/strong&gt;: Support for local deployment and private cloud, ensuring complete data sovereignty&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“Š Application Scenarios&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Scenario&lt;/th&gt; 
   &lt;th&gt;Applications&lt;/th&gt; 
   &lt;th&gt;Core Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Enterprise Knowledge Management&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Internal document retrieval, policy Q&amp;amp;A, operation manual search&lt;/td&gt; 
   &lt;td&gt;Improve knowledge discovery efficiency, reduce training costs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Academic Research Analysis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Paper retrieval, research report analysis, scholarly material organization&lt;/td&gt; 
   &lt;td&gt;Accelerate literature review, assist research decisions&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Product Technical Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Product manual Q&amp;amp;A, technical documentation search, troubleshooting&lt;/td&gt; 
   &lt;td&gt;Enhance customer service quality, reduce support burden&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Legal &amp;amp; Compliance Review&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Contract clause retrieval, regulatory policy search, case analysis&lt;/td&gt; 
   &lt;td&gt;Improve compliance efficiency, reduce legal risks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Medical Knowledge Assistance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Medical literature retrieval, treatment guideline search, case analysis&lt;/td&gt; 
   &lt;td&gt;Support clinical decisions, improve diagnosis quality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ğŸ§© Feature Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Module&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Agent Mode&lt;/td&gt; 
   &lt;td&gt;âœ… ReACT Agent Mode&lt;/td&gt; 
   &lt;td&gt;Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Knowledge Base Types&lt;/td&gt; 
   &lt;td&gt;âœ… FAQ / Document&lt;/td&gt; 
   &lt;td&gt;Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Document Formats&lt;/td&gt; 
   &lt;td&gt;âœ… PDF / Word / Txt / Markdown / Images (with OCR / Caption)&lt;/td&gt; 
   &lt;td&gt;Support for structured and unstructured documents with text extraction from images&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model Management&lt;/td&gt; 
   &lt;td&gt;âœ… Centralized configuration, built-in model sharing&lt;/td&gt; 
   &lt;td&gt;Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Embedding Models&lt;/td&gt; 
   &lt;td&gt;âœ… Local models, BGE / GTE APIs, etc.&lt;/td&gt; 
   &lt;td&gt;Customizable embedding models, compatible with local deployment and cloud vector generation APIs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vector DB Integration&lt;/td&gt; 
   &lt;td&gt;âœ… PostgreSQL (pgvector), Elasticsearch&lt;/td&gt; 
   &lt;td&gt;Support for mainstream vector index backends, flexible switching for different retrieval scenarios&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Retrieval Strategies&lt;/td&gt; 
   &lt;td&gt;âœ… BM25 / Dense Retrieval / GraphRAG&lt;/td&gt; 
   &lt;td&gt;Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;LLM Integration&lt;/td&gt; 
   &lt;td&gt;âœ… Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching&lt;/td&gt; 
   &lt;td&gt;Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Conversation Strategy&lt;/td&gt; 
   &lt;td&gt;âœ… Agent models, normal mode models, retrieval thresholds, Prompt configuration&lt;/td&gt; 
   &lt;td&gt;Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Web Search&lt;/td&gt; 
   &lt;td&gt;âœ… Extensible search engines, DuckDuckGo&lt;/td&gt; 
   &lt;td&gt;Support for extensible web search engines with built-in DuckDuckGo search engine&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MCP Tools&lt;/td&gt; 
   &lt;td&gt;âœ… uvx, npx launchers, Stdio/HTTP Streamable/SSE&lt;/td&gt; 
   &lt;td&gt;Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;QA Capabilities&lt;/td&gt; 
   &lt;td&gt;âœ… Context-aware, multi-turn dialogue, prompt templates&lt;/td&gt; 
   &lt;td&gt;Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;amp;A with configurable prompts and context windows&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;E2E Testing&lt;/td&gt; 
   &lt;td&gt;âœ… Retrieval+generation process visualization and metric evaluation&lt;/td&gt; 
   &lt;td&gt;End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Deployment Modes&lt;/td&gt; 
   &lt;td&gt;âœ… Support for local deployment / Docker images&lt;/td&gt; 
   &lt;td&gt;Meets private, offline deployment and flexible operation requirements, with fast development mode support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;User Interfaces&lt;/td&gt; 
   &lt;td&gt;âœ… Web UI + RESTful API&lt;/td&gt; 
   &lt;td&gt;Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Task Management&lt;/td&gt; 
   &lt;td&gt;âœ… MQ async tasks, automatic database migration&lt;/td&gt; 
   &lt;td&gt;MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ğŸš€ Getting Started&lt;/h2&gt; 
&lt;h3&gt;ğŸ›  Prerequisites&lt;/h3&gt; 
&lt;p&gt;Make sure the following tools are installed on your system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://git-scm.com/"&gt;Git&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ“¦ Installation&lt;/h3&gt; 
&lt;h4&gt;â‘  Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;â‘¡ Configure environment variables&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;â‘¢ Start the services (include Ollama)&lt;/h4&gt; 
&lt;p&gt;Check the images that need to be started in the .env file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;â‘¢.0 Start ollama services (Optional)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama serve &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;â‘¢.1 Activate different combinations of features&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minimum core services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;All features enabled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile full up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tracing logs required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile jaeger up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Neo4j knowledge graph required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Minio file storage service required&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple options combination&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose --profile neo4j --profile minio up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;â‘£ Stop the services&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
# Or
make stop-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸŒ Access Services&lt;/h3&gt; 
&lt;p&gt;Once started, services will be available at:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Web UI: &lt;code&gt;http://localhost&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Backend API: &lt;code&gt;http://localhost:8080&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Jaeger Tracing: &lt;code&gt;http://localhost:16686&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ”Œ Using WeChat Dialog Open Platform&lt;/h3&gt; 
&lt;p&gt;WeKnora serves as the core technology framework for the &lt;a href="https://chatbot.weixin.qq.com"&gt;WeChat Dialog Open Platform&lt;/a&gt;, providing a more convenient usage approach:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Zero-code Deployment&lt;/strong&gt;: Simply upload knowledge to quickly deploy intelligent Q&amp;amp;A services within the WeChat ecosystem, achieving an "ask and answer" experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Efficient Question Management&lt;/strong&gt;: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;WeChat Ecosystem Integration&lt;/strong&gt;: Through the WeChat Dialog Open Platform, WeKnora's intelligent Q&amp;amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ”— Access WeKnora via MCP Server&lt;/h3&gt; 
&lt;h4&gt;1ï¸âƒ£ Clone the repository&lt;/h4&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/Tencent/WeKnora
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2ï¸âƒ£ Configure MCP Server&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;It is recommended to directly refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for configuration.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Configure the MCP client to connect to the server:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "weknora": {
      "args": [
        "path/to/WeKnora/mcp-server/run_server.py"
      ],
      "command": "python",
      "env":{
        "WEKNORA_API_KEY":"Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk",
        "WEKNORA_BASE_URL":"http(s)://your-weknora-address/api/v1"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run directly using stdio command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pip install weknora-mcp-server
python -m weknora-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ”§ Initialization Configuration Guide&lt;/h2&gt; 
&lt;p&gt;To help users quickly configure various models and reduce trial-and-error costs, we've improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows: If this is your first time using this project, you can skip steps â‘ â‘¡ and go directly to steps â‘¢â‘£.&lt;/p&gt; 
&lt;h3&gt;â‘  Stop the services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh --stop
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;â‘¡ Clear existing data tables (recommended when no important data exists)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make clean-db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;â‘¢ Compile and start services&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./scripts/start_all.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;â‘£ Access Web UI&lt;/h3&gt; 
&lt;p&gt;&lt;a href="http://localhost"&gt;http://localhost&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.&lt;/p&gt; 
&lt;h2&gt;ğŸ“± Interface Showcase&lt;/h2&gt; 
&lt;h3&gt;Web UI Interface&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/knowledgebases.png" alt="Knowledge Base Management" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/settings.png" alt="Conversation Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td colspan="2"&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br /&gt;&lt;img src="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/images/agent-qa.png" alt="Agent Mode Tool Call Process" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Knowledge Base Management:&lt;/strong&gt; Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Agent Mode:&lt;/strong&gt; Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Conversation Strategy:&lt;/strong&gt; Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.&lt;/p&gt; 
&lt;h3&gt;Document Knowledge Graph&lt;/h3&gt; 
&lt;p&gt;WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.&lt;/p&gt; 
&lt;p&gt;For detailed configuration, please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/KnowledgeGraph.md"&gt;Knowledge Graph Configuration Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;MCP Server&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/mcp-server/MCP_CONFIG.md"&gt;MCP Configuration Guide&lt;/a&gt; for the necessary setup.&lt;/p&gt; 
&lt;h2&gt;ğŸ“˜ API Reference&lt;/h2&gt; 
&lt;p&gt;Troubleshooting FAQ: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/QA.md"&gt;Troubleshooting FAQ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Detailed API documentation is available at: &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/API.md"&gt;API Docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ§­ Developer Guide&lt;/h2&gt; 
&lt;h3&gt;âš¡ Fast Development Mode (Recommended)&lt;/h3&gt; 
&lt;p&gt;If you need to frequently modify code, &lt;strong&gt;you don't need to rebuild Docker images every time&lt;/strong&gt;! Use fast development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Method 1: Using Make commands (Recommended)
make dev-start      # Start infrastructure
make dev-app        # Start backend (new terminal)
make dev-frontend   # Start frontend (new terminal)

# Method 2: One-click start
./scripts/quick-dev.sh

# Method 3: Using scripts
./scripts/dev.sh start     # Start infrastructure
./scripts/dev.sh app       # Start backend (new terminal)
./scripts/dev.sh frontend  # Start frontend (new terminal)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Development Advantages:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… Frontend modifications auto hot-reload (no restart needed)&lt;/li&gt; 
 &lt;li&gt;âœ… Backend modifications quick restart (5-10 seconds, supports Air hot-reload)&lt;/li&gt; 
 &lt;li&gt;âœ… No need to rebuild Docker images&lt;/li&gt; 
 &lt;li&gt;âœ… Support IDE breakpoint debugging&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Detailed Documentation:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/docs/%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97.md"&gt;Development Environment Quick Start&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;ğŸ“ Directory Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;WeKnora/
â”œâ”€â”€ client/      # go client
â”œâ”€â”€ cmd/         # Main entry point
â”œâ”€â”€ config/      # Configuration files
â”œâ”€â”€ docker/      # docker images files
â”œâ”€â”€ docreader/   # Document parsing app
â”œâ”€â”€ docs/        # Project documentation
â”œâ”€â”€ frontend/    # Frontend app
â”œâ”€â”€ internal/    # Core business logic
â”œâ”€â”€ mcp-server/  # MCP server
â”œâ”€â”€ migrations/  # DB migration scripts
â””â”€â”€ scripts/     # Shell scripts
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome community contributions! For suggestions, bugs, or feature requests, please submit an &lt;a href="https://github.com/Tencent/WeKnora/issues"&gt;Issue&lt;/a&gt; or directly create a Pull Request.&lt;/p&gt; 
&lt;h3&gt;ğŸ¯ How to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› &lt;strong&gt;Bug Fixes&lt;/strong&gt;: Discover and fix system defects&lt;/li&gt; 
 &lt;li&gt;âœ¨ &lt;strong&gt;New Features&lt;/strong&gt;: Propose and implement new capabilities&lt;/li&gt; 
 &lt;li&gt;ğŸ“š &lt;strong&gt;Documentation&lt;/strong&gt;: Improve project documentation&lt;/li&gt; 
 &lt;li&gt;ğŸ§ª &lt;strong&gt;Test Cases&lt;/strong&gt;: Write unit and integration tests&lt;/li&gt; 
 &lt;li&gt;ğŸ¨ &lt;strong&gt;UI/UX Enhancements&lt;/strong&gt;: Improve user interface and experience&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ“‹ Contribution Process&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork the project&lt;/strong&gt; to your GitHub account&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a feature branch&lt;/strong&gt; &lt;code&gt;git checkout -b feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Commit changes&lt;/strong&gt; &lt;code&gt;git commit -m 'Add amazing feature'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Push branch&lt;/strong&gt; &lt;code&gt;git push origin feature/amazing-feature&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Create a Pull Request&lt;/strong&gt; with detailed description of changes&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸ¨ Code Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow &lt;a href="https://github.com/golang/go/wiki/CodeReviewComments"&gt;Go Code Review Comments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Format code using &lt;code&gt;gofmt&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Add necessary unit tests&lt;/li&gt; 
 &lt;li&gt;Update relevant documentation&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ“ Commit Guidelines&lt;/h3&gt; 
&lt;p&gt;Use &lt;a href="https://www.conventionalcommits.org/"&gt;Conventional Commits&lt;/a&gt; standard:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;feat: Add document batch upload functionality
fix: Resolve vector retrieval precision issue
docs: Update API documentation
test: Add retrieval engine test cases
refactor: Restructure document parsing module
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ‘¥ Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to these excellent contributors:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Tencent/WeKnora/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=Tencent/WeKnora" alt="Contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;a href="https://raw.githubusercontent.com/Tencent/WeKnora/main/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code with proper attribution.&lt;/p&gt; 
&lt;h2&gt;ğŸ“ˆ Project Statistics&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;theme=dark&amp;amp;legend=top-left" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/WeKnora&amp;amp;type=date&amp;amp;legend=top-left" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
  </channel>
</rss>