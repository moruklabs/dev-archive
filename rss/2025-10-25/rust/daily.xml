<rss version="2.0">
  <channel>
    <title>GitHub Rust Daily Trending</title>
    <description>Daily Trending of Rust in GitHub</description>
    <pubDate>Fri, 24 Oct 2025 01:40:24 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>abenz1267/walker</title>
      <link>https://github.com/abenz1267/walker</link>
      <description>&lt;p&gt;Multi-Purpose Launcher with a lot of features. Highly Customizable and fast.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Walker - A Modern Application Launcher&lt;/h1&gt; 
&lt;p&gt;A fast, customizable application launcher built with GTK4 and Rust, designed for Linux desktop environments. Walker provides a clean, modern interface for launching applications, running commands, performing calculations, and more.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://benz.gitbook.io/walker/"&gt;GitBook Documentation/Wiki&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/mGQWBQHASt"&gt;&lt;img src="https://img.shields.io/discord/1402235361463242964?logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://www.gnu.org/licenses/gpl-3.0"&gt;&lt;img src="https://img.shields.io/badge/License-GPLv3-blue.svg?sanitize=true" alt="License: GPL v3" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/abenz1267/walker/refs/heads/master/resources/screenshot.png" alt="screenshot" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;The following Elephant providers are implemented by default:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Desktop Applications&lt;/strong&gt;: Launch installed GUI applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Calculator&lt;/strong&gt;: Perform mathematical calculations with &lt;code&gt;=&lt;/code&gt; prefix&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;File Browser&lt;/strong&gt;: Navigate and open files with &lt;code&gt;/&lt;/code&gt; prefix&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Command Runner&lt;/strong&gt;: Execute shell commands&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Websearch&lt;/strong&gt;: Search the web with custom-defined engines&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Clipboard History&lt;/strong&gt;: Access clipboard history with &lt;code&gt;:&lt;/code&gt; prefix&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Symbol Picker&lt;/strong&gt;: Insert special symbols with &lt;code&gt;.&lt;/code&gt; prefix&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Provider List&lt;/strong&gt;: Switch between providers with &lt;code&gt;;&lt;/code&gt; prefix&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Menu Integration&lt;/strong&gt;: Create custom menus with elephant and let walker display them&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dmenu&lt;/strong&gt;: Your good old dmenu ... with seamless menus!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Arch Linux Packages&lt;/strong&gt;: Search through available packages (official and aur), install or delete a target! List all exlusively installed packages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Todo List&lt;/strong&gt;: create simple todo items with basic time tracking, scheduling and notifications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bluetooth&lt;/strong&gt;: basic bluetooth management&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Build from Source&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone the repository
git clone https://github.com/abenz1267/walker.git
cd walker

# Build with Cargo
cargo build --release

# Run Walker
./target/release/walker
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Dependencies&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;GTK4 (version 4.6+)&lt;/li&gt; 
 &lt;li&gt;gtk4-layer-shell&lt;/li&gt; 
 &lt;li&gt;Protocol Buffers compiler&lt;/li&gt; 
 &lt;li&gt;cairo&lt;/li&gt; 
 &lt;li&gt;poppler-glib&lt;/li&gt; 
 &lt;li&gt;make sure &lt;a href="https://github.com/abenz1267/elephant"&gt;elephant&lt;/a&gt; is running before starting Walker&lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt; &lt;h3&gt; Install using Nix &lt;/h3&gt; &lt;/summary&gt; 
 &lt;h4&gt;1. Add flake inputs&lt;/h4&gt; 
 &lt;p&gt;Add walker and elephant to the inputs of your configs &lt;code&gt;flake.nix&lt;/code&gt; and set walker to follow elephant&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-nix"&gt;elephant.url = "github:abenz1267/elephant";

walker = {
  url = "github:abenz1267/walker";
  inputs.elephant.follows = "elephant";
};
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;2. Install walker&lt;/h4&gt; 
 &lt;p&gt;You have 3 options for installing walker.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Option A&lt;/strong&gt; (Home Manager Module): Import the home-manager module to your home-manager config and enable walker.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-nix"&gt;imports = [inputs.walker.homeManagerModules.default];

programs.walker.enable = true;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Option B&lt;/strong&gt; (NixOS Module): Import the nixos module in your NixOS config and enable walker&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-nix"&gt;imports = [inputs.walker.nixosModules.default];

programs.walker.enable = true;
&lt;/code&gt;&lt;/pre&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;Note: this option doesn't support the &lt;code&gt;runAsService&lt;/code&gt; option; It is recommended that you launch the elephant and walker services using your desktop instead.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Option C&lt;/strong&gt; (Package): Add &lt;code&gt;inputs.walker.packages.&amp;lt;system&amp;gt;.default&lt;/code&gt; to your system packages or home-manager packages. replace &lt;code&gt;&amp;lt;system&amp;gt;&lt;/code&gt; with your system architecture. Note: This option doesn't support configuration using nix.&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-nix"&gt;home.packages = [inputs.walker.packages.&amp;lt;system&amp;gt;.default];
&lt;/code&gt;&lt;/pre&gt; 
 &lt;pre&gt;&lt;code class="language-nix"&gt;environment.systemPackages = [inputs.walker.packages.&amp;lt;system&amp;gt;.default];
&lt;/code&gt;&lt;/pre&gt; 
 &lt;h4&gt;3. Configure walker&lt;/h4&gt; 
 &lt;pre&gt;&lt;code class="language-nix"&gt;programs.walker = {
  enable = true;
  runAsService = true; # Note: this option isn't supported in the NixOS module only in the home-manager module

  # All options from the config.toml can be used here https://github.com/abenz1267/walker/blob/master/resources/config.toml
  config = {
    theme = "your theme name";
    placeholders."default" = { input = "Search"; list = "Example"; };
    providers.prefixes = [
      {provider = "websearch"; prefix = "+";}
      {provider = "providerlist"; prefix = "_";}
    ];
    keybinds.quick_activate = ["F1" "F2" "F3"];
  };
  
  # Set `programs.walker.config.theme="your theme name"` to choose the default theme
  themes = {
    "your theme name" = {
      # Check out the default css theme as an example https://github.com/abenz1267/walker/blob/master/resources/themes/default/style.css
      style = " /* css */ ";

      # Check out the default layouts for examples https://github.com/abenz1267/walker/tree/master/resources/themes/default
      layouts = {
        "layout" = " &amp;lt;!-- xml --&amp;gt; ";
        "item_calc" = " &amp;lt;!-- xml --&amp;gt; ";
        # other provider layouts
      };
    };
    "other theme name" = {
        # ...
    };
    # more themes
  };
};
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Optionally, there is 2 binary caches which can be used by adding the following to you config:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-nix"&gt;nix.settings = {
  extra-substituters = ["https://walker.cachix.org" "https://walker-git.cachix.org"];
  extra-trusted-public-keys = ["walker.cachix.org-1:fG8q+uAaMqhsMxWjwvk0IMb4mFPFLqHjuvfwQxE4oJM=" "walker-git.cachix.org-1:vmC0ocfPWh0S/vRAQGtChuiZBTAe4wiKDeyyXM0/7pM="];
};
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Basic Usage&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Make sure &lt;code&gt;elephant&lt;/code&gt; is running and you have providers installed. &lt;code&gt;elephant-providerlist&lt;/code&gt; and f.e. &lt;code&gt;elephant-desktopapplications&lt;/code&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Launch Walker with &lt;code&gt;walker&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;In order to improve startup performance, run a Walker service with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;walker --gapplication-service
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the service is running, you can either open Walker with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;walker
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or for an even faster launch make a socket call, f.e. with &lt;code&gt;openbsd-netcat&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nc -U /run/user/1000/walker/walker.sock
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The downside of the socket call is that it does not handle any commandline options, so it's just a faster alternative to a simple &lt;code&gt;walker&lt;/code&gt; call.&lt;/p&gt; 
&lt;h2&gt;Keybinds&lt;/h2&gt; 
&lt;p&gt;The following modifier keys are valid: &lt;code&gt;ctrl&lt;/code&gt;, &lt;code&gt;alt&lt;/code&gt;, &lt;code&gt;shift&lt;/code&gt;, &lt;code&gt;super&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To get a full list of possible key values, look here: &lt;a href="https://github.com/gtk-rs/gtk4-rs/raw/0.9/gdk4/sys/src/lib.rs#L302"&gt;GDK key-values&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;F.e. &lt;code&gt;pub const GDK_KEY_semicolon: c_int = 59;&lt;/code&gt; means that &lt;code&gt;ctrl semicolon&lt;/code&gt; would be a valid keybind.&lt;/p&gt; 
&lt;h2&gt;Config&lt;/h2&gt; 
&lt;p&gt;Configuration should be done in &lt;code&gt;~/.config/walker&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://raw.githubusercontent.com/abenz1267/walker/refs/heads/master/resources/config.toml"&gt;default config&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Theming&lt;/h2&gt; 
&lt;p&gt;You can customize Walker's appearance by creating a custom theme. Checkout &lt;code&gt;resources/themes/default&lt;/code&gt; for the default theme. Themes inherit the default theme by default, so if you just want to change the CSS, you can just create &lt;code&gt;themes/yours/style.css&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;You can customize rendering of list items for each provider individually, f.e. "item_files.xml" will define the layout for items sourced from the &lt;code&gt;files&lt;/code&gt; provider.&lt;/p&gt; 
&lt;p&gt;Please refer to &lt;a href="https://docs.gtk.org/gtk4/"&gt;the GTK4 docs&lt;/a&gt; to checkout how to write &lt;code&gt;*.xml&lt;/code&gt; files for GTK4.&lt;/p&gt; 
&lt;p&gt;You can set the default theme in your &lt;code&gt;config.toml&lt;/code&gt; f.e. &lt;code&gt;theme = "yours"&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please do not make PRs to fix single typos. Fix all or nothing.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the GNU General Public License v3.0 - see the &lt;a href="https://raw.githubusercontent.com/abenz1267/walker/master/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rustfs/rustfs</title>
      <link>https://github.com/rustfs/rustfs</link>
      <description>&lt;p&gt;🚀 High-performance distributed object storage for MinIO alternative.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://rustfs.com"&gt;&lt;img src="https://rustfs.com/images/rustfs-github.png" alt="RustFS" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt;RustFS is a high-performance distributed object storage software built using Rust&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/rustfs/rustfs/actions/workflows/ci.yml"&gt;&lt;img alt="CI" src="https://github.com/rustfs/rustfs/actions/workflows/ci.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;a href="https://github.com/rustfs/rustfs/actions/workflows/docker.yml"&gt;&lt;img alt="Build and Push Docker Images" src="https://github.com/rustfs/rustfs/actions/workflows/docker.yml/badge.svg?sanitize=true" /&gt;&lt;/a&gt; &lt;img alt="GitHub commit activity" src="https://img.shields.io/github/commit-activity/m/rustfs/rustfs" /&gt; &lt;img alt="Github Last Commit" src="https://img.shields.io/github/last-commit/rustfs/rustfs" /&gt; &lt;a href="https://hellogithub.com/repository/rustfs/rustfs" target="_blank"&gt;&lt;img src="https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=b95bcb72bdc340b68f16fdf6790b7d5b&amp;amp;claim_uid=MsbvjYeLDKAH457&amp;amp;theme=small" alt="Featured｜HelloGitHub" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://docs.rustfs.com/introduction.html"&gt;Getting Started&lt;/a&gt; · &lt;a href="https://docs.rustfs.com/"&gt;Docs&lt;/a&gt; · &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;Bug reports&lt;/a&gt; · &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;Discussions&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; English | &lt;a href="https://github.com/rustfs/rustfs/raw/main/README_ZH.md"&gt;简体中文&lt;/a&gt; | 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=de"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=es"&gt;Español&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=fr"&gt;français&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ja"&gt;日本語&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ko"&gt;한국어&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=pt"&gt;Português&lt;/a&gt; | &lt;a href="https://readme-i18n.com/rustfs/rustfs?lang=ru"&gt;Русский&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;RustFS is a high-performance distributed object storage software built using Rust, one of the most popular languages worldwide. Along with MinIO, it shares a range of advantages such as simplicity, S3 compatibility, open-source nature, support for data lakes, AI, and big data. Furthermore, it has a better and more user-friendly open-source license in comparison to other storage systems, being constructed under the Apache license. As Rust serves as its foundation, RustFS provides faster speed and safer distributed features for high-performance object storage.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;⚠️ &lt;strong&gt;RustFS is under rapid development. Do NOT use in production environments!&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;High Performance&lt;/strong&gt;: Built with Rust, ensuring speed and efficiency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distributed Architecture&lt;/strong&gt;: Scalable and fault-tolerant design for large-scale deployments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S3 Compatibility&lt;/strong&gt;: Seamless integration with existing S3-compatible applications.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Lake Support&lt;/strong&gt;: Optimized for big data and AI workloads.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Open Source&lt;/strong&gt;: Licensed under Apache 2.0, encouraging community contributions and transparency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User-Friendly&lt;/strong&gt;: Designed with simplicity in mind, making it easy to deploy and manage.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;RustFS vs MinIO&lt;/h2&gt; 
&lt;p&gt;Stress test server parameters&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;parameter&lt;/th&gt; 
   &lt;th&gt;Remark&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
   &lt;td&gt;2 Core&lt;/td&gt; 
   &lt;td&gt;Intel Xeon(Sapphire Rapids) Platinum 8475B , 2.7/3.2 GHz&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Memory&lt;/td&gt; 
   &lt;td&gt;4GB&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Network&lt;/td&gt; 
   &lt;td&gt;15Gbp&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Driver&lt;/td&gt; 
   &lt;td&gt;40GB x 4&lt;/td&gt; 
   &lt;td&gt;IOPS 3800 / Driver&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a"&gt;https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;RustFS vs Other object storage&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;RustFS&lt;/th&gt; 
   &lt;th&gt;Other object storage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Powerful Console&lt;/td&gt; 
   &lt;td&gt;Simple and useless Console&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Developed based on Rust language, memory is safer&lt;/td&gt; 
   &lt;td&gt;Developed in Go or C, with potential issues like memory GC/leaks&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Does not report logs to third-party countries&lt;/td&gt; 
   &lt;td&gt;Reporting logs to other third countries may violate national security laws&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Licensed under Apache, more business-friendly&lt;/td&gt; 
   &lt;td&gt;AGPL V3 License and other License, polluted open source and License traps, infringement of intellectual property rights&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Comprehensive S3 support, works with domestic and international cloud providers&lt;/td&gt; 
   &lt;td&gt;Full support for S3, but no local cloud vendor support&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Rust-based development, strong support for secure and innovative devices&lt;/td&gt; 
   &lt;td&gt;Poor support for edge gateways and secure innovative devices&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Stable commercial prices, free community support&lt;/td&gt; 
   &lt;td&gt;High pricing, with costs up to $250,000 for 1PiB&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;No risk&lt;/td&gt; 
   &lt;td&gt;Intellectual property risks and risks of prohibited uses&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;To get started with RustFS, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;One-click installation script (Option 1)​​&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -O  https://rustfs.com/install_rustfs.sh &amp;amp;&amp;amp; bash install_rustfs.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Quick Start (Option 2)​​&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt; # create data and logs directories
 mkdir -p data logs

 # using latest alpha version
 docker run -d -p 9000:9000 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:alpha

 # Specific version
 docker run -d -p 9000:9000 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:1.0.0.alpha.45
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For docker installation, you can also run the container with docker compose. With the &lt;code&gt;docker-compose.yml&lt;/code&gt; file under root directory, running the command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker compose --profile observability up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: You should be better to have a look for &lt;code&gt;docker-compose.yaml&lt;/code&gt; file. Because, several services contains in the file. Grafan,prometheus,jaeger containers will be launched using docker compose file, which is helpful for rustfs observability. If you want to start redis as well as nginx container, you can specify the corresponding profiles.&lt;/p&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Build from Source (Option 3) - Advanced Users&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;For developers who want to build RustFS Docker images from source with multi-architecture support:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Build multi-architecture images locally
./docker-buildx.sh --build-arg RELEASE=latest

# Build and push to registry
./docker-buildx.sh --push

# Build specific version
./docker-buildx.sh --release v1.0.0 --push

# Build for custom registry
./docker-buildx.sh --registry your-registry.com --namespace yourname --push
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;docker-buildx.sh&lt;/code&gt; script supports:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Multi-architecture builds&lt;/strong&gt;: &lt;code&gt;linux/amd64&lt;/code&gt;, &lt;code&gt;linux/arm64&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Automatic version detection&lt;/strong&gt;: Uses git tags or commit hashes&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Registry flexibility&lt;/strong&gt;: Supports Docker Hub, GitHub Container Registry, etc.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Build optimization&lt;/strong&gt;: Includes caching and parallel builds&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;You can also use Make targets for convenience:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;make docker-buildx                    # Build locally
make docker-buildx-push               # Build and push
make docker-buildx-version VERSION=v1.0.0  # Build specific version
make help-docker                      # Show all Docker-related commands
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Access the Console&lt;/strong&gt;: Open your web browser and navigate to &lt;code&gt;http://localhost:9000&lt;/code&gt; to access the RustFS console, default username and password is &lt;code&gt;rustfsadmin&lt;/code&gt; .&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Create a Bucket&lt;/strong&gt;: Use the console to create a new bucket for your objects.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Upload Objects&lt;/strong&gt;: You can upload files directly through the console or use S3-compatible APIs to interact with your RustFS instance.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you want to access RustFS instance with &lt;code&gt;https&lt;/code&gt;, you can refer to &lt;a href="https://docs.rustfs.com/integration/tls-configured.html"&gt;TLS configuration docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For detailed documentation, including configuration options, API references, and advanced usage, please visit our &lt;a href="https://docs.rustfs.com"&gt;Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Help&lt;/h2&gt; 
&lt;p&gt;If you have any questions or need assistance, you can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check the &lt;a href="https://github.com/rustfs/rustfs/discussions/categories/q-a"&gt;FAQ&lt;/a&gt; for common issues and solutions.&lt;/li&gt; 
 &lt;li&gt;Join our &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt; to ask questions and share your experiences.&lt;/li&gt; 
 &lt;li&gt;Open an issue on our &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;GitHub Issues&lt;/a&gt; page for bug reports or feature requests.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.rustfs.com"&gt;Documentation&lt;/a&gt; - The manual you should read&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/releases"&gt;Changelog&lt;/a&gt; - What we broke and fixed&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt; - Where the community lives&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Bugs&lt;/strong&gt;: &lt;a href="https://github.com/rustfs/rustfs/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business&lt;/strong&gt;: &lt;a href="mailto:hello@rustfs.com"&gt;hello@rustfs.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Jobs&lt;/strong&gt;: &lt;a href="mailto:jobs@rustfs.com"&gt;jobs@rustfs.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;General Discussion&lt;/strong&gt;: &lt;a href="https://github.com/rustfs/rustfs/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contributing&lt;/strong&gt;: &lt;a href="https://raw.githubusercontent.com/rustfs/rustfs/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;RustFS is a community-driven project, and we appreciate all contributions. Check out the &lt;a href="https://github.com/rustfs/rustfs/graphs/contributors"&gt;Contributors&lt;/a&gt; page to see the amazing people who have helped make RustFS better.&lt;/p&gt; 
&lt;a href="https://github.com/rustfs/rustfs/graphs/contributors"&gt; &lt;img src="https://opencollective.com/rustfs/contributors.svg?width=890&amp;amp;limit=500&amp;amp;button=false" alt="Contributors" /&gt; &lt;/a&gt; 
&lt;h2&gt;Github Trending Top&lt;/h2&gt; 
&lt;p&gt;🚀 RustFS is beloved by open-source enthusiasts and enterprise users worldwide, often appearing on the GitHub Trending top charts.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/14181" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/rustfs/rustfs/refs/heads/main/docs/rustfs-trending.jpg" alt="rustfs%2Frustfs | Trendshift" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#rustfs/rustfs&amp;amp;type=date&amp;amp;legend=top-left"&gt;&lt;img src="https://api.star-history.com/svg?repos=rustfs/rustfs&amp;amp;type=date&amp;amp;legend=top-left" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;Apache 2.0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;RustFS&lt;/strong&gt; is a trademark of RustFS, Inc. All other trademarks are the property of their respective owners.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tauri-apps/tauri</title>
      <link>https://github.com/tauri-apps/tauri</link>
      <description>&lt;p&gt;Build smaller, faster, and more secure desktop and mobile applications with a web frontend.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/splash.png" alt="Tauri" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/tauri-apps/tauri/tree/dev"&gt;&lt;img src="https://img.shields.io/badge/status-stable-blue.svg?sanitize=true" alt="status" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/tauri"&gt;&lt;img src="https://img.shields.io/badge/License-MIT%20or%20Apache%202-green.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tauri-apps/tauri/actions/workflows/test-core.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/tauri-apps/tauri/test-core.yml?label=test%20core&amp;amp;logo=github" alt="test core" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt; &lt;a href="https://discord.com/invite/tauri"&gt;&lt;img src="https://img.shields.io/badge/chat-discord-7289da.svg?sanitize=true" alt="Chat Server" /&gt;&lt;/a&gt; &lt;a href="https://tauri.app"&gt;&lt;img src="https://img.shields.io/badge/website-tauri.app-purple.svg?sanitize=true" alt="website" /&gt;&lt;/a&gt; &lt;a href="https://good-labs.github.io/greater-good-affirmation"&gt;&lt;img src="https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg?sanitize=true" alt="https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg" /&gt;&lt;/a&gt; &lt;a href="https://opencollective.com/tauri"&gt;&lt;img src="https://img.shields.io/badge/sponsor-Open%20Collective-blue.svg?sanitize=true" alt="support" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Tauri is a framework for building tiny, blazingly fast binaries for all major desktop platforms. Developers can integrate any front-end framework that compiles to HTML, JS and CSS for building their user interface. The backend of the application is a rust-sourced binary with an API that the front-end can interact with.&lt;/p&gt; 
&lt;p&gt;The user interface in Tauri apps currently leverages &lt;a href="https://docs.rs/tao"&gt;&lt;code&gt;tao&lt;/code&gt;&lt;/a&gt; as a window handling library on macOS, Windows, Linux, Android and iOS. To render your application, Tauri uses &lt;a href="https://github.com/tauri-apps/wry"&gt;WRY&lt;/a&gt;, a library which provides a unified interface to the system webview, leveraging WKWebView on macOS &amp;amp; iOS, WebView2 on Windows, WebKitGTK on Linux and Android System WebView on Android.&lt;/p&gt; 
&lt;p&gt;To learn more about the details of how all of these pieces fit together, please consult this &lt;a href="https://github.com/tauri-apps/tauri/raw/dev/ARCHITECTURE.md"&gt;ARCHITECTURE.md&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;If you are interested in making a tauri app, please visit the &lt;a href="https://tauri.app"&gt;documentation website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The quickest way to get started is to install the &lt;a href="https://v2.tauri.app/start/prerequisites/"&gt;prerequisites&lt;/a&gt; for your system and create a new project with &lt;a href="https://github.com/tauri-apps/create-tauri-app/#usage"&gt;&lt;code&gt;create-tauri-app&lt;/code&gt;&lt;/a&gt;. For example with &lt;code&gt;npm&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm create tauri-app@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;The list of Tauri's features includes, but is not limited to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Built-in app bundler to create app bundles in formats like &lt;code&gt;.app&lt;/code&gt;, &lt;code&gt;.dmg&lt;/code&gt;, &lt;code&gt;.deb&lt;/code&gt;, &lt;code&gt;.rpm&lt;/code&gt;, &lt;code&gt;.AppImage&lt;/code&gt; and Windows installers like &lt;code&gt;.exe&lt;/code&gt; (via NSIS) and &lt;code&gt;.msi&lt;/code&gt; (via WiX).&lt;/li&gt; 
 &lt;li&gt;Built-in self updater (desktop only)&lt;/li&gt; 
 &lt;li&gt;System tray icons&lt;/li&gt; 
 &lt;li&gt;Native notifications&lt;/li&gt; 
 &lt;li&gt;Native WebView Protocol (tauri doesn't create a localhost http(s) server to serve the WebView contents)&lt;/li&gt; 
 &lt;li&gt;GitHub action for streamlined CI&lt;/li&gt; 
 &lt;li&gt;VS Code extension&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Platforms&lt;/h3&gt; 
&lt;p&gt;Tauri currently supports development and distribution on the following platforms:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Platform&lt;/th&gt; 
   &lt;th align="left"&gt;Versions&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Windows&lt;/td&gt; 
   &lt;td align="left"&gt;7 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;macOS&lt;/td&gt; 
   &lt;td align="left"&gt;10.15 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Linux&lt;/td&gt; 
   &lt;td align="left"&gt;webkit2gtk 4.0 for Tauri v1 (for example Ubuntu 18.04). webkit2gtk 4.1 for Tauri v2 (for example Ubuntu 22.04).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;iOS/iPadOS&lt;/td&gt; 
   &lt;td align="left"&gt;9 and above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Android&lt;/td&gt; 
   &lt;td align="left"&gt;7 and above (currently 8 and above)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Before you start working on something, it's best to check if there is an existing issue first. It's also a good idea to stop by the Discord server and confirm with the team if it makes sense or if someone else is already working on it.&lt;/p&gt; 
&lt;p&gt;Please make sure to read the &lt;a href="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; before making a pull request.&lt;/p&gt; 
&lt;p&gt;Thank you to everyone contributing to Tauri!&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;p&gt;Documentation in a polyglot system is a tricky proposition. To this end, we prefer to use inline documentation in the Rust &amp;amp; JS source code as much as possible. Check out the hosting repository for the documentation site for further information: &lt;a href="https://github.com/tauri-apps/tauri-docs"&gt;https://github.com/tauri-apps/tauri-docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Partners&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://crabnebula.dev" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tauri-apps/tauri/dev/.github/sponsors/crabnebula.svg?sanitize=true" alt="CrabNebula" width="283" /&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;For the complete list of sponsors please visit our &lt;a href="https://tauri.app#sponsors"&gt;website&lt;/a&gt; and &lt;a href="https://opencollective.com/tauri"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Organization&lt;/h2&gt; 
&lt;p&gt;Tauri aims to be a sustainable collective based on principles that guide sustainable free and open software communities. To this end it has become a Programme within the &lt;a href="https://commonsconservancy.org/"&gt;Commons Conservancy&lt;/a&gt;, and you can contribute financially via &lt;a href="https://opencollective.com/tauri"&gt;Open Collective&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Licenses&lt;/h2&gt; 
&lt;p&gt;Code: (c) 2015 - Present - The Tauri Programme within The Commons Conservancy.&lt;/p&gt; 
&lt;p&gt;MIT or MIT/Apache 2.0 where applicable.&lt;/p&gt; 
&lt;p&gt;Logo: CC-BY-NC-ND&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Original Tauri Logo Designs by &lt;a href="https://alve.io/"&gt;Alve Larsson&lt;/a&gt;, &lt;a href="https://github.com/nothingismagick"&gt;Daniel Thompson-Yvetot&lt;/a&gt; and &lt;a href="https://github.com/akryum"&gt;Guillaume Chau&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri?ref=badge_large"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri.svg?type=large" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>meilisearch/meilisearch</title>
      <link>https://github.com/meilisearch/meilisearch</link>
      <description>&lt;p&gt;A lightning-fast search engine API bringing AI-powered hybrid search to your sites and applications.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=logo#gh-light-mode-only" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/meilisearch/meilisearch/main/assets/meilisearch-logo-light.svg?sanitize=true#gh-light-mode-only" /&gt; &lt;/a&gt; &lt;a href="https://www.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=logo#gh-dark-mode-only" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/meilisearch/meilisearch/main/assets/meilisearch-logo-dark.svg?sanitize=true#gh-dark-mode-only" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://www.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;Website&lt;/a&gt; | &lt;a href="https://roadmap.meilisearch.com/tabs/1-under-consideration"&gt;Roadmap&lt;/a&gt; | &lt;a href="https://www.meilisearch.com/pricing?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;Meilisearch Cloud&lt;/a&gt; | &lt;a href="https://blog.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;Blog&lt;/a&gt; | &lt;a href="https://www.meilisearch.com/docs?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;Documentation&lt;/a&gt; | &lt;a href="https://www.meilisearch.com/docs/faq?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;FAQ&lt;/a&gt; | &lt;a href="https://discord.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=nav"&gt;Discord&lt;/a&gt; &lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a href="https://deps.rs/repo/github/meilisearch/meilisearch"&gt;&lt;img src="https://deps.rs/repo/github/meilisearch/meilisearch/status.svg?sanitize=true" alt="Dependency status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/meilisearch/meilisearch/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT-informational" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/meilisearch/meilisearch/queue"&gt;&lt;img alt="Merge Queues enabled" src="https://img.shields.io/badge/Merge_Queues-enabled-%2357cf60?logo=github" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt;⚡ A lightning-fast search engine that fits effortlessly into your apps, websites, and workflow 🔍&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.meilisearch.com?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=intro"&gt;Meilisearch&lt;/a&gt; helps you shape a delightful search experience in a snap, offering features that work out of the box to speed up your workflow.&lt;/p&gt; 
&lt;p align="center" name="demo"&gt; &lt;a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demo-gif#gh-light-mode-only" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/meilisearch/meilisearch/main/assets/demo-light.gif#gh-light-mode-only" alt="A bright colored application for finding movies screening near the user" /&gt; &lt;/a&gt; &lt;a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demo-gif#gh-dark-mode-only" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/meilisearch/meilisearch/main/assets/demo-dark.gif#gh-dark-mode-only" alt="A dark colored application for finding movies screening near the user" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;🖥 Examples&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=organization"&gt;&lt;strong&gt;Movies&lt;/strong&gt;&lt;/a&gt; — An application to help you find streaming platforms to watch movies using &lt;a href="https://www.meilisearch.com/solutions/hybrid-search?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;hybrid search&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ecommerce.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;&lt;strong&gt;Ecommerce&lt;/strong&gt;&lt;/a&gt; — Ecommerce website using disjunctive &lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;facets&lt;/a&gt;, range and rating filtering, and pagination.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://music.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;&lt;strong&gt;Songs&lt;/strong&gt;&lt;/a&gt; — Search through 47 million of songs.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://saas.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;&lt;strong&gt;SaaS&lt;/strong&gt;&lt;/a&gt; — Search for contacts, deals, and companies in this &lt;a href="https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=demos"&gt;multi-tenant&lt;/a&gt; CRM application.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the list of all our example apps in our &lt;a href="https://github.com/meilisearch/demos"&gt;demos repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;✨ Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hybrid search:&lt;/strong&gt; Combine the best of both &lt;a href="https://www.meilisearch.com/docs/learn/experimental/vector_search?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;semantic&lt;/a&gt; &amp;amp; full-text search to get the most relevant results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search-as-you-type:&lt;/strong&gt; Find &amp;amp; display results in less than 50 milliseconds to provide an intuitive experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/relevancy/typo_tolerance_settings?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Typo tolerance&lt;/a&gt;:&lt;/strong&gt; get relevant matches even when queries contain typos and misspellings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Filtering&lt;/a&gt; and &lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;faceted search&lt;/a&gt;:&lt;/strong&gt; enhance your users' search experience with custom filters and build a faceted search interface in a few lines of code&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Sorting&lt;/a&gt;:&lt;/strong&gt; sort results based on price, date, or pretty much anything else your users need&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/relevancy/synonyms?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Synonym support&lt;/a&gt;:&lt;/strong&gt; configure synonyms to include more relevant content in your search results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Geosearch&lt;/a&gt;:&lt;/strong&gt; filter and sort documents based on geographic data&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/language?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Extensive language support&lt;/a&gt;:&lt;/strong&gt; search datasets in any language, with optimized support for Chinese, Japanese, Hebrew, and languages using the Latin alphabet&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Security management&lt;/a&gt;:&lt;/strong&gt; control which users can access what data with API keys that allow fine-grained permissions handling&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;Multi-Tenancy&lt;/a&gt;:&lt;/strong&gt; personalize search results for any number of application tenants&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Highly Customizable:&lt;/strong&gt; customize Meilisearch to your specific needs or use our out-of-the-box and hassle-free presets&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=features"&gt;RESTful API&lt;/a&gt;:&lt;/strong&gt; integrate Meilisearch in your technical stack with our plugins and SDKs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI-ready:&lt;/strong&gt; works out of the box with &lt;a href="https://www.meilisearch.com/with/langchain"&gt;langchain&lt;/a&gt; and the &lt;a href="https://github.com/meilisearch/meilisearch-mcp"&gt;model context protocol&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Easy to install, deploy, and maintain&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;📖 Documentation&lt;/h2&gt; 
&lt;p&gt;You can consult Meilisearch's documentation at &lt;a href="https://www.meilisearch.com/docs/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=docs"&gt;meilisearch.com/docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🚀 Getting started&lt;/h2&gt; 
&lt;p&gt;For basic instructions on how to set up Meilisearch, add documents to an index, and search for documents, take a look at our &lt;a href="https://www.meilisearch.com/docs?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=get-started"&gt;documentation&lt;/a&gt; guide.&lt;/p&gt; 
&lt;h2&gt;🌍 Supercharge your Meilisearch experience&lt;/h2&gt; 
&lt;p&gt;Say goodbye to server deployment and manual updates with &lt;a href="https://www.meilisearch.com/cloud?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch"&gt;Meilisearch Cloud&lt;/a&gt;. Additional features include analytics &amp;amp; monitoring in many regions around the world. No credit card is required.&lt;/p&gt; 
&lt;h2&gt;🧰 SDKs &amp;amp; integration tools&lt;/h2&gt; 
&lt;p&gt;Install one of our SDKs in your project for seamless integration between Meilisearch and your favorite language or framework!&lt;/p&gt; 
&lt;p&gt;Take a look at the complete &lt;a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=sdks-link"&gt;Meilisearch integration list&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=sdks-logos"&gt;&lt;img src="https://raw.githubusercontent.com/meilisearch/meilisearch/main/assets/integrations.png" alt="Logos belonging to different languages and frameworks supported by Meilisearch, including React, Ruby on Rails, Go, Rust, and PHP" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;⚙️ Advanced usage&lt;/h2&gt; 
&lt;p&gt;Experienced users will want to keep our &lt;a href="https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;API Reference&lt;/a&gt; close at hand.&lt;/p&gt; 
&lt;p&gt;We also offer a wide range of dedicated guides to all Meilisearch features, such as &lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;filtering&lt;/a&gt;, &lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;sorting&lt;/a&gt;, &lt;a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;geosearch&lt;/a&gt;, &lt;a href="https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;API keys&lt;/a&gt;, and &lt;a href="https://www.meilisearch.com/docs/learn/security/tenant_tokens?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;tenant tokens&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Finally, for more in-depth information, refer to our articles explaining fundamental Meilisearch concepts such as &lt;a href="https://www.meilisearch.com/docs/learn/core_concepts/documents?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;documents&lt;/a&gt; and &lt;a href="https://www.meilisearch.com/docs/learn/core_concepts/indexes?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=advanced"&gt;indexes&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🧾 Editions &amp;amp; Licensing&lt;/h2&gt; 
&lt;p&gt;Meilisearch is available in two editions:&lt;/p&gt; 
&lt;h3&gt;🧪 Community Edition (CE)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fully open source under the &lt;a href="https://raw.githubusercontent.com/meilisearch/meilisearch/main/LICENSE"&gt;MIT license&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Core search engine with fast and relevant full-text, semantic or hybrid search&lt;/li&gt; 
 &lt;li&gt;Free to use for anyone, including commercial usage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;🏢 Enterprise Edition (EE)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Includes advanced features such as: 
  &lt;ul&gt; 
   &lt;li&gt;Sharding&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Governed by a &lt;a href="https://raw.githubusercontent.com/meilisearch/meilisearch/main/LICENSE-EE"&gt;commercial license&lt;/a&gt; or the &lt;a href="https://mariadb.com/bsl11"&gt;Business Source License 1.1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Not allowed in production without a commercial agreement with Meilisearch. 
  &lt;ul&gt; 
   &lt;li&gt;You may use, modify, and distribute the Licensed Work for non-production purposes only, such as testing, development, or evaluation.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Want access to Enterprise features? → Contact us at &lt;a href="maito:sales@meilisearch.com"&gt;sales@meilisearch.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;📊 Telemetry&lt;/h2&gt; 
&lt;p&gt;Meilisearch collects &lt;strong&gt;anonymized&lt;/strong&gt; user data to help us improve our product. You can &lt;a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=telemetry#how-to-disable-data-collection"&gt;deactivate this&lt;/a&gt; whenever you want.&lt;/p&gt; 
&lt;p&gt;To request deletion of collected data, please write to us at &lt;a href="mailto:privacy@meilisearch.com"&gt;privacy@meilisearch.com&lt;/a&gt;. Remember to include your &lt;code&gt;Instance UID&lt;/code&gt; in the message, as this helps us quickly find and delete your data.&lt;/p&gt; 
&lt;p&gt;If you want to know more about the kind of data we collect and what we use it for, check the &lt;a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=telemetry#how-to-disable-data-collection"&gt;telemetry section&lt;/a&gt; of our documentation.&lt;/p&gt; 
&lt;h2&gt;📫 Get in touch!&lt;/h2&gt; 
&lt;p&gt;Meilisearch is a search engine created by &lt;a href="https://www.meilisearch.com/careers"&gt;Meili&lt;/a&gt;, a software development company headquartered in France and with team members all over the world. Want to know more about us? &lt;a href="https://blog.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=contact"&gt;Check out our blog!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;🗞 &lt;a href="https://share-eu1.hsforms.com/1LN5N0x_GQgq7ss7tXmSykwfg3aq"&gt;Subscribe to our newsletter&lt;/a&gt; if you don't want to miss any updates! We promise we won't clutter your mailbox: we only send one edition every two months.&lt;/p&gt; 
&lt;p&gt;💌 Want to make a suggestion or give feedback? Here are some of the channels where you can reach us:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For feature requests, please visit our &lt;a href="https://github.com/meilisearch/product/discussions"&gt;product repository&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Found a bug? Open an &lt;a href="https://github.com/meilisearch/meilisearch/issues"&gt;issue&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;Want to be part of our Discord community? &lt;a href="https://discord.meilisearch.com/?utm_campaign=oss&amp;amp;utm_source=github&amp;amp;utm_medium=meilisearch&amp;amp;utm_content=contact"&gt;Join us!&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Thank you for your support!&lt;/p&gt; 
&lt;h2&gt;👩‍💻 Contributing&lt;/h2&gt; 
&lt;p&gt;Meilisearch is, and will always be, open-source! If you want to contribute to the project, please look at &lt;a href="https://raw.githubusercontent.com/meilisearch/meilisearch/main/CONTRIBUTING.md"&gt;our contribution guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;📦 Versioning&lt;/h2&gt; 
&lt;p&gt;Meilisearch releases and their associated binaries are available on the project's &lt;a href="https://github.com/meilisearch/meilisearch/releases"&gt;releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The binaries are versioned following &lt;a href="https://semver.org/"&gt;SemVer conventions&lt;/a&gt;. To know more, read our &lt;a href="https://raw.githubusercontent.com/meilisearch/meilisearch/main/documentation/versioning-policy.md"&gt;versioning policy&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Differently from the binaries, crates in this repository are not currently available on &lt;a href="https://crates.io/"&gt;crates.io&lt;/a&gt; and do not follow &lt;a href="https://semver.org"&gt;SemVer conventions&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>juspay/hyperswitch</title>
      <link>https://github.com/juspay/hyperswitch</link>
      <description>&lt;p&gt;An open source payments switch written in Rust to make payments fast, reliable and affordable&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-logo-dark.svg#gh-dark-mode-only" alt="Hyperswitch-Logo" width="40%" /&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-logo-light.svg#gh-light-mode-only" alt="Hyperswitch-Logo" width="40%" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Composable Open-Source Payments Infrastructure&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/gifs/quickstart.gif" alt="Quickstart demo" /&gt; &lt;/p&gt; 
&lt;!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} --&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/juspay/hyperswitch/actions?query=workflow%3ACI+branch%3Amain"&gt; &lt;img src="https://github.com/juspay/hyperswitch/workflows/CI-push/badge.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;a href="https://github.com/juspay/hyperswitch/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/github/license/juspay/hyperswitch" /&gt; &lt;/a&gt; &lt;a href="https://github.com/juspay/hyperswitch/raw/main/LICENSE"&gt; &lt;img src="https://img.shields.io/badge/Made_in-Rust-orange" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.linkedin.com/company/hyperswitch/"&gt; &lt;img src="https://img.shields.io/badge/follow-hyperswitch-blue?logo=linkedin&amp;amp;labelColor=grey" /&gt; &lt;/a&gt; &lt;a href="https://x.com/hyperswitchio"&gt; &lt;img src="https://img.shields.io/badge/follow-%40hyperswitchio-white?logo=x&amp;amp;labelColor=grey" /&gt; &lt;/a&gt; &lt;a href="https://inviter.co/hyperswitch-slack"&gt; &lt;img src="https://img.shields.io/badge/chat-on_slack-blue?logo=slack&amp;amp;labelColor=grey&amp;amp;color=%233f0e40" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;📁 Table of Contents&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-what-can-i-do-with-hyperswitch"&gt;What Can I Do with Hyperswitch?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-quickstart-local-setup"&gt;Quickstart (Local Setup)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#cloud-deployment"&gt;Cloud Deployment&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#hosted-sandbox-no-setup-required"&gt;Hosted Sandbox (No Setup Required)&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#-why-hyperswitch"&gt;Why Hyperswitch?&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#architectural-overview"&gt;Architectural Overview&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#our-vision"&gt;Our Vision&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#community--contributions"&gt;Community &amp;amp; Contributions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#feature-requests--bugs"&gt;Feature Requests &amp;amp; Bugs&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#versioning"&gt;Versioning&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#copyright-and-license"&gt;License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#team-behind-hyperswitch"&gt;Team Behind Hyperswitch&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;summary&gt;&lt;h2&gt; What Can I Do with Hyperswitch?&lt;/h2&gt;&lt;/summary&gt; 
&lt;p&gt;Hyperswitch offers a modular, open-source payments infrastructure designed for flexibility and control. Apart from our Payment Suite offering, this solution allows businesses to pick and integrate only the modules they need on top of their existing payment stack — without unnecessary complexity or vendor lock-in.&lt;/p&gt; 
&lt;p&gt;Each module is independent and purpose-built to optimize different aspects of payment processing.&lt;/p&gt; 
&lt;h3&gt; Learn More About The Payment Modules &lt;/h3&gt; 
&lt;details&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Cost Observability&lt;/strong&gt;&lt;br /&gt; Advanced observability tools to audit, monitor, and optimize your payment costs. Detect hidden fees, downgrades, and penalties with self-serve dashboards and actionable insights.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/ai-powered-cost-observability"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revenue Recovery&lt;/strong&gt;&lt;br /&gt; Combat passive churn with intelligent retry strategies tuned by card bin, region, method, and more. Offers fine-grained control over retry algorithms, penalty budgets, and recovery transparency.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/revenue-recovery"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Vault&lt;/strong&gt;&lt;br /&gt; A PCI-compliant vault service to store cards, tokens, wallets, and bank credentials. Provides a unified, secure, and reusable store of customer-linked payment methods.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/vault"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Intelligent Routing&lt;/strong&gt;&lt;br /&gt; Route each transaction to the PSP with the highest predicted auth rate. Reduce retries, avoid downtime, and minimize latency while maximizing first attempt success.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/intelligent-routing"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Reconciliation&lt;/strong&gt;&lt;br /&gt; Automate 2-way and 3-way reconciliation with backdated support, staggered scheduling, and customizable outputs. Reduces manual ops effort and increases audit confidence.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/reconciliation"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Alternate Payment Methods&lt;/strong&gt;&lt;br /&gt; Drop-in widgets for PayPal, Apple Pay, Google Pay, Samsung Pay, Pay by Bank, and BNPL providers like Klarna. Maximizes conversions with seamless one-click checkout.&lt;br /&gt; &lt;em&gt;&lt;a href="https://docs.hyperswitch.io/about-hyperswitch/payments-modules/enable-alternate-payment-method-widgets"&gt;Read more&lt;/a&gt;&lt;/em&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;h3&gt; Local Setup via Docker &lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# One-click local setup

git clone --depth 1 --branch latest https://github.com/juspay/hyperswitch

cd hyperswitch

scripts/setup.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;This script: &lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Detects Docker/Podman&lt;/li&gt; 
  &lt;li&gt;Offers multiple deployment profiles: 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Standard&lt;/strong&gt;: App server + Control Center&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Full&lt;/strong&gt;: Includes monitoring + schedulers&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Minimal&lt;/strong&gt;: Standalone App server&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;Provides access links when done&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you need further help, check out our &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/overview/unified-local-setup-using-docker"&gt;video tutorial&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;👉 After setup, &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/using-hyperswitch-control-center#add-a-payment-processor"&gt;configure a connector&lt;/a&gt; and &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/test-a-payment"&gt;test a payment&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;Hosted Sandbox (No Setup Required)&lt;/h3&gt; 
&lt;p&gt;Hyperswitch offers a fully hosted sandbox environment that requires no setup. You can explore the Control Center, configure payment connectors, and test payments directly from the UI.&lt;/p&gt; 
&lt;a href="https://app.hyperswitch.io"&gt; &lt;img src="https://github.com/juspay/hyperswitch/raw/main/docs/imgs/try-the-sandbox.png?raw=true" height="35" /&gt; &lt;/a&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt; What you can do in the Hosted Sandbox&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Access the full Control Center&lt;/li&gt; 
  &lt;li&gt;Configure payment connectors&lt;/li&gt; 
  &lt;li&gt;View logs, routing rules, and retry strategies&lt;/li&gt; 
  &lt;li&gt;Try payments directly from the UI&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;&lt;strong&gt;Cloud Deployment&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;You can deploy to AWS, GCP, or Azure using Helm or CDK scripts. Fastest path:&lt;/p&gt; 
&lt;p&gt;Click to deploy via AWS:&lt;/p&gt; 
&lt;a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=HyperswitchBootstarp&amp;amp;templateURL=https://hyperswitch-synth.s3.eu-central-1.amazonaws.com/hs-starter-config.yaml"&gt; &lt;img src="https://github.com/juspay/hyperswitch/raw/main/docs/imgs/aws_button.png?raw=true" height="35" /&gt; &lt;/a&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Cloud Deployment Instructions&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ol&gt; 
  &lt;li&gt;Click the AWS deployment button above to launch the stack.&lt;/li&gt; 
  &lt;li&gt;Follow the guided steps in the AWS Console (approx. 30–45 mins).&lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;p&gt;✅ This setup provisions Hyperswitch on your cloud account using CloudFormation.&lt;/p&gt; 
 &lt;p&gt;📘 For full instructions and Helm-based deployments, check out the&lt;br /&gt; &lt;a href="https://docs.hyperswitch.io/hyperswitch-open-source/deploy-on-kubernetes-using-helm"&gt;Cloud Install Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#architectural-overview"&gt; &lt;h2 id="architectural-overview"&gt;Architectural Overview&lt;/h2&gt; &lt;/a&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/features.png" /&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/non-functional-features.png" /&gt; 
&lt;img src="https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/imgs/hyperswitch-architecture-v1.png" /&gt; 
&lt;h2&gt;Why Hyperswitch?&lt;/h2&gt; 
&lt;p&gt;Hyperswitch is a commercial open-source payments stack purpose-built for scale, flexibility, and developer experience. Designed with a modular architecture, Hyperswitch lets you pick only the components you need—whether it’s routing, retries, vaulting, or observability—without vendor lock-in or bloated integrations.&lt;/p&gt; 
&lt;p&gt;Built in Rust for performance and reliability, Hyperswitch supports global payment methods (cards, wallets, BNPL, UPI, Pay by Bank), exposes smart routing and retry logic, and provides a visual workflow builder in the Control Center. Whether you're integrating a full payment suite or augmenting an existing stack with a single module, Hyperswitch meets you where you are.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;“Linux for Payments”&lt;/strong&gt; — Hyperswitch is a well-architected reference for teams who want to own their payments stack.&lt;/p&gt; 
&lt;p&gt;We believe in:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Embracing Payment Diversity:&lt;/strong&gt; Innovation comes from enabling choice—across payment methods, processors, and flows.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Open Source by Default:&lt;/strong&gt; Transparency drives trust and builds better, reusable software.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Community-Driven Development:&lt;/strong&gt; Our roadmap is shaped by real-world use cases and contributors.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Systems-Level Engineering:&lt;/strong&gt; We hold ourselves to a high bar for reliability, security, and performance.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Maximizing Value Creation:&lt;/strong&gt; For developers, customers, and partners alike.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt; Community-Driven, Enterprise-Tested:&lt;/strong&gt; Hyperswitch is built in the open with real-world feedback from developers and contributors, and maintained by Juspay, the team powering payment infrastructure for 400+ leading enterprises worldwide.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributors from around the world to help build Hyperswitch. Whether you're fixing bugs, improving documentation, or adding new features, your help is appreciated.&lt;/p&gt; 
&lt;p&gt;Please read our &lt;a href="https://github.com/juspay/hyperswitch/raw/main/docs/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;Join the conversation on &lt;a href="https://inviter.co/hyperswitch-slack"&gt;Slack&lt;/a&gt; or explore open issues on &lt;a href="https://github.com/juspay/hyperswitch/issues"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#feature-requests"&gt; &lt;h2 id="feature-requests"&gt;Feature requests &amp;amp; Bugs&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;For new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our &lt;a href="https://github.com/juspay/hyperswitch/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For reporting a bug, please read the issue guidelines and search for &lt;a href="https://github.com/juspay/hyperswitch/issues"&gt;existing and closed issues&lt;/a&gt;. If your problem or idea is not addressed yet, please &lt;a href="https://github.com/juspay/hyperswitch/issues/new/choose"&gt;open a new issue&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#versioning"&gt; &lt;h2 id="versioning"&gt;Versioning&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;Check the &lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#copyright-and-license"&gt; &lt;h2 id="copyright-and-license"&gt;Copyright and License&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;This product is licensed under the &lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/LICENSE"&gt;Apache 2.0 License&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://raw.githubusercontent.com/juspay/hyperswitch/main/#team-behind-hyperswitch"&gt; &lt;h2 id="team-behind-hyperswitch"&gt;Team behind Hyperswitch&lt;/h2&gt; &lt;/a&gt; 
&lt;p&gt;The core team of 150+ engineers building Hyperswitch. Keep up the great work! 🥂&lt;/p&gt; 
&lt;a href="https://github.com/juspay/hyperswitch/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=juspay/hyperswitch" alt="Contributors" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>denoland/deno</title>
      <link>https://github.com/denoland/deno</link>
      <description>&lt;p&gt;A modern runtime for JavaScript and TypeScript.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Deno&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://crates.io/crates/deno"&gt;&lt;img src="https://img.shields.io/crates/v/deno.svg?sanitize=true" alt="" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=deno_land"&gt;&lt;img src="https://img.shields.io/twitter/follow/deno_land.svg?style=social&amp;amp;label=Follow" alt="Twitter badge" /&gt;&lt;/a&gt; &lt;a href="https://bsky.app/profile/deno.land"&gt;&lt;img src="https://img.shields.io/badge/Follow-whitesmoke?logo=bluesky" alt="Bluesky badge" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/deno"&gt;&lt;img src="https://img.shields.io/discord/684898665143206084?logo=discord&amp;amp;style=social" alt="Discord badge" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/@deno_land"&gt;&lt;img src="https://img.shields.io/youtube/channel/subscribers/UCqC2G2M-rg4fzg1esKFLFIw?style=social" alt="YouTube badge" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img align="right" src="https://deno.land/logo.svg?sanitize=true" height="150px" alt="the deno mascot dinosaur standing in the rain" /&gt; 
&lt;p&gt;&lt;a href="https://deno.com"&gt;Deno&lt;/a&gt; (&lt;a href="https://ipa-reader.com/?text=%CB%88di%CB%90no%CA%8A"&gt;/ˈdiːnoʊ/&lt;/a&gt;, pronounced &lt;code&gt;dee-no&lt;/code&gt;) is a JavaScript, TypeScript, and WebAssembly runtime with secure defaults and a great developer experience. It's built on &lt;a href="https://v8.dev/"&gt;V8&lt;/a&gt;, &lt;a href="https://www.rust-lang.org/"&gt;Rust&lt;/a&gt;, and &lt;a href="https://tokio.rs/"&gt;Tokio&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Learn more about the Deno runtime &lt;a href="https://docs.deno.com/runtime/manual"&gt;in the documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install the Deno runtime on your system using one of the commands below. Note that there are a number of ways to install Deno - a comprehensive list of installation options can be found &lt;a href="https://docs.deno.com/runtime/manual/getting_started/installation"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Shell (Mac, Linux):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -fsSL https://deno.land/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;PowerShell (Windows):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;irm https://deno.land/install.ps1 | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://formulae.brew.sh/formula/deno"&gt;Homebrew&lt;/a&gt; (Mac):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install deno
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://chocolatey.org/packages/deno"&gt;Chocolatey&lt;/a&gt; (Windows):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;choco install deno
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://winstall.app/apps/DenoLand.Deno"&gt;WinGet&lt;/a&gt; (Windows):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;winget install --id=DenoLand.Deno
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build and install from source&lt;/h3&gt; 
&lt;p&gt;Complete instructions for building Deno from source can be found &lt;a href="https://github.com/denoland/deno/raw/main/.github/CONTRIBUTING.md#building-from-source"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Your first Deno program&lt;/h2&gt; 
&lt;p&gt;Deno can be used for many different applications, but is most commonly used to build web servers. Create a file called &lt;code&gt;server.ts&lt;/code&gt; and include the following TypeScript code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;Deno.serve((_req: Request) =&amp;gt; {
  return new Response("Hello, world!");
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run your server with the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;deno run --allow-net server.ts
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This should start a local web server on &lt;a href="http://localhost:8000"&gt;http://localhost:8000&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Learn more about writing and running Deno programs &lt;a href="https://docs.deno.com/runtime/manual"&gt;in the docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Additional resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.deno.com"&gt;Deno Docs&lt;/a&gt;&lt;/strong&gt;: official guides and reference docs for the Deno runtime, &lt;a href="https://deno.com/deploy"&gt;Deno Deploy&lt;/a&gt;, and beyond.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://jsr.io/@std"&gt;Deno Standard Library&lt;/a&gt;&lt;/strong&gt;: officially supported common utilities for Deno programs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://jsr.io/"&gt;JSR&lt;/a&gt;&lt;/strong&gt;: The open-source package registry for modern JavaScript and TypeScript&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://deno.com/blog"&gt;Developer Blog&lt;/a&gt;&lt;/strong&gt;: Product updates, tutorials, and more from the Deno team.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We appreciate your help! To contribute, please read our &lt;a href="https://raw.githubusercontent.com/denoland/deno/main/.github/CONTRIBUTING.md"&gt;contributing instructions&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>paritytech/polkadot-sdk</title>
      <link>https://github.com/paritytech/polkadot-sdk</link>
      <description>&lt;p&gt;The Parity Polkadot Blockchain SDK&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/docs/images/Polkadot_Logo_Horizontal_Pink_White.png#gh-dark-mode-only" alt="SDK Logo" /&gt; &lt;img src="https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/docs/images/Polkadot_Logo_Horizontal_Pink_Black.png#gh-light-mode-only" alt="SDK Logo" /&gt;&lt;/p&gt; 
 &lt;h1&gt;Polkadot SDK&lt;/h1&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/github/stars/paritytech/polkadot-sdk" alt="GitHub stars" /&gt;&amp;nbsp;&amp;nbsp;&lt;img src="https://img.shields.io/github/forks/paritytech/polkadot-sdk" alt="GitHub forks" /&gt;&lt;/p&gt; 
 &lt;!-- markdownlint-disable-next-line MD013 --&gt; 
 &lt;p&gt;&lt;a href="https://substrate.stackexchange.com/"&gt;&lt;img src="https://img.shields.io/badge/StackExchange-Community%20&amp;amp;%20Support-222222?logo=stackexchange" alt="StackExchange" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;img src="https://img.shields.io/github/contributors/paritytech/polkadot-sdk" alt="GitHub contributors" /&gt;&amp;nbsp;&amp;nbsp;&lt;img src="https://img.shields.io/github/commit-activity/m/paritytech/polkadot-sdk" alt="GitHub commit activity" /&gt;&amp;nbsp;&amp;nbsp;&lt;img src="https://img.shields.io/github/last-commit/paritytech/polkadot-sdk" alt="GitHub last commit" /&gt;&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;The Polkadot SDK repository provides all the components needed to start building on the &lt;a href="https://polkadot.com/"&gt;Polkadot&lt;/a&gt; network, a multi-chain blockchain platform that enables different blockchains to interoperate and share information in a secure and scalable way.&lt;/p&gt; 
 &lt;/blockquote&gt; 
&lt;/div&gt; 
&lt;h2&gt;⚡ Quickstart&lt;/h2&gt; 
&lt;p&gt;If you want to get an example node running quickly you can execute the following getting started script:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/scripts/getting-started.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;👩🏽‍💻 Building&lt;/h2&gt; 
&lt;p&gt;In order to build this project you need to install some dependencies, follow the instructions in &lt;a href="https://docs.polkadot.com/develop/parachains/install-polkadot-sdk"&gt;this guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;📚 Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.polkadot.com"&gt;Polkadot Documentation Portal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/index.html"&gt;🦀 rust-docs&lt;/a&gt;: Where we keep track of the API docs of our Rust crates. Includes: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/index.html"&gt;Introduction&lt;/a&gt; to each component of the Polkadot SDK: Substrate, FRAME, Cumulus, and XCM&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/guides/index.html"&gt;Guides&lt;/a&gt;, namely how to build your first FRAME pallet&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/templates/index.html"&gt;Templates&lt;/a&gt; for starting a new project.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/external_resources/index.html"&gt;External Resources&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Have a question? You can ask in the Polkadot SDK Developers Chat. Messages from either of these channels are bridged to the other, so you can use whichever one you like. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://t.me/substratedevs"&gt;Telegram&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://matrix.to/#/#substratedevs:matrix.org"&gt;Matrix&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://discord.com/channels/722223075629727774/997505821955076196"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://substrate.stackexchange.com/"&gt;Polkadot and Substrate StackExchange&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;🚀 Releases&lt;/h2&gt; 
&lt;!-- markdownlint-disable-next-line MD013 --&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/paritytech/release-registry/main/badges/polkadot-sdk-latest.svg?sanitize=true" alt="Current Stable Release" /&gt;&amp;nbsp;&amp;nbsp;&lt;img src="https://raw.githubusercontent.com/paritytech/release-registry/main/badges/polkadot-sdk-next.svg?sanitize=true" alt="Next Stable Release" /&gt;&lt;/p&gt; 
&lt;p&gt;The Polkadot SDK is released every three months as a &lt;code&gt;Polkadot stableYYMM&lt;/code&gt; release. Each stable release is supported for one year with patches. See the next upcoming versions in the &lt;a href="https://github.com/paritytech/release-registry/"&gt;Release Registry&lt;/a&gt; and more docs in &lt;a href="https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/docs/RELEASE.md"&gt;RELEASE.md&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can use &lt;a href="https://github.com/paritytech/psvm"&gt;&lt;code&gt;psvm&lt;/code&gt;&lt;/a&gt; to update all dependencies to a specific version without needing to manually select the correct version for each crate.&lt;/p&gt; 
&lt;h2&gt;🛠️ Tooling&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/paritytech/psvm"&gt;Polkadot SDK Version Manager&lt;/a&gt;: A simple tool to manage and update the Polkadot SDK dependencies in any Cargo.toml file. It will automatically update the Polkadot SDK dependencies to their correct crates.io version.&lt;/p&gt; 
&lt;h2&gt;🔐 Security&lt;/h2&gt; 
&lt;p&gt;The security policy and procedures can be found in &lt;a href="https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/docs/contributor/SECURITY.md"&gt;docs/contributor/SECURITY.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;🤍 Contributing &amp;amp; Code of Conduct&lt;/h2&gt; 
&lt;p&gt;Ensure you follow our &lt;a href="https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/docs/contributor/CONTRIBUTING.md"&gt;contribution guidelines&lt;/a&gt;. In every interaction and contribution, this project adheres to the &lt;a href="https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/docs/contributor/CODE_OF_CONDUCT.md"&gt;Contributor Covenant Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;👾 Ready to Contribute?&lt;/h3&gt; 
&lt;p&gt;Take a look at the issues labeled with &lt;a href="https://github.com/paritytech/polkadot-sdk/labels/C1-mentor"&gt;&lt;code&gt;mentor&lt;/code&gt;&lt;/a&gt; (or alternatively &lt;a href="https://mentor.tasty.limo/"&gt;this&lt;/a&gt; page, created by one of the maintainers) label to get started! We always recognize valuable contributions by proposing an on-chain tip to the Polkadot network as a token of our appreciation.&lt;/p&gt; 
&lt;h2&gt;Polkadot Fellowship&lt;/h2&gt; 
&lt;p&gt;Development in this repo usually goes hand in hand with the &lt;code&gt;fellowship&lt;/code&gt; organization. In short, this repository provides all the SDK pieces needed to build both Polkadot and its parachains. But, the actual Polkadot runtime lives in the &lt;code&gt;fellowship/runtimes&lt;/code&gt; repository. Read more about the fellowship, this separation, the RFC process &lt;a href="https://polkadot-fellows.github.io/dashboard/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;History&lt;/h2&gt; 
&lt;p&gt;This repository is the amalgamation of 3 separate repositories that used to make up Polkadot SDK, namely Substrate, Polkadot and Cumulus. Read more about the merge and its history &lt;a href="https://polkadot-public.notion.site/Polkadot-SDK-FAQ-fbc4cecc2c46443fb37b9eeec2f0d85f"&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>influxdata/influxdb</title>
      <link>https://github.com/influxdata/influxdb</link>
      <description>&lt;p&gt;Scalable datastore for metrics, events, and real-time analytics&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="assets/influxdb-logo.png" /&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="assets/influxdb-logo-dark.png" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/influxdata/influxdb/main/assets/influxdb-logo.png" alt="InfluxDB Logo" width="600" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt; &lt;/p&gt;
&lt;/div&gt; 
&lt;p&gt;InfluxDB Core is a database built to collect, process, transform, and store event and time series data. It is ideal for use cases that require real-time ingest and fast query response times to build user interfaces, monitoring, and automation solutions.&lt;/p&gt; 
&lt;p&gt;Common use cases include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Monitoring sensor data&lt;/li&gt; 
 &lt;li&gt;Server monitoring&lt;/li&gt; 
 &lt;li&gt;Application performance monitoring&lt;/li&gt; 
 &lt;li&gt;Network monitoring&lt;/li&gt; 
 &lt;li&gt;Financial market and trading analytics&lt;/li&gt; 
 &lt;li&gt;Behavioral analytics&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;InfluxDB is optimized for scenarios where near real-time data monitoring is essential and queries need to return quickly to support user experiences such as dashboards and interactive user interfaces.&lt;/p&gt; 
&lt;p&gt;InfluxDB 3 Core’s feature highlights include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Diskless architecture with object storage support (or local disk with no dependencies)&lt;/li&gt; 
 &lt;li&gt;Fast query response times (under 10ms for last-value queries, or 30ms for distinct metadata)&lt;/li&gt; 
 &lt;li&gt;Embedded Python VM for plugins and triggers&lt;/li&gt; 
 &lt;li&gt;Parquet file persistence&lt;/li&gt; 
 &lt;li&gt;Compatibility with InfluxDB 1.x and 2.x write APIs&lt;/li&gt; 
 &lt;li&gt;Compatability with InfluxDB 1.x query API (InfluxQL)&lt;/li&gt; 
 &lt;li&gt;SQL query engine with support for FlightSQL and HTTP query API&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Project Status&lt;/h2&gt; 
&lt;p&gt;InfluxDB 3 Core is GA as of April 15, 2025! We plan to have monthly point releases for the following six months, with patch releases as needed. We will move to a quarterly cadence after that for 3-4 releases, after which we'll reevaluate our release schedule.&lt;/p&gt; 
&lt;p&gt;Join the &lt;a href="https://discord.gg/vZe2w2Ds8B"&gt;InfluxDB3 Discord&lt;/a&gt; or the public channels below to share your feedback, feature requests, and bug reports.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://www.influxdata.com/blog/influxdb-3-oss-ga/"&gt;InfluxDB 3 Core &amp;amp; Enterprise GA release announcement here&lt;/a&gt; or dig into the &lt;a href="https://docs.influxdata.com/influxdb3/core/get-started/"&gt;InfluxDB 3 getting started guide here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Learn InfluxDB&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://docs.influxdata.com/"&gt;Documentation&lt;/a&gt; | &lt;a href="https://community.influxdata.com/"&gt;Community Forum&lt;/a&gt; | &lt;a href="https://www.influxdata.com/slack/"&gt;Community Slack&lt;/a&gt; | &lt;a href="https://www.influxdata.com/blog/"&gt;Blog&lt;/a&gt; | &lt;a href="https://university.influxdata.com/"&gt;InfluxDB University&lt;/a&gt; | &lt;a href="https://www.youtube.com/@influxdata8893"&gt;YouTube&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Try &lt;strong&gt;InfluxDB Cloud&lt;/strong&gt; for free and get started fast with no local setup required. Click &lt;a href="https://cloud2.influxdata.com/signup"&gt;here&lt;/a&gt; to start building your application on InfluxDB Cloud.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;We have nightly and versioned Docker images, Debian packages, RPM packages, and tarballs of InfluxDB available on the &lt;a href="https://portal.influxdata.com/downloads/"&gt;InfluxData downloads page&lt;/a&gt;. We also provide the InfluxDB command line interface (CLI) client as a separate binary available at the same location.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For v1 installation, use the &lt;a href="https://github.com/influxdata/influxdb/tree/master-1.x"&gt;main 1.x branch&lt;/a&gt; or &lt;a href="https://docs.influxdata.com/influxdb/v1/introduction/install/#installing-influxdb-oss"&gt;install InfluxDB OSS directly&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For v2 installation, use the &lt;a href="https://github.com/influxdata/influxdb/tree/main-2.x"&gt;main 2.x branch&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For InfluxDB 3 Core see the &lt;a href="https://docs.influxdata.com/influxdb3/core/get-started/"&gt;InfluxDB 3 Core getting started guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;For InfluxDB 3 Enterprise see the &lt;a href="https://docs.influxdata.com/influxdb3/enterprise/get-started/"&gt;InfluxDB 3 Enterprise getting started guide&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you are interested in building from source, see the &lt;a href="https://raw.githubusercontent.com/influxdata/influxdb/main/CONTRIBUTING.md#building-from-source"&gt;building from source&lt;/a&gt; guide for contributors.&lt;/p&gt; 
&lt;p&gt;To begin using InfluxDB, visit our &lt;a href="https://docs.influxdata.com/influxdb/v1/introduction/get-started/"&gt;Getting Started with InfluxDB&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;The open source software we build is licensed under the permissive MIT or Apache 2 licenses at the user's choosing. We’ve long held the view that our open source code should be truly open and our commercial code should be separate and closed.&lt;/p&gt; 
&lt;h2&gt;Interested in joining the team building InfluxDB?&lt;/h2&gt; 
&lt;p&gt;Check out current job openings at &lt;a href="https://www.influxdata.com/careers"&gt;www.influxdata.com/careers&lt;/a&gt; today!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DioxusLabs/dioxus</title>
      <link>https://github.com/DioxusLabs/dioxus</link>
      <description>&lt;p&gt;Fullstack app framework for web, desktop, and mobile.&lt;/p&gt;&lt;hr&gt;&lt;p&gt; &lt;/p&gt;
&lt;p align="center"&gt; 
 &lt;!-- &lt;img src="./notes/header-light-updated.svg#gh-light-mode-only" &gt;
      &lt;img src="./notes/header-dark-updated.svg#gh-dark-mode-only" &gt; --&gt; 
 &lt;!-- &lt;a href="https://dioxuslabs.com"&gt;
          &lt;img src="./notes/flat-splash.avif"&gt;
      &lt;/a&gt; --&gt; &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/splash-header-darkmode.svg#gh-dark-mode-only" style="width: 80%; height: auto;" /&gt; &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/splash-header.svg#gh-light-mode-only" style="width: 80%; height: auto;" /&gt; &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/image-splash.avif" /&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;!-- Crates version --&gt; 
 &lt;a href="https://crates.io/crates/dioxus"&gt; &lt;img src="https://img.shields.io/crates/v/dioxus.svg?style=flat-square" alt="Crates.io version" /&gt; &lt;/a&gt; 
 &lt;!-- Downloads --&gt; 
 &lt;a href="https://crates.io/crates/dioxus"&gt; &lt;img src="https://img.shields.io/crates/d/dioxus.svg?style=flat-square" alt="Download" /&gt; &lt;/a&gt; 
 &lt;!-- docs --&gt; 
 &lt;a href="https://docs.rs/dioxus"&gt; &lt;img src="https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square" alt="docs.rs docs" /&gt; &lt;/a&gt; 
 &lt;!-- CI --&gt; 
 &lt;a href="https://github.com/jkelleyrtp/dioxus/actions"&gt; &lt;img src="https://github.com/dioxuslabs/dioxus/actions/workflows/main.yml/badge.svg?sanitize=true" alt="CI status" /&gt; &lt;/a&gt; 
 &lt;!--Awesome --&gt; 
 &lt;a href="https://dioxuslabs.com/awesome"&gt; &lt;img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true" alt="Awesome Page" /&gt; &lt;/a&gt; 
 &lt;!-- Discord --&gt; 
 &lt;a href="https://discord.gg/XgGxMSkvUM"&gt; &lt;img src="https://img.shields.io/discord/899851952891002890.svg?logo=discord&amp;amp;style=flat-square" alt="Discord Link" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt; &lt;a href="https://dioxuslabs.com"&gt; Website &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/tree/main/examples"&gt; Examples &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://dioxuslabs.com/learn/0.6/guide"&gt; Guide &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/raw/main/translations/zh-cn/README.md"&gt; 中文 &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/raw/main/translations/pt-br/README.md"&gt; PT-BR &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/raw/main/translations/ja-jp/README.md"&gt; 日本語 &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/raw/main/translations/tr-tr"&gt; Türkçe &lt;/a&gt; &lt;span&gt; | &lt;/span&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/raw/main/translations/ko-kr"&gt; 한국어 &lt;/a&gt; &lt;/h3&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/DioxusLabs/dioxus/releases/tag/v0.7.0-alpha.0"&gt;✨ Dioxus 0.7 is in alpha - test it out! ✨&lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;Build for web, desktop, and mobile, and more with a single codebase. Zero-config setup, integrated hot-reloading, and signals-based state management. Add backend functionality with Server Functions and bundle with our CLI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rust"&gt;fn app() -&amp;gt; Element {
    let mut count = use_signal(|| 0);

    rsx! {
        h1 { "High-Five counter: {count}" }
        button { onclick: move |_| count += 1, "Up high!" }
        button { onclick: move |_| count -= 1, "Down low!" }
    }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;⭐️ Unique features:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cross-platform apps in three lines of code (web, desktop, mobile, server, and more)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dioxuslabs.com/blog/release-050"&gt;Ergonomic state management&lt;/a&gt; combines the best of React, Solid, and Svelte&lt;/li&gt; 
 &lt;li&gt;Built-in featureful, type-safe, fullstack web framework&lt;/li&gt; 
 &lt;li&gt;Integrated bundler for deploying to the web, macOS, Linux, and Windows&lt;/li&gt; 
 &lt;li&gt;Subsecond Rust hot-patching and asset hot-reloading&lt;/li&gt; 
 &lt;li&gt;And more! &lt;a href="https://dioxuslabs.com/learn/0.6/"&gt;Take a tour of Dioxus&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Instant hot-reloading&lt;/h2&gt; 
&lt;p&gt;With one command, &lt;code&gt;dx serve&lt;/code&gt; and your app is running. Edit your markup, styles, and see changes in milliseconds. Use our experimental &lt;code&gt;dx serve --hotpatch&lt;/code&gt; to update Rust code in real time.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/hotreload-video.webp" /&gt; 
 &lt;!-- &lt;video src="https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov" width="500"&gt;&lt;/video&gt; --&gt; 
 &lt;!-- &lt;video src="https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov" width="500"&gt;&lt;/video&gt; --&gt; 
&lt;/div&gt; 
&lt;h2&gt;Build Beautiful Apps&lt;/h2&gt; 
&lt;p&gt;Dioxus apps are styled with HTML and CSS. Use the built-in TailwindCSS support or load your favorite CSS library. Easily call into native code (objective-c, JNI, Web-Sys) for a perfect native touch.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/ebou2.avif" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Truly fullstack applications&lt;/h2&gt; 
&lt;p&gt;Dioxus deeply integrates with &lt;a href="https://github.com/tokio-rs/axum"&gt;axum&lt;/a&gt; to provide powerful fullstack capabilities for both clients and servers. Pick from a wide array of built-in batteries like WebSockets, SSE, Streaming, File Upload/Download, Server-Side-Rendering, Forms, Middleware, and Hot-Reload, or go fully custom and integrate your existing axum backend.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/fullstack-websockets.avif" width="700" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Experimental Native Renderer&lt;/h2&gt; 
&lt;p&gt;Render using web-sys, webview, server-side-rendering, liveview, or even with our experimental WGPU-based renderer. Embed Dioxus in Bevy, WGPU, or even run on embedded Linux!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/native-blitz-wgpu.webp" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;First-party primitive components&lt;/h2&gt; 
&lt;p&gt;Get started quickly with a complete set of primitives modeled after shadcn/ui and Radix-Primitives.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/primitive-components.avif" width="700" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;First-class Android and iOS support&lt;/h2&gt; 
&lt;p&gt;Dioxus is the fastest way to build native mobile apps with Rust. Simply run &lt;code&gt;dx serve --platform android&lt;/code&gt; and your app is running in an emulator or on device in seconds. Call directly into JNI and Native APIs.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/android_and_ios2.avif" width="500" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Bundle for web, desktop, and mobile&lt;/h2&gt; 
&lt;p&gt;Simply run &lt;code&gt;dx bundle&lt;/code&gt; and your app will be built and bundled with maximization optimizations. On the web, take advantage of &lt;a href="https://dioxuslabs.com/learn/0.6/guides/assets"&gt;&lt;code&gt;.avif&lt;/code&gt; generation, &lt;code&gt;.wasm&lt;/code&gt; compression, minification&lt;/a&gt;, and more. Build WebApps weighing &lt;a href="https://github.com/ealmloff/tiny-dioxus/"&gt;less than 50kb&lt;/a&gt; and desktop/mobile apps less than 5mb.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/bundle.gif" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Fantastic documentation&lt;/h2&gt; 
&lt;p&gt;We've put a ton of effort into building clean, readable, and comprehensive documentation. All html elements and listeners are documented with MDN docs, and our Docs runs continuous integration with Dioxus itself to ensure that the docs are always up to date. Check out the &lt;a href="https://dioxuslabs.com/learn/0.6/"&gt;Dioxus website&lt;/a&gt; for guides, references, recipes, and more. Fun fact: we use the Dioxus website as a testbed for new Dioxus features - &lt;a href="https://github.com/dioxusLabs/docsite"&gt;check it out!&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/docs.avif" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Modular and Customizable&lt;/h2&gt; 
&lt;p&gt;Build your own renderer, or use a community renderer like &lt;a href="http://freyaui.dev"&gt;Freya&lt;/a&gt;. Use our modular components like RSX, VirtualDom, Blitz, Taffy, and Subsecond.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/freya-todo-example.webp" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Dioxus is a community-driven project, with a very active &lt;a href="https://discord.gg/XgGxMSkvUM"&gt;Discord&lt;/a&gt; and &lt;a href="https://github.com/DioxusLabs/dioxus/issues"&gt;GitHub&lt;/a&gt; community. We're always looking for help, and we're happy to answer questions and help you get started. &lt;a href="https://github.com/DioxusLabs/dioxus-std"&gt;Our SDK&lt;/a&gt; is community-run and we even have a &lt;a href="https://github.com/dioxus-community/"&gt;GitHub organization&lt;/a&gt; for the best Dioxus crates that receive free upgrades and support.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/DioxusLabs/dioxus/main/notes/dioxus-community.avif" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Full-time core team&lt;/h2&gt; 
&lt;p&gt;Dioxus has grown from a side project to a small team of fulltime engineers. Thanks to the generous support of FutureWei, Satellite.im, the GitHub Accelerator program, we're able to work on Dioxus full-time. Our long term goal is for Dioxus to become self-sustaining by providing paid high-quality enterprise tools. If your company is interested in adopting Dioxus and would like to work with us, please reach out!&lt;/p&gt; 
&lt;h2&gt;Supported Platforms&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table style="width:100%"&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt; &lt;b&gt;Web&lt;/b&gt; &lt;/td&gt; 
    &lt;td&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Render directly to the DOM using WebAssembly&lt;/li&gt; 
      &lt;li&gt;Pre-render with SSR and rehydrate on the client&lt;/li&gt; 
      &lt;li&gt;Simple "hello world" at about 50kb, comparable to React&lt;/li&gt; 
      &lt;li&gt;Built-in dev server and hot reloading for quick iteration&lt;/li&gt; 
     &lt;/ul&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; &lt;b&gt;Desktop&lt;/b&gt; &lt;/td&gt; 
    &lt;td&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Render using Webview or - experimentally - with WGPU or &lt;a href="https://freyaui.dev"&gt;Freya&lt;/a&gt; (Skia) &lt;/li&gt; 
      &lt;li&gt;Zero-config setup. Simply `cargo run` or `dx serve` to build your app &lt;/li&gt; 
      &lt;li&gt;Full support for native system access without IPC &lt;/li&gt; 
      &lt;li&gt;Supports macOS, Linux, and Windows. Portable &amp;lt;3mb binaries &lt;/li&gt; 
     &lt;/ul&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; &lt;b&gt;Mobile&lt;/b&gt; &lt;/td&gt; 
    &lt;td&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Render using Webview or - experimentally - with WGPU or Skia &lt;/li&gt; 
      &lt;li&gt;Build .ipa and .apk files for iOS and Android &lt;/li&gt; 
      &lt;li&gt;Call directly into Java and Objective-C with minimal overhead&lt;/li&gt; 
      &lt;li&gt;From "hello world" to running on device in seconds&lt;/li&gt; 
     &lt;/ul&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt; &lt;b&gt;Server-side Rendering&lt;/b&gt; &lt;/td&gt; 
    &lt;td&gt; 
     &lt;ul&gt; 
      &lt;li&gt;Suspense, hydration, and server-side rendering&lt;/li&gt; 
      &lt;li&gt;Quickly drop in backend functionality with server functions&lt;/li&gt; 
      &lt;li&gt;Extractors, middleware, and routing integrations&lt;/li&gt; 
      &lt;li&gt;Static-site generation and incremental regeneration&lt;/li&gt; 
     &lt;/ul&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Running the examples&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The examples in the main branch of this repository target the git version of dioxus and the CLI. If you are looking for examples that work with the latest stable release of dioxus, check out the &lt;a href="https://github.com/DioxusLabs/dioxus/tree/v0.6/examples"&gt;0.6 branch&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The examples in the top level of this repository can be run with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cargo run --example &amp;lt;example&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;However, we encourage you to download the dioxus-cli to test out features like hot-reloading. To install the most recent binary CLI, you can use cargo binstall.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cargo binstall dioxus-cli@0.7.0-rc.3 --force
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If this CLI is out-of-date, you can install it directly from git&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;cargo install --git https://github.com/DioxusLabs/dioxus dioxus-cli --locked
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;With the CLI, you can also run examples with the web platform. You will need to disable the default desktop feature and enable the web feature with this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;dx serve --example &amp;lt;example&amp;gt; --platform web -- --no-default-features
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check out the website &lt;a href="https://dioxuslabs.com/learn/0.6/contributing"&gt;section on contributing&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Report issues on our &lt;a href="https://github.com/dioxuslabs/dioxus/issues"&gt;issue tracker&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/XgGxMSkvUM"&gt;Join&lt;/a&gt; the discord and ask questions!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;a href="https://github.com/dioxuslabs/dioxus/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=dioxuslabs/dioxus&amp;amp;max=30&amp;amp;columns=10" /&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under either the &lt;a href="https://github.com/DioxusLabs/dioxus/raw/master/LICENSE-MIT"&gt;MIT license&lt;/a&gt; or the &lt;a href="https://github.com/DioxusLabs/dioxus/raw/master/LICENSE-APACHE"&gt;Apache-2 License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in Dioxus by you, shall be licensed as MIT or Apache-2, without any additional terms or conditions.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sxyazi/yazi</title>
      <link>https://github.com/sxyazi/yazi</link>
      <description>&lt;p&gt;💥 Blazing fast terminal file manager written in Rust, based on async I/O.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://go.warp.dev/yazi" target="_blank"&gt; &lt;sup&gt;Special thanks to:&lt;/sup&gt; &lt;br /&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/warpdotdev/brand-assets/raw/main/Github/Sponsor/Warp-Github-LG-02.png" /&gt; &lt;br /&gt; 
  &lt;h&gt;
   Warp, built for coding with multiple AI agents 
   &lt;br /&gt; 
   &lt;sup&gt;Available for macOS, Linux and Windows&lt;/sup&gt; 
  &lt;/h&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;Yazi - ⚡️ Blazing Fast Terminal File Manager&lt;/h2&gt; 
&lt;p&gt;Yazi (means "duck") is a terminal file manager written in Rust, based on non-blocking async I/O. It aims to provide an efficient, user-friendly, and customizable file management experience.&lt;/p&gt; 
&lt;p&gt;💡 A new article explaining its internal workings: &lt;a href="https://yazi-rs.github.io/blog/why-is-yazi-fast"&gt;Why is Yazi Fast?&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;🚀 &lt;strong&gt;Full Asynchronous Support&lt;/strong&gt;: All I/O operations are asynchronous, CPU tasks are spread across multiple threads, making the most of available resources.&lt;/li&gt; 
 &lt;li&gt;💪 &lt;strong&gt;Powerful Async Task Scheduling and Management&lt;/strong&gt;: Provides real-time progress updates, task cancellation, and internal task priority assignment.&lt;/li&gt; 
 &lt;li&gt;🖼️ &lt;strong&gt;Built-in Support for Multiple Image Protocols&lt;/strong&gt;: Also integrated with Überzug++ and Chafa, covering almost all terminals.&lt;/li&gt; 
 &lt;li&gt;🌟 &lt;strong&gt;Built-in Code Highlighting and Image Decoding&lt;/strong&gt;: Combined with the pre-loading mechanism, greatly accelerates image and normal file loading.&lt;/li&gt; 
 &lt;li&gt;🔌 &lt;strong&gt;Concurrent Plugin System&lt;/strong&gt;: UI plugins (rewriting most of the UI), functional plugins, custom previewer/preloader/spotter/fetcher; Just some pieces of Lua.&lt;/li&gt; 
 &lt;li&gt;📡 &lt;strong&gt;Data Distribution Service&lt;/strong&gt;: Built on a client-server architecture (no additional server process required), integrated with a Lua-based publish-subscribe model, achieving cross-instance communication and state persistence.&lt;/li&gt; 
 &lt;li&gt;📦 &lt;strong&gt;Package Manager&lt;/strong&gt;: Install plugins and themes with one command, keeping them up-to-date, or pin them to a specific version.&lt;/li&gt; 
 &lt;li&gt;🧰 Integration with ripgrep, fd, fzf, zoxide&lt;/li&gt; 
 &lt;li&gt;💫 Vim-like input/pick/confirm/which/notify component, auto-completion for cd paths&lt;/li&gt; 
 &lt;li&gt;🏷️ Multi-Tab Support, Cross-directory selection, Scrollable Preview (for videos, PDFs, archives, code, directories, etc.)&lt;/li&gt; 
 &lt;li&gt;🔄 Bulk Renaming, Archive Extraction, Visual Mode, File Chooser, &lt;a href="https://github.com/yazi-rs/plugins/tree/main/git.yazi"&gt;Git Integration&lt;/a&gt;, &lt;a href="https://github.com/yazi-rs/plugins/tree/main/mount.yazi"&gt;Mount Manager&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;🎨 Theme System, Mouse Support, Trash Bin, Custom Layouts, Virtual Filesystem, CSI u, OSC 52&lt;/li&gt; 
 &lt;li&gt;... and more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/sxyazi/yazi/assets/17523360/92ff23fa-0cd5-4f04-b387-894c12265cc7"&gt;https://github.com/sxyazi/yazi/assets/17523360/92ff23fa-0cd5-4f04-b387-894c12265cc7&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Project status&lt;/h2&gt; 
&lt;p&gt;Public beta, can be used as a daily driver.&lt;/p&gt; 
&lt;p&gt;Yazi is currently in heavy development, expect breaking changes.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Usage: &lt;a href="https://yazi-rs.github.io/docs/installation"&gt;https://yazi-rs.github.io/docs/installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Features: &lt;a href="https://yazi-rs.github.io/features"&gt;https://yazi-rs.github.io/features&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Discussion&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Discord Server (English mainly): &lt;a href="https://discord.gg/qfADduSdJu"&gt;https://discord.gg/qfADduSdJu&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Telegram Group (Chinese mainly): &lt;a href="https://t.me/yazi_rs"&gt;https://t.me/yazi_rs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Image Preview&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Platform&lt;/th&gt; 
   &lt;th&gt;Protocol&lt;/th&gt; 
   &lt;th&gt;Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/kovidgoyal/kitty"&gt;kitty&lt;/a&gt; (&amp;gt;= 0.28.0)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://sw.kovidgoyal.net/kitty/graphics-protocol/#unicode-placeholders"&gt;Kitty unicode placeholders&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com"&gt;iTerm2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/wez/wezterm"&gt;WezTerm&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://invent.kde.org/utilities/konsole"&gt;Konsole&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/sxyazi/yazi/raw/main/yazi-adapter/src/drivers/kgp_old.rs"&gt;Kitty old protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://codeberg.org/dnkl/foot"&gt;foot&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.vt100.net/docs/vt3xx-gp/chapter14.html"&gt;Sixel graphics format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ghostty-org/ghostty"&gt;Ghostty&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://sw.kovidgoyal.net/kitty/graphics-protocol/#unicode-placeholders"&gt;Kitty unicode placeholders&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/terminal"&gt;Windows Terminal&lt;/a&gt; (&amp;gt;= v1.22.10352.0)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.vt100.net/docs/vt3xx-gp/chapter14.html"&gt;Sixel graphics format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/bakkeby/st-flexipatch"&gt;st with Sixel patch&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.vt100.net/docs/vt3xx-gp/chapter14.html"&gt;Sixel graphics format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.warp.dev"&gt;Warp&lt;/a&gt; (macOS/Linux only)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/Eugeny/tabby"&gt;Tabby&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/microsoft/vscode"&gt;VSCode&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/raphamorim/rio"&gt;Rio&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;❌ Rio renders images at incorrect sizes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://gitlab.gnome.org/raggesilver/blackbox"&gt;Black Box&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.vt100.net/docs/vt3xx-gp/chapter14.html"&gt;Sixel graphics format&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ismail-yilmaz/Bobcat"&gt;Bobcat&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://iterm2.com/documentation-images.html"&gt;Inline images protocol&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅ Built-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;X11 / Wayland&lt;/td&gt; 
   &lt;td&gt;Window system protocol&lt;/td&gt; 
   &lt;td&gt;☑️ &lt;a href="https://github.com/jstkdng/ueberzugpp"&gt;Überzug++&lt;/a&gt; required&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Fallback&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://en.wikipedia.org/wiki/ASCII_art"&gt;ASCII art (Unicode block)&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;☑️ &lt;a href="https://hpjansson.org/chafa/"&gt;Chafa&lt;/a&gt; required&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;See &lt;a href="https://yazi-rs.github.io/docs/image-preview"&gt;https://yazi-rs.github.io/docs/image-preview&lt;/a&gt; for details.&lt;/p&gt; 
&lt;!-- Protocols --&gt; 
&lt;!-- Dependencies --&gt; 
&lt;h2&gt;Special Thanks&lt;/h2&gt; 
&lt;img alt="RustRover logo" align="right" width="200" src="https://resources.jetbrains.com/storage/products/company/brand/logos/RustRover.svg?sanitize=true" /&gt; 
&lt;p&gt;Thanks to RustRover team for providing open-source licenses to support the maintenance of Yazi.&lt;/p&gt; 
&lt;p&gt;Active code contributors can contact @sxyazi to get a license (if any are still available).&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Yazi is MIT-licensed. For more information check the &lt;a href="https://raw.githubusercontent.com/sxyazi/yazi/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tracel-ai/burn</title>
      <link>https://github.com/tracel-ai/burn</link>
      <description>&lt;p&gt;Burn is a next generation Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/logo-burn-neutral.webp" width="350px" /&gt; 
 &lt;p&gt;&lt;a href="https://discord.gg/uPEBbYYDB6"&gt;&lt;img src="https://img.shields.io/discord/1038839012602941528.svg?color=7289da&amp;amp;&amp;amp;logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/v/burn.svg?sanitize=true" alt="Current Crates.io Version" /&gt;&lt;/a&gt; &lt;a href="https://crates.io/crates/burn"&gt;&lt;img src="https://img.shields.io/crates/msrv/burn" alt="Minimum Supported Rust Version" /&gt;&lt;/a&gt; &lt;a href="https://burn.dev/docs/burn"&gt;&lt;img src="https://img.shields.io/badge/docs-latest-blue" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://github.com/tracel-ai/burn/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/tracel-ai/burn/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Test Status" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/#license"&gt;&lt;img src="https://shields.io/badge/license-MIT%2FApache--2.0-blue" alt="license" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/tracel-ai/burn"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.runblaze.dev"&gt;&lt;img src="https://www.runblaze.dev/ci-blaze-powered.png" width="125px" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;hr /&gt; 
 &lt;p&gt;&lt;strong&gt;Burn is a next generation Tensor Library and Deep Learning Framework that doesn't compromise on &lt;br /&gt; flexibility, efficiency and portability.&lt;/strong&gt;&lt;/p&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;div align="left"&gt; 
 &lt;p&gt;Burn is both a tensor library and a deep learning framework optimized for numerical computing, model inference and model training. Burn leverages Rust to perform optimizations normally only available in static-graph frameworks, offering optimal speed without impacting flexibility.&lt;/p&gt; 
 &lt;h2&gt;Backend&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/backend-chip.png" height="96px" /&gt; 
  &lt;p&gt;Burn strives to be as fast as possible on as many hardwares as possible, with robust implementations. We believe this flexibility is crucial for modern needs where you may train your models in the cloud, then deploy on customer hardwares, which vary from user to user.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;h3&gt;Supported Backends&lt;/h3&gt; 
 &lt;p&gt;Most backends support all operating systems, so we don't mention them in the tables below.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;GPU Backends:&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;CUDA&lt;/th&gt; 
    &lt;th&gt;ROCm&lt;/th&gt; 
    &lt;th&gt;Metal&lt;/th&gt; 
    &lt;th&gt;Vulkan&lt;/th&gt; 
    &lt;th&gt;WebGPU&lt;/th&gt; 
    &lt;th&gt;Candle&lt;/th&gt; 
    &lt;th&gt;LibTorch&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Nvidia&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;AMD&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Apple&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Intel&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Qualcom&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wasm&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;p&gt;&lt;strong&gt;CPU Backends:&lt;/strong&gt;&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;Cpu (CubeCL)&lt;/th&gt; 
    &lt;th&gt;NdArray&lt;/th&gt; 
    &lt;th&gt;Candle&lt;/th&gt; 
    &lt;th&gt;LibTorch&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;X86&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Arm&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;Wasm&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;no-std&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;☑️&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;br /&gt; 
 &lt;p&gt;Compared to other frameworks, Burn has a very different approach to supporting many backends. By design, most code is generic over the Backend trait, which allows us to build Burn with swappable backends. This makes composing backend possible, augmenting them with additional functionalities such as autodifferentiation and automatic kernel fusion.&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Autodiff: Backend decorator that brings backpropagation to any backend 🔄 &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Contrary to the aforementioned backends, Autodiff is actually a backend &lt;em&gt;decorator&lt;/em&gt;. This means that it cannot exist by itself; it must encapsulate another backend.&lt;/p&gt; 
  &lt;p&gt;The simple act of wrapping a base backend with Autodiff transparently equips it with autodifferentiation support, making it possible to call backward on your model.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::backend::{Autodiff, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&amp;lt;Wgpu&amp;gt;;

    let device = Default::default();

    let x: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default, &amp;amp;device);
    let y: Tensor&amp;lt;Backend, 2&amp;gt; = Tensor::random([32, 32], Distribution::Default, &amp;amp;device).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;amp;grads).unwrap();
    println!("{y_grad}");
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, it is impossible to make the mistake of calling backward on a model that runs on a backend that does not support autodiff (for inference), as this method is only offered by an Autodiff backend.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-autodiff/README.md"&gt;Autodiff Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Fusion: Backend decorator that brings kernel fusion to all first-party backends &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;This backend decorator enhances a backend with kernel fusion, provided that the inner backend supports it. Note that you can compose this backend with other backend decorators such as Autodiff. All first-party accelerated backends (like WGPU and CUDA) use Fusion by default (&lt;code&gt;burn/fusion&lt;/code&gt; feature flag), so you typically don't need to apply it manually.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#[cfg(not(feature = "fusion"))]
pub type Cuda&amp;lt;F = f32, I = i32&amp;gt; = CubeBackend&amp;lt;CudaRuntime, F, I, u8&amp;gt;;

#[cfg(feature = "fusion")]
pub type Cuda&amp;lt;F = f32, I = i32&amp;gt; = burn_fusion::Fusion&amp;lt;CubeBackend&amp;lt;CudaRuntime, F, I, u8&amp;gt;&amp;gt;;
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Of note, we plan to implement automatic gradient checkpointing based on compute bound and memory bound operations, which will work gracefully with the fusion backend to make your code run even faster during training, see &lt;a href="https://github.com/tracel-ai/burn/issues/936"&gt;this issue&lt;/a&gt;.&lt;/p&gt; 
  &lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-fusion/README.md"&gt;Fusion Backend README&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Router (Beta): Backend decorator that composes multiple backends into a single one &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;That backend simplifies hardware operability, if for instance you want to execute some operations on the CPU and other operations on the GPU.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::tensor::{Distribution, Tensor};
use burn::backend::{
    NdArray, Router, Wgpu, ndarray::NdArrayDevice, router::duo::MultiDevice, wgpu::WgpuDevice,
};

fn main() {
    type Backend = Router&amp;lt;(Wgpu, NdArray)&amp;gt;;

    let device_0 = MultiDevice::B1(WgpuDevice::DiscreteGpu(0));
    let device_1 = MultiDevice::B2(NdArrayDevice::Cpu);

    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_0);
    let tensor_cpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;amp;device_1);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Remote (Beta): Backend decorator for remote backend execution, useful for distributed computations &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;That backend has two parts, one client and one server. The client sends tensor operations over the network to a remote compute backend. You can use any first-party backend as server in a single line of code:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;fn main_server() {
    // Start a server on port 3000.
    burn::server::start::&amp;lt;burn::backend::Cuda&amp;gt;(Default::default(), 3000);
}

fn main_client() {
    // Create a client that communicate with the server on port 3000.
    use burn::backend::{Autodiff, RemoteBackend};

    type Backend = Autodiff&amp;lt;RemoteDevice&amp;gt;;

    let device = RemoteDevice::new("ws://localhost:3000");
    let tensor_gpu =
        Tensor::&amp;lt;Backend, 2&amp;gt;::random([3, 3], Distribution::Default, &amp;amp;device);
}

&lt;/code&gt;&lt;/pre&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;h2&gt;Training &amp;amp; Inference&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-wall.png" height="96px" /&gt; 
  &lt;p&gt;The whole deep learning workflow is made easy with Burn, as you can monitor your training progress with an ergonomic dashboard, and run inference everywhere from embedded devices to large GPU clusters.&lt;/p&gt; 
  &lt;p&gt;Burn was built from the ground up with training and inference in mind. It's also worth noting how Burn, in comparison to frameworks like PyTorch, simplifies the transition from training to deployment, eliminating the need for code changes.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div align="center"&gt; 
  &lt;br /&gt; 
  &lt;a href="https://www.youtube.com/watch?v=N9RM5CQbNQc" target="_blank"&gt; &lt;img src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/burn-train-tui.png" alt="Burn Train TUI" width="75%" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Click on the following sections to expand 👇&lt;/strong&gt;&lt;/p&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Training Dashboard 📈 &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;As you can see in the previous video (click on the picture!), a new terminal UI dashboard based on the &lt;a href="https://github.com/ratatui-org/ratatui"&gt;Ratatui&lt;/a&gt; crate allows users to follow their training with ease without having to connect to any external application.&lt;/p&gt; 
  &lt;p&gt;You can visualize your training and validation metrics updating in real-time and analyze the lifelong progression or recent history of any registered metrics using only the arrow keys. Break from the training loop without crashing, allowing potential checkpoints to be fully written or important pieces of code to complete without interruption 🛡&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; ONNX Support 🐫 &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Burn supports importing ONNX (Open Neural Network Exchange) models, allowing you to easily port models from TensorFlow or PyTorch to Burn. The ONNX model is converted into Rust code that uses Burn's native APIs, enabling the imported model to run on any Burn backend (CPU, GPU, WebAssembly) and benefit from all of Burn's optimizations like automatic kernel fusion.&lt;/p&gt; 
  &lt;p&gt;Our ONNX support is further described in &lt;a href="https://burn.dev/books/burn/import/onnx-model.html"&gt;this section of the Burn Book 🔥&lt;/a&gt;.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This crate is in active development and currently supports a &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/crates/burn-import/SUPPORTED-ONNX-OPS.md"&gt;limited set of ONNX operators&lt;/a&gt;.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Importing PyTorch or Safetensors Models 🚚 &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;You can load weights from PyTorch or Safetensors formats directly into your Burn-defined models. This makes it easy to reuse existing models while benefiting from Burn's performance and deployment features.&lt;/p&gt; 
  &lt;p&gt;Learn more:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/pytorch-model.html"&gt;Import pre-trained PyTorch models into Burn&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://burn.dev/books/burn/import/safetensors-model.html"&gt;Load models from Safetensors format&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Inference in the Browser 🌐 &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Several of our backends can run in WebAssembly environments: Candle and NdArray for CPU execution, and WGPU for GPU acceleration via WebGPU. This means that you can run inference directly within a browser. We provide several examples of this:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST&lt;/a&gt; where you can draw digits and a small convnet tries to find which one it is! 2️⃣ 7️⃣ 😰&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification&lt;/a&gt; where you can upload images and classify them! 🌄&lt;/li&gt; 
  &lt;/ul&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Embedded: &lt;i&gt;no_std&lt;/i&gt; support ⚙️ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Burn's core components support &lt;a href="https://docs.rust-embedded.org/book/intro/no-std.html"&gt;no_std&lt;/a&gt;. This means it can run in bare metal environment such as embedded devices without an operating system.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;As of now, only the NdArray backend can be used in a &lt;em&gt;no_std&lt;/em&gt; environment.&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;Benchmarks&lt;/h3&gt; 
 &lt;p&gt;To evaluate performance across different backends and track improvements over time, we provide a dedicated benchmarking suite.&lt;/p&gt; 
 &lt;p&gt;Run and compare benchmarks using &lt;a href="https://github.com/tracel-ai/burn-bench"&gt;burn-bench&lt;/a&gt;.&lt;/p&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;⚠️ &lt;strong&gt;Warning&lt;/strong&gt; When using one of the &lt;code&gt;wgpu&lt;/code&gt; backends, you may encounter compilation errors related to recursive type evaluation. This is due to complex type nesting within the &lt;code&gt;wgpu&lt;/code&gt; dependency chain. To resolve this issue, add the following line at the top of your &lt;code&gt;main.rs&lt;/code&gt; or &lt;code&gt;lib.rs&lt;/code&gt; file:&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;#![recursion_limit = "256"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;The default recursion limit (128) is often just below the required depth (typically 130-150) due to deeply nested associated types and trait bounds.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;h2&gt;Getting Started&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-walking.png" height="96px" /&gt; 
  &lt;p&gt;Just heard of Burn? You are at the right place! Just continue reading this section and we hope you can get on board really quickly.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;details&gt; 
  &lt;summary&gt; The Burn Book 🔥 &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;To begin working effectively with Burn, it is crucial to understand its key components and philosophy. This is why we highly recommend new users to read the first sections of &lt;a href="https://burn.dev/books/burn/"&gt;The Burn Book 🔥&lt;/a&gt;. It provides detailed examples and explanations covering every facet of the framework, including building blocks like tensors, modules, and optimizers, all the way to advanced usage, like coding your own GPU kernels.&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;The project is constantly evolving, and we try as much as possible to keep the book up to date with new additions. However, we might miss some details sometimes, so if you see something weird, let us know! We also gladly accept Pull Requests 😄&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Examples 🙏 &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Let's start with a code snippet that shows how intuitive the framework is to use! In the following, we declare a neural network module with some parameters along with its forward pass.&lt;/p&gt; 
  &lt;pre&gt;&lt;code class="language-rust"&gt;use burn::nn;
use burn::module::Module;
use burn::tensor::backend::Backend;

#[derive(Module, Debug)]
pub struct PositionWiseFeedForward&amp;lt;B: Backend&amp;gt; {
    linear_inner: nn::Linear&amp;lt;B&amp;gt;,
    linear_outer: nn::Linear&amp;lt;B&amp;gt;,
    dropout: nn::Dropout,
    gelu: nn::Gelu,
}

impl&amp;lt;B: Backend&amp;gt; PositionWiseFeedForward&amp;lt;B&amp;gt; {
    pub fn forward&amp;lt;const D: usize&amp;gt;(&amp;amp;self, input: Tensor&amp;lt;B, D&amp;gt;) -&amp;gt; Tensor&amp;lt;B, D&amp;gt; {
        let x = self.linear_inner.forward(input);
        let x = self.gelu.forward(x);
        let x = self.dropout.forward(x);

        self.linear_outer.forward(x)
    }
}
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;We have a somewhat large amount of &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples"&gt;examples&lt;/a&gt; in the repository that shows how to use the framework in different scenarios.&lt;/p&gt; 
  &lt;p&gt;Following &lt;a href="https://burn.dev/books/burn/"&gt;the book&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/guide"&gt;Basic Workflow&lt;/a&gt; : Creates a custom CNN &lt;code&gt;Module&lt;/code&gt; to train on the MNIST dataset and use for inference.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-training-loop"&gt;Custom Training Loop&lt;/a&gt; : Implements a basic training loop instead of using the &lt;code&gt;Learner&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-wgpu-kernel"&gt;Custom WGPU Kernel&lt;/a&gt; : Learn how to create your own custom operation with the WGPU backend.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;Additional examples:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-csv-dataset"&gt;Custom CSV Dataset&lt;/a&gt; : Implements a dataset to parse CSV data for a regression task.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/simple-regression"&gt;Regression&lt;/a&gt; : Trains a simple MLP on the California Housing dataset to predict the median house value for a district.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-image-dataset"&gt;Custom Image Dataset&lt;/a&gt; : Trains a simple CNN on custom image dataset following a simple folder structure.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/custom-renderer"&gt;Custom Renderer&lt;/a&gt; : Implements a custom renderer to display the &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/building-blocks/learner.md"&gt;&lt;code&gt;Learner&lt;/code&gt;&lt;/a&gt; progress.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/image-classification-web"&gt;Image Classification Web&lt;/a&gt; : Image classification web browser demo using Burn, WGPU and WebAssembly.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist-inference-web"&gt;MNIST Inference on Web&lt;/a&gt; : An interactive MNIST inference demo in the browser. The demo is available &lt;a href="https://burn.dev/demo/"&gt;online&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/mnist"&gt;MNIST Training&lt;/a&gt; : Demonstrates how to train a custom &lt;code&gt;Module&lt;/code&gt; (MLP) with the &lt;code&gt;Learner&lt;/code&gt; configured to log metrics and keep training checkpoints.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/named-tensor"&gt;Named Tensor&lt;/a&gt; : Performs operations with the experimental &lt;code&gt;NamedTensor&lt;/code&gt; feature.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/onnx-inference"&gt;ONNX Import Inference&lt;/a&gt; : Imports an ONNX model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/import-model-weights"&gt;PyTorch Import Inference&lt;/a&gt; : Imports a PyTorch model pre-trained on MNIST to perform inference on a sample image with Burn.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-classification"&gt;Text Classification&lt;/a&gt; : Trains a text classification transformer model on the AG News or DbPedia dataset. The trained model can then be used to classify a text sample.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/text-generation"&gt;Text Generation&lt;/a&gt; : Trains a text generation transformer model on the DbPedia dataset.&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/examples/wgan"&gt;Wasserstein GAN MNIST&lt;/a&gt; : Trains a WGAN model to generate new handwritten digits based on MNIST.&lt;/li&gt; 
  &lt;/ul&gt; 
  &lt;p&gt;For more practical insights, you can clone the repository and run any of them directly on your computer!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Pre-trained Models 🤖 &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;We keep an updated and curated list of models and examples built with Burn, see the &lt;a href="https://github.com/tracel-ai/models"&gt;tracel-ai/models repository&lt;/a&gt; for more details.&lt;/p&gt; 
  &lt;p&gt;Don't see the model you want? Don't hesitate to open an issue, and we may prioritize it. Built a model using Burn and want to share it? You can also open a Pull Request and add your model under the community section!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;details&gt; 
  &lt;summary&gt; Why use Rust for Deep Learning? 🦀 &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;Deep Learning is a special form of software where you need very high level abstractions as well as extremely fast execution time. Rust is the perfect candidate for that use case since it provides zero-cost abstractions to easily create neural network modules, and fine-grained control over memory to optimize every detail.&lt;/p&gt; 
  &lt;p&gt;It's important that a framework be easy to use at a high level so that its users can focus on innovating in the AI field. However, since running models relies so heavily on computations, performance can't be neglected.&lt;/p&gt; 
  &lt;p&gt;To this day, the mainstream solution to this problem has been to offer APIs in Python, but rely on bindings to low-level languages such as C/C++. This reduces portability, increases complexity and creates frictions between researchers and engineers. We feel like Rust's approach to abstractions makes it versatile enough to tackle this two languages dichotomy.&lt;/p&gt; 
  &lt;p&gt;Rust also comes with the Cargo package manager, which makes it incredibly easy to build, test, and deploy from any environment, which is usually a pain in Python.&lt;/p&gt; 
  &lt;p&gt;Although Rust has the reputation of being a difficult language at first, we strongly believe it leads to more reliable, bug-free solutions built faster (after some practice 😅)!&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;br /&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;&lt;strong&gt;Deprecation Note&lt;/strong&gt;&lt;br /&gt;Since &lt;code&gt;0.14.0&lt;/code&gt;, the internal structure for tensor data has changed. The previous &lt;code&gt;Data&lt;/code&gt; struct was deprecated and officially removed since &lt;code&gt;0.17.0&lt;/code&gt; in favor of the new &lt;code&gt;TensorData&lt;/code&gt; struct, which allows for more flexibility by storing the underlying data as bytes and keeping the data type as a field. If you are using &lt;code&gt;Data&lt;/code&gt; in your code, make sure to switch to &lt;code&gt;TensorData&lt;/code&gt;.&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;!-- &gt;
&gt; In the event that you are trying to load a model record saved in a previous version, make sure to
&gt; enable the `record-backward-compat` feature using a previous version of burn (&lt;=0.16.0). Otherwise,
&gt; the record won't be deserialized correctly and you will get an error message (which will also point
&gt; you to the backward compatible feature flag). The backward compatibility was maintained for
&gt; deserialization (loading), so as soon as you have saved the record again it will be saved according
&gt; to the new structure and you will be able to upgrade to this version. Please note that binary formats
&gt; are not backward compatible. Thus, you will need to load your record in a previous version and save it
&gt; to another of the self-describing record formats before using a compatible version (as described) with the
&gt; `record-backward-compat` feature flag. --&gt; 
 &lt;details id="deprecation"&gt; 
  &lt;summary&gt; Loading Model Records From Previous Versions ⚠️ &lt;/summary&gt; 
  &lt;br /&gt; 
  &lt;p&gt;In the event that you are trying to load a model record saved in a version older than &lt;code&gt;0.14.0&lt;/code&gt;, make sure to use a compatible version (&lt;code&gt;0.14&lt;/code&gt;, &lt;code&gt;0.15&lt;/code&gt; or &lt;code&gt;0.16&lt;/code&gt;) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
  &lt;pre&gt;&lt;code&gt;features = [..., "record-backward-compat"]
&lt;/code&gt;&lt;/pre&gt; 
  &lt;p&gt;Otherwise, the record won't be deserialized correctly and you will get an error message. This error will also point you to the backward compatible feature flag.&lt;/p&gt; 
  &lt;p&gt;The backward compatibility was maintained for deserialization when loading records. Therefore, as soon as you have saved the record again it will be saved according to the new structure and you can upgrade back to the current version&lt;/p&gt; 
  &lt;p&gt;Please note that binary formats are not backward compatible. Thus, you will need to load your record in a previous version and save it in any of the other self-describing record format (e.g., using the &lt;code&gt;NamedMpkFileRecorder&lt;/code&gt;) before using a compatible version (as described) with the &lt;code&gt;record-backward-compat&lt;/code&gt; feature flag.&lt;/p&gt; 
 &lt;/details&gt; 
 &lt;h2&gt;Community&lt;/h2&gt; 
 &lt;div align="left"&gt; 
  &lt;img align="right" src="https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-community.png" height="96px" /&gt; 
  &lt;p&gt;If you are excited about the project, don't hesitate to join our &lt;a href="https://discord.gg/uPEBbYYDB6"&gt;Discord&lt;/a&gt;! We try to be as welcoming as possible to everybody from any background. You can ask your questions and share what you built with the community!&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;strong&gt;Contributing&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Before contributing, please take a moment to review our &lt;a href="https://github.com/tracel-ai/burn/tree/main/CODE-OF-CONDUCT.md"&gt;code of conduct&lt;/a&gt;. It's also highly recommended to read the &lt;a href="https://github.com/tracel-ai/burn/tree/main/contributor-book/src/project-architecture"&gt;architecture overview&lt;/a&gt;, which explains some of our architectural decisions. Refer to our &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; for more details.&lt;/p&gt; 
 &lt;h2&gt;Status&lt;/h2&gt; 
 &lt;p&gt;Burn is currently in active development, and there will be breaking changes. While any resulting issues are likely to be easy to fix, there are no guarantees at this stage.&lt;/p&gt; 
 &lt;h2&gt;License&lt;/h2&gt; 
 &lt;p&gt;Burn is distributed under the terms of both the MIT license and the Apache License (Version 2.0). See &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/tracel-ai/burn/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; for details. Opening a pull request is assumed to signal agreement with these licensing terms.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>apache/opendal</title>
      <link>https://github.com/apache/opendal</link>
      <description>&lt;p&gt;Apache OpenDAL: One Layer, All Storage.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Apache OpenDAL™: &lt;em&gt;One Layer, All Storage.&lt;/em&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/apache/opendal/discussions"&gt;&lt;img src="https://img.shields.io/github/discussions/apache/opendal" alt="" /&gt;&lt;/a&gt; &lt;a href="https://opendal.apache.org/discord"&gt;&lt;img src="https://img.shields.io/discord/1081052318650339399?logo=discord&amp;amp;label=discord" alt="" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/apache/opendal"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OpenDAL (&lt;code&gt;/ˈoʊ.pən.dæl/&lt;/code&gt;, pronounced "OH-puhn-dal") is an Open Data Access Layer that enables seamless interaction with diverse storage services.&lt;/p&gt; 
&lt;p&gt;OpenDAL's development is guided by its vision of &lt;strong&gt;One Layer, All Storage&lt;/strong&gt; and its core principles: &lt;strong&gt;Open Community&lt;/strong&gt;, &lt;strong&gt;Solid Foundation&lt;/strong&gt;, &lt;strong&gt;Fast Access&lt;/strong&gt;, &lt;strong&gt;Object Storage First&lt;/strong&gt;, and &lt;strong&gt;Extensible Architecture&lt;/strong&gt;. Read the explained vision at &lt;a href="https://opendal.apache.org/vision"&gt;OpenDAL Vision&lt;/a&gt;.&lt;/p&gt; 
&lt;img src="https://opendal.apache.org/img/architectural.png" alt="OpenDAL Architectural" width="61.8%" /&gt; 
&lt;h2&gt;For &lt;em&gt;ANY&lt;/em&gt; languages&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Release&lt;/th&gt; 
   &lt;th&gt;Docs&lt;/th&gt; 
   &lt;th&gt;Used By&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/core/README.md"&gt;Rust Core&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://crates.io/crates/opendal"&gt;&lt;img src="https://img.shields.io/crates/v/opendal.svg?sanitize=true" alt="Rust Core Image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.rs/opendal"&gt;&lt;img src="https://img.shields.io/badge/docs-release-blue" alt="Docs Release" /&gt;&lt;/a&gt; &lt;a href="https://opendal.apache.org/docs/rust/opendal/"&gt;&lt;img src="https://img.shields.io/badge/docs-dev-blue" alt="Docs Dev" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/core/users.md"&gt;&lt;img src="https://github.com/user-attachments/assets/2726c336-8509-491d-92d8-1be2040d5136" alt="Rust Core Users Image" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/c/README.md"&gt;C Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://opendal.apache.org/docs/c/"&gt;&lt;img src="https://img.shields.io/badge/docs-dev-blue" alt="Docs Dev" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/c/users.md"&gt;&lt;img src="https://github.com/user-attachments/assets/b1cf4d79-8478-4eac-ae04-0bbe0d6a993d" alt="C Binding Users Image" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/cpp/README.md"&gt;Cpp Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://opendal.apache.org/docs/cpp/"&gt;&lt;img src="https://img.shields.io/badge/docs-dev-blue" alt="Docs Dev" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/d/README.md"&gt;D Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/dart/README.md"&gt;Dart Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/dotnet/README.md"&gt;Dotnet Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/go/README.md"&gt;Go Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://pkg.go.dev/github.com/apache/opendal/bindings/go"&gt;&lt;img src="https://badge.fury.io/go/github.com%2Fapache%2Fopendal%2Fbindings%2Fgo.svg?sanitize=true" alt="Go Binding Image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://pkg.go.dev/github.com/apache/opendal/bindings/go"&gt;&lt;img src="https://img.shields.io/badge/docs-release-blue" alt="Docs Release" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/haskell/README.md"&gt;Haskell Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/java/README.md"&gt;Java Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://central.sonatype.com/artifact/org.apache.opendal/opendal-java"&gt;&lt;img src="https://img.shields.io/maven-central/v/org.apache.opendal/opendal-java" alt="Java Binding Image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://javadoc.io/doc/org.apache.opendal/opendal-java"&gt;&lt;img src="https://img.shields.io/badge/docs-release-blue" alt="Docs Release" /&gt;&lt;/a&gt; &lt;a href="https://opendal.apache.org/docs/java/"&gt;&lt;img src="https://img.shields.io/badge/docs-dev-blue" alt="Docs Dev" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/java/users.md"&gt;&lt;img src="https://github.com/user-attachments/assets/f20a59a9-8f23-4919-a165-980ed4e6e0d0" alt="Java Binding Users Image" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/lua/README.md"&gt;Lua Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/nodejs/README.md"&gt;Node.js Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.npmjs.com/package/opendal"&gt;&lt;img src="https://img.shields.io/npm/v/opendal" alt="Node.js Binding Image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://opendal.apache.org/docs/nodejs/"&gt;&lt;img src="https://img.shields.io/badge/docs-dev-blue" alt="Docs Dev" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/ocaml/README.md"&gt;OCaml Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/php/README.md"&gt;PHP Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/python/README.md"&gt;Python Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://pypi.org/project/opendal/"&gt;&lt;img src="https://img.shields.io/pypi/v/opendal" alt="Python Binding Image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://opendal.apache.org/docs/python/"&gt;&lt;img src="https://img.shields.io/badge/docs-dev-blue" alt="Docs Dev" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/python/users.md"&gt;&lt;img src="https://github.com/user-attachments/assets/6bba7e5b-cada-4cf2-81e3-09d4e4535dcb" alt="Python Binding Users Image" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/ruby/README.md"&gt;Ruby Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/swift/README.md"&gt;Swift Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/bindings/zig/README.md"&gt;Zig Binding&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;For &lt;em&gt;ANY&lt;/em&gt; methods&lt;/h2&gt; 
&lt;p&gt;|| Name | Description | Release | || ----- | ------------------------------------------------------------------ | ------------------------- | || &lt;a href="https://opendal.apache.org/docs/40-apps/oli"&gt;oli&lt;/a&gt; | Access data via Command Line (alternative to s3cmd, s3cli, azcopy) | &lt;a href="https://crates.io/crates/oli"&gt;&lt;img src="https://img.shields.io/crates/v/oli.svg?sanitize=true" alt="oli image" /&gt;&lt;/a&gt; | || &lt;a href="https://opendal.apache.org/docs/40-apps/ofs"&gt;ofs&lt;/a&gt; | Access data via POSIX file system API (alternative to s3fs) | &lt;a href="https://crates.io/crates/ofs"&gt;&lt;img src="https://img.shields.io/crates/v/ofs.svg?sanitize=true" alt="ofs image" /&gt;&lt;/a&gt; |&lt;/p&gt; 
&lt;h2&gt;For &lt;em&gt;ANY&lt;/em&gt; integrations&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Release&lt;/th&gt; 
   &lt;th&gt;Docs&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/integrations/dav-server/README.md"&gt;dav-server-opendalfs&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;a &lt;a href="https://github.com/messense/dav-server-rs"&gt;dav-server-rs&lt;/a&gt; implementation using opendal.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://crates.io/crates/dav-server-opendalfs"&gt;&lt;img src="https://img.shields.io/crates/v/dav-server-opendalfs.svg?sanitize=true" alt="dav-server image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.rs/dav-server-opendalfs/"&gt;&lt;img src="https://img.shields.io/badge/docs-release-blue" alt="Docs Release" /&gt;&lt;/a&gt; &lt;a href="https://opendal.apache.org/docs/dav-server-opendalfs/dav_server_opendalfs/"&gt;&lt;img src="https://img.shields.io/badge/docs-dev-blue" alt="Docs Dev" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/integrations/object_store/README.md"&gt;object_store_opendal&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;an &lt;a href="https://docs.rs/object_store"&gt;object_store&lt;/a&gt; implementation using opendal.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://crates.io/crates/object_store_opendal"&gt;&lt;img src="https://img.shields.io/crates/v/object_store_opendal.svg?sanitize=true" alt="object_store image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.rs/object_store_opendal/"&gt;&lt;img src="https://img.shields.io/badge/docs-release-blue" alt="Docs Release" /&gt;&lt;/a&gt; &lt;a href="https://opendal.apache.org/docs/object-store-opendal/object_store_opendal/"&gt;&lt;img src="https://img.shields.io/badge/docs-dev-blue" alt="Docs Dev" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/integrations/unftp-sbe/README.md"&gt;unftp-sbe-opendal&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;an &lt;a href="https://crates.io/crates/unftp"&gt;unftp&lt;/a&gt; storage backend implementation using opendal.&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://crates.io/crates/unftp-sbe-opendal"&gt;&lt;img src="https://img.shields.io/crates/v/unftp-sbe-opendal.svg?sanitize=true" alt="unftp-sbe image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.rs/unftp-sbe-opendal/"&gt;&lt;img src="https://img.shields.io/badge/docs-release-blue" alt="Docs Release" /&gt;&lt;/a&gt; &lt;a href="https://opendal.apache.org/docs/unftp-sbe-opendal/unftp_sbe_opendal/"&gt;&lt;img src="https://img.shields.io/badge/docs-dev-blue" alt="Docs Dev" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/apache/opendal/main/integrations/parquet/README.md"&gt;parquet_opendal&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Provides &lt;a href="https://crates.io/crates/parquet"&gt;&lt;code&gt;parquet&lt;/code&gt;&lt;/a&gt; efficient IO utilities&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://crates.io/crates/parquet-opendal"&gt;&lt;img src="https://img.shields.io/crates/v/parquet-opendal.svg?sanitize=true" alt="parquet image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.rs/parquet-opendal/"&gt;&lt;img src="https://img.shields.io/badge/docs-release-blue" alt="Docs Release" /&gt;&lt;/a&gt; &lt;a href="https://opendal.apache.org/docs/parquet-opendal/parquet_opendal/"&gt;&lt;img src="https://img.shields.io/badge/docs-dev-blue" alt="Docs Dev" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;For &lt;em&gt;ANY&lt;/em&gt; services&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Services&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Standard Storage Protocols&lt;/td&gt; 
   &lt;td&gt;ftp http &lt;a href="https://datatracker.ietf.org/doc/html/draft-ietf-secsh-filexfer-02"&gt;sftp&lt;/a&gt; &lt;a href="https://datatracker.ietf.org/doc/html/rfc4918"&gt;webdav&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Object Storage Services&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://azure.microsoft.com/en-us/services/storage/blobs/"&gt;azblob&lt;/a&gt; &lt;a href="https://www.tencentcloud.com/products/cos"&gt;cos&lt;/a&gt; &lt;a href="https://cloud.google.com/storage"&gt;gcs&lt;/a&gt; &lt;a href="https://www.huaweicloud.com/intl/en-us/product/obs.html"&gt;obs&lt;/a&gt; &lt;a href="https://www.aliyun.com/product/oss"&gt;oss&lt;/a&gt; &lt;a href="https://aws.amazon.com/s3/"&gt;s3&lt;/a&gt; &lt;br /&gt; &lt;a href="https://www.backblaze.com/"&gt;b2&lt;/a&gt; &lt;a href="https://docs.openstack.org/swift/latest/"&gt;openstack_swift&lt;/a&gt; &lt;a href="https://www.upyun.com/"&gt;upyun&lt;/a&gt; &lt;a href="https://vercel.com/docs/storage/vercel-blob"&gt;vercel-blob&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;File Storage Services&lt;/td&gt; 
   &lt;td&gt;fs &lt;a href="https://docs.alluxio.io/os/user/stable/en/api/REST-API.html"&gt;alluxio&lt;/a&gt; &lt;a href="https://azure.microsoft.com/en-us/products/storage/data-lake-storage/"&gt;azdls&lt;/a&gt; &lt;a href="https://learn.microsoft.com/en-us/rest/api/storageservices/file-service-rest-api"&gt;azfile&lt;/a&gt; &lt;a href="https://github.com/compio-rs/compio/"&gt;compfs&lt;/a&gt; &lt;br /&gt; &lt;a href="https://docs.databricks.com/en/dbfs/index.html"&gt;dbfs&lt;/a&gt; &lt;a href="https://www.mongodb.com/docs/manual/core/gridfs/"&gt;gridfs&lt;/a&gt; &lt;a href="https://hadoop.apache.org/docs/r3.3.4/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html"&gt;hdfs&lt;/a&gt; &lt;a href="https://github.com/Kimahriman/hdfs-native"&gt;hdfs-native&lt;/a&gt; &lt;a href="https://ipfs.tech/"&gt;ipfs&lt;/a&gt; &lt;a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/WebHDFS.html"&gt;webhdfs&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Consumer Cloud Storage Service&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://www.aliyundrive.com/"&gt;aliyun-drive&lt;/a&gt; &lt;a href="https://www.google.com/drive/"&gt;gdrive&lt;/a&gt; &lt;a href="https://www.microsoft.com/en-us/microsoft-365/onedrive/online-cloud-storage"&gt;onedrive&lt;/a&gt; &lt;a href="https://www.dropbox.com/"&gt;dropbox&lt;/a&gt; &lt;a href="https://www.icloud.com/iclouddrive"&gt;icloud&lt;/a&gt; &lt;a href="https://koofr.eu/"&gt;koofr&lt;/a&gt; &lt;br /&gt; &lt;a href="https://www.pcloud.com/"&gt;pcloud&lt;/a&gt; &lt;a href="https://www.seafile.com/"&gt;seafile&lt;/a&gt; &lt;a href="https://360.yandex.com/disk/"&gt;yandex-disk&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Key-Value Storage Services&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://crates.io/crates/cacache"&gt;cacache&lt;/a&gt; &lt;a href="https://developers.cloudflare.com/kv/"&gt;cloudflare-kv&lt;/a&gt; &lt;a href="https://github.com/xacrimon/dashmap"&gt;dashmap&lt;/a&gt; memory &lt;a href="https://etcd.io/"&gt;etcd&lt;/a&gt; &lt;br /&gt; &lt;a href="https://www.foundationdb.org/"&gt;foundationdb&lt;/a&gt; &lt;a href="https://crates.io/crates/persy"&gt;persy&lt;/a&gt; &lt;a href="https://redis.io/"&gt;redis&lt;/a&gt; &lt;a href="http://rocksdb.org/"&gt;rocksdb&lt;/a&gt; &lt;a href="https://crates.io/crates/sled"&gt;sled&lt;/a&gt; &lt;br /&gt; &lt;a href="https://crates.io/crates/redb"&gt;redb&lt;/a&gt; &lt;a href="https://tikv.org/"&gt;tikv&lt;/a&gt; &lt;a href="https://github.com/atomicdata-dev/atomic-server"&gt;atomicserver&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Database Storage Services&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://developers.cloudflare.com/d1/"&gt;d1&lt;/a&gt; &lt;a href="https://www.mongodb.com/"&gt;mongodb&lt;/a&gt; &lt;a href="https://www.mysql.com/"&gt;mysql&lt;/a&gt; &lt;a href="https://www.postgresql.org/"&gt;postgresql&lt;/a&gt; &lt;a href="https://www.sqlite.org/"&gt;sqlite&lt;/a&gt; &lt;a href="https://surrealdb.com/"&gt;surrealdb&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cache Storage Services&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows"&gt;ghac&lt;/a&gt; &lt;a href="https://memcached.org/"&gt;memcached&lt;/a&gt; &lt;a href="https://github.com/moka-rs/mini-moka"&gt;mini-moka&lt;/a&gt; &lt;a href="https://github.com/moka-rs/moka"&gt;moka&lt;/a&gt; &lt;a href="https://vercel.com/docs/concepts/monorepos/remote-caching"&gt;vercel-artifacts&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Git Based Storage Services&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/"&gt;huggingface&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;The examples are available at &lt;a href="https://raw.githubusercontent.com/apache/opendal/main/examples/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The documentation is available at &lt;a href="https://opendal.apache.org"&gt;https://opendal.apache.org&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contribute&lt;/h2&gt; 
&lt;p&gt;OpenDAL is an active open-source project. We are always open to people who want to use it or contribute to it. Here are some ways to go.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Start with &lt;a href="https://raw.githubusercontent.com/apache/opendal/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Submit &lt;a href="https://github.com/apache/opendal/issues/new"&gt;Issues&lt;/a&gt; for bug report or feature requests.&lt;/li&gt; 
 &lt;li&gt;Start &lt;a href="https://github.com/apache/opendal/discussions/new?category=q-a"&gt;Discussions&lt;/a&gt; for questions or ideas.&lt;/li&gt; 
 &lt;li&gt;Talk to community directly at &lt;a href="https://opendal.apache.org/discord"&gt;Discord&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Report security vulnerabilities to &lt;a href="mailto:private@opendal.apache.org"&gt;private mailing list&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Branding&lt;/h2&gt; 
&lt;p&gt;The first and most prominent mentions must use the full form: &lt;strong&gt;Apache OpenDAL™&lt;/strong&gt; of the name for any individual usage (webpage, handout, slides, etc.) Depending on the context and writing style, you should use the full form of the name sufficiently often to ensure that readers clearly understand the association of both the OpenDAL project and the OpenDAL software product to the ASF as the parent organization.&lt;/p&gt; 
&lt;p&gt;For more details, see the &lt;a href="https://www.apache.org/foundation/marks/guide"&gt;Apache Product Name Usage Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License and Trademarks&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0: &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Apache OpenDAL, OpenDAL, and Apache are either registered trademarks or trademarks of the Apache Software Foundation.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ai-dynamo/dynamo</title>
      <link>https://github.com/ai-dynamo/dynamo</link>
      <description>&lt;p&gt;A Datacenter Scale Distributed Inference Serving Framework&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-banner.png" alt="Dynamo banner" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ai-dynamo/dynamo/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/ai-dynamo/dynamo" alt="GitHub Release" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/D92uqZRjCZ"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/ai-dynamo/dynamo"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;| &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/issues/2486"&gt;Roadmap&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/raw/main/docs/reference/support-matrix.md"&gt;Support matrix&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://docs.nvidia.com/dynamo/latest/index.html"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/dynamo/tree/main/examples"&gt;Examples&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo"&gt;Prebuilt containers&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://github.com/ai-dynamo/enhancements"&gt;Design Proposals&lt;/a&gt;&lt;/strong&gt; | &lt;strong&gt;&lt;a href="https://developer.nvidia.com/blog/tag/nvidia-dynamo"&gt;Blogs&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h1&gt;NVIDIA Dynamo&lt;/h1&gt; 
&lt;p&gt;High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.&lt;/p&gt; 
&lt;h2&gt;Latest News&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;[08/05] Deploy &lt;code&gt;openai/gpt-oss-120b&lt;/code&gt; with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/trtllm/gpt-oss.md"&gt;➡️ link&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;The Era of Multi-GPU, Multi-Node&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-gpu-vertical.png" alt="Multi Node Multi-GPU topology" width="600" /&gt; &lt;/p&gt; 
&lt;p&gt;Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs—and sometimes many servers—but it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.&lt;/p&gt; 
&lt;p&gt;Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Disaggregated prefill &amp;amp; decode inference&lt;/strong&gt; – Maximizes GPU throughput and facilitates trade off between throughput and latency.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dynamic GPU scheduling&lt;/strong&gt; – Optimizes performance based on fluctuating demand&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM-aware request routing&lt;/strong&gt; – Eliminates unnecessary KV cache re-computation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Accelerated data transfer&lt;/strong&gt; – Reduces inference response time using NIXL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;KV cache offloading&lt;/strong&gt; – Leverages multiple memory hierarchies for higher system throughput&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/images/frontpage-architecture.png" alt="Dynamo architecture" width="600" /&gt; &lt;/p&gt; 
&lt;h2&gt;Framework Support Matrix&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;vLLM&lt;/th&gt; 
   &lt;th&gt;SGLang&lt;/th&gt; 
   &lt;th&gt;TensorRT-LLM&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/design_docs/disagg_serving.md"&gt;&lt;strong&gt;Disaggregated Serving&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/design_docs/disagg_serving.md#conditional-disaggregation"&gt;&lt;strong&gt;Conditional Disaggregation&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/router/kv_cache_routing.md"&gt;&lt;strong&gt;KV-Aware Routing&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/planner/load_planner.md"&gt;&lt;strong&gt;Load Based Planner&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/planner/sla_planner.md"&gt;&lt;strong&gt;SLA-Based Planner&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/kvbm/kvbm_architecture.md"&gt;&lt;strong&gt;KVBM&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
   &lt;td&gt;🚧&lt;/td&gt; 
   &lt;td&gt;✅&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To learn more about each framework and their capabilities, check out each framework's README!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/vllm/README.md"&gt;vLLM&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/sglang/README.md"&gt;SGLang&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/backends/trtllm/README.md"&gt;TensorRT-LLM&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;p&gt;The following examples require a few system level packages. Recommended to use Ubuntu 24.04 with a x86_64 CPU. See &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/reference/support-matrix.md"&gt;docs/reference/support-matrix.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;1. Initial setup&lt;/h2&gt; 
&lt;p&gt;The Dynamo team recommends the &lt;code&gt;uv&lt;/code&gt; Python package manager, although any way works. Install uv:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install Python development headers&lt;/h3&gt; 
&lt;p&gt;Backend engines require Python development headers for JIT compilation. Install them with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo apt install python3-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Install etcd and NATS (required)&lt;/h3&gt; 
&lt;p&gt;To coordinate across a data center, Dynamo relies on etcd and NATS. To run Dynamo locally, these need to be available.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://etcd.io/"&gt;etcd&lt;/a&gt; can be run directly as &lt;code&gt;./etcd&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nats.io/"&gt;nats&lt;/a&gt; needs jetstream enabled: &lt;code&gt;nats-server -js&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To quickly setup etcd &amp;amp; NATS, you can also run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# At the root of the repository:
# Edit deploy/docker-compose.yml to comment out "runtime: nvidia" of the dcgm-exporter service if the nvidia container runtime isn't deployed or to be used.
docker compose -f deploy/docker-compose.yml up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;2. Select an engine&lt;/h2&gt; 
&lt;p&gt;We publish Python wheels specialized for each of our supported engines: vllm, sglang, and trtllm. The examples that follow use SGLang; continue reading for other engines.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install "ai-dynamo[sglang]"  #replace with [vllm], [trtllm], etc.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Run Dynamo&lt;/h2&gt; 
&lt;h3&gt;Sanity check (optional)&lt;/h3&gt; 
&lt;p&gt;Before trying out Dynamo, you can verify your system configuration and dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./deploy/sanity_check.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This is a quick check for system resources, development tools, LLM frameworks, and Dynamo components.&lt;/p&gt; 
&lt;h3&gt;Running an LLM API server&lt;/h3&gt; 
&lt;p&gt;Dynamo provides a simple way to spin up a local set of inference components including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;OpenAI Compatible Frontend&lt;/strong&gt; – High performance OpenAI compatible http api server written in Rust.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Basic and Kv Aware Router&lt;/strong&gt; – Route and load balance traffic to a set of workers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workers&lt;/strong&gt; – Set of pre-configured LLM serving engines.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
python -m dynamo.frontend --http-port 8000 [--tls-cert-path cert.pem] [--tls-key-path key.pem]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
python -m dynamo.sglang --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Send a Request&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl localhost:8000/v1/chat/completions   -H "Content-Type: application/json"   -d '{
    "model": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "messages": [
    {
        "role": "user",
        "content": "Hello, how are you?"
    }
    ],
    "stream":false,
    "max_tokens": 300
  }' | jq
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Rerun with &lt;code&gt;curl -N&lt;/code&gt; and change &lt;code&gt;stream&lt;/code&gt; in the request to &lt;code&gt;true&lt;/code&gt; to get the responses as soon as the engine issues them.&lt;/p&gt; 
&lt;h3&gt;Deploying Dynamo&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/kubernetes/README.md"&gt;Quickstart Guide&lt;/a&gt; to deploy on Kubernetes.&lt;/li&gt; 
 &lt;li&gt;Check out &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/components/backends"&gt;Backends&lt;/a&gt; to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)&lt;/li&gt; 
 &lt;li&gt;Run some &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/examples"&gt;Examples&lt;/a&gt; to learn about building components in Dynamo and exploring various integrations.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Benchmarking Dynamo&lt;/h3&gt; 
&lt;p&gt;Dynamo provides comprehensive benchmarking tools to evaluate and optimize your deployments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/benchmarks/benchmarking.md"&gt;Benchmarking Guide&lt;/a&gt;&lt;/strong&gt; – Compare deployment topologies (aggregated vs. disaggregated vs. vanilla vLLM) using AIPerf&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/docs/benchmarks/pre_deployment_profiling.md"&gt;Pre-Deployment Profiling&lt;/a&gt;&lt;/strong&gt; – Optimize configurations before deployment to meet SLA requirements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Engines&lt;/h1&gt; 
&lt;p&gt;Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (&lt;code&gt;python -m dynamo.frontend [--interactive]&lt;/code&gt;).&lt;/p&gt; 
&lt;h2&gt;vLLM&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[vllm]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.vllm --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass &lt;code&gt;--context-length &amp;lt;value&amp;gt;&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;To specify which GPUs to use set environment variable &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;SGLang&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.sglang --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can pass any sglang flags directly to this worker, see &lt;a href="https://docs.sglang.ai/advanced_features/server_arguments.html"&gt;https://docs.sglang.ai/advanced_features/server_arguments.html&lt;/a&gt; . See there to use multiple GPUs.&lt;/p&gt; 
&lt;h2&gt;TensorRT-LLM&lt;/h2&gt; 
&lt;p&gt;It is recommended to use &lt;a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch"&gt;NGC PyTorch Container&lt;/a&gt; for running the TensorRT-LLM engine.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Note] Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using. For example, if you are using &lt;code&gt;tensorrt-llm==1.1.0rc5&lt;/code&gt;, use the PyTorch container image version &lt;code&gt;25.06&lt;/code&gt;. To find the correct PyTorch container version for your desired &lt;code&gt;tensorrt-llm&lt;/code&gt; release, visit the &lt;a href="https://github.com/NVIDIA/TensorRT-LLM/raw/main/docker/Dockerfile.multi"&gt;TensorRT-LLM Dockerfile.multi&lt;/a&gt; on GitHub. Switch to the branch that matches your &lt;code&gt;tensorrt-llm&lt;/code&gt; version, and look for the &lt;code&gt;BASE_TAG&lt;/code&gt; line to identify the recommended PyTorch container tag.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] Launch container with the following additional settings &lt;code&gt;--shm-size=1g --ulimit memlock=-1&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Install prerequisites&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install "cuda-python&amp;gt;=12,&amp;lt;13"

sudo apt-get -y install libopenmpi-dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Tip] You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation &lt;a href="https://nvidia.github.io/TensorRT-LLM/installation/linux.html"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;After installing the pre-requisites above, install Dynamo&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install ai-dynamo[trtllm]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Run the backend/worker like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;python -m dynamo.trtllm --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To specify which GPUs to use set environment variable &lt;code&gt;CUDA_VISIBLE_DEVICES&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Developing Locally&lt;/h1&gt; 
&lt;h2&gt;1. Install libraries&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Ubuntu:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://brew.sh/"&gt;Homebrew&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;# if brew is not installed on your system, install it
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code&gt;brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If Metal is accessible, you should see an error like &lt;code&gt;metal: error: no input files&lt;/code&gt;, which confirms it is installed correctly.&lt;/p&gt; 
&lt;h2&gt;2. Install Rust&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;3. Create a Python virtual env:&lt;/h2&gt; 
&lt;p&gt;Follow the instructions in &lt;a href="https://docs.astral.sh/uv/#installation"&gt;uv installation&lt;/a&gt; guide to install uv if you don't have &lt;code&gt;uv&lt;/code&gt; installed. Once uv is installed, create a virtual environment and activate it.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install uv&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a virtual environment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv dynamo
source dynamo/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;4. Install build tools&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;uv pip install pip maturin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://github.com/PyO3/maturin"&gt;Maturin&lt;/a&gt; is the Rust&amp;lt;-&amp;gt;Python bindings build tool.&lt;/p&gt; 
&lt;h2&gt;5. Build the Rust bindings&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd lib/bindings/python
maturin develop --uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;6. Install the wheel&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;cd $PROJECT_ROOT
uv pip install -e .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should now be able to run &lt;code&gt;python -m dynamo.frontend&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Remember that nats and etcd must be running (see earlier).&lt;/p&gt; 
&lt;p&gt;Set the environment variable &lt;code&gt;DYN_LOG&lt;/code&gt; to adjust the logging level; for example, &lt;code&gt;export DYN_LOG=debug&lt;/code&gt;. It has the same syntax as &lt;code&gt;RUST_LOG&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you use vscode or cursor, we have a .devcontainer folder built on &lt;a href="https://code.visualstudio.com/docs/devcontainers/containers"&gt;Microsofts Extension&lt;/a&gt;. For instructions see the &lt;a href="https://raw.githubusercontent.com/ai-dynamo/dynamo/main/.devcontainer/README.md"&gt;ReadMe&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>clockworklabs/SpacetimeDB</title>
      <link>https://github.com/clockworklabs/SpacetimeDB</link>
      <description>&lt;p&gt;Multiplayer at the speed of light&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://spacetimedb.com#gh-dark-mode-only" target="_blank"&gt; &lt;img width="320" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/dark/logo.svg?sanitize=true" alt="SpacetimeDB Logo" /&gt; &lt;/a&gt; &lt;a href="https://spacetimedb.com#gh-light-mode-only" target="_blank"&gt; &lt;img width="320" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/light/logo.svg?sanitize=true" alt="SpacetimeDB Logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://spacetimedb.com#gh-dark-mode-only" target="_blank"&gt; &lt;img width="250" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/dark/logo-text.svg?sanitize=true" alt="SpacetimeDB" /&gt; &lt;/a&gt; &lt;a href="https://spacetimedb.com#gh-light-mode-only" target="_blank"&gt; &lt;img width="250" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/light/logo-text.svg?sanitize=true" alt="SpacetimeDB" /&gt; &lt;/a&gt; &lt;/p&gt;
&lt;h3 align="center"&gt; Multiplayer at the speed of light. &lt;/h3&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/clockworklabs/spacetimedb"&gt;&lt;img src="https://img.shields.io/github/v/release/clockworklabs/spacetimedb?color=%23ff00a0&amp;amp;include_prereleases&amp;amp;label=version&amp;amp;sort=semver&amp;amp;style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/clockworklabs/spacetimedb"&gt;&lt;img src="https://img.shields.io/badge/built_with-Rust-dca282.svg?style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/clockworklabs/spacetimedb/actions"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/clockworklabs/spacetimedb/ci.yml?style=flat-square&amp;amp;branch=master" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://status.spacetimedb.com"&gt;&lt;img src="https://img.shields.io/uptimerobot/ratio/7/m784409192-e472ca350bb615372ededed7?label=cloud%20uptime&amp;amp;style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://hub.docker.com/r/clockworklabs/spacetimedb"&gt;&lt;img src="https://img.shields.io/docker/pulls/clockworklabs/spacetimedb?style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/clockworklabs/spacetimedb/raw/master/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/badge/license-BSL_1.1-00bfff.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://crates.io/crates/spacetimedb"&gt;&lt;img src="https://img.shields.io/crates/d/spacetimedb?color=e45928&amp;amp;label=Rust%20Crate&amp;amp;style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.nuget.org/packages/SpacetimeDB.Runtime"&gt;&lt;img src="https://img.shields.io/nuget/dt/spacetimedb.runtime?color=0b6cff&amp;amp;label=NuGet%20Package&amp;amp;style=flat-square" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/spacetimedb"&gt;&lt;img src="https://img.shields.io/discord/1037340874172014652?label=discord&amp;amp;style=flat-square&amp;amp;color=5a66f6" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://twitter.com/spacetime_db"&gt;&lt;img src="https://img.shields.io/badge/twitter-Follow_us-1d9bf0.svg?style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://clockworklabs.io/join"&gt;&lt;img src="https://img.shields.io/badge/careers-Join_us-86f7b7.svg?style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.linkedin.com/company/clockworklabs/"&gt;&lt;img src="https://img.shields.io/badge/linkedin-Connect_with_us-0a66c2.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/spacetimedb"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/discord.svg?sanitize=true" alt="Discord" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://twitter.com/spacetime_db"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/twitter.svg?sanitize=true" alt="Twitter" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/clockworklabs/spacetimedb"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/github.svg?sanitize=true" alt="GitHub" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://twitch.tv/SpacetimeDB"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/twitch.svg?sanitize=true" alt="Twitch" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://youtube.com/@SpacetimeDB"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/youtube.svg?sanitize=true" alt="YouTube" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.linkedin.com/company/clockwork-labs/"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/linkedin.svg?sanitize=true" alt="LinkedIn" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://stackoverflow.com/questions/tagged/spacetimedb"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/stackoverflow.svg?sanitize=true" alt="StackOverflow" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;What is &lt;a href="https://spacetimedb.com"&gt;SpacetimeDB&lt;/a&gt;?&lt;/h2&gt; 
&lt;p&gt;You can think of SpacetimeDB as both a database and server combined into one.&lt;/p&gt; 
&lt;p&gt;It is a relational database system that lets you upload your application logic directly into the database by way of fancy stored procedures called "modules."&lt;/p&gt; 
&lt;p&gt;Instead of deploying a web or game server that sits in between your clients and your database, your clients connect directly to the database and execute your application logic inside the database itself. You can write all of your permission and authorization logic right inside your module just as you would in a normal server.&lt;/p&gt; 
&lt;p&gt;This means that you can write your entire application in a single language, Rust, and deploy it as a single binary. No more microservices, no more containers, no more Kubernetes, no more Docker, no more VMs, no more DevOps, no more infrastructure, no more ops, no more servers.&lt;/p&gt; 
&lt;figure&gt; 
 &lt;img src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/basic-architecture-diagram.png" alt="SpacetimeDB Architecture" style="width:100%" /&gt; 
 &lt;figcaption align="center"&gt; 
  &lt;p align="center"&gt;&lt;b&gt;SpacetimeDB application architecture&lt;/b&gt;&lt;br /&gt;&lt;sup&gt;&lt;sub&gt;(elements in white are provided by SpacetimeDB)&lt;/sub&gt;&lt;/sup&gt;&lt;/p&gt; 
 &lt;/figcaption&gt; 
&lt;/figure&gt; 
&lt;p&gt;It's actually similar to the idea of smart contracts, except that SpacetimeDB is a database, has nothing to do with blockchain, and is orders of magnitude faster than any smart contract system.&lt;/p&gt; 
&lt;p&gt;So fast, in fact, that the entire backend of our MMORPG &lt;a href="https://bitcraftonline.com"&gt;BitCraft Online&lt;/a&gt; is just a SpacetimeDB module. We don't have any other servers or services running, which means that everything in the game, all of the chat messages, items, resources, terrain, and even the locations of the players are stored and processed by the database before being synchronized out to all of the clients in real-time.&lt;/p&gt; 
&lt;p&gt;SpacetimeDB is optimized for maximum speed and minimum latency rather than batch processing or OLAP workloads. It is designed to be used for real-time applications like games, chat, and collaboration tools.&lt;/p&gt; 
&lt;p&gt;This speed and latency is achieved by holding all of application state in memory, while persisting the data in a write-ahead-log (WAL) which is used to recover application state.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;You can run SpacetimeDB as a standalone database server via the &lt;code&gt;spacetime&lt;/code&gt; CLI tool. Install instructions for supported platforms are outlined below. The same install instructions can be found on our website at &lt;a href="https://spacetimedb.com/install"&gt;https://spacetimedb.com/install&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Install on macOS&lt;/h4&gt; 
&lt;p&gt;Installing on macOS is as simple as running our install script. After that you can use the spacetime command to manage versions.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSf https://install.spacetimedb.com | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Install on Linux&lt;/h4&gt; 
&lt;p&gt;Installing on Linux is as simple as running our install script. After that you can use the spacetime command to manage versions.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSf https://install.spacetimedb.com | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Install on Windows&lt;/h4&gt; 
&lt;p&gt;Installing on Windows is as simple as pasting the above snippet into PowerShell. If you would like to use WSL instead, please follow the Linux install instructions.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ps1"&gt;iwr https://windows.spacetimedb.com -useb | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Installing from Source&lt;/h4&gt; 
&lt;p&gt;A quick note on installing from source: we recommend that you don't install from source unless there is a feature that is available in &lt;code&gt;master&lt;/code&gt; that hasn't been released yet, otherwise follow the official installation instructions.&lt;/p&gt; 
&lt;h5&gt;MacOS + Linux&lt;/h5&gt; 
&lt;p&gt;Installing on macOS + Linux is pretty straightforward. First we are going to build all of the binaries that we need:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install rustup, you can skip this step if you have cargo and the wasm32-unknown-unknown target already installed.
curl https://sh.rustup.rs -sSf | sh
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
mkdir -p ~/.local/bin
export STDB_VERSION="$(./target/release/spacetimedb-cli --version | sed -n 's/.*spacetimedb tool version \([0-9.]*\);.*/\1/p')"
mkdir -p ~/.local/share/spacetime/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/.local/bin/spacetime
cp target/release/spacetimedb-cli ~/.local/share/spacetime/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/.local/share/spacetime/bin/$STDB_VERSION
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;At this stage you'll need to add ~/.local/bin to your path if you haven't already.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Please add the following line to your shell configuration and open a new shell session:
export PATH="$HOME/.local/bin:$PATH"

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then finally set your SpacetimeDB version:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
# Then, in a new shell, set the current version:
spacetime version use $STDB_VERSION

# If STDB_VERSION is not set anymore then you can use the following command to list your versions:
spacetime version list
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can verify that the correct version has been installed via &lt;code&gt;spacetime --version&lt;/code&gt;.&lt;/p&gt; 
&lt;h5&gt;Windows&lt;/h5&gt; 
&lt;p&gt;Building on windows is a bit more complicated. You'll need a slightly different version of perl compared to what comes pre-bundled in most Windows terminals. We recommend &lt;a href="https://strawberryperl.com/"&gt;Strawberry Perl&lt;/a&gt;. You may also need access to an &lt;code&gt;openssl&lt;/code&gt; binary which actually comes pre-installed with &lt;a href="https://git-scm.com/downloads/win"&gt;Git for Windows&lt;/a&gt;. Also, you'll need to install &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt; for Windows.&lt;/p&gt; 
&lt;p&gt;In a Git for Windows shell you should have something that looks like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ which perl
/c/Strawberry/perl/bin/perl
$ which openssl
/mingw64/bin/openssl
$ which cargo 
/c/Users/&amp;lt;user&amp;gt;/.cargo/bin/cargo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If that looks correct then you're ready to proceed!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB

# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
$stdbDir = "$HOME\AppData\Local\SpacetimeDB"
$stdbVersion = &amp;amp; ".\target\release\spacetimedb-cli" --version | Select-String -Pattern 'spacetimedb tool version ([0-9.]+);' | ForEach-Object { $_.Matches.Groups[1].Value }
New-Item -ItemType Directory -Path "$stdbDir\bin\$stdbVersion" -Force | Out-Null

# Install the update binary
Copy-Item "target\release\spacetimedb-update.exe" "$stdbDir\spacetime.exe"
Copy-Item "target\release\spacetimedb-cli.exe" "$stdbDir\bin\$stdbVersion\"
Copy-Item "target\release\spacetimedb-standalone.exe" "$stdbDir\bin\$stdbVersion\"

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;%USERPROFILE%\AppData\Local\SpacetimeDB
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then finally, open a new shell and use the installed SpacetimeDB version:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;spacetime version use $stdbVersion

# If stdbVersion is no longer set, list versions using the following command:
spacetime version list
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can verify that the correct version has been installed via &lt;code&gt;spacetime --version&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you're using Git for Windows you can follow these instructions instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
# Build the CLI binaries - this takes a while on windows so go grab a coffee :)
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
export STDB_VERSION="$(./target/release/spacetimedb-cli --version | sed -n 's/.*spacetimedb tool version \([0-9.]*\);.*/\1/p')"
mkdir -p ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/AppData/Local/SpacetimeDB/spacetime
cp target/release/spacetimedb-cli ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!
# %USERPROFILE%\AppData\Local\SpacetimeDB

# Set the current version
spacetime version use $STDB_VERSION
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can verify that the correct version has been installed via &lt;code&gt;spacetime --version&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Running with Docker&lt;/h4&gt; 
&lt;p&gt;If you prefer to run Spacetime in a container, you can use the following command to start a new instance.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm --pull always -p 3000:3000 clockworklabs/spacetime start
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For more information about SpacetimeDB, getting started guides, game development guides, and reference material please see our &lt;a href="https://spacetimedb.com/docs"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;We've prepared several getting started guides in each of our supported languages to help you get up and running with SpacetimeDB as quickly as possible. You can find them on our &lt;a href="https://spacetimedb.com/docs"&gt;docs page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In summary there are only 4 steps to getting started with SpacetimeDB.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the &lt;code&gt;spacetime&lt;/code&gt; CLI tool.&lt;/li&gt; 
 &lt;li&gt;Start a SpacetimeDB standalone node with &lt;code&gt;spacetime start&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Write and upload a module in one of our supported module languages.&lt;/li&gt; 
 &lt;li&gt;Connect to the database with one of our client libraries.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You can see a summary of the supported languages below with a link to the getting started guide for each.&lt;/p&gt; 
&lt;h2&gt;Language Support&lt;/h2&gt; 
&lt;p&gt;You can write SpacetimeDB modules in several popular languages, with more to come in the future!&lt;/p&gt; 
&lt;h4&gt;Serverside Libraries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://spacetimedb.com/docs/modules/rust/quickstart"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://spacetimedb.com/docs/modules/c-sharp/quickstart"&gt;C#&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Client Libraries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://spacetimedb.com/docs/sdks/rust/quickstart"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://spacetimedb.com/docs/sdks/c-sharp/quickstart"&gt;C#&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://spacetimedb.com/docs/sdks/typescript/quickstart"&gt;Typescript&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;SpacetimeDB is licensed under the BSL 1.1 license. This is not an open source or free software license, however, it converts to the AGPL v3.0 license with a linking exception after a few years.&lt;/p&gt; 
&lt;p&gt;Note that the AGPL v3.0 does not typically include a linking exception. We have added a custom linking exception to the AGPL license for SpacetimeDB. Our motivation for choosing a free software license is to ensure that contributions made to SpacetimeDB are propagated back to the community. We are expressly not interested in forcing users of SpacetimeDB to open source their own code if they link with SpacetimeDB, so we needed to include a linking exception.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>deuxfleurs-org/garage</title>
      <link>https://github.com/deuxfleurs-org/garage</link>
      <description>&lt;p&gt;(Mirror) S3-compatible object store for small self-hosted geo-distributed deployments. Main repo: https://git.deuxfleurs.fr/Deuxfleurs/garage&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Garage &lt;a href="https://woodpecker.deuxfleurs.fr/repos/1"&gt;&lt;img src="https://woodpecker.deuxfleurs.fr/api/badges/1/status.svg?sanitize=true" alt="status-badge" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p align="center" style="text-align:center;"&gt; &lt;a href="https://garagehq.deuxfleurs.fr"&gt; &lt;img alt="Garage logo" src="https://garagehq.deuxfleurs.fr/img/logo.svg?sanitize=true" height="200" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center" style="text-align:center;"&gt; [ &lt;strong&gt;&lt;a href="https://garagehq.deuxfleurs.fr/"&gt;Website and documentation&lt;/a&gt;&lt;/strong&gt; | &lt;a href="https://garagehq.deuxfleurs.fr/_releases.html"&gt;Binary releases&lt;/a&gt; | &lt;a href="https://git.deuxfleurs.fr/Deuxfleurs/garage"&gt;Git repository&lt;/a&gt; | &lt;a href="https://matrix.to/#/%23garage:deuxfleurs.fr"&gt;Matrix channel&lt;/a&gt; ] &lt;/p&gt; 
&lt;p&gt;Garage is an S3-compatible distributed object storage service designed for self-hosting at a small-to-medium scale.&lt;/p&gt; 
&lt;p&gt;Garage is designed for storage clusters composed of nodes running at different physical locations, in order to easily provide a storage service that replicates data at these different locations and stays available even when some servers are unreachable. Garage also focuses on being lightweight, easy to operate, and highly resilient to machine failures.&lt;/p&gt; 
&lt;p&gt;Garage is built by &lt;a href="https://deuxfleurs.fr"&gt;Deuxfleurs&lt;/a&gt;, an experimental small-scale self hosted service provider, which has been using it in production since its first release in 2020.&lt;/p&gt; 
&lt;p&gt;Learn more on our dedicated documentation pages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://garagehq.deuxfleurs.fr/documentation/design/goals/"&gt;Goals and use cases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://garagehq.deuxfleurs.fr/documentation/reference-manual/features/"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://garagehq.deuxfleurs.fr/documentation/quick-start/"&gt;Quick start&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Garage is entirely free software released under the terms of the AGPLv3.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>stalwartlabs/stalwart</title>
      <link>https://github.com/stalwartlabs/stalwart</link>
      <description>&lt;p&gt;All-in-one Mail &amp; Collaboration server. Secure, scalable and fluent in every protocol (IMAP, JMAP, SMTP, CalDAV, CardDAV, WebDAV).&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://stalw.art"&gt; &lt;img src="https://raw.githubusercontent.com/stalwartlabs/stalwart/main/img/logo-red.svg?sanitize=true" height="150" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt; Secure, scalable mail &amp;amp; collaboration server with comprehensive protocol support 🛡️ &lt;br /&gt;(IMAP, JMAP, SMTP, CalDAV, CardDAV, WebDAV) &lt;/h3&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/stalwartlabs/stalwart/actions/workflows/ci.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/stalwartlabs/stalwart/ci.yml?style=flat-square" alt="continuous integration" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.gnu.org/licenses/agpl-3.0"&gt;&lt;img src="https://img.shields.io/badge/License-AGPL_v3-blue.svg?label=license&amp;amp;style=flat-square" alt="License: AGPL v3" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://stalw.art/docs/install/get-started"&gt;&lt;img src="https://img.shields.io/badge/read_the-docs-red?style=flat-square" alt="Documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://mastodon.social/@stalwartlabs"&gt;&lt;img src="https://img.shields.io/mastodon/follow/109929667531941122?style=flat-square&amp;amp;logo=mastodon&amp;amp;color=%236364ff&amp;amp;label=Follow%20on%20Mastodon" alt="Mastodon" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://twitter.com/stalwartlabs"&gt;&lt;img src="https://img.shields.io/twitter/follow/stalwartlabs?style=flat-square&amp;amp;logo=x&amp;amp;label=Follow%20on%20Twitter" alt="Twitter" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.com/servers/stalwart-923615863037390889"&gt;&lt;img src="https://img.shields.io/discord/923615863037390889?label=Join%20Discord&amp;amp;logo=discord&amp;amp;style=flat-square" alt="Discord" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.reddit.com/r/stalwartlabs/"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/stalwartlabs?label=Join%20%2Fr%2Fstalwartlabs&amp;amp;logo=reddit&amp;amp;style=flat-square" alt="Reddit" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Stalwart&lt;/strong&gt; is an open-source mail &amp;amp; collaboration server with JMAP, IMAP4, POP3, SMTP, CalDAV, CardDAV and WebDAV support and a wide range of modern features. It is written in Rust and designed to be secure, fast, robust and scalable.&lt;/p&gt; 
&lt;p&gt;Key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Email&lt;/strong&gt; server with complete protocol support: 
  &lt;ul&gt; 
   &lt;li&gt;JMAP: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc8621"&gt;JMAP for Mail&lt;/a&gt; server.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://www.ietf.org/archive/id/draft-ietf-jmap-sieve-22.html"&gt;JMAP for Sieve Scripts&lt;/a&gt;.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc8887"&gt;WebSocket&lt;/a&gt;, &lt;a href="https://www.rfc-editor.org/rfc/rfc9404.html"&gt;Blob Management&lt;/a&gt; and &lt;a href="https://www.rfc-editor.org/rfc/rfc9425.html"&gt;Quotas&lt;/a&gt; extensions.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;IMAP: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc9051"&gt;IMAP4rev2&lt;/a&gt; and &lt;a href="https://datatracker.ietf.org/doc/html/rfc3501"&gt;IMAP4rev1&lt;/a&gt; server.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc5804"&gt;ManageSieve&lt;/a&gt; server.&lt;/li&gt; 
     &lt;li&gt;Numerous &lt;a href="https://stalw.art/docs/development/rfcs#imap4-and-extensions"&gt;extensions&lt;/a&gt; supported.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;POP3: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc1939"&gt;POP3&lt;/a&gt; server.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc2595"&gt;STLS&lt;/a&gt; and &lt;a href="https://datatracker.ietf.org/doc/html/rfc5034"&gt;SASL&lt;/a&gt; support as well as other &lt;a href="https://datatracker.ietf.org/doc/html/rfc2449"&gt;extensions&lt;/a&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;SMTP: 
    &lt;ul&gt; 
     &lt;li&gt;SMTP server with built-in &lt;a href="https://datatracker.ietf.org/doc/html/rfc7489"&gt;DMARC&lt;/a&gt;, &lt;a href="https://datatracker.ietf.org/doc/html/rfc6376"&gt;DKIM&lt;/a&gt;, &lt;a href="https://datatracker.ietf.org/doc/html/rfc7208"&gt;SPF&lt;/a&gt; and &lt;a href="https://datatracker.ietf.org/doc/html/rfc8617"&gt;ARC&lt;/a&gt; support for message authentication.&lt;/li&gt; 
     &lt;li&gt;Strong transport security through &lt;a href="https://datatracker.ietf.org/doc/html/rfc6698"&gt;DANE&lt;/a&gt;, &lt;a href="https://datatracker.ietf.org/doc/html/rfc8461"&gt;MTA-STS&lt;/a&gt; and &lt;a href="https://datatracker.ietf.org/doc/html/rfc8460"&gt;SMTP TLS&lt;/a&gt; reporting.&lt;/li&gt; 
     &lt;li&gt;Inbound throttling and filtering with granular configuration rules, sieve scripting, MTA hooks and milter integration.&lt;/li&gt; 
     &lt;li&gt;Distributed virtual queues with delayed delivery, priority delivery, quotas, routing rules and throttling support.&lt;/li&gt; 
     &lt;li&gt;Envelope rewriting and message modification.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Collaboration&lt;/strong&gt; server: 
  &lt;ul&gt; 
   &lt;li&gt;Calendaring and scheduling: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc4791"&gt;CalDAV&lt;/a&gt; and &lt;a href="https://datatracker.ietf.org/doc/html/rfc6638"&gt;CalDAV Scheduling&lt;/a&gt; support.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/draft-ietf-jmap-calendars-24"&gt;JMAP for Calendars&lt;/a&gt; support.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Contact management: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc6352"&gt;CardDAV&lt;/a&gt; support.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc9610"&gt;JMAP for Contacts&lt;/a&gt; support.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;File storage: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc4918"&gt;WebDAV&lt;/a&gt; support.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/draft-ietf-jmap-filenode-03"&gt;JMAP for File Storage&lt;/a&gt; support.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Sharing with fine-grained access controls: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc3744"&gt;WebDAV ACL&lt;/a&gt; support.&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://datatracker.ietf.org/doc/html/rfc9670"&gt;JMAP Sharing&lt;/a&gt; support.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Spam&lt;/strong&gt; and &lt;strong&gt;Phishing&lt;/strong&gt; built-in filter: 
  &lt;ul&gt; 
   &lt;li&gt;Comprehensive set of filtering &lt;strong&gt;rules&lt;/strong&gt; on par with popular solutions.&lt;/li&gt; 
   &lt;li&gt;LLM-driven spam filtering and message analysis.&lt;/li&gt; 
   &lt;li&gt;Statistical &lt;strong&gt;spam classifier&lt;/strong&gt; with automatic training capabilities and address book integration.&lt;/li&gt; 
   &lt;li&gt;DNS Blocklists (&lt;strong&gt;DNSBLs&lt;/strong&gt;) checking of IP addresses, domains, and hashes.&lt;/li&gt; 
   &lt;li&gt;Collaborative digest-based spam filtering with &lt;strong&gt;Pyzor&lt;/strong&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Phishing&lt;/strong&gt; protection against homographic URL attacks, sender spoofing and other techniques.&lt;/li&gt; 
   &lt;li&gt;Trusted &lt;strong&gt;reply&lt;/strong&gt; tracking to recognize and prioritize genuine e-mail replies.&lt;/li&gt; 
   &lt;li&gt;Sender &lt;strong&gt;reputation&lt;/strong&gt; monitoring by IP address, ASN, domain and email address.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Greylisting&lt;/strong&gt; to temporarily defer unknown senders.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Spam traps&lt;/strong&gt; to set up decoy email addresses that catch and analyze spam.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Pluggable storage backends with &lt;strong&gt;RocksDB&lt;/strong&gt;, &lt;strong&gt;FoundationDB&lt;/strong&gt;, &lt;strong&gt;PostgreSQL&lt;/strong&gt;, &lt;strong&gt;mySQL&lt;/strong&gt;, &lt;strong&gt;SQLite&lt;/strong&gt;, &lt;strong&gt;S3-Compatible&lt;/strong&gt;, &lt;strong&gt;Azure&lt;/strong&gt;, &lt;strong&gt;Redis&lt;/strong&gt; and &lt;strong&gt;ElasticSearch&lt;/strong&gt; support.&lt;/li&gt; 
   &lt;li&gt;Full-text search available in 17 languages.&lt;/li&gt; 
   &lt;li&gt;Sieve scripting language with support for all &lt;a href="https://www.iana.org/assignments/sieve-extensions/sieve-extensions.xhtml"&gt;registered extensions&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Email aliases, mailing lists, subaddressing and catch-all addresses support.&lt;/li&gt; 
   &lt;li&gt;Automatic account configuration and discovery with &lt;a href="https://www.ietf.org/id/draft-bucksch-autoconfig-02.html"&gt;autoconfig&lt;/a&gt; and &lt;a href="https://learn.microsoft.com/en-us/exchange/architecture/client-access/autodiscover?view=exchserver-2019"&gt;autodiscover&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Multi-tenancy support with domain and tenant isolation.&lt;/li&gt; 
   &lt;li&gt;Disk quotas per user and tenant.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Secure and robust&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Encryption at rest with &lt;strong&gt;S/MIME&lt;/strong&gt; or &lt;strong&gt;OpenPGP&lt;/strong&gt;.&lt;/li&gt; 
   &lt;li&gt;Automatic TLS certificate provisioning with &lt;a href="https://datatracker.ietf.org/doc/html/rfc8555"&gt;ACME&lt;/a&gt; using &lt;code&gt;TLS-ALPN-01&lt;/code&gt;, &lt;code&gt;DNS-01&lt;/code&gt; or &lt;code&gt;HTTP-01&lt;/code&gt; challenges.&lt;/li&gt; 
   &lt;li&gt;Automated blocking of IP addresses that attack, abuse or scan the server for exploits.&lt;/li&gt; 
   &lt;li&gt;Rate limiting.&lt;/li&gt; 
   &lt;li&gt;Security audited (read the &lt;a href="https://stalw.art/blog/security-audit"&gt;report&lt;/a&gt;).&lt;/li&gt; 
   &lt;li&gt;Memory safe (thanks to Rust).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable and fault-tolerant&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Designed to handle growth seamlessly, from small setups to large-scale deployments of thousands of nodes.&lt;/li&gt; 
   &lt;li&gt;Built with &lt;strong&gt;fault tolerance&lt;/strong&gt; and &lt;strong&gt;high availability&lt;/strong&gt; in mind, recovers from hardware or software failures with minimal operational impact.&lt;/li&gt; 
   &lt;li&gt;Peer-to-peer cluster coordination or with &lt;strong&gt;Kafka&lt;/strong&gt;, &lt;strong&gt;Redpanda&lt;/strong&gt;, &lt;strong&gt;NATS&lt;/strong&gt; or &lt;strong&gt;Redis&lt;/strong&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;, &lt;strong&gt;Apache Mesos&lt;/strong&gt; and &lt;strong&gt;Docker Swarm&lt;/strong&gt; support for automated scaling and container orchestration.&lt;/li&gt; 
   &lt;li&gt;Read replicas, sharded blob storage and in-memory data stores for high performance and low latency.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication and Authorization&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;OpenID Connect&lt;/strong&gt; authentication.&lt;/li&gt; 
   &lt;li&gt;OAuth 2.0 authorization with &lt;a href="https://www.rfc-editor.org/rfc/rfc8628"&gt;authorization code&lt;/a&gt; and &lt;a href="https://www.rfc-editor.org/rfc/rfc8628"&gt;device authorization&lt;/a&gt; flows.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;LDAP&lt;/strong&gt;, &lt;strong&gt;OIDC&lt;/strong&gt;, &lt;strong&gt;SQL&lt;/strong&gt; or built-in authentication backend support.&lt;/li&gt; 
   &lt;li&gt;Two-factor authentication with Time-based One-Time Passwords (&lt;code&gt;2FA-TOTP&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;Application passwords (App Passwords).&lt;/li&gt; 
   &lt;li&gt;Roles and permissions.&lt;/li&gt; 
   &lt;li&gt;Access Control Lists (ACLs).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Logging and tracing with &lt;strong&gt;OpenTelemetry&lt;/strong&gt;, journald, log files and console support.&lt;/li&gt; 
   &lt;li&gt;Metrics with &lt;strong&gt;OpenTelemetry&lt;/strong&gt; and &lt;strong&gt;Prometheus&lt;/strong&gt; integration.&lt;/li&gt; 
   &lt;li&gt;Webhooks for event-driven automation.&lt;/li&gt; 
   &lt;li&gt;Alerts with email and webhook notifications.&lt;/li&gt; 
   &lt;li&gt;Live tracing and metrics.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Web-based administration&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Dashboard with real-time statistics and monitoring.&lt;/li&gt; 
   &lt;li&gt;Account, domain, group and mailing list management.&lt;/li&gt; 
   &lt;li&gt;SMTP queue management for messages and outbound DMARC and TLS reports.&lt;/li&gt; 
   &lt;li&gt;Report visualization interface for received DMARC, TLS-RPT and Failure (ARF) reports.&lt;/li&gt; 
   &lt;li&gt;Configuration of every aspect of the mail server.&lt;/li&gt; 
   &lt;li&gt;Log viewer with search and filtering capabilities.&lt;/li&gt; 
   &lt;li&gt;Self-service portal for password reset and encryption-at-rest key management.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;img src="https://raw.githubusercontent.com/stalwartlabs/stalwart/main/img/screencast-setup.gif" /&gt; 
&lt;h2&gt;Presentation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Want a deeper dive?&lt;/strong&gt; Need to explain to your boss why Stalwart is the perfect fit? Whether you're evaluating options, making a case to your team, or simply curious about how it all works under the hood, these slides walk you through the key features, architecture, and benefits of Stalwart. Browse the &lt;a href="https://stalw.art/slides"&gt;slides&lt;/a&gt; to see what makes it stand out.&lt;/p&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;p&gt;Install Stalwart on your server by following the instructions for your platform:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://stalw.art/docs/install/platform/linux"&gt;Linux / MacOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://stalw.art/docs/install/platform/windows"&gt;Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://stalw.art/docs/install/platform/docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All documentation is available at &lt;a href="https://stalw.art/docs/install/get-started"&gt;stalw.art/docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;If you are having problems running Stalwart, you found a bug or just have a question, do not hesitate to reach us on &lt;a href="https://github.com/stalwartlabs/stalwart/discussions"&gt;GitHub Discussions&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/stalwartlabs"&gt;Reddit&lt;/a&gt; or &lt;a href="https://discord.com/servers/stalwart-923615863037390889"&gt;Discord&lt;/a&gt;. Additionally you may purchase an &lt;a href="https://stalw.art/enterprise"&gt;Enterprise License&lt;/a&gt; to obtain priority support from Stalwart Labs LLC.&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Stalwart has reached an exciting point in its journey, it’s now &lt;strong&gt;feature complete&lt;/strong&gt;. All the core functionality and open standard email and collaboration protocols that we set out to support are in place. In other words, Stalwart already does everything you’d expect from a modern, standards-compliant mail and collaboration platform.&lt;/p&gt; 
&lt;p&gt;The next major milestone is all about refinement: finalizing the database schema and focusing on performance optimizations to ensure everything runs as efficiently and reliably as possible. Once that’s done, we’ll be ready to roll out version &lt;strong&gt;1.0&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;Of course, development doesn’t stop there. The community has contributed hundreds of great ideas for improvements and new features, everything from subtle usability tweaks to entirely new integrations. You can see the full list of proposals over on our &lt;a href="https://github.com/stalwartlabs/stalwart/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3Aenhancement"&gt;GitHub issues&lt;/a&gt;. If there’s something you’d like to see prioritized, just give it a thumbs up as we plan to implement enhancements based on the community’s votes.&lt;/p&gt; 
&lt;h2&gt;Sponsorship&lt;/h2&gt; 
&lt;p&gt;Your support is crucial in helping us continue to improve the project, add new features, and maintain the highest level of quality. By &lt;a href="https://opencollective.com/stalwart"&gt;becoming a sponsor&lt;/a&gt;, you help fund the development and future of Stalwart. As a thank-you, sponsors who contribute $5 per month or more will automatically receive a &lt;a href="https://stalw.art/enterprise/"&gt;Enterprise edition&lt;/a&gt; license. And, sponsors who contribute $30 per month or more, also have access to &lt;a href="https://stalw.art/support"&gt;Premium Support&lt;/a&gt; from Stalwart Labs.&lt;/p&gt; 
&lt;p&gt;These are some of our open-source sponsors:&lt;/p&gt; 
&lt;!-- sponsors --&gt;
&lt;a href="https://github.com/kbjr"&gt;&lt;img src="https://github.com/kbjr.png" width="60px" alt="User avatar: James Brumond" /&gt;&lt;/a&gt;
&lt;a href="https://github.com/MailRoute"&gt;&lt;img src="https://github.com/MailRoute.png" width="60px" alt="User avatar: MailRoute, Inc." /&gt;&lt;/a&gt;
&lt;a href="https://github.com/starsong-consulting"&gt;&lt;img src="https://github.com/starsong-consulting.png" width="60px" alt="User avatar: Starsong GmbH" /&gt;&lt;/a&gt;
&lt;a href="https://github.com/mingfu-design"&gt;&lt;img src="https://github.com/mingfu-design.png" width="60px" alt="User avatar: Ming Fu Design Ltd. 明孚設計有限公司" /&gt;&lt;/a&gt;
&lt;a href="https://github.com/tamwuff"&gt;&lt;img src="https://github.com/tamwuff.png" width="60px" alt="User avatar: Tamino" /&gt;&lt;/a&gt;
&lt;a href="https://github.com/panascais"&gt;&lt;img src="https://github.com/panascais.png" width="60px" alt="User avatar: panascais" /&gt;&lt;/a&gt;
&lt;a href="https://github.com/ToxicMushroom"&gt;&lt;img src="https://github.com/ToxicMushroom.png" width="60px" alt="User avatar: Merlijn" /&gt;&lt;/a&gt;
&lt;!-- sponsors --&gt; 
&lt;p&gt;&lt;br /&gt;If you would like to support our work, please consider &lt;a href="https://opencollective.com/stalwart"&gt;becoming a sponsor&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Funding&lt;/h2&gt; 
&lt;p&gt;Part of the development of this project was funded through:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://nlnet.nl/entrust"&gt;NGI0 Entrust Fund&lt;/a&gt;, a fund established by &lt;a href="https://nlnet.nl/"&gt;NLnet&lt;/a&gt; with financial support from the European Commission's &lt;a href="https://ngi.eu/"&gt;Next Generation Internet&lt;/a&gt; programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No 101069594.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nlnet.nl/NGI0/"&gt;NGI Zero Core&lt;/a&gt;, a fund established by &lt;a href="https://nlnet.nl/"&gt;NLnet&lt;/a&gt; with financial support from the European Commission's programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No 101092990.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you find the project useful you can help by &lt;a href="https://opencollective.com/stalwart"&gt;becoming a sponsor&lt;/a&gt;. Thank you!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is dual-licensed under the &lt;strong&gt;GNU Affero General Public License v3.0&lt;/strong&gt; (AGPL-3.0; as published by the Free Software Foundation) and the &lt;strong&gt;Stalwart Enterprise License v1 (SELv1)&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://raw.githubusercontent.com/stalwartlabs/stalwart/main/LICENSES/AGPL-3.0-only.txt"&gt;GNU Affero General Public License v3.0&lt;/a&gt; is a free software license that ensures your freedom to use, modify, and distribute the software, with the condition that any modified versions of the software must also be distributed under the same license.&lt;/li&gt; 
 &lt;li&gt;The &lt;a href="https://raw.githubusercontent.com/stalwartlabs/stalwart/main/LICENSES/LicenseRef-SEL.txt"&gt;Stalwart Enterprise License v1 (SELv1)&lt;/a&gt; is a proprietary license designed for commercial use. It offers additional features and greater flexibility for businesses that do not wish to comply with the AGPL-3.0 license requirements.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each file in this project contains a license notice at the top, indicating the applicable license(s). The license notice follows the &lt;a href="https://reuse.software/"&gt;REUSE guidelines&lt;/a&gt; to ensure clarity and consistency. The full text of each license is available in the &lt;a href="https://raw.githubusercontent.com/stalwartlabs/stalwart/main/LICENSES/"&gt;LICENSES&lt;/a&gt; directory.&lt;/p&gt; 
&lt;h2&gt;Copyright&lt;/h2&gt; 
&lt;p&gt;Copyright (C) 2020, Stalwart Labs LLC&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>astral-sh/uv</title>
      <link>https://github.com/astral-sh/uv</link>
      <description>&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;uv&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/astral-sh/uv"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json" alt="uv" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/v/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/l/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://pypi.python.org/pypi/uv"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/uv.svg?sanitize=true" alt="image" /&gt;&lt;/a&gt; &lt;a href="https://github.com/astral-sh/uv/actions"&gt;&lt;img src="https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Actions status" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/astral-sh"&gt;&lt;img src="https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;An extremely fast Python package and project manager, written in Rust.&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d" /&gt; 
  &lt;img alt="Shows a bar chart with benchmark results." src="https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;i&gt;Installing &lt;a href="https://trio.readthedocs.io/"&gt;Trio&lt;/a&gt;'s dependencies with a warm cache.&lt;/i&gt; &lt;/p&gt; 
&lt;h2&gt;Highlights&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🚀 A single tool to replace &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, &lt;code&gt;pipx&lt;/code&gt;, &lt;code&gt;poetry&lt;/code&gt;, &lt;code&gt;pyenv&lt;/code&gt;, &lt;code&gt;twine&lt;/code&gt;, &lt;code&gt;virtualenv&lt;/code&gt;, and more.&lt;/li&gt; 
 &lt;li&gt;⚡️ &lt;a href="https://github.com/astral-sh/uv/raw/main/BENCHMARKS.md"&gt;10-100x faster&lt;/a&gt; than &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;🗂️ Provides &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#projects"&gt;comprehensive project management&lt;/a&gt;, with a &lt;a href="https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile"&gt;universal lockfile&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;❇️ &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#scripts"&gt;Runs scripts&lt;/a&gt;, with support for &lt;a href="https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies"&gt;inline dependency metadata&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;🐍 &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#python-versions"&gt;Installs and manages&lt;/a&gt; Python versions.&lt;/li&gt; 
 &lt;li&gt;🛠️ &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#tools"&gt;Runs and installs&lt;/a&gt; tools published as Python packages.&lt;/li&gt; 
 &lt;li&gt;🔩 Includes a &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/#the-pip-interface"&gt;pip-compatible interface&lt;/a&gt; for a performance boost with a familiar CLI.&lt;/li&gt; 
 &lt;li&gt;🏢 Supports Cargo-style &lt;a href="https://docs.astral.sh/uv/concepts/projects/workspaces"&gt;workspaces&lt;/a&gt; for scalable projects.&lt;/li&gt; 
 &lt;li&gt;💾 Disk-space efficient, with a &lt;a href="https://docs.astral.sh/uv/concepts/cache"&gt;global cache&lt;/a&gt; for dependency deduplication.&lt;/li&gt; 
 &lt;li&gt;⏬ Installable without Rust or Python via &lt;code&gt;curl&lt;/code&gt; or &lt;code&gt;pip&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;🖥️ Supports macOS, Linux, and Windows.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;uv is backed by &lt;a href="https://astral.sh"&gt;Astral&lt;/a&gt;, the creators of &lt;a href="https://github.com/astral-sh/ruff"&gt;Ruff&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install uv with our standalone installers:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# On Windows.
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or, from &lt;a href="https://pypi.org/project/uv/"&gt;PyPI&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# With pip.
pip install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Or pipx.
pipx install uv
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If installed via the standalone installer, uv can update itself to the latest version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv self update
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;installation documentation&lt;/a&gt; for details and alternative installation methods.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;uv's documentation is available at &lt;a href="https://docs.astral.sh/uv"&gt;docs.astral.sh/uv&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Additionally, the command line reference documentation can be viewed with &lt;code&gt;uv help&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Projects&lt;/h3&gt; 
&lt;p&gt;uv manages project dependencies and environments, with support for lockfiles, workspaces, and more, similar to &lt;code&gt;rye&lt;/code&gt; or &lt;code&gt;poetry&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/projects/"&gt;project documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;p&gt;uv also supports building and publishing projects, even if they're not managed with uv. See the &lt;a href="https://docs.astral.sh/uv/guides/publish/"&gt;publish guide&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;h3&gt;Scripts&lt;/h3&gt; 
&lt;p&gt;uv manages dependencies and environments for single-file scripts.&lt;/p&gt; 
&lt;p&gt;Create a new script and add inline metadata declaring its dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ echo 'import requests; print(requests.get("https://astral.sh"))' &amp;gt; example.py

$ uv add --script example.py requests
Updated `example.py`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then, run the script in an isolated virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&amp;lt;Response [200]&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/scripts/"&gt;scripts documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Tools&lt;/h3&gt; 
&lt;p&gt;uv executes and installs command-line tools provided by Python packages, similar to &lt;code&gt;pipx&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Run a tool in an ephemeral environment using &lt;code&gt;uvx&lt;/code&gt; (an alias for &lt;code&gt;uv tool run&lt;/code&gt;):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uvx pycowsay 'hello world!'
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  """

  ------------
&amp;lt; hello world! &amp;gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install a tool with &lt;code&gt;uv tool install&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/tools/"&gt;tools documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;Python versions&lt;/h3&gt; 
&lt;p&gt;uv installs Python and allows quickly switching between versions.&lt;/p&gt; 
&lt;p&gt;Install multiple Python versions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Download Python versions as needed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&amp;gt;&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use a specific Python version in the current directory:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv python pin 3.11
Pinned `.python-version` to `3.11`
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/guides/install-python/"&gt;Python installation documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h3&gt;The pip interface&lt;/h3&gt; 
&lt;p&gt;uv provides a drop-in replacement for common &lt;code&gt;pip&lt;/code&gt;, &lt;code&gt;pip-tools&lt;/code&gt;, and &lt;code&gt;virtualenv&lt;/code&gt; commands.&lt;/p&gt; 
&lt;p&gt;uv extends their interfaces with advanced features, such as dependency version overrides, platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and more.&lt;/p&gt; 
&lt;p&gt;Migrate to uv without changing your existing workflows — and experience a 10-100x speedup — with the &lt;code&gt;uv pip&lt;/code&gt; interface.&lt;/p&gt; 
&lt;p&gt;Compile requirements into a platform-independent requirements file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Create a virtual environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Install the locked requirements:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://docs.astral.sh/uv/pip/index/"&gt;pip interface documentation&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Platform support&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/platforms/"&gt;platform support&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Versioning policy&lt;/h2&gt; 
&lt;p&gt;See uv's &lt;a href="https://docs.astral.sh/uv/reference/versioning/"&gt;versioning policy&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We are passionate about supporting contributors of all levels of experience and would love to see you get involved in the project. See the &lt;a href="https://github.com/astral-sh/uv/raw/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h4&gt;How do you pronounce uv?&lt;/h4&gt; 
&lt;p&gt;It's pronounced as "you - vee" (&lt;a href="https://en.wikipedia.org/wiki/Help:IPA/English#Key"&gt;&lt;code&gt;/juː viː/&lt;/code&gt;&lt;/a&gt;)&lt;/p&gt; 
&lt;h4&gt;How should I stylize uv?&lt;/h4&gt; 
&lt;p&gt;Just "uv", please. See the &lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/STYLE.md#styling-uv"&gt;style guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;uv's dependency resolver uses &lt;a href="https://github.com/pubgrub-rs/pubgrub"&gt;PubGrub&lt;/a&gt; under the hood. We're grateful to the PubGrub maintainers, especially &lt;a href="https://github.com/Eh2406"&gt;Jacob Finkelman&lt;/a&gt;, for their support.&lt;/p&gt; 
&lt;p&gt;uv's Git implementation is based on &lt;a href="https://github.com/rust-lang/cargo"&gt;Cargo&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Some of uv's optimizations are inspired by the great work we've seen in &lt;a href="https://pnpm.io/"&gt;pnpm&lt;/a&gt;, &lt;a href="https://github.com/orogene/orogene"&gt;Orogene&lt;/a&gt;, and &lt;a href="https://github.com/oven-sh/bun"&gt;Bun&lt;/a&gt;. We've also learned a lot from Nathaniel J. Smith's &lt;a href="https://github.com/njsmith/posy"&gt;Posy&lt;/a&gt; and adapted its &lt;a href="https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline"&gt;trampoline&lt;/a&gt; for Windows support.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;uv is licensed under either of&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Apache License, Version 2.0, (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-APACHE"&gt;LICENSE-APACHE&lt;/a&gt; or &lt;a href="https://www.apache.org/licenses/LICENSE-2.0"&gt;https://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;MIT license (&lt;a href="https://raw.githubusercontent.com/astral-sh/uv/main/LICENSE-MIT"&gt;LICENSE-MIT&lt;/a&gt; or &lt;a href="https://opensource.org/licenses/MIT"&gt;https://opensource.org/licenses/MIT&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;at your option.&lt;/p&gt; 
&lt;p&gt;Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any additional terms or conditions.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a target="_blank" href="https://astral.sh" style="background:none"&gt; &lt;img src="https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg?sanitize=true" alt="Made by Astral" /&gt; &lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>huggingface/text-embeddings-inference</title>
      <link>https://github.com/huggingface/text-embeddings-inference</link>
      <description>&lt;p&gt;A blazing fast inference solution for text embeddings models&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;h1&gt;Text Embeddings Inference&lt;/h1&gt; 
 &lt;a href="https://github.com/huggingface/text-embeddings-inference"&gt; &lt;img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/huggingface/text-embeddings-inference?style=social" /&gt; &lt;/a&gt; 
 &lt;a href="https://huggingface.github.io/text-embeddings-inference"&gt; &lt;img alt="Swagger API documentation" src="https://img.shields.io/badge/API-Swagger-informational" /&gt; &lt;/a&gt; 
 &lt;p&gt;A blazing fast inference solution for text embeddings models.&lt;/p&gt; 
 &lt;p&gt;Benchmark for &lt;a href="https://huggingface.co/BAAI/bge-base-en-v1.5"&gt;BAAI/bge-base-en-v1.5&lt;/a&gt; on an NVIDIA A10 with a sequence length of 512 tokens:&lt;/p&gt; 
 &lt;p&gt; &lt;img src="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/assets/bs1-lat.png" width="400" /&gt; &lt;img src="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/assets/bs1-tp.png" width="400" /&gt; &lt;/p&gt; 
 &lt;p&gt; &lt;img src="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/assets/bs32-lat.png" width="400" /&gt; &lt;img src="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/assets/bs32-tp.png" width="400" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Table of contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#get-started"&gt;Get Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#supported-models"&gt;Supported Models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#docker-images"&gt;Docker Images&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#api-documentation"&gt;API Documentation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#using-a-private-or-gated-model"&gt;Using a private or gated model&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#air-gapped-deployment"&gt;Air gapped deployment&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#using-re-rankers-models"&gt;Using Re-rankers models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#using-sequence-classification-models"&gt;Using Sequence Classification models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#using-splade-pooling"&gt;Using SPLADE pooling&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#distributed-tracing"&gt;Distributed Tracing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#grpc"&gt;gRPC&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#local-install"&gt;Local Install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#docker-build"&gt;Docker Build&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#apple-m1m2-arm64-architectures"&gt;Apple M1/M2 Arm&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/text-embeddings-inference/main/#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Text Embeddings Inference (TEI) is a toolkit for deploying and serving open source text embeddings and sequence classification models. TEI enables high-performance extraction for the most popular models, including FlagEmbedding, Ember, GTE and E5. TEI implements many features such as:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No model graph compilation step&lt;/li&gt; 
 &lt;li&gt;Metal support for local execution on Macs&lt;/li&gt; 
 &lt;li&gt;Small docker images and fast boot times. Get ready for true serverless!&lt;/li&gt; 
 &lt;li&gt;Token based dynamic batching&lt;/li&gt; 
 &lt;li&gt;Optimized transformers code for inference using &lt;a href="https://github.com/HazyResearch/flash-attention"&gt;Flash Attention&lt;/a&gt;, &lt;a href="https://github.com/huggingface/candle"&gt;Candle&lt;/a&gt; and &lt;a href="https://docs.nvidia.com/cuda/cublas/#using-the-cublaslt-api"&gt;cuBLASLt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/safetensors"&gt;Safetensors&lt;/a&gt; weight loading&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/onnx/onnx"&gt;ONNX&lt;/a&gt; weight loading&lt;/li&gt; 
 &lt;li&gt;Production ready (distributed tracing with Open Telemetry, Prometheus metrics)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Get Started&lt;/h2&gt; 
&lt;h3&gt;Supported Models&lt;/h3&gt; 
&lt;h4&gt;Text Embeddings&lt;/h4&gt; 
&lt;p&gt;Text Embeddings Inference currently supports Nomic, BERT, CamemBERT, XLM-RoBERTa models with absolute positions, JinaBERT model with Alibi positions and Mistral, Alibaba GTE, Qwen2 models with Rope positions, MPNet, ModernBERT, Qwen3, and Gemma3.&lt;/p&gt; 
&lt;p&gt;Below are some examples of the currently supported models:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;MTEB Rank&lt;/th&gt; 
   &lt;th&gt;Model Size&lt;/th&gt; 
   &lt;th&gt;Model Type&lt;/th&gt; 
   &lt;th&gt;Model ID&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;7.57B (Very Expensive)&lt;/td&gt; 
   &lt;td&gt;Qwen3&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/Qwen/Qwen3-Embedding-8B"&gt;Qwen/Qwen3-Embedding-8B&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;4.02B (Very Expensive)&lt;/td&gt; 
   &lt;td&gt;Qwen3&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/Qwen/Qwen3-Embedding-4B"&gt;Qwen/Qwen3-Embedding-4B&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;509M&lt;/td&gt; 
   &lt;td&gt;Qwen3&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/Qwen/Qwen3-Embedding-0.6B"&gt;Qwen/Qwen3-Embedding-0.6B&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;7.61B (Very Expensive)&lt;/td&gt; 
   &lt;td&gt;Qwen2&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/Alibaba-NLP/gte-Qwen2-7B-instruct"&gt;Alibaba-NLP/gte-Qwen2-7B-instruct&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;560M&lt;/td&gt; 
   &lt;td&gt;XLM-RoBERTa&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/intfloat/multilingual-e5-large-instruct"&gt;intfloat/multilingual-e5-large-instruct&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;308M&lt;/td&gt; 
   &lt;td&gt;Gemma3&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/google/embeddinggemma-300m"&gt;google/embeddinggemma-300m&lt;/a&gt; (gated)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;1.78B (Expensive)&lt;/td&gt; 
   &lt;td&gt;Qwen2&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/Alibaba-NLP/gte-Qwen2-1.5B-instruct"&gt;Alibaba-NLP/gte-Qwen2-1.5B-instruct&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;7.11B (Very Expensive)&lt;/td&gt; 
   &lt;td&gt;Mistral&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/Salesforce/SFR-Embedding-2_R"&gt;Salesforce/SFR-Embedding-2_R&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;35&lt;/td&gt; 
   &lt;td&gt;568M&lt;/td&gt; 
   &lt;td&gt;XLM-RoBERTa&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/Snowflake/snowflake-arctic-embed-l-v2.0"&gt;Snowflake/snowflake-arctic-embed-l-v2.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;41&lt;/td&gt; 
   &lt;td&gt;305M&lt;/td&gt; 
   &lt;td&gt;Alibaba GTE&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/Snowflake/snowflake-arctic-embed-m-v2.0"&gt;Snowflake/snowflake-arctic-embed-m-v2.0&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;52&lt;/td&gt; 
   &lt;td&gt;335M&lt;/td&gt; 
   &lt;td&gt;BERT&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/WhereIsAI/UAE-Large-V1"&gt;WhereIsAI/UAE-Large-V1&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;58&lt;/td&gt; 
   &lt;td&gt;137M&lt;/td&gt; 
   &lt;td&gt;NomicBERT&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/nomic-ai/nomic-embed-text-v1"&gt;nomic-ai/nomic-embed-text-v1&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;79&lt;/td&gt; 
   &lt;td&gt;137M&lt;/td&gt; 
   &lt;td&gt;NomicBERT&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/nomic-ai/nomic-embed-text-v1.5"&gt;nomic-ai/nomic-embed-text-v1.5&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;103&lt;/td&gt; 
   &lt;td&gt;109M&lt;/td&gt; 
   &lt;td&gt;MPNet&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/sentence-transformers/all-mpnet-base-v2"&gt;sentence-transformers/all-mpnet-base-v2&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;475M-A305M&lt;/td&gt; 
   &lt;td&gt;NomicBERT&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/nomic-ai/nomic-embed-text-v2-moe"&gt;nomic-ai/nomic-embed-text-v2-moe&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;434M&lt;/td&gt; 
   &lt;td&gt;Alibaba GTE&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/Alibaba-NLP/gte-large-en-v1.5"&gt;Alibaba-NLP/gte-large-en-v1.5&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;396M&lt;/td&gt; 
   &lt;td&gt;ModernBERT&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/answerdotai/ModernBERT-large"&gt;answerdotai/ModernBERT-large&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;137M&lt;/td&gt; 
   &lt;td&gt;JinaBERT&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/jinaai/jina-embeddings-v2-base-en"&gt;jinaai/jina-embeddings-v2-base-en&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
   &lt;td&gt;137M&lt;/td&gt; 
   &lt;td&gt;JinaBERT&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://hf.co/jinaai/jina-embeddings-v2-base-code"&gt;jinaai/jina-embeddings-v2-base-code&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;To explore the list of best performing text embeddings models, visit the &lt;a href="https://huggingface.co/spaces/mteb/leaderboard"&gt;Massive Text Embedding Benchmark (MTEB) Leaderboard&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Sequence Classification and Re-Ranking&lt;/h4&gt; 
&lt;p&gt;Text Embeddings Inference currently supports CamemBERT, and XLM-RoBERTa Sequence Classification models with absolute positions.&lt;/p&gt; 
&lt;p&gt;Below are some examples of the currently supported models:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Task&lt;/th&gt; 
   &lt;th&gt;Model Type&lt;/th&gt; 
   &lt;th&gt;Model ID&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Re-Ranking&lt;/td&gt; 
   &lt;td&gt;XLM-RoBERTa&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/BAAI/bge-reranker-large"&gt;BAAI/bge-reranker-large&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Re-Ranking&lt;/td&gt; 
   &lt;td&gt;XLM-RoBERTa&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/BAAI/bge-reranker-base"&gt;BAAI/bge-reranker-base&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Re-Ranking&lt;/td&gt; 
   &lt;td&gt;GTE&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Alibaba-NLP/gte-multilingual-reranker-base"&gt;Alibaba-NLP/gte-multilingual-reranker-base&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Re-Ranking&lt;/td&gt; 
   &lt;td&gt;ModernBert&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/Alibaba-NLP/gte-reranker-modernbert-base"&gt;Alibaba-NLP/gte-reranker-modernbert-base&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Sentiment Analysis&lt;/td&gt; 
   &lt;td&gt;RoBERTa&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/SamLowe/roberta-base-go_emotions"&gt;SamLowe/roberta-base-go_emotions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model=Qwen/Qwen3-Embedding-0.6B
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.8 --model-id $model
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then you can make requests like&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl 127.0.0.1:8080/embed \
    -X POST \
    -d '{"inputs":"What is Deep Learning?"}' \
    -H 'Content-Type: application/json'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; To use GPUs, you need to install the &lt;a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"&gt;NVIDIA Container Toolkit&lt;/a&gt;. NVIDIA drivers on your machine need to be compatible with CUDA version 12.2 or higher.&lt;/p&gt; 
&lt;p&gt;To see all options to serve your models:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ text-embeddings-router --help
Text Embedding Webserver

Usage: text-embeddings-router [OPTIONS]

Options:
      --model-id &amp;lt;MODEL_ID&amp;gt;
          The name of the model to load. Can be a MODEL_ID as listed on &amp;lt;https://hf.co/models&amp;gt; like `BAAI/bge-large-en-v1.5`. Or it can be a local directory containing the necessary files as saved by `save_pretrained(...)` methods of transformers

          [env: MODEL_ID=]
          [default: BAAI/bge-large-en-v1.5]

      --revision &amp;lt;REVISION&amp;gt;
          The actual revision of the model if you're referring to a model on the hub. You can use a specific commit id or a branch like `refs/pr/2`

          [env: REVISION=]

      --tokenization-workers &amp;lt;TOKENIZATION_WORKERS&amp;gt;
          Optionally control the number of tokenizer workers used for payload tokenization, validation and truncation. Default to the number of CPU cores on the machine

          [env: TOKENIZATION_WORKERS=]

      --dtype &amp;lt;DTYPE&amp;gt;
          The dtype to be forced upon the model

          [env: DTYPE=]
          [possible values: float16, float32]

      --pooling &amp;lt;POOLING&amp;gt;
          Optionally control the pooling method for embedding models.

          If `pooling` is not set, the pooling configuration will be parsed from the model `1_Pooling/config.json` configuration.

          If `pooling` is set, it will override the model pooling configuration

          [env: POOLING=]

          Possible values:
          - cls:        Select the CLS token as embedding
          - mean:       Apply Mean pooling to the model embeddings
          - splade:     Apply SPLADE (Sparse Lexical and Expansion) to the model embeddings. This option is only available if the loaded model is a `ForMaskedLM` Transformer model
          - last-token: Select the last token as embedding

      --max-concurrent-requests &amp;lt;MAX_CONCURRENT_REQUESTS&amp;gt;
          The maximum amount of concurrent requests for this particular deployment. Having a low limit will refuse clients requests instead of having them wait for too long and is usually good to handle backpressure correctly

          [env: MAX_CONCURRENT_REQUESTS=]
          [default: 512]

      --max-batch-tokens &amp;lt;MAX_BATCH_TOKENS&amp;gt;
          **IMPORTANT** This is one critical control to allow maximum usage of the available hardware.

          This represents the total amount of potential tokens within a batch.

          For `max_batch_tokens=1000`, you could fit `10` queries of `total_tokens=100` or a single query of `1000` tokens.

          Overall this number should be the largest possible until the model is compute bound. Since the actual memory overhead depends on the model implementation, text-embeddings-inference cannot infer this number automatically.

          [env: MAX_BATCH_TOKENS=]
          [default: 16384]

      --max-batch-requests &amp;lt;MAX_BATCH_REQUESTS&amp;gt;
          Optionally control the maximum number of individual requests in a batch

          [env: MAX_BATCH_REQUESTS=]

      --max-client-batch-size &amp;lt;MAX_CLIENT_BATCH_SIZE&amp;gt;
          Control the maximum number of inputs that a client can send in a single request

          [env: MAX_CLIENT_BATCH_SIZE=]
          [default: 32]

      --auto-truncate
          Automatically truncate inputs that are longer than the maximum supported size

          Unused for gRPC servers

          [env: AUTO_TRUNCATE=]

      --default-prompt-name &amp;lt;DEFAULT_PROMPT_NAME&amp;gt;
          The name of the prompt that should be used by default for encoding. If not set, no prompt will be applied.

          Must be a key in the `sentence-transformers` configuration `prompts` dictionary.

          For example if ``default_prompt_name`` is "query" and the ``prompts`` is {"query": "query: ", ...}, then the sentence "What is the capital of France?" will be encoded as "query: What is the capital of France?" because the prompt text will be prepended before any text to encode.

          The argument '--default-prompt-name &amp;lt;DEFAULT_PROMPT_NAME&amp;gt;' cannot be used with '--default-prompt &amp;lt;DEFAULT_PROMPT&amp;gt;`

          [env: DEFAULT_PROMPT_NAME=]

      --default-prompt &amp;lt;DEFAULT_PROMPT&amp;gt;
          The prompt that should be used by default for encoding. If not set, no prompt will be applied.

          For example if ``default_prompt`` is "query: " then the sentence "What is the capital of France?" will be encoded as "query: What is the capital of France?" because the prompt text will be prepended before any text to encode.

          The argument '--default-prompt &amp;lt;DEFAULT_PROMPT&amp;gt;' cannot be used with '--default-prompt-name &amp;lt;DEFAULT_PROMPT_NAME&amp;gt;`

          [env: DEFAULT_PROMPT=]

      --dense-path &amp;lt;DENSE_PATH&amp;gt;
          Optionally, define the path to the Dense module required for some embedding models.

          Some embedding models require an extra `Dense` module which contains a single Linear layer and an activation function. By default, those `Dense` modules are stored under the `2_Dense` directory, but there might be cases where different `Dense` modules are provided, to convert the pooled embeddings into different dimensions, available as `2_Dense_&amp;lt;dims&amp;gt;` e.g. https://huggingface.co/NovaSearch/stella_en_400M_v5.

          Note that this argument is optional, only required to be set if the path to the `Dense` module is other than `2_Dense`. And it also applies when leveraging the `candle` backend.

          [env: DENSE_PATH=]
          [default: 2_Dense]

      --hf-token &amp;lt;HF_TOKEN&amp;gt;
          Your Hugging Face Hub token

          [env: HF_TOKEN=]

      --hostname &amp;lt;HOSTNAME&amp;gt;
          The IP address to listen on

          [env: HOSTNAME=]
          [default: 0.0.0.0]

      -p, --port &amp;lt;PORT&amp;gt;
          The port to listen on

          [env: PORT=]
          [default: 3000]

      --uds-path &amp;lt;UDS_PATH&amp;gt;
          The name of the unix socket some text-embeddings-inference backends will use as they communicate internally with gRPC

          [env: UDS_PATH=]
          [default: /tmp/text-embeddings-inference-server]

      --huggingface-hub-cache &amp;lt;HUGGINGFACE_HUB_CACHE&amp;gt;
          The location of the huggingface hub cache. Used to override the location if you want to provide a mounted disk for instance

          [env: HUGGINGFACE_HUB_CACHE=]

      --payload-limit &amp;lt;PAYLOAD_LIMIT&amp;gt;
          Payload size limit in bytes

          Default is 2MB

          [env: PAYLOAD_LIMIT=]
          [default: 2000000]

      --api-key &amp;lt;API_KEY&amp;gt;
          Set an api key for request authorization.

          By default the server responds to every request. With an api key set, the requests must have the Authorization header set with the api key as Bearer token.

          [env: API_KEY=]

      --json-output
          Outputs the logs in JSON format (useful for telemetry)

          [env: JSON_OUTPUT=]

      --disable-spans
          [env: DISABLE_SPANS=]

      --otlp-endpoint &amp;lt;OTLP_ENDPOINT&amp;gt;
          The grpc endpoint for opentelemetry. Telemetry is sent to this endpoint as OTLP over gRPC. e.g. `http://localhost:4317`

          [env: OTLP_ENDPOINT=]

      --otlp-service-name &amp;lt;OTLP_SERVICE_NAME&amp;gt;
          The service name for opentelemetry. e.g. `text-embeddings-inference.server`

          [env: OTLP_SERVICE_NAME=]
          [default: text-embeddings-inference.server]

      --prometheus-port &amp;lt;PROMETHEUS_PORT&amp;gt;
          The Prometheus port to listen on

          [env: PROMETHEUS_PORT=]
          [default: 9000]

      --cors-allow-origin &amp;lt;CORS_ALLOW_ORIGIN&amp;gt;
          Unused for gRPC servers

          [env: CORS_ALLOW_ORIGIN=]

  -h, --help
          Print help (see a summary with '-h')

  -V, --version
          Print version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Images&lt;/h3&gt; 
&lt;p&gt;Text Embeddings Inference ships with multiple Docker images that you can use to target a specific backend:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Architecture&lt;/th&gt; 
   &lt;th&gt;Image&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
   &lt;td&gt;ghcr.io/huggingface/text-embeddings-inference:cpu-1.8&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volta&lt;/td&gt; 
   &lt;td&gt;NOT SUPPORTED&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Turing (T4, RTX 2000 series, ...)&lt;/td&gt; 
   &lt;td&gt;ghcr.io/huggingface/text-embeddings-inference:turing-1.8 (experimental)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ampere 80 (A100, A30)&lt;/td&gt; 
   &lt;td&gt;ghcr.io/huggingface/text-embeddings-inference:1.8&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ampere 86 (A10, A40, ...)&lt;/td&gt; 
   &lt;td&gt;ghcr.io/huggingface/text-embeddings-inference:86-1.8&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ada Lovelace (RTX 4000 series, ...)&lt;/td&gt; 
   &lt;td&gt;ghcr.io/huggingface/text-embeddings-inference:89-1.8&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hopper (H100)&lt;/td&gt; 
   &lt;td&gt;ghcr.io/huggingface/text-embeddings-inference:hopper-1.8 (experimental)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: Flash Attention is turned off by default for the Turing image as it suffers from precision issues. You can turn Flash Attention v1 ON by using the &lt;code&gt;USE_FLASH_ATTENTION=True&lt;/code&gt; environment variable.&lt;/p&gt; 
&lt;h3&gt;API documentation&lt;/h3&gt; 
&lt;p&gt;You can consult the OpenAPI documentation of the &lt;code&gt;text-embeddings-inference&lt;/code&gt; REST API using the &lt;code&gt;/docs&lt;/code&gt; route. The Swagger UI is also available at: &lt;a href="https://huggingface.github.io/text-embeddings-inference"&gt;https://huggingface.github.io/text-embeddings-inference&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Using a private or gated model&lt;/h3&gt; 
&lt;p&gt;You have the option to utilize the &lt;code&gt;HF_TOKEN&lt;/code&gt; environment variable for configuring the token employed by &lt;code&gt;text-embeddings-inference&lt;/code&gt;. This allows you to gain access to protected resources.&lt;/p&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Go to &lt;a href="https://huggingface.co/settings/tokens"&gt;https://huggingface.co/settings/tokens&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Copy your CLI READ token&lt;/li&gt; 
 &lt;li&gt;Export &lt;code&gt;HF_TOKEN=&amp;lt;your CLI READ token&amp;gt;&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;or with Docker:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model=&amp;lt;your private model&amp;gt;
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run
token=&amp;lt;your CLI READ token&amp;gt;

docker run --gpus all -e HF_TOKEN=$token -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.8 --model-id $model
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Air gapped deployment&lt;/h3&gt; 
&lt;p&gt;To deploy Text Embeddings Inference in an air-gapped environment, first download the weights and then mount them inside the container using a volume.&lt;/p&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# (Optional) create a `models` directory
mkdir models
cd models

# Make sure you have git-lfs installed (https://git-lfs.com)
git lfs install
git clone https://huggingface.co/Qwen/Qwen3-Embedding-0.6B

# Set the models directory as the volume path
volume=$PWD

# Mount the models directory inside the container with a volume and set the model ID
docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.8 --model-id /data/Qwen3-Embedding-0.6B
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Re-rankers models&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;text-embeddings-inference&lt;/code&gt; v0.4.0 added support for CamemBERT, RoBERTa, XLM-RoBERTa, and GTE Sequence Classification models. Re-rankers models are Sequence Classification cross-encoders models with a single class that scores the similarity between a query and a text.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83"&gt;this blogpost&lt;/a&gt; by the LlamaIndex team to understand how you can use re-rankers models in your RAG pipeline to improve downstream performance.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model=BAAI/bge-reranker-large
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.8 --model-id $model
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;And then you can rank the similarity between a query and a list of texts with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl 127.0.0.1:8080/rerank \
    -X POST \
    -d '{"query": "What is Deep Learning?", "texts": ["Deep Learning is not...", "Deep learning is..."]}' \
    -H 'Content-Type: application/json'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Sequence Classification models&lt;/h3&gt; 
&lt;p&gt;You can also use classic Sequence Classification models like &lt;code&gt;SamLowe/roberta-base-go_emotions&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model=SamLowe/roberta-base-go_emotions
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.8 --model-id $model
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once you have deployed the model you can use the &lt;code&gt;predict&lt;/code&gt; endpoint to get the emotions most associated with an input:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl 127.0.0.1:8080/predict \
    -X POST \
    -d '{"inputs":"I like you."}' \
    -H 'Content-Type: application/json'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using SPLADE pooling&lt;/h3&gt; 
&lt;p&gt;You can choose to activate SPLADE pooling for Bert and Distilbert MaskedLM architectures:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model=naver/efficient-splade-VI-BT-large-query
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.8 --model-id $model --pooling splade
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once you have deployed the model you can use the &lt;code&gt;/embed_sparse&lt;/code&gt; endpoint to get the sparse embedding:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl 127.0.0.1:8080/embed_sparse \
    -X POST \
    -d '{"inputs":"I like you."}' \
    -H 'Content-Type: application/json'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Distributed Tracing&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;text-embeddings-inference&lt;/code&gt; is instrumented with distributed tracing using OpenTelemetry. You can use this feature by setting the address to an OTLP collector with the &lt;code&gt;--otlp-endpoint&lt;/code&gt; argument.&lt;/p&gt; 
&lt;h3&gt;gRPC&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;text-embeddings-inference&lt;/code&gt; offers a gRPC API as an alternative to the default HTTP API for high performance deployments. The API protobuf definition can be found &lt;a href="https://github.com/huggingface/text-embeddings-inference/raw/main/proto/tei.proto"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can use the gRPC API by adding the &lt;code&gt;-grpc&lt;/code&gt; tag to any TEI Docker image. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model=Qwen/Qwen3-Embedding-0.6B
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.8-grpc --model-id $model
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;grpcurl -d '{"inputs": "What is Deep Learning"}' -plaintext 0.0.0.0:8080 tei.v1.Embed/Embed
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Local install&lt;/h2&gt; 
&lt;h3&gt;CPU&lt;/h3&gt; 
&lt;p&gt;You can also opt to install &lt;code&gt;text-embeddings-inference&lt;/code&gt; locally.&lt;/p&gt; 
&lt;p&gt;First &lt;a href="https://rustup.rs/"&gt;install Rust&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# On x86 with ONNX backend (recommended)
cargo install --path router -F ort
# On x86 with Intel backend
cargo install --path router -F mkl
# On M1 or M2
cargo install --path router -F metal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can now launch Text Embeddings Inference on CPU with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model=Qwen/Qwen3-Embedding-0.6B

text-embeddings-router --model-id $model --port 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; on some machines, you may also need the OpenSSL libraries and gcc. On Linux machines, run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sudo apt-get install libssl-dev gcc -y
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;CUDA&lt;/h3&gt; 
&lt;p&gt;GPUs with CUDA compute capabilities &amp;lt; 7.5 are not supported (V100, Titan V, GTX 1000 series, ...).&lt;/p&gt; 
&lt;p&gt;Make sure you have CUDA and the nvidia drivers installed. NVIDIA drivers on your device need to be compatible with CUDA version 12.2 or higher. You also need to add the nvidia binaries to your path:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;export PATH=$PATH:/usr/local/cuda/bin
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# This can take a while as we need to compile a lot of CUDA kernels

# On Turing GPUs (T4, RTX 2000 series ... )
cargo install --path router -F candle-cuda-turing

# On Ampere and Hopper
cargo install --path router -F candle-cuda
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can now launch Text Embeddings Inference on GPU with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;model=Qwen/Qwen3-Embedding-0.6B

text-embeddings-router --model-id $model --port 8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker build&lt;/h2&gt; 
&lt;p&gt;You can build the CPU container with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;docker build .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build the CUDA containers, you need to know the compute cap of the GPU you will be using at runtime.&lt;/p&gt; 
&lt;p&gt;Then you can build the container with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# Get submodule dependencies
git submodule update --init

# Example for Turing (T4, RTX 2000 series, ...)
runtime_compute_cap=75

# Example for A100
runtime_compute_cap=80

# Example for A10
runtime_compute_cap=86

# Example for Ada Lovelace (RTX 4000 series, ...)
runtime_compute_cap=89

# Example for H100
runtime_compute_cap=90

docker build . -f Dockerfile-cuda --build-arg CUDA_COMPUTE_CAP=$runtime_compute_cap
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Apple M1/M2 arm64 architectures&lt;/h3&gt; 
&lt;h4&gt;DISCLAIMER&lt;/h4&gt; 
&lt;p&gt;As explained here &lt;a href="https://github.com/pytorch/pytorch/issues/81224"&gt;MPS-Ready, ARM64 Docker Image&lt;/a&gt;, Metal / MPS is not supported via Docker. As such inference will be CPU bound and most likely pretty slow when using this docker image on an M1/M2 ARM CPU.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker build . -f Dockerfile --platform=linux/arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/learn/cookbook/automatic_embedding_tei_inference_endpoints"&gt;Set up an Inference Endpoint with TEI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/plaggy/rag-containers"&gt;RAG containers with TEI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>biomejs/biome</title>
      <link>https://github.com/biomejs/biome</link>
      <description>&lt;p&gt;A toolchain for web projects, aimed to provide functionalities to maintain them. Biome offers formatter and linter, usable via CLI and LSP.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-dark-transparent.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-light-transparent.svg" /&gt; 
  &lt;img alt="Shows the banner of Biome, with its logo and the phrase 'Biome - Toolchain of the web'." src="https://raw.githubusercontent.com/biomejs/resources/main/svg/slogan-light-transparent.svg?sanitize=true" width="700" /&gt; 
 &lt;/picture&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://github.com/biomejs/biome/actions/workflows/main.yml"&gt;&lt;img src="https://github.com/biomejs/biome/actions/workflows/main.yml/badge.svg?sanitize=true" alt="CI on main" /&gt;&lt;/a&gt; &lt;a href="https://biomejs.dev/chat"&gt;&lt;img src="https://badgen.net/discord/online-members/BypW39g6Yc?icon=discord&amp;amp;label=discord&amp;amp;color=60a5fa" alt="Discord chat" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/@biomejs/biome/v/latest"&gt;&lt;img src="https://badgen.net/npm/v/@biomejs/biome?icon=npm&amp;amp;color=60a5fa&amp;amp;label=%40biomejs%2Fbiome" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://marketplace.visualstudio.com/items?itemName=biomejs.biome"&gt;&lt;img src="https://img.shields.io/visual-studio-marketplace/v/biomejs.biome?label=Visual%20Studio%20Marketplace&amp;amp;labelColor=374151&amp;amp;color=60a5fa" alt="VSCode version" /&gt;&lt;/a&gt; &lt;a href="https://open-vsx.org/extension/biomejs/biome"&gt;&lt;img src="https://img.shields.io/visual-studio-marketplace/v/biomejs.biome?label=Open%20VSX%20Registry&amp;amp;logo=data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPHN2ZyB2aWV3Qm94PSI0LjYgNSA5Ni4yIDEyMi43IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogIDxwYXRoIGQ9Ik0zMCA0NC4yTDUyLjYgNUg3LjN6TTQuNiA4OC41aDQ1LjNMMjcuMiA0OS40em01MSAwbDIyLjYgMzkuMiAyMi42LTM5LjJ6IiBmaWxsPSIjYzE2MGVmIi8+CiAgPHBhdGggZD0iTTUyLjYgNUwzMCA0NC4yaDQ1LjJ6TTI3LjIgNDkuNGwyMi43IDM5LjEgMjIuNi0zOS4xem01MSAwTDU1LjYgODguNWg0NS4yeiIgZmlsbD0iI2E2MGVlNSIvPgo8L3N2Zz4=&amp;amp;labelColor=374151&amp;amp;color=60a5fa" alt="Open VSX version" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;!-- Insert new entries lexicographically by language code.
     For example given below is the same order as these files appear on page:
     https://github.com/biomejs/biome/tree/main/packages/@biomejs/biome --&gt; 
 &lt;p&gt;&lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.hi.md"&gt;हिन्दी&lt;/a&gt; | English | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.es.md"&gt;Español&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.fr.md"&gt;Français&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.zh-TW.md"&gt;繁體中文&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.zh-CN.md"&gt;简体中文&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.ja.md"&gt;日本語&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.pl.md"&gt;Polski&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.pt-BR.md"&gt;Português do Brasil&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.kr.md"&gt;한국어&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.ru.md"&gt;Русский&lt;/a&gt; | &lt;a href="https://github.com/biomejs/biome/raw/main/packages/%40biomejs/biome/README.uk.md"&gt;Українська&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; is a performant toolchain for web projects, it aims to provide developer tools to maintain the health of said projects.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome is a &lt;a href="https://raw.githubusercontent.com/biomejs/biome/main/benchmark#formatting"&gt;fast formatter&lt;/a&gt;&lt;/strong&gt; for &lt;em&gt;JavaScript&lt;/em&gt;, &lt;em&gt;TypeScript&lt;/em&gt;, &lt;em&gt;JSX&lt;/em&gt;, &lt;em&gt;JSON&lt;/em&gt;, &lt;em&gt;CSS&lt;/em&gt; and &lt;em&gt;GraphQL&lt;/em&gt; that scores &lt;strong&gt;&lt;a href="https://console.algora.io/challenges/prettier"&gt;97% compatibility with &lt;em&gt;Prettier&lt;/em&gt;&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome is a &lt;a href="https://github.com/biomejs/biome/tree/main/benchmark#linting"&gt;performant linter&lt;/a&gt;&lt;/strong&gt; for &lt;em&gt;JavaScript&lt;/em&gt;, &lt;em&gt;TypeScript&lt;/em&gt;, &lt;em&gt;JSX&lt;/em&gt;, &lt;em&gt;JSON&lt;/em&gt;, &lt;em&gt;CSS&lt;/em&gt;, and &lt;em&gt;GraphQL&lt;/em&gt; that features &lt;strong&gt;&lt;a href="https://biomejs.dev/linter/javascript/rules/"&gt;more than 340 rules&lt;/a&gt;&lt;/strong&gt; from ESLint, typescript-eslint, and &lt;a href="https://github.com/biomejs/biome/discussions/3"&gt;other sources&lt;/a&gt;. It &lt;strong&gt;outputs detailed and contextualized diagnostics&lt;/strong&gt; that help you to improve your code and become a better programmer!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; is designed from the start to be used &lt;a href="https://biomejs.dev/guides/editors/first-party-extensions/"&gt;interactively within an editor&lt;/a&gt;. It can format and lint malformed code as you are writing it.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;npm install --save-dev --save-exact @biomejs/biome
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;# format files
npx @biomejs/biome format --write

# lint files and apply the safe fixes
npx @biomejs/biome lint --write

# run format, lint, etc. and apply the safe fixes
npx @biomejs/biome check --write

# check all files against format, lint, etc. in CI environments
npx @biomejs/biome ci
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to give Biome a run without installing it, use the &lt;a href="https://biomejs.dev/playground/"&gt;online playground&lt;/a&gt;, compiled to WebAssembly.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Check out our &lt;a href="https://biomejs.dev/"&gt;homepage&lt;/a&gt; to learn more about Biome, or directly head to the &lt;a href="https://biomejs.dev/guides/getting-started/"&gt;Getting Started guide&lt;/a&gt; to start using Biome.&lt;/p&gt; 
&lt;h2&gt;More about Biome&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; has sane defaults and it doesn't require configuration.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; aims to support &lt;a href="https://biomejs.dev/internals/language-support/"&gt;all main languages&lt;/a&gt; of modern web development.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; &lt;a href="https://biomejs.dev/guides/manual-installation/"&gt;doesn't require Node.js&lt;/a&gt; to function.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; has first-class LSP support, with a sophisticated parser that represents the source text in full fidelity and top-notch error recovery.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; wants to offer a high-quality &lt;em&gt;Developer Experience&lt;/em&gt;, with descriptive diagnostics and great performance.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; unifies functionalities that have previously been separate tools. Building upon a shared base allows us to provide a cohesive experience for processing code, displaying errors, parallelize work, caching, and configuration.&lt;/p&gt; 
&lt;p&gt;Read more about our &lt;a href="https://biomejs.dev/internals/philosophy/"&gt;project philosophy&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Biome&lt;/strong&gt; is &lt;a href="https://github.com/biomejs/biome/tree/main/LICENSE-MIT"&gt;MIT licensed&lt;/a&gt; or &lt;a href="https://github.com/biomejs/biome/tree/main/LICENSE-APACHE"&gt;Apache 2.0 licensed&lt;/a&gt; and moderated under the &lt;a href="https://github.com/biomejs/biome/tree/main/CODE_OF_CONDUCT.md"&gt;Contributor Covenant Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Funding&lt;/h2&gt; 
&lt;p&gt;You can fund the project in different ways&lt;/p&gt; 
&lt;h3&gt;Project sponsorship and funding&lt;/h3&gt; 
&lt;p&gt;You can sponsor or fund the project via &lt;a href="https://opencollective.com/biome"&gt;Open collective&lt;/a&gt; or &lt;a href="https://github.com/sponsors/biomejs"&gt;GitHub sponsors&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Biome offers a simple sponsorship program that allows companies to get visibility and recognition among various developers.&lt;/p&gt; 
&lt;p&gt;Biome offers &lt;a href="https://biomejs.dev/enterprise"&gt;enterprise support&lt;/a&gt;, where Core Contributors can be employed to work on company-focused projects.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://depot.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-light@3x.png" /&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-dark@3x.png" /&gt; 
      &lt;img src="https://depot.dev/assets/brand/1693758816/depot-logo-horizontal-on-light@3x.png" width="400" alt="Depot logo" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://vercel.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt; 
     &lt;picture&gt; 
      &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/biomejs/resources/refs/heads/main/sponsors/vercel-dark.png" /&gt; 
      &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/biomejs/resources/refs/heads/main/sponsors/vercel-light.png" /&gt; 
      &lt;img src="https://raw.githubusercontent.com/biomejs/resources/refs/heads/main/sponsors/vercel-dark.png" width="400" alt="Vercel" /&gt; 
     &lt;/picture&gt; &lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Silver Sponsors&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://l2beat.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://images.opencollective.com/l2beat/c2b2a27/logo/256.png" height="100" alt="L2BEAT logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://www.phoenixlabs.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://images.opencollective.com/phoenix-labs/2824ed4/logo/100.png?height=100" height="100" alt="Phoenix Labs logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://lokalise.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/14294501?s=200&amp;amp;v=4" height="100" alt="Lokalise logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Bronze Sponsors&lt;/h3&gt; 
&lt;table&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://nanabit.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://images.opencollective.com/nanabit/d15fd98/logo/256.png?height=80" width="80" alt="Nanabit logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://vital.io/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/25357309?s=200" width="80" alt="Vital logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://coderabbit.ai/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/132028505?s=200&amp;amp;v=4" width="80" alt="CodeRabbit logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://forge42.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/161314831?s=200&amp;amp;v=4" width="80" alt="Forge42 logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="http://rstudio.org/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/513560?s=200&amp;amp;v=4" width="80" alt="RStudio logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://pennylane.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/57875210?s=200&amp;amp;v=4" width="80" alt="Pennylane logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://jetbrains.com/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.png" width="100" alt="JetBrains logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://www.egstock.co.jp/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://images.opencollective.com/egstock/b18c836/logo/256.png?height=256" width="80" alt="EGSTOCK, Inc. logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
   &lt;td align="center" valign="middle"&gt; &lt;a href="https://www.convex.dev/?utm_source=biome&amp;amp;utm_medium=readme" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/81530787?s=200&amp;amp;v=4" width="80" alt="Convex logo" /&gt;&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt;</description>
    </item>
    
    <item>
      <title>servo/servo</title>
      <link>https://github.com/servo/servo</link>
      <description>&lt;p&gt;Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;The Servo Parallel Browser Engine Project&lt;/h1&gt; 
&lt;p&gt;Servo is a prototype web browser engine written in the &lt;a href="https://github.com/rust-lang/rust"&gt;Rust&lt;/a&gt; language. It is currently developed on 64-bit macOS, 64-bit Linux, 64-bit Windows, 64-bit OpenHarmony, and Android.&lt;/p&gt; 
&lt;p&gt;Servo welcomes contribution from everyone. Check out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The &lt;a href="https://book.servo.org"&gt;Servo Book&lt;/a&gt; for documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://servo.org/"&gt;servo.org&lt;/a&gt; for news and guides&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Coordination of Servo development happens:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Here in the Github Issues&lt;/li&gt; 
 &lt;li&gt;On the &lt;a href="https://servo.zulipchat.com/"&gt;Servo Zulip&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;In video calls advertised in the &lt;a href="https://github.com/servo/project/issues"&gt;Servo Project&lt;/a&gt; repo.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;For more detailed build instructions, see the Servo book under &lt;a href="https://book.servo.org/hacking/setting-up-your-environment.html"&gt;Setting up your environment&lt;/a&gt;, &lt;a href="https://book.servo.org/hacking/building-servo.html"&gt;Building Servo&lt;/a&gt;, &lt;a href="https://book.servo.org/hacking/building-for-android.html"&gt;Building for Android&lt;/a&gt; and &lt;a href="https://book.servo.org/hacking/building-for-openharmony.html"&gt;Building for OpenHarmony&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;macOS&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download and install &lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt; and &lt;a href="https://brew.sh/"&gt;&lt;code&gt;brew&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;uv&lt;/code&gt;: &lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;rustup&lt;/code&gt;: &lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Restart your shell to make sure &lt;code&gt;cargo&lt;/code&gt; is available&lt;/li&gt; 
 &lt;li&gt;Install the other dependencies: &lt;code&gt;./mach bootstrap&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Build servoshell: &lt;code&gt;./mach build&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Linux&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;curl&lt;/code&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Arch: &lt;code&gt;sudo pacman -S --needed curl&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Debian, Ubuntu: &lt;code&gt;sudo apt install curl&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Fedora: &lt;code&gt;sudo dnf install curl&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Gentoo: &lt;code&gt;sudo emerge net-misc/curl&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;uv&lt;/code&gt;: &lt;code&gt;curl -LsSf https://astral.sh/uv/install.sh | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install &lt;code&gt;rustup&lt;/code&gt;: &lt;code&gt;curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Restart your shell to make sure &lt;code&gt;cargo&lt;/code&gt; is available&lt;/li&gt; 
 &lt;li&gt;Install the other dependencies: &lt;code&gt;./mach bootstrap&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Build servoshell: &lt;code&gt;./mach build&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Windows&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download &lt;a href="https://docs.astral.sh/uv/getting-started/installation/#standalone-installer"&gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://chocolatey.org/install#individual"&gt;&lt;code&gt;choco&lt;/code&gt;&lt;/a&gt;, and &lt;a href="https://win.rustup.rs/"&gt;&lt;code&gt;rustup&lt;/code&gt;&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Be sure to select &lt;em&gt;Quick install via the Visual Studio Community installer&lt;/em&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;In the Visual Studio Installer, ensure the following components are installed: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Windows 10/11 SDK (anything &amp;gt;= 10.0.19041.0)&lt;/strong&gt; (&lt;code&gt;Microsoft.VisualStudio.Component.Windows{10, 11}SDK.{&amp;gt;=19041}&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)&lt;/strong&gt; (&lt;code&gt;Microsoft.VisualStudio.Component.VC.Tools.x86.x64&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;C++ ATL for latest v143 build tools (x86 &amp;amp; x64)&lt;/strong&gt; (&lt;code&gt;Microsoft.VisualStudio.Component.VC.ATL&lt;/code&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Restart your shell to make sure &lt;code&gt;cargo&lt;/code&gt; is available&lt;/li&gt; 
 &lt;li&gt;Install the other dependencies: &lt;code&gt;.\mach bootstrap&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Build servoshell: &lt;code&gt;.\mach build&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Android&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ensure that the following environment variables are set: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;ANDROID_SDK_ROOT&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;ANDROID_NDK_ROOT&lt;/code&gt;: &lt;code&gt;$ANDROID_SDK_ROOT/ndk/28.2.13676358/&lt;/code&gt; &lt;code&gt;ANDROID_SDK_ROOT&lt;/code&gt; can be any directory (such as &lt;code&gt;~/android-sdk&lt;/code&gt;). All of the Android build dependencies will be installed there.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Install the latest version of the &lt;a href="https://developer.android.com/studio#command-tools"&gt;Android command-line tools&lt;/a&gt; to &lt;code&gt;$ANDROID_SDK_ROOT/cmdline-tools/latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Run the following command to install the necessary components: &lt;pre&gt;&lt;code class="language-shell"&gt;sudo $ANDROID_SDK_ROOT/cmdline-tools/latest/bin/sdkmanager --install \
 "build-tools;34.0.0" \
 "emulator" \
 "ndk;28.2.13676358" \
 "platform-tools" \
 "platforms;android-33" \
 "system-images;android-33;google_apis;x86_64"
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Follow the instructions above for the platform you are building on&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;OpenHarmony&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Follow the instructions above for the platform you are building on to prepare the environment.&lt;/li&gt; 
 &lt;li&gt;Depending on the target distribution (e.g. &lt;code&gt;HarmonyOS NEXT&lt;/code&gt; vs pure &lt;code&gt;OpenHarmony&lt;/code&gt;) the build configuration will differ slightly.&lt;/li&gt; 
 &lt;li&gt;Ensure that the following environment variables are set 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;DEVECO_SDK_HOME&lt;/code&gt; (Required when targeting &lt;code&gt;HarmonyOS NEXT&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OHOS_BASE_SDK_HOME&lt;/code&gt; (Required when targeting &lt;code&gt;OpenHarmony&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OHOS_SDK_NATIVE&lt;/code&gt; (e.g. &lt;code&gt;${DEVECO_SDK_HOME}/default/openharmony/native&lt;/code&gt; or &lt;code&gt;${OHOS_BASE_SDK_HOME}/${API_VERSION}/native&lt;/code&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;SERVO_OHOS_SIGNING_CONFIG&lt;/code&gt;: Path to json file containing a valid signing configuration for the demo app.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Review the detailed instructions at &lt;a href="https://book.servo.org/hacking/building-for-openharmony.html"&gt;Building for OpenHarmony&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;The target distribution can be modified by passing &lt;code&gt;--flavor=&amp;lt;default|harmonyos&amp;gt;&lt;/code&gt; to &lt;code&gt;mach &amp;lt;build|package|install&amp;gt;&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
  </channel>
</rss>