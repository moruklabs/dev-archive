<rss version="2.0">
  <channel>
    <title>GitHub Go Daily Trending</title>
    <description>Daily Trending of Go in GitHub</description>
    <pubDate>Fri, 24 Oct 2025 01:36:12 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>dstotijn/hetty</title>
      <link>https://github.com/dstotijn/hetty</link>
      <description>&lt;p&gt;An HTTP toolkit for security research.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://user-images.githubusercontent.com/983924/156430531-6193e187-7400-436b-81c6-f86862783ea5.svg#gh-light-mode-only" width="240" /&gt; 
&lt;img src="https://user-images.githubusercontent.com/983924/156430660-9d5bd555-dcfd-47e2-ba70-54294c20c1b4.svg#gh-dark-mode-only" width="240" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/dstotijn/hetty/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dstotijn/hetty?color=25ae8f" alt="Latest GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dstotijn/hetty/actions/workflows/build-test.yml"&gt;&lt;img src="https://img.shields.io/endpoint.svg?url=https%3A%2F%2Factions-badge.atrox.dev%2Fdstotijn%2Fhetty%2Fbadge%3Fref%3Dmain&amp;amp;label=build&amp;amp;color=24ae8f" alt="Build Status" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/dstotijn/hetty/total?color=25ae8f" alt="GitHub download count" /&gt; &lt;a href="https://github.com/dstotijn/hetty/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/dstotijn/hetty?color=25ae8f" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://hetty.xyz/"&gt;&lt;img src="https://img.shields.io/badge/hetty-docs-25ae8f" alt="Documentation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Hetty&lt;/strong&gt; is an HTTP toolkit for security research. It aims to become an open source alternative to commercial software like Burp Suite Pro, with powerful features tailored to the needs of the infosec and bug bounty community.&lt;/p&gt; 
&lt;img src="https://hetty.xyz/img/hero.png" width="907" alt="Hetty proxy logs (screenshot)" /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Machine-in-the-middle (MITM) HTTP proxy, with logs and advanced search&lt;/li&gt; 
 &lt;li&gt;HTTP client for manually creating/editing requests, and replay proxied requests&lt;/li&gt; 
 &lt;li&gt;Intercept requests and responses for manual review (edit, send/receive, cancel)&lt;/li&gt; 
 &lt;li&gt;Scope support, to help keep work organized&lt;/li&gt; 
 &lt;li&gt;Easy-to-use web based admin interface&lt;/li&gt; 
 &lt;li&gt;Project based database storage, to help keep work organized&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üë∑‚Äç‚ôÇÔ∏è Hetty is under active development. Check the &lt;a href="https://github.com/dstotijn/hetty/projects/1"&gt;backlog&lt;/a&gt; for the current status.&lt;/p&gt; 
&lt;p&gt;üì£ Are you pen testing professionaly in a team? I would love to hear your thoughts on tooling via &lt;a href="https://forms.gle/36jtgNc3TJ2imi5A8"&gt;this 5 minute survey&lt;/a&gt;. Thank you!&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;üí° The &lt;a href="https://hetty.xyz/docs/getting-started"&gt;Getting started&lt;/a&gt; doc has more detailed install and usage instructions.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;The quickest way to install and update Hetty is via a package manager:&lt;/p&gt; 
&lt;h4&gt;macOS&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install hettysoft/tap/hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Linux&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo snap install hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Windows&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;scoop bucket add hettysoft https://github.com/hettysoft/scoop-bucket.git
scoop install hettysoft/hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Other&lt;/h4&gt; 
&lt;p&gt;Alternatively, you can &lt;a href="https://github.com/dstotijn/hetty/releases/latest"&gt;download the latest release from GitHub&lt;/a&gt; for your OS and architecture, and move the binary to a directory in your &lt;code&gt;$PATH&lt;/code&gt;. If your OS is not available for one of the package managers or not listed in the GitHub releases, you can compile from source &lt;em&gt;(link coming soon)&lt;/em&gt;.&lt;/p&gt; 
&lt;h4&gt;Docker&lt;/h4&gt; 
&lt;p&gt;Docker images are distributed via &lt;a href="https://github.com/dstotijn/hetty/pkgs/container/hetty"&gt;GitHub's Container registry&lt;/a&gt; and &lt;a href="https://hub.docker.com/r/dstotijn/hetty"&gt;Docker Hub&lt;/a&gt;. To run Hetty via with a volume for database and certificate storage, and port 8080 forwarded:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -v $HOME/.hetty:/root/.hetty -p 8080:8080 \
  ghcr.io/dstotijn/hetty:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;Once installed, start Hetty via:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;üí° Read the &lt;a href="https://hetty.xyz/docs/getting-started"&gt;Getting started&lt;/a&gt; doc for more details.&lt;/p&gt; 
&lt;p&gt;To list all available options, run: &lt;code&gt;hetty --help&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ hetty --help

Usage:
    hetty [flags] [subcommand] [flags]

Runs an HTTP server with (MITM) proxy, GraphQL service, and a web based admin interface.

Options:
    --cert         Path to root CA certificate. Creates file if it doesn't exist. (Default: "~/.hetty/hetty_cert.pem")
    --key          Path to root CA private key. Creates file if it doesn't exist. (Default: "~/.hetty/hetty_key.pem")
    --db           Database file path. Creates file if it doesn't exist. (Default: "~/.hetty/hetty.db")
    --addr         TCP address for HTTP server to listen on, in the form \"host:port\". (Default: ":8080")
    --chrome       Launch Chrome with proxy settings applied and certificate errors ignored. (Default: false)
    --verbose      Enable verbose logging.
    --json         Encode logs as JSON, instead of pretty/human readable output.
    --version, -v  Output version.
    --help, -h     Output this usage text.

Subcommands:
    - cert  Certificate management

Run `hetty &amp;lt;subcommand&amp;gt; --help` for subcommand specific usage instructions.

Visit https://hetty.xyz to learn more about Hetty.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;üìñ &lt;a href="https://hetty.xyz/docs"&gt;Read the docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Use &lt;a href="https://github.com/dstotijn/hetty/issues"&gt;issues&lt;/a&gt; for bug reports and feature requests, and &lt;a href="https://github.com/dstotijn/hetty/discussions"&gt;discussions&lt;/a&gt; for questions and troubleshooting.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;üí¨ &lt;a href="https://discord.gg/3HVsj5pTFP"&gt;Join the Hetty Discord server&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Want to contribute? Great! Please check the &lt;a href="https://raw.githubusercontent.com/dstotijn/hetty/main/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thanks to the &lt;a href="https://www.hacker101.com/discord"&gt;Hacker101 community on Discord&lt;/a&gt; for the encouragement and early feedback.&lt;/li&gt; 
 &lt;li&gt;The font used in the logo and admin interface is &lt;a href="https://www.jetbrains.com/lp/mono/"&gt;JetBrains Mono&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;üíñ Are you enjoying Hetty? You can &lt;a href="https://github.com/sponsors/dstotijn"&gt;sponsor me&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/dstotijn/hetty/main/LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;¬© 2019‚Äì2025 Hetty Software&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>uber-go/zap</title>
      <link>https://github.com/uber-go/zap</link>
      <description>&lt;p&gt;Blazing fast, structured, leveled logging in Go.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;Blazing fast, structured, leveled logging in Go.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/uber-go/zap/master/assets/logo.png" alt="Zap logo" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://pkg.go.dev/go.uber.org/zap"&gt;&lt;img src="https://pkg.go.dev/badge/go.uber.org/zap" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/uber-go/zap/actions/workflows/go.yml"&gt;&lt;img src="https://github.com/uber-go/zap/actions/workflows/go.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/uber-go/zap"&gt;&lt;img src="https://codecov.io/gh/uber-go/zap/branch/master/graph/badge.svg?sanitize=true" alt="Coverage Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;go get -u go.uber.org/zap&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note that zap only supports the two most recent minor versions of Go.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;In contexts where performance is nice, but not critical, use the &lt;code&gt;SugaredLogger&lt;/code&gt;. It's 4-10x faster than other structured logging packages and includes both structured and &lt;code&gt;printf&lt;/code&gt;-style APIs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;logger, _ := zap.NewProduction()
defer logger.Sync() // flushes buffer, if any
sugar := logger.Sugar()
sugar.Infow("failed to fetch URL",
  // Structured context as loosely typed key-value pairs.
  "url", url,
  "attempt", 3,
  "backoff", time.Second,
)
sugar.Infof("Failed to fetch URL: %s", url)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When performance and type safety are critical, use the &lt;code&gt;Logger&lt;/code&gt;. It's even faster than the &lt;code&gt;SugaredLogger&lt;/code&gt; and allocates far less, but it only supports structured logging.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;logger, _ := zap.NewProduction()
defer logger.Sync()
logger.Info("failed to fetch URL",
  // Structured context as strongly typed Field values.
  zap.String("url", url),
  zap.Int("attempt", 3),
  zap.Duration("backoff", time.Second),
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://pkg.go.dev/go.uber.org/zap"&gt;documentation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/FAQ.md"&gt;FAQ&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;For applications that log in the hot path, reflection-based serialization and string formatting are prohibitively expensive ‚Äî they're CPU-intensive and make many small allocations. Put differently, using &lt;code&gt;encoding/json&lt;/code&gt; and &lt;code&gt;fmt.Fprintf&lt;/code&gt; to log tons of &lt;code&gt;interface{}&lt;/code&gt;s makes your application slow.&lt;/p&gt; 
&lt;p&gt;Zap takes a different approach. It includes a reflection-free, zero-allocation JSON encoder, and the base &lt;code&gt;Logger&lt;/code&gt; strives to avoid serialization overhead and allocations wherever possible. By building the high-level &lt;code&gt;SugaredLogger&lt;/code&gt; on that foundation, zap lets users &lt;em&gt;choose&lt;/em&gt; when they need to count every allocation and when they'd prefer a more familiar, loosely typed API.&lt;/p&gt; 
&lt;p&gt;As measured by its own &lt;a href="https://github.com/uber-go/zap/tree/master/benchmarks"&gt;benchmarking suite&lt;/a&gt;, not only is zap more performant than comparable structured logging packages ‚Äî it's also faster than the standard library. Like all benchmarks, take these with a grain of salt.&lt;sup id="anchor-versions"&gt;&lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/#footnote-versions"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Log a message and 10 fields:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Package&lt;/th&gt; 
   &lt;th align="center"&gt;Time&lt;/th&gt; 
   &lt;th align="center"&gt;Time % to zap&lt;/th&gt; 
   &lt;th align="center"&gt;Objects Allocated&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/td&gt; 
   &lt;td align="center"&gt;656 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+0%&lt;/td&gt; 
   &lt;td align="center"&gt;5 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap (sugared)&lt;/td&gt; 
   &lt;td align="center"&gt;935 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+43%&lt;/td&gt; 
   &lt;td align="center"&gt;10 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;zerolog&lt;/td&gt; 
   &lt;td align="center"&gt;380 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;-42%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;go-kit&lt;/td&gt; 
   &lt;td align="center"&gt;2249 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+243%&lt;/td&gt; 
   &lt;td align="center"&gt;57 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog (LogAttrs)&lt;/td&gt; 
   &lt;td align="center"&gt;2479 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+278%&lt;/td&gt; 
   &lt;td align="center"&gt;40 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog&lt;/td&gt; 
   &lt;td align="center"&gt;2481 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+278%&lt;/td&gt; 
   &lt;td align="center"&gt;42 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;apex/log&lt;/td&gt; 
   &lt;td align="center"&gt;9591 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1362%&lt;/td&gt; 
   &lt;td align="center"&gt;63 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;log15&lt;/td&gt; 
   &lt;td align="center"&gt;11393 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1637%&lt;/td&gt; 
   &lt;td align="center"&gt;75 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;logrus&lt;/td&gt; 
   &lt;td align="center"&gt;11654 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1677%&lt;/td&gt; 
   &lt;td align="center"&gt;79 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Log a message with a logger that already has 10 fields of context:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Package&lt;/th&gt; 
   &lt;th align="center"&gt;Time&lt;/th&gt; 
   &lt;th align="center"&gt;Time % to zap&lt;/th&gt; 
   &lt;th align="center"&gt;Objects Allocated&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/td&gt; 
   &lt;td align="center"&gt;67 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+0%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap (sugared)&lt;/td&gt; 
   &lt;td align="center"&gt;84 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+25%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;zerolog&lt;/td&gt; 
   &lt;td align="center"&gt;35 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;-48%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog&lt;/td&gt; 
   &lt;td align="center"&gt;193 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+188%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog (LogAttrs)&lt;/td&gt; 
   &lt;td align="center"&gt;200 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+199%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;go-kit&lt;/td&gt; 
   &lt;td align="center"&gt;2460 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+3572%&lt;/td&gt; 
   &lt;td align="center"&gt;56 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;log15&lt;/td&gt; 
   &lt;td align="center"&gt;9038 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+13390%&lt;/td&gt; 
   &lt;td align="center"&gt;70 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;apex/log&lt;/td&gt; 
   &lt;td align="center"&gt;9068 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+13434%&lt;/td&gt; 
   &lt;td align="center"&gt;53 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;logrus&lt;/td&gt; 
   &lt;td align="center"&gt;10521 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+15603%&lt;/td&gt; 
   &lt;td align="center"&gt;68 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Log a static string, without any context or &lt;code&gt;printf&lt;/code&gt;-style templating:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Package&lt;/th&gt; 
   &lt;th align="center"&gt;Time&lt;/th&gt; 
   &lt;th align="center"&gt;Time % to zap&lt;/th&gt; 
   &lt;th align="center"&gt;Objects Allocated&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/td&gt; 
   &lt;td align="center"&gt;63 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+0%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap (sugared)&lt;/td&gt; 
   &lt;td align="center"&gt;81 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+29%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;zerolog&lt;/td&gt; 
   &lt;td align="center"&gt;32 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;-49%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;standard library&lt;/td&gt; 
   &lt;td align="center"&gt;124 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+97%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog&lt;/td&gt; 
   &lt;td align="center"&gt;196 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+211%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog (LogAttrs)&lt;/td&gt; 
   &lt;td align="center"&gt;200 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+217%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;go-kit&lt;/td&gt; 
   &lt;td align="center"&gt;213 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+238%&lt;/td&gt; 
   &lt;td align="center"&gt;9 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;apex/log&lt;/td&gt; 
   &lt;td align="center"&gt;771 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1124%&lt;/td&gt; 
   &lt;td align="center"&gt;5 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;logrus&lt;/td&gt; 
   &lt;td align="center"&gt;1439 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+2184%&lt;/td&gt; 
   &lt;td align="center"&gt;23 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;log15&lt;/td&gt; 
   &lt;td align="center"&gt;2069 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+3184%&lt;/td&gt; 
   &lt;td align="center"&gt;20 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Development Status: Stable&lt;/h2&gt; 
&lt;p&gt;All APIs are finalized, and no breaking changes will be made in the 1.x series of releases. Users of semver-aware dependency management systems should pin zap to &lt;code&gt;^1&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We encourage and support an active, healthy community of contributors ‚Äî including you! Details are in the &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/CODE_OF_CONDUCT.md"&gt;code of conduct&lt;/a&gt;. The zap maintainers keep an eye on issues and pull requests, but you can also report any negative conduct to &lt;a href="mailto:oss-conduct@uber.com"&gt;oss-conduct@uber.com&lt;/a&gt;. That email list is a private, safe space; even the zap maintainers don't have access, so don't hesitate to hold us to a high standard.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Released under the &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;sup id="footnote-versions"&gt;1&lt;/sup&gt; In particular, keep in mind that we may be benchmarking against slightly older versions of other packages. Versions are pinned in the &lt;a href="https://github.com/uber-go/zap/raw/master/benchmarks/go.mod"&gt;benchmarks/go.mod&lt;/a&gt; file. &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/#anchor-versions"&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kubernetes/autoscaler</title>
      <link>https://github.com/kubernetes/autoscaler</link>
      <description>&lt;p&gt;Autoscaling components for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Kubernetes Autoscaler&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/actions/workflows/release.yaml"&gt;&lt;img src="https://github.com/kubernetes/autoscaler/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="Release Charts" /&gt;&lt;/a&gt; &lt;a href="https://github.com/kubernetes/autoscaler/actions/workflows/ci.yaml"&gt;&lt;img src="https://github.com/kubernetes/autoscaler/actions/workflows/ci.yaml/badge.svg?sanitize=true" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/k8s.io/autoscaler"&gt;&lt;img src="https://godoc.org/k8s.io/autoscaler?status.svg?sanitize=true" alt="GoDoc Widget" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;This repository contains autoscaling-related components for Kubernetes.&lt;/p&gt; 
&lt;h2&gt;What's inside&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler"&gt;Cluster Autoscaler&lt;/a&gt; - a component that automatically adjusts the size of a Kubernetes Cluster so that all pods have a place to run and there are no unneeded nodes. Supports several public cloud providers. Version 1.0 (GA) was released with kubernetes 1.8.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler/charts"&gt;Cluster Autoscaler Helm Chart&lt;/a&gt; - Supported Helm chart for Cluster Autoscaler.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler"&gt;Vertical Pod Autoscaler&lt;/a&gt; - a set of components that automatically adjust the amount of CPU and memory requested by pods running in the Kubernetes Cluster. Current state - beta.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/charts"&gt;Vertical Pod Autoscaler Helm Chart&lt;/a&gt; - Supported Helm chart for Vertical Pod Autoscaler.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/addon-resizer"&gt;Addon Resizer&lt;/a&gt; - a simplified version of vertical pod autoscaler that modifies resource requests of a deployment based on the number of nodes in the Kubernetes Cluster. Current state - beta.&lt;/p&gt; 
&lt;h2&gt;Contact Info&lt;/h2&gt; 
&lt;p&gt;Interested in autoscaling? Want to talk? Have questions, concerns or great ideas?&lt;/p&gt; 
&lt;p&gt;Please join us on #sig-autoscaling at &lt;a href="https://kubernetes.slack.com/"&gt;https://kubernetes.slack.com/&lt;/a&gt;, or join one of our weekly meetings. See &lt;a href="https://github.com/kubernetes/community/raw/master/sig-autoscaling/README.md"&gt;the Kubernetes Community Repo&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;Getting the Code&lt;/h2&gt; 
&lt;p&gt;Fork the repository in the cloud:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Visit &lt;a href="https://github.com/kubernetes/autoscaler"&gt;https://github.com/kubernetes/autoscaler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Click Fork button (top right) to establish a cloud-based fork.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;The code must be checked out as a subdirectory of &lt;code&gt;k8s.io&lt;/code&gt;, and not &lt;code&gt;github.com&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;mkdir -p $GOPATH/src/k8s.io
cd $GOPATH/src/k8s.io
# Replace "$YOUR_GITHUB_USERNAME" below with your github username
git clone https://github.com/$YOUR_GITHUB_USERNAME/autoscaler.git
cd autoscaler
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Please refer to Kubernetes &lt;a href="https://github.com/kubernetes/community/raw/master/contributors/guide/github-workflow.md"&gt;Github workflow guide&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tmc/langchaingo</title>
      <link>https://github.com/tmc/langchaingo</link>
      <description>&lt;p&gt;LangChain for Go, the easiest way to write LLM-based programs in Go&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;p&gt;üéâ &lt;strong&gt;Join our new official Discord community!&lt;/strong&gt; Connect with other LangChain Go developers, get help and contribute: &lt;a href="https://discord.gg/t9UbBQs2rG"&gt;Join Discord&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h1&gt;ü¶úÔ∏èüîó LangChain Go&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/tmc/langchaingo"&gt;&lt;img src="https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;amp;logoColor=white&amp;amp;style=flat-square" alt="go.dev reference" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/tmc/langchaingo"&gt;&lt;img src="https://goreportcard.com/badge/github.com/tmc/langchaingo" alt="scorecard" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/t9UbBQs2rG"&gt;&lt;img src="https://dcbadge.vercel.app/api/server/t9UbBQs2rG?compact=true&amp;amp;style=flat" alt="" /&gt;&lt;/a&gt; &lt;a href="https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/tmc/langchaingo"&gt;&lt;img src="https://img.shields.io/static/v1?label=Dev%20Containers&amp;amp;message=Open&amp;amp;color=blue&amp;amp;logo=visualstudiocode" alt="Open in Dev Containers" /&gt;&lt;/a&gt; &lt;a href="https://codespaces.new/tmc/langchaingo"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" title="Open in Github Codespace" width="150" height="20" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;‚ö° Building applications with LLMs through composability, with Go! ‚ö°&lt;/p&gt; 
&lt;h2&gt;ü§î What is this?&lt;/h2&gt; 
&lt;p&gt;This is the Go language implementation of &lt;a href="https://github.com/langchain-ai/langchain"&gt;LangChain&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìñ Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://tmc.github.io/langchaingo/docs/"&gt;Documentation Site&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/tmc/langchaingo"&gt;API Reference&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üéâ Examples&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/tmc/langchaingo/main/examples"&gt;./examples&lt;/a&gt; for example usage.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
  "context"
  "fmt"
  "log"

  "github.com/tmc/langchaingo/llms"
  "github.com/tmc/langchaingo/llms/openai"
)

func main() {
  ctx := context.Background()
  llm, err := openai.New()
  if err != nil {
    log.Fatal(err)
  }
  prompt := "What would be a good company name for a company that makes colorful socks?"
  completion, err := llms.GenerateFromSinglePrompt(ctx, llm, prompt)
  if err != nil {
    log.Fatal(err)
  }
  fmt.Println(completion)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ go run .
Socktastic
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Resources&lt;/h1&gt; 
&lt;p&gt;Join the Discord server for support and discussions: &lt;a href="https://discord.gg/8bHGKzHBkM"&gt;Join Discord&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Here are some links to blog posts and articles on using Langchain Go:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://eli.thegreenplace.net/2024/using-gemini-models-in-go-with-langchaingo/"&gt;Using Gemini models in Go with LangChainGo&lt;/a&gt; - Jan 2024&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://eli.thegreenplace.net/2023/using-ollama-with-langchaingo/"&gt;Using Ollama with LangChainGo&lt;/a&gt; - Nov 2023&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://sausheong.com/creating-a-simple-chatgpt-clone-with-go-c40b4bec9267?sk=53a2bcf4ce3b0cfae1a4c26897c0deb0"&gt;Creating a simple ChatGPT clone with Go&lt;/a&gt; - Aug 2023&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://sausheong.com/creating-a-chatgpt-clone-that-runs-on-your-laptop-with-go-bf9d41f1cf88?sk=05dc67b60fdac6effb1aca84dd2d654e"&gt;Creating a ChatGPT Clone that Runs on Your Laptop with Go&lt;/a&gt; - Aug 2023&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;p&gt;There is a momentum for moving the development of langchaingo to a more community effort, if you are interested in being a maintainer or you are a contributor please join our &lt;a href="https://discord.gg/8bHGKzHBkM"&gt;Discord&lt;/a&gt; and let us know.&lt;/p&gt; 
&lt;a href="https://github.com/tmc/langchaingo/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=tmc/langchaingo" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>minio/minio</title>
      <link>https://github.com/minio/minio</link>
      <description>&lt;p&gt;MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MinIO Quickstart Guide&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://slack.min.io"&gt;&lt;img src="https://slack.min.io/slack?type=svg" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/minio/minio/"&gt;&lt;img src="https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL%20V3-blue" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://min.io"&gt;&lt;img src="https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true" alt="MinIO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license. Designed for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;S3 API Compatible ‚Äì Seamless integration with existing S3 tools&lt;/li&gt; 
 &lt;li&gt;Built for AI &amp;amp; Analytics ‚Äì Optimized for large-scale data pipelines&lt;/li&gt; 
 &lt;li&gt;High Performance ‚Äì Ideal for demanding storage workloads.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This README provides instructions for building MinIO from source and deploying onto baremetal hardware. Use the &lt;a href="https://github.com/minio/docs"&gt;MinIO Documentation&lt;/a&gt; project to build and host a local copy of the documentation.&lt;/p&gt; 
&lt;h2&gt;MinIO is Open Source Software&lt;/h2&gt; 
&lt;p&gt;We designed MinIO as Open Source software for the Open Source software community. We encourage the community to remix, redesign, and reshare MinIO under the terms of the AGPLv3 license.&lt;/p&gt; 
&lt;p&gt;All usage of MinIO in your application stack requires validation against AGPLv3 obligations, which include but are not limited to the release of modified code to the community from which you have benefited. Any commercial/proprietary usage of the AGPLv3 software, including repackaging or reselling services/features, is done at your own risk.&lt;/p&gt; 
&lt;p&gt;The AGPLv3 provides no obligation by any party to support, maintain, or warranty the original or any modified work. All support is provided on a best-effort basis through Github and our &lt;a href="https://raw.githubusercontent.com/minio/minio/master/https//slack.min.io"&gt;Slack&lt;/a&gt; channel, and any member of the community is welcome to contribute and assist others in their usage of the software.&lt;/p&gt; 
&lt;p&gt;MinIO &lt;a href="https://www.min.io/product/aistor"&gt;AIStor&lt;/a&gt; includes enterprise-grade support and licensing for workloads which require commercial or proprietary usage and production-level SLA/SLO-backed support. For more information, &lt;a href="https://min.io/pricing"&gt;reach out for a quote&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Source-Only Distribution&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The MinIO community edition is now distributed as source code only. We will no longer provide pre-compiled binary releases for the community version.&lt;/p&gt; 
&lt;h3&gt;Installing Latest MinIO Community Edition&lt;/h3&gt; 
&lt;p&gt;To use MinIO community edition, you have two options:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install from source&lt;/strong&gt; using &lt;code&gt;go install github.com/minio/minio@latest&lt;/code&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build a Docker image&lt;/strong&gt; from the provided Dockerfile&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the sections below for detailed instructions on each method.&lt;/p&gt; 
&lt;h3&gt;Legacy Binary Releases&lt;/h3&gt; 
&lt;p&gt;Historical pre-compiled binary releases remain available for reference but are no longer maintained:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub Releases: &lt;a href="https://github.com/minio/minio/releases"&gt;https://github.com/minio/minio/releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Direct downloads: &lt;a href="https://dl.min.io/server/minio/release/"&gt;https://dl.min.io/server/minio/release/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;These legacy binaries will not receive updates.&lt;/strong&gt; We strongly recommend using source builds for access to the latest features, bug fixes, and security updates.&lt;/p&gt; 
&lt;h2&gt;Install from Source&lt;/h2&gt; 
&lt;p&gt;Use the following commands to compile and run a standalone MinIO server from source. If you do not have a working Golang environment, please follow &lt;a href="https://golang.org/doc/install"&gt;How to install Golang&lt;/a&gt;. Minimum version required is &lt;a href="https://golang.org/dl/#stable"&gt;go1.24&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/minio/minio@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can alternatively run &lt;code&gt;go build&lt;/code&gt; and use the &lt;code&gt;GOOS&lt;/code&gt; and &lt;code&gt;GOARCH&lt;/code&gt; environment variables to control the OS and architecture target. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env GOOS=linux GOARCh=arm64 go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start MinIO by running &lt;code&gt;minio server PATH&lt;/code&gt; where &lt;code&gt;PATH&lt;/code&gt; is any empty folder on your local filesystem.&lt;/p&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://docs.min.io/community/minio-object-store/developers/minio-drivers.html"&gt;https://docs.min.io/community/minio-object-store/developers/minio-drivers.html&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Production environments using compiled-from-source MinIO binaries do so at their own risk. The AGPLv3 license provides no warranties nor liabilites for any such usage.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Build Docker Image&lt;/h2&gt; 
&lt;p&gt;You can use the &lt;code&gt;docker build .&lt;/code&gt; command to build a Docker image on your local host machine. You must first &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#install-from-source"&gt;build MinIO&lt;/a&gt; and ensure the &lt;code&gt;minio&lt;/code&gt; binary exists in the project root.&lt;/p&gt; 
&lt;p&gt;The following command builds the Docker image using the default &lt;code&gt;Dockerfile&lt;/code&gt; in the root project directory with the repository and image tag &lt;code&gt;myminio:minio&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t myminio:minio .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;docker image ls&lt;/code&gt; to confirm the image exists in your local repository. You can run the server using standard Docker invocation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run -p 9000:9000 -p 9001:9001 myminio:minio server /tmp/minio --console-address :9001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Complete documentation for building Docker containers, managing custom images, or loading images into orchestration platforms is out of scope for this documentation. You can modify the &lt;code&gt;Dockerfile&lt;/code&gt; and &lt;code&gt;dockerscripts/docker-entrypoint.sh&lt;/code&gt; as-needed to reflect your specific image requirements.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/baremetal-deploy-minio-as-a-container.html#deploy-minio-container"&gt;MinIO Container&lt;/a&gt; documentation for more guidance on running MinIO within a Container image.&lt;/p&gt; 
&lt;h2&gt;Install using Helm Charts&lt;/h2&gt; 
&lt;p&gt;There are two paths for installing MinIO onto Kubernetes infrastructure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;a href="https://github.com/minio/operator"&gt;MinIO Operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use the community-maintained &lt;a href="https://github.com/minio/minio/tree/master/helm/minio"&gt;Helm charts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/kubernetes.html"&gt;MinIO Documentation&lt;/a&gt; for guidance on deploying using the Operator. The Community Helm chart has instructions in the folder-level README.&lt;/p&gt; 
&lt;h2&gt;Test MinIO Connectivity&lt;/h2&gt; 
&lt;h3&gt;Test using MinIO Console&lt;/h3&gt; 
&lt;p&gt;MinIO Server comes with an embedded web based object browser. Point your web browser to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; to ensure your server has started successfully.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MinIO runs console on random port by default, if you wish to choose a specific port use &lt;code&gt;--console-address&lt;/code&gt; to pick a specific interface and port.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;mc&lt;/code&gt; provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services.&lt;/p&gt; 
&lt;p&gt;The following commands set a local alias, validate the server information, create a bucket, copy data to that bucket, and list the contents of the bucket.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info
mc mb data
mc cp ~/Downloads/mydata data/
mc ls data/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the MinIO Client &lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html#quickstart"&gt;Quickstart Guide&lt;/a&gt; for further instructions.&lt;/p&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/index.html"&gt;The MinIO documentation website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html"&gt;Use &lt;code&gt;mc&lt;/code&gt; with MinIO Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/developers/go/minio-go.html"&gt;Use &lt;code&gt;minio-go&lt;/code&gt; SDK with MinIO Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute to MinIO Project&lt;/h2&gt; 
&lt;p&gt;Please follow MinIO &lt;a href="https://github.com/minio/minio/raw/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt; for guidance on making new contributions to the repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MinIO source is licensed under the &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;GNU AGPLv3&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;MinIO &lt;a href="https://github.com/minio/minio/tree/master/docs"&gt;documentation&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;CC BY 4.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/minio/minio/raw/master/COMPLIANCE.md"&gt;License Compliance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>base/node</title>
      <link>https://github.com/base/node</link>
      <description>&lt;p&gt;Everything required to run your own Base node&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/base/node/main/logo.webp" alt="Base" /&gt;&lt;/p&gt; 
&lt;h1&gt;Base Node&lt;/h1&gt; 
&lt;p&gt;Base is a secure, low-cost, developer-friendly Ethereum L2 built on Optimism's &lt;a href="https://docs.optimism.io/"&gt;OP Stack&lt;/a&gt;. This repository contains Docker builds to run your own node on the Base network.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://base.org"&gt;&lt;img src="https://img.shields.io/website-up-down-green-red/https/base.org.svg?sanitize=true" alt="Website base.org" /&gt;&lt;/a&gt; &lt;a href="https://docs.base.org/"&gt;&lt;img src="https://img.shields.io/badge/docs-up-green" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://base.org/discord"&gt;&lt;img src="https://img.shields.io/discord/1067165013397213286?label=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/Base"&gt;&lt;img src="https://img.shields.io/twitter/follow/Base?style=social" alt="Twitter Base" /&gt;&lt;/a&gt; &lt;a href="https://farcaster.xyz/base"&gt;&lt;img src="https://img.shields.io/badge/Farcaster_Base-3d8fcc" alt="Farcaster Base" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Ensure you have an Ethereum L1 full node RPC available&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Choose your network:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;For mainnet: Use &lt;code&gt;.env.mainnet&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;For testnet: Use &lt;code&gt;.env.sepolia&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Configure your L1 endpoints in the appropriate &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;OP_NODE_L1_ETH_RPC=&amp;lt;your-preferred-l1-rpc&amp;gt;
OP_NODE_L1_BEACON=&amp;lt;your-preferred-l1-beacon&amp;gt;
OP_NODE_L1_BEACON_ARCHIVER=&amp;lt;your-preferred-l1-beacon-archiver&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Start the node:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# For mainnet (default):
docker compose up --build

# For testnet:
NETWORK_ENV=.env.sepolia docker compose up --build

# To use a specific client (optional):
CLIENT=reth docker compose up --build

# For testnet with a specific client:
NETWORK_ENV=.env.sepolia CLIENT=reth docker compose up --build
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Supported Clients&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;geth&lt;/code&gt; (default)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;reth&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nethermind&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;h3&gt;Minimum Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Modern Multicore CPU&lt;/li&gt; 
 &lt;li&gt;32GB RAM (64GB Recommended)&lt;/li&gt; 
 &lt;li&gt;NVMe SSD drive&lt;/li&gt; 
 &lt;li&gt;Storage: (2 * &lt;a href="https://base.org/stats"&gt;current chain size&lt;/a&gt; + &lt;a href="https://basechaindata.vercel.app"&gt;snapshot size&lt;/a&gt; + 20% buffer) (to accommodate future growth)&lt;/li&gt; 
 &lt;li&gt;Docker and Docker Compose&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Production Hardware Specifications&lt;/h3&gt; 
&lt;p&gt;The following are the hardware specifications we use in production:&lt;/p&gt; 
&lt;h4&gt;Geth Full Node&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Instance&lt;/strong&gt;: AWS i4i.12xlarge&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt;: RAID 0 of all local NVMe drives (&lt;code&gt;/dev/nvme*&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Filesystem&lt;/strong&gt;: ext4&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Reth Archive Node&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Instance&lt;/strong&gt;: AWS i7ie.6xlarge&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt;: RAID 0 of all local NVMe drives (&lt;code&gt;/dev/nvme*&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Filesystem&lt;/strong&gt;: ext4&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] To run the node using a supported client, you can use the following command: &lt;code&gt;CLIENT=supported_client docker compose up --build&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Supported clients:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;geth&lt;/li&gt; 
 &lt;li&gt;reth (with Flashblocks support option, see &lt;a href="https://raw.githubusercontent.com/base/node/main/reth/README.md"&gt;Reth Node README&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;nethermind&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;h3&gt;Required Settings&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;L1 Configuration: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;OP_NODE_L1_ETH_RPC&lt;/code&gt;: Your Ethereum L1 node RPC endpoint&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OP_NODE_L1_BEACON&lt;/code&gt;: Your L1 beacon node endpoint&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OP_NODE_L1_BEACON_ARCHIVER&lt;/code&gt;: Your L1 beacon archiver endpoint&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OP_NODE_L1_RPC_KIND&lt;/code&gt;: The type of RPC provider being used (default: "debug_geth"). Supported values: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;code&gt;alchemy&lt;/code&gt;: Alchemy RPC provider&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;quicknode&lt;/code&gt;: QuickNode RPC provider&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;infura&lt;/code&gt;: Infura RPC provider&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;parity&lt;/code&gt;: Parity RPC provider&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;nethermind&lt;/code&gt;: Nethermind RPC provider&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;debug_geth&lt;/code&gt;: Debug Geth RPC provider&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;erigon&lt;/code&gt;: Erigon RPC provider&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;basic&lt;/code&gt;: Basic RPC provider (standard receipt fetching only)&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;any&lt;/code&gt;: Any available RPC method&lt;/li&gt; 
     &lt;li&gt;&lt;code&gt;standard&lt;/code&gt;: Standard RPC methods including newer optimized methods&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Network Settings&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Mainnet: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;RETH_CHAIN=base&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OP_NODE_NETWORK=base-mainnet&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Sequencer: &lt;code&gt;https://mainnet-sequencer.base.org&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Settings&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Cache Settings: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;GETH_CACHE="20480"&lt;/code&gt; (20GB)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;GETH_CACHE_DATABASE="20"&lt;/code&gt; (4GB)&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;GETH_CACHE_GC="12"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;GETH_CACHE_SNAPSHOT="24"&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;GETH_CACHE_TRIE="44"&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Optional Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;EthStats Monitoring (uncomment to enable)&lt;/li&gt; 
 &lt;li&gt;Trusted RPC Mode (uncomment to enable)&lt;/li&gt; 
 &lt;li&gt;Snap Sync (experimental)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For full configuration options, see the &lt;code&gt;.env.mainnet&lt;/code&gt; file.&lt;/p&gt; 
&lt;h2&gt;Snapshots&lt;/h2&gt; 
&lt;p&gt;Snapshots are available to help you sync your node more quickly. See &lt;a href="https://docs.base.org/chain/run-a-base-node#snapshots"&gt;docs.base.org&lt;/a&gt; for links and more details on how to restore from a snapshot.&lt;/p&gt; 
&lt;h2&gt;Supported Networks&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Network&lt;/th&gt; 
   &lt;th&gt;Status&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mainnet&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Testnet&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;p&gt;For support please join our &lt;a href="https://discord.gg/buildonbase"&gt;Discord&lt;/a&gt; post in &lt;code&gt;üõ†ÔΩúnode-operators&lt;/code&gt;. You can alternatively open a new GitHub issue.&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;THE NODE SOFTWARE IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY KIND. We make no guarantees about asset protection or security. Usage is subject to applicable laws and regulations.&lt;/p&gt; 
&lt;p&gt;For more information, visit &lt;a href="https://docs.base.org/"&gt;docs.base.org&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gogs/gogs</title>
      <link>https://github.com/gogs/gogs</link>
      <description>&lt;p&gt;Gogs is a painless self-hosted Git service&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/2946214/146899259-6a8b58ad-8d6e-40d2-ab02-79dc6aadabbf.png" alt="gogs-brand" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/gogs/gogs/actions?query=branch%3Amain"&gt;&lt;img src="https://img.shields.io/github/checks-status/gogs/gogs/main?logo=github&amp;amp;style=for-the-badge" alt="GitHub Workflow Status" /&gt;&lt;/a&gt; &lt;a href="https://sourcegraph.com/github.com/gogs/gogs"&gt;&lt;img src="https://img.shields.io/badge/view%20on-Sourcegraph-brightgreen.svg?style=for-the-badge&amp;amp;logo=sourcegraph" alt="Sourcegraph" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;üëâ Deploy on DigitalOcean and &lt;a href="https://m.do.co/c/5aeb02268b55"&gt;get $200 in free credits&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;üîÆ Vision&lt;/h2&gt; 
&lt;p&gt;The Gogs (&lt;code&gt;/g…ëgz/&lt;/code&gt;) project aims to build a simple, stable and extensible self-hosted Git service that can be set up in the most painless way. With Go, this can be done with an independent binary distribution across all platforms that Go supports, including Linux, macOS, Windows and ARM-based systems.&lt;/p&gt; 
&lt;h2&gt;üì° Overview&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Please visit &lt;a href="https://gogs.io"&gt;our home page&lt;/a&gt; for user documentation.&lt;/li&gt; 
 &lt;li&gt;Please refer to &lt;a href="https://raw.githubusercontent.com/gogs/gogs/main/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt; for list of changes in each releases.&lt;/li&gt; 
 &lt;li&gt;Want to try it before doing anything else? Do it &lt;a href="https://try.gogs.io/gogs/gogs"&gt;online&lt;/a&gt;!&lt;/li&gt; 
 &lt;li&gt;Having trouble? Help yourself with &lt;a href="https://gogs.io/docs/intro/troubleshooting.html"&gt;troubleshooting&lt;/a&gt; or ask questions in &lt;a href="https://github.com/gogs/gogs/discussions"&gt;Discussions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Want to help with localization? Check out the &lt;a href="https://gogs.io/docs/features/i18n.html"&gt;localization documentation&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Ready to get hands dirty? Read our &lt;a href="https://raw.githubusercontent.com/gogs/gogs/main/.github/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Hmm... What about APIs? We have experimental support with &lt;a href="https://github.com/gogs/docs-api"&gt;documentation&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíå Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;User dashboard, user profile and activity timeline.&lt;/li&gt; 
 &lt;li&gt;Access repositories via SSH, HTTP and HTTPS protocols.&lt;/li&gt; 
 &lt;li&gt;User, organization and repository management.&lt;/li&gt; 
 &lt;li&gt;Repository and organization webhooks, including Slack, Discord and Dingtalk.&lt;/li&gt; 
 &lt;li&gt;Repository Git hooks, deploy keys and Git LFS.&lt;/li&gt; 
 &lt;li&gt;Repository issues, pull requests, wiki, protected branches and collaboration.&lt;/li&gt; 
 &lt;li&gt;Migrate and mirror repositories with wiki from other code hosts.&lt;/li&gt; 
 &lt;li&gt;Web editor for quick editing repository files and wiki.&lt;/li&gt; 
 &lt;li&gt;Jupyter Notebook and PDF rendering.&lt;/li&gt; 
 &lt;li&gt;Authentication via SMTP, LDAP, reverse proxy, GitHub.com and GitHub Enterprise with 2FA.&lt;/li&gt; 
 &lt;li&gt;Customize HTML templates, static files and many others.&lt;/li&gt; 
 &lt;li&gt;Rich database backend support, including PostgreSQL, MySQL, SQLite3 or any database backend that speaks one of those protocols.&lt;/li&gt; 
 &lt;li&gt;Have localization over &lt;a href="https://crowdin.com/project/gogs"&gt;31 languages&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíæ Hardware requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A Raspberry Pi or $5 Digital Ocean Droplet is more than enough to get you started. Some even use 64MB RAM Docker &lt;a href="https://www.docker.com/blog/containers-as-a-service-caas/"&gt;CaaS&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;2 CPU cores and 512MB RAM would be the baseline for teamwork.&lt;/li&gt; 
 &lt;li&gt;Increase CPU cores when your team size gets significantly larger, memory footprint remains low.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üíª Browser support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Please see &lt;a href="https://github.com/Semantic-Org/Semantic-UI#browser-support"&gt;Semantic UI&lt;/a&gt; for specific versions of supported browsers.&lt;/li&gt; 
 &lt;li&gt;The smallest resolution officially supported is &lt;strong&gt;1024*768&lt;/strong&gt;, however the UI may still look right in smaller resolutions, but no promises or fixes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìú Installation&lt;/h2&gt; 
&lt;p&gt;Make sure you install the &lt;a href="https://gogs.io/docs/installation"&gt;prerequisites&lt;/a&gt; first.&lt;/p&gt; 
&lt;p&gt;There are 6 ways to install Gogs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gogs.io/docs/installation/install_from_binary.html"&gt;Install from binary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gogs.io/docs/installation/install_from_source.html"&gt;Install from source&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gogs.io/docs/installation/install_from_packages.html"&gt;Install from packages&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gogs/gogs/tree/main/docker"&gt;Ship with Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/geerlingguy/ansible-vagrant-examples/tree/master/gogs"&gt;Try with Vagrant&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Deploy to cloud&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.cloudron.io/store/io.gogs.cloudronapp.html"&gt;Cloudron&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/YunoHost-Apps/gogs_ynh"&gt;YunoHost&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.alwaysdata.com/en/marketplace/gogs/"&gt;alwaysdata&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Tutorials&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://peppe8o.com/private-git-web-portal-in-raspberry-pi-with-gogs/"&gt;Private Git Web Portal in Raspberry PI With Gogs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-gogs-on-ubuntu-14-04"&gt;How To Set Up Gogs on Ubuntu 14.04&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.hypriot.com/post/run-your-own-github-like-service-with-docker/"&gt;Run your own GitHub-like service with the help of Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://garthwaite.org/docker-gogs.html"&gt;Dockerized Gogs git server and alpine postgres in 20 minutes or less&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://eladnava.com/host-your-own-private-github-with-gogs-io/"&gt;Host Your Own Private GitHub with Gogs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.mynook.info/post/host-your-own-git-server-using-gogs/"&gt;‰ΩøÁî® Gogs Êê≠Âª∫Ëá™Â∑±ÁöÑ Git ÊúçÂä°Âô®&lt;/a&gt; (Chinese)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://my.oschina.net/luyao/blog/375654"&gt;ÈòøÈáå‰∫ë‰∏ä Ubuntu 14.04 64 ‰ΩçÂÆâË£Ö Gogs&lt;/a&gt; (Chinese)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.codejam.info/2015/03/installing-gogs-on-freebsd.html"&gt;Installing Gogs on FreeBSD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=deSfX0gqefE"&gt;How to install Gogs on a Linux Server (DigitalOcean)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¶ Software, service and product support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://plugins.jenkins.io/gogs-webhook/"&gt;Jenkins&lt;/a&gt; (CI)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://forge.puppet.com/modules/Siteminds/gogs"&gt;Puppet&lt;/a&gt; (IT)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.synology.com"&gt;Synology&lt;/a&gt; (Docker)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://syncloud.org/"&gt;Syncloud&lt;/a&gt; (App Store)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôá‚Äç‚ôÇÔ∏è Acknowledgments&lt;/h2&gt; 
&lt;p&gt;This project is proudly supported by:&lt;/p&gt; 
&lt;p&gt; &lt;a href="https://m.do.co/c/5aeb02268b55"&gt; &lt;img src="https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg?sanitize=true" width="201px" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Other acknowledgments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thanks &lt;a href="https://twitter.com/egonelbre"&gt;Egon Elbre&lt;/a&gt; for designing the original version of the logo.&lt;/li&gt; 
 &lt;li&gt;Thanks &lt;a href="https://crowdin.com/project/gogs"&gt;Crowdin&lt;/a&gt; for sponsoring open source translation plan.&lt;/li&gt; 
 &lt;li&gt;Thanks &lt;a href="https://buildkite.com"&gt;Buildkite&lt;/a&gt; for sponsoring open source CI/CD plan.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üëã Contributors&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;See &lt;a href="https://github.com/gogs/gogs/graphs/contributors"&gt;contributors page&lt;/a&gt; for top 100 contributors.&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/gogs/gogs/main/conf/locale/TRANSLATORS"&gt;TRANSLATORS&lt;/a&gt; for public list of translators.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚öñÔ∏è License&lt;/h2&gt; 
&lt;p&gt;This project is under the MIT License. See the &lt;a href="https://github.com/gogs/gogs/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for the full license text.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>prometheus/alertmanager</title>
      <link>https://github.com/prometheus/alertmanager</link>
      <description>&lt;p&gt;Prometheus Alertmanager&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Alertmanager &lt;a href="https://circleci.com/gh/prometheus/alertmanager"&gt;&lt;img src="https://circleci.com/gh/prometheus/alertmanager/tree/main.svg?style=shield" alt="CircleCI" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;&lt;img src="https://quay.io/repository/prometheus/alertmanager/status" alt="Docker Repository on Quay" title="Docker Repository on Quay" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;&lt;img src="https://img.shields.io/docker/pulls/prom/alertmanager.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct &lt;a href="https://prometheus.io/docs/alerting/latest/configuration/#receiver"&gt;receiver integrations&lt;/a&gt; such as email, PagerDuty, OpsGenie, or many other &lt;a href="https://prometheus.io/docs/operating/integrations/#alertmanager-webhook-receiver"&gt;mechanisms&lt;/a&gt; thanks to the webhook receiver. It also takes care of silencing and inhibition of alerts.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="http://prometheus.io/docs/alerting/alertmanager/"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;There are various ways of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Precompiled binaries&lt;/h3&gt; 
&lt;p&gt;Precompiled binaries for released versions are available in the &lt;a href="https://prometheus.io/download/"&gt;&lt;em&gt;download&lt;/em&gt; section&lt;/a&gt; on &lt;a href="https://prometheus.io"&gt;prometheus.io&lt;/a&gt;. Using the latest production release binary is the recommended way of installing Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Docker images&lt;/h3&gt; 
&lt;p&gt;Docker images are available on &lt;a href="https://quay.io/repository/prometheus/alertmanager"&gt;Quay.io&lt;/a&gt; or &lt;a href="https://hub.docker.com/r/prom/alertmanager/"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can launch an Alertmanager container for trying it out with&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ docker run --name alertmanager -d -p 127.0.0.1:9093:9093 quay.io/prometheus/alertmanager
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alertmanager will now be reachable at &lt;a href="http://localhost:9093/"&gt;http://localhost:9093/&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Compiling the binary&lt;/h3&gt; 
&lt;p&gt;You can either &lt;code&gt;go get&lt;/code&gt; it:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ GO15VENDOREXPERIMENT=1 go get github.com/prometheus/alertmanager/cmd/...
# cd $GOPATH/src/github.com/prometheus/alertmanager
$ alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or clone the repository and build manually:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ mkdir -p $GOPATH/src/github.com/prometheus
$ cd $GOPATH/src/github.com/prometheus
$ git clone https://github.com/prometheus/alertmanager.git
$ cd alertmanager
$ make build
$ ./alertmanager --config.file=&amp;lt;your_file&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also build just one of the binaries in this repo by passing a name to the build function:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ make build BINARIES=amtool
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;p&gt;This is an example configuration that should cover most relevant aspects of the new YAML configuration format. The full documentation of the configuration can be found &lt;a href="https://prometheus.io/docs/alerting/configuration/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;global:
  # The smarthost and SMTP sender used for mail notifications.
  smtp_smarthost: 'localhost:25'
  smtp_from: 'alertmanager@example.org'

# The root route on which each incoming alert enters.
route:
  # The root route must not have any matchers as it is the entry point for
  # all alerts. It needs to have a receiver configured so alerts that do not
  # match any of the sub-routes are sent to someone.
  receiver: 'team-X-mails'

  # The labels by which incoming alerts are grouped together. For example,
  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
  # be batched into a single group.
  #
  # To aggregate by all possible labels use '...' as the sole label name.
  # This effectively disables aggregation entirely, passing through all
  # alerts as-is. This is unlikely to be what you want, unless you have
  # a very low alert volume or your upstream notification system performs
  # its own grouping. Example: group_by: [...]
  group_by: ['alertname', 'cluster']

  # When a new group of alerts is created by an incoming alert, wait at
  # least 'group_wait' to send the initial notification.
  # This way ensures that you get multiple alerts for the same group that start
  # firing shortly after another are batched together on the first
  # notification.
  group_wait: 30s

  # When the first notification was sent, wait 'group_interval' to send a batch
  # of new alerts that started firing for that group.
  group_interval: 5m

  # If an alert has successfully been sent, wait 'repeat_interval' to
  # resend them.
  repeat_interval: 3h

  # All the above attributes are inherited by all child routes and can
  # overwritten on each.

  # The child route trees.
  routes:
  # This route performs a regular expression match on alert labels to
  # catch alerts that are related to a list of services.
  - matchers:
    - service=~"^(foo1|foo2|baz)$"
    receiver: team-X-mails

    # The service has a sub-route for critical alerts, any alerts
    # that do not match, i.e. severity != critical, fall-back to the
    # parent node and are sent to 'team-X-mails'
    routes:
    - matchers:
      - severity="critical"
      receiver: team-X-pager

  - matchers:
    - service="files"
    receiver: team-Y-mails

    routes:
    - matchers:
      - severity="critical"
      receiver: team-Y-pager

  # This route handles all alerts coming from a database service. If there's
  # no team to handle it, it defaults to the DB team.
  - matchers:
    - service="database"

    receiver: team-DB-pager
    # Also group alerts by affected database.
    group_by: [alertname, cluster, database]

    routes:
    - matchers:
      - owner="team-X"
      receiver: team-X-pager

    - matchers:
      - owner="team-Y"
      receiver: team-Y-pager


# Inhibition rules allow to mute a set of alerts given that another alert is
# firing.
# We use this to mute any warning-level notifications if the same alert is
# already critical.
inhibit_rules:
- source_matchers:
    - severity="critical"
  target_matchers:
    - severity="warning"
  # Apply inhibition if the alertname is the same.
  # CAUTION: 
  #   If all label names listed in `equal` are missing 
  #   from both the source and target alerts,
  #   the inhibition rule will apply!
  equal: ['alertname']


receivers:
- name: 'team-X-mails'
  email_configs:
  - to: 'team-X+alerts@example.org, team-Y+alerts@example.org'

- name: 'team-X-pager'
  email_configs:
  - to: 'team-X+alerts-critical@example.org'
  pagerduty_configs:
  - routing_key: &amp;lt;team-X-key&amp;gt;

- name: 'team-Y-mails'
  email_configs:
  - to: 'team-Y+alerts@example.org'

- name: 'team-Y-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-Y-key&amp;gt;

- name: 'team-DB-pager'
  pagerduty_configs:
  - routing_key: &amp;lt;team-DB-key&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;p&gt;The current Alertmanager API is version 2. This API is fully generated via the &lt;a href="https://github.com/OAI/OpenAPI-Specification/raw/master/versions/2.0.md"&gt;OpenAPI project&lt;/a&gt; and &lt;a href="https://github.com/go-swagger/go-swagger/"&gt;Go Swagger&lt;/a&gt; with the exception of the HTTP handlers themselves. The API specification can be found in &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;api/v2/openapi.yaml&lt;/a&gt;. A HTML rendered version can be accessed &lt;a href="http://petstore.swagger.io/?url=https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml"&gt;here&lt;/a&gt;. Clients can be easily generated via any OpenAPI generator for all major languages.&lt;/p&gt; 
&lt;p&gt;APIv2 is accessed via the &lt;code&gt;/api/v2&lt;/code&gt; prefix. APIv1 was deprecated in &lt;code&gt;0.16.0&lt;/code&gt; and is removed as of version &lt;code&gt;0.27.0&lt;/code&gt;. The v2 &lt;code&gt;/status&lt;/code&gt; endpoint would be &lt;code&gt;/api/v2/status&lt;/code&gt;. If &lt;code&gt;--web.route-prefix&lt;/code&gt; is set then API routes are prefixed with that as well, so &lt;code&gt;--web.route-prefix=/alertmanager/&lt;/code&gt; would relate to &lt;code&gt;/alertmanager/api/v2/status&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;amtool&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; is a cli tool for interacting with the Alertmanager API. It is bundled with all releases of Alertmanager.&lt;/p&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;p&gt;Alternatively you can install with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ go install github.com/prometheus/alertmanager/cmd/amtool@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Examples&lt;/h3&gt; 
&lt;p&gt;View all currently firing alerts:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool alert
Alertname        Starts At                Summary
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View all currently firing alerts with extended output:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In addition to viewing alerts, you can use the rich query syntax provided by Alertmanager:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool -o extended alert query alertname="Test_Alert"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node0"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query instance=~".+1"
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"       link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname="Check_Foo_Fails" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query alertname=~"Test.*" instance=~".+1"
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname="Test_Alert" instance="node1"  link="https://example.com" summary="This is a testing alert!"  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Silence an alert:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence add alertname=Test_Alert
b3ede22e-ca14-4aa0-932c-ca2f3445f926

$ amtool silence add alertname="Test_Alert" instance=~".+0"
e48cb58a-0b17-49ba-b734-3585139b1d25
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;View silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query
ID                                    Matchers              Ends At                  Created By  Comment
b3ede22e-ca14-4aa0-932c-ca2f3445f926  alertname=Test_Alert  2017-08-02 19:54:50 UTC  kellel

$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire a silence:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire b3ede22e-ca14-4aa0-932c-ca2f3445f926
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences matching a query:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence query instance=~".+0"
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel

$ amtool silence expire $(amtool silence query -q instance=~".+0")

$ amtool silence query instance=~".+0"

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Expire all silences:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ amtool silence expire $(amtool silence query -q)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Try out how a template works. Let's say you have this in your configuration file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;templates:
  - '/foo/bar/*.tmpl'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can test out how a template would look like with example by using this command:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;amtool template render --template.glob='/foo/bar/*.tmpl' --template.text='{{ template "slack.default.markdown.v1" . }}'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows a configuration file to specify some options for convenience. The default configuration file paths are &lt;code&gt;$HOME/.config/amtool/config.yml&lt;/code&gt; or &lt;code&gt;/etc/amtool/config.yml&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;An example configuration file might look like the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Define the path that `amtool` can find your `alertmanager` instance
alertmanager.url: "http://localhost:9093"

# Override the default author. (unset defaults to your username)
author: me@example.com

# Force amtool to give you an error if you don't include a comment on a silence
comment_required: true

# Set a default output format. (unset defaults to simple)
output: extended

# Set a default receiver
receiver: team-X-pager
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Routes&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;amtool&lt;/code&gt; allows you to visualize the routes of your configuration in form of text tree view. Also you can use it to test the routing by passing it label set of an alert and it prints out all receivers the alert would match ordered and separated by &lt;code&gt;,&lt;/code&gt;. (If you use &lt;code&gt;--verify.receivers&lt;/code&gt; amtool returns error code 1 on mismatch)&lt;/p&gt; 
&lt;p&gt;Example of usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# View routing tree of remote Alertmanager
$ amtool config routes --alertmanager.url=http://localhost:9090

# Test if alert matches expected receiver
$ amtool config routes test --config.file=doc/examples/simple.yml --tree --verify.receivers=team-X-pager service=database owner=team-X
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;High Availability&lt;/h2&gt; 
&lt;p&gt;Alertmanager's high availability is in production use at many companies and is enabled by default.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Both UDP and TCP are needed in alertmanager 0.15 and higher for the cluster to work.&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;If you are using a firewall, make sure to whitelist the clustering port for both protocols.&lt;/li&gt; 
  &lt;li&gt;If you are running in a container, make sure to expose the clustering port for both protocols.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;To create a highly available cluster of the Alertmanager the instances need to be configured to communicate with each other. This is configured using the &lt;code&gt;--cluster.*&lt;/code&gt; flags.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.listen-address&lt;/code&gt; string: cluster listen address (default "0.0.0.0:9094"; empty string disables HA mode)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.advertise-address&lt;/code&gt; string: cluster advertise address&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer&lt;/code&gt; value: initial peers (repeat flag for each additional peer)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.peer-timeout&lt;/code&gt; value: peer timeout period (default "15s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.gossip-interval&lt;/code&gt; value: cluster message propagation speed (default "200ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.pushpull-interval&lt;/code&gt; value: lower values will increase convergence speeds at expense of bandwidth (default "1m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.settle-timeout&lt;/code&gt; value: maximum time to wait for cluster connections to settle before evaluating notifications.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.tcp-timeout&lt;/code&gt; value: timeout value for tcp connections, reads and writes (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-timeout&lt;/code&gt; value: time to wait for ack before marking node unhealthy (default "500ms")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.probe-interval&lt;/code&gt; value: interval between random node probes (default "1s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-interval&lt;/code&gt; value: interval between attempting to reconnect to lost peers (default "10s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.reconnect-timeout&lt;/code&gt; value: length of time to attempt to reconnect to a lost peer (default: "6h0m0s")&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;--cluster.label&lt;/code&gt; value: the label is an optional string to include on each packet and stream. It uniquely identifies the cluster and prevents cross-communication issues when sending gossip messages (default:"")&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The chosen port in the &lt;code&gt;cluster.listen-address&lt;/code&gt; flag is the port that needs to be specified in the &lt;code&gt;cluster.peer&lt;/code&gt; flag of the other peers.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;cluster.advertise-address&lt;/code&gt; flag is required if the instance doesn't have an IP address that is part of &lt;a href="https://tools.ietf.org/html/rfc6890"&gt;RFC 6890&lt;/a&gt; with a default route.&lt;/p&gt; 
&lt;p&gt;To start a cluster of three peers on your local machine use &lt;a href="https://github.com/mattn/goreman"&gt;&lt;code&gt;goreman&lt;/code&gt;&lt;/a&gt; and the Procfile within this repository.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;goreman start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To point your Prometheus 1.4, or later, instance to multiple Alertmanagers, configure them in your &lt;code&gt;prometheus.yml&lt;/code&gt; configuration file, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager1:9093
      - alertmanager2:9093
      - alertmanager3:9093
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Important: Do not load balance traffic between Prometheus and its Alertmanagers, but instead point Prometheus to a list of all Alertmanagers. The Alertmanager implementation expects all alerts to be sent to all Alertmanagers to ensure high availability.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Turn off high availability&lt;/h3&gt; 
&lt;p&gt;If running Alertmanager in high availability mode is not desired, setting &lt;code&gt;--cluster.listen-address=&lt;/code&gt; prevents Alertmanager from listening to incoming peer requests.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Check the &lt;a href="https://github.com/prometheus/prometheus/raw/main/CONTRIBUTING.md"&gt;Prometheus contributing page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To contribute to the user interface, refer to &lt;a href="https://raw.githubusercontent.com/prometheus/alertmanager/main/ui/app/CONTRIBUTING.md"&gt;ui/app/CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/prometheus/alertmanager/main/doc/arch.svg?sanitize=true" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Apache License 2.0, see &lt;a href="https://github.com/prometheus/alertmanager/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>pocketbase/pocketbase</title>
      <link>https://github.com/pocketbase/pocketbase</link>
      <description>&lt;p&gt;Open Source realtime backend in 1 file&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://pocketbase.io" target="_blank" rel="noopener"&gt; &lt;img src="https://i.imgur.com/5qimnm5.png" alt="PocketBase - open source backend in 1 file" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/pocketbase/pocketbase/actions/workflows/release.yaml" target="_blank" rel="noopener"&gt;&lt;img src="https://github.com/pocketbase/pocketbase/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/pocketbase/pocketbase/releases" target="_blank" rel="noopener"&gt;&lt;img src="https://img.shields.io/github/release/pocketbase/pocketbase.svg?sanitize=true" alt="Latest releases" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/pocketbase/pocketbase" target="_blank" rel="noopener"&gt;&lt;img src="https://godoc.org/github.com/pocketbase/pocketbase?status.svg?sanitize=true" alt="Go package documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pocketbase.io"&gt;PocketBase&lt;/a&gt; is an open source Go backend that includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;embedded database (&lt;em&gt;SQLite&lt;/em&gt;) with &lt;strong&gt;realtime subscriptions&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;built-in &lt;strong&gt;files and users management&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;convenient &lt;strong&gt;Admin dashboard UI&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;and simple &lt;strong&gt;REST-ish API&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;For documentation and examples, please visit &lt;a href="https://pocketbase.io/docs"&gt;https://pocketbase.io/docs&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Please keep in mind that PocketBase is still under active development and therefore full backward compatibility is not guaranteed before reaching v1.0.0.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;API SDK clients&lt;/h2&gt; 
&lt;p&gt;The easiest way to interact with the PocketBase Web APIs is to use one of the official SDK clients:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;JavaScript - &lt;a href="https://github.com/pocketbase/js-sdk"&gt;pocketbase/js-sdk&lt;/a&gt;&lt;/strong&gt; (&lt;em&gt;Browser, Node.js, React Native&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dart - &lt;a href="https://github.com/pocketbase/dart-sdk"&gt;pocketbase/dart-sdk&lt;/a&gt;&lt;/strong&gt; (&lt;em&gt;Web, Mobile, Desktop, CLI&lt;/em&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You could also check the recommendations in &lt;a href="https://pocketbase.io/docs/how-to-use/"&gt;https://pocketbase.io/docs/how-to-use/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;h3&gt;Use as standalone app&lt;/h3&gt; 
&lt;p&gt;You could download the prebuilt executable for your platform from the &lt;a href="https://github.com/pocketbase/pocketbase/releases"&gt;Releases page&lt;/a&gt;. Once downloaded, extract the archive and run &lt;code&gt;./pocketbase serve&lt;/code&gt; in the extracted directory.&lt;/p&gt; 
&lt;p&gt;The prebuilt executables are based on the &lt;a href="https://github.com/pocketbase/pocketbase/raw/master/examples/base/main.go"&gt;&lt;code&gt;examples/base/main.go&lt;/code&gt; file&lt;/a&gt; and comes with the JS VM plugin enabled by default which allows to extend PocketBase with JavaScript (&lt;em&gt;for more details please refer to &lt;a href="https://pocketbase.io/docs/js-overview/"&gt;Extend with JavaScript&lt;/a&gt;&lt;/em&gt;).&lt;/p&gt; 
&lt;h3&gt;Use as a Go framework/toolkit&lt;/h3&gt; 
&lt;p&gt;PocketBase is distributed as a regular Go library package which allows you to build your own custom app specific business logic and still have a single portable executable at the end.&lt;/p&gt; 
&lt;p&gt;Here is a minimal example:&lt;/p&gt; 
&lt;ol start="0"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://go.dev/doc/install"&gt;Install Go 1.23+&lt;/a&gt; (&lt;em&gt;if you haven't already&lt;/em&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create a new project directory with the following &lt;code&gt;main.go&lt;/code&gt; file inside it:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "log"

    "github.com/pocketbase/pocketbase"
    "github.com/pocketbase/pocketbase/core"
)

func main() {
    app := pocketbase.New()

    app.OnServe().BindFunc(func(se *core.ServeEvent) error {
        // registers new "GET /hello" route
        se.Router.GET("/hello", func(re *core.RequestEvent) error {
            return re.String(200, "Hello world!")
        })

        return se.Next()
    })

    if err := app.Start(); err != nil {
        log.Fatal(err)
    }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To init the dependencies, run &lt;code&gt;go mod init myapp &amp;amp;&amp;amp; go mod tidy&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To start the application, run &lt;code&gt;go run main.go serve&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To build a statically linked executable, you can run &lt;code&gt;CGO_ENABLED=0 go build&lt;/code&gt; and then start the created executable with &lt;code&gt;./myapp serve&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;em&gt;For more details please refer to &lt;a href="https://pocketbase.io/docs/go-overview/"&gt;Extend with Go&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Building and running the repo main.go example&lt;/h3&gt; 
&lt;p&gt;To build the minimal standalone executable, like the prebuilt ones in the releases page, you can simply run &lt;code&gt;go build&lt;/code&gt; inside the &lt;code&gt;examples/base&lt;/code&gt; directory:&lt;/p&gt; 
&lt;ol start="0"&gt; 
 &lt;li&gt;&lt;a href="https://go.dev/doc/install"&gt;Install Go 1.23+&lt;/a&gt; (&lt;em&gt;if you haven't already&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;Clone/download the repo&lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;examples/base&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build&lt;/code&gt; (&lt;em&gt;&lt;a href="https://go.dev/doc/install/source#environment"&gt;https://go.dev/doc/install/source#environment&lt;/a&gt;&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;Start the created executable by running &lt;code&gt;./base serve&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Note that the supported build targets by the pure Go SQLite driver at the moment are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;darwin  amd64
darwin  arm64
freebsd amd64
freebsd arm64
linux   386
linux   amd64
linux   arm
linux   arm64
linux   loong64
linux   ppc64le
linux   riscv64
linux   s390x
windows 386
windows amd64
windows arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing&lt;/h3&gt; 
&lt;p&gt;PocketBase comes with mixed bag of unit and integration tests. To run them, use the standard &lt;code&gt;go test&lt;/code&gt; command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go test ./...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check also the &lt;a href="http://pocketbase.io/docs/testing"&gt;Testing guide&lt;/a&gt; to learn how to write your own custom application tests.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you discover a security vulnerability within PocketBase, please send an e-mail to &lt;strong&gt;support at pocketbase.io&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;All reports will be promptly addressed and you'll be credited in the fix release notes.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;PocketBase is free and open source project licensed under the &lt;a href="https://raw.githubusercontent.com/pocketbase/pocketbase/master/LICENSE.md"&gt;MIT License&lt;/a&gt;. You are free to do whatever you want with it, even offering it as a paid service.&lt;/p&gt; 
&lt;p&gt;You could help continuing its development by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pocketbase/pocketbase/master/CONTRIBUTING.md"&gt;Contribute to the source code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pocketbase/pocketbase/issues"&gt;Suggest new features and report issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PRs for new OAuth2 providers, bug fixes, code optimizations and documentation improvements are more than welcome.&lt;/p&gt; 
&lt;p&gt;But please refrain creating PRs for &lt;em&gt;new features&lt;/em&gt; without previously discussing the implementation details. PocketBase has a &lt;a href="https://github.com/orgs/pocketbase/projects/2"&gt;roadmap&lt;/a&gt; and I try to work on issues in specific order and such PRs often come in out of nowhere and skew all initial planning with tedious back-and-forth communication.&lt;/p&gt; 
&lt;p&gt;Don't get upset if I close your PR, even if it is well executed and tested. This doesn't mean that it will never be merged. Later we can always refer to it and/or take pieces of your implementation when the time comes to work on the issue (don't worry you'll be credited in the release notes).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dagger/dagger</title>
      <link>https://github.com/dagger/dagger</link>
      <description>&lt;p&gt;An open-source runtime for composable workflows. Great for AI agents and CI/CD.&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;What is Dagger?&lt;/h2&gt; 
&lt;p&gt;Dagger is an open-source runtime for composable workflows. It's perfect for systems with many moving parts and a strong need for &lt;strong&gt;repeatability&lt;/strong&gt;, &lt;strong&gt;modularity&lt;/strong&gt;, &lt;strong&gt;observability&lt;/strong&gt; and &lt;strong&gt;cross-platform support&lt;/strong&gt;. This makes it a great choice for AI agents and CI/CD workflows.&lt;/p&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/dagger/dagger/main/docs/static/img/readme/dagger-factory.jpg" width="75%" /&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Containerized Workflow Execution:&lt;/strong&gt; Transform code into containerized, composable operations. Build reproducible workflows in any language with custom environments, parallel processing, and seamless chaining.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Universal Type System:&lt;/strong&gt; Mix and match components from any language with type-safe connections. Use the best tools from each ecosystem without translation headaches.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic Artifact Caching:&lt;/strong&gt; Operations produce cacheable, immutable artifacts ‚Äî even for LLMs and API calls. Your workflows run faster and cost less.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Built-in Observability:&lt;/strong&gt; Full visibility into operations with tracing, logs, and metrics. Debug complex workflows and know exactly what's happening.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/dagger/dagger/main/docs/static/img/readme/cloud-trace.gif" width="60%" /&gt; &lt;/p&gt;
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Open Platform:&lt;/strong&gt; Works with any compute platform and tech stack ‚Äî today and tomorrow. Ship faster, experiment freely, and don‚Äôt get locked into someone else's choices.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LLM Augmentation:&lt;/strong&gt; Native integration of any LLM that automatically discovers and uses available functions in your workflow. Ship mind-blowing agents in just a few dozen lines of code.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Interactive Terminal:&lt;/strong&gt; Directly interact with your workflow or agents in real-time through your terminal. Prototype, test, debug, and ship even faster.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt;&lt;img src="https://raw.githubusercontent.com/dagger/dagger/main/docs/static/img/readme/da-robots-white-box.svg?sanitize=true" width="60%" /&gt; &lt;/p&gt;
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.dagger.io/ai-agents"&gt;Dagger for AI Agents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.dagger.io/quickstart"&gt;Dagger for CI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Join the community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join the &lt;a href="https://discord.gg/NpzVhsGnZu"&gt;Dagger community server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow us on &lt;a href="https://twitter.com/dagger_io"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Check out our &lt;a href="https://dagger.io/community"&gt;community activities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Read more in our &lt;a href="https://docs.dagger.io"&gt;documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Interested in contributing or building dagger from scratch? See &lt;a href="https://github.com/dagger/dagger/tree/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>litmuschaos/litmus</title>
      <link>https://github.com/litmuschaos/litmus</link>
      <description>&lt;p&gt;Litmus helps SREs and developers practice chaos engineering in a Cloud-native way. Chaos experiments are published at the ChaosHub (https://hub.litmuschaos.io). Community notes is at https://hackmd.io/a4Zu_sH4TZGeih-xCimi3Q&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;a href="https://litmuschaos.io/"&gt;LitmusChaos&lt;/a&gt;&lt;/h1&gt; 
&lt;img alt="LitmusChaos" src="https://avatars.githubusercontent.com/u/49853472?s=200&amp;amp;v=4" width="200" align="left" /&gt; 
&lt;h3&gt;Open Source Chaos Engineering Platform&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://slack.litmuschaos.io"&gt;&lt;img src="https://img.shields.io/badge/Slack-Join-purple" alt="Slack Channel" /&gt;&lt;/a&gt; &lt;img src="https://github.com/litmuschaos/litmus/actions/workflows/push.yml/badge.svg?branch=master" alt="GitHub Workflow" /&gt; &lt;a href="https://hub.docker.com/r/litmuschaos/chaos-operator"&gt;&lt;img src="https://img.shields.io/docker/pulls/litmuschaos/chaos-operator.svg?sanitize=true" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/litmuschaos/litmus/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/litmuschaos/litmus?style=social" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://github.com/litmuschaos/litmus/issues"&gt;&lt;img src="https://img.shields.io/github/issues/litmuschaos/litmus" alt="GitHub issues" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/LitmusChaos"&gt;&lt;img src="https://img.shields.io/twitter/follow/litmuschaos?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/3202"&gt;&lt;img src="https://www.bestpractices.dev/projects/3202/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.io/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus?ref=badge_shield"&gt;&lt;img src="https://app.fossa.io/api/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/channel/UCa57PMqmz_j0wnteRa9nCaw"&gt;&lt;img src="https://img.shields.io/badge/YouTube-Subscribe-red" alt="YouTube Channel" /&gt;&lt;/a&gt; &lt;a href="https://gurubase.io/g/litmuschaos"&gt;&lt;img src="https://img.shields.io/badge/Gurubase-Ask%20LitmusChaos%20Guru-006BFF" alt="Gurubase" /&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;h4&gt;&lt;em&gt;Read this in &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/TRANSLATIONS.md"&gt;other languages&lt;/a&gt;.&lt;/em&gt;&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-ko.md"&gt;üá∞üá∑&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-chn.md"&gt;üá®üá≥&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-pt-br.md"&gt;üáßüá∑&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/translations/README-hi.md"&gt;üáÆüá≥&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;LitmusChaos is an open source Chaos Engineering platform that enables teams to identify weaknesses &amp;amp; potential outages in infrastructures by inducing chaos tests in a controlled way. Developers &amp;amp; SREs can practice Chaos Engineering with LitmusChaos as it is easy to use, based on modern Chaos Engineering principles &amp;amp; community collaborated. It is 100% open source &amp;amp; a CNCF project.&lt;/p&gt; 
&lt;p&gt;LitmusChaos takes a cloud-native approach to create, manage and monitor chaos. The platform itself runs as a set of microservices and uses Kubernetes custom resources (CRs) to define the chaos intent, as well as the steady state hypothesis.&lt;/p&gt; 
&lt;p&gt;At a high-level, Litmus comprises of:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Chaos Control Plane&lt;/strong&gt;: A centralized chaos management tool called chaos-center, which helps construct, schedule and visualize Litmus chaos workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chaos Execution Plane Services&lt;/strong&gt;: Made up of a chaos agent and multiple operators that execute &amp;amp; monitor the experiment within a defined target Kubernetes environment.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/litmuschaos/litmus/master/images/litmus-control-and-execution-plane-overview.png" alt="architecture summary" /&gt;&lt;/p&gt; 
&lt;p&gt;At the heart of the platform are the following chaos custom resources:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ChaosExperiment&lt;/strong&gt;: A resource to group the configuration parameters of a particular fault. ChaosExperiment CRs are essentially installable templates that describe the library carrying out the fault, indicate permissions needed to run it &amp;amp; the defaults it will operate with. Through the ChaosExperiment, Litmus supports BYOC (bring-your-own-chaos) that helps integrate (optional) any third-party tooling to perform the fault injection.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;ChaosEngine&lt;/strong&gt;: A resource to link a Kubernetes application workload/service, node or an infra component to a fault described by the ChaosExperiment. It also provides options to tune the run properties and specify the steady state validation constraints using 'probes'. ChaosEngine is watched by the Chaos-Operator, which reconciles it (triggers experiment execution) via runners.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The ChaosExperiment &amp;amp; ChaosEngine CRs are embedded within a Workflow object that can string together one or more experiments in a desired order.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ChaosResult&lt;/strong&gt;: A resource to hold the results of the experiment run. It provides details of the success of each validation constraint, the revert/rollback status of the fault as well as a verdict. The Chaos-exporter reads the results and exposes information as prometheus metrics. ChaosResults are especially useful during automated runs.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;ChaosExperiment CRs are hosted on &lt;a href="https://hub.litmuschaos.io" target="_blank"&gt;hub.litmuschaos.io&lt;/a&gt;. It is a central hub where the application developers or vendors share their chaos experiments so that their users can use them to increase the resilience of the applications in production.&lt;/p&gt; 
&lt;h2&gt;Use cases&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;For Developers&lt;/strong&gt;: To run chaos experiments during application development as an extension of unit testing or integration testing.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For CI/CD pipeline builders&lt;/strong&gt;: To run chaos as a pipeline stage to find bugs when the application is subjected to fail paths in a pipeline.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;For SREs&lt;/strong&gt;: To plan and schedule chaos experiments into the application and/or surrounding infrastructure. This practice identifies the weaknesses in the deployment system and increases resilience.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started with Litmus&lt;/h2&gt; 
&lt;p&gt;To get started, check out the &lt;a href="https://docs.litmuschaos.io/docs/introduction/what-is-litmus" target="_blank"&gt;Litmus Docs&lt;/a&gt; and specifically the &lt;a href="https://docs.litmuschaos.io/docs/getting-started/installation#prerequisites" target="_blank"&gt;Installation section&lt;/a&gt; of the &lt;a href="https://docs.litmuschaos.io/docs/getting-started/installation" target="_blank"&gt;Getting Started with Litmus&lt;/a&gt; page.&lt;/p&gt; 
&lt;h2&gt;Contributing to Chaos Hub&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/litmuschaos/community-charts/raw/master/CONTRIBUTING.md" target="_blank"&gt;Contributing Guidelines for the Chaos Hub&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;h3&gt;Community Resources:&lt;/h3&gt; 
&lt;p&gt;Feel free to reach out if you have any queries,concerns, or feature requests&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Give us a star ‚≠êÔ∏è - If you are using LitmusChaos or think it is an interesting project, we would love a star ‚ù§Ô∏è&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Follow LitmusChaos on Twitter &lt;a href="https://twitter.com/LitmusChaos"&gt;@LitmusChaos&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Subscribe to the &lt;a href="https://www.youtube.com/channel/UCa57PMqmz_j0wnteRa9nCaw"&gt;LitmusChaos YouTube channel&lt;/a&gt; for regular updates &amp;amp; meeting recordings.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To join our &lt;a href="https://slack.litmuschaos.io/"&gt;Slack Community&lt;/a&gt; and meet our community members, put forward your questions &amp;amp; opinions, join the #litmus channel on the &lt;a href="https://slack.k8s.io/"&gt;Kubernetes Slack&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Community Meetings&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Community Meetings&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;These will be hosted every 3rd Wednesday of every month at 5:30 PM GMT /6:30 PM CEST /10 PM IST&lt;/li&gt; 
 &lt;li&gt;These meetings cover community updates, new feature or release announcements, and user/adopter stories. Everyone in the community is welcome to join and participate in discussions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Contributor Meetings&lt;/li&gt; 
&lt;/ol&gt; 
&lt;ul&gt; 
 &lt;li&gt;These will be hosted every second &amp;amp; last Thursday of every month at 2:30 PM GMT /3:30 PM CEST /7 PM IST&lt;/li&gt; 
 &lt;li&gt;These meetings focus on both technical and non-technical contributions to LitmusChaos. Maintainers, current contributors, and aspiring contributors are encouraged to join to discuss issues, fixes, enhancements, and future contributions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Fill out the &lt;a href="https://forms.gle/qawjtFUeL431jmpv7"&gt;LitmusChaos Meetings invite form&lt;/a&gt; to get your Calendar invite!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://hackmd.io/a4Zu_sH4TZGeih-xCimi3Q"&gt;Sync Up Agenda &amp;amp; Meeting Notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/litmuschaos/litmus/milestones"&gt;Release Tracker&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Videos&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=3mjGEh905u4&amp;amp;t=1s"&gt;What if Your System Experiences an Outage? Let's Build a Resilient Systems with Chaos Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/BelNIk4Bkng"&gt;Enhancing Cyber Resilience Through Zero Trust Chaos Experiments in Cloud Native Environments&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ks2R57hhFZk&amp;amp;t=503s"&gt;LitmusChaos, with Karthik Satchitanand&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@TheKubernetesPodcast"&gt;The Kubernetes Podcast from Google&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=WUXFKxgZRsk"&gt;Cultural Shifts: Fostering a Chaos First Mindset in Platform Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=xCDQp5E3VUs"&gt;Fire in the Cloud: Bringing Managed Services Under the Ambit of Cloud-Native Chaos Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=whCkvLKAw74"&gt;Security Controls for Safe Chaos Experimentation&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=BZL-ngvbpbU&amp;amp;t=751s"&gt;Chaos Engineering For Hybrid Targets With LitmusChaos&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/hOghvd9qCzI"&gt;Cloud Native Live: Litmus Chaos Engine and a microservices demo app&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/_x_7SiesjF0"&gt;Chaos Engineering hands-on - An SRE ideating Chaos Experiments and using LitmusChaos | July 2022&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/PQrmBHgk0ps"&gt;Achieve Digital Product Resiliency with Chaos Engineering&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/KSl-oKk6TPA"&gt;Case Study: Bringing Chaos Engineering to the Cloud Native Developers&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ItUUqejdXr0"&gt;Cloud Native Chaos Engineering with LitmusChaos&lt;/a&gt; @ &lt;a href="https://www.youtube.com/@cncf"&gt;CNCF&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/mwu5eLgUKq4"&gt;How to create Chaos Experiments with Litmus | Litmus Chaos tutorial&lt;/a&gt; @ &lt;a href="https://www.youtube.com/c/IsitObservable"&gt;Is it Observable&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/pMWqhS-F3tQ"&gt;Cloud Native Chaos Engineering Preview With LitmusChaos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/5CI8d-SKBfc"&gt;Get started with Chaos Engineering with Litmus&lt;/a&gt; @ &lt;a href="https://www.youtube.com/c/ContainersfromtheCouch"&gt;Containers from the Couch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/B8DfYnDh2F4"&gt;Litmus 2 - Chaos Engineering Meets Argo Workflows&lt;/a&gt; @ &lt;a href="https://youtube.com/c/devopstoolkit"&gt;DevOps Toolkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/D0t3emVLLko"&gt;Hands-on with Litmus 2.0 | Rawkode Live&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCrber_mFvp_FEF7D9u8PDEA"&gt;Rawkode Academy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/97BiCNtJbDw"&gt;Introducing LitmusChaos 2.0 / Dok Talks #74&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCUnXJbHQ89R2uSfKsqQwGvQ"&gt;DoK.community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/LK0oDLQE4S8"&gt;Introduction to Cloud Native Chaos Engineering&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCBGOUQHNNtNGcGzVq5rIXjw"&gt;Kunal Kushwaha&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/IiyrEiK4stQ"&gt;#EveryoneCanContribute cafe: Litmus - Chaos Engineering for your Kubernetes&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCMtZ0sc1HHNtGGWZFDRTh5A"&gt;GitLab Unfiltered&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/rDQ9XKbSJIc"&gt;Litmus - Chaos Engineering for Kubernetes (CNCFMinutes 9)&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UCi-1nnN0eC9nRleXdZA6ncg"&gt;Saiyam Pathak&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/eyAG0svCsQA"&gt;Chaos Engineering with Litmus Chaos by Prithvi Raj || HACKODISHA Workshop&lt;/a&gt; @ &lt;a href="https://www.youtube.com/channel/UC9yM_PkV0QIIsPA3qPrp"&gt;Webwiz&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/channel/UCa57PMqmz_j0wnteRa9nCaw"&gt;And More....&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Blogs&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CNCF: &lt;a href="https://www.cncf.io/blog/2020/08/28/introduction-to-litmuschaos/"&gt;Introduction to LitmusChaos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Hackernoon: &lt;a href="https://hackernoon.com/solid-tips-on-how-to-manage-and-monitor-chaos-via-litmus-custom-resources-5g1s33m9"&gt;Manage and Monitor Chaos via Litmus Custom Resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://dev.to/ksatchit/observability-considerations-in-chaos-the-metrics-story-6cb"&gt;Observability Considerations in Chaos: The Metrics Story&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Community Blogs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;LiveWyer: &lt;a href="https://livewyer.io/blog/2021/03/22/litmuschaos-showcase-chaos-experiments-in-a-helm-chart-test-suite/"&gt;LitmusChaos Showcase: Chaos Experiments in a Helm Chart Test Suite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Jessica Cherry: &lt;a href="https://opensource.com/article/21/6/kubernetes-litmus-chaos"&gt;Test Kubernetes cluster failures and experiments in your terminal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Yang Chuansheng(KubeSphere): &lt;a href="https://kubesphere.io/zh/blogs/litmus-kubesphere/"&gt;KubeSphere ÈÉ®ÁΩ≤ Litmus Ëá≥ Kubernetes ÂºÄÂêØÊ∑∑Ê≤åÂÆûÈ™å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Saiyam Pathak(Civo): &lt;a href="https://www.civo.com/learn/chaos-engineering-kubernetes-litmus"&gt;Chaos Experiments on Kubernetes using Litmus to ensure your cluster is production ready&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Andreas Krivas(Container Solutions):&lt;a href="https://blog.container-solutions.com/comparing-chaos-engineering-tools"&gt;Comparing Chaos Engineering Tools for Kubernetes Workloads&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Akram Riahi(WeScale):&lt;a href="https://blog.wescale.fr/2021/03/11/chaos-engineering-litmus-sous-tous-les-angles/"&gt;Chaos Engineering : Litmus sous tous les angles&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Prashanto Priyanshu(LensKart):&lt;a href="https://blog.lenskart.com/lenskarts-approach-to-chaos-engineering-part-2-6290e4f3a74e"&gt;Lenskart‚Äôs approach to Chaos Engineering-Part 2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;DevsDay.ru(Russian):&lt;a href="https://devsday.ru/blog/details/40746"&gt;LitmusChaos at Kubecon EU '21&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/litmuschaos/litmus/raw/master/ADOPTERS.md" target="_blank"&gt;Adopters of LitmusChaos&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;(&lt;em&gt;Send a PR to the above page if you are using Litmus in your chaos engineering practice&lt;/em&gt;)&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Litmus is licensed under the Apache License, Version 2.0. See &lt;a href="https://raw.githubusercontent.com/litmuschaos/litmus/master/LICENSE"&gt;LICENSE&lt;/a&gt; for the full license text. Some of the projects used by the Litmus project may be governed by a different license, please refer to its specific license.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.io/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus?ref=badge_large"&gt;&lt;img src="https://app.fossa.io/api/projects/git%2Bgithub.com%2Flitmuschaos%2Flitmus.svg?type=large" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Litmus Chaos is part of the CNCF Projects.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://landscape.cncf.io/?selected=litmus"&gt;&lt;img src="https://github.com/cncf/artwork/raw/main/other/cncf/horizontal/color/cncf-color.png" alt="CNCF" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Important Links&lt;/h2&gt; 
&lt;a href="https://docs.litmuschaos.io"&gt; Litmus Docs &lt;img src="https://avatars0.githubusercontent.com/u/49853472?s=200&amp;amp;v=4" alt="Litmus Docs" height="15" /&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;a href="https://landscape.cncf.io/?selected=litmus"&gt; CNCF Landscape &lt;img src="https://landscape.cncf.io/images/cncf-landscape-horizontal-color.svg?sanitize=true" alt="Litmus on CNCF Landscape" height="15" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>argoproj/argo-cd</title>
      <link>https://github.com/argoproj/argo-cd</link>
      <description>&lt;p&gt;Declarative Continuous Deployment for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;Releases:&lt;/strong&gt; &lt;a href="https://github.com/argoproj/argo-cd/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/argoproj/argo-cd?label=argo-cd" alt="Release Version" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/helm/argo/argo-cd"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-cd" alt="Artifact HUB" /&gt;&lt;/a&gt; &lt;a href="https://slsa.dev"&gt;&lt;img src="https://slsa.dev/images/gh-badge-level3.svg?sanitize=true" alt="SLSA 3" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Code:&lt;/strong&gt; &lt;a href="https://github.com/argoproj/argo-cd/actions?query=workflow%3A%22Integration+tests%22"&gt;&lt;img src="https://github.com/argoproj/argo-cd/workflows/Integration%20tests/badge.svg?branch=master" alt="Integration tests" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/argoproj/argo-cd"&gt;&lt;img src="https://codecov.io/gh/argoproj/argo-cd/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/4486"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/4486/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/argoproj/argo-cd"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/argoproj/argo-cd/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Social:&lt;/strong&gt; &lt;a href="https://twitter.com/argoproj"&gt;&lt;img src="https://img.shields.io/twitter/follow/argoproj?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://argoproj.github.io/community/join-slack"&gt;&lt;img src="https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/argoproj/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin" alt="LinkedIn" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Argo CD - Declarative Continuous Delivery for Kubernetes&lt;/h1&gt; 
&lt;h2&gt;What is Argo CD?&lt;/h2&gt; 
&lt;p&gt;Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/argoproj/argo-cd/master/docs/assets/argocd-ui.gif" alt="Argo CD UI" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/0WAm0y2vLIo"&gt;&lt;img src="https://img.youtube.com/vi/0WAm0y2vLIo/0.jpg" alt="Argo CD Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why Argo CD?&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Application definitions, configurations, and environments should be declarative and version controlled.&lt;/li&gt; 
 &lt;li&gt;Application deployment and lifecycle management should be automated, auditable, and easy to understand.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Who uses Argo CD?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/argoproj/argo-cd/master/USERS.md"&gt;Official Argo CD user list&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;To learn more about Argo CD &lt;a href="https://argo-cd.readthedocs.io/"&gt;go to the complete documentation&lt;/a&gt;. Check live demo at &lt;a href="https://cd.apps.argoproj.io/"&gt;https://cd.apps.argoproj.io/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;h3&gt;Contribution, Discussion and Support&lt;/h3&gt; 
&lt;p&gt;You can reach the Argo CD community and developers via the following channels:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Q &amp;amp; A : &lt;a href="https://github.com/argoproj/argo-cd/discussions"&gt;Github Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Chat : &lt;a href="https://argoproj.github.io/community/join-slack"&gt;The #argo-cd Slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Contributors Office Hours: &lt;a href="https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com"&gt;Every Thursday&lt;/a&gt; | &lt;a href="https://docs.google.com/document/d/1xkoFkVviB70YBzSEa4bDnu-rUZ1sIFtwKKG1Uw8XsY8"&gt;Agenda&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;User Community meeting: &lt;a href="https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com"&gt;First Wednesday of the month&lt;/a&gt; | &lt;a href="https://docs.google.com/document/d/1ttgw98MO45Dq7ZUHpIiOIEfbyeitKHNfMjbY5dLLMKQ"&gt;Agenda&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Participation in the Argo CD project is governed by the &lt;a href="https://github.com/cncf/foundation/raw/master/code-of-conduct.md"&gt;CNCF Code of Conduct&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Blogs and Presentations&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/terrytangyuan/awesome-argo"&gt;Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://akuity.io/blog/secret-ingredients-of-continuous-delivery-at-enterprise-scale-with-argocd/"&gt;Unveil the Secret Ingredients of Continuous Delivery at Enterprise Scale with Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/avPUQin9kzU"&gt;GitOps Without Pipelines With ArgoCD Image Updater&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/eEcgn_gU3SM"&gt;Combining Argo CD (GitOps), Crossplane (Control Plane), And KubeVela (OAM)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/yrj4lmScKHQ"&gt;How to Apply GitOps to Everything - Combining Argo CD and Crossplane&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/nkPoPaVzExY"&gt;Couchbase - How To Run a Database Cluster in Kubernetes Using Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/XNXJtxkUKeY"&gt;Automation of Everything - How To Combine Argo Events, Workflows &amp;amp; Pipelines, CD, and Rollouts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/cpAaI8p4R60"&gt;Environments Based On Pull Requests (PRs): Using Argo CD To Apply GitOps Principles On Previews&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/vpWQeoaiRM4"&gt;Argo CD: Applying GitOps Principles To Manage Production Environment In Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codefresh.io/continuous-deployment/creating-temporary-preview-environments-based-pull-requests-argo-cd-codefresh/"&gt;Creating Temporary Preview Environments Based On Pull Requests With Argo CD And Codefresh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=r50tRQjisxw"&gt;Tutorial: Everything You Need To Become A GitOps Ninja&lt;/a&gt; 90m tutorial on GitOps and Argo CD.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.inovex.de/blog/spinnaker-vs-argo-cd-vs-tekton-vs-jenkins-x/"&gt;Comparison of Argo CD, Spinnaker, Jenkins X, and Tekton&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.ibm.com/cloud/blog/simplify-and-automate-deployments-using-gitops-with-ibm-multicloud-manager-3-1-2"&gt;Simplify and Automate Deployments Using GitOps with IBM Multicloud Manager 3.1.2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://v0-6.kubeflow.org/docs/use-cases/gitops-for-kubeflow/"&gt;GitOps for Kubeflow using Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.digitalocean.com/community/tutorials/webinar-series-gitops-tool-sets-on-kubernetes-with-circleci-and-argo-cd"&gt;GitOps Toolsets on Kubernetes with CircleCI and Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=OdzH82VpMwI&amp;amp;feature=youtu.be"&gt;CI/CD in Light Speed with K8s and Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=VXrGp5er1ZE&amp;amp;t=0s&amp;amp;index=135&amp;amp;list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU"&gt;Machine Learning as Code&lt;/a&gt;. Among other things, describes how Kubeflow uses Argo CD to implement GitOPs for ML&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=aWDIQMbp1cc&amp;amp;feature=youtu.be&amp;amp;t=1m4s"&gt;Argo CD - GitOps Continuous Delivery for Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=2WSJF7d8dUg&amp;amp;feature=youtu.be"&gt;Introduction to Argo CD : Kubernetes DevOps CI/CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/riskified-technology/gitops-deployment-and-kubernetes-f1ab289efa4b"&gt;GitOps Deployment and Kubernetes - using Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://itnext.io/deploy-argo-cd-with-ingress-and-tls-in-three-steps-no-yaml-yak-shaving-required-bc536d401491"&gt;Deploy Argo CD with Ingress and TLS in Three Steps: No YAML Yak Shaving Required&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codefresh.io/events/cncf-member-webinar-gitops-continuous-delivery-argo-codefresh/"&gt;GitOps Continuous Delivery with Argo and Codefresh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mjpitz.com/blog/2020/12/03/renovate-your-gitops/"&gt;Stay up to date with Argo CD and Renovate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.arthurkoziel.com/setting-up-argocd-with-helm/"&gt;Setting up Argo CD with Helm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://thenewstack.io/applied-gitops-with-argocd/"&gt;Applied GitOps with Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cncf.io/blog/2020/12/17/solving-configuration-drift-using-gitops-with-argo-cd/"&gt;Solving configuration drift using GitOps with Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blogs.sap.com/2021/05/06/decentralized-gitops-over-environments/"&gt;Decentralized GitOps over environments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/AvLuplh1skA"&gt;Getting Started with ArgoCD for GitOps Deployments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/17894DTru2Y"&gt;Using Argo CD &amp;amp; Datree for Stable Kubernetes CI/CD Deployments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://amralaayassen.medium.com/how-to-create-argocd-applications-automatically-using-applicationset-automation-of-the-gitops-59455eaf4f72"&gt;How to create Argo CD Applications Automatically using ApplicationSet? "Automation of GitOps"&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cncf.io/blog/2022/12/16/progressive-delivery-with-service-mesh-argo-rollouts-with-istio/"&gt;Progressive Delivery with Service Mesh ‚Äì Argo Rollouts with Istio&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>projectcalico/calico</title>
      <link>https://github.com/projectcalico/calico</link>
      <description>&lt;p&gt;Cloud native networking and network security&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/projectcalico/calico"&gt;&lt;img src="https://goreportcard.com/badge/github.com/projectcalico/calico" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/helm/projectcalico/tigera-operator"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/tigera-operator" alt="ArtifactHub" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/projectcalico/calico/master/calico/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/projectcalico/api"&gt;&lt;img src="https://pkg.go.dev/badge/k8s.io/kubernetes.svg?sanitize=true" alt="GoPkg" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/6064"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/6064/badge" alt="CII Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;h1&gt;Calico&lt;/h1&gt; 
 &lt;h2&gt; &lt;a href="https://projectcalico.docs.tigera.io/getting-started/kubernetes/quickstart"&gt;Quickstart&lt;/a&gt; | &lt;a href="https://projectcalico.docs.tigera.io"&gt;Docs&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/projectcalico/calico/master/CONTRIBUTING.md"&gt;Contribute&lt;/a&gt; | &lt;a href="https://slack.projectcalico.org"&gt;Slack&lt;/a&gt; | &lt;a href="https://github.com/projectcalico/calico/releases"&gt;Releases&lt;/a&gt; &lt;/h2&gt; 
&lt;/div&gt; 
&lt;h2&gt;üêæ Welcome to Project Calico!&lt;/h2&gt; 
&lt;p&gt;Project Calico, created and maintained by &lt;a href="https://www.tigera.io/"&gt;Tigera&lt;/a&gt;, is an open-source project with an active development and user community. Calico Open Source has grown to be the most widely adopted solution for container networking and security, powering 8M+ nodes daily across 166 countries.&lt;/p&gt; 
&lt;h2&gt;üåü Why use Calico?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Data Plane Choice&lt;/strong&gt;: eBPF, standard Linux, Windows, and VPP ‚Äî versatility in network solutions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interoperability&lt;/strong&gt;: Works across multiple distros, multiple clouds, bare metal, and VMs.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Optimized Performance&lt;/strong&gt;: Engineered for high speed and low CPU usage, maximizing your cluster investments.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Architecture&lt;/strong&gt;: Grows seamlessly with your Kubernetes clusters without sacrificing performance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Security&lt;/strong&gt;: Get granular access controls and WireGuard encryption.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes Networking Policy Support&lt;/strong&gt;: Continually defining excellence in Kubernetes network policy standards and support.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Vibrant Contributor Community&lt;/strong&gt;: Over 200 contributors from a wide array of global companies.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible networking&lt;/strong&gt;: An array of networking tools at your disposal, including BGP, VXLAN, service advertisement, and more.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://www.tigera.io/app/uploads/2024/02/Ecosystem_shrunken_2023.svg?sanitize=true" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;ü§ù Join the Calico Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.tigera.io/project-calico/calico-big-cats-ambassador-program/#meet-calico-big-cats"&gt;Calico Big Cats&lt;/a&gt;: Become an ambassador and share your journey&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://calendar.google.com/calendar/u/0/embed?src=tigera.io_uunmavdev5ndovf0hc4frtl0i0@group.calendar.google.com"&gt;Community Meetings&lt;/a&gt;: Engage and contribute&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/calico/labels/good%20first%20issue"&gt;Contribute on GitHub&lt;/a&gt;: Start with 'good first issues'&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://slack.projectcalico.org/"&gt;Connect on Slack&lt;/a&gt;: Join the conversation with fellow contributors and our developers&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üí° Contributing to Project Calico&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.tigera.io/calico/latest/about"&gt;Get Started with Project Calico&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/orgs/projectcalico/repositories"&gt;Repositories&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/calico/raw/master/CONTRIBUTING_DOCS.md"&gt;Contribute to our docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://docs.tigera.io/calico/latest/about/training-resources"&gt;Dive into our training and resources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/calico/issues"&gt;Make Calico better&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üõ†Ô∏è Projects We Maintain&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/api"&gt;Calico Golang API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tigera/operator"&gt;Calico operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/vpp-dataplane"&gt;VPP dataplane&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/projectcalico/bird"&gt;Calico BIRD&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¢ Stay Connected&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Subscribe: &lt;a href="https://www.tigera.io/project-calico/#:~:text=Join%20Calico%20Open%20Source%20community%20newsletter"&gt;Join our newsletter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/channel/UCFpTnXDNcBoXI4gqCDmegFA"&gt;YouTube channel for updates &amp;amp; tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tigera.io/blog/?_sft_category=technical-blog"&gt;Technical Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tigera.io/careers/"&gt;Careers&lt;/a&gt;: Passionate about open source? Join our team.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>seaweedfs/seaweedfs</title>
      <link>https://github.com/seaweedfs/seaweedfs</link>
      <description>&lt;p&gt;SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeaweedFS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;&lt;img src="https://img.shields.io/badge/slack-purple" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=seaweedfs"&gt;&lt;img src="https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;amp;label=Follow" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/seaweedfs/seaweedfs/weed"&gt;&lt;img src="https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;&lt;img src="https://img.shields.io/badge/docs-wiki-blue.svg?sanitize=true" alt="Wiki" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/search?q=g:com.github.chrislusf"&gt;&lt;img src="https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client" alt="SeaweedFS on Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=seaweedfs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png" alt="SeaweedFS Logo" /&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt;&lt;a href="https://www.patreon.com/seaweedfs"&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;SeaweedFS is an independent Apache-licensed open source project with its ongoing development made possible entirely thanks to the support of these awesome &lt;a href="https://github.com/seaweedfs/seaweedfs/raw/master/backers.md"&gt;backers&lt;/a&gt;. If you'd like to grow SeaweedFS even stronger, please consider joining our &lt;a href="https://www.patreon.com/seaweedfs"&gt;sponsors on Patreon&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your support will be really appreciated by me and other supporters!&lt;/p&gt; 
&lt;!--
&lt;h4 align="center"&gt;Platinum&lt;/h4&gt;

&lt;p align="center"&gt;
  &lt;a href="" target="_blank"&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.nodion.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png" alt="nodion" /&gt;&lt;/a&gt; &lt;a href="https://www.piknik.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png" alt="piknik" /&gt;&lt;/a&gt; &lt;a href="https://www.keepsec.ca"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png" alt="keepsec" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/releases/latest"&gt;Download Binaries for different platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;SeaweedFS on Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/SeaweedFS"&gt;SeaweedFS on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/Seaweedfs"&gt;SeaweedFS on Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/SeaweedFS/"&gt;SeaweedFS on Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/d/forum/seaweedfs"&gt;SeaweedFS Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;Wiki Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf"&gt;SeaweedFS White Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2025.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2021.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/chrislusf/seaweedfs-introduction"&gt;SeaweedFS Introduction Slides 2019.3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-for-s3-api-on-docker"&gt;Quick Start for S3 API on Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-single-binary"&gt;Quick Start with Single Binary&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-seaweedfs-s3-on-aws"&gt;Quick Start SeaweedFS S3 on AWS&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#additional-features"&gt;Additional Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#filer-features"&gt;Filer Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#example-using-seaweed-object-store"&gt;Example: Using Seaweed Object Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#object-store-architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-other-file-systems"&gt;Compared to Other File Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-hdfs"&gt;Compared to HDFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs-ceph"&gt;Compared to GlusterFS, Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs"&gt;Compared to GlusterFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-ceph"&gt;Compared to Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-minio"&gt;Compared to Minio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#dev-plan"&gt;Dev Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#installation-guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#disk-related-topics"&gt;Disk Related Topics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#benchmark"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#enterprise"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;h2&gt;Quick Start for S3 API on Docker&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker run -p 8333:8333 chrislusf/seaweedfs server -s3&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start with Single Binary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;. Or run &lt;code&gt;go install github.com/seaweedfs/seaweedfs/weed@latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key&lt;/code&gt; as the admin credentials to access the object store.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;weed server -dir=/some/data/dir -s3&lt;/code&gt; to start one master, one volume server, one filer, and one S3 gateway.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, to increase capacity, just add more volume servers by running &lt;code&gt;weed volume -dir="/some/data/dir2" -mserver="&amp;lt;master_host&amp;gt;:9333" -port=8081&lt;/code&gt; locally, or on a different machine, or on thousands of machines. That is it!&lt;/p&gt; 
&lt;h2&gt;Quick Start SeaweedFS S3 on AWS&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setup fast production-ready &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc"&gt;SeaweedFS S3 on AWS with cloudformation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;to store billions of files!&lt;/li&gt; 
 &lt;li&gt;to serve the files fast!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;SeaweedFS started as an Object Store to handle small files efficiently. Instead of managing all file metadata in a central master, the central master only manages volumes on volume servers, and these volume servers manage files and their metadata. This relieves concurrency pressure from the central master and spreads file metadata into volume servers, allowing faster file access (O(1), usually just one disk read operation).&lt;/p&gt; 
&lt;p&gt;There is only 40 bytes of disk storage overhead for each file's metadata. It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.&lt;/p&gt; 
&lt;p&gt;SeaweedFS started by implementing &lt;a href="http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook's Haystack design paper&lt;/a&gt;. Also, SeaweedFS implements erasure coding with ideas from &lt;a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf"&gt;f4: Facebook‚Äôs Warm BLOB Storage System&lt;/a&gt;, and has a lot of similarities with &lt;a href="https://www.usenix.org/system/files/fast21-pan.pdf"&gt;Facebook‚Äôs Tectonic Filesystem&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On top of the object store, optional &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer&lt;/a&gt; can support directories and POSIX attributes. Filer is a separate linearly-scalable stateless server with customizable metadata stores, e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.&lt;/p&gt; 
&lt;p&gt;For any distributed key value stores, the large values can be offloaded to SeaweedFS. With the fast access speed and linearly scalable capacity, SeaweedFS can work as a distributed &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store"&gt;Key-Large-Value store&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can transparently integrate with the cloud. With hot data on local cluster, and warm data on the cloud with O(1) access time, SeaweedFS can achieve both fast local access time and elastic cloud storage capacity. What's more, the cloud storage access API cost is minimized. Faster and cheaper than direct cloud storage!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Can choose no replication or different replication levels, rack and data center aware.&lt;/li&gt; 
 &lt;li&gt;Automatic master servers failover - no single point of failure (SPOF).&lt;/li&gt; 
 &lt;li&gt;Automatic Gzip compression depending on file MIME type.&lt;/li&gt; 
 &lt;li&gt;Automatic compaction to reclaim disk space after deletion or update.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live"&gt;Automatic entry TTL expiration&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Any server with some disk space can add to the total storage space.&lt;/li&gt; 
 &lt;li&gt;Adding/Removing servers does &lt;strong&gt;not&lt;/strong&gt; cause any data re-balancing unless triggered by admin commands.&lt;/li&gt; 
 &lt;li&gt;Optional picture resizing.&lt;/li&gt; 
 &lt;li&gt;Support ETag, Accept-Range, Last-Modified, etc.&lt;/li&gt; 
 &lt;li&gt;Support in-memory/leveldb/readonly mode tuning for memory/performance balance.&lt;/li&gt; 
 &lt;li&gt;Support rebalancing the writable and readonly volumes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage"&gt;Customizable Multiple Storage Tiers&lt;/a&gt;: Customizable storage disk types to balance performance and cost.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier"&gt;Transparent cloud integration&lt;/a&gt;: unlimited capacity via tiered cloud storage for warm data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage"&gt;Erasure Coding for warm storage&lt;/a&gt; Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filer Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer server&lt;/a&gt; provides "normal" directories and files via HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores"&gt;File TTL&lt;/a&gt; automatically expires file metadata and actual file data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount"&gt;Mount filer&lt;/a&gt; reads and writes files directly as a local directory via FUSE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication"&gt;Filer Store Replication&lt;/a&gt; enables HA for filer meta data stores.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization"&gt;Active-Active Replication&lt;/a&gt; enables asynchronous one-way or two-way cross cluster continuous replication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API"&gt;Amazon S3 compatible API&lt;/a&gt; accesses files with S3 tooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System"&gt;Hadoop Compatible File System&lt;/a&gt; accesses files from Hadoop/Spark/Flink/etc or even runs HBase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud"&gt;Async Replication To Cloud&lt;/a&gt; has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/WebDAV"&gt;WebDAV&lt;/a&gt; accesses as a mapped drive on Mac and Windows, or from mobile devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption"&gt;AES256-GCM Encrypted Storage&lt;/a&gt; safely stores the encrypted data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files"&gt;Super Large Files&lt;/a&gt; stores large or super large files in tens of TB.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt; mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage"&gt;Gateway to Remote Object Store&lt;/a&gt; mirrors bucket operations to remote object storage, in addition to &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Kubernetes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-csi-driver"&gt;Kubernetes CSI Driver&lt;/a&gt; A Container Storage Interface (CSI) Driver. &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-operator"&gt;SeaweedFS Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example: Using Seaweed Object Store&lt;/h2&gt; 
&lt;p&gt;By default, the master node runs on port 9333, and the volume nodes run on port 8080. Let's start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We'll use localhost as an example.&lt;/p&gt; 
&lt;p&gt;SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.&lt;/p&gt; 
&lt;h3&gt;Start Master Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; ./weed master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Volume Servers&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; weed volume -dir="/tmp/data1" -max=5  -mserver="localhost:9333" -port=8080 &amp;amp;
&amp;gt; weed volume -dir="/tmp/data2" -max=10 -mserver="localhost:9333" -port=8081 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write File&lt;/h3&gt; 
&lt;p&gt;To upload a file: first, send a HTTP POST, PUT, or GET request to &lt;code&gt;/dir/assign&lt;/code&gt; to get an &lt;code&gt;fid&lt;/code&gt; and a volume server URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/assign
{"count":1,"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Second, to store the file content, send a HTTP multi-part POST request to &lt;code&gt;url + '/' + fid&lt;/code&gt; from the response:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{"name":"myphoto.jpg","size":43234,"eTag":"1cc0118e"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update, send another POST request with updated file content.&lt;/p&gt; 
&lt;p&gt;For deletion, send an HTTP DELETE request to the same &lt;code&gt;url + '/' + fid&lt;/code&gt; URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Save File Id&lt;/h3&gt; 
&lt;p&gt;Now, you can save the &lt;code&gt;fid&lt;/code&gt;, 3,01637037d6 in this case, to a database field.&lt;/p&gt; 
&lt;p&gt;The number 3 at the start represents a volume id. After the comma, it's one file key, 01, and a file cookie, 637037d6.&lt;/p&gt; 
&lt;p&gt;The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.&lt;/p&gt; 
&lt;p&gt;The file key and file cookie are both coded in hex. You can store the &amp;lt;volume id, file key, file cookie&amp;gt; tuple in your own format, or simply store the &lt;code&gt;fid&lt;/code&gt; as a string.&lt;/p&gt; 
&lt;p&gt;If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.&lt;/p&gt; 
&lt;p&gt;If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.&lt;/p&gt; 
&lt;h3&gt;Read File&lt;/h3&gt; 
&lt;p&gt;Here is an example of how to render the URL.&lt;/p&gt; 
&lt;p&gt;First look up the volume server's URLs by the file's volumeId:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/lookup?volumeId=3
{"volumeId":"3","locations":[{"publicUrl":"localhost:8080","url":"localhost:8080"}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since (usually) there are not too many volume servers, and volumes don't move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.&lt;/p&gt; 
&lt;p&gt;Now you can take the public URL, render the URL or directly read from the volume server via URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3,01637037d6.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notice we add a file extension ".jpg" here. It's optional and just one way for the client to specify the file content type.&lt;/p&gt; 
&lt;p&gt;If you want a nicer URL, you can use one of these alternative URL formats:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to get a scaled version of an image, you can add some params:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fill
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rack-Aware and Data Center-Aware Replication&lt;/h3&gt; 
&lt;p&gt;SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:9333/dir/assign?replication=001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication parameter options are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about replication can be found &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Replication"&gt;on the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also set the default replication strategy when starting the master server.&lt;/p&gt; 
&lt;h3&gt;Allocate File Key on Specific Data Center&lt;/h3&gt; 
&lt;p&gt;Volume servers can be started with a specific data center name:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When requesting a file key, an optional "dataCenter" parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to 'dc1':&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:9333/dir/assign?dataCenter=dc1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server"&gt;No Single Point of Failure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys"&gt;Insert with your own keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files"&gt;Chunking large files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space"&gt;Collection as a Simple Name Space&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Object Store Architecture&lt;/h2&gt; 
&lt;p&gt;Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.&lt;/p&gt; 
&lt;p&gt;The main drawback is that the central master can't handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.&lt;/p&gt; 
&lt;p&gt;Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.&lt;/p&gt; 
&lt;p&gt;The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.&lt;/p&gt; 
&lt;p&gt;For comparison, consider that an xfs inode structure in Linux is 536 bytes.&lt;/p&gt; 
&lt;h3&gt;Master Server and Volume Server&lt;/h3&gt; 
&lt;p&gt;The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.&lt;/p&gt; 
&lt;p&gt;All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.&lt;/p&gt; 
&lt;p&gt;On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.&lt;/p&gt; 
&lt;h3&gt;Write and Read files&lt;/h3&gt; 
&lt;p&gt;When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.&lt;/p&gt; 
&lt;p&gt;When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages and let browsers fetch the content.&lt;/p&gt; 
&lt;p&gt;Please see the example for details on the write-read process.&lt;/p&gt; 
&lt;h3&gt;Storage Size&lt;/h3&gt; 
&lt;p&gt;In the current implementation, each volume can hold 32 gibibytes (32GiB or 8x2^32 bytes). This is because we align content to 8 bytes. We can easily increase this to 64GiB, or 128GiB, or more, by changing 2 lines of code, at the cost of some wasted padding space due to alignment.&lt;/p&gt; 
&lt;p&gt;There can be 4 gibibytes (4GiB or 2^32 bytes) of volumes. So the total system size is 8 x 4GiB x 4GiB which is 128 exbibytes (128EiB or 2^67 bytes).&lt;/p&gt; 
&lt;p&gt;Each individual file size is limited to the volume size.&lt;/p&gt; 
&lt;h3&gt;Saving memory&lt;/h3&gt; 
&lt;p&gt;All file meta information stored on a volume server is readable from memory without disk access. Each file takes just a 16-byte map entry of &amp;lt;64bit key, 32bit offset, 32bit size&amp;gt;. Of course, each map entry has its own space cost for the map. But usually the disk space runs out before the memory does.&lt;/p&gt; 
&lt;h3&gt;Tiered Storage to the cloud&lt;/h3&gt; 
&lt;p&gt;The local volume servers are much faster, while cloud storages have elastic capacity and are actually more cost-efficient if not accessed often (usually free to upload, but relatively costly to access). With the append-only structure and O(1) access time, SeaweedFS can take advantage of both local and cloud storage by offloading the warm data to the cloud.&lt;/p&gt; 
&lt;p&gt;Usually hot data are fresh and warm data are old. SeaweedFS puts the newly created volumes on local servers, and optionally upload the older volumes on the cloud. If the older data are accessed less often, this literally gives you unlimited capacity with limited local servers, and still fast for new data.&lt;/p&gt; 
&lt;p&gt;With the O(1) access time, the network latency cost is kept at minimum.&lt;/p&gt; 
&lt;p&gt;If the hot/warm data is split as 20/80, with 20 servers, you can achieve storage capacity of 100 servers. That's a cost saving of 80%! Or you can repurpose the 80 servers to store new data also, and get 5X storage throughput.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compared to Other File Systems&lt;/h2&gt; 
&lt;p&gt;Most other distributed file systems seem more complicated than necessary.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is meant to be fast and simple, in both setup and operation. If you do not understand how it works when you reach here, we've failed! Please raise an issue with any questions or update this file with clarifications.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is constantly moving forward. Same with other systems. These comparisons can be outdated quickly. Please help to keep them updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to HDFS&lt;/h3&gt; 
&lt;p&gt;HDFS uses the chunk approach for each file, and is ideal for storing large files.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is ideal for serving relatively smaller files quickly and concurrently.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can also store extra large files by splitting them into manageable data chunks, and store the file ids of the data chunks into a meta chunk. This is managed by "weed upload/download" tool, and the weed master or volume servers are agnostic about it.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS, Ceph&lt;/h3&gt; 
&lt;p&gt;The architectures are mostly the same. SeaweedFS aims to store and read files fast, with a simple and flat architecture. The main differences are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SeaweedFS optimizes for small files, ensuring O(1) disk seek operation, and can also handle large files.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS statically assigns a volume id for a file. Locating file content becomes just a lookup of the volume id, which can be easily cached.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Filer metadata store can be any well-known and proven data store, e.g., Redis, Cassandra, HBase, Mongodb, Elastic Search, MySql, Postgres, Sqlite, MemSql, TiDB, CockroachDB, Etcd, YDB etc, and is easy to customize.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Volume server also communicates directly with clients via HTTP, supporting range queries, direct uploads, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;File Metadata&lt;/th&gt; 
   &lt;th&gt;File Content Read&lt;/th&gt; 
   &lt;th&gt;POSIX&lt;/th&gt; 
   &lt;th&gt;REST API&lt;/th&gt; 
   &lt;th&gt;Optimized for large number of small files&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS&lt;/td&gt; 
   &lt;td&gt;lookup volume id, cacheable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS Filer&lt;/td&gt; 
   &lt;td&gt;Linearly Scalable, Customizable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GlusterFS&lt;/td&gt; 
   &lt;td&gt;hashing&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE, NFS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ceph&lt;/td&gt; 
   &lt;td&gt;hashing + rules&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MooseFS&lt;/td&gt; 
   &lt;td&gt;in memory&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinIO&lt;/td&gt; 
   &lt;td&gt;separate meta file for each file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS&lt;/h3&gt; 
&lt;p&gt;GlusterFS stores files, both directories and content, in configurable volumes called "bricks".&lt;/p&gt; 
&lt;p&gt;GlusterFS hashes the path and filename into ids, and assigned to virtual volumes, and then mapped to "bricks".&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MooseFS&lt;/h3&gt; 
&lt;p&gt;MooseFS chooses to neglect small file issue. From moosefs 3.0 manual, "even a small file will occupy 64KiB plus additionally 4KiB of checksums and 1KiB for the header", because it "was initially designed for keeping large amounts (like several thousands) of very big files"&lt;/p&gt; 
&lt;p&gt;MooseFS Master Server keeps all meta data in memory. Same issue as HDFS namenode.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to Ceph&lt;/h3&gt; 
&lt;p&gt;Ceph can be setup similar to SeaweedFS as a key-&amp;gt;blob store. It is much more complicated, with the need to support layers on top of it. &lt;a href="https://github.com/seaweedfs/seaweedfs/issues/120"&gt;Here is a more detailed comparison&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;SeaweedFS has a centralized master group to look up free volumes, while Ceph uses hashing and metadata servers to locate its objects. Having a centralized master makes it easy to code and manage.&lt;/p&gt; 
&lt;p&gt;Ceph, like SeaweedFS, is based on the object store RADOS. Ceph is rather complicated with mixed reviews.&lt;/p&gt; 
&lt;p&gt;Ceph uses CRUSH hashing to automatically manage data placement, which is efficient to locate the data. But the data has to be placed according to the CRUSH algorithm. Any wrong configuration would cause data loss. Topology changes, such as adding new servers to increase capacity, will cause data migration with high IO cost to fit the CRUSH algorithm. SeaweedFS places data by assigning them to any writable volumes. If writes to one volume failed, just pick another volume to write. Adding more volumes is also as simple as it can be.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is optimized for small files. Small files are stored as one continuous block of content, with at most 8 unused bytes between files. Small file access is O(1) disk read.&lt;/p&gt; 
&lt;p&gt;SeaweedFS Filer uses off-the-shelf stores, such as MySql, Postgres, Sqlite, Mongodb, Redis, Elastic Search, Cassandra, HBase, MemSql, TiDB, CockroachCB, Etcd, YDB, to manage file directories. These stores are proven, scalable, and easier to manage.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SeaweedFS&lt;/th&gt; 
   &lt;th&gt;comparable to Ceph&lt;/th&gt; 
   &lt;th&gt;advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Master&lt;/td&gt; 
   &lt;td&gt;MDS&lt;/td&gt; 
   &lt;td&gt;simpler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volume&lt;/td&gt; 
   &lt;td&gt;OSD&lt;/td&gt; 
   &lt;td&gt;optimized for small files&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filer&lt;/td&gt; 
   &lt;td&gt;Ceph FS&lt;/td&gt; 
   &lt;td&gt;linearly scalable, Customizable, O(1) or O(logN)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MinIO&lt;/h3&gt; 
&lt;p&gt;MinIO follows AWS S3 closely and is ideal for testing for S3 API. It has good UI, policies, versionings, etc. SeaweedFS is trying to catch up here. It is also possible to put MinIO as a gateway in front of SeaweedFS later.&lt;/p&gt; 
&lt;p&gt;MinIO metadata are in simple files. Each file write will incur extra writes to corresponding meta file.&lt;/p&gt; 
&lt;p&gt;MinIO does not have optimization for lots of small files. The files are simply stored as is to local disks. Plus the extra meta file and shards for erasure coding, it only amplifies the LOSF problem.&lt;/p&gt; 
&lt;p&gt;MinIO has multiple disk IO to read one file. SeaweedFS has O(1) disk reads, even for erasure coded files.&lt;/p&gt; 
&lt;p&gt;MinIO has full-time erasure coding. SeaweedFS uses replication on hot data for faster speed and optionally applies erasure coding on warm data.&lt;/p&gt; 
&lt;p&gt;MinIO does not have POSIX-like API support.&lt;/p&gt; 
&lt;p&gt;MinIO has specific requirements on storage layout. It is not flexible to adjust capacity. In SeaweedFS, just start one volume server pointing to the master. That's all.&lt;/p&gt; 
&lt;h2&gt;Dev Plan&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More tools and documentation, on how to manage and scale the system.&lt;/li&gt; 
 &lt;li&gt;Read and write stream data.&lt;/li&gt; 
 &lt;li&gt;Support structured data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is a super exciting project! And we need helpers and &lt;a href="https://www.patreon.com/seaweedfs"&gt;support&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Installation guide for users who are not familiar with golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Step 1: install go on your machine and setup the environment by following the instructions at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://golang.org/doc/install"&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;make sure to define your $GOPATH&lt;/p&gt; 
&lt;p&gt;Step 2: checkout this repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/seaweedfs/seaweedfs.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step 3: download, compile, and install the project by executing the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd seaweedfs/weed &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this is done, you will find the executable "weed" in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disk Related Topics&lt;/h2&gt; 
&lt;h3&gt;Hard Drive Performance&lt;/h3&gt; 
&lt;p&gt;When testing read performance on SeaweedFS, it basically becomes a performance test of your hard drive's random read speed. Hard drives usually get 100MB/s~200MB/s.&lt;/p&gt; 
&lt;h3&gt;Solid State Disk&lt;/h3&gt; 
&lt;p&gt;To modify or delete small files, SSD must delete a whole block at a time, and move content in existing blocks to a new block. SSD is fast when brand new, but will get fragmented over time and you have to garbage collect, compacting blocks. SeaweedFS is friendly to SSD since it is append-only. Deletion and compaction are done on volume level in the background, not slowing reading and not causing fragmentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;My Own Unscientific Single Machine Results on Mac Book with Solid State Disk, CPU: 1 Intel Core i7 2.6GHz.&lt;/p&gt; 
&lt;p&gt;Write 1 million 1KB file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   66.753 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106789009 bytes
Requests per second:    15708.23 [#/sec]
Transfer rate:          16191.69 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.3      1.0       84.3      0.9

Percentage of the requests served within a certain time (ms)
   50%      0.8 ms
   66%      1.0 ms
   75%      1.1 ms
   80%      1.2 ms
   90%      1.4 ms
   95%      1.7 ms
   98%      2.1 ms
   99%      2.6 ms
  100%     84.3 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Randomly read 1 million files:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   22.301 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106812873 bytes
Requests per second:    47019.38 [#/sec]
Transfer rate:          48467.57 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.0      0.3       54.1      0.2

Percentage of the requests served within a certain time (ms)
   50%      0.3 ms
   90%      0.4 ms
   98%      0.6 ms
   99%      0.7 ms
  100%     54.1 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run WARP and launch a mixed benchmark.&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make benchmark
warp: Benchmark data written to "warp-mixed-2023-10-16[102354]-l70a.csv.zst"                                                                                                                                                                                               
Mixed operations.
Operation: DELETE, 10%, Concurrency: 20, Ran 4m59s.
 * Throughput: 6.19 obj/s

Operation: GET, 45%, Concurrency: 20, Ran 5m0s.
 * Throughput: 279.85 MiB/s, 27.99 obj/s

Operation: PUT, 15%, Concurrency: 20, Ran 5m0s.
 * Throughput: 89.86 MiB/s, 8.99 obj/s

Operation: STAT, 30%, Concurrency: 20, Ran 5m0s.
 * Throughput: 18.63 obj/s

Cluster Total: 369.74 MiB/s, 61.79 obj/s, 0 errors over 5m0s.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see segmented request statistics, use the --analyze.v parameter.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;warp analyze --analyze.v warp-mixed-2023-10-16[102354]-l70a.csv.zst
18642 operations loaded... Done!
Mixed operations.
----------------------------------------
Operation: DELETE - total: 1854, 10.0%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 6.19 obj/s

Requests considered: 1855:
 * Avg: 104ms, 50%: 30ms, 90%: 207ms, 99%: 1.355s, Fastest: 1ms, Slowest: 4.613s, StdDev: 320ms

----------------------------------------
Operation: GET - total: 8388, 45.3%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.12 +0500 +05
 * Throughput: 279.77 MiB/s, 27.98 obj/s

Requests considered: 8389:
 * Avg: 221ms, 50%: 106ms, 90%: 492ms, 99%: 1.739s, Fastest: 8ms, Slowest: 8.633s, StdDev: 383ms
 * TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 171ms, 99th: 669ms, Worst: 4.783s StdDev: 163ms
 * First Access: Avg: 240ms, 50%: 105ms, 90%: 511ms, 99%: 2.08s, Fastest: 12ms, Slowest: 8.633s, StdDev: 480ms
 * First Access TTFB: Avg: 88ms, Best: 2ms, 25th: 24ms, Median: 38ms, 75th: 64ms, 90th: 179ms, 99th: 919ms, Worst: 4.783s StdDev: 199ms
 * Last Access: Avg: 219ms, 50%: 106ms, 90%: 463ms, 99%: 1.782s, Fastest: 9ms, Slowest: 8.633s, StdDev: 416ms
 * Last Access TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 161ms, 99th: 657ms, Worst: 4.783s StdDev: 176ms

----------------------------------------
Operation: PUT - total: 2688, 14.5%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 89.83 MiB/s, 8.98 obj/s

Requests considered: 2689:
 * Avg: 1.165s, 50%: 878ms, 90%: 2.015s, 99%: 5.74s, Fastest: 99ms, Slowest: 8.264s, StdDev: 968ms

----------------------------------------
Operation: STAT - total: 5586, 30.2%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.113 +0500 +05
 * Throughput: 18.63 obj/s

Requests considered: 5587:
 * Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 80ms, Fastest: 0s, Slowest: 245ms, StdDev: 17ms
 * First Access: Avg: 14ms, 50%: 10ms, 90%: 33ms, 99%: 69ms, Fastest: 0s, Slowest: 203ms, StdDev: 16ms
 * Last Access: Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 74ms, Fastest: 0s, Slowest: 203ms, StdDev: 17ms

Cluster Total: 369.64 MiB/s, 61.77 obj/s, 0 errors over 5m0s.
Total Errors:0.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;For enterprise users, please visit &lt;a href="https://seaweedfs.com"&gt;seaweedfs.com&lt;/a&gt; for the SeaweedFS Enterprise Edition, which has a self-healing storage format with better data protection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;p&gt;The text of this page is available for modification and reuse under the terms of the Creative Commons Attribution-Sharealike 3.0 Unported License and the GNU Free Documentation License (unversioned, with no invariant sections, front-cover texts, or back-cover texts).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/chrislusf/seaweedfs"&gt;&lt;img src="https://starchart.cc/chrislusf/seaweedfs.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>gorilla/websocket</title>
      <link>https://github.com/gorilla/websocket</link>
      <description>&lt;p&gt;Package gorilla/websocket is a fast, well-tested and widely used WebSocket implementation for Go.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Gorilla WebSocket&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://godoc.org/github.com/gorilla/websocket"&gt;&lt;img src="https://godoc.org/github.com/gorilla/websocket?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://circleci.com/gh/gorilla/websocket"&gt;&lt;img src="https://circleci.com/gh/gorilla/websocket.svg?style=svg" alt="CircleCI" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Gorilla WebSocket is a &lt;a href="http://golang.org/"&gt;Go&lt;/a&gt; implementation of the &lt;a href="http://www.rfc-editor.org/rfc/rfc6455.txt"&gt;WebSocket&lt;/a&gt; protocol.&lt;/p&gt; 
&lt;h3&gt;Documentation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/gorilla/websocket?tab=doc"&gt;API Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gorilla/websocket/tree/main/examples/chat"&gt;Chat example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gorilla/websocket/tree/main/examples/command"&gt;Command example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gorilla/websocket/tree/main/examples/echo"&gt;Client and server example&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/gorilla/websocket/tree/main/examples/filewatch"&gt;File watch example&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Status&lt;/h3&gt; 
&lt;p&gt;The Gorilla WebSocket package provides a complete and tested implementation of the &lt;a href="http://www.rfc-editor.org/rfc/rfc6455.txt"&gt;WebSocket&lt;/a&gt; protocol. The package API is stable.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;go get github.com/gorilla/websocket
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Protocol Compliance&lt;/h3&gt; 
&lt;p&gt;The Gorilla WebSocket package passes the server tests in the &lt;a href="https://github.com/crossbario/autobahn-testsuite"&gt;Autobahn Test Suite&lt;/a&gt; using the application in the &lt;a href="https://github.com/gorilla/websocket/tree/main/examples/autobahn"&gt;examples/autobahn subdirectory&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>smallstep/certificates</title>
      <link>https://github.com/smallstep/certificates</link>
      <description>&lt;p&gt;üõ°Ô∏è A private certificate authority (X.509 &amp; SSH) &amp; ACME server for secure automated certificate management, so you can use TLS everywhere &amp; SSO for SSH.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;step-ca&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/smallstep/certificates/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release/smallstep/certificates.svg?sanitize=true" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/smallstep/certificates"&gt;&lt;img src="https://goreportcard.com/badge/github.com/smallstep/certificates" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/smallstep/certificates"&gt;&lt;img src="https://github.com/smallstep/certificates/actions/workflows/test.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt;&lt;img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://cla-assistant.io/smallstep/certificates"&gt;&lt;img src="https://cla-assistant.io/readme/badge/smallstep/certificates" alt="CLA assistant" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;step-ca&lt;/code&gt; is an online certificate authority for secure, automated certificate management for DevOps. It's the server counterpart to the &lt;a href="https://github.com/smallstep/cli"&gt;&lt;code&gt;step&lt;/code&gt; CLI tool&lt;/a&gt; for working with certificates and keys. Both projects are maintained by &lt;a href="https://smallstep.com"&gt;Smallstep Labs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can use &lt;code&gt;step-ca&lt;/code&gt; to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Issue HTTPS server and client certificates that &lt;a href="https://smallstep.com/blog/step-v0-8-6-valid-HTTPS-certificates-for-dev-pre-prod.html"&gt;work in browsers&lt;/a&gt; (&lt;a href="https://tools.ietf.org/html/rfc5280"&gt;RFC5280&lt;/a&gt; and &lt;a href="https://cabforum.org/baseline-requirements-documents/"&gt;CA/Browser Forum&lt;/a&gt; compliance)&lt;/li&gt; 
 &lt;li&gt;Issue TLS certificates for DevOps: VMs, containers, APIs, database connections, Kubernetes pods...&lt;/li&gt; 
 &lt;li&gt;Issue SSH certificates: 
  &lt;ul&gt; 
   &lt;li&gt;For people, in exchange for single sign-on identity tokens&lt;/li&gt; 
   &lt;li&gt;For hosts, in exchange for cloud instance identity documents&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Easily automate certificate management: 
  &lt;ul&gt; 
   &lt;li&gt;It's an &lt;a href="https://smallstep.com/docs/step-ca/acme-basics/"&gt;ACME server&lt;/a&gt; that supports all &lt;a href="https://smallstep.com/docs/step-ca/acme-basics/#acme-challenge-types"&gt;popular ACME challenge types&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;It comes with a &lt;a href="https://raw.githubusercontent.com/smallstep/certificates/master/examples#user-content-basic-client-usage"&gt;Go wrapper&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;... and there's a &lt;a href="https://github.com/smallstep/cli"&gt;command-line client&lt;/a&gt; you can use in scripts!&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Comparison with Smallstep's commercial product&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;step-ca&lt;/code&gt; is optimized for a two-tier PKI serving common DevOps use cases.&lt;/p&gt; 
&lt;p&gt;As you design your PKI, if you need any of the following, &lt;a href="http://smallstep.com"&gt;consider our commerical CA&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Multiple certificate authorities&lt;/li&gt; 
 &lt;li&gt;Active revocation (CRL, OSCP)&lt;/li&gt; 
 &lt;li&gt;Turnkey high-volume, high availability CA&lt;/li&gt; 
 &lt;li&gt;An API for seamless IaC management of your PKI&lt;/li&gt; 
 &lt;li&gt;Integrated support for SCEP &amp;amp; NDES, for migrating from legacy Active Directory Certificate Services deployments&lt;/li&gt; 
 &lt;li&gt;Device identity ‚Äî cross-platform device inventory and attestation using Secure Enclave &amp;amp; TPM 2.0&lt;/li&gt; 
 &lt;li&gt;Highly automated PKI ‚Äî managed certificate renewal, monitoring, TPM-based attested enrollment&lt;/li&gt; 
 &lt;li&gt;Seamless client deployments of EAP-TLS Wi-Fi, VPN, SSH, and browser certificates&lt;/li&gt; 
 &lt;li&gt;Jamf, Intune, or other MDM for root distribution and client enrollment&lt;/li&gt; 
 &lt;li&gt;Web Admin UI ‚Äî history, issuance, and metrics&lt;/li&gt; 
 &lt;li&gt;ACME External Account Binding (EAB)&lt;/li&gt; 
 &lt;li&gt;Deep integration with an identity provider&lt;/li&gt; 
 &lt;li&gt;Fine-grained, role-based access control&lt;/li&gt; 
 &lt;li&gt;FIPS-compliant software&lt;/li&gt; 
 &lt;li&gt;HSM-bound private keys&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See our &lt;a href="https://smallstep.com/step-ca-vs-smallstep-certificate-manager/"&gt;full feature comparison&lt;/a&gt; for more.&lt;/p&gt; 
&lt;p&gt;You can &lt;a href="https://smallstep.com/signup"&gt;start a free trial&lt;/a&gt; or &lt;a href="https://go.smallstep.com/request-demo"&gt;set up a call with us&lt;/a&gt; to learn more.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Questions? Find us in &lt;a href="https://github.com/smallstep/certificates/discussions"&gt;Discussions&lt;/a&gt; or &lt;a href="https://u.step.sm/discord"&gt;Join our Discord&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://smallstep.com/certificates"&gt;Website&lt;/a&gt; | &lt;a href="https://smallstep.com/docs/step-ca"&gt;Documentation&lt;/a&gt; | &lt;a href="https://smallstep.com/docs/step-ca/installation"&gt;Installation&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/smallstep/certificates/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;ü¶æ A fast, stable, flexible private CA&lt;/h3&gt; 
&lt;p&gt;Setting up a &lt;em&gt;public key infrastructure&lt;/em&gt; (PKI) is out of reach for many small teams. &lt;code&gt;step-ca&lt;/code&gt; makes it easier.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Choose key types (RSA, ECDSA, EdDSA) and lifetimes to suit your needs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/blog/passive-revocation.html"&gt;Short-lived certificates&lt;/a&gt; with automated enrollment, renewal, and passive revocation&lt;/li&gt; 
 &lt;li&gt;Can operate as &lt;a href="https://smallstep.com/docs/tutorials/intermediate-ca-new-ca"&gt;an online intermediate CA for an existing root CA&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-ca/configuration#databases"&gt;Badger, BoltDB, Postgres, and MySQL database backends&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‚öôÔ∏è Many ways to automate&lt;/h3&gt; 
&lt;p&gt;There are several ways to authorize a request with the CA and establish a chain of trust that suits your flow.&lt;/p&gt; 
&lt;p&gt;You can issue certificates in exchange for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/smallstep/certificates/master/#your-own-private-acme-server"&gt;ACME challenge responses&lt;/a&gt; from any ACMEv2 client&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/blog/easily-curl-services-secured-by-https-tls.html"&gt;OAuth OIDC single sign-on tokens&lt;/a&gt;, eg: 
  &lt;ul&gt; 
   &lt;li&gt;ID tokens from Okta, GSuite, Azure AD, Auth0.&lt;/li&gt; 
   &lt;li&gt;ID tokens from an OAuth OIDC service that you host, like &lt;a href="https://www.keycloak.org/"&gt;Keycloak&lt;/a&gt; or &lt;a href="https://github.com/dexidp/dex"&gt;Dex&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/blog/embarrassingly-easy-certificates-on-aws-azure-gcp/"&gt;Cloud instance identity documents&lt;/a&gt;, for VMs on AWS, GCP, and Azure&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-ca/provisioners#jwk"&gt;Single-use, short-lived JWK tokens&lt;/a&gt; issued by your CD tool ‚Äî Puppet, Chef, Ansible, Terraform, etc.&lt;/li&gt; 
 &lt;li&gt;A trusted X.509 certificate (X5C provisioner)&lt;/li&gt; 
 &lt;li&gt;A host certificate from your Nebula network&lt;/li&gt; 
 &lt;li&gt;A SCEP challenge (SCEP provisioner)&lt;/li&gt; 
 &lt;li&gt;An SSH host certificates needing renewal (the SSHPOP provisioner)&lt;/li&gt; 
 &lt;li&gt;Learn more in our &lt;a href="https://smallstep.com/docs/step-ca/provisioners"&gt;provisioner documentation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üèî Your own private ACME server&lt;/h3&gt; 
&lt;p&gt;ACME is the protocol used by Let's Encrypt to automate the issuance of HTTPS certificates. It's &lt;em&gt;super easy&lt;/em&gt; to issue certificates to any ACMEv2 (&lt;a href="https://tools.ietf.org/html/rfc8555"&gt;RFC8555&lt;/a&gt;) client.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://smallstep.com/blog/private-acme-server/#local-development--pre-production"&gt;Use ACME in development &amp;amp; pre-production&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Supports the most popular &lt;a href="https://letsencrypt.org/docs/challenge-types/"&gt;ACME challenge types&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;For &lt;code&gt;http-01&lt;/code&gt;, place a token at a well-known URL to prove that you control the web server&lt;/li&gt; 
   &lt;li&gt;For &lt;code&gt;dns-01&lt;/code&gt;, add a &lt;code&gt;TXT&lt;/code&gt; record to prove that you control the DNS record set&lt;/li&gt; 
   &lt;li&gt;For &lt;code&gt;tls-alpn-01&lt;/code&gt;, respond to the challenge at the TLS layer (&lt;a href="https://caddy.community/t/caddy-supports-the-acme-tls-alpn-challenge/4860"&gt;as Caddy does&lt;/a&gt;) to prove that you control the web server&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Works with any ACME client. We've written examples for:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#certbot"&gt;certbot&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#acmesh"&gt;acme.sh&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#win-acme"&gt;win-acme&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#caddy-v2"&gt;Caddy&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#traefik"&gt;Traefik&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#apache"&gt;Apache&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#nginx"&gt;nginx&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Get certificates programmatically using ACME, using these libraries:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/go-acme/lego"&gt;&lt;code&gt;lego&lt;/code&gt;&lt;/a&gt; for Golang (&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#golang"&gt;example usage&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;certbot's &lt;a href="https://github.com/certbot/certbot/tree/master/acme"&gt;&lt;code&gt;acme&lt;/code&gt; module&lt;/a&gt; for Python (&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#python"&gt;example usage&lt;/a&gt;)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/publishlab/node-acme-client"&gt;&lt;code&gt;acme-client&lt;/code&gt;&lt;/a&gt; for Node.js (&lt;a href="https://smallstep.com/docs/tutorials/acme-protocol-acme-clients#node"&gt;example usage&lt;/a&gt;)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Our own &lt;a href="https://github.com/smallstep/cli"&gt;&lt;code&gt;step&lt;/code&gt; CLI tool&lt;/a&gt; is also an ACME client!&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;See our &lt;a href="https://smallstep.com/docs/tutorials/acme-challenge"&gt;ACME tutorial&lt;/a&gt; for more&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üë©üèΩ‚Äçüíª An online SSH Certificate Authority&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Delegate SSH authentication to &lt;code&gt;step-ca&lt;/code&gt; by using &lt;a href="https://smallstep.com/blog/use-ssh-certificates/"&gt;SSH certificates&lt;/a&gt; instead of public keys and &lt;code&gt;authorized_keys&lt;/code&gt; files&lt;/li&gt; 
 &lt;li&gt;For user certificates, &lt;a href="https://smallstep.com/blog/diy-single-sign-on-for-ssh/"&gt;connect SSH to your single sign-on provider&lt;/a&gt;, to improve security with short-lived certificates and MFA (or other security policies) via any OAuth OIDC provider.&lt;/li&gt; 
 &lt;li&gt;For host certificates, improve security, &lt;a href="https://smallstep.com/blog/use-ssh-certificates/"&gt;eliminate TOFU warnings&lt;/a&gt;, and set up automated host certificate renewal.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ü§ì A general purpose PKI tool, via &lt;a href="https://github.com/smallstep/cli"&gt;&lt;code&gt;step&lt;/code&gt; CLI&lt;/a&gt; &lt;a href="https://smallstep.com/docs/step-cli/reference/ca/"&gt;integration&lt;/a&gt;&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generate key pairs where they're needed so private keys are never transmitted across the network&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-cli/reference/ca/certificate/"&gt;Authenticate and obtain a certificate&lt;/a&gt; using any provisioner supported by &lt;code&gt;step-ca&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Securely &lt;a href="https://smallstep.com/docs/step-cli/reference/ca/root/"&gt;distribute root certificates&lt;/a&gt; and &lt;a href="https://smallstep.com/docs/step-cli/reference/ca/bootstrap/"&gt;bootstrap&lt;/a&gt; PKI relying parties&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-cli/reference/ca/renew/"&gt;Renew&lt;/a&gt; and &lt;a href="https://smallstep.com/docs/step-cli/reference/ca/revoke/"&gt;revoke&lt;/a&gt; certificates issued by &lt;code&gt;step-ca&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-cli/reference/certificate/install/"&gt;Install root certificates&lt;/a&gt; on your machine and browsers, so your CA is trusted&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-cli/reference/certificate/inspect/"&gt;Inspect&lt;/a&gt; and &lt;a href="https://smallstep.com/docs/step-cli/reference/certificate/lint/"&gt;lint&lt;/a&gt; certificates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;See our installation docs &lt;a href="https://smallstep.com/docs/step-ca/installation"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://smallstep.com/docs/step-ca"&gt;Official documentation&lt;/a&gt; is on smallstep.com&lt;/li&gt; 
 &lt;li&gt;The &lt;code&gt;step&lt;/code&gt; command reference is available via &lt;code&gt;step help&lt;/code&gt;, &lt;a href="https://smallstep.com/docs/step-cli/reference/"&gt;on smallstep.com&lt;/a&gt;, or by running &lt;code&gt;step help --http=:8080&lt;/code&gt; from the command line and visiting &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Feedback?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tell us what you like and don't like about managing your PKI - we're eager to help solve problems in this space. &lt;a href="https://u.step.sm/discord"&gt;Join our Discord&lt;/a&gt; or &lt;a href="https://github.com/smallstep/certificates/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tell us about a feature you'd like to see! &lt;a href="https://github.com/smallstep/certificates/issues/new?assignees=&amp;amp;labels=enhancement%2C+needs+triage&amp;amp;template=enhancement.md&amp;amp;title="&gt;Request a Feature&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ethereum-optimism/optimism</title>
      <link>https://github.com/ethereum-optimism/optimism</link>
      <description>&lt;p&gt;Optimism is Ethereum, scaled.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://optimism.io"&gt;&lt;img alt="Optimism" src="https://raw.githubusercontent.com/ethereum-optimism/brand-kit/main/assets/svg/OPTIMISM-R.svg?sanitize=true" width="600" /&gt;&lt;/a&gt; 
 &lt;br /&gt; 
 &lt;h3&gt;&lt;a href="https://optimism.io"&gt;Optimism&lt;/a&gt; is Ethereum, scaled.&lt;/h3&gt; 
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt; 
&lt;!--TOC--&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#what-is-optimism"&gt;What is Optimism?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#specification"&gt;Specification&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#community"&gt;Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#security-policy-and-vulnerability-reporting"&gt;Security Policy and Vulnerability Reporting&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#directory-structure"&gt;Directory Structure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#development-and-release-process"&gt;Development and Release Process&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#production-releases"&gt;Production Releases&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#development-branch"&gt;Development branch&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!--TOC--&gt; 
&lt;h2&gt;What is Optimism?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.optimism.io/"&gt;Optimism&lt;/a&gt; is a project dedicated to scaling Ethereum's technology and expanding its ability to coordinate people from across the world to build effective decentralized economies and governance systems. The &lt;a href="https://www.optimism.io/vision"&gt;Optimism Collective&lt;/a&gt; builds open-source software that powers scalable blockchains and aims to address key governance and economic challenges in the wider Ethereum ecosystem. Optimism operates on the principle of &lt;strong&gt;impact=profit&lt;/strong&gt;, the idea that individuals who positively impact the Collective should be proportionally rewarded with profit. &lt;strong&gt;Change the incentives and you change the world.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;In this repository you'll find numerous core components of the OP Stack, the decentralized software stack maintained by the Optimism Collective that powers Optimism and forms the backbone of blockchains like &lt;a href="https://explorer.optimism.io/"&gt;OP Mainnet&lt;/a&gt; and &lt;a href="https://base.org"&gt;Base&lt;/a&gt;. The OP Stack is designed to be aggressively open-source ‚Äî you are welcome to explore, modify, and extend this code.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;If you want to build on top of OP Mainnet, refer to the &lt;a href="https://docs.optimism.io"&gt;Optimism Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;If you want to build your own OP Stack based blockchain, refer to the &lt;a href="https://docs.optimism.io/stack/getting-started"&gt;OP Stack Guide&lt;/a&gt; and make sure to understand this repository's &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/#development-and-release-process"&gt;Development and Release Process&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Specification&lt;/h2&gt; 
&lt;p&gt;Detailed specifications for the OP Stack can be found within the &lt;a href="https://github.com/ethereum-optimism/specs"&gt;OP Stack Specs&lt;/a&gt; repository.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;General discussion happens most frequently on the &lt;a href="https://discord.gg/optimism"&gt;Optimism discord&lt;/a&gt;. Governance discussion can also be found on the &lt;a href="https://gov.optimism.io/"&gt;Optimism Governance Forum&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;The OP Stack is a collaborative project. By collaborating on free, open software and shared standards, the Optimism Collective aims to prevent siloed software development and rapidly accelerate the development of the Ethereum ecosystem. Come contribute, build the future, and redefine power, together.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; contains a detailed explanation of the contributing process for this repository. Make sure to use the &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/CONTRIBUTING.md#development-quick-start"&gt;Developer Quick Start&lt;/a&gt; to properly set up your development environment.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/ethereum-optimism/optimism/issues?q=is:open+is:issue+label:D-good-first-issue"&gt;Good First Issues&lt;/a&gt; are a great place to look for tasks to tackle if you're not sure where to start, and see &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for info on larger projects.&lt;/p&gt; 
&lt;h2&gt;Security Policy and Vulnerability Reporting&lt;/h2&gt; 
&lt;p&gt;Please refer to the canonical &lt;a href="https://github.com/ethereum-optimism/.github/raw/master/SECURITY.md"&gt;Security Policy&lt;/a&gt; document for detailed information about how to report vulnerabilities in this codebase. Bounty hunters are encouraged to check out the &lt;a href="https://immunefi.com/bounty/optimism/"&gt;Optimism Immunefi bug bounty program&lt;/a&gt;. The Optimism Immunefi program offers up to $2,000,042 for in-scope critical vulnerabilities.&lt;/p&gt; 
&lt;h2&gt;Directory Structure&lt;/h2&gt; 
&lt;pre&gt;
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/cannon"&gt;cannon&lt;/a&gt;: Onchain MIPS instruction emulator for fault proofs
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/devnet-sdk"&gt;devnet-sdk&lt;/a&gt;: Comprehensive toolkit for standardized devnet interactions
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/docs"&gt;docs&lt;/a&gt;: A collection of documents including audits and post-mortems
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/kurtosis-devnet"&gt;kurtosis-devnet&lt;/a&gt;: OP-Stack Kurtosis devnet
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-acceptance-tests"&gt;op-acceptance-tests&lt;/a&gt;: Acceptance tests and configuration for OP Stack
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-alt-da"&gt;op-alt-da&lt;/a&gt;: Alternative Data Availability mode (beta)
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-batcher"&gt;op-batcher&lt;/a&gt;: L2-Batch Submitter, submits bundles of batches to L1
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-chain-ops"&gt;op-chain-ops&lt;/a&gt;: State surgery utilities
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-challenger"&gt;op-challenger&lt;/a&gt;: Dispute game challenge agent
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-conductor"&gt;op-conductor&lt;/a&gt;: High-availability sequencer service
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-deployer"&gt;op-deployer&lt;/a&gt;: CLI tool for deploying and upgrading OP Stack smart contracts
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-devstack"&gt;op-devstack&lt;/a&gt;: Flexible test frontend for integration and acceptance testing
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-dispute-mon"&gt;op-dispute-mon&lt;/a&gt;: Off-chain service to monitor dispute games
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-dripper"&gt;op-dripper&lt;/a&gt;: Controlled token distribution service
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-e2e"&gt;op-e2e&lt;/a&gt;: End-to-End testing of all bedrock components in Go
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-faucet"&gt;op-faucet&lt;/a&gt;: Dev-faucet with support for multiple chains
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-fetcher"&gt;op-fetcher&lt;/a&gt;: Data fetching utilities
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-interop-mon"&gt;op-interop-mon&lt;/a&gt;: Interoperability monitoring service
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-node"&gt;op-node&lt;/a&gt;: Rollup consensus-layer client
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-preimage"&gt;op-preimage&lt;/a&gt;: Go bindings for Preimage Oracle
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-program"&gt;op-program&lt;/a&gt;: Fault proof program
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-proposer"&gt;op-proposer&lt;/a&gt;: L2-Output Submitter, submits proposals to L1
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-service"&gt;op-service&lt;/a&gt;: Common codebase utilities
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-supervisor"&gt;op-supervisor&lt;/a&gt;: Service to monitor chains and determine cross-chain message safety
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-sync-tester"&gt;op-sync-tester&lt;/a&gt;: Sync testing utilities
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-test-sequencer"&gt;op-test-sequencer&lt;/a&gt;: Test sequencer for development
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-up"&gt;op-up&lt;/a&gt;: Deployment and management utilities
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-validator"&gt;op-validator&lt;/a&gt;: Tool for validating Optimism chain configurations and deployments
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/op-wheel"&gt;op-wheel&lt;/a&gt;: Database utilities
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/ops"&gt;ops&lt;/a&gt;: Various operational packages
‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/packages"&gt;packages&lt;/a&gt;
‚îÇ   ‚îú‚îÄ‚îÄ &lt;a href="https://raw.githubusercontent.com/ethereum-optimism/optimism/develop/packages/contracts-bedrock"&gt;contracts-bedrock&lt;/a&gt;: OP Stack smart contracts
&lt;/pre&gt; 
&lt;h2&gt;Development and Release Process&lt;/h2&gt; 
&lt;h3&gt;Overview&lt;/h3&gt; 
&lt;p&gt;Please read this section carefully if you're planning to fork or make frequent PRs into this repository.&lt;/p&gt; 
&lt;h3&gt;Production Releases&lt;/h3&gt; 
&lt;p&gt;Production releases are always tags, versioned as &lt;code&gt;&amp;lt;component-name&amp;gt;/v&amp;lt;semver&amp;gt;&lt;/code&gt;. For example, an &lt;code&gt;op-node&lt;/code&gt; release might be versioned as &lt;code&gt;op-node/v1.1.2&lt;/code&gt;, and smart contract releases might be versioned as &lt;code&gt;op-contracts/v1.0.0&lt;/code&gt;. Release candidates are versioned in the format &lt;code&gt;op-node/v1.1.2-rc.1&lt;/code&gt;. We always start with &lt;code&gt;rc.1&lt;/code&gt; rather than &lt;code&gt;rc&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For contract releases, refer to the GitHub release notes for a given release which will list the specific contracts being released. Not all contracts are considered production ready within a release and many are under active development.&lt;/p&gt; 
&lt;p&gt;Tags of the form &lt;code&gt;v&amp;lt;semver&amp;gt;&lt;/code&gt;, such as &lt;code&gt;v1.1.4&lt;/code&gt;, indicate releases of all Go code only, and &lt;strong&gt;DO NOT&lt;/strong&gt; include smart contracts. This naming scheme is required by Golang. In the above list, this means these &lt;code&gt;v&amp;lt;semver&amp;gt;&lt;/code&gt; releases contain all &lt;code&gt;op-*&lt;/code&gt; components and exclude all &lt;code&gt;contracts-*&lt;/code&gt; components.&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;op-geth&lt;/code&gt; embeds upstream geth‚Äôs version inside its own version as follows: &lt;code&gt;vMAJOR.GETH_MAJOR GETH_MINOR GETH_PATCH.PATCH&lt;/code&gt;. Basically, geth‚Äôs version is our minor version. For example if geth is at &lt;code&gt;v1.12.0&lt;/code&gt;, the corresponding op-geth version would be &lt;code&gt;v1.101200.0&lt;/code&gt;. Note that we pad out to three characters for the geth minor version and two characters for the geth patch version. Since we cannot left-pad with zeroes, the geth major version is not padded.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.optimism.io/builders/node-operators/releases"&gt;Node Software Releases&lt;/a&gt; page of the documentation for more information about releases for the latest node components.&lt;/p&gt; 
&lt;p&gt;The full set of components that have releases are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;op-batcher&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;op-contracts&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;op-challenger&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;op-node&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;op-proposer&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;All other components and packages should be considered development components only and do not have releases.&lt;/p&gt; 
&lt;h3&gt;Development branch&lt;/h3&gt; 
&lt;p&gt;The primary development branch is &lt;a href="https://github.com/ethereum-optimism/optimism/tree/develop/"&gt;&lt;code&gt;develop&lt;/code&gt;&lt;/a&gt;. &lt;code&gt;develop&lt;/code&gt; contains the most up-to-date software that remains backwards compatible with the latest experimental &lt;a href="https://docs.optimism.io/chain/networks"&gt;network deployments&lt;/a&gt;. If you're making a backwards compatible change, please direct your pull request towards &lt;code&gt;develop&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Changes to contracts within &lt;code&gt;packages/contracts-bedrock/src&lt;/code&gt; are usually NOT considered backwards compatible.&lt;/strong&gt; Some exceptions to this rule exist for cases in which we absolutely must deploy some new contract after a tag has already been fully deployed. If you're changing or adding a contract and you're unsure about which branch to make a PR into, default to using a feature branch. Feature branches are typically used when there are conflicts between 2 projects touching the same code, to avoid conflicts from merging both into &lt;code&gt;develop&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;All other files within this repository are licensed under the &lt;a href="https://github.com/ethereum-optimism/optimism/raw/master/LICENSE"&gt;MIT License&lt;/a&gt; unless stated otherwise.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>grafana/alloy</title>
      <link>https://github.com/grafana/alloy</link>
      <description>&lt;p&gt;OpenTelemetry Collector distribution with programmable pipelines&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/grafana/alloy/main/docs/sources/assets/logo_alloy_light.svg#gh-dark-mode-only" alt="Grafana Alloy logo" height="100px" /&gt; &lt;img src="https://raw.githubusercontent.com/grafana/alloy/main/docs/sources/assets/logo_alloy_dark.svg#gh-light-mode-only" alt="Grafana Alloy logo" height="100px" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/grafana/alloy/releases"&gt;&lt;img src="https://img.shields.io/github/release/grafana/alloy.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://grafana.com/docs/alloy/latest"&gt;&lt;img src="https://img.shields.io/badge/Documentation-link-blue?logo=gitbook" alt="Documentation link" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Grafana Alloy is an open source OpenTelemetry Collector distribution with built-in Prometheus pipelines and support for metrics, logs, traces, and profiles.&lt;/p&gt; 
&lt;p&gt; &lt;img src="https://raw.githubusercontent.com/grafana/alloy/main/docs/sources/assets/alloy_screenshot.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;What can Alloy do?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Programmable pipelines&lt;/strong&gt;: Use a rich &lt;a href="https://grafana.com/docs/alloy/latest/concepts/configuration-syntax/"&gt;expression-based syntax&lt;/a&gt; for configuring powerful observability pipelines.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;OpenTelemetry Collector Distribution&lt;/strong&gt;: Alloy is a &lt;a href="https://opentelemetry.io/docs/collector/distributions/"&gt;distribution&lt;/a&gt; of OpenTelemetry Collector and supports dozens of its components, alongside new components that make use of Alloy's programmable pipelines.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Big tent&lt;/strong&gt;: Alloy embraces Grafana's "big tent" philosophy, where Alloy can be used with other vendors or open source databases. It has components to perfectly integrate with multiple telemetry ecosystems:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://opentelemetry.io"&gt;OpenTelemetry Collector&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://prometheus.io"&gt;Prometheus&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/grafana/loki"&gt;Grafana Loki&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/grafana/pyroscope"&gt;Grafana Pyroscope&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Kubernetes-native&lt;/strong&gt;: Use components to interact with native and custom Kubernetes resources; no need to learn how to use a separate Kubernetes operator.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Shareable pipelines&lt;/strong&gt;: Use &lt;a href="https://grafana.com/docs/alloy/latest/concepts/modules/"&gt;modules&lt;/a&gt; to share your pipelines with the world.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Automatic workload distribution&lt;/strong&gt;: Configure Alloy instances to form a &lt;a href="https://grafana.com/docs/alloy/latest/concepts/clustering/"&gt;cluster&lt;/a&gt; for automatic workload distribution.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Centralized configuration support&lt;/strong&gt;: Alloy supports retrieving its configuration from a &lt;a href="https://grafana.com/docs/alloy/latest/reference/config-blocks/remotecfg/"&gt;server&lt;/a&gt; for centralized configuration management.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Debugging utilities&lt;/strong&gt;: Use the &lt;a href="https://grafana.com/docs/alloy/latest/tasks/debug/"&gt;built-in UI&lt;/a&gt; for visualizing and debugging pipelines.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Example&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-alloy"&gt;otelcol.receiver.otlp "example" {
  grpc {
    endpoint = "127.0.0.1:4317"
  }

  output {
    metrics = [otelcol.processor.batch.example.input]
    logs    = [otelcol.processor.batch.example.input]
    traces  = [otelcol.processor.batch.example.input]
  }
}

otelcol.processor.batch "example" {
  output {
    metrics = [otelcol.exporter.otlp.default.input]
    logs    = [otelcol.exporter.otlp.default.input]
    traces  = [otelcol.exporter.otlp.default.input]
  }
}

otelcol.exporter.otlp "default" {
  client {
    endpoint = "my-otlp-grpc-server:4317"
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;Check out our &lt;a href="https://grafana.com/docs/alloy/latest"&gt;documentation&lt;/a&gt; to see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grafana.com/docs/alloy/latest/get-started/install/"&gt;Installation instructions&lt;/a&gt; for Alloy&lt;/li&gt; 
 &lt;li&gt;Steps for &lt;a href="https://grafana.com/docs/alloy/latest/get-started/"&gt;Getting started&lt;/a&gt; with Alloy&lt;/li&gt; 
 &lt;li&gt;The list of Alloy &lt;a href="https://grafana.com/docs/alloy/latest/reference/components/"&gt;components&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Release cadence&lt;/h2&gt; 
&lt;p&gt;A new minor release is planned every six weeks.&lt;/p&gt; 
&lt;p&gt;The release cadence is best-effort: if necessary, releases may be performed outside of this cadence, or a scheduled release date can be moved forwards or backwards.&lt;/p&gt; 
&lt;p&gt;Minor releases published on cadence include updating dependencies for upstream OpenTelemetry Collector code if new versions are available. Minor releases published outside of the release cadence may not include these dependency updates.&lt;/p&gt; 
&lt;p&gt;Patch and security releases may be published at any time.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;To engage with the Alloy community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Chat with us on our community Slack channel. To invite yourself to the Grafana Slack, visit &lt;a href="https://slack.grafana.com/"&gt;https://slack.grafana.com/&lt;/a&gt; and join the &lt;code&gt;#alloy&lt;/code&gt; channel.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ask questions on the &lt;a href="https://community.grafana.com/c/grafana-alloy"&gt;Grafana community site&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/grafana/alloy/issues/new"&gt;File an issue&lt;/a&gt; for bugs, issues, and feature suggestions.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Attend the monthly &lt;a href="https://docs.google.com/document/d/1TqaZD1JPfNadZ4V81OCBPCG_TksDYGlNlGdMnTWUSpo"&gt;community call&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Refer to our &lt;a href="https://github.com/grafana/alloy/raw/main/docs/developer/contributing.md"&gt;contributors guide&lt;/a&gt; to learn how to contribute.&lt;/p&gt; 
&lt;p&gt;Thanks to all the people who have already contributed!&lt;/p&gt; 
&lt;a href="https://github.com/grafana/alloy/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=grafana/alloy" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>gravitational/teleport</title>
      <link>https://github.com/gravitational/teleport</link>
      <description>&lt;p&gt;The easiest, and most secure way to access and protect all of your infrastructure.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;Teleport provides connectivity, authentication, access controls and audit for infrastructure.&lt;/p&gt; 
&lt;p&gt;Here is why you might use Teleport:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Set up SSO for all of your cloud infrastructure [1].&lt;/li&gt; 
 &lt;li&gt;Protect access to cloud and on-prem services using mTLS endpoints and short-lived certificates.&lt;/li&gt; 
 &lt;li&gt;Establish tunnels to access services behind NATs and firewalls.&lt;/li&gt; 
 &lt;li&gt;Provide an audit log with session recording and replay for various protocols.&lt;/li&gt; 
 &lt;li&gt;Unify Role-Based Access Control (RBAC) and enforce the principle of least privilege with &lt;a href="https://goteleport.com/features/access-requests/"&gt;access requests&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;[1] The open source version supports only GitHub SSO.&lt;/p&gt; 
&lt;p&gt;Teleport works with SSH, Kubernetes, databases, RDP, and web services.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Architecture: &lt;a href="https://goteleport.com/docs/reference/architecture/"&gt;https://goteleport.com/docs/reference/architecture/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Getting Started: &lt;a href="https://goteleport.com/docs/get-started/"&gt;https://goteleport.com/docs/get-started/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://goteleport.com/download"&gt; &lt;img src="https://raw.githubusercontent.com/gravitational/teleport/master/assets/img/hero-teleport-platform.png" width="750/" /&gt; &lt;/a&gt; 
 &lt;div align="center" style="padding: 25px"&gt; 
  &lt;a href="https://goteleport.com/download"&gt; &lt;img src="https://img.shields.io/github/v/release/gravitational/teleport?sort=semver&amp;amp;label=Release&amp;amp;color=651FFF" /&gt; &lt;/a&gt; 
  &lt;a href="https://golang.org/"&gt; &lt;img src="https://img.shields.io/github/go-mod/go-version/gravitational/teleport?color=7fd5ea" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/gravitational/teleport/raw/master/CODE_OF_CONDUCT.md"&gt; &lt;img src="https://img.shields.io/badge/Contribute-üôå-green.svg" /&gt; &lt;/a&gt; 
  &lt;a href="https://www.gnu.org/licenses/agpl-3.0.en.html"&gt; &lt;img src="https://img.shields.io/badge/AGPL-3.0-red.svg?sanitize=true" /&gt; &lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/#installing-and-running"&gt;Installing and Running&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/#docker"&gt;Docker&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/#building-teleport"&gt;Building Teleport&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/#why-did-we-build-teleport"&gt;Why Did We Build Teleport?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/#more-information"&gt;More Information&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/#support-and-contributing"&gt;Support and Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/#is-teleport-secure-and-production-ready"&gt;Is Teleport Secure and Production Ready?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/#who-built-teleport"&gt;Who Built Teleport?&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Teleport includes an identity-aware access proxy, a CA that issues short-lived certificates, a unified access control system and a tunneling system to access resources behind the firewall.&lt;/p&gt; 
&lt;p&gt;We have implemented Teleport as a single Go binary that integrates with multiple protocols and cloud services:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://goteleport.com/docs/enroll-resources/server-access/introduction/"&gt;SSH nodes&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://goteleport.com/docs/enroll-resources/kubernetes-access/introduction/"&gt;Kubernetes clusters&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://goteleport.com/docs/enroll-resources/database-access/"&gt;PostgreSQL, MongoDB, CockroachDB and MySQL databases&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://goteleport.com/docs/enroll-resources/application-access/introduction/"&gt;Internal Web apps&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://goteleport.com/docs/enroll-resources/desktop-access/introduction/"&gt;Windows Hosts&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://goteleport.com/docs/enroll-resources/server-access/introduction/"&gt;Networked servers&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can set up Teleport as a &lt;a href="https://goteleport.com/docs/admin-guides/deploy-a-cluster/linux-demo"&gt;Linux daemon&lt;/a&gt; or a &lt;a href="https://goteleport.com/docs/admin-guides/deploy-a-cluster/helm-deployments/"&gt;Kubernetes deployment&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Teleport focuses on best practices for infrastructure security:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No need to manage shared secrets such as SSH keys or Kubernetes tokens: it uses certificate-based auth with certificate expiration for all protocols.&lt;/li&gt; 
 &lt;li&gt;Two-factor authentication (2FA) for everything.&lt;/li&gt; 
 &lt;li&gt;Collaboratively troubleshoot issues through session sharing.&lt;/li&gt; 
 &lt;li&gt;Single sign-on (SSO) for everything via GitHub Auth, OpenID Connect, or SAML with endpoints like Okta or Microsoft Entra ID.&lt;/li&gt; 
 &lt;li&gt;Infrastructure introspection: Use Teleport via the CLI or Web UI to view the status of every SSH node, database instance, Kubernetes cluster, or internal web app.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Teleport uses &lt;a href="https://godoc.org/golang.org/x/crypto"&gt;Go crypto&lt;/a&gt;. It is &lt;em&gt;fully compatible with OpenSSH&lt;/em&gt;, &lt;code&gt;sshd&lt;/code&gt; servers, and &lt;code&gt;ssh&lt;/code&gt; clients, Kubernetes clusters and more.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Project Links&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://goteleport.com/"&gt;Teleport Website&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;The official website of the project.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://goteleport.com/docs/"&gt;Documentation&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Admin guide, user manual and more.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://goteleport.com/blog/"&gt;Blog&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Our blog where we publish Teleport news.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/gravitational/teleport/discussions"&gt;Forum&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Ask us a setup question, post your tutorial, feedback, or idea on our forum.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://goteleport.com/slack"&gt;Slack&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Need help with your setup? Ping us in our Slack channel.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://goteleport.com/pricing"&gt;Cloud-hosted&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;We offer Enterprise with a Cloud-hosted option. For teams that require easy and secure access to their computing environments.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Installing and Running&lt;/h2&gt; 
&lt;p&gt;To set up a single-instance Teleport cluster, follow our &lt;a href="https://goteleport.com/docs/admin-guides/deploy-a-cluster/linux-demo/"&gt;getting started guide&lt;/a&gt;. You can then register your servers, Kubernetes clusters, and other infrastructure with your Teleport cluster.&lt;/p&gt; 
&lt;p&gt;You can also get started with Teleport Enterprise Cloud, a managed Teleport deployment that makes it easier to enable secure access to your infrastructure.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://goteleport.com/signup"&gt;Sign up for a free trial&lt;/a&gt; of Teleport Enterprise Cloud.&lt;/p&gt; 
&lt;p&gt;Follow our guide to &lt;a href="https://goteleport.com/docs/get-started/"&gt;registering your first server&lt;/a&gt; with Teleport Enterprise Cloud.&lt;/p&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;h3&gt;Deploy Teleport&lt;/h3&gt; 
&lt;p&gt;If you wish to deploy Teleport inside a Docker container see the &lt;a href="https://goteleport.com/docs/installation/#running-teleport-on-docker"&gt;installation guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;For Local Testing and Development&lt;/h3&gt; 
&lt;p&gt;To run a full test suite locally, see &lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/BUILD_macos.md#local-tests-dependencies"&gt;the test dependencies list&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Building Teleport&lt;/h2&gt; 
&lt;p&gt;The &lt;code&gt;teleport&lt;/code&gt; repository contains the Teleport daemon binary (written in Go) and a web UI written in TypeScript.&lt;/p&gt; 
&lt;p&gt;If your intention is to build and deploy for use in a production infrastructure a released tag should be used. The default branch, &lt;code&gt;master&lt;/code&gt;, is the current development branch for an upcoming major version. Get the latest release tags listed at &lt;a href="https://goteleport.com/download/"&gt;https://goteleport.com/download/&lt;/a&gt; and then use that tag in the &lt;code&gt;git clone&lt;/code&gt;. For example &lt;code&gt;git clone https://github.com/gravitational/teleport.git -b v16.0.0&lt;/code&gt; gets release v16.0.0.&lt;/p&gt; 
&lt;h3&gt;Dockerized Build&lt;/h3&gt; 
&lt;p&gt;It is often easiest to build with Docker, which ensures that all required tooling is available for the build. To execute a dockerized build, ensure that docker is installed and running, and execute:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;make -C build.assets build-binaries
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Local Build&lt;/h3&gt; 
&lt;h4&gt;Dependencies&lt;/h4&gt; 
&lt;p&gt;The following dependencies are required to build Teleport from source. For maximum compatibility, install the versions of these dependencies using the versions listed in &lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/build.assets/versions.mk"&gt;&lt;code&gt;build.assets/versions.mk&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://golang.org/dl/"&gt;&lt;code&gt;Go&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.rust-lang.org/tools/install"&gt;&lt;code&gt;Rust&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/en/download/"&gt;&lt;code&gt;Node.js&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Yubico/libfido2"&gt;&lt;code&gt;libfido2&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.freedesktop.org/wiki/Software/pkg-config/"&gt;&lt;code&gt;pkg-config&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For an example of Dev Environment setup on a Mac, see &lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/BUILD_macos.md"&gt;these instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Perform a build&lt;/h4&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;The Go compiler is somewhat sensitive to the amount of memory: you will need &lt;strong&gt;at least&lt;/strong&gt; 1GB of virtual memory to compile Teleport. A 512MB instance without swap will &lt;strong&gt;not&lt;/strong&gt; work.&lt;/li&gt; 
  &lt;li&gt;This will build the latest version of Teleport, &lt;strong&gt;regardless&lt;/strong&gt; of whether it is stable. If you want to build the latest stable release, run &lt;code&gt;git checkout&lt;/code&gt; and &lt;code&gt;git submodule update --recursive&lt;/code&gt; to the corresponding tag (for example,&lt;/li&gt; 
  &lt;li&gt;run &lt;code&gt;git checkout v8.0.0&lt;/code&gt;) &lt;strong&gt;before&lt;/strong&gt; performing a build.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Get the source&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;git clone https://github.com/gravitational/teleport.git
cd teleport
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To perform a build&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make full
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;tsh&lt;/code&gt; dynamically links against libfido2 by default, to support development environments, as long as the library itself can be found:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;$ brew install libfido2 pkg-config  # Replace with your package manager of choice

$ make build/tsh
&amp;gt; libfido2 found, setting FIDO2=dynamic
&amp;gt; (...)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Release binaries are linked statically against libfido2. You may switch the linking mode using the FIDO2 variable:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make build/tsh FIDO2=dynamic # dynamic linking
make build/tsh FIDO2=static  # static linking, for an easy setup use `make enter`
                             # or `build.assets/macos/build-fido2-macos.sh`.
make build/tsh FIDO2=off     # doesn't link libfido2 in any way
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;tsh&lt;/code&gt; builds with Touch ID support require access to an Apple Developer account. If you are a Teleport maintainer, ask the team for access.&lt;/p&gt; 
&lt;h4&gt;Build output and run locally&lt;/h4&gt; 
&lt;p&gt;If the build succeeds, the installer will place the binaries in the &lt;code&gt;build&lt;/code&gt; directory.&lt;/p&gt; 
&lt;p&gt;Before starting, create default data directories:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;sudo mkdir -p -m0700 /var/lib/teleport
sudo chown $USER /var/lib/teleport
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Running Teleport in a hot reload mode&lt;/h4&gt; 
&lt;p&gt;To speed up your development process, you can run Teleport using &lt;a href="https://github.com/githubnemo/CompileDaemon"&gt;&lt;code&gt;CompileDaemon&lt;/code&gt;&lt;/a&gt;. This will build and run the Teleport binary, and then rebuild and restart it whenever any Go source files change.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Install CompileDaemon:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;go install github.com/githubnemo/CompileDaemon@latest
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note that we use &lt;code&gt;go install&lt;/code&gt; instead of the suggested &lt;code&gt;go get&lt;/code&gt;, because we don't want CompileDaemon to become a dependency of the project.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Build and run the Teleport binary:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;make teleport-hot-reload
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;By default, this runs a &lt;code&gt;teleport start&lt;/code&gt; command. If you want to customize the command, for example by providing a custom config file location, you can use the &lt;code&gt;TELEPORT_ARGS&lt;/code&gt; parameter:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-shell"&gt;make teleport-hot-reload TELEPORT_ARGS='start --config=/path/to/config.yaml'
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Note that you still need to run &lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/api/proto/README.md"&gt;&lt;code&gt;make grpc&lt;/code&gt;&lt;/a&gt; if you modify any Protocol Buffers files to regenerate the generated Go sources; regenerating these sources should in turn cause the CompileDaemon to rebuild and restart Teleport.&lt;/p&gt; 
&lt;h3&gt;Web UI&lt;/h3&gt; 
&lt;p&gt;The Teleport Web UI resides in the &lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/web"&gt;web&lt;/a&gt; directory.&lt;/p&gt; 
&lt;h4&gt;Rebuilding Web UI for development&lt;/h4&gt; 
&lt;p&gt;To rebuild the Teleport UI package, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;make docker-ui
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then you can replace Teleport Web UI files with the files from the newly-generated &lt;code&gt;/dist&lt;/code&gt; folder.&lt;/p&gt; 
&lt;p&gt;To enable speedy iterations on the Web UI, you can run a &lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/web#web-ui"&gt;local web-dev server&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also tell Teleport to load the Web UI assets from the source directory. To enable this behavior, set the environment variable &lt;code&gt;DEBUG=1&lt;/code&gt; and rebuild with the default target:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run Teleport as a single-node cluster in development mode:
DEBUG=1 ./build/teleport start -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Keep the server running in this mode, and make your UI changes in &lt;code&gt;/dist&lt;/code&gt; directory. For instructions about how to update the Web UI, read &lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/web#readme"&gt;the &lt;code&gt;web&lt;/code&gt; README&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Managing dependencies&lt;/h3&gt; 
&lt;p&gt;All dependencies are managed using &lt;a href="https://blog.golang.org/using-go-modules"&gt;Go modules&lt;/a&gt;. Here are the instructions for some common tasks:&lt;/p&gt; 
&lt;h4&gt;Add a new dependency&lt;/h4&gt; 
&lt;p&gt;Latest version:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/new/dependency
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;and update the source to use this dependency.&lt;/p&gt; 
&lt;p&gt;To get a specific version, use &lt;code&gt;go get github.com/new/dependency@version&lt;/code&gt; instead.&lt;/p&gt; 
&lt;h4&gt;Set dependency to a specific version&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go get github.com/new/dependency@version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Update dependency to the latest version&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go get -u github.com/new/dependency
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Update all dependencies&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go get -u all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Debugging dependencies&lt;/h4&gt; 
&lt;p&gt;Why is a specific package imported?&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;go mod why $pkgname&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Why is a specific module imported?&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;go mod why -m $modname&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Why is a specific version of a module imported?&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;go mod graph | grep $modname&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Why did We Build Teleport?&lt;/h2&gt; 
&lt;p&gt;The Teleport creators used to work together at Rackspace. We noticed that most cloud computing users struggle with setting up and configuring infrastructure security because popular tools, while flexible, are complex to understand and expensive to maintain. Additionally, most organizations use multiple infrastructure form factors such as several cloud providers, multiple cloud accounts, servers in colocation, and even smart devices. Some of those devices run on untrusted networks, behind third-party firewalls. This only magnifies complexity and increases operational overhead.&lt;/p&gt; 
&lt;p&gt;We had a choice, either start a security consulting business or build a solution that's dead-easy to use and understand. A real-time representation of all of your servers in the same room as you, as if they were magically &lt;em&gt;teleported&lt;/em&gt;. Thus, Teleport was born!&lt;/p&gt; 
&lt;h2&gt;More Information&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://goteleport.com/docs/get-started/"&gt;Teleport Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://goteleport.com/docs/reference/architecture/"&gt;Teleport Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://goteleport.com/docs/reference/"&gt;Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://goteleport.com/docs/faq"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support and Contributing&lt;/h2&gt; 
&lt;p&gt;We offer a few different options for support. First of all, we try to provide clear and comprehensive documentation. The docs are also in GitHub, so feel free to create a PR or file an issue if you have ideas for improvements. If you still have questions after reviewing our docs, you can also:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Join &lt;a href="https://github.com/gravitational/teleport/discussions"&gt;Teleport Discussions&lt;/a&gt; to ask questions. Our engineers are available there to help you.&lt;/li&gt; 
 &lt;li&gt;If you want to contribute to Teleport or file a bug report/issue, you can create an issue here in GitHub.&lt;/li&gt; 
 &lt;li&gt;If you are interested in Teleport Enterprise or more responsive support during a POC, we can also create a dedicated Slack channel for you during your POC. You can &lt;a href="https://goteleport.com/pricing/"&gt;reach out to us through our website&lt;/a&gt; to arrange for a POC.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Is Teleport Secure and Production-Ready?&lt;/h2&gt; 
&lt;p&gt;Yes -- Teleport is production-ready and designed to protect and facilitate access to the most precious and mission-critical applications.&lt;/p&gt; 
&lt;p&gt;Teleport has completed several security audits from nationally and internationally recognized technology security companies.&lt;/p&gt; 
&lt;p&gt;We publicize some of our audit results, security philosophy and related information on our &lt;a href="https://trust.goteleport.com/"&gt;trust page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can see the list of companies that use Teleport in production on the Teleport &lt;a href="https://goteleport.com/case-study/"&gt;product page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Who Built Teleport?&lt;/h2&gt; 
&lt;p&gt;Teleport was created by &lt;a href="https://goteleport.com"&gt;Gravitational, Inc.&lt;/a&gt;. We have built Teleport by borrowing from our previous experiences at Rackspace. &lt;a href="https://goteleport.com/about/"&gt;Learn more about Teleport and our history&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Teleport is distributed in multiple forms with different licensing implications.&lt;/p&gt; 
&lt;p&gt;The Teleport API module (all code in this repository under &lt;code&gt;/api&lt;/code&gt;) is available under the &lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/api/LICENSE"&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The remainder of the source code in this repository is available under the &lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/LICENSE"&gt;GNU Affero General Public License&lt;/a&gt;. Users compiling Teleport from source must comply with the terms of this license.&lt;/p&gt; 
&lt;p&gt;Teleport Community Edition builds distributed on &lt;a href="http://goteleport.com/download"&gt;http://goteleport.com/download&lt;/a&gt; are available under a &lt;a href="https://raw.githubusercontent.com/gravitational/teleport/master/build.assets/LICENSE-community"&gt;modified Apache 2.0 license&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anchore/syft</title>
      <link>https://github.com/anchore/syft</link>
      <description>&lt;p&gt;CLI tool and library for generating a Software Bill of Materials from container images and filesystems&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://user-images.githubusercontent.com/5199289/136844524-1527b09f-c5cb-4aa9-be54-5aa92a6086c1.png" width="271" alt="Cute pink owl syft logo" /&gt; &lt;/p&gt; 
&lt;h1&gt;Syft&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;A CLI tool and Go library for generating a Software Bill of Materials (SBOM) from container images and filesystems. Exceptional for vulnerability detection when used with a scanner like &lt;a href="https://github.com/anchore/grype"&gt;Grype&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &amp;nbsp;&lt;a href="https://github.com/anchore/syft/actions/workflows/validations.yaml" target="_blank"&gt;&lt;img alt="Validations" src="https://github.com/anchore/syft/actions/workflows/validations.yaml/badge.svg?sanitize=true" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://goreportcard.com/report/github.com/anchore/syft" target="_blank"&gt;&lt;img alt="Go Report Card" src="https://goreportcard.com/badge/github.com/anchore/syft" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://github.com/anchore/syft/releases/latest" target="_blank"&gt;&lt;img alt="GitHub release" src="https://img.shields.io/github/release/anchore/syft.svg?sanitize=true" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://github.com/anchore/syft" target="_blank"&gt;&lt;img alt="GitHub go.mod Go version" src="https://img.shields.io/github/go-mod/go-version/anchore/syft.svg?sanitize=true" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="" target="_blank"&gt;&lt;img alt="License: Apache-2.0" src="https://img.shields.io/badge/License-Apache%202.0-blue.svg?sanitize=true" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a href="https://anchore.com/discourse" target="_blank"&gt;&lt;img alt="Join our Discourse" src="https://img.shields.io/badge/Discourse-Join-blue?logo=discourse" /&gt;&lt;/a&gt;&amp;nbsp; &amp;nbsp;&lt;a rel="me" href="https://fosstodon.org/@syft"&gt;&lt;img alt="Follow on Mastodon" src="https://img.shields.io/badge/Mastodon-Follow-blue?logoColor=white&amp;amp;logo=mastodon" /&gt;&lt;/a&gt;&amp;nbsp; &lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/590471/90277200-2a253000-de33-11ea-893f-32c219eea11a.gif" alt="syft-demo" /&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;Syft is a powerful and easy-to-use open-source tool for generating Software Bill of Materials (SBOMs) for container images and filesystems. It provides detailed visibility into the packages and dependencies in your software, helping you manage vulnerabilities, license compliance, and software supply chain security.&lt;/p&gt; 
&lt;p&gt;Syft development is sponsored by &lt;a href="https://anchore.com/"&gt;Anchore&lt;/a&gt;, and is released under the &lt;a href="https://github.com/anchore/syft?tab=Apache-2.0-1-ov-file"&gt;Apache-2.0 License&lt;/a&gt;. For commercial support options with Syft or Grype, please &lt;a href="https://get.anchore.com/contact/"&gt;contact Anchore&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Generates SBOMs for container images, filesystems, archives, and more to discover packages and libraries&lt;/li&gt; 
 &lt;li&gt;Supports OCI, Docker and &lt;a href="https://github.com/sylabs/singularity"&gt;Singularity&lt;/a&gt; image formats&lt;/li&gt; 
 &lt;li&gt;Linux distribution identification&lt;/li&gt; 
 &lt;li&gt;Works seamlessly with &lt;a href="https://github.com/anchore/grype"&gt;Grype&lt;/a&gt; (a fast, modern vulnerability scanner)&lt;/li&gt; 
 &lt;li&gt;Able to create signed SBOM attestations using the &lt;a href="https://github.com/in-toto/attestation/raw/main/spec/README.md"&gt;in-toto specification&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Convert between SBOM formats, such as CycloneDX, SPDX, and Syft's own format.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Syft binaries are provided for Linux, macOS and Windows.&lt;/p&gt; 
&lt;h3&gt;Recommended&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSfL https://get.anchore.io/syft | sudo sh -s -- -b /usr/local/bin
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Install script options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-b&lt;/code&gt;: Specify a custom installation directory (defaults to &lt;code&gt;./bin&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-d&lt;/code&gt;: More verbose logging levels (&lt;code&gt;-d&lt;/code&gt; for debug, &lt;code&gt;-dd&lt;/code&gt; for trace)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v&lt;/code&gt;: Verify the signature of the downloaded artifact before installation (requires &lt;a href="https://github.com/sigstore/cosign"&gt;&lt;code&gt;cosign&lt;/code&gt;&lt;/a&gt; to be installed)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Homebrew&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install syft
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Scoop&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;scoop install syft
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Chocolatey&lt;/h3&gt; 
&lt;p&gt;The chocolatey distribution of Syft is community-maintained and not distributed by the Anchore team&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;choco install syft -y
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Nix&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Nix packaging of Syft is &lt;a href="https://github.com/NixOS/nixpkgs/raw/master/pkgs/by-name/sy/syft/package.nix"&gt;community maintained&lt;/a&gt;. Syft is available in the &lt;a href="https://wiki.nixos.org/wiki/Nix_channels#The_official_channels"&gt;stable channel&lt;/a&gt; since NixOS &lt;code&gt;22.05&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nix-env -i syft
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;... or, just try it out in an ephemeral nix shell:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nix-shell -p syft
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;h3&gt;SBOM&lt;/h3&gt; 
&lt;p&gt;To generate an SBOM for a container image:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;syft &amp;lt;image&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The above output includes only software that is visible in the container (i.e., the squashed representation of the image). To include software from all image layers in the SBOM, regardless of its presence in the final image, provide &lt;code&gt;--scope all-layers&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;syft &amp;lt;image&amp;gt; --scope all-layers
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Output formats&lt;/h3&gt; 
&lt;p&gt;The output format for Syft is configurable as well using the &lt;code&gt;-o&lt;/code&gt; (or &lt;code&gt;--output&lt;/code&gt;) option:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;syft &amp;lt;image&amp;gt; -o &amp;lt;format&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Where the &lt;code&gt;formats&lt;/code&gt; available are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;syft-json&lt;/code&gt;: Use this to get as much information out of Syft as possible!&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;syft-text&lt;/code&gt;: A row-oriented, human-and-machine-friendly output.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cyclonedx-xml&lt;/code&gt;: A XML report conforming to the &lt;a href="https://cyclonedx.org/specification/overview/"&gt;CycloneDX 1.6 specification&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cyclonedx-xml@1.5&lt;/code&gt;: A XML report conforming to the &lt;a href="https://cyclonedx.org/specification/overview/"&gt;CycloneDX 1.5 specification&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cyclonedx-json&lt;/code&gt;: A JSON report conforming to the &lt;a href="https://cyclonedx.org/specification/overview/"&gt;CycloneDX 1.6 specification&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;cyclonedx-json@1.5&lt;/code&gt;: A JSON report conforming to the &lt;a href="https://cyclonedx.org/specification/overview/"&gt;CycloneDX 1.5 specification&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;spdx-tag-value&lt;/code&gt;: A tag-value formatted report conforming to the &lt;a href="https://spdx.github.io/spdx-spec/v2.3/"&gt;SPDX 2.3 specification&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;spdx-tag-value@2.2&lt;/code&gt;: A tag-value formatted report conforming to the &lt;a href="https://spdx.github.io/spdx-spec/v2.2.2/"&gt;SPDX 2.2 specification&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;spdx-json&lt;/code&gt;: A JSON report conforming to the &lt;a href="https://github.com/spdx/spdx-spec/raw/v2.3/schemas/spdx-schema.json"&gt;SPDX 2.3 JSON Schema&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;spdx-json@2.2&lt;/code&gt;: A JSON report conforming to the &lt;a href="https://github.com/spdx/spdx-spec/raw/v2.2/schemas/spdx-schema.json"&gt;SPDX 2.2 JSON Schema&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;github-json&lt;/code&gt;: A JSON report conforming to GitHub's dependency snapshot format.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;syft-table&lt;/code&gt;: A columnar summary (default).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;template&lt;/code&gt;: Lets the user specify the output format. See &lt;a href="https://raw.githubusercontent.com/anchore/syft/main/#using-templates"&gt;"Using templates"&lt;/a&gt; below.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note that flags using the @
 &lt;version&gt;
   can be used for earlier versions of each specification as well.
 &lt;/version&gt;&lt;/p&gt; 
&lt;h3&gt;Supported Ecosystems&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Alpine (apk)&lt;/li&gt; 
 &lt;li&gt;Bitnami packages&lt;/li&gt; 
 &lt;li&gt;C (conan)&lt;/li&gt; 
 &lt;li&gt;C++ (conan)&lt;/li&gt; 
 &lt;li&gt;Dart (pubs)&lt;/li&gt; 
 &lt;li&gt;Debian (dpkg)&lt;/li&gt; 
 &lt;li&gt;Dotnet (deps.json)&lt;/li&gt; 
 &lt;li&gt;Objective-C (cocoapods)&lt;/li&gt; 
 &lt;li&gt;Elixir (mix)&lt;/li&gt; 
 &lt;li&gt;Erlang (rebar3)&lt;/li&gt; 
 &lt;li&gt;Go (go.mod, Go binaries)&lt;/li&gt; 
 &lt;li&gt;GitHub (workflows, actions)&lt;/li&gt; 
 &lt;li&gt;Haskell (cabal, stack)&lt;/li&gt; 
 &lt;li&gt;Java (jar, ear, war, par, sar, nar, native-image)&lt;/li&gt; 
 &lt;li&gt;JavaScript (npm, yarn)&lt;/li&gt; 
 &lt;li&gt;Jenkins Plugins (jpi, hpi)&lt;/li&gt; 
 &lt;li&gt;Linux kernel archives (vmlinz)&lt;/li&gt; 
 &lt;li&gt;Linux kernel modules (ko)&lt;/li&gt; 
 &lt;li&gt;Nix (outputs in /nix/store)&lt;/li&gt; 
 &lt;li&gt;PHP (composer, PECL, Pear)&lt;/li&gt; 
 &lt;li&gt;Python (wheel, egg, poetry, requirements.txt, uv)&lt;/li&gt; 
 &lt;li&gt;Red Hat (rpm)&lt;/li&gt; 
 &lt;li&gt;Ruby (gem)&lt;/li&gt; 
 &lt;li&gt;Rust (cargo.lock, auditable binary)&lt;/li&gt; 
 &lt;li&gt;Swift (cocoapods, swift-package-manager)&lt;/li&gt; 
 &lt;li&gt;Wordpress plugins&lt;/li&gt; 
 &lt;li&gt;Terraform providers (.terraform.lock.hcl)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Our &lt;a href="https://github.com/anchore/syft/wiki"&gt;wiki&lt;/a&gt; contains further details on the following topics:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/supported-sources"&gt;Supported Sources&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/file-selection"&gt;File Selection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/excluding-file-paths"&gt;Excluding file paths&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/output-formats"&gt;Output formats&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/package-cataloger-selection"&gt;Package Cataloger Selection&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/package-cataloger-selection#concepts"&gt;Concepts&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/package-cataloger-selection#examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/using-templates"&gt;Using templates&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/multiple-outputs"&gt;Multiple outputs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/private-registry-authentication"&gt;Private Registry Authentication&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/private-registry-authentication#local-docker"&gt;Local Docker Credentials&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/private-registry-authentication#docker-credentials-in-kubernetes"&gt;Docker Credentials in Kubernetes&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/attestation"&gt;Attestation (experimental)&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/attestation#keyless-support"&gt;Keyless Support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/attestation#local-private-key-support"&gt;Local private key support&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/attestation#adding-an-sbom-to-an-image-as-an-attestation-using-syft"&gt;Adding an SBOM to an image as an attestation using Syft&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anchore/syft/wiki/configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Check out our &lt;a href="https://raw.githubusercontent.com/anchore/syft/main/CONTRIBUTING.md"&gt;contributing&lt;/a&gt; guide and &lt;a href="https://raw.githubusercontent.com/anchore/syft/main/DEVELOPING.md"&gt;developer&lt;/a&gt; docs.&lt;/p&gt; 
&lt;h2&gt;Syft Team Meetings&lt;/h2&gt; 
&lt;p&gt;The Syft Team hold regular community meetings online. All are welcome to join to bring topics for discussion.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check the &lt;a href="https://calendar.google.com/calendar/u/0/r?cid=Y182OTM4dGt0MjRtajI0NnNzOThiaGtnM29qNEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t"&gt;calendar&lt;/a&gt; for the next meeting date.&lt;/li&gt; 
 &lt;li&gt;Add items to the &lt;a href="https://docs.google.com/document/d/1ZtSAa6fj2a6KRWviTn3WoJm09edvrNUp4Iz_dOjjyY8/edit?usp=sharing"&gt;agenda&lt;/a&gt; (join &lt;a href="https://groups.google.com/g/anchore-oss-community"&gt;this group&lt;/a&gt; for write access to the &lt;a href="https://docs.google.com/document/d/1ZtSAa6fj2a6KRWviTn3WoJm09edvrNUp4Iz_dOjjyY8/edit?usp=sharing"&gt;agenda&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;See you there!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Syft Logo&lt;/h2&gt; 
&lt;p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"&gt;&lt;a property="dct:title" rel="cc:attributionURL" href="https://anchore.com/wp-content/uploads/2024/11/syft-logo.svg"&gt;Syft Logo&lt;/a&gt; by &lt;a rel="cc:attributionURL dct:creator" property="cc:attributionName" href="https://anchore.com/"&gt;Anchore&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"&gt;CC BY 4.0&lt;img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?sanitize=true" alt="" /&gt;&lt;img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hashicorp/terraform-provider-azurerm</title>
      <link>https://github.com/hashicorp/terraform-provider-azurerm</link>
      <description>&lt;p&gt;Terraform provider for Azure Resource Manager&lt;/p&gt;&lt;hr&gt;&lt;a href="https://terraform.io"&gt; &lt;img src="https://raw.githubusercontent.com/hashicorp/terraform-provider-azurerm/main/.github/tf.png" alt="Terraform logo" title="Terraform" align="left" height="50" /&gt; &lt;/a&gt; 
&lt;h1&gt;Terraform Provider for Azure (Resource Manager)&lt;/h1&gt; 
&lt;p&gt;The AzureRM Terraform Provider allows managing resources within Azure Resource Manager.&lt;/p&gt; 
&lt;p&gt;When using version 4.0 of the AzureRM Provider we recommend using the latest version of Terraform Core (&lt;a href="https://developer.hashicorp.com/terraform/install"&gt;the latest version can be found here&lt;/a&gt;).&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.terraform.io"&gt;Terraform Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs"&gt;AzureRM Provider Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hashicorp/terraform-provider-azurerm/tree/main/examples"&gt;AzureRM Provider Usage Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://terraform-azure.slack.com"&gt;Slack Workspace for Contributors&lt;/a&gt; (&lt;a href="https://join.slack.com/t/terraform-azure/shared_invite/enQtNDMzNjQ5NzcxMDc3LWNiY2ZhNThhNDgzNmY0MTM0N2MwZjE4ZGU0MjcxYjUyMzRmN2E5NjZhZmQ0ZTA1OTExMGNjYzA4ZDkwZDYxNDE"&gt;Request Invite&lt;/a&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage Example&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-hcl"&gt;# 1. Specify the version of the AzureRM Provider to use
terraform {
  required_providers {
    azurerm = {
      source = "hashicorp/azurerm"
      version = "=4.0.0"
    }
  }
}

# 2. Configure the AzureRM Provider
provider "azurerm" {
  # The AzureRM Provider supports authenticating using via the Azure CLI, a Managed Identity
  # and a Service Principal. More information on the authentication methods supported by
  # the AzureRM Provider can be found here:
  # https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs#authenticating-to-azure

  # The features block allows changing the behaviour of the Azure Provider, more
  # information can be found here:
  # https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/guides/features-block
  features {}
}

# 3. Create a resource group
resource "azurerm_resource_group" "example" {
  name     = "example-resources"
  location = "West Europe"
}

# 4. Create a virtual network within the resource group
resource "azurerm_virtual_network" "example" {
  name                = "example-network"
  resource_group_name = azurerm_resource_group.example.name
  location            = azurerm_resource_group.example.location
  address_space       = ["10.0.0.0/16"]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs"&gt;Usage documentation for the AzureRM Provider can be found in the Terraform Registry&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.hashicorp.com/collections/terraform/azure-get-started"&gt;Learn more about Terraform and the AzureRM Provider on HashiCorp Learn&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/hashicorp/terraform-provider-azurerm/tree/main/examples"&gt;Additional examples can be found in the &lt;code&gt;./examples&lt;/code&gt; folder within this repository&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Developing &amp;amp; Contributing to the Provider&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/hashicorp/terraform-provider-azurerm/main/DEVELOPER.md"&gt;DEVELOPER.md&lt;/a&gt; file is a basic outline on how to build and develop the provider while more detailed guides geared towards contributors can be found in the &lt;a href="https://github.com/hashicorp/terraform-provider-azurerm/tree/main/contributing"&gt;&lt;code&gt;/contributing&lt;/code&gt;&lt;/a&gt; directory of this repository.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>kagent-dev/kagent</title>
      <link>https://github.com/kagent-dev/kagent</link>
      <description>&lt;p&gt;Cloud Native Agentic AI | Discord: https://bit.ly/kagentdiscord&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/kagent-dev/kagent/main/img/icon-dark.svg" alt="kagent" width="400" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/kagent-dev/kagent/main/img/icon-light.svg" alt="kagent" width="400" /&gt; 
  &lt;img alt="kagent" src="https://raw.githubusercontent.com/kagent-dev/kagent/main/img/icon-light.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; 
 &lt;div&gt; 
  &lt;a href="https://github.com/kagent-dev/kagent/releases"&gt; &lt;img src="https://img.shields.io/github/v/release/kagent-dev/kagent?style=flat&amp;amp;label=Latest%20version" alt="Release" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/kagent-dev/kagent/actions/workflows/ci.yaml"&gt; &lt;img src="https://github.com/kagent-dev/kagent/actions/workflows/ci.yaml/badge.svg?sanitize=true" alt="Build Status" height="20" /&gt; &lt;/a&gt; 
  &lt;a href="https://opensource.org/licenses/Apache-2.0"&gt; &lt;img src="https://img.shields.io/badge/License-Apache2.0-brightgreen.svg?style=flat" alt="License: Apache 2.0" /&gt; &lt;/a&gt; 
  &lt;a href="https://github.com/kagent-dev/kagent"&gt; &lt;img src="https://img.shields.io/github/stars/kagent-dev/kagent.svg?style=flat&amp;amp;logo=github&amp;amp;label=Stars" alt="Stars" /&gt; &lt;/a&gt; 
  &lt;a href="https://discord.gg/Fu3k65f2k3"&gt; &lt;img src="https://img.shields.io/discord/1346225185166065826?style=flat&amp;amp;label=Join%20Discord&amp;amp;color=6D28D9" alt="Discord" /&gt; &lt;/a&gt; 
  &lt;a href="https://deepwiki.com/kagent-dev/kagent"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; 
  &lt;a href="https://codespaces.new/kagent-dev/kagent"&gt; &lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="Open in Github Codespaces" style="max-width: 100%;" height="20" /&gt; &lt;/a&gt; 
  &lt;a href="https://www.bestpractices.dev/projects/10723"&gt;&lt;img src="https://www.bestpractices.dev/projects/10723/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;kagent&lt;/strong&gt; is a Kubernetes native framework for building AI agents. Kubernetes is the most popular orchestration platform for running workloads, and &lt;strong&gt;kagent&lt;/strong&gt; makes it easy to build, deploy and manage AI agents in Kubernetes. The &lt;strong&gt;kagent&lt;/strong&gt; framework is designed to be easy to understand and use, and to provide a flexible and powerful way to build and manage AI agents.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/kagent-dev/kagent/main/img/hero.png" alt="Autogen Framework" width="500" /&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://kagent.dev/docs/kagent/getting-started/quickstart"&gt;Quick Start&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://kagent.dev/docs/kagent/introduction/installation"&gt;Installation guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;The kagent documentation is available at &lt;a href="https://kagent.dev/docs/kagent"&gt;kagent.dev/docs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Core Concepts&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Agents&lt;/strong&gt;: Agents are the main building block of kagent. They are a system prompt, a set of tools and agents, and an LLM configuration represented with a Kubernetes custom resource called "Agent".&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM Providers&lt;/strong&gt;: Kagent supports multiple LLM providers, including &lt;a href="https://kagent.dev/docs/kagent/supported-providers/openai"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://kagent.dev/docs/kagent/supported-providers/azure-openai"&gt;Azure OpenAI&lt;/a&gt;, &lt;a href="https://kagent.dev/docs/kagent/supported-providers/anthropic"&gt;Anthropic&lt;/a&gt;, &lt;a href="https://kagent.dev/docs/kagent/supported-providers/google-vertexai"&gt;Google Vertex AI&lt;/a&gt;, &lt;a href="https://kagent.dev/docs/kagent/supported-providers/ollama"&gt;Ollama&lt;/a&gt; and any other &lt;a href="https://kagent.dev/docs/kagent/supported-providers/custom-models"&gt;custom providers and models&lt;/a&gt; accessible via AI gateways. Providers are represented by the ModelConfig resource.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MCP Tools&lt;/strong&gt;: Agents can connect to any MCP server that provides tools. Kagent comes with an MCP server with tools for Kubernetes, Istio, Helm, Argo, Prometheus, Grafana, Cilium, and others. All tools are Kubernetes custom resources (ToolServers) and can be used by multiple agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observability&lt;/strong&gt;: Kagent supports &lt;a href="https://kagent.dev/docs/kagent/getting-started/tracing"&gt;OpenTelemetry tracing&lt;/a&gt;, which allows you to monitor what's happening with your agents and tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Core Principles&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes Native&lt;/strong&gt;: Kagent is designed to be easy to understand and use, and to provide a flexible and powerful way to build and manage AI agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Extensible&lt;/strong&gt;: Kagent is designed to be extensible, so you can add your own agents and tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible&lt;/strong&gt;: Kagent is designed to be flexible, to suit any AI agent use case.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Observable&lt;/strong&gt;: Kagent is designed to be observable, so you can monitor the agents and tools using all common monitoring frameworks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Declarative&lt;/strong&gt;: Kagent is designed to be declarative, so you can define the agents and tools in a YAML file.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testable&lt;/strong&gt;: Kagent is designed to be tested and debugged easily. This is especially important for AI agent applications.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;The kagent framework is designed to be easy to understand and use, and to provide a flexible and powerful way to build and manage AI agents.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/kagent-dev/kagent/main/img/arch.png" alt="kagent" width="500" /&gt; 
&lt;/div&gt; 
&lt;p&gt;Kagent has 4 core components:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Controller&lt;/strong&gt;: The controller is a Kubernetes controller that watches the kagent custom resources and creates the necessary resources to run the agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI&lt;/strong&gt;: The UI is a web UI that allows you to manage the agents and tools.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: The engine runs your agents using &lt;a href="https://google.github.io/adk-docs/"&gt;ADK&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CLI&lt;/strong&gt;: The CLI is a command-line tool that allows you to manage the agents and tools.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;kagent&lt;/code&gt; is currently in active development. You can check out the full roadmap in the project Kanban board &lt;a href="https://github.com/orgs/kagent-dev/projects/3"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Local development&lt;/h2&gt; 
&lt;p&gt;For instructions on how to run everything locally, see the &lt;a href="https://raw.githubusercontent.com/kagent-dev/kagent/main/DEVELOPMENT.md"&gt;DEVELOPMENT.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;For instructions on how to contribute to the kagent project, see the &lt;a href="https://raw.githubusercontent.com/kagent-dev/kagent/main/CONTRIBUTION.md"&gt;CONTRIBUTION.md&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to all contributors who are helping to make kagent better.&lt;/p&gt; 
&lt;a href="https://github.com/kagent-dev/kagent/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=kagent-dev/kagent" /&gt; &lt;/a&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#kagent-dev/kagent&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=kagent-dev/kagent&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=kagent-dev/kagent&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star history of kagent-dev/kagent over time" src="https://api.star-history.com/svg?repos=kagent-dev/kagent&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color/cncf-color.svg" /&gt; 
  &lt;img width="300" alt="Cloud Native Computing Foundation logo" src="https://raw.githubusercontent.com/cncf/artwork/refs/heads/main/other/cncf/horizontal/color-whitetext/cncf-color-whitetext.svg?sanitize=true" /&gt; 
 &lt;/picture&gt; 
 &lt;p&gt;kagent is a &lt;a href="https://cncf.io"&gt;Cloud Native Computing Foundation&lt;/a&gt; project.&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>openbao/openbao</title>
      <link>https://github.com/openbao/openbao</link>
      <description>&lt;p&gt;OpenBao exists to provide a software solution to manage, store, and distribute sensitive data including secrets, certificates, and keys.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;OpenBao&lt;/h1&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Please note&lt;/strong&gt;: We take OpenBao's security and our users' trust very seriously. If you believe you have found a security issue in OpenBao, &lt;em&gt;please responsibly disclose&lt;/em&gt; by contacting us at &lt;a href="mailto:openbao-security@lists.openssf.org"&gt;openbao-security@lists.openssf.org&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://scorecard.dev/viewer/?uri=github.com/openbao/openbao"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/openbao/openbao/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/9126"&gt;&lt;img src="https://www.bestpractices.dev/projects/9126/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.openbao.org"&gt;Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://lists.openssf.org/g/openbao"&gt;Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/openbao/openbao/discussions"&gt;GitHub Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://linuxfoundation.zulipchat.com/"&gt;Chat Server&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://linuxfoundation.zulipchat.com/#narrow/channel/529890-openssf-openbao-discussion"&gt;&lt;code&gt;#openssf-openbao-discussion&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://linuxfoundation.zulipchat.com/#narrow/channel/530381-openssf-openbao-support"&gt;&lt;code&gt;#openssf-openbao-support&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://linuxfoundation.zulipchat.com/#narrow/channel/530382-openssf-openbao-tsc"&gt;&lt;code&gt;#openssf-openbao-tsc&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Working Groups: 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://linuxfoundation.zulipchat.com/#narrow/channel/532995-openssf-openbao-wg-namespaces"&gt;&lt;code&gt;#openssf-openbao-wg-namespaces&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://linuxfoundation.zulipchat.com/#narrow/channel/532994-openssf-openbao-wg-pkcs11"&gt;&lt;code&gt;#openssf-openbao-wg-pkcs11&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://linuxfoundation.zulipchat.com/#narrow/channel/532998-openssf-openbao-wg-scalability"&gt;&lt;code&gt;#openssf-openbao-wg-scalability&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://linuxfoundation.zulipchat.com/#narrow/channel/532999-openssf-openbao-wg-supply"&gt;&lt;code&gt;#openssf-openbao-wg-supply&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://linuxfoundation.zulipchat.com/#narrow/channel/532997-openssf-openbao-wg-ui"&gt;&lt;code&gt;#openssf-openbao-wg-ui&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="center"&gt; &lt;img width="300" alt="OpenBao Mascot" src="https://raw.githubusercontent.com/openbao/artwork/main/color/openbao-color.svg?sanitize=true" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;OpenBao exists to provide a software solution to manage, store, and distribute sensitive data including secrets, certificates, and keys. The OpenBao community intends to provide this software under an OSI-approved open-source license, led by a community run under open governance principles.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where OpenBao steps in.&lt;/p&gt; 
&lt;p&gt;The key features of OpenBao are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secure Secret Storage&lt;/strong&gt;: Arbitrary key/value secrets can be stored in OpenBao. OpenBao encrypts these secrets prior to writing them to persistent storage, so gaining access to the raw storage isn't enough to access your secrets. OpenBao can write to disk, &lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt;, and more.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Secrets&lt;/strong&gt;: OpenBao can generate secrets on-demand for some systems, such as AWS or SQL databases. For example, when an application needs to access an S3 bucket, it asks OpenBao for credentials, and OpenBao will generate an AWS keypair with valid permissions on demand. After creating these dynamic secrets, OpenBao will also automatically revoke them after the lease is up.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: OpenBao can encrypt and decrypt data without storing it. This allows security teams to define encryption parameters and developers to store encrypted data in a location such as a SQL database without having to design their own encryption methods.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Leasing and Renewal&lt;/strong&gt;: All secrets in OpenBao have a &lt;em&gt;lease&lt;/em&gt; associated with them. At the end of the lease, OpenBao will automatically revoke that secret. Clients are able to renew leases via built-in renew APIs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revocation&lt;/strong&gt;: OpenBao has built-in support for secret revocation. OpenBao can revoke not only single secrets, but a tree of secrets, for example, all secrets read by a specific user, or all secrets of a particular type. Revocation assists in key rolling as well as locking down systems in the case of an intrusion.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation, Getting Started, and Certification Exams&lt;/h2&gt; 
&lt;p&gt;Documentation is available on the &lt;a href="https://www.openbao.org/docs/"&gt;OpenBao website&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Developing OpenBao&lt;/h2&gt; 
&lt;p&gt;If you wish to work on OpenBao itself or any of its built-in systems, you'll first need &lt;a href="https://www.golang.org"&gt;Go&lt;/a&gt; installed on your machine.&lt;/p&gt; 
&lt;p&gt;For local dev first make sure Go is properly installed, including setting up a &lt;a href="https://golang.org/doc/code.html#GOPATH"&gt;GOPATH&lt;/a&gt;. Ensure that &lt;code&gt;$GOPATH/bin&lt;/code&gt; is in your path as some distributions bundle the old version of build tools. Next, clone this repository. OpenBao uses &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;Go Modules&lt;/a&gt;, so it is recommended that you clone the repository &lt;em&gt;&lt;strong&gt;outside&lt;/strong&gt;&lt;/em&gt; of the GOPATH. You can then download any required build tools by bootstrapping your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make bootstrap
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of OpenBao, run &lt;code&gt;make&lt;/code&gt; or &lt;code&gt;make dev&lt;/code&gt;. This will put the OpenBao binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make dev
...
$ bin/bao
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of OpenBao with the UI, run &lt;code&gt;make static-dist dev-ui&lt;/code&gt;. This will put the OpenBao binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make static-dist dev-ui
...
$ bin/bao
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run tests, type &lt;code&gt;make test&lt;/code&gt;. Note: this requires Docker to be installed. If this exits with exit status 0, then everything is working!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're developing a specific package, you can run tests for just that package by specifying the &lt;code&gt;TEST&lt;/code&gt; variable. For example below, only &lt;code&gt;vault&lt;/code&gt; package tests will be run.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test TEST=./vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Importing OpenBao&lt;/h3&gt; 
&lt;p&gt;This repository publishes two libraries that may be imported by other projects: &lt;code&gt;github.com/openbao/openbao/api/v2&lt;/code&gt; and &lt;code&gt;github.com/openbao/openbao/sdk/v2&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that this repository also contains OpenBao (the product), and as with most Go projects, OpenBao uses Go modules to manage its dependencies. The mechanism to do that is the &lt;a href="https://raw.githubusercontent.com/openbao/openbao/main/go.mod"&gt;go.mod&lt;/a&gt; file. As it happens, the presence of that file also makes it theoretically possible to import OpenBao as a dependency into other projects. Some other projects have made a practice of doing so in order to take advantage of testing tooling that was developed for testing OpenBao itself. This is not, and has never been, a supported way to use the OpenBao project. We aren't likely to fix bugs relating to failure to import &lt;code&gt;github.com/openbao/openbao&lt;/code&gt; into your project.&lt;/p&gt; 
&lt;p&gt;See also the section "Docker-based tests" below.&lt;/p&gt; 
&lt;h3&gt;Acceptance Tests&lt;/h3&gt; 
&lt;p&gt;OpenBao has comprehensive &lt;a href="https://en.wikipedia.org/wiki/Acceptance_testing"&gt;acceptance tests&lt;/a&gt; covering most of the features of the secret and auth methods.&lt;/p&gt; 
&lt;p&gt;If you're working on a feature of a secret or auth method and want to verify it is functioning (and also hasn't broken anything else), we recommend running the acceptance tests.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; The acceptance tests create/destroy/modify &lt;em&gt;real resources&lt;/em&gt;, which may incur real costs in some cases. In the presence of a bug, it is technically possible that broken backends could leave dangling data behind. Therefore, please run the acceptance tests at your own risk. At the very least, we recommend running them in their own private account for whatever backend you're testing.&lt;/p&gt; 
&lt;p&gt;To run the acceptance tests, invoke &lt;code&gt;make testacc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make testacc TEST=./builtin/logical/pki
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;TEST&lt;/code&gt; variable is required, and you should specify the folder where the backend is. The &lt;code&gt;TESTARGS&lt;/code&gt; variable is recommended to filter down to a specific resource to test, since testing all of them at once can sometimes take a very long time.&lt;/p&gt; 
&lt;p&gt;Acceptance tests typically require other environment variables to be set for things such as access keys. The test itself should error early and tell you what to set, so it is not documented here.&lt;/p&gt; 
&lt;h3&gt;Docker-based Tests&lt;/h3&gt; 
&lt;p&gt;We have created an experimental new testing mechanism inspired by NewTestCluster. An example of how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  "testing"
  "github.com/openbao/openbao/sdk/v2/helper/testcluster/docker"
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: "openbao/openbao",
    ImageTag:    "latest",
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()

  client := cluster.Nodes()[0].APIClient()
  _, err := client.Logical().Read("sys/storage/raft/configuration")
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here is a more realistic example of how we use it in practice. &lt;code&gt;DefaultOptions&lt;/code&gt; uses &lt;code&gt;hashicorp/vault:latest&lt;/code&gt; as the repo and tag, but it also looks at the environment variable &lt;code&gt;BAO_BINARY&lt;/code&gt;. If populated, it will copy the local file referenced by &lt;code&gt;BAO_BINARY&lt;/code&gt; into the container. This is useful when testing local changes.&lt;/p&gt; 
&lt;p&gt;Optionally you can set &lt;code&gt;COMMIT_SHA&lt;/code&gt;, which will be appended to the image name we build as a debugging convenience.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func Test_Custom_Build_With_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, here's an example of running an existing OSS docker test with a custom binary:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ GOOS=linux make dev
$ VAULT_BINARY=$(pwd)/bin/bao go test -run 'TestRaft_Configuration_Docker' ./vault/external_tests/raft/raft_binary
ok      github.com/openbao/openbao/vault/external_tests/raft/raft_binary        20.960s
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>