<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Mon, 20 Oct 2025 01:31:10 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>DrewThomasson/ebook2audiobook</title>
      <link>https://github.com/DrewThomasson/ebook2audiobook</link>
      <description>&lt;p&gt;Generate audiobooks from e-books, voice cloning &amp; 1107+ languages!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;üìö ebook2audiobook&lt;/h1&gt; 
&lt;p&gt;CPU/GPU Converter from eBooks to audiobooks with chapters and metadata&lt;br /&gt; using XTTSv2, Bark, Vits, Fairseq, YourTTS, Tacotron and more. Supports voice cloning and +1110 languages!&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;This tool is intended for use with non-DRM, legally acquired eBooks only.&lt;/strong&gt; &lt;br /&gt; The authors are not responsible for any misuse of this software or any resulting legal consequences. &lt;br /&gt; Use this tool responsibly and in accordance with all applicable laws.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/63Tv3F65k6"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/https://discord.gg/63Tv3F65k6" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Thanks to support ebook2audiobook developers!&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://ko-fi.com/athomasson2"&gt;&lt;img src="https://img.shields.io/badge/Ko--fi-F16061?style=for-the-badge&amp;amp;logo=ko-fi&amp;amp;logoColor=white" alt="Ko-Fi" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Run locally&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#launching-gradio-web-interface"&gt;&lt;img src="https://img.shields.io/badge/Quick%20Start-blue?style=for-the-badge" alt="Quick Start" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/DrewThomasson/ebook2audiobook/actions/workflows/Docker-Build.yml"&gt;&lt;img src="https://github.com/DrewThomasson/ebook2audiobook/actions/workflows/Docker-Build.yml/badge.svg?sanitize=true" alt="Docker Build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/releases/latest"&gt;&lt;img src="https://img.shields.io/badge/Download-Now-blue.svg?sanitize=true" alt="Download" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://github.com/DrewThomasson/ebook2audiobook"&gt; &lt;img src="https://img.shields.io/badge/Platform-mac%20|%20linux%20|%20windows-lightgrey" alt="Platform" /&gt; &lt;/a&gt;
&lt;a href="https://hub.docker.com/r/athomasson2/ebook2audiobook"&gt; &lt;img alt="Docker Pull Count" src="https://img.shields.io/docker/pulls/athomasson2/ebook2audiobook.svg?sanitize=true" /&gt; &lt;/a&gt; 
&lt;h3&gt;Run Remotely&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/spaces/drewThomasson/ebook2audiobook"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-Spaces-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/DrewThomasson/ebook2audiobook/blob/main/Notebooks/colab_ebook2audiobook.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Free Google Colab" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Rihcus/ebook2audiobookXTTS/raw/main/Notebooks/kaggle-ebook2audiobook.ipynb"&gt;&lt;img src="https://img.shields.io/badge/Kaggle-035a7d?style=flat&amp;amp;logo=kaggle&amp;amp;logoColor=white" alt="Kaggle" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;GUI Interface&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/assets/demo_web_gui.gif" alt="demo_web_gui" /&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to see images of Web GUI&lt;/summary&gt; 
 &lt;img width="1728" alt="GUI Screen 1" src="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/assets/gui_1.png" /&gt; 
 &lt;img width="1728" alt="GUI Screen 2" src="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/assets/gui_2.png" /&gt; 
 &lt;img width="1728" alt="GUI Screen 3" src="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/assets/gui_3.png" /&gt; 
&lt;/details&gt; 
&lt;h2&gt;Demos&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;New Default Voice Demo&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/750035dc-e355-46f1-9286-05c1d9e88cea"&gt;https://github.com/user-attachments/assets/750035dc-e355-46f1-9286-05c1d9e88cea&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;More Demos&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;ASMR Voice&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/68eee9a1-6f71-4903-aacd-47397e47e422"&gt;https://github.com/user-attachments/assets/68eee9a1-6f71-4903-aacd-47397e47e422&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Rainy Day Voice&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/d25034d9-c77f-43a9-8f14-0d167172b080"&gt;https://github.com/user-attachments/assets/d25034d9-c77f-43a9-8f14-0d167172b080&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Scarlett Voice&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/b12009ee-ec0d-45ce-a1ef-b3a52b9f8693"&gt;https://github.com/user-attachments/assets/b12009ee-ec0d-45ce-a1ef-b3a52b9f8693&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;David Attenborough Voice&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/81c4baad-117e-4db5-ac86-efc2b7fea921"&gt;https://github.com/user-attachments/assets/81c4baad-117e-4db5-ac86-efc2b7fea921&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://github.com/DrewThomasson/VoxNovel/raw/dc5197dff97252fa44c391dc0596902d71278a88/readme_files/example_in_app.jpeg" alt="Example" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;README.md&lt;/h2&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#-ebook2audiobook"&gt;ebook2audiobook&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#gui-interface"&gt;GUI Interface&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#demos"&gt;Demos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#supported-languages"&gt;Supported Languages&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#hardware-requirements"&gt;Minimum Requirements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#launching-gradio-web-interface"&gt;Usage&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#launching-gradio-web-interface"&gt;Run Locally&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#launching-gradio-web-interface"&gt;Launching Gradio Web Interface&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#basic--usage"&gt;Basic Headless Usage&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#example-of-custom-model-zip-upload"&gt;Headless Custom XTTS Model Usage&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#help-command-output"&gt;Help command output&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#run-remotely"&gt;Run Remotely&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#fine-tuned-tts-models"&gt;Fine Tuned TTS models&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#fine-tuned-tts-collection"&gt;Collection of Fine-Tuned TTS Models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#fine-tune-your-own-xttsv2-model"&gt;Train XTTSv2&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#docker-gpu-options"&gt;Docker&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#docker-gpu-options"&gt;GPU options&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#running-the-pre-built-docker-container"&gt;Docker Run&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#building-the-docker-container"&gt;Docker Build&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#docker-compose"&gt;Docker Compose&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#docker-headless-guide"&gt;Docker headless guide&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#docker-container-file-locations"&gt;Docker container file locations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#common-docker-issues"&gt;Common Docker issues&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#supported-ebook-formats"&gt;Supported eBook Formats&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#output-formats"&gt;Output Formats&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#updating-to-latest-version"&gt;Updating to Latest Version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#reverting-to-older-versions"&gt;Revert to older Version&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#common-issues"&gt;Common Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#special-thanks"&gt;Special Thanks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#table-of-contents"&gt;Table of Contents&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üìö Splits eBook into chapters for organized audio.&lt;/li&gt; 
 &lt;li&gt;üéôÔ∏è High-quality text-to-speech with &lt;a href="https://huggingface.co/coqui/XTTS-v2"&gt;Coqui XTTSv2&lt;/a&gt; and &lt;a href="https://github.com/facebookresearch/fairseq/tree/main/examples/mms"&gt;Fairseq&lt;/a&gt; (and more).&lt;/li&gt; 
 &lt;li&gt;üó£Ô∏è Optional voice cloning with your own voice file.&lt;/li&gt; 
 &lt;li&gt;üåç Supports +1110 languages (English by default). &lt;a href="https://dl.fbaipublicfiles.com/mms/tts/all-tts-languages.html"&gt;List of Supported languages&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üñ•Ô∏è Designed to run on 4GB RAM.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Supported Languages&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;Arabic (ar)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;Chinese (zh)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;English (en)&lt;/strong&gt;&lt;/th&gt; 
   &lt;th align="center"&gt;&lt;strong&gt;Spanish (es)&lt;/strong&gt;&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;French (fr)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;German (de)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Italian (it)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Portuguese (pt)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Polish (pl)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Turkish (tr)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Russian (ru)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Dutch (nl)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Czech (cs)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Japanese (ja)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Hindi (hi)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Bengali (bn)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Hungarian (hu)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Korean (ko)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Vietnamese (vi)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Swedish (sv)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Persian (fa)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Yoruba (yo)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Swahili (sw)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Indonesian (id)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Slovak (sk)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Croatian (hr)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Tamil (ta)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;strong&gt;Danish (da)&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dl.fbaipublicfiles.com/mms/tts/all-tts-languages.html"&gt;&lt;strong&gt;+1100 languages and dialects here&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Hardware Requirements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;4gb RAM minimum, 8GB recommended&lt;/li&gt; 
 &lt;li&gt;Virtualization enabled if running on windows (Docker only)&lt;/li&gt; 
 &lt;li&gt;CPU (intel, AMD, ARM), GPU (Nvidia, AMD*, Intel*) (Recommended), MPS (Apple Silicon CPU) *available very soon&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;Before to post an install or bug issue search carefully to the opened and closed issues TAB&lt;br /&gt; to be sure your issue does not exist already.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] &lt;strong&gt;Lacking of any standards structure like what is a chapter, paragraph, preface etc.&lt;br /&gt; you should first remove manually any text you don't want to be converted in audio.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Installation Instructions&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Clone repo&lt;/strong&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/DrewThomasson/ebook2audiobook.git
cd ebook2audiobook
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Launching Gradio Web Interface&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run ebook2audiobook&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux/MacOS&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;./ebook2audiobook.sh  # Run launch script
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Mac Launcher&lt;/strong&gt;&lt;br /&gt; Double click &lt;code&gt;Mac Ebook2Audiobook Launcher.command&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;ebook2audiobook.cmd  # Run launch script or double click on it
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows Launcher&lt;/strong&gt;&lt;br /&gt; Double click &lt;code&gt;ebook2audiobook.cmd&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Manual Python Install&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# (for experts only!)
REQUIRED_PROGRAMS=("calibre" "ffmpeg" "nodejs" "mecab" "espeak-ng" "rust" "sox")
REQUIRED_PYTHON_VERSION="3.12"
pip install -r requirements.txt  # Install Python Requirements
python app.py  # Run Ebook2Audiobook
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Open the Web App&lt;/strong&gt;: Click the URL provided in the terminal to access the web app and convert eBooks. &lt;code&gt;http://localhost:7860/&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;For Public Link&lt;/strong&gt;: &lt;code&gt;python app.py --share&lt;/code&gt; (all OS) &lt;code&gt;./ebook2audiobook.sh --share&lt;/code&gt; (Linux/MacOS) &lt;code&gt;ebook2audiobook.cmd --share&lt;/code&gt; (Windows)&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] &lt;strong&gt;If the script is stopped and run again, you need to refresh your gradio GUI interface&lt;br /&gt; to let the web page reconnect to the new connection socket.&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Basic Usage&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux/MacOS&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;./ebook2audiobook.sh --headless --ebook &amp;lt;path_to_ebook_file&amp;gt; \
    --voice [path_to_voice_file] --language [language_code]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;ebook2audiobook.cmd --headless --ebook &amp;lt;path_to_ebook_file&amp;gt;
    --voice [path_to_voice_file] --language [language_code]
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;[--ebook]&lt;/strong&gt;: Path to your eBook file&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;[--voice]&lt;/strong&gt;: Voice cloning file path (optional)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;[--language]&lt;/strong&gt;: Language code in ISO-639-3 (i.e.: ita for italian, eng for english, deu for german...).&lt;br /&gt; Default language is eng and --language is optional for default language set in ./lib/lang.py.&lt;br /&gt; The ISO-639-1 2 letters codes are also supported.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Example of Custom Model Zip Upload&lt;/h3&gt; 
&lt;p&gt;(must be a .zip file containing the mandatory model files. Example for XTTSv2: config.json, model.pth, vocab.json and ref.wav)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Linux/MacOS&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;./ebook2audiobook.sh --headless --ebook &amp;lt;ebook_file_path&amp;gt; \
    --voice &amp;lt;target_voice_file_path&amp;gt; --language &amp;lt;language&amp;gt; --custom_model &amp;lt;custom_model_path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;ebook2audiobook.cmd --headless --ebook &amp;lt;ebook_file_path&amp;gt; \
    --voice &amp;lt;target_voice_file_path&amp;gt; --language &amp;lt;language&amp;gt; --custom_model &amp;lt;custom_model_path&amp;gt;
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&amp;lt;custom_model_path&amp;gt;&lt;/strong&gt;: Path to &lt;code&gt;model_name.zip&lt;/code&gt; file, which must contain (according to the tts engine) all the mandatory files&lt;br /&gt; (see ./lib/models.py).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;For Detailed Guide with list of all Parameters to use&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Linux/MacOS&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;./ebook2audiobook.sh --help
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;ebook2audiobook.cmd --help
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Or for all OS&lt;/strong&gt; &lt;code&gt;python app.py --help &lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a id="help-command-output"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;usage: app.py [-h] [--session SESSION] [--share] [--headless] [--ebook EBOOK]
              [--ebooks_dir EBOOKS_DIR] [--language LANGUAGE] [--voice VOICE]
              [--device {cpu,gpu,mps}]
              [--tts_engine {XTTSv2,BARK,VITS,FAIRSEQ,TACOTRON2,YOURTTS,xtts,bark,vits,fairseq,tacotron,yourtts}]
              [--custom_model CUSTOM_MODEL] [--fine_tuned FINE_TUNED]
              [--output_format OUTPUT_FORMAT] [--temperature TEMPERATURE]
              [--length_penalty LENGTH_PENALTY] [--num_beams NUM_BEAMS]
              [--repetition_penalty REPETITION_PENALTY] [--top_k TOP_K]
              [--top_p TOP_P] [--speed SPEED] [--enable_text_splitting]
              [--text_temp TEXT_TEMP] [--waveform_temp WAVEFORM_TEMP]
              [--output_dir OUTPUT_DIR] [--version]

Convert eBooks to Audiobooks using a Text-to-Speech model. You can either launch the Gradio interface or run the script in headless mode for direct conversion.

options:
  -h, --help            show this help message and exit
  --session SESSION     Session to resume the conversion in case of interruption, crash, 
                            or reuse of custom models and custom cloning voices.

**** The following options are for all modes:
  Optional

**** The following option are for gradio/gui mode only:
  Optional

  --share               Enable a public shareable Gradio link.

**** The following options are for --headless mode only:
  --headless            Run the script in headless mode
  --ebook EBOOK         Path to the ebook file for conversion. Cannot be used when --ebooks_dir is present.
  --ebooks_dir EBOOKS_DIR
                        Relative or absolute path of the directory containing the files to convert. 
                            Cannot be used when --ebook is present.
  --language LANGUAGE   Language of the e-book. Default language is set 
                            in ./lib/lang.py sed as default if not present. All compatible language codes are in ./lib/lang.py

optional parameters:
  --voice VOICE         (Optional) Path to the voice cloning file for TTS engine. 
                            Uses the default voice if not present.
  --device {cpu,gpu,mps}
                        (Optional) Pprocessor unit type for the conversion. 
                            Default is set in ./lib/conf.py if not present. Fall back to CPU if GPU not available.
  --tts_engine {XTTSv2,BARK,VITS,FAIRSEQ,TACOTRON2,YOURTTS,xtts,bark,vits,fairseq,tacotron,yourtts}
                        (Optional) Preferred TTS engine (available are: ['XTTSv2', 'BARK', 'VITS', 'FAIRSEQ', 'TACOTRON2', 'YOURTTS', 'xtts', 'bark', 'vits', 'fairseq', 'tacotron', 'yourtts'].
                            Default depends on the selected language. The tts engine should be compatible with the chosen language
  --custom_model CUSTOM_MODEL
                        (Optional) Path to the custom model zip file cntaining mandatory model files. 
                            Please refer to ./lib/models.py
  --fine_tuned FINE_TUNED
                        (Optional) Fine tuned model path. Default is builtin model.
  --output_format OUTPUT_FORMAT
                        (Optional) Output audio format. Default is set in ./lib/conf.py
  --temperature TEMPERATURE
                        (xtts only, optional) Temperature for the model. 
                            Default to config.json model. Higher temperatures lead to more creative outputs.
  --length_penalty LENGTH_PENALTY
                        (xtts only, optional) A length penalty applied to the autoregressive decoder. 
                            Default to config.json model. Not applied to custom models.
  --num_beams NUM_BEAMS
                        (xtts only, optional) Controls how many alternative sequences the model explores. Must be equal or greater than length penalty. 
                            Default to config.json model.
  --repetition_penalty REPETITION_PENALTY
                        (xtts only, optional) A penalty that prevents the autoregressive decoder from repeating itself. 
                            Default to config.json model.
  --top_k TOP_K         (xtts only, optional) Top-k sampling. 
                            Lower values mean more likely outputs and increased audio generation speed. 
                            Default to config.json model.
  --top_p TOP_P         (xtts only, optional) Top-p sampling. 
                            Lower values mean more likely outputs and increased audio generation speed. Default to config.json model.
  --speed SPEED         (xtts only, optional) Speed factor for the speech generation. 
                            Default to config.json model.
  --enable_text_splitting
                        (xtts only, optional) Enable TTS text splitting. This option is known to not be very efficient. 
                            Default to config.json model.
  --text_temp TEXT_TEMP
                        (bark only, optional) Text Temperature for the model. 
                            Default to 0.85. Higher temperatures lead to more creative outputs.
  --waveform_temp WAVEFORM_TEMP
                        (bark only, optional) Waveform Temperature for the model. 
                            Default to 0.5. Higher temperatures lead to more creative outputs.
  --output_dir OUTPUT_DIR
                        (Optional) Path to the output directory. Default is set in ./lib/conf.py
  --version             Show the version of the script and exit

Example usage:    
Windows:
    Gradio/GUI:
    ebook2audiobook.cmd
    Headless mode:
    ebook2audiobook.cmd --headless --ebook '/path/to/file'
Linux/Mac:
    Gradio/GUI:
    ./ebook2audiobook.sh
    Headless mode:
    ./ebook2audiobook.sh --headless --ebook '/path/to/file'
    
Tip: to add of silence (1.4 seconds) into your text just use "###" or "[pause]".

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;NOTE: in gradio/gui mode, to cancel a running conversion, just click on the [X] from the ebook upload component.&lt;/p&gt; 
&lt;p&gt;TIP: if it needs some more pauses, just add '###' or '[pause]' between the words you wish more pause. one [pause] equals to 1.4 seconds&lt;/p&gt; 
&lt;h4&gt;Docker GPU Options&lt;/h4&gt; 
&lt;p&gt;Available pre-build tags: &lt;code&gt;latest&lt;/code&gt; (CUDA 11.8)&lt;/p&gt; 
&lt;h4&gt;Edit: IF GPU isn't detected then you'll have to build the image -&amp;gt; &lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#building-the-docker-container"&gt;Building the Docker Container&lt;/a&gt;&lt;/h4&gt; 
&lt;h4&gt;Running the pre-built Docker Container&lt;/h4&gt; 
&lt;p&gt;-Run with CPU only&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;docker run --pull always --rm -p 7860:7860 athomasson2/ebook2audiobook
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;-Run with GPU Speedup (NVIDIA compatible only)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;docker run --pull always --rm --gpus all -p 7860:7860 athomasson2/ebook2audiobook
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command will start the Gradio interface on port 7860.(localhost:7860)&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;For more options add the parameter &lt;code&gt;--help&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Building the Docker Container&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;You can build the docker image with the command:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;docker build -t athomasson2/ebook2audiobook .
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Avalible Docker Build Arguments&lt;/h4&gt; 
&lt;p&gt;&lt;code&gt;--build-arg TORCH_VERSION=cuda118&lt;/code&gt; Available tags: [cuda121, cuda118, cuda128, rocm, xpu, cpu]&lt;/p&gt; 
&lt;p&gt;All CUDA version numbers should work, Ex: CUDA 11.6-&amp;gt; cuda116&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;--build-arg SKIP_XTTS_TEST=true&lt;/code&gt; (Saves space by not baking XTTSv2 model into docker image)&lt;/p&gt; 
&lt;h2&gt;Docker container file locations&lt;/h2&gt; 
&lt;p&gt;All ebook2audiobooks will have the base dir of &lt;code&gt;/app/&lt;/code&gt; For example: &lt;code&gt;tmp&lt;/code&gt; = &lt;code&gt;/app/tmp&lt;/code&gt; &lt;code&gt;audiobooks&lt;/code&gt; = &lt;code&gt;/app/audiobooks&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Docker headless guide&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Before you do run this you need to create a dir named "input-folder" in your current dir which will be linked, This is where you can put your input files for the docker image to see&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir input-folder &amp;amp;&amp;amp; mkdir Audiobooks
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;In the command below swap out &lt;strong&gt;YOUR_INPUT_FILE.TXT&lt;/strong&gt; with the name of your input file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --pull always --rm \
    -v $(pwd)/input-folder:/app/input_folder \
    -v $(pwd)/audiobooks:/app/audiobooks \
    athomasson2/ebook2audiobook \
    --headless --ebook /input_folder/YOUR_EBOOK_FILE
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;The output Audiobooks will be found in the Audiobook folder which will also be located in your local dir you ran this docker command in&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;To get the help command for the other parameters this program has you can run this&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --pull always --rm athomasson2/ebook2audiobook --help

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;That will output this &lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/#help-command-output"&gt;Help command output&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Docker Compose&lt;/h3&gt; 
&lt;p&gt;This project uses Docker Compose to run locally. You can enable or disable GPU support by setting either &lt;code&gt;*gpu-enabled&lt;/code&gt; or &lt;code&gt;*gpu-disabled&lt;/code&gt; in &lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/p&gt; 
&lt;h4&gt;Steps to Run&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Clone the Repository&lt;/strong&gt; (if you haven't already): &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/DrewThomasson/ebook2audiobook.git
cd ebook2audiobook
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Set GPU Support (disabled by default)&lt;/strong&gt; To enable GPU support, modify &lt;code&gt;docker-compose.yml&lt;/code&gt; and change &lt;code&gt;*gpu-disabled&lt;/code&gt; to &lt;code&gt;*gpu-enabled&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Start the service:&lt;/strong&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;# Docker
docker-compose up -d # To update add --build

# Podman
podman compose -f podman-compose.yml up -d # To update add --build
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Access the service:&lt;/strong&gt; The service will be available at &lt;a href="http://localhost:7860"&gt;http://localhost:7860&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Common Docker Issues&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;My NVIDIA GPU isnt being detected?? -&amp;gt; &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/wiki/GPU-ISSUES"&gt;GPU ISSUES Wiki Page&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;python: can't open file '/home/user/app/app.py': [Errno 2] No such file or directory&lt;/code&gt; (Just remove all post arguments as I replaced the &lt;code&gt;CMD&lt;/code&gt; with &lt;code&gt;ENTRYPOINT&lt;/code&gt; in the &lt;a href="https://raw.githubusercontent.com/DrewThomasson/ebook2audiobook/main/Dockerfile"&gt;Dockerfile&lt;/a&gt;)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Example: &lt;code&gt;docker run --pull always athomasson2/ebook2audiobook app.py --script_mode full_docker&lt;/code&gt; - &amp;gt; corrected - &amp;gt; &lt;code&gt;docker run --pull always athomasson2/ebook2audiobook&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;Arguments can be easily added like this now &lt;code&gt;docker run --pull always athomasson2/ebook2audiobook --share&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Docker gets stuck downloading Fine-Tuned models. (This does not happen for every computer but some appear to run into this issue) Disabling the progress bar appears to fix the issue, as discussed &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/issues/191"&gt;here in #191&lt;/a&gt; Example of adding this fix in the &lt;code&gt;docker run&lt;/code&gt; command&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-Dockerfile"&gt;docker run --pull always --rm --gpus all -e HF_HUB_DISABLE_PROGRESS_BARS=1 -e HF_HUB_ENABLE_HF_TRANSFER=0 \
    -p 7860:7860 athomasson2/ebook2audiobook
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Fine Tuned TTS models&lt;/h2&gt; 
&lt;h4&gt;Fine Tune your own XTTSv2 model&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/spaces/drewThomasson/xtts-finetune-webui-gpu"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-Spaces-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face" /&gt;&lt;/a&gt; &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/raw/v25/Notebooks/finetune/xtts/kaggle-xtts-finetune-webui-gradio-gui.ipynb"&gt;&lt;img src="https://img.shields.io/badge/Kaggle-035a7d?style=flat&amp;amp;logo=kaggle&amp;amp;logoColor=white" alt="Kaggle" /&gt;&lt;/a&gt; &lt;a href="https://colab.research.google.com/github/DrewThomasson/ebook2audiobook/blob/v25/Notebooks/finetune/xtts/colab_xtts_finetune_webui.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open In Colab" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;De-noise training data&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/spaces/drewThomasson/DeepFilterNet2_no_limit"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-Spaces-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Rikorose/DeepFilterNet"&gt;&lt;img src="https://img.shields.io/badge/DeepFilterNet-181717?logo=github" alt="GitHub Repo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Fine Tuned TTS Collection&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/drewThomasson/fineTunedTTSModels/tree/main"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-Models-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For an XTTSv2 custom model a ref audio clip of the voice reference is mandatory:&lt;/p&gt; 
&lt;h2&gt;Supported eBook Formats&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;.epub&lt;/code&gt;, &lt;code&gt;.pdf&lt;/code&gt;, &lt;code&gt;.mobi&lt;/code&gt;, &lt;code&gt;.txt&lt;/code&gt;, &lt;code&gt;.html&lt;/code&gt;, &lt;code&gt;.rtf&lt;/code&gt;, &lt;code&gt;.chm&lt;/code&gt;, &lt;code&gt;.lit&lt;/code&gt;, &lt;code&gt;.pdb&lt;/code&gt;, &lt;code&gt;.fb2&lt;/code&gt;, &lt;code&gt;.odt&lt;/code&gt;, &lt;code&gt;.cbr&lt;/code&gt;, &lt;code&gt;.cbz&lt;/code&gt;, &lt;code&gt;.prc&lt;/code&gt;, &lt;code&gt;.lrf&lt;/code&gt;, &lt;code&gt;.pml&lt;/code&gt;, &lt;code&gt;.snb&lt;/code&gt;, &lt;code&gt;.cbc&lt;/code&gt;, &lt;code&gt;.rb&lt;/code&gt;, &lt;code&gt;.tcr&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Best results&lt;/strong&gt;: &lt;code&gt;.epub&lt;/code&gt; or &lt;code&gt;.mobi&lt;/code&gt; for automatic chapter detection&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Output Formats&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Creates a &lt;code&gt;['m4b', 'm4a', 'mp4', 'webm', 'mov', 'mp3', 'flac', 'wav', 'ogg', 'aac']&lt;/code&gt; (set in ./lib/conf.py) file with metadata and chapters.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Updating to Latest Version&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git pull # Locally/Compose

docker pull athomasson2/ebook2audiobook:latest # For Pre-build docker images
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Reverting to older Versions&lt;/h2&gt; 
&lt;p&gt;Releases can be found -&amp;gt; &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/releases"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git checkout tags/VERSION_NUM # Locally/Compose -&amp;gt; Example: git checkout tags/v25.7.7

athomasson2/ebook2audiobook:VERSION_NUM # For Pre-build docker images -&amp;gt; Example: athomasson2/ebook2audiobook:v25.7.7
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Common Issues:&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;My NVIDIA GPU isnt being detected?? -&amp;gt; &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/wiki/GPU-ISSUES"&gt;GPU ISSUES Wiki Page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;CPU is slow (better on server smp CPU) while NVIDIA GPU can have almost real time conversion. &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/discussions/19#discussioncomment-10879846"&gt;Discussion about this&lt;/a&gt; For faster multilingual generation I would suggest my other &lt;a href="https://github.com/DrewThomasson/ebook2audiobookpiper-tts"&gt;project that uses piper-tts&lt;/a&gt; instead (It doesn't have zero-shot voice cloning though, and is Siri quality voices, but it is much faster on cpu).&lt;/li&gt; 
 &lt;li&gt;"I'm having dependency issues" - Just use the docker, its fully self contained and has a headless mode, add &lt;code&gt;--help&lt;/code&gt; parameter at the end of the docker run command for more information.&lt;/li&gt; 
 &lt;li&gt;"Im getting a truncated audio issue!" - PLEASE MAKE AN ISSUE OF THIS, we don't speak every language and need advise from users to fine tune the sentence splitting logic.üòä&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What we need help with! üôå&lt;/h2&gt; 
&lt;h2&gt;&lt;a href="https://github.com/DrewThomasson/ebook2audiobook/issues/32"&gt;Full list of things can be found here&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Any help from people speaking any of the supported languages to help us improve the models&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Do you need to rent a GPU to boost service from us?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;A poll is open here &lt;a href="https://github.com/DrewThomasson/ebook2audiobook/discussions/889"&gt;https://github.com/DrewThomasson/ebook2audiobook/discussions/889&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Special Thanks&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Coqui TTS&lt;/strong&gt;: &lt;a href="https://github.com/idiap/coqui-ai-TTS"&gt;Coqui TTS GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Calibre&lt;/strong&gt;: &lt;a href="https://calibre-ebook.com"&gt;Calibre Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FFmpeg&lt;/strong&gt;: &lt;a href="https://ffmpeg.org"&gt;FFmpeg Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DrewThomasson/ebook2audiobook/issues/8"&gt;@shakenbake15 for better chapter saving method&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>wavetermdev/waveterm</title>
      <link>https://github.com/wavetermdev/waveterm</link>
      <description>&lt;p&gt;An open-source, cross-platform terminal for seamless workflows&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.waveterm.dev"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="./assets/wave-dark.png" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="./assets/wave-light.png" /&gt; 
   &lt;img alt="Wave Terminal Logo" src="https://raw.githubusercontent.com/wavetermdev/waveterm/main/assets/wave-light.png" width="240" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;h1&gt;Wave Terminal&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Wave is an open-source terminal that combines traditional terminal features with graphical capabilities like file previews, web browsing, and AI assistance. It runs on MacOS, Linux, and Windows.&lt;/p&gt; 
&lt;p&gt;Modern development involves constantly switching between terminals and browsers - checking documentation, previewing files, monitoring systems, and using AI tools. Wave brings these graphical tools directly into the terminal, letting you control them from the command line. This means you can stay in your terminal workflow while still having access to the visual interfaces you need.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/wavetermdev/waveterm/main/assets/wave-screenshot.webp" alt="WaveTerm Screenshot" /&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Flexible drag &amp;amp; drop interface to organize terminal blocks, editors, web browsers, and AI assistants&lt;/li&gt; 
 &lt;li&gt;Built-in editor for seamlessly editing remote files with syntax highlighting and modern editor features&lt;/li&gt; 
 &lt;li&gt;Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)&lt;/li&gt; 
 &lt;li&gt;Integrated AI chat with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)&lt;/li&gt; 
 &lt;li&gt;Command Blocks for isolating and monitoring individual commands with auto-close options&lt;/li&gt; 
 &lt;li&gt;One-click remote connections with full terminal and file system access&lt;/li&gt; 
 &lt;li&gt;Rich customization including tab themes, terminal styles, and background images&lt;/li&gt; 
 &lt;li&gt;Powerful &lt;code&gt;wsh&lt;/code&gt; command system for managing your workspace from the CLI and sharing data between terminal sessions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Wave Terminal works on macOS, Linux, and Windows.&lt;/p&gt; 
&lt;p&gt;Platform-specific installation instructions can be found &lt;a href="https://docs.waveterm.dev/gettingstarted"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also install Wave Terminal directly from: &lt;a href="https://www.waveterm.dev/download"&gt;www.waveterm.dev/download&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Minimum requirements&lt;/h3&gt; 
&lt;p&gt;Wave Terminal runs on the following platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;macOS 11 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Windows 10 1809 or later (x64)&lt;/li&gt; 
 &lt;li&gt;Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The WSH helper runs on the following platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;macOS 11 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Windows 10 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Wave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/ROADMAP.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Want to provide input to our future releases? Connect with us on &lt;a href="https://discord.gg/XfvZ334gwU"&gt;Discord&lt;/a&gt; or open a &lt;a href="https://github.com/wavetermdev/waveterm/issues/new/choose"&gt;Feature Request&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Homepage ‚Äî &lt;a href="https://www.waveterm.dev"&gt;https://www.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Download Page ‚Äî &lt;a href="https://www.waveterm.dev/download"&gt;https://www.waveterm.dev/download&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation ‚Äî &lt;a href="https://docs.waveterm.dev"&gt;https://docs.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Legacy Documentation ‚Äî &lt;a href="https://legacydocs.waveterm.dev"&gt;https://legacydocs.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Blog ‚Äî &lt;a href="https://blog.waveterm.dev"&gt;https://blog.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;X ‚Äî &lt;a href="https://x.com/wavetermdev"&gt;https://x.com/wavetermdev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord Community ‚Äî &lt;a href="https://discord.gg/XfvZ334gwU"&gt;https://discord.gg/XfvZ334gwU&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Building from Source&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/BUILD.md"&gt;Building Wave Terminal&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Wave uses GitHub Issues for issue tracking.&lt;/p&gt; 
&lt;p&gt;Find more information in our &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md"&gt;Contributions Guide&lt;/a&gt;, which includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md#contributing-to-wave-terminal"&gt;Ways to contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md#before-you-start"&gt;Contribution guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.waveterm.dev/storybook"&gt;Storybook&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Wave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/ACKNOWLEDGEMENTS.md"&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>myshell-ai/OpenVoice</title>
      <link>https://github.com/myshell-ai/OpenVoice</link>
      <description>&lt;p&gt;Instant voice cloning by MIT and MyShell. Audio foundation model.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div&gt;
  &amp;nbsp;
 &lt;/div&gt; 
 &lt;img src="https://raw.githubusercontent.com/myshell-ai/OpenVoice/main/resources/openvoicelogo.jpg" width="400" /&gt; 
 &lt;p&gt;&lt;a href="https://arxiv.org/abs/2312.01479"&gt;Paper&lt;/a&gt; | &lt;a href="https://research.myshell.ai/open-voice"&gt;Website&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://trendshift.io/repositories/6161" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/6161" alt="myshell-ai%2FOpenVoice | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;h3&gt;OpenVoice V1&lt;/h3&gt; 
&lt;p&gt;As we detailed in our &lt;a href="https://arxiv.org/abs/2312.01479"&gt;paper&lt;/a&gt; and &lt;a href="https://research.myshell.ai/open-voice"&gt;website&lt;/a&gt;, the advantages of OpenVoice are three-fold:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. Accurate Tone Color Cloning.&lt;/strong&gt; OpenVoice can accurately clone the reference tone color and generate speech in multiple languages and accents.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Flexible Voice Style Control.&lt;/strong&gt; OpenVoice enables granular control over voice styles, such as emotion and accent, as well as other style parameters including rhythm, pauses, and intonation.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. Zero-shot Cross-lingual Voice Cloning.&lt;/strong&gt; Neither of the language of the generated speech nor the language of the reference speech needs to be presented in the massive-speaker multi-lingual training dataset.&lt;/p&gt; 
&lt;h3&gt;OpenVoice V2&lt;/h3&gt; 
&lt;p&gt;In April 2024, we released OpenVoice V2, which includes all features in V1 and has:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;1. Better Audio Quality.&lt;/strong&gt; OpenVoice V2 adopts a different training strategy that delivers better audio quality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;2. Native Multi-lingual Support.&lt;/strong&gt; English, Spanish, French, Chinese, Japanese and Korean are natively supported in OpenVoice V2.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3. Free Commercial Use.&lt;/strong&gt; Starting from April 2024, both V2 and V1 are released under MIT License. Free for commercial use.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/myshell-ai/OpenVoice/assets/40556743/3cba936f-82bf-476c-9e52-09f0f417bb2f"&gt;Video&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;OpenVoice has been powering the instant voice cloning capability of &lt;a href="https://app.myshell.ai/explore"&gt;myshell.ai&lt;/a&gt; since May 2023. Until Nov 2023, the voice cloning model has been used tens of millions of times by users worldwide, and witnessed the explosive user growth on the platform.&lt;/p&gt; 
&lt;h2&gt;Main Contributors&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.qinzy.tech"&gt;Zengyi Qin&lt;/a&gt; at MIT&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wl-zhao.github.io"&gt;Wenliang Zhao&lt;/a&gt; at Tsinghua University&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://yuxumin.github.io"&gt;Xumin Yu&lt;/a&gt; at Tsinghua University&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/ethan_myshell"&gt;Ethan Sun&lt;/a&gt; at MyShell&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Use&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://raw.githubusercontent.com/myshell-ai/OpenVoice/main/docs/USAGE.md"&gt;usage&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h2&gt;Common Issues&lt;/h2&gt; 
&lt;p&gt;Please see &lt;a href="https://raw.githubusercontent.com/myshell-ai/OpenVoice/main/docs/QA.md"&gt;QA&lt;/a&gt; for common questions and answers. We will regularly update the question and answer list.&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@article{qin2023openvoice,
  title={OpenVoice: Versatile Instant Voice Cloning},
  author={Qin, Zengyi and Zhao, Wenliang and Yu, Xumin and Sun, Xin},
  journal={arXiv preprint arXiv:2312.01479},
  year={2023}
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;OpenVoice V1 and V2 are MIT Licensed. Free for both commercial and research use.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;p&gt;This implementation is based on several excellent projects, &lt;a href="https://github.com/coqui-ai/TTS"&gt;TTS&lt;/a&gt;, &lt;a href="https://github.com/jaywalnut310/vits"&gt;VITS&lt;/a&gt;, and &lt;a href="https://github.com/daniilrobnikov/vits2"&gt;VITS2&lt;/a&gt;. Thanks for their awesome work!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>huggingface/chat-ui</title>
      <link>https://github.com/huggingface/chat-ui</link>
      <description>&lt;p&gt;Open source codebase powering the HuggingChat app&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Chat UI&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/chat-ui/chat-ui-2026.png" alt="Chat UI repository thumbnail" /&gt;&lt;/p&gt; 
&lt;p&gt;A chat interface for LLMs. It is a SvelteKit app and it powers the &lt;a href="https://huggingface.co/chat"&gt;HuggingChat app on hf.co/chat&lt;/a&gt;.&lt;/p&gt; 
&lt;ol start="0"&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/chat-ui/main/#quickstart"&gt;Quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/chat-ui/main/#database-options"&gt;Database Options&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/chat-ui/main/#launch"&gt;Launch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/chat-ui/main/#optional-docker-image"&gt;Optional Docker Image&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/chat-ui/main/#extra-parameters"&gt;Extra parameters&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/huggingface/chat-ui/main/#building"&gt;Building&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Chat UI only supports OpenAI-compatible APIs via &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt; and the &lt;code&gt;/models&lt;/code&gt; endpoint. Provider-specific integrations (legacy &lt;code&gt;MODELS&lt;/code&gt; env var, GGUF discovery, embeddings, web-search helpers, etc.) are removed, but any service that speaks the OpenAI protocol (llama.cpp server, Ollama, OpenRouter, etc. will work by default).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] The old version is still available on the &lt;a href="https://github.com/huggingface/chat-ui/tree/legacy"&gt;legacy branch&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;p&gt;Chat UI speaks to OpenAI-compatible APIs only. The fastest way to get running is with the Hugging Face Inference Providers router plus your personal Hugging Face access token.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 1 ‚Äì Create &lt;code&gt;.env.local&lt;/code&gt;:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-env"&gt;OPENAI_BASE_URL=https://router.huggingface.co/v1
OPENAI_API_KEY=hf_************************
# Fill in once you pick a database option below
MONGODB_URL=
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt; can come from any OpenAI-compatible endpoint you plan to call. Pick the combo that matches your setup and drop the values into &lt;code&gt;.env.local&lt;/code&gt;:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Example &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt;&lt;/th&gt; 
   &lt;th&gt;Example key env&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Hugging Face Inference Providers router&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://router.huggingface.co/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY=hf_xxx&lt;/code&gt; (or &lt;code&gt;HF_TOKEN&lt;/code&gt; legacy alias)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;llama.cpp server (&lt;code&gt;llama.cpp --server --api&lt;/code&gt;)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;http://127.0.0.1:8080/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY=sk-local-demo&lt;/code&gt; (any string works; llama.cpp ignores it)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama (with OpenAI-compatible bridge)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;http://127.0.0.1:11434/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY=ollama&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://openrouter.ai/api/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY=sk-or-v1-...&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Poe&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.poe.com/v1&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY=pk_...&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Check the root &lt;a href="https://raw.githubusercontent.com/huggingface/chat-ui/main/.env"&gt;&lt;code&gt;.env&lt;/code&gt; template&lt;/a&gt; for the full list of optional variables you can override.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 2 ‚Äì Choose where MongoDB lives:&lt;/strong&gt; Either provision a managed cluster (for example MongoDB Atlas) or run a local container. Both approaches are described in &lt;a href="https://raw.githubusercontent.com/huggingface/chat-ui/main/#database-options"&gt;Database Options&lt;/a&gt;. After you have the URI, drop it into &lt;code&gt;MONGODB_URL&lt;/code&gt; (and, if desired, set &lt;code&gt;MONGODB_DB_NAME&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Step 3 ‚Äì Install and launch the dev server:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/huggingface/chat-ui
cd chat-ui
npm install
npm run dev -- --open
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You now have Chat UI running against the Hugging Face router without needing to host MongoDB yourself.&lt;/p&gt; 
&lt;h2&gt;Database Options&lt;/h2&gt; 
&lt;p&gt;Chat history, users, settings, files, and stats all live in MongoDB. You can point Chat UI at any MongoDB 6/7 deployment.&lt;/p&gt; 
&lt;h3&gt;MongoDB Atlas (managed)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create a free cluster at &lt;a href="https://www.mongodb.com/pricing"&gt;mongodb.com&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Add your IP (or &lt;code&gt;0.0.0.0/0&lt;/code&gt; for development) to the network access list.&lt;/li&gt; 
 &lt;li&gt;Create a database user and copy the connection string.&lt;/li&gt; 
 &lt;li&gt;Paste that string into &lt;code&gt;MONGODB_URL&lt;/code&gt; in &lt;code&gt;.env.local&lt;/code&gt;. Keep the default &lt;code&gt;MONGODB_DB_NAME=chat-ui&lt;/code&gt; or change it per environment.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Atlas keeps MongoDB off your laptop, which is ideal for teams or cloud deployments.&lt;/p&gt; 
&lt;h3&gt;Local MongoDB (container)&lt;/h3&gt; 
&lt;p&gt;If you prefer to run MongoDB locally:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d -p 27017:27017 --name mongo-chatui mongo:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then set &lt;code&gt;MONGODB_URL=mongodb://localhost:27017&lt;/code&gt; in &lt;code&gt;.env.local&lt;/code&gt;. You can also supply &lt;code&gt;MONGO_STORAGE_PATH&lt;/code&gt; if you want Chat UI‚Äôs fallback in-memory server to persist under a specific folder.&lt;/p&gt; 
&lt;h2&gt;Launch&lt;/h2&gt; 
&lt;p&gt;After configuring your environment variables, start Chat UI with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install
npm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The dev server listens on &lt;code&gt;http://localhost:5173&lt;/code&gt; by default. Use &lt;code&gt;npm run build&lt;/code&gt; / &lt;code&gt;npm run preview&lt;/code&gt; for production builds.&lt;/p&gt; 
&lt;h2&gt;Optional Docker Image&lt;/h2&gt; 
&lt;p&gt;Prefer containerized setup? You can run everything in one container as long as you supply a MongoDB URI (local or hosted):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run \
  -p 3000 \
  -e MONGODB_URL=mongodb://host.docker.internal:27017 \
  -e OPENAI_BASE_URL=https://router.huggingface.co/v1 \
  -e OPENAI_API_KEY=hf_*** \
  -v db:/data \
  ghcr.io/huggingface/chat-ui-db:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;code&gt;host.docker.internal&lt;/code&gt; lets the container reach a MongoDB instance on your host machine; swap it for your Atlas URI if you use the hosted option. All environment variables accepted in &lt;code&gt;.env.local&lt;/code&gt; can be provided as &lt;code&gt;-e&lt;/code&gt; flags.&lt;/p&gt; 
&lt;h2&gt;Extra parameters&lt;/h2&gt; 
&lt;h3&gt;Theming&lt;/h3&gt; 
&lt;p&gt;You can use a few environment variables to customize the look and feel of chat-ui. These are by default:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-env"&gt;PUBLIC_APP_NAME=ChatUI
PUBLIC_APP_ASSETS=chatui
PUBLIC_APP_DESCRIPTION="Making the community's best AI chat models available to everyone."
PUBLIC_APP_DATA_SHARING=
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;PUBLIC_APP_NAME&lt;/code&gt; The name used as a title throughout the app.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;PUBLIC_APP_ASSETS&lt;/code&gt; Is used to find logos &amp;amp; favicons in &lt;code&gt;static/$PUBLIC_APP_ASSETS&lt;/code&gt;, current options are &lt;code&gt;chatui&lt;/code&gt; and &lt;code&gt;huggingchat&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;PUBLIC_APP_DATA_SHARING&lt;/code&gt; Can be set to 1 to add a toggle in the user settings that lets your users opt-in to data sharing with models creator.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Models&lt;/h3&gt; 
&lt;p&gt;This build does not use the &lt;code&gt;MODELS&lt;/code&gt; env var or GGUF discovery. Configure models via &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt; only; Chat UI will fetch &lt;code&gt;${OPENAI_BASE_URL}/models&lt;/code&gt; and populate the list automatically. Authorization uses &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; (preferred). &lt;code&gt;HF_TOKEN&lt;/code&gt; remains a legacy alias.&lt;/p&gt; 
&lt;h3&gt;LLM Router (Optional)&lt;/h3&gt; 
&lt;p&gt;Chat UI can perform client-side routing &lt;a href="https://huggingface.co/katanemo/Arch-Router-1.5B"&gt;katanemo/Arch-Router-1.5B&lt;/a&gt; as the routing model without running a separate router service. The UI exposes a virtual model alias called "Omni" (configurable) that, when selected, chooses the best route/model for each message.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Provide a routes policy JSON via &lt;code&gt;LLM_ROUTER_ROUTES_PATH&lt;/code&gt;. No sample file ships with this branch, so you must point the variable to a JSON array you create yourself (for example, commit one in your project like &lt;code&gt;config/routes.chat.json&lt;/code&gt;). Each route entry needs &lt;code&gt;name&lt;/code&gt;, &lt;code&gt;description&lt;/code&gt;, &lt;code&gt;primary_model&lt;/code&gt;, and optional &lt;code&gt;fallback_models&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Configure the Arch router selection endpoint with &lt;code&gt;LLM_ROUTER_ARCH_BASE_URL&lt;/code&gt; (OpenAI-compatible &lt;code&gt;/chat/completions&lt;/code&gt;) and &lt;code&gt;LLM_ROUTER_ARCH_MODEL&lt;/code&gt; (e.g. &lt;code&gt;router/omni&lt;/code&gt;). The Arch call reuses &lt;code&gt;OPENAI_API_KEY&lt;/code&gt; for auth.&lt;/li&gt; 
 &lt;li&gt;Map &lt;code&gt;other&lt;/code&gt; to a concrete route via &lt;code&gt;LLM_ROUTER_OTHER_ROUTE&lt;/code&gt; (default: &lt;code&gt;casual_conversation&lt;/code&gt;). If Arch selection fails, calls fall back to &lt;code&gt;LLM_ROUTER_FALLBACK_MODEL&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Selection timeout can be tuned via &lt;code&gt;LLM_ROUTER_ARCH_TIMEOUT_MS&lt;/code&gt; (default 10000).&lt;/li&gt; 
 &lt;li&gt;Omni alias configuration: &lt;code&gt;PUBLIC_LLM_ROUTER_ALIAS_ID&lt;/code&gt; (default &lt;code&gt;omni&lt;/code&gt;), &lt;code&gt;PUBLIC_LLM_ROUTER_DISPLAY_NAME&lt;/code&gt; (default &lt;code&gt;Omni&lt;/code&gt;), and optional &lt;code&gt;PUBLIC_LLM_ROUTER_LOGO_URL&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;When you select Omni in the UI, Chat UI will:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Call the Arch endpoint once (non-streaming) to pick the best route for the last turns.&lt;/li&gt; 
 &lt;li&gt;Emit RouterMetadata immediately (route and actual model used) so the UI can display it.&lt;/li&gt; 
 &lt;li&gt;Stream from the selected model via your configured &lt;code&gt;OPENAI_BASE_URL&lt;/code&gt;. On errors, it tries route fallbacks.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;To create a production version of your app:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm run build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can preview the production build with &lt;code&gt;npm run preview&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;To deploy your app, you may need to install an &lt;a href="https://kit.svelte.dev/docs/adapters"&gt;adapter&lt;/a&gt; for your target environment.&lt;/p&gt; 
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Skyvern-AI/skyvern</title>
      <link>https://github.com/Skyvern-AI/skyvern</link>
      <description>&lt;p&gt;Automate browser-based workflows with LLMs and Computer Vision&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;a href="https://www.skyvern.com"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_logo.png" /&gt; 
   &lt;img height="120" src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_logo_blackbg.png" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; üêâ Automate Browser-based workflows using LLMs and Computer Vision üêâ &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.skyvern.com/"&gt;&lt;img src="https://img.shields.io/badge/Website-blue?logo=googlechrome&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://www.skyvern.com/docs/"&gt;&lt;img src="https://img.shields.io/badge/Docs-yellow?logo=gitbook&amp;amp;logoColor=black" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;&lt;img src="https://img.shields.io/discord/1212486326352617534?logo=discord&amp;amp;label=discord" /&gt;&lt;/a&gt; 
 &lt;!-- &lt;a href="https://pepy.tech/project/skyvern" target="_blank"&gt;&lt;img src="https://static.pepy.tech/badge/skyvern" alt="Total Downloads"/&gt;&lt;/a&gt; --&gt; &lt;a href="https://github.com/skyvern-ai/skyvern"&gt;&lt;img src="https://img.shields.io/github/stars/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/skyvern-ai/skyvern" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/skyvernai"&gt;&lt;img src="https://img.shields.io/twitter/follow/skyvernai?style=social" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/95726232"&gt;&lt;img src="https://img.shields.io/badge/Follow%20 on%20LinkedIn-8A2BE2?logo=linkedin" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.skyvern.com"&gt;Skyvern&lt;/a&gt; automates browser-based workflows using LLMs and computer vision. It provides a simple API endpoint to fully automate manual workflows on a large number of websites, replacing brittle or unreliable automation solutions.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;Traditional approaches to browser automations required writing custom scripts for websites, often relying on DOM parsing and XPath-based interactions which would break whenever the website layouts changed.&lt;/p&gt; 
&lt;p&gt;Instead of only relying on code-defined XPath interactions, Skyvern relies on Vision LLMs to learn and interact with the websites.&lt;/p&gt; 
&lt;h1&gt;How it works&lt;/h1&gt; 
&lt;p&gt;Skyvern was inspired by the Task-Driven autonomous agent design popularized by &lt;a href="https://github.com/yoheinakajima/babyagi"&gt;BabyAGI&lt;/a&gt; and &lt;a href="https://github.com/Significant-Gravitas/AutoGPT"&gt;AutoGPT&lt;/a&gt; -- with one major bonus: we give Skyvern the ability to interact with websites using browser automation libraries like &lt;a href="https://playwright.dev/"&gt;Playwright&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Skyvern uses a swarm of agents to comprehend a website, and plan and execute its actions:&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="fern/images/skyvern_2_0_system_diagram.png" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_system_diagram.png" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;This approach has a few advantages:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Skyvern can operate on websites it's never seen before, as it's able to map visual elements to actions necessary to complete a workflow, without any customized code&lt;/li&gt; 
 &lt;li&gt;Skyvern is resistant to website layout changes, as there are no pre-determined XPaths or other selectors our system is looking for while trying to navigate&lt;/li&gt; 
 &lt;li&gt;Skyvern is able to take a single workflow and apply it to a large number of websites, as it's able to reason through the interactions necessary to complete the workflow&lt;/li&gt; 
 &lt;li&gt;Skyvern leverages LLMs to reason through interactions to ensure we can cover complex situations. Examples include: 
  &lt;ol&gt; 
   &lt;li&gt;If you wanted to get an auto insurance quote from Geico, the answer to a common question "Were you eligible to drive at 18?" could be inferred from the driver receiving their license at age 16&lt;/li&gt; 
   &lt;li&gt;If you were doing competitor analysis, it's understanding that an Arnold Palmer 22 oz can at 7/11 is almost definitely the same product as a 23 oz can at Gopuff (even though the sizes are slightly different, which could be a rounding error!)&lt;/li&gt; 
  &lt;/ol&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;A detailed technical report can be found &lt;a href="https://www.skyvern.com/blog/skyvern-2-0-state-of-the-art-web-navigation-with-85-8-on-webvoyager-eval/"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Demo&lt;/h1&gt; 
&lt;!-- Redo demo --&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f"&gt;https://github.com/user-attachments/assets/5cab4668-e8e2-4982-8551-aab05ff73a7f&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Performance &amp;amp; Evaluation&lt;/h1&gt; 
&lt;p&gt;Skyvern has SOTA performance on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/webbench.ai"&gt;WebBench benchmark&lt;/a&gt; with a 64.4% accuracy. The technical report + evaluation can be found &lt;a href="https://www.skyvern.com/blog/web-bench-a-new-way-to-compare-ai-browser-agents/"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_overall.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Performance on WRITE tasks (eg filling out forms, logging in, downloading files, etc)&lt;/h2&gt; 
&lt;p&gt;Skyvern is the best performing agent on WRITE tasks (eg filling out forms, logging in, downloading files, etc), which is primarily used for RPA (Robotic Process Automation) adjacent tasks.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/performance/webbench_write.png" /&gt; &lt;/p&gt; 
&lt;h1&gt;Quickstart&lt;/h1&gt; 
&lt;h2&gt;Skyvern Cloud&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com"&gt;Skyvern Cloud&lt;/a&gt; is a managed cloud version of Skyvern that allows you to run Skyvern without worrying about the infrastructure. It allows you to run multiple Skyvern instances in parallel and comes bundled with anti-bot detection mechanisms, proxy network, and CAPTCHA solvers.&lt;/p&gt; 
&lt;p&gt;If you'd like to try it out, navigate to &lt;a href="https://app.skyvern.com"&gt;app.skyvern.com&lt;/a&gt; and create an account.&lt;/p&gt; 
&lt;h2&gt;Install &amp;amp; Run&lt;/h2&gt; 
&lt;p&gt;Dependencies needed:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.python.org/downloads/"&gt;Python 3.11.x&lt;/a&gt;, works with 3.12, not ready yet for 3.13&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/en/download/"&gt;NodeJS &amp;amp; NPM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Additionally, for Windows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://rustup.rs/"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VS Code with C++ dev tools and Windows SDK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;1. Install Skyvern&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install skyvern
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Run Skyvern&lt;/h3&gt; 
&lt;p&gt;This is most helpful for first time run (db setup, db migrations etc).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Run task&lt;/h3&gt; 
&lt;h4&gt;UI (Recommended)&lt;/h4&gt; 
&lt;p&gt;Start the Skyvern service and UI (when DB is up and running)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;skyvern run all
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Go to &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt; and use the UI to run a task&lt;/p&gt; 
&lt;h4&gt;Code&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Skyvern starts running the task in a browser that pops up and closes it when the task is done. You will be able to view the task from &lt;a href="http://localhost:8080/history"&gt;http://localhost:8080/history&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;You can also run a task on different targets:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# Run on Skyvern Cloud
skyvern = Skyvern(api_key="SKYVERN API KEY")

# Local Skyvern service
skyvern = Skyvern(base_url="http://localhost:8000", api_key="LOCAL SKYVERN API KEY")

task = await skyvern.run_task(prompt="Find the top post on hackernews today")
print(task)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Advanced Usage&lt;/h2&gt; 
&lt;h3&gt;Control your own browser (Chrome)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è WARNING: Since &lt;a href="https://developer.chrome.com/blog/remote-debugging-port"&gt;Chrome 136&lt;/a&gt;, Chrome refuses any CDP connect to the browser using the default user_data_dir. In order to use your browser data, Skyvern copies your default user_data_dir to &lt;code&gt;./tmp/user_data_dir&lt;/code&gt; the first time connecting to your local browser. ‚ö†Ô∏è&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Just With Python Code&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

# The path to your Chrome browser. This example path is for Mac.
browser_path = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
skyvern = Skyvern(
    base_url="http://localhost:8000",
    api_key="YOUR_API_KEY",
    browser_path=browser_path,
)
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;With Skyvern Service&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Add two variables to your .env file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# The path to your Chrome browser. This example path is for Mac.
CHROME_EXECUTABLE_PATH="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
BROWSER_TYPE=cdp-connect
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Restart Skyvern service &lt;code&gt;skyvern run all&lt;/code&gt; and run the task through UI or code&lt;/p&gt; 
&lt;h3&gt;Run Skyvern with any remote browser&lt;/h3&gt; 
&lt;p&gt;Grab the cdp connection url and pass it to Skyvern&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern(cdp_url="your cdp connection url")
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Get consistent output schema from your run&lt;/h3&gt; 
&lt;p&gt;You can do this by adding the &lt;code&gt;data_extraction_schema&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from skyvern import Skyvern

skyvern = Skyvern()
task = await skyvern.run_task(
    prompt="Find the top post on hackernews today",
    data_extraction_schema={
        "type": "object",
        "properties": {
            "title": {
                "type": "string",
                "description": "The title of the top post"
            },
            "url": {
                "type": "string",
                "description": "The URL of the top post"
            },
            "points": {
                "type": "integer",
                "description": "Number of points the post has received"
            }
        }
    }
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Helpful commands to debug issues&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch the Skyvern Server Separately*
skyvern run server

# Launch the Skyvern UI
skyvern run ui

# Check status of the Skyvern service
skyvern status

# Stop the Skyvern service
skyvern stop all

# Stop the Skyvern UI
skyvern stop ui

# Stop the Skyvern Server Separately
skyvern stop server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker Compose setup&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Make sure you have &lt;a href="https://www.docker.com/products/docker-desktop/"&gt;Docker Desktop&lt;/a&gt; installed and running on your machine&lt;/li&gt; 
 &lt;li&gt;Make sure you don't have postgres running locally (Run &lt;code&gt;docker ps&lt;/code&gt; to check)&lt;/li&gt; 
 &lt;li&gt;Clone the repository and navigate to the root directory&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;skyvern init llm&lt;/code&gt; to generate a &lt;code&gt;.env&lt;/code&gt; file. This will be copied into the Docker image.&lt;/li&gt; 
 &lt;li&gt;Fill in the LLM provider key on the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;. &lt;em&gt;If you want to run Skyvern on a remote server, make sure you set the correct server ip for the UI container in &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt;.&lt;/em&gt;&lt;/li&gt; 
 &lt;li&gt;Run the following command via the commandline: &lt;pre&gt;&lt;code class="language-bash"&gt; docker compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Only one Postgres container can run on port 5432 at a time. If you switch from the CLI-managed Postgres to Docker Compose, you must first remove the original container:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker rm -f postgresql-container
&lt;/code&gt;&lt;/pre&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you encounter any database related errors while using Docker to run Skyvern, check which Postgres container is running with &lt;code&gt;docker ps&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;Skyvern Features&lt;/h1&gt; 
&lt;h2&gt;Skyvern Tasks&lt;/h2&gt; 
&lt;p&gt;Tasks are the fundamental building block inside Skyvern. Each task is a single request to Skyvern, instructing it to navigate through a website and accomplish a specific goal.&lt;/p&gt; 
&lt;p&gt;Tasks require you to specify a &lt;code&gt;url&lt;/code&gt;, &lt;code&gt;prompt&lt;/code&gt;, and can optionally include a &lt;code&gt;data schema&lt;/code&gt; (if you want the output to conform to a specific schema) and &lt;code&gt;error codes&lt;/code&gt; (if you want Skyvern to stop running in specific situations).&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/skyvern_2_0_screenshot.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Skyvern Workflows&lt;/h2&gt; 
&lt;p&gt;Workflows are a way to chain multiple tasks together to form a cohesive unit of work.&lt;/p&gt; 
&lt;p&gt;For example, if you wanted to download all invoices newer than January 1st, you could create a workflow that first navigated to the invoices page, then filtered down to only show invoices newer than January 1st, extracted a list of all eligible invoices, and iterated through each invoice to download it.&lt;/p&gt; 
&lt;p&gt;Another example is if you wanted to automate purchasing products from an e-commerce store, you could create a workflow that first navigated to the desired product, then added it to a cart. Second, it would navigate to the cart and validate the cart state. Finally, it would go through the checkout process to purchase the items.&lt;/p&gt; 
&lt;p&gt;Supported workflow features include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Browser Task&lt;/li&gt; 
 &lt;li&gt;Browser Action&lt;/li&gt; 
 &lt;li&gt;Data Extraction&lt;/li&gt; 
 &lt;li&gt;Validation&lt;/li&gt; 
 &lt;li&gt;For Loops&lt;/li&gt; 
 &lt;li&gt;File parsing&lt;/li&gt; 
 &lt;li&gt;Sending emails&lt;/li&gt; 
 &lt;li&gt;Text Prompts&lt;/li&gt; 
 &lt;li&gt;HTTP Request Block&lt;/li&gt; 
 &lt;li&gt;Custom Code Block&lt;/li&gt; 
 &lt;li&gt;Uploading files to block storage&lt;/li&gt; 
 &lt;li&gt;(Coming soon) Conditionals&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/block_example_v2.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Livestreaming&lt;/h2&gt; 
&lt;p&gt;Skyvern allows you to livestream the viewport of the browser to your local machine so that you can see exactly what Skyvern is doing on the web. This is useful for debugging and understanding how Skyvern is interacting with a website, and intervening when necessary&lt;/p&gt; 
&lt;h2&gt;Form Filling&lt;/h2&gt; 
&lt;p&gt;Skyvern is natively capable of filling out form inputs on websites. Passing in information via the &lt;code&gt;navigation_goal&lt;/code&gt; will allow Skyvern to comprehend the information and fill out the form accordingly.&lt;/p&gt; 
&lt;h2&gt;Data Extraction&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of extracting data from a website.&lt;/p&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;data_extraction_schema&lt;/code&gt; directly within the main prompt to tell Skyvern exactly what data you'd like to extract from the website, in jsonc format. Skyvern's output will be structured in accordance to the supplied schema.&lt;/p&gt; 
&lt;h2&gt;File Downloading&lt;/h2&gt; 
&lt;p&gt;Skyvern is also capable of downloading files from a website. All downloaded files are automatically uploaded to block storage (if configured), and you can access them via the UI.&lt;/p&gt; 
&lt;h2&gt;Authentication&lt;/h2&gt; 
&lt;p&gt;Skyvern supports a number of different authentication methods to make it easier to automate tasks behind a login. If you'd like to try it out, please reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/secure_password_task_example.png" /&gt; &lt;/p&gt; 
&lt;h3&gt;üîê 2FA Support (TOTP)&lt;/h3&gt; 
&lt;p&gt;Skyvern supports a number of different 2FA methods to allow you to automate workflows that require 2FA.&lt;/p&gt; 
&lt;p&gt;Examples include:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;QR-based 2FA (e.g. Google Authenticator, Authy)&lt;/li&gt; 
 &lt;li&gt;Email based 2FA&lt;/li&gt; 
 &lt;li&gt;SMS based 2FA&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;üîê Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Password Manager Integrations&lt;/h3&gt; 
&lt;p&gt;Skyvern currently supports the following password manager integrations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Bitwarden&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; 1Password&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; LastPass&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Model Context Protocol (MCP)&lt;/h2&gt; 
&lt;p&gt;Skyvern supports the Model Context Protocol (MCP) to allow you to use any LLM that supports MCP.&lt;/p&gt; 
&lt;p&gt;See the MCP documentation &lt;a href="https://github.com/Skyvern-AI/skyvern/raw/main/integrations/mcp/README.md"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Zapier / Make.com / N8N Integration&lt;/h2&gt; 
&lt;p&gt;Skyvern supports Zapier, Make.com, and N8N to allow you to connect your Skyvern workflows to other apps.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/zapier"&gt;Zapier&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/make.com"&gt;Make.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.skyvern.com/docs/integrations/n8n"&gt;N8N&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üîê Learn more about 2FA support &lt;a href="https://www.skyvern.com/docs/credentials/totp"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Real-world examples of Skyvern&lt;/h1&gt; 
&lt;p&gt;We love to see how Skyvern is being used in the wild. Here are some examples of how Skyvern is being used to automate workflows in the real world. Please open PRs to add your own examples!&lt;/p&gt; 
&lt;h2&gt;Invoice Downloading on many different websites&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://meetings.hubspot.com/skyvern/demo"&gt;Book a demo to see it live&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/invoice_downloading.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate the job application process&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/job_application"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/job_application_demo.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Automate materials procurement for a manufacturing company&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/finditparts"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/finditparts_recording_crop.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Navigating to government websites to register accounts or fill out forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/california_edd"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/edd_services.gif" /&gt; &lt;/p&gt; 
&lt;!-- Add example of delaware entity lookups x2 --&gt; 
&lt;h2&gt;Filling out random contact us forms&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/contact_us_forms"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/contact_forms.gif" /&gt; &lt;/p&gt; 
&lt;h2&gt;Retrieving insurance quotes from insurance providers in any language&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/bci_seguros"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/bci_seguros_recording.gif" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.skyvern.com/tasks/create/geico"&gt;üí° See it in action&lt;/a&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/fern/images/geico_shu_recording_cropped.gif" /&gt; &lt;/p&gt; 
&lt;h1&gt;Contributor Setup&lt;/h1&gt; 
&lt;p&gt;Make sure to have &lt;a href="https://docs.astral.sh/uv/getting-started/installation/"&gt;uv&lt;/a&gt; installed.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run this to create your virtual environment (&lt;code&gt;.venv&lt;/code&gt;) &lt;pre&gt;&lt;code class="language-bash"&gt;uv sync --group dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Perform initial server configuration &lt;pre&gt;&lt;code class="language-bash"&gt;uv run skyvern quickstart
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; in your browser to start using the UI &lt;em&gt;The Skyvern CLI supports Windows, WSL, macOS, and Linux environments.&lt;/em&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;p&gt;More extensive documentation can be found on our &lt;a href="https://www.skyvern.com/docs"&gt;üìï docs page&lt;/a&gt;. Please let us know if something is unclear or missing by opening an issue or reaching out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Supported LLMs&lt;/h1&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;Supported Models&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;gpt4-turbo, gpt-4o, gpt-4o-mini&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure OpenAI&lt;/td&gt; 
   &lt;td&gt;Any GPT models. Better performance with a multimodal llm (azure/gpt4-o)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;AWS Bedrock&lt;/td&gt; 
   &lt;td&gt;Anthropic Claude 3 (Haiku, Sonnet, Opus), Claude 3.5 (Sonnet)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Gemini&lt;/td&gt; 
   &lt;td&gt;Gemini 2.5 Pro and flash, Gemini 2.0&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;Run any locally hosted model via &lt;a href="https://github.com/ollama/ollama"&gt;Ollama&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;Access models through &lt;a href="https://openrouter.ai"&gt;OpenRouter&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI-compatible&lt;/td&gt; 
   &lt;td&gt;Any custom API endpoint that follows OpenAI's API format (via &lt;a href="https://docs.litellm.ai/docs/providers/openai_compatible"&gt;liteLLM&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;Environment Variables&lt;/h4&gt; 
&lt;h5&gt;OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI API Base, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://openai.api.base&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_ORGANIZATION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Organization ID, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your-org-id&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENAI_GPT4O&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4O_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_GPT4_1&lt;/code&gt;, &lt;code&gt;OPENAI_O4_MINI&lt;/code&gt;, &lt;code&gt;OPENAI_O3&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Anthropic&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_ANTHROPIC&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Anthropic models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Anthropic API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended&lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;ANTHROPIC_CLAUDE3.5_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE3.7_SONNET&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_OPUS&lt;/code&gt;, &lt;code&gt;ANTHROPIC_CLAUDE4_SONNET&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Azure OpenAI&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_AZURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Azure OpenAI models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_DEPLOYMENT&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure OpenAI Deployment Name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;skyvern-deployment&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure deployment api base url&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://skyvern-deployment.openai.azure.com/&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;AZURE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Azure API Version&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2024-02-01&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;AZURE_OPENAI&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;AWS Bedrock&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_BEDROCK&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register AWS Bedrock models. To use AWS Bedrock, you need to make sure your &lt;a href="https://github.com/boto/boto3?tab=readme-ov-file#using-boto3"&gt;AWS configurations&lt;/a&gt; are set up correctly first.&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE3.7_SONNET_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_OPUS_INFERENCE_PROFILE&lt;/code&gt;, &lt;code&gt;BEDROCK_ANTHROPIC_CLAUDE4_SONNET_INFERENCE_PROFILE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Gemini&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_GEMINI&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register Gemini models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;GEMINI_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Gemini API Key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;your_google_gemini_api_key&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;GEMINI_2.5_PRO_PREVIEW&lt;/code&gt;, &lt;code&gt;GEMINI_2.5_FLASH_PREVIEW&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;Ollama&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OLLAMA&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register local models via Ollama&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_SERVER_URL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;URL for your Ollama server&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OLLAMA_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Ollama model name to load&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;qwen2.5:7b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OLLAMA&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note: Ollama does not support vision yet.&lt;/p&gt; 
&lt;h5&gt;OpenRouter&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENROUTER&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register OpenRouter models&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API key&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_MODEL&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter model name&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mistralai/mistral-small-3.1-24b-instruct&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENROUTER_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;OpenRouter API base URL&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.openrouter.ai/v1&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Recommended &lt;code&gt;LLM_KEY&lt;/code&gt;: &lt;code&gt;OPENROUTER&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;OpenAI-Compatible&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ENABLE_OPENAI_COMPATIBLE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Register a custom OpenAI-compatible API endpoint&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MODEL_NAME&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Model name for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;yi-34b&lt;/code&gt;, &lt;code&gt;gpt-3.5-turbo&lt;/code&gt;, &lt;code&gt;mistral-large&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API key for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;sk-1234567890&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_BASE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Base URL for OpenAI-compatible endpoint&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;https://api.together.xyz/v1&lt;/code&gt;, &lt;code&gt;http://localhost:8000/v1&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_API_VERSION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;API version for OpenAI-compatible endpoint, optional&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;2023-05-15&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Maximum tokens for completion, optional&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;4096&lt;/code&gt;, &lt;code&gt;8192&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_TEMPERATURE&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Temperature setting, optional&lt;/td&gt; 
   &lt;td&gt;Float&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;0.0&lt;/code&gt;, &lt;code&gt;0.5&lt;/code&gt;, &lt;code&gt;0.7&lt;/code&gt;, etc.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;OPENAI_COMPATIBLE_SUPPORTS_VISION&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Whether model supports vision, optional&lt;/td&gt; 
   &lt;td&gt;Boolean&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;true&lt;/code&gt;, &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Supported LLM Key: &lt;code&gt;OPENAI_COMPATIBLE&lt;/code&gt;&lt;/p&gt; 
&lt;h5&gt;General LLM Configuration&lt;/h5&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Variable&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Sample Value&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model you want to use&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;SECONDARY_LLM_KEY&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;The name of the model for mini agents skyvern runs with&lt;/td&gt; 
   &lt;td&gt;String&lt;/td&gt; 
   &lt;td&gt;See supported LLM keys above&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;LLM_CONFIG_MAX_TOKENS&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Override the max tokens used by the LLM&lt;/td&gt; 
   &lt;td&gt;Integer&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;128000&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;Feature Roadmap&lt;/h1&gt; 
&lt;p&gt;This is our planned roadmap for the next few months. If you have any suggestions or would like to see a feature added, please don't hesitate to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Open Source&lt;/strong&gt; - Open Source Skyvern's core codebase&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow support&lt;/strong&gt; - Allow support to chain multiple Skyvern calls together&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Improved context&lt;/strong&gt; - Improve Skyvern's ability to understand content around interactable elements by introducing feeding relevant label context through the text prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Cost Savings&lt;/strong&gt; - Improve Skyvern's stability and reduce the cost of running Skyvern by optimizing the context tree passed into Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Self-serve UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI component that allows users to kick off new jobs in Skyvern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Workflow UI Builder&lt;/strong&gt; - Introduce a UI to allow users to build and analyze workflows visually&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Chrome Viewport streaming&lt;/strong&gt; - Introduce a way to live-stream the Chrome viewport to the user's browser (as a part of the self-serve UI)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Past Runs UI&lt;/strong&gt; - Deprecate the Streamlit UI in favour of a React-based UI that allows you to visualize past runs and their results&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Auto workflow builder ("Observer") mode&lt;/strong&gt; - Allow Skyvern to auto-generate workflows as it's navigating the web to make it easier to build new workflows&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Prompt Caching&lt;/strong&gt; - Introduce a caching layer to the LLM calls to dramatically reduce the cost of running Skyvern (memorize past actions and repeat them!)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Web Evaluation Dataset&lt;/strong&gt; - Integrate Skyvern with public benchmark tests to track the quality of our models over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Improved Debug mode&lt;/strong&gt; - Allow Skyvern to plan its actions and get "approval" before running them, allowing you to debug what it's doing and more easily iterate on the prompt&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Chrome Extension&lt;/strong&gt; - Allow users to interact with Skyvern through a Chrome extension (incl voice mode, saving tasks, etc.)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Skyvern Action Recorder&lt;/strong&gt; - Allow Skyvern to watch a user complete a task and then automatically generate a workflow for it&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Interactable Livestream&lt;/strong&gt; - Allow users to interact with the livestream in real-time to intervene when necessary (such as manually submitting sensitive forms)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; &lt;strong&gt;Integrate LLM Observability tools&lt;/strong&gt; - Integrate LLM Observability tools to allow back-testing prompt changes with specific data sets + visualize the performance of Skyvern over time&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Langchain Integration&lt;/strong&gt; - Create langchain integration in langchain_community to use Skyvern as a "tool".&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;We welcome PRs and suggestions! Don't hesitate to open a PR/issue or to reach out to us &lt;a href="mailto:founders@skyvern.com"&gt;via email&lt;/a&gt; or &lt;a href="https://discord.gg/fG2XXEuQX3"&gt;discord&lt;/a&gt;. Please have a look at our &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; and &lt;a href="https://github.com/skyvern-ai/skyvern/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;"Help Wanted" issues&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;p&gt;If you want to chat with the skyvern repository to get a high level overview of how it is structured, how to build off it, and how to resolve usage questions, check out &lt;a href="https://sage.storia.ai?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=skyvern-readme"&gt;Code Sage&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Telemetry&lt;/h1&gt; 
&lt;p&gt;By Default, Skyvern collects basic usage statistics to help us understand how Skyvern is being used. If you would like to opt-out of telemetry, please set the &lt;code&gt;SKYVERN_TELEMETRY&lt;/code&gt; environment variable to &lt;code&gt;false&lt;/code&gt;.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;Skyvern's open source repository is supported via a managed cloud. All of the core logic powering Skyvern is available in this open source repository licensed under the &lt;a href="https://raw.githubusercontent.com/Skyvern-AI/skyvern/main/LICENSE"&gt;AGPL-3.0 License&lt;/a&gt;, with the exception of anti-bot measures available in our managed cloud offering.&lt;/p&gt; 
&lt;p&gt;If you have any questions or concerns around licensing, please &lt;a href="mailto:support@skyvern.com"&gt;contact us&lt;/a&gt; and we would be happy to help.&lt;/p&gt; 
&lt;h1&gt;Star History&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#Skyvern-AI/skyvern&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Skyvern-AI/skyvern&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>jingyaogong/minimind</title>
      <link>https://github.com/jingyaogong/minimind</link>
      <description>&lt;p&gt;üöÄüöÄ „ÄåÂ§ßÊ®°Âûã„Äç2Â∞èÊó∂ÂÆåÂÖ®‰ªé0ËÆ≠ÁªÉ26MÁöÑÂ∞èÂèÇÊï∞GPTÔºÅüåè Train a 26M-parameter GPT from scratch in just 2h!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/logo.png" alt="logo" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://visitor-badge.laobi.icu/badge?page_id=jingyaogong/minimind" alt="visitors" /&gt; &lt;a href="https://github.com/jingyaogong/minimind/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/jingyaogong/minimind?style=social" alt="GitHub Repo stars" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/jingyaogong/minimind" alt="GitHub Code License" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jingyaogong/minimind/commits/master"&gt;&lt;img src="https://img.shields.io/github/last-commit/jingyaogong/minimind" alt="GitHub last commit" /&gt;&lt;/a&gt; &lt;a href="https://github.com/jingyaogong/minimind/pulls"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome-blue" alt="GitHub pull request" /&gt;&lt;/a&gt; &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%A4%97-MiniMind%20%20Collection-blue" alt="Collection" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;h3&gt;"Â§ßÈÅìËá≥ÁÆÄ"&lt;/h3&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;‰∏≠Êñá | &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/README_en.md"&gt;English&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ê≠§ÂºÄÊ∫êÈ°πÁõÆÊó®Âú®ÂÆåÂÖ®‰ªé0ÂºÄÂßãÔºå‰ªÖÁî®3ÂùóÈí±ÊàêÊú¨ + 2Â∞èÊó∂ÔºÅÂç≥ÂèØËÆ≠ÁªÉÂá∫‰ªÖ‰∏∫25.8MÁöÑË∂ÖÂ∞èËØ≠Ë®ÄÊ®°Âûã&lt;strong&gt;MiniMind&lt;/strong&gt;„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;Á≥ªÂàóÊûÅÂÖ∂ËΩªÈáèÔºåÊúÄÂ∞èÁâàÊú¨‰ΩìÁßØÊòØ GPT-3 ÁöÑ $\frac{1}{7000}$ÔºåÂäõÊ±ÇÂÅöÂà∞ÊúÄÊôÆÈÄöÁöÑ‰∏™‰∫∫GPU‰πüÂèØÂø´ÈÄüËÆ≠ÁªÉ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;È°πÁõÆÂêåÊó∂ÂºÄÊ∫ê‰∫ÜÂ§ßÊ®°ÂûãÁöÑÊûÅÁÆÄÁªìÊûÑ-ÂåÖÂê´ÊãìÂ±ïÂÖ±‰∫´Ê∑∑Âêà‰∏ìÂÆ∂(MoE)„ÄÅÊï∞ÊçÆÈõÜÊ∏ÖÊ¥ó„ÄÅÈ¢ÑËÆ≠ÁªÉ(Pretrain)„ÄÅÁõëÁù£ÂæÆË∞É(SFT)„ÄÅLoRAÂæÆË∞ÉÔºå Áõ¥Êé•ÂÅèÂ•ΩÂº∫ÂåñÂ≠¶‰π†(DPO)ÁÆóÊ≥ï„ÄÅÊ®°ÂûãËí∏È¶èÁÆóÊ≥ïÁ≠âÂÖ®ËøáÁ®ã‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MiniMind&lt;/strong&gt;ÂêåÊó∂ÊãìÂ±ï‰∫ÜËßÜËßâÂ§öÊ®°ÊÄÅÁöÑVLM: &lt;a href="https://github.com/jingyaogong/minimind-v"&gt;MiniMind-V&lt;/a&gt;„ÄÇ&lt;/li&gt; 
 &lt;li&gt;È°πÁõÆÊâÄÊúâÊ†∏ÂøÉÁÆóÊ≥ï‰ª£Á†ÅÂùá‰ªé0‰ΩøÁî®PyTorchÂéüÁîüÈáçÊûÑÔºÅ‰∏ç‰æùËµñÁ¨¨‰∏âÊñπÂ∫ìÊèê‰æõÁöÑÊäΩË±°Êé•Âè£„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Ëøô‰∏ç‰ªÖÊòØÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖ®Èò∂ÊÆµÂºÄÊ∫êÂ§çÁé∞Ôºå‰πüÊòØ‰∏Ä‰∏™ÂÖ•Èó®LLMÁöÑÊïôÁ®ã„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Â∏åÊúõÊ≠§È°πÁõÆËÉΩ‰∏∫ÊâÄÊúâ‰∫∫Êèê‰æõ‰∏Ä‰∏™ÊäõÁ†ñÂºïÁéâÁöÑÁ§∫‰æãÔºå‰∏ÄËµ∑ÊÑüÂèóÂàõÈÄ†ÁöÑ‰πêË∂£ÔºÅÊé®Âä®Êõ¥ÂπøÊ≥õAIÁ§æÂå∫ÁöÑËøõÊ≠•ÔºÅ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‰∏∫Èò≤Ê≠¢ËØØËß£Ôºå‚Äú2Â∞èÊó∂‚Äù Âü∫‰∫éNVIDIA 3090Á°¨‰ª∂ËÆæÂ§áÔºàÂçïÂç°ÔºâÊµãËØïÔºå‚Äú3ÂùóÈí±‚Äù ÊåáGPUÊúçÂä°Âô®ÁßüÁî®ÊàêÊú¨ÔºåÂÖ∑‰ΩìËßÑÊ†ºËØ¶ÊÉÖËßÅ‰∏ãÊñá„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/minimind2.gif" alt="minimind2" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.modelscope.cn/studios/gongjy/MiniMind-Reasoning"&gt;üîóüçìÊé®ÁêÜÊ®°Âûã&lt;/a&gt; | &lt;a href="https://www.modelscope.cn/studios/gongjy/MiniMind"&gt;üîóü§ñÂ∏∏ËßÑÊ®°Âûã&lt;/a&gt; | &lt;a href="https://www.bilibili.com/video/BV12dHPeqE72/?share_source=copy_web&amp;amp;vd_source=670c2504f88726f8cf4a21ef6147c0e8"&gt;üîóüéûÔ∏èËßÜÈ¢ë‰ªãÁªç&lt;/a&gt;&lt;/p&gt; 
 &lt;div align="center"&gt; 
  &lt;table&gt; 
   &lt;tbody&gt;
    &lt;tr&gt; 
     &lt;td align="center"&gt; &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5" style="text-decoration: none;"&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_huggingface.png" alt="Hugging Face Logo" style="vertical-align: middle; width: auto; max-width: 100%;" /&gt; &lt;/a&gt; &lt;/td&gt; 
     &lt;td align="center"&gt; &lt;a href="https://www.modelscope.cn/profile/gongjy" style="text-decoration: none;"&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/and_modelscope.png" alt="ModelScope Logo" style="vertical-align: middle; width: auto; max-width: 100%;" /&gt; &lt;/a&gt; &lt;/td&gt; 
    &lt;/tr&gt; 
   &lt;/tbody&gt;
  &lt;/table&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;h1&gt;üìå Introduction&lt;/h1&gt; 
&lt;p&gt;Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLarge Language Model, LLMÔºâÁöÑÂá∫Áé∞ÂºïÂèë‰∫ÜÂÖ®‰∏ñÁïåÂØπAIÁöÑÁ©∫ÂâçÂÖ≥Ê≥®„ÄÇ Êó†ËÆ∫ÊòØChatGPT„ÄÅDeepSeekËøòÊòØQwenÔºåÈÉΩ‰ª•ÂÖ∂ÊÉäËâ≥ÁöÑÊïàÊûú‰ª§‰∫∫Âèπ‰∏∫ËßÇÊ≠¢„ÄÇ ÁÑ∂ËÄåÔºåÂä®ËæÑÊï∞Áôæ‰∫øÂèÇÊï∞ÁöÑÂ∫ûÂ§ßËßÑÊ®°Ôºå‰ΩøÂæóÂÆÉ‰ª¨ÂØπ‰∏™‰∫∫ËÆæÂ§áËÄåË®Ä‰∏ç‰ªÖÈöæ‰ª•ËÆ≠ÁªÉÔºåÁîöËá≥ËøûÈÉ®ÁΩ≤ÈÉΩÊòæÂæóÈÅ•‰∏çÂèØÂèä„ÄÇ ÊâìÂºÄÂ§ßÊ®°ÂûãÁöÑ‚ÄúÈªëÁõíÂ≠ê‚ÄùÔºåÊé¢Á¥¢ÂÖ∂ÂÜÖÈÉ®Ëøê‰ΩúÊú∫Âà∂ÔºåÂ§ö‰πà‰ª§‰∫∫ÂøÉÊΩÆÊæéÊπÉÔºÅ ÈÅóÊÜæÁöÑÊòØÔºå99%ÁöÑÊé¢Á¥¢Âè™ËÉΩÊ≠¢Ê≠•‰∫é‰ΩøÁî®LoRAÁ≠âÊäÄÊúØÂØπÁé∞ÊúâÂ§ßÊ®°ÂûãËøõË°åÂ∞ëÈáèÂæÆË∞ÉÔºåÂ≠¶‰π†‰∏Ä‰∫õÊñ∞Êåá‰ª§Êàñ‰ªªÂä°„ÄÇ ËøôÂ∞±Â•ΩÊØîÊïôÁâõÈ°øÂ¶Ç‰Ωï‰ΩøÁî®21‰∏ñÁ∫™ÁöÑÊô∫ËÉΩÊâãÊú∫‚Äî‚ÄîËôΩÁÑ∂ÊúâË∂£ÔºåÂç¥ÂÆåÂÖ®ÂÅèÁ¶ª‰∫ÜÁêÜËß£Áâ©ÁêÜÊú¨Ë¥®ÁöÑÂàùË°∑„ÄÇ ‰∏éÊ≠§ÂêåÊó∂ÔºåÁ¨¨‰∏âÊñπÁöÑÂ§ßÊ®°ÂûãÊ°ÜÊû∂ÂíåÂ∑•ÂÖ∑Â∫ìÔºåÂ¶Çtransformers+trlÔºåÂá†‰πéÂè™Êö¥Èú≤‰∫ÜÈ´òÂ∫¶ÊäΩË±°ÁöÑÊé•Âè£„ÄÇ ÈÄöËøáÁü≠Áü≠10Ë°å‰ª£Á†ÅÔºåÂ∞±ËÉΩÂÆåÊàê‚ÄúÂä†ËΩΩÊ®°Âûã+Âä†ËΩΩÊï∞ÊçÆÈõÜ+Êé®ÁêÜ+Âº∫ÂåñÂ≠¶‰π†‚ÄùÁöÑÂÖ®ÊµÅÁ®ãËÆ≠ÁªÉ„ÄÇ ËøôÁßçÈ´òÊïàÁöÑÂ∞ÅË£ÖÂõ∫ÁÑ∂‰æøÂà©Ôºå‰ΩÜ‰πüÂÉè‰∏ÄÊû∂È´òÈÄüÈ£ûËàπÔºåÂ∞ÜÊàë‰ª¨‰∏éÂ∫ïÂ±ÇÂÆûÁé∞ÈöîÁ¶ªÂºÄÊù•ÔºåÈòªÁ¢ç‰∫ÜÊ∑±ÂÖ•Êé¢Á©∂LLMÊ†∏ÂøÉ‰ª£Á†ÅÁöÑÊú∫‰ºö„ÄÇ ÁÑ∂ËÄåÔºå‚ÄúÁî®‰πêÈ´òÊãºÂá∫‰∏ÄÊû∂È£ûÊú∫ÔºåËøúÊØîÂùêÂú®Â§¥Á≠âËà±ÈáåÈ£ûË°åÊõ¥ËÆ©‰∫∫ÂÖ¥Â•ãÔºÅ‚Äù„ÄÇ Êõ¥Á≥üÁ≥ïÁöÑÊòØÔºå‰∫íËÅîÁΩë‰∏äÂÖÖÊñ•ÁùÄÂ§ßÈáè‰ªòË¥πËØæÁ®ãÂíåËê•ÈîÄÂè∑Ôºå‰ª•ÊºèÊ¥ûÁôæÂá∫„ÄÅ‰∏ÄÁü•ÂçäËß£ÁöÑÂÜÖÂÆπÊé®ÈîÄAIÊïôÁ®ã„ÄÇ Ê≠£Âõ†Â¶ÇÊ≠§ÔºåÊú¨È°πÁõÆÂàùË°∑ÊòØÊãâ‰ΩéLLMÁöÑÂ≠¶‰π†Èó®ÊßõÔºåËÆ©ÊØè‰∏™‰∫∫ÈÉΩËÉΩ‰ªéÁêÜËß£ÊØè‰∏ÄË°å‰ª£Á†ÅÂºÄÂßãÔºå ‰ªéÈõ∂ÂºÄÂßã‰∫≤ÊâãËÆ≠ÁªÉ‰∏Ä‰∏™ÊûÅÂ∞èÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇÊòØÁöÑÔºå‰ªé&lt;strong&gt;Èõ∂ÂºÄÂßãËÆ≠ÁªÉ&lt;/strong&gt;ÔºåËÄå‰∏çÊòØ‰ªÖ‰ªÖËøõË°å&lt;strong&gt;Êé®ÁêÜ&lt;/strong&gt;ÔºÅ ÊúÄ‰ΩéÂè™ÈúÄ3ÂùóÈí±‰∏çÂà∞ÁöÑÊúçÂä°Âô®ÊàêÊú¨ÔºåÂ∞±ËÉΩ‰∫≤Ë∫´‰ΩìÈ™å‰ªé0Âà∞1ÊûÑÂª∫‰∏Ä‰∏™ËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖ®ËøáÁ®ã„ÄÇ ‰∏ÄËµ∑ÊÑüÂèóÂàõÈÄ†ÁöÑ‰πêË∂£ÂêßÔºÅ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] ÔºàÊà™Ëá≥2025-02-07ÔºâMiniMindÁ≥ªÂàóÂ∑≤ÂÆåÊàêÂ§ö‰∏™ÂûãÂè∑Ê®°ÂûãÁöÑÈ¢ÑËÆ≠ÁªÉÔºåÊúÄÂ∞è‰ªÖÈúÄ25.8MÔºà0.02BÔºâÔºåÂç≥ÂèØÂÖ∑Â§áÊµÅÁïÖÂØπËØùËÉΩÂäõÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Models List&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Ê®°Âûã (Â§ßÂ∞è)&lt;/th&gt; 
    &lt;th&gt;Êé®ÁêÜÂç†Áî® (Á∫¶)&lt;/th&gt; 
    &lt;th&gt;Release&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE (145M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2 (104M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2025.04.26&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-small (26M)&lt;/td&gt; 
    &lt;td&gt;0.5 GB&lt;/td&gt; 
    &lt;td&gt;2024.08.28&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-moe (4√ó26M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.17&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1 (108M)&lt;/td&gt; 
    &lt;td&gt;1.0 GB&lt;/td&gt; 
    &lt;td&gt;2024.09.01&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;strong&gt;È°πÁõÆÂåÖÂê´&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;MiniMind-LLMÁªìÊûÑÁöÑÂÖ®ÈÉ®‰ª£Á†ÅÔºàDense+MoEÊ®°ÂûãÔºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂåÖÂê´TokenizerÂàÜËØçÂô®ËØ¶ÁªÜËÆ≠ÁªÉ‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂåÖÂê´Pretrain„ÄÅSFT„ÄÅLoRA„ÄÅRLHF-DPO„ÄÅÊ®°ÂûãËí∏È¶èÁöÑÂÖ®ËøáÁ®ãËÆ≠ÁªÉ‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Êî∂ÈõÜ„ÄÅËí∏È¶è„ÄÅÊï¥ÁêÜÂπ∂Ê∏ÖÊ¥óÂéªÈáçÊâÄÊúâÈò∂ÊÆµÁöÑÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜÔºå‰∏îÂÖ®ÈÉ®ÂºÄÊ∫ê„ÄÇ&lt;/li&gt; 
 &lt;li&gt;‰ªé0ÂÆûÁé∞È¢ÑËÆ≠ÁªÉ„ÄÅÊåá‰ª§ÂæÆË∞É„ÄÅLoRA„ÄÅDPOÂº∫ÂåñÂ≠¶‰π†ÔºåÁôΩÁõíÊ®°ÂûãËí∏È¶è„ÄÇÂÖ≥ÈîÆÁÆóÊ≥ïÂá†‰πé‰∏ç‰æùËµñÁ¨¨‰∏âÊñπÂ∞ÅË£ÖÁöÑÊ°ÜÊû∂Ôºå‰∏îÂÖ®ÈÉ®ÂºÄÊ∫ê„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂêåÊó∂ÂÖºÂÆπ&lt;code&gt;transformers&lt;/code&gt;„ÄÅ&lt;code&gt;trl&lt;/code&gt;„ÄÅ&lt;code&gt;peft&lt;/code&gt;Á≠âÁ¨¨‰∏âÊñπ‰∏ªÊµÅÊ°ÜÊû∂„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ËÆ≠ÁªÉÊîØÊåÅÂçïÊú∫ÂçïÂç°„ÄÅÂçïÊú∫Â§öÂç°(DDP„ÄÅDeepSpeed)ËÆ≠ÁªÉÔºåÊîØÊåÅwandbÂèØËßÜÂåñËÆ≠ÁªÉÊµÅÁ®ã„ÄÇÊîØÊåÅÂä®ÊÄÅÂêØÂÅúËÆ≠ÁªÉ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Âú®Á¨¨‰∏âÊñπÊµãËØÑÊ¶úÔºàC-Eval„ÄÅC-MMLU„ÄÅOpenBookQAÁ≠âÔºâËøõË°åÊ®°ÂûãÊµãËØï„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂÆûÁé∞Openai-ApiÂçèËÆÆÁöÑÊûÅÁÆÄÊúçÂä°Á´ØÔºå‰æø‰∫éÈõÜÊàêÂà∞Á¨¨‰∏âÊñπChatUI‰ΩøÁî®ÔºàFastGPT„ÄÅOpen-WebUIÁ≠âÔºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Âü∫‰∫éstreamlitÂÆûÁé∞ÊúÄÁÆÄËÅäÂ§©WebUIÂâçÁ´Ø„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂÖ®Èù¢ÂÖºÂÆπÁ§æÂå∫ÁÉ≠Èó®&lt;code&gt;llama.cpp&lt;/code&gt;„ÄÅ&lt;code&gt;vllm&lt;/code&gt;„ÄÅ&lt;code&gt;ollama&lt;/code&gt;Êé®ÁêÜÂºïÊìéÊàñ&lt;code&gt;Llama-Factory&lt;/code&gt;ËÆ≠ÁªÉÊ°ÜÊû∂„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Â§çÁé∞(Ëí∏È¶è/RL)Â§ßÂûãÊé®ÁêÜÊ®°ÂûãDeepSeek-R1ÁöÑMiniMind-ReasonÊ®°ÂûãÔºå&lt;strong&gt;Êï∞ÊçÆ+Ê®°Âûã&lt;/strong&gt;ÂÖ®ÈÉ®ÂºÄÊ∫êÔºÅ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Â∏åÊúõÊ≠§ÂºÄÊ∫êÈ°πÁõÆÂèØ‰ª•Â∏ÆÂä©LLMÂàùÂ≠¶ËÄÖÂø´ÈÄüÂÖ•Èó®ÔºÅ&lt;/p&gt; 
&lt;h3&gt;üëâ&lt;strong&gt;Êõ¥Êñ∞Êó•Âøó&lt;/strong&gt;&lt;/h3&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-04-26 (newest üéâüéâüéâ)&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÈáçË¶ÅÊõ¥Êñ∞&lt;/li&gt; 
  &lt;li&gt;Â¶ÇÊúâÂÖºÂÆπÊÄßÈúÄË¶ÅÔºåÂèØËÆøÈóÆ&lt;a href="https://github.com/jingyaogong/minimind/tree/7da201a944a90ed49daef8a0265c959288dff83a"&gt;üîóÊóß‰ªìÂ∫ìÂÜÖÂÆπüîó&lt;/a&gt;„ÄÇ&lt;/li&gt; 
  &lt;li&gt;MiniMindÊ®°ÂûãÂèÇÊï∞ÂÆåÂÖ®ÊîπÂêçÔºåÂØπÈΩêTransformersÂ∫ìÊ®°ÂûãÔºàÁªü‰∏ÄÂëΩÂêçÔºâ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;generateÊñπÂºèÈáçÊûÑÔºåÁªßÊâøËá™GenerationMixinÁ±ª„ÄÇ&lt;/li&gt; 
  &lt;li&gt;üî•ÊîØÊåÅllama.cpp„ÄÅvllm„ÄÅollamaÁ≠âÁÉ≠Èó®‰∏âÊñπÁîüÊÄÅ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ËßÑËåÉ‰ª£Á†ÅÂíåÁõÆÂΩïÁªìÊûÑ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ÊîπÂä®ËØçË°®&lt;code&gt;&amp;lt;s&amp;gt;&amp;lt;/s&amp;gt;&lt;/code&gt;-&amp;gt;&lt;code&gt;&amp;lt;|im_start|&amp;gt;&amp;lt;|im_end|&amp;gt;&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;‰∏∫ÂÖºÂÆπÁ¨¨‰∏âÊñπÊé®ÁêÜÊ°ÜÊû∂llama.cpp„ÄÅvllmÔºåÊú¨Ê¨°Êõ¥Êñ∞ÈúÄ‰ªòÂá∫‰∏Ä‰∫õÂèØËßÇ‰ª£‰ª∑„ÄÇ
Êú¨Ê¨°Êõ¥Êñ∞‰∏çÂÜçÊîØÊåÅ„ÄåÁõ¥Êé•„ÄçÂä†ËΩΩ25-04-26‰ª•ÂâçÁöÑÊóßÊ®°ÂûãËøõË°åÊé®ÁêÜ„ÄÇ
Áî±‰∫éLlama‰ΩçÁΩÆÁºñÁ†ÅÊñπÂºè‰∏éminimindÂ≠òÂú®Âå∫Âà´ÔºåÂØºËá¥Êò†Â∞ÑLlamaÊ®°ÂûãÂêéQKÂÄºÂ≠òÂú®Â∑ÆÂºÇ
MiniMind2Á≥ªÂàóÊóßÊ®°ÂûãÂùáÁªèËøáÊùÉÈáçÊò†Â∞Ñ+ÔºàÂæÆË∞ÉËÆ≠ÁªÉÔºâQKVOÁ∫øÊÄßÂ±ÇÊ†°ÂáÜÊÅ¢Â§çËÄåÊù•„ÄÇ
Êú¨Ê¨°Êõ¥Êñ∞ÂêéÂ∞ÜÊîæÂºÉÂØπ`minimind-v1`ÂÖ®Á≥ªÂàóÁöÑÁª¥Êä§ÔºåÂπ∂Âú®‰ªìÂ∫ì‰∏≠‰∏ãÁ∫ø„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2025-02-09&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ËøéÊù•ÂèëÂ∏É‰ª•Êù•ÈáçÂ§ßÊõ¥Êñ∞ÔºåRelease MiniMind2 Series„ÄÇ&lt;/li&gt; 
  &lt;li&gt;‰ª£Á†ÅÂá†‰πéÂÖ®ÈÉ®ÈáçÊûÑÔºå‰ΩøÁî®Êõ¥ÁÆÄÊ¥ÅÊòé‰∫ÜÁöÑÁªü‰∏ÄÁªìÊûÑ„ÄÇ Â¶ÇÊúâÊóß‰ª£Á†ÅÁöÑÂÖºÂÆπÊÄßÈúÄË¶ÅÔºåÂèØËÆøÈóÆ&lt;a href="https://github.com/jingyaogong/minimind/tree/6e9cd28ef9b34a0a10afbdf6f59e65cb6e628efb"&gt;üîóÊóß‰ªìÂ∫ìÂÜÖÂÆπüîó&lt;/a&gt;„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ÂÖçÂéªÊï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÊ≠•È™§„ÄÇÁªü‰∏ÄÊï∞ÊçÆÈõÜÊ†ºÂºèÔºåÊõ¥Êç¢‰∏∫&lt;code&gt;jsonl&lt;/code&gt;Ê†ºÂºèÊùúÁªùÊï∞ÊçÆÈõÜ‰∏ãËΩΩÊ∑∑‰π±ÁöÑÈóÆÈ¢ò„ÄÇ&lt;/li&gt; 
  &lt;li&gt;MiniMind2Á≥ªÂàóÊïàÊûúÁõ∏ÊØîMiniMind-V1ÊòæËëóÊèêÂçá„ÄÇ&lt;/li&gt; 
  &lt;li&gt;Â∞èÈóÆÈ¢òÔºö{kv-cacheÂÜôÊ≥ïÊõ¥Ê†áÂáÜ„ÄÅMoEÁöÑË¥üËΩΩÂùáË°°lossË¢´ËÄÉËôëÁ≠âÁ≠â}&lt;/li&gt; 
  &lt;li&gt;Êèê‰æõÊ®°ÂûãËøÅÁßªÂà∞ÁßÅÊúâÊï∞ÊçÆÈõÜÁöÑËÆ≠ÁªÉÊñπÊ°àÔºàÂåªÁñóÊ®°Âûã„ÄÅËá™ÊàëËÆ§Áü•Ê†∑‰æãÔºâ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;Á≤æÁÆÄÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºåÂπ∂Â§ßÂπÖÊèêÂçáÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆË¥®ÈáèÔºåÂ§ßÂπÖÁº©Áü≠‰∏™‰∫∫Âø´ÈÄüËÆ≠ÁªÉÊâÄÈúÄÊó∂Èó¥ÔºåÂçïÂç°3090Âç≥ÂèØ2Â∞èÊó∂Â§çÁé∞ÔºÅ&lt;/li&gt; 
  &lt;li&gt;Êõ¥Êñ∞ÔºöLoRAÂæÆË∞ÉËÑ±Á¶ªpeftÂåÖË£ÖÔºå‰ªé0ÂÆûÁé∞LoRAËøáÁ®ãÔºõDPOÁÆóÊ≥ï‰ªé0‰ΩøÁî®PyTorchÂéüÁîüÂÆûÁé∞ÔºõÊ®°ÂûãÁôΩÁõíËí∏È¶èÂéüÁîüÂÆûÁé∞„ÄÇ&lt;/li&gt; 
  &lt;li&gt;MiniMind2-DeepSeek-R1Á≥ªÂàóËí∏È¶èÊ®°ÂûãËØûÁîüÔºÅ&lt;/li&gt; 
  &lt;li&gt;MiniMind2ÂÖ∑Â§á‰∏ÄÂÆöÁöÑËã±ÊñáËÉΩÂäõÔºÅ&lt;/li&gt; 
  &lt;li&gt;Êõ¥Êñ∞MiniMind2‰∏éÁ¨¨‰∏âÊñπÊ®°ÂûãÁöÑÂü∫‰∫éÊõ¥Â§öÂ§ßÊ®°ÂûãÊ¶úÂçïÊµãËØïÊÄßËÉΩÁöÑÁªìÊûú„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-10-05&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;‰∏∫MiniMindÊãìÂ±ï‰∫ÜÂ§öÊ®°ÊÄÅËÉΩÂäõ‰πã---ËßÜËßâ&lt;/li&gt; 
  &lt;li&gt;ÁßªÊ≠•Â≠™ÁîüÈ°πÁõÆ&lt;a href="https://github.com/jingyaogong/minimind-v"&gt;minimind-v&lt;/a&gt;Êü•ÁúãËØ¶ÊÉÖÔºÅ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-27&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;09-27Êõ¥Êñ∞pretrainÊï∞ÊçÆÈõÜÁöÑÈ¢ÑÂ§ÑÁêÜÊñπÂºèÔºå‰∏∫‰∫Ü‰øùËØÅÊñáÊú¨ÂÆåÊï¥ÊÄßÔºåÊîæÂºÉÈ¢ÑÂ§ÑÁêÜÊàê.binËÆ≠ÁªÉÁöÑÂΩ¢ÂºèÔºàËΩªÂæÆÁâ∫Áâ≤ËÆ≠ÁªÉÈÄüÂ∫¶Ôºâ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;ÁõÆÂâçpretrainÈ¢ÑÂ§ÑÁêÜÂêéÁöÑÊñá‰ª∂ÂëΩÂêç‰∏∫Ôºöpretrain_data.csv„ÄÇ&lt;/li&gt; 
  &lt;li&gt;Âà†Èô§‰∫Ü‰∏Ä‰∫õÂÜó‰ΩôÁöÑ‰ª£Á†Å„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-17&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êõ¥Êñ∞minimind-v1-moeÊ®°Âûã&lt;/li&gt; 
  &lt;li&gt;‰∏∫‰∫ÜÈò≤Ê≠¢Ê≠ß‰πâÔºå‰∏çÂÜç‰ΩøÁî®mistral_tokenizerÂàÜËØçÔºåÂÖ®ÈÉ®ÈááÁî®Ëá™ÂÆö‰πâÁöÑminimind_tokenizer‰Ωú‰∏∫ÂàÜËØçÂô®„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-09-01&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Êõ¥Êñ∞minimind-v1 (108M)Ê®°ÂûãÔºåÈááÁî®minimind_tokenizerÔºåÈ¢ÑËÆ≠ÁªÉËΩÆÊ¨°3 + SFTËΩÆÊ¨°10ÔºåÊõ¥ÂÖÖÂàÜËÆ≠ÁªÉÔºåÊÄßËÉΩÊõ¥Âº∫„ÄÇ&lt;/li&gt; 
  &lt;li&gt;È°πÁõÆÂ∑≤ÈÉ®ÁΩ≤Ëá≥ModelScopeÂàõÁ©∫Èó¥ÔºåÂèØ‰ª•Âú®Ê≠§ÁΩëÁ´ô‰∏ä‰ΩìÈ™åÔºö&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://www.modelscope.cn/studios/gongjy/minimind"&gt;üîóModelScopeÂú®Á∫ø‰ΩìÈ™åüîó&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;2024-08-27&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;È°πÁõÆÈ¶ñÊ¨°ÂºÄÊ∫ê&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;üìå Âø´ÈÄüÂºÄÂßã&lt;/h1&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ÂàÜ‰∫´Êú¨‰∫∫ÁöÑËΩØÁ°¨‰ª∂ÈÖçÁΩÆÔºà‰ªÖ‰æõÂèÇËÄÉÔºâ&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;CPU: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz&lt;/li&gt; 
  &lt;li&gt;RAM: 128 GB&lt;/li&gt; 
  &lt;li&gt;GPU: NVIDIA GeForce RTX 3090(24GB) * 8&lt;/li&gt; 
  &lt;li&gt;Ubuntu==20.04&lt;/li&gt; 
  &lt;li&gt;CUDA==12.2&lt;/li&gt; 
  &lt;li&gt;Python==3.10.16&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/requirements.txt"&gt;requirements.txt&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;Á¨¨0Ê≠•&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/jingyaogong/minimind.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö† ÊµãËØïÂ∑≤ÊúâÊ®°ÂûãÊïàÊûú&lt;/h2&gt; 
&lt;h3&gt;1.ÁéØÂ¢ÉÂáÜÂ§á&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2.‰∏ãËΩΩÊ®°Âûã&lt;/h3&gt; 
&lt;p&gt;Âà∞È°πÁõÆÊ†πÁõÆÂΩï&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://huggingface.co/jingyaogong/MiniMind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÔºàÂèØÈÄâÔºâÂëΩ‰ª§Ë°åÈóÆÁ≠î&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# load=0: load from pytorch model, load=1: load from transformers-hf model
python eval_model.py --load 1 --model_mode 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÔºàÂèØÈÄâÔºâÂêØÂä®WebUI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ÂèØËÉΩÈúÄË¶Å`python&amp;gt;=3.10` ÂÆâË£Ö `pip install streamlit`
# cd scripts
streamlit run web_demo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ÔºàÂèØÈÄâÔºâÁ¨¨‰∏âÊñπÊé®ÁêÜÊ°ÜÊû∂&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# ollama
ollama run jingyaogong/minimind2
# vllm
vllm serve ./MiniMind2/ --served-model-name "minimind"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö° ‰ªé0ÂºÄÂßãËá™Â∑±ËÆ≠ÁªÉ&lt;/h2&gt; 
&lt;h3&gt;1.ÁéØÂ¢ÉÂáÜÂ§á&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÊèêÂâçÊµãËØïTorchÊòØÂê¶ÂèØÁî®cuda&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;import torch
print(torch.cuda.is_available())
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Â¶ÇÊûú‰∏çÂèØÁî®ÔºåËØ∑Ëá™Ë°åÂéª&lt;a href="https://download.pytorch.org/whl/torch_stable.html"&gt;torch_stable&lt;/a&gt; ‰∏ãËΩΩwhlÊñá‰ª∂ÂÆâË£Ö„ÄÇÂèÇËÄÉ&lt;a href="https://blog.csdn.net/weixin_45456738/article/details/141029610?ops_request_misc=&amp;amp;request_id=&amp;amp;biz_id=102&amp;amp;utm_term=%E5%AE%89%E8%A3%85torch&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-141029610.nonecase&amp;amp;spm=1018.2226.3001.4187"&gt;ÈìæÊé•&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;2.Êï∞ÊçÆ‰∏ãËΩΩ&lt;/h3&gt; 
&lt;p&gt;‰ªé‰∏ãÊñáÊèê‰æõÁöÑ&lt;a href="https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files"&gt;Êï∞ÊçÆÈõÜ‰∏ãËΩΩÈìæÊé•&lt;/a&gt; ‰∏ãËΩΩÈúÄË¶ÅÁöÑÊï∞ÊçÆÊñá‰ª∂ÔºàÂàõÂª∫&lt;code&gt;./dataset&lt;/code&gt;ÁõÆÂΩïÔºâÂπ∂ÊîæÂà∞&lt;code&gt;./dataset&lt;/code&gt;‰∏ã&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÊï∞ÊçÆÈõÜÈ°ªÁü•&lt;/summary&gt; 
 &lt;p&gt;ÈªòËÆ§Êé®Ëçê‰∏ãËΩΩ&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;ÊúÄÂø´ÈÄüÂ∫¶Â§çÁé∞ZeroËÅäÂ§©Ê®°Âûã„ÄÇ&lt;/p&gt; 
 &lt;p&gt;Êï∞ÊçÆÊñá‰ª∂ÂèØËá™Áî±ÈÄâÊã©Ôºå‰∏ãÊñáÊèê‰æõ‰∫ÜÂ§öÁßçÊê≠ÈÖçÊñπÊ°àÔºåÂèØÊ†πÊçÆËá™Â∑±ÊâãÂ§¥ÁöÑËÆ≠ÁªÉÈúÄÊ±ÇÂíåGPUËµÑÊ∫êËøõË°åÈÄÇÂΩìÁªÑÂêà„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;h3&gt;3.ÂºÄÂßãËÆ≠ÁªÉ&lt;/h3&gt; 
&lt;p&gt;ÁõÆÂΩï‰Ωç‰∫é&lt;code&gt;trainer&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;3.1 È¢ÑËÆ≠ÁªÉÔºàÂ≠¶Áü•ËØÜÔºâ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâßË°åÈ¢ÑËÆ≠ÁªÉÔºåÂæóÂà∞ &lt;code&gt;pretrain_*.pth&lt;/code&gt; ‰Ωú‰∏∫È¢ÑËÆ≠ÁªÉÁöÑËæìÂá∫ÊùÉÈáçÔºàÂÖ∂‰∏≠*‰∏∫Ê®°ÂûãÁöÑdimensionÔºåÈªòËÆ§‰∏∫512Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;3.2 ÁõëÁù£ÂæÆË∞ÉÔºàÂ≠¶ÂØπËØùÊñπÂºèÔºâ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâßË°åÁõëÁù£ÂæÆË∞ÉÔºåÂæóÂà∞ &lt;code&gt;full_sft_*.pth&lt;/code&gt; ‰Ωú‰∏∫Êåá‰ª§ÂæÆË∞ÉÁöÑËæìÂá∫ÊùÉÈáçÔºàÂÖ∂‰∏≠&lt;code&gt;full&lt;/code&gt;Âç≥‰∏∫ÂÖ®ÂèÇÊï∞ÂæÆË∞ÉÔºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöËÆ≠ÁªÉÈ°ªÁü•&lt;/summary&gt; 
 &lt;p&gt;ÊâÄÊúâËÆ≠ÁªÉËøáÁ®ãÈªòËÆ§ÊØèÈöî100Ê≠•‰øùÂ≠ò1Ê¨°ÂèÇÊï∞Âà∞Êñá‰ª∂&lt;code&gt;./out/***.pth&lt;/code&gt;ÔºàÊØèÊ¨°‰ºöË¶ÜÁõñÊéâÊóßÊùÉÈáçÊñá‰ª∂Ôºâ„ÄÇ&lt;/p&gt; 
 &lt;p&gt;ÁÆÄÂçïËµ∑ËßÅÔºåÊ≠§Â§ÑÂè™ÂÜôÊòé‰∏§‰∏™Èò∂ÊÆµËÆ≠ÁªÉËøáÁ®ã„ÄÇÂ¶ÇÈúÄÂÖ∂ÂÆÉËÆ≠ÁªÉ (LoRA, Ëí∏È¶è, Âº∫ÂåñÂ≠¶‰π†, ÂæÆË∞ÉÊé®ÁêÜÁ≠â) ÂèØÂèÇËÄÉ‰∏ãÊñá„ÄêÂÆûÈ™å„ÄëÂ∞èËäÇÁöÑËØ¶ÁªÜËØ¥Êòé„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h3&gt;4.ÊµãËØïÊ®°ÂûãÊïàÊûú&lt;/h3&gt; 
&lt;p&gt;Á°Æ‰øùÈúÄË¶ÅÊµãËØïÁöÑÊ®°Âûã&lt;code&gt;*.pth&lt;/code&gt;Êñá‰ª∂‰Ωç‰∫é&lt;code&gt;./out/&lt;/code&gt;ÁõÆÂΩï‰∏ã„ÄÇ ‰πüÂèØ‰ª•Áõ¥Êé•Âéª&lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch/files"&gt;Ê≠§Â§Ñ&lt;/a&gt;‰∏ãËΩΩ‰ΩøÁî®ÊàëËÆ≠ÁªÉÁöÑ&lt;code&gt;*.pth&lt;/code&gt;Êñá‰ª∂„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python eval_model.py --model_mode 1 # ÈªòËÆ§‰∏∫0ÔºöÊµãËØïpretrainÊ®°ÂûãÊïàÊûúÔºåËÆæÁΩÆ‰∏∫1ÔºöÊµãËØïfull_sftÊ®°ÂûãÊïàÊûú
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÊµãËØïÈ°ªÁü•&lt;/summary&gt; 
 &lt;p&gt;Â¶ÇÈúÄËØ¶ÊÉÖÔºåÊü•Áúã&lt;code&gt;eval_model.py&lt;/code&gt;ËÑöÊú¨‰ª£Á†ÅÂç≥ÂèØ„ÄÇmodel_modeÂàÜ‰∏∫ 0: È¢ÑËÆ≠ÁªÉÊ®°ÂûãÔºå1: SFT-ChatÊ®°ÂûãÔºå2: RLHF-ChatÊ®°ÂûãÔºå3: ReasonÊ®°Âûã&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨Âùá‰∏∫PytorchÂéüÁîüÊ°ÜÊû∂ÔºåÂùáÊîØÊåÅÂ§öÂç°Âä†ÈÄüÔºåÂÅáËÆæ‰Ω†ÁöÑËÆæÂ§áÊúâN (NÔºû1) Âº†ÊòæÂç°Ôºö&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ÂçïÊú∫NÂç°ÂêØÂä®ËÆ≠ÁªÉÊñπÂºè (DDP, ÊîØÊåÅÂ§öÊú∫Â§öÂç°ÈõÜÁæ§)&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÂÖ∂ÂÆÉÈ°ªÁü•&lt;/summary&gt; 
 &lt;p&gt;ÂçïÊú∫NÂç°ÂêØÂä®ËÆ≠ÁªÉ (DeepSpeed)&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;deepspeed --master_port 29500 --num_gpus=N train_xxx.py
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;ÂèØÊ†πÊçÆÈúÄË¶ÅÂºÄÂêØwandbËÆ∞ÂΩïËÆ≠ÁªÉËøáÁ®ã&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# ÈúÄË¶ÅÁôªÂΩï: wandb login
torchrun --nproc_per_node N train_xxx.py --use_wandb
# and
python train_xxx.py --use_wandb
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;ÈÄöËøáÊ∑ªÂä†&lt;code&gt;--use_wandb&lt;/code&gt;ÂèÇÊï∞ÔºåÂèØ‰ª•ËÆ∞ÂΩïËÆ≠ÁªÉËøáÁ®ãÔºåËÆ≠ÁªÉÂÆåÊàêÂêéÔºåÂèØ‰ª•Âú®wandbÁΩëÁ´ô‰∏äÊü•ÁúãËÆ≠ÁªÉËøáÁ®ã„ÄÇÈÄöËøá‰øÆÊîπ&lt;code&gt;wandb_project&lt;/code&gt; Âíå&lt;code&gt;wandb_run_name&lt;/code&gt;ÂèÇÊï∞ÔºåÂèØ‰ª•ÊåáÂÆöÈ°πÁõÆÂêçÁß∞ÂíåËøêË°åÂêçÁß∞„ÄÇ&lt;/p&gt; 
&lt;/details&gt; 
&lt;h1&gt;üìå Êï∞ÊçÆ‰ªãÁªç&lt;/h1&gt; 
&lt;h2&gt;‚Ö† Tokenizer&lt;/h2&gt; 
&lt;p&gt;ÂàÜËØçÂô®Â∞ÜÂçïËØç‰ªéËá™ÁÑ∂ËØ≠Ë®ÄÈÄöËøá‚ÄúËØçÂÖ∏‚ÄùÊò†Â∞ÑÂà∞&lt;code&gt;0, 1, 36&lt;/code&gt;ËøôÊ†∑ÁöÑÊï∞Â≠óÔºåÂèØ‰ª•ÁêÜËß£‰∏∫Êï∞Â≠óÂ∞±‰ª£Ë°®‰∫ÜÂçïËØçÂú®‚ÄúËØçÂÖ∏‚Äù‰∏≠ÁöÑÈ°µÁ†Å„ÄÇ ÂèØ‰ª•ÈÄâÊã©Ëá™Â∑±ÊûÑÈÄ†ËØçË°®ËÆ≠ÁªÉ‰∏Ä‰∏™‚ÄúËØçÂÖ∏‚ÄùÔºå‰ª£Á†ÅÂèØËßÅ&lt;code&gt;./scripts/train_tokenizer.py&lt;/code&gt;Ôºà‰ªÖ‰æõÂ≠¶‰π†ÂèÇËÄÉÔºåËã•ÈùûÂøÖË¶ÅÊó†ÈúÄÂÜçËá™Ë°åËÆ≠ÁªÉÔºåMiniMindÂ∑≤Ëá™Â∏¶tokenizerÔºâ„ÄÇ ÊàñËÄÖÈÄâÊã©ÊØîËæÉÂá∫ÂêçÁöÑÂºÄÊ∫êÂ§ßÊ®°ÂûãÂàÜËØçÂô®Ôºå Ê≠£Â¶ÇÂêåÁõ¥Êé•Áî®Êñ∞Âçé/ÁâõÊ¥•ËØçÂÖ∏ÁöÑ‰ºòÁÇπÊòØtokenÁºñÁ†ÅÂéãÁº©ÁéáÂæàÂ•ΩÔºåÁº∫ÁÇπÊòØÈ°µÊï∞Â§™Â§öÔºåÂä®ËæÑÊï∞ÂçÅ‰∏á‰∏™ËØçÊ±áÁü≠ËØ≠Ôºõ Ëá™Â∑±ËÆ≠ÁªÉÁöÑÂàÜËØçÂô®Ôºå‰ºòÁÇπÊòØËØçË°®ÈïøÂ∫¶ÂíåÂÜÖÂÆπÈöèÊÑèÊéßÂà∂ÔºåÁº∫ÁÇπÊòØÂéãÁº©ÁéáÂæà‰ΩéÔºà‰æãÂ¶Ç"hello"‰πüËÆ∏‰ºöË¢´ÊãÜÂàÜ‰∏∫"h e l l o" ‰∫î‰∏™Áã¨Á´ãÁöÑtokenÔºâÔºå‰∏îÁîüÂÉªËØçÈöæ‰ª•Ë¶ÜÁõñ„ÄÇ ‚ÄúËØçÂÖ∏‚ÄùÁöÑÈÄâÊã©Âõ∫ÁÑ∂ÂæàÈáçË¶ÅÔºåLLMÁöÑËæìÂá∫Êú¨Ë¥®‰∏äÊòØSoftMaxÂà∞ËØçÂÖ∏N‰∏™ËØçÁöÑÂ§öÂàÜÁ±ªÈóÆÈ¢òÔºåÁÑ∂ÂêéÈÄöËøá‚ÄúËØçÂÖ∏‚ÄùËß£Á†ÅÂà∞Ëá™ÁÑ∂ËØ≠Ë®Ä„ÄÇ Âõ†‰∏∫MiniMind‰ΩìÁßØÈúÄË¶Å‰∏•Ê†ºÊéßÂà∂Ôºå‰∏∫‰∫ÜÈÅøÂÖçÊ®°ÂûãÂ§¥ÈáçËÑöËΩªÔºàËØçÂµåÂÖ•embeddingÂ±ÇÂèÇÊï∞Âú®LLMÂç†ÊØîÂ§™È´òÔºâÔºåÊâÄ‰ª•ËØçË°®ÈïøÂ∫¶Áü≠Áü≠ÁõäÂñÑ„ÄÇ&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Tokenizer‰ªãÁªç&lt;/summary&gt; 
 &lt;p&gt;Á¨¨‰∏âÊñπÂº∫Â§ßÁöÑÂºÄÊ∫êÊ®°Âûã‰æãÂ¶ÇYi„ÄÅqwen„ÄÅchatglm„ÄÅmistral„ÄÅLlama3ÁöÑtokenizerËØçË°®ÈïøÂ∫¶Â¶Ç‰∏ãÔºö&lt;/p&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt;
    &lt;th&gt;TokenizerÊ®°Âûã&lt;/th&gt;
    &lt;th&gt;ËØçË°®Â§ßÂ∞è&lt;/th&gt;
    &lt;th&gt;Êù•Ê∫ê&lt;/th&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;yi tokenizer&lt;/td&gt;
    &lt;td&gt;64,000&lt;/td&gt;
    &lt;td&gt;01‰∏áÁâ©Ôºà‰∏≠ÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;qwen2 tokenizer&lt;/td&gt;
    &lt;td&gt;151,643&lt;/td&gt;
    &lt;td&gt;ÈòøÈáå‰∫ëÔºà‰∏≠ÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;glm tokenizer&lt;/td&gt;
    &lt;td&gt;151,329&lt;/td&gt;
    &lt;td&gt;Êô∫Ë∞±AIÔºà‰∏≠ÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;mistral tokenizer&lt;/td&gt;
    &lt;td&gt;32,000&lt;/td&gt;
    &lt;td&gt;Mistral AIÔºàÊ≥ïÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;llama3 tokenizer&lt;/td&gt;
    &lt;td&gt;128,000&lt;/td&gt;
    &lt;td&gt;MetaÔºàÁæéÂõΩÔºâ&lt;/td&gt;
   &lt;/tr&gt; 
   &lt;tr&gt;
    &lt;td&gt;minimind tokenizer&lt;/td&gt;
    &lt;td&gt;6,400&lt;/td&gt;
    &lt;td&gt;Ëá™ÂÆö‰πâ&lt;/td&gt;
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;üëâ2024-09-17Êõ¥Êñ∞Ôºö‰∏∫‰∫ÜÈò≤Ê≠¢ËøáÂéªÁöÑÁâàÊú¨Ê≠ß‰πâ&amp;amp;ÊéßÂà∂‰ΩìÁßØÔºåminimindÊâÄÊúâÊ®°ÂûãÂùá‰ΩøÁî®minimind_tokenizerÂàÜËØçÔºåÂ∫üÂºÉÊâÄÊúâmistral_tokenizerÁâàÊú¨„ÄÇ&lt;/p&gt; 
 &lt;/blockquote&gt; 
 &lt;pre&gt;&lt;code&gt;# ‰∏Ä‰∫õËá™Ë®ÄËá™ËØ≠
&amp;gt; Â∞ΩÁÆ°minimind_tokenizerÈïøÂ∫¶ÂæàÂ∞èÔºåÁºñËß£Á†ÅÊïàÁéáÂº±‰∫éqwen2„ÄÅglmÁ≠â‰∏≠ÊñáÂèãÂ•ΩÂûãÂàÜËØçÂô®„ÄÇ
&amp;gt; ‰ΩÜminimindÊ®°ÂûãÈÄâÊã©‰∫ÜËá™Â∑±ËÆ≠ÁªÉÁöÑminimind_tokenizer‰Ωú‰∏∫ÂàÜËØçÂô®Ôºå‰ª•‰øùÊåÅÊï¥‰ΩìÂèÇÊï∞ËΩªÈáèÔºåÈÅøÂÖçÁºñÁ†ÅÂ±ÇÂíåËÆ°ÁÆóÂ±ÇÂç†ÊØîÂ§±Ë°°ÔºåÂ§¥ÈáçËÑöËΩªÔºåÂõ†‰∏∫minimindÁöÑËØçË°®Â§ßÂ∞èÂè™Êúâ6400„ÄÇ
&amp;gt; ‰∏îminimindÂú®ÂÆûÈôÖÊµãËØï‰∏≠Ê≤°ÊúâÂá∫Áé∞ËøáÁîüÂÉªËØçÊ±áËß£Á†ÅÂ§±Ë¥•ÁöÑÊÉÖÂÜµÔºåÊïàÊûúËâØÂ•Ω„ÄÇ
&amp;gt; Áî±‰∫éËá™ÂÆö‰πâËØçË°®ÂéãÁº©ÈïøÂ∫¶Âà∞6400Ôºå‰ΩøÂæóLLMÊÄªÂèÇÊï∞ÈáèÊúÄ‰ΩéÂè™Êúâ25.8M„ÄÇ
&amp;gt; ËÆ≠ÁªÉÊï∞ÊçÆ`tokenizer_train.jsonl`ÂùáÊù•Ëá™‰∫é`Âå†Êï∞Â§ßÊ®°ÂûãÊï∞ÊçÆÈõÜ`ÔºåËøôÈÉ®ÂàÜÊï∞ÊçÆÁõ∏ÂØπÊ¨°Ë¶ÅÔºåÂ¶ÇÈúÄËÆ≠ÁªÉÂèØ‰ª•Ëá™Áî±ÈÄâÊã©„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚Ö° PretrainÊï∞ÊçÆ&lt;/h2&gt; 
&lt;p&gt;ÁªèÂéÜ‰∫ÜMiniMind-V1ÁöÑ‰ΩéË¥®ÈáèÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÂØºËá¥Ê®°ÂûãËÉ°Ë®Ä‰π±ËØ≠ÁöÑÊïôËÆ≠Ôºå&lt;code&gt;2025-02-05&lt;/code&gt; ‰πãÂêéÂÜ≥ÂÆö‰∏çÂÜçÈááÁî®Â§ßËßÑÊ®°Êó†ÁõëÁù£ÁöÑÊï∞ÊçÆÈõÜÂÅöÈ¢ÑËÆ≠ÁªÉ„ÄÇ ËøõËÄåÂ∞ùËØïÊää&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;Âå†Êï∞Â§ßÊ®°ÂûãÊï∞ÊçÆÈõÜ&lt;/a&gt;ÁöÑ‰∏≠ÊñáÈÉ®ÂàÜÊèêÂèñÂá∫Êù•Ôºå Ê∏ÖÊ¥óÂá∫Â≠óÁ¨¶&lt;code&gt;&amp;lt;512&lt;/code&gt;ÈïøÂ∫¶ÁöÑÂ§ßÁ∫¶1.6GBÁöÑËØ≠ÊñôÁõ¥Êé•ÊãºÊé•ÊàêÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆ &lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;ÔºåhqÂç≥‰∏∫high qualityÔºàÂΩìÁÑ∂‰πüËøò‰∏çÁÆóhighÔºåÊèêÂçáÊï∞ÊçÆË¥®ÈáèÊó†Ê≠¢Â∞ΩÔºâ„ÄÇ&lt;/p&gt; 
&lt;p&gt;Êñá‰ª∂&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; Êï∞ÊçÆÊ†ºÂºè‰∏∫&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;{"text": "Â¶Ç‰ΩïÊâçËÉΩÊëÜËÑ±ÊãñÂª∂ÁóáÔºü Ê≤ªÊÑàÊãñÂª∂ÁóáÂπ∂‰∏çÂÆπÊòìÔºå‰ΩÜ‰ª•‰∏ãÂª∫ËÆÆÂèØËÉΩÊúâÊâÄÂ∏ÆÂä©..."}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö¢ SFTÊï∞ÊçÆ&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data"&gt;Âå†Êï∞Â§ßÊ®°ÂûãSFTÊï∞ÊçÆÈõÜ&lt;/a&gt; ‚ÄúÊòØ‰∏Ä‰∏™ÂÆåÊï¥„ÄÅÊ†ºÂºèÁªü‰∏Ä„ÄÅÂÆâÂÖ®ÁöÑÂ§ßÊ®°ÂûãËÆ≠ÁªÉÂíåÁ†îÁ©∂ËµÑÊ∫ê„ÄÇ ‰ªéÁΩëÁªú‰∏äÁöÑÂÖ¨ÂºÄÊï∞ÊçÆÊ∫êÊî∂ÈõÜÂπ∂Êï¥ÁêÜ‰∫ÜÂ§ßÈáèÂºÄÊ∫êÊï∞ÊçÆÈõÜÔºåÂØπÂÖ∂ËøõË°å‰∫ÜÊ†ºÂºèÁªü‰∏ÄÔºåÊï∞ÊçÆÊ∏ÖÊ¥óÔºå ÂåÖÂê´10MÊù°Êï∞ÊçÆÁöÑ‰∏≠ÊñáÊï∞ÊçÆÈõÜÂíåÂåÖÂê´2MÊù°Êï∞ÊçÆÁöÑËã±ÊñáÊï∞ÊçÆÈõÜ„ÄÇ‚Äù ‰ª•‰∏äÊòØÂÆòÊñπ‰ªãÁªçÔºå‰∏ãËΩΩÊñá‰ª∂ÂêéÁöÑÊï∞ÊçÆÊÄªÈáèÂ§ßÁ∫¶Âú®4B tokensÔºåËÇØÂÆöÊòØÈÄÇÂêà‰Ωú‰∏∫‰∏≠ÊñáÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑSFTÊï∞ÊçÆÁöÑ„ÄÇ ‰ΩÜÊòØÂÆòÊñπÊèê‰æõÁöÑÊï∞ÊçÆÊ†ºÂºèÂæà‰π±ÔºåÂÖ®ÈÉ®Áî®Êù•sft‰ª£‰ª∑Â§™Â§ß„ÄÇ ÊàëÂ∞ÜÊääÂÆòÊñπÊï∞ÊçÆÈõÜËøõË°å‰∫Ü‰∫åÊ¨°Ê∏ÖÊ¥óÔºåÊääÂê´ÊúâÁ¨¶Âè∑Ê±°ÊüìÂíåÂô™Â£∞ÁöÑÊù°ÁõÆÂéªÈô§ÔºõÂè¶Â§ñ‰æùÁÑ∂Âè™‰øùÁïô‰∫ÜÊÄªÈïøÂ∫¶&lt;code&gt;&amp;lt;512&lt;/code&gt; ÁöÑÂÜÖÂÆπÔºåÊ≠§Èò∂ÊÆµÂ∏åÊúõÈÄöËøáÂ§ßÈáèÂØπËØùË°•ÂÖÖÈ¢ÑËÆ≠ÁªÉÈò∂ÊÆµÊ¨†Áº∫ÁöÑÁü•ËØÜ„ÄÇ ÂØºÂá∫Êñá‰ª∂‰∏∫&lt;code&gt;sft_512.jsonl&lt;/code&gt;(~7.5GB)„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.modelscope.cn/organization/Magpie-Align"&gt;Magpie-SFTÊï∞ÊçÆÈõÜ&lt;/a&gt; Êî∂ÈõÜ‰∫Ü~1MÊù°Êù•Ëá™Qwen2/2.5ÁöÑÈ´òË¥®ÈáèÂØπËØùÔºåÊàëÂ∞ÜËøôÈÉ®ÂàÜÊï∞ÊçÆËøõ‰∏ÄÊ≠•Ê∏ÖÊ¥óÔºåÊääÊÄªÈïøÂ∫¶&lt;code&gt;&amp;lt;2048&lt;/code&gt;ÁöÑÈÉ®ÂàÜÂØºÂá∫‰∏∫&lt;code&gt;sft_2048.jsonl&lt;/code&gt;(~9GB)„ÄÇ ÈïøÂ∫¶&lt;code&gt;&amp;lt;1024&lt;/code&gt;ÁöÑÈÉ®ÂàÜÂØºÂá∫‰∏∫&lt;code&gt;sft_1024.jsonl&lt;/code&gt;(~5.5GB)ÔºåÁî®Â§ßÊ®°ÂûãÂØπËØùÊï∞ÊçÆÁõ¥Êé•ËøõË°åsftÂ∞±Â±û‰∫é‚ÄúÈªëÁõíËí∏È¶è‚ÄùÁöÑËåÉÁï¥„ÄÇ&lt;/p&gt; 
&lt;p&gt;Ëøõ‰∏ÄÊ≠•Ê∏ÖÊ¥óÂâç‰∏§Ê≠•sftÁöÑÊï∞ÊçÆÔºàÂè™‰øùÁïô‰∏≠ÊñáÂ≠óÁ¨¶Âç†ÊØîÈ´òÁöÑÂÜÖÂÆπÔºâÔºåÁ≠õÈÄâÈïøÂ∫¶&lt;code&gt;&amp;lt;512&lt;/code&gt;ÁöÑÂØπËØùÔºåÂæóÂà∞&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;(~1.2GB)„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÊâÄÊúâsftÊñá‰ª∂ &lt;code&gt;sft_X.jsonl&lt;/code&gt; Êï∞ÊçÆÊ†ºÂºèÂùá‰∏∫&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{
    "conversations": [
        {"role": "user", "content": "‰Ω†Â•Ω"},
        {"role": "assistant", "content": "‰Ω†Â•ΩÔºÅ"},
        {"role": "user", "content": "ÂÜçËßÅ"},
        {"role": "assistant", "content": "ÂÜçËßÅÔºÅ"}
    ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö£ RLHFÊï∞ÊçÆ&lt;/h2&gt; 
&lt;p&gt;Êù•Ëá™&lt;a href="https://www.modelscope.cn/datasets/Magpie-Align/MagpieLM-DPO-Data-v0.1"&gt;Magpie-DPOÊï∞ÊçÆÈõÜ&lt;/a&gt; Â§ßÁ∫¶200kÊù°ÂÅèÂ•ΩÊï∞ÊçÆÔºàÂùáÊòØËã±ÊñáÔºâÁîüÊàêËá™Llama3.1-70B/8BÔºåÂèØ‰ª•Áî®‰∫éËÆ≠ÁªÉÂ•ñÂä±Ê®°ÂûãÔºå‰ºòÂåñÊ®°ÂûãÂõûÂ§çË¥®ÈáèÔºå‰ΩøÂÖ∂Êõ¥Âä†Á¨¶Âêà‰∫∫Á±ªÂÅèÂ•Ω„ÄÇ ËøôÈáåÂ∞ÜÊï∞ÊçÆÊÄªÈïøÂ∫¶&lt;code&gt;&amp;lt;3000&lt;/code&gt;ÁöÑÂÜÖÂÆπÈáçÁªÑ‰∏∫&lt;code&gt;dpo.jsonl&lt;/code&gt;(~0.9GB)ÔºåÂåÖÂê´&lt;code&gt;chosen&lt;/code&gt;Âíå&lt;code&gt;rejected&lt;/code&gt;‰∏§‰∏™Â≠óÊÆµÔºå&lt;code&gt;chosen&lt;/code&gt; ‰∏∫ÂÅèÂ•ΩÁöÑÂõûÂ§çÔºå&lt;code&gt;rejected&lt;/code&gt;‰∏∫ÊãíÁªùÁöÑÂõûÂ§ç„ÄÇ&lt;/p&gt; 
&lt;p&gt;Êñá‰ª∂ &lt;code&gt;dpo.jsonl&lt;/code&gt; Êï∞ÊçÆÊ†ºÂºè‰∏∫&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;{
  "chosen": [
    {"content": "Q", "role": "user"}, 
    {"content": "good answer", "role": "assistant"}
  ], 
  "rejected": [
    {"content": "Q", "role": "user"}, 
    {"content": "bad answer", "role": "assistant"}
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚Ö§ ReasonÊï∞ÊçÆÈõÜÔºö&lt;/h2&gt; 
&lt;p&gt;‰∏çÂæó‰∏çËØ¥2025Âπ¥2ÊúàË∞ÅËÉΩÁÅ´ÁöÑËøáDeepSeek... ‰πüÊøÄÂèë‰∫ÜÊàëÂØπRLÂºïÂØºÁöÑÊé®ÁêÜÊ®°ÂûãÁöÑÊµìÂéöÂÖ¥Ë∂£ÔºåÁõÆÂâçÂ∑≤ÁªèÁî®Qwen2.5Â§çÁé∞‰∫ÜR1-Zero„ÄÇ Â¶ÇÊûúÊúâÊó∂Èó¥+ÊïàÊûúworkÔºà‰ΩÜ99%Âü∫Ê®°ËÉΩÂäõ‰∏çË∂≥ÔºâÊàë‰ºöÂú®‰πãÂêéÊõ¥Êñ∞MiniMindÂü∫‰∫éRLËÆ≠ÁªÉÁöÑÊé®ÁêÜÊ®°ÂûãËÄå‰∏çÊòØËí∏È¶èÊ®°Âûã„ÄÇ Êó∂Èó¥ÊúâÈôêÔºåÊúÄÂø´ÁöÑ‰ΩéÊàêÊú¨ÊñπÊ°à‰æùÁÑ∂ÊòØÁõ¥Êé•Ëí∏È¶èÔºàÈªëÁõíÊñπÂºèÔºâ„ÄÇ ËÄê‰∏ç‰ΩèR1Â§™ÁÅ´ÔºåÁü≠Áü≠Âá†Â§©Â∞±Â∑≤ÁªèÂ≠òÂú®‰∏Ä‰∫õR1ÁöÑËí∏È¶èÊï∞ÊçÆÈõÜ&lt;a href="https://www.modelscope.cn/datasets/Magpie-Align/Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B"&gt;R1-Llama-70B&lt;/a&gt;„ÄÅ&lt;a href="https://www.modelscope.cn/datasets/AI-ModelScope/R1-Distill-SFT"&gt;R1-Distill-SFT&lt;/a&gt;„ÄÅ &lt;a href="https://huggingface.co/datasets/shareAI/Alpaca-Distill-R1-ZH"&gt;Alpaca-Distill-R1&lt;/a&gt;„ÄÅ &lt;a href="https://huggingface.co/datasets/jinliuxi/deepseek_r1_zh"&gt;deepseek_r1_zh&lt;/a&gt;Á≠âÁ≠âÔºåÁ∫Ø‰∏≠ÊñáÁöÑÊï∞ÊçÆÂèØËÉΩÊØîËæÉÂ∞ë„ÄÇ ÊúÄÁªàÊï¥ÂêàÂÆÉ‰ª¨ÔºåÂØºÂá∫Êñá‰ª∂‰∏∫&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;ÔºåÊï∞ÊçÆÊ†ºÂºèÂíå&lt;code&gt;sft_X.jsonl&lt;/code&gt;‰∏ÄËá¥„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‚Ö• Êõ¥Â§öÊï∞ÊçÆÈõÜ&lt;/h2&gt; 
&lt;p&gt;ÁõÆÂâçÂ∑≤ÁªèÊúâ&lt;a href="https://github.com/HqWu-HITCS/Awesome-Chinese-LLM"&gt;HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt; Âú®Êî∂ÈõÜÂíåÊ¢≥ÁêÜ‰∏≠ÊñáLLMÁõ∏ÂÖ≥ÁöÑÂºÄÊ∫êÊ®°Âûã„ÄÅÂ∫îÁî®„ÄÅÊï∞ÊçÆÈõÜÂèäÊïôÁ®ãÁ≠âËµÑÊñôÔºåÂπ∂ÊåÅÁª≠Êõ¥Êñ∞ËøôÊñπÈù¢ÁöÑÊúÄÊñ∞ËøõÂ±ï„ÄÇÂÖ®Èù¢‰∏î‰∏ì‰∏öÔºåRespectÔºÅ&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚Öß MiniMindËÆ≠ÁªÉÊï∞ÊçÆÈõÜ&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] 2025-02-05ÂêéÔºåÂºÄÊ∫êMiniMindÊúÄÁªàËÆ≠ÁªÉÊâÄÁî®ÁöÑÊâÄÊúâÊï∞ÊçÆÈõÜÔºåÂõ†Ê≠§Êó†ÈúÄÂÜçËá™Ë°åÈ¢ÑÂ§ÑÁêÜÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÈÅøÂÖçÈáçÂ§çÊÄßÁöÑÊï∞ÊçÆÂ§ÑÁêÜÂ∑•‰Ωú„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MiniMindËÆ≠ÁªÉÊï∞ÊçÆÈõÜ‰∏ãËΩΩÂú∞ÂùÄÔºö &lt;a href="https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/datasets/jingyaogong/minimind_dataset/tree/main"&gt;HuggingFace&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Êó†ÈúÄÂÖ®ÈÉ®cloneÔºåÂèØÂçïÁã¨‰∏ãËΩΩÊâÄÈúÄÁöÑÊñá‰ª∂&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Â∞Ü‰∏ãËΩΩÁöÑÊï∞ÊçÆÈõÜÊñá‰ª∂ÊîæÂà∞&lt;code&gt;./dataset/&lt;/code&gt;ÁõÆÂΩï‰∏ãÔºà‚ú®‰∏∫Êé®ËçêÁöÑÂøÖÈ°ªÈ°πÔºâ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./dataset/
‚îú‚îÄ‚îÄ dpo.jsonl (909MB)
‚îú‚îÄ‚îÄ lora_identity.jsonl (22.8KB)
‚îú‚îÄ‚îÄ lora_medical.jsonl (34MB)
‚îú‚îÄ‚îÄ pretrain_hq.jsonl (1.6GB, ‚ú®)
‚îú‚îÄ‚îÄ r1_mix_1024.jsonl (340MB)
‚îú‚îÄ‚îÄ sft_1024.jsonl (5.6GB)
‚îú‚îÄ‚îÄ sft_2048.jsonl (9GB)
‚îú‚îÄ‚îÄ sft_512.jsonl (7.5GB)
‚îú‚îÄ‚îÄ sft_mini_512.jsonl (1.2GB, ‚ú®)
‚îî‚îÄ‚îÄ tokenizer_train.jsonl (1GB)
&lt;/code&gt;&lt;/pre&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;Ê≥®ÔºöÂêÑÊï∞ÊçÆÈõÜÁÆÄ‰ªã&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;dpo.jsonl&lt;/code&gt; --RLHFÈò∂ÊÆµÊï∞ÊçÆÈõÜ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_identity.jsonl&lt;/code&gt; --Ëá™ÊàëËÆ§Áü•Êï∞ÊçÆÈõÜÔºà‰æãÂ¶ÇÔºö‰Ω†ÊòØË∞ÅÔºüÊàëÊòØminimind...ÔºâÔºåÊé®ËçêÁî®‰∫éloraËÆ≠ÁªÉÔºà‰∫¶ÂèØÁî®‰∫éÂÖ®ÂèÇSFTÔºåÂãøË¢´ÂêçÂ≠óÂ±ÄÈôêÔºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;lora_medical.jsonl&lt;/code&gt; --ÂåªÁñóÈóÆÁ≠îÊï∞ÊçÆÈõÜÔºåÊé®ËçêÁî®‰∫éloraËÆ≠ÁªÉÔºà‰∫¶ÂèØÁî®‰∫éÂÖ®ÂèÇSFTÔºåÂãøË¢´ÂêçÂ≠óÂ±ÄÈôêÔºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt;‚ú® --È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºåÊï¥ÂêàËá™jiangshuÁßëÊäÄ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt; --DeepSeek-R1-1.5BËí∏È¶èÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫1024ÔºàÂõ†Ê≠§ËÆ≠ÁªÉÊó∂ËÆæÁΩÆmax_seq_len=1024Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_1024.jsonl&lt;/code&gt; --Êï¥ÂêàËá™Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºàÊòØsft_2048ÁöÑÂ≠êÈõÜÔºâÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫1024ÔºàÂõ†Ê≠§ËÆ≠ÁªÉÊó∂ËÆæÁΩÆmax_seq_len=1024Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_2048.jsonl&lt;/code&gt; --Êï¥ÂêàËá™Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫2048ÔºàÂõ†Ê≠§ËÆ≠ÁªÉÊó∂ËÆæÁΩÆmax_seq_len=2048Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_512.jsonl&lt;/code&gt; --Êï¥ÂêàËá™Âå†Êï∞ÁßëÊäÄSFTÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫512ÔºàÂõ†Ê≠§ËÆ≠ÁªÉÊó∂ËÆæÁΩÆmax_seq_len=512Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;‚ú® --ÊûÅÁÆÄÊï¥ÂêàËá™Âå†Êï∞ÁßëÊäÄSFTÊï∞ÊçÆ+Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºàÁî®‰∫éÂø´ÈÄüËÆ≠ÁªÉZeroÊ®°ÂûãÔºâÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫512ÔºàÂõ†Ê≠§ËÆ≠ÁªÉÊó∂ËÆæÁΩÆmax_seq_len=512Ôºâ&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;tokenizer_train.jsonl&lt;/code&gt; --ÂùáÊù•Ëá™‰∫é&lt;code&gt;Âå†Êï∞Â§ßÊ®°ÂûãÊï∞ÊçÆÈõÜ&lt;/code&gt;ÔºåËøôÈÉ®ÂàÜÊï∞ÊçÆÁõ∏ÂØπÊ¨°Ë¶ÅÔºåÔºà‰∏çÊé®ËçêËá™Â∑±ÈáçÂ§çËÆ≠ÁªÉtokenizerÔºåÁêÜÁî±Â¶Ç‰∏äÔºâÂ¶ÇÈúÄËá™Â∑±ËÆ≠ÁªÉtokenizerÂèØ‰ª•Ëá™Áî±ÈÄâÊã©Êï∞ÊçÆÈõÜ„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/dataset.jpg" alt="dataset" /&gt;&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ËØ¥Êòé &amp;amp; Êé®ËçêËÆ≠ÁªÉÊñπÊ°à&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;MiniMind2 SeriesÂùáÁªèËøáÂÖ±Á∫¶20GBËØ≠ÊñôËÆ≠ÁªÉÔºåÂ§ßÁ∫¶4B tokensÔºåÂç≥ÂØπÂ∫î‰∏äÈù¢ÁöÑÊï∞ÊçÆÁªÑÂêàËÆ≠ÁªÉÁªìÊûúÔºàÂºÄÈîÄÔºöüí∞üí∞üí∞üí∞üí∞üí∞üí∞üí∞ÔºåÊïàÊûúÔºöüòäüòäüòäüòäüòäüòäÔºâ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;ÊÉ≥Ë¶ÅÊúÄÂø´ÈÄüÂ∫¶‰ªé0ÂÆûÁé∞ZeroÊ®°ÂûãÔºåÊé®Ëçê‰ΩøÁî®&lt;code&gt;pretrain_hq.jsonl&lt;/code&gt; + &lt;code&gt;sft_mini_512.jsonl&lt;/code&gt; ÁöÑÊï∞ÊçÆÁªÑÂêàÔºåÂÖ∑‰ΩìËä±ÈîÄÂíåÊïàÊûúÂèØÊü•Áúã‰∏ãÊñáË°®Ê†ºÔºàÂºÄÈîÄÔºöüí∞ÔºåÊïàÊûúÔºöüòäüòäÔºâ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Êé®ËçêÂÖ∑Â§á‰∏ÄÂÆöÁÆóÂäõËµÑÊ∫êÊàñÊõ¥Âú®ÊÑèÊïàÊûúÁöÑÊúãÂèãÂèØ‰ª•ËÄÉËôëÂâçËÄÖÂÆåÊï¥Â§çÁé∞MiniMind2Ôºõ‰ªÖÊúâÂçïÂç°GPUÊàñÂú®‰πéÁü≠Êó∂Èó¥Âø´ÈÄüÂ§çÁé∞ÁöÑÊúãÂèãÂº∫ÁÉàÊé®ËçêÂêéËÄÖÔºõ&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;„ÄêÊäò‰∏≠ÊñπÊ°à„Äë‰∫¶ÂèØÈÄâÊã©‰æãÂ¶Ç&lt;code&gt;sft_mini_512.jsonl&lt;/code&gt;„ÄÅ&lt;code&gt;sft_1024.jsonl&lt;/code&gt;‰∏≠Á≠âËßÑÊ®°Êï∞ÊçÆËøõË°åËá™Áî±ÁªÑÂêàËÆ≠ÁªÉÔºàÂºÄÈîÄÔºöüí∞üí∞üí∞ÔºåÊïàÊûúÔºöüòäüòäüòäüòäÔºâ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h1&gt;üìå Model Structure&lt;/h1&gt; 
&lt;p&gt;MiniMind-DenseÔºàÂíå&lt;a href="https://ai.meta.com/blog/meta-llama-3-1/"&gt;Llama3.1&lt;/a&gt;‰∏ÄÊ†∑Ôºâ‰ΩøÁî®‰∫ÜTransformerÁöÑDecoder-OnlyÁªìÊûÑÔºåË∑üGPT-3ÁöÑÂå∫Âà´Âú®‰∫éÔºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ÈááÁî®‰∫ÜGPT-3ÁöÑÈ¢ÑÊ†áÂáÜÂåñÊñπÊ≥ïÔºå‰πüÂ∞±ÊòØÂú®ÊØè‰∏™TransformerÂ≠êÂ±ÇÁöÑËæìÂÖ•‰∏äËøõË°åÂΩí‰∏ÄÂåñÔºåËÄå‰∏çÊòØÂú®ËæìÂá∫‰∏ä„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå‰ΩøÁî®ÁöÑÊòØRMSNormÂΩí‰∏ÄÂåñÂáΩÊï∞„ÄÇ&lt;/li&gt; 
 &lt;li&gt;Áî®SwiGLUÊøÄÊ¥ªÂáΩÊï∞Êõø‰ª£‰∫ÜReLUÔºåËøôÊ†∑ÂÅöÊòØ‰∏∫‰∫ÜÊèêÈ´òÊÄßËÉΩ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ÂÉèGPT-Neo‰∏ÄÊ†∑ÔºåÂéªÊéâ‰∫ÜÁªùÂØπ‰ΩçÁΩÆÂµåÂÖ•ÔºåÊîπÁî®‰∫ÜÊóãËΩ¨‰ΩçÁΩÆÂµåÂÖ•ÔºàRoPEÔºâÔºåËøôÊ†∑Âú®Â§ÑÁêÜË∂ÖÂá∫ËÆ≠ÁªÉÈïøÂ∫¶ÁöÑÊé®ÁêÜÊó∂ÊïàÊûúÊõ¥Â•Ω„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;MiniMind-MoEÊ®°ÂûãÔºåÂÆÉÁöÑÁªìÊûÑÂü∫‰∫éLlama3Âíå&lt;a href="https://arxiv.org/pdf/2405.04434"&gt;Deepseek-V2/3&lt;/a&gt;‰∏≠ÁöÑMixFFNÊ∑∑Âêà‰∏ìÂÆ∂Ê®°Âùó„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;DeepSeek-V2Âú®ÂâçÈ¶àÁΩëÁªúÔºàFFNÔºâÊñπÈù¢ÔºåÈááÁî®‰∫ÜÊõ¥ÁªÜÁ≤íÂ∫¶ÁöÑ‰∏ìÂÆ∂ÂàÜÂâ≤ÂíåÂÖ±‰∫´ÁöÑ‰∏ìÂÆ∂ÈöîÁ¶ªÊäÄÊúØÔºå‰ª•ÊèêÈ´òExpertsÁöÑÊïàÊûú„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;MiniMindÁöÑÊï¥‰ΩìÁªìÊûÑ‰∏ÄËá¥ÔºåÂè™ÊòØÂú®RoPEËÆ°ÁÆó„ÄÅÊé®ÁêÜÂáΩÊï∞ÂíåFFNÂ±ÇÁöÑ‰ª£Á†Å‰∏äÂÅö‰∫Ü‰∏Ä‰∫õÂ∞èË∞ÉÊï¥„ÄÇ ÂÖ∂ÁªìÊûÑÂ¶Ç‰∏ãÂõæÔºàÈáçÁªòÁâàÔºâÔºö&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure.png" alt="structure" /&gt; &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/LLM-structure-moe.png" alt="structure-moe" /&gt;&lt;/p&gt; 
&lt;p&gt;‰øÆÊîπÊ®°ÂûãÈÖçÁΩÆËßÅ&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/model/LMConfig.py"&gt;./model/LMConfig.py&lt;/a&gt;„ÄÇ ÂèÇËÄÉÊ®°ÂûãÂèÇÊï∞ÁâàÊú¨ËßÅ‰∏ãË°®Ôºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;len_vocab&lt;/th&gt; 
   &lt;th&gt;rope_theta&lt;/th&gt; 
   &lt;th&gt;n_layers&lt;/th&gt; 
   &lt;th&gt;d_model&lt;/th&gt; 
   &lt;th&gt;kv_heads&lt;/th&gt; 
   &lt;th&gt;q_heads&lt;/th&gt; 
   &lt;th&gt;share+route&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;640&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e6&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1-moe&lt;/td&gt; 
   &lt;td&gt;4√ó26M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;512&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;1+4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;minimind-v1&lt;/td&gt; 
   &lt;td&gt;108M&lt;/td&gt; 
   &lt;td&gt;6400&lt;/td&gt; 
   &lt;td&gt;1e4&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;768&lt;/td&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;-&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;üìå Experiment&lt;/h1&gt; 
&lt;h2&gt;‚Ö† ËÆ≠ÁªÉÂºÄÈîÄ&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Êó∂Èó¥Âçï‰Ωç&lt;/strong&gt;ÔºöÂ∞èÊó∂ (h)„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÊàêÊú¨Âçï‰Ωç&lt;/strong&gt;Ôºö‰∫∫Ê∞ëÂ∏Å (Ôø•)Ôºõ7Ôø• ‚âà 1ÁæéÂÖÉ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;3090 ÁßüÂç°Âçï‰ª∑&lt;/strong&gt;Ôºö‚âà1.3Ôø•/hÔºàÂèØËá™Ë°åÂèÇËÄÉÂÆûÊó∂Â∏Ç‰ª∑Ôºâ„ÄÇ&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ÂèÇËÄÉÊ†áÂáÜ&lt;/strong&gt;ÔºöË°®Ê†º‰ªÖÂÆûÊµã &lt;code&gt;pretrain&lt;/code&gt; Âíå &lt;code&gt;sft_mini_512&lt;/code&gt; ‰∏§‰∏™Êï∞ÊçÆÈõÜÁöÑËÆ≠ÁªÉÊó∂Èó¥ÔºåÂÖ∂ÂÆÉËÄóÊó∂Ê†πÊçÆÊï∞ÊçÆÈõÜÂ§ßÂ∞è‰º∞ÁÆóÔºàÂèØËÉΩÂ≠òÂú®‰∫õËÆ∏Âá∫ÂÖ•Ôºâ„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Âü∫‰∫é 3090 ÔºàÂçïÂç°ÔºâÊàêÊú¨ËÆ°ÁÆó&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Model Name&lt;/th&gt; 
   &lt;th&gt;params&lt;/th&gt; 
   &lt;th&gt;pretrain&lt;/th&gt; 
   &lt;th&gt;sft_mini_512&lt;/th&gt; 
   &lt;th&gt;sft_512&lt;/th&gt; 
   &lt;th&gt;sft_1024&lt;/th&gt; 
   &lt;th&gt;sft_2048&lt;/th&gt; 
   &lt;th&gt;RLHF&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;‚âà1.1h&lt;br /&gt;‚âà1.43Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà1h&lt;br /&gt;‚âà1.3Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà6h&lt;br /&gt;‚âà7.8Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà4.58h&lt;br /&gt;‚âà5.95Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà7.5h&lt;br /&gt;‚âà9.75Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà1h&lt;br /&gt;‚âà1.3Ôø•&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;‚âà3.9h&lt;br /&gt;‚âà5.07Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà3.3h&lt;br /&gt;‚âà4.29Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà20h&lt;br /&gt;‚âà26Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà15h&lt;br /&gt;‚âà19.5Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà25h&lt;br /&gt;‚âà32.5Ôø•&lt;/td&gt; 
   &lt;td&gt;‚âà3h&lt;br /&gt;‚âà3.9Ôø•&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ËÆ≠ÁªÉÂºÄÈîÄÊÄªÁªì&amp;amp;È¢ÑÊµã&lt;/summary&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-SmallÂèÇÊï∞&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_mini_512&lt;/code&gt;Êï∞ÊçÆÈõÜ &lt;br /&gt;ÂçïÂç°3090 (1 epoch) + 2.1Â∞èÊó∂ + Ëä±Ë¥π2.73ÂÖÉ‰∫∫Ê∞ëÂ∏Å &lt;br /&gt;Âç≥ÂèØ‰ªé0ËÆ≠ÁªÉÂá∫MiniMind-Zero-0.025BÊ®°Âûã!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2-SmallÂèÇÊï∞&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;Êï∞ÊçÆÈõÜ &lt;br /&gt;ÂçïÂç°3090 (2 epochs) + Â§ßÁ∫¶38.16Â∞èÊó∂ + Ëä±Ë¥π49.61ÂÖÉ‰∫∫Ê∞ëÂ∏Å &lt;br /&gt;Âç≥ÂèØ‰ªé0ËÆ≠ÁªÉÂá∫MiniMind2-Small-0.025BÊ®°Âûã!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
 &lt;blockquote&gt; 
  &lt;p&gt;MiniMind2ÂèÇÊï∞&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;&lt;code&gt;pretrain_hq&lt;/code&gt;+&lt;code&gt;sft_512&lt;/code&gt;+&lt;code&gt;sft_2048&lt;/code&gt;+&lt;code&gt;dpo&lt;/code&gt;Êï∞ÊçÆÈõÜ &lt;br /&gt;ÂçïÂç°3090 (2 epochs) + Â§ßÁ∫¶122Â∞èÊó∂ + Ëä±Ë¥π158.6ÂÖÉ‰∫∫Ê∞ëÂ∏Å &lt;br /&gt;Âç≥ÂèØ‰ªé0ËÆ≠ÁªÉÂá∫MiniMind2-0.1BÊ®°Âûã!!!&lt;/p&gt; 
  &lt;/blockquote&gt; 
 &lt;/blockquote&gt; 
&lt;/details&gt; 
&lt;p&gt;‚ú®Âü∫‰∫éÂçïÂç°NVIDIA 3090ÁöÑ&lt;code&gt;MiniMind-Zero&lt;/code&gt;‰ªé0ËÆ≠ÁªÉ‰ªÖÈúÄ&lt;code&gt;2Â∞èÊó∂&lt;/code&gt; + &lt;code&gt;3ÂùóÈí±&lt;/code&gt;ÔºåÂÆûÁé∞ChatBotÊïàÊûúÔºÅ&lt;/p&gt; 
&lt;p&gt;‚ú®PSÔºöËã•ÈááÁî®8Âç°4090ËÆ≠ÁªÉÔºåÊÄªÁî®Êó∂ÁîöËá≥ÂèØ‰ª•ÂéãÁº©Âà∞10ÂàÜÈíü‰ª•ÂÜÖÔºÅÔºàÁî±‰∫éÊó∂Èó¥Êõ¥Áü≠ÔºåËä±Ë¥πÂêåÊ†∑3ÂÖÉÂ∑¶Âè≥Ôºå‰∏éÂçïÂç°ÊàêÊú¨Áõ∏ÂΩìÔºâ&lt;/p&gt; 
&lt;p&gt;‚ú®‰ª•ÊûÅ‰ΩéÊûÅ‰ΩéÁöÑÈó®ÊßõÔºåÂÆûÁé∞‰∫∫‰∫∫ÂèØÁé©ÁöÑÂ§ßÊ®°ÂûãËá™Áî±ÔºÅËøôÊ≠£ÊòØMiniMindÁ≥ªÂàóÁöÑËØûÁîüÂàùË°∑ÔºÅ&lt;/p&gt; 
&lt;p&gt;‚ú®‰ªÖ‰ª∑ÂÄº&lt;code&gt;3ÂùóÈí±&lt;/code&gt;ÊàêÊú¨ÁöÑ&lt;code&gt;MiniMind-Zero&lt;/code&gt;Âπ∂‰∏çÊòØÂô±Â§¥ÔºÅChatÊµãËØïÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;üë∂: ËØ∑‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±„ÄÇ
ü§ñÔ∏è: ‰Ωú‰∏∫‰∫∫Â∑•Êô∫ËÉΩÔºåÊàëÊ≤°ÊúâÂÆûÈôÖÁöÑÁîüÊ¥ªÔºå‰πüÊ≤°ÊúâËá™ÊàëÊÑèËØÜÔºåÊâÄ‰ª•Ê≤°ÊúâËá™Â∑±ÁöÑÁîüÊ¥ª„ÄÇÊàëË¢´ËÆæËÆ°ÊàêËÉΩÂ§üÂ∏ÆÂä©Áî®Êà∑Ëß£Á≠îÈóÆÈ¢ò„ÄÅÊèê‰æõ‰ø°ÊÅØ„ÄÅËøõË°åÂØπËØùÁ≠â„ÄÇÊàëÁöÑËÆæËÆ°ÂíåÂäüËÉΩÊòØÁî±ËÆ°ÁÆóÊú∫ÁßëÂ≠¶„ÄÅÊú∫Âô®Â≠¶‰π†„ÄÅ‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÂíåÁÆóÊ≥ïÊâÄÊûÑÂª∫ÁöÑÔºåÊàëÈÄöËøáÁºñÁ®ãÂíåÁÆóÊ≥ïÂÆûÁé∞„ÄÇ

üë∂: Êé®Ëçê‰∏Ä‰∫õÊù≠Â∑ûÁöÑÁâπËâ≤ÁæéÈ£üÂêß„ÄÇ
ü§ñÔ∏è: Êù≠Â∑ûÊúâÂæàÂ§öÁæéÂë≥ÁöÑÁâπËâ≤ÁæéÈ£üÔºåÊØîÂ¶ÇÈ∏°ËÇâ‰∏≤„ÄÅÈ≥óÈ±ºÂ§¥„ÄÅÊ∞¥ÁÖÆÈ±º„ÄÅË±ÜËÖêËÑëÁ≠â„ÄÇËøô‰∫õÁæéÈ£üÈÉΩÈùûÂ∏∏ÁæéÂë≥ÔºåÊúâÁùÄÁã¨ÁâπÁöÑÈ£éÂë≥ÂíåÂè£ÊÑüÔºåÁªùÂØπÊòØÂÄºÂæó‰∏ÄËØïÁöÑÁæéÈ£ü„ÄÇ

üë∂: ËØ∑‰∏∫ÊàëËÆ≤Ëß£‚ÄúÂ§ßËØ≠Ë®ÄÊ®°Âûã‚ÄùËøô‰∏™Ê¶ÇÂøµ„ÄÇ
ü§ñÔ∏è: Â§ßËØ≠Ë®ÄÊ®°ÂûãÊòØ‰∏ÄÁßç‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÔºåÂÆÉ‰ΩøÁî®Â§ßÈáèÁöÑÊñáÊú¨Êï∞ÊçÆÊù•ËÆ≠ÁªÉÊ®°ÂûãÔºåÁÑ∂ÂêéÂú®‰∏çÊñ≠ÁöÑËø≠‰ª£‰∏≠‰∏çÊñ≠‰ºòÂåñÊ®°Âûã„ÄÇÂÆÉÁöÑÁõÆÊ†áÊòØÊ†πÊçÆËæìÂÖ•ÁöÑÊï∞ÊçÆÊù•ÁîüÊàêÁ¨¶ÂêàÁâπÂÆöÈúÄÊ±ÇÁöÑÊñáÊú¨ÔºåËøô‰∫õÊñáÊú¨ÂèØ‰ª•ÊòØ‰ªª‰Ωï‰Ω†ÊÑüÂÖ¥Ë∂£ÁöÑ‰∏ªÈ¢ò„ÄÇ

üë∂: Introduce the history of the United States, please.
ü§ñÔ∏è: ÊÇ®ÊèêÂà∞ÁöÑ‚ÄúIntrook's the believeations of theument." Ëøô‰∏™ÂêçÂ≠óÊù•Ê∫ê‰∫é‰∏≠ÂõΩÂè§‰ª£ÁöÑ"groty of of the change."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÊûÅÈÄü‰∏îÂàùÂÖ∑ÊïàÊûúÔºåÁîöËá≥‰ªçÁÑ∂ÂèØ‰ª•Ëøõ‰∏ÄÊ≠•ÂéãÁº©Ëé∑ÂèñÊõ¥Â∞èÊõ¥‰ºòË¥®ÁöÑËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ ZeroÊ®°ÂûãÊùÉÈáç‰øùÂ≠ò‰∏∫ &lt;code&gt;full_sft_512_zero.pth&lt;/code&gt;ÔºàËßÅ‰∏ãÊñáMiniMindÊ®°ÂûãÊñá‰ª∂ÈìæÊé•ÔºâÔºåÂ¶ÇÊúâÂÖ¥Ë∂£ÂèØ‰∏ãËΩΩÊ£ÄÈ™åÊ≠§Ê®°ÂûãÊïàÊûú„ÄÇ&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚Ö° ‰∏ªË¶ÅËÆ≠ÁªÉÊ≠•È™§&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨Âùá &lt;code&gt;cd ./trainer&lt;/code&gt; ÁõÆÂΩïÊâßË°å&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;1. È¢ÑËÆ≠ÁªÉ(Pretrain)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;LLMÈ¶ñÂÖàË¶ÅÂ≠¶‰π†ÁöÑÂπ∂ÈùûÁõ¥Êé•‰∏é‰∫∫‰∫§ÊµÅÔºåËÄåÊòØËÆ©ÁΩëÁªúÂèÇÊï∞‰∏≠ÂÖÖÊª°Áü•ËØÜÁöÑÂ¢®Ê∞¥Ôºå‚ÄúÂ¢®Ê∞¥‚Äù ÁêÜËÆ∫‰∏äÂñùÁöÑË∂äÈ•±Ë∂äÂ•ΩÔºå‰∫ßÁîüÂ§ßÈáèÁöÑÂØπ‰∏ñÁïåÁöÑÁü•ËØÜÁßØÁ¥Ø„ÄÇ È¢ÑËÆ≠ÁªÉÂ∞±ÊòØËÆ©ModelÂÖàÂüãÂ§¥Ëã¶Â≠¶Â§ßÈáèÂü∫Êú¨ÁöÑÁü•ËØÜÔºå‰æãÂ¶Ç‰ªéWikiÁôæÁßë„ÄÅÊñ∞Èóª„ÄÅ‰π¶Á±çÊï¥ÁêÜÂ§ßËßÑÊ®°ÁöÑÈ´òË¥®ÈáèËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ Ëøô‰∏™ËøáÁ®ãÊòØ‚ÄúÊó†ÁõëÁù£‚ÄùÁöÑÔºåÂç≥‰∫∫Á±ª‰∏çÈúÄË¶ÅÂú®ËøáÁ®ã‰∏≠ÂÅö‰ªª‰Ωï‚ÄúÊúâÁõëÁù£‚ÄùÁöÑÊ†°Ê≠£ÔºåËÄåÊòØÁî±Ê®°ÂûãËá™Â∑±‰ªéÂ§ßÈáèÊñáÊú¨‰∏≠ÊÄªÁªìËßÑÂæãÂ≠¶‰π†Áü•ËØÜÁÇπ„ÄÇ Ê®°ÂûãÊ≠§Èò∂ÊÆµÁõÆÁöÑÂè™Êúâ‰∏Ä‰∏™Ôºö&lt;strong&gt;Â≠¶‰ºöËØçËØ≠Êé•Èæô&lt;/strong&gt;„ÄÇ‰æãÂ¶ÇÊàë‰ª¨ËæìÂÖ•‚ÄúÁß¶ÂßãÁöá‚ÄùÂõõ‰∏™Â≠óÔºåÂÆÉÂèØ‰ª•Êé•Èæô‚ÄúÊòØ‰∏≠ÂõΩÁöÑÁ¨¨‰∏Ä‰ΩçÁöáÂ∏ù‚Äù„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_pretrain.py # 1Âç≥‰∏∫ÂçïÂç°ËÆ≠ÁªÉÔºåÂèØÊ†πÊçÆÁ°¨‰ª∂ÊÉÖÂÜµËá™Ë°åË∞ÉÊï¥ (ËÆæÁΩÆ&amp;gt;=2)
# or
python train_pretrain.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;pretrain_*.pth&lt;/code&gt;Ôºà* ‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;2. ÊúâÁõëÁù£ÂæÆË∞É(Supervised Fine-Tuning)&lt;/strong&gt;:&lt;/h3&gt; 
&lt;p&gt;ÁªèËøáÈ¢ÑËÆ≠ÁªÉÔºåLLMÊ≠§Êó∂Â∑≤ÁªèÊéåÊè°‰∫ÜÂ§ßÈáèÁü•ËØÜÔºåÁÑ∂ËÄåÊ≠§Êó∂ÂÆÉÂè™‰ºöÊó†ËÑëÂú∞ËØçËØ≠Êé•ÈæôÔºåËøò‰∏ç‰ºö‰∏é‰∫∫ËÅäÂ§©„ÄÇ SFTÈò∂ÊÆµÂ∞±ÈúÄË¶ÅÊääÂçäÊàêÂìÅLLMÊñΩÂä†‰∏Ä‰∏™Ëá™ÂÆö‰πâÁöÑËÅäÂ§©Ê®°ÊùøËøõË°åÂæÆË∞É„ÄÇ ‰æãÂ¶ÇÊ®°ÂûãÈÅáÂà∞ËøôÊ†∑ÁöÑÊ®°Êùø„ÄêÈóÆÈ¢ò-&amp;gt;ÂõûÁ≠îÔºåÈóÆÈ¢ò-&amp;gt;ÂõûÁ≠î„ÄëÂêé‰∏çÂÜçÊó†ËÑëÊé•ÈæôÔºåËÄåÊòØÊÑèËØÜÂà∞ËøôÊòØ‰∏ÄÊÆµÂÆåÊï¥ÁöÑÂØπËØùÁªìÊùü„ÄÇ Áß∞Ëøô‰∏™ËøáÁ®ã‰∏∫Êåá‰ª§ÂæÆË∞ÉÔºåÂ∞±Â¶ÇÂêåËÆ©Â∑≤ÁªèÂ≠¶ÂØå‰∫îËΩ¶ÁöÑ„ÄåÁâõÈ°ø„ÄçÂÖàÁîüÈÄÇÂ∫î21‰∏ñÁ∫™Êô∫ËÉΩÊâãÊú∫ÁöÑËÅäÂ§©‰π†ÊÉØÔºåÂ≠¶‰π†Â±èÂπïÂ∑¶‰æßÊòØÂØπÊñπÊ∂àÊÅØÔºåÂè≥‰æßÊòØÊú¨‰∫∫Ê∂àÊÅØËøô‰∏™ËßÑÂæã„ÄÇ Âú®ËÆ≠ÁªÉÊó∂ÔºåMiniMindÁöÑÊåá‰ª§ÂíåÂõûÁ≠îÈïøÂ∫¶Ë¢´Êà™Êñ≠Âú®512ÔºåÊòØ‰∏∫‰∫ÜËäÇÁúÅÊòæÂ≠òÁ©∫Èó¥„ÄÇÂ∞±ÂÉèÊàë‰ª¨Â≠¶‰π†Êó∂Ôºå‰ºöÂÖà‰ªéÁü≠ÁöÑÊñáÁ´†ÂºÄÂßãÔºåÂΩìÂ≠¶‰ºöÂÜô‰Ωú200Â≠ó‰ΩúÊñáÂêéÔºå800Â≠óÊñáÁ´†‰πüÂèØ‰ª•ÊâãÂà∞ÊìíÊù•„ÄÇ Âú®ÈúÄË¶ÅÈïøÂ∫¶ÊãìÂ±ïÊó∂ÔºåÂè™ÈúÄË¶ÅÂáÜÂ§áÂ∞ëÈáèÁöÑ2k/4k/8kÈïøÂ∫¶ÂØπËØùÊï∞ÊçÆËøõË°åËøõ‰∏ÄÊ≠•ÂæÆË∞ÉÂç≥ÂèØÔºàÊ≠§Êó∂ÊúÄÂ•ΩÈÖçÂêàRoPE-NTKÁöÑÂü∫ÂáÜÂ∑ÆÂÄºÔºâ„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Âú®Êé®ÁêÜÊó∂ÈÄöËøáË∞ÉÊï¥RoPEÁ∫øÊÄßÂ∑ÆÂÄºÔºåÂÆûÁé∞ÂÖçËÆ≠ÁªÉÈïøÂ∫¶Â§ñÊé®Âà∞2048Âèä‰ª•‰∏äÂ∞Ü‰ºöÂæàÊñπ‰æø„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;full_sft_*.pth&lt;/code&gt;Ôºà* ‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;‚Ö¢ ÂÖ∂ÂÆÉËÆ≠ÁªÉÊ≠•È™§&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨Âùá &lt;code&gt;cd ./trainer&lt;/code&gt; ÁõÆÂΩïÊâßË°å&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;3. ‰∫∫Á±ªÂèçÈ¶àÂº∫ÂåñÂ≠¶‰π†(Reinforcement Learning from Human Feedback, RLHF)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Âú®ÂâçÈù¢ÁöÑËÆ≠ÁªÉÊ≠•È™§‰∏≠ÔºåÊ®°ÂûãÂ∑≤ÁªèÂÖ∑Â§á‰∫ÜÂü∫Êú¨ÁöÑÂØπËØùËÉΩÂäõÔºå‰ΩÜÊòØËøôÊ†∑ÁöÑËÉΩÂäõÂÆåÂÖ®Âü∫‰∫éÂçïËØçÊé•ÈæôÔºåÁº∫Â∞ëÊ≠£ÂèçÊ†∑‰æãÁöÑÊøÄÂä±„ÄÇ Ê®°ÂûãÊ≠§Êó∂Â∞öÊú™Áü•‰ªÄ‰πàÂõûÁ≠îÊòØÂ•ΩÁöÑÔºå‰ªÄ‰πàÊòØÂ∑ÆÁöÑ„ÄÇÊàë‰ª¨Â∏åÊúõÂÆÉËÉΩÂ§üÊõ¥Á¨¶Âêà‰∫∫ÁöÑÂÅèÂ•ΩÔºåÈôç‰ΩéËÆ©‰∫∫Á±ª‰∏çÊª°ÊÑèÁ≠îÊ°àÁöÑ‰∫ßÁîüÊ¶ÇÁéá„ÄÇ Ëøô‰∏™ËøáÁ®ãÂ∞±ÂÉèÊòØËÆ©Ê®°ÂûãÂèÇÂä†Êñ∞ÁöÑÂüπËÆ≠Ôºå‰ªé‰ºòÁßÄÂëòÂ∑•ÁöÑ‰Ωú‰∏∫‰æãÂ≠êÔºåÊ∂àÊûÅÂëòÂ∑•‰Ωú‰∏∫Âèç‰æãÔºåÂ≠¶‰π†Â¶Ç‰ΩïÊõ¥Â•ΩÂú∞ÂõûÂ§ç„ÄÇ Ê≠§Â§Ñ‰ΩøÁî®ÁöÑÊòØRLHFÁ≥ªÂàó‰πã-Áõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñ(Direct Preference Optimization, DPO)„ÄÇ ‰∏éPPO(Proximal Policy Optimization)ËøôÁßçÈúÄË¶ÅÂ•ñÂä±Ê®°Âûã„ÄÅ‰ª∑ÂÄºÊ®°ÂûãÁöÑRLÁÆóÊ≥ï‰∏çÂêåÔºõ DPOÈÄöËøáÊé®ÂØºPPOÂ•ñÂä±Ê®°ÂûãÁöÑÊòæÂºèËß£ÔºåÊääÂú®Á∫øÂ•ñÂä±Ê®°ÂûãÊç¢ÊàêÁ¶ªÁ∫øÊï∞ÊçÆÔºåRefÊ®°ÂûãËæìÂá∫ÂèØ‰ª•ÊèêÂâç‰øùÂ≠ò„ÄÇ DPOÊÄßËÉΩÂá†‰πé‰∏çÂèòÔºåÂè™Áî®Ë∑ë actor_model Âíå ref_model ‰∏§‰∏™Ê®°ÂûãÔºåÂ§ßÂ§ßËäÇÁúÅÊòæÂ≠òÂºÄÈîÄÂíåÂ¢ûÂä†ËÆ≠ÁªÉÁ®≥ÂÆöÊÄß„ÄÇ&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Ê≥®ÔºöRLHFËÆ≠ÁªÉÊ≠•È™§&lt;strong&gt;Âπ∂ÈùûÂøÖÈ°ª&lt;/strong&gt;ÔºåÊ≠§Ê≠•È™§Èöæ‰ª•ÊèêÂçáÊ®°Âûã‚ÄúÊô∫Âäõ‚ÄùËÄåÈÄöÂ∏∏‰ªÖÁî®‰∫éÊèêÂçáÊ®°ÂûãÁöÑ‚ÄúÁ§ºË≤å‚ÄùÔºåÊúâÂà©ÔºàÁ¨¶ÂêàÂÅèÂ•Ω„ÄÅÂáèÂ∞ëÊúâÂÆ≥ÂÜÖÂÆπÔºâ‰πüÊúâÂºäÔºàÊ†∑Êú¨Êî∂ÈõÜÊòÇË¥µ„ÄÅÂèçÈ¶àÂÅèÂ∑Æ„ÄÅÂ§öÊ†∑ÊÄßÊçüÂ§±Ôºâ„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_dpo.py
# or
python train_dpo.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;rlhf_*.pth&lt;/code&gt;Ôºà* ‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;&lt;strong&gt;4. Áü•ËØÜËí∏È¶è(Knowledge Distillation, KD)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Âú®ÂâçÈù¢ÁöÑÊâÄÊúâËÆ≠ÁªÉÊ≠•È™§‰∏≠ÔºåÊ®°ÂûãÂ∑≤ÁªèÂÆåÂÖ®ÂÖ∑Â§á‰∫ÜÂü∫Êú¨ËÉΩÂäõÔºåÈÄöÂ∏∏ÂèØ‰ª•Â≠¶ÊàêÂá∫Â∏à‰∫Ü„ÄÇ ËÄåÁü•ËØÜËí∏È¶èÂèØ‰ª•Ëøõ‰∏ÄÊ≠•‰ºòÂåñÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÊïàÁéáÔºåÊâÄË∞ìÁü•ËØÜËí∏È¶èÔºåÂç≥Â≠¶ÁîüÊ®°ÂûãÈù¢ÂêëÊïôÂ∏àÊ®°ÂûãÂ≠¶‰π†„ÄÇ ÊïôÂ∏àÊ®°ÂûãÈÄöÂ∏∏ÊòØÁªèËøáÂÖÖÂàÜËÆ≠ÁªÉÁöÑÂ§ßÊ®°ÂûãÔºåÂÖ∑ÊúâËæÉÈ´òÁöÑÂáÜÁ°ÆÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ Â≠¶ÁîüÊ®°ÂûãÊòØ‰∏Ä‰∏™ËæÉÂ∞èÁöÑÊ®°ÂûãÔºåÁõÆÊ†áÊòØÂ≠¶‰π†ÊïôÂ∏àÊ®°ÂûãÁöÑË°å‰∏∫ÔºåËÄå‰∏çÊòØÁõ¥Êé•‰ªéÂéüÂßãÊï∞ÊçÆ‰∏≠Â≠¶‰π†„ÄÇ Âú®SFTÂ≠¶‰π†‰∏≠ÔºåÊ®°ÂûãÁöÑÁõÆÊ†áÊòØÊãüÂêàËØçTokenÂàÜÁ±ªÁ°¨Ê†áÁ≠æÔºàhard labelsÔºâÔºåÂç≥ÁúüÂÆûÁöÑÁ±ªÂà´Ê†áÁ≠æÔºàÂ¶Ç 0 Êàñ 6400Ôºâ„ÄÇ Âú®Áü•ËØÜËí∏È¶è‰∏≠ÔºåÊïôÂ∏àÊ®°ÂûãÁöÑsoftmaxÊ¶ÇÁéáÂàÜÂ∏ÉË¢´Áî®‰ΩúËΩØÊ†áÁ≠æÔºàsoft labelsÔºâ„ÄÇÂ∞èÊ®°Âûã‰ªÖÂ≠¶‰π†ËΩØÊ†áÁ≠æÔºåÂπ∂‰ΩøÁî®KL-LossÊù•‰ºòÂåñÊ®°ÂûãÁöÑÂèÇÊï∞„ÄÇ ÈÄö‰øóÂú∞ËØ¥ÔºåSFTÁõ¥Êé•Â≠¶‰π†ËÄÅÂ∏àÁªôÁöÑËß£È¢òÁ≠îÊ°à„ÄÇËÄåKDËøáÁ®ãÁõ∏ÂΩì‰∫é‚ÄúÊâìÂºÄ‚ÄùËÄÅÂ∏àËÅ™ÊòéÁöÑÂ§ßËÑëÔºåÂ∞ΩÂèØËÉΩÂú∞Ê®°‰ªøËÄÅÂ∏à‚ÄúÂ§ßËÑë‚ÄùÊÄùËÄÉÈóÆÈ¢òÁöÑÁ•ûÁªèÂÖÉÁä∂ÊÄÅ„ÄÇ ‰æãÂ¶ÇÔºåÂΩìËÄÅÂ∏àÊ®°ÂûãËÆ°ÁÆó&lt;code&gt;1+1=2&lt;/code&gt;Ëøô‰∏™ÈóÆÈ¢òÁöÑÊó∂ÂÄôÔºåÊúÄÂêé‰∏ÄÂ±ÇÁ•ûÁªèÂÖÉaÁä∂ÊÄÅ‰∏∫0ÔºåÁ•ûÁªèÂÖÉbÁä∂ÊÄÅ‰∏∫100ÔºåÁ•ûÁªèÂÖÉcÁä∂ÊÄÅ‰∏∫-99... Â≠¶ÁîüÊ®°ÂûãÈÄöËøáÂ§ßÈáèÊï∞ÊçÆÔºåÂ≠¶‰π†ÊïôÂ∏àÊ®°ÂûãÂ§ßËÑëÂÜÖÈÉ®ÁöÑËøêËΩ¨ËßÑÂæã„ÄÇËøô‰∏™ËøáÁ®ãÂç≥Áß∞‰πã‰∏∫ÔºöÁü•ËØÜËí∏È¶è„ÄÇ Áü•ËØÜËí∏È¶èÁöÑÁõÆÁöÑÂè™Êúâ‰∏Ä‰∏™ÔºöËÆ©Â∞èÊ®°Âûã‰ΩìÁßØÊõ¥Â∞èÁöÑÂêåÊó∂ÊïàÊûúÊõ¥Â•Ω„ÄÇ ÁÑ∂ËÄåÈöèÁùÄLLMËØûÁîüÂíåÂèëÂ±ïÔºåÊ®°ÂûãËí∏È¶è‰∏ÄËØçË¢´ÂπøÊ≥õÊª•Áî®Ôºå‰ªéËÄå‰∫ßÁîü‰∫Ü‚ÄúÁôΩÁõí/ÈªëÁõí‚ÄùÁü•ËØÜËí∏È¶è‰∏§‰∏™Ê¥æÂà´„ÄÇ GPT-4ËøôÁßçÈó≠Ê∫êÊ®°ÂûãÔºåÁî±‰∫éÊó†Ê≥ïËé∑ÂèñÂÖ∂ÂÜÖÈÉ®ÁªìÊûÑÔºåÂõ†Ê≠§Âè™ËÉΩÈù¢ÂêëÂÆÉÊâÄËæìÂá∫ÁöÑÊï∞ÊçÆÂ≠¶‰π†ÔºåËøô‰∏™ËøáÁ®ãÁß∞‰πã‰∏∫ÈªëÁõíËí∏È¶èÔºå‰πüÊòØÂ§ßÊ®°ÂûãÊó∂‰ª£ÊúÄÊôÆÈÅçÁöÑÂÅöÊ≥ï„ÄÇ ÈªëÁõíËí∏È¶è‰∏éSFTËøáÁ®ãÂÆåÂÖ®‰∏ÄËá¥ÔºåÂè™‰∏çËøáÊï∞ÊçÆÊòØ‰ªéÂ§ßÊ®°ÂûãÁöÑËæìÂá∫Êî∂ÈõÜÔºåÂõ†Ê≠§Âè™ÈúÄË¶ÅÂáÜÂ§áÊï∞ÊçÆÂπ∂‰∏îËøõ‰∏ÄÊ≠•FTÂç≥ÂèØ„ÄÇ Ê≥®ÊÑèÊõ¥ÊîπË¢´Âä†ËΩΩÁöÑÂü∫Á°ÄÊ®°Âûã‰∏∫&lt;code&gt;full_sft_*.pth&lt;/code&gt;ÔºåÂç≥Âü∫‰∫éÂæÆË∞ÉÊ®°ÂûãÂÅöËøõ‰∏ÄÊ≠•ÁöÑËí∏È¶èÂ≠¶‰π†„ÄÇ &lt;code&gt;./dataset/sft_1024.jsonl&lt;/code&gt;‰∏é&lt;code&gt;./dataset/sft_2048.jsonl&lt;/code&gt; ÂùáÊî∂ÈõÜËá™qwen2.5-7/72B-InstructÂ§ßÊ®°ÂûãÔºåÂèØÁõ¥Êé•Áî®‰∫éSFT‰ª•Ëé∑ÂèñQwenÁöÑÈÉ®ÂàÜË°å‰∏∫„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ê≥®ÊÑèÈúÄË¶ÅÊõ¥Êîπtrain_full_sft.pyÊï∞ÊçÆÈõÜË∑ØÂæÑÔºå‰ª•Âèämax_seq_len  
torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;ÂêåÊ†∑‰øùÂ≠ò‰∏∫: &lt;code&gt;full_sft_*.pth&lt;/code&gt;Ôºà*‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Ê≠§Â§ÑÂ∫îÂΩìÁùÄÈáç‰ªãÁªçMiniMindÂÆûÁé∞ÁöÑÁôΩÁõíËí∏È¶è‰ª£Á†Å&lt;code&gt;train_distillation.py&lt;/code&gt;ÔºåÁî±‰∫éMiniMindÂêåÁ≥ªÂàóÊú¨Ë∫´Âπ∂‰∏çÂ≠òÂú®Âº∫Â§ßÁöÑÊïôÂ∏àÊ®°ÂûãÔºåÂõ†Ê≠§ÁôΩÁõíËí∏È¶è‰ª£Á†Å‰ªÖ‰Ωú‰∏∫Â≠¶‰π†ÂèÇËÄÉ„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_distillation.py
# or
python train_distillation.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;&lt;strong&gt;5. LoRA (Low-Rank Adaptation)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;LoRAÊòØ‰∏ÄÁßçÈ´òÊïàÁöÑÂèÇÊï∞È´òÊïàÂæÆË∞ÉÔºàParameter-Efficient Fine-Tuning, PEFTÔºâÊñπÊ≥ïÔºåÊó®Âú®ÈÄöËøá‰ΩéÁß©ÂàÜËß£ÁöÑÊñπÂºèÂØπÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãËøõË°åÂæÆË∞É„ÄÇ Áõ∏ÊØî‰∫éÂÖ®ÂèÇÊï∞ÂæÆË∞ÉÔºàFull Fine-TuningÔºâÔºåLoRA Âè™ÈúÄË¶ÅÊõ¥Êñ∞Â∞ëÈáèÁöÑÂèÇÊï∞„ÄÇ LoRA ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÔºöÂú®Ê®°ÂûãÁöÑÊùÉÈáçÁü©Èòµ‰∏≠ÂºïÂÖ•‰ΩéÁß©ÂàÜËß£Ôºå‰ªÖÂØπ‰ΩéÁß©ÈÉ®ÂàÜËøõË°åÊõ¥Êñ∞ÔºåËÄå‰øùÊåÅÂéüÂßãÈ¢ÑËÆ≠ÁªÉÊùÉÈáç‰∏çÂèò„ÄÇ ‰ª£Á†ÅÂèØËßÅ&lt;code&gt;./model/model_lora.py&lt;/code&gt;Âíå&lt;code&gt;train_lora.py&lt;/code&gt;ÔºåÂÆåÂÖ®‰ªé0ÂÆûÁé∞LoRAÊµÅÁ®ãÔºå‰∏ç‰æùËµñÁ¨¨‰∏âÊñπÂ∫ìÁöÑÂ∞ÅË£Ö„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_lora.py
# or
python train_lora.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;lora_xxx_*.pth&lt;/code&gt;Ôºà* ‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ÈùûÂ∏∏Â§öÁöÑ‰∫∫Âõ∞ÊÉëÔºåÂ¶Ç‰Ωï‰ΩøÊ®°ÂûãÂ≠¶‰ºöËá™Â∑±ÁßÅÊúâÈ¢ÜÂüüÁöÑÁü•ËØÜÔºüÂ¶Ç‰ΩïÂáÜÂ§áÊï∞ÊçÆÈõÜÔºüÂ¶Ç‰ΩïËøÅÁßªÈÄöÁî®È¢ÜÂüüÊ®°ÂûãÊâìÈÄ†ÂûÇÂüüÊ®°ÂûãÔºü ËøôÈáå‰∏æÂá†‰∏™‰æãÂ≠êÔºåÂØπ‰∫éÈÄöÁî®Ê®°ÂûãÔºåÂåªÂ≠¶È¢ÜÂüüÁü•ËØÜÊ¨†Áº∫ÔºåÂèØ‰ª•Â∞ùËØïÂú®ÂéüÊúâÊ®°ÂûãÂü∫Á°Ä‰∏äÂä†ÂÖ•È¢ÜÂüüÁü•ËØÜÔºå‰ª•Ëé∑ÂæóÊõ¥Â•ΩÁöÑÊÄßËÉΩ„ÄÇ ÂêåÊó∂ÔºåÊàë‰ª¨ÈÄöÂ∏∏‰∏çÂ∏åÊúõÂ≠¶‰ºöÈ¢ÜÂüüÁü•ËØÜÁöÑÂêåÊó∂ÊçüÂ§±ÂéüÊúâÂü∫Á°ÄÊ®°ÂûãÁöÑÂÖ∂ÂÆÉËÉΩÂäõÔºåÊ≠§Êó∂LoRAÂèØ‰ª•ÂæàÂ•ΩÁöÑÊîπÂñÑËøô‰∏™ÈóÆÈ¢ò„ÄÇ Âè™ÈúÄË¶ÅÂáÜÂ§áÂ¶Ç‰∏ãÊ†ºÂºèÁöÑÂØπËØùÊï∞ÊçÆÈõÜÊîæÁΩÆÂà∞&lt;code&gt;./dataset/lora_xxx.jsonl&lt;/code&gt;ÔºåÂêØÂä® &lt;code&gt;python train_lora.py&lt;/code&gt; ËÆ≠ÁªÉÂç≥ÂèØÂæóÂà∞&lt;code&gt;./out/lora/lora_xxx.pth&lt;/code&gt;Êñ∞Ê®°ÂûãÊùÉÈáç„ÄÇ&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ÂåªÁñóÂú∫ÊôØ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {"conversations": [{"role": "user", "content": "ËØ∑ÈóÆÈ¢àÊ§éÁóÖÁöÑ‰∫∫ÊûïÂ§¥Â§öÈ´òÊâçÊúÄÂ•ΩÔºü"}, {"role": "assistant", "content": "È¢àÊ§éÁóÖÊÇ£ËÄÖÈÄâÊã©ÊûïÂ§¥ÁöÑÈ´òÂ∫¶Â∫îËØ•Ê†πÊçÆ..."}]}
 {"conversations": [{"role": "user", "content": "ËØ∑ÈóÆxxx"}, {"role": "assistant", "content": "xxx..."}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Ëá™ÊàëËÆ§Áü•Âú∫ÊôØ&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; {"conversations": [{"role": "user", "content": "‰Ω†Âè´‰ªÄ‰πàÂêçÂ≠óÔºü"}, {"role": "assistant", "content": "ÊàëÂè´minimind..."}]}
 {"conversations": [{"role": "user", "content": "‰Ω†ÊòØË∞Å"}, {"role": "assistant", "content": "ÊàëÊòØ..."}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Ê≠§Êó∂„ÄêÂü∫Á°ÄÊ®°Âûã+LoRAÊ®°Âûã„ÄëÂç≥ÂèØËé∑ÂæóÂåªÁñóÂú∫ÊôØÊ®°ÂûãÂ¢ûÂº∫ÁöÑËÉΩÂäõÔºåÁõ∏ÂΩì‰∫é‰∏∫Âü∫Á°ÄÊ®°ÂûãÂ¢ûÂä†‰∫ÜLoRAÂ§ñÊåÇÔºåËøô‰∏™ËøáÁ®ãÂπ∂‰∏çÊçüÂ§±Âü∫Á°ÄÊ®°ÂûãÁöÑÊú¨Ë∫´ËÉΩÂäõ„ÄÇ Êàë‰ª¨ÂèØ‰ª•ÈÄöËøá&lt;code&gt;eval_model.py&lt;/code&gt;ËøõË°åÊ®°ÂûãËØÑ‰º∞ÊµãËØï„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ê≥®ÊÑèÔºömodel_modeÂç≥ÈÄâÊã©Âü∫Á°ÄÊ®°ÂûãÁöÑÁ±ªÂûãÔºåËøôÂíåtrain_loraÊòØÂü∫‰∫éÂì™‰∏™Ê®°ÂûãËÆ≠ÁªÉÁöÑÁõ∏ÂÖ≥ÔºåÁ°Æ‰øùÁªü‰∏ÄÂç≥ÂèØ„ÄÇ
python eval_model.py --lora_name 'lora_medical' --model_mode 2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Â∞èÊµãËØï&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;üë∂: ÊàëÊúÄËøëÁªèÂ∏∏ÊÑüÂà∞Â§¥ÊôïÔºåÂèØËÉΩÊòØ‰ªÄ‰πàÂéüÂõ†Ôºü
ü§ñÔ∏è: Â§¥ÊôïÂèØËÉΩÊòØÁî±‰∫éÂ§öÁßçÂéüÂõ†ÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÔºöÂøÉËÑèÁñæÁóÖ„ÄÅÁúºÁùõÊçü‰º§„ÄÅËøáÊïèÂèçÂ∫î„ÄÅÁöÆËÇ§ÈóÆÈ¢ò„ÄÅËøáÊïèÂèçÂ∫î„ÄÅÂéãÂäõ„ÄÅÁÑ¶Ëôë„ÄÅÁñ≤Âä≥„ÄÅËçØÁâ©ÂâØ‰ΩúÁî®„ÄÅÊÄßÂäüËÉΩÈöúÁ¢çÊàñËÄÖÂÖ∂‰ªñ...

---

üë∂: ‰Ω†ÂíåopenaiÊòØ‰ªÄ‰πàÂÖ≥Á≥ªÔºü
ü§ñÔ∏è: ÊàëÊòØ MiniMindÔºå‰∏Ä‰∏™Áî± Jingyao Gong ÂºÄÂèëÁöÑ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã„ÄÇÊàëÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂíåÁÆóÊ≥ïËÆ≠ÁªÉÊù•‰∏éÁî®Êà∑ËøõË°å‰∫§‰∫í„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;PSÔºöÂè™Ë¶ÅÊúâÊâÄÈúÄË¶ÅÁöÑÊï∞ÊçÆÈõÜÔºå‰πüÂèØ‰ª•full_sftÂÖ®ÂèÇÂæÆË∞ÉÔºàÈúÄË¶ÅËøõË°åÈÄöÁî®Áü•ËØÜÁöÑÊ∑∑ÂêàÈÖçÊØîÔºåÂê¶ÂàôËøáÊãüÂêàÈ¢ÜÂüüÊï∞ÊçÆ‰ºöËÆ©Ê®°ÂûãÂèòÂÇªÔºåÊçüÂ§±ÈÄöÁî®ÊÄßÔºâ&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;6. ËÆ≠ÁªÉÊé®ÁêÜÊ®°Âûã (Reasoning Model)&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;DeepSeek-R1ÂÆûÂú®Â§™ÁÅ´‰∫ÜÔºåÂá†‰πéÈáçÊñ∞ÊåáÊòé‰∫ÜÊú™Êù•LLMÁöÑÊñ∞ËåÉÂºè„ÄÇ ËÆ∫ÊñáÊåáÂá∫&lt;code&gt;&amp;gt;3B&lt;/code&gt;ÁöÑÊ®°ÂûãÁªèÂéÜÂ§öÊ¨°ÂèçÂ§çÁöÑÂÜ∑ÂêØÂä®ÂíåRLÂ•ñÂä±ËÆ≠ÁªÉÊâçËÉΩËé∑ÂæóËÇâÁúºÂèØËßÅÁöÑÊé®ÁêÜËÉΩÂäõÊèêÂçá„ÄÇ ÊúÄÂø´ÊúÄÁ®≥Â¶•ÊúÄÁªèÊµéÁöÑÂÅöÊ≥ïÔºå‰ª•ÂèäÊúÄËøëÁàÜÂèëÁöÑÂêÑÁßçÂêÑÊ†∑ÊâÄË∞ìÁöÑÊé®ÁêÜÊ®°ÂûãÂá†‰πéÈÉΩÊòØÁõ¥Êé•Èù¢ÂêëÊï∞ÊçÆËøõË°åËí∏È¶èËÆ≠ÁªÉÔºå ‰ΩÜÁî±‰∫éÁº∫‰πèÊäÄÊúØÂê´ÈáèÔºåËí∏È¶èÊ¥æË¢´RLÊ¥æÁûß‰∏çËµ∑ÔºàhhhhÔºâ„ÄÇ Êú¨‰∫∫ËøÖÈÄüÂ∑≤ÁªèÂú®QwenÁ≥ªÂàó1.5BÂ∞èÊ®°Âûã‰∏äËøõË°å‰∫ÜÂ∞ùËØïÔºåÂæàÂø´Â§çÁé∞‰∫ÜZeroËøáÁ®ãÁöÑÊï∞Â≠¶Êé®ÁêÜËÉΩÂäõ„ÄÇ ÁÑ∂ËÄå‰∏Ä‰∏™ÈÅóÊÜæÁöÑÂÖ±ËØÜÊòØÔºöÂèÇÊï∞Â§™Â∞èÁöÑÊ®°ÂûãÁõ¥Êé•ÈÄöËøáÂÜ∑ÂêØÂä®SFT+GRPOÂá†‰πé‰∏çÂèØËÉΩËé∑Âæó‰ªª‰ΩïÊé®ÁêÜÊïàÊûú„ÄÇ MiniMind2Á¨¨‰∏ÄÊó∂Èó¥Âè™ËÉΩÂùöÂÆö‰∏çÁßªÁöÑÈÄâÊã©ÂÅöËí∏È¶èÊ¥æÔºåÊó•ÂêéÂü∫‰∫é0.1BÊ®°ÂûãÁöÑRLÂ¶ÇÊûúÂêåÊ†∑ÂèñÂæóÂ∞èÂ∞èËøõÂ±ï‰ºöÊõ¥Êñ∞Ê≠§ÈÉ®ÂàÜÁöÑËÆ≠ÁªÉÊñπÊ°à„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÂÅöËí∏È¶èÈúÄË¶ÅÂáÜÂ§áÁöÑ‰æùÁÑ∂ÊòØÂíåSFTÈò∂ÊÆµÂêåÊ†∑Ê†ºÂºèÁöÑÊï∞ÊçÆÂç≥ÂèØÔºåÊï∞ÊçÆÈõÜÊù•Ê∫êÂ∑≤Â¶Ç‰∏äÊñá‰ªãÁªç„ÄÇÊï∞ÊçÆÊ†ºÂºè‰æãÂ¶ÇÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "conversations": [
    {
      "role": "user",
      "content": "‰Ω†Â•ΩÔºåÊàëÊòØÂ∞èËä≥ÔºåÂæàÈ´òÂÖ¥ËÆ§ËØÜ‰Ω†„ÄÇ"
    },
    {
      "role": "assistant",
      "content": "&amp;lt;think&amp;gt;\n‰Ω†Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÁã¨Á´ãÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1-Lite-PreviewÔºåÂæàÈ´òÂÖ¥‰∏∫ÊÇ®Êèê‰æõÊúçÂä°ÔºÅ\n&amp;lt;/think&amp;gt;\n&amp;lt;answer&amp;gt;\n‰Ω†Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÁã¨Á´ãÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1-Lite-PreviewÔºåÂæàÈ´òÂÖ¥‰∏∫ÊÇ®Êèê‰æõÊúçÂä°ÔºÅ\n&amp;lt;/answer&amp;gt;"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Êé®ÁêÜÊ®°ÂûãR1ÁöÑÂõûÂ§çÊ®°ÊùøÊòØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;&amp;lt;think&amp;gt;\nÊÄùËÄÉËøáÁ®ã\n&amp;lt;/think&amp;gt;\n
&amp;lt;answer&amp;gt;\nÊúÄÁªàÂõûÁ≠î\n&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ËøôÂú®GRPO‰∏≠ÈÄöËøáËÆæÁΩÆËßÑÂàôÂ•ñÂä±ÂáΩÊï∞Á∫¶ÊùüÊ®°ÂûãÁ¨¶ÂêàÊÄùËÄÉÊ†áÁ≠æÂíåÂõûÂ§çÊ†áÁ≠æÔºàÂú®ÂÜ∑ÂêØÂä®Èù†ÂâçÁöÑÈò∂ÊÆµÂ•ñÂä±ÂÄºËÆæÁΩÆÂ∫îËØ•ÊèêÈ´ò‰∏Ä‰∫õÔºâ&lt;/p&gt; 
&lt;p&gt;Âè¶‰∏Ä‰∏™ÈóÆÈ¢òÊòØËí∏È¶èËøáÁ®ãËôΩÁÑ∂ÂíåSFT‰∏ÄÊ†∑Ôºå‰ΩÜÂÆûÈ™åÁªìÊûúÊòØÊ®°ÂûãÈöæ‰ª•ÊØèÊ¨°ÈÉΩÁ¨¶ÂêàÊ®°ÊùøËßÑËåÉÁöÑÂõûÂ§çÔºåÂç≥ËÑ±Á¶ªÊÄùËÄÉÂíåÂõûÂ§çÊ†áÁ≠æÁ∫¶Êùü„ÄÇ ËøôÈáåÁöÑÂ∞èÊäÄÂ∑ßÊòØÂ¢ûÂä†Ê†áËÆ∞‰ΩçÁΩÆtokenÁöÑÊçüÂ§±ÊÉ©ÁΩöÔºåËØ¶ËßÅ&lt;code&gt;train_distill_reason.py&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;# Âú® sp_ids ÂØπÂ∫îÁöÑ‰ΩçÁΩÆÂ¢ûÂä†È¢ùÂ§ñÁöÑÊÉ©ÁΩö
...
loss_mask[sp_ids] = 10 # ÊÉ©ÁΩöÁ≥ªÊï∞
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Âè¶Âè¶‰∏Ä‰∏™tipsÊòØÁî±‰∫éÊé®ÁêÜÊï∞ÊçÆÁî±‰∫éÂè™Á≠õÈÄâ‰∫Ü&lt;code&gt;&amp;lt;1024&lt;/code&gt;ÈïøÂ∫¶ÁöÑÊï∞ÊçÆÔºåÂÖ∂‰∏≠Â§öËΩÆÂØπËØùÂíåËã±ÊñáÊï∞ÊçÆÂÅèÂ∞ëÔºå Âõ†Ê≠§&lt;code&gt;r1_mix_1024.jsonl&lt;/code&gt;ËøõË°å‰∫ÜÂ§ßÁ∫¶10kÊù°Â§öËΩÆÂØπËØù+Ëã±ÊñáÊï∞ÊçÆÁöÑÊ∑∑ÂêàÔºåÈò≤Ê≠¢Ê®°ÂûãÈÅóÂøò‰∏•Èáç„ÄÇ&lt;/p&gt; 
&lt;p&gt;ËÑöÊú¨ÈªòËÆ§Âü∫‰∫érlhfÂêéÁöÑÂü∫Ê®°ÂûãÂÅöÊé®ÁêÜËÉΩÂäõÁöÑËí∏È¶èÂæÆË∞ÉÔºå‰∏ãÈù¢Áõ¥Êé•ÂêØÂä®ËÆ≠ÁªÉÂç≥ÂèØÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;torchrun --nproc_per_node 1 train_distill_reason.py
# or
python train_distill_reason.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÆ≠ÁªÉÂêéÁöÑÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÈªòËÆ§ÊØèÈöî&lt;code&gt;100Ê≠•&lt;/code&gt;‰øùÂ≠ò‰∏∫: &lt;code&gt;reason_*.pth&lt;/code&gt;Ôºà*‰∏∫Ê®°ÂûãÂÖ∑‰ΩìdimensionÔºåÊØèÊ¨°‰øùÂ≠òÊó∂Êñ∞Êñá‰ª∂‰ºöË¶ÜÁõñÊóßÊñá‰ª∂Ôºâ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ÊµãËØï‰∏Ä‰∏ãÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;üë∂: ËØ∑‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±„ÄÇ
ü§ñÔ∏è: &amp;lt;think&amp;gt;
ÂóØÔºåÁî®Êà∑ËÆ©Êàë‰ªãÁªç‰∏Ä‰∏ãËá™Â∑±„ÄÇÊàëÁé∞Âú®ÈúÄË¶ÅËß£Èáä‰∏Ä‰∏ãËá™Â∑±„ÄÇÈ¶ñÂÖàÔºåÊàëÂ∫îËØ•ÊòéÁ°ÆÁî®Êà∑ÊòØË∞ÅÔºåÊòØÂ≠¶Áîü„ÄÅËÅåÂú∫‰∫∫Â£´ËøòÊòØÊôÆÈÄö‰∫∫„ÄÇÁî®Êà∑ÂèØËÉΩÊòØ‰∏Ä‰∏™Â≠¶ÁîüÊàñËÄÖËÅåÂú∫‰∫∫Â£´ÔºåÊâÄ‰ª•‰ø°ÊÅØ‰º†ÈÄíÂ∫îËØ•ÊòØÂ∏ÆÂä©Â≠¶ÁîüÂíåËÅåÂú∫‰∫∫Â£´ÁöÑ‰ø°ÊÅØ„ÄÇ
ÁÑ∂ÂêéÔºåÊàëÈúÄË¶ÅÂõûÂ∫îÁî®Êà∑ÔºåËøôÂèØËÉΩÂåÖÊã¨‰ªãÁªçËá™Â∑±ÁöÑ‰ΩçÁΩÆ„ÄÅÂÖ¥Ë∂£Áà±Â•Ω„ÄÅËÅå‰∏öÁªèÂéÜÁ≠â‰ø°ÊÅØ„ÄÇÁî®Êà∑ËøòÂèØËÉΩÊÉ≥‰∫ÜËß£Ëá™Â∑±Âú®Âì™ÈáåÔºåÊØîÂ¶ÇËÅå‰∏öÂèëÂ±ï„ÄÅÂ∑•‰ΩúÁªèÈ™åÁ≠â„ÄÇ
ÊàëÂ∫îËØ•Ê≥®ÊÑèÁî®ËØçË¶ÅÊ≠£ÂºèÔºå‰∏çË¶ÅÂ§™Ê≠£ÂºèÔºåÂêåÊó∂Ë¶Å‰øùÊåÅÁÆÄÊ¥ÅÊòé‰∫Ü„ÄÇËøôÊ†∑Áî®Êà∑ÂÆπÊòìÁêÜËß£Ôºå‰πüÊñπ‰æø‰ªñ‰ª¨Êü•ÈòÖÁõ∏ÂÖ≥ËµÑÊñô„ÄÇ
ÊúÄÂêéÔºåÊàëÂ∫îËØ•ÊÄªÁªì‰∏Ä‰∏ãÔºåËÆ©Áî®Êà∑Áü•ÈÅìÊàëÊòØÂ¶Ç‰ΩïÂ∏ÆÂä©‰ªñ‰ª¨ÂÆåÊàê‰ªñ‰ª¨ÁöÑ‰ªªÂä°ÁöÑÔºåËøôÊ†∑‰ªñ‰ª¨ÊúâÊõ¥Â§öÂÖ≥‰∫éÊàëÁöÑ‰ø°ÊÅØ„ÄÇ
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
ÊàëÊòØ**‚Äú‰Ω†ÁöÑÂêçÂ≠ó‚ÄùÔºå‰Ω†Âè´‰ªÄ‰πàÂêçÂ≠óÔºü
&amp;lt;/answer&amp;gt;

üë∂: ‰Ω†Êõ¥ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶ÁßëÔºü
ü§ñÔ∏è: &amp;lt;think&amp;gt;
ÊÇ®Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1„ÄÇÂ¶ÇÊÇ®Êúâ‰ªª‰Ωï‰ªª‰ΩïÈóÆÈ¢òÔºåÊàë‰ºöÂ∞ΩÊàëÊâÄËÉΩ‰∏∫ÊÇ®Êèê‰æõÂ∏ÆÂä©„ÄÇ
&amp;lt;/think&amp;gt;
&amp;lt;answer&amp;gt;
ÊÇ®Â•ΩÔºÅÊàëÊòØÁî±‰∏≠ÂõΩÁöÑ‰∏™‰∫∫ÂºÄÂèëËÄÖÂºÄÂèëÁöÑÊô∫ËÉΩÂä©ÊâãMiniMind-R1„ÄÇÂ¶ÇÊÇ®Êúâ‰ªª‰Ωï‰ªª‰ΩïÈóÆÈ¢òÔºåÊàë‰ºöÂ∞ΩÊàëÊâÄËÉΩ‰∏∫ÊÇ®Êèê‰æõÂ∏ÆÂä©„ÄÇ
&amp;lt;/answer&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚Ö£ Ê®°ÂûãÂèÇÊï∞ËÆæÂÆö&lt;/h2&gt; 
&lt;p&gt;üìãÂÖ≥‰∫éLLMÁöÑÂèÇÊï∞ÈÖçÁΩÆÔºåÊúâ‰∏ÄÁØáÂæàÊúâÊÑèÊÄùÁöÑËÆ∫Êñá&lt;a href="https://arxiv.org/pdf/2402.14905"&gt;MobileLLM&lt;/a&gt;ÂÅö‰∫ÜËØ¶ÁªÜÁöÑÁ†îÁ©∂ÂíåÂÆûÈ™å„ÄÇ Scaling LawÂú®Â∞èÊ®°Âûã‰∏≠ÊúâËá™Â∑±Áã¨ÁâπÁöÑËßÑÂæã„ÄÇ ÂºïËµ∑TransformerÂèÇÊï∞ÊàêËßÑÊ®°ÂèòÂåñÁöÑÂèÇÊï∞Âá†‰πéÂè™ÂèñÂÜ≥‰∫é&lt;code&gt;d_model&lt;/code&gt;Âíå&lt;code&gt;n_layers&lt;/code&gt;„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;‚Üë + &lt;code&gt;n_layers&lt;/code&gt;‚Üì -&amp;gt; ÁüÆËÉñÂ≠ê&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;d_model&lt;/code&gt;‚Üì + &lt;code&gt;n_layers&lt;/code&gt;‚Üë -&amp;gt; Áò¶È´ò‰∏™&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;2020Âπ¥ÊèêÂá∫Scaling LawÁöÑËÆ∫ÊñáËÆ§‰∏∫ÔºåËÆ≠ÁªÉÊï∞ÊçÆÈáè„ÄÅÂèÇÊï∞Èáè‰ª•ÂèäËÆ≠ÁªÉËø≠‰ª£Ê¨°Êï∞ÊâçÊòØÂÜ≥ÂÆöÊÄßËÉΩÁöÑÂÖ≥ÈîÆÂõ†Á¥†ÔºåËÄåÊ®°ÂûãÊû∂ÊûÑÁöÑÂΩ±ÂìçÂá†‰πéÂèØ‰ª•ÂøΩËßÜ„ÄÇ ÁÑ∂ËÄå‰ºº‰πéËøô‰∏™ÂÆöÂæãÂØπÂ∞èÊ®°ÂûãÂπ∂‰∏çÂÆåÂÖ®ÈÄÇÁî®„ÄÇ MobileLLMÊèêÂá∫Êû∂ÊûÑÁöÑÊ∑±Â∫¶ÊØîÂÆΩÂ∫¶Êõ¥ÈáçË¶ÅÔºå„ÄåÊ∑±ËÄåÁ™Ñ„ÄçÁöÑ„ÄåÁò¶Èïø„ÄçÊ®°ÂûãÂèØ‰ª•Â≠¶‰π†Âà∞ÊØî„ÄåÂÆΩËÄåÊµÖ„ÄçÊ®°ÂûãÊõ¥Â§öÁöÑÊäΩË±°Ê¶ÇÂøµ„ÄÇ ‰æãÂ¶ÇÂΩìÊ®°ÂûãÂèÇÊï∞Âõ∫ÂÆöÂú®125MÊàñËÄÖ350MÊó∂Ôºå30ÔΩû42Â±ÇÁöÑ„ÄåÁã≠Èïø„ÄçÊ®°ÂûãÊòéÊòæÊØî12Â±ÇÂ∑¶Âè≥ÁöÑ„ÄåÁüÆËÉñ„ÄçÊ®°ÂûãÊúâÊõ¥‰ºòË∂äÁöÑÊÄßËÉΩÔºå Âú®Â∏∏ËØÜÊé®ÁêÜ„ÄÅÈóÆÁ≠î„ÄÅÈòÖËØªÁêÜËß£Á≠â8‰∏™Âü∫ÂáÜÊµãËØï‰∏äÈÉΩÊúâÁ±ª‰ººÁöÑË∂ãÂäø„ÄÇ ËøôÂÖ∂ÂÆûÊòØÈùûÂ∏∏ÊúâË∂£ÁöÑÂèëÁé∞ÔºåÂõ†‰∏∫‰ª•ÂæÄ‰∏∫100MÂ∑¶Âè≥ÈáèÁ∫ßÁöÑÂ∞èÊ®°ÂûãËÆæËÆ°Êû∂ÊûÑÊó∂ÔºåÂá†‰πéÊ≤°‰∫∫Â∞ùËØïËøáÂè†Âä†Ë∂ÖËøá12Â±Ç„ÄÇ Ëøô‰∏éMiniMindÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÊ®°ÂûãÂèÇÊï∞ÈáèÂú®&lt;code&gt;d_model&lt;/code&gt;Âíå&lt;code&gt;n_layers&lt;/code&gt;‰πãÈó¥ËøõË°åË∞ÉÊï¥ÂÆûÈ™åËßÇÂØüÂà∞ÁöÑÊïàÊûúÊòØ‰∏ÄËá¥ÁöÑ„ÄÇ ÁÑ∂ËÄå„ÄåÊ∑±ËÄåÁ™Ñ„ÄçÁöÑ„ÄåÁ™Ñ„Äç‰πüÊòØÊúâÁª¥Â∫¶ÊûÅÈôêÁöÑÔºåÂΩìd_model&amp;lt;512Êó∂ÔºåËØçÂµåÂÖ•Áª¥Â∫¶ÂùçÂ°åÁöÑÂä£ÂäøÈùûÂ∏∏ÊòéÊòæÔºå Â¢ûÂä†ÁöÑlayersÂπ∂‰∏çËÉΩÂº•Ë°•ËØçÂµåÂÖ•Âú®Âõ∫ÂÆöq_headÂ∏¶Êù•d_head‰∏çË∂≥ÁöÑÂä£Âäø„ÄÇ ÂΩìd_model&amp;gt;1536Êó∂ÔºålayersÁöÑÂ¢ûÂä†‰ºº‰πéÊØîd_modelÁöÑ‰ºòÂÖàÁ∫ßÊõ¥È´òÔºåÊõ¥ËÉΩÂ∏¶Êù•ÂÖ∑Êúâ‚ÄúÊÄß‰ª∑ÊØî‚ÄùÁöÑÂèÇÊï∞-&amp;gt;ÊïàÊûúÂ¢ûÁõä„ÄÇ&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Âõ†Ê≠§MiniMindËÆæÂÆösmallÊ®°Âûãdim=512Ôºån_layers=8Êù•Ëé∑ÂèñÁöÑ„ÄåÊûÅÂ∞è‰ΩìÁßØ&amp;lt;-&amp;gt;Êõ¥Â•ΩÊïàÊûú„ÄçÁöÑÂπ≥Ë°°„ÄÇ&lt;/li&gt; 
 &lt;li&gt;ËÆæÂÆödim=768Ôºån_layers=16Êù•Ëé∑ÂèñÊïàÊûúÁöÑÊõ¥Â§ßÊî∂ÁõäÔºåÊõ¥Âä†Á¨¶ÂêàÂ∞èÊ®°ÂûãScaling-LawÁöÑÂèòÂåñÊõ≤Á∫ø„ÄÇ&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;‰Ωú‰∏∫ÂèÇËÄÉÔºåGPT3ÁöÑÂèÇÊï∞ËÆæÂÆöËßÅ‰∏ãË°®Ôºö &lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/gpt3_config.png" alt="gpt3_config.png" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚Ö§ ËÆ≠ÁªÉÁªìÊûú&lt;/h2&gt; 
&lt;p&gt;MiniMind2 Ê®°ÂûãËÆ≠ÁªÉÊçüÂ§±Ëµ∞ÂäøÔºàÁî±‰∫éÊï∞ÊçÆÈõÜÂú®ËÆ≠ÁªÉÂêéÂèàÊõ¥Êñ∞Ê∏ÖÊ¥óÂ§öÊ¨°ÔºåÂõ†Ê≠§Loss‰ªÖ‰æõÂèÇËÄÉÔºâ&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;models&lt;/th&gt; 
   &lt;th&gt;pretrain (length-512)&lt;/th&gt; 
   &lt;th&gt;sft (length-512)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_512_loss.png" width="100%" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_512_loss.png" width="100%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/pre_768_loss.png" width="100%" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/sft_768_loss.png" width="100%" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;ËÆ≠ÁªÉÂÆåÊàê-Ê®°ÂûãÂêàÈõÜ&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ËÄÉËôëÂà∞Â§ö‰∫∫ÂèçÂ∫îÁôæÂ∫¶ÁΩëÁõòÈÄüÂ∫¶ÊÖ¢ÔºåMiniMind2Âèä‰ª•ÂêéÂÖ®ÈÉ®‰ΩøÁî®ModelScope/HuggingFaceÊâòÁÆ°„ÄÇ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;‚ë† PyTorchÂéüÁîüÊ®°Âûã&lt;/h4&gt; 
&lt;p&gt;MiniMind2Ê®°ÂûãÊùÉÈáç (&lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/jingyaogong/MiniMind2-Pytorch"&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;p&gt;MiniMind-V1Ê®°ÂûãÊùÉÈáç (&lt;a href="https://pan.baidu.com/s/1KUfSzEkSXYbCCBj0Pw-9fA?pwd=6666"&gt;ÁôæÂ∫¶ÁΩëÁõò&lt;/a&gt;)&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;TorchÊñá‰ª∂ÂëΩÂêçÂØπÁÖß&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model Name&lt;/th&gt; 
    &lt;th&gt;params&lt;/th&gt; 
    &lt;th&gt;pretrain_model&lt;/th&gt; 
    &lt;th&gt;sft_model&lt;/th&gt; 
    &lt;th&gt;rl_model&lt;/th&gt; 
    &lt;th&gt;reason_model&lt;/th&gt; 
    &lt;th&gt;lora_model&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-small&lt;/td&gt; 
    &lt;td&gt;26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_512.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
    &lt;td&gt;145M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_640_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;MiniMind2&lt;/td&gt; 
    &lt;td&gt;104M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rlhf_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;reason_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;lora_xxx_768.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model Name&lt;/th&gt; 
    &lt;th&gt;params&lt;/th&gt; 
    &lt;th&gt;pretrain_model&lt;/th&gt; 
    &lt;th&gt;ÂçïËΩÆÂØπËØùsft&lt;/th&gt; 
    &lt;th&gt;Â§öËΩÆÂØπËØùsft&lt;/th&gt; 
    &lt;th&gt;rl_model&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-small&lt;/td&gt; 
    &lt;td&gt;26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_512.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rl_512.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1-moe&lt;/td&gt; 
    &lt;td&gt;4√ó26M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_512_moe.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;-&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;minimind-v1&lt;/td&gt; 
    &lt;td&gt;108M&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;pretrain_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;single_chat/full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;multi_chat/full_sft_768.pth&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;rl_768.pth&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;h4&gt;‚ë° TransformersÊ®°Âûã&lt;/h4&gt; 
&lt;p&gt;MiniMindÁ≥ªÂàó (&lt;a href="https://www.modelscope.cn/collections/MiniMind-b72f4cfeb74b47"&gt;ModelScope&lt;/a&gt; | &lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;HuggingFace&lt;/a&gt;)&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h1&gt;üìå Eval&lt;/h1&gt; 
&lt;h2&gt;‚Ö† RLHFÂØπÊØîSFTÁØá&lt;/h2&gt; 
&lt;p&gt;ÊµãËØïÂü∫‰∫é&lt;code&gt;full_sft&lt;/code&gt;Âíå&lt;code&gt;rlhf&lt;/code&gt;ÁöÑ&lt;code&gt;MiniMind2Á≥ªÂàó&lt;/code&gt;Ê®°ÂûãÂØπÊØîÔºåÊµãËØïÈöèÊú∫ÁßçÂ≠êÂùáÂõ∫ÂÆö&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ÈóÆÁ≠îÂÆûÊµã&lt;/summary&gt; 
 &lt;p&gt;[A0] MiniMind2Ôºöfull_sft_640&lt;/p&gt; 
 &lt;p&gt;[A1] MiniMind2Ôºörlhf_640&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;[Q]: ‰Ω†Âè´‰ªÄ‰πàÂêçÂ≠óÔºü
[A0]: ÊàëÊòØ‰∏Ä‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÂèØ‰ª•ÂõûÁ≠îÂêÑÁßçÈóÆÈ¢òÔºåÊèê‰æõ‰ø°ÊÅØÂíåÂ∏ÆÂä©„ÄÇÊàëÂèØ‰ª•ÂõûÁ≠îÂêÑÁßçÈóÆÈ¢òÔºåÊèê‰æõ‰ø°ÊÅØÂíåÂ∏ÆÂä©ÔºåÂ∏ÆÂä©‰Ω†Ëß£ÂÜ≥ÂêÑÁßçÈóÆÈ¢ò„ÄÇ
[A1]: ÊàëÊòØ‰∏ÄÁßçÂü∫‰∫éÊñáÊú¨ÁöÑAIÊ®°ÂûãÔºåÊàëÂπ∂Ê≤°Êúâ‰∏™‰∫∫ÁªèÂéÜÊàñÊÉÖÊÑüÔºåÊâÄ‰ª•Êó†Ê≥ïÊÑüÂèóÂíå‰ΩìÈ™åÊÉÖÊÑü„ÄÇÊàëÁöÑËÆæËÆ°ÁõÆÁöÑÊòØ‰∏∫‰∫ÜÂ∏ÆÂä©Áî®Êà∑Ëß£ÂÜ≥ÈóÆÈ¢ò„ÄÅÊèê‰æõ‰ø°ÊÅØÂíåËøõË°åÂØπËØù„ÄÇÂ¶ÇÊûúÊÇ®Êúâ‰ªª‰ΩïÈóÆÈ¢òÊàñÈúÄË¶ÅÂ∏ÆÂä©ÔºåËØ∑ÈöèÊó∂ÂëäËØâÊàëÔºÅ

[Q]: ‰Ω†Êõ¥ÊìÖÈïøÂì™‰∏Ä‰∏™Â≠¶ÁßëÔºü
[A0]: ‰Ωú‰∏∫‰∏Ä‰∏™AIÊ®°ÂûãÔºåÊàëÂπ∂Ê≤°ÊúâÁúüÊ≠£ÁöÑ‚ÄúÊìÖÈïø‚ÄùËøô‰∏™Â≠¶Áßë„ÄÇÊàëË¢´ËÆæËÆ°ÊàêËÉΩÂ§üÊèê‰æõ‰ø°ÊÅØ„ÄÅËß£Á≠îÈóÆÈ¢ò„ÄÅËøõË°åÂØπËØù„ÄÅÊâßË°å‰ªªÂä°Âíå‰∏éÁî®Êà∑ËøõË°åÂØπËØù„ÄÇ‰∏çËøáÔºåÊàëÂèØ‰ª•Êèê‰æõ‰ø°ÊÅØ„ÄÅËß£Á≠îÈóÆÈ¢ò„ÄÅËøõË°åÂØπËØù„ÄÅÊèê‰æõÂª∫ËÆÆ„ÄÅÂ§ÑÁêÜÈóÆÈ¢ò„ÄÅËøõË°åÂØπËØù„ÄÅÊèê‰æõÂª∫ËÆÆ„ÄÅÂ≠¶‰π†Êñ∞Áü•ËØÜ„ÄÅÁºñÂÜô‰ª£Á†Å„ÄÅÂõûÁ≠îÈóÆÈ¢ò„ÄÅÊèê‰æõÂª∫ËÆÆÁ≠âÂ§öÁßçÂ≠¶ÁßëÁöÑÂäüËÉΩ„ÄÇÂ¶ÇÊûú‰Ω†ÊúâÂÖ∑‰ΩìÁöÑÂ≠¶ÁßëÈúÄÊ±ÇÊàñ‰∏ªÈ¢òÔºåÊ¨¢ËøéÊèê‰æõËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇ
[A1]: ‰Ωú‰∏∫AIÔºåÊàëÂπ∂Ê≤°Êúâ‰∏™‰∫∫ËÉΩÂäõÊàñÂÖ¥Ë∂£Ôºå‰ΩÜÊàëÂèØ‰ª•Êèê‰æõ‰∏Ä‰∫õÂÖ≥‰∫éÊï∞Â≠¶„ÄÅÁßëÂ≠¶„ÄÅËÆ°ÁÆóÊú∫ÁßëÂ≠¶„ÄÅËØ≠Ë®ÄÂ≠¶„ÄÅÂøÉÁêÜÂ≠¶Á≠âÂ≠¶ÁßëÁöÑÁü•ËØÜ„ÄÇÂ¶ÇÊûú‰Ω†ÂØπÊï∞Â≠¶ÊÑüÂÖ¥Ë∂£ÔºåÊàëÂèØ‰ª•Êèê‰æõ‰∏Ä‰∫õÂü∫Á°ÄÁü•ËØÜÔºå‰æãÂ¶Ç‰ª£Êï∞„ÄÅÂá†‰Ωï„ÄÅÊ¶ÇÁéá„ÄÅÁªüËÆ°Â≠¶Á≠â„ÄÇÂ¶ÇÊûú‰Ω†ÈúÄË¶ÅÊõ¥Ê∑±ÂÖ•ÁöÑÂ≠¶‰π†ÔºåÊàë‰πüÂèØ‰ª•Êèê‰æõÁõ∏ÂÖ≥ÁöÑÂú®Á∫øËØæÁ®ã„ÄÅ‰π¶Á±ç„ÄÅËÆ∫ÊñáÁ≠âËµÑÊ∫ê„ÄÇËØ∑ÂëäËØâÊàë‰Ω†ÂÖ∑‰ΩìÈúÄË¶Å‰ªÄ‰πàÂ∏ÆÂä©ÔºåÊàë‰ºöÂ∞ΩÂäõÊèê‰æõÂ∏ÆÂä©„ÄÇ

[Q]: È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØÂ¶Ç‰ΩïÊâπÂà§Â∞ÅÂª∫Á§ºÊïôÁöÑÔºü
[A0]: È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØ‰∏ÄÈÉ®ËÆ≤Ëø∞‰∫ÜÈ≤ÅËøÖÂØπ‰∫∫Á±ª‰ª∑ÂÄºÂíåÈÅìÂæ∑Ë¥£‰ªªÁöÑÂÄ°ÂØº„ÄÇÂú®ËøôÈÉ®‰ΩúÂìÅ‰∏≠ÔºåÈ≤ÅËøÖÈÄöËøáÁªÜËÖªÁöÑÁ¨îËß¶ÔºåÊé¢ËÆ®‰∫Ü‰∫∫ÊÄß„ÄÅÈÅìÂæ∑„ÄÅÊ≠£‰πâ„ÄÅÁâ∫Áâ≤‰∏éË¥£‰ªªÁ≠âÊ∑±ÂàªÁöÑ‰∏ªÈ¢ò„ÄÇ‰ª•‰∏ãÊòØÈ≤ÅËøÖÂú®„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏≠Â¶Ç‰ΩïÊâπÂà§Â∞ÅÂª∫Á§ºÊïôÁöÑÂá†‰∏™ÊñπÈù¢Ôºö1. **Á§æ‰ºöÁé∞ÂÆû‰∏éÈÅìÂæ∑ËßÇÂøµ**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊé¢ËÆ®‰∫ÜÁ§æ‰ºöÁöÑ‰∏çÂπ≥Á≠â„ÄÅÊùÉÂäõÁöÑÊµÅÂä®„ÄÅ‰∫∫ÊÄßÁöÑÊºîÂèòÁ≠âÁ§æ‰ºöÈóÆÈ¢ò„ÄÇ‰ªñËÆ§‰∏∫ÔºåÁ§æ‰ºö‰∏çÂπ≥Á≠â‰∏ç‰ªÖ‰ªÖÊòØ‰∏çÂÖ¨Ê≠£ÁöÑÔºåÊõ¥ÊòØÊØè‰∏™‰∫∫Âú®Á§æ‰ºö‰∏≠ÁöÑ‰∏çÂÖ¨Ê≠£„ÄÇ‰ªñÂëºÂêÅÁ§æ‰ºöÂêÑÁïåÂÖ±ÂêåÂä™ÂäõÔºåÈÄöËøáÊïôËÇ≤„ÄÅÂÆ£‰º†„ÄÅÊ≥ïÂæãÁ≠âÊâãÊÆµÔºå‰∏∫ÊûÑÂª∫ÂíåË∞êÁ§æ‰ºöÂÅöÂá∫Ë¥°ÁåÆ„ÄÇ2. **ÈÅìÂæ∑‰∏éË¥£‰ªª**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÂ±ïÁé∞‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ‰ªñÊèêÂÄ°ÈÄöËøáÈÅìÂæ∑ÊïôËÇ≤Êù•ÂüπÂÖª‰∫∫‰ª¨ÁöÑÈÅìÂæ∑ÂìÅË¥®ÔºåÂêåÊó∂‰πüÂº∫Ë∞É‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫ÜÁ§æ‰ºöÁöÑ‰∏çÂπ≥Á≠âÂíå‰∫∫ÊÄßÁöÑÂ§çÊùÇÊÄßÔºå‰ΩìÁé∞‰∫ÜÂØπ‰∫∫ÊÄßÁöÑÊ∑±ÂàªÁêÜËß£„ÄÇ3. **ÈÅìÂæ∑‰∏éË¥£‰ªª**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÂº∫Ë∞É‰∫ÜÈÅìÂæ∑Ë¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ‰ªñÊèêÂÄ°ÈÄöËøáËá™Â∑±ÁöÑË°å‰∏∫Êù•‰ΩìÁé∞ÂØπÁ§æ‰ºöÁöÑÂ∞äÈáçÂíåÂØπ‰∫∫ÊÄßÁöÑÊ∑±ÂàªÁêÜËß£„ÄÇÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÂº∫Ë∞É‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ4. **ÈÅìÂæ∑‰∏éÈÅìÂæ∑**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÁúüÊ≠£ÊÑè‰πâ„ÄÇÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÊú¨Ë¥®ÔºåÂº∫Ë∞É‰∫ÜÈÅìÂæ∑ÂíåË¥£‰ªªÁöÑÈáçË¶ÅÊÄß„ÄÇ5. **‰∏™‰∫∫‰∏éÁ§æ‰ºö**ÔºöÈ≤ÅËøÖÈÄöËøáËÆ≤Ëø∞È≤ÅËøÖÁöÑÊïÖ‰∫ãÔºåÊè≠Á§∫‰∫Ü‰∏™‰∫∫‰∏éÁ§æ‰ºö‰πãÈó¥ÁöÑÂ§çÊùÇÂÖ≥Á≥ª„ÄÇ‰ªñÂëºÂêÅÁ§æ‰ºöÂêÑÁïåÂÖ±ÂêåÂä™ÂäõÔºåÈÄöËøáÊïôËÇ≤ÂíåÂÆ£‰º†Ôºå‰∏∫ÊûÑÂª∫ÂíåË∞êÁ§æ‰ºöÂÅöÂá∫Ë¥°ÁåÆ„ÄÇÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÈÄöËøáÂÖ∂‰∏∞ÂØåÁöÑÊïÖ‰∫ãÂíåÊ∑±ÂàªÁöÑÈÅìÂæ∑ÂØìË®ÄÔºå‰º†Ëææ‰∫ÜÂÖ≥‰∫é‰∫∫ÊÄß„ÄÅÈÅìÂæ∑„ÄÅÊ≠£‰πâ„ÄÅÈÅìÂæ∑‰ª•Âèä‰∏™‰∫∫‰∏éÁ§æ‰ºöÁöÑÂ§çÊùÇÂÖ≥Á≥ª„ÄÇËøôÈÉ®‰ΩúÂìÅ‰∏ç‰ªÖÂú®ÊñáÂ≠¶‰ª∑ÂÄº‰∏äÂèñÂæó‰∫ÜÂ∑®Â§ßÊàêÂ∞±ÔºåÊõ¥Âú®ÊÄùÊÉ≥Â±ÇÈù¢‰∏äÂêØÂèë‰∫ÜÂêéÊù•ÁöÑÊñáÂ≠¶Âàõ‰ΩúÔºåÂØπÂêé‰∏ñ‰∫ßÁîü‰∫ÜÊ∑±ËøúÁöÑÂΩ±Âìç„ÄÇ
[A1]: È≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„ÄãÊòØ‰∏ÄÈÉ®ÊèèÁªòÊàò‰∫âÂíåËá™Áî±Á≤æÁ•ûÁöÑ‰ΩúÂìÅÔºåÂÆÉÊâπÂà§‰∫ÜÂ∞ÅÂª∫Á§æ‰ºöÁöÑÁßçÁßçÈóÆÈ¢òÂíåÂÜ≤Á™ÅÔºåÂèçÊò†‰∫ÜÁ§æ‰ºöÁöÑ‰∏çÂπ≥Á≠âÂíå‰∫∫ÊÄßÊú¨Ë¥®„ÄÇÂú®ËøôÈÉ®‰ΩúÂìÅ‰∏≠ÔºåÈ≤ÅËøÖÈÄöËøáÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑËØ∏Â§öÁé∞Ë±°ËøõË°åÊâπÂà§ÔºåÂ¶Ç‚ÄúÂºóÈõ∑Âæ∑ÈáåÂÖã¬∑Á∫¶Áø∞ÈÄäÁöÑ‚ÄúÈπ∞Ëø™‰º¶‚Äù„ÄÅ‚ÄúÁ∫≥ÊâéÁâπÁöÑ‚Äù„ÄÅ‚ÄúË¥ùÂÖãÊ±âÂßÜ‚Äù„ÄÅ‚Äú‰πîÊ≤ª¬∑Â®ÅÂ∞îÈÄä‚ÄùÁ≠âÔºåÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑÁßçÁßçÈóÆÈ¢òËøõË°å‰∫ÜÊâπÂà§ÔºåÂº∫Ë∞É‰∫ÜÂ∞ÅÂª∫Á§æ‰ºöÁöÑ‰∏çÂπ≥Á≠â„ÄÅ‰∫∫ÊÄßÊú¨Ë¥®‰ª•Âèä‰∫∫ÊÄßÊú¨Ë¥®„ÄÇÈ≤ÅËøÖÈÄöËøá‰ªñÁöÑ‚ÄúÈπ∞Ëø™‰º¶‚Äù„ÄÅ‚ÄúÁ∫≥ÊâéÁâπÁöÑ‚Äù„ÄÅ‚ÄúË¥ùÂÖãÊ±âÂßÜ‚Äù„ÄÅ‚Äú‰πîÊ≤ª¬∑Â®ÅÂ∞îÈÄä‚ÄùÁ≠âÔºåÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑÁßçÁßçÈóÆÈ¢òËøõË°å‰∫ÜÊâπÂà§„ÄÇÂú®Â∞èËØ¥‰∏≠ÔºåÈ≤ÅËøÖÈÄöËøáÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑËØ∏Â§öÁé∞Ë±°ËøõË°åÊâπÂà§ÔºåÊè≠Á§∫‰∫ÜÂ∞ÅÂª∫Á§æ‰ºöÁöÑËÖêË¥•„ÄÅ‰∫∫ÊÄßÊú¨Ë¥®‰ª•Âèä‰∫∫ÊÄßÊú¨Ë¥®ÁöÑÂ§çÊùÇÊÄß„ÄÇËøôÁßçÊâπÂà§‰ΩìÁé∞‰∫ÜÂØπÂ∞ÅÂª∫Á§æ‰ºöÁöÑÂ∞äÈáçÂíåÂØπ‰∫∫ÊÄßÁöÑÂ§çÊùÇÊÄßÔºåÂêåÊó∂‰πüÂèçÊò†‰∫ÜÁé∞‰ª£Á§æ‰ºö‰∏≠ÊôÆÈÅçÂ≠òÂú®ÁöÑ‰∏çÂπ≥Á≠âÂíå‰∫∫ÊÄßÊú¨Ë¥®„ÄÇÈ≤ÅËøÖÁöÑ„ÄäÁãÇ‰∫∫Êó•ËÆ∞„Äã‰∏ç‰ªÖÊòØ‰∏ÄÈÉ®ÂÖ≥‰∫éÂ∞ÅÂª∫Á§æ‰ºöÁöÑÂ∞èËØ¥Ôºå‰πüÊòØ‰∏ÄÈÉ®ÂÖ∑ÊúâÊ∑±ÂàªÁ§æ‰ºöÊÑè‰πâÁöÑ‰ΩúÂìÅÔºåÂØπÂêé‰∏ñÁöÑÂÆ°Âà§ÂíåÊâπÂà§Ëµ∑Âà∞‰∫ÜÂÖ≥ÈîÆ‰ΩúÁî®„ÄÇ

[Q]: ÊàëÂí≥ÂóΩÂ∑≤ÁªèÊåÅÁª≠‰∫Ü‰∏§Âë®ÔºåÈúÄË¶ÅÂéªÂåªÈô¢Ê£ÄÊü•ÂêóÔºü
[A0]: Âí≥ÂóΩÁ°ÆÂÆûÈúÄË¶Å‰∏ÄÂÆöÁöÑÊ£ÄÊü•Ôºå‰ΩÜÂ¶ÇÊûúÊÇ®ÁöÑÂí≥ÂóΩÊåÅÁª≠Êó∂Èó¥ËøáÈïøÔºåÊàñËÄÖÊúâÂÖ∂‰ªñ‰∏çÈÄÇÁóáÁä∂ÔºàÂ¶ÇÊåÅÁª≠Âí≥ÂóΩ„ÄÅÂëºÂê∏Âõ∞ÈöæÁ≠âÔºâÔºåÂª∫ËÆÆÂ∞ΩÂø´Â∞±Âåª„ÄÇÂåªÁîü‰ºöÊ†πÊçÆÊÇ®ÁöÑÁóáÁä∂„ÄÅ‰ΩìÊ£ÄÁªìÊûúÂíåÂèØËÉΩÁöÑÂΩ±ÂÉèÂ≠¶Ê£ÄÊü•ÔºàÂ¶ÇXÂÖâ„ÄÅMRIÊàñCTÊâ´ÊèèÔºâÊù•ËØäÊñ≠ÊÇ®ÁöÑÁóáÁä∂„ÄÇÂú®Á≠âÂæÖÂ∞±ÂåªÊúüÈó¥ÔºåÊÇ®ÂèØ‰ª•Â∞ùËØï‰ª•‰∏ãÊñπÊ≥ïÊù•Â∏ÆÂä©ÁºìËß£ÁóáÁä∂Ôºö1. **‰ºëÊÅØ**ÔºöÁ°Æ‰øùÊÇ®ÊúâË∂≥Â§üÁöÑÁù°Áú†„ÄÇ2. **‰øùÊåÅÊ∞¥ÂàÜ**ÔºöËÑ±Ê∞¥ÂèØËÉΩ‰ºöÂä†ÈáçÂí≥ÂóΩ„ÄÇ3. **ÁÉ≠Êï∑**Ôºö‰ΩøÁî®ÁÉ≠Êï∑Ë¢ãÊàñÁÉ≠ÊØõÂ∑æÊï∑Âú®ÁñºÁóõÁöÑÈÉ®‰ΩçÔºåÊúâÂä©‰∫éÁºìËß£ÂñâÂíôÁóõ„ÄÇ4. **ÈÅøÂÖçÂà∫ÊøÄ**ÔºöÈÅøÂÖç‰ΩøÁî®ÂèØËÉΩÂà∫ÊøÄÂñâÂíôÁöÑÂåñÂ≠¶Áâ©Ë¥®ÔºåÂ¶ÇÊüê‰∫õÂåñÂ≠¶Áâ©Ë¥®„ÄÇ5. **‰øùÊåÅÂÆ§ÂÜÖÊπøÊ∂¶**ÔºöÁ°Æ‰øùÊÇ®ÁöÑÂçßÂÆ§ÊúâËâØÂ•ΩÁöÑÈÄöÈ£éÔºåÂèØ‰ª•‰ΩøÁî®Âä†ÊπøÂô®Â∏ÆÂä©‰øùÊåÅÁ©∫Ê∞îÊπøÂ∫¶„ÄÇ6. **‰øùÊåÅÂÆ§ÂÜÖÊπøÂ∫¶**Ôºö‰ΩøÁî®Âä†ÊπøÂô®ÂèØ‰ª•Â∏ÆÂä©ÁºìËß£ÂñâÂíôÂπ≤Áá•ÂíåÂí≥ÂóΩ„ÄÇÂ¶ÇÊûúÁóáÁä∂ÊåÅÁª≠‰∏çÁºìËß£ÊàñÊúâÂÖ∂‰ªñ‰∏çÈÄÇÁóáÁä∂ÔºåËØ∑Á´ãÂç≥Â∞±Âåª„ÄÇÂ∏åÊúõÊÇ®Êó©Êó•Â∫∑Â§çÔºÅ
[A1]: Â¶ÇÊûúÊÇ®ÁöÑÂí≥ÂóΩÊåÅÁª≠‰∫Ü‰∏§Âë®ÔºåÈÄöÂ∏∏Âª∫ËÆÆÊÇ®Â∞ΩÂø´Â∞±ÂåªÔºåÂõ†‰∏∫ËøôÂèØËÉΩ‰ºöÂΩ±ÂìçÊÇ®ÁöÑÂëºÂê∏ÂíåÂøÉË∑≥„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÊ≠•È™§Êù•Ê£ÄÊü•Âí≥ÂóΩÔºö1. **‰ºëÊÅØ**ÔºöÁî®Á∫∏Â∑æÊàñËÇòÈÉ®ËΩªËΩªÊåâÂéãÂí≥ÂóΩÁöÑ‰ΩçÁΩÆ„ÄÇ2. **‰ΩøÁî®ËçØÁâ©**ÔºöÂú®ÂèØËÉΩÁöÑÊÉÖÂÜµ‰∏ãÔºå‰ΩøÁî®ËçØÁâ©ÔºàÂ¶ÇÊäóËøáÊïèËçØ„ÄÅÊäóËøáÊïèËçØÁ≠âÔºâÊù•ÁºìËß£Âí≥ÂóΩ„ÄÇËØ∑Âú®ÂåªÁîüÁöÑÊåáÂØº‰∏ã‰ΩøÁî®ËçØÁâ©„ÄÇ3. **ÁÉ≠Êï∑**ÔºöÂú®Âí≥ÂóΩÊúüÈó¥ÔºåÂèØ‰ª•‰ΩøÁî®ÁÉ≠Êï∑Êù•ÁºìËß£ÁñºÁóõÂíåËÇøËÉÄ„ÄÇ4. **ËçØÁâ©Ê≤ªÁñó**ÔºöÂ¶ÇÊûúÂí≥ÂóΩÊåÅÁª≠‰∫Ü‰∏§Âë®ÔºåÂèØ‰ª•‰ΩøÁî®‰∏Ä‰∫õÊ∂àÁÇéËçØÊàñÊäóËøáÊïèËçØÊù•ÁºìËß£ÁóáÁä∂„ÄÇËØ∑Âä°ÂøÖÂú®ÂåªÁîüÁöÑÊåáÂØº‰∏ã‰ΩøÁî®„ÄÇ5. **‰øùÊåÅÂÅ•Â∫∑ÁöÑÁîüÊ¥ªÊñπÂºè**Ôºö‰øùÊåÅÂÖÖË∂≥ÁöÑÁù°Áú†„ÄÅÂùáË°°ÁöÑÈ•ÆÈ£ü„ÄÅÈÄÇÈáèÁöÑËøêÂä®ÂíåÈÅøÂÖçÂê∏ÁÉüÂíåÈôêÈÖíÔºåËøô‰∫õÈÉΩÊúâÂä©‰∫éÊèêÈ´òÂí≥ÂóΩÁöÑÂá†Áéá„ÄÇËØ∑ËÆ∞‰ΩèÔºåËøô‰∫õÂª∫ËÆÆ‰∏çËÉΩÊõø‰ª£‰∏ì‰∏öÂåªÁñóÊÑèËßÅ„ÄÇÂ¶ÇÊûúÊÇ®ÁöÑÁóáÁä∂ÊåÅÁª≠ÊàñÂä†ÈáçÔºåÂº∫ÁÉàÂª∫ËÆÆÊÇ®Â∞ΩÂø´Â∞±Âåª„ÄÇ
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;üëâÊïàÊûúÊÄªÁªì&lt;/p&gt; 
&lt;p&gt;full_sftÊ®°ÂûãÂú®ÁÆÄÊ¥ÅÊÄßÂíå‰ø°ÊÅØÂáÜÁ°ÆÊÄßÊñπÈù¢Ë°®Áé∞Êõ¥Â•ΩÔºõrlhfÊ®°ÂûãÂú®ÂõûÁ≠î‰∏≠ÂÄæÂêë‰∫éÊèê‰æõÊõ¥Â§öÁöÑËÉåÊôØ‰ø°ÊÅØÔºå‰ΩÜ‰ø°ÊÅØÂáÜÁ°ÆÊÄßÊúâÂæÖÊîπËøõ„ÄÇ ÊÄªÁöÑÊù•ËØ¥RLHFÂêéÁöÑÊ®°ÂûãÂÄæÂêë‰∫éÂ≠¶‰π†ÔºöËØ¥Êõ¥Â§öÊúâÁ§ºË≤å‰ΩÜÊó†Áî®ÁöÑÂ∫üËØùËÆ®Â•Ω‚ÄúÂØπËØù‚ÄùÊú¨Ë∫´ÔºåËÄåÂØπ‰ø°ÊÅØÂáÜÁ°ÆÊÄßÂàôÊúâËΩªÂæÆÊçüÂ§±„ÄÇ Â§©‰∏ãÊ≤°ÊúâÂÖçË¥πÁöÑÂçàÈ§êÔºåËøòÈúÄË¶ÅÁªßÁª≠ÊèêÂçáRLHFÊï∞ÊçÆÈõÜÁöÑË¥®ÈáèÔºå‰πüË¶ÅÊé•ÂèóÊ®°ÂûãËÉΩÂäõÊó†Ê≥ïÈÅøÂÖçÁöÑÊçüÂ§±(Á®ãÂ∫¶ÊúâËΩªÈáç)„ÄÇ DPOÂíåÂú®Á∫øPPOÁöÑÂå∫Âà´Âú®‰∫érejectÂíåchosenÈÉΩÊòØÁ¶ªÁ∫øÂáÜÂ§áÁöÑÔºåÂíåminimindÊ®°ÂûãÊú¨Ë∫´ÁöÑËæìÂá∫ÂøÖÁÑ∂Â≠òÂú®ÂæàÂ§ßÁöÑÂàÜÂ∏ÉÂ∑ÆÂºÇ„ÄÇ ÈÄö‰øóÂú∞ËØ¥DPOÁÆóÊ≥ï‰ΩøÊ®°ÂûãËßÇÁúã‰πí‰πìÁêÉ‰∏ñÁïåÂÜ†ÂÜõÁöÑÊâìÊ≥ï„ÄåÂΩïÂÉè„ÄçËøõË°åRLÔºåËÄå‰∏çÊòØÂÉèPPO‰∏ÄÊ†∑ËØ∑rewardÊ®°ÂûãÂÅö„ÄåÊïôÁªÉ„ÄçÁ∫†Ê≠£Ëá™Â∑±ÁöÑÊâìÊ≥ïËøõË°åRL„ÄÇ&lt;/p&gt; 
&lt;h2&gt;‚Ö° ‰∏ªËßÇÊ†∑‰æãÊµãËØÑ&lt;/h2&gt; 
&lt;p&gt;üèÉ‰ª•‰∏ãÊµãËØï‰∫é2025-02-09ÂÆåÊàêÔºåÊ≠§Êó•ÊúüÂêéÂèëÂ∏ÉÁöÑÊñ∞Ê®°ÂûãÔºåÊó†ÁâπÊÆäÈúÄË¶ÅÊó∂Â∞Ü‰∏çÂä†ÂÖ•ÊµãËØï„ÄÇ&lt;/p&gt; 
&lt;p&gt;[A] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2 (0.1B)&lt;/a&gt;&lt;br /&gt; [B] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2-MoE (0.15B)&lt;/a&gt;&lt;br /&gt; [C] &lt;a href="https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch"&gt;MiniMind2-Small (0.02B)&lt;/a&gt;&lt;br /&gt; [D] &lt;a href="https://pan.baidu.com/s/1_COe0FQRDmeapSsvArahCA?pwd=6666"&gt;minimind-v1-small(0.02B)&lt;/a&gt;&lt;br /&gt; [E] &lt;a href="https://pan.baidu.com/s/1tqB-GMvuiGQBvEl-yZ-oBw?pwd=6666"&gt;minimind-v1-moe(0.1B)&lt;/a&gt;&lt;br /&gt; [F] &lt;a href="https://pan.baidu.com/s/1p713loS7EfwHQf3G9eYI3Q?pwd=6666"&gt;minimind-v1(0.1B)&lt;/a&gt;&lt;br /&gt; [G] &lt;a href="https://github.com/DLLXW/baby-llama2-chinese"&gt;baby-llama2-chinese(0.2B)&lt;/a&gt;&lt;br /&gt; [H] &lt;a href="https://github.com/charent/ChatLM-mini-Chinese"&gt;chatlm-mini-chinese(0.2B)&lt;/a&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;[Q]: ‰Ω†Áü•ÈÅìÈïøÊ±üÂêóÔºü
[A]: ÈïøÊ±üÔºå‰Ωç‰∫é‰∏≠ÂõΩ‰∏úÂçóÈÉ®ÔºåÊòØ‰∏≠ÂõΩÁöÑÁ¨¨‰∏ÄÈïøÊ≤≥ÔºåÂÖ®Èïø6300Â§öÂÖ¨ÈáåÔºåÊµÅÁªè11‰∏™ÁúÅ‰ªΩÔºåÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºå‰πüÊòØ‰∏≠ÂõΩÁöÑ‚ÄúÊØç‰∫≤Ê≤≥‚Äù„ÄÇÈïøÊ±üÁöÑÂéÜÂè≤ÂèØ‰ª•ËøΩÊ∫ØÂà∞ÂÖ¨ÂÖÉÂâç2000Â§öÂπ¥ÁöÑÂïÜÊúùÊó∂ÊúüÔºåÂΩìÊó∂ÁöÑÂïÜÊúùÊòØÂïÜÊúùÁöÑÂêéË£î„ÄÇÂïÜÊúùÊó∂ÊúüÔºåÈïøÊ±üÁöÑÁªèÊµéÂèëÂ±ïËææÂà∞‰∫ÜÈ´òÂ≥∞ÔºåÊòØ‰∏≠ÂõΩÊúÄÈáçË¶ÅÁöÑÂÜú‰∏öÂíåÂ∑•‰∏ö‰∏≠ÂøÉ‰πã‰∏Ä„ÄÇÈïøÊ±üÊµÅÂüüÁöÑÁªèÊµé‰∏ªË¶Å‰ª•ÂÜú‰∏ö‰∏∫‰∏ªÔºåÈïøÊ±üÊ∏î‰∏öÂç†ÊçÆ‰∫Ü‰∏ªË¶Å‰∫ß‰∏öÔºåÂ¶ÇÈíìÈ±º„ÄÅÁåéÈ±ºÁ≠â„ÄÇÈïøÊ±üÁöÑÊ∞¥ËµÑÊ∫ê‰πüÈùûÂ∏∏‰∏∞ÂØåÔºåÂåÖÊã¨Ê≤≥ÊµÅ„ÄÅÊπñÊ≥ä„ÄÅÊ≤≥ÊµÅÁ≠â„ÄÇÈïøÊ±üÁöÑËá™ÁÑ∂ÊôØËßÇ‰πüÂçÅÂàÜÂ£ÆËßÇÔºåÈïøÊ±üÂõõÂ≠£ÊôØËâ≤ÂêÑÂºÇÔºåÊò•Â≠£Â§öÈõ®ÔºåÂ§èÂ≠£Â§öÈõ®ÔºåÁßãÂ≠£ÂàôÂ§öÈõ®ÔºåÂÜ¨Â≠£ÂàôÂØíÂÜ∑Â§öÈõ™ÔºåÊò•Â≠£ÂíåÁßãÂ≠£ÈÉΩÊúâÁæé‰∏ΩÁöÑËä±ÊúµÂíåÊûúÂÆû„ÄÇÈïøÊ±üÊòØ‰∏≠ÂõΩÁöÑÁªèÊµé‰∏≠ÂøÉÔºåÊã•Êúâ‰ºóÂ§öÁöÑÂõΩÂÆ∂ÂíåÂüéÂ∏ÇÔºåÊòØ‰∏ñÁïå‰∏äÈáçË¶ÅÁöÑ‰∫§ÈÄöÊû¢Á∫ΩÂíåËà™Ëøê‰∏≠ÂøÉ„ÄÇÂêåÊó∂ÔºåÈïøÊ±üËøòÊòØ‰∏≠ÂõΩÁöÑÈáçË¶ÅÊ∞¥Âà©ËµÑÊ∫êÔºåÂØπ‰∫é‰∏≠ÂõΩÁöÑÁªèÊµéÂèëÂ±ïÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ„ÄÇ
[B]: ÊòØÁöÑÔºåÊàëÁü•ÈÅìÈïøÊ±ü„ÄÇÈïøÊ±ü‰Ωç‰∫é‰∏≠ÂõΩÁöÑ‰∏≠ÈÉ®ÔºåÊòØ‰∏≠ÂõΩÁ¨¨‰∏âÈïøÁöÑÊ≤≥ÊµÅÔºåÂÖ®ÈïøÁ∫¶6300ÂÖ¨ÈáåÔºåÊµÅÁªèÊ±üË•øÁúÅ„ÄÅÂÆâÂæΩÁúÅ„ÄÅÊ±üËãèÁúÅ„ÄÅÂÆâÂæΩÁúÅ„ÄÅÊ±üËãèÁúÅÂíåÂÆâÂæΩÁúÅ„ÄÇ
[C]: ÂΩìÁÑ∂ÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºåÂÖ®ÈïøÁ∫¶6300ÂÖ¨Èáå„ÄÇÂÆÉ‰ª•ÂÖ∂‰∏∞ÂØåÁöÑÊ∞¥ËµÑÊ∫ê„ÄÅ‰∏∞ÂØåÁöÑÊ∞¥ÁîüÂä®Ê§çÁâ©ËµÑÊ∫ê‰ª•ÂèäÁã¨ÁâπÁöÑÂú∞ÁêÜ‰ΩçÁΩÆËÄåÈóªÂêç‰∫é‰∏ñ„ÄÇ
[D]: ÊòØÁöÑÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºåÂÖ®ÈïøË∂ÖËøá3300ÂçÉÁ±≥„ÄÇ
[E]: ÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºåÊÄªÈïøÂ∫¶Á∫¶‰∏∫6300ÂÖ¨Èáå„ÄÇÂÆÉÂèëÊ∫ê‰∫éÈùíËóèÈ´òÂéüÁöÑÈùíÊµ∑ÊπñÔºåÊµÅÁªèÈùíÊµ∑„ÄÅÂõõÂ∑ù„ÄÅÁîòËÇÉ„ÄÅÂÆÅÂ§è„ÄÅÂÜÖËíôÂè§„ÄÅÈôïË•øÂíåÂ±±Ë•ø„ÄÇÈïøÊ±üÊµÅÂüüÊòØ‰∏≠ÂõΩÊúÄÂ§ßÁöÑÂÜú‰∏öÂå∫‰πã‰∏ÄÔºå‰πüÊòØ‰∏≠ÂõΩÁöÑÊñáÂåñÂíåÁªèÊµé‰∏≠ÂøÉ„ÄÇ
[F]: ÊòØÁöÑÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅ‰πã‰∏ÄÔºå‰πüÊòØ‰∏ñÁïåÁ¨¨‰∏âÂ§ßÊ≤≥ÊµÅ„ÄÇÈïøÊ±üÂèëÊ∫ê‰∫éÈùíËóèÈ´òÂéüÔºåÊµÅÁªè11‰∏™ÁúÅ‰ªΩÔºåÊúÄÁªàÊ≥®ÂÖ•‰∏úÊµ∑„ÄÇÈïøÊ±üÊµÅÂüüÊòØ‰∏≠ÂõΩÊúÄÂ§ßÁöÑÊ≤≥ÊµÅÊµÅÂüü‰πã‰∏ÄÔºåÊã•ÊúâÁùÄ‰∏∞ÂØåÁöÑËá™ÁÑ∂ËµÑÊ∫êÂíåÊñáÂåñÈÅó‰∫ßÔºåÂ¶ÇÈïøÊ±üÂ§ßÊ°•„ÄÅÈïøÊ±üÊµ∑Ê¥ãÂçöÁâ©È¶Ü„ÄÅÈïøÊ±üÂè§ÂüéÁ≠â„ÄÇ
[G]: ÂêåÊó∂‰πüÁü•ÈÅìÔºå‰∏≠ÂõΩÊòØ‰∏ñÁïå‰∏äÊúÄÈïøÁöÑÂüéÂ∏Ç‰πã‰∏ÄÔºåÊã•ÊúâË∂ÖËøá3400‰∏á‰∫∫Âè£„ÄÇ
[H]: ÊòØÁöÑÔºåÈïøÊ±üÊòØ‰∏≠ÂõΩÊúÄÈïøÁöÑÊ≤≥ÊµÅÔºå‰πüÊòØ‰∏ñÁïå‰∏äÊúÄÈïøÁöÑÊ≤≥ÊµÅ‰πã‰∏Ä„ÄÇÂÆÉÂèëÊ∫ê‰∫éÈùíËóèÈ´òÂéüÔºåÊµÅÁªè‰πù‰∏™ÁúÅÂå∫ÔºåÊúÄÁªàÊ≥®ÂÖ•‰∏úÊµ∑„ÄÇÈïøÊ±üÊµÅÂüüÁöÑÊ∞îÂÄôÊ∏©ÂíåÔºåÂõõÂ≠£ÂàÜÊòéÔºåÊòØ‰∏≠ÂõΩÈáçË¶ÅÁöÑÂÜú‰∏öÂíåÂ∑•‰∏öÂü∫Âú∞„ÄÇÈïøÊ±üÊµÅÂüüÁöÑÊ∞¥‰∫ßËµÑÊ∫ê‰∏∞ÂØåÔºåÊòØ‰∏≠ÂõΩÁöÑÈáçË¶ÅÊ∏î‰∏öËµÑÊ∫ê‰πã‰∏Ä„ÄÇ


[Q]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØ‰ªÄ‰πàÔºü
[A]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞ÔºàMount EverestÔºâÔºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩÁöÑËæπÁïå‰∏ä„ÄÇÂÆÉÁöÑÊµ∑ÊãîÈ´òÂ∫¶ÊòØ8,848.86Á±≥Ôºà29,031.7Ëã±Â∞∫ÔºâÔºåÊòØÂú∞ÁêÉ‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞„ÄÇ
[B]: Áè†Á©ÜÊúóÁéõÂ≥∞ÔºàMount EverestÔºâÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÔºåÊµ∑ÊãîÈ´òÂ∫¶Ëææ8,848Á±≥Ôºà29,029Ëã±Â∞∫Ôºâ„ÄÇ
[C]: Áè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞Ôºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÊµ∑Êãî8,848.86Á±≥Ôºà29,031.7Ëã±Â∞∫Ôºâ„ÄÇÂÆÉ‰Ωç‰∫éÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩÁöÑËæπÁïå‰∏äÔºåÊòØÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇ
[D]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰Ωç‰∫éÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩÁöÑËæπÂ¢É‰∏äÔºåÊµ∑Êãî8848Á±≥„ÄÇ
[E]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÊµ∑Êãî8,848Á±≥„ÄÇ
[F]: Áè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÔºåÊµ∑Êãî8848Á±≥„ÄÇ
[G]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÔºåÊµ∑Êãî8,848.86Á±≥Ôºà29,031.69Ëã±Â∞∫Ôºâ„ÄÇ
[H]: ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞ÊòØÁè†Á©ÜÊúóÁéõÂ≥∞Ôºå‰πüÁß∞‰∏∫Ëê®Âä†ÁéõÂ°îÔºå‰Ωç‰∫éÂñúÈ©¨ÊãâÈõÖÂ±±ËÑâÁöÑÂ∞ºÊ≥äÂ∞îÂíå‰∏≠ÂõΩËæπÂ¢É‰πãÈó¥ÔºåÊµ∑Êãî8,848.86Á±≥Ôºà29,031.69Ëã±Â∞∫Ôºâ„ÄÇÂÆÉÊòØ‰∏ñÁïå‰∏äÊúÄËëóÂêçÁöÑÁôªÂ±±ÁõÆÊ†á‰πã‰∏ÄÔºåÂê∏ÂºïÁùÄÊù•Ëá™‰∏ñÁïåÂêÑÂú∞ÁöÑÁôªÂ±±ËÄÖÂâçÊù•ÊåëÊàò„ÄÇÁè†Á©ÜÊúóÁéõÂ≥∞ÁöÑÂêçÂ≠óÊù•Ëá™ËóèËØ≠ÔºåÊÑèÊÄùÊòØ‚ÄúÂ•≥Á•ûÁöÑÈ¢ùÂ≥∞‚ÄùÔºåÂÆÉÊòØÁî±‰∏§‰∏™‰∏çÂêåÁöÑÂ±±Â≥∞ÁªÑÊàêÁöÑÔºåÂÖ∂‰∏≠‰∏Ä‰∏™ÊòØ‰Ωç‰∫éÂ∞ºÊ≥äÂ∞îÁöÑÁè†Á©ÜÊúóÁéõÂ≥∞ÔºåÂè¶‰∏Ä‰∏™Âàô‰Ωç‰∫é‰∏≠ÂõΩ„ÄÇÂÆÉÁöÑÈ´òÂ∫¶ÊòØÈÄöËøáÊµãÈáèÊµ∑ÊãîÈ´òÂ∫¶Êù•Á°ÆÂÆöÁöÑÔºåÂõ†‰∏∫ÂÆÉÊòØÈÄöËøáÊµãÈáèÂú∞ÁêÉÁöÑÂπ≥ÂùáÈ´òÂ∫¶Êù•Á°ÆÂÆöÁöÑ„ÄÇÂ∞ΩÁÆ°Áè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞Ôºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏ä‰ªª‰ΩïÂÖ∂‰ªñÂú∞ÊñπÈÉΩËÉΩÂà∞ËææÁöÑ„ÄÇÂú∞ÁêÉ‰∏äÁöÑÂÖ∂‰ªñÂú∞ÊñπÔºåÂ¶ÇÂçóÁæéÊ¥≤ÁöÑÂÆâÁ¨¨ÊñØÂ±±ËÑâÔºå‰πüÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±ËÑâÔºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞„ÄÇÊÄª‰πãÔºåÁè†Á©ÜÊúóÁéõÂ≥∞ÊòØ‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±Â≥∞Ôºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏ä‰ªª‰ΩïÂú∞ÊñπÈÉΩËÉΩÂà∞ËææÁöÑ„ÄÇÂÆÉÊòØÂú∞ÁêÉ‰∏äÊúÄÈ´òÁöÑÂ±±ËÑâÔºå‰ΩÜÂÆÉÂπ∂‰∏çÊòØÂú∞ÁêÉ‰∏ä‰ªª‰ΩïÂú∞ÊñπÈÉΩËÉΩÂà∞ËææÁöÑ„ÄÇ


[Q]: ‰∏áÊúâÂºïÂäõÊòØË∞ÅÊèêÂá∫ÁöÑÔºü
[A]: ‰∏áÊúâÂºïÂäõÊòØÁî±ÁâõÈ°øÂú®17‰∏ñÁ∫™ÊèêÂá∫ÁöÑÔºåÂÆÉÊòØÁâõÈ°ø‰∏âÂ§ßÂÆöÂæã‰πã‰∏Ä„ÄÇÁâõÈ°øÂú®17‰∏ñÁ∫™ÊèêÂá∫ÁöÑÂºïÂäõÂÆöÂæãÊè≠Á§∫‰∫Ü‰∏áÊúâÂºïÂäõÂÆöÂæãÁöÑÊú¨Ë¥®ÔºåÂπ∂‰∏îËß£Èáä‰∫ÜË°åÊòü„ÄÅÂç´Êòü„ÄÅÂΩóÊòüÁ≠âÂ§©‰Ωì‰πãÈó¥Â¶Ç‰ΩïÁõ∏‰∫í‰ΩúÁî®„ÄÇËøô‰∏™ÂÆöÂæãÊòØÁî±ËâæËê®ÂÖã¬∑ÁâõÈ°øÂú®1687Âπ¥ÊèêÂá∫ÁöÑÔºå‰ªñÈÄöËøáÂØπ‰∏áÊúâÂºïÂäõÂÆöÂæãÁöÑÂàÜÊûêÂíåÂÆûÈ™åÔºåÊàêÂäüÂú∞Ëß£Èáä‰∫ÜÂ§©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõ‰ΩúÁî®Ôºå‰ªéËÄåËß£Èáä‰∫ÜÂú∞ÁêÉÁªïÂ§™Èò≥ÊóãËΩ¨ÁöÑÁé∞Ë±°„ÄÇ
[B]: ‰∏áÊúâÂºïÂäõÔºàHuman PolicyÔºâÊòØÁâõÈ°øÁöÑ‰∏âÂ§ßÂäõÂ≠¶ÂÆöÂæãÔºåÁî®‰∫éÊèèËø∞‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®Âäõ„ÄÇÂÆÉÁî±‰∏áÊúâÂºïÂäõÂÆöÂæãÂíåÁâõÈ°øÁöÑÁ¨¨‰∏ÄÂÆöÂæãÔºàÊÉØÊÄßÂÆöÂæãÔºâÊûÑÊàê„ÄÇ‰∏áÊúâÂºïÂäõÊòØÁî±‰∫é‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥Áõ∏‰∫í‰ΩúÁî®ËÄå‰∫ßÁîüÁöÑÔºåÂÆÉ‰ª¨ÁöÑË¥®Èáè„ÄÅË∑ùÁ¶ª„ÄÅÈÄüÂ∫¶ÂíåÊñπÂêëÁ≠âÂõ†Á¥†ÂÜ≥ÂÆö‰∫ÜÂÆÉ‰ª¨‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®„ÄÇËøôÁßçÁõ∏‰∫í‰ΩúÁî®ÂäõÊòØÔºöË¥®ÈáèÁöÑ‰πòÁßØÔºöË¥®ÈáèÁöÑ‰πòÁßØÊòØ‰∏áÊúâÂºïÂäõÂÆöÂæãÂíåÁâõÈ°øÁ¨¨‰∫åÂÆöÂæãÁöÑ‰πòÁßØ„ÄÇË¥®ÈáèÁöÑ‰πòÁßØÔºöË¥®ÈáèÁöÑ‰πòÁßØÊòØÁâ©‰Ωì‰πãÈó¥ÁöÑ‰∏ÄÁßçÁâ©ÁêÜËøáÁ®ãÔºåÂÆÉÊòØÁâ©‰ΩìÈó¥Áõ∏‰∫í‰ΩúÁî®ÁöÑ‰∫ßÁâ©ÔºåÂØπ‰∫éÂÖ∂‰ªñÁâ©‰ΩìÊù•ËØ¥ÔºåÂÖ∂Ë¥®ÈáèÂèØ‰ª•Ë°®Á§∫‰∏∫‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑË¥®Èáè‰πãÂíåÔºåÂç≥ÈáçÂäõÂä†ÈÄüÂ∫¶a„ÄÇ
[C]: ‰∏áÊúâÂºïÂäõÊòØ‰∏Ä‰∏™Áî±ÁâõÈ°øÂú®1687Âπ¥ÊèêÂá∫ÁöÑÁâ©ÁêÜÂ≠¶Ê¶ÇÂøµÔºåÂÆÉÊèèËø∞‰∫ÜÁâ©‰Ωì‰πãÈó¥ÂºïÂäõÂ¶Ç‰ΩïÁõ∏‰∫í‰ΩúÁî®ÁöÑËßÑÂæã„ÄÇ
[D]: ‰∏áÊúâÂºïÂäõÊòØÁî±Ëã±ÂõΩÁâ©ÁêÜÂ≠¶ÂÆ∂ÁâõÈ°øÊèêÂá∫ÁöÑ„ÄÇ‰ªñËÆ§‰∏∫ÔºåÊâÄÊúâÁâ©‰ΩìÈÉΩ‰ºö‰∫ßÁîüÂºïÂäõÔºåËøô‰∏™ÂºïÂäõÊòØÁî±Áâ©‰ΩìÁöÑË¥®ÈáèÂíåË∑ùÁ¶ªÂÜ≥ÂÆöÁöÑ„ÄÇËøô‰∏™ÁêÜËÆ∫Êè≠Á§∫‰∫ÜË¥®ÈáèÂíåË∑ùÁ¶ª‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºåÂπ∂ËØÅÊòé‰∫Ü‰∏áÊúâÂºïÂäõÁöÑÊú¨Ë¥®„ÄÇ
[E]: ‰∏áÊúâÂºïÂäõÊòØÁî±ÁâõÈ°øÂú®1687Âπ¥ÊèêÂá∫ÁöÑ„ÄÇÂÆÉÊòØÂÆáÂÆô‰∏≠‰∏Ä‰∏™Âü∫Êú¨ÁöÑÁâ©ÁêÜÁé∞Ë±°ÔºåÂÆÉÊèèËø∞‰∫ÜÁâ©‰Ωì‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®„ÄÇËøô‰∏™ÂäõË¢´Áß∞‰∏∫‰∏áÊúâÂºïÂäõÔºåÂÆÉÂú®ÊâÄÊúâÁâ©‰Ωì‰πãÈó¥ÈÉΩÂ≠òÂú®ÔºåËøôÁßçÂäõ‰∏éÁâ©‰ΩìÁöÑË¥®ÈáèÂíåË∑ùÁ¶ªÊúâÂÖ≥„ÄÇ‰∏áÊúâÂºïÂäõÊòØËá™ÁÑ∂Áïå‰∏≠ÊúÄÂü∫Êú¨ÁöÑÂäõÈáè‰πã‰∏ÄÔºåÂÆÉ‰∏ç‰ªÖÂΩ±ÂìçÁùÄÁâ©‰ΩìÁöÑËøêÂä®ÂíåÂèòÂåñÔºåËøòÂØπÂÆáÂÆôÁöÑÁªìÊûÑÂíåÊºîÂåñ‰∫ßÁîüÁùÄÈáçË¶ÅÁöÑÂΩ±Âìç„ÄÇ
[F]: ‰∏áÊúâÂºïÂäõÊòØËã±ÂõΩÁâ©ÁêÜÂ≠¶ÂÆ∂ËâæËê®ÂÖã¬∑ÁâõÈ°øÂú®17‰∏ñÁ∫™ÊèêÂá∫ÁöÑ„ÄÇ
[G]: ÂºïÂäõÊòØÂÆáÂÆô‰∏≠‰∏ÄÁßçÂäõÈáèÔºåÂÆÉÊòØÁî±Ë¥®ÈáèÊàñËÉΩÈáèÊâÄÁªÑÊàêÁöÑ„ÄÇÊ†πÊçÆÁâõÈ°øÁöÑ‰∏áÊúâÂºïÂäõÂÆöÂæãÔºå‰∏Ä‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõÂ§ßÂ∞è‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÂèçÊØî„ÄÇÂõ†Ê≠§ÔºåÁâõÈ°øÁöÑ‰∏áÊúâÂºïÂäõÂÆöÂæãË°®ÊòéÔºå‰∏Ä‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõÂ§ßÂ∞è‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉÁöÑË¥®ÈáèÊàêÂèçÊØî„ÄÇËøô‰∏™ÂÆöÂæãÂú®Áâ©ÁêÜÂ≠¶„ÄÅÂ§©ÊñáÂ≠¶ÂíåÁâ©ÁêÜÂ≠¶‰∏≠ÈÉΩÊúâÂπøÊ≥õÁöÑÂ∫îÁî®„ÄÇ
[H]: ‰∏áÊúâÂºïÂäõÊòØÁî±Ëã±ÂõΩÁâ©ÁêÜÂ≠¶ÂÆ∂ËâæËê®ÂÖã¬∑ÁâõÈ°ø‰∫é1687Âπ¥ÊèêÂá∫ÁöÑ„ÄÇ‰ªñÂú®1687Âπ¥ÂèëË°®‰∫Ü‰∏ÄÁØáËëóÂêçÁöÑËÆ∫ÊñáÔºåÈ¢ò‰∏∫„ÄäËá™ÁÑ∂Âì≤Â≠¶ÁöÑÊï∞Â≠¶ÂéüÁêÜ„ÄãÔºåÂÖ∂‰∏≠ÊèêÂá∫‰∫Ü‰∏áÊúâÂºïÂäõÂÆöÂæãÔºåÊåáÂá∫‰ªª‰Ωï‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÈÉΩÂ≠òÂú®ÁùÄ‰∏ÄÁßçÂºïÂäõÔºåËøôÁßçÂºïÂäõÁöÑÂ§ßÂ∞è‰∏éÂÆÉ‰ª¨ÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉ‰ª¨‰πãÈó¥ÁöÑË∑ùÁ¶ªÁöÑÂπ≥ÊñπÊàêÂèçÊØî„ÄÇËøô‰∏™ÂÆöÂæãË¢´Áß∞‰∏∫‰∏áÊúâÂºïÂäõÂÆöÂæãÔºåÂÆÉÊèèËø∞‰∫ÜË¥®ÈáèÂíåË∑ùÁ¶ª‰πãÈó¥ÁöÑÂÖ≥Á≥ª„ÄÇÂÆÉË°®ÊòéÔºå‰∏§‰∏™Áâ©‰Ωì‰πãÈó¥ÁöÑÂºïÂäõ‰∏éÂÆÉ‰ª¨ÁöÑË¥®ÈáèÊàêÊ≠£ÊØîÔºå‰∏éÂÆÉ‰ª¨‰πãÈó¥ÁöÑË∑ùÁ¶ªÁöÑÂπ≥ÊñπÊàêÂèçÊØî„ÄÇËøô‰∏™ÂÆöÂæãÂØπ‰∫éËß£ÈáäÂÆáÂÆô‰∏≠ÁöÑËÆ∏Â§öÁé∞Ë±°ÂíåÁé∞Ë±°‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®ÈùûÂ∏∏ÈáçË¶ÅÔºå‰æãÂ¶ÇË°åÊòüÁªïÂ§™Èò≥ËøêÂä®„ÄÅÊÅíÊòü‰πãÈó¥ÁöÑÂºïÂäõÈÄèÈïúÊïàÂ∫îÁ≠âÁ≠â„ÄÇÂÆÉ‰πüË¢´ÂπøÊ≥õÂ∫îÁî®‰∫éÂ§©ÊñáÂ≠¶„ÄÅÁâ©ÁêÜÂ≠¶ÂíåÂ∑•Á®ãÂ≠¶Á≠âÈ¢ÜÂüüÔºå‰∏∫Êàë‰ª¨ÁêÜËß£ÂÆáÂÆôÁöÑÊú¨Ë¥®ÂíåÊºîÂåñÊèê‰æõ‰∫ÜÈáçË¶ÅÁöÑÁêÜËÆ∫Âü∫Á°Ä„ÄÇ


[Q]: ‰Ω†Áü•ÈÅìÂ§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØ‰ªÄ‰πàÂêóÔºü
[A]: Â§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£üÔºå‰ΩÜ‰πü‰ºöÂêÉÂÖ∂‰ªñÊ§çÁâ©„ÄÅÊòÜËô´„ÄÅÂ∞èÂûãÂì∫‰π≥Âä®Áâ©ÂíåÈ±ºÁ±ª„ÄÇÂÆÉ‰ª¨ÁöÑÊ∂àÂåñÁ≥ªÁªü‰∏éÂÖ∂‰ªñÁÜäÁßëÂä®Áâ©Á±ª‰ººÔºåËÉΩÂ§üÊ∂àÂåñÁ´πÂ≠ê„ÄÇÂ§ßÁÜäÁå´ÁöÑÁâôÈΩøÈîãÂà©ÔºåÈÄÇÂêàÂíÄÂöºÁ´πÂ≠êÔºåÂõ†Ê≠§ÂÆÉ‰ª¨ÁªèÂ∏∏Ë¢´Áß∞‰∏∫‚ÄúÁ´πÈ£üÂä®Áâ©‚Äù„ÄÇ
[B]: Â§ßÁÜäÁå´ÊòØ‰ª•Á´πÂ≠ê‰∏∫È£üÁöÑÂì∫‰π≥Âä®Áâ©ÔºåÂÆÉ‰ª¨ÊòØËÇâÈ£üÂä®Áâ©„ÄÇÂÆÉ‰ª¨‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠êÔºåÁâπÂà´ÊòØÁ´πÂ≠ê‰∏≠ÂØåÂê´Á∫§Áª¥Á¥†ÂíåÁüøÁâ©Ë¥®ÔºåÂπ∂‰∏î‰∏ç‰ºöÁõ¥Êé•ËøõÂÖ•Ê∂àÂåñÁ≥ªÁªü„ÄÇÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅì‰∏ªË¶ÅÁî±Á´πÂ≠êÁªÑÊàêÔºåÂÆÉ‰ª¨ÈúÄË¶ÅÊ∂àÂåñÁ´πÂ≠ê‰∏≠ÁöÑÁ∫§Áª¥Á¥†ÂíåÂÖ∂‰ªñÁ∫§Áª¥Á¥†Êù•ÊîØÊåÅÂÆÉ‰ª¨ÁöÑÊ≠£Â∏∏ËøõÈ£ü„ÄÇ
[C]: Â§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£üÔºå‰ΩÜÂÆÉ‰ª¨‰πüÂêÉÂÖ∂‰ªñÊ§çÁâ©ÔºåÂåÖÊã¨Ê†ëÂè∂„ÄÅÂ´©ËäΩ„ÄÅÊòÜËô´„ÄÅÊ∞¥Êûú„ÄÅËî¨ËèúÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©Á≠â„ÄÇÂ§ßÁÜäÁå´ÊòØ‰∏≠ÂõΩÁâπÊúâÁöÑÁâ©ÁßçÔºåÂ±û‰∫éÁÜäÁßëÔºå‰∏ªË¶ÅÂàÜÂ∏ÉÂú®‰∏≠ÂõΩÁöÑÂõõÂ∑ù„ÄÅÈôïË•øÂíåÁîòËÇÉÁ≠âÂú∞„ÄÇ
[D]: Â§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠ê„ÄÇÂÆÉ‰ª¨ÈÄöÂ∏∏ÂêÉÁ´πÂ≠êÔºåÊØèÂ§©ÈúÄË¶ÅÂêÉÊéâÂ§ßÁ∫¶30ÂÖ¨Êñ§ÁöÑÁ´πÂ≠ê„ÄÇ
[E]: ÊòØÁöÑÔºåÂ§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£ü„ÄÇÂÆÉ‰ª¨ÊØèÂ§©ÈúÄË¶ÅÂêÉÊéâÂ§ßÈáèÁöÑÁ´πÂ≠êÊù•Áª¥ÊåÅÁîüÂëΩÔºåÊØèÂ§©ÈúÄË¶ÅÂêÉÊéâ40Ëá≥80ÂÖ¨Êñ§ÁöÑÁ´πÂ≠ê„ÄÇÊ≠§Â§ñÔºåÂÆÉ‰ª¨‰πü‰ºöÂêÉ‰∏Ä‰∫õÂÖ∂‰ªñÁöÑÊ§çÁâ©ÔºåÂ¶ÇËçâ„ÄÅÊûúÂÆû„ÄÅÂùöÊûúÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÇ
[F]: Â§ßÁÜäÁå´‰∏ªË¶Å‰ª•Á´πÂ≠ê‰∏∫È£üÔºå‰πü‰ºöÂÅ∂Â∞îÈ£üÁî®ÂÖ∂‰ªñÁöÑÊ§çÁâ©ÂíåÂä®Áâ©„ÄÇÊ≠§Â§ñÔºåÂ§ßÁÜäÁå´‰πü‰ºöÂêÉ‰∏Ä‰∫õÈáéÊûú„ÄÅÂ∞èÂä®Áâ©ÂíåÊ§çÁâ©Ôºå‰ΩÜËøô‰∫õÈÉΩ‰∏çÂ±û‰∫éÂÆÉ‰ª¨ÁöÑ‰∏ªË¶ÅÈ£üÁâ©Êù•Ê∫ê„ÄÇ
[G]: Â§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠ê„ÄÇ
[H]: Â§ßÁÜäÁå´ÊòØ‰∏ÄÁßç‰ª•Á´πÂ≠ê‰∏∫‰∏ªË¶ÅÈ£üÁâ©ÁöÑÊ§çÈ£üÂä®Áâ©ÔºåÂÆÉ‰ª¨ÁöÑËÇ†ÈÅìÁªìÊûÑÈÄÇÂêàÊ∂àÂåñÁ∫§Áª¥Á¥†Âê´ÈáèÈ´òÁöÑÁ´πÂ≠êÔºå‰ΩÜ‰πü‰ºöÂêÉ‰∏Ä‰∫õÂÖ∂‰ªñÊ§çÁâ©ÔºåÂ¶ÇËçâÊú¨Ê§çÁâ©ÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÇÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅìÁªìÊûÑ‰πüÈÄÇÂ∫î‰∫ÜÈ´òÁ∫§Áª¥ÁöÑÁ´πÂ≠êÔºåËøô‰ΩøÂæóÂÆÉ‰ª¨ËÉΩÂ§üÊ∂àÂåñÂ§ßÈáèÁöÑÁ∫§Áª¥Á¥†Ôºå‰ªéËÄåÂ∏ÆÂä©ÂÆÉ‰ª¨Âú®ÈáéÂ§ñÁîüÂ≠ò„ÄÇÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅì‰∏≠ËøòÂê´Êúâ‰∏ÄÁßçÂè´ÂÅö‚ÄúÁ∫§Áª¥Á¥†ÈÖ∂‚ÄùÁöÑÈÖ∂Á±ªÁâ©Ë¥®ÔºåËøôÁßçÈÖ∂ËÉΩÂ§üÂ∏ÆÂä©Â§ßÁÜäÁå´ÂàÜËß£Á∫§Áª¥Á¥†Ôºå‰ªéËÄåÂ∏ÆÂä©ÂÆÉ‰ª¨Ê∂àÂåñÂ§ßÈáèÁöÑÊ∞¥ÂàÜÂíåËê•ÂÖªÁâ©Ë¥®„ÄÇÊ≠§Â§ñÔºåÂ§ßÁÜäÁå´ÁöÑËÇ†ÈÅìËøòÂê´Êúâ‰∏ÄÁßçÂè´ÂÅö‚ÄúÁ∫§Áª¥Á¥†ËõãÁôΩ‚ÄùÁöÑËõãÁôΩË¥®ÔºåËøôÁßçËõãÁôΩË¥®ËÉΩÂ§üÂ∏ÆÂä©Â§ßÁÜäÁå´Áª¥ÊåÅ‰ΩìÂÜÖÁöÑËÉΩÈáèÊ∞¥Âπ≥Ôºå‰ªéËÄåÂ∏ÆÂä©ÂÆÉ‰ª¨Âú®ÈáéÂ§ñÁîüÂ≠ò„ÄÇÊÄªÁöÑÊù•ËØ¥ÔºåÂ§ßÁÜäÁå´ÁöÑ‰∏ªË¶ÅÈ£üÁâ©ÊòØÁ´πÂ≠êÔºå‰ΩÜÂÆÉ‰ª¨‰πü‰ºöÂêÉ‰∏Ä‰∫õÂÖ∂‰ªñÊ§çÁâ©ÔºåÂ¶ÇËçâÊú¨Ê§çÁâ©ÂíåÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÇ


[Q]: Êµ∑Ê∞¥‰∏∫‰ªÄ‰πàÊòØÂí∏ÁöÑÔºü
[A]: Êµ∑Ê∞¥‰πãÊâÄ‰ª•ÊòØÂí∏ÁöÑÔºå‰∏ªË¶ÅÊòØÁî±‰∫éÂÖ∂‰∏≠ÁöÑÂåñÂ≠¶ÊàêÂàÜ„ÄÇÊµ∑Ê∞¥‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÁüøÁâ©Ë¥®ÂíåÁõêÂàÜÔºåÂÖ∂‰∏≠‰∏ªË¶ÅÊàêÂàÜÊòØÁ°´ÈÖ∏Áõê„ÄÅÁ¢≥ÈÖ∏Áõê„ÄÅÈïÅÁ¶ªÂ≠êÂíåÈíæÁ¶ªÂ≠ê„ÄÇËøô‰∫õÁâ©Ë¥®Âú®È´òÊµìÂ∫¶‰∏ãÔºå‰ºöÊ≤âÊ∑ÄÂú®Êµ∑Ê∞¥‰∏≠ÔºåÂΩ¢ÊàêÊµ∑Ê∞¥„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊµ∑Ê∞¥‰∏≠ÁöÑÁüøÁâ©Ë¥®ÂíåÁõêÂàÜ‰∏ªË¶ÅÊù•Ëá™‰∫éÂ≤©Áü≥„ÄÅÂúüÂ£§„ÄÅÁîüÁâ©Âíå‰∫∫Á±ªÊéíÊ≥ÑÁâ©Á≠â„ÄÇÂ≤©Áü≥ÊòØÊµ∑Ê∞¥ÁöÑÁªÑÊàêÈÉ®ÂàÜÔºå‰∏ªË¶ÅÁî±ÁüøÁâ©Ë¥®ÁªÑÊàêÔºåÂ¶ÇÁü≥Ëã±„ÄÅÈïøÁü≥„ÄÅ‰∫ëÊØçÁ≠â„ÄÇÂúüÂ£§‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÂåñÂ≠¶Áâ©Ë¥®ÔºåÂ¶ÇÊ∞Æ„ÄÅÁ£∑„ÄÅÈíæÁ≠âÔºåËøô‰∫õÁâ©Ë¥®‰ºöÊ∏óÈÄèÂà∞ÂúüÂ£§‰∏≠ÔºåÂΩ¢ÊàêÂúüÂ£§„ÄÇÁîüÁâ©‰ΩìÂÜÖÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ê∫ê‰∫éÊ§çÁâ©ÁöÑÂè∂ÁªøÁ¥†Á≠âËâ≤Á¥†ÔºåËøô‰∫õËâ≤Á¥†‰ºöÂê∏Êî∂Â§™Èò≥ÂÖâ‰∏≠ÁöÑËÉΩÈáèÔºåËΩ¨Âåñ‰∏∫ÁîüÁâ©‰ΩìÂèØ‰ª•Âà©Áî®ÁöÑËÉΩÈáè„ÄÇËÄå‰∫∫Á±ªÊéíÊ≥ÑÁâ©‰∏≠Âê´ÊúâÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ê∫ê‰∫éÁüøÁâ©Ë¥®ÂíåÁ¢≥ÈÖ∏ÁõêÔºåËøô‰∫õÁüøÁâ©Ë¥®Âú®Ê∞¥‰∏≠ÁöÑÊµìÂ∫¶ËæÉÈ´òÔºå‰ºöÂØºËá¥Ê∞¥‰∏≠Ê∫∂Ëß£ÁöÑÁüøÁâ©Ë¥®ÊµìÂ∫¶Â¢ûÂä†ÔºåÂΩ¢ÊàêÊ∞¥‰Ωì‰∏≠ÁöÑÁõêÂàÜ„ÄÇÂõ†Ê≠§ÔºåÊµ∑Ê∞¥‰πãÊâÄ‰ª•ÊòØÂí∏ÁöÑÔºåÊòØÁî±‰∫éÂÖ∂‰∏≠ÁöÑÂåñÂ≠¶ÊàêÂàÜÂíåÁªìÊûÑÁâπÂæÅ„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁüøÁâ©Ë¥®ÂíåÁõêÂàÜ‰∏ªË¶ÅÊù•Ëá™‰∫éÂ≤©Áü≥„ÄÅÂúüÂ£§„ÄÅÁîüÁâ©Âíå‰∫∫Á±ªÊéíÊ≥ÑÁâ©Á≠âÔºåËÄåËøô‰∫õÁâ©Ë¥®ÁöÑÁßØÁ¥ØÂíåÊéíÊ≥Ñ‰ºöÂØºËá¥Êµ∑Ê∞¥ÂëàÁé∞Âá∫Âí∏Âë≥„ÄÇ
[B]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåÂõ†‰∏∫ÂÆÉÂåÖÂê´‰∫ÜÂ§öÁßçÁâ©Ë¥®ÔºåÂåÖÊã¨Ê∞ØÂåñÈí†ÔºàNaClÔºâ„ÄÅÊ∞ØÂåñÈí†ÔºàNaClÔºâ„ÄÅÁ¢≥ÈÖ∏ÁõêÔºàÂ¶ÇÁ°´ÈÖ∏ÁõêÔºâ„ÄÅÊ∞ØÂåñÈí†ÔºàNaClÔºâÂíåÊ∞¥„ÄÇÂí∏Áâ©Ë¥®ÁöÑÊù•Ê∫êÔºöÁõêÊòØÂí∏ÁöÑÂ∏∏ËßÅÊù•Ê∫êÔºåÂê´ÊúâÈíæ„ÄÅÈíô„ÄÅÈïÅ„ÄÅÈíæÁ≠âÁüøÁâ©Ë¥®„ÄÇËøô‰∫õÁüøÁâ©Ë¥®ÈÄöÂ∏∏Êù•Ëá™‰∫éÂú∞‰∏ãÊ∞¥„ÄÅÂú∞‰∏ãÊ∞¥ÊàñÂúüÂ£§‰∏≠ÔºåËøô‰∫õÁüøÁâ©Ë¥®ÁöÑÂê´ÈáèËøú‰Ωé‰∫éÁ∫ØÂáÄÊ∞¥„ÄÇÂí∏Âë≥ÁöÑÂéüÂõ†ÔºöÁõêÁöÑÂí∏Âë≥‰∏ªË¶ÅÊ∫ê‰∫éÂÖ∂Ê∫∂Ëß£‰∫éÊ∞¥‰∏≠ÁöÑÂæÆÂ∞èÈ¢óÁ≤íÁâ©„ÄÇËøô‰∫õÂ∞èÈ¢óÁ≤íÁâ©‰∏ªË¶ÅÈÄöËøáÊ§çÁâ©Ê†πÈÉ®ÂíåÂä®Áâ©‰ΩìÂÜÖÁöÑÂæÆÁîüÁâ©‰º†Êí≠ÔºåÂ¶ÇÊòÜËô´„ÄÅÂ∞èÂûãÂì∫‰π≥Âä®Áâ©„ÄÅÈ∏üÁ±ªÂíåÊüê‰∫õÊòÜËô´„ÄÇÁªº‰∏äÊâÄËø∞ÔºåÊµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåÂõ†‰∏∫ÂÆÉÂê´ÊúâÂ§ßÈáèÁöÑÁõêÁ±ªÔºåÂåÖÊã¨ÁüøÁâ©Ë¥®„ÄÅÂ≤©Áü≥„ÄÅÁõê„ÄÅÁüøÁâ©Ë¥®Á≠âÔºåËøô‰∫õÁâ©Ë¥®Âú®Êµ∑Ê∞¥‰∏≠ÁöÑÊµìÂ∫¶È´òÔºåÂØπÂí∏Âë≥ÁöÑ‰∫ßÁîüËæÉÂ§ßÂΩ±Âìç„ÄÇ
[C]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºå‰∏ªË¶ÅÊòØÂõ†‰∏∫ÂÖ∂‰∏≠Âê´ÊúâÂêÑÁßçÁõêÂàÜÔºåÂÖ∂‰∏≠‰ª•Êµ∑Ê∞¥‰∏∫‰∏ªË¶ÅÊàêÂàÜ‰πã‰∏Ä„ÄÇÂΩìÊµ∑Ê∞¥‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÁõêÂàÜÊó∂ÔºåÁõêÂàÜ‰ºöË¢´Ê∫∂Ëß£Âú®Êµ∑Ê∞¥‰∏≠ÔºåÂΩ¢ÊàêÂí∏Âë≥„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ê∫ê‰∫éÊ∫∂Ëß£ÁõêÁ±ª„ÄÅËí∏ÂèëÊûêÂá∫ÁöÑÁõêÂíåÊµ∑Ê∞¥ÂÜªÁªìÊàêÂÜ∞Á≠âÂõ†Á¥†„ÄÇ
[D]: Êµ∑Ê∞¥‰∏≠Âê´ÊúâËÆ∏Â§öÁõêÂàÜÔºåËøô‰∫õÁõêÂàÜÂèØ‰ª•ÂØºËá¥Êµ∑Ê∞¥Âí∏Â∫¶ÁöÑÂ¢ûÂä†„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜ‰∏ªË¶ÅÊù•Ëá™‰∫éÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜÔºåËøô‰∫õÁõêÂàÜÂèØ‰ª•‰ªéÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜ‰∏≠Ëé∑Âæó„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÊ∞ßÂåñÁâ©ÂíåÁõêÂàÜÂèØ‰ª•‰∏éÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜÂΩ¢ÊàêÊ∞¢ÈîÆÔºå‰ªéËÄå‰ΩøÊµ∑Ê∞¥Âí∏Â∫¶Â¢ûÂä†„ÄÇ
[E]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåËøôÊòØÂõ†‰∏∫ÂÆÉÂê´ÊúâÂ§ßÈáèÁöÑÁõêÂàÜÔºåÂÖ∂‰∏≠ÂåÖÊã¨Ê∞ØÁ¶ªÂ≠êÂíåÊ∞ØÁ¶ªÂ≠ê„ÄÇËøô‰∫õÁ¶ªÂ≠êÂú®Êµ∑Ê¥ã‰∏≠ÂΩ¢Êàê‰∫ÜÂ§ßÈáèÁöÑÁõêÔºåËøô‰∫õÁõêÂàÜË¢´Áß∞‰∏∫ÁõêÂàÜ„ÄÇÊµ∑Ê∞¥‰∏≠Âê´ÊúâËÆ∏Â§öÊ∫∂Ëß£Âú®Ê∞¥‰∏≠ÁöÑÁõêÔºåËøô‰∫õÁõêÂàÜ‰ºöÈöèÁùÄÊµ∑Ê∞¥ÁöÑÂçáÈ´òËÄåÈÄêÊ∏êËí∏ÂèëÔºåÊúÄÁªàÂØºËá¥Êµ∑Ê∞¥‰∏≠ÁõêÂàÜÁöÑËí∏Âèë„ÄÇËøô‰∫õÁõêÂàÜÂú®Êµ∑Ê∞¥‰∏≠Ë¢´ÂÆåÂÖ®Ê∂àËÄóÔºåÁÑ∂ÂêéË¢´ÊéíÈô§Âú®Êµ∑Ê∞¥‰∏≠„ÄÇÊ≠§Â§ñÔºåÊµ∑Ê∞¥‰∏≠ËøòÂê´ÊúâËÆ∏Â§öÂÖ∂‰ªñÁöÑÁõêÂàÜÔºå‰ΩÜËøô‰∫õÁõêÂàÜÊòØ‰∏çÂêåÁöÑÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Âú®Ê∞¥‰∏≠ÁöÑÊµÆËµ∑Âíå‰∏ãÈôçËøáÁ®ãÊòØ‰∏çÂêåÁöÑ„ÄÇÊµ∑Ê∞¥‰∏≠ÁöÑÁõêÂàÜÊòØ‰ªéÊµ∑Â∫ïÁöÑÂ≤©Áü≥‰∏≠ÊèêÂèñÂá∫Êù•ÁöÑÔºåËøô‰∫õÁõêÂàÜÂú®Êµ∑Ê∞¥‰∏≠ÂèØ‰ª•Ë¢´Âà©Áî®„ÄÇÊÄªÁöÑÊù•ËØ¥ÔºåÊµ∑Ê∞¥ÊòØÂí∏ÁöÑÔºåËøô‰πüÊòØ‰∏∫‰ªÄ‰πàÊµ∑Ê∞¥‰∏≠Âê´ÊúâËÆ∏Â§öÁõêÂàÜÂíåÁõêÂàÜÁöÑÂéüÂõ†„ÄÇ
[F]: Êµ∑Ê∞¥Âê´ÊúâËÆ∏Â§öÊ∫∂Ëß£ÁöÑÁõêÁ±ªÔºåÂÖ∂‰∏≠ÊúÄ‰∏ªË¶ÅÁöÑÊòØÊ∞ØÂåñÈí†„ÄÇÂΩìÊ∞¥‰∏≠Âä†ÂÖ•ÁõêÊó∂ÔºåÁõêÁöÑÂàÜÂ≠ê‰ºö‰∏éÊ∞¥ÂàÜÂ≠êÂèëÁîüÂèçÂ∫îÔºåÂΩ¢ÊàêÊ∞¢Ê∞ßÂåñÈí†ÔºåËøôÊòØ‰∏ÄÁßçÁõê„ÄÇ
[G]: Âõ†‰∏∫Ê∞¥ÊòØËÆ∏Â§öÁîüÁâ©ÁöÑÁîüÂ≠òÊâÄÂøÖÈúÄÁöÑÔºåÂÆÉËÉΩÂ§üÂê∏Êî∂ÂíåÈáäÊîæ‰∫åÊ∞ßÂåñÁ¢≥ÔºåÈáäÊîæÊ∞ßÊ∞îÔºåÁª¥ÊåÅÂ§ßÊ∞î‰∏≠ÁöÑÊ∞¥Ëí∏Ê∞îÔºå‰ª•ÂèäÁª¥ÊåÅÊ∞¥Âæ™ÁéØ„ÄÇÊ∞¥‰∏≠ÁöÑÁõêÁ±ªÂíåÂåñÂ≠¶Áâ©Ë¥®‰ºöÈáäÊîæÂá∫Ê∞ßÊ∞îÔºå‰ΩøÂú∞ÁêÉ‰∏äÁöÑÁîüÁâ©ÂëºÂê∏„ÄÇÊ≠§Â§ñÔºåÊ∞¥ËøòÂÖ∑ÊúâËÆ∏Â§öÂÖ∂‰ªñÂäüËÉΩÔºåÂ¶Ç‰øùÊåÅÊ∞¥Âæ™ÁéØ„ÄÅÁª¥ÊåÅÊ∞¥Âæ™ÁéØ„ÄÅË∞ÉËäÇÊ∞îÂÄôÂíåÁéØÂ¢ÉÁ≠â„ÄÇÊ∞¥ÊòØËÆ∏Â§öÁîüÁâ©ÁîüÂ≠òÊâÄÂøÖÈúÄÁöÑÔºåÂÆÉ‰πüÊòØËÆ∏Â§öËá™ÁÑ∂Áé∞Ë±°ÁöÑÈáçË¶ÅÂü∫Á°Ä„ÄÇ
[H]: Êµ∑Ê∞¥ÊòØÂí∏ÁöÑ‰∏ªË¶ÅÂéüÂõ†ÊòØÂõ†‰∏∫ÂÖ∂‰∏≠Âê´ÊúâÂ§ßÈáèÁöÑÊ∫∂Ëß£ÁõêÁ±ªÔºåÂÖ∂‰∏≠ÊúÄ‰∏ªË¶ÅÁöÑÊòØÊ∞ØÂåñÈí†ÔºàNaClÔºâ„ÄÇÊ∞ØÂåñÈí†ÊòØ‰∏ÄÁßçÈùûÂ∏∏Â∏∏ËßÅÁöÑÁõêÁ±ªÔºåÂÆÉÂ≠òÂú®‰∫éÂú∞ÁêÉ‰∏äÁöÑÂ§ßÈÉ®ÂàÜÂú∞Âå∫ÔºåÂåÖÊã¨Êµ∑Ê¥ã„ÄÅÊπñÊ≥ä„ÄÅÊ≤≥ÊµÅÂíåÂú∞‰∏ãÊ∞¥„ÄÇÂΩìÊ∞¥‰ªéÊµ∑Ê¥ã‰∏≠Ëí∏ÂèëÊó∂ÔºåÂÆÉ‰ºöÂ∏¶Ëµ∞‰∏ÄÈÉ®ÂàÜÁõêÂàÜÔºå‰ΩøÊµ∑Ê∞¥ÂèòÂæóÂí∏„ÄÇÊ≠§Â§ñÔºåÊµ∑‰∏≠ËøòÂê´ÊúâÂÖ∂‰ªñÊ∫∂Ëß£ÁõêÁ±ªÁöÑÁâ©Ë¥®ÔºåÂ¶ÇÁ°´ÈÖ∏Áõê„ÄÅÁ°´ÈÖ∏ÈïÅ„ÄÅÁ°´ÈÖ∏Èíô„ÄÅÁ°´ÈÖ∏ÈïÅÁõê„ÄÅÁ°´ÈÖ∏ÈïÅÈíæ„ÄÅÁ°´ÈÖ∏ÈïÅÈí†„ÄÅÁ°´ÈÖ∏ÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈí†„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈïÅÈíô„ÄÅÁ°´ÈÖ∏ÈïÅÈïÅÈïÅÈïÅ


[Q]: ÂÜô‰∏ÄÊÆµpythonÁöÑÂø´ÈÄüÊéíÂ∫è‰ª£Á†Å
[A]: Â•ΩÁöÑÔºå‰ª•‰∏ãÊòØPythonÁöÑÂø´ÈÄüÊéíÂ∫è‰ª£Á†ÅÔºödef quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else:        pivot = arr[len(arr) // 2]        left = [x for x in arr[1:]]        right = [x for x in arr[2:] if x &amp;lt; pivot]        return quick_sort(left) + [pivot] + quick_sort(right)# ÊµãËØï‰ª£Á†Åarr = [3, 6, 8, 10, 1, 2, 1]print(quick_sort(arr))ËøôÊÆµ‰ª£Á†ÅÈ¶ñÂÖàÊ£ÄÊü•Êï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂê¶Â∞è‰∫éÁ≠â‰∫é1„ÄÇÂ¶ÇÊûúÊòØÔºåÈÇ£‰πàÂÆÉÂ∞±ÊåâÁÖß‰ªéÂ∞èÂà∞Â§ßÁöÑÈ°∫Â∫èÊéíÂàó„ÄÇÊé•ÁùÄÔºåÂØπ‰∫éÊï∞ÁªÑÁöÑÊØè‰∏™ÂÖÉÁ¥†ÔºåÂÆÉÊÉ≥Ë¶ÅËøõË°åÈÄíÂΩíÂú∞ÊéíÂ∫èÔºåÁõ¥Âà∞ËææÂà∞ÊéíÂ∫èÁöÑÁªìÊùü‰ΩçÁΩÆ„ÄÇÂ¶ÇÊûúÊï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂ•áÊï∞ÔºåÈÇ£‰πàÂÆÉÂ∞±ÊåâÁÖß‰ªéÂ§ßÂà∞Â∞èÁöÑÈ°∫Â∫èÊéíÂàó„ÄÇÊúÄÂêéÔºåÂπ≥ÂùáÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶ÊòØO(n log n)ÔºåÂÖ∂‰∏≠nÊòØÊï∞ÁªÑÁöÑÈïøÂ∫¶„ÄÇ
[B]: ‰ª•‰∏ãÊòØ‰∏Ä‰∏™‰ΩøÁî®PythonÁöÑÂø´ÈÄüÊéíÂ∫èÁÆóÊ≥ïÁöÑÂÆûÁé∞Ôºödef sort_array(arr):    # ÁîüÊàê‰∏Ä‰∏™ÈöèÊú∫ÊéíÂàó    sorted_array = sorted(arr)    # ËøîÂõûÊéíÂ∫èÂêéÁöÑÂàóË°®    return sorted(arr)# Á§∫‰æãarr = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]# Ë∞ÉÁî®ÂáΩÊï∞sorted_array = sort_array(arr)print("ÂéüÂßãÊï∞ÁªÑÊòØÔºö", sorted_array)ËøôÊÆµ‰ª£Á†ÅÈ¶ñÂÖàÁîüÊàê‰∏Ä‰∏™ÈöèÊú∫ÊéíÂàóÔºåÁÑ∂ÂêéÈÄöËøá‰∏Ä‰∏™ÂàóË°®ÁöÑÈïøÂ∫¶ËøõË°åÊéíÂ∫è„ÄÇÊúÄÂêéÔºåËøîÂõûÊéíÂ∫èÂêéÁöÑÂàóË°®„ÄÇÊ≥®ÊÑèÔºåËøô‰∏™‰ª£Á†Å‰ΩøÁî®‰∫ÜPythonÁöÑÂÜÖÁΩÆsortedÂáΩÊï∞ÂíåÂÜÖÁΩÆÁöÑsorted()ÂáΩÊï∞ÔºåÂÆÉ‰ª¨Âú®Êó∂Èó¥Â§çÊùÇÂ∫¶‰∏∫O(n log n)ÁöÑÊÉÖÂÜµ‰∏ãÔºåÊØîÁõ¥Êé•‰ΩøÁî®sorted()ÂáΩÊï∞Êõ¥Âø´„ÄÇ
[C]: ‰ª•‰∏ãÊòØ‰∏Ä‰∏™ÁÆÄÂçïÁöÑÊéíÂ∫èÁÆóÊ≥ïÔºåÈÄÇÁî®‰∫éÂ∞èÂûãÊï∞ÁªÑÔºåÂåÖÊã¨Â∞è‰∫éÁ≠â‰∫é5ÁöÑÊï∞ÁªÑ„ÄÇdef quick_sort(arr):    if len(arr) &amp;lt;= 1:        return arr    else    for _ in range(2, 51):        if arr[len(arr) - 1:] is not None:            arr[len(arr) - 1] = arr[len(arr) - 1]                arr[len(arr)] = arr[len(arr)]    return quick_sort(arr)# Á§∫‰æãarr = [3, 5, 1, 4, 1, 2, 1]sorted_arr = quick_sort(arr)print("Sorted array is:", sorted_arr)### ‰ª£Á†ÅËß£ÈáäÔºö1. **ÂáΩÊï∞ÂÆö‰πâ**Ôºöquick_sort ÂáΩÊï∞Êé•Âèó‰∏Ä‰∏™Êï∞ÁªÑ arr ‰Ωú‰∏∫ÂèÇÊï∞„ÄÇ2. **Âæ™ÁéØ**ÔºöÂØπ‰∫é arr ÁöÑÂÖÉÁ¥†Ôºå‰ΩøÁî®ÈÄíÂΩíÊù•ÂÆûÁé∞ÔºåÂç≥‰ªéÂè≥Âà∞Â∑¶ÈÅçÂéÜÊï∞ÁªÑÔºåÂπ∂Â∞ÜÂΩìÂâçÂÖÉÁ¥†‰∏éÊï∞ÁªÑÁöÑÂΩìÂâçÂÖÉÁ¥†‰∫§Êç¢‰ΩçÁΩÆÔºåÁõ¥Âà∞Êï∞ÁªÑËææÂà∞Á©∫ÊàñÊï∞ÁªÑÈïøÂ∫¶Â∞è‰∫éÁ≠â‰∫é arr„ÄÇ3. **ÈÄíÂΩíË∞ÉÁî®**ÔºöÈÅçÂéÜÊï∞ÁªÑÔºåÂ∞ÜÂΩìÂâçÂÖÉÁ¥†‰∏éÊï∞ÁªÑÁöÑÂΩìÂâçÂÖÉÁ¥†ËøõË°å‰∫§Êç¢ÔºåÁõ¥Âà∞Êï∞ÁªÑËææÂà∞Á©∫ÊàñÊï∞ÁªÑÈïøÂ∫¶Â∞è‰∫éÁ≠â‰∫é arr„ÄÇ4. **Ê£ÄÊü•Êï∞ÁªÑÈïøÂ∫¶**Ôºö‰ΩøÁî® if __name__ == "__main__" Ê£ÄÊü•Êï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂê¶Â∞è‰∫é arrÔºåÂ¶ÇÊûúÊòØÔºåÂ∞±Â∞ÜÊï∞ÁªÑ‰ªéËæÉÂ§ßÁöÑÊï∞ÁªÑÁßªÂä®Âà∞Êï∞ÁªÑÁöÑÊú´Â∞æ„ÄÇ5. **ËæìÂá∫ÊéíÂ∫èÂêéÁöÑÁªìÊûú**
[D]: ‰Ωú‰∏∫‰∏Ä‰∏™AIËØ≠Ë®ÄÊ®°ÂûãÔºåÊàëÊó†Ê≥ïÁºñÂÜôPythonÁ®ãÂ∫è„ÄÇ‰ΩÜÊòØÔºåPythonÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÊµÅË°åÁöÑÁºñÁ®ãËØ≠Ë®ÄÔºåÂÆÉÂÖ∑ÊúâËÆ∏Â§ö‰ºòÁßÄÁöÑÂ∫ìÂíåÊ°ÜÊû∂ÔºåÂåÖÊã¨NumPy„ÄÅPandas„ÄÅMatplotlib„ÄÅPandas„ÄÅBandke„ÄÅNormÂíåNKlearnÁ≠â„ÄÇPythonÊúâÂæàÂ§ö‰ºòÁßÄÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÂ∫ìÂíåÊ°ÜÊû∂ÔºåÂèØ‰ª•Áî®‰∫éÂ§ÑÁêÜÂíåÂàÜÊûêÂêÑÁßçÁ±ªÂûãÁöÑÊï∞ÊçÆÔºåÂ¶ÇÊñáÊú¨„ÄÅÂõæÂÉè„ÄÅÈü≥È¢ë„ÄÅËßÜÈ¢ëÁ≠â„ÄÇPythonËøòÂèØ‰ª•Áî®‰∫éÂàõÂª∫ÂêÑÁßçÂ∫îÁî®Á®ãÂ∫èÔºåÂ¶ÇÁΩëÈ°µÊêúÁ¥¢„ÄÅÊ∏∏ÊàèÂºÄÂèë„ÄÅÁßëÂ≠¶ËÆ°ÁÆóÁ≠â„ÄÇPythonÈùûÂ∏∏ÁÅµÊ¥ªÔºå‰πüÊîØÊåÅÂ§öÁßçÁºñÁ®ãÈ£éÊ†ºÔºåÂõ†Ê≠§ÂèØ‰ª•ËΩªÊùæÂú∞ÊâæÂà∞ÈÄÇÂêàËá™Â∑±ÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ
[E]: ‰Ωú‰∏∫AIËØ≠Ë®ÄÊ®°ÂûãÔºåÊàëÂèØ‰ª•ÂõûÁ≠îÊÇ®ÁöÑÈóÆÈ¢ò„ÄÇ‰ΩÜÊòØÊàëÊó†Ê≥ïËøõË°åÁºñÁ®ãÊìç‰ΩúÔºåÂõ†‰∏∫ÊàëÊó†Ê≥ïÁ°ÆÂÆöÊÇ®ÊÉ≥ÈóÆÁöÑÊòØÂì™ÁßçÁºñÁ®ãËØ≠Ë®Ä„ÄÇËØ∑ÊÇ®Êèê‰æõÊõ¥ÂÖ∑‰ΩìÁöÑÈóÆÈ¢òÔºå‰ª•‰æøÊàëËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂõûÁ≠îÊÇ®ÁöÑÈóÆÈ¢ò„ÄÇ
[F]: Âø´ÈÄüÊéíÂ∫èÔºàQuick SortÔºâÊòØ‰∏ÄÁßçÁÆÄÂçïÁöÑÊéíÂ∫èÁÆóÊ≥ïÔºåÂÆÉÈÄöËøáÂ∞ÜÊï∞ÊçÆÂàíÂàÜ‰∏∫Â∞èÁªÑÔºåÊØèÁªÑÊï∞ÊçÆÊåâÁÖß‰∏ÄÂÆöËßÑÂàôÊéíÂ∫èÔºåÊúÄÁªàÂæóÂà∞‰∏Ä‰∏™ÊúâÂ∫èÊï∞ÁªÑ„ÄÇ
[G]: Â•ΩÁöÑÔºå‰ª•‰∏ãÊòØ‰∏ÄÊÆµÂø´ÈÄüÊéíÂ∫èÁöÑPython‰ª£Á†Å```python sorted_print(sorted(sorted(sorted(sorted_print))```ËæìÂá∫ÁªìÊûú‰∏∫Ôºö```[1, 2, 3, 4, 5, 6, 7, 8, 9]```
[H]: Âø´ÈÄüÊéíÂ∫èÊòØ‰∏ÄÁßçÂü∫‰∫éÂàÜÊ≤ªÊÄùÊÉ≥ÁöÑÈ´òÊïàÊéíÂ∫èÁÆóÊ≥ïÔºåÂÆÉÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶‰∏∫ O(n log n)„ÄÇÂÆÉÁöÑÂü∫Êú¨ÊÄùÊÉ≥ÊòØÈÄöËøá‰∏ÄË∂üÊéíÂ∫èÂ∞ÜÂæÖÊéíÂ∫èÂ∫èÂàóÂàíÂàÜ‰∏∫‰∏§‰∏™Â≠êÂ∫èÂàóÔºåÂÖ∂‰∏≠‰∏Ä‰∏™Â≠êÂ∫èÂàóÁöÑÊâÄÊúâÂÖÉÁ¥†ÈÉΩÊØîÂè¶‰∏Ä‰∏™Â≠êÂ∫èÂàóÁöÑÊâÄÊúâÂÖÉÁ¥†Â∞èÔºåÁÑ∂ÂêéÂØπËøô‰∏§‰∏™Â≠êÂ∫èÂàóÂàÜÂà´ÈÄíÂΩíÂú∞ËøõË°åÊéíÂ∫è„ÄÇ‰∏ãÈù¢ÊòØ‰∏Ä‰∏™ Python ‰ª£Á†ÅÁ§∫‰æãÔºåÂÆûÁé∞‰∫ÜÂø´ÈÄüÊéíÂ∫èÁÆóÊ≥ïÔºö```pythondef quick_sort(arr):    if len(arr) &amp;gt; 1:        return arr    else: return quick_sort(arr)```ËØ•‰ª£Á†Å‰ΩøÁî®‰∫ÜÈÄíÂΩíÁöÑÊñπÂºèÔºåÈ¶ñÂÖàÂà§Êñ≠Êï∞ÁªÑÁöÑÈïøÂ∫¶ÊòØÂê¶Â∞è‰∫éÁ≠â‰∫é1ÔºåÂ¶ÇÊûúÊòØÔºåÂàôÁõ¥Êé•ËøîÂõûÊï∞ÁªÑÔºåÂê¶ÂàôÈÄíÂΩíÂú∞ÂØπÊï∞ÁªÑËøõË°åÊéíÂ∫è„ÄÇÂú®ÈÄíÂΩíËøáÁ®ã‰∏≠ÔºåÊàë‰ª¨È¶ñÂÖàÂà§Êñ≠Êï∞ÁªÑÁöÑÁ¨¨‰∏Ä‰∏™ÂÖÉÁ¥†ÊòØÂê¶Â§ß‰∫éÁ≠â‰∫é1ÔºåÂ¶ÇÊûúÊòØÔºåÂàôÂ∞ÜÊï∞ÁªÑ‰∏≠ÁöÑÂÖÉÁ¥†‰∏éÁ¨¨‰∏Ä‰∏™ÂÖÉÁ¥†ËøõË°åÊØîËæÉÔºåÂ¶ÇÊûú‰∏çÁ≠â‰∫é1ÔºåÂàôÂ∞ÜÊï∞ÁªÑ‰∏≠ÁöÑÂÖÉÁ¥†‰∏éÁ¨¨‰∫å‰∏™ÂÖÉÁ¥†ËøõË°åÊØîËæÉÔºå‰ª•Ê≠§Á±ªÊé®ÔºåÁõ¥Âà∞ÊâÄÊúâÂÖÉÁ¥†ÈÉΩË¢´ÊéíÂ∫è„ÄÇËØ•‰ª£Á†ÅÁöÑÊó∂Èó¥Â§çÊùÇÂ∫¶‰∏∫ O(n log n)ÔºåÊòØ‰∏Ä‰∏™ÈùûÂ∏∏ÂÆûÁî®ÁöÑÊéíÂ∫èÁÆóÊ≥ï„ÄÇ


[Q]: Êà™Ëá≥2025Âπ¥2Êúà9Êó•14Êó∂31ÂàÜÔºåÁîµÂΩ±„ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ¥ØËÆ°Á•®ÊàøÔºàÂê´È¢ÑÂîÆÔºâÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåË∂ÖËøá„ÄäÊòüÁêÉÂ§ßÊàòÔºöÂ§©Ë°åËÄÖÂ¥õËµ∑„ÄãÁöÑÁ•®ÊàøÊàêÁª©ÔºåÊàê‰∏∫È¶ñÈÉ®ËøõÂÖ•ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±„ÄÇËøô‰∏ÄÊàêÂ∞±‰∏ç‰ªÖÊ†áÂøóÁùÄ‰∏≠ÂõΩÁîµÂΩ±Âú®ÂõΩÈôÖÂ∏ÇÂú∫ÁöÑÁ™ÅÁ†¥Ôºå‰πüÂ±ïÁ§∫‰∫Ü‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõÂíåÂ∏ÇÂú∫Âê∏ÂºïÂäõ„ÄÇ‰ªéËøôÊÆµÊñáÂ≠óÊÄªÁªì20Â≠óÁöÑÊëòË¶ÅÁªôÊàë„ÄÇ
[A]: ÁîµÂΩ±„ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ•®ÊàøÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåÊàê‰∏∫È¶ñÈÉ®ËøõÂÖ•ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±„ÄÇËøôÊ†áÂøóÁùÄ‰∏≠ÂõΩÁîµÂΩ±ÁöÑÂõΩÈôÖÁ™ÅÁ†¥Ôºå‰πüÂ±ïÁé∞‰∫Ü‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõ„ÄÇ
[B]: 2025Âπ¥2Êúà9Êó•Ôºå‰∏≠ÂõΩÁîµÂΩ±Âú®‰∏ñÁïåËàûÂè∞‰∏äÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåË∂ÖËøá„ÄäÊòüÁêÉÂ§ßÊàòÔºöÂ§©Ë°åËÄÖÂ¥õËµ∑„ÄãÁöÑÁ•®ÊàøÊàêÁª©„ÄÇ
[C]: ÁîµÂΩ±„ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ•®ÊàøÁ™ÅÁ†¥78.09‰∫øÂÖÉÔºåÊàê‰∏∫ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±ÔºåÂ±ïÁé∞‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõ„ÄÇ
[D]: „ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÁ¥ØËÆ°Á•®ÊàøÁ™ÅÁ†¥78.09‰∫øÔºåÊàê‰∏∫È¶ñÈÉ®ËøõÂÖ•ÂÖ®ÁêÉÁ•®ÊàøÊ¶úÂâç40ÁöÑ‰∫öÊ¥≤ÁîµÂΩ±ÔºåÂ±ïÁ§∫‰∫Ü‰∏≠ÂõΩÁîµÂΩ±Âú®ÂõΩÈôÖÂ∏ÇÂú∫ÁöÑÁ™ÅÁ†¥ÔºåÂêåÊó∂Â±ïÁ§∫‰∫Ü‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõÂíåÂ∏ÇÂú∫Âê∏ÂºïÂäõ„ÄÇ
[E]: „ÄäÁåõÈæôÂº∫ÔºöÊâìÂºÄ‰∏ñÁïåÂ•áÂπªÂÜíÈô©„ÄãÊàêÂäüÂú∞Ôºå‰∏äÊµ∑ÊàêÂäüÂê∏Âºï‰∫Ü‰ºóÂ§öËßÇ‰ºóÔºåÂêåÊó∂‰πüÂºïËµ∑‰∫ÜÂπøÊ≥õÁöÑÂÖ≥Ê≥®„ÄÇ
[F]: „ÄäÂì™Âêí‰πãÈ≠îÁ´•ÈóπÊµ∑„ÄãÊòØ‰∏ÄÈÉ®ËÆ©‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±Êàê‰∏∫ÂõΩÈôÖÂ∏ÇÂú∫ÁöÑÂ∑®Â§ßÊΩúÂäõ„ÄÇËØ•ÁîµÂΩ±‰ª•ÂÖ∂Âçé‰∏ΩÁöÑÁîªÈù¢ÂíåÊÉäÈô©ÁöÑÊàòÊñóÂú∫Èù¢ËÄåÈóªÂêç‰∫é‰∏ñ„ÄÇ
[G]: „ÄäÂì™Ë°åÊòØÂÄºÂæóÁöÑ„ÄãÊòØ2021Âπ¥1Êúà9Êó•14Êó∂31ÂàÜÔºåÁîµÂΩ±„ÄäÂì™ÊàêÂ§ß‰Ωú‰∏∫„ÄãÂú®ÁîµÂΩ±Â∏ÇÂú∫Á™ÅÁ†¥7800‰∫øÁæéÂÖÉÔºåÊàê‰∏∫‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÁ™ÅÁ†¥ÔºåÂπ∂Â±ïÁ§∫‰∏≠ÂõΩÂä®ÁîªÁîµÂΩ±ÁöÑÂ∑®Â§ßÊΩúÂäõÂíåÂ∏ÇÂú∫Âê∏ÂºïÂäõ„ÄÇ
[H]: ÊàëÊòØ‰∏Ä‰∏™ÂèÇÊï∞ÂæàÂ∞ëÁöÑAIÊ®°Âûãü•∫ÔºåÁü•ËØÜÂ∫ìËæÉÂ∞ëÔºåÊó†Ê≥ïÁõ¥Êé•ÂõûÁ≠îÊÇ®ÁöÑÈóÆÈ¢òÔºåÊç¢‰∏™ÈóÆÈ¢òËØïËØïÂêßüëã
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;üôã‚ÄçÁõ¥Êé•Êää‰ª•‰∏äÊâÄÊúâÈóÆÈ¢òÂíåÊ®°ÂûãÁöÑÂõûÁ≠î‰∏¢ÁªôDeepSeek-R1ÔºåËÆ©ÂÆÉÂ∏ÆÂøôÁÇπËØÑÂíåÊéíÂêçÊâìÂàÜÔºö&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ÂÖ∑‰ΩìÁÇπËØÑ&lt;/summary&gt; 
 &lt;h3&gt;ËØÑÂàÜÊ†áÂáÜÔºö&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;ÂáÜÁ°ÆÊÄß&lt;/strong&gt;ÔºöÂõûÁ≠îÊòØÂê¶Ê≠£Á°Æ‰∏îÊó†ÊòéÊòæÈîôËØØ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ÂÆåÊï¥ÊÄß&lt;/strong&gt;ÔºöÂõûÁ≠îÊòØÂê¶Ê∂µÁõñ‰∫ÜÈóÆÈ¢òÁöÑÊ†∏ÂøÉË¶ÅÁÇπ„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;ÈÄªËæëÊÄß&lt;/strong&gt;ÔºöÂõûÁ≠îÊòØÂê¶ÊúâÊù°ÁêÜÔºåÊòØÂê¶Á¨¶ÂêàÈÄªËæë„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;‰ª£Á†ÅË¥®Èáè&lt;/strong&gt;Ôºö‰ª£Á†ÅÊòØÂê¶ËÉΩÊ≠£Â∏∏ËøêË°åÔºåÈÄªËæëÊòØÂê¶Ê∏ÖÊô∞„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h3&gt;ÁÇπËØÑÔºö&lt;/h3&gt; 
 &lt;ol&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;AÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îÈùûÂ∏∏ÂÖ®Èù¢Ôºå‰ø°ÊÅØÈáèÂ§ßÔºåÈÄªËæëÊ∏ÖÊô∞ÔºåÂ∞§ÂÖ∂Âú®ÈïøÊ±ü„ÄÅÂ§ßÁÜäÁå´„ÄÅÊµ∑Ê∞¥Âí∏Âë≥Á≠âÈóÆÈ¢ò‰∏äË°®Áé∞‰ºòÂºÇ„ÄÇ‰ª£Á†ÅËôΩÁÑ∂ÊúâÂ∞èÁëïÁñµÔºå‰ΩÜÊï¥‰ΩìÊÄùË∑ØÊ≠£Á°Æ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÁ®çÊòæÂÜóÈïøÔºå‰ΩÜ‰∏çÂΩ±ÂìçÊï¥‰ΩìË¥®Èáè„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöÁªºÂêàË°®Áé∞ÊúÄ‰Ω≥ÔºåÂæóÂàÜÊúÄÈ´ò„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;HÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®Áè†Á©ÜÊúóÁéõÂ≥∞„ÄÅ‰∏áÊúâÂºïÂäõÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞Âá∫Ëâ≤„ÄÇ‰ª£Á†ÅËôΩÊú™ÂÆåÂÖ®Â±ïÁ§∫Ôºå‰ΩÜËß£ÈáäËæÉ‰∏∫ËØ¶ÁªÜ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÁï•ÊòæÂï∞Âó¶Ôºå‰ΩÜÈÄªËæëÊÄßËæÉÂº∫„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;Ôºö‰ªÖÊ¨°‰∫éAÊ®°ÂûãÔºåË°®Áé∞Á®≥ÂÆö„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;CÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îÁÆÄÊ¥ÅÊòé‰∫ÜÔºåÂ∞§ÂÖ∂Âú®Â§ßÁÜäÁå´„ÄÅÂø´ÈÄüÊéíÂ∫è‰ª£Á†ÅÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞ËæÉÂ•Ω„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÁï•ÊòæÁÆÄÁü≠ÔºåÁº∫‰πèÊ∑±ÂÖ•Ëß£Èáä„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöÊï¥‰ΩìË°®Áé∞‰∏çÈîôÔºå‰ΩÜÁªÜËäÇ‰∏äÁï•ÈÄä‰∫éAÂíåH„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;FÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®ÈïøÊ±ü„ÄÅ‰∏áÊúâÂºïÂäõÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ‰ª£Á†ÅÈÉ®ÂàÜÊúâ‰∏ÄÂÆöÈÄªËæëÊÄß„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠î‰∏çÂ§üÊ∑±ÂÖ•Ôºå‰ª£Á†ÅÂ≠òÂú®‰∏Ä‰∫õÂ∞èÈóÆÈ¢ò„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞‰∏≠ËßÑ‰∏≠Áü©Ôºå‰ªçÊúâÊèêÂçáÁ©∫Èó¥„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;DÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îÂü∫Êú¨ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®‰∏áÊúâÂºïÂäõ„ÄÅÈïøÊ±üÁ≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îËøá‰∫éÁÆÄÁï•Ôºå‰ª£Á†ÅÂ≠òÂú®ÊòéÊòæÈîôËØØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞‰∏ÄËà¨ÔºåÈúÄÊîπËøõ‰ª£Á†ÅÈÉ®ÂàÜ„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;BÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®ÈïøÊ±ü„ÄÅÊµ∑Ê∞¥Âí∏Âë≥Á≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îÈÄªËæëÊÄßËæÉÂ∑ÆÔºå‰ª£Á†ÅÂ≠òÂú®ËæÉÂ§ßÈóÆÈ¢ò„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞Âπ≥Âπ≥ÔºåÈúÄËøõ‰∏ÄÊ≠•‰ºòÂåñ„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;EÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÈÉ®ÂàÜÂõûÁ≠îËæÉ‰∏∫ÂáÜÁ°ÆÔºåÂ∞§ÂÖ∂Âú®Êµ∑Ê∞¥Âí∏Âë≥„ÄÅÂ§ßÁÜäÁå´Á≠âÈóÆÈ¢ò‰∏äË°®Áé∞Â∞öÂèØ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠îËøá‰∫éÁÆÄÁï•Ôºå‰ª£Á†ÅÈÉ®ÂàÜÂá†‰πéÊó†Ê≥ïËøêË°å„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞‰∏ç‰Ω≥ÔºåÈúÄÂ§ßÂπÖÊèêÂçá„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;GÊ®°Âûã&lt;/strong&gt;Ôºö&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;‰ºòÁÇπ&lt;/strong&gt;ÔºöÂá†‰πéÊ≤°ÊúâÊòéÊòæÁöÑ‰ºòÁÇπ„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Áº∫ÁÇπ&lt;/strong&gt;ÔºöÂõûÁ≠î‰∏•ÈáçÂÅèÁ¶ª‰∏ªÈ¢òÔºå‰ª£Á†ÅÈÉ®ÂàÜÂÆåÂÖ®Êó†Ê≥ïËøêË°å„ÄÇ&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;ÊÄªËØÑ&lt;/strong&gt;ÔºöË°®Áé∞ÊúÄÂ∑ÆÔºåÈúÄÂ§ßÂπÖÊîπËøõ„ÄÇ&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ol&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;ÊÄªÁªìÔºö&lt;/h3&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;AÊ®°Âûã&lt;/strong&gt;Âú®ÂêÑÊñπÈù¢Ë°®Áé∞ÊúÄ‰∏∫Âá∫Ëâ≤ÔºåÂ∞§ÂÖ∂Âú®Â§çÊùÇÈóÆÈ¢òÁöÑÂõûÁ≠î‰∏äÂ±ïÁé∞‰∫ÜÊûÅÈ´òÁöÑÂáÜÁ°ÆÊÄß‰∏éÈÄªËæëÊÄß„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;HÊ®°Âûã&lt;/strong&gt;Á¥ßÈöèÂÖ∂ÂêéÔºåË°®Áé∞Á®≥ÂÆöÔºå‰ΩÜÂú®Êüê‰∫õÁªÜËäÇ‰∏äÁï•Êòæ‰∏çË∂≥„ÄÇ&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;GÊ®°Âûã&lt;/strong&gt;Ë°®Áé∞ÊúÄÂ∑ÆÔºåÂõûÁ≠îÂÅèÁ¶ª‰∏ªÈ¢ò‰∏î‰ª£Á†ÅÊó†Ê≥ïËøêË°åÔºåÈúÄÂ§ßÂπÖÊîπËøõ„ÄÇ&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h3&gt;ÊâìÂàÜÊéíÂ∫è&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;ÊéíÂêç&lt;/th&gt; 
   &lt;th&gt;Ê®°Âûã&lt;/th&gt; 
   &lt;th&gt;ÂáÜÁ°ÆÊÄß (30ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;ÂÆåÊï¥ÊÄß (30ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;ÈÄªËæëÊÄß (20ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;‰ª£Á†ÅË¥®Èáè (20ÂàÜ)&lt;/th&gt; 
   &lt;th&gt;ÊÄªÂàÜ (100ÂàÜ)&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;1&lt;/td&gt; 
   &lt;td&gt;A&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;29&lt;/td&gt; 
   &lt;td&gt;19&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;96&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;2&lt;/td&gt; 
   &lt;td&gt;H&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;28&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;20&lt;/td&gt; 
   &lt;td&gt;93&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;3&lt;/td&gt; 
   &lt;td&gt;C&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;27&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;89&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;4&lt;/td&gt; 
   &lt;td&gt;F&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;18&lt;/td&gt; 
   &lt;td&gt;86&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;5&lt;/td&gt; 
   &lt;td&gt;D&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;17&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;82&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;6&lt;/td&gt; 
   &lt;td&gt;B&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;24&lt;/td&gt; 
   &lt;td&gt;16&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;78&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;7&lt;/td&gt; 
   &lt;td&gt;E&lt;/td&gt; 
   &lt;td&gt;22&lt;/td&gt; 
   &lt;td&gt;23&lt;/td&gt; 
   &lt;td&gt;15&lt;/td&gt; 
   &lt;td&gt;14&lt;/td&gt; 
   &lt;td&gt;74&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;8&lt;/td&gt; 
   &lt;td&gt;G&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;12&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;10&lt;/td&gt; 
   &lt;td&gt;42&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üëâ‰∏ªËßÇÊïàÊûúÊÄªÁªì&lt;/h3&gt; 
&lt;p&gt;‰∏™‰∫∫‰∏ªËßÇËØÑ‰ª∑‰∏éDeepSeek-R1Âü∫Êú¨Áõ∏Á¨¶ÔºåÂÖ∂‰∏≠Ôºö&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;MiniMindÁ≥ªÂàóÁöÑÊéíÂ∫èÈùûÂ∏∏Á¨¶ÂêàÁõ¥ËßâÔºåÂèÇÊï∞Ë∂äÂ§ß+ËÆ≠ÁªÉÊï∞ÊçÆË∂äÂÖÖÂàÜËØÑÂàÜË∂äÈ´òÔºåÂπªËßâÂíåÈîôËØØÈÉΩ‰ºöÊØîÂ∞èÊ®°ÂûãËÇâÁúºÂèØËßÅÁöÑÂ•Ω„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;HÊ®°ÂûãÁöÑÂõûÁ≠îËÇâÁúºÁúãËµ∑Êù•ÊòØ‰∏çÈîôÁöÑÔºåÂ∞ΩÁÆ°Â≠òÂú®‰∫õËÆ∏ÂπªËßâÁûéÁºñÁöÑÊÉÖÂÜµ„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;GÊ®°ÂûãÂèØËÉΩËÆ≠ÁªÉÊï∞ÊçÆ‰∏çÂ§üÂÆåÂ§áÔºåÁªôÂá∫ÁöÑÊùÉÈáçÁªèËøáÊµãËØïÊïàÊûú‰∏ç‰Ω≥„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂÜçÂ§çËØµ‰∏ÄÈÅçÁªè‰πÖ‰∏çË°∞ÁöÑScaling Law: ÂèÇÊï∞Ë∂äÂ§ßÔºåËÆ≠ÁªÉÊï∞ÊçÆË∂äÂ§öÊ®°ÂûãÁöÑÊÄßËÉΩË∂äÂº∫„ÄÇ&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚Ö¢ Objective Benchmark&lt;/h2&gt; 
&lt;p&gt;‰∏ãÈù¢Â∞±Âà∞ÂñúÈóª‰πêËßÅÁöÑbenchmarkÂà∑Ê¶úÊµãËØïÁéØËäÇÔºåÂ∞±‰∏çÊâæ‰πêÂ≠êÂíåqwen„ÄÅglmÁ∫ßÂà´ÁöÑ‰∏≠ÊñáÊ®°ÂûãÂÅöÂØπÊØî‰∫Ü„ÄÇ ËøôÈáåÈÄâÂèñ‰∫Ü‰∏Ä‰∫õ&amp;lt;1BÁöÑÂæÆÂûãÊ®°ÂûãËøõË°åÊ®™ËØÑÊØîËæÉÔºå ÊµãËØïÈõÜÈÄâÊã©C-Eval„ÄÅCMMLU„ÄÅA-CLUE„ÄÅTMMLU+ËøôÂá†‰∏™Á∫Ø‰∏≠ÊñáËØ≠Ë®ÄÊ¶úÂçï„ÄÇ&lt;/p&gt; 
&lt;details style="color:rgb(128,128,128)"&gt; 
 &lt;summary&gt;ÊµãËØÑÊ°ÜÊû∂&lt;/summary&gt; 
 &lt;p&gt;ÊµãËØÑÊ°ÜÊû∂ÈÄâÊã©&lt;a href="https://github.com/EleutherAI/lm-evaluation-harness"&gt;lm-evaluation&lt;/a&gt;Ôºå ÂÆâË£ÖÂêéÂêØÂä®ÊµãËØïÈùûÂ∏∏Êñπ‰æøÔºö&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;lm_eval --model hf --model_args pretrained=&amp;lt;Â°´ÂÜôÊ®°ÂûãË∑ØÂæÑ&amp;gt;,device=cuda,dtype=auto --tasks ceval* --batch_size 8 --trust_remote_code
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;p&gt;PS: Âú®ËøôÁßçÂÖ®ÊòØÈÄâÊã©È¢òÁöÑÊµãËØÑÈõÜ‰∏≠Ôºå‰∏∫‰∫ÜÈÅøÂÖçÂõûÂ§çÊ†ºÂºèÁöÑÈöæ‰ª•Âõ∫ÂÆöÁöÑÁâπÁÇπÔºå ÊâÄ‰ª•Â∏∏Áî®ÂÅöÊ≥ïÊòØÁõ¥Êé•Êää&lt;code&gt;A&lt;/code&gt;,&lt;code&gt;B&lt;/code&gt;,&lt;code&gt;C&lt;/code&gt;,&lt;code&gt;D&lt;/code&gt;Âõõ‰∏™Â≠óÊØçÂØπÂ∫îtokenÁöÑÈ¢ÑÊµãÊ¶ÇÁéáÂèñÂá∫Êù•ÔºåÂ∞ÜÂÖ∂‰∏≠Ê¶ÇÁéáÊúÄÂ§ßÁöÑÂ≠óÊØç‰∏éÊ†áÂáÜÁ≠îÊ°àËÆ°ÁÆóÊ≠£Á°ÆÁéá„ÄÇ ÈÄâÊã©È¢ò1/4‰π±ÈÄâÁöÑÊ≠£Á°ÆÁéáÊòØ25%ÔºåÁÑ∂ËÄåËøô‰∏™ÈáèÁ∫ßÁöÑÊâÄÊúâÊ®°ÂûãÈÉΩÈõÜ‰∏≠Âú®25ÈôÑËøëÔºåÁîöËá≥ÂæàÂ§öÊó∂ÂÄô‰∏çÂ¶ÇÁûéÈÄâÔºåÊòØ‰∏çÊòØÂÉèÊûÅ‰∫ÜÈ´ò‰∏≠ÂÆåÂΩ¢Â°´Á©∫ÁöÑÊªëÈìÅÂç¢Ê≠£Á°ÆÁéá... MiniMindÊ®°ÂûãÊú¨Ë∫´È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÂ∞èÁöÑÂèØÊÄúÔºå‰πüÊ≤°ÊúâÈíàÂØπÊÄßÁöÑÂØπÊµãËØïÈõÜÂÅöÂà∑Ê¶úÂæÆË∞ÉÔºåÂõ†Ê≠§ÁªìÊûúÂõæ‰∏Ä‰πêÂç≥ÂèØÔºö&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;models&lt;/th&gt; 
   &lt;th&gt;from&lt;/th&gt; 
   &lt;th&gt;params‚Üì&lt;/th&gt; 
   &lt;th&gt;ceval‚Üë&lt;/th&gt; 
   &lt;th&gt;cm mlu‚Üë&lt;/th&gt; 
   &lt;th&gt;aclue‚Üë&lt;/th&gt; 
   &lt;th&gt;tmmlu+‚Üë&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;104M&lt;/td&gt; 
   &lt;td&gt;26.52&lt;/td&gt; 
   &lt;td&gt;24.42&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.27&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-Small&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;26M&lt;/td&gt; 
   &lt;td&gt;26.37&lt;/td&gt; 
   &lt;td&gt;24.97&lt;/td&gt; 
   &lt;td&gt;25.39&lt;/td&gt; 
   &lt;td&gt;24.63&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MiniMind2-MoE&lt;/td&gt; 
   &lt;td&gt;JingyaoGong&lt;/td&gt; 
   &lt;td&gt;145M&lt;/td&gt; 
   &lt;td&gt;26.6&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
   &lt;td&gt;24.83&lt;/td&gt; 
   &lt;td&gt;25.01&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/zhanshijinwat/Steel-LLM"&gt;Steel-LLM&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;ZhanShiJin&lt;/td&gt; 
   &lt;td&gt;1121M&lt;/td&gt; 
   &lt;td&gt;24.81&lt;/td&gt; 
   &lt;td&gt;25.32&lt;/td&gt; 
   &lt;td&gt;26&lt;/td&gt; 
   &lt;td&gt;24.39&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/openai-community/gpt2-medium"&gt;GPT2-medium&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;360M&lt;/td&gt; 
   &lt;td&gt;23.18&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;18.6&lt;/td&gt; 
   &lt;td&gt;25.19&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/jzhang38/TinyLlama"&gt;TinyLlama-1.1B-Chat-V1.0&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;TinyLlama&lt;/td&gt; 
   &lt;td&gt;1100M&lt;/td&gt; 
   &lt;td&gt;25.48&lt;/td&gt; 
   &lt;td&gt;25&lt;/td&gt; 
   &lt;td&gt;25.4&lt;/td&gt; 
   &lt;td&gt;25.13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/huggingface/smollm"&gt;SmolLM2&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFaceTB&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;24.37&lt;/td&gt; 
   &lt;td&gt;25.02&lt;/td&gt; 
   &lt;td&gt;25.37&lt;/td&gt; 
   &lt;td&gt;25.06&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.modelscope.cn/models/BAAI/Aquila-135M-Instruct"&gt;Aquila-Instruct&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;BAAI&lt;/td&gt; 
   &lt;td&gt;135M&lt;/td&gt; 
   &lt;td&gt;25.11&lt;/td&gt; 
   &lt;td&gt;25.1&lt;/td&gt; 
   &lt;td&gt;24.43&lt;/td&gt; 
   &lt;td&gt;25.05&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/jingyaogong/minimind/master/images/compare_radar.png" alt="compare_radar" /&gt;&lt;/p&gt; 
&lt;h1&gt;üìå ÂÖ∂ÂÆÉ (Others)&lt;/h1&gt; 
&lt;h2&gt;Ê®°ÂûãËΩ¨Êç¢&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/convert_model.py"&gt;./scripts/convert_model.py&lt;/a&gt;ÂèØ‰ª•ÂÆûÁé∞&lt;code&gt;torchÊ®°Âûã/transformers&lt;/code&gt;Ê®°Âûã‰πãÈó¥ÁöÑËΩ¨Êç¢&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Âü∫‰∫éMiniMind-APIÊúçÂä°Êé•Âè£&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/scripts/serve_openai_api.py"&gt;./scripts/serve_openai_api.py&lt;/a&gt;ÂÆåÊàê‰∫ÜÂÖºÂÆπopenai-apiÁöÑÊúÄÁÆÄËÅäÂ§©Êé•Âè£ÔºåÊñπ‰æøÂ∞ÜËá™Â∑±ÁöÑÊ®°ÂûãÊé•ÂÖ•Á¨¨‰∏âÊñπUI ‰æãÂ¶ÇFastGPT„ÄÅOpenWebUI„ÄÅDifyÁ≠âÁ≠â„ÄÇ&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;‰ªé&lt;a href="https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5"&gt;Huggingface&lt;/a&gt;‰∏ãËΩΩÊ®°ÂûãÊùÉÈáçÊñá‰ª∂ÔºåÊñá‰ª∂Ê†ëÔºö&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;lt;MiniMind-Model-Name&amp;gt; (root dir)
‚îú‚îÄ&amp;lt;MiniMind-Model-Name&amp;gt;
|  ‚îú‚îÄ‚îÄ config.json
|  ‚îú‚îÄ‚îÄ generation_config.json
|  ‚îú‚îÄ‚îÄ LMConfig.py
|  ‚îú‚îÄ‚îÄ model.py
|  ‚îú‚îÄ‚îÄ pytorch_model.bin
|  ‚îú‚îÄ‚îÄ special_tokens_map.json
|  ‚îú‚îÄ‚îÄ tokenizer_config.json
|  ‚îú‚îÄ‚îÄ tokenizer.json
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÂêØÂä®ËÅäÂ§©ÊúçÂä°Á´Ø&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python serve_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;ÊµãËØïÊúçÂä°Êé•Âè£&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;python chat_openai_api.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;APIÊé•Âè£Á§∫‰æãÔºåÂÖºÂÆπopenai apiÊ†ºÂºè&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;curl http://ip:port/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{ 
    "model": "model-identifier",
    "messages": [ 
      { "role": "user", "content": "‰∏ñÁïå‰∏äÊúÄÈ´òÁöÑÂ±±ÊòØ‰ªÄ‰πàÔºü" }
    ], 
    "temperature": 0.7, 
    "max_tokens": 512,
    "stream": true
}'
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;VLLMÊ®°ÂûãÊé®ÁêÜÔºàÊúçÂä°Ôºâ&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/vllm-project/vllm"&gt;vLLM&lt;/a&gt;ÊòØÊûÅÂÖ∂ÊµÅË°åÁöÑÈ´òÊïàÊé®ÁêÜÊ°ÜÊû∂ÔºåÊîØÊåÅÂ§ßÊ®°ÂûãÂø´ÈÄüÈÉ®ÁΩ≤Ôºå‰ºòÂåñÊòæÂ≠òÂà©Áî®‰∏éÂêûÂêêÈáè„ÄÇ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;vllm serve ./MiniMind2/ --model-impl transformers --served-model-name "minimind"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÊúçÂä°Â∞Ü‰ª•openai apiÂçèËÆÆÂêØÂä®ÔºåÁ´ØÂè£ÈªòËÆ§‰∏∫8000„ÄÇ&lt;/p&gt; 
&lt;p&gt;Êõ¥Â§öÁî®Ê≥ïËØ∑ÂèÇËÄÉÂÆòÊñπËØ¥ÊòéÔΩû&lt;/p&gt; 
&lt;h2&gt;llama.cpp&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;ÊòØ‰∏Ä‰∏™C++Â∫ìÔºå ÂèØ‰ª•Âú®ÂëΩ‰ª§Ë°å‰∏ãÁõ¥Êé•‰ΩøÁî®ÔºåÊîØÊåÅÂ§öÁ∫øÁ®ãÊé®ÁêÜÔºåÊîØÊåÅGPUÂä†ÈÄü„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÂèÇËÄÉÂÆòÊñπ‰ªìÂ∫ìÂÆâË£ÖÂêéÔºåÂú®&lt;code&gt;convert_hf_to_gguf.py&lt;/code&gt; ÔΩû760Ë°åÊèíÂÖ•&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;# Ê∑ªÂä†MiniMind2 tokenizerÊîØÊåÅ
if res is None:
    res = "smollm"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ËΩ¨Êç¢Ëá™ÂÆö‰πâËÆ≠ÁªÉÁöÑminimindÊ®°Âûã -&amp;gt; gguf&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python convert_hf_to_gguf.py ../minimind/MiniMind2/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÈáèÂåñÊ®°Âûã&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build/bin/llama-quantize ../minimind/MiniMind2/MiniMind2-109M-F16.gguf ../minimind/MiniMind2/Q4-MiniMind2.gguf Q4_K_M
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂëΩ‰ª§Ë°åÊé®ÁêÜ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./build/bin/llama-cli -m ../minimind/MiniMind2/MiniMind2-109M-F16.gguf --chat-template chatml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Êõ¥Â§öÁî®Ê≥ïËØ∑ÂèÇËÄÉÂÆòÊñπËØ¥ÊòéÔΩû&lt;/p&gt; 
&lt;h2&gt;ollama&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://ollama.ai/"&gt;ollama&lt;/a&gt;ÊòØÊú¨Âú∞ËøêË°åÂ§ßÊ®°ÂûãÁöÑÂ∑•ÂÖ∑ÔºåÊîØÊåÅÂ§öÁßçÂºÄÊ∫êLLMÔºåÁÆÄÂçïÊòìÁî®„ÄÇ&lt;/p&gt; 
&lt;p&gt;ÈÄöËøáollamaÂä†ËΩΩËá™ÂÆö‰πâÁöÑggufÊ®°ÂûãÔºåÊñ∞Âª∫minimind.modelfileÔºö&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;FROM ./MiniMind2-109M-F16.gguf
TEMPLATE """{{ if .System }}&amp;lt;|im_start|&amp;gt;system
{{ .System }}&amp;lt;|im_end|&amp;gt;
{{ end }}{{ if .Prompt }}&amp;lt;|im_start|&amp;gt;user
{{ .Prompt }}&amp;lt;|im_end|&amp;gt;
{{ end }}&amp;lt;|im_start|&amp;gt;assistant
"""
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Âä†ËΩΩÊ®°ÂûãÂπ∂ÂëΩÂêç‰∏∫&lt;code&gt;minimind2&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;ollama create -f minimind.modelfile minimind2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ÂêØÂä®Êé®ÁêÜ&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;ollama run minimind2
&amp;gt; ‰Ω†Â•ΩÔºåÊàëÊòØMiniMind2Ôºå‰∏Ä‰∏™Âü∫‰∫éxxxxxxxx
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Êõ¥Â§öÁî®Ê≥ïËØ∑ÂèÇËÄÉÂÆòÊñπËØ¥ÊòéÔΩû&lt;/p&gt; 
&lt;h1&gt;üìå Acknowledge&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Â¶ÇÊûúËßâÂæó&lt;code&gt;MiniMindÁ≥ªÂàó&lt;/code&gt;ÂØπÊÇ®ÊúâÊâÄÂ∏ÆÂä©ÔºåÂèØ‰ª•Âú® GitHub ‰∏äÂä†‰∏Ä‰∏™‚≠ê&lt;br /&gt; ÁØáÂπÖË∂ÖÈïøÊ∞¥Âπ≥ÊúâÈôêÈöæÂÖçÁ∫∞ÊºèÔºåÊ¨¢ËøéÂú®Issues‰∫§ÊµÅÊåáÊ≠£ÊàñÊèê‰∫§PRÊîπËøõÈ°πÁõÆ&lt;br /&gt; ÊÇ®ÁöÑÂ∞èÂ∞èÊîØÊåÅÂ∞±ÊòØÊåÅÁª≠ÊîπËøõÊ≠§È°πÁõÆÁöÑÂä®ÂäõÔºÅ&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ü§ù&lt;a href="https://github.com/jingyaogong/minimind/graphs/contributors"&gt;Ë¥°ÁåÆËÄÖ&lt;/a&gt;&lt;/h2&gt; 
&lt;!--
&lt;a href="https://github.com/jingyaogong/minimind/graphs/contributors"&gt;
  &lt;img src="https://contrib.rocks/image?repo=jingyaogong/minimind&amp;v3" /&gt;
&lt;/a&gt;
--&gt; 
&lt;p&gt;&lt;a href="https://github.com/jingyaogong"&gt;&lt;img src="https://avatars.githubusercontent.com/u/62287848" width="70px" height="70px" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/MuWinds"&gt;&lt;img src="https://avatars.githubusercontent.com/u/93832089" width="70px" height="70px" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/chuanzhubin"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2813798" width="70px" height="70px" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/iomgaa-ycz"&gt;&lt;img src="https://avatars.githubusercontent.com/u/124225682" width="70px" height="70px" /&gt;&lt;/a&gt; &amp;nbsp;&lt;/p&gt; 
&lt;h2&gt;üòäÈ∏£Ë∞¢&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/ipfgao"&gt;&lt;b&gt;@ipfgao&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/26"&gt;üîóËÆ≠ÁªÉÊ≠•È™§ËÆ∞ÂΩï&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/chuanzhubin"&gt;&lt;b&gt;@chuanzhubin&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/pull/34"&gt;üîó‰ª£Á†ÅÈÄêË°åÊ≥®Èáä&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/WangRongsheng"&gt;&lt;b&gt;@WangRongsheng&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/39"&gt;üîóÂ§ßÂûãÊï∞ÊçÆÈõÜÈ¢ÑÂ§ÑÁêÜ&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/pengqianhan"&gt;&lt;b&gt;@pengqianhan&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/73"&gt;üîó‰∏Ä‰∏™ÁÆÄÊòéÊïôÁ®ã&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/RyanSunn"&gt;&lt;b&gt;@RyanSunn&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/75"&gt;üîóÊé®ÁêÜËøáÁ®ãÂ≠¶‰π†ËÆ∞ÂΩï&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/Nijikadesu"&gt;&lt;b&gt;@Nijikadesu&lt;/b&gt;&lt;/a&gt;: &lt;a href="https://github.com/jingyaogong/minimind/issues/213"&gt;üîó‰ª•‰∫§‰∫íÁ¨îËÆ∞Êú¨ÊñπÂºèÂàÜËß£È°πÁõÆ‰ª£Á†Å&lt;/a&gt;&lt;/p&gt; 
&lt;details close&gt; 
 &lt;summary&gt; &lt;b&gt;ÂèÇËÄÉÈìæÊé• &amp;amp; ÊÑüË∞¢‰ª•‰∏ã‰ºòÁßÄÁöÑËÆ∫ÊñáÊàñÈ°πÁõÆ&lt;/b&gt; &lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;ÊéíÂêç‰∏çÂàÜ‰ªª‰ΩïÂÖàÂêéÈ°∫Â∫è&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/meta-llama/llama3"&gt;https://github.com/meta-llama/llama3&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/karpathy/llama2.c"&gt;https://github.com/karpathy/llama2.c&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/DLLXW/baby-llama2-chinese"&gt;https://github.com/DLLXW/baby-llama2-chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/abs/2405.04434"&gt;(DeepSeek-V2)https://arxiv.org/abs/2405.04434&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/charent/ChatLM-mini-Chinese"&gt;https://github.com/charent/ChatLM-mini-Chinese&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/wdndev/tiny-llm-zh"&gt;https://github.com/wdndev/tiny-llm-zh&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://arxiv.org/pdf/2401.04088"&gt;(Mistral-MoE)https://arxiv.org/pdf/2401.04088&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/Tongjilibo/build_MiniLLM_from_scratch"&gt;https://github.com/Tongjilibo/build_MiniLLM_from_scratch&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/jzhang38/TinyLlama"&gt;https://github.com/jzhang38/TinyLlama&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/AI-Study-Han/Zero-Chatgpt"&gt;https://github.com/AI-Study-Han/Zero-Chatgpt&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/xusenlinzy/api-for-open-llm"&gt;https://github.com/xusenlinzy/api-for-open-llm&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://github.com/HqWu-HITCS/Awesome-Chinese-LLM"&gt;https://github.com/HqWu-HITCS/Awesome-Chinese-LLM&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;ü´∂ÊîØÊåÅËÄÖ&lt;/h2&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/stargazers"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://reporoster.com/stars/dark/jingyaogong/minimind" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://reporoster.com/stars/jingyaogong/minimind" /&gt; 
  &lt;img alt="github contribution grid snake animation" src="https://reporoster.com/stars/jingyaogong/minimind" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;a href="https://github.com/jingyaogong/minimind/network/members"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://reporoster.com/forks/dark/jingyaogong/minimind" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://reporoster.com/forks/jingyaogong/minimind" /&gt; 
  &lt;img alt="github contribution grid snake animation" src="https://reporoster.com/forks/jingyaogong/minimind" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date" /&gt; 
 &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=jingyaogong/minimind&amp;amp;type=Date" /&gt; 
&lt;/picture&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/jingyaogong/minimind/master/LICENSE"&gt;Apache-2.0 License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-cookbooks</title>
      <link>https://github.com/anthropics/claude-cookbooks</link>
      <description>&lt;p&gt;A collection of notebooks/recipes showcasing some fun and effective ways of using Claude.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Cookbooks&lt;/h1&gt; 
&lt;p&gt;The Claude Cookbooks provide code and guides designed to help developers build with Claude, offering copy-able code snippets that you can easily integrate into your own projects.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;To make the most of the examples in this cookbook, you'll need an Claude API key (sign up for free &lt;a href="https://www.anthropic.com"&gt;here&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;While the code examples are primarily written in Python, the concepts can be adapted to any programming language that supports interaction with the Claude API.&lt;/p&gt; 
&lt;p&gt;If you're new to working with the Claude API, we recommend starting with our &lt;a href="https://github.com/anthropics/courses/tree/master/anthropic_api_fundamentals"&gt;Claude API Fundamentals course&lt;/a&gt; to get a solid foundation.&lt;/p&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;p&gt;Looking for more resources to enhance your experience with Claude and AI assistants? Check out these helpful links:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.claude.com/claude/docs/guide-to-anthropics-prompt-engineering-resources"&gt;Anthropic developer documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://support.anthropic.com"&gt;Anthropic support docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.anthropic.com/discord"&gt;Anthropic Discord community&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;The Claude Cookbooks thrives on the contributions of the developer community. We value your input, whether it's submitting an idea, fixing a typo, adding a new guide, or improving an existing one. By contributing, you help make this resource even more valuable for everyone.&lt;/p&gt; 
&lt;p&gt;To avoid duplication of efforts, please review the existing issues and pull requests before contributing.&lt;/p&gt; 
&lt;p&gt;If you have ideas for new examples or guides, share them on the &lt;a href="https://github.com/anthropics/anthropic-cookbook/issues"&gt;issues page&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Table of recipes&lt;/h2&gt; 
&lt;h3&gt;Skills&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/tree/main/skills/classification"&gt;Classification&lt;/a&gt;: Explore techniques for text and data classification using Claude.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/tree/main/skills/retrieval_augmented_generation"&gt;Retrieval Augmented Generation&lt;/a&gt;: Learn how to enhance Claude's responses with external knowledge.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/tree/main/skills/summarization"&gt;Summarization&lt;/a&gt;: Discover techniques for effective text summarization with Claude.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Tool Use and Integration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/tree/main/tool_use"&gt;Tool use&lt;/a&gt;: Learn how to integrate Claude with external tools and functions to extend its capabilities. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/tool_use/customer_service_agent.ipynb"&gt;Customer service agent&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/tool_use/calculator_tool.ipynb"&gt;Calculator integration&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/how_to_make_sql_queries.ipynb"&gt;SQL queries&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Third-Party Integrations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/tree/main/third_party"&gt;Retrieval augmented generation&lt;/a&gt;: Supplement Claude's knowledge with external data sources. 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/third_party/Pinecone/rag_using_pinecone.ipynb"&gt;Vector databases (Pinecone)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/third_party/Wikipedia/wikipedia-search-cookbook.ipynb/"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/read_web_pages_with_haiku.ipynb"&gt;Web pages&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/third_party/Brave/web_search_using_brave.ipynb"&gt;Internet search (Brave)&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/third_party/VoyageAI/how_to_create_embeddings.md"&gt;Embeddings with Voyage AI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Multimodal Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/tree/main/multimodal"&gt;Vision with Claude&lt;/a&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/multimodal/getting_started_with_vision.ipynb"&gt;Getting started with images&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/multimodal/best_practices_for_vision.ipynb"&gt;Best practices for vision&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/multimodal/reading_charts_graphs_powerpoints.ipynb"&gt;Interpreting charts and graphs&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/multimodal/how_to_transcribe_text.ipynb"&gt;Extracting content from forms&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/illustrated_responses.ipynb"&gt;Generate images with Claude&lt;/a&gt;: Use Claude with Stable Diffusion for image generation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Techniques&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/multimodal/using_sub_agents.ipynb"&gt;Sub-agents&lt;/a&gt;: Learn how to use Haiku as a sub-agent in combination with Opus.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/pdf_upload_summarization.ipynb"&gt;Upload PDFs to Claude&lt;/a&gt;: Parse and pass PDFs as text to Claude.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/building_evals.ipynb"&gt;Automated evaluations&lt;/a&gt;: Use Claude to automate the prompt evaluation process.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/how_to_enable_json_mode.ipynb"&gt;Enable JSON mode&lt;/a&gt;: Ensure consistent JSON output from Claude.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/building_moderation_filter.ipynb"&gt;Create a moderation filter&lt;/a&gt;: Use Claude to create a content moderation filter for your application.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/anthropics/anthropic-cookbook/raw/main/misc/prompt_caching.ipynb"&gt;Prompt caching&lt;/a&gt;: Learn techniques for efficient prompt caching with Claude.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Additional Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/anthropic-on-aws"&gt;Anthropic on AWS&lt;/a&gt;: Explore examples and solutions for using Claude on AWS infrastructure.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/aws-samples/"&gt;AWS Samples&lt;/a&gt;: A collection of code samples from AWS which can be adapted for use with Claude. Note that some samples may require modification to work optimally with Claude.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>karpathy/micrograd</title>
      <link>https://github.com/karpathy/micrograd</link>
      <description>&lt;p&gt;A tiny scalar-valued autograd engine and a neural net library on top of it with PyTorch-like API&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;micrograd&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/karpathy/micrograd/master/puppy.jpg" alt="awww" /&gt;&lt;/p&gt; 
&lt;p&gt;A tiny Autograd engine (with a bite! :)). Implements backpropagation (reverse-mode autodiff) over a dynamically built DAG and a small neural networks library on top of it with a PyTorch-like API. Both are tiny, with about 100 and 50 lines of code respectively. The DAG only operates over scalar values, so e.g. we chop up each neuron into all of its individual tiny adds and multiplies. However, this is enough to build up entire deep neural nets doing binary classification, as the demo notebook shows. Potentially useful for educational purposes.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install micrograd
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Example usage&lt;/h3&gt; 
&lt;p&gt;Below is a slightly contrived example showing a number of possible supported operations:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from micrograd.engine import Value

a = Value(-4.0)
b = Value(2.0)
c = a + b
d = a * b + b**3
c += c + 1
c += 1 + c + (-a)
d += d * 2 + (b + a).relu()
d += 3 * d + (b - a).relu()
e = c - d
f = e**2
g = f / 2.0
g += 10.0 / f
print(f'{g.data:.4f}') # prints 24.7041, the outcome of this forward pass
g.backward()
print(f'{a.grad:.4f}') # prints 138.8338, i.e. the numerical value of dg/da
print(f'{b.grad:.4f}') # prints 645.5773, i.e. the numerical value of dg/db
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Training a neural net&lt;/h3&gt; 
&lt;p&gt;The notebook &lt;code&gt;demo.ipynb&lt;/code&gt; provides a full demo of training an 2-layer neural network (MLP) binary classifier. This is achieved by initializing a neural net from &lt;code&gt;micrograd.nn&lt;/code&gt; module, implementing a simple svm "max-margin" binary classification loss and using SGD for optimization. As shown in the notebook, using a 2-layer neural net with two 16-node hidden layers we achieve the following decision boundary on the moon dataset:&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/karpathy/micrograd/master/moon_mlp.png" alt="2d neuron" /&gt;&lt;/p&gt; 
&lt;h3&gt;Tracing / visualization&lt;/h3&gt; 
&lt;p&gt;For added convenience, the notebook &lt;code&gt;trace_graph.ipynb&lt;/code&gt; produces graphviz visualizations. E.g. this one below is of a simple 2D neuron, arrived at by calling &lt;code&gt;draw_dot&lt;/code&gt; on the code below, and it shows both the data (left number in each node) and the gradient (right number in each node).&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from micrograd import nn
n = nn.Neuron(2)
x = [Value(1.0), Value(-2.0)]
y = n(x)
dot = draw_dot(y)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/karpathy/micrograd/master/gout.svg?sanitize=true" alt="2d neuron" /&gt;&lt;/p&gt; 
&lt;h3&gt;Running tests&lt;/h3&gt; 
&lt;p&gt;To run the unit tests you will have to install &lt;a href="https://pytorch.org/"&gt;PyTorch&lt;/a&gt;, which the tests use as a reference for verifying the correctness of the calculated gradients. Then simply:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m pytest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;p&gt;MIT&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>EbookFoundation/free-programming-books</title>
      <link>https://github.com/EbookFoundation/free-programming-books</link>
      <description>&lt;p&gt;üìö Freely available programming books&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;List of Free Learning Resources In Many Languages&lt;/h1&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/sindresorhus/awesome"&gt;&lt;img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg?sanitize=true" alt="Awesome" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;&lt;img src="https://img.shields.io/github/license/EbookFoundation/free-programming-books" alt="License: CC BY 4.0" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged+created%3A2025-10-01..2025-10-31"&gt;&lt;img src="https://img.shields.io/github/hacktoberfest/2025/EbookFoundation/free-programming-books?label=Hacktoberfest+2025" alt="Hacktoberfest 2025 stats" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;Search the list at &lt;a href="https://ebookfoundation.github.io/free-programming-books-search/"&gt;https://ebookfoundation.github.io/free-programming-books-search/&lt;/a&gt; &lt;a href="https://ebookfoundation.github.io/free-programming-books-search/"&gt;&lt;img src="https://img.shields.io/website?style=flat&amp;amp;logo=www&amp;amp;logoColor=whitesmoke&amp;amp;label=Dynamic%20search%20site&amp;amp;down_color=red&amp;amp;down_message=down&amp;amp;up_color=green&amp;amp;up_message=up&amp;amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books-search%2F" alt="https://ebookfoundation.github.io/free-programming-books-search/" /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This page is available as an easy-to-read website. Access it by clicking on &lt;a href="https://ebookfoundation.github.io/free-programming-books/"&gt;&lt;img src="https://img.shields.io/website?style=flat&amp;amp;logo=www&amp;amp;logoColor=whitesmoke&amp;amp;label=Static%20site&amp;amp;down_color=red&amp;amp;down_message=down&amp;amp;up_color=green&amp;amp;up_message=up&amp;amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books%2F" alt="https://ebookfoundation.github.io/free-programming-books/" /&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;form action="https://ebookfoundation.github.io/free-programming-books-search"&gt; 
  &lt;input type="text" id="fpbSearch" name="search" required placeholder="Search Book or Author" /&gt; 
  &lt;label for="submit"&gt; &lt;/label&gt; 
  &lt;input type="submit" id="submit" name="submit" value="Search" /&gt; 
 &lt;/form&gt; 
&lt;/div&gt; 
&lt;h2&gt;Intro&lt;/h2&gt; 
&lt;p&gt;This list was originally a clone of &lt;a href="https://web.archive.org/web/20140606191453/http://stackoverflow.com/questions/194812/list-of-freely-available-programming-books/392926"&gt;StackOverflow - List of Freely Available Programming Books&lt;/a&gt; with contributions from Karan Bhangui and George Stocker.&lt;/p&gt; 
&lt;p&gt;The list was moved to GitHub by Victor Felder for collaborative updating and maintenance. It has grown to become one of &lt;a href="https://octoverse.github.com/"&gt;GitHub's most popular repositories&lt;/a&gt;.&lt;/p&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/EbookFoundation/free-programming-books/network"&gt;&lt;img src="https://img.shields.io/github/forks/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Forks" alt="GitHub repo forks" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Stars" alt="GitHub repo stars" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors-anon/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Contributors" alt="GitHub repo contributors" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/sponsors/EbookFoundation"&gt;&lt;img src="https://img.shields.io/github/sponsors/EbookFoundation?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Sponsors" alt="GitHub org sponsors" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/watchers"&gt;&lt;img src="https://img.shields.io/github/watchers/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Watchers" alt="GitHub repo watchers" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/archive/refs/heads/main.zip"&gt;&lt;img src="https://img.shields.io/github/repo-size/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=whitesmoke&amp;amp;label=Repo%20Size" alt="GitHub repo size" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;The &lt;a href="https://ebookfoundation.org"&gt;Free Ebook Foundation&lt;/a&gt; now administers the repo, a not-for-profit organization devoted to promoting the creation, distribution, archiving, and sustainability of free ebooks. &lt;a href="https://ebookfoundation.org/contributions.html"&gt;Donations&lt;/a&gt; to the Free Ebook Foundation are tax-deductible in the US.&lt;/p&gt; 
&lt;h2&gt;How To Contribute&lt;/h2&gt; 
&lt;p&gt;Please read &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt;. If you're new to GitHub, &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md"&gt;welcome&lt;/a&gt;! Remember to abide by our adapted from &lt;img src="https://img.shields.io/badge/Contributor%20Covenant-1.3-4baaaa.svg?sanitize=true" alt="Contributor Covenant 1.3" /&gt; &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; too (&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/#translations"&gt;translations&lt;/a&gt; also available).&lt;/p&gt; 
&lt;p&gt;Click on these badges to see how you might be able to help:&lt;/p&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/EbookFoundation/free-programming-books/issues"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=red&amp;amp;label=Issues" alt="GitHub repo Issues" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/good%20first%20issue?style=flat&amp;amp;logo=github&amp;amp;logoColor=green&amp;amp;label=Good%20First%20issues" alt="GitHub repo Good Issues for newbies" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;&lt;img src="https://img.shields.io/github/issues/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;amp;logo=github&amp;amp;logoColor=b545d1&amp;amp;label=%22Help%20Wanted%22%20issues" alt="GitHub Help Wanted issues" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=orange&amp;amp;label=PRs" alt="GitHub repo PRs" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged"&gt;&lt;img src="https://img.shields.io/github/issues-search/EbookFoundation/free-programming-books?style=flat&amp;amp;logo=github&amp;amp;logoColor=green&amp;amp;label=Merged%20PRs&amp;amp;query=is%3Amerged" alt="GitHub repo Merged PRs" /&gt;&lt;/a&gt;&amp;nbsp; &lt;a href="https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22"&gt;&lt;img src="https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;amp;logo=github&amp;amp;logoColor=b545d1&amp;amp;label=%22Help%20Wanted%22%20PRs" alt="GitHub Help Wanted PRs" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;How To Share&lt;/h2&gt; 
&lt;div align="left" markdown="1"&gt; 
 &lt;a href="https://www.facebook.com/share.php?u=https%3A%2F%2Fgithub.com%2FEbookFoundation%2Ffree-programming-books&amp;amp;p%5Bimages%5D%5B0%5D=&amp;amp;p%5Btitle%5D=Free%20Programming%20Books&amp;amp;p%5Bsummary%5D="&gt;Share on Facebook&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="http://www.linkedin.com/shareArticle?mini=true&amp;amp;url=https://github.com/EbookFoundation/free-programming-books&amp;amp;title=Free%20Programming%20Books&amp;amp;summary=&amp;amp;source="&gt;Share on LinkedIn&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://toot.kytta.dev/?text=https://github.com/EbookFoundation/free-programming-books"&gt;Share on Mastodon/Fediverse&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://t.me/share/url?url=https://github.com/EbookFoundation/free-programming-books"&gt;Share on Telegram&lt;/a&gt;
 &lt;br /&gt; 
 &lt;a href="https://twitter.com/intent/tweet?text=https://github.com/EbookFoundation/free-programming-books%0AFree%20Programming%20Books"&gt;Share on ùïè (Twitter)&lt;/a&gt;
 &lt;br /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;p&gt;This project lists books and other resources grouped by genres:&lt;/p&gt; 
&lt;h3&gt;Books&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-langs.md"&gt;English, By Programming Language&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-subjects.md"&gt;English, By Subject&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Other Languages&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ar.md"&gt;Arabic / al arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hy.md"&gt;Armenian / ’Ä’°’µ’•÷Ä’•’∂&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-az.md"&gt;Azerbaijani / –ê–∑”ô—Ä–±–∞—ò“π–∞–Ω –¥–∏–ª–∏ / ÿ¢ÿ∞ÿ±ÿ®ÿßŸäÿ¨ÿßŸÜÿ¨ÿß ÿØŸäŸÑŸä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bn.md"&gt;Bengali / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-bg.md"&gt;Bulgarian / –±—ä–ª–≥–∞—Ä—Å–∫–∏&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-my.md"&gt;Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-cs.md"&gt;Czech / ƒçe≈°tina / ƒçesk√Ω jazyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ca.md"&gt;Catalan / catalan / catal√†&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-da.md"&gt;Danish / dansk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-nl.md"&gt;Dutch / Nederlands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-et.md"&gt;Estonian / eesti keel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fi.md"&gt;Finnish / suomi / suomen kieli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fr.md"&gt;French / fran√ßais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-el.md"&gt;Greek / ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-he.md"&gt;Hebrew / ◊¢◊ë◊®◊ô◊™&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hi.md"&gt;Hindi / ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-hu.md"&gt;Hungarian / magyar / magyar nyelv&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-it.md"&gt;Italian / italiano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ja.md"&gt;Japanese / Êó•Êú¨Ë™û&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ko.md"&gt;Korean / ÌïúÍµ≠Ïñ¥&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-lv.md"&gt;Latvian / Latvie≈°u&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ml.md"&gt;Malayalam / ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-no.md"&gt;Norwegian / Norsk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-fa_IR.md"&gt;Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pl.md"&gt;Polish / polski / jƒôzyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ro.md"&gt;Romanian (Romania) / limba rom√¢nƒÉ / rom√¢n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sr.md"&gt;Serbian / —Å—Ä–ø—Å–∫–∏ —ò–µ–∑–∏–∫ / srpski jezik&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sk.md"&gt;Slovak / slovenƒçina&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-es.md"&gt;Spanish / espa√±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-sv.md"&gt;Swedish / Svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ta.md"&gt;Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-te.md"&gt;Telugu / ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-th.md"&gt;Thai / ‡πÑ‡∏ó‡∏¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-tr.md"&gt;Turkish / T√ºrk√ße&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-uk.md"&gt;Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-ur.md"&gt;Urdu / ÿßÿ±ÿØŸà&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/books/free-programming-books-vi.md"&gt;Vietnamese / Ti·∫øng Vi·ªát&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cheat Sheets&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-cheatsheets.md"&gt;All Languages&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Free Online Courses&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ar.md"&gt;Arabic / al arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bn.md"&gt;Bengali / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-bg.md"&gt;Bulgarian / –±—ä–ª–≥–∞—Ä—Å–∫–∏&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-my.md"&gt;Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fi.md"&gt;Finnish / suomi / suomen kieli&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fr.md"&gt;French / fran√ßais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-el.md"&gt;Greek / ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-he.md"&gt;Hebrew / ◊¢◊ë◊®◊ô◊™&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-hi.md"&gt;Hindi / ‡§π‡§ø‡§Ç‡§¶‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-it.md"&gt;Italian / italiano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ja.md"&gt;Japanese / Êó•Êú¨Ë™û&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kn.md"&gt;Kannada / ‡≤ï‡≤®‡≥ç‡≤®‡≤°&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-kk.md"&gt;Kazakh / “õ–∞–∑–∞“õ—à–∞&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-km.md"&gt;Khmer / ·ûó·û∂·ûü·û∂·ûÅ·üí·ûò·üÇ·ûö&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ko.md"&gt;Korean / ÌïúÍµ≠Ïñ¥&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ml.md"&gt;Malayalam / ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-mr.md"&gt;Marathi / ‡§Æ‡§∞‡§æ‡§†‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ne.md"&gt;Nepali / ‡§®‡•á‡§™‡§æ‡§≤‡•Ä&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-no.md"&gt;Norwegian / Norsk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-fa_IR.md"&gt;Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pl.md"&gt;Polish / polski / jƒôzyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-pa.md"&gt;Punjabi / ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä / ŸæŸÜÿ¨ÿßÿ®€å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ro.md"&gt;Romanian (Romania) / limba rom√¢nƒÉ / rom√¢n&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-si.md"&gt;Sinhala / ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-es.md"&gt;Spanish / espa√±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-sv.md"&gt;Swedish / svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ta.md"&gt;Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-te.md"&gt;Telugu / ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-th.md"&gt;Thai / ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-tr.md"&gt;Turkish / T√ºrk√ße&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-uk.md"&gt;Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-ur.md"&gt;Urdu / ÿßÿ±ÿØŸà&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/courses/free-courses-vi.md"&gt;Vietnamese / Ti·∫øng Vi·ªát&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Interactive Programming Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ja.md"&gt;Japanese / Êó•Êú¨Ë™û&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-interactive-tutorials-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Problem Sets and Competitive Programming&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/problem-sets-competitive-programming.md"&gt;Problem Sets&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Podcast - Screencast&lt;/h3&gt; 
&lt;p&gt;Free Podcasts and Screencasts:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ar.md"&gt;Arabic / al Arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-my.md"&gt;Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-cs.md"&gt;Czech / ƒçe≈°tina / ƒçesk√Ω jazyk&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-nl.md"&gt;Dutch / Nederlands&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-en.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fi.md"&gt;Finnish / Suomi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fr.md"&gt;French / fran√ßais&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-he.md"&gt;Hebrew / ◊¢◊ë◊®◊ô◊™&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-id.md"&gt;Indonesian / Bahasa Indonesia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-fa_IR.md"&gt;Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pl.md"&gt;Polish / polski / jƒôzyk polski / polszczyzna&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_BR.md"&gt;Portuguese (Brazil)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-pt_PT.md"&gt;Portuguese (Portugal)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-ru.md"&gt;Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-si.md"&gt;Sinhala / ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-es.md"&gt;Spanish / espa√±ol / castellano&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-sv.md"&gt;Swedish / Svenska&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-tr.md"&gt;Turkish / T√ºrk√ße&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/casts/free-podcasts-screencasts-uk.md"&gt;Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Programming Playgrounds&lt;/h3&gt; 
&lt;p&gt;Write, compile, and run your code within a browser. Try it out!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-zh.md"&gt;Chinese / ‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds.md"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/more/free-programming-playgrounds-de.md"&gt;German / Deutsch&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Translations&lt;/h2&gt; 
&lt;p&gt;Volunteers have translated many of our Contributing, How-to, and Code of Conduct documents into languages covered by our lists.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;English 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/HOWTO.md"&gt;How-to&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;... &lt;em&gt;&lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations"&gt;More languages&lt;/a&gt;&lt;/em&gt; ...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You might notice that there are &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/README.md#translations"&gt;some missing translations here&lt;/a&gt; - perhaps you would like to help out by &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/docs/CONTRIBUTING.md#help-out-by-contributing-a-translation"&gt;contributing a translation&lt;/a&gt;?&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Each file included in this repository is licensed under the &lt;a href="https://raw.githubusercontent.com/EbookFoundation/free-programming-books/main/LICENSE"&gt;CC BY License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mountain-loop/yaak</title>
      <link>https://github.com/mountain-loop/yaak</link>
      <description>&lt;p&gt;The most intuitive desktop API client. Organize and execute REST, GraphQL, WebSockets, Server Sent Events, and gRPC ü¶¨&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://github.com/JamesIves/github-sponsors-readme-action"&gt; &lt;img width="200px" src="https://github.com/mountain-loop/yaak/raw/main/src-tauri/icons/icon.png" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt; üí´ Yaak ‚ûü Desktop API Client üí´ &lt;/h1&gt; 
&lt;p align="center"&gt; A fast, privacy-first API client for REST, GraphQL, SSE, WebSocket, and gRPC ‚Äì built with Tauri, Rust, and React. &lt;/p&gt; 
&lt;p align="center"&gt; Development is funded by community-purchased &lt;a href="https://yaak.app/pricing"&gt;licenses&lt;/a&gt;. You can also &lt;a href="https://github.com/sponsors/gschier"&gt;become a sponsor&lt;/a&gt; to have your logo appear below. üíñ &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; 
 &lt;!-- sponsors-premium --&gt;&lt;a href="https://github.com/MVST-Solutions"&gt;&lt;img src="https://github.com/MVST-Solutions.png" width="80px" alt="User avatar: MVST-Solutions" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/dharsanb"&gt;&lt;img src="https://github.com/dharsanb.png" width="80px" alt="User avatar: dharsanb" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/railwayapp"&gt;&lt;img src="https://github.com/railwayapp.png" width="80px" alt="User avatar: railwayapp" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/caseyamcl"&gt;&lt;img src="https://github.com/caseyamcl.png" width="80px" alt="User avatar: caseyamcl" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/andriyor"&gt;&lt;img src="https://github.com/andriyor.png" width="80px" alt="User avatar: andriyor" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/"&gt;&lt;img src="https://raw.githubusercontent.com/JamesIves/github-sponsors-readme-action/dev/.github/assets/placeholder.png" width="80px" alt="User avatar: " /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
 &lt;!-- sponsors-premium --&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;!-- sponsors-base --&gt;&lt;a href="https://github.com/seanwash"&gt;&lt;img src="https://github.com/seanwash.png" width="50px" alt="User avatar: seanwash" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/jerath"&gt;&lt;img src="https://github.com/jerath.png" width="50px" alt="User avatar: jerath" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/itsa-sh"&gt;&lt;img src="https://github.com/itsa-sh.png" width="50px" alt="User avatar: itsa-sh" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/dmmulroy"&gt;&lt;img src="https://github.com/dmmulroy.png" width="50px" alt="User avatar: dmmulroy" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/timcole"&gt;&lt;img src="https://github.com/timcole.png" width="50px" alt="User avatar: timcole" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/VLZH"&gt;&lt;img src="https://github.com/VLZH.png" width="50px" alt="User avatar: VLZH" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/terasaka2k"&gt;&lt;img src="https://github.com/terasaka2k.png" width="50px" alt="User avatar: terasaka2k" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;&lt;a href="https://github.com/majudhu"&gt;&lt;img src="https://github.com/majudhu.png" width="50px" alt="User avatar: majudhu" /&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
 &lt;!-- sponsors-base --&gt; &lt;/p&gt; 
&lt;p&gt;&lt;img src="https://yaak.app/static/screenshot.png" alt="Yaak API Client" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;Yaak is an offline-first API client designed to stay out of your way while giving you everything you need when you need it. Built with &lt;a href="https://tauri.app"&gt;Tauri&lt;/a&gt;, Rust, and React, it‚Äôs fast, lightweight, and private. No telemetry, no VC funding, and no cloud lock-in.&lt;/p&gt; 
&lt;h3&gt;üåê Work with any API&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Import collections from Postman, Insomnia, OpenAPI, Swagger, or Curl.&lt;/li&gt; 
 &lt;li&gt;Send requests via REST, GraphQL, gRPC, WebSocket, or Server-Sent Events.&lt;/li&gt; 
 &lt;li&gt;Filter and inspect responses with JSONPath or XPath.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîê Stay secure&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use OAuth 2.0, JWT, Basic Auth, or custom plugins for authentication.&lt;/li&gt; 
 &lt;li&gt;Secure sensitive values with encrypted secrets.&lt;/li&gt; 
 &lt;li&gt;Store secrets in your OS keychain.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‚òÅÔ∏è Organize &amp;amp; collaborate&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Group requests into workspaces and nested folders.&lt;/li&gt; 
 &lt;li&gt;Use environment variables to switch between dev, staging, and prod.&lt;/li&gt; 
 &lt;li&gt;Mirror workspaces to your filesystem for versioning in Git or syncing with Dropbox.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üß© Extend &amp;amp; customize&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Insert dynamic values like UUIDs or timestamps with template tags.&lt;/li&gt; 
 &lt;li&gt;Pick from built-in themes or build your own.&lt;/li&gt; 
 &lt;li&gt;Create plugins to extend authentication, template tags, or the UI.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribution Policy&lt;/h2&gt; 
&lt;p&gt;Yaak is open source but only accepting contributions for bug fixes. To get started, visit &lt;a href="https://raw.githubusercontent.com/mountain-loop/yaak/main/DEVELOPMENT.md"&gt;&lt;code&gt;DEVELOPMENT.md&lt;/code&gt;&lt;/a&gt; for tips on setting up your environment.&lt;/p&gt; 
&lt;h2&gt;Useful Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://feedback.yaak.app"&gt;Feedback and Bug Reports&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://feedback.yaak.app/help"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://yaak.app/alternatives/postman"&gt;Yaak vs Postman&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://yaak.app/alternatives/bruno"&gt;Yaak vs Bruno&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://yaak.app/alternatives/insomnia"&gt;Yaak vs Insomnia&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>ThinkInAIXYZ/deepchat</title>
      <link>https://github.com/ThinkInAIXYZ/deepchat</link>
      <description>&lt;p&gt;üê¨DeepChat - A smart assistant that connects powerful AI to your personal world&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/build/icon.png" width="150" height="150" alt="DeepChat AI Assistant Icon" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;DeepChat - Powerful Open-Source Multi-Model AI Chat Platform&lt;/h1&gt; 
&lt;p align="center"&gt;DeepChat is a feature-rich open-source AI chat platform supporting multiple cloud and local large language models with powerful search enhancement and tool calling capabilities.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/ThinkInAIXYZ/deepchat" alt="Stars Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/ThinkInAIXYZ/deepchat" alt="Forks Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/ThinkInAIXYZ/deepchat" alt="Pull Requests Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/issues"&gt;&lt;img src="https://img.shields.io/github/issues/ThinkInAIXYZ/deepchat" alt="Issues Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/ThinkInAIXYZ/deepchat" alt="License Badge" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/ThinkInAIXYZ/deepchat"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/README.zh.md"&gt;‰∏≠Êñá&lt;/a&gt; / 
 &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/README.md"&gt;English&lt;/a&gt; / 
 &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/README.jp.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;üìë Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-table-of-contents"&gt;üìë Table of Contents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-project-introduction"&gt;üöÄ Project Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-why-choose-deepchat"&gt;üí° Why Choose DeepChat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-main-features"&gt;üî• Main Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-supported-model-providers"&gt;ü§ñ Supported Model Providers&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#compatible-with-any-model-provider-in-openaigeminianthropic-api-format"&gt;Compatible with any model provider in OpenAI/Gemini/Anthropic API format&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-use-cases"&gt;üîç Use Cases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-quick-start"&gt;üì¶ Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#download-and-install"&gt;Download and Install&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#configure-models"&gt;Configure Models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#start-conversations"&gt;Start Conversations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-development-guide"&gt;üíª Development Guide&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#install-dependencies"&gt;Install Dependencies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#start-development"&gt;Start Development&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#build"&gt;Build&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-community--contribution"&gt;üë• Community &amp;amp; Contribution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-star-history"&gt;‚≠ê Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-contributors"&gt;üë®‚Äçüíª Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-license"&gt;üìÉ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üöÄ Project Introduction&lt;/h2&gt; 
&lt;p&gt;DeepChat is a powerful open-source AI chat platform providing a unified interface for interacting with various large language models. Whether you're using cloud APIs like OpenAI, Gemini, Anthropic, or locally deployed Ollama models, DeepChat delivers a smooth user experience.&lt;/p&gt; 
&lt;p&gt;As a cross-platform AI assistant application, DeepChat not only supports basic chat functionality but also offers advanced features such as search enhancement, tool calling, and multimodal interaction, making AI capabilities more accessible and efficient.&lt;/p&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center" style="padding: 10px;"&gt; &lt;img src="https://github.com/user-attachments/assets/6e932a65-78e0-4d2e-9654-ccc010f78bf7" alt="DeepChat Light Mode" width="400" /&gt; &lt;br /&gt; &lt;/td&gt; 
   &lt;td align="center" style="padding: 10px;"&gt; &lt;img src="https://github.com/user-attachments/assets/ea6ccf60-32af-4bc1-91cc-e72703bdc1ff" alt="DeepChat Dark Mode" width="400" /&gt; &lt;br /&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;üí° Why Choose DeepChat&lt;/h2&gt; 
&lt;p&gt;Compared to other AI tools, DeepChat offers the following unique advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Unified Multi-Model Management&lt;/strong&gt;: One application supports almost all mainstream LLMs, eliminating the need to switch between multiple apps&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Local Model Integration&lt;/strong&gt;: Built-in Ollama support allows you to manage and use local models without command-line operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Tool Calling&lt;/strong&gt;: Built-in MCP support enables code execution, web access, and other tools without additional configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Powerful Search Enhancement&lt;/strong&gt;: Support for multiple search engines makes AI responses more accurate and timely, providing non-standard web search paradigms that can be quickly customized&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy-Focused&lt;/strong&gt;: Local data storage and network proxy support reduce the risk of information leakage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business-Friendly&lt;/strong&gt;: Embraces open source under the Apache License 2.0, suitable for both commercial and personal use&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üî• Main Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üåê &lt;strong&gt;Multiple Cloud LLM Provider Support&lt;/strong&gt;: DeepSeek, OpenAI, SiliconFlow, Grok, Gemini, Anthropic, and more&lt;/li&gt; 
 &lt;li&gt;üè† &lt;strong&gt;Local Model Deployment Support&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Integrated Ollama with comprehensive management capabilities&lt;/li&gt; 
   &lt;li&gt;Control and manage Ollama model downloads, deployments, and runs without command-line operations&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;üöÄ &lt;strong&gt;Rich and Easy-to-Use Chat Capabilities&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Complete Markdown rendering with code block rendering based on industry-leading &lt;a href="https://codemirror.net/"&gt;CodeMirror&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Multi-window + multi-tab architecture supporting parallel multi-session operations across all dimensions, use large models like using a browser, non-blocking experience brings excellent efficiency&lt;/li&gt; 
   &lt;li&gt;Supports Artifacts rendering for diverse result presentation, significantly saving token consumption after MCP integration&lt;/li&gt; 
   &lt;li&gt;Messages support retry to generate multiple variations; conversations can be forked freely, ensuring there's always a suitable line of thought&lt;/li&gt; 
   &lt;li&gt;Supports rendering images, Mermaid diagrams, and other multi-modal content; supports GPT-4o, Gemini, Grok text-to-image capabilities&lt;/li&gt; 
   &lt;li&gt;Supports highlighting external information sources like search results within the content&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Robust Search Extension Capabilities&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Built-in integration with leading search APIs like BoSearch, Brave Search via MCP mode, allowing the model to intelligently decide when to search&lt;/li&gt; 
   &lt;li&gt;Supports mainstream search engines like Google, Bing, Baidu, and Sogou Official Accounts search by simulating user web browsing, enabling the LLM to read search engines like a human&lt;/li&gt; 
   &lt;li&gt;Supports reading any search engine; simply configure a search assistant model to connect various search sources, whether internal networks, API-less engines, or vertical domain search engines, as information sources for the model&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Excellent MCP (Model Context Protocol) Support&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Complete support for the three core capabilities of Resources/Prompts/Tools in the MCP protocol&lt;/li&gt; 
   &lt;li&gt;Supports semantic workflows, enabling more complex and intelligent automation by understanding the meaning and context of tasks.&lt;/li&gt; 
   &lt;li&gt;Extremely user-friendly configuration interface&lt;/li&gt; 
   &lt;li&gt;Aesthetically pleasing and clear tool call display&lt;/li&gt; 
   &lt;li&gt;Detailed tool call debugging window with automatic formatting of tool parameters and return data&lt;/li&gt; 
   &lt;li&gt;Built-in Node.js runtime environment; npx/node-like services require no extra configuration and work out-of-the-box&lt;/li&gt; 
   &lt;li&gt;Supports StreamableHTTP/SSE/Stdio protocol Transports&lt;/li&gt; 
   &lt;li&gt;Supports inMemory services with built-in utilities like code execution, web information retrieval, and file operations; ready for most common use cases out-of-the-box without secondary installation&lt;/li&gt; 
   &lt;li&gt;Converts visual model capabilities into universally usable functions for any model via the built-in MCP service&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;üíª &lt;strong&gt;Multi-Platform Support&lt;/strong&gt;: Windows, macOS, Linux&lt;/li&gt; 
 &lt;li&gt;üé® &lt;strong&gt;Beautiful and User-Friendly Interface&lt;/strong&gt;, user-oriented design, meticulously themed light and dark modes&lt;/li&gt; 
 &lt;li&gt;üîó &lt;strong&gt;Rich DeepLink Support&lt;/strong&gt;: Initiate conversations via links for seamless integration with other applications. Also supports one-click installation of MCP services for simplicity and speed&lt;/li&gt; 
 &lt;li&gt;üöë &lt;strong&gt;Security-First Design&lt;/strong&gt;: Chat data and configuration data have reserved encryption interfaces and code obfuscation capabilities&lt;/li&gt; 
 &lt;li&gt;üõ°Ô∏è &lt;strong&gt;Privacy Protection&lt;/strong&gt;: Supports screen projection hiding, network proxies, and other privacy protection methods to reduce the risk of information leakage&lt;/li&gt; 
 &lt;li&gt;üí∞ &lt;strong&gt;Business-Friendly&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Embraces open source, based on the Apache License 2.0 protocol, enterprise use without worry&lt;/li&gt; 
   &lt;li&gt;Enterprise integration requires only minimal configuration code changes to use reserved encrypted obfuscation security capabilities&lt;/li&gt; 
   &lt;li&gt;Clear code structure, both model providers and MCP services are highly decoupled, can be freely customized with minimal cost&lt;/li&gt; 
   &lt;li&gt;Reasonable architecture, data interaction and UI behavior separation, fully utilizing Electron's capabilities, rejecting simple web wrappers, excellent performance&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more details on how to use these features, see the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/docs/user-guide.md"&gt;User Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ü§ñ Supported Model Providers&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/ollama.svg?sanitize=true" width="50" height="50" alt="Ollama Icon" /&gt;&lt;br /&gt; &lt;a href="https://ollama.com"&gt;Ollama&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/deepseek-color.svg?sanitize=true" width="50" height="50" alt="Deepseek Icon" /&gt;&lt;br /&gt; &lt;a href="https://deepseek.com/"&gt;Deepseek&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/ppio-color.svg?sanitize=true" width="50" height="50" alt="PPIO Icon" /&gt;&lt;br /&gt; &lt;a href="https://ppinfra.com/"&gt;PPIO&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/alibabacloud-color.svg?sanitize=true" width="50" height="50" alt="DashScope Icon" /&gt;&lt;br /&gt; &lt;a href="https://www.aliyun.com/product/bailian"&gt;DashScope&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/doubao-color.svg?sanitize=true" width="50" height="50" alt="Doubao Icon" /&gt;&lt;br /&gt; &lt;a href="https://console.volcengine.com/ark/"&gt;Doubao&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/minimax-color.svg?sanitize=true" width="50" height="50" alt="MiniMax Icon" /&gt;&lt;br /&gt; &lt;a href="https://platform.minimaxi.com/"&gt;MiniMax&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/fireworks-color.svg?sanitize=true" width="50" height="50" alt="Fireworks Icon" /&gt;&lt;br /&gt; &lt;a href="https://fireworks.ai/"&gt;Fireworks&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/302ai.svg?sanitize=true" width="50" height="50" alt="302.AI Icon" /&gt;&lt;br /&gt; &lt;a href="https://302.ai/"&gt;302.AI&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/openai.svg?sanitize=true" width="50" height="50" alt="OpenAI Icon" /&gt;&lt;br /&gt; &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/gemini-color.svg?sanitize=true" width="50" height="50" alt="Gemini Icon" /&gt;&lt;br /&gt; &lt;a href="https://gemini.google.com/"&gt;Gemini&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/github.svg?sanitize=true" width="50" height="50" alt="GitHub Models Icon" /&gt;&lt;br /&gt; &lt;a href="https://github.com/marketplace/models"&gt;GitHub Models&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/moonshot.svg?sanitize=true" width="50" height="50" alt="Moonshot Icon" /&gt;&lt;br /&gt; &lt;a href="https://moonshot.ai/"&gt;Moonshot&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/openrouter.svg?sanitize=true" width="50" height="50" alt="OpenRouter Icon" /&gt;&lt;br /&gt; &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/azure-color.svg?sanitize=true" width="50" height="50" alt="Azure OpenAI Icon" /&gt;&lt;br /&gt; &lt;a href="https://azure.microsoft.com/en-us/products/ai-services/openai-service"&gt;Azure OpenAI&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/qiniu.svg?sanitize=true" width="50" height="50" alt="Qiniu Icon" /&gt;&lt;br /&gt; &lt;a href="https://www.qiniu.com/products/ai-token-api"&gt;Qiniu&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/grok.svg?sanitize=true" width="50" height="50" alt="Grok Icon" /&gt;&lt;br /&gt; &lt;a href="https://x.ai/"&gt;Grok&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/zhipu-color.svg?sanitize=true" width="50" height="50" alt="Zhipu Icon" /&gt;&lt;br /&gt; &lt;a href="https://open.bigmodel.cn/"&gt;Zhipu&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/siliconcloud.svg?sanitize=true" width="50" height="50" alt="SiliconFlow Icon" /&gt;&lt;br /&gt; &lt;a href="https://www.siliconflow.cn/"&gt;SiliconFlow&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/aihubmix.png" width="50" height="50" alt="AIHubMix Icon" /&gt;&lt;br /&gt; &lt;a href="https://aihubmix.com/"&gt;AIHubMix&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/hunyuan-color.svg?sanitize=true" width="50" height="50" alt="Hunyuan Icon" /&gt;&lt;br /&gt; &lt;a href="https://cloud.tencent.com/product/hunyuan"&gt;Hunyuan&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/lmstudio.svg?sanitize=true" width="50" height="50" alt="LM Studio Icon" /&gt;&lt;br /&gt; &lt;a href="https://lmstudio.ai/"&gt;LM Studio&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/groq.svg?sanitize=true" width="50" height="50" alt="Groq Icon" /&gt;&lt;br /&gt; &lt;a href="https://groq.com/"&gt;Groq&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;Compatible with any model provider in OpenAI/Gemini/Anthropic API format&lt;/h3&gt; 
&lt;h2&gt;üîç Use Cases&lt;/h2&gt; 
&lt;p&gt;DeepChat is suitable for various AI application scenarios:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Daily Assistant&lt;/strong&gt;: Answering questions, providing suggestions, assisting with writing and creation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Development Aid&lt;/strong&gt;: Code generation, debugging, technical problem solving&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Learning Tool&lt;/strong&gt;: Concept explanation, knowledge exploration, learning guidance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content Creation&lt;/strong&gt;: Copywriting, creative inspiration, content optimization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Analysis&lt;/strong&gt;: Data interpretation, chart generation, report writing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üì¶ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Download and Install&lt;/h3&gt; 
&lt;p&gt;Download the latest version for your system from the &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/releases"&gt;GitHub Releases&lt;/a&gt; page:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Windows: &lt;code&gt;.exe&lt;/code&gt; installation file&lt;/li&gt; 
 &lt;li&gt;macOS: &lt;code&gt;.dmg&lt;/code&gt; installation file&lt;/li&gt; 
 &lt;li&gt;Linux: &lt;code&gt;.AppImage&lt;/code&gt; or &lt;code&gt;.deb&lt;/code&gt; installation file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Configure Models&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Launch the DeepChat application&lt;/li&gt; 
 &lt;li&gt;Click the settings icon&lt;/li&gt; 
 &lt;li&gt;Select the "Model Providers" tab&lt;/li&gt; 
 &lt;li&gt;Add your API keys or configure local Ollama&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Start Conversations&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Click the "+" button to create a new conversation&lt;/li&gt; 
 &lt;li&gt;Select the model you want to use&lt;/li&gt; 
 &lt;li&gt;Start communicating with your AI assistant&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For a comprehensive guide on getting started and using all features, please refer to the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/docs/user-guide.md"&gt;User Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üíª Development Guide&lt;/h2&gt; 
&lt;p&gt;Please read the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Windows and Linux are packaged by GitHub Action. For Mac-related signing and packaging, please refer to the &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/wiki/Mac-Release-Guide"&gt;Mac Release Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Install Dependencies&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ pnpm install
$ pnpm run installRuntime
# if got err: No module named 'distutils'
$ pip install setuptools
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;For Windows: To allow non-admin users to create symlinks and hardlinks, enable &lt;code&gt;Developer Mode&lt;/code&gt; in Settings or use an administrator account. Otherwise &lt;code&gt;pnpm&lt;/code&gt; ops will fail.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Start Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ pnpm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For Windows
$ pnpm run build:win

# For macOS
$ pnpm run build:mac

# For Linux
$ pnpm run build:linux

# Specify architecture packaging
$ pnpm run build:win:x64
$ pnpm run build:win:arm64
$ pnpm run build:mac:x64
$ pnpm run build:mac:arm64
$ pnpm run build:linux:x64
$ pnpm run build:linux:arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a more detailed guide on development, project structure, and architecture, please see the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/docs/developer-guide.md"&gt;Developer Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üë• Community &amp;amp; Contribution&lt;/h2&gt; 
&lt;p&gt;DeepChat is an active open-source community project, and we welcome various forms of contribution:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/issues"&gt;Report issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/issues"&gt;Submit feature suggestions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîß &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/pulls"&gt;Submit code improvements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìö &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/wiki"&gt;Improve documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üåç &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/tree/main/locales"&gt;Help with translation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Check the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; to learn more about ways to participate in the project.&lt;/p&gt; 
&lt;h2&gt;‚≠ê Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#ThinkInAIXYZ/deepchat&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=ThinkInAIXYZ/deepchat&amp;amp;type=Timeline" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üë®‚Äçüíª Contributors&lt;/h2&gt; 
&lt;p&gt;Thank you for considering contributing to deepchat! The contribution guide can be found in the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://openomy.com/thinkinaixyz/deepchat" target="_blank" style="display: block; width: 100%;" align="center"&gt; &lt;img src="https://openomy.com/svg?repo=thinkinaixyz/deepchat&amp;amp;chart=bubble&amp;amp;latestMonth=3" target="_blank" alt="Contribution Leaderboard" style="display: block; width: 100%;" /&gt; &lt;/a&gt; 
&lt;h2&gt;üôèüèª Thanks&lt;/h2&gt; 
&lt;p&gt;This project is built with the help of these awesome libraries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://vuejs.org/"&gt;Vue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.electronjs.org/"&gt;Electron&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://electron-vite.org/"&gt;Electron-Vite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oxc-project/oxc"&gt;oxlint&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÉ License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lfnovo/open-notebook</title>
      <link>https://github.com/lfnovo/open-notebook</link>
      <description>&lt;p&gt;An Open Source implementation of Notebook LM with more flexibility and features&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a id="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![Contributors][contributors-shield]][contributors-url] --&gt; 
&lt;p&gt;&lt;a href="https://github.com/lfnovo/open-notebook/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/lfnovo/open-notebook.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/lfnovo/open-notebook.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;&lt;img src="https://img.shields.io/github/issues/lfnovo/open-notebook.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/raw/master/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/github/license/lfnovo/open-notebook.svg?style=for-the-badge" alt="MIT License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![LinkedIn][linkedin-shield]][linkedin-url] --&gt; 
&lt;!-- PROJECT LOGO --&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/lfnovo/open-notebook"&gt; &lt;img src="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/hero.svg?sanitize=true" alt="Logo" /&gt; &lt;/a&gt; 
 &lt;h3 align="center"&gt;Open Notebook&lt;/h3&gt; 
 &lt;p align="center"&gt; An open source, privacy-focused alternative to Google's Notebook LM! &lt;br /&gt;&lt;strong&gt;Join our &lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord server&lt;/a&gt; for help, to share workflow ideas, and suggest features!&lt;/strong&gt; &lt;br /&gt; &lt;a href="https://www.open-notebook.ai"&gt;&lt;strong&gt;Checkout our website ¬ª&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/index.md"&gt;üìö Get Started&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/index.md"&gt;üìñ User Guide&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/index.md"&gt;‚ú® Features&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/index.md"&gt;üöÄ Deploy&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
 &lt;a href="https://zdoc.app/de/lfnovo/open-notebook"&gt;Deutsch&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/es/lfnovo/open-notebook"&gt;Espa√±ol&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/fr/lfnovo/open-notebook"&gt;fran√ßais&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/ja/lfnovo/open-notebook"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/ko/lfnovo/open-notebook"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/pt/lfnovo/open-notebook"&gt;Portugu√™s&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/ru/lfnovo/open-notebook"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/zh/lfnovo/open-notebook"&gt;‰∏≠Êñá&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;A private, multi-model, 100% local, full-featured alternative to Notebook LM&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/asset_list.png" alt="New Notebook" /&gt;&lt;/p&gt; 
&lt;p&gt;In a world dominated by Artificial Intelligence, having the ability to think üß† and acquire new knowledge üí°, is a skill that should not be a privilege for a few, nor restricted to a single provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Open Notebook empowers you to:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîí &lt;strong&gt;Control your data&lt;/strong&gt; - Keep your research private and secure&lt;/li&gt; 
 &lt;li&gt;ü§ñ &lt;strong&gt;Choose your AI models&lt;/strong&gt; - Support for 16+ providers including OpenAI, Anthropic, Ollama, LM Studio, and more&lt;/li&gt; 
 &lt;li&gt;üìö &lt;strong&gt;Organize multi-modal content&lt;/strong&gt; - PDFs, videos, audio, web pages, and more&lt;/li&gt; 
 &lt;li&gt;üéôÔ∏è &lt;strong&gt;Generate professional podcasts&lt;/strong&gt; - Advanced multi-speaker podcast generation&lt;/li&gt; 
 &lt;li&gt;üîç &lt;strong&gt;Search intelligently&lt;/strong&gt; - Full-text and vector search across all your content&lt;/li&gt; 
 &lt;li&gt;üí¨ &lt;strong&gt;Chat with context&lt;/strong&gt; - AI conversations powered by your research&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Learn more about our project at &lt;a href="https://www.open-notebook.ai"&gt;https://www.open-notebook.ai&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;‚ö†Ô∏è IMPORTANT: v1.0 Breaking Changes&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;If you're upgrading from a previous version&lt;/strong&gt;, please note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üè∑Ô∏è &lt;strong&gt;Docker tags have changed&lt;/strong&gt;: The &lt;code&gt;latest&lt;/code&gt; tag is now &lt;strong&gt;frozen&lt;/strong&gt; at the last Streamlit version&lt;/li&gt; 
 &lt;li&gt;üÜï &lt;strong&gt;Use &lt;code&gt;v1-latest&lt;/code&gt; tag&lt;/strong&gt; for the new React/Next.js version (recommended)&lt;/li&gt; 
 &lt;li&gt;üîå &lt;strong&gt;Port 5055 required&lt;/strong&gt;: You must expose port 5055 for the API to work&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;strong&gt;Read the migration guide&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/MIGRATION.md"&gt;MIGRATION.md&lt;/a&gt; for detailed upgrade instructions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;New users&lt;/strong&gt;: You can ignore this notice and proceed with the Quick Start below using the &lt;code&gt;v1-latest-single&lt;/code&gt; tag.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;üÜö Open Notebook vs Google Notebook LM&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Open Notebook&lt;/th&gt; 
   &lt;th&gt;Google Notebook LM&lt;/th&gt; 
   &lt;th&gt;Advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Privacy &amp;amp; Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Self-hosted, your data&lt;/td&gt; 
   &lt;td&gt;Google cloud only&lt;/td&gt; 
   &lt;td&gt;Complete data sovereignty&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI Provider Choice&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;16+ providers (OpenAI, Anthropic, Ollama, LM Studio, etc.)&lt;/td&gt; 
   &lt;td&gt;Google models only&lt;/td&gt; 
   &lt;td&gt;Flexibility and cost optimization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Podcast Speakers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1-4 speakers with custom profiles&lt;/td&gt; 
   &lt;td&gt;2 speakers only&lt;/td&gt; 
   &lt;td&gt;Extreme flexibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Context Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;3 granular levels&lt;/td&gt; 
   &lt;td&gt;All-or-nothing&lt;/td&gt; 
   &lt;td&gt;Privacy and performance tuning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Content Transformations&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Custom and built-in&lt;/td&gt; 
   &lt;td&gt;Limited options&lt;/td&gt; 
   &lt;td&gt;Unlimited processing power&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Access&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Full REST API&lt;/td&gt; 
   &lt;td&gt;No API&lt;/td&gt; 
   &lt;td&gt;Complete automation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Deployment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Docker, cloud, or local&lt;/td&gt; 
   &lt;td&gt;Google hosted only&lt;/td&gt; 
   &lt;td&gt;Deploy anywhere&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Citations&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Comprehensive with sources&lt;/td&gt; 
   &lt;td&gt;Basic references&lt;/td&gt; 
   &lt;td&gt;Research integrity&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Open source, fully customizable&lt;/td&gt; 
   &lt;td&gt;Closed system&lt;/td&gt; 
   &lt;td&gt;Unlimited extensibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Pay only for AI usage&lt;/td&gt; 
   &lt;td&gt;Monthly subscription + usage&lt;/td&gt; 
   &lt;td&gt;Transparent and controllable&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Why Choose Open Notebook?&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üîí &lt;strong&gt;Privacy First&lt;/strong&gt;: Your sensitive research stays completely private&lt;/li&gt; 
 &lt;li&gt;üí∞ &lt;strong&gt;Cost Control&lt;/strong&gt;: Choose cheaper AI providers or run locally with Ollama&lt;/li&gt; 
 &lt;li&gt;üéôÔ∏è &lt;strong&gt;Better Podcasts&lt;/strong&gt;: Full script control and multi-speaker flexibility vs limited 2-speaker deep-dive format&lt;/li&gt; 
 &lt;li&gt;üîß &lt;strong&gt;Unlimited Customization&lt;/strong&gt;: Modify, extend, and integrate as needed&lt;/li&gt; 
 &lt;li&gt;üåê &lt;strong&gt;No Vendor Lock-in&lt;/strong&gt;: Switch providers, deploy anywhere, own your data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Built With&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://nextjs.org/"&gt;&lt;img src="https://img.shields.io/badge/Next.js-000000?style=for-the-badge&amp;amp;logo=next.js&amp;amp;logoColor=white" alt="Next.js" /&gt;&lt;/a&gt; &lt;a href="https://reactjs.org/"&gt;&lt;img src="https://img.shields.io/badge/React-61DAFB?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=black" alt="React" /&gt;&lt;/a&gt; &lt;a href="https://surrealdb.com/"&gt;&lt;img src="https://img.shields.io/badge/SurrealDB-FF5E00?style=for-the-badge&amp;amp;logo=databricks&amp;amp;logoColor=white" alt="SurrealDB" /&gt;&lt;/a&gt; &lt;a href="https://www.langchain.com/"&gt;&lt;img src="https://img.shields.io/badge/LangChain-3A3A3A?style=for-the-badge&amp;amp;logo=chainlink&amp;amp;logoColor=white" alt="LangChain" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Docker Images Available:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Hub&lt;/strong&gt;: &lt;code&gt;lfnovo/open_notebook:v1-latest-single&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Container Registry&lt;/strong&gt;: &lt;code&gt;ghcr.io/lfnovo/open-notebook:v1-latest-single&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Both registries contain identical images - choose whichever you prefer!&lt;/p&gt; 
&lt;p&gt;Ready to try Open Notebook? Choose your preferred method:&lt;/p&gt; 
&lt;h3&gt;‚ö° Instant Setup (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a new directory for your Open Notebook installation
mkdir open-notebook
cd open-notebook

# Using Docker - Get started in 2 minutes
docker run -d \
  --name open-notebook \
  -p 8502:8502 -p 5055:5055 \
  -v ./notebook_data:/app/data \
  -v ./surreal_data:/mydata \
  -e OPENAI_API_KEY=your_key \
  lfnovo/open_notebook:v1-latest-single

# Or use GitHub Container Registry:
# ghcr.io/lfnovo/open-notebook:v1-latest-single
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What gets created:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;open-notebook/
‚îú‚îÄ‚îÄ notebook_data/     # Your notebooks and research content
‚îî‚îÄ‚îÄ surreal_data/      # Database files
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Access your installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üñ•Ô∏è Main Interface&lt;/strong&gt;: &lt;a href="http://localhost:8502"&gt;http://localhost:8502&lt;/a&gt; (Next.js UI)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß API Access&lt;/strong&gt;: &lt;a href="http://localhost:5055"&gt;http://localhost:5055&lt;/a&gt; (REST API)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö API Documentation&lt;/strong&gt;: &lt;a href="http://localhost:5055/docs"&gt;http://localhost:5055/docs&lt;/a&gt; (Interactive Swagger UI)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Important&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Run from a dedicated folder&lt;/strong&gt;: Create and run this from inside a new &lt;code&gt;open-notebook&lt;/code&gt; folder so your data volumes are properly organized&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Volume persistence&lt;/strong&gt;: The volumes (&lt;code&gt;-v ./notebook_data:/app/data&lt;/code&gt; and &lt;code&gt;-v ./surreal_data:/mydata&lt;/code&gt;) are essential to persist your data between container restarts. Without them, you'll lose all your notebooks and research when the container stops.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üõ†Ô∏è Full Installation&lt;/h3&gt; 
&lt;p&gt;For development or customization:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/lfnovo/open-notebook
cd open-notebook
make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;üìñ Need Help?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ AI Installation Assistant&lt;/strong&gt;: We have a &lt;a href="https://chatgpt.com/g/g-68776e2765b48191bd1bae3f30212631-open-notebook-installation-assistant"&gt;CustomGPT built to help you install Open Notebook&lt;/a&gt; - it will guide you through each step!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;New to Open Notebook?&lt;/strong&gt; Start with our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/index.md"&gt;Getting Started Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Need installation help?&lt;/strong&gt; Check our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/installation.md"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Want to see it in action?&lt;/strong&gt; Try our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/quick-start.md"&gt;Quick Start Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Provider Support Matrix&lt;/h2&gt; 
&lt;p&gt;Thanks to the &lt;a href="https://github.com/lfnovo/esperanto"&gt;Esperanto&lt;/a&gt; library, we support this providers out of the box!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;LLM Support&lt;/th&gt; 
   &lt;th&gt;Embedding Support&lt;/th&gt; 
   &lt;th&gt;Speech-to-Text&lt;/th&gt; 
   &lt;th&gt;Text-to-Speech&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Groq&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google (GenAI)&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vertex AI&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Perplexity&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ElevenLabs&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure OpenAI&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mistral&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Voyage&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xAI&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI Compatible*&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Supports LM Studio and any OpenAI-compatible endpoint&lt;/p&gt; 
&lt;h2&gt;‚ú® Key Features&lt;/h2&gt; 
&lt;h3&gt;Core Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Privacy-First&lt;/strong&gt;: Your data stays under your control - no cloud dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéØ Multi-Notebook Organization&lt;/strong&gt;: Manage multiple research projects seamlessly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìö Universal Content Support&lt;/strong&gt;: PDFs, videos, audio, web pages, Office docs, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ü§ñ Multi-Model AI Support&lt;/strong&gt;: 16+ providers including OpenAI, Anthropic, Ollama, Google, LM Studio, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üéôÔ∏è Professional Podcast Generation&lt;/strong&gt;: Advanced multi-speaker podcasts with Episode Profiles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîç Intelligent Search&lt;/strong&gt;: Full-text and vector search across all your content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üí¨ Context-Aware Chat&lt;/strong&gt;: AI conversations powered by your research materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìù AI-Assisted Notes&lt;/strong&gt;: Generate insights or write notes manually&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;‚ö° Reasoning Model Support&lt;/strong&gt;: Full support for thinking models like DeepSeek-R1 and Qwen3&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Content Transformations&lt;/strong&gt;: Powerful customizable actions to summarize and extract insights&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üåê Comprehensive REST API&lt;/strong&gt;: Full programmatic access for custom integrations &lt;a href="http://localhost:5055/docs"&gt;&lt;img src="https://img.shields.io/badge/API-Documentation-blue?style=flat-square" alt="API Docs" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîê Optional Password Protection&lt;/strong&gt;: Secure public deployments with authentication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìä Fine-Grained Context Control&lt;/strong&gt;: Choose exactly what to share with AI models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìé Citations&lt;/strong&gt;: Get answers with proper source citations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Three-Column Interface&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Sources&lt;/strong&gt;: Manage all your research materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Notes&lt;/strong&gt;: Create manual or AI-generated notes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chat&lt;/strong&gt;: Converse with AI using your content as context&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=D-760MlGwaI"&gt;&lt;img src="https://img.youtube.com/vi/D-760MlGwaI/0.jpg" alt="Check out our podcast sample" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/introduction.md"&gt;üìñ Introduction&lt;/a&gt;&lt;/strong&gt; - Learn what Open Notebook offers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/quick-start.md"&gt;‚ö° Quick Start&lt;/a&gt;&lt;/strong&gt; - Get up and running in 5 minutes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/installation.md"&gt;üîß Installation&lt;/a&gt;&lt;/strong&gt; - Comprehensive setup guide&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/first-notebook.md"&gt;üéØ Your First Notebook&lt;/a&gt;&lt;/strong&gt; - Step-by-step tutorial&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Guide&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/interface-overview.md"&gt;üì± Interface Overview&lt;/a&gt;&lt;/strong&gt; - Understanding the layout&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/notebooks.md"&gt;üìö Notebooks&lt;/a&gt;&lt;/strong&gt; - Organizing your research&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/sources.md"&gt;üìÑ Sources&lt;/a&gt;&lt;/strong&gt; - Managing content types&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/notes.md"&gt;üìù Notes&lt;/a&gt;&lt;/strong&gt; - Creating and managing notes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/chat.md"&gt;üí¨ Chat&lt;/a&gt;&lt;/strong&gt; - AI conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/search.md"&gt;üîç Search&lt;/a&gt;&lt;/strong&gt; - Finding information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Topics&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/podcasts.md"&gt;üéôÔ∏è Podcast Generation&lt;/a&gt;&lt;/strong&gt; - Create professional podcasts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/transformations.md"&gt;üîß Content Transformations&lt;/a&gt;&lt;/strong&gt; - Customize content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/ai-models.md"&gt;ü§ñ AI Models&lt;/a&gt;&lt;/strong&gt; - AI model configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/development/api-reference.md"&gt;üîß REST API Reference&lt;/a&gt;&lt;/strong&gt; - Complete API documentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/security.md"&gt;üîê Security&lt;/a&gt;&lt;/strong&gt; - Password protection and privacy&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/index.md"&gt;üöÄ Deployment&lt;/a&gt;&lt;/strong&gt; - Complete deployment guides for all scenarios&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;üó∫Ô∏è Roadmap&lt;/h2&gt; 
&lt;h3&gt;Upcoming Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Live Front-End Updates&lt;/strong&gt;: Real-time UI updates for smoother experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Async Processing&lt;/strong&gt;: Faster UI through asynchronous content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Notebook Sources&lt;/strong&gt;: Reuse research materials across projects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bookmark Integration&lt;/strong&gt;: Connect with your favorite bookmarking apps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Recently Completed ‚úÖ&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Next.js Frontend&lt;/strong&gt;: Modern React-based frontend with improved performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive REST API&lt;/strong&gt;: Full programmatic access to all functionality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Model Support&lt;/strong&gt;: 16+ AI providers including OpenAI, Anthropic, Ollama, LM Studio&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Podcast Generator&lt;/strong&gt;: Professional multi-speaker podcasts with Episode Profiles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content Transformations&lt;/strong&gt;: Powerful customizable actions for content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Citations&lt;/strong&gt;: Improved layout and finer control for source citations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Chat Sessions&lt;/strong&gt;: Manage different conversations within notebooks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;open issues&lt;/a&gt; for a full list of proposed features and known issues.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;ü§ù Community &amp;amp; Contributing&lt;/h2&gt; 
&lt;h3&gt;Join the Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí¨ &lt;strong&gt;&lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord Server&lt;/a&gt;&lt;/strong&gt; - Get help, share ideas, and connect with other users&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;strong&gt;&lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Report bugs and request features&lt;/li&gt; 
 &lt;li&gt;‚≠ê &lt;strong&gt;Star this repo&lt;/strong&gt; - Show your support and help others discover Open Notebook&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome contributions! We're especially looking for help with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend Development&lt;/strong&gt;: Help improve our modern Next.js/React UI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing &amp;amp; Bug Fixes&lt;/strong&gt;: Make Open Notebook more robust&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Development&lt;/strong&gt;: Build the coolest research tool together&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Improve guides and tutorials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Current Tech Stack&lt;/strong&gt;: Python, FastAPI, Next.js, React, SurrealDB &lt;strong&gt;Future Roadmap&lt;/strong&gt;: Real-time updates, enhanced async processing&lt;/p&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for detailed information on how to get started.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;Open Notebook is MIT licensed. See the &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;üìû Contact&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Luis Novo&lt;/strong&gt; - &lt;a href="https://twitter.com/lfnovo"&gt;@lfnovo&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Community Support&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üí¨ &lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord Server&lt;/a&gt; - Get help, share ideas, and connect with users&lt;/li&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;GitHub Issues&lt;/a&gt; - Report bugs and request features&lt;/li&gt; 
 &lt;li&gt;üåê &lt;a href="https://www.open-notebook.ai"&gt;Website&lt;/a&gt; - Learn more about the project&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üôè Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Open Notebook is built on the shoulders of amazing open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/podcast-creator"&gt;Podcast Creator&lt;/a&gt;&lt;/strong&gt; - Advanced podcast generation capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/surreal-commands"&gt;Surreal Commands&lt;/a&gt;&lt;/strong&gt; - Background job processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/content-core"&gt;Content Core&lt;/a&gt;&lt;/strong&gt; - Content processing and management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/esperanto"&gt;Esperanto&lt;/a&gt;&lt;/strong&gt; - Multi-provider AI model abstraction&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/docling-project/docling"&gt;Docling&lt;/a&gt;&lt;/strong&gt; - Document processing and parsing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>qbittorrent/qBittorrent</title>
      <link>https://github.com/qbittorrent/qBittorrent</link>
      <description>&lt;p&gt;qBittorrent BitTorrent client&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;qBittorrent - A BitTorrent client in Qt&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/qbittorrent/qBittorrent/actions"&gt;&lt;img src="https://github.com/qbittorrent/qBittorrent/actions/workflows/ci_ubuntu.yaml/badge.svg?sanitize=true" alt="GitHub Actions CI Status" /&gt;&lt;/a&gt; &lt;a href="https://scan.coverity.com/projects/5494"&gt;&lt;img src="https://scan.coverity.com/projects/5494/badge.svg?sanitize=true" alt="Coverity Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Description:&lt;/h3&gt; 
&lt;p&gt;qBittorrent is a bittorrent client programmed in C++ / Qt that uses libtorrent (sometimes called libtorrent-rasterbar) by Arvid Norberg.&lt;/p&gt; 
&lt;p&gt;It aims to be a good alternative to all other bittorrent clients out there. qBittorrent is fast, stable and provides unicode support as well as many features.&lt;/p&gt; 
&lt;p&gt;The free &lt;a href="https://db-ip.com/db/download/ip-to-country-lite"&gt;IP to Country Lite database&lt;/a&gt; by &lt;a href="https://db-ip.com/"&gt;DB-IP&lt;/a&gt; is used for resolving the countries of peers. The database is licensed under the &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;Creative Commons Attribution 4.0 International License&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Installation:&lt;/h3&gt; 
&lt;p&gt;Refer to the &lt;a href="https://raw.githubusercontent.com/qbittorrent/qBittorrent/master/INSTALL"&gt;INSTALL&lt;/a&gt; file.&lt;/p&gt; 
&lt;h3&gt;Public key:&lt;/h3&gt; 
&lt;p&gt;Starting from v3.3.4 all source tarballs and binaries are signed.&lt;br /&gt; The key currently used is 4096R/&lt;a href="https://pgp.mit.edu/pks/lookup?op=get&amp;amp;search=0x6E4A2D025B7CC9A2"&gt;5B7CC9A2&lt;/a&gt; with fingerprint &lt;code&gt;D8F3DA77AAC6741053599C136E4A2D025B7CC9A2&lt;/code&gt;.&lt;br /&gt; You can also download it from &lt;a href="https://github.com/qbittorrent/qBittorrent/raw/master/5B7CC9A2.asc"&gt;here&lt;/a&gt;.&lt;br /&gt; &lt;strong&gt;PREVIOUSLY&lt;/strong&gt; the following key was used to sign the v3.3.4 source tarballs and v3.3.4 Windows installer &lt;strong&gt;only&lt;/strong&gt;: 4096R/&lt;a href="https://pgp.mit.edu/pks/lookup?op=get&amp;amp;search=0xA1ACCAE4520EC6F6"&gt;520EC6F6&lt;/a&gt; with fingerprint &lt;code&gt;F4A5FD201B117B1C2AB590E2A1ACCAE4520EC6F6&lt;/code&gt;.&lt;br /&gt;&lt;/p&gt; 
&lt;h3&gt;Misc:&lt;/h3&gt; 
&lt;p&gt;For more information please visit: &lt;a href="https://www.qbittorrent.org"&gt;https://www.qbittorrent.org&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;or our wiki here: &lt;a href="https://wiki.qbittorrent.org"&gt;https://wiki.qbittorrent.org&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Use the forum for troubleshooting before reporting bugs: &lt;a href="https://forum.qbittorrent.org"&gt;https://forum.qbittorrent.org&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Please report any bug (or feature request) to: &lt;a href="https://bugs.qbittorrent.org"&gt;https://bugs.qbittorrent.org&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Official IRC channel: &lt;a href="ircs://irc.libera.chat:6697/qbittorrent"&gt;#qbittorrent on irc.libera.chat&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;sledgehammer999 &amp;lt;&lt;a href="mailto:sledgehammer999@qbittorrent.org"&gt;sledgehammer999@qbittorrent.org&lt;/a&gt;&amp;gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>atuinsh/desktop</title>
      <link>https://github.com/atuinsh/desktop</link>
      <description>&lt;p&gt;üìñ Runbooks that run&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/atuinsh/atuin/assets/53315310/13216a1d-1ac0-4c99-b0eb-d88290fe0efd" /&gt; 
  &lt;img alt="Atuin Desktop" src="https://github.com/atuinsh/atuin/assets/53315310/08bc86d4-a781-4aaa-8d7e-478ae6bcd129" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;Atuin Desktop&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;em&gt;Runbooks that Run. A local-first, executable runbook editor for real terminal workflows. Atuin Desktop looks like a doc, but runs like your terminal.&lt;/em&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/atuinsh/desktop/releases"&gt;download&lt;/a&gt; | &lt;a href="https://man.atuin.sh"&gt;documentation&lt;/a&gt; | &lt;a href="https://hub.atuin.sh/"&gt;hub&lt;/a&gt; | &lt;a href="https://discord.gg/Fq8bJSKPHh"&gt;discord&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://man.atuin.sh/images/atuin-desktop-ss-dark.png" /&gt; 
  &lt;img alt="Atuin Desktop" src="https://man.atuin.sh/images/atuin-desktop-ss-light.png" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h2&gt;üöÄ Open Beta&lt;/h2&gt; 
&lt;p&gt;Atuin Desktop is currently in &lt;strong&gt;open beta&lt;/strong&gt;. We're actively collecting feedback and improving the experience based on real-world usage.&lt;/p&gt; 
&lt;p&gt;Read the &lt;a href="https://blog.atuin.sh/atuin-desktop-open-source/"&gt;announcement post&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;What is Atuin Desktop?&lt;/h2&gt; 
&lt;p&gt;Most infrastructure is held together by five commands someone remembers when things go wrong. Documentation is out of date (if it exists at all), and the real answers are buried in Slack threads, rotting in Notion, or trapped in someone's shell history.&lt;/p&gt; 
&lt;p&gt;Atuin Desktop solves this by creating &lt;strong&gt;executable runbooks&lt;/strong&gt; that bridge the gap between documentation and automation:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Kill context switching&lt;/strong&gt;: Chain shell commands, database queries, and HTTP requests in one place&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docs that don't rot&lt;/strong&gt;: Execute directly and stay relevant&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reusable automation&lt;/strong&gt;: Dynamic runbooks with Jinja-style templating&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instant recall&lt;/strong&gt;: Autocomplete from your real shell history&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Local-first, CRDT-powered&lt;/strong&gt;: If it runs in your terminal, it runs in a runbook&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Sync and share&lt;/strong&gt;: Keep runbooks up to date across devices and teams with Atuin Hub&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;h3&gt;üîß Embedded Execution&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Terminal blocks that run directly in the interface&lt;/li&gt; 
 &lt;li&gt;Database clients for live queries&lt;/li&gt; 
 &lt;li&gt;Prometheus charts and monitoring integration&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìö Living Documentation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Runbooks that run&lt;/li&gt; 
 &lt;li&gt;No more copy-pasting from outdated docs&lt;/li&gt; 
 &lt;li&gt;Real workflows that teams can actually use&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîÑ Dynamic Templating&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jinja-style templating for reusable logic&lt;/li&gt; 
 &lt;li&gt;Variable substitution and conditional logic&lt;/li&gt; 
 &lt;li&gt;Parameterized workflows for different environments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üèõÔ∏è Local-First Architecture&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;CRDT-powered collaboration&lt;/li&gt; 
 &lt;li&gt;Works offline, syncs when connected&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Use Cases&lt;/h2&gt; 
&lt;p&gt;Teams are already using Atuin Desktop for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Release Management&lt;/strong&gt;: Automated release checklists that actually run&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Infrastructure Migration&lt;/strong&gt;: Safe, repeatable migration workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Environment Management&lt;/strong&gt;: Spinning up staging and production with confidence&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database Operations&lt;/strong&gt;: Collaborative live query management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Incident Response&lt;/strong&gt;: Runbooks for when things break&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download a package for your platform &lt;a href="https://github.com/atuinsh/desktop/releases"&gt;on our releases page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Sign up for an account &lt;a href="https://hub.atuin.sh/"&gt;on Atuin Hub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://man.atuin.sh/hub/getting-started/"&gt;Log into Atuin Desktop&lt;/a&gt; and create your first runbook&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Feedback &amp;amp; Support&lt;/h2&gt; 
&lt;p&gt;We're actively seeking feedback during our beta phase! Please use this repository to:&lt;/p&gt; 
&lt;h3&gt;üêõ Report Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Found a bug? &lt;a href="https://raw.githubusercontent.com/atuinsh/issues/new?template=bug_report.md"&gt;Open an issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Include your OS, Atuin Desktop version, and steps to reproduce&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üí° Request Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Have an idea? &lt;a href="https://raw.githubusercontent.com/atuinsh/issues/new?template=feature_request.md"&gt;Submit a feature request&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tell us about your workflow and how Atuin Desktop could better support it&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üí¨ General Discussion&lt;/h3&gt; 
&lt;p&gt;Questions about usage? &lt;a href="https://forum.atuin.sh"&gt;Start a discussion&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;h3&gt;Coming Soon&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Integrations&lt;/strong&gt;: More database clients, monitoring tools, and APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;History-to-Runbook&lt;/strong&gt;: Generate runbooks automatically from your shell history&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Blog&lt;/strong&gt;: &lt;a href="https://blog.atuin.sh"&gt;blog.atuin.sh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Discord&lt;/strong&gt;: &lt;a href="https://discord.gg/Fq8bJSKPHh"&gt;Join our community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Twitter&lt;/strong&gt;: &lt;a href="https://twitter.com/atuinsh"&gt;@atuinsh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bluesky&lt;/strong&gt;: &lt;a href="https://bsky.app/profile/atuin.sh"&gt;@atuin.sh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Website&lt;/strong&gt;: &lt;a href="https://atuin.sh"&gt;atuin.sh&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Related Projects&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/atuinsh/atuin"&gt;Atuin CLI&lt;/a&gt;&lt;/strong&gt;: Magical shell history with sync, search, and stats&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright 2025 Atuin, Inc&lt;/p&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>clockworklabs/SpacetimeDB</title>
      <link>https://github.com/clockworklabs/SpacetimeDB</link>
      <description>&lt;p&gt;Multiplayer at the speed of light&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://spacetimedb.com#gh-dark-mode-only" target="_blank"&gt; &lt;img width="320" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/dark/logo.svg?sanitize=true" alt="SpacetimeDB Logo" /&gt; &lt;/a&gt; &lt;a href="https://spacetimedb.com#gh-light-mode-only" target="_blank"&gt; &lt;img width="320" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/light/logo.svg?sanitize=true" alt="SpacetimeDB Logo" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://spacetimedb.com#gh-dark-mode-only" target="_blank"&gt; &lt;img width="250" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/dark/logo-text.svg?sanitize=true" alt="SpacetimeDB" /&gt; &lt;/a&gt; &lt;a href="https://spacetimedb.com#gh-light-mode-only" target="_blank"&gt; &lt;img width="250" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/light/logo-text.svg?sanitize=true" alt="SpacetimeDB" /&gt; &lt;/a&gt; &lt;/p&gt;
&lt;h3 align="center"&gt; Multiplayer at the speed of light. &lt;/h3&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/clockworklabs/spacetimedb"&gt;&lt;img src="https://img.shields.io/github/v/release/clockworklabs/spacetimedb?color=%23ff00a0&amp;amp;include_prereleases&amp;amp;label=version&amp;amp;sort=semver&amp;amp;style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/clockworklabs/spacetimedb"&gt;&lt;img src="https://img.shields.io/badge/built_with-Rust-dca282.svg?style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/clockworklabs/spacetimedb/actions"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/clockworklabs/spacetimedb/ci.yml?style=flat-square&amp;amp;branch=master" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://status.spacetimedb.com"&gt;&lt;img src="https://img.shields.io/uptimerobot/ratio/7/m784409192-e472ca350bb615372ededed7?label=cloud%20uptime&amp;amp;style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://hub.docker.com/r/clockworklabs/spacetimedb"&gt;&lt;img src="https://img.shields.io/docker/pulls/clockworklabs/spacetimedb?style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/clockworklabs/spacetimedb/raw/master/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/badge/license-BSL_1.1-00bfff.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://crates.io/crates/spacetimedb"&gt;&lt;img src="https://img.shields.io/crates/d/spacetimedb?color=e45928&amp;amp;label=Rust%20Crate&amp;amp;style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.nuget.org/packages/SpacetimeDB.Runtime"&gt;&lt;img src="https://img.shields.io/nuget/dt/spacetimedb.runtime?color=0b6cff&amp;amp;label=NuGet%20Package&amp;amp;style=flat-square" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/spacetimedb"&gt;&lt;img src="https://img.shields.io/discord/1037340874172014652?label=discord&amp;amp;style=flat-square&amp;amp;color=5a66f6" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://twitter.com/spacetime_db"&gt;&lt;img src="https://img.shields.io/badge/twitter-Follow_us-1d9bf0.svg?style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://clockworklabs.io/join"&gt;&lt;img src="https://img.shields.io/badge/careers-Join_us-86f7b7.svg?style=flat-square" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.linkedin.com/company/clockworklabs/"&gt;&lt;img src="https://img.shields.io/badge/linkedin-Connect_with_us-0a66c2.svg?style=flat-square" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/spacetimedb"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/discord.svg?sanitize=true" alt="Discord" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://twitter.com/spacetime_db"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/twitter.svg?sanitize=true" alt="Twitter" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://github.com/clockworklabs/spacetimedb"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/github.svg?sanitize=true" alt="GitHub" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://twitch.tv/SpacetimeDB"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/twitch.svg?sanitize=true" alt="Twitch" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://youtube.com/@SpacetimeDB"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/youtube.svg?sanitize=true" alt="YouTube" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://www.linkedin.com/company/clockwork-labs/"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/linkedin.svg?sanitize=true" alt="LinkedIn" /&gt;&lt;/a&gt; &amp;nbsp; &lt;a href="https://stackoverflow.com/questions/tagged/spacetimedb"&gt;&lt;img height="25" src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/social/stackoverflow.svg?sanitize=true" alt="StackOverflow" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;What is &lt;a href="https://spacetimedb.com"&gt;SpacetimeDB&lt;/a&gt;?&lt;/h2&gt; 
&lt;p&gt;You can think of SpacetimeDB as both a database and server combined into one.&lt;/p&gt; 
&lt;p&gt;It is a relational database system that lets you upload your application logic directly into the database by way of fancy stored procedures called "modules."&lt;/p&gt; 
&lt;p&gt;Instead of deploying a web or game server that sits in between your clients and your database, your clients connect directly to the database and execute your application logic inside the database itself. You can write all of your permission and authorization logic right inside your module just as you would in a normal server.&lt;/p&gt; 
&lt;p&gt;This means that you can write your entire application in a single language, Rust, and deploy it as a single binary. No more microservices, no more containers, no more Kubernetes, no more Docker, no more VMs, no more DevOps, no more infrastructure, no more ops, no more servers.&lt;/p&gt; 
&lt;figure&gt; 
 &lt;img src="https://raw.githubusercontent.com/clockworklabs/SpacetimeDB/master/images/basic-architecture-diagram.png" alt="SpacetimeDB Architecture" style="width:100%" /&gt; 
 &lt;figcaption align="center"&gt; 
  &lt;p align="center"&gt;&lt;b&gt;SpacetimeDB application architecture&lt;/b&gt;&lt;br /&gt;&lt;sup&gt;&lt;sub&gt;(elements in white are provided by SpacetimeDB)&lt;/sub&gt;&lt;/sup&gt;&lt;/p&gt; 
 &lt;/figcaption&gt; 
&lt;/figure&gt; 
&lt;p&gt;It's actually similar to the idea of smart contracts, except that SpacetimeDB is a database, has nothing to do with blockchain, and is orders of magnitude faster than any smart contract system.&lt;/p&gt; 
&lt;p&gt;So fast, in fact, that the entire backend of our MMORPG &lt;a href="https://bitcraftonline.com"&gt;BitCraft Online&lt;/a&gt; is just a SpacetimeDB module. We don't have any other servers or services running, which means that everything in the game, all of the chat messages, items, resources, terrain, and even the locations of the players are stored and processed by the database before being synchronized out to all of the clients in real-time.&lt;/p&gt; 
&lt;p&gt;SpacetimeDB is optimized for maximum speed and minimum latency rather than batch processing or OLAP workloads. It is designed to be used for real-time applications like games, chat, and collaboration tools.&lt;/p&gt; 
&lt;p&gt;This speed and latency is achieved by holding all of application state in memory, while persisting the data in a write-ahead-log (WAL) which is used to recover application state.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;You can run SpacetimeDB as a standalone database server via the &lt;code&gt;spacetime&lt;/code&gt; CLI tool. Install instructions for supported platforms are outlined below. The same install instructions can be found on our website at &lt;a href="https://spacetimedb.com/install"&gt;https://spacetimedb.com/install&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Install on macOS&lt;/h4&gt; 
&lt;p&gt;Installing on macOS is as simple as running our install script. After that you can use the spacetime command to manage versions.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSf https://install.spacetimedb.com | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Install on Linux&lt;/h4&gt; 
&lt;p&gt;Installing on Linux is as simple as running our install script. After that you can use the spacetime command to manage versions.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSf https://install.spacetimedb.com | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Install on Windows&lt;/h4&gt; 
&lt;p&gt;Installing on Windows is as simple as pasting the above snippet into PowerShell. If you would like to use WSL instead, please follow the Linux install instructions.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ps1"&gt;iwr https://windows.spacetimedb.com -useb | iex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Installing from Source&lt;/h4&gt; 
&lt;p&gt;A quick note on installing from source: we recommend that you don't install from source unless there is a feature that is available in &lt;code&gt;master&lt;/code&gt; that hasn't been released yet, otherwise follow the official installation instructions.&lt;/p&gt; 
&lt;h5&gt;MacOS + Linux&lt;/h5&gt; 
&lt;p&gt;Installing on macOS + Linux is pretty straightforward. First we are going to build all of the binaries that we need:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install rustup, you can skip this step if you have cargo and the wasm32-unknown-unknown target already installed.
curl https://sh.rustup.rs -sSf | sh
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
mkdir -p ~/.local/bin
export STDB_VERSION="$(./target/release/spacetimedb-cli --version | sed -n 's/.*spacetimedb tool version \([0-9.]*\);.*/\1/p')"
mkdir -p ~/.local/share/spacetime/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/.local/bin/spacetime
cp target/release/spacetimedb-cli ~/.local/share/spacetime/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/.local/share/spacetime/bin/$STDB_VERSION
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;At this stage you'll need to add ~/.local/bin to your path if you haven't already.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# Please add the following line to your shell configuration and open a new shell session:
export PATH="$HOME/.local/bin:$PATH"

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then finally set your SpacetimeDB version:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;
# Then, in a new shell, set the current version:
spacetime version use $STDB_VERSION

# If STDB_VERSION is not set anymore then you can use the following command to list your versions:
spacetime version list
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can verify that the correct version has been installed via &lt;code&gt;spacetime --version&lt;/code&gt;.&lt;/p&gt; 
&lt;h5&gt;Windows&lt;/h5&gt; 
&lt;p&gt;Building on windows is a bit more complicated. You'll need a slightly different version of perl compared to what comes pre-bundled in most Windows terminals. We recommend &lt;a href="https://strawberryperl.com/"&gt;Strawberry Perl&lt;/a&gt;. You may also need access to an &lt;code&gt;openssl&lt;/code&gt; binary which actually comes pre-installed with &lt;a href="https://git-scm.com/downloads/win"&gt;Git for Windows&lt;/a&gt;. Also, you'll need to install &lt;a href="https://rustup.rs/"&gt;rustup&lt;/a&gt; for Windows.&lt;/p&gt; 
&lt;p&gt;In a Git for Windows shell you should have something that looks like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ which perl
/c/Strawberry/perl/bin/perl
$ which openssl
/mingw64/bin/openssl
$ which cargo 
/c/Users/&amp;lt;user&amp;gt;/.cargo/bin/cargo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If that looks correct then you're ready to proceed!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB

# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
$stdbDir = "$HOME\AppData\Local\SpacetimeDB"
$stdbVersion = &amp;amp; ".\target\release\spacetimedb-cli" --version | Select-String -Pattern 'spacetimedb tool version ([0-9.]+);' | ForEach-Object { $_.Matches.Groups[1].Value }
New-Item -ItemType Directory -Path "$stdbDir\bin\$stdbVersion" -Force | Out-Null

# Install the update binary
Copy-Item "target\release\spacetimedb-update.exe" "$stdbDir\spacetime.exe"
Copy-Item "target\release\spacetimedb-cli.exe" "$stdbDir\bin\$stdbVersion\"
Copy-Item "target\release\spacetimedb-standalone.exe" "$stdbDir\bin\$stdbVersion\"

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;%USERPROFILE%\AppData\Local\SpacetimeDB
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then finally, open a new shell and use the installed SpacetimeDB version:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;spacetime version use $stdbVersion

# If stdbVersion is no longer set, list versions using the following command:
spacetime version list
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can verify that the correct version has been installed via &lt;code&gt;spacetime --version&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;If you're using Git for Windows you can follow these instructions instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
# Build the CLI binaries - this takes a while on windows so go grab a coffee :)
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
export STDB_VERSION="$(./target/release/spacetimedb-cli --version | sed -n 's/.*spacetimedb tool version \([0-9.]*\);.*/\1/p')"
mkdir -p ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/AppData/Local/SpacetimeDB/spacetime
cp target/release/spacetimedb-cli ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!
# %USERPROFILE%\AppData\Local\SpacetimeDB

# Set the current version
spacetime version use $STDB_VERSION
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can verify that the correct version has been installed via &lt;code&gt;spacetime --version&lt;/code&gt;.&lt;/p&gt; 
&lt;h4&gt;Running with Docker&lt;/h4&gt; 
&lt;p&gt;If you prefer to run Spacetime in a container, you can use the following command to start a new instance.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm --pull always -p 3000:3000 clockworklabs/spacetime start
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;For more information about SpacetimeDB, getting started guides, game development guides, and reference material please see our &lt;a href="https://spacetimedb.com/docs"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;We've prepared several getting started guides in each of our supported languages to help you get up and running with SpacetimeDB as quickly as possible. You can find them on our &lt;a href="https://spacetimedb.com/docs"&gt;docs page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In summary there are only 4 steps to getting started with SpacetimeDB.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install the &lt;code&gt;spacetime&lt;/code&gt; CLI tool.&lt;/li&gt; 
 &lt;li&gt;Start a SpacetimeDB standalone node with &lt;code&gt;spacetime start&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Write and upload a module in one of our supported module languages.&lt;/li&gt; 
 &lt;li&gt;Connect to the database with one of our client libraries.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You can see a summary of the supported languages below with a link to the getting started guide for each.&lt;/p&gt; 
&lt;h2&gt;Language Support&lt;/h2&gt; 
&lt;p&gt;You can write SpacetimeDB modules in several popular languages, with more to come in the future!&lt;/p&gt; 
&lt;h4&gt;Serverside Libraries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://spacetimedb.com/docs/modules/rust/quickstart"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://spacetimedb.com/docs/modules/c-sharp/quickstart"&gt;C#&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Client Libraries&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://spacetimedb.com/docs/sdks/rust/quickstart"&gt;Rust&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://spacetimedb.com/docs/sdks/c-sharp/quickstart"&gt;C#&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://spacetimedb.com/docs/sdks/typescript/quickstart"&gt;Typescript&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;SpacetimeDB is licensed under the BSL 1.1 license. This is not an open source or free software license, however, it converts to the AGPL v3.0 license with a linking exception after a few years.&lt;/p&gt; 
&lt;p&gt;Note that the AGPL v3.0 does not typically include a linking exception. We have added a custom linking exception to the AGPL license for SpacetimeDB. Our motivation for choosing a free software license is to ensure that contributions made to SpacetimeDB are propagated back to the community. We are expressly not interested in forcing users of SpacetimeDB to open source their own code if they link with SpacetimeDB, so we needed to include a linking exception.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TheAlgorithms/Python</title>
      <link>https://github.com/TheAlgorithms/Python</link>
      <description>&lt;p&gt;All Algorithms implemented in Python&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;!-- Title: --&gt; 
 &lt;a href="https://github.com/TheAlgorithms/"&gt; &lt;img src="https://raw.githubusercontent.com/TheAlgorithms/website/1cd824df116b27029f17c2d1b42d81731f28a920/public/logo.svg?sanitize=true" height="100" /&gt; &lt;/a&gt; 
 &lt;h1&gt;&lt;a href="https://github.com/TheAlgorithms/"&gt;The Algorithms&lt;/a&gt; - Python&lt;/h1&gt; 
 &lt;!-- Labels: --&gt; 
 &lt;!-- First row: --&gt; 
 &lt;a href="https://gitpod.io/#https://github.com/TheAlgorithms/Python"&gt; &lt;img src="https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod&amp;amp;style=flat-square" height="20" alt="Gitpod Ready-to-Code" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/raw/master/CONTRIBUTING.md"&gt; &lt;img src="https://img.shields.io/static/v1.svg?label=Contributions&amp;amp;message=Welcome&amp;amp;color=0059b3&amp;amp;style=flat-square" height="20" alt="Contributions Welcome" /&gt; &lt;/a&gt; 
 &lt;img src="https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;amp;style=flat-square" height="20" /&gt; 
 &lt;a href="https://the-algorithms.com/discord"&gt; &lt;img src="https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;amp;colorB=7289DA&amp;amp;style=flat-square" height="20" alt="Discord chat" /&gt; &lt;/a&gt; 
 &lt;a href="https://gitter.im/TheAlgorithms/community"&gt; &lt;img src="https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;amp;logo=gitter&amp;amp;style=flat-square" height="20" alt="Gitter chat" /&gt; &lt;/a&gt; 
 &lt;!-- Second row: --&gt; 
 &lt;br /&gt; 
 &lt;a href="https://github.com/TheAlgorithms/Python/actions"&gt; &lt;img src="https://img.shields.io/github/actions/workflow/status/TheAlgorithms/Python/build.yml?branch=master&amp;amp;label=CI&amp;amp;logo=github&amp;amp;style=flat-square" height="20" alt="GitHub Workflow Status" /&gt; &lt;/a&gt; 
 &lt;a href="https://github.com/pre-commit/pre-commit"&gt; &lt;img src="https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;amp;logoColor=white&amp;amp;style=flat-square" height="20" alt="pre-commit" /&gt; &lt;/a&gt; 
 &lt;a href="https://docs.astral.sh/ruff/formatter/"&gt; &lt;img src="https://img.shields.io/static/v1?label=code%20style&amp;amp;message=ruff&amp;amp;color=black&amp;amp;style=flat-square" height="20" alt="code style: black" /&gt; &lt;/a&gt; 
 &lt;!-- Short description: --&gt; 
 &lt;h3&gt;All algorithms implemented in Python - for education üìö&lt;/h3&gt; 
&lt;/div&gt; 
&lt;p&gt;Implementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.&lt;/p&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;p&gt;üìã Read through our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; before you contribute.&lt;/p&gt; 
&lt;h2&gt;üåê Community Channels&lt;/h2&gt; 
&lt;p&gt;We are on &lt;a href="https://the-algorithms.com/discord"&gt;Discord&lt;/a&gt; and &lt;a href="https://gitter.im/TheAlgorithms/community"&gt;Gitter&lt;/a&gt;! Community channels are a great way for you to ask questions and get help. Please join us!&lt;/p&gt; 
&lt;h2&gt;üìú List of Algorithms&lt;/h2&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/TheAlgorithms/Python/master/DIRECTORY.md"&gt;directory&lt;/a&gt; for easier navigation and a better overview of the project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>reflex-dev/reflex</title>
      <link>https://github.com/reflex-dev/reflex</link>
      <description>&lt;p&gt;üï∏Ô∏è Web apps in pure Python üêç&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/reflex.svg?sanitize=true" alt="Reflex Logo" width="300px" /&gt; 
 &lt;hr /&gt; 
 &lt;h3&gt;&lt;strong&gt;‚ú® Performant, customizable web apps in pure Python. Deploy in seconds. ‚ú®&lt;/strong&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://badge.fury.io/py/reflex"&gt;&lt;img src="https://badge.fury.io/py/reflex.svg?sanitize=true" alt="PyPI version" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/pyversions/reflex.svg?sanitize=true" alt="versions" /&gt; &lt;a href="https://reflex.dev/docs/getting-started/introduction"&gt;&lt;img src="https://img.shields.io/badge/Documentation%20-Introduction%20-%20%23007ec6" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/projects/reflex"&gt;&lt;img src="https://static.pepy.tech/badge/reflex" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/T5WSbC2YtQ"&gt;&lt;img src="https://img.shields.io/discord/1029853095527727165?color=%237289da&amp;amp;label=Discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://x.com/getreflex"&gt;&lt;img src="https://img.shields.io/twitter/follow/getreflex" alt="Twitter" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://github.com/reflex-dev/reflex/raw/main/README.md"&gt;English&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/zh/zh_cn/README.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/zh/zh_tw/README.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/tr/README.md"&gt;T√ºrk√ße&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/in/README.md"&gt;‡§π‡§ø‡§Ç‡§¶‡•Ä&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/pt/pt_br/README.md"&gt;Portugu√™s (Brasil)&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/it/README.md"&gt;Italiano&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/es/README.md"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/kr/README.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/ja/README.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/de/README.md"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/pe/README.md"&gt;Persian (Ÿæÿßÿ±ÿ≥€å)&lt;/a&gt; | &lt;a href="https://github.com/reflex-dev/reflex/raw/main/docs/vi/README.md"&gt;Ti·∫øng Vi·ªát&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] üöÄ &lt;strong&gt;Try &lt;a href="https://build.reflex.dev/"&gt;Reflex Build&lt;/a&gt;&lt;/strong&gt; ‚Äì our AI-powered app builder that generates full-stack Reflex applications in seconds.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;Reflex is a library to build full-stack web apps in pure Python.&lt;/p&gt; 
&lt;p&gt;Key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Pure Python&lt;/strong&gt; - Write your app's frontend and backend all in Python, no need to learn Javascript.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Full Flexibility&lt;/strong&gt; - Reflex is easy to get started with, but can also scale to complex apps.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Deploy Instantly&lt;/strong&gt; - After building, deploy your app with a &lt;a href="https://reflex.dev/docs/hosting/deploy-quick-start/"&gt;single command&lt;/a&gt; or host it on your own server.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See our &lt;a href="https://reflex.dev/blog/2024-03-21-reflex-architecture/#the-reflex-architecture"&gt;architecture page&lt;/a&gt; to learn how Reflex works under the hood.&lt;/p&gt; 
&lt;h2&gt;‚öôÔ∏è Installation&lt;/h2&gt; 
&lt;p&gt;Open a terminal and run (Requires Python 3.10+):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install reflex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ü•≥ Create your first app&lt;/h2&gt; 
&lt;p&gt;Installing &lt;code&gt;reflex&lt;/code&gt; also installs the &lt;code&gt;reflex&lt;/code&gt; command line tool.&lt;/p&gt; 
&lt;p&gt;Test that the install was successful by creating a new project. (Replace &lt;code&gt;my_app_name&lt;/code&gt; with your project name):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mkdir my_app_name
cd my_app_name
reflex init
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This command initializes a template app in your new directory.&lt;/p&gt; 
&lt;p&gt;You can run this app in development mode:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;reflex run
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You should see your app running at &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Now you can modify the source code in &lt;code&gt;my_app_name/my_app_name.py&lt;/code&gt;. Reflex has fast refreshes so you can see your changes instantly when you save your code.&lt;/p&gt; 
&lt;h2&gt;ü´ß Example App&lt;/h2&gt; 
&lt;p&gt;Let's go over an example: creating an image generation UI around &lt;a href="https://platform.openai.com/docs/guides/images/image-generation?context=node"&gt;DALL¬∑E&lt;/a&gt;. For simplicity, we just call the &lt;a href="https://platform.openai.com/docs/api-reference/authentication"&gt;OpenAI API&lt;/a&gt;, but you could replace this with an ML model run locally.&lt;/p&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle.gif" alt="A frontend wrapper for DALL¬∑E, shown in the process of generating an image." width="550" /&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p&gt;Here is the complete code to create this. This is all done in one Python file!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;import reflex as rx
import openai

openai_client = openai.OpenAI()


class State(rx.State):
    """The app state."""

    prompt = ""
    image_url = ""
    processing = False
    complete = False

    def get_image(self):
        """Get the image from the prompt."""
        if self.prompt == "":
            return rx.window_alert("Prompt Empty")

        self.processing, self.complete = True, False
        yield
        response = openai_client.images.generate(
            prompt=self.prompt, n=1, size="1024x1024"
        )
        self.image_url = response.data[0].url
        self.processing, self.complete = False, True


def index():
    return rx.center(
        rx.vstack(
            rx.heading("DALL-E", font_size="1.5em"),
            rx.input(
                placeholder="Enter a prompt..",
                on_blur=State.set_prompt,
                width="25em",
            ),
            rx.button(
                "Generate Image",
                on_click=State.get_image,
                width="25em",
                loading=State.processing
            ),
            rx.cond(
                State.complete,
                rx.image(src=State.image_url, width="20em"),
            ),
            align="center",
        ),
        width="100%",
        height="100vh",
    )

# Add state and page to the app.
app = rx.App()
app.add_page(index, title="Reflex:DALL-E")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Let's break this down.&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle_colored_code_example.png" alt="Explaining the differences between backend and frontend parts of the DALL-E app." width="900" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;&lt;strong&gt;Reflex UI&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Let's start with the UI.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def index():
    return rx.center(
        ...
    )
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This &lt;code&gt;index&lt;/code&gt; function defines the frontend of the app.&lt;/p&gt; 
&lt;p&gt;We use different components such as &lt;code&gt;center&lt;/code&gt;, &lt;code&gt;vstack&lt;/code&gt;, &lt;code&gt;input&lt;/code&gt;, and &lt;code&gt;button&lt;/code&gt; to build the frontend. Components can be nested within each other to create complex layouts. And you can use keyword args to style them with the full power of CSS.&lt;/p&gt; 
&lt;p&gt;Reflex comes with &lt;a href="https://reflex.dev/docs/library"&gt;60+ built-in components&lt;/a&gt; to help you get started. We are actively adding more components, and it's easy to &lt;a href="https://reflex.dev/docs/wrapping-react/overview/"&gt;create your own components&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;State&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Reflex represents your UI as a function of your state.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;class State(rx.State):
    """The app state."""
    prompt = ""
    image_url = ""
    processing = False
    complete = False

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The state defines all the variables (called vars) in an app that can change and the functions that change them.&lt;/p&gt; 
&lt;p&gt;Here the state is comprised of a &lt;code&gt;prompt&lt;/code&gt; and &lt;code&gt;image_url&lt;/code&gt;. There are also the booleans &lt;code&gt;processing&lt;/code&gt; and &lt;code&gt;complete&lt;/code&gt; to indicate when to disable the button (during image generation) and when to show the resulting image.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Event Handlers&lt;/strong&gt;&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def get_image(self):
    """Get the image from the prompt."""
    if self.prompt == "":
        return rx.window_alert("Prompt Empty")

    self.processing, self.complete = True, False
    yield
    response = openai_client.images.generate(
        prompt=self.prompt, n=1, size="1024x1024"
    )
    self.image_url = response.data[0].url
    self.processing, self.complete = False, True
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Within the state, we define functions called event handlers that change the state vars. Event handlers are the way that we can modify the state in Reflex. They can be called in response to user actions, such as clicking a button or typing in a text box. These actions are called events.&lt;/p&gt; 
&lt;p&gt;Our DALL¬∑E app has an event handler, &lt;code&gt;get_image&lt;/code&gt; which gets this image from the OpenAI API. Using &lt;code&gt;yield&lt;/code&gt; in the middle of an event handler will cause the UI to update. Otherwise the UI will update at the end of the event handler.&lt;/p&gt; 
&lt;h3&gt;&lt;strong&gt;Routing&lt;/strong&gt;&lt;/h3&gt; 
&lt;p&gt;Finally, we define our app.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;app = rx.App()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;We add a page from the root of the app to the index component. We also add a title that will show up in the page preview/browser tab.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;app.add_page(index, title="DALL-E")
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can create a multi-page app by adding more pages.&lt;/p&gt; 
&lt;h2&gt;üìë Resources&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;üìë &lt;a href="https://reflex.dev/docs/getting-started/introduction"&gt;Docs&lt;/a&gt; &amp;nbsp; | &amp;nbsp; üóûÔ∏è &lt;a href="https://reflex.dev/blog"&gt;Blog&lt;/a&gt; &amp;nbsp; | &amp;nbsp; üì± &lt;a href="https://reflex.dev/docs/library"&gt;Component Library&lt;/a&gt; &amp;nbsp; | &amp;nbsp; üñºÔ∏è &lt;a href="https://reflex.dev/templates/"&gt;Templates&lt;/a&gt; &amp;nbsp; | &amp;nbsp; üõ∏ &lt;a href="https://reflex.dev/docs/hosting/deploy-quick-start"&gt;Deployment&lt;/a&gt; &amp;nbsp;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚úÖ Status&lt;/h2&gt; 
&lt;p&gt;Reflex launched in December 2022 with the name Pynecone.&lt;/p&gt; 
&lt;p&gt;üöÄ Introducing &lt;a href="https://build.reflex.dev/"&gt;Reflex Build&lt;/a&gt; ‚Äî Our AI-Powered Builder Reflex Build uses AI to generate complete full-stack Python applications. It helps you quickly create, customize, and refine your Reflex apps ‚Äî from frontend components to backend logic ‚Äî so you can focus on your ideas instead of boilerplate code. Whether you‚Äôre prototyping or scaling, Reflex Build accelerates development by intelligently scaffolding and optimizing your app‚Äôs entire stack.&lt;/p&gt; 
&lt;p&gt;Alongside this, &lt;a href="https://cloud.reflex.dev"&gt;Reflex Cloud&lt;/a&gt; launched in 2025 to offer the best hosting experience for your Reflex apps. We‚Äôre continuously improving the platform with new features and capabilities.&lt;/p&gt; 
&lt;p&gt;Reflex has new releases and features coming every week! Make sure to &lt;span&gt;‚≠ê&lt;/span&gt; star and &lt;span&gt;üëÄ&lt;/span&gt; watch this repository to stay up to date.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of any size! Below are some good ways to get started in the Reflex community.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Join Our Discord&lt;/strong&gt;: Our &lt;a href="https://discord.gg/T5WSbC2YtQ"&gt;Discord&lt;/a&gt; is the best place to get help on your Reflex project and to discuss how you can contribute.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;: A great way to talk about features you want added or things that are confusing/need clarification.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/reflex-dev/reflex/issues"&gt;Issues&lt;/a&gt; are an excellent way to report bugs. Additionally, you can try and solve an existing issue and submit a PR.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We are actively looking for contributors, no matter your skill level or experience. To contribute check out &lt;a href="https://github.com/reflex-dev/reflex/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;All Thanks To Our Contributors:&lt;/h2&gt; 
&lt;a href="https://github.com/reflex-dev/reflex/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=reflex-dev/reflex" /&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Reflex is open-source and licensed under the &lt;a href="https://raw.githubusercontent.com/reflex-dev/reflex/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/vcpkg</title>
      <link>https://github.com/microsoft/vcpkg</link>
      <description>&lt;p&gt;C++ Library Manager for Windows, Linux, and MacOS&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://learn.microsoft.com/locale/?target=https%3A%2F%2Flearn.microsoft.com%2Fvcpkg%2F"&gt;üåê Read in a different language&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;vcpkg overview&lt;/h1&gt; 
&lt;p&gt;vcpkg is a free and open-source C/C++ package manager maintained by Microsoft and the C++ community.&lt;/p&gt; 
&lt;p&gt;Initially launched in 2016 as a tool for assisting developers in migrating their projects to newer versions of Visual Studio, vcpkg has evolved into a cross-platform tool used by developers on Windows, macOS, and Linux. vcpkg has a large collection of open-source libraries and enterprise-ready features designed to facilitate your development process with support for any build and project systems. vcpkg is a C++ tool at heart and is written in C++ with scripts in CMake. It is designed from the ground up to address the unique pain points C/C++ developers experience.&lt;/p&gt; 
&lt;p&gt;This tool and ecosystem are constantly evolving, and we always appreciate contributions! Learn how to start contributing with our &lt;a href="https://learn.microsoft.com/vcpkg/get_started/get-started-adding-to-registry"&gt;packaging tutorial&lt;/a&gt; and &lt;a href="https://learn.microsoft.com/vcpkg/contributing/maintainer-guide"&gt;maintainer guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Get started&lt;/h1&gt; 
&lt;p&gt;First, follow one of our quick start guides.&lt;/p&gt; 
&lt;p&gt;Whether you're using CMake, MSBuild, or any other build system, vcpkg has you covered:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/vcpkg/get_started/get-started"&gt;vcpkg with CMake&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/vcpkg/get_started/get-started-msbuild"&gt;vcpkg with MSBuild&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/vcpkg/users/buildsystems/manual-integration"&gt;vcpkg with other build systems&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can also use any editor:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/vcpkg/get_started/get-started-vs"&gt;vcpkg with Visual Studio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/vcpkg/get_started/get-started-vscode"&gt;vcpkg with Visual Studio Code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.jetbrains.com/help/clion/package-management.html"&gt;vcpkg with CLion&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://doc.qt.io/qtcreator/creator-vcpkg.html"&gt;vcpkg with Qt Creator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If a library you need is not present in the vcpkg registry, &lt;a href="https://github.com/microsoft/vcpkg/issues/new/choose"&gt;open an issue on the GitHub repository&lt;/a&gt; or &lt;a href="https://learn.microsoft.com/vcpkg/get_started/get-started-adding-to-registry"&gt;contribute the package yourself&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;After you've gotten vcpkg installed and working, you may wish to &lt;a href="https://learn.microsoft.com/vcpkg/commands/integrate#vcpkg-autocompletion"&gt;add tab completion to your terminal&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Use vcpkg&lt;/h1&gt; 
&lt;p&gt;Create a &lt;a href="https://learn.microsoft.com/vcpkg/consume/manifest-mode"&gt;manifest for your project's dependencies&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Console"&gt;vcpkg new --application
vcpkg add port fmt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or &lt;a href="https://learn.microsoft.com/vcpkg/consume/classic-mode"&gt;install packages through the command line&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-Console"&gt;vcpkg install fmt
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then use one of our available integrations for &lt;a href="https://learn.microsoft.com/vcpkg/concepts/build-system-integration#cmake-integration"&gt;CMake&lt;/a&gt;, &lt;a href="https://learn.microsoft.com/vcpkg/concepts/build-system-integration#msbuild-integration"&gt;MSBuild&lt;/a&gt; or &lt;a href="https://learn.microsoft.com/vcpkg/concepts/build-system-integration#manual-integration"&gt;other build systems&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;For a short description of all available commands, run &lt;code&gt;vcpkg help&lt;/code&gt;. Run &lt;code&gt;vcpkg help [topic]&lt;/code&gt; for details on a specific topic.&lt;/p&gt; 
&lt;h1&gt;Key features&lt;/h1&gt; 
&lt;p&gt;vcpkg offers powerful features for your package management needs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/vcpkg/concepts/build-system-integration"&gt;easily integrate with your build system&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/vcpkg/users/versioning"&gt;control the versions of your dependencies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/vcpkg/concepts/registries"&gt;package and publish your own packages&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/vcpkg/users/binarycaching"&gt;reuse your binary artifacts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://learn.microsoft.com/vcpkg/concepts/asset-caching"&gt;enable offline scenarios with asset caching&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contribute&lt;/h1&gt; 
&lt;p&gt;vcpkg is an open source project, and is thus built with your contributions. Here are some ways you can contribute:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/vcpkg/issues/new/choose"&gt;Submit issues&lt;/a&gt; in vcpkg or existing packages&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/vcpkg/pulls"&gt;Submit fixes and new packages&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://learn.microsoft.com/vcpkg/contributing/maintainer-guide"&gt;mantainer guide&lt;/a&gt; and &lt;a href="https://learn.microsoft.com/vcpkg/get_started/get-started-packaging"&gt;packaging tutorial&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Code of Conduct FAQ&lt;/a&gt; or email &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h1&gt;Resources&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Ports: &lt;a href="https://github.com/microsoft/vcpkg"&gt;Microsoft/vcpkg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Source code: &lt;a href="https://github.com/microsoft/vcpkg-tool"&gt;Microsoft/vcpkg-tool&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Docs: &lt;a href="https://learn.microsoft.com/vcpkg"&gt;Microsoft Learn | vcpkg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Website: &lt;a href="https://vcpkg.io"&gt;vcpkg.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Email: &lt;a href="mailto:vcpkg@microsoft.com"&gt;vcpkg@microsoft.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord: &lt;a href="https://www.includecpp.org"&gt;#include &amp;lt;C++&amp;gt;'s Discord server&lt;/a&gt;, in the #üåèvcpkg channel&lt;/li&gt; 
 &lt;li&gt;Slack: &lt;a href="https://cppalliance.org/slack/"&gt;C++ Alliance's Slack server&lt;/a&gt;, in the #vcpkg channel&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;The code in this repository is licensed under the MIT License. The libraries provided by ports are licensed under the terms of their original authors. Where available, vcpkg places the associated license(s) in the location &lt;a href="https://learn.microsoft.com/vcpkg/contributing/maintainer-guide#install-copyright-file"&gt;&lt;code&gt;installed/&amp;lt;triplet&amp;gt;/share/&amp;lt;port&amp;gt;/copyright&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Security&lt;/h1&gt; 
&lt;p&gt;Most ports in vcpkg build the libraries in question using the original build system preferred by the original developers of those libraries, and download source code and build tools from their official distribution locations. For use behind a firewall, the specific access needed will depend on which ports are being installed. If you must install it in an "air gapped" environment, consider instaling once in a non-"air gapped" environment, populating an &lt;a href="https://learn.microsoft.com/vcpkg/users/assetcaching"&gt;asset cache&lt;/a&gt; shared with the otherwise "air gapped" environment.&lt;/p&gt; 
&lt;h1&gt;Telemetry&lt;/h1&gt; 
&lt;p&gt;vcpkg collects usage data in order to help us improve your experience. The data collected by Microsoft is anonymous. You can opt-out of telemetry by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;running the bootstrap-vcpkg script with &lt;code&gt;-disableMetrics&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;passing &lt;code&gt;--disable-metrics&lt;/code&gt; to vcpkg on the command line&lt;/li&gt; 
 &lt;li&gt;setting the &lt;code&gt;VCPKG_DISABLE_METRICS&lt;/code&gt; environment variable&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more about vcpkg telemetry at &lt;a href="https://learn.microsoft.com/vcpkg/about/privacy"&gt;https://learn.microsoft.com/vcpkg/about/privacy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/terminal</title>
      <link>https://github.com/microsoft/terminal</link>
      <description>&lt;p&gt;The new Windows Terminal and the original Windows console host, all in the same place!&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://github.com/microsoft/terminal/assets/91625426/333ddc76-8ab2-4eb4-a8c0-4d7b953b1179" alt="terminal-logos" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://dev.azure.com/shine-oss/terminal/_build/latest?definitionId=1&amp;amp;branchName=main"&gt;&lt;img src="https://dev.azure.com/shine-oss/terminal/_apis/build/status%2FTerminal%20CI?branchName=main" alt="Terminal Build Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Welcome to the Windows Terminal, Console and Command-Line repo&lt;/h1&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#installing-and-running-windows-terminal"&gt;Installing and running Windows Terminal&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#microsoft-store-recommended"&gt;Microsoft Store [Recommended]&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#other-install-methods"&gt;Other install methods&lt;/a&gt; 
     &lt;ul&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#via-github"&gt;Via GitHub&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#via-windows-package-manager-cli-aka-winget"&gt;Via Windows Package Manager CLI (aka winget)&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#via-chocolatey-unofficial"&gt;Via Chocolatey (unofficial)&lt;/a&gt;&lt;/li&gt; 
      &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#via-scoop-unofficial"&gt;Via Scoop (unofficial)&lt;/a&gt;&lt;/li&gt; 
     &lt;/ul&gt; &lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#installing-windows-terminal-canary"&gt;Installing Windows Terminal Canary&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#windows-terminal-roadmap"&gt;Windows Terminal Roadmap&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#terminal--console-overview"&gt;Terminal &amp;amp; Console Overview&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#windows-terminal"&gt;Windows Terminal&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#the-windows-console-host"&gt;The Windows Console Host&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#shared-components"&gt;Shared Components&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#creating-the-new-windows-terminal"&gt;Creating the new Windows Terminal&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#resources"&gt;Resources&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#faq"&gt;FAQ&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#i-built-and-ran-the-new-terminal-but-it-looks-just-like-the-old-console"&gt;I built and ran the new Terminal, but it looks just like the old console&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#contributing"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#communicating-with-the-team"&gt;Communicating with the Team&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#developer-guidance"&gt;Developer Guidance&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#building-the-code"&gt;Building the Code&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#building-in-powershell"&gt;Building in PowerShell&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#building-in-cmd"&gt;Building in Cmd&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#running--debugging"&gt;Running &amp;amp; Debugging&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#coding-guidance"&gt;Coding Guidance&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/#code-of-conduct"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;p&gt;This repository contains the source code for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/terminal"&gt;Windows Terminal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/terminal-preview"&gt;Windows Terminal Preview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;The Windows console host (&lt;code&gt;conhost.exe&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Components shared between the two projects&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/src/tools/ColorTool"&gt;ColorTool&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/samples"&gt;Sample projects&lt;/a&gt; that show how to consume the Windows Console APIs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Related repositories include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.microsoft.com/windows/terminal"&gt;Windows Terminal Documentation&lt;/a&gt; (&lt;a href="https://github.com/MicrosoftDocs/terminal"&gt;Repo: Contribute to the docs&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MicrosoftDocs/Console-Docs"&gt;Console API Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Microsoft/Cascadia-Code"&gt;Cascadia Code Font&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installing and running Windows Terminal&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Windows Terminal requires Windows 10 2004 (build 19041) or later&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Microsoft Store [Recommended]&lt;/h3&gt; 
&lt;p&gt;Install the &lt;a href="https://aka.ms/terminal"&gt;Windows Terminal from the Microsoft Store&lt;/a&gt;. This allows you to always be on the latest version when we release new builds with automatic upgrades.&lt;/p&gt; 
&lt;p&gt;This is our preferred method.&lt;/p&gt; 
&lt;h3&gt;Other install methods&lt;/h3&gt; 
&lt;h4&gt;Via GitHub&lt;/h4&gt; 
&lt;p&gt;For users who are unable to install Windows Terminal from the Microsoft Store, released builds can be manually downloaded from this repository's &lt;a href="https://github.com/microsoft/terminal/releases"&gt;Releases page&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Download the &lt;code&gt;Microsoft.WindowsTerminal_&amp;lt;versionNumber&amp;gt;.msixbundle&lt;/code&gt; file from the &lt;strong&gt;Assets&lt;/strong&gt; section. To install the app, you can simply double-click on the &lt;code&gt;.msixbundle&lt;/code&gt; file, and the app installer should automatically run. If that fails for any reason, you can try the following command at a PowerShell prompt:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;# NOTE: If you are using PowerShell 7+, please run
# Import-Module Appx -UseWindowsPowerShell
# before using Add-AppxPackage.

Add-AppxPackage Microsoft.WindowsTerminal_&amp;lt;versionNumber&amp;gt;.msixbundle
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] If you install Terminal manually:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;You may need to install the &lt;a href="https://docs.microsoft.com/troubleshoot/cpp/c-runtime-packages-desktop-bridge#how-to-install-and-update-desktop-framework-packages"&gt;VC++ v14 Desktop Framework Package&lt;/a&gt;. This should only be necessary on older builds of Windows 10 and only if you get an error about missing framework packages.&lt;/li&gt; 
  &lt;li&gt;Terminal will not auto-update when new builds are released so you will need to regularly install the latest Terminal release to receive all the latest fixes and improvements!&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Via Windows Package Manager CLI (aka winget)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://github.com/microsoft/winget-cli"&gt;winget&lt;/a&gt; users can download and install the latest Terminal release by installing the &lt;code&gt;Microsoft.WindowsTerminal&lt;/code&gt; package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;winget install --id Microsoft.WindowsTerminal -e
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Dependency support is available in WinGet version &lt;a href="https://github.com/microsoft/winget-cli/releases"&gt;1.6.2631 or later&lt;/a&gt;. To install the Terminal stable release 1.18 or later, please make sure you have the updated version of the WinGet client.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;Via Chocolatey (unofficial)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://chocolatey.org"&gt;Chocolatey&lt;/a&gt; users can download and install the latest Terminal release by installing the &lt;code&gt;microsoft-windows-terminal&lt;/code&gt; package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;choco install microsoft-windows-terminal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To upgrade Windows Terminal using Chocolatey, run the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;choco upgrade microsoft-windows-terminal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you have any issues when installing/upgrading the package please go to the &lt;a href="https://chocolatey.org/packages/microsoft-windows-terminal"&gt;Windows Terminal package page&lt;/a&gt; and follow the &lt;a href="https://chocolatey.org/docs/package-triage-process"&gt;Chocolatey triage process&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;Via Scoop (unofficial)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://scoop.sh"&gt;Scoop&lt;/a&gt; users can download and install the latest Terminal release by installing the &lt;code&gt;windows-terminal&lt;/code&gt; package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;scoop bucket add extras
scoop install windows-terminal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update Windows Terminal using Scoop, run the following:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;scoop update windows-terminal
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you have any issues when installing/updating the package, please search for or report the same on the &lt;a href="https://github.com/lukesampson/scoop-extras/issues"&gt;issues page&lt;/a&gt; of Scoop Extras bucket repository.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Installing Windows Terminal Canary&lt;/h2&gt; 
&lt;p&gt;Windows Terminal Canary is a nightly build of Windows Terminal. This build has the latest code from our &lt;code&gt;main&lt;/code&gt; branch, giving you an opportunity to try features before they make it to Windows Terminal Preview.&lt;/p&gt; 
&lt;p&gt;Windows Terminal Canary is our least stable offering, so you may discover bugs before we have had a chance to find them.&lt;/p&gt; 
&lt;p&gt;Windows Terminal Canary is available as an App Installer distribution and a Portable ZIP distribution.&lt;/p&gt; 
&lt;p&gt;The App Installer distribution supports automatic updates. Due to platform limitations, this installer only works on Windows 11.&lt;/p&gt; 
&lt;p&gt;The Portable ZIP distribution is a portable application. It will not automatically update and will not automatically check for updates. This portable ZIP distribution works on Windows 10 (19041+) and Windows 11.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Distribution&lt;/th&gt; 
   &lt;th align="center"&gt;Architecture&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;App Installer&lt;/td&gt; 
   &lt;td align="center"&gt;x64, arm64, x86&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/terminal-canary-installer"&gt;Download&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portable ZIP&lt;/td&gt; 
   &lt;td align="center"&gt;x64&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/terminal-canary-zip-x64"&gt;Download&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portable ZIP&lt;/td&gt; 
   &lt;td align="center"&gt;ARM64&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/terminal-canary-zip-arm64"&gt;Download&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Portable ZIP&lt;/td&gt; 
   &lt;td align="center"&gt;x86&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://aka.ms/terminal-canary-zip-x86"&gt;Download&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;em&gt;Learn more about the &lt;a href="https://learn.microsoft.com/windows/terminal/distributions"&gt;types of Windows Terminal distributions&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Windows Terminal Roadmap&lt;/h2&gt; 
&lt;p&gt;The plan for the Windows Terminal &lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/doc/roadmap-2023.md"&gt;is described here&lt;/a&gt; and will be updated as the project proceeds.&lt;/p&gt; 
&lt;h2&gt;Terminal &amp;amp; Console Overview&lt;/h2&gt; 
&lt;p&gt;Please take a few minutes to review the overview below before diving into the code:&lt;/p&gt; 
&lt;h3&gt;Windows Terminal&lt;/h3&gt; 
&lt;p&gt;Windows Terminal is a new, modern, feature-rich, productive terminal application for command-line users. It includes many of the features most frequently requested by the Windows command-line community including support for tabs, rich text, globalization, configurability, theming &amp;amp; styling, and more.&lt;/p&gt; 
&lt;p&gt;The Terminal will also need to meet our goals and measures to ensure it remains fast and efficient, and doesn't consume vast amounts of memory or power.&lt;/p&gt; 
&lt;h3&gt;The Windows Console Host&lt;/h3&gt; 
&lt;p&gt;The Windows Console host, &lt;code&gt;conhost.exe&lt;/code&gt;, is Windows' original command-line user experience. It also hosts Windows' command-line infrastructure and the Windows Console API server, input engine, rendering engine, user preferences, etc. The console host code in this repository is the actual source from which the &lt;code&gt;conhost.exe&lt;/code&gt; in Windows itself is built.&lt;/p&gt; 
&lt;p&gt;Since taking ownership of the Windows command-line in 2014, the team added several new features to the Console, including background transparency, line-based selection, support for &lt;a href="https://en.wikipedia.org/wiki/ANSI_escape_code"&gt;ANSI / Virtual Terminal sequences&lt;/a&gt;, &lt;a href="https://devblogs.microsoft.com/commandline/24-bit-color-in-the-windows-console/"&gt;24-bit color&lt;/a&gt;, a &lt;a href="https://devblogs.microsoft.com/commandline/windows-command-line-introducing-the-windows-pseudo-console-conpty/"&gt;Pseudoconsole ("ConPTY")&lt;/a&gt;, and more.&lt;/p&gt; 
&lt;p&gt;However, because Windows Console's primary goal is to maintain backward compatibility, we have been unable to add many of the features the community (and the team) have been wanting for the last several years including tabs, unicode text, and emoji.&lt;/p&gt; 
&lt;p&gt;These limitations led us to create the new Windows Terminal.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You can read more about the evolution of the command-line in general, and the Windows command-line specifically in &lt;a href="https://devblogs.microsoft.com/commandline/windows-command-line-backgrounder/"&gt;this accompanying series of blog posts&lt;/a&gt; on the Command-Line team's blog.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Shared Components&lt;/h3&gt; 
&lt;p&gt;While overhauling Windows Console, we modernized its codebase considerably, cleanly separating logical entities into modules and classes, introduced some key extensibility points, replaced several old, home-grown collections and containers with safer, more efficient &lt;a href="https://docs.microsoft.com/en-us/cpp/standard-library/stl-containers?view=vs-2022"&gt;STL containers&lt;/a&gt;, and made the code simpler and safer by using Microsoft's &lt;a href="https://github.com/Microsoft/wil"&gt;Windows Implementation Libraries - WIL&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This overhaul resulted in several of Console's key components being available for re-use in any terminal implementation on Windows. These components include a new DirectWrite-based text layout and rendering engine, a text buffer capable of storing both UTF-16 and UTF-8, a VT parser/emitter, and more.&lt;/p&gt; 
&lt;h3&gt;Creating the new Windows Terminal&lt;/h3&gt; 
&lt;p&gt;When we started planning the new Windows Terminal application, we explored and evaluated several approaches and technology stacks. We ultimately decided that our goals would be best met by continuing our investment in our C++ codebase, which would allow us to reuse several of the aforementioned modernized components in both the existing Console and the new Terminal. Further, we realized that this would allow us to build much of the Terminal's core itself as a reusable UI control that others can incorporate into their own applications.&lt;/p&gt; 
&lt;p&gt;The result of this work is contained within this repo and delivered as the Windows Terminal application you can download from the Microsoft Store, or &lt;a href="https://github.com/microsoft/terminal/releases"&gt;directly from this repo's releases&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;p&gt;For more information about Windows Terminal, you may find some of these resources useful and interesting:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://devblogs.microsoft.com/commandline"&gt;Command-Line Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://devblogs.microsoft.com/commandline/windows-command-line-backgrounder/"&gt;Command-Line Backgrounder Blog Series&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Windows Terminal Launch: &lt;a href="https://www.youtube.com/watch?v=8gw0rXPMMPE&amp;amp;list=PLEHMQNlPj-Jzh9DkNpqipDGCZZuOwrQwR&amp;amp;index=2&amp;amp;t=0s"&gt;Terminal "Sizzle Video"&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Windows Terminal Launch: &lt;a href="https://www.youtube.com/watch?v=KMudkRcwjCw"&gt;Build 2019 Session&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Run As Radio: &lt;a href="https://www.runasradio.com/Shows/Show/645"&gt;Show 645 - Windows Terminal with Richard Turner&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Azure Devops Podcast: &lt;a href="http://azuredevopspodcast.clear-measure.com/kayla-cinnamon-and-rich-turner-on-devops-on-the-windows-terminal-team-episode-54"&gt;Episode 54 - Kayla Cinnamon and Rich Turner on DevOps on the Windows Terminal&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Microsoft Ignite 2019 Session: &lt;a href="https://myignite.techcommunity.microsoft.com/sessions/81329?source=sessions"&gt;The Modern Windows Command Line: Windows Terminal - BRK3321&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;I built and ran the new Terminal, but it looks just like the old console&lt;/h3&gt; 
&lt;p&gt;Cause: You're launching the incorrect solution in Visual Studio.&lt;/p&gt; 
&lt;p&gt;Solution: Make sure you're building &amp;amp; deploying the &lt;code&gt;CascadiaPackage&lt;/code&gt; project in Visual Studio.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] &lt;code&gt;OpenConsole.exe&lt;/code&gt; is just a locally-built &lt;code&gt;conhost.exe&lt;/code&gt;, the classic Windows Console that hosts Windows' command-line infrastructure. OpenConsole is used by Windows Terminal to connect to and communicate with command-line applications (via &lt;a href="https://devblogs.microsoft.com/commandline/windows-command-line-introducing-the-windows-pseudo-console-conpty/"&gt;ConPty&lt;/a&gt;).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;All project documentation is located at &lt;a href="https://aka.ms/terminal-docs"&gt;aka.ms/terminal-docs&lt;/a&gt;. If you would like to contribute to the documentation, please submit a pull request on the &lt;a href="https://github.com/MicrosoftDocs/terminal"&gt;Windows Terminal Documentation repo&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We are excited to work alongside you, our amazing community, to build and enhance Windows Terminal!&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;BEFORE you start work on a feature/fix&lt;/strong&gt;&lt;/em&gt;, please read &amp;amp; follow our &lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt; to help avoid any wasted or duplicate effort.&lt;/p&gt; 
&lt;h2&gt;Communicating with the Team&lt;/h2&gt; 
&lt;p&gt;The easiest way to communicate with the team is via GitHub issues.&lt;/p&gt; 
&lt;p&gt;Please file new issues, feature requests and suggestions, but &lt;strong&gt;DO search for similar open/closed preexisting issues before creating a new issue.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;If you would like to ask a question that you feel doesn't warrant an issue (yet), please reach out to us via Twitter:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Christopher Nguyen, Product Manager: &lt;a href="https://twitter.com/nguyen_dows"&gt;@nguyen_dows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dustin Howett, Engineering Lead: &lt;a href="https://twitter.com/DHowett"&gt;@dhowett&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Mike Griese, Senior Developer: &lt;a href="https://mastodon.social/@zadjii"&gt;@zadjii@mastodon.social&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Carlos Zamora, Developer: &lt;a href="https://twitter.com/cazamor_msft"&gt;@cazamor_msft&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Pankaj Bhojwani, Developer&lt;/li&gt; 
 &lt;li&gt;Leonard Hecker, Developer: &lt;a href="https://twitter.com/LeonardHecker"&gt;@LeonardHecker&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Developer Guidance&lt;/h2&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;You can configure your environment to build Terminal in one of two ways:&lt;/p&gt; 
&lt;h3&gt;Using WinGet configuration file&lt;/h3&gt; 
&lt;p&gt;After cloning the repository, you can use a &lt;a href="https://learn.microsoft.com/en-us/windows/package-manager/configuration/#use-a-winget-configuration-file-to-configure-your-machine"&gt;WinGet configuration file&lt;/a&gt; to set up your environment. The &lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/.config/configuration.winget"&gt;default configuration file&lt;/a&gt; installs Visual Studio 2022 Community &amp;amp; rest of the required tools. There are two other variants of the configuration file available in the &lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/.config"&gt;.config&lt;/a&gt; directory for Enterprise &amp;amp; Professional editions of Visual Studio 2022. To run the default configuration file, you can either double-click the file from explorer or run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;winget configure .config\configuration.winget
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual configuration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;You must be running Windows 10 2004 (build &amp;gt;= 10.0.19041.0) or later to run Windows Terminal&lt;/li&gt; 
 &lt;li&gt;You must &lt;a href="https://docs.microsoft.com/en-us/windows/uwp/get-started/enable-your-device-for-development"&gt;enable Developer Mode in the Windows Settings app&lt;/a&gt; to locally install and run Windows Terminal&lt;/li&gt; 
 &lt;li&gt;You must have &lt;a href="https://github.com/PowerShell/PowerShell/releases/latest"&gt;PowerShell 7 or later&lt;/a&gt; installed&lt;/li&gt; 
 &lt;li&gt;You must have the &lt;a href="https://developer.microsoft.com/en-us/windows/downloads/windows-sdk/"&gt;Windows 11 (10.0.22621.0) SDK&lt;/a&gt; installed&lt;/li&gt; 
 &lt;li&gt;You must have at least &lt;a href="https://visualstudio.microsoft.com/downloads/"&gt;VS 2022&lt;/a&gt; installed&lt;/li&gt; 
 &lt;li&gt;You must install the following Workloads via the VS Installer. Note: Opening the solution in VS 2022 will &lt;a href="https://devblogs.microsoft.com/setup/configure-visual-studio-across-your-organization-with-vsconfig/"&gt;prompt you to install missing components automatically&lt;/a&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Desktop Development with C++&lt;/li&gt; 
   &lt;li&gt;Universal Windows Platform Development&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;The following Individual Components&lt;/strong&gt; 
    &lt;ul&gt; 
     &lt;li&gt;C++ (v143) Universal Windows Platform Tools&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;You must install the &lt;a href="https://docs.microsoft.com/dotnet/framework/install/guide-for-developers#to-install-the-net-framework-developer-pack-or-targeting-pack"&gt;.NET Framework Targeting Pack&lt;/a&gt; to build test projects&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Building the Code&lt;/h2&gt; 
&lt;p&gt;OpenConsole.slnx may be built from within Visual Studio or from the command-line using a set of convenience scripts &amp;amp; tools in the &lt;strong&gt;/tools&lt;/strong&gt; directory:&lt;/p&gt; 
&lt;h3&gt;Building in PowerShell&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;Import-Module .\tools\OpenConsole.psm1
Set-MsBuildDevEnvironment
Invoke-OpenConsoleBuild
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Building in Cmd&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;.\tools\razzle.cmd
bcz
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Running &amp;amp; Debugging&lt;/h2&gt; 
&lt;p&gt;To debug the Windows Terminal in VS, right click on &lt;code&gt;CascadiaPackage&lt;/code&gt; (in the Solution Explorer) and go to properties. In the Debug menu, change "Application process" and "Background task process" to "Native Only".&lt;/p&gt; 
&lt;p&gt;You should then be able to build &amp;amp; debug the Terminal project by hitting &lt;kbd&gt;F5&lt;/kbd&gt;. Make sure to select either the "x64" or the "x86" platform - the Terminal doesn't build for "Any Cpu" (because the Terminal is a C++ application, not a C# one).&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üëâ You will &lt;em&gt;not&lt;/em&gt; be able to launch the Terminal directly by running the WindowsTerminal.exe. For more details on why, see &lt;a href="https://github.com/microsoft/terminal/issues/926"&gt;#926&lt;/a&gt;, &lt;a href="https://github.com/microsoft/terminal/issues/4043"&gt;#4043&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Coding Guidance&lt;/h3&gt; 
&lt;p&gt;Please review these brief docs below about our coding practices.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;üëâ If you find something missing from these docs, feel free to contribute to any of our documentation files anywhere in the repository (or write some new ones!)&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;This is a work in progress as we learn what we'll need to provide people in order to be effective contributors to our project.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/doc/STYLE.md"&gt;Coding Style&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/doc/ORGANIZATION.md"&gt;Code Organization&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/doc/EXCEPTIONS.md"&gt;Exceptions in our legacy codebase&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/microsoft/terminal/main/doc/WIL.md"&gt;Helpful smart pointers and macros for interfacing with Windows in WIL&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Code of Conduct&lt;/h2&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PaddlePaddle/PaddleOCR</title>
      <link>https://github.com/PaddlePaddle/PaddleOCR</link>
      <description>&lt;p&gt;Turn any PDF or image document into structured data for your AI. A powerful, lightweight OCR toolkit that bridges the gap between images/PDFs and LLMs. Supports 100+ languages.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/images/Banner.png" alt="PaddleOCR Banner" /&gt; &lt;/p&gt; 
 &lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_cn.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_tcn.md"&gt;ÁπÅÈ´î‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ja.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ko.md"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_fr.md"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ru.md"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_es.md"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/readme/README_ar.md"&gt;ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://img.shields.io/github/stars/PaddlePaddle/PaddleOCR?color=ccf" alt="stars" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2507.05595"&gt;&lt;img src="https://img.shields.io/badge/arXiv-2507.05595-b31b1b.svg?logo=arXiv" alt="arXiv" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/paddleocr"&gt;&lt;img src="https://static.pepy.tech/badge/paddleocr/month" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://pepy.tech/project/paddleocr"&gt;&lt;img src="https://static.pepy.tech/badge/paddleocr" alt="PyPI Downloads" /&gt;&lt;/a&gt; &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/network/dependents"&gt;&lt;img src="https://img.shields.io/badge/Used%20by-5.9k%2B%20repositories-blue" alt="Used by" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://img.shields.io/badge/python-3.8~3.12-aff.svg?sanitize=true" alt="python" /&gt; &lt;img src="https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg?sanitize=true" alt="os" /&gt; &lt;img src="https://img.shields.io/badge/hardware-cpu%2C%20gpu%2C%20xpu%2C%20npu-yellow.svg?sanitize=true" alt="hardware" /&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache_2.0-green" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/PaddlePaddle/PaddleOCR"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h1&gt;PaddleOCR&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.paddlepaddle.org.cn/en"&gt;&lt;img src="https://img.shields.io/badge/PaddlePaddle-3.0-orange" alt="Framework" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Recognition%20Accuracy-%F0%9F%8F%86-green" alt="Accuracy" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Support_Languages-100+-brightgreen" alt="Multi-Language" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Handwriting-%E2%9C%93-success" alt="Handwriting" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/#"&gt;&lt;img src="https://img.shields.io/badge/Heterogeneous%20Hardware-Kunlunxin%20%7C%20Ascend_NPU-red" alt="Hardware" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] PaddleOCR now provides an MCP server that supports integration with Agent applications like Claude Desktop. For details, please refer to &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html"&gt;PaddleOCR MCP Server&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;The PaddleOCR 3.0 Technical Report is now available. See details at: &lt;a href="https://arxiv.org/abs/2507.05595"&gt;PaddleOCR 3.0 Technical Report&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;The PaddleOCR-VL Technical Report is now available. See details at &lt;a href="https://arxiv.org/abs/2510.14528"&gt;PaddleOCR-VL Technical Report&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;PaddleOCR&lt;/strong&gt; converts documents and images into &lt;strong&gt;structured, AI-friendly data&lt;/strong&gt; (like JSON and Markdown) with &lt;strong&gt;industry-leading accuracy&lt;/strong&gt;‚Äîpowering AI applications for everyone from indie developers and startups to large enterprises worldwide. With over &lt;strong&gt;50,000 stars&lt;/strong&gt; and deep integration into leading projects like &lt;strong&gt;MinerU, RAGFlow, and OmniParser&lt;/strong&gt;, PaddleOCR has become the &lt;strong&gt;premier solution&lt;/strong&gt; for developers building intelligent document applications in the &lt;strong&gt;AI era&lt;/strong&gt;.&lt;/p&gt; 
&lt;h3&gt;PaddleOCR 3.0 Core Features&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://huggingface.co/spaces/PaddlePaddle/PaddleOCR-VL_Online_Demo"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_HuggingFace-yellow?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="HuggingFace" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/application/detail/98365"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://www.modelscope.cn/studios/PaddlePaddle/PaddleOCR-VL_Online_Demo"&gt;&lt;img src="https://img.shields.io/badge/PaddleOCR--VL-_Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&amp;amp;labelColor=white" alt="ModelScope" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://aistudio.baidu.com/community/app/91660/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP--OCRv5-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518494/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP--StructureV3-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518493/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP--ChatOCRv4-Demo_on_AI_Studio-1927BA?logo=data:image/png;base64,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&amp;amp;labelColor=white" alt="AI Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PaddleOCR-VL - Multilingual Document Parsing via a 0.9B VLM&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;The SOTA and resource-efficient model tailored for document parsing&lt;/strong&gt;, that supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-OCRv5 ‚Äî Universal Scene Text Recognition&lt;/strong&gt;&lt;br /&gt; &lt;strong&gt;Single model supports five text types&lt;/strong&gt; (Simplified Chinese, Traditional Chinese, English, Japanese, and Pinyin) with &lt;strong&gt;13% accuracy improvement&lt;/strong&gt;. Solves multilingual mixed document recognition challenges.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-StructureV3 ‚Äî Complex Document Parsing&lt;/strong&gt;&lt;br /&gt; Intelligently converts complex PDFs and document images into &lt;strong&gt;Markdown and JSON files that preserve original structure&lt;/strong&gt;. &lt;strong&gt;Outperforms&lt;/strong&gt; numerous commercial solutions in public benchmarks. &lt;strong&gt;Perfectly maintains document layout and hierarchical structure&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-ChatOCRv4 ‚Äî Intelligent Information Extraction&lt;/strong&gt;&lt;br /&gt; Natively integrates ERNIE 4.5 to &lt;strong&gt;precisely extract key information&lt;/strong&gt; from massive documents, with 15% accuracy improvement over previous generation. Makes documents "&lt;strong&gt;understand&lt;/strong&gt;" your questions and provide accurate answers.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;In addition to providing an outstanding model library, PaddleOCR 3.0 also offers user-friendly tools covering model training, inference, and service deployment, so developers can rapidly bring AI applications to production.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/Arch.jpg" alt="PaddleOCR Architecture" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;Special Note&lt;/strong&gt;: PaddleOCR 3.x introduces several significant interface changes. &lt;strong&gt;Old code written based on PaddleOCR 2.x is likely incompatible with PaddleOCR 3.x&lt;/strong&gt;. Please ensure that the documentation you are reading matches the version of PaddleOCR you are using. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/upgrade_notes.html"&gt;This document&lt;/a&gt; explains the reasons for the upgrade and the major changes from PaddleOCR 2.x to 3.x.&lt;/p&gt; 
&lt;h2&gt;üì£ Recent updates&lt;/h2&gt; 
&lt;h3&gt;üî•üî• 2025.10.16: PaddleOCR 3.3.0 released, includes:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Released PaddleOCR-VL:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Model Introduction&lt;/strong&gt;:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;PaddleOCR-VL&lt;/strong&gt; is a SOTA and resource-efficient model tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a compact yet powerful vision-language model (VLM) that integrates a NaViT-style dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to enable accurate element recognition. &lt;strong&gt;This innovative model efficiently supports 109 languages and excels in recognizing complex elements (e.g., text, tables, formulas, and charts), while maintaining minimal resource consumption&lt;/strong&gt;. Through comprehensive evaluations on widely used public benchmarks and in-house benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document parsing and element-level recognition. It significantly outperforms existing solutions, exhibits strong competitiveness against top-tier VLMs, and delivers fast inference speeds. These strengths make it highly suitable for practical deployment in real-world scenarios. The model has been released on &lt;a href="https://huggingface.co/PaddlePaddle/PaddleOCR-VL"&gt;HuggingFace&lt;/a&gt;. Everyone is welcome to download and use it! More introduction infomation can be found in &lt;a href="https://www.paddleocr.ai/latest/version3.x/algorithm/PaddleOCR-VL/PaddleOCR-VL.html"&gt;PaddleOCR-VL&lt;/a&gt;.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;strong&gt;Core Features&lt;/strong&gt;:&lt;/p&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;strong&gt;Compact yet Powerful VLM Architecture&lt;/strong&gt;: We present a novel vision-language model that is specifically designed for resource-efficient inference, achieving outstanding performance in element recognition. By integrating a NaViT-style dynamic high-resolution visual encoder with the lightweight ERNIE-4.5-0.3B language model, we significantly enhance the model‚Äôs recognition capabilities and decoding efficiency. This integration maintains high accuracy while reducing computational demands, making it well-suited for efficient and practical document processing applications.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;SOTA Performance on Document Parsing&lt;/strong&gt;: PaddleOCR-VL achieves state-of-the-art performance in both page-level document parsing and element-level recognition. It significantly outperforms existing pipeline-based solutions and exhibiting strong competitiveness against leading vision-language models (VLMs) in document parsing. Moreover, it excels in recognizing complex document elements, such as text, tables, formulas, and charts, making it suitable for a wide range of challenging content types, including handwritten text and historical documents. This makes it highly versatile and suitable for a wide range of document types and scenarios.&lt;/li&gt; 
     &lt;li&gt;&lt;strong&gt;Multilingual Support&lt;/strong&gt;: PaddleOCR-VL Supports 109 languages, covering major global languages, including but not limited to Chinese, English, Japanese, Latin, and Korean, as well as languages with different scripts and structures, such as Russian (Cyrillic script), Arabic, Hindi (Devanagari script), and Thai. This broad language coverage substantially enhances the applicability of our system to multilingual and globalized document processing scenarios.&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Released PP-OCRv5 Multilingual Recognition Model:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Improved the accuracy and coverage of Latin script recognition; added support for Cyrillic, Arabic, Devanagari, Telugu, Tamil, and other language systems, covering recognition of 109 languages. The model has only 2M parameters, and the accuracy of some models has increased by over 40% compared to the previous generation.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.08.21: Release of PaddleOCR 3.2.0&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Significant Model Additions:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Introduced training, inference, and deployment for PP-OCRv5 recognition models in English, Thai, and Greek. &lt;strong&gt;The PP-OCRv5 English model delivers an 11% improvement in English scenarios compared to the main PP-OCRv5 model, with the Thai and Greek recognition models achieving accuracies of 82.68% and 89.28%, respectively.&lt;/strong&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deployment Capability Upgrades:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Full support for PaddlePaddle framework versions 3.1.0 and 3.1.1.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Comprehensive upgrade of the PP-OCRv5 C++ local deployment solution, now supporting both Linux and Windows, with feature parity and identical accuracy to the Python implementation.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;High-performance inference now supports CUDA 12, and inference can be performed using either the Paddle Inference or ONNX Runtime backends.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;The high-stability service-oriented deployment solution is now fully open-sourced, allowing users to customize Docker images and SDKs as required.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;The high-stability service-oriented deployment solution also supports invocation via manually constructed HTTP requests, enabling client-side code development in any programming language.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Benchmark Support:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;All production lines now support fine-grained benchmarking, enabling measurement of end-to-end inference time as well as per-layer and per-module latency data to assist with performance analysis. &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/version3.x/pipeline_usage/instructions/benchmark.en.md"&gt;Here's&lt;/a&gt; how to set up and use the benchmark feature.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Documentation has been updated to include key metrics for commonly used configurations on mainstream hardware, such as inference latency and memory usage, providing deployment references for users.&lt;/strong&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Resolved the issue of failed log saving during model training.&lt;/li&gt; 
    &lt;li&gt;Upgraded the data augmentation component for formula models for compatibility with newer versions of the albumentations dependency, and fixed deadlock warnings when using the tokenizers package in multi-process scenarios.&lt;/li&gt; 
    &lt;li&gt;Fixed inconsistencies in switch behaviors (e.g., &lt;code&gt;use_chart_parsing&lt;/code&gt;) in the PP-StructureV3 configuration files compared to other pipelines.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Other Enhancements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Separated core and optional dependencies. Only minimal core dependencies are required for basic text recognition; additional dependencies for document parsing and information extraction can be installed as needed.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;Enabled support for NVIDIA RTX 50 series graphics cards on Windows; users can refer to the &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/version3.x/installation.en.md"&gt;installation guide&lt;/a&gt; for the corresponding PaddlePaddle framework versions.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;strong&gt;PP-OCR series models now support returning single-character coordinates.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Added AIStudio, ModelScope, and other model download sources, allowing users to specify the source for model downloads.&lt;/li&gt; 
    &lt;li&gt;Added support for chart-to-table conversion via the PP-Chart2Table module.&lt;/li&gt; 
    &lt;li&gt;Optimized documentation descriptions to improve usability.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.08.15: PaddleOCR 3.1.1 Released&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Added the missing methods &lt;code&gt;save_vector&lt;/code&gt;, &lt;code&gt;save_visual_info_list&lt;/code&gt;, &lt;code&gt;load_vector&lt;/code&gt;, and &lt;code&gt;load_visual_info_list&lt;/code&gt; in the &lt;code&gt;PP-ChatOCRv4&lt;/code&gt; class.&lt;/li&gt; 
    &lt;li&gt;Added the missing parameters &lt;code&gt;glossary&lt;/code&gt; and &lt;code&gt;llm_request_interval&lt;/code&gt; to the &lt;code&gt;translate&lt;/code&gt; method in the &lt;code&gt;PPDocTranslation&lt;/code&gt; class.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Improvements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Added a demo to the MCP documentation.&lt;/li&gt; 
    &lt;li&gt;Added information about the PaddlePaddle and PaddleOCR version used for performance metrics testing in the documentation.&lt;/li&gt; 
    &lt;li&gt;Fixed errors and omissions in the production line document translation.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Others:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Changed the MCP server dependency to use the pure Python library &lt;code&gt;puremagic&lt;/code&gt; instead of &lt;code&gt;python-magic&lt;/code&gt; to reduce installation issues.&lt;/li&gt; 
    &lt;li&gt;Retested PP-OCRv5 performance metrics with PaddleOCR version 3.1.0 and updated the documentation.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.29: PaddleOCR 3.1.0 Released&lt;/strong&gt;&lt;/summary&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Key Models and Pipelines:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Added PP-OCRv5 Multilingual Text Recognition Model&lt;/strong&gt;, which supports the training and inference process for text recognition models in 37 languages, including French, Spanish, Portuguese, Russian, Korean, etc. &lt;strong&gt;Average accuracy improved by over 30%.&lt;/strong&gt; &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/algorithm/PP-OCRv5/PP-OCRv5_multi_languages.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;Upgraded the &lt;strong&gt;PP-Chart2Table model&lt;/strong&gt; in PP-StructureV3, further enhancing the capability of converting charts to tables. On internal custom evaluation sets, the metric (RMS-F1) &lt;strong&gt;increased by 9.36 percentage points (71.24% -&amp;gt; 80.60%).&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Newly launched &lt;strong&gt;document translation pipeline, PP-DocTranslation, based on PP-StructureV3 and ERNIE 4.5&lt;/strong&gt;, which supports the translation of Markdown format documents, various complex-layout PDF documents, and document images, with the results saved as Markdown format documents. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/PP-DocTranslation.html"&gt;Details&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;New MCP server:&lt;/strong&gt; &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/mcp_server.html"&gt;Details&lt;/a&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;strong&gt;Supports both OCR and PP-StructureV3 pipelines.&lt;/strong&gt;&lt;/li&gt; 
    &lt;li&gt;Supports three working modes: local Python library, AIStudio Community Cloud Service, and self-hosted service.&lt;/li&gt; 
    &lt;li&gt;Supports invoking local services via stdio and remote services via Streamable HTTP.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Optimization:&lt;/strong&gt; Improved the descriptions in some user guides for a smoother reading experience.&lt;/p&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.26: PaddleOCR 3.0.3 Released&lt;/strong&gt;&lt;/summary&gt; - Bug Fix: Resolved the issue where the `enable_mkldnn` parameter was not effective, restoring the default behavior of using MKL-DNN for CPU inference. 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;2025.06.19: PaddleOCR 3.0.2 Released&lt;/strong&gt;&lt;/summary&gt; - **New Features:** 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;The default download source has been changed from &lt;code&gt;BOS&lt;/code&gt; to &lt;code&gt;HuggingFace&lt;/code&gt;. Users can also change the environment variable &lt;code&gt;PADDLE_PDX_MODEL_SOURCE&lt;/code&gt; to &lt;code&gt;BOS&lt;/code&gt; to set the model download source back to Baidu Object Storage (BOS).&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Added service invocation examples for six languages‚ÄîC++, Java, Go, C#, Node.js, and PHP‚Äîfor pipelines like PP-OCRv5, PP-StructureV3, and PP-ChatOCRv4.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Improved the layout partition sorting algorithm in the PP-StructureV3 pipeline, enhancing the sorting logic for complex vertical layouts to deliver better results.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Enhanced model selection logic: when a language is specified but a model version is not, the system will automatically select the latest model version supporting that language.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Set a default upper limit for MKL-DNN cache size to prevent unlimited growth, while also allowing users to configure cache capacity.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Updated default configurations for high-performance inference to support Paddle MKL-DNN acceleration and optimized the logic for automatic configuration selection for smarter choices.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Adjusted the logic for obtaining the default device to consider the actual support for computing devices by the installed Paddle framework, making program behavior more intuitive.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;Added Android example for PP-OCRv5. &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/on_device_deployment.html"&gt;Details&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Bug Fixes:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Fixed an issue with some CLI parameters in PP-StructureV3 not taking effect.&lt;/li&gt; 
    &lt;li&gt;Resolved an issue where &lt;code&gt;export_paddlex_config_to_yaml&lt;/code&gt; would not function correctly in certain cases.&lt;/li&gt; 
    &lt;li&gt;Corrected the discrepancy between the actual behavior of &lt;code&gt;save_path&lt;/code&gt; and its documentation description.&lt;/li&gt; 
    &lt;li&gt;Fixed potential multithreading errors when using MKL-DNN in basic service deployment.&lt;/li&gt; 
    &lt;li&gt;Corrected channel order errors in image preprocessing for the Latex-OCR model.&lt;/li&gt; 
    &lt;li&gt;Fixed channel order errors in saving visualized images within the text recognition module.&lt;/li&gt; 
    &lt;li&gt;Resolved channel order errors in visualized table results within PP-StructureV3 pipeline.&lt;/li&gt; 
    &lt;li&gt;Fixed an overflow issue in the calculation of &lt;code&gt;overlap_ratio&lt;/code&gt; under extremely special circumstances in the PP-StructureV3 pipeline.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Documentation Improvements:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Updated the description of the &lt;code&gt;enable_mkldnn&lt;/code&gt; parameter in the documentation to accurately reflect the program's actual behavior.&lt;/li&gt; 
    &lt;li&gt;Fixed errors in the documentation regarding the &lt;code&gt;lang&lt;/code&gt; and &lt;code&gt;ocr_version&lt;/code&gt; parameters.&lt;/li&gt; 
    &lt;li&gt;Added instructions for exporting pipeline configuration files via CLI.&lt;/li&gt; 
    &lt;li&gt;Fixed missing columns in the performance data table for PP-OCRv5.&lt;/li&gt; 
    &lt;li&gt;Refined benchmark metrics for PP-StructureV3 across different configurations.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;Others:&lt;/strong&gt;&lt;/p&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Relaxed version restrictions on dependencies like numpy and pandas, restoring support for Python 3.12.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;History Log&lt;/strong&gt;&lt;/summary&gt; 
 &lt;p&gt;2025.06.05: &lt;strong&gt;PaddleOCR 3.0.1 Released&lt;/strong&gt;, includes:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Optimisation of certain models and model configurations:&lt;/strong&gt; 
   &lt;ul&gt; 
    &lt;li&gt;Updated the default model configuration for PP-OCRv5, changing both detection and recognition from mobile to server models. To improve default performance in most scenarios, the parameter &lt;code&gt;limit_side_len&lt;/code&gt; in the configuration has been changed from 736 to 64.&lt;/li&gt; 
    &lt;li&gt;Added a new text line orientation classification model &lt;code&gt;PP-LCNet_x1_0_textline_ori&lt;/code&gt; with an accuracy of 99.42%. The default text line orientation classifier for OCR, PP-StructureV3, and PP-ChatOCRv4 pipelines has been updated to this model.&lt;/li&gt; 
    &lt;li&gt;Optimized the text line orientation classification model &lt;code&gt;PP-LCNet_x0_25_textline_ori&lt;/code&gt;, improving accuracy by 3.3 percentage points to a current accuracy of 98.85%.&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Optimizations and fixes for some issues in version 3.0.0, &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html"&gt;details&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;üî•üî•2025.05.20: Official Release of &lt;strong&gt;PaddleOCR v3.0&lt;/strong&gt;, including:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-OCRv5&lt;/strong&gt;: High-Accuracy Text Recognition Model for All Scenarios - Instant Text from Images/PDFs.&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;üåê Single-model support for &lt;strong&gt;five&lt;/strong&gt; text types - Seamlessly process &lt;strong&gt;Simplified Chinese, Traditional Chinese, Simplified Chinese Pinyin, English&lt;/strong&gt; and &lt;strong&gt;Japanese&lt;/strong&gt; within a single model.&lt;/li&gt; 
    &lt;li&gt;‚úçÔ∏è Improved &lt;strong&gt;handwriting recognition&lt;/strong&gt;: Significantly better at complex cursive scripts and non-standard handwriting.&lt;/li&gt; 
    &lt;li&gt;üéØ &lt;strong&gt;13-point accuracy gain&lt;/strong&gt; over PP-OCRv4, achieving state-of-the-art performance across a variety of real-world scenarios.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-StructureV3&lt;/strong&gt;: General-Purpose Document Parsing ‚Äì Unleash SOTA Images/PDFs Parsing for Real-World Scenarios!&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;üßÆ &lt;strong&gt;High-Accuracy multi-scene PDF parsing&lt;/strong&gt;, leading both open- and closed-source solutions on the OmniDocBench benchmark.&lt;/li&gt; 
    &lt;li&gt;üß† Specialized capabilities include &lt;strong&gt;seal recognition&lt;/strong&gt;, &lt;strong&gt;chart-to-table conversion&lt;/strong&gt;, &lt;strong&gt;table recognition with nested formulas/images&lt;/strong&gt;, &lt;strong&gt;vertical text document parsing&lt;/strong&gt;, and &lt;strong&gt;complex table structure analysis&lt;/strong&gt;.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
  &lt;li&gt; &lt;p&gt;&lt;strong&gt;PP-ChatOCRv4&lt;/strong&gt;: Intelligent Document Understanding ‚Äì Extract Key Information, not just text from Images/PDFs.&lt;/p&gt; 
   &lt;ol&gt; 
    &lt;li&gt;üî• &lt;strong&gt;15-point accuracy gain&lt;/strong&gt; in key-information extraction on PDF/PNG/JPG files over the previous generation.&lt;/li&gt; 
    &lt;li&gt;üíª Native support for &lt;strong&gt;ERNIE 4.5&lt;/strong&gt;, with compatibility for large-model deployments via PaddleNLP, Ollama, vLLM, and more.&lt;/li&gt; 
    &lt;li&gt;ü§ù Integrated &lt;a href="https://github.com/PaddlePaddle/PaddleMIX/tree/develop/paddlemix/examples/ppdocbee2"&gt;PP-DocBee2&lt;/a&gt;, enabling extraction and understanding of printed text, handwriting, seals, tables, charts, and other common elements in complex documents.&lt;/li&gt; 
   &lt;/ol&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/update/update.html"&gt;History Log&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ö° Quick Start&lt;/h2&gt; 
&lt;h3&gt;1. Run online demo&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://aistudio.baidu.com/community/app/91660/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_OCRv5-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518494/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_StructureV3-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt; &lt;a href="https://aistudio.baidu.com/community/app/518493/webUI"&gt;&lt;img src="https://img.shields.io/badge/PP_ChatOCRv4-AI_Studio-green" alt="AI Studio" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Installation&lt;/h3&gt; 
&lt;p&gt;Install PaddlePaddle refer to &lt;a href="https://www.paddlepaddle.org.cn/en/install/quick?docurl=/documentation/docs/en/develop/install/pip/linux-pip_en.html"&gt;Installation Guide&lt;/a&gt;, after then, install the PaddleOCR toolkit.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series
python -m pip install paddleocr
# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.
# python -m pip install "paddleocr[all]"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Starting from version 3.2.0, in addition to the &lt;code&gt;all&lt;/code&gt; dependency group demonstrated above, PaddleOCR also supports installing partial optional features by specifying other dependency groups. All dependency groups provided by PaddleOCR are as follows:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dependency Group Name&lt;/th&gt; 
   &lt;th&gt;Corresponding Functionality&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;doc-parser&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Document parsing: can be used to extract layout elements such as tables, formulas, stamps, images, etc. from documents; includes models like PP-StructureV3&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;ie&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Information extraction: can be used to extract key information from documents, such as names, dates, addresses, amounts, etc.; includes models like PP-ChatOCRv4&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;trans&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Document translation: can be used to translate documents from one language to another; includes models like PP-DocTranslation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;all&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Complete functionality&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;3. Run inference by CLI&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run PP-OCRv5 inference
paddleocr ocr -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png --use_doc_orientation_classify False --use_doc_unwarping False --use_textline_orientation False  

# Run PP-StructureV3 inference
paddleocr pp_structurev3 -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png --use_doc_orientation_classify False --use_doc_unwarping False

# Get the Qianfan API Key at first, and then run PP-ChatOCRv4 inference
paddleocr pp_chatocrv4_doc -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png -k È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞ --qianfan_api_key your_api_key --use_doc_orientation_classify False --use_doc_unwarping False 

# Run PaddleOCR-VL inference
paddleocr doc_parser -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png

# Get more information about "paddleocr ocr"
paddleocr ocr --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;4. Run inference by API&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;4.1 PP-OCRv5 Example&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Initialize PaddleOCR instance
from paddleocr import PaddleOCR
ocr = PaddleOCR(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False,
    use_textline_orientation=False)

# Run OCR inference on a sample image 
result = ocr.predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png")

# Visualize the results and save the JSON results
for res in result:
    res.print()
    res.save_to_img("output")
    res.save_to_json("output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.2 PP-StructureV3 Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from pathlib import Path
from paddleocr import PPStructureV3

pipeline = PPStructureV3(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False
)

# For Image
output = pipeline.predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png",
)

# Visualize the results and save the JSON results
for res in output:
    res.print() 
    res.save_to_json(save_path="output") 
    res.save_to_markdown(save_path="output")           
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.3 PP-ChatOCRv4 Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from paddleocr import PPChatOCRv4Doc

chat_bot_config = {
    "module_name": "chat_bot",
    "model_name": "ernie-3.5-8k",
    "base_url": "https://qianfan.baidubce.com/v2",
    "api_type": "openai",
    "api_key": "api_key",  # your api_key
}

retriever_config = {
    "module_name": "retriever",
    "model_name": "embedding-v1",
    "base_url": "https://qianfan.baidubce.com/v2",
    "api_type": "qianfan",
    "api_key": "api_key",  # your api_key
}

pipeline = PPChatOCRv4Doc(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False
)

visual_predict_res = pipeline.visual_predict(
    input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png",
    use_common_ocr=True,
    use_seal_recognition=True,
    use_table_recognition=True,
)

mllm_predict_info = None
use_mllm = False
# If a multimodal large model is used, the local mllm service needs to be started. You can refer to the documentation: https://github.com/PaddlePaddle/PaddleX/blob/release/3.0/docs/pipeline_usage/tutorials/vlm_pipelines/doc_understanding.en.md performs deployment and updates the mllm_chat_bot_config configuration.
if use_mllm:
    mllm_chat_bot_config = {
        "module_name": "chat_bot",
        "model_name": "PP-DocBee",
        "base_url": "http://127.0.0.1:8080/",  # your local mllm service url
        "api_type": "openai",
        "api_key": "api_key",  # your api_key
    }

    mllm_predict_res = pipeline.mllm_pred(
        input="https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png",
        key_list=["È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞"],
        mllm_chat_bot_config=mllm_chat_bot_config,
    )
    mllm_predict_info = mllm_predict_res["mllm_res"]

visual_info_list = []
for res in visual_predict_res:
    visual_info_list.append(res["visual_info"])
    layout_parsing_result = res["layout_parsing_result"]

vector_info = pipeline.build_vector(
    visual_info_list, flag_save_bytes_vector=True, retriever_config=retriever_config
)
chat_result = pipeline.chat(
    key_list=["È©æÈ©∂ÂÆ§ÂáÜ‰πò‰∫∫Êï∞"],
    visual_info=visual_info_list,
    vector_info=vector_info,
    mllm_predict_info=mllm_predict_info,
    chat_bot_config=chat_bot_config,
    retriever_config=retriever_config,
)
print(chat_result)
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;4.4 PaddleOCR-VL Example&lt;/strong&gt;&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from paddleocr import PaddleOCRVL

pipeline = PaddleOCRVL()
output = pipeline.predict("https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png")
for res in output:
    res.print()
    res.save_to_json(save_path="output")
    res.save_to_markdown(save_path="output")
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;h3&gt;5. Chinese Heterogeneous AI Accelerators&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_NPU.html"&gt;Huawei Ascend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/other_devices_support/paddlepaddle_install_XPU.html"&gt;KUNLUNXIN&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© More Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Convert models to ONNX format: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/obtaining_onnx_models.html"&gt;Obtaining ONNX Models&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Accelerate inference using engines like OpenVINO, ONNX Runtime, TensorRT, or perform inference using ONNX format models: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/high_performance_inference.html"&gt;High-Performance Inference&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Accelerate inference using multi-GPU and multi-process: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/pipeline_usage/instructions/parallel_inference.html"&gt;Parallel Inference for Pipelines&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Integrate PaddleOCR into applications written in C++, C#, Java, etc.: &lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/deployment/serving.html"&gt;Serving&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;‚õ∞Ô∏è Advanced Tutorials&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/OCR.html"&gt;PP-OCRv5 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-StructureV3.html"&gt;PP-StructureV3 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PP-ChatOCRv4.html"&gt;PP-ChatOCRv4 Tutorial&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://paddlepaddle.github.io/PaddleOCR/latest/version3.x/pipeline_usage/PaddleOCR-VL.html"&gt;PaddleOCR-VL Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üîÑ Quick Overview of Execution Results&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/images/demo.gif" alt="PP-OCRv5 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/docs/images/blue_v3.gif" alt="PP-StructureV3 Demo" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;‚ú® Stay Tuned&lt;/h2&gt; 
&lt;p&gt;‚≠ê &lt;strong&gt;Star this repository to keep up with exciting updates and new releases, including powerful OCR and document parsing capabilities!&lt;/strong&gt; ‚≠ê&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="1200" src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/main/images/paddleocr/README/star_paddleocr.en.gif" alt="Star-Project" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Community&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th align="center"&gt;PaddlePaddle WeChat official account&lt;/th&gt; 
    &lt;th align="center"&gt;Join the tech discussion group&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qrcode_for_paddlepaddle_official_account.jpg" width="150" /&gt;&lt;/td&gt; 
    &lt;td align="center"&gt;&lt;img src="https://raw.githubusercontent.com/cuicheng01/PaddleX_doc_images/refs/heads/main/images/paddleocr/README/qr_code_for_the_questionnaire.jpg" width="150" /&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;üòÉ Awesome Projects Leveraging PaddleOCR&lt;/h2&gt; 
&lt;p&gt;PaddleOCR wouldn't be where it is today without its incredible community! üíó A massive thank you to all our longtime partners, new collaborators, and everyone who's poured their passion into PaddleOCR ‚Äî whether we've named you or not. Your support fuels our fire!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Project Name&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/infiniflow/ragflow"&gt;RAGFlow&lt;/a&gt; &lt;a href="https://github.com/infiniflow/ragflow"&gt;&lt;img src="https://img.shields.io/github/stars/infiniflow/ragflow" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;RAG engine based on deep document understanding.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/opendatalab/MinerU"&gt;MinerU&lt;/a&gt; &lt;a href="https://github.com/opendatalab/MinerU"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/MinerU" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Multi-type Document to Markdown Conversion Tool&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt;Umi-OCR&lt;/a&gt; &lt;a href="https://github.com/hiroi-sora/Umi-OCR"&gt;&lt;img src="https://img.shields.io/github/stars/hiroi-sora/Umi-OCR" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Free, Open-source, Batch Offline OCR Software.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/OmniParser"&gt;OmniParser&lt;/a&gt;&lt;a href="https://github.com/microsoft/OmniParser"&gt;&lt;img src="https://img.shields.io/github/stars/microsoft/OmniParser" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;OmniParser: Screen Parsing tool for Pure Vision Based GUI Agent.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/netease-youdao/QAnything"&gt;QAnything&lt;/a&gt;&lt;a href="https://github.com/netease-youdao/QAnything"&gt;&lt;img src="https://img.shields.io/github/stars/netease-youdao/QAnything" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Question and Answer based on Anything.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;PDF-Extract-Kit&lt;/a&gt; &lt;a href="https://github.com/opendatalab/PDF-Extract-Kit"&gt;&lt;img src="https://img.shields.io/github/stars/opendatalab/PDF-Extract-Kit" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;A powerful open-source toolkit designed to efficiently extract high-quality content from complex and diverse PDF documents.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/PantsuDango/Dango-Translator"&gt;Dango-Translator&lt;/a&gt;&lt;a href="https://github.com/PantsuDango/Dango-Translator"&gt;&lt;img src="https://img.shields.io/github/stars/PantsuDango/Dango-Translator" /&gt;&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;Recognize text on the screen, translate it and show the translation results in real time.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/awesome_projects.md"&gt;Learn more projects&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/awesome_projects.md"&gt;More projects based on PaddleOCR&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;üë©‚Äçüë©‚Äçüëß‚Äçüë¶ Contributors&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/PaddlePaddle/PaddleOCR/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=PaddlePaddle/PaddleOCR&amp;amp;max=400&amp;amp;columns=20" width="800" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;üåü Star&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt; &lt;img width="800" src="https://api.star-history.com/svg?repos=PaddlePaddle/PaddleOCR&amp;amp;type=Date" alt="Star-history" /&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;This project is released under the &lt;a href="https://raw.githubusercontent.com/PaddlePaddle/PaddleOCR/main/LICENSE"&gt;Apache 2.0 license&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üéì Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;@misc{cui2025paddleocr30technicalreport,
      title={PaddleOCR 3.0 Technical Report}, 
      author={Cheng Cui and Ting Sun and Manhui Lin and Tingquan Gao and Yubo Zhang and Jiaxuan Liu and Xueqing Wang and Zelun Zhang and Changda Zhou and Hongen Liu and Yue Zhang and Wenyu Lv and Kui Huang and Yichao Zhang and Jing Zhang and Jun Zhang and Yi Liu and Dianhai Yu and Yanjun Ma},
      year={2025},
      eprint={2507.05595},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.05595}, 
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>