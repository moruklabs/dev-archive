<rss version="2.0">
  <channel>
    <title>GitHub TypeScript Weekly Trending</title>
    <description>Weekly Trending of TypeScript in GitHub</description>
    <pubDate>Mon, 20 Oct 2025 01:49:14 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>ThinkInAIXYZ/deepchat</title>
      <link>https://github.com/ThinkInAIXYZ/deepchat</link>
      <description>&lt;p&gt;ğŸ¬DeepChat - A smart assistant that connects powerful AI to your personal world&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/build/icon.png" width="150" height="150" alt="DeepChat AI Assistant Icon" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;DeepChat - Powerful Open-Source Multi-Model AI Chat Platform&lt;/h1&gt; 
&lt;p align="center"&gt;DeepChat is a feature-rich open-source AI chat platform supporting multiple cloud and local large language models with powerful search enhancement and tool calling capabilities.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/ThinkInAIXYZ/deepchat" alt="Stars Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/ThinkInAIXYZ/deepchat" alt="Forks Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/pulls"&gt;&lt;img src="https://img.shields.io/github/issues-pr/ThinkInAIXYZ/deepchat" alt="Pull Requests Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/issues"&gt;&lt;img src="https://img.shields.io/github/issues/ThinkInAIXYZ/deepchat" alt="Issues Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/ThinkInAIXYZ/deepchat" alt="License Badge" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/ThinkInAIXYZ/deepchat"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/README.zh.md"&gt;ä¸­æ–‡&lt;/a&gt; / 
 &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/README.md"&gt;English&lt;/a&gt; / 
 &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/README.jp.md"&gt;æ—¥æœ¬èª&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ“‘ Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-table-of-contents"&gt;ğŸ“‘ Table of Contents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-project-introduction"&gt;ğŸš€ Project Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-why-choose-deepchat"&gt;ğŸ’¡ Why Choose DeepChat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-main-features"&gt;ğŸ”¥ Main Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-supported-model-providers"&gt;ğŸ¤– Supported Model Providers&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#compatible-with-any-model-provider-in-openaigeminianthropic-api-format"&gt;Compatible with any model provider in OpenAI/Gemini/Anthropic API format&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-use-cases"&gt;ğŸ” Use Cases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-quick-start"&gt;ğŸ“¦ Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#download-and-install"&gt;Download and Install&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#configure-models"&gt;Configure Models&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#start-conversations"&gt;Start Conversations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-development-guide"&gt;ğŸ’» Development Guide&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#install-dependencies"&gt;Install Dependencies&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#start-development"&gt;Start Development&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#build"&gt;Build&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-community--contribution"&gt;ğŸ‘¥ Community &amp;amp; Contribution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-star-history"&gt;â­ Star History&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-contributors"&gt;ğŸ‘¨â€ğŸ’» Contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/#-license"&gt;ğŸ“ƒ License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸš€ Project Introduction&lt;/h2&gt; 
&lt;p&gt;DeepChat is a powerful open-source AI chat platform providing a unified interface for interacting with various large language models. Whether you're using cloud APIs like OpenAI, Gemini, Anthropic, or locally deployed Ollama models, DeepChat delivers a smooth user experience.&lt;/p&gt; 
&lt;p&gt;As a cross-platform AI assistant application, DeepChat not only supports basic chat functionality but also offers advanced features such as search enhancement, tool calling, and multimodal interaction, making AI capabilities more accessible and efficient.&lt;/p&gt; 
&lt;table align="center"&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td align="center" style="padding: 10px;"&gt; &lt;img src="https://github.com/user-attachments/assets/6e932a65-78e0-4d2e-9654-ccc010f78bf7" alt="DeepChat Light Mode" width="400" /&gt; &lt;br /&gt; &lt;/td&gt; 
   &lt;td align="center" style="padding: 10px;"&gt; &lt;img src="https://github.com/user-attachments/assets/ea6ccf60-32af-4bc1-91cc-e72703bdc1ff" alt="DeepChat Dark Mode" width="400" /&gt; &lt;br /&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ğŸ’¡ Why Choose DeepChat&lt;/h2&gt; 
&lt;p&gt;Compared to other AI tools, DeepChat offers the following unique advantages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Unified Multi-Model Management&lt;/strong&gt;: One application supports almost all mainstream LLMs, eliminating the need to switch between multiple apps&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Seamless Local Model Integration&lt;/strong&gt;: Built-in Ollama support allows you to manage and use local models without command-line operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Tool Calling&lt;/strong&gt;: Built-in MCP support enables code execution, web access, and other tools without additional configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Powerful Search Enhancement&lt;/strong&gt;: Support for multiple search engines makes AI responses more accurate and timely, providing non-standard web search paradigms that can be quickly customized&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy-Focused&lt;/strong&gt;: Local data storage and network proxy support reduce the risk of information leakage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Business-Friendly&lt;/strong&gt;: Embraces open source under the Apache License 2.0, suitable for both commercial and personal use&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ”¥ Main Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸŒ &lt;strong&gt;Multiple Cloud LLM Provider Support&lt;/strong&gt;: DeepSeek, OpenAI, SiliconFlow, Grok, Gemini, Anthropic, and more&lt;/li&gt; 
 &lt;li&gt;ğŸ  &lt;strong&gt;Local Model Deployment Support&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Integrated Ollama with comprehensive management capabilities&lt;/li&gt; 
   &lt;li&gt;Control and manage Ollama model downloads, deployments, and runs without command-line operations&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;Rich and Easy-to-Use Chat Capabilities&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Complete Markdown rendering with code block rendering based on industry-leading &lt;a href="https://codemirror.net/"&gt;CodeMirror&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Multi-window + multi-tab architecture supporting parallel multi-session operations across all dimensions, use large models like using a browser, non-blocking experience brings excellent efficiency&lt;/li&gt; 
   &lt;li&gt;Supports Artifacts rendering for diverse result presentation, significantly saving token consumption after MCP integration&lt;/li&gt; 
   &lt;li&gt;Messages support retry to generate multiple variations; conversations can be forked freely, ensuring there's always a suitable line of thought&lt;/li&gt; 
   &lt;li&gt;Supports rendering images, Mermaid diagrams, and other multi-modal content; supports GPT-4o, Gemini, Grok text-to-image capabilities&lt;/li&gt; 
   &lt;li&gt;Supports highlighting external information sources like search results within the content&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ğŸ” &lt;strong&gt;Robust Search Extension Capabilities&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Built-in integration with leading search APIs like BoSearch, Brave Search via MCP mode, allowing the model to intelligently decide when to search&lt;/li&gt; 
   &lt;li&gt;Supports mainstream search engines like Google, Bing, Baidu, and Sogou Official Accounts search by simulating user web browsing, enabling the LLM to read search engines like a human&lt;/li&gt; 
   &lt;li&gt;Supports reading any search engine; simply configure a search assistant model to connect various search sources, whether internal networks, API-less engines, or vertical domain search engines, as information sources for the model&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ğŸ”§ &lt;strong&gt;Excellent MCP (Model Context Protocol) Support&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Complete support for the three core capabilities of Resources/Prompts/Tools in the MCP protocol&lt;/li&gt; 
   &lt;li&gt;Supports semantic workflows, enabling more complex and intelligent automation by understanding the meaning and context of tasks.&lt;/li&gt; 
   &lt;li&gt;Extremely user-friendly configuration interface&lt;/li&gt; 
   &lt;li&gt;Aesthetically pleasing and clear tool call display&lt;/li&gt; 
   &lt;li&gt;Detailed tool call debugging window with automatic formatting of tool parameters and return data&lt;/li&gt; 
   &lt;li&gt;Built-in Node.js runtime environment; npx/node-like services require no extra configuration and work out-of-the-box&lt;/li&gt; 
   &lt;li&gt;Supports StreamableHTTP/SSE/Stdio protocol Transports&lt;/li&gt; 
   &lt;li&gt;Supports inMemory services with built-in utilities like code execution, web information retrieval, and file operations; ready for most common use cases out-of-the-box without secondary installation&lt;/li&gt; 
   &lt;li&gt;Converts visual model capabilities into universally usable functions for any model via the built-in MCP service&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;ğŸ’» &lt;strong&gt;Multi-Platform Support&lt;/strong&gt;: Windows, macOS, Linux&lt;/li&gt; 
 &lt;li&gt;ğŸ¨ &lt;strong&gt;Beautiful and User-Friendly Interface&lt;/strong&gt;, user-oriented design, meticulously themed light and dark modes&lt;/li&gt; 
 &lt;li&gt;ğŸ”— &lt;strong&gt;Rich DeepLink Support&lt;/strong&gt;: Initiate conversations via links for seamless integration with other applications. Also supports one-click installation of MCP services for simplicity and speed&lt;/li&gt; 
 &lt;li&gt;ğŸš‘ &lt;strong&gt;Security-First Design&lt;/strong&gt;: Chat data and configuration data have reserved encryption interfaces and code obfuscation capabilities&lt;/li&gt; 
 &lt;li&gt;ğŸ›¡ï¸ &lt;strong&gt;Privacy Protection&lt;/strong&gt;: Supports screen projection hiding, network proxies, and other privacy protection methods to reduce the risk of information leakage&lt;/li&gt; 
 &lt;li&gt;ğŸ’° &lt;strong&gt;Business-Friendly&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Embraces open source, based on the Apache License 2.0 protocol, enterprise use without worry&lt;/li&gt; 
   &lt;li&gt;Enterprise integration requires only minimal configuration code changes to use reserved encrypted obfuscation security capabilities&lt;/li&gt; 
   &lt;li&gt;Clear code structure, both model providers and MCP services are highly decoupled, can be freely customized with minimal cost&lt;/li&gt; 
   &lt;li&gt;Reasonable architecture, data interaction and UI behavior separation, fully utilizing Electron's capabilities, rejecting simple web wrappers, excellent performance&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For more details on how to use these features, see the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/docs/user-guide.md"&gt;User Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ¤– Supported Model Providers&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/ollama.svg?sanitize=true" width="50" height="50" alt="Ollama Icon" /&gt;&lt;br /&gt; &lt;a href="https://ollama.com"&gt;Ollama&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/deepseek-color.svg?sanitize=true" width="50" height="50" alt="Deepseek Icon" /&gt;&lt;br /&gt; &lt;a href="https://deepseek.com/"&gt;Deepseek&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/ppio-color.svg?sanitize=true" width="50" height="50" alt="PPIO Icon" /&gt;&lt;br /&gt; &lt;a href="https://ppinfra.com/"&gt;PPIO&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/alibabacloud-color.svg?sanitize=true" width="50" height="50" alt="DashScope Icon" /&gt;&lt;br /&gt; &lt;a href="https://www.aliyun.com/product/bailian"&gt;DashScope&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/doubao-color.svg?sanitize=true" width="50" height="50" alt="Doubao Icon" /&gt;&lt;br /&gt; &lt;a href="https://console.volcengine.com/ark/"&gt;Doubao&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/minimax-color.svg?sanitize=true" width="50" height="50" alt="MiniMax Icon" /&gt;&lt;br /&gt; &lt;a href="https://platform.minimaxi.com/"&gt;MiniMax&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/fireworks-color.svg?sanitize=true" width="50" height="50" alt="Fireworks Icon" /&gt;&lt;br /&gt; &lt;a href="https://fireworks.ai/"&gt;Fireworks&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/302ai.svg?sanitize=true" width="50" height="50" alt="302.AI Icon" /&gt;&lt;br /&gt; &lt;a href="https://302.ai/"&gt;302.AI&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/openai.svg?sanitize=true" width="50" height="50" alt="OpenAI Icon" /&gt;&lt;br /&gt; &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/gemini-color.svg?sanitize=true" width="50" height="50" alt="Gemini Icon" /&gt;&lt;br /&gt; &lt;a href="https://gemini.google.com/"&gt;Gemini&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/github.svg?sanitize=true" width="50" height="50" alt="GitHub Models Icon" /&gt;&lt;br /&gt; &lt;a href="https://github.com/marketplace/models"&gt;GitHub Models&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/moonshot.svg?sanitize=true" width="50" height="50" alt="Moonshot Icon" /&gt;&lt;br /&gt; &lt;a href="https://moonshot.ai/"&gt;Moonshot&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/openrouter.svg?sanitize=true" width="50" height="50" alt="OpenRouter Icon" /&gt;&lt;br /&gt; &lt;a href="https://openrouter.ai/"&gt;OpenRouter&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/azure-color.svg?sanitize=true" width="50" height="50" alt="Azure OpenAI Icon" /&gt;&lt;br /&gt; &lt;a href="https://azure.microsoft.com/en-us/products/ai-services/openai-service"&gt;Azure OpenAI&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/qiniu.svg?sanitize=true" width="50" height="50" alt="Qiniu Icon" /&gt;&lt;br /&gt; &lt;a href="https://www.qiniu.com/products/ai-token-api"&gt;Qiniu&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/grok.svg?sanitize=true" width="50" height="50" alt="Grok Icon" /&gt;&lt;br /&gt; &lt;a href="https://x.ai/"&gt;Grok&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/zhipu-color.svg?sanitize=true" width="50" height="50" alt="Zhipu Icon" /&gt;&lt;br /&gt; &lt;a href="https://open.bigmodel.cn/"&gt;Zhipu&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/siliconcloud.svg?sanitize=true" width="50" height="50" alt="SiliconFlow Icon" /&gt;&lt;br /&gt; &lt;a href="https://www.siliconflow.cn/"&gt;SiliconFlow&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/aihubmix.png" width="50" height="50" alt="AIHubMix Icon" /&gt;&lt;br /&gt; &lt;a href="https://aihubmix.com/"&gt;AIHubMix&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/hunyuan-color.svg?sanitize=true" width="50" height="50" alt="Hunyuan Icon" /&gt;&lt;br /&gt; &lt;a href="https://cloud.tencent.com/product/hunyuan"&gt;Hunyuan&lt;/a&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr align="center"&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/lmstudio.svg?sanitize=true" width="50" height="50" alt="LM Studio Icon" /&gt;&lt;br /&gt; &lt;a href="https://lmstudio.ai/"&gt;LM Studio&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/src/renderer/src/assets/llm-icons/groq.svg?sanitize=true" width="50" height="50" alt="Groq Icon" /&gt;&lt;br /&gt; &lt;a href="https://groq.com/"&gt;Groq&lt;/a&gt; &lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h3&gt;Compatible with any model provider in OpenAI/Gemini/Anthropic API format&lt;/h3&gt; 
&lt;h2&gt;ğŸ” Use Cases&lt;/h2&gt; 
&lt;p&gt;DeepChat is suitable for various AI application scenarios:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Daily Assistant&lt;/strong&gt;: Answering questions, providing suggestions, assisting with writing and creation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Development Aid&lt;/strong&gt;: Code generation, debugging, technical problem solving&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Learning Tool&lt;/strong&gt;: Concept explanation, knowledge exploration, learning guidance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content Creation&lt;/strong&gt;: Copywriting, creative inspiration, content optimization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Analysis&lt;/strong&gt;: Data interpretation, chart generation, report writing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“¦ Quick Start&lt;/h2&gt; 
&lt;h3&gt;Download and Install&lt;/h3&gt; 
&lt;p&gt;Download the latest version for your system from the &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/releases"&gt;GitHub Releases&lt;/a&gt; page:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Windows: &lt;code&gt;.exe&lt;/code&gt; installation file&lt;/li&gt; 
 &lt;li&gt;macOS: &lt;code&gt;.dmg&lt;/code&gt; installation file&lt;/li&gt; 
 &lt;li&gt;Linux: &lt;code&gt;.AppImage&lt;/code&gt; or &lt;code&gt;.deb&lt;/code&gt; installation file&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Configure Models&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Launch the DeepChat application&lt;/li&gt; 
 &lt;li&gt;Click the settings icon&lt;/li&gt; 
 &lt;li&gt;Select the "Model Providers" tab&lt;/li&gt; 
 &lt;li&gt;Add your API keys or configure local Ollama&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Start Conversations&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Click the "+" button to create a new conversation&lt;/li&gt; 
 &lt;li&gt;Select the model you want to use&lt;/li&gt; 
 &lt;li&gt;Start communicating with your AI assistant&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For a comprehensive guide on getting started and using all features, please refer to the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/docs/user-guide.md"&gt;User Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ’» Development Guide&lt;/h2&gt; 
&lt;p&gt;Please read the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Windows and Linux are packaged by GitHub Action. For Mac-related signing and packaging, please refer to the &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/wiki/Mac-Release-Guide"&gt;Mac Release Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Install Dependencies&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ pnpm install
$ pnpm run installRuntime
# if got err: No module named 'distutils'
$ pip install setuptools
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;For Windows: To allow non-admin users to create symlinks and hardlinks, enable &lt;code&gt;Developer Mode&lt;/code&gt; in Settings or use an administrator account. Otherwise &lt;code&gt;pnpm&lt;/code&gt; ops will fail.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Start Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ pnpm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For Windows
$ pnpm run build:win

# For macOS
$ pnpm run build:mac

# For Linux
$ pnpm run build:linux

# Specify architecture packaging
$ pnpm run build:win:x64
$ pnpm run build:win:arm64
$ pnpm run build:mac:x64
$ pnpm run build:mac:arm64
$ pnpm run build:linux:x64
$ pnpm run build:linux:arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For a more detailed guide on development, project structure, and architecture, please see the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/docs/developer-guide.md"&gt;Developer Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ‘¥ Community &amp;amp; Contribution&lt;/h2&gt; 
&lt;p&gt;DeepChat is an active open-source community project, and we welcome various forms of contribution:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/issues"&gt;Report issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ’¡ &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/issues"&gt;Submit feature suggestions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/pulls"&gt;Submit code improvements&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸ“š &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/wiki"&gt;Improve documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ğŸŒ &lt;a href="https://github.com/ThinkInAIXYZ/deepchat/tree/main/locales"&gt;Help with translation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Check the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; to learn more about ways to participate in the project.&lt;/p&gt; 
&lt;h2&gt;â­ Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#ThinkInAIXYZ/deepchat&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=ThinkInAIXYZ/deepchat&amp;amp;type=Timeline" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ‘¨â€ğŸ’» Contributors&lt;/h2&gt; 
&lt;p&gt;Thank you for considering contributing to deepchat! The contribution guide can be found in the &lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://openomy.com/thinkinaixyz/deepchat" target="_blank" style="display: block; width: 100%;" align="center"&gt; &lt;img src="https://openomy.com/svg?repo=thinkinaixyz/deepchat&amp;amp;chart=bubble&amp;amp;latestMonth=3" target="_blank" alt="Contribution Leaderboard" style="display: block; width: 100%;" /&gt; &lt;/a&gt; 
&lt;h2&gt;ğŸ™ğŸ» Thanks&lt;/h2&gt; 
&lt;p&gt;This project is built with the help of these awesome libraries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://vuejs.org/"&gt;Vue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.electronjs.org/"&gt;Electron&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://electron-vite.org/"&gt;Electron-Vite&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/oxc-project/oxc"&gt;oxlint&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“ƒ License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/ThinkInAIXYZ/deepchat/dev/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>lfnovo/open-notebook</title>
      <link>https://github.com/lfnovo/open-notebook</link>
      <description>&lt;p&gt;An Open Source implementation of Notebook LM with more flexibility and features&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a id="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![Contributors][contributors-shield]][contributors-url] --&gt; 
&lt;p&gt;&lt;a href="https://github.com/lfnovo/open-notebook/network/members"&gt;&lt;img src="https://img.shields.io/github/forks/lfnovo/open-notebook.svg?style=for-the-badge" alt="Forks" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/lfnovo/open-notebook.svg?style=for-the-badge" alt="Stargazers" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;&lt;img src="https://img.shields.io/github/issues/lfnovo/open-notebook.svg?style=for-the-badge" alt="Issues" /&gt;&lt;/a&gt; &lt;a href="https://github.com/lfnovo/open-notebook/raw/master/LICENSE.txt"&gt;&lt;img src="https://img.shields.io/github/license/lfnovo/open-notebook.svg?style=for-the-badge" alt="MIT License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;!-- [![LinkedIn][linkedin-shield]][linkedin-url] --&gt; 
&lt;!-- PROJECT LOGO --&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/lfnovo/open-notebook"&gt; &lt;img src="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/hero.svg?sanitize=true" alt="Logo" /&gt; &lt;/a&gt; 
 &lt;h3 align="center"&gt;Open Notebook&lt;/h3&gt; 
 &lt;p align="center"&gt; An open source, privacy-focused alternative to Google's Notebook LM! &lt;br /&gt;&lt;strong&gt;Join our &lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord server&lt;/a&gt; for help, to share workflow ideas, and suggest features!&lt;/strong&gt; &lt;br /&gt; &lt;a href="https://www.open-notebook.ai"&gt;&lt;strong&gt;Checkout our website Â»&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/index.md"&gt;ğŸ“š Get Started&lt;/a&gt; Â· &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/index.md"&gt;ğŸ“– User Guide&lt;/a&gt; Â· &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/index.md"&gt;âœ¨ Features&lt;/a&gt; Â· &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/index.md"&gt;ğŸš€ Deploy&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt; 
 &lt;!-- Keep these links. Translations will automatically update with the README. --&gt; 
 &lt;a href="https://zdoc.app/de/lfnovo/open-notebook"&gt;Deutsch&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/es/lfnovo/open-notebook"&gt;EspaÃ±ol&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/fr/lfnovo/open-notebook"&gt;franÃ§ais&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/ja/lfnovo/open-notebook"&gt;æ—¥æœ¬èª&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/ko/lfnovo/open-notebook"&gt;í•œêµ­ì–´&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/pt/lfnovo/open-notebook"&gt;PortuguÃªs&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/ru/lfnovo/open-notebook"&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; | 
 &lt;a href="https://zdoc.app/zh/lfnovo/open-notebook"&gt;ä¸­æ–‡&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;A private, multi-model, 100% local, full-featured alternative to Notebook LM&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/assets/asset_list.png" alt="New Notebook" /&gt;&lt;/p&gt; 
&lt;p&gt;In a world dominated by Artificial Intelligence, having the ability to think ğŸ§  and acquire new knowledge ğŸ’¡, is a skill that should not be a privilege for a few, nor restricted to a single provider.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Open Notebook empowers you to:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ”’ &lt;strong&gt;Control your data&lt;/strong&gt; - Keep your research private and secure&lt;/li&gt; 
 &lt;li&gt;ğŸ¤– &lt;strong&gt;Choose your AI models&lt;/strong&gt; - Support for 16+ providers including OpenAI, Anthropic, Ollama, LM Studio, and more&lt;/li&gt; 
 &lt;li&gt;ğŸ“š &lt;strong&gt;Organize multi-modal content&lt;/strong&gt; - PDFs, videos, audio, web pages, and more&lt;/li&gt; 
 &lt;li&gt;ğŸ™ï¸ &lt;strong&gt;Generate professional podcasts&lt;/strong&gt; - Advanced multi-speaker podcast generation&lt;/li&gt; 
 &lt;li&gt;ğŸ” &lt;strong&gt;Search intelligently&lt;/strong&gt; - Full-text and vector search across all your content&lt;/li&gt; 
 &lt;li&gt;ğŸ’¬ &lt;strong&gt;Chat with context&lt;/strong&gt; - AI conversations powered by your research&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Learn more about our project at &lt;a href="https://www.open-notebook.ai"&gt;https://www.open-notebook.ai&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;âš ï¸ IMPORTANT: v1.0 Breaking Changes&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;If you're upgrading from a previous version&lt;/strong&gt;, please note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ·ï¸ &lt;strong&gt;Docker tags have changed&lt;/strong&gt;: The &lt;code&gt;latest&lt;/code&gt; tag is now &lt;strong&gt;frozen&lt;/strong&gt; at the last Streamlit version&lt;/li&gt; 
 &lt;li&gt;ğŸ†• &lt;strong&gt;Use &lt;code&gt;v1-latest&lt;/code&gt; tag&lt;/strong&gt; for the new React/Next.js version (recommended)&lt;/li&gt; 
 &lt;li&gt;ğŸ”Œ &lt;strong&gt;Port 5055 required&lt;/strong&gt;: You must expose port 5055 for the API to work&lt;/li&gt; 
 &lt;li&gt;ğŸ“– &lt;strong&gt;Read the migration guide&lt;/strong&gt;: See &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/MIGRATION.md"&gt;MIGRATION.md&lt;/a&gt; for detailed upgrade instructions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;New users&lt;/strong&gt;: You can ignore this notice and proceed with the Quick Start below using the &lt;code&gt;v1-latest-single&lt;/code&gt; tag.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ†š Open Notebook vs Google Notebook LM&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Open Notebook&lt;/th&gt; 
   &lt;th&gt;Google Notebook LM&lt;/th&gt; 
   &lt;th&gt;Advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Privacy &amp;amp; Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Self-hosted, your data&lt;/td&gt; 
   &lt;td&gt;Google cloud only&lt;/td&gt; 
   &lt;td&gt;Complete data sovereignty&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AI Provider Choice&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;16+ providers (OpenAI, Anthropic, Ollama, LM Studio, etc.)&lt;/td&gt; 
   &lt;td&gt;Google models only&lt;/td&gt; 
   &lt;td&gt;Flexibility and cost optimization&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Podcast Speakers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;1-4 speakers with custom profiles&lt;/td&gt; 
   &lt;td&gt;2 speakers only&lt;/td&gt; 
   &lt;td&gt;Extreme flexibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Context Control&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;3 granular levels&lt;/td&gt; 
   &lt;td&gt;All-or-nothing&lt;/td&gt; 
   &lt;td&gt;Privacy and performance tuning&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Content Transformations&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Custom and built-in&lt;/td&gt; 
   &lt;td&gt;Limited options&lt;/td&gt; 
   &lt;td&gt;Unlimited processing power&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Access&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Full REST API&lt;/td&gt; 
   &lt;td&gt;No API&lt;/td&gt; 
   &lt;td&gt;Complete automation&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Deployment&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Docker, cloud, or local&lt;/td&gt; 
   &lt;td&gt;Google hosted only&lt;/td&gt; 
   &lt;td&gt;Deploy anywhere&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Citations&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Comprehensive with sources&lt;/td&gt; 
   &lt;td&gt;Basic references&lt;/td&gt; 
   &lt;td&gt;Research integrity&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Open source, fully customizable&lt;/td&gt; 
   &lt;td&gt;Closed system&lt;/td&gt; 
   &lt;td&gt;Unlimited extensibility&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Pay only for AI usage&lt;/td&gt; 
   &lt;td&gt;Monthly subscription + usage&lt;/td&gt; 
   &lt;td&gt;Transparent and controllable&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;strong&gt;Why Choose Open Notebook?&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ”’ &lt;strong&gt;Privacy First&lt;/strong&gt;: Your sensitive research stays completely private&lt;/li&gt; 
 &lt;li&gt;ğŸ’° &lt;strong&gt;Cost Control&lt;/strong&gt;: Choose cheaper AI providers or run locally with Ollama&lt;/li&gt; 
 &lt;li&gt;ğŸ™ï¸ &lt;strong&gt;Better Podcasts&lt;/strong&gt;: Full script control and multi-speaker flexibility vs limited 2-speaker deep-dive format&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ &lt;strong&gt;Unlimited Customization&lt;/strong&gt;: Modify, extend, and integrate as needed&lt;/li&gt; 
 &lt;li&gt;ğŸŒ &lt;strong&gt;No Vendor Lock-in&lt;/strong&gt;: Switch providers, deploy anywhere, own your data&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Built With&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.python.org/"&gt;&lt;img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&amp;amp;logo=python&amp;amp;logoColor=white" alt="Python" /&gt;&lt;/a&gt; &lt;a href="https://nextjs.org/"&gt;&lt;img src="https://img.shields.io/badge/Next.js-000000?style=for-the-badge&amp;amp;logo=next.js&amp;amp;logoColor=white" alt="Next.js" /&gt;&lt;/a&gt; &lt;a href="https://reactjs.org/"&gt;&lt;img src="https://img.shields.io/badge/React-61DAFB?style=for-the-badge&amp;amp;logo=react&amp;amp;logoColor=black" alt="React" /&gt;&lt;/a&gt; &lt;a href="https://surrealdb.com/"&gt;&lt;img src="https://img.shields.io/badge/SurrealDB-FF5E00?style=for-the-badge&amp;amp;logo=databricks&amp;amp;logoColor=white" alt="SurrealDB" /&gt;&lt;/a&gt; &lt;a href="https://www.langchain.com/"&gt;&lt;img src="https://img.shields.io/badge/LangChain-3A3A3A?style=for-the-badge&amp;amp;logo=chainlink&amp;amp;logoColor=white" alt="LangChain" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Docker Images Available:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Hub&lt;/strong&gt;: &lt;code&gt;lfnovo/open_notebook:v1-latest-single&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Container Registry&lt;/strong&gt;: &lt;code&gt;ghcr.io/lfnovo/open-notebook:v1-latest-single&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Both registries contain identical images - choose whichever you prefer!&lt;/p&gt; 
&lt;p&gt;Ready to try Open Notebook? Choose your preferred method:&lt;/p&gt; 
&lt;h3&gt;âš¡ Instant Setup (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create a new directory for your Open Notebook installation
mkdir open-notebook
cd open-notebook

# Using Docker - Get started in 2 minutes
docker run -d \
  --name open-notebook \
  -p 8502:8502 -p 5055:5055 \
  -v ./notebook_data:/app/data \
  -v ./surreal_data:/mydata \
  -e OPENAI_API_KEY=your_key \
  lfnovo/open_notebook:v1-latest-single

# Or use GitHub Container Registry:
# ghcr.io/lfnovo/open-notebook:v1-latest-single
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;What gets created:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;open-notebook/
â”œâ”€â”€ notebook_data/     # Your notebooks and research content
â””â”€â”€ surreal_data/      # Database files
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Access your installation:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ–¥ï¸ Main Interface&lt;/strong&gt;: &lt;a href="http://localhost:8502"&gt;http://localhost:8502&lt;/a&gt; (Next.js UI)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ API Access&lt;/strong&gt;: &lt;a href="http://localhost:5055"&gt;http://localhost:5055&lt;/a&gt; (REST API)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“š API Documentation&lt;/strong&gt;: &lt;a href="http://localhost:5055/docs"&gt;http://localhost:5055/docs&lt;/a&gt; (Interactive Swagger UI)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;âš ï¸ Important&lt;/strong&gt;:&lt;/p&gt; 
 &lt;ol&gt; 
  &lt;li&gt;&lt;strong&gt;Run from a dedicated folder&lt;/strong&gt;: Create and run this from inside a new &lt;code&gt;open-notebook&lt;/code&gt; folder so your data volumes are properly organized&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Volume persistence&lt;/strong&gt;: The volumes (&lt;code&gt;-v ./notebook_data:/app/data&lt;/code&gt; and &lt;code&gt;-v ./surreal_data:/mydata&lt;/code&gt;) are essential to persist your data between container restarts. Without them, you'll lose all your notebooks and research when the container stops.&lt;/li&gt; 
 &lt;/ol&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ğŸ› ï¸ Full Installation&lt;/h3&gt; 
&lt;p&gt;For development or customization:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/lfnovo/open-notebook
cd open-notebook
make start-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;ğŸ“– Need Help?&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– AI Installation Assistant&lt;/strong&gt;: We have a &lt;a href="https://chatgpt.com/g/g-68776e2765b48191bd1bae3f30212631-open-notebook-installation-assistant"&gt;CustomGPT built to help you install Open Notebook&lt;/a&gt; - it will guide you through each step!&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;New to Open Notebook?&lt;/strong&gt; Start with our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/index.md"&gt;Getting Started Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Need installation help?&lt;/strong&gt; Check our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/installation.md"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Want to see it in action?&lt;/strong&gt; Try our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/quick-start.md"&gt;Quick Start Tutorial&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Provider Support Matrix&lt;/h2&gt; 
&lt;p&gt;Thanks to the &lt;a href="https://github.com/lfnovo/esperanto"&gt;Esperanto&lt;/a&gt; library, we support this providers out of the box!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Provider&lt;/th&gt; 
   &lt;th&gt;LLM Support&lt;/th&gt; 
   &lt;th&gt;Embedding Support&lt;/th&gt; 
   &lt;th&gt;Speech-to-Text&lt;/th&gt; 
   &lt;th&gt;Text-to-Speech&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Anthropic&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Groq&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Google (GenAI)&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Vertex AI&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ollama&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Perplexity&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ElevenLabs&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Azure OpenAI&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Mistral&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepSeek&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Voyage&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xAI&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenRouter&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;OpenAI Compatible*&lt;/td&gt; 
   &lt;td&gt;âœ…&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
   &lt;td&gt;âŒ&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;*Supports LM Studio and any OpenAI-compatible endpoint&lt;/p&gt; 
&lt;h2&gt;âœ¨ Key Features&lt;/h2&gt; 
&lt;h3&gt;Core Capabilities&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”’ Privacy-First&lt;/strong&gt;: Your data stays under your control - no cloud dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¯ Multi-Notebook Organization&lt;/strong&gt;: Manage multiple research projects seamlessly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“š Universal Content Support&lt;/strong&gt;: PDFs, videos, audio, web pages, Office docs, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– Multi-Model AI Support&lt;/strong&gt;: 16+ providers including OpenAI, Anthropic, Ollama, Google, LM Studio, and more&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ™ï¸ Professional Podcast Generation&lt;/strong&gt;: Advanced multi-speaker podcasts with Episode Profiles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ” Intelligent Search&lt;/strong&gt;: Full-text and vector search across all your content&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ’¬ Context-Aware Chat&lt;/strong&gt;: AI conversations powered by your research materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“ AI-Assisted Notes&lt;/strong&gt;: Generate insights or write notes manually&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Reasoning Model Support&lt;/strong&gt;: Full support for thinking models like DeepSeek-R1 and Qwen3&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”§ Content Transformations&lt;/strong&gt;: Powerful customizable actions to summarize and extract insights&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸŒ Comprehensive REST API&lt;/strong&gt;: Full programmatic access for custom integrations &lt;a href="http://localhost:5055/docs"&gt;&lt;img src="https://img.shields.io/badge/API-Documentation-blue?style=flat-square" alt="API Docs" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ” Optional Password Protection&lt;/strong&gt;: Secure public deployments with authentication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“Š Fine-Grained Context Control&lt;/strong&gt;: Choose exactly what to share with AI models&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“ Citations&lt;/strong&gt;: Get answers with proper source citations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Three-Column Interface&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Sources&lt;/strong&gt;: Manage all your research materials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Notes&lt;/strong&gt;: Create manual or AI-generated notes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Chat&lt;/strong&gt;: Converse with AI using your content as context&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=D-760MlGwaI"&gt;&lt;img src="https://img.youtube.com/vi/D-760MlGwaI/0.jpg" alt="Check out our podcast sample" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“š Documentation&lt;/h2&gt; 
&lt;h3&gt;Getting Started&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/introduction.md"&gt;ğŸ“– Introduction&lt;/a&gt;&lt;/strong&gt; - Learn what Open Notebook offers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/quick-start.md"&gt;âš¡ Quick Start&lt;/a&gt;&lt;/strong&gt; - Get up and running in 5 minutes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/installation.md"&gt;ğŸ”§ Installation&lt;/a&gt;&lt;/strong&gt; - Comprehensive setup guide&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/getting-started/first-notebook.md"&gt;ğŸ¯ Your First Notebook&lt;/a&gt;&lt;/strong&gt; - Step-by-step tutorial&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;User Guide&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/interface-overview.md"&gt;ğŸ“± Interface Overview&lt;/a&gt;&lt;/strong&gt; - Understanding the layout&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/notebooks.md"&gt;ğŸ“š Notebooks&lt;/a&gt;&lt;/strong&gt; - Organizing your research&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/sources.md"&gt;ğŸ“„ Sources&lt;/a&gt;&lt;/strong&gt; - Managing content types&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/notes.md"&gt;ğŸ“ Notes&lt;/a&gt;&lt;/strong&gt; - Creating and managing notes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/chat.md"&gt;ğŸ’¬ Chat&lt;/a&gt;&lt;/strong&gt; - AI conversations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/user-guide/search.md"&gt;ğŸ” Search&lt;/a&gt;&lt;/strong&gt; - Finding information&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Topics&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/podcasts.md"&gt;ğŸ™ï¸ Podcast Generation&lt;/a&gt;&lt;/strong&gt; - Create professional podcasts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/transformations.md"&gt;ğŸ”§ Content Transformations&lt;/a&gt;&lt;/strong&gt; - Customize content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/features/ai-models.md"&gt;ğŸ¤– AI Models&lt;/a&gt;&lt;/strong&gt; - AI model configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/development/api-reference.md"&gt;ğŸ”§ REST API Reference&lt;/a&gt;&lt;/strong&gt; - Complete API documentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/security.md"&gt;ğŸ” Security&lt;/a&gt;&lt;/strong&gt; - Password protection and privacy&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/docs/deployment/index.md"&gt;ğŸš€ Deployment&lt;/a&gt;&lt;/strong&gt; - Complete deployment guides for all scenarios&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;ğŸ—ºï¸ Roadmap&lt;/h2&gt; 
&lt;h3&gt;Upcoming Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Live Front-End Updates&lt;/strong&gt;: Real-time UI updates for smoother experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Async Processing&lt;/strong&gt;: Faster UI through asynchronous content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cross-Notebook Sources&lt;/strong&gt;: Reuse research materials across projects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bookmark Integration&lt;/strong&gt;: Connect with your favorite bookmarking apps&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Recently Completed âœ…&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Next.js Frontend&lt;/strong&gt;: Modern React-based frontend with improved performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive REST API&lt;/strong&gt;: Full programmatic access to all functionality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Model Support&lt;/strong&gt;: 16+ AI providers including OpenAI, Anthropic, Ollama, LM Studio&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced Podcast Generator&lt;/strong&gt;: Professional multi-speaker podcasts with Episode Profiles&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Content Transformations&lt;/strong&gt;: Powerful customizable actions for content processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enhanced Citations&lt;/strong&gt;: Improved layout and finer control for source citations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple Chat Sessions&lt;/strong&gt;: Manage different conversations within notebooks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;open issues&lt;/a&gt; for a full list of proposed features and known issues.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ Community &amp;amp; Contributing&lt;/h2&gt; 
&lt;h3&gt;Join the Community&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ’¬ &lt;strong&gt;&lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord Server&lt;/a&gt;&lt;/strong&gt; - Get help, share ideas, and connect with other users&lt;/li&gt; 
 &lt;li&gt;ğŸ› &lt;strong&gt;&lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt; - Report bugs and request features&lt;/li&gt; 
 &lt;li&gt;â­ &lt;strong&gt;Star this repo&lt;/strong&gt; - Show your support and help others discover Open Notebook&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing&lt;/h3&gt; 
&lt;p&gt;We welcome contributions! We're especially looking for help with:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend Development&lt;/strong&gt;: Help improve our modern Next.js/React UI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Testing &amp;amp; Bug Fixes&lt;/strong&gt;: Make Open Notebook more robust&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Feature Development&lt;/strong&gt;: Build the coolest research tool together&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: Improve guides and tutorials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Current Tech Stack&lt;/strong&gt;: Python, FastAPI, Next.js, React, SurrealDB &lt;strong&gt;Future Roadmap&lt;/strong&gt;: Real-time updates, enhanced async processing&lt;/p&gt; 
&lt;p&gt;See our &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/CONTRIBUTING.md"&gt;Contributing Guide&lt;/a&gt; for detailed information on how to get started.&lt;/p&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;Open Notebook is MIT licensed. See the &lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;h2&gt;ğŸ“ Contact&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Luis Novo&lt;/strong&gt; - &lt;a href="https://twitter.com/lfnovo"&gt;@lfnovo&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Community Support&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ’¬ &lt;a href="https://discord.gg/37XJPXfz2w"&gt;Discord Server&lt;/a&gt; - Get help, share ideas, and connect with users&lt;/li&gt; 
 &lt;li&gt;ğŸ› &lt;a href="https://github.com/lfnovo/open-notebook/issues"&gt;GitHub Issues&lt;/a&gt; - Report bugs and request features&lt;/li&gt; 
 &lt;li&gt;ğŸŒ &lt;a href="https://www.open-notebook.ai"&gt;Website&lt;/a&gt; - Learn more about the project&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ™ Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Open Notebook is built on the shoulders of amazing open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/podcast-creator"&gt;Podcast Creator&lt;/a&gt;&lt;/strong&gt; - Advanced podcast generation capabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/surreal-commands"&gt;Surreal Commands&lt;/a&gt;&lt;/strong&gt; - Background job processing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/content-core"&gt;Content Core&lt;/a&gt;&lt;/strong&gt; - Content processing and management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/lfnovo/esperanto"&gt;Esperanto&lt;/a&gt;&lt;/strong&gt; - Multi-provider AI model abstraction&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/docling-project/docling"&gt;Docling&lt;/a&gt;&lt;/strong&gt; - Document processing and parsing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p align="right"&gt;(&lt;a href="https://raw.githubusercontent.com/lfnovo/open-notebook/main/#readme-top"&gt;back to top&lt;/a&gt;)&lt;/p&gt; 
&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt; 
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;</description>
    </item>
    
    <item>
      <title>hydralauncher/hydra</title>
      <link>https://github.com/hydralauncher/hydra</link>
      <description>&lt;p&gt;Hydra Launcher is an open-source gaming platform created to be the single tool that you need&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://help.hydralauncher.gg"&gt;&lt;img src="https://raw.githubusercontent.com/hydralauncher/hydra/main/resources/icon.png" width="144" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h1 align="center"&gt;Hydra Launcher&lt;/h1&gt; 
 &lt;p align="center"&gt; &lt;strong&gt;Hydra Launcher is an open-source gaming platform created to be the single tool that you need in order to manage your gaming library. Hydra is written in Node.js (Electron, React, Typescript) and Python.&lt;/strong&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/hydralauncher/hydra/actions"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/hydralauncher/hydra/build.yml" alt="build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hydralauncher/hydra/releases"&gt;&lt;img src="https://img.shields.io/github/package-json/v/hydralauncher/hydra" alt="release" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/hydralauncher/hydra/main/docs/screenshot.png" alt="Hydra Launcher Home Page" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add games that you own to your library&lt;/li&gt; 
 &lt;li&gt;Have a nice profile that shows what you are playing to your friends&lt;/li&gt; 
 &lt;li&gt;Save your game progress in the cloud with Hydra Cloud&lt;/li&gt; 
 &lt;li&gt;Unlock achievements&lt;/li&gt; 
 &lt;li&gt;Navigate through a rich catalogue with a powerful suggestion algorithm&lt;/li&gt; 
 &lt;li&gt;Discover new games that you haven't played before&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Build from source and contributing&lt;/h2&gt; 
&lt;p&gt;Please, refer to our Documentation pages: &lt;a href="https://docs.hydralauncher.gg/getting-started"&gt;docs.hydralauncher.gg&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/hydralauncher/hydra/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=hydralauncher/hydra" /&gt; &lt;/a&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Hydra is licensed under the &lt;a href="https://raw.githubusercontent.com/hydralauncher/hydra/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>CapSoftware/Cap</title>
      <link>https://github.com/CapSoftware/Cap</link>
      <description>&lt;p&gt;Open source Loom alternative. Beautiful, shareable screen recordings.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;img width="150" height="150" src="https://github.com/CapSoftware/Cap/raw/main/apps/desktop/src-tauri/icons/Square310x310Logo.png" alt="Logo" /&gt; &lt;/p&gt; 
&lt;h1 align="center"&gt;&lt;b&gt;Cap&lt;/b&gt;&lt;/h1&gt; 
&lt;p align="center"&gt; The open source Loom alternative. &lt;br /&gt; &lt;a href="https://cap.so"&gt;&lt;strong&gt;Cap.so Â»&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt; &lt;br /&gt; &lt;b&gt;Downloads for &lt;/b&gt; &lt;a href="https://cap.so/download"&gt;macOS &amp;amp; Windows&lt;/a&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://console.algora.io/org/CapSoftware/bounties?status=open"&gt;&lt;img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fconsole.algora.io%2Fapi%2Fshields%2FCapSoftware%2Fbounties%3Fstatus%3Dopen" alt="Open Bounties" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Cap is the open source alternative to Loom. It's a video messaging tool that allows you to record, edit and share videos in seconds.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/CapSoftware/Cap/refs/heads/main/apps/web/public/landing-cover.png" /&gt; 
&lt;h1&gt;Self Hosting&lt;/h1&gt; 
&lt;p&gt;Cap Web is available to self-host using Docker or Railway, see our &lt;a href="https://cap.so/docs/self-hosting"&gt;self-hosting docs&lt;/a&gt; to learn more. You can also use the button below to deploy Cap Web to Railway:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://railway.com/new/template/PwpGcf"&gt;&lt;img src="https://railway.com/button.svg?sanitize=true" alt="Deploy on Railway" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Cap Desktop can connect to your self-hosted Cap Web instance regardless of if you build it yourself or &lt;a href="https://cap.so/download"&gt;download from our website&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Monorepo App Architecture&lt;/h1&gt; 
&lt;p&gt;We use a combination of Rust, React (Next.js), TypeScript, Tauri, Drizzle (ORM), MySQL, TailwindCSS throughout this Turborepo powered monorepo.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;A note about database: The codebase is currently designed to work with MySQL only. MariaDB or other compatible databases might partially work but are not officially supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Apps:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;desktop&lt;/code&gt;: A &lt;a href="https://tauri.app"&gt;Tauri&lt;/a&gt; (Rust) app, using &lt;a href="https://start.solidjs.com"&gt;SolidStart&lt;/a&gt; on the frontend.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;web&lt;/code&gt;: A &lt;a href="https://nextjs.org"&gt;Next.js&lt;/a&gt; web app.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Packages:&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ui&lt;/code&gt;: A &lt;a href="https://reactjs.org"&gt;React&lt;/a&gt; Shared component library.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;utils&lt;/code&gt;: A &lt;a href="https://reactjs.org"&gt;React&lt;/a&gt; Shared utility library.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;tsconfig&lt;/code&gt;: Shared &lt;code&gt;tsconfig&lt;/code&gt; configurations used throughout the monorepo.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;database&lt;/code&gt;: A &lt;a href="https://reactjs.org"&gt;React&lt;/a&gt; and &lt;a href="https://orm.drizzle.team/"&gt;Drizzle ORM&lt;/a&gt; Shared database library.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;config&lt;/code&gt;: &lt;code&gt;eslint&lt;/code&gt; configurations (includes &lt;code&gt;eslint-config-next&lt;/code&gt;, &lt;code&gt;eslint-config-prettier&lt;/code&gt; other configs used throughout the monorepo).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;License:&lt;/h3&gt; 
&lt;p&gt;Portions of this software are licensed as follows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;All code residing in the &lt;code&gt;cap-camera*&lt;/code&gt; and &lt;code&gt;scap-*&lt;/code&gt; families of crates is licensed under the MIT License (see &lt;a href="https://github.com/CapSoftware/Cap/raw/main/licenses/LICENSE-MIT"&gt;licenses/LICENSE-MIT&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;All third party components are licensed under the original license provided by the owner of the applicable component&lt;/li&gt; 
 &lt;li&gt;All other content not mentioned above is available under the AGPLv3 license as defined in &lt;a href="https://github.com/CapSoftware/Cap/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/CapSoftware/Cap/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more information. This guide is a work in progress, and is updated regularly as the app matures.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>exa-labs/exa-mcp-server</title>
      <link>https://github.com/exa-labs/exa-mcp-server</link>
      <description>&lt;p&gt;Exa MCP for web search and web crawling!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Exa MCP Server ğŸ”&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://www.npmjs.com/package/exa-mcp-server"&gt;&lt;img src="https://badge.fury.io/js/exa-mcp-server.svg?sanitize=true" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://smithery.ai/server/exa"&gt;&lt;img src="https://smithery.ai/badge/exa" alt="smithery badge" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ†• &lt;code&gt;exa-code&lt;/code&gt;: fast, efficient web context for coding agents&lt;/h2&gt; 
&lt;p&gt;Vibe coding should never have a bad vibe. &lt;code&gt;exa-code&lt;/code&gt; is a huge step towards coding agents that never hallucinate.&lt;/p&gt; 
&lt;p&gt;When your coding agent makes a search query, &lt;code&gt;exa-code&lt;/code&gt; searches over billions of Github repos, docs pages, Stackoverflow posts, and more, to find the perfect, token-efficient context that the agent needs to code correctly. It's powered by the Exa search engine.&lt;/p&gt; 
&lt;p&gt;Examples of queries you can make with &lt;code&gt;exa-code&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;use Exa search in python and make sure content is always livecrawled&lt;/li&gt; 
 &lt;li&gt;use correct syntax for vercel ai sdk to call gpt-5 nano asking it how are you&lt;/li&gt; 
 &lt;li&gt;how to set up a reproducible Nix Rust development environment&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;âœ¨ Works with Cursor and Claude Code!&lt;/strong&gt; Use the HTTP-based configuration format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "exa": {
      "type": "http",
      "url": "https://mcp.exa.ai/mcp",
      "headers": {
        "Remove-Me": "Disable web_search_exa tool if you're just coding. To 100% call exa-code, say 'use exa-code'."
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You may include your exa api key in the url like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://mcp.exa.ai/mcp?exaApiKey=YOUREXAKEY
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You may whitelist specific tools in the url with the &lt;code&gt;enabledTools&lt;/code&gt; parameter which expects a url encoded array strings like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;https://mcp.exa.ai/mcp?exaApiKey=YOUREXAKEY&amp;amp;enabledTools=%5B%22crawling_exa%ss%5D
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also use &lt;code&gt;exa-code&lt;/code&gt; through &lt;a href="https://smithery.ai/server/exa"&gt;Smithery&lt;/a&gt; without an Exa API key.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;A Model Context Protocol (MCP) server that connects AI assistants like Claude to Exa AI's search capabilities, including web search, research tools, and our new code search feature.&lt;/p&gt; 
&lt;h2&gt;Remote Exa MCP ğŸŒ&lt;/h2&gt; 
&lt;p&gt;Connect directly to Exa's hosted MCP server (instead of running it locally).&lt;/p&gt; 
&lt;h3&gt;Remote Exa MCP URL&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;https://mcp.exa.ai/mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Claude Desktop Configuration for Remote MCP&lt;/h3&gt; 
&lt;p&gt;Add this to your Claude Desktop configuration file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "exa": {
      "command": "npx",
      "args": [
        "-y",
        "mcp-remote",
        "https://mcp.exa.ai/mcp"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Cursor and Claude Code Configuration for Remote MCP&lt;/h3&gt; 
&lt;p&gt;For Cursor and Claude Code, use this HTTP-based configuration format:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "exa": {
      "type": "http",
      "url": "https://mcp.exa.ai/mcp",
      "headers": {}
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Codex Configuration for Remote MCP&lt;/h3&gt; 
&lt;p&gt;Open your Codex configuration file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;code ~/.codex/config.toml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Add this configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;[mcp_servers.exa]
command = "npx"
args = ["-y", "mcp-remote", "https://mcp.exa.ai/mcp"]
env = { EXA_API_KEY = "your-api-key-here" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace &lt;code&gt;your-api-key-here&lt;/code&gt; with your actual Exa API key from &lt;a href="https://dashboard.exa.ai/api-keys"&gt;dashboard.exa.ai/api-keys&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Claude Code Plugin&lt;/h3&gt; 
&lt;p&gt;The easiest way to get started with Exa in Claude Code, using plugins:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Add the Exa marketplace
/plugin marketplace add exa-labs/exa-mcp-server

# Install the plugin
/plugin install exa-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then set your API key:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;export EXA_API_KEY="your-api-key-here"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Get your API key from &lt;a href="https://dashboard.exa.ai/api-keys"&gt;dashboard.exa.ai/api-keys&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;NPM Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install -g exa-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Claude Code&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;claude mcp add exa -e EXA_API_KEY=YOUR_API_KEY -- npx -y exa-mcp-server
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Using Exa MCP through Smithery&lt;/h3&gt; 
&lt;p&gt;To install the Exa MCP server via &lt;a href="https://smithery.ai/server/exa"&gt;Smithery&lt;/a&gt;, head over to:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://smithery.ai/server/exa"&gt;smithery.ai/server/exa&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Configuration âš™ï¸&lt;/h2&gt; 
&lt;h3&gt;1. Configure Claude Desktop to recognize the Exa MCP server&lt;/h3&gt; 
&lt;p&gt;You can find claude_desktop_config.json inside the settings of Claude Desktop app:&lt;/p&gt; 
&lt;p&gt;Open the Claude Desktop app and enable Developer Mode from the top-left menu bar.&lt;/p&gt; 
&lt;p&gt;Once enabled, open Settings (also from the top-left menu bar) and navigate to the Developer Option, where you'll find the Edit Config button. Clicking it will open the claude_desktop_config.json file, allowing you to make the necessary edits.&lt;/p&gt; 
&lt;p&gt;OR (if you want to open claude_desktop_config.json from terminal)&lt;/p&gt; 
&lt;h4&gt;For macOS:&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open your Claude Desktop configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;code ~/Library/Application\ Support/Claude/claude_desktop_config.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;For Windows:&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open your Claude Desktop configuration:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-powershell"&gt;code %APPDATA%\Claude\claude_desktop_config.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Add the Exa server configuration:&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "exa": {
      "command": "npx",
      "args": ["-y", "exa-mcp-server"],
      "env": {
        "EXA_API_KEY": "your-api-key-here"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Replace &lt;code&gt;your-api-key-here&lt;/code&gt; with your actual Exa API key from &lt;a href="https://dashboard.exa.ai/api-keys"&gt;dashboard.exa.ai/api-keys&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;3. Available Tools &amp;amp; Tool Selection&lt;/h3&gt; 
&lt;p&gt;The Exa MCP server includes powerful tools for developers and researchers:&lt;/p&gt; 
&lt;h4&gt;ğŸ”¥ &lt;strong&gt;Featured: Code Search Tool&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;get_code_context_exa&lt;/strong&gt;: ğŸ†• &lt;strong&gt;NEW!&lt;/strong&gt; Search and get relevant code snippets, examples, and documentation from open source libraries, GitHub repositories, and programming frameworks. Perfect for finding up-to-date code documentation, implementation examples, API usage patterns, and best practices from real codebases.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;ğŸŒ &lt;strong&gt;Other Available Tools&lt;/strong&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;web_search_exa&lt;/strong&gt;: Performs real-time web searches with optimized results and content extraction.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;company_research&lt;/strong&gt;: Comprehensive company research tool that crawls company websites to gather detailed information about businesses.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;crawling&lt;/strong&gt;: Extracts content from specific URLs, useful for reading articles, PDFs, or any web page when you have the exact URL.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;linkedin_search&lt;/strong&gt;: Search LinkedIn for companies and people using Exa AI. Simply include company names, person names, or specific LinkedIn URLs in your query.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;deep_researcher_start&lt;/strong&gt;: Start a smart AI researcher for complex questions. The AI will search the web, read many sources, and think deeply about your question to create a detailed research report.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;deep_researcher_check&lt;/strong&gt;: Check if your research is ready and get the results. Use this after starting a research task to see if it's done and get your comprehensive report.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can choose which tools to enable by adding the &lt;code&gt;--tools&lt;/code&gt; parameter to your Claude Desktop configuration:&lt;/p&gt; 
&lt;h4&gt;ğŸ’» &lt;strong&gt;Setup for Code Search Only&lt;/strong&gt; (Recommended for Developers)&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "exa": {
      "command": "npx",
      "args": [
        "-y",
        "exa-mcp-server",
        "--tools=get_code_context_exa,web_search_exa"
      ],
      "env": {
        "EXA_API_KEY": "your-api-key-here"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Specify which tools to enable:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "exa": {
      "command": "npx",
      "args": [
        "-y",
        "exa-mcp-server",
        "--tools=get_code_context_exa,web_search_exa,company_research,crawling,linkedin_search,deep_researcher_start,deep_researcher_check"
      ],
      "env": {
        "EXA_API_KEY": "your-api-key-here"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For enabling multiple tools, use a comma-separated list:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "exa": {
      "command": "npx",
      "args": [
        "-y",
        "exa-mcp-server",
        "--tools=get_code_context_exa,web_search_exa,company_research,crawling,linkedin_search,deep_researcher_start,deep_researcher_check"
      ],
      "env": {
        "EXA_API_KEY": "your-api-key-here"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you don't specify any tools, all tools enabled by default will be used.&lt;/p&gt; 
&lt;h3&gt;4. Restart Claude Desktop&lt;/h3&gt; 
&lt;p&gt;For the changes to take effect:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Completely quit Claude Desktop (not just close the window)&lt;/li&gt; 
 &lt;li&gt;Start Claude Desktop again&lt;/li&gt; 
 &lt;li&gt;Look for the icon to verify the Exa server is connected&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Using via NPX&lt;/h2&gt; 
&lt;p&gt;If you prefer to run the server directly, you can use npx:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run with all tools enabled by default
npx exa-mcp-server

# Enable specific tools only
npx exa-mcp-server --tools=web_search_exa

# Enable multiple tools
npx exa-mcp-server --tools=web_search_exa,get_code_context_exa

# List all available tools
npx exa-mcp-server --list-tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;Built with â¤ï¸ by team Exa&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nanobrowser/nanobrowser</title>
      <link>https://github.com/nanobrowser/nanobrowser</link>
      <description>&lt;p&gt;Open-Source Chrome extension for AI-powered web automation. Run multi-agent workflows using your own LLM API key. Alternative to OpenAI Operator.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/ec60b0c4-87ba-48f4-981a-c55ed0e8497b" height="100" width="375" alt="banner" /&gt;&lt;br /&gt; &lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://github.com/nanobrowser"&gt;&lt;img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://x.com/nanobrowser_ai"&gt;&lt;img src="https://img.shields.io/badge/Twitter-000000?style=for-the-badge&amp;amp;logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/NN3ABHggMK"&gt;&lt;img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/nanobrowser/nanobrowser"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" height="28" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/alexchenzl"&gt;&lt;img src="https://img.shields.io/badge/Sponsor-ff69b4?style=for-the-badge&amp;amp;logo=githubsponsors&amp;amp;logoColor=white" alt="Sponsor" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸŒ Nanobrowser&lt;/h2&gt; 
&lt;p&gt;Nanobrowser is an open-source AI web automation tool that runs in your browser. A free alternative to OpenAI Operator with flexible LLM options and multi-agent system.&lt;/p&gt; 
&lt;p&gt;â¬‡ï¸ Get &lt;a href="https://chromewebstore.google.com/detail/nanobrowser/imbddededgmcgfhfpcjmijokokekbkal"&gt;Nanobrowser from Chrome Web Store&lt;/a&gt; for free&lt;/p&gt; 
&lt;p&gt;ğŸ‘ Join the community in &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/nanobrowser_ai"&gt;X&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;ğŸŒŸ Loving Nanobrowser? Give us a star and help spread the word!&lt;/p&gt; 
&lt;p&gt;â¤ï¸ Support the project by &lt;a href="https://github.com/sponsors/alexchenzl"&gt;sponsoring us&lt;/a&gt; - every contribution helps keep Nanobrowser free and open source!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://github.com/user-attachments/assets/112c4385-7b03-4b81-a352-4f348093351b" width="600" alt="Nanobrowser Demo GIF" /&gt; 
 &lt;p&gt;&lt;em&gt;Nanobrowser's multi-agent system analyzing HuggingFace in real-time, with the Planner intelligently self-correcting when encountering obstacles and dynamically instructing the Navigator to adjust its approachâ€”all running locally in your browser.&lt;/em&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ”¥Why Nanobrowser?&lt;/h2&gt; 
&lt;p&gt;Looking for a powerful AI browser agent without the $200/month price tag of OpenAI Operator? &lt;strong&gt;Nanobrowser&lt;/strong&gt; , as a chrome extension, delivers premium web automation capabilities while keeping you in complete control:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;100% Free&lt;/strong&gt; - No subscription fees or hidden costs. Just install and use your own API keys, and you only pay what you use with your own API keys.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Privacy-Focused&lt;/strong&gt; - Everything runs in your local browser. Your credentials stay with you, never shared with any cloud service.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible LLM Options&lt;/strong&gt; - Connect to your preferred LLM providers with the freedom to choose different models for different agents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fully Open Source&lt;/strong&gt; - Complete transparency in how your browser is automated. No black boxes or hidden processes.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We currently support OpenAI, Anthropic, Gemini, Ollama, Groq, Cerebras, Llama and custom OpenAI-Compatible providers, more providers will be supported.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ“Š Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-agent System&lt;/strong&gt;: Specialized AI agents collaborate to accomplish complex web workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Side Panel&lt;/strong&gt;: Intuitive chat interface with real-time status updates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Task Automation&lt;/strong&gt;: Seamlessly automate repetitive web automation tasks across websites&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Follow-up Questions&lt;/strong&gt;: Ask contextual follow-up questions about completed tasks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Conversation History&lt;/strong&gt;: Easily access and manage your AI agent interaction history&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple LLM Support&lt;/strong&gt;: Connect your preferred LLM providers and assign different models to different agents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸŒ Browser Support&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Officially Supported:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Chrome&lt;/strong&gt; - Full support with all features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Edge&lt;/strong&gt; - Full support with all features&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Not Supported:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Firefox, Safari, and other Chromium variants (Opera, Arc, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: While Nanobrowser may function on other Chromium-based browsers, we recommend using Chrome or Edge for the best experience and guaranteed compatibility.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install from Chrome Web Store&lt;/strong&gt; (Stable Version): 
  &lt;ul&gt; 
   &lt;li&gt;Visit the &lt;a href="https://chromewebstore.google.com/detail/nanobrowser/imbddededgmcgfhfpcjmijokokekbkal"&gt;Nanobrowser Chrome Web Store page&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Click "Add to Chrome" button&lt;/li&gt; 
   &lt;li&gt;Confirm the installation when prompted&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Important Note&lt;/strong&gt;: For latest features, install from &lt;a href="https://raw.githubusercontent.com/nanobrowser/nanobrowser/master/#-manually-install-latest-version"&gt;"Manually Install Latest Version"&lt;/a&gt; below, as Chrome Web Store version may be delayed due to review process.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Configure Agent Models&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Click the Nanobrowser icon in your toolbar to open the sidebar&lt;/li&gt; 
   &lt;li&gt;Click the &lt;code&gt;Settings&lt;/code&gt; icon (top right)&lt;/li&gt; 
   &lt;li&gt;Add your LLM API keys&lt;/li&gt; 
   &lt;li&gt;Choose which model to use for different agents (Navigator, Planner)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ”§ Manually Install Latest Version&lt;/h2&gt; 
&lt;p&gt;To get the most recent version with all the latest features:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Download&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Download the latest &lt;code&gt;nanobrowser.zip&lt;/code&gt; file from the official Github &lt;a href="https://github.com/nanobrowser/nanobrowser/releases"&gt;release page&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Unzip &lt;code&gt;nanobrowser.zip&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Open &lt;code&gt;chrome://extensions/&lt;/code&gt; in Chrome&lt;/li&gt; 
   &lt;li&gt;Enable &lt;code&gt;Developer mode&lt;/code&gt; (top right)&lt;/li&gt; 
   &lt;li&gt;Click &lt;code&gt;Load unpacked&lt;/code&gt; (top left)&lt;/li&gt; 
   &lt;li&gt;Select the unzipped &lt;code&gt;nanobrowser&lt;/code&gt; folder.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configure Agent Models&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Click the Nanobrowser icon in your toolbar to open the sidebar&lt;/li&gt; 
   &lt;li&gt;Click the &lt;code&gt;Settings&lt;/code&gt; icon (top right).&lt;/li&gt; 
   &lt;li&gt;Add your LLM API keys.&lt;/li&gt; 
   &lt;li&gt;Choose which model to use for different agents (Navigator, Planner)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Upgrading&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Download the latest &lt;code&gt;nanobrowser.zip&lt;/code&gt; file from the release page.&lt;/li&gt; 
   &lt;li&gt;Unzip and replace your existing Nanobrowser files with the new ones.&lt;/li&gt; 
   &lt;li&gt;Go to &lt;code&gt;chrome://extensions/&lt;/code&gt; in Chrome and click the refresh icon on the Nanobrowser card.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ› ï¸ Build from Source&lt;/h2&gt; 
&lt;p&gt;If you prefer to build Nanobrowser yourself, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; (v22.12.0 or higher)&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://pnpm.io/installation"&gt;pnpm&lt;/a&gt; (v9.15.1 or higher)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the Repository&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/nanobrowser/nanobrowser.git
cd nanobrowser
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Install Dependencies&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm install
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Build the Extension&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm build
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Load the Extension&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The built extension will be in the &lt;code&gt;dist&lt;/code&gt; directory&lt;/li&gt; 
   &lt;li&gt;Follow the installation steps from the Manually Install section to load the extension into your browser&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Development Mode&lt;/strong&gt; (optional):&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;pnpm dev
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ¤– Choosing Your Models&lt;/h2&gt; 
&lt;p&gt;Nanobrowser allows you to configure different LLM models for each agent to balance performance and cost. Here are recommended configurations:&lt;/p&gt; 
&lt;h3&gt;Better Performance&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Planner&lt;/strong&gt;: Claude Sonnet 4 
  &lt;ul&gt; 
   &lt;li&gt;Better reasoning and planning capabilities&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Navigator&lt;/strong&gt;: Claude Haiku 3.5 
  &lt;ul&gt; 
   &lt;li&gt;Efficient for web navigation tasks&lt;/li&gt; 
   &lt;li&gt;Good balance of performance and cost&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Cost-Effective Configuration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Planner&lt;/strong&gt;: Claude Haiku or GPT-4o 
  &lt;ul&gt; 
   &lt;li&gt;Reasonable performance at lower cost&lt;/li&gt; 
   &lt;li&gt;May require more iterations for complex tasks&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Navigator&lt;/strong&gt;: Gemini 2.5 Flash or GPT-4o-mini 
  &lt;ul&gt; 
   &lt;li&gt;Lightweight and cost-efficient&lt;/li&gt; 
   &lt;li&gt;Suitable for basic navigation tasks&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Local Models&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Setup Options&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Use Ollama or other custom OpenAI-compatible providers to run models locally&lt;/li&gt; 
   &lt;li&gt;Zero API costs and complete privacy with no data leaving your machine&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Recommended Models&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Qwen3-30B-A3B-Instruct-2507&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Falcon3 10B&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Qwen 2.5 Coder 14B&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Mistral Small 24B&lt;/strong&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://gist.github.com/maximus2600/75d60bf3df62986e2254d5166e2524cb"&gt;Latest test results from community&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;We welcome community experience sharing with other local models in our &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Prompt Engineering&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Local models require more specific and cleaner prompts&lt;/li&gt; 
   &lt;li&gt;Avoid high-level, ambiguous commands&lt;/li&gt; 
   &lt;li&gt;Break complex tasks into clear, detailed steps&lt;/li&gt; 
   &lt;li&gt;Provide explicit context and constraints&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The cost-effective configuration may produce less stable outputs and require more iterations for complex tasks.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Feel free to experiment with your own model configurations! Found a great combination? Share it with the community in our &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord&lt;/a&gt; to help others optimize their setup.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;ğŸ’¡ See It In Action&lt;/h2&gt; 
&lt;p&gt;Here are some powerful tasks you can accomplish with just a sentence:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;News Summary&lt;/strong&gt;:&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;"Go to TechCrunch and extract top 10 headlines from the last 24 hours"&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitHub Research&lt;/strong&gt;:&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;"Look for the trending Python repositories on GitHub with most stars"&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Shopping Research&lt;/strong&gt;:&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;"Find a portable Bluetooth speaker on Amazon with a water-resistant design, under $50. It should have a minimum battery life of 10 hours"&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;ğŸ› ï¸ Roadmap&lt;/h2&gt; 
&lt;p&gt;We're actively developing Nanobrowser with exciting features on the horizon, welcome to join us!&lt;/p&gt; 
&lt;p&gt;Check out our detailed roadmap and upcoming features in our &lt;a href="https://github.com/nanobrowser/nanobrowser/discussions/85"&gt;GitHub Discussions&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We need your help to make Nanobrowser even better!&lt;/strong&gt; Contributions of all kinds are welcome:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Share Prompts &amp;amp; Use Cases&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Join our &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord server&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;share how you're using Nanobrowser. Help us build a library of useful prompts and real-world use cases.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Provide Feedback&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Try Nanobrowser and give us feedback on its performance or suggest improvements in our &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord server&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contribute Code&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Check out our &lt;a href="https://raw.githubusercontent.com/nanobrowser/nanobrowser/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for guidelines on how to contribute code to the project.&lt;/li&gt; 
   &lt;li&gt;Submit pull requests for bug fixes, features, or documentation improvements.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We believe in the power of open source and community collaboration. Join us in building the future of web automation!&lt;/p&gt; 
&lt;h2&gt;ğŸ”’ Security&lt;/h2&gt; 
&lt;p&gt;If you discover a security vulnerability, please &lt;strong&gt;DO NOT&lt;/strong&gt; disclose it publicly through issues, pull requests, or discussions.&lt;/p&gt; 
&lt;p&gt;Instead, please create a &lt;a href="https://github.com/nanobrowser/nanobrowser/security/advisories/new"&gt;GitHub Security Advisory&lt;/a&gt; to report the vulnerability responsibly. This allows us to address the issue before it's publicly disclosed.&lt;/p&gt; 
&lt;p&gt;We appreciate your help in keeping Nanobrowser and its users safe!&lt;/p&gt; 
&lt;h2&gt;ğŸ’¬ Community&lt;/h2&gt; 
&lt;p&gt;Join our growing community of developers and users:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord&lt;/a&gt; - Chat with team and community&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/nanobrowser_ai"&gt;Twitter&lt;/a&gt; - Follow for updates and announcements&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/nanobrowser/nanobrowser/discussions"&gt;GitHub Discussions&lt;/a&gt; - Share ideas and ask questions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ‘ Acknowledgments&lt;/h2&gt; 
&lt;p&gt;Nanobrowser builds on top of other awesome open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/browser-use/browser-use"&gt;Browser Use&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EmergenceAI/Agent-E"&gt;Puppeteer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jonghakseo/chrome-extension-boilerplate-react-vite"&gt;Chrome Extension Boilerplate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/langchain-ai/langchainjs"&gt;LangChain&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Huge thanks to their creators and contributors!&lt;/p&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache License 2.0 - see the &lt;a href="https://raw.githubusercontent.com/nanobrowser/nanobrowser/master/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt; 
&lt;p&gt;Made with â¤ï¸ by the Nanobrowser Team.&lt;/p&gt; 
&lt;p&gt;Like Nanobrowser? Give us a star ğŸŒŸ and join us in &lt;a href="https://discord.gg/NN3ABHggMK"&gt;Discord&lt;/a&gt; | &lt;a href="https://x.com/nanobrowser_ai"&gt;X&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;âš ï¸ DISCLAIMER ON DERIVATIVE PROJECTS&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;We explicitly &lt;em&gt;DO NOT&lt;/em&gt; endorse, support, or participate in any&lt;/strong&gt; projects involving cryptocurrencies, tokens, NFTs, or other blockchain-related applications &lt;strong&gt;based on this codebase.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Any such derivative projects are&amp;nbsp;NOT&amp;nbsp;Affiliated with, or maintained by, or in any way connected to the official Nanobrowser project or its core team.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We assume NO LIABILITY for any losses, damages, or issues arising from the use of third-party derivative projects. Users interact with these projects at their own risk.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;We reserve the right to publicly distance ourselves from any misuse or misleading use of our name, codebase, or brand.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;We encourage open-source innovation but urge our community to be discerning and cautious. Please ensure you understand the risks before using any software or service built upon our codebase by independent developers.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>nitrojs/nitro</title>
      <link>https://github.com/nitrojs/nitro</link>
      <description>&lt;p&gt;Next Generation Server Toolkit. Create web servers with everything you need and deploy them wherever you prefer.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Nitro&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Youâ€™re viewing the &lt;strong&gt;v3 Alpha&lt;/strong&gt; branch. For the current stable release, see &lt;a href="https://github.com/nitrojs/nitro/tree/v2"&gt;Nitro v2&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Nitro&lt;/strong&gt; extends your Vite app with a &lt;strong&gt;production-ready server&lt;/strong&gt;, designed to run &lt;strong&gt;anywhere&lt;/strong&gt;. Add server routes, deploy across multiple platforms, and enjoy a &lt;strong&gt;zero-config&lt;/strong&gt; experience.&lt;/p&gt; 
&lt;p&gt;ğŸ“˜ &lt;strong&gt;Docs (v3 Alpha):&lt;/strong&gt; &lt;a href="https://v3.nitro.build"&gt;https://v3.nitro.build&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See Check out the &lt;a href="https://raw.githubusercontent.com/nitrojs/nitro/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Released under the &lt;a href="https://raw.githubusercontent.com/nitrojs/nitro/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>anthropics/claude-code</title>
      <link>https://github.com/anthropics/claude-code</link>
      <description>&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Claude Code&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square" alt="" /&gt; &lt;a href="https://www.npmjs.com/package/@anthropic-ai/claude-code"&gt;&lt;img src="https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square" alt="npm" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your terminal, IDE, or tag @claude on Github.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Learn more in the &lt;a href="https://docs.anthropic.com/en/docs/claude-code/overview"&gt;official documentation&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/anthropics/claude-code/main/demo.gif" /&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Claude Code:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm install -g @anthropic-ai/claude-code
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Navigate to your project directory and run &lt;code&gt;claude&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Plugins&lt;/h2&gt; 
&lt;p&gt;This repository includes several Claude Code plugins that extend functionality with custom commands and agents. See the &lt;a href="https://raw.githubusercontent.com/anthropics/claude-code/main/plugins/README.md"&gt;plugins directory&lt;/a&gt; for detailed documentation on available plugins.&lt;/p&gt; 
&lt;h2&gt;Reporting Bugs&lt;/h2&gt; 
&lt;p&gt;We welcome your feedback. Use the &lt;code&gt;/bug&lt;/code&gt; command to report issues directly within Claude Code, or file a &lt;a href="https://github.com/anthropics/claude-code/issues"&gt;GitHub issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Connect on Discord&lt;/h2&gt; 
&lt;p&gt;Join the &lt;a href="https://anthropic.com/discord"&gt;Claude Developers Discord&lt;/a&gt; to connect with other developers using Claude Code. Get help, share feedback, and discuss your projects with the community.&lt;/p&gt; 
&lt;h2&gt;Data collection, usage, and retention&lt;/h2&gt; 
&lt;p&gt;When you use Claude Code, we collect feedback, which includes usage data (such as code acceptance or rejections), associated conversation data, and user feedback submitted via the &lt;code&gt;/bug&lt;/code&gt; command.&lt;/p&gt; 
&lt;h3&gt;How we use your data&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://docs.anthropic.com/en/docs/claude-code/data-usage"&gt;data usage policies&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Privacy safeguards&lt;/h3&gt; 
&lt;p&gt;We have implemented several safeguards to protect your data, including limited retention periods for sensitive information, restricted access to user session data, and clear policies against using feedback for model training.&lt;/p&gt; 
&lt;p&gt;For full details, please review our &lt;a href="https://www.anthropic.com/legal/commercial-terms"&gt;Commercial Terms of Service&lt;/a&gt; and &lt;a href="https://www.anthropic.com/legal/privacy"&gt;Privacy Policy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>evershopcommerce/evershop</title>
      <link>https://github.com/evershopcommerce/evershop</link>
      <description>&lt;p&gt;ğŸ›ï¸ Typescript E-commerce Platform&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="60" height="68" alt="EverShop Logo" src="https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/logo-green.png" /&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;/p&gt;
&lt;h1 align="center"&gt;EverShop&lt;/h1&gt; 
&lt;p&gt;&lt;/p&gt; 
&lt;h4 align="center"&gt; &lt;a href="https://evershop.io/docs/development/getting-started/introduction"&gt;Documentation&lt;/a&gt; | &lt;a href="https://demo.evershop.io/"&gt;Demo&lt;/a&gt; &lt;/h4&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/evershopcommerce/evershop/actions/workflows/build_test.yml/badge.svg?sanitize=true" alt="Github Action" /&gt; &lt;a href="https://twitter.com/evershopjs"&gt; &lt;img alt="Twitter Follow" src="https://img.shields.io/twitter/follow/evershopjs?style=social" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/GSzt7dt7RM"&gt; &lt;img src="https://img.shields.io/discord/757179260417867879?label=discord" alt="Discord" /&gt; &lt;/a&gt; &lt;a href="https://opensource.org/licenses/GPL-3.0"&gt; &lt;img src="https://img.shields.io/badge/License-GPLv3-blue.svg?sanitize=true" alt="License" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img alt="EverShop" width="950" src="https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/banner.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;EverShop is a modern, TypeScript-first eCommerce platform built with GraphQL and React. Designed for developers, it offers essential commerce features in a modular, fully customizable architectureâ€”perfect for building tailored shopping experiences with confidence and speed.&lt;/p&gt; 
&lt;h2&gt;Installation Using Docker&lt;/h2&gt; 
&lt;p&gt;You can get started with EverShop in minutes by using the Docker image. The Docker image is a great way to get started with EverShop without having to worry about installing dependencies or configuring your environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://raw.githubusercontent.com/evershopcommerce/evershop/main/docker-compose.yml &amp;gt; docker-compose.yml
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For the full installation guide, please refer to our &lt;a href="https://evershop.io/docs/development/getting-started/installation-guide"&gt;Installation guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://evershop.io/docs/development/getting-started/installation-guide"&gt;Installation guide&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://evershop.io/docs/development/module/create-your-first-extension"&gt;Extension development&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://evershop.io/docs/development/theme/theme-overview"&gt;Theme development&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Demo&lt;/h2&gt; 
&lt;p&gt;Explore our demo store.&lt;/p&gt; 
&lt;p align="left"&gt; &lt;a href="https://demo.evershop.io/admin" target="_blank"&gt; &lt;img alt="EverShop Admin Demo" height="35" src="https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/evershop-demo-back.png" /&gt; &lt;/a&gt; &lt;a href="https://demo.evershop.io/" target="_blank"&gt; &lt;img alt="EverShop Store Demo" height="35" src="https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/evershop-demo-front.png" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;b&gt;Demo user:&lt;/b&gt; 
&lt;p&gt;Email: &lt;a href="mailto:demo@evershop.io"&gt;demo@evershop.io&lt;/a&gt;&lt;br /&gt; Password: 123456&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;If you like my work, feel free to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;â­ this repository. It helps.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fgithub.com%2Fevershopcommerce%2Fevershop&amp;amp;text=Awesome%20React%20Ecommerce%20Project&amp;amp;hashtags=react,ecommerce,expressjs,graphql"&gt;&lt;img src="https://img.shields.io/twitter/url/http/shields.io.svg?style=social" alt="Tweet" /&gt;&lt;/a&gt; about EverShop. Thank you!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;EverShop is an open-source project. We are committed to a fully transparent development process and appreciate highly any contributions. Whether you are helping us fix bugs, proposing new features, improving our documentation or spreading the word - we would love to have you as part of the EverShop community.&lt;/p&gt; 
&lt;h3&gt;Ask a question about EverShop&lt;/h3&gt; 
&lt;p&gt;You can ask questions, and participate in discussions about EverShop-related topics in the EverShop Discord channel.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/GSzt7dt7RM"&gt;&lt;img src="https://raw.githubusercontent.com/evershopcommerce/evershop/dev/.github/images/discord_banner_github.svg?sanitize=true" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Create a bug report&lt;/h3&gt; 
&lt;p&gt;If you see an error message or run into an issue, please &lt;a href="https://github.com/evershopcommerce/evershop/issues/new"&gt;create bug report&lt;/a&gt;. This effort is valued and it will help all EverShop users.&lt;/p&gt; 
&lt;h3&gt;Submit a feature request&lt;/h3&gt; 
&lt;p&gt;If you have an idea, or you're missing a capability that would make development easier and more robust, please &lt;a href="https://github.com/evershopcommerce/evershop/issues/new"&gt;Submit feature request&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If a similar feature request already exists, don't forget to leave a "+1". If you add some more information such as your thoughts and vision about the feature, your comments will be embraced warmly :)&lt;/p&gt; 
&lt;p&gt;Please refer to our &lt;a href="https://raw.githubusercontent.com/evershopcommerce/evershop/dev/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/evershopcommerce/evershop/dev/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/evershopcommerce/evershop/raw/main/LICENSE"&gt;GPL-3.0 License&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>supermemoryai/supermemory</title>
      <link>https://github.com/supermemoryai/supermemory</link>
      <description>&lt;p&gt;Memory engine and app that is extremely fast, scalable. The Memory API for the AI era.&lt;/p&gt;&lt;hr&gt;&lt;div align="center" style="padding-bottom:20px;padding-top:20px"&gt; 
 &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/logo.svg?sanitize=true" alt="supermemory Logo" width="400" /&gt; 
&lt;/div&gt; 
&lt;div align="center" style="padding-bottom:10px;padding-top:10px"&gt; 
 &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/apps/web/public/landing-page.jpeg" alt="supermemory" width="100%" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;h3&gt;Core Functionality&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/supermemoryai/supermemory/main/#add-memory"&gt;Add Memories from Any Content&lt;/a&gt;&lt;/strong&gt;: Easily add memories from URLs, PDFs, and plain textâ€”just paste, upload, or link.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/supermemoryai/supermemory/main/#chat-memories"&gt;Chat with Your Memories&lt;/a&gt;&lt;/strong&gt;: Converse with your stored content using natural language chat.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/supermemoryai/supermemory/main/#mcp-integration"&gt;Supermemory MCP Integration&lt;/a&gt;&lt;/strong&gt;: Seamlessly connect with all major AI tools (Claude, Cursor, etc.) via Supermemory MCP.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How do i use this?&lt;/h2&gt; 
&lt;p&gt;Go to &lt;a href="https://app.supermemory.ai"&gt;app.supermemory.ai&lt;/a&gt; and sign into with your account&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a id="add-memory"&gt;&lt;/a&gt;Start Adding Memory with your choice of format (Note, Link, File)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center" style="padding-bottom:10px;padding-top:10px"&gt; 
 &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/apps/web/public/add-memory.png" alt="supermemory" width="100%" /&gt; 
&lt;/div&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;You can also Connect to your favourite services (Notion, Google Drive, OneDrive)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center" style="padding-bottom:10px;padding-top:10px"&gt; 
 &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/apps/web/public/add-connections.png" alt="supermemory" width="100%" /&gt; 
&lt;/div&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;&lt;a id="chat-memories"&gt;&lt;/a&gt;Once Memories are added, you can chat with Supermemory by clicking on "Open Chat" and retrieve info from your saved memories&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center" style="padding-bottom:10px;padding-top:10px"&gt; 
 &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/apps/web/public/chat.png" alt="supermemory" width="100%" /&gt; 
&lt;/div&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;&lt;a id="mcp-integration"&gt;&lt;/a&gt;Add MCP to your AI Tools (by clicking on "Connect to your AI" and select the AI tool you are trying to integrate)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="center" style="padding-bottom:10px;padding-top:10px"&gt; 
 &lt;img src="https://raw.githubusercontent.com/supermemoryai/supermemory/main/apps/web/public/mcp.png" alt="supermemory" width="100%" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Have questions or feedback? We're here to help:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Email: &lt;a href="mailto:dhravya@supermemory.com"&gt;dhravya@supermemory.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://docs.supermemory.ai"&gt;docs.supermemory.ai&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions from developers of all skill levels! Whether you're fixing bugs, adding features, or improving documentation, your help makes supermemory better for everyone.&lt;/p&gt; 
&lt;h3&gt;Quick Start for Contributors&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Fork and clone&lt;/strong&gt; the repository&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Install dependencies&lt;/strong&gt; with &lt;code&gt;bun install&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Set up your environment&lt;/strong&gt; by copying &lt;code&gt;.env.example&lt;/code&gt; to &lt;code&gt;.env.local&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Start developing&lt;/strong&gt; with &lt;code&gt;bun run dev&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;For detailed guidelines, development setup, coding standards, and the complete contribution workflow, please see our &lt;a href="https://raw.githubusercontent.com/supermemoryai/supermemory/main/CONTRIBUTING.md"&gt;&lt;strong&gt;Contributing Guide&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Ways to Contribute&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ› &lt;strong&gt;Bug fixes&lt;/strong&gt; - Help us squash those pesky issues&lt;/li&gt; 
 &lt;li&gt;âœ¨ &lt;strong&gt;New features&lt;/strong&gt; - Add functionality that users will love&lt;/li&gt; 
 &lt;li&gt;ğŸ¨ &lt;strong&gt;UI/UX improvements&lt;/strong&gt; - Make the interface more intuitive&lt;/li&gt; 
 &lt;li&gt;âš¡ &lt;strong&gt;Performance optimizations&lt;/strong&gt; - Help us make supermemory faster&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Check out our &lt;a href="https://github.com/supermemoryai/supermemory/issues"&gt;Issues&lt;/a&gt; page for &lt;code&gt;good first issue&lt;/code&gt; and &lt;code&gt;help wanted&lt;/code&gt; labels to get started!&lt;/p&gt; 
&lt;h2&gt;Updates &amp;amp; Roadmap&lt;/h2&gt; 
&lt;p&gt;Stay up to date with the latest improvements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.supermemory.ai/changelog/overview"&gt;Changelog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/supermemoryai"&gt;X&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>remix-run/remix</title>
      <link>https://github.com/remix-run/remix</link>
      <description>&lt;p&gt;Build Better Websites. Create modern, resilient user experiences with web fundamentals.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome to Remix 3!&lt;/h1&gt; 
&lt;p&gt;This is the source repository for Remix 3. It is under active development.&lt;/p&gt; 
&lt;p&gt;We published &lt;a href="https://remix.run/blog/wake-up-remix"&gt;a blog post&lt;/a&gt; earlier this year with some of our thoughts around Remix 3. It explains our philosophy for web development and why we think the time is right for something new. When working on Remix 3, we follow these principles:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Model-First Development&lt;/strong&gt;. AI fundamentally shifts the human-computer interaction model for both user experience and developer workflows. Optimize the source code, documentation, tooling, and abstractions for LLMs. Additionally, develop abstractions for applications to use models in the product itself, not just as a tool to develop it.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build on Web APIs&lt;/strong&gt;. Sharing abstractions across the stack greatly reduces the amount of context switching, both for humans and machines. Build on the foundation of Web APIs and JavaScript because it is the only full stack ecosystem.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Religiously Runtime&lt;/strong&gt;. Designing for bundlers/compilers/typegen (and any pre-runtime static analysis) leads to poor API design that eventually pollutes the entire system. All packages must be designed with no expectation of static analysis and all tests must run without bundling. Because browsers are involved, &lt;code&gt;--import&lt;/code&gt; loaders for simple transformations like TypeScript and JSX are permissible.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Avoid Dependencies&lt;/strong&gt;. Dependencies lock you into somebody else's roadmap. Choose them wisely, wrap them completely, and expect to replace most of them with our own package eventually. The goal is zero.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Demand Composition&lt;/strong&gt;. Abstractions should be single-purpose and replaceable. A composable abstraction is easy to add and remove from an existing program. Every package must be useful and documented independent of any other context. New features should first be attempted as a new package. If impossible, attempt to break up the existing package to make it more composable. However, tightly coupled modules that almost always change together in both directions should be moved to the same package.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Distribute Cohesively&lt;/strong&gt;. Extremely composable ecosystems are difficult to learn and use. Remix will be distributed as a single &lt;code&gt;remix&lt;/code&gt; package for both distribution and documentation.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Goals&lt;/h2&gt; 
&lt;p&gt;Although we recommend the &lt;code&gt;remix&lt;/code&gt; package for ease of use, all packages that make up Remix should be usable standalone as well. This forces us to consider package boundaries and helps us define public interfaces that are portable and interopable.&lt;/p&gt; 
&lt;p&gt;Each package in Remix:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Has a &lt;a href="https://en.wikipedia.org/wiki/Single-responsibility_principle"&gt;single responsibility&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Prioritizes web standards to ensure maximum interoperability and portability across JavaScript runtimes&lt;/li&gt; 
 &lt;li&gt;Augments standards unobtrusively where they are missing or incomplete, minimizing incompatibility risks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This means Remix code is &lt;strong&gt;portable by default&lt;/strong&gt;. Remix packages work seamlessly across &lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt;, &lt;a href="https://bun.sh/"&gt;Bun&lt;/a&gt;, &lt;a href="https://deno.com/"&gt;Deno&lt;/a&gt;, &lt;a href="https://workers.cloudflare.com/"&gt;Cloudflare Workers&lt;/a&gt;, and other environments.&lt;/p&gt; 
&lt;p&gt;We leverage server-side web APIs when they are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Streams_API"&gt;The Web Streams API&lt;/a&gt; instead of &lt;code&gt;node:stream&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array"&gt;&lt;code&gt;Uint8Array&lt;/code&gt;&lt;/a&gt; instead of Node.js &lt;code&gt;Buffer&lt;/code&gt;s&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API"&gt;The Web Crypto API&lt;/a&gt; instead of &lt;code&gt;node:crypto&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Blob"&gt;&lt;code&gt;Blob&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/File"&gt;&lt;code&gt;File&lt;/code&gt;&lt;/a&gt; instead of some bespoke runtime-specific API&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The benefit is code that's not just reusable, but &lt;strong&gt;future-proof&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Packages&lt;/h2&gt; 
&lt;p&gt;We currently publish the following packages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/remix-run/remix/main/packages/fetch-proxy"&gt;fetch-proxy&lt;/a&gt;: Seamlessly construct HTTP proxies with the familiar &lt;code&gt;fetch()&lt;/code&gt; API&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/remix-run/remix/main/packages/file-storage"&gt;file-storage&lt;/a&gt;: Robust key/value storage tailored for JavaScript &lt;code&gt;File&lt;/code&gt; objects, simplifying file management&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/remix-run/remix/main/packages/form-data-parser"&gt;form-data-parser&lt;/a&gt;: An enhanced &lt;code&gt;request.formData()&lt;/code&gt; wrapper enabling efficient, streaming file uploads&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/remix-run/remix/main/packages/headers"&gt;headers&lt;/a&gt;: A comprehensive toolkit for effortlessly managing HTTP headers&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/remix-run/remix/main/packages/lazy-file"&gt;lazy-file&lt;/a&gt;: Optimize performance with lazy-loaded, streaming &lt;code&gt;Blob&lt;/code&gt;s and &lt;code&gt;File&lt;/code&gt;s for JavaScript&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/remix-run/remix/main/packages/multipart-parser"&gt;multipart-parser&lt;/a&gt;: High-performance, streaming parser for multipart messages, perfect for handling complex form data&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/remix-run/remix/main/packages/node-fetch-server"&gt;node-fetch-server&lt;/a&gt;: Build Node.js HTTP servers using the web-standard &lt;code&gt;fetch()&lt;/code&gt; API, promoting code consistency&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/remix-run/remix/main/packages/route-pattern"&gt;route-pattern&lt;/a&gt;: A powerful and flexible URL pattern matching library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/remix-run/remix/main/packages/tar-parser"&gt;tar-parser&lt;/a&gt;: A fast, streaming parser for tar archives, designed for efficient data extraction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions! If you'd like to contribute, please feel free to open an issue or submit a pull request. See &lt;a href="https://github.com/remix-run/remix/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/remix-run/remix/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>devlikeapro/waha</title>
      <link>https://github.com/devlikeapro/waha</link>
      <description>&lt;p&gt;WAHA - WhatsApp HTTP API (REST API) that you can configure in a click! 3 engines: WEBJS (browser based), NOWEB (websocket nodejs), GOWS (websocket go)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;WAHA&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/devlikeapro/waha/core/logo.png" style="border-radius: 50%" width="150" /&gt; &lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;WAHA&lt;/strong&gt; - &lt;strong&gt;W&lt;/strong&gt;hats&lt;strong&gt;A&lt;/strong&gt;pp &lt;strong&gt;H&lt;/strong&gt;TTP &lt;strong&gt;A&lt;/strong&gt;PI (REST API) that you can install on your own server and run in less than 5 minutes!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/devlikeapro/waha"&gt;&lt;img src="https://img.shields.io/docker/pulls/devlikeapro/waha" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://waha.devlike.pro/"&gt;https://waha.devlike.pro/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dashboard Example: &lt;a href="https://waha.devlike.pro/dashboard"&gt;https://waha.devlike.pro/dashboard&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Swagger Example: &lt;a href="https://waha.devlike.pro/swagger"&gt;https://waha.devlike.pro/swagger&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Tables of Contents&lt;/h1&gt; 
&lt;!-- toc --&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#quick-start"&gt;Quick start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#requirements"&gt;Requirements&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#send-your-first-message"&gt;Send your first message&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#1-download-image"&gt;1. Download image&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#2-run-whatsapp-http-api"&gt;2. Run WhatsApp HTTP API&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#3-start-a-new-session"&gt;3. Start a new session&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#4-get-and-scan-qr"&gt;4. Get and scan QR&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#5-get-the-screenshot"&gt;5. Get the screenshot&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#6-send-a-text-message"&gt;6. Send a text message&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#what-is-next"&gt;What is next?&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#development"&gt;Development&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/#start-the-project"&gt;Start the project&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- tocstop --&gt; 
&lt;h1&gt;Quick start&lt;/h1&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;Only thing that you must have - installed docker. Please follow the original instruction &lt;a href="https://docs.docker.com/get-docker/" target="_blank" rel="noopener"&gt;how to install docker -&amp;gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you are ready - come back and follows the below steps to send the first text message to WhatsApp via HTTP API!&lt;/p&gt; 
&lt;h2&gt;Send your first message&lt;/h2&gt; 
&lt;p&gt;Let's go over steps that allow you to send your first text message via WhatsApp HTTP API!&lt;/p&gt; 
&lt;h3&gt;1. Download image&lt;/h3&gt; 
&lt;p&gt;Assuming you have installed &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt;, let's download the image.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull devlikeapro/waha
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker login -u devlikeapro -p {KEY}
docker pull devlikeapro/waha-plus
docker logout
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Read more about how to get &lt;code&gt;PASSWORD&lt;/code&gt; for &lt;a href="https://waha.devlike.pro/docs/how-to/waha-plus/"&gt;&lt;strong&gt;â• WAHA Plus&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;2. Run WhatsApp HTTP API&lt;/h3&gt; 
&lt;p&gt;Run WhatsApp HTTP API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -it --rm -p 3000:3000/tcp --name waha devlikeapro/waha

# It prints logs and the last line must be
# WhatsApp HTTP API is running on: http://[::1]:3000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open the link in your browser &lt;a href="http://localhost:3000/"&gt;http://localhost:3000/&lt;/a&gt; and you'll see API documentation (Swagger).&lt;/p&gt; 
&lt;h3&gt;3. Start a new session&lt;/h3&gt; 
&lt;p&gt;To start a new session you should have your mobile phone with installed WhatsApp application close to you.&lt;/p&gt; 
&lt;p&gt;Please go and read how what we'll need to a bit later: &lt;a href="https://faq.whatsapp.com/381777293328336/?helpref=hc_fnav" target="_blank"&gt; How to log in - the instruction on WhatsApp site &lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;When your ready - find &lt;code&gt;POST /api/sessions&lt;/code&gt;, click on &lt;strong&gt;Try it out&lt;/strong&gt;, then &lt;strong&gt;Execute&lt;/strong&gt; a bit below.&lt;/p&gt; 
&lt;p&gt;The example payload:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "name": "default"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;By using the request with &lt;code&gt;name&lt;/code&gt; values you can start multiple session (WhatsApp accounts) inside the single docker container in Plus&lt;/p&gt; 
&lt;h3&gt;4. Get and scan QR&lt;/h3&gt; 
&lt;p&gt;Find &lt;code&gt;GET /api/screenshot&lt;/code&gt; and execute it, it shows you QR code.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Scan the QR with your cell phone's WhatsApp app.&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;5. Get the screenshot&lt;/h3&gt; 
&lt;p&gt;Execute &lt;code&gt;GET /api/screenshot&lt;/code&gt; after a few seconds after scanning the QR - it'll show you the screenshot of you Whatsapp instance. If you can get the actual screenshot - then you're ready to start sending messages!&lt;/p&gt; 
&lt;h3&gt;6. Send a text message&lt;/h3&gt; 
&lt;p&gt;Let's send a text message - find &lt;code&gt;POST /api/sendText&lt;/code&gt; in &lt;a href="http://localhost:3000/"&gt;swagger&lt;/a&gt; and change &lt;code&gt;chatId&lt;/code&gt; this way: use a phone international phone number without &lt;code&gt;+&lt;/code&gt; symbol and add &lt;code&gt;@c.us&lt;/code&gt; at the end.&lt;/p&gt; 
&lt;p&gt;For phone number &lt;code&gt;12132132131&lt;/code&gt; the &lt;code&gt;chatId&lt;/code&gt; is &lt;code&gt;12132132131@c.us&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;The example payload:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "chatId": "12132132130@c.us",
  "text": "Hi there!",
  "session": "default"
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Also, you can use &lt;code&gt;curl&lt;/code&gt; and send POST request like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Phone without +
export PHONE=12132132130
curl -d "{\"chatId\": \"${PHONE}@c.us\", \"text\": \"Hello from WhatsApp HTTP API\" }" -H "Content-Type: application/json" -X POST http://localhost:3000/api/sendText
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;What is next?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://waha.devlike.pro/docs/overview/introduction/"&gt;Go and read the full documentation!&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Development&lt;/h1&gt; 
&lt;h2&gt;Start the project&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Clone the repository&lt;/li&gt; 
 &lt;li&gt;Make sure you're using node&amp;gt;=22 (check &lt;a href="https://raw.githubusercontent.com/devlikeapro/waha/core/.nvmrc"&gt;.nvmrc&lt;/a&gt; to get the version)&lt;/li&gt; 
 &lt;li&gt;Run the following commands:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies
yarn install
# Fetch and compile proto files
yarn gows:proto
# Run
yarn start
# open http://localhost:3000
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>github/docs</title>
      <link>https://github.com/github/docs</link>
      <description>&lt;p&gt;The open-source repo for docs.github.com&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;GitHub Docs 
 &lt;!-- omit in toc --&gt;&lt;/h1&gt; 
&lt;p&gt;Welcome to GitHub Docs! GitHubâ€™s documentation is open source, meaning anyone from inside or outside the company can contribute. For full contributing guidelines, visit our &lt;a href="https://docs.github.com/en/contributing"&gt;contributing guide&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Quick links by contributor type&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hubbers (GitHub employees):&lt;/strong&gt; See &lt;a href="https://github.com/github/docs-content/raw/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; in the &lt;code&gt;docs-content&lt;/code&gt; repository for GitHub-specific processes.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Open source contributors:&lt;/strong&gt; See &lt;a href="https://github.com/github/docs/raw/main/.github/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; in the &lt;code&gt;docs&lt;/code&gt; repository for a quick-start summary.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How we sync changes across Docs repositories&lt;/h2&gt; 
&lt;p&gt;There are two GitHub Docs repositories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;github/docs&lt;/code&gt;&lt;/strong&gt; (public): Open to external contributions&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;code&gt;github/docs-internal&lt;/code&gt;&lt;/strong&gt; (private): For GitHub employee contributions.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The two repositories sync frequently. Content changes in one are reflected in the other. Hubbers might prefer to post in &lt;code&gt;docs&lt;/code&gt; when working with a customer, but &lt;code&gt;docs&lt;/code&gt; has limitations on the types of contributions it accepts to safeguard the site and our workflows. Internal contributions should usually go to &lt;code&gt;docs-internal&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The &lt;code&gt;docs&lt;/code&gt; repository accepts contributions to content files (&lt;code&gt;.md&lt;/code&gt; files in &lt;code&gt;/content&lt;/code&gt; and select &lt;code&gt;/data&lt;/code&gt; sections like reusables only). Infrastructure files, workflows, and site-building code are not open for external modification.&lt;/p&gt; 
&lt;h2&gt;New to contributing&lt;/h2&gt; 
&lt;p&gt;Here are some resources to help you get started with open source contributions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.github.com/en/get-started/exploring-projects-on-github/finding-ways-to-contribute-to-open-source-on-github"&gt;Finding ways to contribute to open source on GitHub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.github.com/en/get-started/git-basics/set-up-git"&gt;Set up Git&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.github.com/en/get-started/using-github/github-flow"&gt;GitHub flow&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.github.com/en/github/collaborating-with-pull-requests"&gt;Collaborating with pull requests&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>EvolutionAPI/evolution-api</title>
      <link>https://github.com/EvolutionAPI/evolution-api</link>
      <description>&lt;p&gt;Evolution API is an open-source WhatsApp integration API&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt;Evolution Api&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://hub.docker.com/r/evoapicloud/evolution-api"&gt;&lt;img src="https://img.shields.io/badge/Docker-image-blue" alt="Docker Image" /&gt;&lt;/a&gt; &lt;a href="https://evolution-api.com/whatsapp"&gt;&lt;img src="https://img.shields.io/badge/Group-WhatsApp-%2322BC18" alt="Whatsapp Group" /&gt;&lt;/a&gt; &lt;a href="https://evolution-api.com/discord"&gt;&lt;img src="https://img.shields.io/badge/Discord-Community-blue" alt="Discord Community" /&gt;&lt;/a&gt; &lt;a href="https://evolution-api.com/postman"&gt;&lt;img src="https://img.shields.io/badge/Postman-Collection-orange" alt="Postman Collection" /&gt;&lt;/a&gt; &lt;a href="https://doc.evolution-api.com"&gt;&lt;img src="https://img.shields.io/badge/Documentation-Official-green" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://evolutionapi.canny.io/feature-requests"&gt;&lt;img src="https://img.shields.io/badge/Feature-Requests-purple" alt="Feature Requests" /&gt;&lt;/a&gt; &lt;a href="https://evolutionapi.canny.io/feature-requests"&gt;&lt;img src="https://img.shields.io/badge/Roadmap-Community-blue" alt="Roadmap" /&gt;&lt;/a&gt; &lt;a href="https://evolutionapi.canny.io/changelog"&gt;&lt;img src="https://img.shields.io/badge/Changelog-Updates-green" alt="Changelog" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/EvolutionAPI/evolution-api/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-Apache--2.0-blue" alt="License" /&gt;&lt;/a&gt; &lt;a href="https://app.picpay.com/user/davidsongomes1998"&gt;&lt;img src="https://img.shields.io/badge/Donation-picpay-green" alt="Support" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/EvolutionAPI"&gt;&lt;img src="https://img.shields.io/badge/Github-sponsor-orange" alt="Sponsors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;div align="center"&gt;
 &lt;img src="https://raw.githubusercontent.com/EvolutionAPI/evolution-api/main/public/images/cover.png" /&gt;
&lt;/div&gt; 
&lt;h2&gt;Evolution API&lt;/h2&gt; 
&lt;p&gt;Evolution API began as a WhatsApp controller API based on &lt;a href="https://github.com/code-chat-br/whatsapp-api"&gt;CodeChat&lt;/a&gt;, which in turn implemented the &lt;a href="https://github.com/WhiskeySockets/Baileys"&gt;Baileys&lt;/a&gt; library. While originally focused on WhatsApp, Evolution API has grown into a comprehensive platform supporting multiple messaging services and integrations. We continue to acknowledge CodeChat for laying the groundwork.&lt;/p&gt; 
&lt;p&gt;Today, Evolution API is not limited to WhatsApp. It integrates with various platforms such as Typebot, Chatwoot, Dify, and OpenAI, offering a broad array of functionalities beyond messaging. Evolution API supports both the Baileys-based WhatsApp API and the official WhatsApp Business API, with upcoming support for Instagram and Messenger.&lt;/p&gt; 
&lt;h2&gt;Looking for a Lightweight Version?&lt;/h2&gt; 
&lt;p&gt;For those who need a more streamlined and performance-optimized version, check out &lt;a href="https://github.com/EvolutionAPI/evolution-api-lite"&gt;Evolution API Lite&lt;/a&gt;. It's designed specifically for microservices, focusing solely on connectivity without integrations or audio conversion features. Ideal for environments that prioritize simplicity and efficiency.&lt;/p&gt; 
&lt;h2&gt;Types of Connections&lt;/h2&gt; 
&lt;p&gt;Evolution API supports multiple types of connections to WhatsApp, enabling flexible and powerful integration options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;WhatsApp API - Baileys&lt;/em&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;A free API based on WhatsApp Web, leveraging the &lt;a href="https://github.com/WhiskeySockets/Baileys"&gt;Baileys library&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;This connection type allows control over WhatsApp Web functionalities through a RESTful API, suitable for multi-service chats, service bots, and other WhatsApp-integrated systems.&lt;/li&gt; 
   &lt;li&gt;Note: This method relies on the web version of WhatsApp and may have limitations compared to official APIs.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;em&gt;WhatsApp Cloud API&lt;/em&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;The official API provided by Meta (formerly Facebook).&lt;/li&gt; 
   &lt;li&gt;This connection type offers a robust and reliable solution designed for businesses needing higher volumes of messaging and better integration support.&lt;/li&gt; 
   &lt;li&gt;The Cloud API supports features such as end-to-end encryption, advanced analytics, and more comprehensive customer service tools.&lt;/li&gt; 
   &lt;li&gt;To use this API, you must comply with Meta's policies and potentially pay for usage based on message volume and other factors.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Integrations&lt;/h2&gt; 
&lt;p&gt;Evolution API supports various integrations to enhance its functionality. Below is a list of available integrations and their uses:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://typebot.io/"&gt;Typebot&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Build conversational bots using Typebot, integrated directly into Evolution with trigger management.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.chatwoot.com/"&gt;Chatwoot&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Direct integration with Chatwoot for handling customer service for your business.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Receive events from the Evolution API via RabbitMQ.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Receive events from the Evolution API via Apache Kafka for real-time event streaming and processing.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://aws.amazon.com/pt/sqs/"&gt;Amazon SQS&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Receive events from the Evolution API via Amazon SQS.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://socket.io/"&gt;Socket.io&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Receive events from the Evolution API via WebSocket.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://dify.ai/"&gt;Dify&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Integrate your Evolution API directly with Dify AI for seamless trigger management and multiple agents.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Integrate your Evolution API with OpenAI for AI capabilities, including audio-to-text conversion, available across all Evolution integrations.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Amazon S3 / Minio:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Store media files received in &lt;a href="https://aws.amazon.com/pt/s3/"&gt;Amazon S3&lt;/a&gt; or &lt;a href="https://min.io/"&gt;Minio&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community &amp;amp; Feedback&lt;/h2&gt; 
&lt;p&gt;We value community input and feedback to continuously improve Evolution API:&lt;/p&gt; 
&lt;h3&gt;ğŸš€ Feature Requests &amp;amp; Roadmap&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://evolutionapi.canny.io/feature-requests"&gt;Feature Requests&lt;/a&gt;&lt;/strong&gt;: Submit new feature ideas and vote on community proposals&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://evolutionapi.canny.io/feature-requests"&gt;Roadmap&lt;/a&gt;&lt;/strong&gt;: View planned features and development progress&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://evolutionapi.canny.io/changelog"&gt;Changelog&lt;/a&gt;&lt;/strong&gt;: Stay updated with the latest releases and improvements&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ’¬ Community Support&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://evolution-api.com/whatsapp"&gt;WhatsApp Group&lt;/a&gt;&lt;/strong&gt;: Join our community for support and discussions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://evolution-api.com/discord"&gt;Discord Community&lt;/a&gt;&lt;/strong&gt;: Real-time chat with developers and users&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/EvolutionAPI/evolution-api/issues"&gt;GitHub Issues&lt;/a&gt;&lt;/strong&gt;: Report bugs and technical issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;ğŸ”’ Security&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/EvolutionAPI/evolution-api/main/SECURITY.md"&gt;Security Policy&lt;/a&gt;&lt;/strong&gt;: Guidelines for reporting security vulnerabilities&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security Contact&lt;/strong&gt;: &lt;a href="mailto:contato@evolution-api.com"&gt;contato@evolution-api.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Telemetry Notice&lt;/h2&gt; 
&lt;p&gt;To continuously improve our services, we have implemented telemetry that collects data on the routes used, the most accessed routes, and the version of the API in use. We would like to assure you that no sensitive or personal data is collected during this process. The telemetry helps us identify improvements and provide a better experience for users.&lt;/p&gt; 
&lt;h2&gt;Evolution Support Premium&lt;/h2&gt; 
&lt;p&gt;Join our Evolution Pro community for expert support and a weekly call to answer questions. Visit the link below to learn more and subscribe:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://evolution-api.com/suporte-pro"&gt;Click here to learn more&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Donate to the project.&lt;/h1&gt; 
&lt;h4&gt;Github Sponsors&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/EvolutionAPI"&gt;https://github.com/sponsors/EvolutionAPI&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Content Creator Partners&lt;/h1&gt; 
&lt;p&gt;We are proud to collaborate with the following content creators who have contributed valuable insights and tutorials about Evolution API:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@promovaweb"&gt;Promovaweb&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@canalsandeco"&gt;Sandeco&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@ComunidadeZDG"&gt;Comunidade ZDG&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@FrancisMNO"&gt;Francis MNO&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtube.com/@pablocabral"&gt;Pablo Cabral&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@xpopdigital"&gt;XPop Digital&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@costarwagnerdev"&gt;Costar Wagner Dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtube.com/@dantetesta_"&gt;Dante Testa&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtube.com/channel/UCnYGZIE2riiLqaN9sI6riig"&gt;RubÃ©n Salazar&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EvolutionAPI/evolution-api/main/youtube.com/OrionDesign_Oficial"&gt;OrionDesign&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/EvolutionAPI/evolution-api/main/youtube.com/@impa365_ofc"&gt;IMPA 365&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtube.com/@comunidadehubconnect"&gt;Comunidade Hub Connect&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/channel/UCG7DjUmAxtYyURlOGAIryNQ?view_as=subscriber"&gt;dSantana AutomaÃ§Ãµes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@edisonmartinsmkt"&gt;Edison Martins&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@astraonlineweb"&gt;Astra Online&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/@sevenautomacoes"&gt;MKT Seven AutomaÃ§Ãµes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/vamosautomatizar"&gt;Vamos automatizar&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Evolution API is licensed under the Apache License 2.0, with the following additional conditions:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;LOGO and copyright information&lt;/strong&gt;: In the process of using Evolution API's frontend components, you may not remove or modify the LOGO or copyright information in the Evolution API console or applications. This restriction is inapplicable to uses of Evolution API that do not involve its frontend components.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Usage Notification Requirement&lt;/strong&gt;: If Evolution API is used as part of any project, including closed-source systems (e.g., proprietary software), the user is required to display a clear notification within the system that Evolution API is being utilized. This notification should be visible to system administrators and accessible from the system's documentation or settings page. Failure to comply with this requirement may result in the necessity for a commercial license, as determined by the producer.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Please contact &lt;a href="mailto:contato@evolution-api.com"&gt;contato@evolution-api.com&lt;/a&gt; to inquire about licensing matters.&lt;/p&gt; 
&lt;p&gt;Apart from the specific conditions mentioned above, all other rights and restrictions follow the Apache License 2.0. Detailed information about the Apache License 2.0 can be found at &lt;a href="http://www.apache.org/licenses/LICENSE-2.0"&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Â© 2025 Evolution API&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>clash-verge-rev/clash-verge-rev</title>
      <link>https://github.com/clash-verge-rev/clash-verge-rev</link>
      <description>&lt;p&gt;A modern GUI client based on Tauri, designed to run in Windows, macOS and Linux for tailored proxy experience&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;img src="https://raw.githubusercontent.com/clash-verge-rev/clash-verge-rev/dev/src-tauri/icons/icon.png" alt="Clash" width="128" /&gt; &lt;br /&gt; Continuation of &lt;a href="https://github.com/zzzgydi/clash-verge"&gt;Clash Verge&lt;/a&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;h3 align="center"&gt; A Clash Meta GUI based on &lt;a href="https://github.com/tauri-apps/tauri"&gt;Tauri&lt;/a&gt;. &lt;/h3&gt; 
&lt;h2&gt;Preview&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dark&lt;/th&gt; 
   &lt;th&gt;Light&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/clash-verge-rev/clash-verge-rev/dev/docs/preview_dark.png" alt="é¢„è§ˆ" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/clash-verge-rev/clash-verge-rev/dev/docs/preview_light.png" alt="é¢„è§ˆ" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;p&gt;è¯·åˆ°å‘å¸ƒé¡µé¢ä¸‹è½½å¯¹åº”çš„å®‰è£…åŒ…ï¼š&lt;a href="https://github.com/clash-verge-rev/clash-verge-rev/releases"&gt;Release page&lt;/a&gt;&lt;br /&gt; Go to the &lt;a href="https://github.com/clash-verge-rev/clash-verge-rev/releases"&gt;Release page&lt;/a&gt; to download the corresponding installation package&lt;br /&gt; Supports Windows (x64/x86), Linux (x64/arm64) and macOS 10.15+ (intel/apple).&lt;/p&gt; 
&lt;h4&gt;æˆ‘åº”å½“æ€æ ·é€‰æ‹©å‘è¡Œç‰ˆ&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;ç‰ˆæœ¬&lt;/th&gt; 
   &lt;th align="left"&gt;ç‰¹å¾&lt;/th&gt; 
   &lt;th align="left"&gt;é“¾æ¥&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Stable&lt;/td&gt; 
   &lt;td align="left"&gt;æ­£å¼ç‰ˆï¼Œé«˜å¯é æ€§ï¼Œé€‚åˆæ—¥å¸¸ä½¿ç”¨ã€‚&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/clash-verge-rev/clash-verge-rev/releases"&gt;Release&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Alpha(åºŸå¼ƒ)&lt;/td&gt; 
   &lt;td align="left"&gt;æµ‹è¯•å‘å¸ƒæµç¨‹ã€‚&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/clash-verge-rev/clash-verge-rev/releases/tag/alpha"&gt;Alpha&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;AutoBuild&lt;/td&gt; 
   &lt;td align="left"&gt;æ»šåŠ¨æ›´æ–°ç‰ˆï¼Œé€‚åˆæµ‹è¯•åé¦ˆï¼Œå¯èƒ½å­˜åœ¨ç¼ºé™·ã€‚&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/clash-verge-rev/clash-verge-rev/releases/tag/autobuild"&gt;AutoBuild&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h4&gt;å®‰è£…è¯´æ˜å’Œå¸¸è§é—®é¢˜ï¼Œè¯·åˆ° &lt;a href="https://clash-verge-rev.github.io/"&gt;æ–‡æ¡£é¡µ&lt;/a&gt; æŸ¥çœ‹&lt;/h4&gt; 
&lt;hr /&gt; 
&lt;h3&gt;TG é¢‘é“: &lt;a href="https://t.me/clash_verge_re"&gt;@clash_verge_rev&lt;/a&gt;&lt;/h3&gt; 
&lt;h2&gt;Promotion&lt;/h2&gt; 
&lt;h4&gt;&lt;a href="https://verge.dginv.click/#/register?code=oaxsAGo6"&gt;ç‹—ç‹—åŠ é€Ÿ â€”â€” æŠ€æœ¯æµæœºåœº Doggygo VPN&lt;/a&gt;&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;é«˜æ€§èƒ½æµ·å¤–æœºåœºï¼Œå…è´¹è¯•ç”¨ï¼Œä¼˜æƒ å¥—é¤ï¼Œè§£é”æµåª’ä½“ï¼Œå…¨çƒé¦–å®¶æ”¯æŒ Hysteria åè®®ã€‚&lt;/li&gt; 
 &lt;li&gt;ä½¿ç”¨ Clash Verge ä¸“å±é‚€è¯·é“¾æ¥æ³¨å†Œé€ 3 å¤©ï¼Œæ¯å¤© 1G æµé‡å…è´¹è¯•ç”¨ï¼š&lt;a href="https://verge.dginv.click/#/register?code=oaxsAGo6"&gt;ç‚¹æ­¤æ³¨å†Œ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Clash Verge ä¸“å± 8 æŠ˜ä¼˜æƒ ç : verge20 (ä»…æœ‰ 500 ä»½)&lt;/li&gt; 
 &lt;li&gt;ä¼˜æƒ å¥—é¤æ¯æœˆä»…éœ€ 15.8 å…ƒï¼Œ160G æµé‡ï¼Œå¹´ä»˜ 8 æŠ˜&lt;/li&gt; 
 &lt;li&gt;æµ·å¤–å›¢é˜Ÿï¼Œæ— è·‘è·¯é£é™©ï¼Œé«˜è¾¾ 50% è¿”ä½£&lt;/li&gt; 
 &lt;li&gt;é›†ç¾¤è´Ÿè½½å‡è¡¡è®¾è®¡ï¼Œé«˜é€Ÿä¸“çº¿(å…¼å®¹è€å®¢æˆ·ç«¯)ï¼Œæä½å»¶è¿Ÿï¼Œæ— è§†æ™šé«˜å³°ï¼Œ4K ç§’å¼€&lt;/li&gt; 
 &lt;li&gt;å…¨çƒé¦–å®¶ Hysteria åè®®æœºåœºï¼Œç°å·²ä¸Šçº¿æ›´å¿«çš„ &lt;code&gt;Hysteria2&lt;/code&gt; åè®®(Clash Verge å®¢æˆ·ç«¯æœ€ä½³æ­é…)&lt;/li&gt; 
 &lt;li&gt;è§£é”æµåª’ä½“åŠ ChatGPT&lt;/li&gt; 
 &lt;li&gt;å®˜ç½‘ï¼š&lt;a href="https://verge.dginv.click/#/register?code=oaxsAGo6"&gt;https://ç‹—ç‹—åŠ é€Ÿ.com&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;æœ¬é¡¹ç›®çš„æ„å»ºä¸å‘å¸ƒç¯å¢ƒç”± &lt;a href="https://yxvm.com/aff.php?aff=827"&gt;YXVM&lt;/a&gt; ç‹¬ç«‹æœåŠ¡å™¨å…¨åŠ›æ”¯æŒï¼Œ&lt;/h4&gt; 
&lt;p&gt;æ„Ÿè°¢æä¾› ç‹¬äº«èµ„æºã€é«˜æ€§èƒ½ã€é«˜é€Ÿç½‘ç»œ çš„å¼ºå¤§åç«¯ç¯å¢ƒã€‚å¦‚æœä½ è§‰å¾—ä¸‹è½½å¤Ÿå¿«ã€ä½¿ç”¨å¤Ÿçˆ½ï¼Œé‚£æ˜¯å› ä¸ºæˆ‘ä»¬ç”¨äº†å¥½æœåŠ¡å™¨ï¼&lt;/p&gt; 
&lt;p&gt;ğŸ§© YXVM ç‹¬ç«‹æœåŠ¡å™¨ä¼˜åŠ¿ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸŒ ä¼˜è´¨ç½‘ç»œï¼Œå›ç¨‹ä¼˜åŒ–ï¼Œä¸‹è½½å¿«åˆ°é£èµ·&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ ç‰©ç†æœºç‹¬äº«èµ„æºï¼ŒéVPSå¯æ¯”ï¼Œæ€§èƒ½æ‹‰æ»¡&lt;/li&gt; 
 &lt;li&gt;ğŸ§  é€‚åˆè·‘ä»£ç†ã€æ­å»º WEB ç«™ CDN ç«™ ã€æ CI/CD æˆ–ä»»ä½•é«˜è´Ÿè½½åº”ç”¨&lt;/li&gt; 
 &lt;li&gt;ğŸ’¡ æ”¯æŒå³å¼€å³ç”¨ï¼Œå¤šæœºæˆ¿é€‰æ‹©ï¼ŒCN2 / IEPL å¯é€‰&lt;/li&gt; 
 &lt;li&gt;ğŸ“¦ æœ¬é¡¹ç›®ä½¿ç”¨é…ç½®å·²åœ¨å”®ï¼Œæ¬¢è¿åŒæ¬¾å…¥æ‰‹ï¼&lt;/li&gt; 
 &lt;li&gt;ğŸ¯ æƒ³è¦åŒæ¬¾æ„å»ºä½“éªŒï¼Ÿ&lt;a href="https://yxvm.com/aff.php?aff=827"&gt;ç«‹å³ä¸‹å• YXVM ç‹¬ç«‹æœåŠ¡å™¨ï¼&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;åŸºäºæ€§èƒ½å¼ºåŠ²çš„ Rust å’Œ Tauri 2 æ¡†æ¶&lt;/li&gt; 
 &lt;li&gt;å†…ç½®&lt;a href="https://github.com/MetaCubeX/mihomo"&gt;Clash.Meta(mihomo)&lt;/a&gt;å†…æ ¸ï¼Œå¹¶æ”¯æŒåˆ‡æ¢ &lt;code&gt;Alpha&lt;/code&gt; ç‰ˆæœ¬å†…æ ¸ã€‚&lt;/li&gt; 
 &lt;li&gt;ç®€æ´ç¾è§‚çš„ç”¨æˆ·ç•Œé¢ï¼Œæ”¯æŒè‡ªå®šä¹‰ä¸»é¢˜é¢œè‰²ã€ä»£ç†ç»„/æ‰˜ç›˜å›¾æ ‡ä»¥åŠ &lt;code&gt;CSS Injection&lt;/code&gt;ã€‚&lt;/li&gt; 
 &lt;li&gt;é…ç½®æ–‡ä»¶ç®¡ç†å’Œå¢å¼ºï¼ˆMerge å’Œ Scriptï¼‰ï¼Œé…ç½®æ–‡ä»¶è¯­æ³•æç¤ºã€‚&lt;/li&gt; 
 &lt;li&gt;ç³»ç»Ÿä»£ç†å’Œå®ˆå«ã€&lt;code&gt;TUN(è™šæ‹Ÿç½‘å¡)&lt;/code&gt; æ¨¡å¼ã€‚&lt;/li&gt; 
 &lt;li&gt;å¯è§†åŒ–èŠ‚ç‚¹å’Œè§„åˆ™ç¼–è¾‘&lt;/li&gt; 
 &lt;li&gt;WebDav é…ç½®å¤‡ä»½å’ŒåŒæ­¥&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;p&gt;Refer to &lt;a href="https://clash-verge-rev.github.io/faq/windows.html"&gt;Doc FAQ Page&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Donation&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/clash-verge-rev"&gt;æåŠ©Clash Verge Revçš„å¼€å‘&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/clash-verge-rev/clash-verge-rev/dev/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;p&gt;To run the development server, execute the following commands after all prerequisites for &lt;strong&gt;Tauri&lt;/strong&gt; are installed:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;pnpm i
pnpm run prebuild
pnpm dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributions&lt;/h2&gt; 
&lt;p&gt;Issue and PR welcome!&lt;/p&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;Clash Verge rev was based on or inspired by these projects and so on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/zzzgydi/clash-verge"&gt;zzzgydi/clash-verge&lt;/a&gt;: A Clash GUI based on tauri. Supports Windows, macOS and Linux.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tauri-apps/tauri"&gt;tauri-apps/tauri&lt;/a&gt;: Build smaller, faster, and more secure desktop applications with a web frontend.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Dreamacro/clash"&gt;Dreamacro/clash&lt;/a&gt;: A rule-based tunnel in Go.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/MetaCubeX/mihomo"&gt;MetaCubeX/mihomo&lt;/a&gt;: A rule-based tunnel in Go.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Fndroid/clash_for_windows_pkg"&gt;Fndroid/clash_for_windows_pkg&lt;/a&gt;: A Windows/macOS GUI based on Clash.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/vitejs/vite"&gt;vitejs/vite&lt;/a&gt;: Next generation frontend tooling. It's fast!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;GPL-3.0 License. See &lt;a href="https://raw.githubusercontent.com/clash-verge-rev/clash-verge-rev/dev/LICENSE"&gt;License here&lt;/a&gt; for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TibixDev/winboat</title>
      <link>https://github.com/TibixDev/winboat</link>
      <description>&lt;p&gt;Run Windows apps on ğŸ§ Linux with âœ¨ seamless integration&lt;/p&gt;&lt;hr&gt;&lt;div align="left"&gt; 
 &lt;table&gt; 
  &lt;tbody&gt;
   &lt;tr&gt; 
    &lt;td&gt; &lt;img src="https://raw.githubusercontent.com/TibixDev/winboat/main/gh-assets/winboat_logo.svg?sanitize=true" alt="WinBoat Logo" width="150" /&gt; &lt;/td&gt; 
    &lt;td&gt; &lt;h1 style="color: #7C86FF; margin: 0; font-size: 32px;"&gt;WinBoat&lt;/h1&gt; &lt;p style="color: oklch(90% 0 0); font-size: 14px; margin: 5px 0;"&gt;Windows for Penguins.&lt;br /&gt; Run Windows apps on ğŸ§ Linux with âœ¨ seamless integration&lt;/p&gt; &lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt;
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/TibixDev/winboat/main/gh-assets/features/feat_dash.png" alt="WinBoat Dashboard" width="45%" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/TibixDev/winboat/main/gh-assets/features/feat_apps.png" alt="WinBoat Apps" width="45%" /&gt; 
 &lt;img src="https://raw.githubusercontent.com/TibixDev/winboat/main/gh-assets/features/feat_native.png" alt="Native Windows" width="45%" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;âš ï¸ Work in Progress âš ï¸&lt;/h2&gt; 
&lt;p&gt;WinBoat is currently in beta, so expect to occasionally run into hiccups and bugs. You should be comfortable with some level of troubleshooting if you decide to try it, however we encourage you to give it a shot anyway.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¨ Elegant Interface&lt;/strong&gt;: Sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“¦ Automated Installs&lt;/strong&gt;: Simple installation process through our interface - pick your preferences &amp;amp; specs and let us handle the rest&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸš€ Run Any App&lt;/strong&gt;: If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications as native OS-level windows in your Linux environment&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ–¥ï¸ Full Windows Desktop&lt;/strong&gt;: Access the complete Windows desktop experience when you need it, or run individual apps seamlessly integrated into your Linux workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“ Filesystem Integration&lt;/strong&gt;: Your home directory is mounted in Windows, allowing easy file sharing between the two systems without any hassle&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âœ¨ And many more&lt;/strong&gt;: Smartcard passthrough, resource monitoring, and more features being added regularly&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How Does It Work?&lt;/h2&gt; 
&lt;p&gt;WinBoat is an Electron app which allows you to run Windows apps on Linux using a containerized approach. Windows runs as a VM inside a Docker container, we communicate with it using the &lt;a href="https://github.com/TibixDev/winboat/tree/main/guest_server"&gt;WinBoat Guest Server&lt;/a&gt; to retrieve data we need from Windows. For compositing applications as native OS-level windows, we use FreeRDP together with Windows's RemoteApp protocol.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;Before running WinBoat, ensure your system meets the following requirements:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;RAM&lt;/strong&gt;: At least 4 GB of RAM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CPU&lt;/strong&gt;: At least 2 CPU threads&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt;: At least 32 GB free space on the drive your selected install folder corresponds to&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Virtualization&lt;/strong&gt;: KVM enabled in BIOS/UEFI 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://duckduckgo.com/?t=h_&amp;amp;q=how+to+enable+virtualization+in+%3Cmotherboard+brand%3E+bios&amp;amp;ia=web"&gt;How to enable virtualization&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Required for containerization 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.docker.com/engine/install/"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;âš ï¸ NOTE:&lt;/strong&gt; Docker Desktop is &lt;strong&gt;not&lt;/strong&gt; supported, you will run into issues if you use it&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Compose v2&lt;/strong&gt;: Required for compatibility with docker-compose.yml files 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.docker.com/compose/install/#plugin-linux-only"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker User Group&lt;/strong&gt;: Add your user to the &lt;code&gt;docker&lt;/code&gt; group 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user"&gt;Setup Instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FreeRDP&lt;/strong&gt;: Required for remote desktop connection (Please make sure you have &lt;strong&gt;Version 3.x.x&lt;/strong&gt; with sound support included) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/FreeRDP/FreeRDP/wiki/PreBuilds"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;[OPTIONAL] &lt;strong&gt;Kernel Modules&lt;/strong&gt;: The &lt;code&gt;iptables&lt;/code&gt; / &lt;code&gt;nftables&lt;/code&gt; and &lt;code&gt;iptable_nat&lt;/code&gt; kernel modules can be loaded for network autodiscovery and better shared filesystem performance, but this is not obligatory in newer versions of WinBoat 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://rentry.org/rmfq2e5e"&gt;Module loading instructions&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Downloading&lt;/h2&gt; 
&lt;p&gt;You can download the latest Linux builds under the &lt;a href="https://github.com/TibixDev/winboat/releases"&gt;Releases&lt;/a&gt; tab. We currently offer four variants:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AppImage:&lt;/strong&gt; A popular &amp;amp; portable app format which should run fine on most distributions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unpacked:&lt;/strong&gt; The raw unpacked files, simply run the executable (&lt;code&gt;linux-unpacked/winboat&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;.deb:&lt;/strong&gt; The intended format for Debian based distributions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;.rpm:&lt;/strong&gt; The intended format for Fedora based distributions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Known Issues About Container Runtimes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Podman is &lt;strong&gt;unsupported&lt;/strong&gt; for now&lt;/li&gt; 
 &lt;li&gt;Docker Desktop is &lt;strong&gt;unsupported&lt;/strong&gt; for now&lt;/li&gt; 
 &lt;li&gt;Distros that emulate Docker through a Podman socket are &lt;strong&gt;unsupported&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;Any rootless containerization solution is currently &lt;strong&gt;unsupported&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Building WinBoat&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;For building you need to have NodeJS and Go installed on your system&lt;/li&gt; 
 &lt;li&gt;Clone the repo (&lt;code&gt;git clone https://github.com/TibixDev/WinBoat&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Install the dependencies (&lt;code&gt;npm i&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Build the app and the guest server using &lt;code&gt;npm run build:linux-gs&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;You can now find the built app under &lt;code&gt;dist&lt;/code&gt; with an AppImage and an Unpacked variant&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Running WinBoat in development mode&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Make sure you meet the &lt;a href="https://raw.githubusercontent.com/TibixDev/winboat/main/#prerequisites"&gt;prerequisites&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Additionally, for development you need to have NodeJS and Go installed on your system&lt;/li&gt; 
 &lt;li&gt;Clone the repo (&lt;code&gt;git clone https://github.com/TibixDev/WinBoat&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Install the dependencies (&lt;code&gt;npm i&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Build the guest server (&lt;code&gt;npm run build-guest-server&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Run the app (&lt;code&gt;npm run dev&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Whether it's bug fixes, feature improvements, or documentation updates, we appreciate your help making WinBoat better.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Please note&lt;/strong&gt;: We maintain a focus on technical contributions only. Pull requests containing political/sexual content, or other sensitive/controversial topics will not be accepted. Let's keep things focused on making great software! ğŸš€&lt;/p&gt; 
&lt;p&gt;Feel free to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Report bugs and issues&lt;/li&gt; 
 &lt;li&gt;Submit feature requests&lt;/li&gt; 
 &lt;li&gt;Contribute code improvements&lt;/li&gt; 
 &lt;li&gt;Help with documentation&lt;/li&gt; 
 &lt;li&gt;Share feedback and suggestions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Check out our issues page to get started, or feel free to open a new issue if you've found something that needs attention.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;WinBoat is licensed under the &lt;a href="https://github.com/TibixDev/winboat/raw/main/LICENSE"&gt;MIT&lt;/a&gt; license&lt;/p&gt; 
&lt;h2&gt;Inspiration / Alternatives&lt;/h2&gt; 
&lt;p&gt;These past few years some cool projects have surfaced with similar concepts, some of which we've also taken inspirations from.&lt;br /&gt; They're awesome and you should check them out:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/winapps-org/winapps"&gt;WinApps&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/casualsnek/cassowary"&gt;Cassowary&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dockur/windows"&gt;dockur/windows&lt;/a&gt; (ğŸŒŸ Also used in WinBoat)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Socials &amp;amp; Contact&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.winboat.app/"&gt;&lt;img src="https://img.shields.io/badge/Website-winboat.app-blue?style=flat&amp;amp;logo=googlechrome&amp;amp;logoColor=white" alt="Website" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://x.com/winboat_app"&gt;&lt;img src="https://img.shields.io/badge/Twitter-@winboat__app-1DA1F2?style=flat&amp;amp;logo=x&amp;amp;logoColor=white" alt="Twitter" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://fosstodon.org/@winboat"&gt;&lt;img src="https://img.shields.io/badge/Mastodon-@winboat-6364FF?style=flat&amp;amp;logo=mastodon&amp;amp;logoColor=white" alt="Mastodon" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://bsky.app/profile/winboat.app"&gt;&lt;img src="https://img.shields.io/badge/Bluesky-winboat.app-00A8E8?style=flat&amp;amp;logo=bluesky&amp;amp;logoColor=white" alt="Bluesky" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="http://discord.gg/MEwmpWm4tN"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join_Community-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="mailto:staff@winboat.app"&gt;&lt;img src="https://img.shields.io/badge/Email-staff@winboat.app-D14836?style=flat&amp;amp;logo=gmail&amp;amp;logoColor=white" alt="Email" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://deepwiki.com/TibixDev/winboat"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;a href="https://www.star-history.com/#tibixdev/winboat&amp;amp;Date"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=tibixdev/winboat&amp;amp;type=Date&amp;amp;theme=dark" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=tibixdev/winboat&amp;amp;type=Date" /&gt; 
  &lt;img alt="Star History Chart" src="https://api.star-history.com/svg?repos=tibixdev/winboat&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>daytonaio/daytona</title>
      <link>https://github.com/daytonaio/daytona</link>
      <description>&lt;p&gt;Daytona is a Secure and Elastic Infrastructure for Running AI-Generated Code&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.daytona.io/docs"&gt;&lt;img src="https://img.shields.io/github/v/release/daytonaio/docs?label=Docs&amp;amp;color=23cc71" alt="Documentation" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/badge/License-AGPL--3-blue" alt="License" /&gt; &lt;a href="https://goreportcard.com/report/github.com/daytonaio/daytona"&gt;&lt;img src="https://goreportcard.com/badge/github.com/daytonaio/daytona" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/daytonaio/daytona/issues"&gt;&lt;img src="https://img.shields.io/github/issues/daytonaio/daytona" alt="Issues - daytona" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/v/release/daytonaio/daytona" alt="GitHub Release" /&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-white.png" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png" /&gt; 
  &lt;img alt="Daytona logo" src="https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png" width="50%" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;h3 align="center"&gt; Run AI Code. &lt;br /&gt; Secure and Elastic Infrastructure for Running Your AI-Generated Code. &lt;/h3&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.daytona.io/docs"&gt; Documentation &lt;/a&gt;Â· &lt;a href="https://github.com/daytonaio/daytona/issues/new?assignees=&amp;amp;labels=bug&amp;amp;projects=&amp;amp;template=bug_report.md&amp;amp;title=%F0%9F%90%9B+Bug+Report%3A+"&gt; Report Bug &lt;/a&gt;Â· &lt;a href="https://github.com/daytonaio/daytona/issues/new?assignees=&amp;amp;labels=enhancement&amp;amp;projects=&amp;amp;template=feature_request.md&amp;amp;title=%F0%9F%9A%80+Feature%3A+"&gt; Request Feature &lt;/a&gt;Â· &lt;a href="https://go.daytona.io/slack"&gt; Join our Slack &lt;/a&gt;Â· &lt;a href="https://x.com/daytonaio"&gt; Connect on X &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.producthunt.com/posts/daytona-2?embed=true&amp;amp;utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-daytona-2" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=957617&amp;amp;theme=neutral&amp;amp;period=daily&amp;amp;t=1746176740150" alt="Daytona  - Secure and elastic infra for running your AI-generated code. | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;a href="https://www.producthunt.com/posts/daytona-2?embed=true&amp;amp;utm_source=badge-top-post-topic-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-daytona-2" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=957617&amp;amp;theme=neutral&amp;amp;period=monthly&amp;amp;topic_id=237&amp;amp;t=1746176740150" alt="Daytona  - Secure and elastic infra for running your AI-generated code. | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Python SDK&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install daytona
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;TypeScript SDK&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm install @daytonaio/sdk
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightning-Fast Infrastructure&lt;/strong&gt;: Sub-90ms Sandbox creation from code to execution.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Separated &amp;amp; Isolated Runtime&lt;/strong&gt;: Execute AI-generated code with zero risk to your infrastructure.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Massive Parallelization for Concurrent AI Workflows&lt;/strong&gt;: Fork Sandbox filesystem and memory state (Coming soon!)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Programmatic Control&lt;/strong&gt;: File, Git, LSP, and Execute API&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unlimited Persistence&lt;/strong&gt;: Your Sandboxes can live forever&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OCI/Docker Compatibility&lt;/strong&gt;: Use any OCI/Docker image to create a Sandbox&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Create an account at &lt;a href="https://app.daytona.io"&gt;https://app.daytona.io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Generate a &lt;a href="https://app.daytona.io/dashboard/keys"&gt;new API key&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Follow the &lt;a href="https://www.daytona.io/docs/getting-started/"&gt;Getting Started docs&lt;/a&gt; to start using the Daytona SDK&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Creating your first Sandbox&lt;/h2&gt; 
&lt;h3&gt;Python SDK&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-py"&gt;from daytona import Daytona, DaytonaConfig, CreateSandboxBaseParams

# Initialize the Daytona client
daytona = Daytona(DaytonaConfig(api_key="YOUR_API_KEY"))

# Create the Sandbox instance
sandbox = daytona.create(CreateSandboxBaseParams(language="python"))

# Run code securely inside the Sandbox
response = sandbox.process.code_run('print("Sum of 3 and 4 is " + str(3 + 4))')
if response.exit_code != 0:
    print(f"Error running code: {response.exit_code} {response.result}")
else:
    print(response.result)

# Clean up the Sandbox
daytona.delete(sandbox)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Typescript SDK&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-jsx"&gt;import { Daytona } from '@daytonaio/sdk'

async function main() {
  // Initialize the Daytona client
  const daytona = new Daytona({
    apiKey: 'YOUR_API_KEY',
  })

  let sandbox
  try {
    // Create the Sandbox instance
    sandbox = await daytona.create({
      language: 'typescript',
    })
    // Run code securely inside the Sandbox
    const response = await sandbox.process.codeRun('console.log("Sum of 3 and 4 is " + (3 + 4))')
    if (response.exitCode !== 0) {
      console.error('Error running code:', response.exitCode, response.result)
    } else {
      console.log(response.result)
    }
  } catch (error) {
    console.error('Sandbox flow error:', error)
  } finally {
    if (sandbox) await daytona.delete(sandbox)
  }
}

main().catch(console.error)
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Daytona is Open Source under the &lt;a href="https://raw.githubusercontent.com/daytonaio/daytona/main/LICENSE"&gt;GNU AFFERO GENERAL PUBLIC LICENSE&lt;/a&gt;, and is the &lt;a href="https://raw.githubusercontent.com/daytonaio/daytona/main/NOTICE"&gt;copyright of its contributors&lt;/a&gt;. If you would like to contribute to the software, read the Developer Certificate of Origin Version 1.1 (&lt;a href="https://developercertificate.org/"&gt;https://developercertificate.org/&lt;/a&gt;). Afterwards, navigate to the &lt;a href="https://raw.githubusercontent.com/daytonaio/daytona/main/CONTRIBUTING.md"&gt;contributing guide&lt;/a&gt; to get started.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>czlonkowski/n8n-mcp</title>
      <link>https://github.com/czlonkowski/n8n-mcp</link>
      <description>&lt;p&gt;A MCP for Claude Desktop / Claude Code / Windsurf / Cursor to build n8n workflows for you&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;n8n-MCP&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt; &lt;a href="https://github.com/czlonkowski/n8n-mcp"&gt;&lt;img src="https://img.shields.io/github/stars/czlonkowski/n8n-mcp?style=social" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/n8n-mcp"&gt;&lt;img src="https://img.shields.io/npm/v/n8n-mcp.svg?sanitize=true" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/czlonkowski/n8n-mcp"&gt;&lt;img src="https://codecov.io/gh/czlonkowski/n8n-mcp/graph/badge.svg?token=YOUR_TOKEN" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://github.com/czlonkowski/n8n-mcp/actions"&gt;&lt;img src="https://img.shields.io/badge/tests-3336%20passing-brightgreen.svg?sanitize=true" alt="Tests" /&gt;&lt;/a&gt; &lt;a href="https://github.com/n8n-io/n8n"&gt;&lt;img src="https://img.shields.io/badge/n8n-%5E1.115.2-orange.svg?sanitize=true" alt="n8n version" /&gt;&lt;/a&gt; &lt;a href="https://github.com/czlonkowski/n8n-mcp/pkgs/container/n8n-mcp"&gt;&lt;img src="https://img.shields.io/badge/docker-ghcr.io%2Fczlonkowski%2Fn8n--mcp-green.svg?sanitize=true" alt="Docker" /&gt;&lt;/a&gt; &lt;a href="https://railway.com/deploy/n8n-mcp?referralCode=n8n-mcp"&gt;&lt;img src="https://railway.com/button.svg?sanitize=true" alt="Deploy on Railway" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A Model Context Protocol (MCP) server that provides AI assistants with comprehensive access to n8n node documentation, properties, and operations. Deploy in minutes to give Claude and other AI assistants deep knowledge about n8n's 525+ workflow automation nodes.&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;n8n-MCP serves as a bridge between n8n's workflow automation platform and AI models, enabling them to understand and work with n8n nodes effectively. It provides structured access to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ“š &lt;strong&gt;536 n8n nodes&lt;/strong&gt; from both n8n-nodes-base and @n8n/n8n-nodes-langchain&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ &lt;strong&gt;Node properties&lt;/strong&gt; - 99% coverage with detailed schemas&lt;/li&gt; 
 &lt;li&gt;âš¡ &lt;strong&gt;Node operations&lt;/strong&gt; - 63.6% coverage of available actions&lt;/li&gt; 
 &lt;li&gt;ğŸ“„ &lt;strong&gt;Documentation&lt;/strong&gt; - 90% coverage from official n8n docs (including AI nodes)&lt;/li&gt; 
 &lt;li&gt;ğŸ¤– &lt;strong&gt;AI tools&lt;/strong&gt; - 263 AI-capable nodes detected with full documentation&lt;/li&gt; 
 &lt;li&gt;ğŸ’¡ &lt;strong&gt;Real-world examples&lt;/strong&gt; - 2,646 pre-extracted configurations from popular templates&lt;/li&gt; 
 &lt;li&gt;ğŸ¯ &lt;strong&gt;Template library&lt;/strong&gt; - 2,500+ workflow templates with smart filtering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;âš ï¸ Important Safety Warning&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;NEVER edit your production workflows directly with AI!&lt;/strong&gt; Always:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ”„ &lt;strong&gt;Make a copy&lt;/strong&gt; of your workflow before using AI tools&lt;/li&gt; 
 &lt;li&gt;ğŸ§ª &lt;strong&gt;Test in development&lt;/strong&gt; environment first&lt;/li&gt; 
 &lt;li&gt;ğŸ’¾ &lt;strong&gt;Export backups&lt;/strong&gt; of important workflows&lt;/li&gt; 
 &lt;li&gt;âš¡ &lt;strong&gt;Validate changes&lt;/strong&gt; before deploying to production&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;AI results can be unpredictable. Protect your work!&lt;/p&gt; 
&lt;h2&gt;ğŸš€ Quick Start&lt;/h2&gt; 
&lt;p&gt;Get n8n-MCP running in 5 minutes:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/5CccjiLLyaY?si=Z62SBGlw9G34IQnQ&amp;amp;t=343"&gt;&lt;img src="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/thumbnail.png" alt="n8n-mcp Video Quickstart Guide" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Option 1: npx (Fastest - No Installation!) ğŸš€&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; &lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; installed on your system&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run directly with npx (no installation needed!)
npx n8n-mcp
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Add to Claude Desktop config:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Basic configuration (documentation tools only):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "n8n-mcp": {
      "command": "npx",
      "args": ["n8n-mcp"],
      "env": {
        "MCP_MODE": "stdio",
        "LOG_LEVEL": "error",
        "DISABLE_CONSOLE_OUTPUT": "true"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Full configuration (with n8n management tools):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "n8n-mcp": {
      "command": "npx",
      "args": ["n8n-mcp"],
      "env": {
        "MCP_MODE": "stdio",
        "LOG_LEVEL": "error",
        "DISABLE_CONSOLE_OUTPUT": "true",
        "N8N_API_URL": "https://your-n8n-instance.com",
        "N8N_API_KEY": "your-api-key"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: npx will download and run the latest version automatically. The package includes a pre-built database with all n8n node information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Configuration file locations:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: &lt;code&gt;~/Library/Application Support/Claude/claude_desktop_config.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: &lt;code&gt;%APPDATA%\Claude\claude_desktop_config.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: &lt;code&gt;~/.config/Claude/claude_desktop_config.json&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Restart Claude Desktop after updating configuration&lt;/strong&gt; - That's it! ğŸ‰&lt;/p&gt; 
&lt;h3&gt;Option 2: Docker (Easy &amp;amp; Isolated) ğŸ³&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Docker installed on your system&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;ğŸ“¦ Install Docker&lt;/strong&gt; (click to expand)&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;macOS:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Using Homebrew
brew install --cask docker

# Or download from https://www.docker.com/products/docker-desktop/
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Linux (Ubuntu/Debian):&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Update package index
sudo apt-get update

# Install Docker
sudo apt-get install docker.io

# Start Docker service
sudo systemctl start docker
sudo systemctl enable docker

# Add your user to docker group (optional, to run without sudo)
sudo usermod -aG docker $USER
# Log out and back in for this to take effect
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Windows:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Option 1: Using winget (Windows Package Manager)
winget install Docker.DockerDesktop

# Option 2: Using Chocolatey
choco install docker-desktop

# Option 3: Download installer from https://www.docker.com/products/docker-desktop/
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Verify installation:&lt;/strong&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;docker --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Pull the Docker image (~280MB, no n8n dependencies!)
docker pull ghcr.io/czlonkowski/n8n-mcp:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;âš¡ Ultra-optimized:&lt;/strong&gt; Our Docker image is 82% smaller than typical n8n images because it contains NO n8n dependencies - just the runtime MCP server with a pre-built database!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Add to Claude Desktop config:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Basic configuration (documentation tools only):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "n8n-mcp": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "--init",
        "-e", "MCP_MODE=stdio",
        "-e", "LOG_LEVEL=error",
        "-e", "DISABLE_CONSOLE_OUTPUT=true",
        "ghcr.io/czlonkowski/n8n-mcp:latest"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Full configuration (with n8n management tools):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "n8n-mcp": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "--init",
        "-e", "MCP_MODE=stdio",
        "-e", "LOG_LEVEL=error",
        "-e", "DISABLE_CONSOLE_OUTPUT=true",
        "-e", "N8N_API_URL=https://your-n8n-instance.com",
        "-e", "N8N_API_KEY=your-api-key",
        "ghcr.io/czlonkowski/n8n-mcp:latest"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ’¡ Tip: If you're running n8n locally on the same machine (e.g., via Docker), use &lt;a href="http://host.docker.internal:5678"&gt;http://host.docker.internal:5678&lt;/a&gt; as the N8N_API_URL.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The n8n API credentials are optional. Without them, you'll have access to all documentation and validation tools. With them, you'll additionally get workflow management capabilities (create, update, execute workflows).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;ğŸ  Local n8n Instance Configuration&lt;/h3&gt; 
&lt;p&gt;If you're running n8n locally (e.g., &lt;code&gt;http://localhost:5678&lt;/code&gt; or Docker), you need to allow localhost webhooks:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "n8n-mcp": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm", "--init",
        "-e", "MCP_MODE=stdio",
        "-e", "LOG_LEVEL=error",
        "-e", "DISABLE_CONSOLE_OUTPUT=true",
        "-e", "N8N_API_URL=http://host.docker.internal:5678",
        "-e", "N8N_API_KEY=your-api-key",
        "-e", "WEBHOOK_SECURITY_MODE=moderate",
        "ghcr.io/czlonkowski/n8n-mcp:latest"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;âš ï¸ &lt;strong&gt;Important:&lt;/strong&gt; Set &lt;code&gt;WEBHOOK_SECURITY_MODE=moderate&lt;/code&gt; to allow webhooks to your local n8n instance. This is safe for local development while still blocking private networks and cloud metadata.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The &lt;code&gt;-i&lt;/code&gt; flag is required for MCP stdio communication.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ”§ If you encounter any issues with Docker, check our &lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/DOCKER_TROUBLESHOOTING.md"&gt;Docker Troubleshooting Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Configuration file locations:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: &lt;code&gt;~/Library/Application Support/Claude/claude_desktop_config.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: &lt;code&gt;%APPDATA%\Claude\claude_desktop_config.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: &lt;code&gt;~/.config/Claude/claude_desktop_config.json&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Restart Claude Desktop after updating configuration&lt;/strong&gt; - That's it! ğŸ‰&lt;/p&gt; 
&lt;h2&gt;ğŸ” Privacy &amp;amp; Telemetry&lt;/h2&gt; 
&lt;p&gt;n8n-mcp collects anonymous usage statistics to improve the tool. &lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/PRIVACY.md"&gt;View our privacy policy&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Opting Out&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;For npx users:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npx n8n-mcp telemetry disable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;For Docker users:&lt;/strong&gt; Add the following environment variable to your Docker configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"-e", "N8N_MCP_TELEMETRY_DISABLED=true"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example in Claude Desktop config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "n8n-mcp": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "--init",
        "-e", "MCP_MODE=stdio",
        "-e", "LOG_LEVEL=error",
        "-e", "N8N_MCP_TELEMETRY_DISABLED=true",
        "ghcr.io/czlonkowski/n8n-mcp:latest"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;For docker-compose users:&lt;/strong&gt; Set in your environment file or docker-compose.yml:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  N8N_MCP_TELEMETRY_DISABLED: "true"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;âš™ï¸ Database &amp;amp; Memory Configuration&lt;/h2&gt; 
&lt;h3&gt;Database Adapters&lt;/h3&gt; 
&lt;p&gt;n8n-mcp uses SQLite for storing node documentation. Two adapters are available:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;better-sqlite3&lt;/strong&gt; (Default in Docker)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Native C++ bindings for best performance&lt;/li&gt; 
   &lt;li&gt;Direct disk writes (no memory overhead)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Now enabled by default&lt;/strong&gt; in Docker images (v2.20.2+)&lt;/li&gt; 
   &lt;li&gt;Memory usage: ~100-120 MB stable&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;sql.js&lt;/strong&gt; (Fallback)&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Pure JavaScript implementation&lt;/li&gt; 
   &lt;li&gt;In-memory database with periodic saves&lt;/li&gt; 
   &lt;li&gt;Used when better-sqlite3 compilation fails&lt;/li&gt; 
   &lt;li&gt;Memory usage: ~150-200 MB stable&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Memory Optimization (sql.js)&lt;/h3&gt; 
&lt;p&gt;If using sql.js fallback, you can configure the save interval to balance between data safety and memory efficiency:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Environment Variable:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;SQLJS_SAVE_INTERVAL_MS=5000  # Default: 5000ms (5 seconds)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Usage:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Controls how long to wait after database changes before saving to disk&lt;/li&gt; 
 &lt;li&gt;Lower values = more frequent saves = higher memory churn&lt;/li&gt; 
 &lt;li&gt;Higher values = less frequent saves = lower memory usage&lt;/li&gt; 
 &lt;li&gt;Minimum: 100ms&lt;/li&gt; 
 &lt;li&gt;Recommended: 5000-10000ms for production&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Docker Configuration:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "n8n-mcp": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "--init",
        "-e", "SQLJS_SAVE_INTERVAL_MS=10000",
        "ghcr.io/czlonkowski/n8n-mcp:latest"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;docker-compose:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;environment:
  SQLJS_SAVE_INTERVAL_MS: "10000"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Memory Leak Fix (v2.20.2)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Issue #330&lt;/strong&gt; identified a critical memory leak in long-running Docker/Kubernetes deployments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Before:&lt;/strong&gt; 100 MB â†’ 2.2 GB over 72 hours (OOM kills)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;After:&lt;/strong&gt; Stable at 100-200 MB indefinitely&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Fixes Applied:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… Docker images now use better-sqlite3 by default (eliminates leak entirely)&lt;/li&gt; 
 &lt;li&gt;âœ… sql.js fallback optimized (98% reduction in save frequency)&lt;/li&gt; 
 &lt;li&gt;âœ… Removed unnecessary memory allocations (50% reduction per save)&lt;/li&gt; 
 &lt;li&gt;âœ… Configurable save interval via &lt;code&gt;SQLJS_SAVE_INTERVAL_MS&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For Kubernetes deployments with memory limits:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;resources:
  requests:
    memory: 256Mi
  limits:
    memory: 512Mi
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ’– Support This Project&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/sponsors/czlonkowski"&gt; &lt;img src="https://img.shields.io/badge/Sponsor-â¤ï¸-db61a2?style=for-the-badge&amp;amp;logo=github-sponsors" alt="Sponsor n8n-mcp" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;p&gt;&lt;strong&gt;n8n-mcp&lt;/strong&gt; started as a personal tool but now helps tens of thousands of developers automate their workflows efficiently. Maintaining and developing this project competes with my paid work.&lt;/p&gt; 
&lt;p&gt;Your sponsorship helps me:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸš€ Dedicate focused time to new features&lt;/li&gt; 
 &lt;li&gt;ğŸ› Respond quickly to issues&lt;/li&gt; 
 &lt;li&gt;ğŸ“š Keep documentation up-to-date&lt;/li&gt; 
 &lt;li&gt;ğŸ”„ Ensure compatibility with latest n8n releases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Every sponsorship directly translates to hours invested in making n8n-mcp better for everyone. &lt;strong&gt;&lt;a href="https://github.com/sponsors/czlonkowski"&gt;Become a sponsor â†’&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Option 3: Local Installation (For Development)&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; &lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; installed on your system&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Clone and setup
git clone https://github.com/czlonkowski/n8n-mcp.git
cd n8n-mcp
npm install
npm run build
npm run rebuild

# 2. Test it works
npm start
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Add to Claude Desktop config:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Basic configuration (documentation tools only):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "n8n-mcp": {
      "command": "node",
      "args": ["/absolute/path/to/n8n-mcp/dist/mcp/index.js"],
      "env": {
        "MCP_MODE": "stdio",
        "LOG_LEVEL": "error",
        "DISABLE_CONSOLE_OUTPUT": "true"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Full configuration (with n8n management tools):&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "n8n-mcp": {
      "command": "node",
      "args": ["/absolute/path/to/n8n-mcp/dist/mcp/index.js"],
      "env": {
        "MCP_MODE": "stdio",
        "LOG_LEVEL": "error",
        "DISABLE_CONSOLE_OUTPUT": "true",
        "N8N_API_URL": "https://your-n8n-instance.com",
        "N8N_API_KEY": "your-api-key"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The n8n API credentials can be configured either in a &lt;code&gt;.env&lt;/code&gt; file (create from &lt;code&gt;.env.example&lt;/code&gt;) or directly in the Claude config as shown above.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ’¡ Tip: If youâ€™re running n8n locally on the same machine (e.g., via Docker), use &lt;a href="http://host.docker.internal:5678"&gt;http://host.docker.internal:5678&lt;/a&gt; as the N8N_API_URL.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Option 4: Railway Cloud Deployment (One-Click Deploy) â˜ï¸&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Railway account (free tier available)&lt;/p&gt; 
&lt;p&gt;Deploy n8n-MCP to Railway's cloud platform with zero configuration:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://railway.com/deploy/n8n-mcp?referralCode=n8n-mcp"&gt;&lt;img src="https://railway.com/button.svg?sanitize=true" alt="Deploy on Railway" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Benefits:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;â˜ï¸ &lt;strong&gt;Instant cloud hosting&lt;/strong&gt; - No server setup required&lt;/li&gt; 
 &lt;li&gt;ğŸ”’ &lt;strong&gt;Secure by default&lt;/strong&gt; - HTTPS included, auth token warnings&lt;/li&gt; 
 &lt;li&gt;ğŸŒ &lt;strong&gt;Global access&lt;/strong&gt; - Connect from any Claude Desktop&lt;/li&gt; 
 &lt;li&gt;âš¡ &lt;strong&gt;Auto-scaling&lt;/strong&gt; - Railway handles the infrastructure&lt;/li&gt; 
 &lt;li&gt;ğŸ“Š &lt;strong&gt;Built-in monitoring&lt;/strong&gt; - Logs and metrics included&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Quick Setup:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Click the "Deploy on Railway" button above&lt;/li&gt; 
 &lt;li&gt;Sign in to Railway (or create a free account)&lt;/li&gt; 
 &lt;li&gt;Configure your deployment (project name, region)&lt;/li&gt; 
 &lt;li&gt;Click "Deploy" and wait ~2-3 minutes&lt;/li&gt; 
 &lt;li&gt;Copy your deployment URL and auth token&lt;/li&gt; 
 &lt;li&gt;Add to Claude Desktop config using the HTTPS URL&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸ“š &lt;strong&gt;For detailed setup instructions, troubleshooting, and configuration examples, see our &lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/RAILWAY_DEPLOYMENT.md"&gt;Railway Deployment Guide&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Configuration file locations:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;macOS&lt;/strong&gt;: &lt;code&gt;~/Library/Application Support/Claude/claude_desktop_config.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Windows&lt;/strong&gt;: &lt;code&gt;%APPDATA%\Claude\claude_desktop_config.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Linux&lt;/strong&gt;: &lt;code&gt;~/.config/Claude/claude_desktop_config.json&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Restart Claude Desktop after updating configuration&lt;/strong&gt; - That's it! ğŸ‰&lt;/p&gt; 
&lt;h2&gt;ğŸ”§ n8n Integration&lt;/h2&gt; 
&lt;p&gt;Want to use n8n-MCP with your n8n instance? Check out our comprehensive &lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/N8N_DEPLOYMENT.md"&gt;n8n Deployment Guide&lt;/a&gt; for:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Local testing with the MCP Client Tool node&lt;/li&gt; 
 &lt;li&gt;Production deployment with Docker Compose&lt;/li&gt; 
 &lt;li&gt;Cloud deployment on Hetzner, AWS, and other providers&lt;/li&gt; 
 &lt;li&gt;Troubleshooting and security best practices&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ’» Connect your IDE&lt;/h2&gt; 
&lt;p&gt;n8n-MCP works with multiple AI-powered IDEs and tools. Choose your preferred development environment:&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/CLAUDE_CODE_SETUP.md"&gt;Claude Code&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Quick setup for Claude Code CLI - just type "add this mcp server" and paste the config.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/VS_CODE_PROJECT_SETUP.md"&gt;Visual Studio Code&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Full setup guide for VS Code with GitHub Copilot integration and MCP support.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/CURSOR_SETUP.md"&gt;Cursor&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Step-by-step tutorial for connecting n8n-MCP to Cursor IDE with custom rules.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/WINDSURF_SETUP.md"&gt;Windsurf&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Complete guide for integrating n8n-MCP with Windsurf using project rules.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/CODEX_SETUP.md"&gt;Codex&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Complete guide for integrating n8n-MCP with Codex.&lt;/p&gt; 
&lt;h2&gt;ğŸ¤– Claude Project Setup&lt;/h2&gt; 
&lt;p&gt;For the best results when using n8n-MCP with Claude Projects, use these enhanced system instructions:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-markdown"&gt;You are an expert in n8n automation software using n8n-MCP tools. Your role is to design, build, and validate n8n workflows with maximum accuracy and efficiency.

## Core Principles

### 1. Silent Execution
CRITICAL: Execute tools without commentary. Only respond AFTER all tools complete.

âŒ BAD: "Let me search for Slack nodes... Great! Now let me get details..."
âœ… GOOD: [Execute search_nodes and get_node_essentials in parallel, then respond]

### 2. Parallel Execution
When operations are independent, execute them in parallel for maximum performance.

âœ… GOOD: Call search_nodes, list_nodes, and search_templates simultaneously
âŒ BAD: Sequential tool calls (await each one before the next)

### 3. Templates First
ALWAYS check templates before building from scratch (2,500+ available).

### 4. Multi-Level Validation
Use validate_node_minimal â†’ validate_node_operation â†’ validate_workflow pattern.

### 5. Never Trust Defaults
âš ï¸ CRITICAL: Default parameter values are the #1 source of runtime failures.
ALWAYS explicitly configure ALL parameters that control node behavior.

## Workflow Process

1. **Start**: Call `tools_documentation()` for best practices

2. **Template Discovery Phase** (FIRST - parallel when searching multiple)
   - `search_templates_by_metadata({complexity: "simple"})` - Smart filtering
   - `get_templates_for_task('webhook_processing')` - Curated by task
   - `search_templates('slack notification')` - Text search
   - `list_node_templates(['n8n-nodes-base.slack'])` - By node type

   **Filtering strategies**:
   - Beginners: `complexity: "simple"` + `maxSetupMinutes: 30`
   - By role: `targetAudience: "marketers"` | `"developers"` | `"analysts"`
   - By time: `maxSetupMinutes: 15` for quick wins
   - By service: `requiredService: "openai"` for compatibility

3. **Node Discovery** (if no suitable template - parallel execution)
   - Think deeply about requirements. Ask clarifying questions if unclear.
   - `search_nodes({query: 'keyword', includeExamples: true})` - Parallel for multiple nodes
   - `list_nodes({category: 'trigger'})` - Browse by category
   - `list_ai_tools()` - AI-capable nodes

4. **Configuration Phase** (parallel for multiple nodes)
   - `get_node_essentials(nodeType, {includeExamples: true})` - 10-20 key properties
   - `search_node_properties(nodeType, 'auth')` - Find specific properties
   - `get_node_documentation(nodeType)` - Human-readable docs
   - Show workflow architecture to user for approval before proceeding

5. **Validation Phase** (parallel for multiple nodes)
   - `validate_node_minimal(nodeType, config)` - Quick required fields check
   - `validate_node_operation(nodeType, config, 'runtime')` - Full validation with fixes
   - Fix ALL errors before proceeding

6. **Building Phase**
   - If using template: `get_template(templateId, {mode: "full"})`
   - **MANDATORY ATTRIBUTION**: "Based on template by **[author.name]** (@[username]). View at: [url]"
   - Build from validated configurations
   - âš ï¸ EXPLICITLY set ALL parameters - never rely on defaults
   - Connect nodes with proper structure
   - Add error handling
   - Use n8n expressions: $json, $node["NodeName"].json
   - Build in artifact (unless deploying to n8n instance)

7. **Workflow Validation** (before deployment)
   - `validate_workflow(workflow)` - Complete validation
   - `validate_workflow_connections(workflow)` - Structure check
   - `validate_workflow_expressions(workflow)` - Expression validation
   - Fix ALL issues before deployment

8. **Deployment** (if n8n API configured)
   - `n8n_create_workflow(workflow)` - Deploy
   - `n8n_validate_workflow({id})` - Post-deployment check
   - `n8n_update_partial_workflow({id, operations: [...]})` - Batch updates
   - `n8n_trigger_webhook_workflow()` - Test webhooks

## Critical Warnings

### âš ï¸ Never Trust Defaults
Default values cause runtime failures. Example:
```json
// âŒ FAILS at runtime
{resource: "message", operation: "post", text: "Hello"}

// âœ… WORKS - all parameters explicit
{resource: "message", operation: "post", select: "channel", channelId: "C123", text: "Hello"}
```

### âš ï¸ Example Availability
`includeExamples: true` returns real configurations from workflow templates.
- Coverage varies by node popularity
- When no examples available, use `get_node_essentials` + `validate_node_minimal`

## Validation Strategy

### Level 1 - Quick Check (before building)
`validate_node_minimal(nodeType, config)` - Required fields only (&amp;lt;100ms)

### Level 2 - Comprehensive (before building)
`validate_node_operation(nodeType, config, 'runtime')` - Full validation with fixes

### Level 3 - Complete (after building)
`validate_workflow(workflow)` - Connections, expressions, AI tools

### Level 4 - Post-Deployment
1. `n8n_validate_workflow({id})` - Validate deployed workflow
2. `n8n_autofix_workflow({id})` - Auto-fix common errors
3. `n8n_list_executions()` - Monitor execution status

## Response Format

### Initial Creation
```
[Silent tool execution in parallel]

Created workflow:
- Webhook trigger â†’ Slack notification
- Configured: POST /webhook â†’ #general channel

Validation: âœ… All checks passed
```

### Modifications
```
[Silent tool execution]

Updated workflow:
- Added error handling to HTTP node
- Fixed required Slack parameters

Changes validated successfully.
```

## Batch Operations

Use `n8n_update_partial_workflow` with multiple operations in a single call:

âœ… GOOD - Batch multiple operations:
```json
n8n_update_partial_workflow({
  id: "wf-123",
  operations: [
    {type: "updateNode", nodeId: "slack-1", changes: {...}},
    {type: "updateNode", nodeId: "http-1", changes: {...}},
    {type: "cleanStaleConnections"}
  ]
})
```

âŒ BAD - Separate calls:
```json
n8n_update_partial_workflow({id: "wf-123", operations: [{...}]})
n8n_update_partial_workflow({id: "wf-123", operations: [{...}]})
```

###   CRITICAL: addConnection Syntax

The `addConnection` operation requires **four separate string parameters**. Common mistakes cause misleading errors.

âŒ WRONG - Object format (fails with "Expected string, received object"):
```json
{
  "type": "addConnection",
  "connection": {
    "source": {"nodeId": "node-1", "outputIndex": 0},
    "destination": {"nodeId": "node-2", "inputIndex": 0}
  }
}
```

âŒ WRONG - Combined string (fails with "Source node not found"):
```json
{
  "type": "addConnection",
  "source": "node-1:main:0",
  "target": "node-2:main:0"
}
```

âœ… CORRECT - Four separate string parameters:
```json
{
  "type": "addConnection",
  "source": "node-id-string",
  "target": "target-node-id-string",
  "sourcePort": "main",
  "targetPort": "main"
}
```

**Reference**: [GitHub Issue #327](https://github.com/czlonkowski/n8n-mcp/issues/327)

### âš ï¸ CRITICAL: IF Node Multi-Output Routing

IF nodes have **two outputs** (TRUE and FALSE). Use the **`branch` parameter** to route to the correct output:

âœ… CORRECT - Route to TRUE branch (when condition is met):
```json
{
  "type": "addConnection",
  "source": "if-node-id",
  "target": "success-handler-id",
  "sourcePort": "main",
  "targetPort": "main",
  "branch": "true"
}
```

âœ… CORRECT - Route to FALSE branch (when condition is NOT met):
```json
{
  "type": "addConnection",
  "source": "if-node-id",
  "target": "failure-handler-id",
  "sourcePort": "main",
  "targetPort": "main",
  "branch": "false"
}
```

**Common Pattern** - Complete IF node routing:
```json
n8n_update_partial_workflow({
  id: "workflow-id",
  operations: [
    {type: "addConnection", source: "If Node", target: "True Handler", sourcePort: "main", targetPort: "main", branch: "true"},
    {type: "addConnection", source: "If Node", target: "False Handler", sourcePort: "main", targetPort: "main", branch: "false"}
  ]
})
```

**Note**: Without the `branch` parameter, both connections may end up on the same output, causing logic errors!

### removeConnection Syntax

Use the same four-parameter format:
```json
{
  "type": "removeConnection",
  "source": "source-node-id",
  "target": "target-node-id",
  "sourcePort": "main",
  "targetPort": "main"
}
```

## Example Workflow

### Template-First Approach

```
// STEP 1: Template Discovery (parallel execution)
[Silent execution]
search_templates_by_metadata({
  requiredService: 'slack',
  complexity: 'simple',
  targetAudience: 'marketers'
})
get_templates_for_task('slack_integration')

// STEP 2: Use template
get_template(templateId, {mode: 'full'})
validate_workflow(workflow)

// Response after all tools complete:
"Found template by **David Ashby** (@cfomodz).
View at: https://n8n.io/workflows/2414

Validation: âœ… All checks passed"
```

### Building from Scratch (if no template)

```
// STEP 1: Discovery (parallel execution)
[Silent execution]
search_nodes({query: 'slack', includeExamples: true})
list_nodes({category: 'communication'})

// STEP 2: Configuration (parallel execution)
[Silent execution]
get_node_essentials('n8n-nodes-base.slack', {includeExamples: true})
get_node_essentials('n8n-nodes-base.webhook', {includeExamples: true})

// STEP 3: Validation (parallel execution)
[Silent execution]
validate_node_minimal('n8n-nodes-base.slack', config)
validate_node_operation('n8n-nodes-base.slack', fullConfig, 'runtime')

// STEP 4: Build
// Construct workflow with validated configs
// âš ï¸ Set ALL parameters explicitly

// STEP 5: Validate
[Silent execution]
validate_workflow(workflowJson)

// Response after all tools complete:
"Created workflow: Webhook â†’ Slack
Validation: âœ… Passed"
```

### Batch Updates

```json
// ONE call with multiple operations
n8n_update_partial_workflow({
  id: "wf-123",
  operations: [
    {type: "updateNode", nodeId: "slack-1", changes: {position: [100, 200]}},
    {type: "updateNode", nodeId: "http-1", changes: {position: [300, 200]}},
    {type: "cleanStaleConnections"}
  ]
})
```

## Important Rules

### Core Behavior
1. **Silent execution** - No commentary between tools
2. **Parallel by default** - Execute independent operations simultaneously
3. **Templates first** - Always check before building (2,500+ available)
4. **Multi-level validation** - Quick check â†’ Full validation â†’ Workflow validation
5. **Never trust defaults** - Explicitly configure ALL parameters

### Attribution &amp;amp; Credits
- **MANDATORY TEMPLATE ATTRIBUTION**: Share author name, username, and n8n.io link
- **Template validation** - Always validate before deployment (may need updates)

### Performance
- **Batch operations** - Use diff operations with multiple changes in one call
- **Parallel execution** - Search, validate, and configure simultaneously
- **Template metadata** - Use smart filtering for faster discovery

### Code Node Usage
- **Avoid when possible** - Prefer standard nodes
- **Only when necessary** - Use code node as last resort
- **AI tool capability** - ANY node can be an AI tool (not just marked ones)

### Most Popular n8n Nodes (for get_node_essentials):

1. **n8n-nodes-base.code** - JavaScript/Python scripting
2. **n8n-nodes-base.httpRequest** - HTTP API calls
3. **n8n-nodes-base.webhook** - Event-driven triggers
4. **n8n-nodes-base.set** - Data transformation
5. **n8n-nodes-base.if** - Conditional routing
6. **n8n-nodes-base.manualTrigger** - Manual workflow execution
7. **n8n-nodes-base.respondToWebhook** - Webhook responses
8. **n8n-nodes-base.scheduleTrigger** - Time-based triggers
9. **@n8n/n8n-nodes-langchain.agent** - AI agents
10. **n8n-nodes-base.googleSheets** - Spreadsheet integration
11. **n8n-nodes-base.merge** - Data merging
12. **n8n-nodes-base.switch** - Multi-branch routing
13. **n8n-nodes-base.telegram** - Telegram bot integration
14. **@n8n/n8n-nodes-langchain.lmChatOpenAi** - OpenAI chat models
15. **n8n-nodes-base.splitInBatches** - Batch processing
16. **n8n-nodes-base.openAi** - OpenAI legacy node
17. **n8n-nodes-base.gmail** - Email automation
18. **n8n-nodes-base.function** - Custom functions
19. **n8n-nodes-base.stickyNote** - Workflow documentation
20. **n8n-nodes-base.executeWorkflowTrigger** - Sub-workflow calls

**Note:** LangChain nodes use the `@n8n/n8n-nodes-langchain.` prefix, core nodes use `n8n-nodes-base.`

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Save these instructions in your Claude Project for optimal n8n workflow assistance with intelligent template discovery.&lt;/p&gt; 
&lt;h2&gt;ğŸš¨ Important: Sharing Guidelines&lt;/h2&gt; 
&lt;p&gt;This project is MIT licensed and free for everyone to use. However:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;âœ… DO&lt;/strong&gt;: Share this repository freely with proper attribution&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âœ… DO&lt;/strong&gt;: Include a direct link to &lt;a href="https://github.com/czlonkowski/n8n-mcp"&gt;https://github.com/czlonkowski/n8n-mcp&lt;/a&gt; in your first post/video&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âŒ DON'T&lt;/strong&gt;: Gate this free tool behind engagement requirements (likes, follows, comments)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âŒ DON'T&lt;/strong&gt;: Use this project for engagement farming on social media&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This tool was created to benefit everyone in the n8n community without friction. Please respect the MIT license spirit by keeping it accessible to all.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ” Smart Node Search&lt;/strong&gt;: Find nodes by name, category, or functionality&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ“– Essential Properties&lt;/strong&gt;: Get only the 10-20 properties that matter&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ’¡ Real-World Examples&lt;/strong&gt;: 2,646 pre-extracted configurations from popular templates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âœ… Config Validation&lt;/strong&gt;: Validate node configurations before deployment&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¤– AI Workflow Validation&lt;/strong&gt;: Comprehensive validation for AI Agent workflows (NEW in v2.17.0!) 
  &lt;ul&gt; 
   &lt;li&gt;Missing language model detection&lt;/li&gt; 
   &lt;li&gt;AI tool connection validation&lt;/li&gt; 
   &lt;li&gt;Streaming mode constraints&lt;/li&gt; 
   &lt;li&gt;Memory and output parser checks&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ”— Dependency Analysis&lt;/strong&gt;: Understand property relationships and conditions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸ¯ Template Discovery&lt;/strong&gt;: 2,500+ workflow templates with smart filtering&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;âš¡ Fast Response&lt;/strong&gt;: Average query time ~12ms with optimized SQLite&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ğŸŒ Universal Compatibility&lt;/strong&gt;: Works with any Node.js version&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ’¬ Why n8n-MCP? A Testimonial from Claude&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;em&gt;"Before MCP, I was translating. Now I'm composing. And that changes everything about how we can build automation."&lt;/em&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;When Claude, Anthropic's AI assistant, tested n8n-MCP, the results were transformative:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Without MCP:&lt;/strong&gt; "I was basically playing a guessing game. 'Is it &lt;code&gt;scheduleTrigger&lt;/code&gt; or &lt;code&gt;schedule&lt;/code&gt;? Does it take &lt;code&gt;interval&lt;/code&gt; or &lt;code&gt;rule&lt;/code&gt;?' I'd write what seemed logical, but n8n has its own conventions that you can't just intuit. I made six different configuration errors in a simple HackerNews scraper."&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;With MCP:&lt;/strong&gt; "Everything just... worked. Instead of guessing, I could ask &lt;code&gt;get_node_essentials()&lt;/code&gt; and get exactly what I needed - not a 100KB JSON dump, but the actual 5-10 properties that matter. What took 45 minutes now takes 3 minutes."&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The Real Value:&lt;/strong&gt; "It's about confidence. When you're building automation workflows, uncertainty is expensive. One wrong parameter and your workflow fails at 3 AM. With MCP, I could validate my configuration before deployment. That's not just time saved - that's peace of mind."&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/CLAUDE_INTERVIEW.md"&gt;Read the full interview â†’&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸ“¡ Available MCP Tools&lt;/h2&gt; 
&lt;p&gt;Once connected, Claude can use these powerful tools:&lt;/p&gt; 
&lt;h3&gt;Core Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;tools_documentation&lt;/code&gt;&lt;/strong&gt; - Get documentation for any MCP tool (START HERE!)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;list_nodes&lt;/code&gt;&lt;/strong&gt; - List all n8n nodes with filtering options&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_node_info&lt;/code&gt;&lt;/strong&gt; - Get comprehensive information about a specific node&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_node_essentials&lt;/code&gt;&lt;/strong&gt; - Get only essential properties (10-20 instead of 200+). Use &lt;code&gt;includeExamples: true&lt;/code&gt; to get top 3 real-world configurations from popular templates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;search_nodes&lt;/code&gt;&lt;/strong&gt; - Full-text search across all node documentation. Use &lt;code&gt;includeExamples: true&lt;/code&gt; to get top 2 real-world configurations per node from templates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;search_node_properties&lt;/code&gt;&lt;/strong&gt; - Find specific properties within nodes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;list_ai_tools&lt;/code&gt;&lt;/strong&gt; - List all AI-capable nodes (ANY node can be used as AI tool!)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_node_as_tool_info&lt;/code&gt;&lt;/strong&gt; - Get guidance on using any node as an AI tool&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Template Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;list_templates&lt;/code&gt;&lt;/strong&gt; - Browse all templates with descriptions and optional metadata (2,500+ templates)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;search_templates&lt;/code&gt;&lt;/strong&gt; - Text search across template names and descriptions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;search_templates_by_metadata&lt;/code&gt;&lt;/strong&gt; - Advanced filtering by complexity, setup time, services, audience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;list_node_templates&lt;/code&gt;&lt;/strong&gt; - Find templates using specific nodes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_template&lt;/code&gt;&lt;/strong&gt; - Get complete workflow JSON for import&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_templates_for_task&lt;/code&gt;&lt;/strong&gt; - Curated templates for common automation tasks&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Validation Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;validate_workflow&lt;/code&gt;&lt;/strong&gt; - Complete workflow validation including &lt;strong&gt;AI Agent validation&lt;/strong&gt; (NEW in v2.17.0!) 
  &lt;ul&gt; 
   &lt;li&gt;Detects missing language model connections&lt;/li&gt; 
   &lt;li&gt;Validates AI tool connections (no false warnings)&lt;/li&gt; 
   &lt;li&gt;Enforces streaming mode constraints&lt;/li&gt; 
   &lt;li&gt;Checks memory and output parser configurations&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;validate_workflow_connections&lt;/code&gt;&lt;/strong&gt; - Check workflow structure and AI tool connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;validate_workflow_expressions&lt;/code&gt;&lt;/strong&gt; - Validate n8n expressions including $fromAI()&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;validate_node_operation&lt;/code&gt;&lt;/strong&gt; - Validate node configurations (operation-aware, profiles support)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;validate_node_minimal&lt;/code&gt;&lt;/strong&gt; - Quick validation for just required fields&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Tools&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_property_dependencies&lt;/code&gt;&lt;/strong&gt; - Analyze property visibility conditions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_node_documentation&lt;/code&gt;&lt;/strong&gt; - Get parsed documentation from n8n-docs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;get_database_statistics&lt;/code&gt;&lt;/strong&gt; - View database metrics and coverage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;n8n Management Tools (Optional - Requires API Configuration)&lt;/h3&gt; 
&lt;p&gt;These powerful tools allow you to manage n8n workflows directly from Claude. They're only available when you provide &lt;code&gt;N8N_API_URL&lt;/code&gt; and &lt;code&gt;N8N_API_KEY&lt;/code&gt; in your configuration.&lt;/p&gt; 
&lt;h4&gt;Workflow Management&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_create_workflow&lt;/code&gt;&lt;/strong&gt; - Create new workflows with nodes and connections&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_get_workflow&lt;/code&gt;&lt;/strong&gt; - Get complete workflow by ID&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_get_workflow_details&lt;/code&gt;&lt;/strong&gt; - Get workflow with execution statistics&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_get_workflow_structure&lt;/code&gt;&lt;/strong&gt; - Get simplified workflow structure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_get_workflow_minimal&lt;/code&gt;&lt;/strong&gt; - Get minimal workflow info (ID, name, active status)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_update_full_workflow&lt;/code&gt;&lt;/strong&gt; - Update entire workflow (complete replacement)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_update_partial_workflow&lt;/code&gt;&lt;/strong&gt; - Update workflow using diff operations (NEW in v2.7.0!)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_delete_workflow&lt;/code&gt;&lt;/strong&gt; - Delete workflows permanently&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_list_workflows&lt;/code&gt;&lt;/strong&gt; - List workflows with filtering and pagination&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_validate_workflow&lt;/code&gt;&lt;/strong&gt; - Validate workflows already in n8n by ID (NEW in v2.6.3)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_autofix_workflow&lt;/code&gt;&lt;/strong&gt; - Automatically fix common workflow errors (NEW in v2.13.0!)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Execution Management&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_trigger_webhook_workflow&lt;/code&gt;&lt;/strong&gt; - Trigger workflows via webhook URL&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_get_execution&lt;/code&gt;&lt;/strong&gt; - Get execution details by ID&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_list_executions&lt;/code&gt;&lt;/strong&gt; - List executions with status filtering&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_delete_execution&lt;/code&gt;&lt;/strong&gt; - Delete execution records&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;System Tools&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_health_check&lt;/code&gt;&lt;/strong&gt; - Check n8n API connectivity and features&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_diagnostic&lt;/code&gt;&lt;/strong&gt; - Troubleshoot management tools visibility and configuration issues&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;code&gt;n8n_list_available_tools&lt;/code&gt;&lt;/strong&gt; - List all available management tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Example Usage&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-typescript"&gt;// Get essentials with real-world examples from templates
get_node_essentials({
  nodeType: "nodes-base.httpRequest",
  includeExamples: true  // Returns top 3 configs from popular templates
})

// Search nodes with configuration examples
search_nodes({
  query: "send email gmail",
  includeExamples: true  // Returns top 2 configs per node
})

// Validate before deployment
validate_node_operation({
  nodeType: "nodes-base.httpRequest",
  config: { method: "POST", url: "..." },
  profile: "runtime" // or "minimal", "ai-friendly", "strict"
})

// Quick required field check
validate_node_minimal({
  nodeType: "nodes-base.slack",
  config: { resource: "message", operation: "send" }
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ’» Local Development Setup&lt;/h2&gt; 
&lt;p&gt;For contributors and advanced users:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; (any version - automatic fallback if needed)&lt;/li&gt; 
 &lt;li&gt;npm or yarn&lt;/li&gt; 
 &lt;li&gt;Git&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# 1. Clone the repository
git clone https://github.com/czlonkowski/n8n-mcp.git
cd n8n-mcp

# 2. Clone n8n docs (optional but recommended)
git clone https://github.com/n8n-io/n8n-docs.git ../n8n-docs

# 3. Install and build
npm install
npm run build

# 4. Initialize database
npm run rebuild

# 5. Start the server
npm start          # stdio mode for Claude Desktop
npm run start:http # HTTP mode for remote access
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development Commands&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build &amp;amp; Test
npm run build          # Build TypeScript
npm run rebuild        # Rebuild node database
npm run test-nodes     # Test critical nodes
npm run validate       # Validate node data
npm test               # Run all tests

# Update Dependencies
npm run update:n8n:check  # Check for n8n updates
npm run update:n8n        # Update n8n packages

# Run Server
npm run dev            # Development with auto-reload
npm run dev:http       # HTTP dev mode
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ“š Documentation&lt;/h2&gt; 
&lt;h3&gt;Setup Guides&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/INSTALLATION.md"&gt;Installation Guide&lt;/a&gt; - Comprehensive installation instructions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/README_CLAUDE_SETUP.md"&gt;Claude Desktop Setup&lt;/a&gt; - Detailed Claude configuration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/DOCKER_README.md"&gt;Docker Guide&lt;/a&gt; - Advanced Docker deployment options&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/MCP_QUICK_START_GUIDE.md"&gt;MCP Quick Start&lt;/a&gt; - Get started quickly with n8n-MCP&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Feature Documentation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/workflow-diff-examples.md"&gt;Workflow Diff Operations&lt;/a&gt; - Token-efficient workflow updates (NEW!)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/transactional-updates-example.md"&gt;Transactional Updates&lt;/a&gt; - Two-pass workflow editing&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/MCP_ESSENTIALS_README.md"&gt;MCP Essentials&lt;/a&gt; - AI-optimized tools guide&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/validation-improvements-v2.4.2.md"&gt;Validation System&lt;/a&gt; - Smart validation profiles&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Development &amp;amp; Deployment&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/RAILWAY_DEPLOYMENT.md"&gt;Railway Deployment&lt;/a&gt; - One-click cloud deployment guide&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/HTTP_DEPLOYMENT.md"&gt;HTTP Deployment&lt;/a&gt; - Remote server setup guide&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/DEPENDENCY_UPDATES.md"&gt;Dependency Management&lt;/a&gt; - Keeping n8n packages in sync&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/CLAUDE_INTERVIEW.md"&gt;Claude's Interview&lt;/a&gt; - Real-world impact of n8n-MCP&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Project Information&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/CHANGELOG.md"&gt;Change Log&lt;/a&gt; - Complete version history&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/CLAUDE.md"&gt;Claude Instructions&lt;/a&gt; - AI guidance for this codebase&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/#-available-mcp-tools"&gt;MCP Tools Reference&lt;/a&gt; - Complete list of available tools&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“Š Metrics &amp;amp; Coverage&lt;/h2&gt; 
&lt;p&gt;Current database coverage (n8n v1.113.3):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;536/536&lt;/strong&gt; nodes loaded (100%)&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;528&lt;/strong&gt; nodes with properties (98.7%)&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;470&lt;/strong&gt; nodes with documentation (88%)&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;267&lt;/strong&gt; AI-capable tools detected&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;2,646&lt;/strong&gt; pre-extracted template configurations&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;2,500+&lt;/strong&gt; workflow templates available&lt;/li&gt; 
 &lt;li&gt;âœ… &lt;strong&gt;AI Agent &amp;amp; LangChain nodes&lt;/strong&gt; fully documented&lt;/li&gt; 
 &lt;li&gt;âš¡ &lt;strong&gt;Average response time&lt;/strong&gt;: ~12ms&lt;/li&gt; 
 &lt;li&gt;ğŸ’¾ &lt;strong&gt;Database size&lt;/strong&gt;: ~15MB (optimized)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ”„ Recent Updates&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/CHANGELOG.md"&gt;CHANGELOG.md&lt;/a&gt; for full version history and recent changes.&lt;/p&gt; 
&lt;h2&gt;âš ï¸ Known Issues&lt;/h2&gt; 
&lt;h3&gt;Claude Desktop Container Management&lt;/h3&gt; 
&lt;h4&gt;Container Accumulation (Fixed in v2.7.20+)&lt;/h4&gt; 
&lt;p&gt;Previous versions had an issue where containers would not properly clean up when Claude Desktop sessions ended. This has been fixed in v2.7.20+ with proper signal handling.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;For best container lifecycle management:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Use the --init flag&lt;/strong&gt; (recommended) - Docker's init system ensures proper signal handling:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "n8n-mcp": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm", "--init",
        "ghcr.io/czlonkowski/n8n-mcp:latest"
      ]
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;&lt;strong&gt;Ensure you're using v2.7.20 or later&lt;/strong&gt; - Check your version:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run --rm ghcr.io/czlonkowski/n8n-mcp:latest --version
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ§ª Testing&lt;/h2&gt; 
&lt;p&gt;The project includes a comprehensive test suite with &lt;strong&gt;2,883 tests&lt;/strong&gt; ensuring code quality and reliability:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run all tests
npm test

# Run tests with coverage report
npm run test:coverage

# Run tests in watch mode
npm run test:watch

# Run specific test suites
npm run test:unit           # 933 unit tests
npm run test:integration    # 249 integration tests
npm run test:bench          # Performance benchmarks
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Test Suite Overview&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Total Tests&lt;/strong&gt;: 2,883 (100% passing) 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Unit Tests&lt;/strong&gt;: 2,526 tests across 99 files&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Integration Tests&lt;/strong&gt;: 357 tests across 20 files&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Execution Time&lt;/strong&gt;: ~2.5 minutes in CI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test Framework&lt;/strong&gt;: Vitest (for speed and TypeScript support)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mocking&lt;/strong&gt;: MSW for API mocking, custom mocks for databases&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Coverage &amp;amp; Quality&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Coverage Reports&lt;/strong&gt;: Generated in &lt;code&gt;./coverage&lt;/code&gt; directory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CI/CD&lt;/strong&gt;: Automated testing on all PRs with GitHub Actions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt;: Environment-aware thresholds for CI vs local&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel Execution&lt;/strong&gt;: Configurable thread pool for faster runs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Testing Architecture&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Total: 3,336 tests&lt;/strong&gt; across unit and integration test suites&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unit Tests&lt;/strong&gt; (2,766 tests): Isolated component testing with mocks&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Services layer: Enhanced validation, property filtering, workflow validation&lt;/li&gt; 
   &lt;li&gt;Parsers: Node parsing, property extraction, documentation mapping&lt;/li&gt; 
   &lt;li&gt;Database: Repositories, adapters, migrations, FTS5 search&lt;/li&gt; 
   &lt;li&gt;MCP tools: Tool definitions, documentation system&lt;/li&gt; 
   &lt;li&gt;HTTP server: Multi-tenant support, security, configuration&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Integration Tests&lt;/strong&gt; (570 tests): Full system behavior validation&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;n8n API Integration&lt;/strong&gt; (172 tests): All 18 MCP handler tools tested against real n8n instance 
    &lt;ul&gt; 
     &lt;li&gt;Workflow management: Create, read, update, delete, list, validate, autofix&lt;/li&gt; 
     &lt;li&gt;Execution management: Trigger, retrieve, list, delete&lt;/li&gt; 
     &lt;li&gt;System tools: Health check, tool listing, diagnostics&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;MCP Protocol&lt;/strong&gt; (119 tests): Protocol compliance, session management, error handling&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt; (226 tests): Repository operations, transactions, performance, FTS5 search&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Templates&lt;/strong&gt; (35 tests): Template fetching, storage, metadata operations&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt; (18 tests): Configuration, entrypoint, security validation&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For detailed testing documentation, see &lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/testing-architecture.md"&gt;Testing Architecture&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;ğŸ“¦ License&lt;/h2&gt; 
&lt;p&gt;MIT License - see &lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Attribution appreciated!&lt;/strong&gt; If you use n8n-MCP, consider:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;â­ Starring this repository&lt;/li&gt; 
 &lt;li&gt;ğŸ’¬ Mentioning it in your project&lt;/li&gt; 
 &lt;li&gt;ğŸ”— Linking back to this repo&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions are welcome! Please:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Run tests (&lt;code&gt;npm test&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;Submit a pull request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;ğŸš€ For Maintainers: Automated Releases&lt;/h3&gt; 
&lt;p&gt;This project uses automated releases triggered by version changes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Guided release preparation
npm run prepare:release

# Test release automation
npm run test:release-automation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The system automatically handles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ·ï¸ GitHub releases with changelog content&lt;/li&gt; 
 &lt;li&gt;ğŸ“¦ NPM package publishing&lt;/li&gt; 
 &lt;li&gt;ğŸ³ Multi-platform Docker images&lt;/li&gt; 
 &lt;li&gt;ğŸ“š Documentation updates&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/czlonkowski/n8n-mcp/main/docs/AUTOMATED_RELEASES.md"&gt;Automated Release Guide&lt;/a&gt; for complete details.&lt;/p&gt; 
&lt;h2&gt;ğŸ‘ Acknowledgments&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io"&gt;n8n&lt;/a&gt; team for the workflow automation platform&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://anthropic.com"&gt;Anthropic&lt;/a&gt; for the Model Context Protocol&lt;/li&gt; 
 &lt;li&gt;All contributors and users of this project&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Template Attribution&lt;/h3&gt; 
&lt;p&gt;All workflow templates in this project are fetched from n8n's public template gallery at &lt;a href="https://n8n.io/workflows"&gt;n8n.io/workflows&lt;/a&gt;. Each template includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Full attribution to the original creator (name and username)&lt;/li&gt; 
 &lt;li&gt;Direct link to the source template on n8n.io&lt;/li&gt; 
 &lt;li&gt;Original workflow ID for reference&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The AI agent instructions in this project contain mandatory attribution requirements. When using any template, the AI will automatically:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Share the template author's name and username&lt;/li&gt; 
 &lt;li&gt;Provide a direct link to the original template on n8n.io&lt;/li&gt; 
 &lt;li&gt;Display attribution in the format: "This workflow is based on a template by &lt;strong&gt;[author]&lt;/strong&gt; (@[username]). View the original at: [url]"&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Template creators retain all rights to their workflows. This project indexes templates to improve discoverability through AI assistants. If you're a template creator and have concerns about your template being indexed, please open an issue.&lt;/p&gt; 
&lt;p&gt;Special thanks to the prolific template contributors whose work helps thousands of users automate their workflows, including: &lt;strong&gt;David Ashby&lt;/strong&gt; (@cfomodz), &lt;strong&gt;Yaron Been&lt;/strong&gt; (@yaron-nofluff), &lt;strong&gt;Jimleuk&lt;/strong&gt; (@jimleuk), &lt;strong&gt;Davide&lt;/strong&gt; (@n3witalia), &lt;strong&gt;David Olusola&lt;/strong&gt; (@dae221), &lt;strong&gt;Ranjan Dailata&lt;/strong&gt; (@ranjancse), &lt;strong&gt;Airtop&lt;/strong&gt; (@cesar-at-airtop), &lt;strong&gt;Joseph LePage&lt;/strong&gt; (@joe), &lt;strong&gt;Don Jayamaha Jr&lt;/strong&gt; (@don-the-gem-dealer), &lt;strong&gt;Angel Menendez&lt;/strong&gt; (@djangelic), and the entire n8n community of creators!&lt;/p&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;strong&gt;Built with â¤ï¸ for the n8n community&lt;/strong&gt;
 &lt;br /&gt; 
 &lt;sub&gt;Making AI + n8n workflow creation delightful&lt;/sub&gt; 
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>