<rss version="2.0">
  <channel>
    <title>GitHub Go Weekly Trending</title>
    <description>Weekly Trending of Go in GitHub</description>
    <pubDate>Tue, 28 Oct 2025 01:44:31 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>pocketbase/pocketbase</title>
      <link>https://github.com/pocketbase/pocketbase</link>
      <description>&lt;p&gt;Open Source realtime backend in 1 file&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://pocketbase.io" target="_blank" rel="noopener"&gt; &lt;img src="https://i.imgur.com/5qimnm5.png" alt="PocketBase - open source backend in 1 file" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/pocketbase/pocketbase/actions/workflows/release.yaml" target="_blank" rel="noopener"&gt;&lt;img src="https://github.com/pocketbase/pocketbase/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/pocketbase/pocketbase/releases" target="_blank" rel="noopener"&gt;&lt;img src="https://img.shields.io/github/release/pocketbase/pocketbase.svg?sanitize=true" alt="Latest releases" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/pocketbase/pocketbase" target="_blank" rel="noopener"&gt;&lt;img src="https://godoc.org/github.com/pocketbase/pocketbase?status.svg?sanitize=true" alt="Go package documentation" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://pocketbase.io"&gt;PocketBase&lt;/a&gt; is an open source Go backend that includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;embedded database (&lt;em&gt;SQLite&lt;/em&gt;) with &lt;strong&gt;realtime subscriptions&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;built-in &lt;strong&gt;files and users management&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;convenient &lt;strong&gt;Admin dashboard UI&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;and simple &lt;strong&gt;REST-ish API&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;For documentation and examples, please visit &lt;a href="https://pocketbase.io/docs"&gt;https://pocketbase.io/docs&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] Please keep in mind that PocketBase is still under active development and therefore full backward compatibility is not guaranteed before reaching v1.0.0.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;API SDK clients&lt;/h2&gt; 
&lt;p&gt;The easiest way to interact with the PocketBase Web APIs is to use one of the official SDK clients:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;JavaScript - &lt;a href="https://github.com/pocketbase/js-sdk"&gt;pocketbase/js-sdk&lt;/a&gt;&lt;/strong&gt; (&lt;em&gt;Browser, Node.js, React Native&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dart - &lt;a href="https://github.com/pocketbase/dart-sdk"&gt;pocketbase/dart-sdk&lt;/a&gt;&lt;/strong&gt; (&lt;em&gt;Web, Mobile, Desktop, CLI&lt;/em&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You could also check the recommendations in &lt;a href="https://pocketbase.io/docs/how-to-use/"&gt;https://pocketbase.io/docs/how-to-use/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;h3&gt;Use as standalone app&lt;/h3&gt; 
&lt;p&gt;You could download the prebuilt executable for your platform from the &lt;a href="https://github.com/pocketbase/pocketbase/releases"&gt;Releases page&lt;/a&gt;. Once downloaded, extract the archive and run &lt;code&gt;./pocketbase serve&lt;/code&gt; in the extracted directory.&lt;/p&gt; 
&lt;p&gt;The prebuilt executables are based on the &lt;a href="https://github.com/pocketbase/pocketbase/raw/master/examples/base/main.go"&gt;&lt;code&gt;examples/base/main.go&lt;/code&gt; file&lt;/a&gt; and comes with the JS VM plugin enabled by default which allows to extend PocketBase with JavaScript (&lt;em&gt;for more details please refer to &lt;a href="https://pocketbase.io/docs/js-overview/"&gt;Extend with JavaScript&lt;/a&gt;&lt;/em&gt;).&lt;/p&gt; 
&lt;h3&gt;Use as a Go framework/toolkit&lt;/h3&gt; 
&lt;p&gt;PocketBase is distributed as a regular Go library package which allows you to build your own custom app specific business logic and still have a single portable executable at the end.&lt;/p&gt; 
&lt;p&gt;Here is a minimal example:&lt;/p&gt; 
&lt;ol start="0"&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://go.dev/doc/install"&gt;Install Go 1.23+&lt;/a&gt; (&lt;em&gt;if you haven't already&lt;/em&gt;)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Create a new project directory with the following &lt;code&gt;main.go&lt;/code&gt; file inside it:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
    "log"

    "github.com/pocketbase/pocketbase"
    "github.com/pocketbase/pocketbase/core"
)

func main() {
    app := pocketbase.New()

    app.OnServe().BindFunc(func(se *core.ServeEvent) error {
        // registers new "GET /hello" route
        se.Router.GET("/hello", func(re *core.RequestEvent) error {
            return re.String(200, "Hello world!")
        })

        return se.Next()
    })

    if err := app.Start(); err != nil {
        log.Fatal(err)
    }
}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To init the dependencies, run &lt;code&gt;go mod init myapp &amp;amp;&amp;amp; go mod tidy&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To start the application, run &lt;code&gt;go run main.go serve&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;To build a statically linked executable, you can run &lt;code&gt;CGO_ENABLED=0 go build&lt;/code&gt; and then start the created executable with &lt;code&gt;./myapp serve&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;em&gt;For more details please refer to &lt;a href="https://pocketbase.io/docs/go-overview/"&gt;Extend with Go&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt; 
&lt;h3&gt;Building and running the repo main.go example&lt;/h3&gt; 
&lt;p&gt;To build the minimal standalone executable, like the prebuilt ones in the releases page, you can simply run &lt;code&gt;go build&lt;/code&gt; inside the &lt;code&gt;examples/base&lt;/code&gt; directory:&lt;/p&gt; 
&lt;ol start="0"&gt; 
 &lt;li&gt;&lt;a href="https://go.dev/doc/install"&gt;Install Go 1.23+&lt;/a&gt; (&lt;em&gt;if you haven't already&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;Clone/download the repo&lt;/li&gt; 
 &lt;li&gt;Navigate to &lt;code&gt;examples/base&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build&lt;/code&gt; (&lt;em&gt;&lt;a href="https://go.dev/doc/install/source#environment"&gt;https://go.dev/doc/install/source#environment&lt;/a&gt;&lt;/em&gt;)&lt;/li&gt; 
 &lt;li&gt;Start the created executable by running &lt;code&gt;./base serve&lt;/code&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Note that the supported build targets by the pure Go SQLite driver at the moment are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;darwin  amd64
darwin  arm64
freebsd amd64
freebsd arm64
linux   386
linux   amd64
linux   arm
linux   arm64
linux   loong64
linux   ppc64le
linux   riscv64
linux   s390x
windows 386
windows amd64
windows arm64
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Testing&lt;/h3&gt; 
&lt;p&gt;PocketBase comes with mixed bag of unit and integration tests. To run them, use the standard &lt;code&gt;go test&lt;/code&gt; command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go test ./...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check also the &lt;a href="http://pocketbase.io/docs/testing"&gt;Testing guide&lt;/a&gt; to learn how to write your own custom application tests.&lt;/p&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you discover a security vulnerability within PocketBase, please send an e-mail to &lt;strong&gt;support at pocketbase.io&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;All reports will be promptly addressed and you'll be credited in the fix release notes.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;PocketBase is free and open source project licensed under the &lt;a href="https://raw.githubusercontent.com/pocketbase/pocketbase/master/LICENSE.md"&gt;MIT License&lt;/a&gt;. You are free to do whatever you want with it, even offering it as a paid service.&lt;/p&gt; 
&lt;p&gt;You could help continuing its development by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/pocketbase/pocketbase/master/CONTRIBUTING.md"&gt;Contribute to the source code&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pocketbase/pocketbase/issues"&gt;Suggest new features and report issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;PRs for new OAuth2 providers, bug fixes, code optimizations and documentation improvements are more than welcome.&lt;/p&gt; 
&lt;p&gt;But please refrain creating PRs for &lt;em&gt;new features&lt;/em&gt; without previously discussing the implementation details. PocketBase has a &lt;a href="https://github.com/orgs/pocketbase/projects/2"&gt;roadmap&lt;/a&gt; and I try to work on issues in specific order and such PRs often come in out of nowhere and skew all initial planning with tedious back-and-forth communication.&lt;/p&gt; 
&lt;p&gt;Don't get upset if I close your PR, even if it is well executed and tested. This doesn't mean that it will never be merged. Later we can always refer to it and/or take pieces of your implementation when the time comes to work on the issue (don't worry you'll be credited in the release notes).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>usememos/memos</title>
      <link>https://github.com/usememos/memos</link>
      <description>&lt;p&gt;An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Memos&lt;/h1&gt; 
&lt;img align="right" height="96px" src="https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/logo-rounded.png" alt="Memos" /&gt; 
&lt;p&gt;An open-source, self-hosted note-taking service. Your thoughts, your data, your control ‚Äî no tracking, no ads, no subscription fees.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.usememos.com"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%8F%A0-usememos.com-blue?style=flat-square" alt="Home" /&gt;&lt;/a&gt; &lt;a href="https://demo.usememos.com/"&gt;&lt;img src="https://img.shields.io/badge/%E2%9C%A8-Try%20Demo-orange?style=flat-square" alt="Live Demo" /&gt;&lt;/a&gt; &lt;a href="https://www.usememos.com/docs"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%93%9A-Documentation-green?style=flat-square" alt="Docs" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/tfPJa4UmAv"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%92%AC-Discord-5865f2?style=flat-square&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/neosmemo/memos"&gt;&lt;img src="https://img.shields.io/docker/pulls/neosmemo/memos?style=flat-square&amp;amp;logo=docker" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/usememos/.github/refs/heads/main/assets/demo.png" alt="Memos Demo Screenshot" height="512" /&gt; 
&lt;h3&gt;üíé Featured Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://go.warp.dev/memos"&gt;&lt;strong&gt;Warp&lt;/strong&gt; ‚Äî The AI-powered terminal built for speed and collaboration&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://go.warp.dev/memos" target="_blank" rel="noopener"&gt; &lt;img src="https://raw.githubusercontent.com/warpdotdev/brand-assets/main/Github/Sponsor/Warp-Github-LG-02.png" alt="Warp - The terminal for the 21st century" height="300" /&gt; &lt;/a&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Memos is a privacy-first, self-hosted knowledge base that works seamlessly for personal notes, team wikis, and knowledge management. Built with Go and React, it offers lightning-fast performance without compromising on features or usability.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Why choose Memos over cloud services?&lt;/strong&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;Memos&lt;/th&gt; 
   &lt;th&gt;Cloud Services&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Privacy&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Self-hosted, zero telemetry&lt;/td&gt; 
   &lt;td&gt;‚ùå Your data on their servers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cost&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Free forever, MIT license&lt;/td&gt; 
   &lt;td&gt;‚ùå Subscription fees&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Performance&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Instant load, no latency&lt;/td&gt; 
   &lt;td&gt;‚ö†Ô∏è Depends on internet&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Ownership&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Full control &amp;amp; export&lt;/td&gt; 
   &lt;td&gt;‚ùå Vendor lock-in&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;API Access&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Full REST + gRPC APIs&lt;/td&gt; 
   &lt;td&gt;‚ö†Ô∏è Limited or paid&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Customization&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ Open source, forkable&lt;/td&gt; 
   &lt;td&gt;‚ùå Closed ecosystem&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîí Privacy-First Architecture&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Self-hosted on your infrastructure with zero telemetry&lt;/li&gt; 
   &lt;li&gt;Complete data ownership and export capabilities&lt;/li&gt; 
   &lt;li&gt;No tracking, no ads, no vendor lock-in&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üìù Markdown Native&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full markdown support&lt;/li&gt; 
   &lt;li&gt;Plain text storage ‚Äî take your data anywhere&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;‚ö° Blazing Fast&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Built with Go backend and React frontend&lt;/li&gt; 
   &lt;li&gt;Optimized for performance at any scale&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üê≥ Simple Deployment&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;One-line Docker installation&lt;/li&gt; 
   &lt;li&gt;Supports SQLite, MySQL, and PostgreSQL&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üîó Developer-Friendly&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Full REST and gRPC APIs&lt;/li&gt; 
   &lt;li&gt;Easy integration with existing workflows&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;üé® Beautiful Interface&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Clean, minimal design and dark mode support&lt;/li&gt; 
   &lt;li&gt;Mobile-responsive layout&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Docker (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name memos \
  -p 5230:5230 \
  -v ~/.memos:/var/opt/memos \
  neosmemo/memos:stable
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open &lt;code&gt;http://localhost:5230&lt;/code&gt; and start writing!&lt;/p&gt; 
&lt;h3&gt;Try the Live Demo&lt;/h3&gt; 
&lt;p&gt;Don't want to install yet? Try our &lt;a href="https://demo.usememos.com/"&gt;live demo&lt;/a&gt; first!&lt;/p&gt; 
&lt;h3&gt;Other Installation Methods&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt; - Recommended for production deployments&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Pre-built Binaries&lt;/strong&gt; - Available for Linux, macOS, and Windows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt; - Helm charts and manifests available&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build from Source&lt;/strong&gt; - For development and customization&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See our &lt;a href="https://www.usememos.com/docs/installation"&gt;installation guide&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions of all kinds! Whether you're fixing bugs, adding features, improving documentation, or helping with translations ‚Äî every contribution matters.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Ways to contribute:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;üêõ &lt;a href="https://github.com/usememos/memos/issues/new?template=bug_report.md"&gt;Report bugs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üí° &lt;a href="https://github.com/usememos/memos/issues/new?template=feature_request.md"&gt;Suggest features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîß &lt;a href="https://github.com/usememos/memos/pulls"&gt;Submit pull requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://github.com/usememos/memos/tree/main/docs"&gt;Improve documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üåç &lt;a href="https://github.com/usememos/memos/tree/main/web/src/locales"&gt;Help with translations&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;Love Memos? &lt;a href="https://github.com/sponsors/usememos"&gt;Sponsor us on GitHub&lt;/a&gt; to help keep the project growing!&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Featured Supportors:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/fixermark" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/169982?v=4" alt="fixermark" height="50" style="border-radius: 50%; margin: 5px;" /&gt;&lt;/a&gt; &lt;a href="https://github.com/alik-agaev" target="_blank"&gt;&lt;img src="https://avatars.githubusercontent.com/u/2662697?v=4" alt="alik-agaev" height="50" style="border-radius: 50%; margin: 5px;" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#usememos/memos&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=usememos/memos&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Memos is open-source software licensed under the &lt;a href="https://raw.githubusercontent.com/usememos/memos/main/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.usememos.com"&gt;Website&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://www.usememos.com/docs"&gt;Documentation&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://demo.usememos.com/"&gt;Demo&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://discord.gg/tfPJa4UmAv"&gt;Discord&lt;/a&gt;&lt;/strong&gt; ‚Ä¢ &lt;strong&gt;&lt;a href="https://x.com/usememos"&gt;X/Twitter&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Made with ‚ù§Ô∏è by the Memos community&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>v2fly/domain-list-community</title>
      <link>https://github.com/v2fly/domain-list-community</link>
      <description>&lt;p&gt;Community managed domain list. Generate geosite.dat for V2Ray.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Domain list community&lt;/h1&gt; 
&lt;p&gt;This project manages a list of domains, to be used as geosites for routing purpose in Project V.&lt;/p&gt; 
&lt;h2&gt;Purpose of this project&lt;/h2&gt; 
&lt;p&gt;This project is not opinionated. In other words, it does NOT endorse, claim or imply that a domain should be blocked or proxied. It can be used to generate routing rules on demand.&lt;/p&gt; 
&lt;h2&gt;Download links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;dlc.dat&lt;/strong&gt;Ôºö&lt;a href="https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat"&gt;https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;dlc.dat.sha256sum&lt;/strong&gt;Ôºö&lt;a href="https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum"&gt;https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Usage example&lt;/h2&gt; 
&lt;p&gt;Each file in the &lt;code&gt;data&lt;/code&gt; directory can be used as a rule in this format: &lt;code&gt;geosite:filename&lt;/code&gt;.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;"routing": {
  "domainStrategy": "IPIfNonMatch",
  "rules": [
    {
      "type": "field",
      "outboundTag": "Reject",
      "domain": [
        "geosite:category-ads-all",
        "geosite:category-porn"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Direct",
      "domain": [
        "domain:icloud.com",
        "domain:icloud-content.com",
        "domain:cdn-apple.com",
        "geosite:cn",
        "geosite:private"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-1",
      "domain": [
        "geosite:category-anticensorship",
        "geosite:category-media",
        "geosite:category-vpnservices"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-2",
      "domain": [
        "geosite:category-dev"
      ]
    },
    {
      "type": "field",
      "outboundTag": "Proxy-3",
      "domain": [
        "geosite:geolocation-!cn"
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Generate &lt;code&gt;dlc.dat&lt;/code&gt; manually&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Install &lt;code&gt;golang&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Clone project code: &lt;code&gt;git clone https://github.com/v2fly/domain-list-community.git&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Navigate to project root directory: &lt;code&gt;cd domain-list-community&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install project dependencies: &lt;code&gt;go mod download&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Generate &lt;code&gt;dlc.dat&lt;/code&gt; (without &lt;code&gt;datapath&lt;/code&gt; option means to use domain lists in &lt;code&gt;data&lt;/code&gt; directory of current working directory): 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;go run ./&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;go run ./ --datapath=/path/to/your/custom/data/directory&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Run &lt;code&gt;go run ./ --help&lt;/code&gt; for more usage information.&lt;/p&gt; 
&lt;h2&gt;Structure of data&lt;/h2&gt; 
&lt;p&gt;All data are under &lt;code&gt;data&lt;/code&gt; directory. Each file in the directory represents a sub-list of domains, named by the file name. File content is in the following format.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# comments
include:another-file
domain:google.com @attr1 @attr2
keyword:google
regexp:www\.google\.com$
full:www.google.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Syntax:&lt;/strong&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The following types of rules are &lt;strong&gt;NOT&lt;/strong&gt; fully compatible with the ones that defined by user in V2Ray config file. Do &lt;strong&gt;Not&lt;/strong&gt; copy and paste directly.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Comment begins with &lt;code&gt;#&lt;/code&gt;. It may begin anywhere in the file. The content in the line after &lt;code&gt;#&lt;/code&gt; is treated as comment and ignored in production.&lt;/li&gt; 
 &lt;li&gt;Inclusion begins with &lt;code&gt;include:&lt;/code&gt;, followed by the file name of an existing file in the same directory.&lt;/li&gt; 
 &lt;li&gt;Subdomain begins with &lt;code&gt;domain:&lt;/code&gt;, followed by a valid domain name. The prefix &lt;code&gt;domain:&lt;/code&gt; may be omitted.&lt;/li&gt; 
 &lt;li&gt;Keyword begins with &lt;code&gt;keyword:&lt;/code&gt;, followed by a string.&lt;/li&gt; 
 &lt;li&gt;Regular expression begins with &lt;code&gt;regexp:&lt;/code&gt;, followed by a valid regular expression (per Golang's standard).&lt;/li&gt; 
 &lt;li&gt;Full domain begins with &lt;code&gt;full:&lt;/code&gt;, followed by a complete and valid domain name.&lt;/li&gt; 
 &lt;li&gt;Domains (including &lt;code&gt;domain&lt;/code&gt;, &lt;code&gt;keyword&lt;/code&gt;, &lt;code&gt;regexp&lt;/code&gt; and &lt;code&gt;full&lt;/code&gt;) may have one or more attributes. Each attribute begins with &lt;code&gt;@&lt;/code&gt; and followed by the name of the attribute.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Adding new &lt;code&gt;regexp&lt;/code&gt; and &lt;code&gt;keyword&lt;/code&gt; rules is discouraged because it is easy to use them incorrectly, and proxy software cannot efficiently match these types of rules.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;How it works&lt;/h2&gt; 
&lt;p&gt;The entire &lt;code&gt;data&lt;/code&gt; directory will be built into an external &lt;code&gt;geosite&lt;/code&gt; file for Project V. Each file in the directory represents a section in the generated file.&lt;/p&gt; 
&lt;p&gt;To generate a section:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Remove all the comments in the file.&lt;/li&gt; 
 &lt;li&gt;Replace &lt;code&gt;include:&lt;/code&gt; lines with the actual content of the file.&lt;/li&gt; 
 &lt;li&gt;Omit all empty lines.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;domain:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/config.proto#L21"&gt;sub-domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;keyword:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/config.proto#L17"&gt;plain domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;regexp:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/config.proto#L19"&gt;regex domain routing rule&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Generate each &lt;code&gt;full:&lt;/code&gt; line into a &lt;a href="https://github.com/v2fly/v2ray-core/raw/master/app/router/config.proto#L23"&gt;full domain routing rule&lt;/a&gt;.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;How to organize domains&lt;/h2&gt; 
&lt;h3&gt;File name&lt;/h3&gt; 
&lt;p&gt;Theoretically any string can be used as the name, as long as it is a valid file name. In practice, we prefer names for determinic group of domains, such as the owner (usually a company name) of the domains, e.g., "google", "netflix". Names with unclear scope are generally unrecommended, such as "evil", or "local".&lt;/p&gt; 
&lt;h3&gt;Attributes&lt;/h3&gt; 
&lt;p&gt;Attribute is useful for sub-group of domains, especially for filtering purpose. For example, the list of &lt;code&gt;google&lt;/code&gt; domains may contains its main domains, as well as domains that serve ads. The ads domains may be marked by attribute &lt;code&gt;@ads&lt;/code&gt;, and can be used as &lt;code&gt;geosite:google@ads&lt;/code&gt; in V2Ray routing.&lt;/p&gt; 
&lt;h2&gt;Contribution guideline&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fork this repo, make modifications to your own repo, file a PR.&lt;/li&gt; 
 &lt;li&gt;Please begin with small size PRs, say modification in a single file.&lt;/li&gt; 
 &lt;li&gt;A PR must be reviewed and approved by another member.&lt;/li&gt; 
 &lt;li&gt;A script will verify your pull request to test whether your PR is correct or not every time you update the PR. Only the PR which passes the test will be merged. Please go to the Action label to get detailed information if you didn't pass it. We also provide the file which has been generated to make you test.&lt;/li&gt; 
 &lt;li&gt;After a few successful PRs, you may apply for manager access to this repository.&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>rook/rook</title>
      <link>https://github.com/rook/rook</link>
      <description>&lt;p&gt;Storage Orchestration for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;img alt="Rook" src="https://raw.githubusercontent.com/rook/rook/master/Documentation/media/logo.svg?sanitize=true" width="50%" height="50%" /&gt; 
&lt;p&gt;&lt;a href="https://www.cncf.io/projects"&gt;&lt;img src="https://img.shields.io/badge/cncf%20status-graduated-blue.svg?sanitize=true" alt="CNCF Status" /&gt;&lt;/a&gt; &lt;a href="https://github.com/rook/rook/releases"&gt;&lt;img src="https://img.shields.io/github/release/rook/rook/all.svg?sanitize=true" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/u/rook"&gt;&lt;img src="https://img.shields.io/docker/pulls/rook/ceph" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/rook/rook"&gt;&lt;img src="https://goreportcard.com/badge/github.com/rook/rook" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/rook/rook"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/rook/rook/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/1599"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/1599/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://github.com/rook/rook/actions/workflows/snyk.yaml"&gt;&lt;img src="https://github.com/rook/rook/actions/workflows/snyk.yaml/badge.svg?sanitize=true" alt="Security scanning" /&gt;&lt;/a&gt; &lt;a href="https://slack.rook.io"&gt;&lt;img src="https://img.shields.io/badge/rook-slack-blue" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=rook_io&amp;amp;user_id=788180534543339520"&gt;&lt;img src="https://img.shields.io/twitter/follow/rook_io.svg?style=social&amp;amp;label=Follow" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;What is Rook?&lt;/h1&gt; 
&lt;p&gt;Rook is an open source &lt;strong&gt;cloud-native storage orchestrator&lt;/strong&gt; for Kubernetes, providing the platform, framework, and support for Ceph storage to natively integrate with Kubernetes.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ceph.com/"&gt;Ceph&lt;/a&gt; is a distributed storage system that provides file, block and object storage and is deployed in large scale production clusters.&lt;/p&gt; 
&lt;p&gt;Rook automates deployment and management of Ceph to provide self-managing, self-scaling, and self-healing storage services. The Rook operator does this by building on Kubernetes resources to deploy, configure, provision, scale, upgrade, and monitor Ceph.&lt;/p&gt; 
&lt;p&gt;The status of the Ceph storage provider is &lt;strong&gt;Stable&lt;/strong&gt;. Features and improvements will be planned for many future versions. Upgrades between versions are provided to ensure backward compatibility between releases.&lt;/p&gt; 
&lt;p&gt;Rook is hosted by the &lt;a href="https://cncf.io"&gt;Cloud Native Computing Foundation&lt;/a&gt; (CNCF) as a &lt;a href="https://www.cncf.io/announcements/2020/10/07/cloud-native-computing-foundation-announces-rook-graduation/"&gt;graduated&lt;/a&gt; level project. If you are a company that wants to help shape the evolution of technologies that are container-packaged, dynamically-scheduled and microservices-oriented, consider joining the CNCF. For details about who's involved and how Rook plays a role, read the CNCF &lt;a href="https://www.cncf.io/blog/2018/01/29/cncf-host-rook-project-cloud-native-storage-capabilities"&gt;announcement&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Getting Started and Documentation&lt;/h2&gt; 
&lt;p&gt;For installation, deployment, and administration, see our &lt;a href="https://rook.github.io/docs/rook/latest-release"&gt;Documentation&lt;/a&gt; and &lt;a href="https://rook.github.io/docs/rook/latest-release/Getting-Started/quickstart"&gt;QuickStart Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions. See &lt;a href="https://raw.githubusercontent.com/rook/rook/master/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Report a Bug&lt;/h2&gt; 
&lt;p&gt;For filing bugs, suggesting improvements, or requesting new features, please open an &lt;a href="https://github.com/rook/rook/issues"&gt;issue&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Reporting Security Vulnerabilities&lt;/h3&gt; 
&lt;p&gt;If you find a vulnerability or a potential vulnerability in Rook please let us know immediately at &lt;a href="mailto:cncf-rook-security@lists.cncf.io"&gt;cncf-rook-security@lists.cncf.io&lt;/a&gt;. We'll send a confirmation email to acknowledge your report, and we'll send an additional email when we've identified the issues positively or negatively.&lt;/p&gt; 
&lt;p&gt;For further details, please see the complete &lt;a href="https://raw.githubusercontent.com/rook/rook/master/SECURITY.md"&gt;security release process&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contact&lt;/h2&gt; 
&lt;p&gt;Please use the following to reach members of the community:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Slack: Join our &lt;a href="https://slack.rook.io"&gt;slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;GitHub: Start a &lt;a href="https://github.com/rook/rook/discussions"&gt;discussion&lt;/a&gt; or open an &lt;a href="https://github.com/rook/rook/issues"&gt;issue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Twitter: &lt;a href="https://twitter.com/rook_io"&gt;@rook_io&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Security topics: &lt;a href="https://raw.githubusercontent.com/rook/rook/master/#reporting-security-vulnerabilities"&gt;cncf-rook-security@lists.cncf.io&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community Meeting&lt;/h2&gt; 
&lt;p&gt;A regular community meeting takes place the &lt;a href="https://zoom.us/j/98052644520?pwd=K0R4RUZCc3NhQisyMnA5VlV2MVBhQT09"&gt;2nd Tuesday of every month at 9:00 AM PT (Pacific Time)&lt;/a&gt;. Convert to your &lt;a href="http://www.thetimezoneconverter.com/?t=9:00&amp;amp;tz=PT%20%28Pacific%20Time%29"&gt;local timezone&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Any changes to the meeting schedule will be added to the &lt;a href="https://docs.google.com/document/d/1exd8_IG6DkdvyA0eiTtL2z5K2Ra-y68VByUUgwP7I9A/edit?usp=sharing"&gt;agenda doc&lt;/a&gt; and posted to &lt;a href="https://rook-io.slack.com/messages/C76LLCEE7/"&gt;Slack #announcements&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Anyone who wants to discuss the direction of the project, design and implementation reviews, or general questions with the broader community is welcome and encouraged to join.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Meeting link: &lt;a href="https://zoom.us/j/98052644520?pwd=K0R4RUZCc3NhQisyMnA5VlV2MVBhQT09"&gt;https://zoom.us/j/98052644520?pwd=K0R4RUZCc3NhQisyMnA5VlV2MVBhQT09&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/document/d/1exd8_IG6DkdvyA0eiTtL2z5K2Ra-y68VByUUgwP7I9A/edit?usp=sharing"&gt;Current agenda and past meeting notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLP0uDo-ZFnQP6NAgJWAtR9jaRcgqyQKVy"&gt;Past meeting recordings&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Official Releases&lt;/h2&gt; 
&lt;p&gt;Official releases of Rook can be found on the &lt;a href="https://github.com/rook/rook/releases"&gt;releases page&lt;/a&gt;. Please note that it is &lt;strong&gt;strongly recommended&lt;/strong&gt; that you use &lt;a href="https://github.com/rook/rook/releases"&gt;official releases&lt;/a&gt; of Rook, as unreleased versions from the master branch are subject to changes and incompatibilities that will not be supported in the official releases. Builds from the master branch can have functionality changed and even removed at any time without compatibility support and without prior notice.&lt;/p&gt; 
&lt;h2&gt;Licensing&lt;/h2&gt; 
&lt;p&gt;Rook is under the Apache 2.0 license.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.io/projects/git%2Bgithub.com%2Frook%2Frook?ref=badge_large"&gt;&lt;img src="https://app.fossa.io/api/projects/git%2Bgithub.com%2Frook%2Frook.svg?type=large" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>cloudnative-pg/cloudnative-pg</title>
      <link>https://github.com/cloudnative-pg/cloudnative-pg</link>
      <description>&lt;p&gt;CloudNativePG is a comprehensive platform designed to seamlessly manage PostgreSQL databases within Kubernetes environments, covering the entire operational lifecycle from initial deployment to ongoing maintenance&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://landscape.cncf.io/?item=app-definition-and-development--database--cloudnativepg"&gt;&lt;img src="https://img.shields.io/badge/CNCF%20Landscape-5699C6" alt="CNCF Landscape" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cloudnative-pg/cloudnative-pg/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/cloudnative-pg/cloudnative-pg.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/cloudnative-pg/cloudnative-pg?tab=Apache-2.0-1-ov-file#readme"&gt;&lt;img src="https://img.shields.io/github/license/cloudnative-pg/cloudnative-pg" alt="GitHub License" /&gt;&lt;/a&gt; &lt;a href="https://www.bestpractices.dev/projects/9933"&gt;&lt;img src="https://www.bestpractices.dev/projects/9933/badge" alt="OpenSSF Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/cloudnative-pg/cloudnative-pg"&gt;&lt;img src="https://api.scorecard.dev/projects/github.com/cloudnative-pg/cloudnative-pg/badge" alt="OpenSSF Scorecard Badge" /&gt;&lt;/a&gt; &lt;a href="https://cloudnative-pg.io/documentation/current/"&gt;&lt;img src="https://img.shields.io/badge/Documentation-white?logo=data%3Aimage%2Fpng%3Bbase64%2CiVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAGN0lEQVR4nJRXXWwcVxU%2B8%2F%2BzP%2BPZtR2v7dqy07jUJUALNaiK6lZyUVVKWgGKaIv8QCMekBAVQlQICcEzVZFQVYFKQhASEBHlISJPCRJEshTFChgrIYHEiYMh69jetffHM7Mzc%2B9Bs7vjnTs7yZpZWbt37s%2F5zne%2Bc861CD0eXRkbHc3NfjeffvxNAGEAgULD2756v35%2B3qe1Nc4fnQVEXlA2LnOcXlCF8S%2B6vvVgq%2FL3M65X3e51PvfQCU4WJgZe%2B8GQ8fS7AKgjBB8KEHwjDXZSjkf0CREAaXM2eI9c65siqWxWl360Xl74ANHz%2Fy8AitxnTBfmz%2BhyYS4wGhwObQCIHSA0AigOMBzvOsXzd4pnjyL6NMmWEH8hi2b28Og3%2FqRJA0ewfQy0v1vGO2NovwPo%2FEU%2FwVgSU1PI%2BSu79v3lJAB8HM%2BTI%2FO%2FUUXzM4xHIe0xI4DdRqOAwnF%2F38ePPyzaDIDh%2FMxcWh462m08aojuGY97C0nrAEHg9BlF0fmeAPr0J15vbaKsp0BZQzEDEAlP9B209UIIVXUta%2FQEQHwxgxFjTc%2BRskAwrgVWmHtg22vMPJwLDqGUNJIAMHVAkGu3WdpZz6NAkgSXpINSycluV28er1a3rJ4M3F2%2F9AtCvXKycRrTQttrjINjxxxIL9jevxdaDHU%2FTBr6pL5ruzuLZubgUQBOY2hPij3GBUe7tBCMBRE2KrXVSz0BBI%2FtPVgtV%2F%2FxkZ5WSjI%2F%2BFIXC3sHJwgT4yFqrZFFTSlVrp3sGYLwcfxSmXCbS00j2Ms4K7qkOsFx6qdTuiHtG4AimfmM8NyvOvR2G48qXtZ2fsfrN7%2BqpcRyUp0glKiimDm4TwAcHBp%2B9WeA4ki0GMWNR9OVF8BZvn7xtI%2FF09H8jzLEgz6yLwCDuelnFXHkTZZOytCOEdqDOtGwsm%2BNj00fXt%2B6%2Bj4vcA7bwNrZwENmXwAKuZnvsNRThs5ozMPfPiHyoDF7xiduHcXb70A8dRFheHjiySQATBZk0nl9MHPkBEWUoEtYjyrPFNwGzfdlD37Zdu98KCv%2BMmD2BYpUCvcST39e0%2BS1Wr249FAAg7mPzWrS5NstEbE0xrsiA6QN1PfRFLnhr%2BspxVJTlY8Mw1DqNXeyCQFREEXz9cHB0QOev73QaNhOF4B%2B45PHFHFgDhJTqjuubJFqX1KQco7NTTuW8kq95k2G4eLEGzM7lfItnjNeTKcOfV%2FT8hOuV77A9IK0XjgMpCO0ZiuV3L%2F6njCFAOmucGB3OII5XgCXEJTDdZLElVbu3Vz0fWexvL30k0B6ggBACOmIUBAEUKX0dDTvW7RCYcdZPq6n%2FSsQnUO2RuyBRgQ9Rc5mMvJ6CNIj1nXfd9qWAsCkaZzJAk1L8UjVqY737dSjfCGrPHWqXL32Q0mB%2F2BXnke00WaEYv2aTzAbnuV5pcWkDGAAGJmhSafh6hjr%2BW2SVYHrP7bb%2BOdPW%2FUgflGlTM2gaK%2Ft7tp6%2BN6yixdN89DcIwGktIFPABfNbwoQqQWEUnDJzg1g0jDeK5p7Kp7nensXFI7uyAr%2FLyM7fYLnpa6LYScE8vDnot5hrKlslm%2BfE3nVxJgO4o3KcYu%2FF8XM8yFQ27n%2F65Te%2FzKl3Jhpjj6TCIDneRD5%2FItxr1vdkALw7p1qfeWPpjHxMtsXaPxu6FLc%2BrnbSB1r7fcrlr36nqwMzQfnplJDryQCGOh%2FbLjhcM%2FEvQ4Pdund9xRV5m1LfTXaF%2BK9gsLGB9nsgddcz8thM%2FarPzYM8%2FFazf9sMFaU%2Fi%2FwvNANwEhPvUGR8ozn7d%2BiDKXixtKpbHp81nV9E7puRy31ixKUbOe%2Fv3Ud891ghhDrL5Z975eaOvV%2BCNRp0Gfz%2BcJjDABdTwlpdfKbId0t5XYAcHz5D5ZVtWUp9%2Flog2L7PgVJqZx0HOE5Cqghemv1%2Bt%2FeGBmZ%2BdB2yNN72UEpnzXG32YADA186i3bIpPxMhuKrFK%2Fd77JUnbkKbYvRJlC8DzKSZK76Lq1he2dKy%2BZuSfesSz5a2xHDbLJ%2BJaqdv5H4EUY%2BzbG2m9HgN7mg81bfw4W1uu7AjvHaqDhqF%2FZ3Fq5XFy%2FcESSDsx5fvZ7wLEsNfXk%2BjlVHfpSCOB%2FAQAA%2F%2F8zd8orZc2N9AAAAABJRU5ErkJggg%3D%3D" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/cloudnative-pg"&gt;&lt;img src="https://img.shields.io/badge/stackoverflow-cloudnative--pg-blue?logo=stackoverflow&amp;amp;logoColor=%23F48024&amp;amp;link=https%3A%2F%2Fstackoverflow.com%2Fquestions%2Ftagged%2Fcloudnative-pg" alt="Stack Overflow" /&gt;&lt;/a&gt; &lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Fcloudnative-pg%2Fcloudnative-pg?ref=badge_small"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Fcloudnative-pg%2Fcloudnative-pg.svg?type=small" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Welcome to the CloudNativePG Project!&lt;/h1&gt; 
&lt;p&gt;&lt;strong&gt;CloudNativePG (CNPG)&lt;/strong&gt; is an open-source platform designed to seamlessly manage &lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; databases in Kubernetes environments. It covers the entire operational lifecycle‚Äîfrom deployment to ongoing maintenance‚Äîthrough its core component, the CloudNativePG operator.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudnative-pg/governance/raw/main/GOVERNANCE.md"&gt;Governance Policies&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/ADOPTERS.md"&gt;Adopters&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudnative-pg.io/support/"&gt;Commercial Support&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/LICENSE"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;The best way to get started is the &lt;a href="https://cloudnative-pg.io/documentation/current/quickstart/"&gt;Quickstart Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Scope&lt;/h2&gt; 
&lt;h3&gt;Mission&lt;/h3&gt; 
&lt;p&gt;CloudNativePG aims to increase PostgreSQL adoption within Kubernetes by making it an integral part of the development process and GitOps-driven CI/CD automation.&lt;/p&gt; 
&lt;h3&gt;Core Principles &amp;amp; Features&lt;/h3&gt; 
&lt;p&gt;Designed by PostgreSQL experts for Kubernetes administrators, CloudNativePG follows a Kubernetes-native approach to PostgreSQL primary/standby cluster management. Instead of relying on external high-availability tools (like Patroni, repmgr, or Stolon), it integrates directly with the Kubernetes API to automate database operations that a skilled DBA would perform manually.&lt;/p&gt; 
&lt;p&gt;Key design decisions include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Direct integration with Kubernetes API: The PostgreSQL cluster‚Äôs status is available directly in the &lt;code&gt;Cluster&lt;/code&gt; resource, allowing users to inspect it via the Kubernetes API.&lt;/li&gt; 
 &lt;li&gt;Operator pattern: The operator ensures that the desired PostgreSQL state is reconciled automatically, following Kubernetes best practices.&lt;/li&gt; 
 &lt;li&gt;Immutable application containers: Updates follow an immutable infrastructure model, as explained in &lt;a href="https://www.enterprisedb.com/blog/why-edb-chose-immutable-application-containers"&gt;"Why EDB Chose Immutable Application Containers"&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;How CloudNativePG Works&lt;/h3&gt; 
&lt;p&gt;The operator continuously monitors and updates the PostgreSQL cluster state. Examples of automated actions include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Failover management: If the primary instance fails, the operator elects a new primary, updates the cluster status, and orchestrates the transition.&lt;/li&gt; 
 &lt;li&gt;Scaling read replicas: When the number of desired replicas changes, the operator provisions or removes resources such as persistent volumes, secrets, and config maps while managing streaming replication.&lt;/li&gt; 
 &lt;li&gt;Service updates: Kubernetes remains the single source of truth, ensuring that PostgreSQL service endpoints are always up to date.&lt;/li&gt; 
 &lt;li&gt;Rolling updates: When an image is updated, the operator follows a rolling strategy‚Äîfirst updating replica pods before performing a controlled switchover for the primary.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CloudNativePG manages additional Kubernetes resources to enhance PostgreSQL management, including: &lt;code&gt;Backup&lt;/code&gt;, &lt;code&gt;ClusterImageCatalog&lt;/code&gt;, &lt;code&gt;Database&lt;/code&gt;, &lt;code&gt;ImageCatalog&lt;/code&gt;, &lt;code&gt;Pooler&lt;/code&gt;, &lt;code&gt;Publication&lt;/code&gt;, &lt;code&gt;ScheduledBackup&lt;/code&gt;, and &lt;code&gt;Subscription&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Out of Scope&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Kubernetes only:&lt;/strong&gt; CloudNativePG is dedicated to vanilla Kubernetes maintained by the &lt;a href="https://kubernetes.io/"&gt;Cloud Native Computing Foundation (CNCF)&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL only:&lt;/strong&gt; CloudNativePG is dedicated to vanilla PostgreSQL maintained by the &lt;a href="https://www.postgresql.org/about/"&gt;PostgreSQL Global Development Group (PGDG)&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No support for forks:&lt;/strong&gt; Features from PostgreSQL forks will only be considered if they can be integrated as extensions or pluggable frameworks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Not a general-purpose database operator:&lt;/strong&gt; CloudNativePG does not support other databases (e.g., MariaDB).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CloudNativePG can be extended via the &lt;a href="https://github.com/cloudnative-pg/cnpg-i"&gt;CNPG-I plugin interface&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Communications&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudnative-pg/cloudnative-pg/discussions"&gt;Github Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloud-native.slack.com/archives/C08MAUJ7NPM"&gt;Slack&lt;/a&gt; (join the &lt;a href="https://communityinviter.com/apps/cloud-native/cncf"&gt;CNCF Slack Workspace&lt;/a&gt;).&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/CloudNativePg"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@CloudNativePG"&gt;Mastodon&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bsky.app/profile/cloudnativepg.bsky.social"&gt;Bluesky&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/orgs/cloudnative-pg/projects/1"&gt;Roadmap&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudnative-pg.io"&gt;Website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/docs/src/faq.md"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudnative-pg.io/blog/"&gt;Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cloudnative-pg/cnpg-i"&gt;CloudNativePG plugin Interface (CNPG-I)&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;A list of publicly known users of the CloudNativePG operator is in &lt;a href="https://raw.githubusercontent.com/cloudnative-pg/cloudnative-pg/main/ADOPTERS.md"&gt;ADOPTERS.md&lt;/a&gt;. Help us grow our community and CloudNativePG by adding yourself and your organization to this list!&lt;/p&gt; 
&lt;h3&gt;CloudNativePG at KubeCon&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;April 4 2025, KubeCon Europe in London: &lt;a href="https://sched.co/1tx8g"&gt;"Consistent Volume Group Snapshots, Unraveling the Magic"&lt;/a&gt; - Leonardo Cecchi (EDB) and Xing Yang (VMware)&lt;/li&gt; 
 &lt;li&gt;November 11 2024, Cloud Native Rejekts NA 2024: &lt;a href="https://www.youtube.com/watch?v=uBzl_stoxoc&amp;amp;ab_channel=CloudNativeRejekts"&gt;"Maximising Microservice Databases with Kubernetes, Postgres, and CloudNativePG"&lt;/a&gt; - Gabriele Bartolini (EDB) and Leonardo Cecchi (EDB)&lt;/li&gt; 
 &lt;li&gt;March 21 2024, KubeCon Europe 2024 in Paris: &lt;a href="https://kccnceu2024.sched.com/event/1YeM4/scaling-heights-mastering-postgres-database-vertical-scalability-with-kubernetes-storage-magic-gabriele-bartolini-edb-gari-singh-google"&gt;"Scaling Heights: Mastering Postgres Database Vertical Scalability with Kubernetes Storage Magic"&lt;/a&gt; - Gari Singh, Google &amp;amp; Gabriele Bartolini, EDB&lt;/li&gt; 
 &lt;li&gt;March 19 2024, Data on Kubernetes Day at KubeCon Europe 2024 in Paris: &lt;a href="https://colocatedeventseu2024.sched.com/event/1YFha/from-zero-to-hero-scaling-postgres-in-kubernetes-using-the-power-of-cloudnativepg-gabriele-bartolini-edb"&gt;"From Zero to Hero: Scaling Postgres in Kubernetes Using the Power of CloudNativePG"&lt;/a&gt; - Gabriele Bartolini, EDB&lt;/li&gt; 
 &lt;li&gt;7 November 2023, KubeCon North America 2023 in Chicago: &lt;a href="https://kccncna2023.sched.com/event/1R2ml/disaster-recovery-with-very-large-postgres-databases-gabriele-bartolini-edb-michelle-au-google"&gt;"Disaster Recovery with Very Large Postgres Databases (in Kubernetes)"&lt;/a&gt; - Michelle Au, Google &amp;amp; Gabriele Bartolini, EDB&lt;/li&gt; 
 &lt;li&gt;27 October 2022, KubeCon North America 2022 in Detroit: &lt;a href="https://kccncna2022.sched.com/event/182GB/data-on-kubernetes-deploying-and-running-postgresql-and-patterns-for-databases-in-a-kubernetes-cluster-chris-milsted-ondat-gabriele-bartolini-edb"&gt;"Data On Kubernetes, Deploying And Running PostgreSQL And Patterns For Databases In a Kubernetes Cluster"&lt;/a&gt; - Chris Milsted, Ondat &amp;amp; Gabriele Bartolini, EDB&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Useful links&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://dok.community/"&gt;Data on Kubernetes (DoK) Community&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cncf.io/blog/2024/11/20/cloud-neutral-postgres-databases-with-kubernetes-and-cloudnativepg/"&gt;"Cloud Neutral Postgres Databases with Kubernetes and CloudNativePG" by Gabriele Bartolini&lt;/a&gt; (November 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gabrielebartolini.it/articles/2024/03/cloudnativepg-recipe-5-how-to-migrate-your-postgresql-database-in-kubernetes-with-~0-downtime-from-anywhere/"&gt;"How to migrate your PostgreSQL database in Kubernetes with ~0 downtime from anywhere" by Gabriele Bartolini&lt;/a&gt; (March 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gabrielebartolini.it/articles/2024/02/maximizing-microservice-databases-with-kubernetes-postgres-and-cloudnativepg/"&gt;"Maximizing Microservice Databases with Kubernetes, Postgres, and CloudNativePG" by Gabriele Bartolini&lt;/a&gt; (February 2024)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cncf.io/blog/2023/09/29/recommended-architectures-for-postgresql-in-kubernetes/"&gt;"Recommended Architectures for PostgreSQL in Kubernetes" by Gabriele Bartolini&lt;/a&gt; (September 2023)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.enterprisedb.com/blog/current-state-major-postgresql-upgrades-cloudnativepg-kubernetes"&gt;"The Current State of Major PostgreSQL Upgrades with CloudNativePG" by Gabriele Bartolini&lt;/a&gt; (August 2023)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://thenewstack.io/the-rise-of-the-kubernetes-native-database/"&gt;"The Rise of the Kubernetes Native Database" by Jeff Carpenter&lt;/a&gt; (December 2022)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloudnativenow.com/kubecon-cnc-eu-2022/why-run-postgres-in-kubernetes/"&gt;"Why Run Postgres in Kubernetes?" by Gabriele Bartolini&lt;/a&gt; (May 2022)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.tfir.io/shift-left-security-the-path-to-postgresql-on-kubernetes/"&gt;"Shift-Left Security: The Path To PostgreSQL On Kubernetes" by Gabriele Bartolini&lt;/a&gt; (April 2021)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.2ndquadrant.com/en/blog/local-persistent-volumes-and-postgresql-usage-in-kubernetes/"&gt;"Local Persistent Volumes and PostgreSQL usage in Kubernetes" by Gabriele Bartolini&lt;/a&gt; (June 2020)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; We are a &lt;a href="https://www.cncf.io/sandbox-projects/"&gt;Cloud Native Computing Foundation Sandbox project&lt;/a&gt;. &lt;/p&gt; 
&lt;p style="text-align:center;" align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/white/cncf-white.svg?raw=true" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/cncf/artwork/blob/main/other/cncf/horizontal/color/cncf-color.svg?raw=true" /&gt; 
  &lt;img align="center" src="https://github.com/cncf/artwork/raw/main/other/cncf/horizontal/color/cncf-color.svg?raw=true" alt="CNCF logo" width="50%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; CloudNativePG was originally built and sponsored by &lt;a href="https://www.enterprisedb.com"&gt;EDB&lt;/a&gt;. &lt;/p&gt; 
&lt;p style="text-align:center;" align="center"&gt; 
 &lt;picture align="center"&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_white.svg" /&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_grey.svg" /&gt; 
  &lt;img align="center" src="https://raw.githubusercontent.com/cloudnative-pg/.github/main/logo/edb_landscape_color_grey.svg?sanitize=true" alt="EDB logo" width="25%" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.postgresql.org/about/policies/trademarks/"&gt;Postgres, PostgreSQL, and the Slonik Logo&lt;/a&gt; are trademarks or registered trademarks of the PostgreSQL Community Association of Canada, and used with their permission. &lt;/p&gt; 
&lt;hr /&gt;</description>
    </item>
    
    <item>
      <title>Notifuse/notifuse</title>
      <link>https://github.com/Notifuse/notifuse</link>
      <description>&lt;p&gt;Notifuse is an open-source &amp; modern emailing platform&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Notifuse&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://goreportcard.com/report/github.com/Notifuse/notifuse"&gt;&lt;img src="https://img.shields.io/badge/go%20report-A+-brightgreen.svg?style=flat" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Notifuse/notifuse/actions/workflows/go.yml"&gt;&lt;img src="https://github.com/Notifuse/notifuse/actions/workflows/go.yml/badge.svg?sanitize=true" alt="Go" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/Notifuse/notifuse"&gt;&lt;img src="https://codecov.io/gh/Notifuse/notifuse/graph/badge.svg?token=VZ0HBEM9OZ" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://demo.notifuse.com/signin?email=demo@notifuse.com"&gt;üéØ Try the Live Demo&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;The open-source alternative to Mailchimp, Brevo, Mailjet, Listmonk, Mailerlite, and Klaviyo, Loop.so, etc.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Notifuse is a modern, self-hosted emailing platform that allows you to send newsletters and transactional emails at a fraction of the cost. Built with Go and React, it provides enterprise-grade features with the flexibility of open-source software.&lt;/p&gt; 
&lt;img src="https://www.notifuse.com/_astro/email_editor.CGyLoCOD.png" alt="Email Editor" /&gt; 
&lt;h2&gt;üöÄ Key Features&lt;/h2&gt; 
&lt;h3&gt;üìß Email Marketing&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Visual Email Builder&lt;/strong&gt;: Drag-and-drop editor with MJML components and real-time preview&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Campaign Management&lt;/strong&gt;: Create, schedule, and send targeted email campaigns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;A/B Testing&lt;/strong&gt;: Optimize campaigns with built-in testing for subject lines, content, and send times&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;List Management&lt;/strong&gt;: Advanced subscriber segmentation and list organization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Contact Profiles&lt;/strong&gt;: Rich contact management with custom fields and detailed profiles&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîß Developer-Friendly&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Easy Setup&lt;/strong&gt;: Interactive setup wizard for quick deployment and configuration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Transactional API&lt;/strong&gt;: Powerful REST API for automated email delivery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Webhook Integration&lt;/strong&gt;: Real-time event notifications and integrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Liquid Templating&lt;/strong&gt;: Dynamic content with variables like &lt;code&gt;{{ contact.first_name }}&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Provider Support&lt;/strong&gt;: Connect with Amazon SES, Mailgun, Postmark, Mailjet, SparkPost, and SMTP&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üìä Analytics &amp;amp; Insights&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Open &amp;amp; Click Tracking&lt;/strong&gt;: Detailed engagement metrics and campaign performance&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time Analytics&lt;/strong&gt;: Monitor delivery rates, opens, clicks, and conversions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Campaign Reports&lt;/strong&gt;: Comprehensive reporting and analytics dashboard&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üé® Advanced Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;S3 File Manager&lt;/strong&gt;: Integrated file management with CDN delivery&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Notification Center&lt;/strong&gt;: Centralized notification system for your applications&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Responsive Templates&lt;/strong&gt;: Mobile-optimized email templates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom Fields&lt;/strong&gt;: Flexible contact data management&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Workspace Management&lt;/strong&gt;: Multi-tenant support for teams and agencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üèóÔ∏è Architecture&lt;/h2&gt; 
&lt;p&gt;Notifuse follows clean architecture principles with clear separation of concerns:&lt;/p&gt; 
&lt;h3&gt;Backend (Go)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Domain Layer&lt;/strong&gt;: Core business logic and entities (&lt;code&gt;internal/domain/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Service Layer&lt;/strong&gt;: Business logic implementation (&lt;code&gt;internal/service/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Repository Layer&lt;/strong&gt;: Data access and storage (&lt;code&gt;internal/repository/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP Layer&lt;/strong&gt;: API handlers and middleware (&lt;code&gt;internal/http/&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Frontend (React)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Console&lt;/strong&gt;: Admin interface built with React, Ant Design, and TypeScript (&lt;code&gt;console/&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Notification Center&lt;/strong&gt;: Embeddable widget for customer notifications (&lt;code&gt;notification_center/&lt;/code&gt;)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;PostgreSQL&lt;/strong&gt;: Primary data storage with Squirrel query builder&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìÅ Project Structure&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;‚îú‚îÄ‚îÄ cmd/                    # Application entry points
‚îú‚îÄ‚îÄ internal/               # Private application code
‚îÇ   ‚îú‚îÄ‚îÄ domain/            # Business entities and logic
‚îÇ   ‚îú‚îÄ‚îÄ service/           # Business logic implementation
‚îÇ   ‚îú‚îÄ‚îÄ repository/        # Data access layer
‚îÇ   ‚îú‚îÄ‚îÄ http/              # HTTP handlers and middleware
‚îÇ   ‚îî‚îÄ‚îÄ database/          # Database configuration
‚îú‚îÄ‚îÄ console/               # React-based admin interface
‚îú‚îÄ‚îÄ notification_center/   # Embeddable notification widget
‚îú‚îÄ‚îÄ pkg/                   # Public packages
‚îî‚îÄ‚îÄ config/                # Configuration files
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;üöÄ Getting Started&lt;/h2&gt; 
&lt;h3&gt;One-click deployment&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://railway.com/deploy/aBzOMu?referralCode=73Ps3m"&gt;&lt;img src="https://railway.com/button.svg?sanitize=true" alt="Deploy on Railway" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Quick Start with Docker Compose&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Clone the repository&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/Notifuse/notifuse.git
cd notifuse
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Configure required environment variables&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;cp env.example .env
# Edit .env with database credentials and SECRET_KEY
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Minimum required variables&lt;/strong&gt;: &lt;code&gt;DB_HOST&lt;/code&gt;, &lt;code&gt;DB_PORT&lt;/code&gt;, &lt;code&gt;DB_USER&lt;/code&gt;, &lt;code&gt;DB_PASSWORD&lt;/code&gt;, &lt;code&gt;SECRET_KEY&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Start the services&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Access the application and complete setup&lt;/strong&gt;:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Open &lt;a href="http://localhost:8080"&gt;http://localhost:8080&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Follow the interactive &lt;strong&gt;Setup Wizard&lt;/strong&gt; to configure: 
    &lt;ul&gt; 
     &lt;li&gt;Root administrator email&lt;/li&gt; 
     &lt;li&gt;API endpoint&lt;/li&gt; 
     &lt;li&gt;SMTP settings&lt;/li&gt; 
     &lt;li&gt;PASETO keys (automatically generated)&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;Save the generated keys securely!&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Alternative&lt;/strong&gt;: You can skip the setup wizard by pre-configuring all environment variables in your &lt;code&gt;.env&lt;/code&gt; file. Generate PASETO keys at &lt;a href="https://paseto.notifuse.com"&gt;paseto.notifuse.com&lt;/a&gt; or use &lt;code&gt;make keygen&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Environment Configuration&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;‚ö†Ô∏è Important&lt;/strong&gt;: The included &lt;code&gt;docker-compose.yml&lt;/code&gt; is designed for &lt;strong&gt;testing and development only&lt;/strong&gt;. For production deployments:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Use a separate PostgreSQL database&lt;/strong&gt; (managed service recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Configure external storage&lt;/strong&gt; for file uploads&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Set up proper SSL/TLS termination&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Use a reverse proxy&lt;/strong&gt; (nginx, Traefik, etc.)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Development Setup&lt;/h4&gt; 
&lt;p&gt;The docker-compose includes a PostgreSQL container for quick testing. Simply run &lt;code&gt;docker-compose up -d&lt;/code&gt; to get started, then complete the setup wizard in your browser.&lt;/p&gt; 
&lt;h4&gt;Production Setup&lt;/h4&gt; 
&lt;p&gt;&lt;strong&gt;Required Environment Variables:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;DB_HOST&lt;/code&gt;, &lt;code&gt;DB_PORT&lt;/code&gt;, &lt;code&gt;DB_USER&lt;/code&gt;, &lt;code&gt;DB_PASSWORD&lt;/code&gt; - External PostgreSQL database&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SECRET_KEY&lt;/code&gt; - Secret key for encrypting sensitive data (or &lt;code&gt;PASETO_PRIVATE_KEY&lt;/code&gt; as fallback)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;DB_SSLMODE=require&lt;/code&gt; - For secure database connections&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Optional (can be configured via Setup Wizard or environment variables):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;ROOT_EMAIL&lt;/code&gt; - Root administrator email&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;API_ENDPOINT&lt;/code&gt; - Public API endpoint URL&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;PASETO_PRIVATE_KEY&lt;/code&gt;, &lt;code&gt;PASETO_PUBLIC_KEY&lt;/code&gt; - Authentication keys (auto-generated in wizard)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SMTP_HOST&lt;/code&gt;, &lt;code&gt;SMTP_PORT&lt;/code&gt;, &lt;code&gt;SMTP_USERNAME&lt;/code&gt;, &lt;code&gt;SMTP_PASSWORD&lt;/code&gt; - Email provider settings&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;SMTP_FROM_EMAIL&lt;/code&gt;, &lt;code&gt;SMTP_FROM_NAME&lt;/code&gt; - From address and name&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Environment variables always take precedence over database settings configured via the setup wizard.&lt;/p&gt; 
&lt;p&gt;For detailed installation instructions, configuration options, and setup guides, visit &lt;strong&gt;&lt;a href="https://docs.notifuse.com"&gt;docs.notifuse.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;üìö Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://docs.notifuse.com"&gt;Complete Documentation&lt;/a&gt;&lt;/strong&gt; - Comprehensive guides and tutorials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ù Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions!&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Make your changes&lt;/li&gt; 
 &lt;li&gt;Add tests&lt;/li&gt; 
 &lt;li&gt;Submit a pull request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;üìÑ License&lt;/h2&gt; 
&lt;p&gt;Notifuse is released under the &lt;a href="https://raw.githubusercontent.com/Notifuse/notifuse/main/LICENSE"&gt;GNU Affero General Public License v3.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üÜò Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Documentation&lt;/strong&gt;: &lt;a href="https://docs.notifuse.com"&gt;docs.notifuse.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Email Support&lt;/strong&gt;: &lt;a href="mailto:hello@notifuse.com"&gt;hello@notifuse.com&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub Issues&lt;/strong&gt;: &lt;a href="https://github.com/Notifuse/notifuse/issues"&gt;Report bugs or request features&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåü Why Choose Notifuse?&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;üí∞ Cost-Effective&lt;/strong&gt;: Self-hosted solution with no per-email pricing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîí Privacy-First&lt;/strong&gt;: Your data stays on your infrastructure&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üõ†Ô∏è Customizable&lt;/strong&gt;: Open-source with extensive customization options&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üìà Scalable&lt;/strong&gt;: Built to handle millions of emails&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üöÄ Modern&lt;/strong&gt;: Built with modern technologies and best practices&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;üîß Developer-Friendly&lt;/strong&gt;: Comprehensive API and webhook support&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Ready to get started?&lt;/strong&gt; &lt;a href="https://demo.notifuse.com/signin?email=demo@notifuse.com"&gt;Try the live demo&lt;/a&gt; or &lt;a href="https://docs.notifuse.com"&gt;deploy your own instance&lt;/a&gt; in minutes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>rcourtman/Pulse</title>
      <link>https://github.com/rcourtman/Pulse</link>
      <description>&lt;p&gt;A responsive monitoring platform for Proxmox VE, PBS, and Docker with real-time metrics across nodes and containers&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Pulse&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/rcourtman/Pulse/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/rcourtman/Pulse" alt="GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/rcourtman/pulse"&gt;&lt;img src="https://img.shields.io/docker/pulls/rcourtman/pulse" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/rcourtman/Pulse" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Real-time monitoring for Proxmox VE, Proxmox Mail Gateway, PBS, and Docker infrastructure with alerts and webhooks.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Monitor your hybrid Proxmox and Docker estate from a single dashboard. Get instant alerts when nodes go down, containers misbehave, backups fail, or storage fills up. Supports email, Discord, Slack, Telegram, and more.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://demo.pulserelay.pro"&gt;Try the live demo ‚Üí&lt;/a&gt;&lt;/strong&gt; (read-only with mock data)&lt;/p&gt; 
&lt;img width="2872" height="1502" alt="image" src="https://github.com/user-attachments/assets/41ac125c-59e3-4bdc-bfd2-e300109aa1f7" /&gt; 
&lt;h2&gt;Support Pulse Development&lt;/h2&gt; 
&lt;p&gt;Pulse is built by a solo developer in evenings and weekends. Your support helps:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Keep me motivated to add new features&lt;/li&gt; 
 &lt;li&gt;Prioritize bug fixes and user requests&lt;/li&gt; 
 &lt;li&gt;Ensure Pulse stays 100% free and open-source forever&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://github.com/sponsors/rcourtman"&gt;&lt;img src="https://img.shields.io/github/sponsors/rcourtman?style=social&amp;amp;label=Sponsor" alt="GitHub Sponsors" /&gt;&lt;/a&gt; &lt;a href="https://ko-fi.com/rcourtman"&gt;&lt;img src="https://ko-fi.com/img/githubbutton_sm.svg?sanitize=true" alt="ko-fi" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Not ready to sponsor?&lt;/strong&gt; Star the project or share it with your homelab community!&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Auto-Discovery&lt;/strong&gt;: Finds Proxmox nodes on your network, one-liner setup via generated scripts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cluster Support&lt;/strong&gt;: Configure one node, monitor entire cluster&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise Security&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Credentials encrypted at rest, masked in logs, never sent to frontend&lt;/li&gt; 
   &lt;li&gt;CSRF protection for all state-changing operations&lt;/li&gt; 
   &lt;li&gt;Rate limiting (500 req/min general, 10 attempts/min for auth)&lt;/li&gt; 
   &lt;li&gt;Account lockout after failed login attempts&lt;/li&gt; 
   &lt;li&gt;Secure session management with HttpOnly cookies&lt;/li&gt; 
   &lt;li&gt;bcrypt password hashing (cost 12) - passwords NEVER stored in plain text&lt;/li&gt; 
   &lt;li&gt;API tokens stored securely with restricted file permissions&lt;/li&gt; 
   &lt;li&gt;Security headers (CSP, X-Frame-Options, etc.)&lt;/li&gt; 
   &lt;li&gt;Comprehensive audit logging&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Live monitoring of VMs, containers, nodes, storage&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Alerts&lt;/strong&gt;: Email and webhooks (Discord, Slack, Telegram, Teams, ntfy.sh, Gotify) 
  &lt;ul&gt; 
   &lt;li&gt;Example: "VM 'webserver' is down on node 'pve1'"&lt;/li&gt; 
   &lt;li&gt;Example: "Storage 'local-lvm' at 85% capacity"&lt;/li&gt; 
   &lt;li&gt;Example: "VM 'database' is back online"&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Adaptive Thresholds&lt;/strong&gt;: Hysteresis-based trigger/clear levels, fractional network thresholds, per-metric search, reset-to-defaults, and Custom overrides with inline audit trail&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alert Timeline Analytics&lt;/strong&gt;: Rich history explorer with acknowledgement/clear markers, escalation breadcrumbs, and quick filters for noisy resources&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ceph Awareness&lt;/strong&gt;: Surface Ceph health, pool utilisation, and daemon status automatically when Proxmox exposes Ceph-backed storage&lt;/li&gt; 
 &lt;li&gt;Unified view of PBS backups, PVE backups, and snapshots&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interactive Backup Explorer&lt;/strong&gt;: Cross-highlighted bar chart + grid with quick time-range pivots (24h/7d/30d/custom) and contextual tooltips for the busiest jobs&lt;/li&gt; 
 &lt;li&gt;Proxmox Mail Gateway analytics: mail volume, spam/virus trends, quarantine health, and cluster node status&lt;/li&gt; 
 &lt;li&gt;Optional Docker container monitoring via lightweight agent&lt;/li&gt; 
 &lt;li&gt;Config export/import with encryption and authentication&lt;/li&gt; 
 &lt;li&gt;Automatic stable updates with safe rollback (opt-in)&lt;/li&gt; 
 &lt;li&gt;Dark/light themes, responsive design&lt;/li&gt; 
 &lt;li&gt;Built with Go for minimal resource usage&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SCREENSHOTS.md"&gt;Screenshots ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Privacy&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Pulse respects your privacy:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;No telemetry or analytics collection&lt;/li&gt; 
 &lt;li&gt;No phone-home functionality&lt;/li&gt; 
 &lt;li&gt;No external API calls (except for configured webhooks)&lt;/li&gt; 
 &lt;li&gt;All data stays on your server&lt;/li&gt; 
 &lt;li&gt;Open source - verify it yourself&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Your infrastructure data is yours alone.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Install&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Recommended: Official installer (auto-detects Proxmox and creates container)
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash

# Need to roll back to a previous release? Pass the tag you want
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --version v4.20.0

# Alternative: Docker
docker run -d -p 7655:7655 -v pulse_data:/data rcourtman/pulse:latest

# Testing: Install from main branch source (for testing latest fixes)
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --source

# Alternative: Kubernetes (Helm)
helm registry login ghcr.io
helm install pulse oci://ghcr.io/rcourtman/pulse-chart \
  --version $(curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/VERSION) \
  --namespace pulse \
  --create-namespace
# Replace the VERSION lookup with a specific release if you need to pin. For local development, see docs/KUBERNETES.md.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Proxmox users&lt;/strong&gt;: The installer detects PVE hosts and automatically creates an optimized LXC container. Choose Quick mode for one-minute setup.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/INSTALL.md"&gt;Advanced installation options ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Updating&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Automatic Updates (New!):&lt;/strong&gt; Enable during installation or via Settings UI to stay current automatically&lt;br /&gt; &lt;strong&gt;Standard Install:&lt;/strong&gt; Re-run the installer&lt;br /&gt; &lt;strong&gt;Docker:&lt;/strong&gt; &lt;code&gt;docker pull rcourtman/pulse:latest&lt;/code&gt; then recreate container&lt;/p&gt; 
&lt;h3&gt;Initial Setup&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Option A: Interactive Setup (UI)&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;code&gt;http://&amp;lt;your-server&amp;gt;:7655&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complete the mandatory security setup&lt;/strong&gt; (first-time only)&lt;/li&gt; 
 &lt;li&gt;Create your admin username and password&lt;/li&gt; 
 &lt;li&gt;Use &lt;strong&gt;Settings ‚Üí Security ‚Üí API tokens&lt;/strong&gt; to mint dedicated tokens for automation (issue one token per integration so you can revoke credentials individually)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Option B: Automated Setup (No UI)&lt;/strong&gt; For automated deployments, configure authentication via environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start Pulse with auth pre-configured - skips setup screen
API_TOKENS="ansible-token,docker-agent-token" ./pulse

# Or use basic auth
PULSE_AUTH_USER=admin PULSE_AUTH_PASS=password ./pulse

# Plain text credentials are automatically hashed for security
# `API_TOKEN` is still accepted for back-compat, but `API_TOKENS` lets you manage multiple credentials
# You can also provide pre-hashed values if preferred
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md#automated-setup-skip-ui"&gt;Configuration Guide&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h3&gt;Configure Nodes&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Two authentication methods available:&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Method 1: Manual Setup (Recommended for interactive use)&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;After login, go to Settings ‚Üí Nodes&lt;/li&gt; 
 &lt;li&gt;Discovered nodes appear automatically&lt;/li&gt; 
 &lt;li&gt;Click "Setup Script" next to any node&lt;/li&gt; 
 &lt;li&gt;Click "Generate Setup Code" button (creates a 6-character code valid for 5 minutes)&lt;/li&gt; 
 &lt;li&gt;Copy and run the provided one-liner on your Proxmox/PBS host&lt;/li&gt; 
 &lt;li&gt;Node is configured and monitoring starts automatically&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL "http://pulse:7655/api/setup-script?type=pve&amp;amp;host=https://pve:8006&amp;amp;auth_token=ABC123" | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Method 2: Automated Setup (For scripts/automation)&lt;/h4&gt; 
&lt;p&gt;Use your permanent API token directly in the URL for automation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For Proxmox VE
curl -sSL "http://pulse:7655/api/setup-script?type=pve&amp;amp;host=https://pve:8006&amp;amp;auth_token=YOUR_API_TOKEN" | bash

# For Proxmox Backup Server
curl -sSL "http://pulse:7655/api/setup-script?type=pbs&amp;amp;host=https://pbs:8007&amp;amp;auth_token=YOUR_API_TOKEN" | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;type&lt;/code&gt;: &lt;code&gt;pve&lt;/code&gt; for Proxmox VE, &lt;code&gt;pbs&lt;/code&gt; for Proxmox Backup Server&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;host&lt;/code&gt;: Full URL of your Proxmox/PBS server (e.g., &lt;a href="https://192.168.1.100:8006"&gt;https://192.168.1.100:8006&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;auth_token&lt;/code&gt;: Either a 6-character setup code (expires in 5 min) or your permanent API token&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;backup_perms=true&lt;/code&gt; (optional): Add backup management permissions&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;pulse_url&lt;/code&gt; (optional): Pulse server URL if different from where script is downloaded&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The script handles user creation, permissions, token generation, and registration automatically.&lt;/p&gt; 
&lt;h3&gt;Monitor Docker Containers (optional)&lt;/h3&gt; 
&lt;p&gt;Deploy the lightweight &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/DOCKER_MONITORING.md"&gt;Pulse Docker agent&lt;/a&gt; on any host running Docker to stream container status and resource data back to Pulse. Install the agent alongside your stack, point it at your Pulse URL and API token, and the &lt;strong&gt;Docker&lt;/strong&gt; workspace lights up with host summaries, restart loop detection, per-container CPU/memory charts, and quick filters for stacks and unhealthy workloads.&lt;/p&gt; 
&lt;h2&gt;Docker&lt;/h2&gt; 
&lt;h3&gt;Basic&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  --restart unless-stopped \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Network Discovery&lt;/h3&gt; 
&lt;p&gt;Pulse automatically discovers Proxmox nodes on your network! By default, it scans:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;192.168.0.0/16 (home networks)&lt;/li&gt; 
 &lt;li&gt;10.0.0.0/8 (private networks)&lt;/li&gt; 
 &lt;li&gt;172.16.0.0/12 (Docker/internal networks)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To scan a custom subnet instead:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  -e DISCOVERY_SUBNET="192.168.50.0/24" \
  --restart unless-stopped \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Automated Deployment&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Deploy with authentication pre-configured
docker run -d \
  --name pulse \
  -p 7655:7655 \
  -v pulse_data:/data \
  -e API_TOKENS="ansible-token,docker-agent-token" \
  -e PULSE_AUTH_USER="admin" \
  -e PULSE_AUTH_PASS="your-password" \
  --restart unless-stopped \
  rcourtman/pulse:latest

# Plain text credentials are automatically hashed for security
# No setup required - API works immediately
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Compose&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;services:
  pulse:
    image: rcourtman/pulse:latest
    container_name: pulse
    ports:
      - "7655:7655"
    volumes:
      - pulse_data:/data
    environment:
      # NOTE: Env vars override UI settings. Remove env var to allow UI configuration.
      
      # Network discovery (usually not needed - auto-scans common networks)
      # - DISCOVERY_SUBNET=192.168.50.0/24  # Only for non-standard networks
      
      # Ports
      # - PORT=7655                         # Backend port (default: 7655)
      # - FRONTEND_PORT=7655                # Frontend port (default: 7655)
      
      # Security (all optional - runs open by default)
      # - PULSE_AUTH_USER=admin             # Username for web UI login
      # - PULSE_AUTH_PASS=your-password     # Plain text or bcrypt hash (auto-hashed if plain)
      # - API_TOKENS=token-a,token-b        # Comma-separated tokens (plain or SHA3-256 hashed)
      # - API_TOKEN=legacy-token            # Optional single-token fallback
      # - ALLOW_UNPROTECTED_EXPORT=false    # Allow export without auth (default: false)
      
      # Security: Plain text credentials are automatically hashed
      # You can provide either:
      # 1. Plain text (auto-hashed): PULSE_AUTH_PASS=mypassword
      # 2. Pre-hashed (advanced): PULSE_AUTH_PASS='$$2a$$12$$...'
      #    Note: Escape $ as $$ in docker-compose.yml for pre-hashed values
      
      # Performance
      # - CONNECTION_TIMEOUT=10             # Connection timeout in seconds (default: 10)
      
      # CORS &amp;amp; logging
      # - ALLOWED_ORIGINS=https://app.example.com  # CORS origins (default: none, same-origin only)
      # - LOG_LEVEL=info                    # Log level: debug/info/warn/error (default: info)
    restart: unless-stopped

volumes:
  pulse_data:
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication required&lt;/strong&gt; - Protects your Proxmox infrastructure credentials&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quick setup wizard&lt;/strong&gt; - Secure your installation in under a minute&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multiple auth methods&lt;/strong&gt;: Password authentication, API tokens, proxy auth (SSO), or combinations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Proxy/SSO support&lt;/strong&gt; - Integrate with Authentik, Authelia, and other authentication proxies (&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;docs&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise-grade protection&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Credentials encrypted at rest (AES-256-GCM)&lt;/li&gt; 
   &lt;li&gt;CSRF tokens for state-changing operations&lt;/li&gt; 
   &lt;li&gt;Rate limiting and account lockout protection&lt;/li&gt; 
   &lt;li&gt;Secure session management with HttpOnly cookies&lt;/li&gt; 
   &lt;li&gt;bcrypt password hashing (cost 12) - passwords NEVER stored in plain text&lt;/li&gt; 
   &lt;li&gt;API tokens stored securely with restricted file permissions&lt;/li&gt; 
   &lt;li&gt;Security headers (CSP, X-Frame-Options, etc.)&lt;/li&gt; 
   &lt;li&gt;Comprehensive audit logging&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security by design&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;Frontend never receives node credentials&lt;/li&gt; 
   &lt;li&gt;API tokens visible only to authenticated users&lt;/li&gt; 
   &lt;li&gt;Export/import requires authentication when configured&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security Documentation&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Updating&lt;/h2&gt; 
&lt;h3&gt;Update Notifications&lt;/h3&gt; 
&lt;p&gt;Pulse checks for updates and displays notifications in the UI when new versions are available. For security reasons, updates must be installed manually using the appropriate method for your deployment.&lt;/p&gt; 
&lt;h3&gt;Manual Installation (systemd)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Update to latest stable
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash

# Update to latest RC/pre-release  
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --rc

# Install specific version
curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash -s -- --version v4.8.0-rc.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker Updates&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Latest stable
docker pull rcourtman/pulse:latest

# Latest RC
docker pull rcourtman/pulse:rc

# Specific version
docker pull rcourtman/pulse:v4.8.0-rc.1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Configuration&lt;/h2&gt; 
&lt;p&gt;Quick start - most settings are in the web UI:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Settings ‚Üí Nodes&lt;/strong&gt;: Add/remove Proxmox instances&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Settings ‚Üí System&lt;/strong&gt;: Polling intervals, timeouts, update settings&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Settings ‚Üí Security&lt;/strong&gt;: Authentication and API tokens&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alerts&lt;/strong&gt;: Thresholds and notifications&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Apprise Notifications&lt;/h3&gt; 
&lt;p&gt;Pulse can broadcast grouped alerts through &lt;a href="https://github.com/caronc/apprise"&gt;Apprise&lt;/a&gt; using either the local CLI or a remote Apprise API gateway. Configure everything under &lt;strong&gt;Alerts ‚Üí Notifications ‚Üí Apprise&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local CLI&lt;/strong&gt; ‚Äì Install Apprise on the Pulse host (for example &lt;code&gt;pip install apprise&lt;/code&gt;) and enter one Apprise URL per line in the delivery targets field. You can override the CLI path and timeout if the executable lives outside of &lt;code&gt;$PATH&lt;/code&gt;. Pulse skips CLI delivery automatically when no targets are configured.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remote API&lt;/strong&gt; ‚Äì Point Pulse at an Apprise API server by providing the base URL (such as &lt;code&gt;https://apprise-api.local:8000&lt;/code&gt;). Optionally include a configuration key (for &lt;code&gt;/notify/{key}&lt;/code&gt; routes), an API key header/value pair, and allow self-signed certificates for lab deployments. Targets remain optional in API mode‚Äîleave the list empty to let the Apprise server use its stored defaults.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For both modes, delivery targets accept any Apprise URL (Discord, Slack, email, SMS, etc.). The timeout applies to the CLI process or HTTP request respectively.&lt;/p&gt; 
&lt;h3&gt;Configuration Files&lt;/h3&gt; 
&lt;p&gt;Pulse uses three separate configuration files with clear separation of concerns:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;.env&lt;/code&gt; - Authentication credentials only&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;system.json&lt;/code&gt; - Application settings&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;nodes.enc&lt;/code&gt; - Encrypted node credentials&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;docs/CONFIGURATION.md&lt;/a&gt; for detailed documentation on configuration structure and management.&lt;/p&gt; 
&lt;h3&gt;Email Alerts Configuration&lt;/h3&gt; 
&lt;p&gt;Configure email notifications in &lt;strong&gt;Settings ‚Üí Alerts ‚Üí Email Destinations&lt;/strong&gt;&lt;/p&gt; 
&lt;h4&gt;Supported Providers&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Gmail/Google Workspace&lt;/strong&gt;: Requires app-specific password&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Outlook/Office 365&lt;/strong&gt;: Requires app-specific password&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Custom SMTP&lt;/strong&gt;: Any SMTP server&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Recommended Settings&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Port 587 with STARTTLS&lt;/strong&gt; (recommended for most providers)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Port 465&lt;/strong&gt; for SSL/TLS&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Port 25&lt;/strong&gt; for unencrypted (not recommended)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Gmail Setup&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Enable 2-factor authentication&lt;/li&gt; 
 &lt;li&gt;Generate app-specific password at &lt;a href="https://myaccount.google.com/apppasswords"&gt;https://myaccount.google.com/apppasswords&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use your email as username and app password as password&lt;/li&gt; 
 &lt;li&gt;Server: smtp.gmail.com, Port: 587, Enable STARTTLS&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Outlook Setup&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Generate app password at &lt;a href="https://account.microsoft.com/security"&gt;https://account.microsoft.com/security&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use your email as username and app password as password&lt;/li&gt; 
 &lt;li&gt;Server: smtp-mail.outlook.com, Port: 587, Enable STARTTLS&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Alert Configuration&lt;/h3&gt; 
&lt;p&gt;Pulse provides two complementary approaches for managing alerts:&lt;/p&gt; 
&lt;h4&gt;Custom Alert Rules (Permanent Policy)&lt;/h4&gt; 
&lt;p&gt;Configure persistent alert policies in &lt;strong&gt;Settings ‚Üí Alerts ‚Üí Custom Rules&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Define thresholds for specific VMs/containers based on name patterns&lt;/li&gt; 
 &lt;li&gt;Set different thresholds for production vs development environments&lt;/li&gt; 
 &lt;li&gt;Create complex rules with AND/OR logic&lt;/li&gt; 
 &lt;li&gt;Manage all rules through the UI with priority ordering&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Use for:&lt;/strong&gt; Long-term alert policies like "all database VMs should alert at 90%"&lt;/p&gt; 
&lt;h3&gt;HTTPS/TLS Configuration&lt;/h3&gt; 
&lt;p&gt;Enable HTTPS by setting these environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Systemd (service: pulse; legacy installs may use pulse-backend): sudo systemctl edit pulse
Environment="HTTPS_ENABLED=true"
Environment="TLS_CERT_FILE=/etc/pulse/cert.pem"
Environment="TLS_KEY_FILE=/etc/pulse/key.pem"

# Docker
docker run -d -p 7655:7655 \
  -e HTTPS_ENABLED=true \
  -e TLS_CERT_FILE=/data/cert.pem \
  -e TLS_KEY_FILE=/data/key.pem \
  -v pulse_data:/data \
  -v /path/to/certs:/data/certs:ro \
  rcourtman/pulse:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For deployment overrides (ports, etc), use environment variables:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Systemd (service: pulse; legacy installs may use pulse-backend): sudo systemctl edit pulse
Environment="FRONTEND_PORT=8080"

# Docker: -e FRONTEND_PORT=8080
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;Full Configuration Guide ‚Üí&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Backup/Restore&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Via UI (recommended):&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Settings ‚Üí Security ‚Üí Backup &amp;amp; Restore&lt;/li&gt; 
 &lt;li&gt;Export: Choose login password or custom passphrase for encryption&lt;/li&gt; 
 &lt;li&gt;Import: Upload backup file with passphrase&lt;/li&gt; 
 &lt;li&gt;Includes all settings, nodes, and custom console URLs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Via CLI:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Export (v4.0.3+)
pulse config export -o backup.enc

# Import
pulse config import -i backup.enc
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;p&gt;Pulse shows when updates are available and provides deployment-specific instructions:&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker pull rcourtman/pulse:latest
docker stop pulse
docker rm pulse
# Run docker run command again with your settings
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual Install&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -fsSL https://raw.githubusercontent.com/rcourtman/Pulse/main/install.sh | bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The UI will detect your deployment type and show the appropriate update method when a new version is available.&lt;/p&gt; 
&lt;h2&gt;API&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Status
curl http://localhost:7655/api/health

# Metrics (default time range: 1h)
curl http://localhost:7655/api/charts

# With authentication (if configured)
curl -H "X-API-Token: your-token" http://localhost:7655/api/health
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/API.md"&gt;Full API Documentation ‚Üí&lt;/a&gt;&lt;/strong&gt; - Complete endpoint reference with examples&lt;/p&gt; 
&lt;h2&gt;Reverse Proxy &amp;amp; SSO&lt;/h2&gt; 
&lt;p&gt;Using Pulse behind a reverse proxy? &lt;strong&gt;WebSocket support is required for real-time updates.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;NEW: Proxy Authentication Support&lt;/strong&gt; - Integrate with Authentik, Authelia, and other SSO providers. See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;Proxy Authentication Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/REVERSE_PROXY.md"&gt;Reverse Proxy Configuration Guide&lt;/a&gt; for nginx, Caddy, Apache, Traefik, HAProxy, and Cloudflare Tunnel configurations.&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;Authentication Issues&lt;/h3&gt; 
&lt;h4&gt;Cannot login after setting up security&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;: Ensure bcrypt hash is exactly 60 characters and wrapped in single quotes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Compose&lt;/strong&gt;: MUST escape $ characters as $$ (e.g., &lt;code&gt;$$2a$$12$$...&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example (docker run)&lt;/strong&gt;: &lt;code&gt;PULSE_AUTH_PASS='$2a$12$YTZXOCEylj4TaevZ0DCeI.notayQZ..b0OZ97lUZ.Q24fljLiMQHK'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Example (docker-compose.yml)&lt;/strong&gt;: &lt;code&gt;PULSE_AUTH_PASS='$$2a$$12$$YTZXOCEylj4TaevZ0DCeI.notayQZ..b0OZ97lUZ.Q24fljLiMQHK'&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;If hash is truncated or mangled, authentication will fail&lt;/li&gt; 
 &lt;li&gt;Use Quick Security Setup in the UI to avoid manual configuration errors&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;.env file not created (Docker)&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Expected behavior&lt;/strong&gt;: When using environment variables, no .env file is created in /data&lt;/li&gt; 
 &lt;li&gt;The .env file is only created when using Quick Security Setup or password changes&lt;/li&gt; 
 &lt;li&gt;If you provide credentials via environment variables, they take precedence&lt;/li&gt; 
 &lt;li&gt;To use Quick Security Setup: Start container WITHOUT auth environment variables&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;VM Disk Stats Show "-"&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;VMs require QEMU Guest Agent to report disk usage (Proxmox API returns 0 for VMs)&lt;/li&gt; 
 &lt;li&gt;Install guest agent in VM: &lt;code&gt;apt install qemu-guest-agent&lt;/code&gt; (Linux) or virtio-win tools (Windows)&lt;/li&gt; 
 &lt;li&gt;Enable in VM Options ‚Üí QEMU Guest Agent, then restart VM&lt;/li&gt; 
 &lt;li&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/VM_DISK_MONITORING.md"&gt;VM Disk Monitoring Guide&lt;/a&gt; for setup&lt;/li&gt; 
 &lt;li&gt;Container (LXC) disk stats always work (no guest agent needed)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Connection Issues&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check Proxmox API is accessible (port 8006/8007)&lt;/li&gt; 
 &lt;li&gt;Verify credentials have PVEAuditor role plus VM.GuestAgent.Audit (PVE 9) or VM.Monitor (PVE 8); the setup script applies these via the PulseMonitor role (adds Sys.Audit when available)&lt;/li&gt; 
 &lt;li&gt;For PBS: ensure API token has Datastore.Audit permission&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;High CPU/Memory&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Reduce polling interval in Settings&lt;/li&gt; 
 &lt;li&gt;Check number of monitored nodes&lt;/li&gt; 
 &lt;li&gt;Disable unused features (backups, snapshots)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Logs&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Docker
docker logs pulse

# Manual
journalctl -u pulse -f
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/DOCKER.md"&gt;Docker Guide&lt;/a&gt; - Complete Docker deployment guide&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/CONFIGURATION.md"&gt;Configuration Guide&lt;/a&gt; - Complete setup and configuration&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/VM_DISK_MONITORING.md"&gt;VM Disk Monitoring&lt;/a&gt; - Set up QEMU Guest Agent for accurate VM disk usage&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PORT_CONFIGURATION.md"&gt;Port Configuration&lt;/a&gt; - How to change the default port&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/TROUBLESHOOTING.md"&gt;Troubleshooting&lt;/a&gt; - Common issues and solutions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/API.md"&gt;API Reference&lt;/a&gt; - REST API endpoints and examples&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/WEBHOOKS.md"&gt;Webhook Guide&lt;/a&gt; - Setting up webhooks and custom payloads&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/PROXY_AUTH.md"&gt;Proxy Authentication&lt;/a&gt; - SSO integration with Authentik, Authelia, etc.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/REVERSE_PROXY.md"&gt;Reverse Proxy Setup&lt;/a&gt; - nginx, Caddy, Apache, Traefik configs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security&lt;/a&gt; - Security features and best practices&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/FAQ.md"&gt;FAQ&lt;/a&gt; - Common questions and troubleshooting&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/MIGRATION.md"&gt;Migration Guide&lt;/a&gt; - Backup and migration procedures&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Mandatory authentication&lt;/strong&gt; protects your infrastructure&lt;/li&gt; 
 &lt;li&gt;Credentials stored encrypted (AES-256-GCM)&lt;/li&gt; 
 &lt;li&gt;API token support for automation&lt;/li&gt; 
 &lt;li&gt;Export/import requires authentication&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Setup script authentication&lt;/strong&gt;: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Setup codes&lt;/strong&gt;: Temporary 6-character codes for manual setup (expire in 5 minutes)&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;API tokens&lt;/strong&gt;: Permanent tokens for automation and scripting&lt;/li&gt; 
   &lt;li&gt;Use setup codes when giving access to others without sharing your API token&lt;/li&gt; 
   &lt;li&gt;Use API tokens for your own automation or trusted environments&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SECURITY.md"&gt;Security Details ‚Üí&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development&lt;/h2&gt; 
&lt;h3&gt;Quick Start - Hot Reload (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Launch Vite + Go with automatic frontend proxying
make dev-hot
# Frontend HMR: http://127.0.0.1:5173
# Backend API:   http://127.0.0.1:7655 (served via the Go app)
# Ports come from FRONTEND_PORT/PULSE_DEV_API_PORT (loaded from .env*. Override there if you need a different port.)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The backend now detects &lt;code&gt;FRONTEND_DEV_SERVER&lt;/code&gt; and proxies requests straight to the Vite dev server. Edit files under &lt;code&gt;frontend-modern/src/&lt;/code&gt; and the browser refreshes instantly‚Äîno manual rebuilds or service restarts required. Use &lt;code&gt;CTRL+C&lt;/code&gt; to stop both processes.&lt;/p&gt; 
&lt;h3&gt;Mock Mode - Develop Without Real Infrastructure&lt;/h3&gt; 
&lt;p&gt;Work on Pulse without needing Proxmox servers! Mock mode generates realistic test data and auto-reloads when toggled. The &lt;code&gt;mock.env&lt;/code&gt; configuration file is &lt;strong&gt;included in the repository&lt;/strong&gt;, so it works out of the box for all developers.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Enable mock mode with 7 nodes, ~90 guests
npm run mock:on

# Disable mock mode (use real infrastructure)
npm run mock:off

# Edit mock configuration
npm run mock:edit

# Create local overrides (not committed to git)
cp mock.env mock.env.local
# Edit mock.env.local with your personal preferences

# Data directories are isolated automatically:
# - Mock mode:   /opt/pulse/tmp/mock-data
# - Production:  /etc/pulse
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Backend auto-reloads when mock.env changes - no manual restarts!&lt;/strong&gt; The toggle scripts keep mock data isolated from &lt;code&gt;/etc/pulse&lt;/code&gt; so your real credentials stay untouched.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/development/MOCK_MODE.md"&gt;docs/development/MOCK_MODE.md&lt;/a&gt; for full details.&lt;/p&gt; 
&lt;h3&gt;Production-like Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Watches files and rebuilds/embeds frontend into Go binary
./dev.sh
# Access at: http://localhost:7655
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual Development&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Frontend only
cd frontend-modern
npm install
npm run dev

# Backend only
go build -o pulse ./cmd/pulse
./pulse

# Or use make for full rebuild
make dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Visual Tour&lt;/h2&gt; 
&lt;p&gt;See Pulse in action with our &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/SCREENSHOTS.md"&gt;complete screenshot gallery ‚Üí&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Core Features&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Dashboard&lt;/th&gt; 
   &lt;th&gt;Storage&lt;/th&gt; 
   &lt;th&gt;Backups&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/01-dashboard.png" alt="Dashboard" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/02-storage.png" alt="Storage" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/03-backups.png" alt="Backups" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Real-time monitoring of nodes, VMs &amp;amp; containers&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Storage pool usage across all nodes&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Unified backup management &amp;amp; PBS integration&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Alerts &amp;amp; Configuration&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Alert Configuration&lt;/th&gt; 
   &lt;th&gt;Alert History&lt;/th&gt; 
   &lt;th&gt;Settings&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/04-alerts.png" alt="Alerts" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/05-alert-history.png" alt="Alert History" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/06-settings.png" alt="Settings" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Configure thresholds &amp;amp; notifications&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Track patterns with visual timeline&lt;/em&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;Manage nodes &amp;amp; authentication&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Mobile Experience&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Mobile Dashboard&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/rcourtman/Pulse/main/docs/images/08-mobile.png" alt="Mobile" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;em&gt;Fully responsive interface for monitoring on the go&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rcourtman/Pulse/releases"&gt;Releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hub.docker.com/r/rcourtman/pulse"&gt;Docker Hub&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rcourtman/Pulse/issues"&gt;Issues&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT - See &lt;a href="https://raw.githubusercontent.com/rcourtman/Pulse/main/LICENSE"&gt;LICENSE&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>tailscale/tailscale</title>
      <link>https://github.com/tailscale/tailscale</link>
      <description>&lt;p&gt;The easiest, most secure way to use WireGuard and 2FA.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Tailscale&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://tailscale.com"&gt;https://tailscale.com&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Private WireGuard¬Æ networks made easy&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;This repository contains the majority of Tailscale's open source code. Notably, it includes the &lt;code&gt;tailscaled&lt;/code&gt; daemon and the &lt;code&gt;tailscale&lt;/code&gt; CLI tool. The &lt;code&gt;tailscaled&lt;/code&gt; daemon runs on Linux, Windows, &lt;a href="https://tailscale.com/kb/1065/macos-variants/"&gt;macOS&lt;/a&gt;, and to varying degrees on FreeBSD and OpenBSD. The Tailscale iOS and Android apps use this repo's code, but this repo doesn't contain the mobile GUI code.&lt;/p&gt; 
&lt;p&gt;Other &lt;a href="https://github.com/orgs/tailscale/repositories"&gt;Tailscale repos&lt;/a&gt; of note:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;the Android app is at &lt;a href="https://github.com/tailscale/tailscale-android"&gt;https://github.com/tailscale/tailscale-android&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the Synology package is at &lt;a href="https://github.com/tailscale/tailscale-synology"&gt;https://github.com/tailscale/tailscale-synology&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the QNAP package is at &lt;a href="https://github.com/tailscale/tailscale-qpkg"&gt;https://github.com/tailscale/tailscale-qpkg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;the Chocolatey packaging is at &lt;a href="https://github.com/tailscale/tailscale-chocolatey"&gt;https://github.com/tailscale/tailscale-chocolatey&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;For background on which parts of Tailscale are open source and why, see &lt;a href="https://tailscale.com/opensource/"&gt;https://tailscale.com/opensource/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Using&lt;/h2&gt; 
&lt;p&gt;We serve packages for a variety of distros and platforms at &lt;a href="https://pkgs.tailscale.com/"&gt;https://pkgs.tailscale.com&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Other clients&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://tailscale.com/download"&gt;macOS, iOS, and Windows clients&lt;/a&gt; use the code in this repository but additionally include small GUI wrappers. The GUI wrappers on non-open source platforms are themselves not open source.&lt;/p&gt; 
&lt;h2&gt;Building&lt;/h2&gt; 
&lt;p&gt;We always require the latest Go release, currently Go 1.25. (While we build releases with our &lt;a href="https://github.com/tailscale/go/"&gt;Go fork&lt;/a&gt;, its use is not required.)&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;go install tailscale.com/cmd/tailscale{,d}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're packaging Tailscale for distribution, use &lt;code&gt;build_dist.sh&lt;/code&gt; instead, to burn commit IDs and version info into the binaries:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./build_dist.sh tailscale.com/cmd/tailscale
./build_dist.sh tailscale.com/cmd/tailscaled
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If your distro has conventions that preclude the use of &lt;code&gt;build_dist.sh&lt;/code&gt;, please do the equivalent of what it does in your distro's way, so that bug reports contain useful version information.&lt;/p&gt; 
&lt;h2&gt;Bugs&lt;/h2&gt; 
&lt;p&gt;Please file any issues about this code or the hosted service on &lt;a href="https://github.com/tailscale/tailscale/issues"&gt;the issue tracker&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;PRs welcome! But please file bugs. Commit messages should &lt;a href="https://docs.github.com/en/github/writing-on-github/autolinked-references-and-urls"&gt;reference bugs&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We require &lt;a href="https://en.wikipedia.org/wiki/Developer_Certificate_of_Origin"&gt;Developer Certificate of Origin&lt;/a&gt; &lt;code&gt;Signed-off-by&lt;/code&gt; lines in commits.&lt;/p&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/tailscale/tailscale/main/docs/commit-messages.md"&gt;commit-messages.md&lt;/a&gt; (or skim &lt;code&gt;git log&lt;/code&gt;) for our commit message style.&lt;/p&gt; 
&lt;h2&gt;About Us&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://tailscale.com/"&gt;Tailscale&lt;/a&gt; is primarily developed by the people at &lt;a href="https://github.com/orgs/tailscale/people"&gt;https://github.com/orgs/tailscale/people&lt;/a&gt;. For other contributors, see:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tailscale/tailscale/graphs/contributors"&gt;https://github.com/tailscale/tailscale/graphs/contributors&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tailscale/tailscale-android/graphs/contributors"&gt;https://github.com/tailscale/tailscale-android/graphs/contributors&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Legal&lt;/h2&gt; 
&lt;p&gt;WireGuard is a registered trademark of Jason A. Donenfeld.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>minio/minio</title>
      <link>https://github.com/minio/minio</link>
      <description>&lt;p&gt;MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MinIO Quickstart Guide&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://slack.min.io"&gt;&lt;img src="https://slack.min.io/slack?type=svg" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/minio/minio/"&gt;&lt;img src="https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-AGPL%20V3-blue" alt="license" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://min.io"&gt;&lt;img src="https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true" alt="MinIO" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;MinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license. Designed for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;S3 API Compatible ‚Äì Seamless integration with existing S3 tools&lt;/li&gt; 
 &lt;li&gt;Built for AI &amp;amp; Analytics ‚Äì Optimized for large-scale data pipelines&lt;/li&gt; 
 &lt;li&gt;High Performance ‚Äì Ideal for demanding storage workloads.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This README provides instructions for building MinIO from source and deploying onto baremetal hardware. Use the &lt;a href="https://github.com/minio/docs"&gt;MinIO Documentation&lt;/a&gt; project to build and host a local copy of the documentation.&lt;/p&gt; 
&lt;h2&gt;MinIO is Open Source Software&lt;/h2&gt; 
&lt;p&gt;We designed MinIO as Open Source software for the Open Source software community. We encourage the community to remix, redesign, and reshare MinIO under the terms of the AGPLv3 license.&lt;/p&gt; 
&lt;p&gt;All usage of MinIO in your application stack requires validation against AGPLv3 obligations, which include but are not limited to the release of modified code to the community from which you have benefited. Any commercial/proprietary usage of the AGPLv3 software, including repackaging or reselling services/features, is done at your own risk.&lt;/p&gt; 
&lt;p&gt;The AGPLv3 provides no obligation by any party to support, maintain, or warranty the original or any modified work. All support is provided on a best-effort basis through Github and our &lt;a href="https://raw.githubusercontent.com/minio/minio/master/https//slack.min.io"&gt;Slack&lt;/a&gt; channel, and any member of the community is welcome to contribute and assist others in their usage of the software.&lt;/p&gt; 
&lt;p&gt;MinIO &lt;a href="https://www.min.io/product/aistor"&gt;AIStor&lt;/a&gt; includes enterprise-grade support and licensing for workloads which require commercial or proprietary usage and production-level SLA/SLO-backed support. For more information, &lt;a href="https://min.io/pricing"&gt;reach out for a quote&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Source-Only Distribution&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The MinIO community edition is now distributed as source code only. We will no longer provide pre-compiled binary releases for the community version.&lt;/p&gt; 
&lt;h3&gt;Installing Latest MinIO Community Edition&lt;/h3&gt; 
&lt;p&gt;To use MinIO community edition, you have two options:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Install from source&lt;/strong&gt; using &lt;code&gt;go install github.com/minio/minio@latest&lt;/code&gt; (recommended)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Build a Docker image&lt;/strong&gt; from the provided Dockerfile&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See the sections below for detailed instructions on each method.&lt;/p&gt; 
&lt;h3&gt;Legacy Binary Releases&lt;/h3&gt; 
&lt;p&gt;Historical pre-compiled binary releases remain available for reference but are no longer maintained:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;GitHub Releases: &lt;a href="https://github.com/minio/minio/releases"&gt;https://github.com/minio/minio/releases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Direct downloads: &lt;a href="https://dl.min.io/server/minio/release/"&gt;https://dl.min.io/server/minio/release/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;These legacy binaries will not receive updates.&lt;/strong&gt; We strongly recommend using source builds for access to the latest features, bug fixes, and security updates.&lt;/p&gt; 
&lt;h2&gt;Install from Source&lt;/h2&gt; 
&lt;p&gt;Use the following commands to compile and run a standalone MinIO server from source. If you do not have a working Golang environment, please follow &lt;a href="https://golang.org/doc/install"&gt;How to install Golang&lt;/a&gt;. Minimum version required is &lt;a href="https://golang.org/dl/#stable"&gt;go1.24&lt;/a&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go install github.com/minio/minio@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can alternatively run &lt;code&gt;go build&lt;/code&gt; and use the &lt;code&gt;GOOS&lt;/code&gt; and &lt;code&gt;GOARCH&lt;/code&gt; environment variables to control the OS and architecture target. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;env GOOS=linux GOARCh=arm64 go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Start MinIO by running &lt;code&gt;minio server PATH&lt;/code&gt; where &lt;code&gt;PATH&lt;/code&gt; is any empty folder on your local filesystem.&lt;/p&gt; 
&lt;p&gt;The MinIO deployment starts using default root credentials &lt;code&gt;minioadmin:minioadmin&lt;/code&gt;. You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server. Point a web browser running on the host machine to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; and log in with the root credentials. You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.&lt;/p&gt; 
&lt;p&gt;You can also connect using any S3-compatible tool, such as the MinIO Client &lt;code&gt;mc&lt;/code&gt; commandline tool:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info local
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#test-using-minio-client-mc"&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/a&gt; for more information on using the &lt;code&gt;mc&lt;/code&gt; commandline tool. For application developers, see &lt;a href="https://docs.min.io/enterprise/aistor-object-store/developers/sdk/"&gt;https://docs.min.io/enterprise/aistor-object-store/developers/sdk/&lt;/a&gt; to view MinIO SDKs for supported languages.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Production environments using compiled-from-source MinIO binaries do so at their own risk. The AGPLv3 license provides no warranties nor liabilites for any such usage.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Build Docker Image&lt;/h2&gt; 
&lt;p&gt;You can use the &lt;code&gt;docker build .&lt;/code&gt; command to build a Docker image on your local host machine. You must first &lt;a href="https://raw.githubusercontent.com/minio/minio/master/#install-from-source"&gt;build MinIO&lt;/a&gt; and ensure the &lt;code&gt;minio&lt;/code&gt; binary exists in the project root.&lt;/p&gt; 
&lt;p&gt;The following command builds the Docker image using the default &lt;code&gt;Dockerfile&lt;/code&gt; in the root project directory with the repository and image tag &lt;code&gt;myminio:minio&lt;/code&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t myminio:minio .
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Use &lt;code&gt;docker image ls&lt;/code&gt; to confirm the image exists in your local repository. You can run the server using standard Docker invocation:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker run -p 9000:9000 -p 9001:9001 myminio:minio server /tmp/minio --console-address :9001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Complete documentation for building Docker containers, managing custom images, or loading images into orchestration platforms is out of scope for this documentation. You can modify the &lt;code&gt;Dockerfile&lt;/code&gt; and &lt;code&gt;dockerscripts/docker-entrypoint.sh&lt;/code&gt; as-needed to reflect your specific image requirements.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/baremetal-deploy-minio-as-a-container.html#deploy-minio-container"&gt;MinIO Container&lt;/a&gt; documentation for more guidance on running MinIO within a Container image.&lt;/p&gt; 
&lt;h2&gt;Install using Helm Charts&lt;/h2&gt; 
&lt;p&gt;There are two paths for installing MinIO onto Kubernetes infrastructure:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;a href="https://github.com/minio/operator"&gt;MinIO Operator&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Use the community-maintained &lt;a href="https://github.com/minio/minio/tree/master/helm/minio"&gt;Helm charts&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://docs.min.io/community/minio-object-store/operations/deployments/kubernetes.html"&gt;MinIO Documentation&lt;/a&gt; for guidance on deploying using the Operator. The Community Helm chart has instructions in the folder-level README.&lt;/p&gt; 
&lt;h2&gt;Test MinIO Connectivity&lt;/h2&gt; 
&lt;h3&gt;Test using MinIO Console&lt;/h3&gt; 
&lt;p&gt;MinIO Server comes with an embedded web based object browser. Point your web browser to &lt;a href="http://127.0.0.1:9000"&gt;http://127.0.0.1:9000&lt;/a&gt; to ensure your server has started successfully.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] MinIO runs console on random port by default, if you wish to choose a specific port use &lt;code&gt;--console-address&lt;/code&gt; to pick a specific interface and port.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Test using MinIO Client &lt;code&gt;mc&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;mc&lt;/code&gt; provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services.&lt;/p&gt; 
&lt;p&gt;The following commands set a local alias, validate the server information, create a bucket, copy data to that bucket, and list the contents of the bucket.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info
mc mb data
mc cp ~/Downloads/mydata data/
mc ls data/
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Follow the MinIO Client &lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html#quickstart"&gt;Quickstart Guide&lt;/a&gt; for further instructions.&lt;/p&gt; 
&lt;h2&gt;Explore Further&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/index.html"&gt;The MinIO documentation website&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/operations/concepts/erasure-coding.html"&gt;MinIO Erasure Code Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/community/minio-object-store/reference/minio-mc.html"&gt;Use &lt;code&gt;mc&lt;/code&gt; with MinIO Server&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.min.io/enterprise/aistor-object-store/developers/sdk/go/"&gt;Use &lt;code&gt;minio-go&lt;/code&gt; SDK with MinIO Server&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contribute to MinIO Project&lt;/h2&gt; 
&lt;p&gt;Please follow MinIO &lt;a href="https://github.com/minio/minio/raw/master/CONTRIBUTING.md"&gt;Contributor's Guide&lt;/a&gt; for guidance on making new contributions to the repository.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;MinIO source is licensed under the &lt;a href="https://github.com/minio/minio/raw/master/LICENSE"&gt;GNU AGPLv3&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;MinIO &lt;a href="https://github.com/minio/minio/tree/master/docs"&gt;documentation&lt;/a&gt; is licensed under &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;CC BY 4.0&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/minio/minio/raw/master/COMPLIANCE.md"&gt;License Compliance&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>redis/go-redis</title>
      <link>https://github.com/redis/go-redis</link>
      <description>&lt;p&gt;Redis Go client&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Redis client for Go&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://github.com/redis/go-redis/actions"&gt;&lt;img src="https://github.com/redis/go-redis/actions/workflows/build.yml/badge.svg?sanitize=true" alt="build workflow" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9?tab=doc"&gt;&lt;img src="https://pkg.go.dev/badge/github.com/redis/go-redis/v9" alt="PkgGoDev" /&gt;&lt;/a&gt; &lt;a href="https://redis.uptrace.dev/"&gt;&lt;img src="https://img.shields.io/badge/redis-documentation-informational" alt="Documentation" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/redis/go-redis/v9"&gt;&lt;img src="https://goreportcard.com/badge/github.com/redis/go-redis/v9" alt="Go Report Card" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/github/redis/go-redis"&gt;&lt;img src="https://codecov.io/github/redis/go-redis/graph/badge.svg?token=tsrCZKuSSw" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/W4txy5AeKM"&gt;&lt;img src="https://img.shields.io/discord/697882427875393627.svg?style=social&amp;amp;logo=discord" alt="Discord" /&gt;&lt;/a&gt; &lt;a href="https://www.twitch.tv/redisinc"&gt;&lt;img src="https://img.shields.io/twitch/status/redisinc?style=social" alt="Twitch" /&gt;&lt;/a&gt; &lt;a href="https://www.youtube.com/redisinc"&gt;&lt;img src="https://img.shields.io/youtube/channel/views/UCD78lHSwYqMlyetR0_P4Vig?style=social" alt="YouTube" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/redisinc"&gt;&lt;img src="https://img.shields.io/twitter/follow/redisinc?style=social" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://stackoverflow.com/questions/tagged/go-redis"&gt;&lt;img src="https://img.shields.io/stackexchange/stackoverflow/t/go-redis?style=social&amp;amp;logo=stackoverflow&amp;amp;label=Stackoverflow" alt="Stack Exchange questions" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;go-redis is the official Redis client library for the Go programming language. It offers a straightforward interface for interacting with Redis servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Supported versions&lt;/h2&gt; 
&lt;p&gt;In &lt;code&gt;go-redis&lt;/code&gt; we are aiming to support the last three releases of Redis. Currently, this means we do support:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/7.2/00-RELEASENOTES"&gt;Redis 7.2&lt;/a&gt; - using Redis Stack 7.2 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/7.4/00-RELEASENOTES"&gt;Redis 7.4&lt;/a&gt; - using Redis Stack 7.4 for modules support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/8.0/00-RELEASENOTES"&gt;Redis 8.0&lt;/a&gt; - using Redis CE 8.0 where modules are included&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/redis/8.2/00-RELEASENOTES"&gt;Redis 8.2&lt;/a&gt; - using Redis CE 8.2 where modules are included&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Although the &lt;code&gt;go.mod&lt;/code&gt; states it requires at minimum &lt;code&gt;go 1.18&lt;/code&gt;, our CI is configured to run the tests against all three versions of Redis and latest two versions of Go (&lt;a href="https://go.dev/doc/devel/release#go1.23.0"&gt;1.23&lt;/a&gt;, &lt;a href="https://go.dev/doc/devel/release#go1.24.0"&gt;1.24&lt;/a&gt;). We observe that some modules related test may not pass with Redis Stack 7.2 and some commands are changed with Redis CE 8.0. Please do refer to the documentation and the tests if you experience any issues. We do plan to update the go version in the &lt;code&gt;go.mod&lt;/code&gt; to &lt;code&gt;go 1.24&lt;/code&gt; in one of the next releases.&lt;/p&gt; 
&lt;h2&gt;How do I Redis?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://university.redis.com/"&gt;Learn for free at Redis University&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://launchpad.redis.com/"&gt;Build faster with the Redis Launchpad&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/try-free/"&gt;Try the Redis Cloud&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://developer.redis.com/"&gt;Dive in developer tutorials&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/community/"&gt;Join the Redis community&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://redis.com/company/careers/jobs/"&gt;Work at Redis&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev"&gt;English&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/zh/"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/redis/go-redis/discussions"&gt;Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/W4txy5AeKM"&gt;Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9"&gt;Reference&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://pkg.go.dev/github.com/redis/go-redis/v9#pkg-examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Ecosystem&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/redismock"&gt;Redis Mock&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/bsm/redislock"&gt;Distributed Locks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/cache"&gt;Redis Cache&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-redis/redis_rate"&gt;Rate limiting&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This client also works with &lt;a href="https://github.com/apache/incubator-kvrocks"&gt;Kvrocks&lt;/a&gt;, a distributed key value NoSQL database that uses RocksDB as storage engine and is compatible with Redis protocol.&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Redis commands except QUIT and SYNC.&lt;/li&gt; 
 &lt;li&gt;Automatic connection pooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/#1-streaming-credentials-provider-highest-priority"&gt;StreamingCredentialsProvider (e.g. entra id, oauth)&lt;/a&gt; (experimental)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-pubsub.html"&gt;Pub/Sub&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-pipelines.html"&gt;Pipelines and transactions&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/lua-scripting.html"&gt;Scripting&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-sentinel.html"&gt;Redis Sentinel&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/go-redis-cluster.html"&gt;Redis Cluster&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/ring.html"&gt;Redis Ring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.uptrace.dev/guide/redis-performance-monitoring.html"&gt;Redis Performance Monitoring&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://redis.io/docs/data-types/probabilistic/"&gt;Redis Probabilistic [RedisStack]&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/#custom-buffer-sizes"&gt;Customizable read and write buffers size.&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;go-redis supports 2 last Go versions and requires a Go version with &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;modules&lt;/a&gt; support. So make sure to initialize a Go module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go mod init github.com/my/repo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install go-redis/&lt;strong&gt;v9&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;go get github.com/redis/go-redis/v9
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Quickstart&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "context"
    "fmt"

    "github.com/redis/go-redis/v9"
)

var ctx = context.Background()

func ExampleClient() {
    rdb := redis.NewClient(&amp;amp;redis.Options{
        Addr:     "localhost:6379",
        Password: "", // no password set
        DB:       0,  // use default DB
    })

    err := rdb.Set(ctx, "key", "value", 0).Err()
    if err != nil {
        panic(err)
    }

    val, err := rdb.Get(ctx, "key").Result()
    if err != nil {
        panic(err)
    }
    fmt.Println("key", val)

    val2, err := rdb.Get(ctx, "key2").Result()
    if err == redis.Nil {
        fmt.Println("key2 does not exist")
    } else if err != nil {
        panic(err)
    } else {
        fmt.Println("key2", val2)
    }
    // Output: key value
    // key2 does not exist
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Authentication&lt;/h3&gt; 
&lt;p&gt;The Redis client supports multiple ways to provide authentication credentials, with a clear priority order. Here are the available options:&lt;/p&gt; 
&lt;h4&gt;1. Streaming Credentials Provider (Highest Priority) - Experimental feature&lt;/h4&gt; 
&lt;p&gt;The streaming credentials provider allows for dynamic credential updates during the connection lifetime. This is particularly useful for managed identity services and token-based authentication.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;type StreamingCredentialsProvider interface {
    Subscribe(listener CredentialsListener) (Credentials, UnsubscribeFunc, error)
}

type CredentialsListener interface {
    OnNext(credentials Credentials)  // Called when credentials are updated
    OnError(err error)              // Called when an error occurs
}

type Credentials interface {
    BasicAuth() (username string, password string)
    RawCredentials() string
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example usage:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    StreamingCredentialsProvider: &amp;amp;MyCredentialsProvider{},
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The streaming credentials provider can be used with &lt;a href="https://github.com/redis/go-redis-entraid"&gt;go-redis-entraid&lt;/a&gt; to enable Entra ID (formerly Azure AD) authentication. This allows for seamless integration with Azure's managed identity services and token-based authentication.&lt;/p&gt; 
&lt;p&gt;Example with Entra ID:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
    "github.com/redis/go-redis-entraid"
)

// Create an Entra ID credentials provider
provider := entraid.NewDefaultAzureIdentityProvider()

// Configure Redis client with Entra ID authentication
rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "your-redis-server.redis.cache.windows.net:6380",
    StreamingCredentialsProvider: provider,
    TLSConfig: &amp;amp;tls.Config{
        MinVersion: tls.VersionTLS12,
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;2. Context-based Credentials Provider&lt;/h4&gt; 
&lt;p&gt;The context-based provider allows credentials to be determined at the time of each operation, using the context.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    CredentialsProviderContext: func(ctx context.Context) (string, string, error) {
        // Return username, password, and any error
        return "user", "pass", nil
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;3. Regular Credentials Provider&lt;/h4&gt; 
&lt;p&gt;A simple function-based provider that returns static credentials.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr: "localhost:6379",
    CredentialsProvider: func() (string, string) {
        // Return username and password
        return "user", "pass"
    },
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;4. Username/Password Fields (Lowest Priority)&lt;/h4&gt; 
&lt;p&gt;The most basic way to provide credentials is through the &lt;code&gt;Username&lt;/code&gt; and &lt;code&gt;Password&lt;/code&gt; fields in the options.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     "localhost:6379",
    Username: "user",
    Password: "pass",
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Priority Order&lt;/h4&gt; 
&lt;p&gt;The client will use credentials in the following priority order:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Streaming Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Context-based Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Regular Credentials Provider (if set)&lt;/li&gt; 
 &lt;li&gt;Username/Password fields (if set)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If none of these are set, the client will attempt to connect without authentication.&lt;/p&gt; 
&lt;h3&gt;Protocol Version&lt;/h3&gt; 
&lt;p&gt;The client supports both RESP2 and RESP3 protocols. You can specify the protocol version in the options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:     "localhost:6379",
    Password: "", // no password set
    DB:       0,  // use default DB
    Protocol: 3,  // specify 2 for RESP 2 or 3 for RESP 3
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Connecting via a redis url&lt;/h3&gt; 
&lt;p&gt;go-redis also supports connecting via the &lt;a href="https://github.com/redis/redis-specifications/tree/master/uri/redis.txt"&gt;redis uri specification&lt;/a&gt;. The example below demonstrates how the connection can easily be configured using a string, adhering to this specification.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
)

func ExampleClient() *redis.Client {
    url := "redis://user:password@localhost:6379/0?protocol=3"
    opts, err := redis.ParseURL(url)
    if err != nil {
        panic(err)
    }

    return redis.NewClient(opts)
}

&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Instrument with OpenTelemetry&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
    "github.com/redis/go-redis/v9"
    "github.com/redis/go-redis/extra/redisotel/v9"
    "errors"
)

func main() {
    ...
    rdb := redis.NewClient(&amp;amp;redis.Options{...})

    if err := errors.Join(redisotel.InstrumentTracing(rdb), redisotel.InstrumentMetrics(rdb)); err != nil {
        log.Fatal(err)
    }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Buffer Size Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis uses 32KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Advanced Configuration&lt;/h3&gt; 
&lt;p&gt;go-redis supports extending the client identification phase to allow projects to send their own custom client identification.&lt;/p&gt; 
&lt;h4&gt;Default Client Identification&lt;/h4&gt; 
&lt;p&gt;By default, go-redis automatically sends the client library name and version during the connection process. This feature is available in redis-server as of version 7.2. As a result, the command is "fire and forget", meaning it should fail silently, in the case that the redis server does not support this feature.&lt;/p&gt; 
&lt;h4&gt;Disabling Identity Verification&lt;/h4&gt; 
&lt;p&gt;When connection identity verification is not required or needs to be explicitly disabled, a &lt;code&gt;DisableIdentity&lt;/code&gt; configuration option exists. Initially there was a typo and the option was named &lt;code&gt;DisableIndentity&lt;/code&gt; instead of &lt;code&gt;DisableIdentity&lt;/code&gt;. The misspelled option is marked as Deprecated and will be removed in V10 of this library. Although both options will work at the moment, the correct option is &lt;code&gt;DisableIdentity&lt;/code&gt;. The deprecated option will be removed in V10 of this library, so please use the correct option name to avoid any issues.&lt;/p&gt; 
&lt;p&gt;To disable verification, set the &lt;code&gt;DisableIdentity&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt; in the Redis client options:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    Password:        "",
    DB:              0,
    DisableIdentity: true, // Disable set-info on connect
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Unstable RESP3 Structures for RediSearch Commands&lt;/h4&gt; 
&lt;p&gt;When integrating Redis with application functionalities using RESP3, it's important to note that some response structures aren't final yet. This is especially true for more complex structures like search and query results. We recommend using RESP2 when using the search and query capabilities, but we plan to stabilize the RESP3-based API-s in the coming versions. You can find more guidance in the upcoming release notes.&lt;/p&gt; 
&lt;p&gt;To enable unstable RESP3, set the option in your client configuration:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;redis.NewClient(&amp;amp;redis.Options{
			UnstableResp3: true,
		})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; When UnstableResp3 mode is enabled, it's necessary to use RawResult() and RawVal() to retrieve a raw data. Since, raw response is the only option for unstable search commands Val() and Result() calls wouldn't have any affect on them:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;res1, err := client.FTSearchWithArgs(ctx, "txt", "foo bar", &amp;amp;redis.FTSearchOptions{}).RawResult()
val1 := client.FTSearchWithArgs(ctx, "txt", "foo bar", &amp;amp;redis.FTSearchOptions{}).RawVal()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Redis-Search Default Dialect&lt;/h4&gt; 
&lt;p&gt;In the Redis-Search module, &lt;strong&gt;the default dialect is 2&lt;/strong&gt;. If needed, you can explicitly specify a different dialect using the appropriate configuration in your queries.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Be aware that the query dialect may impact the results returned. If needed, you can revert to a different dialect version by passing the desired dialect in the arguments of the command you want to execute. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;	res2, err := rdb.FTSearchWithArgs(ctx,
		"idx:bicycle",
		"@pickup_zone:[CONTAINS $bike]",
		&amp;amp;redis.FTSearchOptions{
			Params: map[string]interface{}{
				"bike": "POINT(-0.1278 51.5074)",
			},
			DialectVersion: 3,
		},
	).Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can find further details in the &lt;a href="https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/dialects/"&gt;query dialect documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Custom buffer sizes&lt;/h4&gt; 
&lt;p&gt;Prior to v9.12, the buffer size was the default go value of 4096 bytes. Starting from v9.12, go-redis uses 32KiB read and write buffers by default for optimal performance. For high-throughput applications or large pipelines, you can customize buffer sizes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;rdb := redis.NewClient(&amp;amp;redis.Options{
    Addr:            "localhost:6379",
    ReadBufferSize:  1024 * 1024, // 1MiB read buffer
    WriteBufferSize: 1024 * 1024, // 1MiB write buffer
})
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: If you experience any issues with the default buffer sizes, please try setting them to the go default of 4096 bytes.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions to the go-redis library! If you have a bug fix, feature request, or improvement, please open an issue or pull request on GitHub. We appreciate your help in making go-redis better for everyone. If you are interested in contributing to the go-redis library, please check out our &lt;a href="https://raw.githubusercontent.com/redis/go-redis/master/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt; for more information on how to get started.&lt;/p&gt; 
&lt;h2&gt;Look and feel&lt;/h2&gt; 
&lt;p&gt;Some corner cases:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// SET key value EX 10 NX
set, err := rdb.SetNX(ctx, "key", "value", 10*time.Second).Result()

// SET key value keepttl NX
set, err := rdb.SetNX(ctx, "key", "value", redis.KeepTTL).Result()

// SORT list LIMIT 0 2 ASC
vals, err := rdb.Sort(ctx, "list", &amp;amp;redis.Sort{Offset: 0, Count: 2, Order: "ASC"}).Result()

// ZRANGEBYSCORE zset -inf +inf WITHSCORES LIMIT 0 2
vals, err := rdb.ZRangeByScoreWithScores(ctx, "zset", &amp;amp;redis.ZRangeBy{
    Min: "-inf",
    Max: "+inf",
    Offset: 0,
    Count: 2,
}).Result()

// ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 AGGREGATE SUM
vals, err := rdb.ZInterStore(ctx, "out", &amp;amp;redis.ZStore{
    Keys: []string{"zset1", "zset2"},
    Weights: []int64{2, 3}
}).Result()

// EVAL "return {KEYS[1],ARGV[1]}" 1 "key" "hello"
vals, err := rdb.Eval(ctx, "return {KEYS[1],ARGV[1]}", []string{"key"}, "hello").Result()

// custom command
res, err := rdb.Do(ctx, "set", "key", "value").Result()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Run the test&lt;/h2&gt; 
&lt;p&gt;Recommended to use Docker, just need to run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;See also&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://bun.uptrace.dev"&gt;Golang ORM&lt;/a&gt; for PostgreSQL, MySQL, MSSQL, and SQLite&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bun.uptrace.dev/postgres/"&gt;Golang PostgreSQL&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://bunrouter.uptrace.dev/"&gt;Golang HTTP router&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/uptrace/go-clickhouse"&gt;Golang ClickHouse ORM&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The go-redis project was originally initiated by &lt;span&gt;‚≠ê&lt;/span&gt; &lt;a href="https://github.com/uptrace/uptrace"&gt;&lt;strong&gt;uptrace/uptrace&lt;/strong&gt;&lt;/a&gt;. Uptrace is an open-source APM tool that supports distributed tracing, metrics, and logs. You can use it to monitor applications and set up automatic alerts to receive notifications via email, Slack, Telegram, and others.&lt;/p&gt; 
 &lt;p&gt;See &lt;a href="https://github.com/redis/go-redis/tree/master/example/otel"&gt;OpenTelemetry&lt;/a&gt; example which demonstrates how you can use Uptrace to monitor go-redis.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Thanks to all the people who already contributed!&lt;/p&gt; 
&lt;a href="https://github.com/redis/go-redis/graphs/contributors"&gt; &lt;img src="https://contributors-img.web.app/image?repo=redis/go-redis" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>wavetermdev/waveterm</title>
      <link>https://github.com/wavetermdev/waveterm</link>
      <description>&lt;p&gt;An open-source, cross-platform terminal for seamless workflows&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.waveterm.dev"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="./assets/wave-dark.png" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="./assets/wave-light.png" /&gt; 
   &lt;img alt="Wave Terminal Logo" src="https://raw.githubusercontent.com/wavetermdev/waveterm/main/assets/wave-light.png" width="240" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;h1&gt;Wave Terminal&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Wave is an open-source terminal that combines traditional terminal features with graphical capabilities like file previews, web browsing, and AI assistance. It runs on MacOS, Linux, and Windows.&lt;/p&gt; 
&lt;p&gt;Modern development involves constantly switching between terminals and browsers - checking documentation, previewing files, monitoring systems, and using AI tools. Wave brings these graphical tools directly into the terminal, letting you control them from the command line. This means you can stay in your terminal workflow while still having access to the visual interfaces you need.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/wavetermdev/waveterm/main/assets/wave-screenshot.webp" alt="WaveTerm Screenshot" /&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Flexible drag &amp;amp; drop interface to organize terminal blocks, editors, web browsers, and AI assistants&lt;/li&gt; 
 &lt;li&gt;Built-in editor for seamlessly editing remote files with syntax highlighting and modern editor features&lt;/li&gt; 
 &lt;li&gt;Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)&lt;/li&gt; 
 &lt;li&gt;Integrated AI chat with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)&lt;/li&gt; 
 &lt;li&gt;Command Blocks for isolating and monitoring individual commands with auto-close options&lt;/li&gt; 
 &lt;li&gt;One-click remote connections with full terminal and file system access&lt;/li&gt; 
 &lt;li&gt;Rich customization including tab themes, terminal styles, and background images&lt;/li&gt; 
 &lt;li&gt;Powerful &lt;code&gt;wsh&lt;/code&gt; command system for managing your workspace from the CLI and sharing data between terminal sessions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Wave Terminal works on macOS, Linux, and Windows.&lt;/p&gt; 
&lt;p&gt;Platform-specific installation instructions can be found &lt;a href="https://docs.waveterm.dev/gettingstarted"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also install Wave Terminal directly from: &lt;a href="https://www.waveterm.dev/download"&gt;www.waveterm.dev/download&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Minimum requirements&lt;/h3&gt; 
&lt;p&gt;Wave Terminal runs on the following platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;macOS 11 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Windows 10 1809 or later (x64)&lt;/li&gt; 
 &lt;li&gt;Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The WSH helper runs on the following platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;macOS 11 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Windows 10 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Wave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/ROADMAP.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Want to provide input to our future releases? Connect with us on &lt;a href="https://discord.gg/XfvZ334gwU"&gt;Discord&lt;/a&gt; or open a &lt;a href="https://github.com/wavetermdev/waveterm/issues/new/choose"&gt;Feature Request&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Homepage ‚Äî &lt;a href="https://www.waveterm.dev"&gt;https://www.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Download Page ‚Äî &lt;a href="https://www.waveterm.dev/download"&gt;https://www.waveterm.dev/download&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation ‚Äî &lt;a href="https://docs.waveterm.dev"&gt;https://docs.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Legacy Documentation ‚Äî &lt;a href="https://legacydocs.waveterm.dev"&gt;https://legacydocs.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Blog ‚Äî &lt;a href="https://blog.waveterm.dev"&gt;https://blog.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;X ‚Äî &lt;a href="https://x.com/wavetermdev"&gt;https://x.com/wavetermdev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord Community ‚Äî &lt;a href="https://discord.gg/XfvZ334gwU"&gt;https://discord.gg/XfvZ334gwU&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Building from Source&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/BUILD.md"&gt;Building Wave Terminal&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Wave uses GitHub Issues for issue tracking.&lt;/p&gt; 
&lt;p&gt;Find more information in our &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md"&gt;Contributions Guide&lt;/a&gt;, which includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md#contributing-to-wave-terminal"&gt;Ways to contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md#before-you-start"&gt;Contribution guidelines&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.waveterm.dev/storybook"&gt;Storybook&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Wave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/ACKNOWLEDGEMENTS.md"&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>seaweedfs/seaweedfs</title>
      <link>https://github.com/seaweedfs/seaweedfs</link>
      <description>&lt;p&gt;SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;SeaweedFS&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;&lt;img src="https://img.shields.io/badge/slack-purple" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/intent/follow?screen_name=seaweedfs"&gt;&lt;img src="https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;amp;label=Follow" alt="Twitter" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://godoc.org/github.com/seaweedfs/seaweedfs/weed"&gt;&lt;img src="https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;&lt;img src="https://img.shields.io/badge/docs-wiki-blue.svg?sanitize=true" alt="Wiki" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://search.maven.org/search?q=g:com.github.chrislusf"&gt;&lt;img src="https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client" alt="SeaweedFS on Maven Central" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/search?repo=seaweedfs"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png" alt="SeaweedFS Logo" /&gt;&lt;/p&gt; 
&lt;h2 align="center"&gt;&lt;a href="https://www.patreon.com/seaweedfs"&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;SeaweedFS is an independent Apache-licensed open source project with its ongoing development made possible entirely thanks to the support of these awesome &lt;a href="https://github.com/seaweedfs/seaweedfs/raw/master/backers.md"&gt;backers&lt;/a&gt;. If you'd like to grow SeaweedFS even stronger, please consider joining our &lt;a href="https://www.patreon.com/seaweedfs"&gt;sponsors on Patreon&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Your support will be really appreciated by me and other supporters!&lt;/p&gt; 
&lt;!--
&lt;h4 align="center"&gt;Platinum&lt;/h4&gt;

&lt;p align="center"&gt;
  &lt;a href="" target="_blank"&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt; 
&lt;h3&gt;Gold Sponsors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://www.nodion.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png" alt="nodion" /&gt;&lt;/a&gt; &lt;a href="https://www.piknik.com"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png" alt="piknik" /&gt;&lt;/a&gt; &lt;a href="https://www.keepsec.ca"&gt;&lt;img src="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png" alt="keepsec" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/releases/latest"&gt;Download Binaries for different platforms&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY"&gt;SeaweedFS on Slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/SeaweedFS"&gt;SeaweedFS on Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://t.me/Seaweedfs"&gt;SeaweedFS on Telegram&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/SeaweedFS/"&gt;SeaweedFS on Reddit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/d/forum/seaweedfs"&gt;SeaweedFS Mailing List&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki"&gt;Wiki Documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf"&gt;SeaweedFS White Paper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2025.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing"&gt;SeaweedFS Introduction Slides 2021.5&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.slideshare.net/chrislusf/seaweedfs-introduction"&gt;SeaweedFS Introduction Slides 2019.3&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Table of Contents&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start"&gt;Quick Start&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-for-s3-api-on-docker"&gt;Quick Start for S3 API on Docker&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-with-single-binary"&gt;Quick Start with Single Binary&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#quick-start-seaweedfs-s3-on-aws"&gt;Quick Start SeaweedFS S3 on AWS&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#features"&gt;Features&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#additional-features"&gt;Additional Features&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#filer-features"&gt;Filer Features&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#example-using-seaweed-object-store"&gt;Example: Using Seaweed Object Store&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#object-store-architecture"&gt;Architecture&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-other-file-systems"&gt;Compared to Other File Systems&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-hdfs"&gt;Compared to HDFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs-ceph"&gt;Compared to GlusterFS, Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-glusterfs"&gt;Compared to GlusterFS&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-ceph"&gt;Compared to Ceph&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#compared-to-minio"&gt;Compared to Minio&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#dev-plan"&gt;Dev Plan&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#installation-guide"&gt;Installation Guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#disk-related-topics"&gt;Disk Related Topics&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#benchmark"&gt;Benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#enterprise"&gt;Enterprise&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Quick Start&lt;/h1&gt; 
&lt;h2&gt;Quick Start for S3 API on Docker&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;docker run -p 8333:8333 chrislusf/seaweedfs server -s3&lt;/code&gt;&lt;/p&gt; 
&lt;h2&gt;Quick Start with Single Binary&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Download the latest binary from &lt;a href="https://github.com/seaweedfs/seaweedfs/releases"&gt;https://github.com/seaweedfs/seaweedfs/releases&lt;/a&gt; and unzip a single binary file &lt;code&gt;weed&lt;/code&gt; or &lt;code&gt;weed.exe&lt;/code&gt;. Or run &lt;code&gt;go install github.com/seaweedfs/seaweedfs/weed@latest&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key&lt;/code&gt; as the admin credentials to access the object store.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;weed server -dir=/some/data/dir -s3&lt;/code&gt; to start one master, one volume server, one filer, and one S3 gateway.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Also, to increase capacity, just add more volume servers by running &lt;code&gt;weed volume -dir="/some/data/dir2" -mserver="&amp;lt;master_host&amp;gt;:9333" -port=8081&lt;/code&gt; locally, or on a different machine, or on thousands of machines. That is it!&lt;/p&gt; 
&lt;h2&gt;Quick Start SeaweedFS S3 on AWS&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Setup fast production-ready &lt;a href="https://aws.amazon.com/marketplace/pp/prodview-nzelz5gprlrjc"&gt;SeaweedFS S3 on AWS with cloudformation&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;to store billions of files!&lt;/li&gt; 
 &lt;li&gt;to serve the files fast!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;SeaweedFS started as an Object Store to handle small files efficiently. Instead of managing all file metadata in a central master, the central master only manages volumes on volume servers, and these volume servers manage files and their metadata. This relieves concurrency pressure from the central master and spreads file metadata into volume servers, allowing faster file access (O(1), usually just one disk read operation).&lt;/p&gt; 
&lt;p&gt;There is only 40 bytes of disk storage overhead for each file's metadata. It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.&lt;/p&gt; 
&lt;p&gt;SeaweedFS started by implementing &lt;a href="http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf"&gt;Facebook's Haystack design paper&lt;/a&gt;. Also, SeaweedFS implements erasure coding with ideas from &lt;a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf"&gt;f4: Facebook‚Äôs Warm BLOB Storage System&lt;/a&gt;, and has a lot of similarities with &lt;a href="https://www.usenix.org/system/files/fast21-pan.pdf"&gt;Facebook‚Äôs Tectonic Filesystem&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;On top of the object store, optional &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer&lt;/a&gt; can support directories and POSIX attributes. Filer is a separate linearly-scalable stateless server with customizable metadata stores, e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.&lt;/p&gt; 
&lt;p&gt;For any distributed key value stores, the large values can be offloaded to SeaweedFS. With the fast access speed and linearly scalable capacity, SeaweedFS can work as a distributed &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store"&gt;Key-Large-Value store&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can transparently integrate with the cloud. With hot data on local cluster, and warm data on the cloud with O(1) access time, SeaweedFS can achieve both fast local access time and elastic cloud storage capacity. What's more, the cloud storage access API cost is minimized. Faster and cheaper than direct cloud storage!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h2&gt;Additional Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Can choose no replication or different replication levels, rack and data center aware.&lt;/li&gt; 
 &lt;li&gt;Automatic master servers failover - no single point of failure (SPOF).&lt;/li&gt; 
 &lt;li&gt;Automatic Gzip compression depending on file MIME type.&lt;/li&gt; 
 &lt;li&gt;Automatic compaction to reclaim disk space after deletion or update.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live"&gt;Automatic entry TTL expiration&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Any server with some disk space can add to the total storage space.&lt;/li&gt; 
 &lt;li&gt;Adding/Removing servers does &lt;strong&gt;not&lt;/strong&gt; cause any data re-balancing unless triggered by admin commands.&lt;/li&gt; 
 &lt;li&gt;Optional picture resizing.&lt;/li&gt; 
 &lt;li&gt;Support ETag, Accept-Range, Last-Modified, etc.&lt;/li&gt; 
 &lt;li&gt;Support in-memory/leveldb/readonly mode tuning for memory/performance balance.&lt;/li&gt; 
 &lt;li&gt;Support rebalancing the writable and readonly volumes.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage"&gt;Customizable Multiple Storage Tiers&lt;/a&gt;: Customizable storage disk types to balance performance and cost.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier"&gt;Transparent cloud integration&lt;/a&gt;: unlimited capacity via tiered cloud storage for warm data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage"&gt;Erasure Coding for warm storage&lt;/a&gt; Rack-Aware 10.4 erasure coding reduces storage cost and increases availability.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Filer Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files"&gt;Filer server&lt;/a&gt; provides "normal" directories and files via HTTP.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores"&gt;File TTL&lt;/a&gt; automatically expires file metadata and actual file data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount"&gt;Mount filer&lt;/a&gt; reads and writes files directly as a local directory via FUSE.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication"&gt;Filer Store Replication&lt;/a&gt; enables HA for filer meta data stores.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization"&gt;Active-Active Replication&lt;/a&gt; enables asynchronous one-way or two-way cross cluster continuous replication.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API"&gt;Amazon S3 compatible API&lt;/a&gt; accesses files with S3 tooling.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System"&gt;Hadoop Compatible File System&lt;/a&gt; accesses files from Hadoop/Spark/Flink/etc or even runs HBase.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud"&gt;Async Replication To Cloud&lt;/a&gt; has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/WebDAV"&gt;WebDAV&lt;/a&gt; accesses as a mapped drive on Mac and Windows, or from mobile devices.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption"&gt;AES256-GCM Encrypted Storage&lt;/a&gt; safely stores the encrypted data.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files"&gt;Super Large Files&lt;/a&gt; stores large or super large files in tens of TB.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt; mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage"&gt;Gateway to Remote Object Store&lt;/a&gt; mirrors bucket operations to remote object storage, in addition to &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture"&gt;Cloud Drive&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Kubernetes&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-csi-driver"&gt;Kubernetes CSI Driver&lt;/a&gt; A Container Storage Interface (CSI) Driver. &lt;a href="https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/"&gt;&lt;img src="https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800" alt="Docker Pulls" /&gt;&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs-operator"&gt;SeaweedFS Operator&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Example: Using Seaweed Object Store&lt;/h2&gt; 
&lt;p&gt;By default, the master node runs on port 9333, and the volume nodes run on port 8080. Let's start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We'll use localhost as an example.&lt;/p&gt; 
&lt;p&gt;SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.&lt;/p&gt; 
&lt;h3&gt;Start Master Server&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; ./weed master
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Start Volume Servers&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; weed volume -dir="/tmp/data1" -max=5  -mserver="localhost:9333" -port=8080 &amp;amp;
&amp;gt; weed volume -dir="/tmp/data2" -max=10 -mserver="localhost:9333" -port=8081 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Write File&lt;/h3&gt; 
&lt;p&gt;To upload a file: first, send a HTTP POST, PUT, or GET request to &lt;code&gt;/dir/assign&lt;/code&gt; to get an &lt;code&gt;fid&lt;/code&gt; and a volume server URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/assign
{"count":1,"fid":"3,01637037d6","url":"127.0.0.1:8080","publicUrl":"localhost:8080"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Second, to store the file content, send a HTTP multi-part POST request to &lt;code&gt;url + '/' + fid&lt;/code&gt; from the response:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{"name":"myphoto.jpg","size":43234,"eTag":"1cc0118e"}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To update, send another POST request with updated file content.&lt;/p&gt; 
&lt;p&gt;For deletion, send an HTTP DELETE request to the same &lt;code&gt;url + '/' + fid&lt;/code&gt; URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Save File Id&lt;/h3&gt; 
&lt;p&gt;Now, you can save the &lt;code&gt;fid&lt;/code&gt;, 3,01637037d6 in this case, to a database field.&lt;/p&gt; 
&lt;p&gt;The number 3 at the start represents a volume id. After the comma, it's one file key, 01, and a file cookie, 637037d6.&lt;/p&gt; 
&lt;p&gt;The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.&lt;/p&gt; 
&lt;p&gt;The file key and file cookie are both coded in hex. You can store the &amp;lt;volume id, file key, file cookie&amp;gt; tuple in your own format, or simply store the &lt;code&gt;fid&lt;/code&gt; as a string.&lt;/p&gt; 
&lt;p&gt;If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.&lt;/p&gt; 
&lt;p&gt;If space is really a concern, you can store the file id in your own format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.&lt;/p&gt; 
&lt;h3&gt;Read File&lt;/h3&gt; 
&lt;p&gt;Here is an example of how to render the URL.&lt;/p&gt; 
&lt;p&gt;First look up the volume server's URLs by the file's volumeId:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt; curl http://localhost:9333/dir/lookup?volumeId=3
{"volumeId":"3","locations":[{"publicUrl":"localhost:8080","url":"localhost:8080"}]}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Since (usually) there are not too many volume servers, and volumes don't move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.&lt;/p&gt; 
&lt;p&gt;Now you can take the public URL, render the URL or directly read from the volume server via URL:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3,01637037d6.jpg
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Notice we add a file extension ".jpg" here. It's optional and just one way for the client to specify the file content type.&lt;/p&gt; 
&lt;p&gt;If you want a nicer URL, you can use one of these alternative URL formats:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want to get a scaled version of an image, you can add some params:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;amp;width=200&amp;amp;mode=fill
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Rack-Aware and Data Center-Aware Replication&lt;/h3&gt; 
&lt;p&gt;SeaweedFS applies the replication strategy at a volume level. So, when you are getting a file id, you can specify the replication strategy. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;curl http://localhost:9333/dir/assign?replication=001
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The replication parameter options are:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More details about replication can be found &lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Replication"&gt;on the wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also set the default replication strategy when starting the master server.&lt;/p&gt; 
&lt;h3&gt;Allocate File Key on Specific Data Center&lt;/h3&gt; 
&lt;p&gt;Volume servers can be started with a specific data center name:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When requesting a file key, an optional "dataCenter" parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to 'dc1':&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt; http://localhost:9333/dir/assign?dataCenter=dc1
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Other Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server"&gt;No Single Point of Failure&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys"&gt;Insert with your own keys&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files"&gt;Chunking large files&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space"&gt;Collection as a Simple Name Space&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Object Store Architecture&lt;/h2&gt; 
&lt;p&gt;Usually distributed file systems split each file into chunks, a central master keeps a mapping of filenames, chunk indices to chunk handles, and also which chunks each chunk server has.&lt;/p&gt; 
&lt;p&gt;The main drawback is that the central master can't handle many small files efficiently, and since all read requests need to go through the chunk master, so it might not scale well for many concurrent users.&lt;/p&gt; 
&lt;p&gt;Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of files. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.&lt;/p&gt; 
&lt;p&gt;The actual file metadata is stored in each volume on volume servers. Since each volume server only manages metadata of files on its own disk, with only 16 bytes for each file, all file access can read file metadata just from memory and only needs one disk operation to actually read file data.&lt;/p&gt; 
&lt;p&gt;For comparison, consider that an xfs inode structure in Linux is 536 bytes.&lt;/p&gt; 
&lt;h3&gt;Master Server and Volume Server&lt;/h3&gt; 
&lt;p&gt;The architecture is fairly simple. The actual data is stored in volumes on storage nodes. One volume server can have multiple volumes, and can both support read and write access with basic authentication.&lt;/p&gt; 
&lt;p&gt;All volumes are managed by a master server. The master server contains the volume id to volume server mapping. This is fairly static information, and can be easily cached.&lt;/p&gt; 
&lt;p&gt;On each write request, the master server also generates a file key, which is a growing 64-bit unsigned integer. Since write requests are not generally as frequent as read requests, one master server should be able to handle the concurrency well.&lt;/p&gt; 
&lt;h3&gt;Write and Read files&lt;/h3&gt; 
&lt;p&gt;When a client sends a write request, the master server returns (volume id, file key, file cookie, volume node URL) for the file. The client then contacts the volume node and POSTs the file content.&lt;/p&gt; 
&lt;p&gt;When a client needs to read a file based on (volume id, file key, file cookie), it asks the master server by the volume id for the (volume node URL, volume node public URL), or retrieves this from a cache. Then the client can GET the content, or just render the URL on web pages and let browsers fetch the content.&lt;/p&gt; 
&lt;p&gt;Please see the example for details on the write-read process.&lt;/p&gt; 
&lt;h3&gt;Storage Size&lt;/h3&gt; 
&lt;p&gt;In the current implementation, each volume can hold 32 gibibytes (32GiB or 8x2^32 bytes). This is because we align content to 8 bytes. We can easily increase this to 64GiB, or 128GiB, or more, by changing 2 lines of code, at the cost of some wasted padding space due to alignment.&lt;/p&gt; 
&lt;p&gt;There can be 4 gibibytes (4GiB or 2^32 bytes) of volumes. So the total system size is 8 x 4GiB x 4GiB which is 128 exbibytes (128EiB or 2^67 bytes).&lt;/p&gt; 
&lt;p&gt;Each individual file size is limited to the volume size.&lt;/p&gt; 
&lt;h3&gt;Saving memory&lt;/h3&gt; 
&lt;p&gt;All file meta information stored on a volume server is readable from memory without disk access. Each file takes just a 16-byte map entry of &amp;lt;64bit key, 32bit offset, 32bit size&amp;gt;. Of course, each map entry has its own space cost for the map. But usually the disk space runs out before the memory does.&lt;/p&gt; 
&lt;h3&gt;Tiered Storage to the cloud&lt;/h3&gt; 
&lt;p&gt;The local volume servers are much faster, while cloud storages have elastic capacity and are actually more cost-efficient if not accessed often (usually free to upload, but relatively costly to access). With the append-only structure and O(1) access time, SeaweedFS can take advantage of both local and cloud storage by offloading the warm data to the cloud.&lt;/p&gt; 
&lt;p&gt;Usually hot data are fresh and warm data are old. SeaweedFS puts the newly created volumes on local servers, and optionally upload the older volumes on the cloud. If the older data are accessed less often, this literally gives you unlimited capacity with limited local servers, and still fast for new data.&lt;/p&gt; 
&lt;p&gt;With the O(1) access time, the network latency cost is kept at minimum.&lt;/p&gt; 
&lt;p&gt;If the hot/warm data is split as 20/80, with 20 servers, you can achieve storage capacity of 100 servers. That's a cost saving of 80%! Or you can repurpose the 80 servers to store new data also, and get 5X storage throughput.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Compared to Other File Systems&lt;/h2&gt; 
&lt;p&gt;Most other distributed file systems seem more complicated than necessary.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is meant to be fast and simple, in both setup and operation. If you do not understand how it works when you reach here, we've failed! Please raise an issue with any questions or update this file with clarifications.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is constantly moving forward. Same with other systems. These comparisons can be outdated quickly. Please help to keep them updated.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to HDFS&lt;/h3&gt; 
&lt;p&gt;HDFS uses the chunk approach for each file, and is ideal for storing large files.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is ideal for serving relatively smaller files quickly and concurrently.&lt;/p&gt; 
&lt;p&gt;SeaweedFS can also store extra large files by splitting them into manageable data chunks, and store the file ids of the data chunks into a meta chunk. This is managed by "weed upload/download" tool, and the weed master or volume servers are agnostic about it.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS, Ceph&lt;/h3&gt; 
&lt;p&gt;The architectures are mostly the same. SeaweedFS aims to store and read files fast, with a simple and flat architecture. The main differences are&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;SeaweedFS optimizes for small files, ensuring O(1) disk seek operation, and can also handle large files.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS statically assigns a volume id for a file. Locating file content becomes just a lookup of the volume id, which can be easily cached.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Filer metadata store can be any well-known and proven data store, e.g., Redis, Cassandra, HBase, Mongodb, Elastic Search, MySql, Postgres, Sqlite, MemSql, TiDB, CockroachDB, Etcd, YDB etc, and is easy to customize.&lt;/li&gt; 
 &lt;li&gt;SeaweedFS Volume server also communicates directly with clients via HTTP, supporting range queries, direct uploads, etc.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;System&lt;/th&gt; 
   &lt;th&gt;File Metadata&lt;/th&gt; 
   &lt;th&gt;File Content Read&lt;/th&gt; 
   &lt;th&gt;POSIX&lt;/th&gt; 
   &lt;th&gt;REST API&lt;/th&gt; 
   &lt;th&gt;Optimized for large number of small files&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS&lt;/td&gt; 
   &lt;td&gt;lookup volume id, cacheable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;SeaweedFS Filer&lt;/td&gt; 
   &lt;td&gt;Linearly Scalable, Customizable&lt;/td&gt; 
   &lt;td&gt;O(1) disk seek&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;GlusterFS&lt;/td&gt; 
   &lt;td&gt;hashing&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE, NFS&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ceph&lt;/td&gt; 
   &lt;td&gt;hashing + rules&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MooseFS&lt;/td&gt; 
   &lt;td&gt;in memory&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;FUSE&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;MinIO&lt;/td&gt; 
   &lt;td&gt;separate meta file for each file&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Yes&lt;/td&gt; 
   &lt;td&gt;No&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to GlusterFS&lt;/h3&gt; 
&lt;p&gt;GlusterFS stores files, both directories and content, in configurable volumes called "bricks".&lt;/p&gt; 
&lt;p&gt;GlusterFS hashes the path and filename into ids, and assigned to virtual volumes, and then mapped to "bricks".&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MooseFS&lt;/h3&gt; 
&lt;p&gt;MooseFS chooses to neglect small file issue. From moosefs 3.0 manual, "even a small file will occupy 64KiB plus additionally 4KiB of checksums and 1KiB for the header", because it "was initially designed for keeping large amounts (like several thousands) of very big files"&lt;/p&gt; 
&lt;p&gt;MooseFS Master Server keeps all meta data in memory. Same issue as HDFS namenode.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to Ceph&lt;/h3&gt; 
&lt;p&gt;Ceph can be setup similar to SeaweedFS as a key-&amp;gt;blob store. It is much more complicated, with the need to support layers on top of it. &lt;a href="https://github.com/seaweedfs/seaweedfs/issues/120"&gt;Here is a more detailed comparison&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;SeaweedFS has a centralized master group to look up free volumes, while Ceph uses hashing and metadata servers to locate its objects. Having a centralized master makes it easy to code and manage.&lt;/p&gt; 
&lt;p&gt;Ceph, like SeaweedFS, is based on the object store RADOS. Ceph is rather complicated with mixed reviews.&lt;/p&gt; 
&lt;p&gt;Ceph uses CRUSH hashing to automatically manage data placement, which is efficient to locate the data. But the data has to be placed according to the CRUSH algorithm. Any wrong configuration would cause data loss. Topology changes, such as adding new servers to increase capacity, will cause data migration with high IO cost to fit the CRUSH algorithm. SeaweedFS places data by assigning them to any writable volumes. If writes to one volume failed, just pick another volume to write. Adding more volumes is also as simple as it can be.&lt;/p&gt; 
&lt;p&gt;SeaweedFS is optimized for small files. Small files are stored as one continuous block of content, with at most 8 unused bytes between files. Small file access is O(1) disk read.&lt;/p&gt; 
&lt;p&gt;SeaweedFS Filer uses off-the-shelf stores, such as MySql, Postgres, Sqlite, Mongodb, Redis, Elastic Search, Cassandra, HBase, MemSql, TiDB, CockroachCB, Etcd, YDB, to manage file directories. These stores are proven, scalable, and easier to manage.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;SeaweedFS&lt;/th&gt; 
   &lt;th&gt;comparable to Ceph&lt;/th&gt; 
   &lt;th&gt;advantage&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Master&lt;/td&gt; 
   &lt;td&gt;MDS&lt;/td&gt; 
   &lt;td&gt;simpler&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Volume&lt;/td&gt; 
   &lt;td&gt;OSD&lt;/td&gt; 
   &lt;td&gt;optimized for small files&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Filer&lt;/td&gt; 
   &lt;td&gt;Ceph FS&lt;/td&gt; 
   &lt;td&gt;linearly scalable, Customizable, O(1) or O(logN)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Compared to MinIO&lt;/h3&gt; 
&lt;p&gt;MinIO follows AWS S3 closely and is ideal for testing for S3 API. It has good UI, policies, versionings, etc. SeaweedFS is trying to catch up here. It is also possible to put MinIO as a gateway in front of SeaweedFS later.&lt;/p&gt; 
&lt;p&gt;MinIO metadata are in simple files. Each file write will incur extra writes to corresponding meta file.&lt;/p&gt; 
&lt;p&gt;MinIO does not have optimization for lots of small files. The files are simply stored as is to local disks. Plus the extra meta file and shards for erasure coding, it only amplifies the LOSF problem.&lt;/p&gt; 
&lt;p&gt;MinIO has multiple disk IO to read one file. SeaweedFS has O(1) disk reads, even for erasure coded files.&lt;/p&gt; 
&lt;p&gt;MinIO has full-time erasure coding. SeaweedFS uses replication on hot data for faster speed and optionally applies erasure coding on warm data.&lt;/p&gt; 
&lt;p&gt;MinIO does not have POSIX-like API support.&lt;/p&gt; 
&lt;p&gt;MinIO has specific requirements on storage layout. It is not flexible to adjust capacity. In SeaweedFS, just start one volume server pointing to the master. That's all.&lt;/p&gt; 
&lt;h2&gt;Dev Plan&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;More tools and documentation, on how to manage and scale the system.&lt;/li&gt; 
 &lt;li&gt;Read and write stream data.&lt;/li&gt; 
 &lt;li&gt;Support structured data.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This is a super exciting project! And we need helpers and &lt;a href="https://www.patreon.com/seaweedfs"&gt;support&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Installation Guide&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Installation guide for users who are not familiar with golang&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Step 1: install go on your machine and setup the environment by following the instructions at:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://golang.org/doc/install"&gt;https://golang.org/doc/install&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;make sure to define your $GOPATH&lt;/p&gt; 
&lt;p&gt;Step 2: checkout this repo:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/seaweedfs/seaweedfs.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Step 3: download, compile, and install the project by executing the following command&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd seaweedfs/weed &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Once this is done, you will find the executable "weed" in your &lt;code&gt;$GOPATH/bin&lt;/code&gt; directory&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disk Related Topics&lt;/h2&gt; 
&lt;h3&gt;Hard Drive Performance&lt;/h3&gt; 
&lt;p&gt;When testing read performance on SeaweedFS, it basically becomes a performance test of your hard drive's random read speed. Hard drives usually get 100MB/s~200MB/s.&lt;/p&gt; 
&lt;h3&gt;Solid State Disk&lt;/h3&gt; 
&lt;p&gt;To modify or delete small files, SSD must delete a whole block at a time, and move content in existing blocks to a new block. SSD is fast when brand new, but will get fragmented over time and you have to garbage collect, compacting blocks. SeaweedFS is friendly to SSD since it is append-only. Deletion and compaction are done on volume level in the background, not slowing reading and not causing fragmentation.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Benchmark&lt;/h2&gt; 
&lt;p&gt;My Own Unscientific Single Machine Results on Mac Book with Solid State Disk, CPU: 1 Intel Core i7 2.6GHz.&lt;/p&gt; 
&lt;p&gt;Write 1 million 1KB file:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   66.753 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106789009 bytes
Requests per second:    15708.23 [#/sec]
Transfer rate:          16191.69 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.3      1.0       84.3      0.9

Percentage of the requests served within a certain time (ms)
   50%      0.8 ms
   66%      1.0 ms
   75%      1.1 ms
   80%      1.2 ms
   90%      1.4 ms
   95%      1.7 ms
   98%      2.1 ms
   99%      2.6 ms
  100%     84.3 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Randomly read 1 million files:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Concurrency Level:      16
Time taken for tests:   22.301 seconds
Completed requests:      1048576
Failed requests:        0
Total transferred:      1106812873 bytes
Requests per second:    47019.38 [#/sec]
Transfer rate:          48467.57 [Kbytes/sec]

Connection Times (ms)
              min      avg        max      std
Total:        0.0      0.3       54.1      0.2

Percentage of the requests served within a certain time (ms)
   50%      0.3 ms
   90%      0.4 ms
   98%      0.6 ms
   99%      0.7 ms
  100%     54.1 ms
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run WARP and launch a mixed benchmark.&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;make benchmark
warp: Benchmark data written to "warp-mixed-2023-10-16[102354]-l70a.csv.zst"                                                                                                                                                                                               
Mixed operations.
Operation: DELETE, 10%, Concurrency: 20, Ran 4m59s.
 * Throughput: 6.19 obj/s

Operation: GET, 45%, Concurrency: 20, Ran 5m0s.
 * Throughput: 279.85 MiB/s, 27.99 obj/s

Operation: PUT, 15%, Concurrency: 20, Ran 5m0s.
 * Throughput: 89.86 MiB/s, 8.99 obj/s

Operation: STAT, 30%, Concurrency: 20, Ran 5m0s.
 * Throughput: 18.63 obj/s

Cluster Total: 369.74 MiB/s, 61.79 obj/s, 0 errors over 5m0s.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see segmented request statistics, use the --analyze.v parameter.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;warp analyze --analyze.v warp-mixed-2023-10-16[102354]-l70a.csv.zst
18642 operations loaded... Done!
Mixed operations.
----------------------------------------
Operation: DELETE - total: 1854, 10.0%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 6.19 obj/s

Requests considered: 1855:
 * Avg: 104ms, 50%: 30ms, 90%: 207ms, 99%: 1.355s, Fastest: 1ms, Slowest: 4.613s, StdDev: 320ms

----------------------------------------
Operation: GET - total: 8388, 45.3%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.12 +0500 +05
 * Throughput: 279.77 MiB/s, 27.98 obj/s

Requests considered: 8389:
 * Avg: 221ms, 50%: 106ms, 90%: 492ms, 99%: 1.739s, Fastest: 8ms, Slowest: 8.633s, StdDev: 383ms
 * TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 171ms, 99th: 669ms, Worst: 4.783s StdDev: 163ms
 * First Access: Avg: 240ms, 50%: 105ms, 90%: 511ms, 99%: 2.08s, Fastest: 12ms, Slowest: 8.633s, StdDev: 480ms
 * First Access TTFB: Avg: 88ms, Best: 2ms, 25th: 24ms, Median: 38ms, 75th: 64ms, 90th: 179ms, 99th: 919ms, Worst: 4.783s StdDev: 199ms
 * Last Access: Avg: 219ms, 50%: 106ms, 90%: 463ms, 99%: 1.782s, Fastest: 9ms, Slowest: 8.633s, StdDev: 416ms
 * Last Access TTFB: Avg: 81ms, Best: 2ms, 25th: 24ms, Median: 39ms, 75th: 65ms, 90th: 161ms, 99th: 657ms, Worst: 4.783s StdDev: 176ms

----------------------------------------
Operation: PUT - total: 2688, 14.5%, Size: 10485760 bytes. Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.115 +0500 +05
 * Throughput: 89.83 MiB/s, 8.98 obj/s

Requests considered: 2689:
 * Avg: 1.165s, 50%: 878ms, 90%: 2.015s, 99%: 5.74s, Fastest: 99ms, Slowest: 8.264s, StdDev: 968ms

----------------------------------------
Operation: STAT - total: 5586, 30.2%, Concurrency: 20, Ran 5m0s, starting 2023-10-16 10:23:57.113 +0500 +05
 * Throughput: 18.63 obj/s

Requests considered: 5587:
 * Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 80ms, Fastest: 0s, Slowest: 245ms, StdDev: 17ms
 * First Access: Avg: 14ms, 50%: 10ms, 90%: 33ms, 99%: 69ms, Fastest: 0s, Slowest: 203ms, StdDev: 16ms
 * Last Access: Avg: 15ms, 50%: 11ms, 90%: 34ms, 99%: 74ms, Fastest: 0s, Slowest: 203ms, StdDev: 17ms

Cluster Total: 369.64 MiB/s, 61.77 obj/s, 0 errors over 5m0s.
Total Errors:0.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Enterprise&lt;/h2&gt; 
&lt;p&gt;For enterprise users, please visit &lt;a href="https://seaweedfs.com"&gt;seaweedfs.com&lt;/a&gt; for the SeaweedFS Enterprise Edition, which has a self-healing storage format with better data protection.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;http://www.apache.org/licenses/LICENSE-2.0
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.&lt;/p&gt; 
&lt;p&gt;The text of this page is available for modification and reuse under the terms of the Creative Commons Attribution-Sharealike 3.0 Unported License and the GNU Free Documentation License (unversioned, with no invariant sections, front-cover texts, or back-cover texts).&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/#table-of-contents"&gt;Back to TOC&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Stargazers over time&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://starchart.cc/chrislusf/seaweedfs"&gt;&lt;img src="https://starchart.cc/chrislusf/seaweedfs.svg?sanitize=true" alt="Stargazers over time" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dstotijn/hetty</title>
      <link>https://github.com/dstotijn/hetty</link>
      <description>&lt;p&gt;An HTTP toolkit for security research.&lt;/p&gt;&lt;hr&gt;&lt;img src="https://user-images.githubusercontent.com/983924/156430531-6193e187-7400-436b-81c6-f86862783ea5.svg#gh-light-mode-only" width="240" /&gt; 
&lt;img src="https://user-images.githubusercontent.com/983924/156430660-9d5bd555-dcfd-47e2-ba70-54294c20c1b4.svg#gh-dark-mode-only" width="240" /&gt; 
&lt;p&gt;&lt;a href="https://github.com/dstotijn/hetty/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dstotijn/hetty?color=25ae8f" alt="Latest GitHub release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dstotijn/hetty/actions/workflows/build-test.yml"&gt;&lt;img src="https://img.shields.io/endpoint.svg?url=https%3A%2F%2Factions-badge.atrox.dev%2Fdstotijn%2Fhetty%2Fbadge%3Fref%3Dmain&amp;amp;label=build&amp;amp;color=24ae8f" alt="Build Status" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/downloads/dstotijn/hetty/total?color=25ae8f" alt="GitHub download count" /&gt; &lt;a href="https://github.com/dstotijn/hetty/raw/master/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/dstotijn/hetty?color=25ae8f" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://hetty.xyz/"&gt;&lt;img src="https://img.shields.io/badge/hetty-docs-25ae8f" alt="Documentation" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Hetty&lt;/strong&gt; is an HTTP toolkit for security research. It aims to become an open source alternative to commercial software like Burp Suite Pro, with powerful features tailored to the needs of the infosec and bug bounty community.&lt;/p&gt; 
&lt;img src="https://hetty.xyz/img/hero.png" width="907" alt="Hetty proxy logs (screenshot)" /&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Machine-in-the-middle (MITM) HTTP proxy, with logs and advanced search&lt;/li&gt; 
 &lt;li&gt;HTTP client for manually creating/editing requests, and replay proxied requests&lt;/li&gt; 
 &lt;li&gt;Intercept requests and responses for manual review (edit, send/receive, cancel)&lt;/li&gt; 
 &lt;li&gt;Scope support, to help keep work organized&lt;/li&gt; 
 &lt;li&gt;Easy-to-use web based admin interface&lt;/li&gt; 
 &lt;li&gt;Project based database storage, to help keep work organized&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üë∑‚Äç‚ôÇÔ∏è Hetty is under active development. Check the &lt;a href="https://github.com/dstotijn/hetty/projects/1"&gt;backlog&lt;/a&gt; for the current status.&lt;/p&gt; 
&lt;p&gt;üì£ Are you pen testing professionaly in a team? I would love to hear your thoughts on tooling via &lt;a href="https://forms.gle/36jtgNc3TJ2imi5A8"&gt;this 5 minute survey&lt;/a&gt;. Thank you!&lt;/p&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;üí° The &lt;a href="https://hetty.xyz/docs/getting-started"&gt;Getting started&lt;/a&gt; doc has more detailed install and usage instructions.&lt;/p&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;p&gt;The quickest way to install and update Hetty is via a package manager:&lt;/p&gt; 
&lt;h4&gt;macOS&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;brew install hettysoft/tap/hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Linux&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;sudo snap install hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Windows&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;scoop bucket add hettysoft https://github.com/hettysoft/scoop-bucket.git
scoop install hettysoft/hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Other&lt;/h4&gt; 
&lt;p&gt;Alternatively, you can &lt;a href="https://github.com/dstotijn/hetty/releases/latest"&gt;download the latest release from GitHub&lt;/a&gt; for your OS and architecture, and move the binary to a directory in your &lt;code&gt;$PATH&lt;/code&gt;. If your OS is not available for one of the package managers or not listed in the GitHub releases, you can compile from source &lt;em&gt;(link coming soon)&lt;/em&gt;.&lt;/p&gt; 
&lt;h4&gt;Docker&lt;/h4&gt; 
&lt;p&gt;Docker images are distributed via &lt;a href="https://github.com/dstotijn/hetty/pkgs/container/hetty"&gt;GitHub's Container registry&lt;/a&gt; and &lt;a href="https://hub.docker.com/r/dstotijn/hetty"&gt;Docker Hub&lt;/a&gt;. To run Hetty via with a volume for database and certificate storage, and port 8080 forwarded:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;docker run -v $HOME/.hetty:/root/.hetty -p 8080:8080 \
  ghcr.io/dstotijn/hetty:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Usage&lt;/h3&gt; 
&lt;p&gt;Once installed, start Hetty via:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;hetty
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;üí° Read the &lt;a href="https://hetty.xyz/docs/getting-started"&gt;Getting started&lt;/a&gt; doc for more details.&lt;/p&gt; 
&lt;p&gt;To list all available options, run: &lt;code&gt;hetty --help&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;$ hetty --help

Usage:
    hetty [flags] [subcommand] [flags]

Runs an HTTP server with (MITM) proxy, GraphQL service, and a web based admin interface.

Options:
    --cert         Path to root CA certificate. Creates file if it doesn't exist. (Default: "~/.hetty/hetty_cert.pem")
    --key          Path to root CA private key. Creates file if it doesn't exist. (Default: "~/.hetty/hetty_key.pem")
    --db           Database file path. Creates file if it doesn't exist. (Default: "~/.hetty/hetty.db")
    --addr         TCP address for HTTP server to listen on, in the form \"host:port\". (Default: ":8080")
    --chrome       Launch Chrome with proxy settings applied and certificate errors ignored. (Default: false)
    --verbose      Enable verbose logging.
    --json         Encode logs as JSON, instead of pretty/human readable output.
    --version, -v  Output version.
    --help, -h     Output this usage text.

Subcommands:
    - cert  Certificate management

Run `hetty &amp;lt;subcommand&amp;gt; --help` for subcommand specific usage instructions.

Visit https://hetty.xyz to learn more about Hetty.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;üìñ &lt;a href="https://hetty.xyz/docs"&gt;Read the docs&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Use &lt;a href="https://github.com/dstotijn/hetty/issues"&gt;issues&lt;/a&gt; for bug reports and feature requests, and &lt;a href="https://github.com/dstotijn/hetty/discussions"&gt;discussions&lt;/a&gt; for questions and troubleshooting.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;üí¨ &lt;a href="https://discord.gg/3HVsj5pTFP"&gt;Join the Hetty Discord server&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Want to contribute? Great! Please check the &lt;a href="https://raw.githubusercontent.com/dstotijn/hetty/main/CONTRIBUTING.md"&gt;Contribution Guidelines&lt;/a&gt; for details.&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thanks to the &lt;a href="https://www.hacker101.com/discord"&gt;Hacker101 community on Discord&lt;/a&gt; for the encouragement and early feedback.&lt;/li&gt; 
 &lt;li&gt;The font used in the logo and admin interface is &lt;a href="https://www.jetbrains.com/lp/mono/"&gt;JetBrains Mono&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;üíñ Are you enjoying Hetty? You can &lt;a href="https://github.com/sponsors/dstotijn"&gt;sponsor me&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/dstotijn/hetty/main/LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;¬© 2019‚Äì2025 Hetty Software&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>prometheus/node_exporter</title>
      <link>https://github.com/prometheus/node_exporter</link>
      <description>&lt;p&gt;Exporter for machine metrics&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Node exporter&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://circleci.com/gh/prometheus/node_exporter"&gt;&lt;img src="https://circleci.com/gh/prometheus/node_exporter/tree/master.svg?style=shield" alt="CircleCI" /&gt;&lt;/a&gt; &lt;img src="https://github.com/prometheus/node_exporter/actions/workflows/bsd.yml/badge.svg?sanitize=true" alt="bsd workflow" /&gt; &lt;img src="https://github.com/prometheus/node_exporter/actions/workflows/golangci-lint.yml/badge.svg?sanitize=true" alt="golangci-lint workflow" /&gt; &lt;a href="https://quay.io/repository/prometheus/node-exporter"&gt;&lt;img src="https://quay.io/repository/prometheus/node-exporter/status" alt="Docker Repository on Quay" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/prom/node-exporter/"&gt;&lt;img src="https://img.shields.io/docker/pulls/prom/node-exporter.svg?maxAge=604800" alt="Docker Pulls" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/prometheus/node_exporter"&gt;&lt;img src="https://goreportcard.com/badge/github.com/prometheus/node_exporter" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Prometheus exporter for hardware and OS metrics exposed by *NIX kernels, written in Go with pluggable metric collectors.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://github.com/prometheus-community/windows_exporter"&gt;Windows exporter&lt;/a&gt; is recommended for Windows users. To expose NVIDIA GPU metrics, &lt;a href="https://github.com/NVIDIA/dcgm-exporter"&gt;prometheus-dcgm &lt;/a&gt; can be used.&lt;/p&gt; 
&lt;h2&gt;Installation and Usage&lt;/h2&gt; 
&lt;p&gt;If you are new to Prometheus and &lt;code&gt;node_exporter&lt;/code&gt; there is a &lt;a href="https://prometheus.io/docs/guides/node-exporter/"&gt;simple step-by-step guide&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;node_exporter&lt;/code&gt; listens on HTTP port 9100 by default. See the &lt;code&gt;--help&lt;/code&gt; output for more options.&lt;/p&gt; 
&lt;h3&gt;Ansible&lt;/h3&gt; 
&lt;p&gt;For automated installs with &lt;a href="https://www.ansible.com/"&gt;Ansible&lt;/a&gt;, there is the &lt;a href="https://github.com/prometheus-community/ansible"&gt;Prometheus Community role&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;node_exporter&lt;/code&gt; is designed to monitor the host system. Deploying in containers requires extra care in order to avoid monitoring the container itself.&lt;/p&gt; 
&lt;p&gt;For situations where containerized deployment is needed, some extra flags must be used to allow the &lt;code&gt;node_exporter&lt;/code&gt; access to the host namespaces.&lt;/p&gt; 
&lt;p&gt;Be aware that any non-root mount points you want to monitor will need to be bind-mounted into the container.&lt;/p&gt; 
&lt;p&gt;If you start container for host monitoring, specify &lt;code&gt;path.rootfs&lt;/code&gt; argument. This argument must match path in bind-mount of host root. The node_exporter will use &lt;code&gt;path.rootfs&lt;/code&gt; as prefix to access host filesystem.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --net="host" \
  --pid="host" \
  -v "/:/host:ro,rslave" \
  quay.io/prometheus/node-exporter:latest \
  --path.rootfs=/host
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For Docker compose, similar flag changes are needed.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;---
version: '3.8'

services:
  node_exporter:
    image: quay.io/prometheus/node-exporter:latest
    container_name: node_exporter
    command:
      - '--path.rootfs=/host'
    network_mode: host
    pid: host
    restart: unless-stopped
    volumes:
      - '/:/host:ro,rslave'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;On some systems, the &lt;code&gt;timex&lt;/code&gt; collector requires an additional Docker flag, &lt;code&gt;--cap-add=SYS_TIME&lt;/code&gt;, in order to access the required syscalls.&lt;/p&gt; 
&lt;h2&gt;Collectors&lt;/h2&gt; 
&lt;p&gt;There is varying support for collectors on each operating system. The tables below list all existing collectors and the supported systems.&lt;/p&gt; 
&lt;p&gt;Collectors are enabled by providing a &lt;code&gt;--collector.&amp;lt;name&amp;gt;&lt;/code&gt; flag. Collectors that are enabled by default can be disabled by providing a &lt;code&gt;--no-collector.&amp;lt;name&amp;gt;&lt;/code&gt; flag. To enable only some specific collector(s), use &lt;code&gt;--collector.disable-defaults --collector.&amp;lt;name&amp;gt; ...&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Include &amp;amp; Exclude flags&lt;/h3&gt; 
&lt;p&gt;A few collectors can be configured to include or exclude certain patterns using dedicated flags. The exclude flags are used to indicate "all except", while the include flags are used to say "none except". Note that these flags are mutually exclusive on collectors that support both.&lt;/p&gt; 
&lt;p&gt;Example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-txt"&gt;--collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;List:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Collector&lt;/th&gt; 
   &lt;th&gt;Scope&lt;/th&gt; 
   &lt;th&gt;Include Flag&lt;/th&gt; 
   &lt;th&gt;Exclude Flag&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;arp&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.arp.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.arp.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu&lt;/td&gt; 
   &lt;td&gt;bugs&lt;/td&gt; 
   &lt;td&gt;--collector.cpu.info.bugs-include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu&lt;/td&gt; 
   &lt;td&gt;flags&lt;/td&gt; 
   &lt;td&gt;--collector.cpu.info.flags-include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;diskstats&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.diskstats.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.diskstats.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ethtool&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.ethtool.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.ethtool.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ethtool&lt;/td&gt; 
   &lt;td&gt;metrics&lt;/td&gt; 
   &lt;td&gt;--collector.ethtool.metrics-include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filesystem&lt;/td&gt; 
   &lt;td&gt;fs-types&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.fs-types-include&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.fs-types-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filesystem&lt;/td&gt; 
   &lt;td&gt;mount-points&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.mount-points-include&lt;/td&gt; 
   &lt;td&gt;--collector.filesystem.mount-points-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;hwmon&lt;/td&gt; 
   &lt;td&gt;chip&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.chip-include&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.chip-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;hwmon&lt;/td&gt; 
   &lt;td&gt;sensor&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.sensor-include&lt;/td&gt; 
   &lt;td&gt;--collector.hwmon.sensor-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;interrupts&lt;/td&gt; 
   &lt;td&gt;name&lt;/td&gt; 
   &lt;td&gt;--collector.interrupts.name-include&lt;/td&gt; 
   &lt;td&gt;--collector.interrupts.name-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netdev&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.netdev.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.netdev.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;qdisk&lt;/td&gt; 
   &lt;td&gt;device&lt;/td&gt; 
   &lt;td&gt;--collector.qdisk.device-include&lt;/td&gt; 
   &lt;td&gt;--collector.qdisk.device-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;slabinfo&lt;/td&gt; 
   &lt;td&gt;slab-names&lt;/td&gt; 
   &lt;td&gt;--collector.slabinfo.slabs-include&lt;/td&gt; 
   &lt;td&gt;--collector.slabinfo.slabs-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;sysctl&lt;/td&gt; 
   &lt;td&gt;all&lt;/td&gt; 
   &lt;td&gt;--collector.sysctl.include&lt;/td&gt; 
   &lt;td&gt;N/A&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;systemd&lt;/td&gt; 
   &lt;td&gt;unit&lt;/td&gt; 
   &lt;td&gt;--collector.systemd.unit-include&lt;/td&gt; 
   &lt;td&gt;--collector.systemd.unit-exclude&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Enabled by default&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;OS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;arp&lt;/td&gt; 
   &lt;td&gt;Exposes ARP statistics from &lt;code&gt;/proc/net/arp&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;bcache&lt;/td&gt; 
   &lt;td&gt;Exposes bcache statistics from &lt;code&gt;/sys/fs/bcache/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;bonding&lt;/td&gt; 
   &lt;td&gt;Exposes the number of configured and active slaves of Linux bonding interfaces.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;btrfs&lt;/td&gt; 
   &lt;td&gt;Exposes btrfs statistics&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;boottime&lt;/td&gt; 
   &lt;td&gt;Exposes system boot time derived from the &lt;code&gt;kern.boottime&lt;/code&gt; sysctl.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, NetBSD, OpenBSD, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;conntrack&lt;/td&gt; 
   &lt;td&gt;Shows conntrack statistics (does nothing if no &lt;code&gt;/proc/sys/net/netfilter/&lt;/code&gt; present).&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu&lt;/td&gt; 
   &lt;td&gt;Exposes CPU statistics&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, Solaris, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpufreq&lt;/td&gt; 
   &lt;td&gt;Exposes CPU frequency statistics&lt;/td&gt; 
   &lt;td&gt;Linux, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;diskstats&lt;/td&gt; 
   &lt;td&gt;Exposes disk I/O statistics.&lt;/td&gt; 
   &lt;td&gt;Darwin, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;dmi&lt;/td&gt; 
   &lt;td&gt;Expose Desktop Management Interface (DMI) info from &lt;code&gt;/sys/class/dmi/id/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;edac&lt;/td&gt; 
   &lt;td&gt;Exposes error detection and correction statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;entropy&lt;/td&gt; 
   &lt;td&gt;Exposes available entropy.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;exec&lt;/td&gt; 
   &lt;td&gt;Exposes execution statistics.&lt;/td&gt; 
   &lt;td&gt;Dragonfly, FreeBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;fibrechannel&lt;/td&gt; 
   &lt;td&gt;Exposes fibre channel information and statistics from &lt;code&gt;/sys/class/fc_host/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filefd&lt;/td&gt; 
   &lt;td&gt;Exposes file descriptor statistics from &lt;code&gt;/proc/sys/fs/file-nr&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;filesystem&lt;/td&gt; 
   &lt;td&gt;Exposes filesystem statistics, such as disk space used.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;hwmon&lt;/td&gt; 
   &lt;td&gt;Expose hardware monitoring and sensor data from &lt;code&gt;/sys/class/hwmon/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;infiniband&lt;/td&gt; 
   &lt;td&gt;Exposes network statistics specific to InfiniBand and Intel OmniPath configurations.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ipvs&lt;/td&gt; 
   &lt;td&gt;Exposes IPVS status from &lt;code&gt;/proc/net/ip_vs&lt;/code&gt; and stats from &lt;code&gt;/proc/net/ip_vs_stats&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;loadavg&lt;/td&gt; 
   &lt;td&gt;Exposes load average.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, NetBSD, OpenBSD, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;mdadm&lt;/td&gt; 
   &lt;td&gt;Exposes statistics about devices in &lt;code&gt;/proc/mdstat&lt;/code&gt; (does nothing if no &lt;code&gt;/proc/mdstat&lt;/code&gt; present).&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;meminfo&lt;/td&gt; 
   &lt;td&gt;Exposes memory statistics.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netclass&lt;/td&gt; 
   &lt;td&gt;Exposes network interface info from &lt;code&gt;/sys/class/net/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netdev&lt;/td&gt; 
   &lt;td&gt;Exposes network interface statistics such as bytes transferred.&lt;/td&gt; 
   &lt;td&gt;Darwin, Dragonfly, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netisr&lt;/td&gt; 
   &lt;td&gt;Exposes netisr statistics&lt;/td&gt; 
   &lt;td&gt;FreeBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;netstat&lt;/td&gt; 
   &lt;td&gt;Exposes network statistics from &lt;code&gt;/proc/net/netstat&lt;/code&gt;. This is the same information as &lt;code&gt;netstat -s&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nfs&lt;/td&gt; 
   &lt;td&gt;Exposes NFS client statistics from &lt;code&gt;/proc/net/rpc/nfs&lt;/code&gt;. This is the same information as &lt;code&gt;nfsstat -c&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nfsd&lt;/td&gt; 
   &lt;td&gt;Exposes NFS kernel server statistics from &lt;code&gt;/proc/net/rpc/nfsd&lt;/code&gt;. This is the same information as &lt;code&gt;nfsstat -s&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;nvme&lt;/td&gt; 
   &lt;td&gt;Exposes NVMe info from &lt;code&gt;/sys/class/nvme/&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;os&lt;/td&gt; 
   &lt;td&gt;Expose OS release info from &lt;code&gt;/etc/os-release&lt;/code&gt; or &lt;code&gt;/usr/lib/os-release&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;powersupplyclass&lt;/td&gt; 
   &lt;td&gt;Exposes Power Supply statistics from &lt;code&gt;/sys/class/power_supply&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;pressure&lt;/td&gt; 
   &lt;td&gt;Exposes pressure stall statistics from &lt;code&gt;/proc/pressure/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux (kernel 4.20+ and/or &lt;a href="https://www.kernel.org/doc/html/latest/accounting/psi.html"&gt;CONFIG_PSI&lt;/a&gt;)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;rapl&lt;/td&gt; 
   &lt;td&gt;Exposes various statistics from &lt;code&gt;/sys/class/powercap&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;schedstat&lt;/td&gt; 
   &lt;td&gt;Exposes task scheduler statistics from &lt;code&gt;/proc/schedstat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;selinux&lt;/td&gt; 
   &lt;td&gt;Exposes SELinux statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;sockstat&lt;/td&gt; 
   &lt;td&gt;Exposes various statistics from &lt;code&gt;/proc/net/sockstat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;softnet&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/proc/net/softnet_stat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;stat&lt;/td&gt; 
   &lt;td&gt;Exposes various statistics from &lt;code&gt;/proc/stat&lt;/code&gt;. This includes boot time, forks and interrupts.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tapestats&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/sys/class/scsi_tape&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;textfile&lt;/td&gt; 
   &lt;td&gt;Exposes statistics read from local disk. The &lt;code&gt;--collector.textfile.directory&lt;/code&gt; flag must be set.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;thermal&lt;/td&gt; 
   &lt;td&gt;Exposes thermal statistics like &lt;code&gt;pmset -g therm&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Darwin&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;thermal_zone&lt;/td&gt; 
   &lt;td&gt;Exposes thermal zone &amp;amp; cooling device statistics from &lt;code&gt;/sys/class/thermal&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;time&lt;/td&gt; 
   &lt;td&gt;Exposes the current system time.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;timex&lt;/td&gt; 
   &lt;td&gt;Exposes selected adjtimex(2) system call stats.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;udp_queues&lt;/td&gt; 
   &lt;td&gt;Exposes UDP total lengths of the rx_queue and tx_queue from &lt;code&gt;/proc/net/udp&lt;/code&gt; and &lt;code&gt;/proc/net/udp6&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;uname&lt;/td&gt; 
   &lt;td&gt;Exposes system information as provided by the uname system call.&lt;/td&gt; 
   &lt;td&gt;Darwin, FreeBSD, Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;vmstat&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/proc/vmstat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;watchdog&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/sys/class/watchdog&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xfs&lt;/td&gt; 
   &lt;td&gt;Exposes XFS runtime statistics.&lt;/td&gt; 
   &lt;td&gt;Linux (kernel 4.4+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;zfs&lt;/td&gt; 
   &lt;td&gt;Exposes &lt;a href="http://open-zfs.org/"&gt;ZFS&lt;/a&gt; performance statistics.&lt;/td&gt; 
   &lt;td&gt;FreeBSD, &lt;a href="http://zfsonlinux.org/"&gt;Linux&lt;/a&gt;, Solaris&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Disabled by default&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;node_exporter&lt;/code&gt; also implements a number of collectors that are disabled by default. Reasons for this vary by collector, and may include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;High cardinality&lt;/li&gt; 
 &lt;li&gt;Prolonged runtime that exceeds the Prometheus &lt;code&gt;scrape_interval&lt;/code&gt; or &lt;code&gt;scrape_timeout&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Significant resource demands on the host&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You can enable additional collectors as desired by adding them to your init system's or service supervisor's startup configuration for &lt;code&gt;node_exporter&lt;/code&gt; but caution is advised. Enable at most one at a time, testing first on a non-production system, then by hand on a single production node. When enabling additional collectors, you should carefully monitor the change by observing the &lt;code&gt; scrape_duration_seconds&lt;/code&gt; metric to ensure that collection completes and does not time out. In addition, monitor the &lt;code&gt;scrape_samples_post_metric_relabeling&lt;/code&gt; metric to see the changes in cardinality.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;OS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;buddyinfo&lt;/td&gt; 
   &lt;td&gt;Exposes statistics of memory fragments as reported by /proc/buddyinfo.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cgroups&lt;/td&gt; 
   &lt;td&gt;A summary of the number of active and enabled cgroups&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;cpu_vulnerabilities&lt;/td&gt; 
   &lt;td&gt;Exposes CPU vulnerability information from sysfs.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;devstat&lt;/td&gt; 
   &lt;td&gt;Exposes device statistics&lt;/td&gt; 
   &lt;td&gt;Dragonfly, FreeBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;drm&lt;/td&gt; 
   &lt;td&gt;Expose GPU metrics using sysfs / DRM, &lt;code&gt;amdgpu&lt;/code&gt; is the only driver which exposes this information through DRM&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;drbd&lt;/td&gt; 
   &lt;td&gt;Exposes Distributed Replicated Block Device statistics (to version 8.4)&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ethtool&lt;/td&gt; 
   &lt;td&gt;Exposes network interface information and network driver statistics equivalent to &lt;code&gt;ethtool&lt;/code&gt;, &lt;code&gt;ethtool -S&lt;/code&gt;, and &lt;code&gt;ethtool -i&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;interrupts&lt;/td&gt; 
   &lt;td&gt;Exposes detailed interrupts statistics.&lt;/td&gt; 
   &lt;td&gt;Linux, OpenBSD&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ksmd&lt;/td&gt; 
   &lt;td&gt;Exposes kernel and system statistics from &lt;code&gt;/sys/kernel/mm/ksm&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;lnstat&lt;/td&gt; 
   &lt;td&gt;Exposes stats from &lt;code&gt;/proc/net/stat/&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;logind&lt;/td&gt; 
   &lt;td&gt;Exposes session counts from &lt;a href="http://www.freedesktop.org/wiki/Software/systemd/logind/"&gt;logind&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;meminfo_numa&lt;/td&gt; 
   &lt;td&gt;Exposes memory statistics from &lt;code&gt;/sys/devices/system/node/node[0-9]*/meminfo&lt;/code&gt;, &lt;code&gt;/sys/devices/system/node/node[0-9]*/numastat&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;mountstats&lt;/td&gt; 
   &lt;td&gt;Exposes filesystem statistics from &lt;code&gt;/proc/self/mountstats&lt;/code&gt;. Exposes detailed NFS client statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;network_route&lt;/td&gt; 
   &lt;td&gt;Exposes the routing table as metrics&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;pcidevice&lt;/td&gt; 
   &lt;td&gt;Exposes pci devices' information including their link status and parent devices.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;perf&lt;/td&gt; 
   &lt;td&gt;Exposes perf based metrics (Warning: Metrics are dependent on kernel configuration and settings).&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;processes&lt;/td&gt; 
   &lt;td&gt;Exposes aggregate process statistics from &lt;code&gt;/proc&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;qdisc&lt;/td&gt; 
   &lt;td&gt;Exposes &lt;a href="https://en.wikipedia.org/wiki/Network_scheduler#Linux_kernel"&gt;queuing discipline&lt;/a&gt; statistics&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;slabinfo&lt;/td&gt; 
   &lt;td&gt;Exposes slab statistics from &lt;code&gt;/proc/slabinfo&lt;/code&gt;. Note that permission of &lt;code&gt;/proc/slabinfo&lt;/code&gt; is usually 0400, so set it appropriately.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;softirqs&lt;/td&gt; 
   &lt;td&gt;Exposes detailed softirq statistics from &lt;code&gt;/proc/softirqs&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;sysctl&lt;/td&gt; 
   &lt;td&gt;Expose sysctl values from &lt;code&gt;/proc/sys&lt;/code&gt;. Use &lt;code&gt;--collector.sysctl.include(-info)&lt;/code&gt; to configure.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;swap&lt;/td&gt; 
   &lt;td&gt;Expose swap information from &lt;code&gt;/proc/swaps&lt;/code&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;systemd&lt;/td&gt; 
   &lt;td&gt;Exposes service and system status from &lt;a href="http://www.freedesktop.org/wiki/Software/systemd/"&gt;systemd&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;tcpstat&lt;/td&gt; 
   &lt;td&gt;Exposes TCP connection status information from &lt;code&gt;/proc/net/tcp&lt;/code&gt; and &lt;code&gt;/proc/net/tcp6&lt;/code&gt;. (Warning: the current version has potential performance issues in high load situations.)&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;wifi&lt;/td&gt; 
   &lt;td&gt;Exposes WiFi device and station statistics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;xfrm&lt;/td&gt; 
   &lt;td&gt;Exposes statistics from &lt;code&gt;/proc/net/xfrm_stat&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;zoneinfo&lt;/td&gt; 
   &lt;td&gt;Exposes NUMA memory zone metrics.&lt;/td&gt; 
   &lt;td&gt;Linux&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Deprecated&lt;/h3&gt; 
&lt;p&gt;These collectors are deprecated and will be removed in the next major release.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Name&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;OS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ntp&lt;/td&gt; 
   &lt;td&gt;Exposes local NTP daemon health to check &lt;a href="https://raw.githubusercontent.com/prometheus/node_exporter/master/docs/TIME.md"&gt;time&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;runit&lt;/td&gt; 
   &lt;td&gt;Exposes service status from &lt;a href="http://smarden.org/runit/"&gt;runit&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;supervisord&lt;/td&gt; 
   &lt;td&gt;Exposes service status from &lt;a href="http://supervisord.org/"&gt;supervisord&lt;/a&gt;.&lt;/td&gt; 
   &lt;td&gt;&lt;em&gt;any&lt;/em&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Perf Collector&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;perf&lt;/code&gt; collector may not work out of the box on some Linux systems due to kernel configuration and security settings. To allow access, set the following &lt;code&gt;sysctl&lt;/code&gt; parameter:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;sysctl -w kernel.perf_event_paranoid=X
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;2 allow only user-space measurements (default since Linux 4.6).&lt;/li&gt; 
 &lt;li&gt;1 allow both kernel and user measurements (default before Linux 4.6).&lt;/li&gt; 
 &lt;li&gt;0 allow access to CPU-specific data but not raw tracepoint samples.&lt;/li&gt; 
 &lt;li&gt;-1 no restrictions.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Depending on the configured value different metrics will be available, for most cases &lt;code&gt;0&lt;/code&gt; will provide the most complete set. For more information see &lt;a href="http://man7.org/linux/man-pages/man2/perf_event_open.2.html"&gt;&lt;code&gt;man 2 perf_event_open&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;By default, the &lt;code&gt;perf&lt;/code&gt; collector will only collect metrics of the CPUs that &lt;code&gt;node_exporter&lt;/code&gt; is running on (ie &lt;a href="https://golang.org/pkg/runtime/#NumCPU"&gt;&lt;code&gt;runtime.NumCPU&lt;/code&gt;&lt;/a&gt;. If this is insufficient (e.g. if you run &lt;code&gt;node_exporter&lt;/code&gt; with its CPU affinity set to specific CPUs), you can specify a list of alternate CPUs by using the &lt;code&gt;--collector.perf.cpus&lt;/code&gt; flag. For example, to collect metrics on CPUs 2-6, you would specify: &lt;code&gt;--collector.perf --collector.perf.cpus=2-6&lt;/code&gt;. The CPU configuration is zero indexed and can also take a stride value; e.g. &lt;code&gt;--collector.perf --collector.perf.cpus=1-10:5&lt;/code&gt; would collect on CPUs 1, 5, and 10.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;perf&lt;/code&gt; collector is also able to collect &lt;a href="https://www.kernel.org/doc/html/latest/core-api/tracepoint.html"&gt;tracepoint&lt;/a&gt; counts when using the &lt;code&gt;--collector.perf.tracepoint&lt;/code&gt; flag. Tracepoints can be found using &lt;a href="http://man7.org/linux/man-pages/man1/perf.1.html"&gt;&lt;code&gt;perf list&lt;/code&gt;&lt;/a&gt; or from debugfs. And example usage of this would be &lt;code&gt;--collector.perf.tracepoint="sched:sched_process_exec"&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Sysctl Collector&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;sysctl&lt;/code&gt; collector can be enabled with &lt;code&gt;--collector.sysctl&lt;/code&gt;. It supports exposing numeric sysctl values as metrics using the &lt;code&gt;--collector.sysctl.include&lt;/code&gt; flag and string values as info metrics by using the &lt;code&gt;--collector.sysctl.include-info&lt;/code&gt; flag. The flags can be repeated. For sysctl with multiple numeric values, an optional mapping can be given to expose each value as its own metric. Otherwise an &lt;code&gt;index&lt;/code&gt; label is used to identify the different fields.&lt;/p&gt; 
&lt;h4&gt;Examples&lt;/h4&gt; 
&lt;h5&gt;Numeric values&lt;/h5&gt; 
&lt;h6&gt;Single values&lt;/h6&gt; 
&lt;p&gt;Using &lt;code&gt;--collector.sysctl.include=vm.user_reserve_kbytes&lt;/code&gt;: &lt;code&gt;vm.user_reserve_kbytes = 131072&lt;/code&gt; -&amp;gt; &lt;code&gt;node_sysctl_vm_user_reserve_kbytes 131072&lt;/code&gt;&lt;/p&gt; 
&lt;h6&gt;Multiple values&lt;/h6&gt; 
&lt;p&gt;A sysctl can contain multiple values, for example:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;net.ipv4.tcp_rmem = 4096	131072	6291456
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Using &lt;code&gt;--collector.sysctl.include=net.ipv4.tcp_rmem&lt;/code&gt; the collector will expose:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;node_sysctl_net_ipv4_tcp_rmem{index="0"} 4096
node_sysctl_net_ipv4_tcp_rmem{index="1"} 131072
node_sysctl_net_ipv4_tcp_rmem{index="2"} 6291456
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If the indexes have defined meaning like in this case, the values can be mapped to multiple metrics by appending the mapping to the --collector.sysctl.include flag: Using &lt;code&gt;--collector.sysctl.include=net.ipv4.tcp_rmem:min,default,max&lt;/code&gt; the collector will expose:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;node_sysctl_net_ipv4_tcp_rmem_min 4096
node_sysctl_net_ipv4_tcp_rmem_default 131072
node_sysctl_net_ipv4_tcp_rmem_max 6291456
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;String values&lt;/h5&gt; 
&lt;p&gt;String values need to be exposed as info metric. The user selects them by using the &lt;code&gt;--collector.sysctl.include-info&lt;/code&gt; flag.&lt;/p&gt; 
&lt;h6&gt;Single values&lt;/h6&gt; 
&lt;p&gt;&lt;code&gt;kernel.core_pattern = core&lt;/code&gt; -&amp;gt; &lt;code&gt;node_sysctl_info{key="kernel.core_pattern_info", value="core"} 1&lt;/code&gt;&lt;/p&gt; 
&lt;h6&gt;Multiple values&lt;/h6&gt; 
&lt;p&gt;Given the following sysctl:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;kernel.seccomp.actions_avail = kill_process kill_thread trap errno trace log allow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Setting &lt;code&gt;--collector.sysctl.include-info=kernel.seccomp.actions_avail&lt;/code&gt; will yield:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;node_sysctl_info{key="kernel.seccomp.actions_avail", index="0", value="kill_process"} 1
node_sysctl_info{key="kernel.seccomp.actions_avail", index="1", value="kill_thread"} 1
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Textfile Collector&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;textfile&lt;/code&gt; collector is similar to the &lt;a href="https://github.com/prometheus/pushgateway"&gt;Pushgateway&lt;/a&gt;, in that it allows exporting of statistics from batch jobs. It can also be used to export static metrics, such as what role a machine has. The Pushgateway should be used for service-level metrics. The &lt;code&gt;textfile&lt;/code&gt; module is for metrics that are tied to a machine.&lt;/p&gt; 
&lt;p&gt;To use it, set the &lt;code&gt;--collector.textfile.directory&lt;/code&gt; flag on the &lt;code&gt;node_exporter&lt;/code&gt; commandline. The collector will parse all files in that directory matching the glob &lt;code&gt;*.prom&lt;/code&gt; using the &lt;a href="http://prometheus.io/docs/instrumenting/exposition_formats/"&gt;text format&lt;/a&gt;. &lt;strong&gt;Note:&lt;/strong&gt; Timestamps are not supported.&lt;/p&gt; 
&lt;p&gt;To atomically push completion time for a cron job:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;echo my_batch_job_completion_time $(date +%s) &amp;gt; /path/to/directory/my_batch_job.prom.$$
mv /path/to/directory/my_batch_job.prom.$$ /path/to/directory/my_batch_job.prom
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To statically set roles for a machine using labels:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;echo 'role{role="application_server"} 1' &amp;gt; /path/to/directory/role.prom.$$
mv /path/to/directory/role.prom.$$ /path/to/directory/role.prom
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Filtering enabled collectors&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;node_exporter&lt;/code&gt; will expose all metrics from enabled collectors by default. This is the recommended way to collect metrics to avoid errors when comparing metrics of different families.&lt;/p&gt; 
&lt;p&gt;For advanced use the &lt;code&gt;node_exporter&lt;/code&gt; can be passed an optional list of collectors to filter metrics. The parameters &lt;code&gt;collect[]&lt;/code&gt; and &lt;code&gt;exclude[]&lt;/code&gt; can be used multiple times (but cannot be combined). In Prometheus configuration you can use this syntax under the &lt;a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#%3Cscrape_config%3E"&gt;scrape config&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Collect only &lt;code&gt;cpu&lt;/code&gt; and &lt;code&gt;meminfo&lt;/code&gt; collector metrics:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  params:
    collect[]:
      - cpu
      - meminfo
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Collect all enabled collector metrics but exclude &lt;code&gt;netdev&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;  params:
    exclude[]:
      - netdev
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This can be useful for having different Prometheus servers collect specific metrics from nodes.&lt;/p&gt; 
&lt;h2&gt;Development building and running&lt;/h2&gt; 
&lt;p&gt;Prerequisites:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://golang.org/dl/"&gt;Go compiler&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;RHEL/CentOS: &lt;code&gt;glibc-static&lt;/code&gt; package.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Building:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;git clone https://github.com/prometheus/node_exporter.git
cd node_exporter
make build
./node_exporter &amp;lt;flags&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see all available configuration flags:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;./node_exporter -h
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Running tests&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;make test
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;TLS endpoint&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;EXPERIMENTAL&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The exporter supports TLS via a new web configuration file.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;./node_exporter --web.config.file=web-config.yml
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/prometheus/exporter-toolkit/raw/master/docs/web-configuration.md"&gt;exporter-toolkit web-configuration&lt;/a&gt; for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>argoproj/argo-cd</title>
      <link>https://github.com/argoproj/argo-cd</link>
      <description>&lt;p&gt;Declarative Continuous Deployment for Kubernetes&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;strong&gt;Releases:&lt;/strong&gt; &lt;a href="https://github.com/argoproj/argo-cd/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/argoproj/argo-cd?label=argo-cd" alt="Release Version" /&gt;&lt;/a&gt; &lt;a href="https://artifacthub.io/packages/helm/argo/argo-cd"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-cd" alt="Artifact HUB" /&gt;&lt;/a&gt; &lt;a href="https://slsa.dev"&gt;&lt;img src="https://slsa.dev/images/gh-badge-level3.svg?sanitize=true" alt="SLSA 3" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Code:&lt;/strong&gt; &lt;a href="https://github.com/argoproj/argo-cd/actions?query=workflow%3A%22Integration+tests%22"&gt;&lt;img src="https://github.com/argoproj/argo-cd/workflows/Integration%20tests/badge.svg?branch=master" alt="Integration tests" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/argoproj/argo-cd"&gt;&lt;img src="https://codecov.io/gh/argoproj/argo-cd/branch/master/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt; &lt;a href="https://bestpractices.coreinfrastructure.org/projects/4486"&gt;&lt;img src="https://bestpractices.coreinfrastructure.org/projects/4486/badge" alt="CII Best Practices" /&gt;&lt;/a&gt; &lt;a href="https://scorecard.dev/viewer/?uri=github.com/argoproj/argo-cd"&gt;&lt;img src="https://api.securityscorecards.dev/projects/github.com/argoproj/argo-cd/badge" alt="OpenSSF Scorecard" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Social:&lt;/strong&gt; &lt;a href="https://twitter.com/argoproj"&gt;&lt;img src="https://img.shields.io/twitter/follow/argoproj?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://argoproj.github.io/community/join-slack"&gt;&lt;img src="https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack" alt="Slack" /&gt;&lt;/a&gt; &lt;a href="https://www.linkedin.com/company/argoproj/"&gt;&lt;img src="https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin" alt="LinkedIn" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Argo CD - Declarative Continuous Delivery for Kubernetes&lt;/h1&gt; 
&lt;h2&gt;What is Argo CD?&lt;/h2&gt; 
&lt;p&gt;Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/argoproj/argo-cd/master/docs/assets/argocd-ui.gif" alt="Argo CD UI" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://youtu.be/0WAm0y2vLIo"&gt;&lt;img src="https://img.youtube.com/vi/0WAm0y2vLIo/0.jpg" alt="Argo CD Demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Why Argo CD?&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Application definitions, configurations, and environments should be declarative and version controlled.&lt;/li&gt; 
 &lt;li&gt;Application deployment and lifecycle management should be automated, auditable, and easy to understand.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Who uses Argo CD?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/argoproj/argo-cd/master/USERS.md"&gt;Official Argo CD user list&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;To learn more about Argo CD &lt;a href="https://argo-cd.readthedocs.io/"&gt;go to the complete documentation&lt;/a&gt;. Check live demo at &lt;a href="https://cd.apps.argoproj.io/"&gt;https://cd.apps.argoproj.io/&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;h3&gt;Contribution, Discussion and Support&lt;/h3&gt; 
&lt;p&gt;You can reach the Argo CD community and developers via the following channels:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Q &amp;amp; A : &lt;a href="https://github.com/argoproj/argo-cd/discussions"&gt;Github Discussions&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Chat : &lt;a href="https://argoproj.github.io/community/join-slack"&gt;The #argo-cd Slack channel&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Contributors Office Hours: &lt;a href="https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com"&gt;Every Thursday&lt;/a&gt; | &lt;a href="https://docs.google.com/document/d/1xkoFkVviB70YBzSEa4bDnu-rUZ1sIFtwKKG1Uw8XsY8"&gt;Agenda&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;User Community meeting: &lt;a href="https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com"&gt;First Wednesday of the month&lt;/a&gt; | &lt;a href="https://docs.google.com/document/d/1ttgw98MO45Dq7ZUHpIiOIEfbyeitKHNfMjbY5dLLMKQ"&gt;Agenda&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Participation in the Argo CD project is governed by the &lt;a href="https://github.com/cncf/foundation/raw/master/code-of-conduct.md"&gt;CNCF Code of Conduct&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Blogs and Presentations&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;a href="https://github.com/terrytangyuan/awesome-argo"&gt;Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://akuity.io/blog/secret-ingredients-of-continuous-delivery-at-enterprise-scale-with-argocd/"&gt;Unveil the Secret Ingredients of Continuous Delivery at Enterprise Scale with Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/avPUQin9kzU"&gt;GitOps Without Pipelines With ArgoCD Image Updater&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/eEcgn_gU3SM"&gt;Combining Argo CD (GitOps), Crossplane (Control Plane), And KubeVela (OAM)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/yrj4lmScKHQ"&gt;How to Apply GitOps to Everything - Combining Argo CD and Crossplane&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/nkPoPaVzExY"&gt;Couchbase - How To Run a Database Cluster in Kubernetes Using Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/XNXJtxkUKeY"&gt;Automation of Everything - How To Combine Argo Events, Workflows &amp;amp; Pipelines, CD, and Rollouts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/cpAaI8p4R60"&gt;Environments Based On Pull Requests (PRs): Using Argo CD To Apply GitOps Principles On Previews&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/vpWQeoaiRM4"&gt;Argo CD: Applying GitOps Principles To Manage Production Environment In Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codefresh.io/continuous-deployment/creating-temporary-preview-environments-based-pull-requests-argo-cd-codefresh/"&gt;Creating Temporary Preview Environments Based On Pull Requests With Argo CD And Codefresh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=r50tRQjisxw"&gt;Tutorial: Everything You Need To Become A GitOps Ninja&lt;/a&gt; 90m tutorial on GitOps and Argo CD.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.inovex.de/blog/spinnaker-vs-argo-cd-vs-tekton-vs-jenkins-x/"&gt;Comparison of Argo CD, Spinnaker, Jenkins X, and Tekton&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.ibm.com/cloud/blog/simplify-and-automate-deployments-using-gitops-with-ibm-multicloud-manager-3-1-2"&gt;Simplify and Automate Deployments Using GitOps with IBM Multicloud Manager 3.1.2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://v0-6.kubeflow.org/docs/use-cases/gitops-for-kubeflow/"&gt;GitOps for Kubeflow using Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.digitalocean.com/community/tutorials/webinar-series-gitops-tool-sets-on-kubernetes-with-circleci-and-argo-cd"&gt;GitOps Toolsets on Kubernetes with CircleCI and Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=OdzH82VpMwI&amp;amp;feature=youtu.be"&gt;CI/CD in Light Speed with K8s and Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=VXrGp5er1ZE&amp;amp;t=0s&amp;amp;index=135&amp;amp;list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU"&gt;Machine Learning as Code&lt;/a&gt;. Among other things, describes how Kubeflow uses Argo CD to implement GitOPs for ML&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=aWDIQMbp1cc&amp;amp;feature=youtu.be&amp;amp;t=1m4s"&gt;Argo CD - GitOps Continuous Delivery for Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=2WSJF7d8dUg&amp;amp;feature=youtu.be"&gt;Introduction to Argo CD : Kubernetes DevOps CI/CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/riskified-technology/gitops-deployment-and-kubernetes-f1ab289efa4b"&gt;GitOps Deployment and Kubernetes - using Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://itnext.io/deploy-argo-cd-with-ingress-and-tls-in-three-steps-no-yaml-yak-shaving-required-bc536d401491"&gt;Deploy Argo CD with Ingress and TLS in Three Steps: No YAML Yak Shaving Required&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://codefresh.io/events/cncf-member-webinar-gitops-continuous-delivery-argo-codefresh/"&gt;GitOps Continuous Delivery with Argo and Codefresh&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mjpitz.com/blog/2020/12/03/renovate-your-gitops/"&gt;Stay up to date with Argo CD and Renovate&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.arthurkoziel.com/setting-up-argocd-with-helm/"&gt;Setting up Argo CD with Helm&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://thenewstack.io/applied-gitops-with-argocd/"&gt;Applied GitOps with Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cncf.io/blog/2020/12/17/solving-configuration-drift-using-gitops-with-argo-cd/"&gt;Solving configuration drift using GitOps with Argo CD&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blogs.sap.com/2021/05/06/decentralized-gitops-over-environments/"&gt;Decentralized GitOps over environments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/AvLuplh1skA"&gt;Getting Started with ArgoCD for GitOps Deployments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/17894DTru2Y"&gt;Using Argo CD &amp;amp; Datree for Stable Kubernetes CI/CD Deployments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://amralaayassen.medium.com/how-to-create-argocd-applications-automatically-using-applicationset-automation-of-the-gitops-59455eaf4f72"&gt;How to create Argo CD Applications Automatically using ApplicationSet? "Automation of GitOps"&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.cncf.io/blog/2022/12/16/progressive-delivery-with-service-mesh-argo-rollouts-with-istio/"&gt;Progressive Delivery with Service Mesh ‚Äì Argo Rollouts with Istio&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>charmbracelet/glow</title>
      <link>https://github.com/charmbracelet/glow</link>
      <description>&lt;p&gt;Render markdown on the CLI, with pizzazz! üíÖüèª&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Glow&lt;/h1&gt; 
&lt;p&gt;Render markdown on the CLI, with &lt;em&gt;pizzazz&lt;/em&gt;!&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://stuff.charm.sh/glow/glow-banner-github.gif" alt="Glow Logo" /&gt; &lt;a href="https://github.com/charmbracelet/glow/releases"&gt;&lt;img src="https://img.shields.io/github/release/charmbracelet/glow.svg?sanitize=true" alt="Latest Release" /&gt;&lt;/a&gt; &lt;a href="https://pkg.go.dev/github.com/charmbracelet/glow?tab=doc"&gt;&lt;img src="https://godoc.org/github.com/golang/gddo?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/charmbracelet/glow/actions"&gt;&lt;img src="https://github.com/charmbracelet/glow/workflows/build/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/charmbracelet/glow"&gt;&lt;img src="https://goreportcard.com/badge/charmbracelet/glow" alt="Go ReportCard" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://github.com/user-attachments/assets/c2246366-f84b-4847-b431-32a61ca07b74" width="800" alt="Glow UI Demo" /&gt; &lt;/p&gt; 
&lt;h2&gt;What is it?&lt;/h2&gt; 
&lt;p&gt;Glow is a terminal based markdown reader designed from the ground up to bring out the beauty‚Äîand power‚Äîof the CLI.&lt;/p&gt; 
&lt;p&gt;Use it to discover markdown files, read documentation directly on the command line. Glow will find local markdown files in subdirectories or a local Git repository.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Package Manager&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS or Linux
brew install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# macOS (with MacPorts)
sudo port install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Arch Linux (btw)
pacman -S glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Void Linux
xbps-install -S glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Nix shell
nix-shell -p glow --command glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# FreeBSD
pkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Solus
eopkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Windows (with Chocolatey, Scoop, or Winget)
choco install glow
scoop install glow
winget install charmbracelet.glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Android (with termux)
pkg install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Ubuntu (Snapcraft)
sudo snap install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Debian/Ubuntu
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo "deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *" | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;amp;&amp;amp; sudo apt install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Fedora/RHEL
echo '[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key' | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install glow
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or download a binary from the &lt;a href="https://github.com/charmbracelet/glow/releases"&gt;releases&lt;/a&gt; page. MacOS, Linux, Windows, FreeBSD and OpenBSD binaries are available, as well as Debian, RPM, and Alpine packages. ARM builds are also available for macOS, Linux, FreeBSD and OpenBSD.&lt;/p&gt; 
&lt;h3&gt;Go&lt;/h3&gt; 
&lt;p&gt;Or just install it with &lt;code&gt;go&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;go install github.com/charmbracelet/glow/v2@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build (requires Go 1.21+)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/charmbracelet/glow.git
cd glow
go build
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;The TUI&lt;/h2&gt; 
&lt;p&gt;Simply run &lt;code&gt;glow&lt;/code&gt; without arguments to start the textual user interface and browse local. Glow will find local markdown files in the current directory and below or, if you‚Äôre in a Git repository, Glow will search the repo.&lt;/p&gt; 
&lt;p&gt;Markdown files can be read with Glow's high-performance pager. Most of the keystrokes you know from &lt;code&gt;less&lt;/code&gt; are the same, but you can press &lt;code&gt;?&lt;/code&gt; to list the hotkeys.&lt;/p&gt; 
&lt;h2&gt;The CLI&lt;/h2&gt; 
&lt;p&gt;In addition to a TUI, Glow has a CLI for working with Markdown. To format a document use a markdown source as the primary argument:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Read from file
glow README.md

# Read from stdin
echo "[Glow](https://github.com/charmbracelet/glow)" | glow -

# Fetch README from GitHub / GitLab
glow github.com/charmbracelet/glow

# Fetch markdown from HTTP
glow https://host.tld/file.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Word Wrapping&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;-w&lt;/code&gt; flag lets you set a maximum width at which the output will be wrapped:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -w 60
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Paging&lt;/h3&gt; 
&lt;p&gt;CLI output can be displayed in your preferred pager with the &lt;code&gt;-p&lt;/code&gt; flag. This defaults to the ANSI-aware &lt;code&gt;less -r&lt;/code&gt; if &lt;code&gt;$PAGER&lt;/code&gt; is not explicitly set.&lt;/p&gt; 
&lt;h3&gt;Styles&lt;/h3&gt; 
&lt;p&gt;You can choose a style with the &lt;code&gt;-s&lt;/code&gt; flag. When no flag is provided &lt;code&gt;glow&lt;/code&gt; tries to detect your terminal's current background color and automatically picks either the &lt;code&gt;dark&lt;/code&gt; or the &lt;code&gt;light&lt;/code&gt; style for you.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -s [dark|light]
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Alternatively you can also supply a custom JSON stylesheet:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow -s mystyle.json
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For additional usage details see:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;glow --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/charmbracelet/glamour/raw/master/styles/gallery/README.md"&gt;Glamour Style Section&lt;/a&gt; to find more styles. Or &lt;a href="https://github.com/charmbracelet/glamour/tree/master/styles"&gt;make your own&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;The Config File&lt;/h2&gt; 
&lt;p&gt;If you find yourself supplying the same flags to &lt;code&gt;glow&lt;/code&gt; all the time, it's probably a good idea to create a config file. Run &lt;code&gt;glow config&lt;/code&gt;, which will open it in your favorite $EDITOR. Alternatively you can manually put a file named &lt;code&gt;glow.yml&lt;/code&gt; in the default config path of you platform. If you're not sure where that is, please refer to &lt;code&gt;glow --help&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Here's an example config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-yaml"&gt;# style name or JSON path (default "auto")
style: "light"
# mouse wheel support (TUI-mode only)
mouse: true
# use pager to display markdown
pager: true
# at which column should we word wrap?
width: 80
# show all files, including hidden and ignored.
all: false
# show line numbers (TUI-mode only)
showLineNumbers: false
# preserve newlines in the output
preserveNewLines: false
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/charmbracelet/glow/contribute"&gt;contributing&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Feedback&lt;/h2&gt; 
&lt;p&gt;We‚Äôd love to hear your thoughts on this project. Feel free to drop us a note!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/charmcli"&gt;Twitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mastodon.social/@charmcli"&gt;The Fediverse&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://charm.sh/chat"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/charmbracelet/glow/raw/master/LICENSE"&gt;MIT&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Part of &lt;a href="https://charm.sh"&gt;Charm&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://charm.sh/"&gt;&lt;img alt="The Charm logo" src="https://stuff.charm.sh/charm-badge.jpg" width="400" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SagerNet/sing-box</title>
      <link>https://github.com/SagerNet/sing-box</link>
      <description>&lt;p&gt;The universal proxy platform&lt;/p&gt;&lt;hr&gt;&lt;blockquote&gt; 
 &lt;p&gt;Sponsored by &lt;a href="https://go.warp.dev/sing-box"&gt;Warp&lt;/a&gt;, built for coding with multiple AI agents&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;a href="https://go.warp.dev/sing-box"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/warpdotdev/brand-assets/raw/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;h1&gt;sing-box&lt;/h1&gt; 
&lt;p&gt;The universal proxy platform.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://repology.org/project/sing-box/versions"&gt;&lt;img src="https://repology.org/badge/vertical-allrepos/sing-box.svg?sanitize=true" alt="Packaging status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://sing-box.sagernet.org"&gt;https://sing-box.sagernet.org&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;pre&gt;&lt;code&gt;Copyright (C) 2022 by nekohasekai &amp;lt;contact-sagernet@sekai.icu&amp;gt;

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program. If not, see &amp;lt;http://www.gnu.org/licenses/&amp;gt;.

In addition, no derivative work may use the name or imply association
with this application without prior consent.
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>gohugoio/hugo</title>
      <link>https://github.com/gohugoio/hugo</link>
      <description>&lt;p&gt;The world‚Äôs fastest framework for building websites.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://gohugo.io/"&gt;&lt;img src="https://raw.githubusercontent.com/gohugoio/gohugoioTheme/master/static/images/hugo-logo-wide.svg?sanitize=true" alt="Hugo" width="565" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A fast and flexible static site generator built with love by &lt;a href="https://github.com/bep"&gt;bep&lt;/a&gt;, &lt;a href="https://github.com/spf13"&gt;spf13&lt;/a&gt;, and &lt;a href="https://github.com/gohugoio/hugo/graphs/contributors"&gt;friends&lt;/a&gt; in &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://godoc.org/github.com/gohugoio/hugo"&gt;&lt;img src="https://godoc.org/github.com/gohugoio/hugo?status.svg?sanitize=true" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/gohugoio/hugo/actions?query=workflow%3ATest"&gt;&lt;img src="https://github.com/gohugoio/hugo/workflows/Test/badge.svg?sanitize=true" alt="Tests on Linux, MacOS and Windows" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/gohugoio/hugo"&gt;&lt;img src="https://goreportcard.com/badge/github.com/gohugoio/hugo" alt="Go Report Card" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://gohugo.io"&gt;Website&lt;/a&gt; | &lt;a href="https://gohugo.io/installation"&gt;Installation&lt;/a&gt; | &lt;a href="https://gohugo.io/documentation"&gt;Documentation&lt;/a&gt; | &lt;a href="https://discourse.gohugo.io"&gt;Support&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/gohugoio/hugo/master/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt; | &lt;a rel="me" href="https://fosstodon.org/@gohugoio"&gt;Mastodon&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Hugo is a &lt;a href="https://en.wikipedia.org/wiki/Static_site_generator"&gt;static site generator&lt;/a&gt; written in &lt;a href="https://go.dev/"&gt;Go&lt;/a&gt;, optimized for speed and designed for flexibility. With its advanced templating system and fast asset pipelines, Hugo renders a complete site in seconds, often less.&lt;/p&gt; 
&lt;p&gt;Due to its flexible framework, multilingual support, and powerful taxonomy system, Hugo is widely used to create:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Corporate, government, nonprofit, education, news, event, and project sites&lt;/li&gt; 
 &lt;li&gt;Documentation sites&lt;/li&gt; 
 &lt;li&gt;Image portfolios&lt;/li&gt; 
 &lt;li&gt;Landing pages&lt;/li&gt; 
 &lt;li&gt;Business, professional, and personal blogs&lt;/li&gt; 
 &lt;li&gt;Resumes and CVs&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Use Hugo's embedded web server during development to instantly see changes to content, structure, behavior, and presentation. Then deploy the site to your host, or push changes to your Git provider for automated builds and deployment.&lt;/p&gt; 
&lt;p&gt;Hugo's fast asset pipelines include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Image processing ‚Äì Convert, resize, crop, rotate, adjust colors, apply filters, overlay text and images, and extract EXIF data&lt;/li&gt; 
 &lt;li&gt;JavaScript bundling ‚Äì Transpile TypeScript and JSX to JavaScript, bundle, tree shake, minify, create source maps, and perform SRI hashing.&lt;/li&gt; 
 &lt;li&gt;Sass processing ‚Äì Transpile Sass to CSS, bundle, tree shake, minify, create source maps, perform SRI hashing, and integrate with PostCSS&lt;/li&gt; 
 &lt;li&gt;Tailwind CSS processing ‚Äì Compile Tailwind CSS utility classes into standard CSS, bundle, tree shake, optimize, minify, perform SRI hashing, and integrate with PostCSS&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;And with &lt;a href="https://gohugo.io/hugo-modules/"&gt;Hugo Modules&lt;/a&gt;, you can share content, assets, data, translations, themes, templates, and configuration with other projects via public or private Git repositories.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://gohugo.io/about/features/"&gt;features&lt;/a&gt; section of the documentation for a comprehensive summary of Hugo's capabilities.&lt;/p&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p float="left"&gt; &lt;a href="https://www.linode.com/?utm_campaign=hugosponsor&amp;amp;utm_medium=banner&amp;amp;utm_source=hugogithub" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/gohugoio/hugoDocs/master/assets/images/sponsors/linode-logo_standard_light_medium.png" width="200" alt="Linode" /&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://www.jetbrains.com/go/?utm_source=OSS&amp;amp;utm_medium=referral&amp;amp;utm_campaign=hugo" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/gohugoio/hugoDocs/master/assets/images/sponsors/goland.svg?sanitize=true" width="200" alt="The complete IDE crafted for professional Go developers." /&gt;&lt;/a&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;a href="https://cloudcannon.com/hugo-cms/?utm_campaign=HugoSponsorship&amp;amp;utm_source=sponsor&amp;amp;utm_content=gohugo" target="_blank"&gt;&lt;img src="https://raw.githubusercontent.com/gohugoio/hugoDocs/master/assets/images/sponsors/cloudcannon-cms-logo.svg?sanitize=true" width="200" alt="CloudCannon" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;Editions&lt;/h2&gt; 
&lt;p&gt;Hugo is available in three editions: standard, extended, and extended/deploy. While the standard edition provides core functionality, the extended and extended/deploy editions offer advanced features.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Feature&lt;/th&gt; 
   &lt;th align="center"&gt;extended edition&lt;/th&gt; 
   &lt;th align="center"&gt;extended/deploy edition&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Encode to the WebP format when &lt;a href="https://gohugo.io/content-management/image-processing/"&gt;processing images&lt;/a&gt;. You can decode WebP images with any edition.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;‚úî&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;‚úî&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://gohugo.io/functions/css/sass/"&gt;Transpile Sass to CSS&lt;/a&gt; using the embedded LibSass transpiler. You can use the &lt;a href="https://gohugo.io/functions/css/sass/#dart-sass"&gt;Dart Sass&lt;/a&gt; transpiler with any edition.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;‚úî&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;‚úî&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;Deploy your site directly to a Google Cloud Storage bucket, an AWS S3 bucket, or an Azure Storage container. See&amp;nbsp;&lt;a href="https://gohugo.io/hosting-and-deployment/hugo-deploy/"&gt;details&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;‚ùå&lt;/span&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;span&gt;‚úî&lt;/span&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Unless your specific deployment needs require the extended/deploy edition, we recommend the extended edition.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Install Hugo from a &lt;a href="https://github.com/gohugoio/hugo/releases/latest"&gt;prebuilt binary&lt;/a&gt;, package manager, or package repository. Please see the installation instructions for your operating system:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gohugo.io/installation/macos"&gt;macOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gohugo.io/installation/linux"&gt;Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gohugo.io/installation/windows"&gt;Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://gohugo.io/installation/bsd"&gt;DragonFly BSD, FreeBSD, NetBSD, and OpenBSD&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Build from source&lt;/h2&gt; 
&lt;p&gt;Prerequisites to build Hugo from source:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Standard edition: Go 1.24.0 or later&lt;/li&gt; 
 &lt;li&gt;Extended edition: Go 1.24.0 or later, and GCC&lt;/li&gt; 
 &lt;li&gt;Extended/deploy edition: Go 1.24.0 or later, and GCC&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Build the standard edition:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;go install github.com/gohugoio/hugo@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Build the extended edition:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;CGO_ENABLED=1 go install -tags extended github.com/gohugoio/hugo@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Build the extended/deploy edition:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-text"&gt;CGO_ENABLED=1 go install -tags extended,withdeploy github.com/gohugoio/hugo@latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#gohugoio/hugo&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=gohugoio/hugo&amp;amp;type=Timeline" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Hugo's &lt;a href="https://gohugo.io/documentation"&gt;documentation&lt;/a&gt; includes installation instructions, a quick start guide, conceptual explanations, reference information, and examples.&lt;/p&gt; 
&lt;p&gt;Please submit documentation issues and pull requests to the &lt;a href="https://github.com/gohugoio/hugoDocs"&gt;documentation repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;Please &lt;strong&gt;do not use the issue queue&lt;/strong&gt; for questions or troubleshooting. Unless you are certain that your issue is a software defect, use the &lt;a href="https://discourse.gohugo.io"&gt;forum&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Hugo‚Äôs &lt;a href="https://discourse.gohugo.io"&gt;forum&lt;/a&gt; is an active community of users and developers who answer questions, share knowledge, and provide examples. A quick search of over 20,000 topics will often answer your question. Please be sure to read about &lt;a href="https://discourse.gohugo.io/t/requesting-help/9132"&gt;requesting help&lt;/a&gt; before asking your first question.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;You can contribute to the Hugo project by:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Answering questions on the &lt;a href="https://discourse.gohugo.io"&gt;forum&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Improving the &lt;a href="https://gohugo.io/documentation"&gt;documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Monitoring the &lt;a href="https://github.com/gohugoio/hugo/issues"&gt;issue queue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Creating or improving &lt;a href="https://themes.gohugo.io/"&gt;themes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Squashing &lt;a href="https://github.com/gohugoio/hugo/issues?q=is%3Aopen+is%3Aissue+label%3ABug"&gt;bugs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please submit documentation issues and pull requests to the &lt;a href="https://github.com/gohugoio/hugoDocs"&gt;documentation repository&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you have an idea for an enhancement or new feature, create a new topic on the &lt;a href="https://discourse.gohugo.io"&gt;forum&lt;/a&gt; in the "Feature" category. This will help you to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Determine if the capability already exists&lt;/li&gt; 
 &lt;li&gt;Measure interest&lt;/li&gt; 
 &lt;li&gt;Refine the concept&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If there is sufficient interest, &lt;a href="https://github.com/gohugoio/hugo/issues/new?labels=Proposal%2C+NeedsTriage&amp;amp;template=feature_request.md"&gt;create a proposal&lt;/a&gt;. Do not submit a pull request until the project lead accepts the proposal.&lt;/p&gt; 
&lt;p&gt;For a complete guide to contributing to Hugo, see the &lt;a href="https://raw.githubusercontent.com/gohugoio/hugo/master/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Dependencies&lt;/h2&gt; 
&lt;p&gt;Hugo stands on the shoulders of great open source libraries. Run &lt;code&gt;hugo env --logLevel info&lt;/code&gt; to display a list of dependencies.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;See current dependencies&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-text"&gt;github.com/BurntSushi/locker="v0.0.0-20171006230638-a6e239ea1c69"
github.com/PuerkitoBio/goquery="v1.10.1"
github.com/alecthomas/chroma/v2="v2.15.0"
github.com/andybalholm/cascadia="v1.3.3"
github.com/armon/go-radix="v1.0.1-0.20221118154546-54df44f2176c"
github.com/bep/clocks="v0.5.0"
github.com/bep/debounce="v1.2.0"
github.com/bep/gitmap="v1.6.0"
github.com/bep/goat="v0.5.0"
github.com/bep/godartsass/v2="v2.3.2"
github.com/bep/golibsass="v1.2.0"
github.com/bep/gowebp="v0.3.0"
github.com/bep/imagemeta="v0.8.4"
github.com/bep/lazycache="v0.7.0"
github.com/bep/logg="v0.4.0"
github.com/bep/mclib="v1.20400.20402"
github.com/bep/overlayfs="v0.9.2"
github.com/bep/simplecobra="v0.5.0"
github.com/bep/tmc="v0.5.1"
github.com/cespare/xxhash/v2="v2.3.0"
github.com/clbanning/mxj/v2="v2.7.0"
github.com/cpuguy83/go-md2man/v2="v2.0.4"
github.com/disintegration/gift="v1.2.1"
github.com/dlclark/regexp2="v1.11.5"
github.com/dop251/goja="v0.0.0-20250125213203-5ef83b82af17"
github.com/evanw/esbuild="v0.24.2"
github.com/fatih/color="v1.18.0"
github.com/frankban/quicktest="v1.14.6"
github.com/fsnotify/fsnotify="v1.8.0"
github.com/getkin/kin-openapi="v0.129.0"
github.com/ghodss/yaml="v1.0.0"
github.com/go-openapi/jsonpointer="v0.21.0"
github.com/go-openapi/swag="v0.23.0"
github.com/go-sourcemap/sourcemap="v2.1.4+incompatible"
github.com/gobuffalo/flect="v1.0.3"
github.com/gobwas/glob="v0.2.3"
github.com/gohugoio/go-i18n/v2="v2.1.3-0.20230805085216-e63c13218d0e"
github.com/gohugoio/hashstructure="v0.5.0"
github.com/gohugoio/httpcache="v0.7.0"
github.com/gohugoio/hugo-goldmark-extensions/extras="v0.2.0"
github.com/gohugoio/hugo-goldmark-extensions/passthrough="v0.3.0"
github.com/gohugoio/locales="v0.14.0"
github.com/gohugoio/localescompressed="v1.0.1"
github.com/golang/freetype="v0.0.0-20170609003504-e2365dfdc4a0"
github.com/google/go-cmp="v0.6.0"
github.com/google/pprof="v0.0.0-20250208200701-d0013a598941"
github.com/gorilla/websocket="v1.5.3"
github.com/hairyhenderson/go-codeowners="v0.7.0"
github.com/hashicorp/golang-lru/v2="v2.0.7"
github.com/jdkato/prose="v1.2.1"
github.com/josharian/intern="v1.0.0"
github.com/kr/pretty="v0.3.1"
github.com/kr/text="v0.2.0"
github.com/kyokomi/emoji/v2="v2.2.13"
github.com/lucasb-eyer/go-colorful="v1.2.0"
github.com/mailru/easyjson="v0.7.7"
github.com/makeworld-the-better-one/dither/v2="v2.4.0"
github.com/marekm4/color-extractor="v1.2.1"
github.com/mattn/go-colorable="v0.1.13"
github.com/mattn/go-isatty="v0.0.20"
github.com/mattn/go-runewidth="v0.0.9"
github.com/mazznoer/csscolorparser="v0.1.5"
github.com/mitchellh/mapstructure="v1.5.1-0.20231216201459-8508981c8b6c"
github.com/mohae/deepcopy="v0.0.0-20170929034955-c48cc78d4826"
github.com/muesli/smartcrop="v0.3.0"
github.com/niklasfasching/go-org="v1.7.0"
github.com/oasdiff/yaml3="v0.0.0-20241210130736-a94c01f36349"
github.com/oasdiff/yaml="v0.0.0-20241210131133-6b86fb107d80"
github.com/olekukonko/tablewriter="v0.0.5"
github.com/pbnjay/memory="v0.0.0-20210728143218-7b4eea64cf58"
github.com/pelletier/go-toml/v2="v2.2.3"
github.com/perimeterx/marshmallow="v1.1.5"
github.com/pkg/browser="v0.0.0-20240102092130-5ac0b6a4141c"
github.com/pkg/errors="v0.9.1"
github.com/rivo/uniseg="v0.4.7"
github.com/rogpeppe/go-internal="v1.13.1"
github.com/russross/blackfriday/v2="v2.1.0"
github.com/sass/libsass="3.6.6"
github.com/spf13/afero="v1.11.0"
github.com/spf13/cast="v1.7.1"
github.com/spf13/cobra="v1.8.1"
github.com/spf13/fsync="v0.10.1"
github.com/spf13/pflag="v1.0.6"
github.com/tdewolff/minify/v2="v2.20.37"
github.com/tdewolff/parse/v2="v2.7.15"
github.com/tetratelabs/wazero="v1.8.2"
github.com/webmproject/libwebp="v1.3.2"
github.com/yuin/goldmark-emoji="v1.0.4"
github.com/yuin/goldmark="v1.7.8"
go.uber.org/automaxprocs="v1.5.3"
golang.org/x/crypto="v0.33.0"
golang.org/x/exp="v0.0.0-20250210185358-939b2ce775ac"
golang.org/x/image="v0.24.0"
golang.org/x/mod="v0.23.0"
golang.org/x/net="v0.35.0"
golang.org/x/sync="v0.11.0"
golang.org/x/sys="v0.30.0"
golang.org/x/text="v0.22.0"
golang.org/x/tools="v0.30.0"
golang.org/x/xerrors="v0.0.0-20240903120638-7835f813f4da"
gonum.org/v1/plot="v0.15.0"
google.golang.org/protobuf="v1.36.5"
gopkg.in/yaml.v2="v2.4.0"
gopkg.in/yaml.v3="v3.0.1"
oss.terrastruct.com/d2="v0.6.9"
oss.terrastruct.com/util-go="v0.0.0-20241005222610-44c011a04896"
rsc.io/qr="v0.2.0"
software.sslmate.com/src/go-pkcs12="v0.2.0"
&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>go-chi/chi</title>
      <link>https://github.com/go-chi/chi</link>
      <description>&lt;p&gt;lightweight, idiomatic and composable router for building Go HTTP services&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img alt="chi" src="https://cdn.rawgit.com/go-chi/chi/master/_examples/chi.svg?sanitize=true" width="220" /&gt;&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/v5"&gt;&lt;img src="https://godoc.org/github.com/go-chi/chi?status.svg?sanitize=true" alt="GoDoc Widget" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;chi&lt;/code&gt; is a lightweight, idiomatic and composable router for building Go HTTP services. It's especially good at helping you write large REST API services that are kept maintainable as your project grows and changes. &lt;code&gt;chi&lt;/code&gt; is built on the new &lt;code&gt;context&lt;/code&gt; package introduced in Go 1.7 to handle signaling, cancelation and request-scoped values across a handler chain.&lt;/p&gt; 
&lt;p&gt;The focus of the project has been to seek out an elegant and comfortable design for writing REST API servers, written during the development of the Pressly API service that powers our public API service, which in turn powers all of our client-side applications.&lt;/p&gt; 
&lt;p&gt;The key considerations of chi's design are: project structure, maintainability, standard http handlers (stdlib-only), developer productivity, and deconstructing a large system into many small parts. The core router &lt;code&gt;github.com/go-chi/chi&lt;/code&gt; is quite small (less than 1000 LOC), but we've also included some useful/optional subpackages: &lt;a href="https://raw.githubusercontent.com/go-chi/chi/master/middleware"&gt;middleware&lt;/a&gt;, &lt;a href="https://github.com/go-chi/render"&gt;render&lt;/a&gt; and &lt;a href="https://github.com/go-chi/docgen"&gt;docgen&lt;/a&gt;. We hope you enjoy it too!&lt;/p&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;go get -u github.com/go-chi/chi/v5
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt; - cloc'd in ~1000 LOC for the chi router&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt; - yes, see &lt;a href="https://raw.githubusercontent.com/go-chi/chi/master/#benchmarks"&gt;benchmarks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% compatible with net/http&lt;/strong&gt; - use any http or middleware pkg in the ecosystem that is also compatible with &lt;code&gt;net/http&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Designed for modular/composable APIs&lt;/strong&gt; - middlewares, inline middlewares, route groups and sub-router mounting&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Context control&lt;/strong&gt; - built on new &lt;code&gt;context&lt;/code&gt; package, providing value chaining, cancellations and timeouts&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Robust&lt;/strong&gt; - in production at Pressly, Cloudflare, Heroku, 99Designs, and many others (see &lt;a href="https://github.com/go-chi/chi/issues/91"&gt;discussion&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Doc generation&lt;/strong&gt; - &lt;code&gt;docgen&lt;/code&gt; auto-generates routing documentation from your source to JSON or Markdown&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Go.mod support&lt;/strong&gt; - as of v5, go.mod support (see &lt;a href="https://github.com/go-chi/chi/raw/master/CHANGELOG.md"&gt;CHANGELOG&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;No external dependencies&lt;/strong&gt; - plain ol' Go stdlib + net/http&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Examples&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://github.com/go-chi/chi/raw/master/_examples/"&gt;_examples/&lt;/a&gt; for a variety of examples.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;As easy as:&lt;/strong&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;package main

import (
	"net/http"

	"github.com/go-chi/chi/v5"
	"github.com/go-chi/chi/v5/middleware"
)

func main() {
	r := chi.NewRouter()
	r.Use(middleware.Logger)
	r.Get("/", func(w http.ResponseWriter, r *http.Request) {
		w.Write([]byte("welcome"))
	})
	http.ListenAndServe(":3000", r)
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;REST Preview:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Here is a little preview of what routing looks like with chi. Also take a look at the generated routing docs in JSON (&lt;a href="https://github.com/go-chi/chi/raw/master/_examples/rest/routes.json"&gt;routes.json&lt;/a&gt;) and in Markdown (&lt;a href="https://github.com/go-chi/chi/raw/master/_examples/rest/routes.md"&gt;routes.md&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;I highly recommend reading the source of the &lt;a href="https://github.com/go-chi/chi/raw/master/_examples/"&gt;examples&lt;/a&gt; listed above, they will show you all the features of chi and serve as a good form of documentation.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  //...
  "context"
  "github.com/go-chi/chi/v5"
  "github.com/go-chi/chi/v5/middleware"
)

func main() {
  r := chi.NewRouter()

  // A good base middleware stack
  r.Use(middleware.RequestID)
  r.Use(middleware.RealIP)
  r.Use(middleware.Logger)
  r.Use(middleware.Recoverer)

  // Set a timeout value on the request context (ctx), that will signal
  // through ctx.Done() that the request has timed out and further
  // processing should be stopped.
  r.Use(middleware.Timeout(60 * time.Second))

  r.Get("/", func(w http.ResponseWriter, r *http.Request) {
    w.Write([]byte("hi"))
  })

  // RESTy routes for "articles" resource
  r.Route("/articles", func(r chi.Router) {
    r.With(paginate).Get("/", listArticles)                           // GET /articles
    r.With(paginate).Get("/{month}-{day}-{year}", listArticlesByDate) // GET /articles/01-16-2017

    r.Post("/", createArticle)                                        // POST /articles
    r.Get("/search", searchArticles)                                  // GET /articles/search

    // Regexp url parameters:
    r.Get("/{articleSlug:[a-z-]+}", getArticleBySlug)                // GET /articles/home-is-toronto

    // Subrouters:
    r.Route("/{articleID}", func(r chi.Router) {
      r.Use(ArticleCtx)
      r.Get("/", getArticle)                                          // GET /articles/123
      r.Put("/", updateArticle)                                       // PUT /articles/123
      r.Delete("/", deleteArticle)                                    // DELETE /articles/123
    })
  })

  // Mount the admin sub-router
  r.Mount("/admin", adminRouter())

  http.ListenAndServe(":3333", r)
}

func ArticleCtx(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    articleID := chi.URLParam(r, "articleID")
    article, err := dbGetArticle(articleID)
    if err != nil {
      http.Error(w, http.StatusText(404), 404)
      return
    }
    ctx := context.WithValue(r.Context(), "article", article)
    next.ServeHTTP(w, r.WithContext(ctx))
  })
}

func getArticle(w http.ResponseWriter, r *http.Request) {
  ctx := r.Context()
  article, ok := ctx.Value("article").(*Article)
  if !ok {
    http.Error(w, http.StatusText(422), 422)
    return
  }
  w.Write([]byte(fmt.Sprintf("title:%s", article.Title)))
}

// A completely separate router for administrator routes
func adminRouter() http.Handler {
  r := chi.NewRouter()
  r.Use(AdminOnly)
  r.Get("/", adminIndex)
  r.Get("/accounts", adminListAccounts)
  return r
}

func AdminOnly(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    ctx := r.Context()
    perm, ok := ctx.Value("acl.permission").(YourPermissionType)
    if !ok || !perm.IsAdmin() {
      http.Error(w, http.StatusText(403), 403)
      return
    }
    next.ServeHTTP(w, r)
  })
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Router interface&lt;/h2&gt; 
&lt;p&gt;chi's router is based on a kind of &lt;a href="https://en.wikipedia.org/wiki/Radix_tree"&gt;Patricia Radix trie&lt;/a&gt;. The router is fully compatible with &lt;code&gt;net/http&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Built on top of the tree is the &lt;code&gt;Router&lt;/code&gt; interface:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// Router consisting of the core routing methods used by chi's Mux,
// using only the standard net/http.
type Router interface {
	http.Handler
	Routes

	// Use appends one or more middlewares onto the Router stack.
	Use(middlewares ...func(http.Handler) http.Handler)

	// With adds inline middlewares for an endpoint handler.
	With(middlewares ...func(http.Handler) http.Handler) Router

	// Group adds a new inline-Router along the current routing
	// path, with a fresh middleware stack for the inline-Router.
	Group(fn func(r Router)) Router

	// Route mounts a sub-Router along a `pattern` string.
	Route(pattern string, fn func(r Router)) Router

	// Mount attaches another http.Handler along ./pattern/*
	Mount(pattern string, h http.Handler)

	// Handle and HandleFunc adds routes for `pattern` that matches
	// all HTTP methods.
	Handle(pattern string, h http.Handler)
	HandleFunc(pattern string, h http.HandlerFunc)

	// Method and MethodFunc adds routes for `pattern` that matches
	// the `method` HTTP method.
	Method(method, pattern string, h http.Handler)
	MethodFunc(method, pattern string, h http.HandlerFunc)

	// HTTP-method routing along `pattern`
	Connect(pattern string, h http.HandlerFunc)
	Delete(pattern string, h http.HandlerFunc)
	Get(pattern string, h http.HandlerFunc)
	Head(pattern string, h http.HandlerFunc)
	Options(pattern string, h http.HandlerFunc)
	Patch(pattern string, h http.HandlerFunc)
	Post(pattern string, h http.HandlerFunc)
	Put(pattern string, h http.HandlerFunc)
	Trace(pattern string, h http.HandlerFunc)

	// NotFound defines a handler to respond whenever a route could
	// not be found.
	NotFound(h http.HandlerFunc)

	// MethodNotAllowed defines a handler to respond whenever a method is
	// not allowed.
	MethodNotAllowed(h http.HandlerFunc)
}

// Routes interface adds two methods for router traversal, which is also
// used by the github.com/go-chi/docgen package to generate documentation for Routers.
type Routes interface {
	// Routes returns the routing tree in an easily traversable structure.
	Routes() []Route

	// Middlewares returns the list of middlewares in use by the router.
	Middlewares() Middlewares

	// Match searches the routing tree for a handler that matches
	// the method/path - similar to routing a http request, but without
	// executing the handler thereafter.
	Match(rctx *Context, method, path string) bool
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Each routing method accepts a URL &lt;code&gt;pattern&lt;/code&gt; and chain of &lt;code&gt;handlers&lt;/code&gt;. The URL pattern supports named params (ie. &lt;code&gt;/users/{userID}&lt;/code&gt;) and wildcards (ie. &lt;code&gt;/admin/*&lt;/code&gt;). URL parameters can be fetched at runtime by calling &lt;code&gt;chi.URLParam(r, "userID")&lt;/code&gt; for named parameters and &lt;code&gt;chi.URLParam(r, "*")&lt;/code&gt; for a wildcard parameter.&lt;/p&gt; 
&lt;h3&gt;Middleware handlers&lt;/h3&gt; 
&lt;p&gt;chi's middlewares are just stdlib net/http middleware handlers. There is nothing special about them, which means the router and all the tooling is designed to be compatible and friendly with any middleware in the community. This offers much better extensibility and reuse of packages and is at the heart of chi's purpose.&lt;/p&gt; 
&lt;p&gt;Here is an example of a standard net/http middleware where we assign a context key &lt;code&gt;"user"&lt;/code&gt; the value of &lt;code&gt;"123"&lt;/code&gt;. This middleware sets a hypothetical user identifier on the request context and calls the next handler in the chain.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// HTTP middleware setting a value on the request context
func MyMiddleware(next http.Handler) http.Handler {
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    // create new context from `r` request context, and assign key `"user"`
    // to value of `"123"`
    ctx := context.WithValue(r.Context(), "user", "123")

    // call the next handler in the chain, passing the response writer and
    // the updated request object with the new context value.
    //
    // note: context.Context values are nested, so any previously set
    // values will be accessible as well, and the new `"user"` key
    // will be accessible from this point forward.
    next.ServeHTTP(w, r.WithContext(ctx))
  })
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Request handlers&lt;/h3&gt; 
&lt;p&gt;chi uses standard net/http request handlers. This little snippet is an example of a http.Handler func that reads a user identifier from the request context - hypothetically, identifying the user sending an authenticated request, validated+set by a previous middleware handler.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// HTTP handler accessing data from the request context.
func MyRequestHandler(w http.ResponseWriter, r *http.Request) {
  // here we read from the request context and fetch out `"user"` key set in
  // the MyMiddleware example above.
  user := r.Context().Value("user").(string)

  // respond to the client
  w.Write([]byte(fmt.Sprintf("hi %s", user)))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;URL parameters&lt;/h3&gt; 
&lt;p&gt;chi's router parses and stores URL parameters right onto the request context. Here is an example of how to access URL params in your net/http handlers. And of course, middlewares are able to access the same information.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;// HTTP handler accessing the url routing parameters.
func MyRequestHandler(w http.ResponseWriter, r *http.Request) {
  // fetch the url parameter `"userID"` from the request of a matching
  // routing pattern. An example routing pattern could be: /users/{userID}
  userID := chi.URLParam(r, "userID")

  // fetch `"key"` from the request context
  ctx := r.Context()
  key := ctx.Value("key").(string)

  // respond to the client
  w.Write([]byte(fmt.Sprintf("hi %v, %v", userID, key)))
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Middlewares&lt;/h2&gt; 
&lt;p&gt;chi comes equipped with an optional &lt;code&gt;middleware&lt;/code&gt; package, providing a suite of standard &lt;code&gt;net/http&lt;/code&gt; middlewares. Please note, any middleware in the ecosystem that is also compatible with &lt;code&gt;net/http&lt;/code&gt; can be used with chi's mux.&lt;/p&gt; 
&lt;h3&gt;Core middlewares&lt;/h3&gt; 
&lt;hr /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;chi/middleware Handler&lt;/th&gt; 
   &lt;th align="left"&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#AllowContentEncoding"&gt;AllowContentEncoding&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Enforces a whitelist of request Content-Encoding headers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#AllowContentType"&gt;AllowContentType&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Explicit whitelist of accepted request Content-Types&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#BasicAuth"&gt;BasicAuth&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Basic HTTP authentication&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Compress"&gt;Compress&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Gzip compression for clients that accept compressed responses&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#ContentCharset"&gt;ContentCharset&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Ensure charset for Content-Type request headers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#CleanPath"&gt;CleanPath&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Clean double slashes from request path&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#GetHead"&gt;GetHead&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Automatically route undefined HEAD requests to GET handlers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Heartbeat"&gt;Heartbeat&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Monitoring endpoint to check the servers pulse&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Logger"&gt;Logger&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Logs the start and end of each request with the elapsed processing time&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#NoCache"&gt;NoCache&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sets response headers to prevent clients from caching&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Profiler"&gt;Profiler&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Easily attach net/http/pprof to your routers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#RealIP"&gt;RealIP&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sets a http.Request's RemoteAddr to either X-Real-IP or X-Forwarded-For&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Recoverer"&gt;Recoverer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Gracefully absorb panics and prints the stack trace&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#RequestID"&gt;RequestID&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Injects a request ID into the context of each request&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#RedirectSlashes"&gt;RedirectSlashes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Redirect slashes on routing paths&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#RouteHeaders"&gt;RouteHeaders&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Route handling for request headers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#SetHeader"&gt;SetHeader&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Short-hand middleware to set a response header key/value&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#StripSlashes"&gt;StripSlashes&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Strip slashes on routing paths&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/v5/middleware#Sunset"&gt;Sunset&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Sunset set Deprecation/Sunset header to response&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Throttle"&gt;Throttle&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Puts a ceiling on the number of concurrent requests&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#Timeout"&gt;Timeout&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Signals to the request context when the timeout deadline is reached&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#URLFormat"&gt;URLFormat&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Parse extension from url and put it on request context&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://pkg.go.dev/github.com/go-chi/chi/middleware#WithValue"&gt;WithValue&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Short-hand middleware to set a key/value on the request context&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Extra middlewares &amp;amp; packages&lt;/h3&gt; 
&lt;p&gt;Please see &lt;a href="https://github.com/go-chi"&gt;https://github.com/go-chi&lt;/a&gt; for additional packages.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;package&lt;/th&gt; 
   &lt;th align="left"&gt;description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/cors"&gt;cors&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Cross-origin resource sharing (CORS)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/docgen"&gt;docgen&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Print chi.Router routes at runtime&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/jwtauth"&gt;jwtauth&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;JWT authentication&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/hostrouter"&gt;hostrouter&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Domain/host based request routing&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/httplog"&gt;httplog&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Small but powerful structured HTTP request logging&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/httprate"&gt;httprate&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;HTTP request rate limiter&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/httptracer"&gt;httptracer&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;HTTP request performance tracing library&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/httpvcr"&gt;httpvcr&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;Write deterministic tests for external sources&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://github.com/go-chi/stampede"&gt;stampede&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;HTTP request coalescer&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;context?&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;context&lt;/code&gt; is a tiny pkg that provides simple interface to signal context across call stacks and goroutines. It was originally written by &lt;a href="https://github.com/Sajmani"&gt;Sameer Ajmani&lt;/a&gt; and is available in stdlib since go1.7.&lt;/p&gt; 
&lt;p&gt;Learn more at &lt;a href="https://blog.golang.org/context"&gt;https://blog.golang.org/context&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;and..&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Docs: &lt;a href="https://golang.org/pkg/context"&gt;https://golang.org/pkg/context&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Source: &lt;a href="https://github.com/golang/go/tree/master/src/context"&gt;https://github.com/golang/go/tree/master/src/context&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmarks&lt;/h2&gt; 
&lt;p&gt;The benchmark suite: &lt;a href="https://github.com/pkieltyka/go-http-routing-benchmark"&gt;https://github.com/pkieltyka/go-http-routing-benchmark&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Results as of Nov 29, 2020 with Go 1.15.5 on Linux AMD 3950x&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-shell"&gt;BenchmarkChi_Param          	3075895	        384 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_Param5         	2116603	        566 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_Param20        	 964117	       1227 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_ParamWrite     	2863413	        420 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GithubStatic   	3045488	        395 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GithubParam    	2204115	        540 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GithubAll      	  10000	     113811 ns/op	    81203 B/op    406 allocs/op
BenchmarkChi_GPlusStatic    	3337485	        359 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GPlusParam     	2825853	        423 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GPlus2Params   	2471697	        483 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_GPlusAll       	 194220	       5950 ns/op	     5200 B/op     26 allocs/op
BenchmarkChi_ParseStatic    	3365324	        356 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_ParseParam     	2976614	        404 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_Parse2Params   	2638084	        439 ns/op	      400 B/op      2 allocs/op
BenchmarkChi_ParseAll       	 109567	      11295 ns/op	    10400 B/op     52 allocs/op
BenchmarkChi_StaticAll      	  16846	      71308 ns/op	    62802 B/op    314 allocs/op
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Comparison with other routers: &lt;a href="https://gist.github.com/pkieltyka/123032f12052520aaccab752bd3e78cc"&gt;https://gist.github.com/pkieltyka/123032f12052520aaccab752bd3e78cc&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;NOTE: the allocs in the benchmark above are from the calls to http.Request's &lt;code&gt;WithContext(context.Context)&lt;/code&gt; method that clones the http.Request, sets the &lt;code&gt;Context()&lt;/code&gt; on the duplicated (alloc'd) request and returns it the new request object. This is just how setting context on a request in Go works.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Carl Jackson for &lt;a href="https://github.com/zenazn/goji"&gt;https://github.com/zenazn/goji&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Parts of chi's thinking comes from goji, and chi's middleware package sources from &lt;a href="https://github.com/zenazn/goji/tree/master/web/middleware"&gt;goji&lt;/a&gt;.&lt;/li&gt; 
   &lt;li&gt;Please see goji's &lt;a href="https://github.com/zenazn/goji/raw/master/LICENSE"&gt;LICENSE&lt;/a&gt; (MIT)&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Armon Dadgar for &lt;a href="https://github.com/armon/go-radix"&gt;https://github.com/armon/go-radix&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Contributions: &lt;a href="https://github.com/VojtechVitek"&gt;@VojtechVitek&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We'll be more than happy to see &lt;a href="https://raw.githubusercontent.com/go-chi/chi/master/CONTRIBUTING.md"&gt;your contributions&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Beyond REST&lt;/h2&gt; 
&lt;p&gt;chi is just a http router that lets you decompose request handling into many smaller layers. Many companies use chi to write REST services for their public APIs. But, REST is just a convention for managing state via HTTP, and there's a lot of other pieces required to write a complete client-server system or network of microservices.&lt;/p&gt; 
&lt;p&gt;Looking beyond REST, I also recommend some newer works in the field:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/webrpc/webrpc"&gt;webrpc&lt;/a&gt; - Web-focused RPC client+server framework with code-gen&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/grpc/grpc-go"&gt;gRPC&lt;/a&gt; - Google's RPC framework via protobufs&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/99designs/gqlgen"&gt;graphql&lt;/a&gt; - Declarative query language&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nats.io"&gt;NATS&lt;/a&gt; - lightweight pub-sub&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Copyright (c) 2015-present &lt;a href="https://github.com/pkieltyka"&gt;Peter Kieltyka&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Licensed under &lt;a href="https://raw.githubusercontent.com/go-chi/chi/master/LICENSE"&gt;MIT License&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AdguardTeam/AdGuardHome</title>
      <link>https://github.com/AdguardTeam/AdGuardHome</link>
      <description>&lt;p&gt;Network-wide ads &amp; trackers blocking DNS server&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt; 
&lt;p align="center"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: dark)" srcset="doc/adguard_home_darkmode.svg" /&gt; 
  &lt;img alt="AdGuard Home" src="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/doc/adguard_home_lightmode.svg?sanitize=true" width="300px" /&gt; 
 &lt;/picture&gt; &lt;/p&gt; 
&lt;h3 align="center"&gt;Privacy protection center for you and your devices&lt;/h3&gt; 
&lt;p align="center"&gt; Free and open source, powerful network-wide ads &amp;amp; trackers blocking DNS server. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://adguard.com/"&gt;AdGuard.com&lt;/a&gt; | &lt;a href="https://github.com/AdguardTeam/AdGuardHome/wiki"&gt;Wiki&lt;/a&gt; | &lt;a href="https://reddit.com/r/Adguard"&gt;Reddit&lt;/a&gt; | &lt;a href="https://twitter.com/AdGuard"&gt;Twitter&lt;/a&gt; | &lt;a href="https://t.me/adguard_en"&gt;Telegram&lt;/a&gt; &lt;br /&gt;&lt;br /&gt; &lt;a href="https://codecov.io/github/AdguardTeam/AdGuardHome?branch=master"&gt; &lt;img src="https://img.shields.io/codecov/c/github/AdguardTeam/AdGuardHome/master.svg?sanitize=true" alt="Code Coverage" /&gt; &lt;/a&gt; &lt;a href="https://goreportcard.com/report/AdguardTeam/AdGuardHome"&gt; &lt;img src="https://goreportcard.com/badge/github.com/AdguardTeam/AdGuardHome" alt="Go Report Card" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/adguard/adguardhome"&gt; &lt;img alt="Docker Pulls" src="https://img.shields.io/docker/pulls/adguard/adguardhome.svg?maxAge=604800" /&gt; &lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/AdguardTeam/AdGuardHome/releases"&gt; &lt;img src="https://img.shields.io/github/release/AdguardTeam/AdGuardHome/all.svg?sanitize=true" alt="Latest release" /&gt; &lt;/a&gt; &lt;a href="https://snapcraft.io/adguard-home"&gt; &lt;img alt="adguard-home" src="https://snapcraft.io/adguard-home/badge.svg?sanitize=true" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;br /&gt; 
&lt;p align="center"&gt; &lt;img src="https://cdn.adtidy.org/public/Adguard/Common/adguard_home.gif" width="800" /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;AdGuard Home is a network-wide software for blocking ads and tracking. After you set it up, it'll cover ALL your home devices, and you don't need any client-side software for that.&lt;/p&gt; 
&lt;p&gt;It operates as a DNS server that re-routes tracking domains to a ‚Äúblack hole‚Äù, thus preventing your devices from connecting to those servers. It's based on software we use for our public &lt;a href="https://adguard-dns.io/"&gt;AdGuard DNS&lt;/a&gt; servers, and both share a lot of code.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#getting-started"&gt;Getting Started&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#automated-install-linux-and-mac"&gt;Automated install (Linux/Unix/MacOS/FreeBSD/OpenBSD)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#alternative-methods"&gt;Alternative methods&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#guides"&gt;Guides&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#api"&gt;API&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#comparison"&gt;Comparing AdGuard Home to other solutions&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#comparison-adguard-dns"&gt;How is this different from public AdGuard DNS servers?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#comparison-pi-hole"&gt;How does AdGuard Home compare to Pi-Hole&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#comparison-adblock"&gt;How does AdGuard Home compare to traditional ad blockers&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#comparison-limitations"&gt;Known limitations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#how-to-build"&gt;How to build from source&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#building"&gt;Building&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#contributing"&gt;Contributing&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#test-unstable-versions"&gt;Test unstable versions&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#reporting-issues"&gt;Reporting issues&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#translate"&gt;Help with translations&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#help-other"&gt;Other&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#uses"&gt;Projects that use AdGuard Home&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#acknowledgments"&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#privacy"&gt;Privacy&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#getting-started" id="getting-started" name="getting-started"&gt;Getting Started&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#automated-install-linux-and-mac" id="automated-install-linux-and-mac" name="automated-install-linux-and-mac"&gt;Automated install (Linux/Unix/MacOS/FreeBSD/OpenBSD)&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;To install with &lt;code&gt;curl&lt;/code&gt; run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install with &lt;code&gt;wget&lt;/code&gt; run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;wget --no-verbose -O - https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To install with &lt;code&gt;fetch&lt;/code&gt; run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;fetch -o - https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The script also accepts some options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;-c &amp;lt;channel&amp;gt;&lt;/code&gt; to use specified channel;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-r&lt;/code&gt; to reinstall AdGuard Home;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-u&lt;/code&gt; to uninstall AdGuard Home;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;-v&lt;/code&gt; for verbose output.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Note that options &lt;code&gt;-r&lt;/code&gt; and &lt;code&gt;-u&lt;/code&gt; are mutually exclusive.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#alternative-methods" id="alternative-methods" name="alternative-methods"&gt;Alternative methods&lt;/a&gt;&lt;/h3&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#manual-installation" id="manual-installation" name="manual-installation"&gt;Manual installation&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;Please read the &lt;strong&gt;&lt;a href="https://adguard-dns.io/kb/adguard-home/getting-started/"&gt;Getting Started&lt;/a&gt;&lt;/strong&gt; article on our Wiki to learn how to install AdGuard Home manually, and how to configure your devices to use it.&lt;/p&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#docker" id="docker" name="docker"&gt;Docker&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;You can use our official Docker image on &lt;a href="https://hub.docker.com/r/adguard/adguardhome"&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#snap-store" id="snap-store" name="snap-store"&gt;Snap Store&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;If you're running &lt;strong&gt;Linux,&lt;/strong&gt; there's a secure and easy way to install AdGuard Home: get it from the &lt;a href="https://snapcraft.io/adguard-home"&gt;Snap Store&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#guides" id="guides" name="guides"&gt;Guides&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;See our &lt;a href="https://github.com/AdguardTeam/AdGuardHome/wiki"&gt;Wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#api" id="api" name="api"&gt;API&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;If you want to integrate with AdGuard Home, you can use our &lt;a href="https://github.com/AdguardTeam/AdGuardHome/tree/master/openapi"&gt;REST API&lt;/a&gt;. Alternatively, you can use this &lt;a href="https://pypi.org/project/adguardhome/"&gt;python client&lt;/a&gt;, which is used to build the &lt;a href="https://www.home-assistant.io/integrations/adguard/"&gt;AdGuard Home Hass.io Add-on&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#comparison" id="comparison" name="comparison"&gt;Comparing AdGuard Home to other solutions&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#comparison-adguard-dns" id="comparison-adguard-dns" name="comparison-adguard-dns"&gt;How is this different from public AdGuard DNS servers?&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Running your own AdGuard Home server allows you to do much more than using a public DNS server. It's a completely different level. See for yourself:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Choose what exactly the server blocks and permits.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Monitor your network activity.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Add your own custom filtering rules.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Most importantly, it's your own server, and you are the only one who's in control.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#comparison-pi-hole" id="comparison-pi-hole" name="comparison-pi-hole"&gt;How does AdGuard Home compare to Pi-Hole&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;At this point, AdGuard Home has a lot in common with Pi-Hole. Both block ads and trackers using the so-called ‚ÄúDNS sinkholing‚Äù method and both allow customizing what's blocked.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] We're not going to stop here. DNS sinkholing is not a bad starting point, but this is just the beginning.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;AdGuard Home provides a lot of features out-of-the-box with no need to install and configure additional software. We want it to be simple to the point when even casual users can set it up with minimal effort.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Some of the listed features can be added to Pi-Hole by installing additional software or by manually using SSH terminal and reconfiguring one of the utilities Pi-Hole consists of. However, in our opinion, this cannot be legitimately counted as a Pi-Hole's feature.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Feature&lt;/th&gt; 
   &lt;th&gt;AdGuard&amp;nbsp;Home&lt;/th&gt; 
   &lt;th&gt;Pi-Hole&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Blocking ads and trackers&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Customizing blocklists&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Built-in DHCP server&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;HTTPS for the Admin interface&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;Kind of, but you'll need to manually configure lighttpd&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Encrypted DNS upstream servers (DNS-over-HTTPS, DNS-over-TLS, DNSCrypt)&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå (requires additional software)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Cross-platform&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå (not natively, only via Docker)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Running as a DNS-over-HTTPS or DNS-over-TLS server&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå (requires additional software)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Blocking phishing and malware domains&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå (requires non-default blocklists)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Parental control (blocking adult domains)&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå (requires non-default blocklists)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Force Safe search on search engines&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Per-client (device) configuration&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Access settings (choose who can use AGH DNS)&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Running &lt;a href="https://adguard-dns.io/kb/adguard-home/getting-started/#running-without-superuser"&gt;without root privileges&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;‚úÖ&lt;/td&gt; 
   &lt;td&gt;‚ùå&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#comparison-adblock" id="comparison-adblock" name="comparison-adblock"&gt;How does AdGuard Home compare to traditional ad blockers&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;It depends.&lt;/p&gt; 
&lt;p&gt;DNS sinkholing is capable of blocking a big percentage of ads, but it lacks the flexibility and the power of traditional ad blockers. You can get a good impression about the difference between these methods by reading &lt;a href="https://adguard.com/blog/adguard-vs-adaway-dns66.html"&gt;this article&lt;/a&gt;, which compares AdGuard for Android (a traditional ad blocker) to hosts-level ad blockers (which are almost identical to DNS-based blockers in their capabilities). This level of protection is enough for some users.&lt;/p&gt; 
&lt;p&gt;Additionally, using a DNS-based blocker can help to block ads, tracking and analytics requests on other types of devices, such as SmartTVs, smart speakers or other kinds of IoT devices (on which you can't install traditional ad blockers).&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#comparison-limitations" id="comparison-limitations" name="comparison-limitations"&gt;Known limitations&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Here are some examples of what cannot be blocked by a DNS-level blocker:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;YouTube, Twitch ads;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Facebook, Twitter, Instagram sponsored posts.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Essentially, any advertising that shares a domain with content cannot be blocked by a DNS-level blocker.&lt;/p&gt; 
&lt;p&gt;Is there a chance to handle this in the future? DNS will never be enough to do this. Our only option is to use a content blocking proxy like what we do in the standalone AdGuard applications. We're &lt;a href="https://github.com/AdguardTeam/AdGuardHome/issues/1228"&gt;going to bring&lt;/a&gt; this feature support to AdGuard Home in the future. Unfortunately, even in this case, there still will be cases when this won't be enough or would require quite a complicated configuration.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#how-to-build" id="how-to-build" name="how-to-build"&gt;How to build from source&lt;/a&gt;&lt;/h2&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#prerequisites" id="prerequisites" name="prerequisites"&gt;Prerequisites&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Run &lt;code&gt;make init&lt;/code&gt; to prepare the development environment.&lt;/p&gt; 
&lt;p&gt;You will need this to build AdGuard Home:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://golang.org/dl/"&gt;Go&lt;/a&gt; v1.25 or later;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/en/download/"&gt;Node.js&lt;/a&gt; v24.10.0 or later;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.npmjs.com/"&gt;npm&lt;/a&gt; v10.8 or later;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#building" id="building" name="building"&gt;Building&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Open your terminal and execute these commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/AdguardTeam/AdGuardHome
cd AdGuardHome
make
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] The non-standard &lt;code&gt;-j&lt;/code&gt; flag is currently not supported, so building with &lt;code&gt;make -j 4&lt;/code&gt; or setting your &lt;code&gt;MAKEFLAGS&lt;/code&gt; to include, for example, &lt;code&gt;-j 4&lt;/code&gt; is likely to break the build. If you do have your &lt;code&gt;MAKEFLAGS&lt;/code&gt; set to that, and you don't want to change it, you can override it by running &lt;code&gt;make -j 1&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Check the &lt;a href="https://github.com/AdguardTeam/AdGuardHome/raw/master/Makefile"&gt;&lt;code&gt;Makefile&lt;/code&gt;&lt;/a&gt; to learn about other commands.&lt;/p&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#building-cross" id="building-cross" name="building-cross"&gt;Building for a different platform&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;You can build AdGuard Home for any OS/ARCH that Go supports. In order to do this, specify &lt;code&gt;GOOS&lt;/code&gt; and &lt;code&gt;GOARCH&lt;/code&gt; environment variables as macros when running &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;env GOOS='linux' GOARCH='arm64' make
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;or:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;make GOOS='linux' GOARCH='arm64'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#preparing-releases" id="preparing-releases" name="preparing-releases"&gt;Preparing releases&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;You'll need &lt;a href="https://snapcraft.io/"&gt;&lt;code&gt;snapcraft&lt;/code&gt;&lt;/a&gt; to prepare a release build. Once installed, run the following command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;make build-release CHANNEL='...' VERSION='...'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/AdguardTeam/AdGuardHome/tree/master/scripts#build-releasesh-build-a-release-for-all-platforms"&gt;&lt;code&gt;build-release&lt;/code&gt; target documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#docker-image" id="docker-image" name="docker-image"&gt;Docker image&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;Run &lt;code&gt;make build-docker&lt;/code&gt; to build the Docker image locally (the one that we publish to DockerHub). Please note, that we're using &lt;a href="https://docs.docker.com/buildx/working-with-buildx/"&gt;Docker Buildx&lt;/a&gt; to build our official image.&lt;/p&gt; 
&lt;p&gt;You may need to prepare before using these builds:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;(Linux-only) Install Qemu:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;docker run --rm --privileged multiarch/qemu-user-static --reset -p yes --credential yes
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Prepare the builder:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;docker buildx create --name buildx-builder --driver docker-container --use
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/AdguardTeam/AdGuardHome/tree/master/scripts#build-dockersh-build-a-multi-architecture-docker-image"&gt;&lt;code&gt;build-docker&lt;/code&gt; target documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#debugging-the-frontend" id="debugging-the-frontend" name="debugging-the-frontend"&gt;Debugging the frontend&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;When you need to debug the frontend without recompiling the production version every time, for example to check how your labels would look on a form, you can run the frontend build a development environment.&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;In a separate terminal, run:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;( cd ./client/ &amp;amp;&amp;amp; env NODE_ENV='development' npm run watch )
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run your &lt;code&gt;AdGuardHome&lt;/code&gt; binary with the &lt;code&gt;--local-frontend&lt;/code&gt; flag, which instructs AdGuard Home to ignore the built-in frontend files and use those from the &lt;code&gt;./build/&lt;/code&gt; directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Now any changes you make in the &lt;code&gt;./client/&lt;/code&gt; directory should be recompiled and become available on the web UI. Make sure that you disable the browser cache to make sure that you actually get the recompiled version.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#e2e-frontend-tests" id="e2e-frontend-tests" name="e2e-frontend-tests"&gt;End-to-End (E2E) Frontend Tests&lt;/a&gt;&lt;/h4&gt; 
&lt;p&gt;AdGuard Home uses &lt;a href="https://playwright.dev"&gt;Playwright&lt;/a&gt; for E2E testing. Tests are located in &lt;code&gt;tests/e2e&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Running Tests:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;npm run test:e2e&lt;/code&gt; ‚Äì run all tests (headless).&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm run test:e2e:interactive&lt;/code&gt; ‚Äì run tests interactively.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm run test:e2e:debug&lt;/code&gt; ‚Äì run tests in debug mode.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm run test:e2e:codegen&lt;/code&gt; ‚Äì generate new test code.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Setup:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Run &lt;code&gt;npm install&lt;/code&gt; to install dependencies.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;npx playwright install&lt;/code&gt; to set up required browsers.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; Playwright will download and install its own browser binaries for testing, which may differ from the browsers installed on your system.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#contributing" id="contributing" name="contributing"&gt;Contributing&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;You are welcome to fork this repository, make your changes and &lt;a href="https://github.com/AdguardTeam/AdGuardHome/pulls"&gt;submit a pull request&lt;/a&gt;. Please make sure you follow our &lt;a href="https://github.com/AdguardTeam/CodeGuidelines/"&gt;code guidelines&lt;/a&gt; though.&lt;/p&gt; 
&lt;p&gt;Please note that we don't expect people to contribute to both UI and backend parts of the program simultaneously. Ideally, the backend part is implemented first, i.e. configuration, API, and the functionality itself. The UI part can be implemented later in a different pull request by a different person.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#test-unstable-versions" id="test-unstable-versions" name="test-unstable-versions"&gt;Test unstable versions&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;There are two update channels that you can use:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;beta&lt;/code&gt;: beta versions of AdGuard Home. More or less stable versions, usually released every two weeks or more often.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;code&gt;edge&lt;/code&gt;: the newest version of AdGuard Home from the development branch. New updates are pushed to this channel daily.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;There are three options how you can install an unstable version:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://snapcraft.io/adguard-home"&gt;Snap Store&lt;/a&gt;: look for the &lt;code&gt;beta&lt;/code&gt; and &lt;code&gt;edge&lt;/code&gt; channels.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://hub.docker.com/r/adguard/adguardhome"&gt;Docker Hub&lt;/a&gt;: look for the &lt;code&gt;beta&lt;/code&gt; and &lt;code&gt;edge&lt;/code&gt; tags.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Standalone builds. Use the automated installation script or look for the available builds &lt;a href="https://github.com/AdguardTeam/AdGuardHome/wiki/Platforms"&gt;on the Wiki&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Script to install a beta version:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -c beta
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Script to install an edge version:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -c edge
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#reporting-issues" id="reporting-issues" name="reporting-issues"&gt;Report issues&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;If you run into any problem or have a suggestion, head to &lt;a href="https://github.com/AdguardTeam/AdGuardHome/issues"&gt;this page&lt;/a&gt; and click on the ‚ÄúNew issue‚Äù button. Please follow the instructions in the issue form carefully and don't forget to start by searching for duplicates.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#translate" id="translate" name="translate"&gt;Help with translations&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;If you want to help with AdGuard Home translations, please learn more about translating AdGuard products &lt;a href="https://kb.adguard.com/en/general/adguard-translations"&gt;in our Knowledge Base&lt;/a&gt;. You can contribute to the &lt;a href="https://crowdin.com/project/adguard-applications/en#/adguard-home"&gt;AdGuardHome project on CrowdIn&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#help-other" id="help-other" name="help-other"&gt;Other&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;Another way you can contribute is by &lt;a href="https://github.com/AdguardTeam/AdGuardHome/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22"&gt;looking for issues&lt;/a&gt; marked as &lt;code&gt;help wanted&lt;/code&gt;, asking if the issue is up for grabs, and sending a PR fixing the bug or implementing the feature.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#uses" id="uses" name="uses"&gt;Projects that use AdGuard Home&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Please note that these projects are not affiliated with AdGuard, but are made by third-party developers and fans.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://apps.apple.com/app/apple-store/id1543143740"&gt;AdGuard Home Remote&lt;/a&gt;: iOS app by &lt;a href="https://rocketscience-it.nl/"&gt;Joost&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/frenck/python-adguardhome"&gt;Python library&lt;/a&gt; by &lt;a href="https://github.com/frenck"&gt;@frenck&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/hassio-addons/addon-adguard-home"&gt;Home Assistant add-on&lt;/a&gt; by &lt;a href="https://github.com/frenck"&gt;@frenck&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/kongfl888/luci-app-adguardhome"&gt;OpenWrt LUCI app&lt;/a&gt; by &lt;a href="https://github.com/kongfl888"&gt;@kongfl888&lt;/a&gt; (originally by &lt;a href="https://github.com/rufengsuixing"&gt;@rufengsuixing&lt;/a&gt;).&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/bakito/adguardhome-sync"&gt;AdGuardHome sync&lt;/a&gt; by &lt;a href="https://github.com/bakito"&gt;@bakito&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/Lissy93/AdGuardian-Term"&gt;Terminal-based, real-time traffic monitoring and statistics for your AdGuard Home instance&lt;/a&gt; by &lt;a href="https://github.com/Lissy93"&gt;@Lissy93&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://forum.gl-inet.com/t/adguardhome-on-gl-routers/10664"&gt;AdGuard Home on GLInet routers&lt;/a&gt; by &lt;a href="https://gl-inet.com/"&gt;Gl-Inet&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://git.cloudron.io/cloudron/adguard-home-app"&gt;Cloudron app&lt;/a&gt; by &lt;a href="https://github.com/gramakri"&gt;@gramakri&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/jumpsmm7/Asuswrt-Merlin-AdGuardHome-Installer"&gt;Asuswrt-Merlin-AdGuardHome-Installer&lt;/a&gt; by &lt;a href="https://github.com/jumpsmm7"&gt;@jumpsmm7&lt;/a&gt; aka &lt;a href="https://www.snbforums.com/members/somewhereovertherainbow.64179/"&gt;@SomeWhereOverTheRainBow&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/Andrea055/AdguardHomeAPI"&gt;Node.js library&lt;/a&gt; by &lt;a href="https://github.com/Andrea055/"&gt;@Andrea055&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/satheshshiva/Adguard-Home-Browser-Ext"&gt;Browser Extension&lt;/a&gt; by &lt;a href="https://github.com/satheshshiva/"&gt;@satheshshiva&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/diasdmhub/AdGuard_Home_Zabbix_Template"&gt;Zabbix Template for AdGuard Home&lt;/a&gt; by &lt;a href="https://github.com/diasdmhub"&gt;@diasdmhub&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://community.chocolatey.org/packages/adguardhome/"&gt;Chocolatey package&lt;/a&gt; by &lt;a href="https://community.chocolatey.org/profiles/niks255"&gt;niks255&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#acknowledgments" id="acknowledgments" name="acknowledgments"&gt;Acknowledgments&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;This software wouldn't have been possible without:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://golang.org/dl/"&gt;Go&lt;/a&gt; and its libraries: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://github.com/bluele/gcache"&gt;gcache&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/miekg/dns"&gt;miekg's dns&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/go-yaml/yaml"&gt;go-yaml&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://godoc.org/github.com/kardianos/service"&gt;service&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/AdguardTeam/dnsproxy"&gt;dnsproxy&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/AdguardTeam/urlfilter"&gt;urlfilter&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; and its libraries: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://reactjs.org"&gt;React.js&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://github.com/tabler/tabler"&gt;Tabler&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;And many more Node.js packages.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cliqz-oss/whotracks.me"&gt;whotracks.me data&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;You might have seen that &lt;a href="https://coredns.io"&gt;CoreDNS&lt;/a&gt; was mentioned here before, but we've stopped using it in AdGuard Home.&lt;/p&gt; 
&lt;p&gt;For the full list of all Node.js packages in use, please take a look at &lt;a href="https://github.com/AdguardTeam/AdGuardHome/raw/master/client/package.json"&gt;&lt;code&gt;client/package.json&lt;/code&gt;&lt;/a&gt; file.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/#privacy" id="privacy" name="privacy"&gt;Privacy&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Our main idea is that you are the one, who should be in control of your data. So it is only natural, that AdGuard Home does not collect any usage statistics, and does not use any web services unless you configure it to do so. See also the &lt;a href="https://adguard.com/en/privacy/home.html"&gt;full privacy policy&lt;/a&gt; with every bit that &lt;em&gt;could in theory be sent&lt;/em&gt; by AdGuard Home is available.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>henrygd/beszel</title>
      <link>https://github.com/henrygd/beszel</link>
      <description>&lt;p&gt;Lightweight server monitoring hub with historical data, docker stats, and alerts.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Beszel&lt;/h1&gt; 
&lt;p&gt;Beszel is a lightweight server monitoring platform that includes Docker statistics, historical data, and alert functions.&lt;/p&gt; 
&lt;p&gt;It has a friendly web interface, simple configuration, and is ready to use out of the box. It supports automatic backup, multi-user, OAuth authentication, and API access.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://hub.docker.com/r/henrygd/beszel-agent"&gt;&lt;img src="https://img.shields.io/docker/image-size/henrygd/beszel-agent/latest?logo=docker&amp;amp;label=agent%20image%20size" alt="agent Docker Image Size" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/henrygd/beszel"&gt;&lt;img src="https://img.shields.io/docker/image-size/henrygd/beszel/latest?logo=docker&amp;amp;label=hub%20image%20size" alt="hub Docker Image Size" /&gt;&lt;/a&gt; &lt;a href="https://github.com/henrygd/beszel/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/github/license/henrygd/beszel?color=%239944ee" alt="MIT license" /&gt;&lt;/a&gt; &lt;a href="https://crowdin.com/project/beszel"&gt;&lt;img src="https://badges.crowdin.net/beszel/localized.svg?sanitize=true" alt="Crowdin" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://henrygd-assets.b-cdn.net/beszel/screenshot-new.png" alt="Screenshot of Beszel dashboard and system page, side by side. The dashboard shows metrics from multiple connected systems, while the system page shows detailed metrics for a single system." /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Lightweight&lt;/strong&gt;: Smaller and less resource-intensive than leading solutions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Simple&lt;/strong&gt;: Easy setup with little manual configuration required.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Docker stats&lt;/strong&gt;: Tracks CPU, memory, and network usage history for each container.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Alerts&lt;/strong&gt;: Configurable alerts for CPU, memory, disk, bandwidth, temperature, load average, and status.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-user&lt;/strong&gt;: Users manage their own systems. Admins can share systems across users.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;OAuth / OIDC&lt;/strong&gt;: Supports many OAuth2 providers. Password auth can be disabled.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic backups&lt;/strong&gt;: Save to and restore from disk or S3-compatible storage.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- - **REST API**: Use or update your data in your own scripts and applications. --&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;Beszel consists of two main components: the &lt;strong&gt;hub&lt;/strong&gt; and the &lt;strong&gt;agent&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Hub&lt;/strong&gt;: A web application built on &lt;a href="https://pocketbase.io/"&gt;PocketBase&lt;/a&gt; that provides a dashboard for viewing and managing connected systems.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Agent&lt;/strong&gt;: Runs on each system you want to monitor and communicates system metrics to the hub.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Getting started&lt;/h2&gt; 
&lt;p&gt;The &lt;a href="https://beszel.dev/guide/getting-started"&gt;quick start guide&lt;/a&gt; and other documentation is available on our website, &lt;a href="https://beszel.dev"&gt;beszel.dev&lt;/a&gt;. You'll be up and running in a few minutes.&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://beszel.dev/image/dashboard.png" alt="Dashboard" /&gt; &lt;img src="https://beszel.dev/image/system-full.png" alt="System page" /&gt; &lt;img src="https://beszel.dev/image/settings-notifications.png" alt="Notification Settings" /&gt;&lt;/p&gt; 
&lt;h2&gt;Supported metrics&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;CPU usage&lt;/strong&gt; - Host system and Docker / Podman containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Memory usage&lt;/strong&gt; - Host system and containers. Includes swap and ZFS ARC.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Disk usage&lt;/strong&gt; - Host system. Supports multiple partitions and devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Disk I/O&lt;/strong&gt; - Host system. Supports multiple partitions and devices.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Network usage&lt;/strong&gt; - Host system and containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Load average&lt;/strong&gt; - Host system.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Temperature&lt;/strong&gt; - Host system sensors.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GPU usage / power draw&lt;/strong&gt; - Nvidia, AMD, and Intel.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Battery&lt;/strong&gt; - Host system battery charge.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Containers&lt;/strong&gt; - Status and metrics of all running Docker / Podman containers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;S.M.A.R.T.&lt;/strong&gt; - Host system disk health.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Help and discussion&lt;/h2&gt; 
&lt;p&gt;Please search existing issues and discussions before opening a new one. I try my best to respond, but may not always have time to do so.&lt;/p&gt; 
&lt;h4&gt;Bug reports and feature requests&lt;/h4&gt; 
&lt;p&gt;Bug reports and feature requests can be posted on &lt;a href="https://github.com/henrygd/beszel/issues"&gt;GitHub issues&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Support and general discussion&lt;/h4&gt; 
&lt;p&gt;Support requests and general discussion can be posted on &lt;a href="https://github.com/henrygd/beszel/discussions"&gt;GitHub discussions&lt;/a&gt; or the community-run &lt;a href="https://matrix.to/#/#beszel:matrix.org"&gt;Matrix room&lt;/a&gt;: &lt;code&gt;#beszel:matrix.org&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Beszel is licensed under the MIT License. See the &lt;a href="https://raw.githubusercontent.com/henrygd/beszel/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for more details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>hashicorp/vault</title>
      <link>https://github.com/hashicorp/vault</link>
      <description>&lt;p&gt;A tool for secrets management, encryption as a service, and privileged access management&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Vault &lt;a href="https://github.com/hashicorp/vault/actions/workflows/build.yml"&gt;&lt;img src="https://github.com/hashicorp/vault/actions/workflows/build.yml/badge.svg?sanitize=true" alt="build" /&gt;&lt;/a&gt; &lt;a href="https://github.com/hashicorp/vault/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/hashicorp/vault/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="ci" /&gt;&lt;/a&gt; &lt;a href="https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=banner&amp;amp;utm_campaign=github-vault-enterprise"&gt;&lt;img src="https://img.shields.io/badge/vault-enterprise-yellow.svg?colorB=7c8797&amp;amp;colorA=000000" alt="vault enterprise" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Please note&lt;/strong&gt;: We take Vault's security and our users' trust very seriously. If you believe you have found a security issue in Vault, &lt;em&gt;please responsibly disclose&lt;/em&gt; by contacting us at &lt;a href="mailto:security@hashicorp.com"&gt;security@hashicorp.com&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;ul&gt; 
 &lt;li&gt;Website: &lt;a href="https://developer.hashicorp.com/vault"&gt;developer.hashicorp.com/vault&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Announcement list: &lt;a href="https://groups.google.com/group/hashicorp-announce"&gt;Google Groups&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discussion forum: &lt;a href="https://discuss.hashicorp.com/c/vault"&gt;Discuss&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation: &lt;a href="https://developer.hashicorp.com/vault/docs"&gt;https://developer.hashicorp.com/vault/docs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Tutorials: &lt;a href="https://developer.hashicorp.com/vault/tutorials"&gt;https://developer.hashicorp.com/vault/tutorials&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Certification exam: &lt;a href="https://developer.hashicorp.com/certifications/security-automation"&gt;https://developer.hashicorp.com/certifications/security-automation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation source: &lt;a href="https://github.com/hashicorp/web-unified-docs"&gt;https://github.com/hashicorp/web-unified-docs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img width="300" alt="Vault Logo" src="https://github.com/hashicorp/vault/raw/f22d202cde2018f9455dec755118a9b84586e082/Vault_PrimaryLogo_Black.png" /&gt; 
&lt;p&gt;Vault is a tool for securely accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, and more. Vault provides a unified interface to any secret, while providing tight access control and recording a detailed audit log.&lt;/p&gt; 
&lt;p&gt;A modern system requires access to a multitude of secrets: database credentials, API keys for external services, credentials for service-oriented architecture communication, etc. Understanding who is accessing what secrets is already very difficult and platform-specific. Adding on key rolling, secure storage, and detailed audit logs is almost impossible without a custom solution. This is where Vault steps in.&lt;/p&gt; 
&lt;p&gt;The key features of Vault are:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Secure Secret Storage&lt;/strong&gt;: Vault can store arbitrary key/value pairs. Vault encrypts data before writing it to persistent storage, so gaining access to the raw storage isn't enough to access your secrets. Vault can write to disk, &lt;a href="https://www.consul.io"&gt;Consul&lt;/a&gt;, and more.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Dynamic Secrets&lt;/strong&gt;: Vault can generate secrets on-demand for some systems, such as AWS or SQL databases. For example, when an application needs to access an S3 bucket, it asks Vault for credentials, and Vault will generate an AWS keypair with valid permissions on demand. After creating these dynamic secrets, Vault will also automatically revoke them after the lease is up.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Data Encryption&lt;/strong&gt;: Vault can encrypt and decrypt data without storing it. This allows security teams to define encryption parameters and developers to store encrypted data in a location such as a SQL database without having to design their own encryption methods.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Leasing and Renewal&lt;/strong&gt;: Vault associates a &lt;strong&gt;lease&lt;/strong&gt; with each secret. At the end of the lease, Vault automatically revokes the secret. Clients are able to renew leases via built-in renew APIs.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Revocation&lt;/strong&gt;: Vault has built-in support for secret revocation. Vault can revoke not only single secrets, but a tree of secrets, for example, all secrets read by a specific user, or all secrets of a particular type. Revocation assists in key rolling as well as locking down systems in the case of an intrusion.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation, Getting Started, and Certification Exams&lt;/h2&gt; 
&lt;p&gt;Documentation is available on the &lt;a href="https://developer.hashicorp.com/vault/docs"&gt;Vault website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;If you're new to Vault and want to get started with security automation, please check out our &lt;a href="https://learn.hashicorp.com/collections/vault/getting-started"&gt;Getting Started guides&lt;/a&gt; on HashiCorp's learning platform. There are also &lt;a href="https://learn.hashicorp.com/vault"&gt;additional guides&lt;/a&gt; to continue your learning.&lt;/p&gt; 
&lt;p&gt;For examples of how to interact with Vault from inside your application in different programming languages, see the &lt;a href="https://github.com/hashicorp/vault-examples"&gt;vault-examples&lt;/a&gt; repo. An out-of-the-box &lt;a href="https://github.com/hashicorp/hello-vault-go"&gt;sample application&lt;/a&gt; is also available.&lt;/p&gt; 
&lt;p&gt;Show off your Vault knowledge by passing a certification exam. Visit the &lt;a href="https://www.hashicorp.com/certification/#hashicorp-certified-vault-associate"&gt;certification page&lt;/a&gt; for information about exams and find &lt;a href="https://learn.hashicorp.com/collections/vault/certification"&gt;study materials&lt;/a&gt; on HashiCorp's learning platform.&lt;/p&gt; 
&lt;h2&gt;Developing Vault&lt;/h2&gt; 
&lt;p&gt;If you wish to work on Vault itself or any of its built-in systems, you'll first need &lt;a href="https://www.golang.org"&gt;Go&lt;/a&gt; installed on your machine.&lt;/p&gt; 
&lt;p&gt;For local dev first make sure Go is properly installed, including setting up a &lt;a href="https://golang.org/doc/code.html#GOPATH"&gt;GOPATH&lt;/a&gt;, then setting the &lt;a href="https://pkg.go.dev/cmd/go#hdr-Environment_variables"&gt;GOBIN&lt;/a&gt; variable to &lt;code&gt;$GOPATH/bin&lt;/code&gt;. Ensure that &lt;code&gt;$GOPATH/bin&lt;/code&gt; is in your path as some distributions bundle the old version of build tools.&lt;/p&gt; 
&lt;p&gt;Next, clone this repository. Vault uses &lt;a href="https://github.com/golang/go/wiki/Modules"&gt;Go Modules&lt;/a&gt;, so it is recommended that you clone the repository &lt;em&gt;&lt;strong&gt;outside&lt;/strong&gt;&lt;/em&gt; of the GOPATH. You can then download any required build tools by bootstrapping your environment:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make bootstrap
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault, run &lt;code&gt;make&lt;/code&gt; or &lt;code&gt;make dev&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make dev
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To compile a development version of Vault with the UI, run &lt;code&gt;make static-dist dev-ui&lt;/code&gt;. This will put the Vault binary in the &lt;code&gt;bin&lt;/code&gt; and &lt;code&gt;$GOPATH/bin&lt;/code&gt; folders:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make static-dist dev-ui
...
$ bin/vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run tests, type &lt;code&gt;make test&lt;/code&gt;. Note: this requires Docker to be installed. If this exits with exit status 0, then everything is working!&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you're developing a specific package, you can run tests for just that package by specifying the &lt;code&gt;TEST&lt;/code&gt; variable. For example below, only &lt;code&gt;vault&lt;/code&gt; package tests will be run.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make test TEST=./vault
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;p&gt;If you encounter an error like &lt;code&gt;could not read Username for 'https://github.com'&lt;/code&gt; you may need to adjust your git config like so:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ git config --global --add url."git@github.com:".insteadOf "https://github.com/"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Importing Vault&lt;/h3&gt; 
&lt;p&gt;This repository publishes two libraries that may be imported by other projects: &lt;code&gt;github.com/hashicorp/vault/api&lt;/code&gt; and &lt;code&gt;github.com/hashicorp/vault/sdk&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Note that this repository also contains Vault (the product), and as with most Go projects, Vault uses Go modules to manage its dependencies. The mechanism to do that is the &lt;a href="https://raw.githubusercontent.com/hashicorp/vault/main/go.mod"&gt;go.mod&lt;/a&gt; file. As it happens, the presence of that file also makes it theoretically possible to import Vault as a dependency into other projects. Some other projects have made a practice of doing so in order to take advantage of testing tooling that was developed for testing Vault itself. This is not, and has never been, a supported way to use the Vault project. We aren't likely to fix bugs relating to failure to import &lt;code&gt;github.com/hashicorp/vault&lt;/code&gt; into your project.&lt;/p&gt; 
&lt;p&gt;See also the section "Docker-based tests" below.&lt;/p&gt; 
&lt;h3&gt;Acceptance Tests&lt;/h3&gt; 
&lt;p&gt;Vault has comprehensive &lt;a href="https://en.wikipedia.org/wiki/Acceptance_testing"&gt;acceptance tests&lt;/a&gt; covering most of the features of the secret and auth methods.&lt;/p&gt; 
&lt;p&gt;If you're working on a feature of a secret or auth method and want to verify it is functioning (and also hasn't broken anything else), we recommend running the acceptance tests.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Warning:&lt;/strong&gt; The acceptance tests create/destroy/modify &lt;em&gt;real resources&lt;/em&gt;, which may incur real costs in some cases. In the presence of a bug, it is technically possible that broken backends could leave dangling data behind. Therefore, please run the acceptance tests at your own risk. At the very least, we recommend running them in their own private account for whatever backend you're testing.&lt;/p&gt; 
&lt;p&gt;To run the acceptance tests, invoke &lt;code&gt;make testacc&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;$ make testacc TEST=./builtin/logical/consul
...
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The &lt;code&gt;TEST&lt;/code&gt; variable is required, and you should specify the folder where the backend is. The &lt;code&gt;TESTARGS&lt;/code&gt; variable is recommended to filter down to a specific resource to test, since testing all of them at once can sometimes take a very long time.&lt;/p&gt; 
&lt;p&gt;Acceptance tests typically require other environment variables to be set for things such as access keys. The test itself should error early and tell you what to set, so it is not documented here.&lt;/p&gt; 
&lt;p&gt;For more information on Vault Enterprise features, visit the &lt;a href="https://www.hashicorp.com/products/vault/?utm_source=github&amp;amp;utm_medium=referral&amp;amp;utm_campaign=github-vault-enterprise"&gt;Vault Enterprise site&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker-based Tests&lt;/h3&gt; 
&lt;p&gt;We have created an experimental new testing mechanism inspired by NewTestCluster. An example of how to use it:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  "testing"
  "github.com/hashicorp/vault/sdk/helper/testcluster/docker"
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: "hashicorp/vault", // or "hashicorp/vault-enterprise"
    ImageTag:    "latest",
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
  
  client := cluster.Nodes()[0].APIClient()
  _, err := client.Logical().Read("sys/storage/raft/configuration")
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or for Enterprise:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import (
  "testing"
  "github.com/hashicorp/vault/sdk/helper/testcluster/docker"
)

func Test_Something_With_Docker(t *testing.T) {
  opts := &amp;amp;docker.DockerClusterOptions{
    ImageRepo: "hashicorp/vault-enterprise",
    ImageTag:  "latest",
	VaultLicense: licenseString, // not a path, the actual license bytes
  }
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Here is a more realistic example of how we use it in practice. DefaultOptions uses &lt;code&gt;hashicorp/vault&lt;/code&gt;:&lt;code&gt;latest&lt;/code&gt; as the repo and tag, but it also looks at the environment variable VAULT_BINARY. If populated, it will copy the local file referenced by VAULT_BINARY into the container. This is useful when testing local changes.&lt;/p&gt; 
&lt;p&gt;Instead of setting the VaultLicense option, you can set the VAULT_LICENSE_CI environment variable, which is better than committing a license to version control.&lt;/p&gt; 
&lt;p&gt;Optionally you can set COMMIT_SHA, which will be appended to the image name we build as a debugging convenience.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func Test_Custom_Build_With_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  cluster := docker.NewTestDockerCluster(t, opts)
  defer cluster.Cleanup()
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are a variety of helpers in the &lt;code&gt;github.com/hashicorp/vault/sdk/helper/testcluster&lt;/code&gt; package, e.g. these tests below will create a pair of 3-node clusters and link them using PR or DR replication respectively, and fail if the replication state doesn't become healthy before the passed context expires.&lt;/p&gt; 
&lt;p&gt;Again, as written, these depend on having a Vault Enterprise binary locally and the env var VAULT_BINARY set to point to it, as well as having VAULT_LICENSE_CI set.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;func TestStandardPerfReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
      t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardPerfReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}

func TestStandardDRReplication_Docker(t *testing.T) {
  opts := docker.DefaultOptions(t)
  r, err := docker.NewReplicationSetDocker(t, opts)
  if err != nil {
    t.Fatal(err)
  }
  defer r.Cleanup()

  ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
  defer cancel()
  err = r.StandardDRReplication(ctx)
  if err != nil {
    t.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Finally, here's an example of running an existing OSS docker test with a custom binary:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;$ GOOS=linux make dev
$ VAULT_BINARY=$(pwd)/bin/vault go test -run 'TestRaft_Configuration_Docker' ./vault/external_tests/raft/raft_binary
ok      github.com/hashicorp/vault/vault/external_tests/raft/raft_binary        20.960s
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>uber-go/zap</title>
      <link>https://github.com/uber-go/zap</link>
      <description>&lt;p&gt;Blazing fast, structured, leveled logging in Go.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/h1&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;Blazing fast, structured, leveled logging in Go.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/uber-go/zap/master/assets/logo.png" alt="Zap logo" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://pkg.go.dev/go.uber.org/zap"&gt;&lt;img src="https://pkg.go.dev/badge/go.uber.org/zap" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://github.com/uber-go/zap/actions/workflows/go.yml"&gt;&lt;img src="https://github.com/uber-go/zap/actions/workflows/go.yml/badge.svg?sanitize=true" alt="Build Status" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/uber-go/zap"&gt;&lt;img src="https://codecov.io/gh/uber-go/zap/branch/master/graph/badge.svg?sanitize=true" alt="Coverage Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;go get -u go.uber.org/zap&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Note that zap only supports the two most recent minor versions of Go.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;In contexts where performance is nice, but not critical, use the &lt;code&gt;SugaredLogger&lt;/code&gt;. It's 4-10x faster than other structured logging packages and includes both structured and &lt;code&gt;printf&lt;/code&gt;-style APIs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;logger, _ := zap.NewProduction()
defer logger.Sync() // flushes buffer, if any
sugar := logger.Sugar()
sugar.Infow("failed to fetch URL",
  // Structured context as loosely typed key-value pairs.
  "url", url,
  "attempt", 3,
  "backoff", time.Second,
)
sugar.Infof("Failed to fetch URL: %s", url)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;When performance and type safety are critical, use the &lt;code&gt;Logger&lt;/code&gt;. It's even faster than the &lt;code&gt;SugaredLogger&lt;/code&gt; and allocates far less, but it only supports structured logging.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;logger, _ := zap.NewProduction()
defer logger.Sync()
logger.Info("failed to fetch URL",
  // Structured context as strongly typed Field values.
  zap.String("url", url),
  zap.Int("attempt", 3),
  zap.Duration("backoff", time.Second),
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See the &lt;a href="https://pkg.go.dev/go.uber.org/zap"&gt;documentation&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/FAQ.md"&gt;FAQ&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Performance&lt;/h2&gt; 
&lt;p&gt;For applications that log in the hot path, reflection-based serialization and string formatting are prohibitively expensive ‚Äî they're CPU-intensive and make many small allocations. Put differently, using &lt;code&gt;encoding/json&lt;/code&gt; and &lt;code&gt;fmt.Fprintf&lt;/code&gt; to log tons of &lt;code&gt;interface{}&lt;/code&gt;s makes your application slow.&lt;/p&gt; 
&lt;p&gt;Zap takes a different approach. It includes a reflection-free, zero-allocation JSON encoder, and the base &lt;code&gt;Logger&lt;/code&gt; strives to avoid serialization overhead and allocations wherever possible. By building the high-level &lt;code&gt;SugaredLogger&lt;/code&gt; on that foundation, zap lets users &lt;em&gt;choose&lt;/em&gt; when they need to count every allocation and when they'd prefer a more familiar, loosely typed API.&lt;/p&gt; 
&lt;p&gt;As measured by its own &lt;a href="https://github.com/uber-go/zap/tree/master/benchmarks"&gt;benchmarking suite&lt;/a&gt;, not only is zap more performant than comparable structured logging packages ‚Äî it's also faster than the standard library. Like all benchmarks, take these with a grain of salt.&lt;sup id="anchor-versions"&gt;&lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/#footnote-versions"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt; 
&lt;p&gt;Log a message and 10 fields:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Package&lt;/th&gt; 
   &lt;th align="center"&gt;Time&lt;/th&gt; 
   &lt;th align="center"&gt;Time % to zap&lt;/th&gt; 
   &lt;th align="center"&gt;Objects Allocated&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/td&gt; 
   &lt;td align="center"&gt;656 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+0%&lt;/td&gt; 
   &lt;td align="center"&gt;5 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap (sugared)&lt;/td&gt; 
   &lt;td align="center"&gt;935 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+43%&lt;/td&gt; 
   &lt;td align="center"&gt;10 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;zerolog&lt;/td&gt; 
   &lt;td align="center"&gt;380 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;-42%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;go-kit&lt;/td&gt; 
   &lt;td align="center"&gt;2249 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+243%&lt;/td&gt; 
   &lt;td align="center"&gt;57 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog (LogAttrs)&lt;/td&gt; 
   &lt;td align="center"&gt;2479 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+278%&lt;/td&gt; 
   &lt;td align="center"&gt;40 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog&lt;/td&gt; 
   &lt;td align="center"&gt;2481 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+278%&lt;/td&gt; 
   &lt;td align="center"&gt;42 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;apex/log&lt;/td&gt; 
   &lt;td align="center"&gt;9591 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1362%&lt;/td&gt; 
   &lt;td align="center"&gt;63 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;log15&lt;/td&gt; 
   &lt;td align="center"&gt;11393 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1637%&lt;/td&gt; 
   &lt;td align="center"&gt;75 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;logrus&lt;/td&gt; 
   &lt;td align="center"&gt;11654 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1677%&lt;/td&gt; 
   &lt;td align="center"&gt;79 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Log a message with a logger that already has 10 fields of context:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Package&lt;/th&gt; 
   &lt;th align="center"&gt;Time&lt;/th&gt; 
   &lt;th align="center"&gt;Time % to zap&lt;/th&gt; 
   &lt;th align="center"&gt;Objects Allocated&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/td&gt; 
   &lt;td align="center"&gt;67 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+0%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap (sugared)&lt;/td&gt; 
   &lt;td align="center"&gt;84 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+25%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;zerolog&lt;/td&gt; 
   &lt;td align="center"&gt;35 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;-48%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog&lt;/td&gt; 
   &lt;td align="center"&gt;193 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+188%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog (LogAttrs)&lt;/td&gt; 
   &lt;td align="center"&gt;200 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+199%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;go-kit&lt;/td&gt; 
   &lt;td align="center"&gt;2460 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+3572%&lt;/td&gt; 
   &lt;td align="center"&gt;56 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;log15&lt;/td&gt; 
   &lt;td align="center"&gt;9038 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+13390%&lt;/td&gt; 
   &lt;td align="center"&gt;70 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;apex/log&lt;/td&gt; 
   &lt;td align="center"&gt;9068 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+13434%&lt;/td&gt; 
   &lt;td align="center"&gt;53 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;logrus&lt;/td&gt; 
   &lt;td align="center"&gt;10521 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+15603%&lt;/td&gt; 
   &lt;td align="center"&gt;68 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Log a static string, without any context or &lt;code&gt;printf&lt;/code&gt;-style templating:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Package&lt;/th&gt; 
   &lt;th align="center"&gt;Time&lt;/th&gt; 
   &lt;th align="center"&gt;Time % to zap&lt;/th&gt; 
   &lt;th align="center"&gt;Objects Allocated&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap&lt;/td&gt; 
   &lt;td align="center"&gt;63 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+0%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;span&gt;‚ö°&lt;/span&gt; zap (sugared)&lt;/td&gt; 
   &lt;td align="center"&gt;81 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+29%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;zerolog&lt;/td&gt; 
   &lt;td align="center"&gt;32 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;-49%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;standard library&lt;/td&gt; 
   &lt;td align="center"&gt;124 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+97%&lt;/td&gt; 
   &lt;td align="center"&gt;1 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog&lt;/td&gt; 
   &lt;td align="center"&gt;196 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+211%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;slog (LogAttrs)&lt;/td&gt; 
   &lt;td align="center"&gt;200 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+217%&lt;/td&gt; 
   &lt;td align="center"&gt;0 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;go-kit&lt;/td&gt; 
   &lt;td align="center"&gt;213 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+238%&lt;/td&gt; 
   &lt;td align="center"&gt;9 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;apex/log&lt;/td&gt; 
   &lt;td align="center"&gt;771 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+1124%&lt;/td&gt; 
   &lt;td align="center"&gt;5 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;logrus&lt;/td&gt; 
   &lt;td align="center"&gt;1439 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+2184%&lt;/td&gt; 
   &lt;td align="center"&gt;23 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;log15&lt;/td&gt; 
   &lt;td align="center"&gt;2069 ns/op&lt;/td&gt; 
   &lt;td align="center"&gt;+3184%&lt;/td&gt; 
   &lt;td align="center"&gt;20 allocs/op&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Development Status: Stable&lt;/h2&gt; 
&lt;p&gt;All APIs are finalized, and no breaking changes will be made in the 1.x series of releases. Users of semver-aware dependency management systems should pin zap to &lt;code&gt;^1&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We encourage and support an active, healthy community of contributors ‚Äî including you! Details are in the &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/CONTRIBUTING.md"&gt;contribution guide&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/CODE_OF_CONDUCT.md"&gt;code of conduct&lt;/a&gt;. The zap maintainers keep an eye on issues and pull requests, but you can also report any negative conduct to &lt;a href="mailto:oss-conduct@uber.com"&gt;oss-conduct@uber.com&lt;/a&gt;. That email list is a private, safe space; even the zap maintainers don't have access, so don't hesitate to hold us to a high standard.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Released under the &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/LICENSE"&gt;MIT License&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;sup id="footnote-versions"&gt;1&lt;/sup&gt; In particular, keep in mind that we may be benchmarking against slightly older versions of other packages. Versions are pinned in the &lt;a href="https://github.com/uber-go/zap/raw/master/benchmarks/go.mod"&gt;benchmarks/go.mod&lt;/a&gt; file. &lt;a href="https://raw.githubusercontent.com/uber-go/zap/master/#anchor-versions"&gt;‚Ü©&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>