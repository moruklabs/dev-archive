<rss version="2.0">
  <channel>
    <title>GitHub All Languages Weekly Trending</title>
    <description>Weekly Trending of All Languages in GitHub</description>
    <pubDate>Sun, 21 Sep 2025 01:40:59 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>nocodb/nocodb</title>
      <link>https://github.com/nocodb/nocodb</link>
      <description>&lt;p&gt;ğŸ”¥ ğŸ”¥ ğŸ”¥ Open Source Airtable Alternative&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center" style="border-bottom: none"&gt; 
 &lt;div&gt; 
  &lt;a style="color:#36f" href="https://www.nocodb.com"&gt; &lt;img src="https://raw.githubusercontent.com/nocodb/nocodb/develop/packages/nc-gui/assets/img/brand/nocodb-full.png" height="80" /&gt; &lt;br /&gt; The Open Source Airtable Alternative &lt;/a&gt; 
  &lt;br /&gt; 
 &lt;/div&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; NocoDB is the fastest and easiest way to build databases online. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="http://www.nocodb.com"&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; â€¢ &lt;a href="https://discord.gg/5RgZmkW"&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;/a&gt; â€¢ &lt;a href="https://community.nocodb.com/"&gt;&lt;b&gt;Community&lt;/b&gt;&lt;/a&gt; â€¢ &lt;a href="https://twitter.com/nocodb"&gt;&lt;b&gt;Twitter&lt;/b&gt;&lt;/a&gt; â€¢ &lt;a href="https://www.reddit.com/r/NocoDB/"&gt;&lt;b&gt;Reddit&lt;/b&gt;&lt;/a&gt; â€¢ &lt;a href="https://docs.nocodb.com/"&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;&lt;img src="https://github.com/nocodb/nocodb/assets/86527202/e2fad786-f211-4dcb-9bd3-aaece83a6783" alt="video avi" /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/chinese.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263434-75fe793d-42af-49e4-b964-d70920e41655.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/french.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263474-787d71e7-3a87-42a8-92a8-be1d1f55413d.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/german.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263531-fae58600-6616-4b43-95a0-5891019dd35d.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/spanish.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263589-3dbeda9a-0d2e-4bbd-b1fc-691404bb74fb.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/portuguese.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263669-f567196a-d4e8-4143-a80a-93d3be32ba90.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/italian.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263707-ba4e04a4-268a-4626-91b8-048e572fd9f6.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/japanese.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263770-38e3e79d-11d4-472e-ac27-ae0f17cf65c4.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/korean.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263822-28fce9de-915a-44dc-962d-7a61d340e91d.png" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/russian.md"&gt;&lt;img height="38" src="https://user-images.githubusercontent.com/61551451/135263888-151d4ad1-7084-4943-97c9-56f28cd40b80.png" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt;&lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/markdown/readme/languages/README.md"&gt;&lt;b&gt;See other languages Â»&lt;/b&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;img src="https://static.scarf.sh/a.png?x-pxid=c12a77cc-855e-4602-8a0f-614b2d0da56a" /&gt; 
&lt;h1&gt;Join Our Community&lt;/h1&gt; 
&lt;a href="https://discord.gg/5RgZmkW" target="_blank"&gt; &lt;img src="https://discordapp.com/api/guilds/661905455894888490/widget.png?style=banner3" alt="" /&gt; &lt;/a&gt; 
&lt;p&gt;&lt;a href="https://github.com/nocodb/nocodb/stargazers"&gt;&lt;img src="http://reporoster.com/stars/nocodb/nocodb" alt="Stargazers repo roster for @nocodb/nocodb" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Installation&lt;/h1&gt; 
&lt;h2&gt;Docker with SQLite&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name noco \
  -v "$(pwd)"/nocodb:/usr/app/data/ \
  -p 8080:8080 \
  nocodb/nocodb:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Docker with PG&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name noco \
  -v "$(pwd)"/nocodb:/usr/app/data/ \
  -p 8080:8080 \
  -e NC_DB="pg://host.docker.internal:5432?u=root&amp;amp;p=password&amp;amp;d=d1" \
  -e NC_AUTH_JWT_SECRET="569a1821-0a93-45e8-87ab-eb857f20a010" \
  nocodb/nocodb:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Auto-upstall&lt;/h2&gt; 
&lt;p&gt;Auto-upstall is a single command that sets up NocoDB on a server for production usage. Behind the scenes it auto-generates docker-compose for you.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash &amp;lt;(curl -sSL http://install.nocodb.com/noco.sh) &amp;lt;(mktemp)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Auto-upstall does the following: ğŸ•Š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ³ Automatically installs all pre-requisites like docker, docker-compose&lt;/li&gt; 
 &lt;li&gt;ğŸš€ Automatically installs NocoDB with PostgreSQL, Redis, Minio, Traefik gateway using Docker Compose. ğŸ˜ ğŸ—„ï¸ ğŸŒ&lt;/li&gt; 
 &lt;li&gt;ğŸ”„ Automatically upgrades NocoDB to the latest version when you run the command again.&lt;/li&gt; 
 &lt;li&gt;ğŸ”’ Automatically setups SSL and also renews it. Needs a domain or subdomain as input while installation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;install.nocodb.com/noco.sh script can be found &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/docker-compose/1_Auto_Upstall/noco.sh"&gt;here in our github&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Other Methods&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Binaries are only for quick testing locally.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Install Method&lt;/th&gt; 
   &lt;th&gt;Command to install&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ MacOS arm64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/macos-arm64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ MacOS x64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/macos-x64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ§ Linux arm64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/linux-arm64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸ§ Linux x64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;curl http://get.nocodb.com/linux-x64 -o nocodb -L &amp;amp;&amp;amp; chmod +x nocodb &amp;amp;&amp;amp; ./nocodb&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸªŸ Windows arm64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;iwr http://get.nocodb.com/win-arm64.exe -OutFile Noco-win-arm64.exe &amp;amp;&amp;amp; .\Noco-win-arm64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ğŸªŸ Windows x64 &lt;br /&gt;(Binary)&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;iwr http://get.nocodb.com/win-x64.exe -OutFile Noco-win-x64.exe &amp;amp;&amp;amp; .\Noco-win-x64.exe&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;When running locally access nocodb by visiting: &lt;a href="http://localhost:8080/dashboard"&gt;http://localhost:8080/dashboard&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more installation methods, please refer to &lt;a href="https://docs.nocodb.com/category/installation"&gt;our docs&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Screenshots&lt;/h1&gt; 
&lt;p&gt;&lt;img src="https://github.com/nocodb/nocodb/assets/86527202/a127c05e-2121-4af2-a342-128e0e2d0291" alt="2" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/674da952-8a06-4848-a0e8-a7b02d5f5c88" alt="3" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/cbc5152a-9caf-4f77-a8f7-92a9d06d025b" alt="4" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/dc75dfdc-c486-4f5a-a853-2a8f9e6b569a" alt="5" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/35857179/194844886-a17006e0-979d-493f-83c4-0e72f5a9b716.png" alt="5" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/be64e619-7295-43e2-aa95-cace4462b17f" alt="7" /&gt; &lt;img src="https://github.com/nocodb/nocodb/assets/86527202/4538bf5a-371f-4ec1-a867-8197e5824286" alt="8" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://user-images.githubusercontent.com/35857179/194844893-82d5e21b-ae61-41bd-9990-31ad659bf490.png" alt="8" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844897-cfd79946-e413-4c97-b16d-eb4d7678bb79.png" alt="9" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844902-c0122570-0dd5-41cf-a26f-6f8d71fefc99.png" alt="10" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844903-c1e47f40-e782-4f5d-8dce-6449cc70b181.png" alt="11" /&gt; &lt;img src="https://user-images.githubusercontent.com/35857179/194844907-09277d3e-cbbf-465c-9165-6afc4161e279.png" alt="12" /&gt;&lt;/p&gt; 
&lt;h1&gt;Features&lt;/h1&gt; 
&lt;h3&gt;Rich Spreadsheet Interface&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;Basic Operations: Create, Read, Update and Delete Tables, Columns, and Rows&lt;/li&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;Fields Operations: Sort, Filter, Group, Hide / Unhide Columns&lt;/li&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;Multiple Views Types: Grid (By default), Gallery, Form, Kanban and Calendar View&lt;/li&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;View Permissions Types: Collaborative Views, &amp;amp; Locked Views&lt;/li&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;Share Bases / Views: either Public or Private (with Password Protected)&lt;/li&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;Variant Cell Types: ID, Links, Lookup, Rollup, SingleLineText, Attachment, Currency, Formula, User, etc&lt;/li&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;Access Control with Roles: Fine-grained Access Control at different levels&lt;/li&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;and more ...&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;App Store for Workflow Automations&lt;/h3&gt; 
&lt;p&gt;We provide different integrations in three main categories. See &lt;a href="https://docs.nocodb.com/account-settings/oss-specific-details/#app-store" target="_blank"&gt;App Store&lt;/a&gt; for details.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;Chat: Slack, Discord, Mattermost, and etc&lt;/li&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;Email: AWS SES, SMTP, MailerSend, and etc&lt;/li&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;Storage: AWS S3, Google Cloud Storage, Minio, and etc&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Programmatic Access&lt;/h3&gt; 
&lt;p&gt;We provide the following ways to let users programmatically invoke actions. You can use a token (either JWT or Social Auth) to sign your requests for authorization to NocoDB.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;REST APIs&lt;/li&gt; 
 &lt;li&gt;âš¡ &amp;nbsp;NocoDB SDK&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Contributing&lt;/h1&gt; 
&lt;p&gt;Please refer to &lt;a href="https://github.com/nocodb/nocodb/raw/master/.github/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Why are we building this?&lt;/h1&gt; 
&lt;p&gt;Most internet businesses equip themselves with either spreadsheet or a database to solve their business needs. Spreadsheets are used by Billion+ humans collaboratively every single day. However, we are way off working at similar speeds on databases which are way more powerful tools when it comes to computing. Attempts to solve this with SaaS offerings have meant horrible access controls, vendor lock-in, data lock-in, abrupt price changes &amp;amp; most importantly a glass ceiling on what's possible in the future.&lt;/p&gt; 
&lt;h1&gt;Our Mission&lt;/h1&gt; 
&lt;p&gt;Our mission is to provide the most powerful no-code interface for databases that is open source to every single internet business in the world. This would not only democratise access to a powerful computing tool but also bring forth a billion+ people who will have radical tinkering-and-building abilities on the internet.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt; This project is licensed under &lt;a href="https://raw.githubusercontent.com/nocodb/nocodb/develop/LICENSE"&gt;AGPLv3&lt;/a&gt;. &lt;/p&gt; 
&lt;h1&gt;Contributors&lt;/h1&gt; 
&lt;p&gt;Thank you for your contributions! We appreciate all the contributions from the community.&lt;/p&gt; 
&lt;a href="https://github.com/nocodb/nocodb/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=nocodb/nocodb" /&gt; &lt;/a&gt;</description>
    </item>
    
    <item>
      <title>CorentinJ/Real-Time-Voice-Cloning</title>
      <link>https://github.com/CorentinJ/Real-Time-Voice-Cloning</link>
      <description>&lt;p&gt;Clone a voice in 5 seconds to generate arbitrary speech in real-time&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Real-Time Voice Cloning&lt;/h1&gt; 
&lt;p&gt;This repository is an implementation of &lt;a href="https://arxiv.org/pdf/1806.04558.pdf"&gt;Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis&lt;/a&gt; (SV2TTS) with a vocoder that works in real-time. This was my &lt;a href="https://matheo.uliege.be/handle/2268.2/6801"&gt;master's thesis&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;SV2TTS is a deep learning framework in three stages. In the first stage, one creates a digital representation of a voice from a few seconds of audio. In the second and third stages, this representation is used as reference to generate speech given arbitrary text.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Video demonstration&lt;/strong&gt; (click the picture):&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=-O_hYhToKoA"&gt;&lt;img src="https://i.imgur.com/8lFUlgz.png" alt="Toolbox demo" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Papers implemented&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;URL&lt;/th&gt; 
   &lt;th&gt;Designation&lt;/th&gt; 
   &lt;th&gt;Title&lt;/th&gt; 
   &lt;th&gt;Implementation source&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/1806.04558.pdf"&gt;&lt;strong&gt;1806.04558&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;SV2TTS&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;This repo&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/1802.08435.pdf"&gt;1802.08435&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;WaveRNN (vocoder)&lt;/td&gt; 
   &lt;td&gt;Efficient Neural Audio Synthesis&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/fatchord/WaveRNN"&gt;fatchord/WaveRNN&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/1703.10135.pdf"&gt;1703.10135&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Tacotron (synthesizer)&lt;/td&gt; 
   &lt;td&gt;Tacotron: Towards End-to-End Speech Synthesis&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/fatchord/WaveRNN"&gt;fatchord/WaveRNN&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://arxiv.org/pdf/1710.10467.pdf"&gt;1710.10467&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;GE2E (encoder)&lt;/td&gt; 
   &lt;td&gt;Generalized End-To-End Loss for Speaker Verification&lt;/td&gt; 
   &lt;td&gt;This repo&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Heads up&lt;/h2&gt; 
&lt;p&gt;Like everything else in Deep Learning, this repo has quickly gotten old. Many SaaS apps (often paying) will give you a better audio quality than this repository will. If you wish for an open-source solution with a high voice quality:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Check out &lt;a href="https://paperswithcode.com/task/speech-synthesis/"&gt;paperswithcode&lt;/a&gt; for other repositories and recent research in the field of speech synthesis.&lt;/li&gt; 
 &lt;li&gt;Check out &lt;a href="https://github.com/resemble-ai/chatterbox"&gt;Chatterbox&lt;/a&gt; for a similar project up to date with the 2025 SOTA in voice cloning&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Setup&lt;/h2&gt; 
&lt;h3&gt;1. Install Requirements&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Both Windows and Linux are supported. A GPU is recommended for training and for inference speed, but is not mandatory.&lt;/li&gt; 
 &lt;li&gt;Python 3.7 is recommended. Python 3.5 or greater should work, but you'll probably have to tweak the dependencies' versions. I recommend setting up a virtual environment using &lt;code&gt;venv&lt;/code&gt;, but this is optional.&lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://ffmpeg.org/download.html#get-packages"&gt;ffmpeg&lt;/a&gt;. This is necessary for reading audio files.&lt;/li&gt; 
 &lt;li&gt;Install &lt;a href="https://pytorch.org/get-started/locally/"&gt;PyTorch&lt;/a&gt;. Pick the latest stable version, your operating system, your package manager (pip by default) and finally pick any of the proposed CUDA versions if you have a GPU, otherwise pick CPU. Run the given command.&lt;/li&gt; 
 &lt;li&gt;Install the remaining requirements with &lt;code&gt;pip install -r requirements.txt&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;2. (Optional) Download Pretrained Models&lt;/h3&gt; 
&lt;p&gt;Pretrained models are now downloaded automatically. If this doesn't work for you, you can manually download them &lt;a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning/wiki/Pretrained-models"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;3. (Optional) Test Configuration&lt;/h3&gt; 
&lt;p&gt;Before you download any dataset, you can begin by testing your configuration with:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python demo_cli.py&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;If all tests pass, you're good to go.&lt;/p&gt; 
&lt;h3&gt;4. (Optional) Download Datasets&lt;/h3&gt; 
&lt;p&gt;For playing with the toolbox alone, I only recommend downloading &lt;a href="https://www.openslr.org/resources/12/train-clean-100.tar.gz"&gt;&lt;code&gt;LibriSpeech/train-clean-100&lt;/code&gt;&lt;/a&gt;. Extract the contents as &lt;code&gt;&amp;lt;datasets_root&amp;gt;/LibriSpeech/train-clean-100&lt;/code&gt; where &lt;code&gt;&amp;lt;datasets_root&amp;gt;&lt;/code&gt; is a directory of your choosing. Other datasets are supported in the toolbox, see &lt;a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning/wiki/Training#datasets"&gt;here&lt;/a&gt;. You're free not to download any dataset, but then you will need your own data as audio files or you will have to record it with the toolbox.&lt;/p&gt; 
&lt;h3&gt;5. Launch the Toolbox&lt;/h3&gt; 
&lt;p&gt;You can then try the toolbox:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;python demo_toolbox.py -d &amp;lt;datasets_root&amp;gt;&lt;/code&gt;&lt;br /&gt; or&lt;br /&gt; &lt;code&gt;python demo_toolbox.py&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;depending on whether you downloaded any datasets. If you are running an X-server or if you have the error &lt;code&gt;Aborted (core dumped)&lt;/code&gt;, see &lt;a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning/issues/11#issuecomment-504733590"&gt;this issue&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>dataease/SQLBot</title>
      <link>https://github.com/dataease/SQLBot</link>
      <description>&lt;p&gt;ğŸ”¥ åŸºäºå¤§æ¨¡å‹å’Œ RAG çš„æ™ºèƒ½é—®æ•°ç³»ç»Ÿã€‚Text-to-SQL Generation via LLMs using RAG.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt;&lt;img src="https://resource-fit2cloud-com.oss-cn-hangzhou.aliyuncs.com/sqlbot/sqlbot.png" alt="SQLBot" width="300" /&gt;&lt;/p&gt; 
&lt;h3 align="center"&gt;åŸºäºå¤§æ¨¡å‹å’Œ RAG çš„æ™ºèƒ½é—®æ•°ç³»ç»Ÿ&lt;/h3&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/dataease/SQLBot/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/dataease/SQLBot" alt="Latest release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/dataease/SQLBot"&gt;&lt;img src="https://img.shields.io/github/stars/dataease/SQLBot?color=%231890FF&amp;amp;style=flat-square" alt="Stars" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/dataease/SQLbot"&gt;&lt;img src="https://img.shields.io/docker/pulls/dataease/sqlbot?label=downloads" alt="Download" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;SQLBot æ˜¯ä¸€æ¬¾åŸºäºå¤§æ¨¡å‹å’Œ RAG çš„æ™ºèƒ½é—®æ•°ç³»ç»Ÿã€‚SQLBot çš„ä¼˜åŠ¿åŒ…æ‹¬ï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;å¼€ç®±å³ç”¨&lt;/strong&gt;: åªéœ€é…ç½®å¤§æ¨¡å‹å’Œæ•°æ®æºå³å¯å¼€å¯é—®æ•°ä¹‹æ—…ï¼Œé€šè¿‡å¤§æ¨¡å‹å’Œ RAG çš„ç»“åˆæ¥å®ç°é«˜è´¨é‡çš„ text2sqlï¼›&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;æ˜“äºé›†æˆ&lt;/strong&gt;: æ”¯æŒå¿«é€ŸåµŒå…¥åˆ°ç¬¬ä¸‰æ–¹ä¸šåŠ¡ç³»ç»Ÿï¼Œä¹Ÿæ”¯æŒè¢« n8nã€MaxKBã€Difyã€Coze ç­‰ AI åº”ç”¨å¼€å‘å¹³å°é›†æˆè°ƒç”¨ï¼Œè®©å„ç±»åº”ç”¨å¿«é€Ÿæ‹¥æœ‰æ™ºèƒ½é—®æ•°èƒ½åŠ›ï¼›&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;å®‰å…¨å¯æ§&lt;/strong&gt;: æä¾›åŸºäºå·¥ä½œç©ºé—´çš„èµ„æºéš”ç¦»æœºåˆ¶ï¼Œèƒ½å¤Ÿå®ç°ç»†ç²’åº¦çš„æ•°æ®æƒé™æ§åˆ¶ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;å·¥ä½œåŸç†&lt;/h2&gt; 
&lt;img width="1189" height="624" alt="system-arch" src="https://github.com/user-attachments/assets/cde40783-369e-493e-bb59-44ce43c2e7c5" /&gt; 
&lt;h2&gt;å¿«é€Ÿå¼€å§‹&lt;/h2&gt; 
&lt;h3&gt;å®‰è£…éƒ¨ç½²&lt;/h3&gt; 
&lt;p&gt;å‡†å¤‡ä¸€å° Linux æœåŠ¡å™¨ï¼Œå®‰è£…å¥½ &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker&lt;/a&gt;ï¼Œæ‰§è¡Œä»¥ä¸‹ä¸€é”®å®‰è£…è„šæœ¬ï¼š&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -d \
  --name sqlbot \
  --restart unless-stopped \
  -p 8000:8000 \
  -p 8001:8001 \
  -v ./data/sqlbot/excel:/opt/sqlbot/data/excel \
  -v ./data/sqlbot/images:/opt/sqlbot/images \
  -v ./data/sqlbot/logs:/opt/sqlbot/app/logs \
  -v ./data/postgresql:/var/lib/postgresql/data \
  --privileged=true \
  dataease/sqlbot
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;ä½ ä¹Ÿå¯ä»¥é€šè¿‡ &lt;a href="https://apps.fit2cloud.com/1panel"&gt;1Panel åº”ç”¨å•†åº—&lt;/a&gt; å¿«é€Ÿéƒ¨ç½² SQLBotã€‚&lt;/p&gt; 
&lt;p&gt;å¦‚æœæ˜¯å†…ç½‘ç¯å¢ƒï¼Œä½ å¯ä»¥é€šè¿‡ &lt;a href="https://community.fit2cloud.com/#/products/sqlbot/downloads"&gt;ç¦»çº¿å®‰è£…åŒ…æ–¹å¼&lt;/a&gt; éƒ¨ç½² SQLBotã€‚&lt;/p&gt; 
&lt;h3&gt;è®¿é—®æ–¹å¼&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: http://&amp;lt;ä½ çš„æœåŠ¡å™¨IP&amp;gt;:8000/&lt;/li&gt; 
 &lt;li&gt;ç”¨æˆ·å: admin&lt;/li&gt; 
 &lt;li&gt;å¯†ç : SQLBot@123456&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;è”ç³»æˆ‘ä»¬&lt;/h3&gt; 
&lt;p&gt;å¦‚ä½ æœ‰æ›´å¤šé—®é¢˜ï¼Œå¯ä»¥åŠ å…¥æˆ‘ä»¬çš„æŠ€æœ¯äº¤æµç¾¤ä¸æˆ‘ä»¬äº¤æµã€‚&lt;/p&gt; 
&lt;img width="180" height="180" alt="contact_me_qr" src="https://github.com/user-attachments/assets/2594ff29-5426-4457-b051-279855610030" /&gt; 
&lt;h2&gt;UI å±•ç¤º&lt;/h2&gt;  
&lt;img alt="q&amp;amp;a" src="https://github.com/user-attachments/assets/55526514-52f3-4cfe-98ec-08a986259280" /&gt;  
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#dataease/sqlbot&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=dataease/sqlbot&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;é£è‡´äº‘æ——ä¸‹çš„å…¶ä»–æ˜æ˜Ÿé¡¹ç›®&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/dataease/dataease/"&gt;DataEase&lt;/a&gt; - äººäººå¯ç”¨çš„å¼€æº BI å·¥å…·&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/1panel/"&gt;1Panel&lt;/a&gt; - ç°ä»£åŒ–ã€å¼€æºçš„ Linux æœåŠ¡å™¨è¿ç»´ç®¡ç†é¢æ¿&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1panel-dev/MaxKB/"&gt;MaxKB&lt;/a&gt; - å¼ºå¤§æ˜“ç”¨çš„ä¼ä¸šçº§æ™ºèƒ½ä½“å¹³å°&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/jumpserver/jumpserver/"&gt;JumpServer&lt;/a&gt; - å¹¿å—æ¬¢è¿çš„å¼€æºå ¡å’æœº&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/1Panel-dev/CordysCRM"&gt;Cordys CRM&lt;/a&gt; - æ–°ä¸€ä»£çš„å¼€æº AI CRM ç³»ç»Ÿ&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/halo-dev/halo/"&gt;Halo&lt;/a&gt; - å¼ºå¤§æ˜“ç”¨çš„å¼€æºå»ºç«™å·¥å…·&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/metersphere/metersphere/"&gt;MeterSphere&lt;/a&gt; - æ–°ä¸€ä»£çš„å¼€æºæŒç»­æµ‹è¯•å·¥å…·&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;æœ¬ä»“åº“éµå¾ª &lt;a href="https://raw.githubusercontent.com/dataease/SQLBot/main/LICENSE"&gt;FIT2CLOUD Open Source License&lt;/a&gt; å¼€æºåè®®ï¼Œè¯¥è®¸å¯è¯æœ¬è´¨ä¸Šæ˜¯ GPLv3ï¼Œä½†æœ‰ä¸€äº›é¢å¤–çš„é™åˆ¶ã€‚&lt;/p&gt; 
&lt;p&gt;ä½ å¯ä»¥åŸºäº SQLBot çš„æºä»£ç è¿›è¡ŒäºŒæ¬¡å¼€å‘ï¼Œä½†æ˜¯éœ€è¦éµå®ˆä»¥ä¸‹è§„å®šï¼š&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ä¸èƒ½æ›¿æ¢å’Œä¿®æ”¹ SQLBot çš„ Logo å’Œç‰ˆæƒä¿¡æ¯ï¼›&lt;/li&gt; 
 &lt;li&gt;äºŒæ¬¡å¼€å‘åçš„è¡ç”Ÿä½œå“å¿…é¡»éµå®ˆ GPL V3 çš„å¼€æºä¹‰åŠ¡ã€‚&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;å¦‚éœ€å•†ä¸šæˆæƒï¼Œè¯·è”ç³» &lt;a href="mailto:support@fit2cloud.com"&gt;support@fit2cloud.com&lt;/a&gt; ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>firebase/genkit</title>
      <link>https://github.com/firebase/genkit</link>
      <description>&lt;p&gt;Open-source framework for building AI-powered apps in JavaScript, Go, and Python, built and used in production by Google&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/firebase/genkit/main/docs/resources/genkit-logo-dark.png#gh-dark-mode-only" alt="Genkit logo" title="Genkit" /&gt; &lt;img src="https://raw.githubusercontent.com/firebase/genkit/main/docs/resources/genkit-logo.png#gh-light-mode-only" alt="Genkit logo" title="Genkit" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://genkit.dev"&gt;Genkit&lt;/a&gt; is an open-source framework for building full-stack AI-powered applications, built and used in production by Google's Firebase. It provides SDKs for multiple programming languages with varying levels of stability:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;JavaScript/TypeScript&lt;/strong&gt;: Production-ready with full feature support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Go&lt;/strong&gt;: Production-ready with full feature support&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Python (Alpha)&lt;/strong&gt;: Early development with core functionality&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;It offers a unified interface for integrating AI models from providers like &lt;a href="https://genkit.dev/docs/plugins/google-genai"&gt;Google&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/plugins/openai"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-anthropic"&gt;Anthropic&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/plugins/ollama/"&gt;Ollama&lt;/a&gt;, and more. Rapidly build and deploy production-ready chatbots, automations, and recommendation systems using streamlined APIs for multimodal content, structured outputs, tool calling, and agentic workflows.&lt;/p&gt; 
&lt;p&gt;Get started with just a few lines of code:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-ts"&gt;import { genkit } from 'genkit';
import { googleAI } from '@genkit-ai/google-genai';

const ai = genkit({ plugins: [googleAI()] });

const { text } = await ai.generate({
    model: googleAI.model('gemini-2.5-flash'),
    prompt: 'Why is Firebase awesome?'
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Explore &amp;amp; build with Genkit&lt;/h2&gt; 
&lt;p&gt;Play with AI sample apps, with visualizations of the Genkit code that powers them, at no cost to you.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://examples.genkit.dev"&gt;Explore Genkit by Example&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Key capabilities&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Broad AI model support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Use a unified interface to integrate with hundreds of models from providers like &lt;a href="https://genkit.dev/docs/plugins/google-genai"&gt;Google&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/plugins/openai"&gt; OpenAI&lt;/a&gt;, &lt;a href="https://thefireco.github.io/genkit-plugins/docs/plugins/genkitx-anthropic"&gt; Anthropic&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/plugins/ollama"&gt;Ollama&lt;/a&gt;, and more. Explore, compare, and use the best models for your needs.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Simplified AI development&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Use streamlined APIs to build AI features with &lt;a href="https://genkit.dev/docs/models#structured-output"&gt; structured output&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/tool-calling"&gt;agentic tool calling&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/rag"&gt;context-aware generation&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/models#multimodal"&gt;multi-modal input/output&lt;/a&gt;, and more. Genkit handles the complexity of AI development, so you can build and iterate faster.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Web and mobile ready&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Integrate seamlessly with frameworks and platforms including Next.js, React, Angular, iOS, Android, using purpose-built &lt;a href="https://genkit.dev/docs/firebase"&gt;client SDKs&lt;/a&gt; and helpers.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cross-language support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Build with the language that best fits your project. Genkit provides SDKs for JavaScript/TypeScript, Go, and Python (Alpha) with consistent APIs and capabilities across all supported languages.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Deploy anywhere&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Deploy AI logic to any environment that supports your chosen programming language, such as &lt;a href="https://genkit.dev/docs/firebase"&gt;Cloud Functions for Firebase&lt;/a&gt;, &lt;a href="https://genkit.dev/docs/cloud-run"&gt;Google Cloud Run&lt;/a&gt;, or &lt;a href="https://genkit.dev/docs/deploy-node"&gt;third-party platforms&lt;/a&gt;, with or without Google services.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Developer tools&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Accelerate AI development with a purpose-built, local &lt;a href="https://genkit.dev/docs/devtools"&gt;CLI and Developer UI&lt;/a&gt;. Test prompts and flows against individual inputs or datasets, compare outputs from different models, debug with detailed execution traces, and use immediate visual feedback to iterate rapidly on prompts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Production monitoring&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Ship AI features with confidence using comprehensive production monitoring. Track model performance, and request volumes, latency, and error rates in a &lt;a href="https://genkit.dev/docs/observability/getting-started"&gt; purpose-built dashboard&lt;/a&gt;. Identify issues quickly with detailed observability metrics, and ensure your AI features meet quality and performance targets in real-world usage.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;How does it work?&lt;/h2&gt; 
&lt;p&gt;Genkit simplifies AI integration with an open-source SDK and unified APIs that work across various model providers and programming languages. It abstracts away complexity so you can focus on delivering great user experiences.&lt;/p&gt; 
&lt;p&gt;Some key features offered by Genkit include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/models"&gt;Text and image generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/models#structured-output"&gt;Type-safe, structured data generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/tool-calling"&gt;Tool calling&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/dotprompt"&gt;Prompt templating&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/chat"&gt;Persisted chat interfaces&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/flows"&gt;AI workflows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/rag"&gt;AI-powered data retrieval (RAG)&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Genkit is designed for server-side deployment in multiple language environments, and also provides seamless client-side integration through dedicated helpers and &lt;a href="https://genkit.dev/docs/firebase"&gt;client SDKs&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Implementation path&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt;&lt;span&gt;1&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;Choose your language and model provider&lt;/td&gt; 
   &lt;td&gt;Select the Genkit SDK for your preferred language (JavaScript/TypeScript, Go, or Python (Alpha)). Choose a model provider like &lt;a href="https://genkit.dev/docs/plugins/google-genai"&gt;Google Gemini&lt;/a&gt; or Anthropic, and get an API key. Some providers, like &lt;a href="https://genkit.dev/docs/plugins/vertex-ai"&gt;Vertex AI&lt;/a&gt;, may rely on a different means of authentication.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;span&gt;2&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;Install the SDK and initialize&lt;/td&gt; 
   &lt;td&gt;Install the Genkit SDK, model-provider package of your choice, and the Genkit CLI. Import the Genkit and provider packages and initialize Genkit with the provider API key.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;span&gt;3&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;Write and test AI features&lt;/td&gt; 
   &lt;td&gt;Use the Genkit SDK to build AI features for your use case, from basic text generation to complex multi-step workflows and agents. Use the CLI and Developer UI to help you rapidly test and iterate.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;span&gt;4&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;Deploy and monitor&lt;/td&gt; 
   &lt;td&gt;Deploy your AI features to Firebase, Google Cloud Run, or any environment that supports your chosen programming language. Integrate them into your app, and monitor them in production in the Firebase console.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/docs/get-started"&gt;JavaScript/TypeScript quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/go/docs/get-started-go"&gt;Go quickstart&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://genkit.dev/python/docs/get-started/"&gt;Python quickstart&lt;/a&gt; (Alpha)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Development tools&lt;/h2&gt; 
&lt;p&gt;Genkit provides a CLI and a local UI to streamline your AI development workflow.&lt;/p&gt; 
&lt;h3&gt;CLI&lt;/h3&gt; 
&lt;p&gt;The Genkit CLI includes commands for running and evaluating your Genkit functions (flows) and collecting telemetry and logs.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Install:&lt;/strong&gt; &lt;code&gt;npm install -g genkit-cli&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Run a command, wrapped with telemetry, a interactive developer UI, etc:&lt;/strong&gt; &lt;code&gt;genkit start -- &amp;lt;command to run your code&amp;gt;&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Developer UI&lt;/h3&gt; 
&lt;p&gt;The Genkit developer UI is a local interface for testing, debugging, and iterating on your AI application.&lt;/p&gt; 
&lt;p&gt;Key features:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Run:&lt;/strong&gt; Execute and experiment with Genkit flows, prompts, queries, and more in dedicated playgrounds.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Inspect:&lt;/strong&gt; Analyze detailed traces of past executions, including step-by-step breakdowns of complex flows.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evaluate:&lt;/strong&gt; Review the results of evaluations run against your flows, including performance metrics and links to relevant traces.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;img src="https://raw.githubusercontent.com/firebase/genkit/main/docs/resources/readme-ui-traces-screenshot.png" width="700" alt="Screenshot of Genkit Developer UI showing traces" /&gt; 
&lt;h2&gt;Try Genkit in Firebase Studio&lt;/h2&gt; 
&lt;p&gt;Want to skip the local setup? Click below to try out Genkit using &lt;a href="https://firebase.studio"&gt;Firebase Studio&lt;/a&gt;, Google's AI-assisted workspace for full-stack app development in the cloud.&lt;/p&gt; 
&lt;a href="https://studio.firebase.google.com/new/genkit"&gt; &lt;img height="32" alt="Open in Firebase Studio" src="https://cdn.firebasestudio.dev/btn/open_bright_32.svg?sanitize=true" /&gt; &lt;/a&gt; 
&lt;h2&gt;Connect with us&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/qXt5zzQKpc"&gt;&lt;strong&gt;Join us on Discord&lt;/strong&gt;&lt;/a&gt; â€“ Get help, share ideas, and chat with other developers.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/firebase/genkit/issues"&gt;&lt;strong&gt;Contribute on GitHub&lt;/strong&gt;&lt;/a&gt; â€“ Report bugs, suggest features, or explore the source code.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/genkit-ai/"&gt;&lt;strong&gt;Contribute to Documentation and Samples&lt;/strong&gt;&lt;/a&gt; â€“ Report issues in Genkit's &lt;a href="https://github.com/genkit-ai/docsite"&gt;documentation&lt;/a&gt;, or contribute to the &lt;a href="https://github.com/genkit-ai/samples"&gt;samples&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions to Genkit are welcome and highly appreciated! See our &lt;a href="https://raw.githubusercontent.com/firebase/genkit/main/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;h2&gt;Authors&lt;/h2&gt; 
&lt;p&gt;Genkit is built by &lt;a href="https://firebase.google.com/"&gt;Firebase&lt;/a&gt; with contributions from the &lt;a href="https://github.com/firebase/genkit/graphs/contributors"&gt;Open Source Community&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ItzCrazyKns/Perplexica</title>
      <link>https://github.com/ItzCrazyKns/Perplexica</link>
      <description>&lt;p&gt;Perplexica is an AI-powered search engine. It is an Open source alternative to Perplexity AI&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;ğŸš€ Perplexica - An AI-powered search engine ğŸ” 
 &lt;!-- omit in toc --&gt;&lt;/h1&gt; 
&lt;div align="center" markdown="1"&gt; 
 &lt;sup&gt;Special thanks to:&lt;/sup&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;a href="https://www.warp.dev/perplexica"&gt; &lt;img alt="Warp sponsorship" width="400" src="https://github.com/user-attachments/assets/775dd593-9b5f-40f1-bf48-479faff4c27b" /&gt; &lt;/a&gt; 
 &lt;h3&gt;&lt;a href="https://www.warp.dev/perplexica"&gt;Warp, the AI Devtool that lives in your terminal&lt;/a&gt;&lt;/h3&gt; 
 &lt;p&gt;&lt;a href="https://www.warp.dev/perplexica"&gt;Available for MacOS, Linux, &amp;amp; Windows&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://discord.gg/26aArMy8tT"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/26aArMy8tT?style=flat" alt="Discord" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/.assets/perplexica-screenshot.png?" alt="preview" /&gt;&lt;/p&gt; 
&lt;h2&gt;Table of Contents 
 &lt;!-- omit in toc --&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#overview"&gt;Overview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#preview"&gt;Preview&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#installation"&gt;Installation&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#getting-started-with-docker-recommended"&gt;Getting Started with Docker (Recommended)&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#non-docker-installation"&gt;Non-Docker Installation&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#ollama-connection-errors"&gt;Ollama Connection Errors&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#lemonade-connection-errors"&gt;Lemonade Connection Errors&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#using-as-a-search-engine"&gt;Using as a Search Engine&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#using-perplexicas-api"&gt;Using Perplexica's API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#expose-perplexica-to-network"&gt;Expose Perplexica to a network&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#one-click-deployment"&gt;One-Click Deployment&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#upcoming-features"&gt;Upcoming Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#support-us"&gt;Support Us&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#donations"&gt;Donations&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#contribution"&gt;Contribution&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#help-and-support"&gt;Help and Support&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;Perplexica is an open-source AI-powered searching tool or an AI-powered search engine that goes deep into the internet to find answers. Inspired by Perplexity AI, it's an open-source option that not just searches the web but understands your questions. It uses advanced machine learning algorithms like similarity searching and embeddings to refine results and provides clear answers with sources cited.&lt;/p&gt; 
&lt;p&gt;Using SearxNG to stay current and fully open source, Perplexica ensures you always get the most up-to-date information without compromising your privacy.&lt;/p&gt; 
&lt;p&gt;Want to know more about its architecture and how it works? You can read it &lt;a href="https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/architecture/README.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Preview&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/.assets/perplexica-preview.gif" alt="video-preview" /&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Local LLMs&lt;/strong&gt;: You can utilize local LLMs such as Qwen, DeepSeek, Llama, and Mistral.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Two Main Modes:&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Copilot Mode:&lt;/strong&gt; (In development) Boosts search by generating different queries to find more relevant internet sources. Like normal search instead of just using the context by SearxNG, it visits the top matches and tries to find relevant sources to the user's query directly from the page.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Normal Mode:&lt;/strong&gt; Processes your query and performs a web search.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Focus Modes:&lt;/strong&gt; Special modes to better answer specific types of questions. Perplexica currently has 6 focus modes: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;All Mode:&lt;/strong&gt; Searches the entire web to find the best results.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Writing Assistant Mode:&lt;/strong&gt; Helpful for writing tasks that do not require searching the web.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Academic Search Mode:&lt;/strong&gt; Finds articles and papers, ideal for academic research.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;YouTube Search Mode:&lt;/strong&gt; Finds YouTube videos based on the search query.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Wolfram Alpha Search Mode:&lt;/strong&gt; Answers queries that need calculations or data analysis using Wolfram Alpha.&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Reddit Search Mode:&lt;/strong&gt; Searches Reddit for discussions and opinions related to the query.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Current Information:&lt;/strong&gt; Some search tools might give you outdated info because they use data from crawling bots and convert them into embeddings and store them in a index. Unlike them, Perplexica uses SearxNG, a metasearch engine to get the results and rerank and get the most relevant source out of it, ensuring you always get the latest information without the overhead of daily data updates.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Integrate Perplexica into your existing applications and make use of its capibilities.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;It has many more features like image and video search. Some of the planned features are mentioned in &lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/#upcoming-features"&gt;upcoming features&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;There are mainly 2 ways of installing Perplexica - With Docker, Without Docker. Using Docker is highly recommended.&lt;/p&gt; 
&lt;h3&gt;Getting Started with Docker (Recommended)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Ensure Docker is installed and running on your system.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Clone the Perplexica repository:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/ItzCrazyKns/Perplexica.git
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;After cloning, navigate to the directory containing the project files.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Rename the &lt;code&gt;sample.config.toml&lt;/code&gt; file to &lt;code&gt;config.toml&lt;/code&gt;. For Docker setups, you need only fill in the following fields:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;OPENAI&lt;/code&gt;: Your OpenAI API key. &lt;strong&gt;You only need to fill this if you wish to use OpenAI's models&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;CUSTOM_OPENAI&lt;/code&gt;: Your OpenAI-API-compliant local server URL, model name, and API key. You should run your local server with host set to &lt;code&gt;0.0.0.0&lt;/code&gt;, take note of which port number it is running on, and then use that port number to set &lt;code&gt;API_URL = http://host.docker.internal:PORT_NUMBER&lt;/code&gt;. You must specify the model name, such as &lt;code&gt;MODEL_NAME = "unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF:Q4_K_XL"&lt;/code&gt;. Finally, set &lt;code&gt;API_KEY&lt;/code&gt; to the appropriate value. If you have not defined an API key, just put anything you want in-between the quotation marks: &lt;code&gt;API_KEY = "whatever-you-want-but-not-blank"&lt;/code&gt; &lt;strong&gt;You only need to configure these settings if you want to use a local OpenAI-compliant server, such as Llama.cpp's &lt;a href="https://github.com/ggml-org/llama.cpp/raw/master/tools/server/README.md"&gt;&lt;code&gt;llama-server&lt;/code&gt;&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;OLLAMA&lt;/code&gt;: Your Ollama API URL. You should enter it as &lt;code&gt;http://host.docker.internal:PORT_NUMBER&lt;/code&gt;. If you installed Ollama on port 11434, use &lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;. For other ports, adjust accordingly. &lt;strong&gt;You need to fill this if you wish to use Ollama's models instead of OpenAI's&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;LEMONADE&lt;/code&gt;: Your Lemonade API URL. Since Lemonade runs directly on your local machine (not in Docker), you should enter it as &lt;code&gt;http://host.docker.internal:PORT_NUMBER&lt;/code&gt;. If you installed Lemonade on port 8000, use &lt;code&gt;http://host.docker.internal:8000&lt;/code&gt;. For other ports, adjust accordingly. &lt;strong&gt;You need to fill this if you wish to use Lemonade's models&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;GROQ&lt;/code&gt;: Your Groq API key. &lt;strong&gt;You only need to fill this if you wish to use Groq's hosted models&lt;/strong&gt;.`&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;ANTHROPIC&lt;/code&gt;: Your Anthropic API key. &lt;strong&gt;You only need to fill this if you wish to use Anthropic models&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;Gemini&lt;/code&gt;: Your Gemini API key. &lt;strong&gt;You only need to fill this if you wish to use Google's models&lt;/strong&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;DEEPSEEK&lt;/code&gt;: Your Deepseek API key. &lt;strong&gt;Only needed if you want Deepseek models.&lt;/strong&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;AIMLAPI&lt;/code&gt;: Your AI/ML API key. &lt;strong&gt;Only needed if you want to use AI/ML API models and embeddings.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: You can change these after starting Perplexica from the settings dialog.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;&lt;code&gt;SIMILARITY_MEASURE&lt;/code&gt;: The similarity measure to use (This is filled by default; you can leave it as is if you are unsure about it.)&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Ensure you are in the directory containing the &lt;code&gt;docker-compose.yaml&lt;/code&gt; file and execute:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Wait a few minutes for the setup to complete. You can access Perplexica at &lt;a href="http://localhost:3000"&gt;http://localhost:3000&lt;/a&gt; in your web browser.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: After the containers are built, you can start Perplexica directly from Docker without having to open a terminal.&lt;/p&gt; 
&lt;h3&gt;Non-Docker Installation&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install SearXNG and allow &lt;code&gt;JSON&lt;/code&gt; format in the SearXNG settings.&lt;/li&gt; 
 &lt;li&gt;Clone the repository and rename the &lt;code&gt;sample.config.toml&lt;/code&gt; file to &lt;code&gt;config.toml&lt;/code&gt; in the root directory. Ensure you complete all required fields in this file.&lt;/li&gt; 
 &lt;li&gt;After populating the configuration run &lt;code&gt;npm i&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Install the dependencies and then execute &lt;code&gt;npm run build&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Finally, start the app by running &lt;code&gt;npm run start&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Using Docker is recommended as it simplifies the setup process, especially for managing environment variables and dependencies.&lt;/p&gt; 
&lt;p&gt;See the &lt;a href="https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/installation"&gt;installation documentation&lt;/a&gt; for more information like updating, etc.&lt;/p&gt; 
&lt;h3&gt;Troubleshooting&lt;/h3&gt; 
&lt;h4&gt;Local OpenAI-API-Compliant Servers&lt;/h4&gt; 
&lt;p&gt;If Perplexica tells you that you haven't configured any chat model providers, ensure that:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Your server is running on &lt;code&gt;0.0.0.0&lt;/code&gt; (not &lt;code&gt;127.0.0.1&lt;/code&gt;) and on the same port you put in the API URL.&lt;/li&gt; 
 &lt;li&gt;You have specified the correct model name loaded by your local LLM server.&lt;/li&gt; 
 &lt;li&gt;You have specified the correct API key, or if one is not defined, you have put &lt;em&gt;something&lt;/em&gt; in the API key field and not left it empty.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Ollama Connection Errors&lt;/h4&gt; 
&lt;p&gt;If you're encountering an Ollama connection error, it is likely due to the backend being unable to connect to Ollama's API. To fix this issue you can:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Check your Ollama API URL:&lt;/strong&gt; Ensure that the API URL is correctly set in the settings menu.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Update API URL Based on OS:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; Use &lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Mac:&lt;/strong&gt; Use &lt;code&gt;http://host.docker.internal:11434&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Linux:&lt;/strong&gt; Use &lt;code&gt;http://&amp;lt;private_ip_of_host&amp;gt;:11434&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Adjust the port number if you're using a different one.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Linux Users - Expose Ollama to Network:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Inside &lt;code&gt;/etc/systemd/system/ollama.service&lt;/code&gt;, you need to add &lt;code&gt;Environment="OLLAMA_HOST=0.0.0.0:11434"&lt;/code&gt;. (Change the port number if you are using a different one.) Then reload the systemd manager configuration with &lt;code&gt;systemctl daemon-reload&lt;/code&gt;, and restart Ollama by &lt;code&gt;systemctl restart ollama&lt;/code&gt;. For more information see &lt;a href="https://github.com/ollama/ollama/raw/main/docs/faq.md#setting-environment-variables-on-linux"&gt;Ollama docs&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Ensure that the port (default is 11434) is not blocked by your firewall.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;Lemonade Connection Errors&lt;/h4&gt; 
&lt;p&gt;If you're encountering a Lemonade connection error, it is likely due to the backend being unable to connect to Lemonade's API. To fix this issue you can:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Check your Lemonade API URL:&lt;/strong&gt; Ensure that the API URL is correctly set in the settings menu.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Update API URL Based on OS:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; Use &lt;code&gt;http://host.docker.internal:8000&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Mac:&lt;/strong&gt; Use &lt;code&gt;http://host.docker.internal:8000&lt;/code&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;strong&gt;Linux:&lt;/strong&gt; Use &lt;code&gt;http://&amp;lt;private_ip_of_host&amp;gt;:8000&lt;/code&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;p&gt;Adjust the port number if you're using a different one.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Ensure Lemonade Server is Running:&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Make sure your Lemonade server is running and accessible on the configured port (default is 8000).&lt;/li&gt; 
   &lt;li&gt;Verify that Lemonade is configured to accept connections from all interfaces (&lt;code&gt;0.0.0.0&lt;/code&gt;), not just localhost (&lt;code&gt;127.0.0.1&lt;/code&gt;).&lt;/li&gt; 
   &lt;li&gt;Ensure that the port (default is 8000) is not blocked by your firewall.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Using as a Search Engine&lt;/h2&gt; 
&lt;p&gt;If you wish to use Perplexica as an alternative to traditional search engines like Google or Bing, or if you want to add a shortcut for quick access from your browser's search bar, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open your browser's settings.&lt;/li&gt; 
 &lt;li&gt;Navigate to the 'Search Engines' section.&lt;/li&gt; 
 &lt;li&gt;Add a new site search with the following URL: &lt;code&gt;http://localhost:3000/?q=%s&lt;/code&gt;. Replace &lt;code&gt;localhost&lt;/code&gt; with your IP address or domain name, and &lt;code&gt;3000&lt;/code&gt; with the port number if Perplexica is not hosted locally.&lt;/li&gt; 
 &lt;li&gt;Click the add button. Now, you can use Perplexica directly from your browser's search bar.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Using Perplexica's API&lt;/h2&gt; 
&lt;p&gt;Perplexica also provides an API for developers looking to integrate its powerful search engine into their own applications. You can run searches, use multiple models and get answers to your queries.&lt;/p&gt; 
&lt;p&gt;For more details, check out the full documentation &lt;a href="https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/API/SEARCH.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Expose Perplexica to network&lt;/h2&gt; 
&lt;p&gt;Perplexica runs on Next.js and handles all API requests. It works right away on the same network and stays accessible even with port forwarding.&lt;/p&gt; 
&lt;h2&gt;One-Click Deployment&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://usw.sealos.io/?openapp=system-template%3FtemplateName%3Dperplexica"&gt;&lt;img src="https://raw.githubusercontent.com/labring-actions/templates/main/Deploy-on-Sealos.svg?sanitize=true" alt="Deploy to Sealos" /&gt;&lt;/a&gt; &lt;a href="https://repocloud.io/details/?app_id=267"&gt;&lt;img src="https://d16t0pc4846x52.cloudfront.net/deploylobe.svg?sanitize=true" alt="Deploy to RepoCloud" /&gt;&lt;/a&gt; &lt;a href="https://template.run.claw.cloud/?referralCode=U11MRQ8U9RM4&amp;amp;openapp=system-fastdeploy%3FtemplateName%3Dperplexica"&gt;&lt;img src="https://raw.githubusercontent.com/ClawCloud/Run-Template/refs/heads/main/Run-on-ClawCloud.svg?sanitize=true" alt="Run on ClawCloud" /&gt;&lt;/a&gt; &lt;a href="https://www.hostinger.com/vps/docker-hosting?compose_url=https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/refs/heads/master/docker-compose.yaml"&gt;&lt;img src="https://assets.hostinger.com/vps/deploy.svg?sanitize=true" alt="Deploy on Hostinger" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Upcoming Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Add settings page&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Adding support for local LLMs&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; History Saving features&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Introducing various Focus Modes&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Adding API support&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Adding Discover&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Finalizing Copilot Mode&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Support Us&lt;/h2&gt; 
&lt;p&gt;If you find Perplexica useful, consider giving us a star on GitHub. This helps more people discover Perplexica and supports the development of new features. Your support is greatly appreciated.&lt;/p&gt; 
&lt;h3&gt;Donations&lt;/h3&gt; 
&lt;p&gt;We also accept donations to help sustain our project. If you would like to contribute, you can use the following options to donate. Thank you for your support!&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Ethereum&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Address: &lt;code&gt;0xB025a84b2F269570Eb8D4b05DEdaA41D8525B6DD&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Perplexica is built on the idea that AI and large language models should be easy for everyone to use. If you find bugs or have ideas, please share them in via GitHub Issues. For more information on contributing to Perplexica you can read the &lt;a href="https://raw.githubusercontent.com/ItzCrazyKns/Perplexica/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; file to learn more about Perplexica and how you can contribute to it.&lt;/p&gt; 
&lt;h2&gt;Help and Support&lt;/h2&gt; 
&lt;p&gt;If you have any questions or feedback, please feel free to reach out to us. You can create an issue on GitHub or join our Discord server. There, you can connect with other users, share your experiences and reviews, and receive more personalized help. &lt;a href="https://discord.gg/EFwsmQDgAu"&gt;Click here&lt;/a&gt; to join the Discord server. To discuss matters outside of regular support, feel free to contact me on Discord at &lt;code&gt;itzcrazykns&lt;/code&gt;.&lt;/p&gt; 
&lt;p&gt;Thank you for exploring Perplexica, the AI-powered search engine designed to enhance your search experience. We are constantly working to improve Perplexica and expand its capabilities. We value your feedback and contributions which help us make Perplexica even better. Don't forget to check back for updates and new features!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zie619/n8n-workflows</title>
      <link>https://github.com/Zie619/n8n-workflows</link>
      <description>&lt;p&gt;all of the workflows of n8n i could find (also from the site itself)&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;âš¡ N8N Workflow Collection &amp;amp; Documentation&lt;/h1&gt; 
&lt;p&gt;A professionally organized collection of &lt;strong&gt;2,053 n8n workflows&lt;/strong&gt; with a lightning-fast documentation system that provides instant search, analysis, and browsing capabilities.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;âš ï¸ IMPORTANT NOTICE (Aug 14, 2025):&lt;/strong&gt; Repository history has been rewritten due to DMCA compliance. If you have a fork or local clone, please see &lt;a href="https://github.com/Zie619/n8n-workflows/issues/85"&gt;Issue 85&lt;/a&gt; for instructions on syncing your copy.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Support My Work&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.buymeacoffee.com/zie619"&gt;&lt;img src="https://img.shields.io/badge/-Buy%20Me%20a%20Coffee-ffdd00?logo=buy-me-a-coffee&amp;amp;logoColor=black&amp;amp;style=flat" alt="Buy Me a Coffee" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;If you'd like to say thanks, consider buying me a coffeeâ€”your support helps me keep improving this project!&lt;/p&gt; 
&lt;h2&gt;ğŸš€ &lt;strong&gt;NEW: High-Performance Documentation System&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Experience 100x performance improvement over traditional documentation!&lt;/strong&gt;&lt;/p&gt; 
&lt;h3&gt;Quick Start - Fast Documentation System&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install dependencies
pip install -r requirements.txt

# Start the fast API server
python run.py

# Open in browser
http://localhost:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;âš¡ &lt;strong&gt;Sub-100ms response times&lt;/strong&gt; with SQLite FTS5 search&lt;/li&gt; 
 &lt;li&gt;ğŸ” &lt;strong&gt;Instant full-text search&lt;/strong&gt; with advanced filtering&lt;/li&gt; 
 &lt;li&gt;ğŸ“± &lt;strong&gt;Responsive design&lt;/strong&gt; - works perfectly on mobile&lt;/li&gt; 
 &lt;li&gt;ğŸŒ™ &lt;strong&gt;Dark/light themes&lt;/strong&gt; with system preference detection&lt;/li&gt; 
 &lt;li&gt;ğŸ“Š &lt;strong&gt;Live statistics&lt;/strong&gt; - 365 unique integrations, 29,445 total nodes&lt;/li&gt; 
 &lt;li&gt;ğŸ¯ &lt;strong&gt;Smart categorization&lt;/strong&gt; by trigger type and complexity&lt;/li&gt; 
 &lt;li&gt;ğŸ¯ &lt;strong&gt;Use case categorization&lt;/strong&gt; by service name mapped to categories&lt;/li&gt; 
 &lt;li&gt;ğŸ“„ &lt;strong&gt;On-demand JSON viewing&lt;/strong&gt; and download&lt;/li&gt; 
 &lt;li&gt;ğŸ”— &lt;strong&gt;Mermaid diagram generation&lt;/strong&gt; for workflow visualization&lt;/li&gt; 
 &lt;li&gt;ğŸ”„ &lt;strong&gt;Real-time workflow naming&lt;/strong&gt; with intelligent formatting&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Comparison&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Metric&lt;/th&gt; 
   &lt;th&gt;Old System&lt;/th&gt; 
   &lt;th&gt;New System&lt;/th&gt; 
   &lt;th&gt;Improvement&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;File Size&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;71MB HTML&lt;/td&gt; 
   &lt;td&gt;&amp;lt;100KB&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;700x smaller&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Load Time&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;10+ seconds&lt;/td&gt; 
   &lt;td&gt;&amp;lt;1 second&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;10x faster&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Search&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Client-side only&lt;/td&gt; 
   &lt;td&gt;Full-text with FTS5&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Instant&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Memory Usage&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;~2GB RAM&lt;/td&gt; 
   &lt;td&gt;&amp;lt;50MB RAM&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;40x less&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Mobile Support&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Poor&lt;/td&gt; 
   &lt;td&gt;Excellent&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Fully responsive&lt;/strong&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“‚ Repository Organization&lt;/h2&gt; 
&lt;h3&gt;Workflow Collection&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2,053 workflows&lt;/strong&gt; with meaningful, searchable names&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;365 unique integrations&lt;/strong&gt; across popular platforms&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;29,445 total nodes&lt;/strong&gt; with professional categorization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quality assurance&lt;/strong&gt; - All workflows analyzed and categorized&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Naming System âœ¨&lt;/h3&gt; 
&lt;p&gt;Our intelligent naming system converts technical filenames into readable titles:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Before&lt;/strong&gt;: &lt;code&gt;2051_Telegram_Webhook_Automation_Webhook.json&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;After&lt;/strong&gt;: &lt;code&gt;Telegram Webhook Automation&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% meaningful names&lt;/strong&gt; with smart capitalization&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Automatic integration detection&lt;/strong&gt; from node analysis&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Use Case Category âœ¨&lt;/h3&gt; 
&lt;p&gt;The search interface includes a dropdown filter that lets you browse 2,000+ workflows by category.&lt;/p&gt; 
&lt;p&gt;The system includes an automated categorization feature that organizes workflows by service categories to make them easier to discover and filter.&lt;/p&gt; 
&lt;h3&gt;How Categorization Works&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Run the categorization script&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python create_categories.py
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Service Name Recognition&lt;/strong&gt; The script analyzes each workflow JSON filename to identify recognized service names (e.g., "Twilio", "Slack", "Gmail", etc.)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Category Mapping&lt;/strong&gt; Each recognized service name is matched to its corresponding category using the definitions in &lt;code&gt;context/def_categories.json&lt;/code&gt;. For example:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Twilio â†’ Communication &amp;amp; Messaging&lt;/li&gt; 
   &lt;li&gt;Gmail â†’ Communication &amp;amp; Messaging&lt;/li&gt; 
   &lt;li&gt;Airtable â†’ Data Processing &amp;amp; Analysis&lt;/li&gt; 
   &lt;li&gt;Salesforce â†’ CRM &amp;amp; Sales&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Search Categories Generation&lt;/strong&gt; The script produces a &lt;code&gt;search_categories.json&lt;/code&gt; file that contains the categorized workflow data&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Filter Interface&lt;/strong&gt; Users can then filter workflows by category in the search interface, making it easier to find workflows for specific use cases&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Available Categories&lt;/h3&gt; 
&lt;p&gt;The categorization system includes the following main categories:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;AI Agent Development&lt;/li&gt; 
 &lt;li&gt;Business Process Automation&lt;/li&gt; 
 &lt;li&gt;Cloud Storage &amp;amp; File Management&lt;/li&gt; 
 &lt;li&gt;Communication &amp;amp; Messaging&lt;/li&gt; 
 &lt;li&gt;Creative Content &amp;amp; Video Automation&lt;/li&gt; 
 &lt;li&gt;Creative Design Automation&lt;/li&gt; 
 &lt;li&gt;CRM &amp;amp; Sales&lt;/li&gt; 
 &lt;li&gt;Data Processing &amp;amp; Analysis&lt;/li&gt; 
 &lt;li&gt;E-commerce &amp;amp; Retail&lt;/li&gt; 
 &lt;li&gt;Financial &amp;amp; Accounting&lt;/li&gt; 
 &lt;li&gt;Marketing &amp;amp; Advertising Automation&lt;/li&gt; 
 &lt;li&gt;Project Management&lt;/li&gt; 
 &lt;li&gt;Social Media Management&lt;/li&gt; 
 &lt;li&gt;Technical Infrastructure &amp;amp; DevOps&lt;/li&gt; 
 &lt;li&gt;Web Scraping &amp;amp; Data Extraction&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contribute Categories&lt;/h3&gt; 
&lt;p&gt;You can help expand the categorization by adding more service-to-category mappings (e.g., Twilio â†’ Communication &amp;amp; Messaging) in context/defs_categories.json.&lt;/p&gt; 
&lt;p&gt;Many workflow JSON files are conveniently named with the service name, often separated by underscores (_).&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ›  Usage Instructions&lt;/h2&gt; 
&lt;h3&gt;Option 1: Modern Fast System (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone repository
git clone &amp;lt;repo-url&amp;gt;
cd n8n-workflows

# Install Python dependencies
pip install -r requirements.txt

# Start the documentation server
python run.py

# Browse workflows at http://localhost:8000
# - Instant search across 2,053 workflows
# - Professional responsive interface
# - Real-time workflow statistics
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Option 2: Development Mode&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start with auto-reload for development
python run.py --dev

# Or specify custom host/port
python run.py --host 0.0.0.0 --port 3000

# Force database reindexing
python run.py --reindex
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Import Workflows into n8n&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Use the Python importer (recommended)
python import_workflows.py

# Or manually import individual workflows:
# 1. Open your n8n Editor UI
# 2. Click menu (â˜°) â†’ Import workflow
# 3. Choose any .json file from the workflows/ folder
# 4. Update credentials/webhook URLs before running
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“Š Workflow Statistics&lt;/h2&gt; 
&lt;h3&gt;Current Collection Stats&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Total Workflows&lt;/strong&gt;: 2,053 automation workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Active Workflows&lt;/strong&gt;: 215 (10.5% active rate)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Total Nodes&lt;/strong&gt;: 29,445 (avg 14.3 nodes per workflow)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Unique Integrations&lt;/strong&gt;: 365 different services and APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Database&lt;/strong&gt;: SQLite with FTS5 full-text search&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Trigger Distribution&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Complex&lt;/strong&gt;: 831 workflows (40.5%) - Multi-trigger systems&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Webhook&lt;/strong&gt;: 519 workflows (25.3%) - API-triggered automations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Manual&lt;/strong&gt;: 477 workflows (23.2%) - User-initiated workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scheduled&lt;/strong&gt;: 226 workflows (11.0%) - Time-based executions&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Complexity Analysis&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Low (â‰¤5 nodes)&lt;/strong&gt;: ~35% - Simple automations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Medium (6-15 nodes)&lt;/strong&gt;: ~45% - Standard workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;High (16+ nodes)&lt;/strong&gt;: ~20% - Complex enterprise systems&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Popular Integrations&lt;/h3&gt; 
&lt;p&gt;Top services by usage frequency:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Communication&lt;/strong&gt;: Telegram, Discord, Slack, WhatsApp&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Cloud Storage&lt;/strong&gt;: Google Drive, Google Sheets, Dropbox&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Databases&lt;/strong&gt;: PostgreSQL, MySQL, MongoDB, Airtable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;AI/ML&lt;/strong&gt;: OpenAI, Anthropic, Hugging Face&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Development&lt;/strong&gt;: HTTP Request, Webhook, GraphQL&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ” Advanced Search Features&lt;/h2&gt; 
&lt;h3&gt;Smart Search Categories&lt;/h3&gt; 
&lt;p&gt;Our system automatically categorizes workflows into 12 service categories:&lt;/p&gt; 
&lt;h4&gt;Available Categories:&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;messaging&lt;/strong&gt;: Telegram, Discord, Slack, WhatsApp, Teams&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ai_ml&lt;/strong&gt;: OpenAI, Anthropic, Hugging Face&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;database&lt;/strong&gt;: PostgreSQL, MySQL, MongoDB, Redis, Airtable&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;email&lt;/strong&gt;: Gmail, Mailjet, Outlook, SMTP/IMAP&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;cloud_storage&lt;/strong&gt;: Google Drive, Google Docs, Dropbox, OneDrive&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;project_management&lt;/strong&gt;: Jira, GitHub, GitLab, Trello, Asana&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;social_media&lt;/strong&gt;: LinkedIn, Twitter/X, Facebook, Instagram&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;ecommerce&lt;/strong&gt;: Shopify, Stripe, PayPal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;analytics&lt;/strong&gt;: Google Analytics, Mixpanel&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;calendar_tasks&lt;/strong&gt;: Google Calendar, Cal.com, Calendly&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;forms&lt;/strong&gt;: Typeform, Google Forms, Form Triggers&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;development&lt;/strong&gt;: Webhook, HTTP Request, GraphQL, SSE&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;API Usage Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Search workflows by text
curl "http://localhost:8000/api/workflows?q=telegram+automation"

# Filter by trigger type and complexity
curl "http://localhost:8000/api/workflows?trigger=Webhook&amp;amp;complexity=high"

# Find all messaging workflows
curl "http://localhost:8000/api/workflows/category/messaging"

# Get database statistics
curl "http://localhost:8000/api/stats"

# Browse available categories
curl "http://localhost:8000/api/categories"
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ— Technical Architecture&lt;/h2&gt; 
&lt;h3&gt;Modern Stack&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SQLite Database&lt;/strong&gt; - FTS5 full-text search with 365 indexed integrations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;FastAPI Backend&lt;/strong&gt; - RESTful API with automatic OpenAPI documentation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Responsive Frontend&lt;/strong&gt; - Modern HTML5 with embedded CSS/JavaScript&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Analysis&lt;/strong&gt; - Automatic workflow categorization and naming&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Key Features&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Change Detection&lt;/strong&gt; - MD5 hashing for efficient re-indexing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background Processing&lt;/strong&gt; - Non-blocking workflow analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Compressed Responses&lt;/strong&gt; - Gzip middleware for optimal speed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Error Handling&lt;/strong&gt; - Graceful degradation and comprehensive logging&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mobile Optimization&lt;/strong&gt; - Touch-friendly interface design&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Database Performance&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sql"&gt;-- Optimized schema for lightning-fast queries
CREATE TABLE workflows (
    id INTEGER PRIMARY KEY,
    filename TEXT UNIQUE,
    name TEXT,
    active BOOLEAN,
    trigger_type TEXT,
    complexity TEXT,
    node_count INTEGER,
    integrations TEXT,  -- JSON array of 365 unique services
    description TEXT,
    file_hash TEXT,     -- MD5 for change detection
    analyzed_at TIMESTAMP
);

-- Full-text search with ranking
CREATE VIRTUAL TABLE workflows_fts USING fts5(
    filename, name, description, integrations, tags,
    content='workflows', content_rowid='id'
);
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ”§ Setup &amp;amp; Requirements&lt;/h2&gt; 
&lt;h3&gt;System Requirements&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Python 3.7+&lt;/strong&gt; - For running the documentation system&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Modern Browser&lt;/strong&gt; - Chrome, Firefox, Safari, Edge&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;50MB Storage&lt;/strong&gt; - For SQLite database and indexes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;n8n Instance&lt;/strong&gt; - For importing and running workflows&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Installation&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Clone repository
git clone &amp;lt;repo-url&amp;gt;
cd n8n-workflows

# Install dependencies
pip install -r requirements.txt

# Start documentation server
python run.py

# Access at http://localhost:8000
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Development Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# or .venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Run with auto-reload for development
python api_server.py --reload

# Force database reindexing
python workflow_db.py --index --force
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“‹ Naming Convention&lt;/h2&gt; 
&lt;h3&gt;Intelligent Formatting System&lt;/h3&gt; 
&lt;p&gt;Our system automatically converts technical filenames to user-friendly names:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Automatic transformations:
2051_Telegram_Webhook_Automation_Webhook.json â†’ "Telegram Webhook Automation"
0250_HTTP_Discord_Import_Scheduled.json â†’ "HTTP Discord Import Scheduled"  
0966_OpenAI_Data_Processing_Manual.json â†’ "OpenAI Data Processing Manual"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Technical Format&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;[ID]_[Service1]_[Service2]_[Purpose]_[Trigger].json
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Smart Capitalization Rules&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP&lt;/strong&gt; â†’ HTTP (not Http)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API&lt;/strong&gt; â†’ API (not Api)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;webhook&lt;/strong&gt; â†’ Webhook&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;automation&lt;/strong&gt; â†’ Automation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;scheduled&lt;/strong&gt; â†’ Scheduled&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸš€ API Documentation&lt;/h2&gt; 
&lt;h3&gt;Core Endpoints&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /&lt;/code&gt; - Main workflow browser interface&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/stats&lt;/code&gt; - Database statistics and metrics&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows&lt;/code&gt; - Search with filters and pagination&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}&lt;/code&gt; - Detailed workflow information&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}/download&lt;/code&gt; - Download workflow JSON&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/{filename}/diagram&lt;/code&gt; - Generate Mermaid diagram&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Advanced Search&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/workflows/category/{category}&lt;/code&gt; - Search by service category&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/categories&lt;/code&gt; - List all available categories&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;GET /api/integrations&lt;/code&gt; - Get integration statistics&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;POST /api/reindex&lt;/code&gt; - Trigger background reindexing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Response Examples&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;// GET /api/stats
{
  "total": 2053,
  "active": 215,
  "inactive": 1838,
  "triggers": {
    "Complex": 831,
    "Webhook": 519,
    "Manual": 477,
    "Scheduled": 226
  },
  "total_nodes": 29445,
  "unique_integrations": 365
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ¤ Contributing&lt;/h2&gt; 
&lt;h3&gt;Adding New Workflows&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Export workflow&lt;/strong&gt; as JSON from n8n&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Name descriptively&lt;/strong&gt; following the established pattern&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Add to workflows/&lt;/strong&gt; directory&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Remove sensitive data&lt;/strong&gt; (credentials, personal URLs)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Run reindexing&lt;/strong&gt; to update the database&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Quality Standards&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;âœ… Workflow must be functional and tested&lt;/li&gt; 
 &lt;li&gt;âœ… Remove all credentials and sensitive data&lt;/li&gt; 
 &lt;li&gt;âœ… Follow naming convention for consistency&lt;/li&gt; 
 &lt;li&gt;âœ… Verify compatibility with recent n8n versions&lt;/li&gt; 
 &lt;li&gt;âœ… Include meaningful description or comments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;âš ï¸ Important Notes&lt;/h2&gt; 
&lt;h3&gt;Security &amp;amp; Privacy&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Review before use&lt;/strong&gt; - All workflows shared as-is for educational purposes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Update credentials&lt;/strong&gt; - Replace API keys, tokens, and webhooks&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Test safely&lt;/strong&gt; - Verify in development environment first&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Check permissions&lt;/strong&gt; - Ensure proper access rights for integrations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Compatibility&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;n8n Version&lt;/strong&gt; - Compatible with n8n 1.0+ (most workflows)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Community Nodes&lt;/strong&gt; - Some workflows may require additional node installations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;API Changes&lt;/strong&gt; - External services may have updated their APIs since creation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dependencies&lt;/strong&gt; - Verify required integrations before importing&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ“š Resources &amp;amp; References&lt;/h2&gt; 
&lt;h3&gt;Workflow Sources&lt;/h3&gt; 
&lt;p&gt;This comprehensive collection includes workflows from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Official n8n.io&lt;/strong&gt; - Documentation and community examples&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub repositories&lt;/strong&gt; - Open source community contributions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Blog posts &amp;amp; tutorials&lt;/strong&gt; - Real-world automation patterns&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;User submissions&lt;/strong&gt; - Tested and verified workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Enterprise use cases&lt;/strong&gt; - Business process automations&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Learn More&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/"&gt;n8n Documentation&lt;/a&gt; - Official documentation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://community.n8n.io/"&gt;n8n Community&lt;/a&gt; - Community forum and support&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://n8n.io/workflows/"&gt;Workflow Templates&lt;/a&gt; - Official template library&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://docs.n8n.io/integrations/"&gt;Integration Docs&lt;/a&gt; - Service-specific guides&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;h2&gt;ğŸ† Project Achievements&lt;/h2&gt; 
&lt;h3&gt;Repository Transformation&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2,053 workflows&lt;/strong&gt; professionally organized and named&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;365 unique integrations&lt;/strong&gt; automatically detected and categorized&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;100% meaningful names&lt;/strong&gt; (improved from basic filename patterns)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Zero data loss&lt;/strong&gt; during intelligent renaming process&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Advanced search&lt;/strong&gt; with 12 service categories&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Performance Revolution&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Sub-100ms search&lt;/strong&gt; with SQLite FTS5 full-text indexing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Instant filtering&lt;/strong&gt; across 29,445 workflow nodes&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Mobile-optimized&lt;/strong&gt; responsive design for all devices&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Real-time statistics&lt;/strong&gt; with live database queries&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Professional interface&lt;/strong&gt; with modern UX principles&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;System Reliability&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Robust error handling&lt;/strong&gt; with graceful degradation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Change detection&lt;/strong&gt; for efficient database updates&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Background processing&lt;/strong&gt; for non-blocking operations&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Comprehensive logging&lt;/strong&gt; for debugging and monitoring&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Production-ready&lt;/strong&gt; with proper middleware and security&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;em&gt;This repository represents the most comprehensive and well-organized collection of n8n workflows available, featuring cutting-edge search technology and professional documentation that makes workflow discovery and usage a delightful experience.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;ğŸ¯ Perfect for&lt;/strong&gt;: Developers, automation engineers, business analysts, and anyone looking to streamline their workflows with proven n8n automations.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/Zie619/n8n-workflows/main/README_ZH.md"&gt;ä¸­æ–‡&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>grpc/grpc-go</title>
      <link>https://github.com/grpc/grpc-go</link>
      <description>&lt;p&gt;The Go language implementation of gRPC. HTTP/2 based RPC&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;gRPC-Go&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pkg.go.dev/google.golang.org/grpc"&gt;&lt;img src="https://pkg.go.dev/badge/google.golang.org/grpc" alt="GoDoc" /&gt;&lt;/a&gt; &lt;a href="https://goreportcard.com/report/github.com/grpc/grpc-go"&gt;&lt;img src="https://goreportcard.com/badge/grpc/grpc-go" alt="GoReportCard" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/grpc/grpc-go"&gt;&lt;img src="https://codecov.io/gh/grpc/grpc-go/graph/badge.svg?sanitize=true" alt="codecov" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://golang.org"&gt;Go&lt;/a&gt; implementation of &lt;a href="https://grpc.io"&gt;gRPC&lt;/a&gt;: A high performance, open source, general RPC framework that puts mobile and HTTP/2 first. For more information see the &lt;a href="https://grpc.io/docs/languages/go"&gt;Go gRPC docs&lt;/a&gt;, or jump directly into the &lt;a href="https://grpc.io/docs/languages/go/quickstart"&gt;quick start&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://golang.org"&gt;Go&lt;/a&gt;&lt;/strong&gt;: any one of the &lt;strong&gt;two latest major&lt;/strong&gt; &lt;a href="https://golang.org/doc/devel/release.html"&gt;releases&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Simply add the following import to your code, and then &lt;code&gt;go [build|run|test]&lt;/code&gt; will automatically fetch the necessary dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;import "google.golang.org/grpc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you are trying to access &lt;code&gt;grpc-go&lt;/code&gt; from &lt;strong&gt;China&lt;/strong&gt;, see the &lt;a href="https://raw.githubusercontent.com/grpc/grpc-go/master/#FAQ"&gt;FAQ&lt;/a&gt; below.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Learn more&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://grpc.io/docs/languages/go"&gt;Go gRPC docs&lt;/a&gt;, which include a &lt;a href="https://grpc.io/docs/languages/go/quickstart"&gt;quick start&lt;/a&gt; and &lt;a href="https://pkg.go.dev/google.golang.org/grpc"&gt;API reference&lt;/a&gt; among other resources&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/grpc/grpc-go/master/Documentation"&gt;Low-level technical docs&lt;/a&gt; from this repository&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://performance-dot-grpc-testing.appspot.com/explore?dashboard=5180705743044608"&gt;Performance benchmark&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/grpc/grpc-go/master/examples"&gt;Examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/grpc/grpc-go/master/CONTRIBUTING.md"&gt;Contribution guidelines&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;I/O Timeout Errors&lt;/h3&gt; 
&lt;p&gt;The &lt;code&gt;golang.org&lt;/code&gt; domain may be blocked from some countries. &lt;code&gt;go get&lt;/code&gt; usually produces an error like the following when this happens:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ go get -u google.golang.org/grpc
package google.golang.org/grpc: unrecognized import path "google.golang.org/grpc" (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To build Go code, there are several options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Set up a VPN and access google.golang.org through that.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;With Go module support: it is possible to use the &lt;code&gt;replace&lt;/code&gt; feature of &lt;code&gt;go mod&lt;/code&gt; to create aliases for golang.org packages. In your project's directory:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latest
go mod tidy
go mod vendor
go build -mod=vendor
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Again, this will need to be done for all transitive dependencies hosted on golang.org as well. For details, refer to &lt;a href="https://github.com/golang/go/issues/28652"&gt;golang/go issue #28652&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Compiling error, undefined: grpc.SupportPackageIsVersion&lt;/h3&gt; 
&lt;p&gt;Please update to the latest version of gRPC-Go using &lt;code&gt;go get google.golang.org/grpc&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;How to turn on logging&lt;/h3&gt; 
&lt;p&gt;The default logger is controlled by environment variables. Turn everything on like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-console"&gt;$ export GRPC_GO_LOG_VERBOSITY_LEVEL=99
$ export GRPC_GO_LOG_SEVERITY_LEVEL=info
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;The RPC failed with error &lt;code&gt;"code = Unavailable desc = transport is closing"&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;This error means the connection the RPC is using was closed, and there are many possible reasons, including:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;mis-configured transport credentials, connection failed on handshaking&lt;/li&gt; 
 &lt;li&gt;bytes disrupted, possibly by a proxy in between&lt;/li&gt; 
 &lt;li&gt;server shutdown&lt;/li&gt; 
 &lt;li&gt;Keepalive parameters caused connection shutdown, for example if you have configured your server to terminate connections regularly to &lt;a href="https://github.com/grpc/grpc-go/issues/3170#issuecomment-552517779"&gt;trigger DNS lookups&lt;/a&gt;. If this is the case, you may want to increase your &lt;a href="https://pkg.go.dev/google.golang.org/grpc/keepalive?tab=doc#ServerParameters"&gt;MaxConnectionAgeGrace&lt;/a&gt;, to allow longer RPC calls to finish.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;It can be tricky to debug this because the error happens on the client side but the root cause of the connection being closed is on the server side. Turn on logging on &lt;strong&gt;both client and server&lt;/strong&gt;, and see if there are any transport errors.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PowerShell/PowerShell</title>
      <link>https://github.com/PowerShell/PowerShell</link>
      <description>&lt;p&gt;PowerShell for every system!&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;&lt;img src="https://raw.githubusercontent.com/PowerShell/PowerShell/master/assets/ps_black_64.svg?sanitize=true" alt="logo" /&gt; PowerShell&lt;/h1&gt; 
&lt;p&gt;Welcome to the PowerShell GitHub Community! &lt;a href="https://learn.microsoft.com/powershell/scripting/overview"&gt;PowerShell&lt;/a&gt; is a cross-platform (Windows, Linux, and macOS) automation and configuration tool/framework that works well with your existing tools and is optimized for dealing with structured data (e.g. JSON, CSV, XML, etc.), REST APIs, and object models. It includes a command-line shell, an associated scripting language, and a framework for processing cmdlets.&lt;/p&gt; 
&lt;h2&gt;Windows PowerShell vs. PowerShell 7+&lt;/h2&gt; 
&lt;p&gt;Although this repository started as a fork of the Windows PowerShell codebase, changes made in this repository are not ported back to Windows PowerShell 5.1. This also means that &lt;a href="https://github.com/PowerShell/PowerShell/issues"&gt;issues tracked here&lt;/a&gt; are only for PowerShell 7.x and higher. Windows PowerShell specific issues should be reported with the &lt;a href="https://support.microsoft.com/windows/send-feedback-to-microsoft-with-the-feedback-hub-app-f59187f8-8739-22d6-ba93-f66612949332"&gt;Feedback Hub app&lt;/a&gt;, by choosing "Apps &amp;gt; PowerShell" in the category.&lt;/p&gt; 
&lt;h2&gt;New to PowerShell?&lt;/h2&gt; 
&lt;p&gt;If you are new to PowerShell and want to learn more, we recommend reviewing the &lt;a href="https://learn.microsoft.com/powershell/scripting/learn/more-powershell-learning"&gt;getting started&lt;/a&gt; documentation.&lt;/p&gt; 
&lt;h2&gt;Get PowerShell&lt;/h2&gt; 
&lt;p&gt;PowerShell is supported on Windows, macOS, and a variety of Linux platforms. For more information, see &lt;a href="https://learn.microsoft.com/powershell/scripting/install/installing-powershell"&gt;Installing PowerShell&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Upgrading PowerShell&lt;/h2&gt; 
&lt;p&gt;For best results when upgrading, you should use the same install method you used when you first installed PowerShell. The update method is different for each platform and install method.&lt;/p&gt; 
&lt;h2&gt;Community Dashboard&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://aka.ms/PSPublicDashboard"&gt;Dashboard&lt;/a&gt; with visualizations for community contributions and project status using PowerShell, Azure, and PowerBI.&lt;/p&gt; 
&lt;p&gt;For more information on how and why we built this dashboard, check out this &lt;a href="https://devblogs.microsoft.com/powershell/powershell-open-source-community-dashboard/"&gt;blog post&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Discussions&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://docs.github.com/discussions/quickstart"&gt;GitHub Discussions&lt;/a&gt; is a feature to enable free and open discussions within the community for topics that are not related to code, unlike issues.&lt;/p&gt; 
&lt;p&gt;This is an experiment we are trying in our repositories, to see if it helps move discussions out of issues so that issues remain actionable by the team or members of the community. There should be no expectation that PowerShell team members are regular participants in these discussions. Individual PowerShell team members may choose to participate in discussions, but the expectation is that community members help drive discussions so that team members can focus on issues.&lt;/p&gt; 
&lt;p&gt;Create or join a &lt;a href="https://github.com/PowerShell/PowerShell/discussions"&gt;discussion&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Chat&lt;/h2&gt; 
&lt;p&gt;Want to chat with other members of the PowerShell community?&lt;/p&gt; 
&lt;p&gt;There are dozens of topic-specific channels on our community-driven PowerShell Virtual User Group, which you can join on:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://gitter.im/PowerShell/PowerShell"&gt;Gitter&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/PowerShell"&gt;Discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://web.libera.chat/#powershell"&gt;IRC&lt;/a&gt; on Libera.Chat&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://aka.ms/psslack"&gt;Slack&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Build status of nightly builds&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="left"&gt;Azure CI (Windows)&lt;/th&gt; 
   &lt;th align="left"&gt;Azure CI (Linux)&lt;/th&gt; 
   &lt;th align="left"&gt;Azure CI (macOS)&lt;/th&gt; 
   &lt;th align="left"&gt;CodeFactor Grade&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="left"&gt;&lt;a href="https://powershell.visualstudio.com/PowerShell/_build?definitionId=32"&gt;&lt;img src="https://powershell.visualstudio.com/PowerShell/_apis/build/status/PowerShell-CI-Windows-daily" alt="windows-nightly-image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://powershell.visualstudio.com/PowerShell/_build?definitionId=23"&gt;&lt;img src="https://powershell.visualstudio.com/PowerShell/_apis/build/status/PowerShell-CI-linux-daily?branchName=master" alt="linux-nightly-image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://powershell.visualstudio.com/PowerShell/_build?definitionId=24"&gt;&lt;img src="https://powershell.visualstudio.com/PowerShell/_apis/build/status/PowerShell-CI-macos-daily?branchName=master" alt="macOS-nightly-image" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="left"&gt;&lt;a href="https://www.codefactor.io/repository/github/powershell/powershell"&gt;&lt;img src="https://www.codefactor.io/repository/github/powershell/powershell/badge" alt="cf-image" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Developing and Contributing&lt;/h2&gt; 
&lt;p&gt;Want to contribute to PowerShell? Please start with the &lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/.github/CONTRIBUTING.md"&gt;Contribution Guide&lt;/a&gt; to learn how to develop and contribute.&lt;/p&gt; 
&lt;p&gt;If you are developing .NET Core C# applications targeting PowerShell Core, &lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/docs/FAQ.md#where-do-i-get-the-powershell-core-sdk-package"&gt;check out our FAQ&lt;/a&gt; to learn more about the PowerShell SDK NuGet package.&lt;/p&gt; 
&lt;p&gt;Also, make sure to check out our &lt;a href="https://github.com/powershell/powershell-rfc"&gt;PowerShell-RFC repository&lt;/a&gt; for request-for-comments (RFC) documents to submit and give comments on proposed and future designs.&lt;/p&gt; 
&lt;h2&gt;Building PowerShell&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Linux&lt;/th&gt; 
   &lt;th&gt;Windows&lt;/th&gt; 
   &lt;th&gt;macOS&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/docs/building/linux.md"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/docs/building/windows-core.md"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/docs/building/macos.md"&gt;Instructions&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;If you have any problems building PowerShell, please start by consulting the developer &lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/docs/FAQ.md"&gt;FAQ&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Downloading the Source Code&lt;/h2&gt; 
&lt;p&gt;You can clone the repository:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;git clone https://github.com/PowerShell/PowerShell.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information, see &lt;a href="https://github.com/PowerShell/PowerShell/tree/master/docs/git"&gt;working with the PowerShell repository&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;p&gt;For support, see the &lt;a href="https://github.com/PowerShell/PowerShell/tree/master/.github/SUPPORT.md"&gt;Support Section&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Legal and Licensing&lt;/h2&gt; 
&lt;p&gt;PowerShell is licensed under the &lt;a href="https://github.com/PowerShell/PowerShell/tree/master/LICENSE.txt"&gt;MIT license&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Docker Containers&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!Important] The PowerShell container images are now &lt;a href="https://github.com/PowerShell/Announcements/issues/75"&gt;maintained by the .NET team&lt;/a&gt;. The containers at &lt;code&gt;mcr.microsoft.com/powershell&lt;/code&gt; are currently not maintained.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;License: By requesting and using the Container OS Image for Windows containers, you acknowledge, understand, and consent to the Supplemental License Terms available on &lt;a href="https://mcr.microsoft.com/en-us/product/powershell/tags"&gt;Microsoft Artifact Registry&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Telemetry&lt;/h3&gt; 
&lt;p&gt;Please visit our &lt;a href="https://learn.microsoft.com/powershell/module/microsoft.powershell.core/about/about_telemetry"&gt;about_Telemetry&lt;/a&gt; topic to read details about telemetry gathered by PowerShell.&lt;/p&gt; 
&lt;h2&gt;Governance&lt;/h2&gt; 
&lt;p&gt;The governance policy for the PowerShell project is described the &lt;a href="https://github.com/PowerShell/PowerShell/raw/master/docs/community/governance.md"&gt;PowerShell Governance&lt;/a&gt; document.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Please see our &lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; before participating in this project.&lt;/p&gt; 
&lt;h2&gt;&lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/.github/SECURITY.md"&gt;Security Policy&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;For any security issues, please see our &lt;a href="https://raw.githubusercontent.com/PowerShell/PowerShell/master/.github/SECURITY.md"&gt;Security Policy&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SkyworkAI/DeepResearchAgent</title>
      <link>https://github.com/SkyworkAI/DeepResearchAgent</link>
      <description>&lt;p&gt;DeepResearchAgent is a hierarchical multi-agent system designed not only for deep research tasks but also for general-purpose task solving. The framework leverages a top-level planning agent to coordinate multiple specialized lower-level agents, enabling automated task decomposition and efficient execution across diverse and complex domains.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;DeepResearchAgent&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://skyworkai.github.io/DeepResearchAgent/"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%8C%90-Website-blue?style=for-the-badge&amp;amp;logo=github" alt="Website" /&gt;&lt;/a&gt; &lt;a href="https://arxiv.org/abs/2506.12508"&gt;&lt;img src="https://img.shields.io/badge/%F0%9F%93%84-arXiv%20Paper-red?style=for-the-badge&amp;amp;logo=arxiv" alt="Paper" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/SkyworkAI/DeepResearchAgent/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="License" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;English | &lt;a href="https://raw.githubusercontent.com/SkyworkAI/DeepResearchAgent/main/README_CN.md"&gt;ç®€ä½“ä¸­æ–‡&lt;/a&gt; | &lt;a href="https://skyworkai.github.io/DeepResearchAgent/"&gt;ğŸŒ &lt;strong&gt;Website&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Introduction&lt;/h2&gt; 
&lt;p&gt;image.png DeepResearchAgent is a hierarchical multi-agent system designed not only for deep research tasks but also for general-purpose task solving. The framework leverages a top-level planning agent to coordinate multiple specialized lower-level agents, enabling automated task decomposition and efficient execution across diverse and complex domains.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;ğŸŒ &lt;strong&gt;Check out our interactive website&lt;/strong&gt;: &lt;a href="https://skyworkai.github.io/DeepResearchAgent/"&gt;https://skyworkai.github.io/DeepResearchAgent/&lt;/a&gt; - Explore the architecture, view experiments, and learn more about our research!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SkyworkAI/DeepResearchAgent/main/docs/assets/architecture.png" alt="Architecture" width="700" /&gt; &lt;/p&gt; 
&lt;p&gt;The system adopts a two-layer structure:&lt;/p&gt; 
&lt;h3&gt;1. Top-Level Planning Agent&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Responsible for understanding, decomposing, and planning the overall workflow for a given task.&lt;/li&gt; 
 &lt;li&gt;Breaks down tasks into manageable sub-tasks and assigns them to appropriate lower-level agents.&lt;/li&gt; 
 &lt;li&gt;Dynamically coordinates the collaboration among agents to ensure smooth task completion.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. Specialized Lower-Level Agents&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deep Analyzer&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Performs in-depth analysis of input information, extracting key insights and potential requirements.&lt;/li&gt; 
   &lt;li&gt;Supports analysis of various data types, including text and structured data.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deep Researcher&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Conducts thorough research on specified topics or questions, retrieving and synthesizing high-quality information.&lt;/li&gt; 
   &lt;li&gt;Capable of generating research reports or knowledge summaries automatically.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Browser Use&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Automates browser operations, supporting web search, information extraction, and data collection tasks.&lt;/li&gt; 
   &lt;li&gt;Assists the Deep Researcher in acquiring up-to-date information from the internet.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;MCP Manager Agent&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Manages and orchestrates Model Context Protocol (MCP) tools and services.&lt;/li&gt; 
   &lt;li&gt;Enables dynamic tool discovery, registration, and execution through MCP standards.&lt;/li&gt; 
   &lt;li&gt;Supports both local and remote MCP tool integration for enhanced agent capabilities.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;General Tool Calling Agent&lt;/strong&gt;&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Provides a general-purpose interface for invoking various tools and APIs.&lt;/li&gt; 
   &lt;li&gt;Supports function calling, allowing the agent to execute specific tasks or retrieve information from external services.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Hierarchical agent collaboration for complex and dynamic task scenarios&lt;/li&gt; 
 &lt;li&gt;Extensible agent system, allowing easy integration of additional specialized agents&lt;/li&gt; 
 &lt;li&gt;Automated information analysis, research, and web interaction capabilities&lt;/li&gt; 
 &lt;li&gt;Secure Python code execution environment for tools, featuring configurable import controls, restricted built-ins, attribute access limitations, and resource limits. (See &lt;a href="https://raw.githubusercontent.com/SkyworkAI/DeepResearchAgent/main/docs/python_interpreter_sandbox.md"&gt;PythonInterpreterTool Sandboxing&lt;/a&gt; for details).&lt;/li&gt; 
 &lt;li&gt;Support for asynchronous operations, enabling efficient handling of multiple tasks and agents&lt;/li&gt; 
 &lt;li&gt;Support for local and remote model inference, including OpenAI, Anthropic, Google LLMs, and local Qwen models via vLLM&lt;/li&gt; 
 &lt;li&gt;Support for image and video generation tools based on the Imagen and Veo3 models, respectively&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Image and Video Examples:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SkyworkAI/DeepResearchAgent/main/docs/assets/cat_yarn_playful_reference.png" alt="Image Example" width="300" /&gt; &lt;img src="https://raw.githubusercontent.com/SkyworkAI/DeepResearchAgent/main/docs/assets/cat_playing_with_yarn_video.gif" alt="Video Example" width="600" /&gt; &lt;/p&gt; 
&lt;h2&gt;Updates&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;2025.08.04&lt;/strong&gt;: Add the support for loading mcp tools from the local json file.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025.07.08&lt;/strong&gt;: Add the video generator tool, which can generate a video based on the input text and/or image. The video generator tool is based on the Veo3 model.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025.07.08&lt;/strong&gt;: Add the image generator tool, which can generate images based on the input text. The image generator tool is based on the Imagen model.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025.07.07&lt;/strong&gt;: Due to the limited flexibility of TOML configuration files, we have switched to using the config format supported by mmengine.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025.06.20&lt;/strong&gt;: Add the support for the mcp (Both the local mcp and remote mcp).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025.06.17&lt;/strong&gt;: Update technical report &lt;a href="https://arxiv.org/pdf/2506.12508"&gt;https://arxiv.org/pdf/2506.12508&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025.06.01&lt;/strong&gt;: Update the browser-use to 0.1.48.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025.05.30&lt;/strong&gt;: Convert the sub agent to a function call. Planning agent can now be gpt-4.1 or gemini-2.5-pro.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;2025.05.27&lt;/strong&gt;: Support OpenAI, Anthropic, Google LLMs, and local Qwen models (via vLLM, see details in &lt;a href="https://raw.githubusercontent.com/SkyworkAI/DeepResearchAgent/main/#usage"&gt;Usage&lt;/a&gt;).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;TODO List&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Asynchronous feature completed&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Image Generator Tool completed&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Video Generator Tool completed&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; MCP in progress&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Load local MCP tools from JSON file completed&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; AI4Research Agent to be developed&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" disabled /&gt; Novel Writing Agent to be developed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Prepare Environment&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# poetry install environment
conda create -n dra python=3.11
conda activate dra
make install

# (Optional) You can also use requirements.txt
conda create -n dra python=3.11
conda activate dra
make install-requirements

# playwright install if needed
pip install playwright
playwright install chromium --with-deps --no-shell
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Set Up &lt;code&gt;.env&lt;/code&gt;&lt;/h3&gt; 
&lt;p&gt;Please refer to the &lt;code&gt;.env.template&lt;/code&gt; file and create a &lt;code&gt;.env&lt;/code&gt; file in the root directory of the project. This file is used to configure API keys and other environment variables.&lt;/p&gt; 
&lt;p&gt;Refer to the following instructions to obtain the necessary google gemini-2.5-pro API key and set it in the &lt;code&gt;.env&lt;/code&gt; file:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://aistudio.google.com/app/apikey"&gt;https://aistudio.google.com/app/apikey&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://cloud.google.com/docs/authentication/application-default-credentials?hl=zh-cn"&gt;https://cloud.google.com/docs/authentication/application-default-credentials?hl=zh-cn&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brew install --cask google-cloud-sdk
gcloud init
gcloud auth application-default login
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Main Example&lt;/h3&gt; 
&lt;p&gt;A simple example to demonstrate the usage of the DeepResearchAgent framework.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run Single Agent Example&lt;/h3&gt; 
&lt;p&gt;A simple example to demonstrate the usage of a single agent, such as a general tool calling agent.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python examples/run_general.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;RUN GAIA Evaluation Example&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Download GAIA
mkdir data &amp;amp;&amp;amp; cd data
git clone https://huggingface.co/datasets/gaia-benchmark/GAIA

# Run
python examples/run_gaia.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Experiments&lt;/h2&gt; 
&lt;p&gt;We evaluated our agent on both GAIA validation and test sets, achieving state-of-the-art performance. Our system demonstrates superior performance across all difficulty levels.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/SkyworkAI/DeepResearchAgent/main/docs/assets/gaia_test.png" alt="GAIA Test Results" width="300" /&gt; &lt;img src="https://raw.githubusercontent.com/SkyworkAI/DeepResearchAgent/main/docs/assets/gaia_validation.png" alt="GAIA Validation Results" width="300" /&gt; &lt;/p&gt; 
&lt;p&gt;With the integration of the Computer Use and MCP Manager Agent, which now enables pixel-level control of the browser, our system demonstrates remarkable evolutionary capabilities. The agents can dynamically acquire and enhance their abilities through learning and adaptation, leading to significantly improved performance. The latest results show:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Test Set&lt;/strong&gt;: 83.39 (average), with 93.55 on Level 1, 83.02 on Level 2, and 65.31 on Level 3&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Validation Set&lt;/strong&gt;: 82.4 (average), with 92.5 on Level 1, 83.7 on Level 2, and 57.7 on Level 3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Questions&lt;/h2&gt; 
&lt;h3&gt;1. About Qwen Models&lt;/h3&gt; 
&lt;p&gt;Our framework now supports:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;qwen2.5-7b-instruct&lt;/li&gt; 
 &lt;li&gt;qwen2.5-14b-instruct&lt;/li&gt; 
 &lt;li&gt;qwen2.5-32b-instruct&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Update your config:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-toml"&gt;model_id = "qwen2.5-7b-instruct"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Browser Use&lt;/h3&gt; 
&lt;p&gt;If problems occur, reinstall:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install "browser-use[memory]"==0.1.48
pip install playwright
playwright install chromium --with-deps --no-shell
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Sub-Agent Calling&lt;/h3&gt; 
&lt;p&gt;Function-calling is now supported natively by GPT-4.1 / Gemini 2.5 Pro. Claude-3.7-Sonnet is also recommended.&lt;/p&gt; 
&lt;h3&gt;4. Use vllm for local models&lt;/h3&gt; 
&lt;p&gt;We provide huggingface as a shortcut to the local model. Also provide vllm as a way to start services so that parallel acceleration can be provided.&lt;/p&gt; 
&lt;h4&gt;Step 1: Launch the vLLM Inference Service&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;nohup bash -c 'CUDA_VISIBLE_DEVICES=0,1 python -m vllm.entrypoints.openai.api_server \
  --model /input0/Qwen3-32B \
  --served-model-name Qwen \
  --host 0.0.0.0 \
  --port 8000 \
  --max-num-seqs 16 \
  --enable-auto-tool-choice \
  --tool-call-parser hermes \
  --tensor_parallel_size 2' &amp;gt; vllm_qwen.log 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Update &lt;code&gt;.env&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;QWEN_API_BASE=http://localhost:8000/v1
QWEN_API_KEY="abc"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Step 2: Launch the Agent Service&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python main.py
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Example command:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;Use deep_researcher_agent to search the latest papers on the topic of 'AI Agent' and then summarize it.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Acknowledgement&lt;/h2&gt; 
&lt;p&gt;DeepResearchAgent is primarily inspired by the architecture of smolagents. The following improvements have been made:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The codebase of smolagents has been modularized for better structure and organization.&lt;/li&gt; 
 &lt;li&gt;The original synchronous framework has been refactored into an asynchronous one.&lt;/li&gt; 
 &lt;li&gt;The multi-agent setup process has been optimized to make it more user-friendly and efficient.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We would like to express our gratitude to the following open source projects, which have greatly contributed to the development of this work:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/huggingface/smolagents"&gt;smolagents&lt;/a&gt; - A lightweight agent framework.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mannaandpoem/OpenManus"&gt;OpenManus&lt;/a&gt; - An asynchronous agent framework.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/browser-use/browser-use"&gt;browser-use&lt;/a&gt; - An AI-powered browser automation tool.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/unclecode/crawl4ai"&gt;crawl4ai&lt;/a&gt; - A web crawling library for AI applications.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/microsoft/markitdown"&gt;markitdown&lt;/a&gt; - A tool for converting files to Markdown format.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;We sincerely appreciate the efforts of all contributors and maintainers of these projects for their commitment to advancing AI technologies and making them available to the wider community.&lt;/p&gt; 
&lt;h2&gt;Contribution&lt;/h2&gt; 
&lt;p&gt;Contributions and suggestions are welcome! Feel free to open issues or submit pull requests.&lt;/p&gt; 
&lt;h2&gt;Cite&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{zhang2025agentorchestrahierarchicalmultiagentframework,
      title={AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving}, 
      author={Wentao Zhang, Liang Zeng, Yuzhen Xiao, Yongcong Li, Ce Cui, Yilei Zhao, Rui Hu, Yang Liu, Yahui Zhou, Bo An},
      year={2025},
      eprint={2506.12508},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2506.12508}, 
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç‰ˆè¯´æ˜æ–‡æ¡£&lt;/h3&gt; 
&lt;p&gt;å¦‚æœä½ æ›´ä¹ æƒ¯é˜…è¯»ä¸­æ–‡è¯´æ˜æ–‡æ¡£ï¼Œè¯·æŸ¥é˜… &lt;a href="https://raw.githubusercontent.com/SkyworkAI/DeepResearchAgent/main/README_CN.md"&gt;README_CN.md&lt;/a&gt;ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>TEN-framework/ten-framework</title>
      <link>https://github.com/TEN-framework/ten-framework</link>
      <description>&lt;p&gt;Open-source framework for conversational voice AI agents.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a name="readme-top"&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/7c8f72d7-3993-4d01-8504-b71578a22944" alt="TEN banner" /&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/releases"&gt;&lt;img src="https://img.shields.io/github/v/release/ten-framework/ten-framework?color=369eff&amp;amp;labelColor=gray&amp;amp;logo=github&amp;amp;style=flat-square" alt="TEN Releases" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/releases"&gt;&lt;img src="https://img.shields.io/github/release-date/ten-framework/ten-framework?labelColor=gray&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/discussions/"&gt;&lt;img src="https://img.shields.io/github/discussions/TEN-framework/ten_framework?labelColor=gray&amp;amp;color=%20%23f79009" alt="Discussion posts" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/graphs/commit-activity"&gt;&lt;img src="https://img.shields.io/github/commit-activity/m/TEN-framework/ten_framework?labelColor=gray&amp;amp;color=pink" alt="Commits" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/issues"&gt;&lt;img src="https://img.shields.io/github/issues-search?query=repo%3ATEN-framework%2Ften-framework%20is%3Aclosed&amp;amp;label=issues%20closed&amp;amp;labelColor=gray&amp;amp;color=green" alt="Issues closed" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/graphs/contributors"&gt;&lt;img src="https://img.shields.io/github/contributors/ten-framework/ten-framework?color=c4f042&amp;amp;labelColor=gray&amp;amp;style=flat-square" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/pulls"&gt;&lt;img src="https://img.shields.io/badge/PRs-welcome!-brightgreen.svg?style=flat-square" alt="PRs Welcome" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten_framework/raw/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/License-Apache_2.0_with_certain_conditions-blue.svg?labelColor=%20%23155EEF&amp;amp;color=%20%23528bff" alt="GitHub license" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/TEN-framework/TEN-framework"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt; &lt;a href="https://readmex.com/TEN-framework/ten-framework"&gt;&lt;img src="https://raw.githubusercontent.com/CodePhiliaX/resource-trusteeship/main/readmex.svg?sanitize=true" alt="ReadmeX" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://GitHub.com/TEN-framework/ten_framework/watchers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/watchers/TEN-framework/ten_framework?style=social&amp;amp;label=Watch" alt="GitHub watchers" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/TEN-framework/ten_framework/network/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/forks/TEN-framework/ten_framework?style=social&amp;amp;label=Fork" alt="GitHub forks" /&gt;&lt;/a&gt; &lt;a href="https://GitHub.com/TEN-framework/ten_framework/stargazers/?WT.mc_id=academic-105485-koreyst"&gt;&lt;img src="https://img.shields.io/github/stars/TEN-framework/ten_framework?style=social&amp;amp;label=Star" alt="GitHub stars" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/README.md"&gt;&lt;img alt="README in English" src="https://img.shields.io/badge/English-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-CN.md"&gt;&lt;img alt="ç®€ä½“ä¸­æ–‡æ“ä½œæŒ‡å—" src="https://img.shields.io/badge/ç®€ä½“ä¸­æ–‡-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-JP.md"&gt;&lt;img alt="æ—¥æœ¬èªã®README" src="https://img.shields.io/badge/æ—¥æœ¬èª-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-KR.md"&gt;&lt;img alt="README in í•œêµ­ì–´" src="https://img.shields.io/badge/í•œêµ­ì–´-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-ES.md"&gt;&lt;img alt="README en EspaÃ±ol" src="https://img.shields.io/badge/EspaÃ±ol-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-FR.md"&gt;&lt;img alt="README en FranÃ§ais" src="https://img.shields.io/badge/FranÃ§ais-lightgrey" /&gt;&lt;/a&gt; &lt;a href="https://github.com/TEN-framework/ten-framework/raw/main/docs/README-IT.md"&gt;&lt;img alt="README in Italiano" src="https://img.shields.io/badge/Italiano-lightgrey" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://theten.ai"&gt;Official Site&lt;/a&gt; â€¢ &lt;a href="https://theten.ai/docs/ten_agent/overview"&gt;Documentation&lt;/a&gt; â€¢ &lt;a href="https://theten.ai/blog"&gt;Blog&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/11978" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/11978" alt="TEN-framework%2Ften_framework | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Table of Contents&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;h4&gt;Table of Contents&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-welcome-to-ten"&gt;ğŸ‘‹ Welcome to TEN&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-tman-designer"&gt;ğŸ¨ TMAN Designer&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-features"&gt;âœ¨ Features&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#1%EF%B8%8F%E2%83%A3-real-time-avatar"&gt;1ï¸âƒ£ Real-time Avatar&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#2%EF%B8%8F%E2%83%A3-real-time-voice-with-mcp-servers"&gt;2ï¸âƒ£ Real-time voice with MCP servers&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#3%EF%B8%8F%E2%83%A3-real-time-communication-with-hardware"&gt;3ï¸âƒ£ Real-time communication with hardware&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#4%EF%B8%8F%E2%83%A3-real-time-vision-and-real-time-screenshare-detection"&gt;4ï¸âƒ£ Real-time vision and real-time screenshare detection&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#5%EF%B8%8F%E2%83%A3-ten-with-other-llm-platforms"&gt;5ï¸âƒ£ TEN with other LLM platforms&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#6%EF%B8%8F%E2%83%A3-storyteller---ten-image-generation"&gt;6ï¸âƒ£ StoryTeller - TEN image generation&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-get-ten-agent-up-and-running"&gt;ğŸ‘©â€ğŸ’» Get TEN Agent up and running&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B0%EF%B8%8F-run-ten-agent-in-localhost"&gt;ğŸ…°ï¸ Run TEN Agent in &lt;code&gt;localhost&lt;/code&gt;&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B1%EF%B8%8F-run-ten-agent-in-codespaceno-docker"&gt;ğŸ…±ï¸ Run TEN Agent in Codespace(no docker)&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%EF%B8%8F-ten-agent-self-hosting"&gt;ğŸ›³ï¸ TEN Agent Self Hosting&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B0%EF%B8%8F-deploying-with-docker"&gt;ğŸ…°ï¸ Deploying with Docker&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#%F0%9F%85%B1%EF%B8%8F-deploying-with-other-cloud-services"&gt;ğŸ…±ï¸ Deploying with other cloud services&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-ten-ecosystem"&gt;ğŸŒ TEN Ecosystem&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-ask-questions"&gt;â“ Ask Questions&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-contributing"&gt;ğŸ¥° Contributing&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#code-contributors"&gt;Code Contributors&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#contribution-guidelines"&gt;Contribution Guidelines&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;br /&gt; 
&lt;/details&gt; 
&lt;h2&gt;ğŸ‘‹ Welcome to TEN&lt;/h2&gt; 
&lt;p&gt;TEN is a comprehensive open-source ecosystem for creating, customizing, and deploying real-time conversational AI agents with multimodal capabilities including voice, vision, and avatar interactions.&lt;/p&gt; 
&lt;p&gt;TEN includes &lt;a href="https://github.com/ten-framework/ten-framework"&gt;TEN Framework&lt;/a&gt;, &lt;a href="https://github.com/ten-framework/ten-turn-detection"&gt;TEN Turn Detection&lt;/a&gt;, &lt;a href="https://github.com/ten-framework/ten-vad"&gt;TEN VAD&lt;/a&gt;, &lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents/demo"&gt;TEN Agent&lt;/a&gt;, &lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/core/src/ten_manager/designer_frontend"&gt;TMAN Designer&lt;/a&gt;, and &lt;a href="https://github.com/ten-framework/portal"&gt;TEN Portal&lt;/a&gt;. Check out &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#-ten-ecosystem"&gt;ğŸŒ TEN Ecosystem&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;br /&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Community Channel&lt;/th&gt; 
   &lt;th&gt;Purpose&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://twitter.com/intent/follow?screen_name=TenFramework"&gt;&lt;img src="https://img.shields.io/twitter/follow/TenFramework?logo=X&amp;amp;color=%20%23f5f5f5" alt="Follow on X" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Follow TEN Framework on X for updates and announcements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.linkedin.com/company/ten-framework"&gt;&lt;img src="https://custom-icon-badges.demolab.com/badge/LinkedIn-TEN_Framework-0A66C2?logo=linkedin-white&amp;amp;logoColor=fff" alt="Follow on LinkedIn" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Follow TEN Framework on LinkedIn for updates and announcements&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/VnPftUzAMJ"&gt;&lt;img src="https://img.shields.io/badge/Discord-Join%20TEN%20Community-5865F2?style=flat&amp;amp;logo=discord&amp;amp;logoColor=white" alt="Discord TEN Community" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our Discord community to connect with developers&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://huggingface.co/TEN-framework"&gt;&lt;img src="https://img.shields.io/badge/Hugging%20Face-TEN%20Framework-yellow?style=flat&amp;amp;logo=huggingface" alt="Hugging Face Space" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our Hugging Face community to explore our spaces and models&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-agent/discussions/170"&gt;&lt;img src="https://img.shields.io/badge/TEN_Framework-WeChat_Group-%2307C160?logo=wechat&amp;amp;labelColor=darkgreen&amp;amp;color=gray" alt="WeChat" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Join our WeChat group for Chinese community discussions&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Star TEN Repositories&lt;/strong&gt; â­ï¸&lt;/p&gt; 
 &lt;p&gt;Get instant notifications for new releases and updates. Your support helps us grow and improve TEN!&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/eeebe996-8c14-4bf7-82ae-f1a1f7e30705" alt="TEN star us gif" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Star History&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;picture&gt; 
  &lt;img width="100%" src="https://api.star-history.com/svg?repos=ten-framework/ten-framework&amp;amp;type=Date" /&gt; 
 &lt;/picture&gt; 
&lt;/details&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ¨ TMAN Designer&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/44c6a087-ec7a-45b0-a084-dab5dac5e36b"&gt;https://github.com/user-attachments/assets/44c6a087-ec7a-45b0-a084-dab5dac5e36b&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;TMAN Designer&lt;/h3&gt; 
&lt;p&gt;TMAN Designer is a low/no-code option to create voice agents with an easy-to-use workflow UI. It can load apps and graphs, and includes an online editor, log viewer, and much more.&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://theten.ai/blog/tman-designer-of-ten-framework"&gt;this blog&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;âœ¨ Features&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/c6702995-de94-4d3e-8cae-af097f087ac1" alt="TEN Agent with Trulience" /&gt;&lt;/p&gt; 
&lt;h3&gt;1ï¸âƒ£ Real-time Avatar&lt;/h3&gt; 
&lt;p&gt;Build engaging AI avatars with TEN Agent using &lt;a href="https://trulience.com"&gt;Trulience&lt;/a&gt;'s diverse collection of free avatar options. To get it up and running, you only need 2 steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Follow the README to finish setting up and running the Playground&lt;/li&gt; 
 &lt;li&gt;Enter the avatar ID and &lt;a href="https://trulience.com/docs#/authentication/jwt-tokens/jwt-tokens?id=use-your-custom-userid"&gt;token&lt;/a&gt; you get from &lt;a href="https://trulience.com"&gt;Trulience&lt;/a&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/afb77ad3-9c23-452f-b870-216687779017" alt="TEN with MCP servers" /&gt;&lt;/p&gt; 
&lt;h3&gt;2ï¸âƒ£ Real-time voice with MCP servers&lt;/h3&gt; 
&lt;p&gt;TEN Agent now integrates seamlessly with MCP servers, expanding its LLM capabilities. To get started:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open the Module Picker in Playground&lt;/li&gt; 
 &lt;li&gt;Add the MCP server tool for LLM integration&lt;/li&gt; 
 &lt;li&gt;Paste a URL from your MCP server in the extension&lt;/li&gt; 
 &lt;li&gt;Start a realtime conversation with TEN Agent&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;This integration allows you to leverage MCP's diverse servers offerings while maintaining TEN Agent's powerful conversational abilities.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://github.com/user-attachments/assets/78647eef-2d66-44e6-99a8-1918a940fb9f"&gt;https://github.com/user-attachments/assets/78647eef-2d66-44e6-99a8-1918a940fb9f&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;3ï¸âƒ£ Real-time communication with hardware&lt;/h3&gt; 
&lt;p&gt;TEN Agent is now running on the Espressif ESP32-S3 Korvo V3 development board, an excellent way to integrate realtime communication with LLM on hardware.&lt;/p&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents/esp32-client"&gt;integration guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/a1addb02-a450-47be-8cb2-d25e3b574f53" alt="Real-time Vision" /&gt;&lt;/p&gt; 
&lt;h3&gt;4ï¸âƒ£ Real-time vision and real-time screenshare detection&lt;/h3&gt; 
&lt;p&gt;Try Google Gemini Multimodal Live API with realtime vision and realtime screenshare detection capabilities, it is a ready-to-use extension, along with powerful tools like Weather Check and Web Search integrated perfectly into TEN Agent.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/234ff443-bef8-4cc4-9a10-09d6ec3f5bc1" alt="TEN with Dify" /&gt;&lt;/p&gt; 
&lt;h3&gt;5ï¸âƒ£ TEN with other LLM platforms&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://theten.ai/docs/ten_agent/playground/use-cases/voice-assistant/run_dify#steps"&gt;TEN Agent + Dify&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;TEN offers a great support to make the realtime interactive experience even better on other LLM platform as well, check out docs for more.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;img src="https://github.com/user-attachments/assets/fe28a549-ddb9-431e-9282-57539fb87371" alt="TEN StoryTeller" /&gt;&lt;/p&gt; 
&lt;h3&gt;6ï¸âƒ£ StoryTeller - TEN image generation&lt;/h3&gt; 
&lt;p&gt;Experience the real-time image generation with StoryTeller, it is a ready-to-use extension, along with powerful tools like Weather Check and Web Search integrated perfectly into TEN.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ‘©â€ğŸ’» Get TEN Agent up and running&lt;/h2&gt; 
&lt;h4&gt;ğŸ…°ï¸ Run TEN Agent in localhost&lt;/h4&gt; 
&lt;h4&gt;Step â“µ - Prerequisites&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Category&lt;/th&gt; 
   &lt;th&gt;Requirements&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Keys&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;â€¢ Agora &lt;a href="https://docs.agora.io/en/video-calling/get-started/manage-agora-account?platform=web#create-an-agora-project"&gt;App ID&lt;/a&gt; and &lt;a href="https://docs.agora.io/en/video-calling/get-started/manage-agora-account?platform=web#create-an-agora-project"&gt;App Certificate&lt;/a&gt; (free minutes every month) &lt;br /&gt;â€¢ &lt;a href="https://openai.com/index/openai-api/"&gt;OpenAI&lt;/a&gt; API key (any LLM that is compatible with OpenAI)&lt;br /&gt;â€¢ &lt;a href="https://deepgram.com/"&gt;Deepgram&lt;/a&gt; ASR (free credits available with signup)&lt;br /&gt;â€¢ &lt;a href="https://elevenlabs.io/"&gt;Elevenlabs&lt;/a&gt; TTS (free credits available with signup)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;â€¢ &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; / &lt;a href="https://docs.docker.com/compose/"&gt;Docker Compose&lt;/a&gt;&lt;br /&gt;â€¢ &lt;a href="https://nodejs.org/en"&gt;Node.js(LTS) v18&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Minimum System Requirements&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;â€¢ CPU &amp;gt;= 2 Core&lt;br /&gt;â€¢ RAM &amp;gt;= 4 GB&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;macOS: Docker setting on Apple Silicon&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Uncheck "Use Rosetta for x86/amd64 emulation" in Docker settings, it may result in slower build times on ARM, but performance will be normal when deployed to x64 servers.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h4&gt;Step â“¶ - Build agent in VM&lt;/h4&gt; 
&lt;h5&gt;1. Clone down the repo,&lt;code&gt;cd&lt;/code&gt; to &lt;code&gt;ai-agents&lt;/code&gt; and create &lt;code&gt;.env&lt;/code&gt; file from &lt;code&gt;.env.example&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cd ai_agents
cp ./.env.example ./.env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;2. Setup Agora App ID and App Certificate in &lt;code&gt;.env&lt;/code&gt;&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;AGORA_APP_ID=
AGORA_APP_CERTIFICATE=
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;3. Start agent development containers&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;4. Enter container&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker exec -it ten_agent_dev bash
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;5. Build agent with the default &lt;code&gt;graph&lt;/code&gt; ( ~5min - ~8min)&lt;/h5&gt; 
&lt;p&gt;check the &lt;code&gt;/examples&lt;/code&gt; folder for more examples&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# use the chained voice assistant
task use AGENT=voice-assistant

# or use the speech-to-speech voice assistant realtime
task use AGENT=voice-assistant-realtime
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;6. Start the web server&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# run task build if you changed any local source code, this is necessary if you are working on languages which require compilation like TypeScript or Golang.
task build

task run
&lt;/code&gt;&lt;/pre&gt; 
&lt;br /&gt; 
&lt;h4&gt;Step â“· - Customize your agent with TMAN Designer&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Open &lt;a href="http://localhost:49483"&gt;localhost:49483&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Right-click on the STT, LLM, and TTS extensions.&lt;/li&gt; 
 &lt;li&gt;Open their properties and enter APIs respectively.&lt;/li&gt; 
 &lt;li&gt;Right-click the canvas and select 'Manage Apps' to open the Apps Manager.&lt;/li&gt; 
 &lt;li&gt;Right under the Actions, click the â–¶ to run the App.&lt;/li&gt; 
 &lt;li&gt;Check the 'Run with TEN Agent' option and click the Run button.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h3&gt;ğŸ…±ï¸ Run TEN Agent in Codespace(no docker)&lt;/h3&gt; 
&lt;p&gt;GitHub offers free Codespace for each repository, you can run the playground in Codespace without using Docker.Also, the speed of Codespace is much faster than localhost.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://codespaces.new/ten-framework/ten-agent"&gt;&lt;img src="https://github.com/codespaces/badge.svg?sanitize=true" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Check out &lt;a href="https://theten.ai/docs/ten_agent/setup_development_env/setting_up_development_inside_codespace"&gt;this guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸ›³ï¸ TEN Agent Self Hosting&lt;/h2&gt; 
&lt;h4&gt;ğŸ…°ï¸ Deploying with Docker&lt;/h4&gt; 
&lt;p&gt;Once you have customized your agent (either by using the TMAN Manager, Playground, or editing &lt;code&gt;property.json&lt;/code&gt; directly), you can deploy it by creating a release Docker image for your service.&lt;/p&gt; 
&lt;p&gt;Read the &lt;a href="https://theten.ai/docs/ten_agent/deploy_ten_agent/deploy_agent_service"&gt;Deployment Guide&lt;/a&gt; for detailed information about deployment.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h4&gt;ğŸ…±ï¸ Deploying with other cloud services&lt;/h4&gt; 
&lt;p&gt;&lt;em&gt;coming soon&lt;/em&gt;&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;ğŸŒ TEN Ecosystem&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Project&lt;/th&gt; 
   &lt;th&gt;Preview&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten_framework"&gt;&lt;strong&gt;ğŸšï¸ TEN Framework&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN is an open-source framework for real-time, multimodal conversational AI.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten_framework?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/7c8f72d7-3993-4d01-8504-b71578a22944" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-turn-detection"&gt;&lt;strong&gt;ï¸ğŸ”‚ TEN Turn Detection&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN is for full-duplex dialogue communication.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-turn-detection?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/8d0ec716-5d0e-43e4-ad9a-d97b17305658" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/ten-vad"&gt;&lt;strong&gt;ğŸ”‰ TEN VAD&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN VAD is a low-latency, lightweight and high-performance streaming voice activity detector (VAD).&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/ten-vad?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/d45870e4-9453-4047-8163-08737f82863f" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/ai_agents"&gt;&lt;strong&gt;ğŸ™ï¸ TEN Agent&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TEN Agent is a showcase of TEN Framewrok.&lt;br /&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/38de2207-939b-4702-a0aa-04491f5b5275" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/TEN-framework/ten-framework/tree/main/core/src/ten_manager/designer_frontend"&gt;&lt;strong&gt;ğŸ¨ TMAN Designer&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;TMAN Designer is low/no code option to make a voice agent with easy to use workflow UI.&lt;br /&gt;&lt;br /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/804c3543-0a47-42b7-b40b-ef32b742fb8f" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/ten-framework/portal"&gt;&lt;strong&gt;ğŸ“’ TEN Portal&lt;/strong&gt;&lt;/a&gt;&lt;br /&gt;The official site of TEN framework, it has documentation and blog.&lt;br /&gt;&lt;br /&gt;&lt;img src="https://img.shields.io/github/stars/ten-framework/portal?color=ffcb47&amp;amp;labelColor=gray&amp;amp;style=flat-square&amp;amp;logo=github" alt="" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://github.com/user-attachments/assets/e17d8aaa-5928-45dd-ac71-814928e26a89" alt="" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;h2&gt;â“ Ask Questions&lt;/h2&gt; 
&lt;p&gt;TEN Framework is available on these AI-powered Q&amp;amp;A platforms. They can help you find answers quickly and accurately in multiple languages, covering everything from basic setup to advanced implementation details.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Service&lt;/th&gt; 
   &lt;th&gt;Link&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;DeepWiki&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://deepwiki.com/TEN-framework/TEN-framework"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;ReadmeX&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://readmex.com/TEN-framework/ten-framework"&gt;&lt;img src="https://raw.githubusercontent.com/CodePhiliaX/resource-trusteeship/main/readmex.svg?sanitize=true" alt="ReadmeX" /&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;br /&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ¥° Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome all forms of open-source collaboration! Whether you're fixing bugs, adding features, improving documentation, or sharing ideas - your contributions help advance personalized AI tools. Check out our GitHub Issues and Projects to find ways to contribute and show your skills. Together, we can build something amazing!&lt;/p&gt; 
&lt;br /&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Welcome all kinds of contributions&lt;/strong&gt; ğŸ™&lt;/p&gt; 
 &lt;p&gt;Join us in building TEN better! Every contribution makes a difference, from code to documentation. Share your TEN Agent projects on social media with to inspire others!&lt;/p&gt; 
 &lt;p&gt;Connect with one of the TEN maintainers &lt;a href="https://x.com/elliotchen100"&gt;@elliotchen100&lt;/a&gt; on ğ• or &lt;a href="https://github.com/cyfyifanchen"&gt;@cyfyifanchen&lt;/a&gt; on GitHub for project updates, discussions and collaboration opportunities.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;br /&gt; 
&lt;h3&gt;Code Contributors&lt;/h3&gt; 
&lt;p&gt;&lt;a href="https://github.com/TEN-framework/ten-agent/graphs/contributors"&gt;&lt;img src="https://contrib.rocks/image?repo=TEN-framework/ten-agent" alt="TEN" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Contribution Guidelines&lt;/h3&gt; 
&lt;p&gt;Contributions are welcome! Please read the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/docs/code-of-conduct/contributing.md"&gt;contribution guidelines&lt;/a&gt; first.&lt;/p&gt; 
&lt;h3&gt;License&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;The entire TEN framework (except for the folders explicitly listed below) is released under the Apache License, Version 2.0, with additional restrictions. For details, please refer to the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/LICENSE"&gt;LICENSE&lt;/a&gt; file located in the root directory of the TEN framework.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The components within the &lt;code&gt;packages&lt;/code&gt; directory are released under the Apache License, Version 2.0. For details, please refer to the &lt;code&gt;LICENSE&lt;/code&gt; file located in each package's root directory.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;The third-party libraries used by the TEN framework are listed and described in detail. For more information, please refer to the &lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/third_party/"&gt;third_party&lt;/a&gt; folder.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;div align="right"&gt; 
 &lt;p&gt;&lt;a href="https://raw.githubusercontent.com/TEN-framework/ten-framework/main/#readme-top"&gt;&lt;img src="https://img.shields.io/badge/-Back_to_top-gray?style=flat-square" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Alibaba-NLP/DeepResearch</title>
      <link>https://github.com/Alibaba-NLP/DeepResearch</link>
      <description>&lt;p&gt;Tongyi Deep Research, the Leading Open-source Deep Research Agent&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;picture&gt; 
  &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/logo.png" width="100%" /&gt; 
 &lt;/picture&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center" style="line-height: 1;"&gt; 
 &lt;p&gt;&lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B"&gt;&lt;img src="https://img.shields.io/badge/Models-5EDDD2?style=for-the-badge&amp;amp;logo=huggingface&amp;amp;logoColor=ffffff&amp;amp;labelColor" alt="MODELS" /&gt;&lt;/a&gt; &lt;a href="https://github.com/Alibaba-NLP/DeepResearch"&gt;&lt;img src="https://img.shields.io/badge/Github-24292F?style=for-the-badge&amp;amp;logo=github&amp;amp;logoColor=white" alt="GITHUB" /&gt;&lt;/a&gt; &lt;a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/"&gt;&lt;img src="https://img.shields.io/badge/Blog-4285F4?style=for-the-badge&amp;amp;logo=google-chrome&amp;amp;logoColor=white" alt="Blog" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; ğŸ¤— &lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B" target="_blank"&gt;HuggingFace&lt;/a&gt; ï½œ &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;a href="https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B" target="_blank"&gt;ModelScope&lt;/a&gt; &lt;/p&gt;
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/14217" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14217" alt="Alibaba-NLP%2FWebAgent | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h1&gt;Introduction&lt;/h1&gt; 
&lt;p&gt;We present &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;strong&gt;Tongyi DeepResearch&lt;/strong&gt;, an agentic large language model featuring 30.5 billion total parameters, with only 3.3 billion activated per token. Developed by Tongyi Lab, the model is specifically designed for &lt;strong&gt;long-horizon, deep information-seeking&lt;/strong&gt; tasks. Tongyi DeepResearch demonstrates state-of-the-art performance across a range of agentic search benchmarks, including Humanity's Last Exam, BrowserComp, BrowserComp-ZH, WebWalkerQA,xbench-DeepSearch, FRAMES and SimpleQA.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Tongyi DeepResearch builds upon our previous work on the &lt;img src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/tongyi.png" width="14px" style="display:inline;" /&gt; &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/WebAgent/"&gt;WebAgent&lt;/a&gt; project.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;More details can be found in our ğŸ“°&amp;nbsp;&lt;a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/"&gt;Tech Blog&lt;/a&gt;.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/performance.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;âš™ï¸ &lt;strong&gt;Fully automated synthetic data generation pipeline&lt;/strong&gt;: We design a highly scalable data synthesis pipeline, which is fully automatic and empowers agentic pre-training, supervised fine-tuning, and reinforcement learning.&lt;/li&gt; 
 &lt;li&gt;ğŸ”„ &lt;strong&gt;Large-scale continual pre-training on agentic data&lt;/strong&gt;: Leveraging diverse, high-quality agentic interaction data to extend model capabilities, maintain freshness, and strengthen reasoning performance.&lt;/li&gt; 
 &lt;li&gt;ğŸ” &lt;strong&gt;End-to-end reinforcement learning&lt;/strong&gt;: We employ a strictly on-policy RL approach based on a customized Group Relative Policy Optimization framework, with token-level policy gradients, leave-one-out advantage estimation, and selective filtering of negative samples to stabilize training in a nonâ€‘stationary environment.&lt;/li&gt; 
 &lt;li&gt;ğŸ¤– &lt;strong&gt;Agent Inference Paradigm Compatibility&lt;/strong&gt;: At inference, Tongyi DeepResearch is compatible with two inference paradigms: ReAct, for rigorously evaluating the model's core intrinsic abilities, and an IterResearch-based 'Heavy' mode, which uses a test-time scaling strategy to unlock the model's maximum performance ceiling.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Model Download&lt;/h1&gt; 
&lt;p&gt;You can directly download the model by following the links below.&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Model&lt;/th&gt; 
   &lt;th align="center"&gt;Download Links&lt;/th&gt; 
   &lt;th align="center"&gt;Model Size&lt;/th&gt; 
   &lt;th align="center"&gt;Context Length&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Tongyi-DeepResearch-30B-A3B&lt;/td&gt; 
   &lt;td align="center"&gt;&lt;a href="https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B"&gt;ğŸ¤— HuggingFace&lt;/a&gt;&lt;br /&gt; &lt;a href="https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B"&gt;ğŸ¤– ModelScope&lt;/a&gt;&lt;/td&gt; 
   &lt;td align="center"&gt;30B-A3B&lt;/td&gt; 
   &lt;td align="center"&gt;128K&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h1&gt;News&lt;/h1&gt; 
&lt;p&gt;[2025/09/17]ğŸ”¥ We have released &lt;strong&gt;Tongyi-DeepResearch-30B-A3B&lt;/strong&gt;.&lt;/p&gt; 
&lt;h1&gt;Deep Research Benchmark Results&lt;/h1&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/benchmark.png" /&gt; &lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;p&gt;This guide provides instructions for setting up the environment and running inference scripts located in the &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/inference/"&gt;inference&lt;/a&gt; folder.&lt;/p&gt; 
&lt;h3&gt;1. Environment Setup&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Recommended Python version: &lt;strong&gt;3.10.0&lt;/strong&gt; (using other versions may cause dependency issues).&lt;/li&gt; 
 &lt;li&gt;It is strongly advised to create an isolated environment using &lt;code&gt;conda&lt;/code&gt; or &lt;code&gt;virtualenv&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Example with Conda
conda create -n react_infer_env python=3.10.0 
conda activate react_infer_env
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Installation&lt;/h3&gt; 
&lt;p&gt;Install the required dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install -r requirements.txt
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;3. Prepare Evaluation Data&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a folder named &lt;code&gt;eval_data/&lt;/code&gt; in the project root.&lt;/li&gt; 
 &lt;li&gt;Place your QA file in &lt;strong&gt;JSONL&lt;/strong&gt; format inside this directory, e.g. &lt;code&gt;eval_data/example.jsonl&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Each line must be a JSON object that includes &lt;strong&gt;both&lt;/strong&gt; of the following keys: &lt;pre&gt;&lt;code class="language-json"&gt;{"question": "...","answer": "..."}
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt;A sample file is provided in the &lt;code&gt;eval_data&lt;/code&gt; folder for reference.&lt;/li&gt; 
 &lt;li&gt;If you plan to use the &lt;em&gt;file parser&lt;/em&gt; tool, &lt;strong&gt;prepend the file name to the &lt;code&gt;question&lt;/code&gt; field&lt;/strong&gt; and place the referenced file inside the &lt;code&gt;eval_data/file_corpus/&lt;/code&gt; directory.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. Configure the Inference Script&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;Open &lt;code&gt;run_react_infer.sh&lt;/code&gt; and modify the following variables as instructed in the comments: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;MODEL_PATH&lt;/code&gt; - path to the local or remote model weights.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;DATASET&lt;/code&gt; - path to the evaluation set, e.g. &lt;code&gt;example&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;OUTPUT_PATH&lt;/code&gt; - path for saving the prediction results, e.g. &lt;code&gt;./outputs&lt;/code&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Depending on the tools you enable (retrieval, calculator, web search, etc.), provide the required &lt;code&gt;API_KEY&lt;/code&gt;, &lt;code&gt;BASE_URL&lt;/code&gt;, or other credentials. Each key is explained inline in the bash script.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. Run the Inference Script&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;bash run_react_infer.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;p&gt;With these steps, you can fully prepare the environment, configure the dataset, and run the model. For more details, consult the inline comments in each script or open an issue.&lt;/p&gt; 
&lt;h3&gt;6. You can use OpenRouter's API to call our model&lt;/h3&gt; 
&lt;p&gt;Tongyi-DeepResearch-30B-A3B is now available at &lt;a href="https://openrouter.ai/alibaba/tongyi-deepresearch-30b-a3b"&gt;OpenRouter&lt;/a&gt;. You can run the inference without any GPUs.&lt;/p&gt; 
&lt;p&gt;You need to modify the following in the file &lt;a href="https://github.com/Alibaba-NLP/DeepResearch/raw/main/inference/react_agent.py"&gt;inference/react_agent.py&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;In the call_server function: Set the API key and URL to your OpenRouter accountâ€™s API and URL.&lt;/li&gt; 
 &lt;li&gt;Change the model name to alibaba/tongyi-deepresearch-30b-a3b.&lt;/li&gt; 
 &lt;li&gt;Adjust the content concatenation way as described in the comments on lines &lt;strong&gt;88â€“90.&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Benchmark Evaluation&lt;/h2&gt; 
&lt;p&gt;We provide benchmark evaluation scripts for various datasets. Please refer to the &lt;a href="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/evaluation/"&gt;evaluation scripts&lt;/a&gt; directory for more details.&lt;/p&gt; 
&lt;h2&gt;Deep Research Agent Family&lt;/h2&gt; 
&lt;p align="center"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/Alibaba-NLP/DeepResearch/main/assets/family.png" /&gt; &lt;/p&gt; 
&lt;p&gt;Tongyi DeepResearch also has an extensive deep research agent family. You can find more information in the following paper:&lt;/p&gt; 
&lt;p&gt;[1] &lt;a href="https://arxiv.org/pdf/2501.07572"&gt;WebWalker: Benchmarking LLMs in Web Traversal&lt;/a&gt; (ACL 2025)&lt;br /&gt; [2] &lt;a href="https://arxiv.org/pdf/2505.22648"&gt;WebDancer: Towards Autonomous Information Seeking Agency&lt;/a&gt; (NeurIPS 2025)&lt;br /&gt; [3] &lt;a href="https://arxiv.org/pdf/2507.02592"&gt;WebSailor: Navigating Super-human Reasoning for Web Agent&lt;/a&gt;&lt;br /&gt; [4] &lt;a href="https://arxiv.org/pdf/2507.15061"&gt;WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization&lt;/a&gt;&lt;br /&gt; [5] &lt;a href="https://arxiv.org/pdf/2508.05748"&gt;WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent&lt;/a&gt;&lt;br /&gt; [6] &lt;a href="https://arxiv.org/pdf/2509.13309"&gt;WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents&lt;/a&gt;&lt;br /&gt; [7] &lt;a href="https://arxiv.org/pdf/2509.13313"&gt;ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization&lt;/a&gt;&lt;br /&gt; [8] &lt;a href="https://arxiv.org/pdf/2509.13312"&gt;WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research&lt;/a&gt;&lt;br /&gt; [9] &lt;a href="https://arxiv.org/pdf/2509.13305"&gt;WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning&lt;/a&gt;&lt;br /&gt; [10] &lt;a href="https://arxiv.org/pdf/2509.13310"&gt;Scaling Agents via Continual Pre-training&lt;/a&gt;&lt;br /&gt; [11] &lt;a href="https://arxiv.org/pdf/2509.13311"&gt;Towards General Agentic Intelligence via Environment Scaling&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;ğŸŒŸ Misc&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.star-history.com/#Alibaba-NLP/DeepResearch&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=Alibaba-NLP/DeepResearch&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸš© Talent Recruitment&lt;/h2&gt; 
&lt;p&gt;ğŸ”¥ğŸ”¥ğŸ”¥ We are hiring! Research intern positions are open (based in Hangzhouã€Beijingã€Shanghai)&lt;/p&gt; 
&lt;p&gt;ğŸ“š &lt;strong&gt;Research Area&lt;/strong&gt;ï¼šWeb Agent, Search Agent, Agent RL, MultiAgent RL, Agentic RAG&lt;/p&gt; 
&lt;p&gt;â˜ï¸ &lt;strong&gt;Contact&lt;/strong&gt;ï¼š&lt;a href=""&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contact Information&lt;/h2&gt; 
&lt;p&gt;For communications, please contact Yong Jiang (&lt;a href="mailto:yongjiang.jy@alibaba-inc.com"&gt;yongjiang.jy@alibaba-inc.com&lt;/a&gt;).&lt;/p&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@misc{tongyidr,
  author={Tongyi DeepResearch Team},
  title={Tongyi-DeepResearch},
  year={2025},
  howpublished={\url{https://github.com/Alibaba-NLP/DeepResearch}}
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>sentient-agi/ROMA</title>
      <link>https://github.com/sentient-agi/ROMA</link>
      <description>&lt;p&gt;Recursive-Open-Meta-Agent v0.1 (Beta). A meta-agent framework to build high-performance multi-agent systems.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;div align="center"&gt; 
  &lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/sentient-logo-new-M.png" alt="alt text" width="60%" /&gt; 
 &lt;/div&gt; 
 &lt;h1&gt;ROMA: Recursive Open Meta-Agents&lt;/h1&gt; 
 &lt;p align="center"&gt; &lt;strong&gt;Building hierarchical high-performance multi-agent systems made easy! (Beta) &lt;/strong&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://trendshift.io/repositories/14848" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/14848" alt="sentient-agi%2FROMA | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://sentient.xyz/" target="_blank" style="margin: 2px;"&gt; &lt;img alt="Homepage" src="https://img.shields.io/badge/Sentient-Homepage-%23EAEAEA?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%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%2BPC9zdmc%2B&amp;amp;link=https%3A%2F%2Fhuggingface.co%2FSentientagi" style="display: inline-block; vertical-align: middle;" /&gt; &lt;/a&gt; &lt;a href="https://github.com/sentient-agi" target="_blank" style="margin: 2px;"&gt; &lt;img alt="GitHub" src="https://img.shields.io/badge/Github-sentient_agi-181717?logo=github" style="display: inline-block; vertical-align: middle;" /&gt; &lt;/a&gt; &lt;a href="https://huggingface.co/Sentientagi" target="_blank" style="margin: 2px;"&gt; &lt;img alt="Hugging Face" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-SentientAGI-ffc107?color=ffc107&amp;amp;logoColor=white" style="display: inline-block; vertical-align: middle;" /&gt; &lt;/a&gt; &lt;/p&gt;
&lt;/div&gt; 
&lt;div align="center" style="line-height: 1;"&gt; 
 &lt;a href="https://discord.gg/sentientfoundation" target="_blank" style="margin: 2px;"&gt; &lt;img alt="Discord" src="https://img.shields.io/badge/Discord-SentientAGI-7289da?logo=discord&amp;amp;logoColor=white&amp;amp;color=7289da" style="display: inline-block; vertical-align: middle;" /&gt; &lt;/a&gt; 
 &lt;a href="https://x.com/SentientAGI" target="_blank" style="margin: 2px;"&gt; &lt;img alt="Twitter Follow" src="https://img.shields.io/badge/-SentientAGI-grey?logo=x&amp;amp;link=https%3A%2F%2Fx.com%2FSentientAGI%2F" style="display: inline-block; vertical-align: middle;" /&gt; &lt;/a&gt; 
 &lt;p&gt;&lt;/p&gt; 
 &lt;p align="center"&gt; &lt;a href="https://www.sentient.xyz/blog/recursive-open-meta-agent"&gt;Technical Blog&lt;/a&gt; â€¢ &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/"&gt;Paper (Coming soon)&lt;/a&gt; â€¢ &lt;a href="https://www.sentient.xyz/"&gt;Build Agents for $$$&lt;/a&gt; &lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt;  
&lt;h2&gt;ğŸ“– Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/INTRODUCTION.md"&gt;ğŸš€ Introduction&lt;/a&gt;&lt;/strong&gt; - Understand the vision and architecture behind ROMA&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/SETUP.md"&gt;ğŸ“¦ Setup&lt;/a&gt;&lt;/strong&gt; - Detailed configuration options and environment setup&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/AGENTS_GUIDE.md"&gt;ğŸ¤– Agents Guide&lt;/a&gt;&lt;/strong&gt; - Learn how to create and customize your own agents&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/CONFIGURATION.md"&gt;âš™ï¸ Configuration&lt;/a&gt;&lt;/strong&gt; - Detailed configuration options and environment setup&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/ROADMAP.md"&gt;ğŸ—ºï¸ Roadmap&lt;/a&gt;&lt;/strong&gt; - See what's coming next for ROMA&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¯ What is ROMA?&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/roma_run.gif" alt="alt text" width="80%" /&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;strong&gt;ROMA&lt;/strong&gt; is a &lt;strong&gt;meta-agent framework&lt;/strong&gt; that uses recursive hierarchical structures to solve complex problems. By breaking down tasks into parallelizable components, ROMA enables agents to tackle sophisticated reasoning challenges while maintaining transparency that makes context-engineering and iteration straightforward. The framework offers &lt;strong&gt;parallel problem solving&lt;/strong&gt; where agents work simultaneously on different parts of complex tasks, &lt;strong&gt;transparent development&lt;/strong&gt; with a clear structure for easy debugging, and &lt;strong&gt;proven performance&lt;/strong&gt; demonstrated through our search agent's strong benchmark results. We've shown the framework's effectiveness, but this is just the beginning. As an &lt;strong&gt;open-source and extensible&lt;/strong&gt; platform, ROMA is designed for community-driven development, allowing you to build and customize agents for your specific needs while benefiting from the collective improvements of the community.&lt;/p&gt; 
&lt;h2&gt;ğŸ—ï¸ How It Works&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;ROMA&lt;/strong&gt; framework processes tasks through a recursive &lt;strong&gt;planâ€“execute loop&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;def solve(task):
    if is_atomic(task):                 # Step 1: Atomizer
        return execute(task)            # Step 2: Executor
    else:
        subtasks = plan(task)           # Step 2: Planner
        results = []
        for subtask in subtasks:
            results.append(solve(subtask))  # Recursive call
        return aggregate(results)       # Step 3: Aggregator

# Entry point:
answer = solve(initial_request)
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Atomizer&lt;/strong&gt; â€“ Decides whether a request is &lt;strong&gt;atomic&lt;/strong&gt; (directly executable) or requires &lt;strong&gt;planning&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Planner&lt;/strong&gt; â€“ If planning is needed, the task is broken into smaller &lt;strong&gt;subtasks&lt;/strong&gt;. Each subtask is fed back into the &lt;strong&gt;Atomizer&lt;/strong&gt;, making the process recursive.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Executors&lt;/strong&gt; â€“ Handle atomic tasks. Executors can be &lt;strong&gt;LLMs, APIs, or even other agents&lt;/strong&gt; â€” as long as they implement an &lt;code&gt;agent.execute()&lt;/code&gt; interface.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Aggregator&lt;/strong&gt; â€“ Collects and integrates results from subtasks. Importantly, the Aggregator produces the &lt;strong&gt;answer to the original parent task&lt;/strong&gt;, not just raw child outputs.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h4&gt;ğŸ“ Information Flow&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Top-down:&lt;/strong&gt; Tasks are decomposed into subtasks recursively.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Bottom-up:&lt;/strong&gt; Subtask results are aggregated upwards into solutions for parent tasks.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Left-to-right:&lt;/strong&gt; If a subtask depends on the output of a previous one, it waits until that subtask completes before execution.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;This structure makes the system flexible, recursive, and dependency-aware â€” capable of decomposing complex problems into smaller steps while ensuring results are integrated coherently.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Click to view the system flow diagram&lt;/summary&gt; 
 &lt;pre&gt;&lt;code class="language-mermaid"&gt;flowchart TB
    A[Your Request] --&amp;gt; B{Atomizer}
    B --&amp;gt;|Plan Needed| C[Planner]
    B --&amp;gt;|Atomic Task| D[Executor]

    %% Planner spawns subtasks
    C --&amp;gt; E[Subtasks]
    E --&amp;gt; G[Aggregator]

    %% Recursion
    E -.-&amp;gt; B  

    %% Execution + Aggregation
    D --&amp;gt; F[Final Result]
    G --&amp;gt; F

    style A fill:#e1f5fe
    style F fill:#c8e6c9
    style B fill:#fff3e0
    style C fill:#ffe0b2
    style D fill:#d1c4e9
    style G fill:#c5cae9

&lt;/code&gt;&lt;/pre&gt; 
&lt;/details&gt;
&lt;br /&gt; 
&lt;h3&gt;ğŸš€ 30-Second Quick Start&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/sentient-agi/ROMA.git
cd ROMA

# Run the automated setup
./setup.sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Choose between:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker Setup&lt;/strong&gt; (Recommended) - One-command setup with isolation&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Native Setup&lt;/strong&gt; - Direct installation for development&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ› ï¸ Technical Stack&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework&lt;/strong&gt;: Built on &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/%5Bhttps://github.com/your/agnoagents%5D(https://github.com/agno-agi/agno)"&gt;AgnoAgents&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Backend&lt;/strong&gt;: Python 3.12+ with FastAPI/Flask&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Frontend&lt;/strong&gt;: React + TypeScript with real-time WebSocket&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;LLM Support&lt;/strong&gt;: Any provider via LiteLLM&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Data Persistence&lt;/strong&gt;: Enterprise S3 mounting with security validation 
  &lt;ul&gt; 
   &lt;li&gt;ğŸ”’ &lt;strong&gt;goofys FUSE mounting&lt;/strong&gt; for zero-latency file access&lt;/li&gt; 
   &lt;li&gt;ğŸ›¡ï¸ &lt;strong&gt;Path injection protection&lt;/strong&gt; with comprehensive validation&lt;/li&gt; 
   &lt;li&gt;ğŸ” &lt;strong&gt;AWS credentials verification&lt;/strong&gt; before operations&lt;/li&gt; 
   &lt;li&gt;ğŸ“ &lt;strong&gt;Dynamic Docker Compose&lt;/strong&gt; with secure volume mounting&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Code Execution&lt;/strong&gt;: E2B sandboxes with unified S3 integration&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: Production-grade validation and error handling&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Features&lt;/strong&gt;: Multi-modal, tools, MCP, hooks, caching&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“¦ Installation Options&lt;/h2&gt; 
&lt;h3&gt;Quick Start (Recommended)&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Main setup (choose Docker or Native)
./setup.sh

# Optional: Setup E2B sandbox integration
./setup.sh --e2b

# Test E2B integration  
./setup.sh --test-e2b
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Command Line Options&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;./setup.sh --docker     # Run Docker setup directly
./setup.sh --docker-from-scratch  # Rebuild Docker images/containers from scratch (down -v, no cache)
./setup.sh --native     # Run native setup directly (macOS/Ubuntu/Debian)
./setup.sh --e2b        # Setup E2B template (requires E2B_API_KEY + AWS creds)
./setup.sh --test-e2b   # Test E2B template integration
./setup.sh --help       # Show all available options
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Manual Installation&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/SETUP.md"&gt;setup docs&lt;/a&gt; for detailed instructions.&lt;/p&gt; 
&lt;h3&gt;ğŸ—ï¸ Optional: E2B Sandbox Integration&lt;/h3&gt; 
&lt;p&gt;For secure code execution capabilities, optionally set up E2B sandboxes:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# After main setup, configure E2B (requires E2B_API_KEY and AWS credentials in .env)
./setup.sh --e2b

# Test E2B integration
./setup.sh --test-e2b
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;E2B Features:&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;ğŸ”’ &lt;strong&gt;Secure Code Execution&lt;/strong&gt; - Run untrusted code in isolated sandboxes&lt;/li&gt; 
 &lt;li&gt;â˜ï¸ &lt;strong&gt;S3 Integration&lt;/strong&gt; - Automatic data sync between local and sandbox environments&lt;/li&gt; 
 &lt;li&gt;ğŸš€ &lt;strong&gt;goofys Mounting&lt;/strong&gt; - High-performance S3 filesystem mounting&lt;/li&gt; 
 &lt;li&gt;ğŸ”§ &lt;strong&gt;AWS Credentials&lt;/strong&gt; - Passed securely via Docker build arguments&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ¤– Pre-built Agents&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; These agents are demonstrations built using ROMA's framework through simple vibe-prompting and minimal manual tuning. They showcase how easily you can create high-performance agents with ROMA, rather than being production-final solutions. Our mission is to empower the community to build, share, and get rewarded for creating innovative agent recipes and use-cases.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;ROMA comes with example agents that demonstrate the framework's capabilities:&lt;/p&gt; 
&lt;h3&gt;ğŸ” General Task Solver&lt;/h3&gt; 
&lt;p&gt;A versatile agent powered by ChatGPT Search Preview for handling diverse tasks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Search&lt;/strong&gt;: Leverages OpenAI's latest search capabilities for real-time information&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flexible Planning&lt;/strong&gt;: Adapts task decomposition based on query complexity&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Domain&lt;/strong&gt;: Handles everything from technical questions to creative projects&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Quick Prototyping&lt;/strong&gt;: Perfect for testing ROMA's capabilities without domain-specific setup&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Perfect for: General research, fact-checking, exploratory analysis, quick information gathering&lt;/p&gt; 
&lt;h3&gt;ğŸ”¬ Deep Research Agent&lt;/h3&gt; 
&lt;p&gt;A comprehensive research system that breaks down complex research questions into manageable sub-tasks:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Smart Task Decomposition&lt;/strong&gt;: Automatically splits research topics into search, analysis, and synthesis phases&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Parallel Information Gathering&lt;/strong&gt;: Executes multiple searches simultaneously for faster results&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Source Integration&lt;/strong&gt;: Combines results from web search, Wikipedia, and specialized APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Intelligent Synthesis&lt;/strong&gt;: Aggregates findings into coherent, well-structured reports&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Perfect for: Academic research, market analysis, competitive intelligence, technical documentation&lt;/p&gt; 
&lt;h3&gt;ğŸ’¹ Crypto Analytics Agent&lt;/h3&gt; 
&lt;p&gt;Specialized financial analysis agent with deep blockchain and DeFi expertise:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Real-Time Market Data&lt;/strong&gt;: Integrates with Binance, CoinGecko, and DefiLlama APIs&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;On-Chain Analytics&lt;/strong&gt;: Access to Arkham Intelligence for wallet tracking and token flows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Technical Analysis&lt;/strong&gt;: Advanced charting with OHLC data and market indicators&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DeFi Metrics&lt;/strong&gt;: TVL tracking, yield analysis, protocol comparisons&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Secure Execution&lt;/strong&gt;: Runs analysis in E2B sandboxes with data persistence&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Perfect for: Token research, portfolio analysis, DeFi protocol evaluation, market trend analysis&lt;/p&gt; 
&lt;p&gt;All three agents demonstrate ROMA's recursive architecture in action, showing how complex queries that would overwhelm single-pass systems can be elegantly decomposed and solved. They serve as templates and inspiration for building your own specialized agents.&lt;/p&gt; 
&lt;h3&gt;Your First Agent in 5 Minutes&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;./setup.sh  # Automated setup with Docker or native installation
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Access all the pre-defined agents through the frontend on &lt;code&gt;localhost:3000&lt;/code&gt; after setting up the backend on &lt;code&gt;localhost:5000&lt;/code&gt;. Please checkout &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/SETUP.md"&gt;Setup&lt;/a&gt; and the &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/docs/AGENTS_GUIDE.md"&gt;Agents guide&lt;/a&gt; to get started!&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/agent_customization.png" alt="alt text" width="60%" /&gt; 
&lt;/div&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;# Your first agent in 3 lines
from sentientresearchagent import SentientAgent

agent = SentientAgent.create()
result = await agent.run("Create a podcast about AI safety")
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸ“Š Benchmarks&lt;/h2&gt; 
&lt;p&gt;We evaluate our simple implementation of a search system using ROMA, called ROMA-Search across three benchmarks: &lt;strong&gt;SEAL-0&lt;/strong&gt;, &lt;strong&gt;FRAMES&lt;/strong&gt;, and &lt;strong&gt;SimpleQA&lt;/strong&gt;.&lt;br /&gt; Below are the performance graphs for each benchmark.&lt;/p&gt; 
&lt;h3&gt;&lt;a href="https://huggingface.co/datasets/vtllms/sealqa"&gt;SEAL-0&lt;/a&gt;&lt;/h3&gt; 
&lt;p&gt;SealQA is a new challenging benchmark for evaluating Search-Augmented Language models on fact-seeking questions where web search yields conflicting, noisy, or unhelpful results.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/seal-0-full.001.jpeg" alt="SEAL-0 Results" /&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;&lt;a href="https://huggingface.co/datasets/google/frames-benchmark"&gt;FRAMES&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;View full results&lt;/summary&gt; 
 &lt;p&gt;A comprehensive evaluation dataset designed to test the capabilities of Retrieval-Augmented Generation (RAG) systems across factuality, retrieval accuracy, and reasoning.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/FRAMES-full.001.jpeg" alt="FRAMES Results" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;hr /&gt; 
&lt;h3&gt;&lt;a href="https://openai.com/index/introducing-simpleqa/"&gt;SimpleQA&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;View full results&lt;/summary&gt; 
 &lt;p&gt;Factuality benchmark that measures the ability for language models to answer short, fact-seeking questions.&lt;/p&gt; 
 &lt;p&gt;&lt;img src="https://raw.githubusercontent.com/sentient-agi/ROMA/main/assets/simpleQAFull.001.jpeg" alt="SimpleQA Results" /&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;âœ¨ Features&lt;/h2&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;ğŸ”„ &lt;strong&gt;Recursive Task Decomposition&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;Automatically breaks down complex tasks into manageable subtasks with intelligent dependency management. Runs independent sub-tasks in &lt;strong&gt;parallel&lt;/strong&gt;.&lt;/p&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;ğŸ¤– &lt;strong&gt;Agent Agnostic&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;Works with any provider (OpenAI, Anthropic, Google, local models) through unified interface, as long as it has an &lt;code&gt;agent.run()&lt;/code&gt; command, then you can use it!&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;ğŸ” &lt;strong&gt;Complete Transparency&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;Stage tracing shows exactly what happens at each step - debug and optimize with full visibility&lt;/p&gt; &lt;/td&gt; 
   &lt;td width="50%"&gt; &lt;h3&gt;ğŸ”Œ Connect Any Tool&lt;/h3&gt; &lt;p&gt;Seamlessly integrate external tools and protocols with configurable intervention points. Already includes production-grade connectors such as E2B, file-read-write, and more.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;ğŸ™ Acknowledgments&lt;/h2&gt; 
&lt;p&gt;This framework would not have been possible if it wasn't for these amazing open-source contributions!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Inspired by the hierarchical planning approach described in &lt;a href="https://arxiv.org/abs/2503.08275"&gt;"Beyond Outlining: Heterogeneous Recursive Planning"&lt;/a&gt; by Xiong et al.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/pydantic/pydantic"&gt;Pydantic&lt;/a&gt; - Data validation using Python type annotations&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/%5Bhttps://github.com/agno-ai/agno%5D(https://github.com/agno-agi/agno)"&gt;Agno&lt;/a&gt; - Framework for building AI agents&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/e2b-dev/e2b"&gt;E2B&lt;/a&gt; - Cloud runtime for AI agents&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ğŸ“š Citation&lt;/h2&gt; 
&lt;p&gt;If you use the ROMA repo in your research, please cite:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bibtex"&gt;@software{al_zubi_2025_17052592,
  author       = {Al-Zubi, Salah and
                  Nama, Baran and
                  Kaz, Arda and
                  Oh, Sewoong},
  title        = {SentientResearchAgent: A Hierarchical AI Agent
                   Framework for Research and Analysis
                  },
  month        = sep,
  year         = 2025,
  publisher    = {Zenodo},
  version      = {ROMA},
  doi          = {10.5281/zenodo.17052592},
  url          = {https://doi.org/10.5281/zenodo.17052592},
  swhid        = {swh:1:dir:69cd1552103e0333dd0c39fc4f53cb03196017ce
                   ;origin=https://doi.org/10.5281/zenodo.17052591;vi
                   sit=swh:1:snp:f50bf99634f9876adb80c027361aec9dff97
                   3433;anchor=swh:1:rel:afa7caa843ce1279f5b4b29b5d3d
                   5e3fe85edc95;path=salzubi401-ROMA-b31c382
                  },
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;ğŸŒŸ Star History&lt;/h2&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;a href="https://www.star-history.com/#sentient-agi/roma&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=sentient-agi/roma&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;ğŸ“„ License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the Apache 2.0 License - see the &lt;a href="https://raw.githubusercontent.com/sentient-agi/ROMA/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>microsoft/markitdown</title>
      <link>https://github.com/microsoft/markitdown</link>
      <description>&lt;p&gt;Python tool for converting files and office documents to Markdown.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MarkItDown&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://pypi.org/project/markitdown/"&gt;&lt;img src="https://img.shields.io/pypi/v/markitdown.svg?sanitize=true" alt="PyPI" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/pypi/dd/markitdown" alt="PyPI - Downloads" /&gt; &lt;a href="https://github.com/microsoft/autogen"&gt;&lt;img src="https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue" alt="Built by AutoGen Team" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See &lt;a href="https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp"&gt;markitdown-mcp&lt;/a&gt; for more information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT] Breaking changes between 0.0.1 to 0.1.0:&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;Dependencies are now organized into optional feature-groups (further details below). Use &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt; to have backward-compatible behavior.&lt;/li&gt; 
  &lt;li&gt;convert_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.&lt;/li&gt; 
  &lt;li&gt;The DocumentConverter class interface has changed to read from file-like streams rather than file paths. &lt;em&gt;No temporary files are created anymore&lt;/em&gt;. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to &lt;a href="https://github.com/deanmalmgren/textract"&gt;textract&lt;/a&gt;, but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.&lt;/p&gt; 
&lt;p&gt;MarkItDown currently supports the conversion from:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;PDF&lt;/li&gt; 
 &lt;li&gt;PowerPoint&lt;/li&gt; 
 &lt;li&gt;Word&lt;/li&gt; 
 &lt;li&gt;Excel&lt;/li&gt; 
 &lt;li&gt;Images (EXIF metadata and OCR)&lt;/li&gt; 
 &lt;li&gt;Audio (EXIF metadata and speech transcription)&lt;/li&gt; 
 &lt;li&gt;HTML&lt;/li&gt; 
 &lt;li&gt;Text-based formats (CSV, JSON, XML)&lt;/li&gt; 
 &lt;li&gt;ZIP files (iterates over contents)&lt;/li&gt; 
 &lt;li&gt;Youtube URLs&lt;/li&gt; 
 &lt;li&gt;EPubs&lt;/li&gt; 
 &lt;li&gt;... and more!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Why Markdown?&lt;/h2&gt; 
&lt;p&gt;Markdown is extremely close to plain text, with minimal markup or formatting, but still provides a way to represent important document structure. Mainstream LLMs, such as OpenAI's GPT-4o, natively "&lt;em&gt;speak&lt;/em&gt;" Markdown, and often incorporate Markdown into their responses unprompted. This suggests that they have been trained on vast amounts of Markdown-formatted text, and understand it well. As a side benefit, Markdown conventions are also highly token-efficient.&lt;/p&gt; 
&lt;h2&gt;Prerequisites&lt;/h2&gt; 
&lt;p&gt;MarkItDown requires Python 3.10 or higher. It is recommended to use a virtual environment to avoid dependency conflicts.&lt;/p&gt; 
&lt;p&gt;With the standard Python installation, you can create and activate a virtual environment using the following commands:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;python -m venv .venv
source .venv/bin/activate
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If using &lt;code&gt;uv&lt;/code&gt;, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;uv venv --python=3.12 .venv
source .venv/bin/activate
# NOTE: Be sure to use 'uv pip install' rather than just 'pip install' to install packages in this virtual environment
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you are using Anaconda, you can create a virtual environment with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;conda create -n markitdown python=3.12
conda activate markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;To install MarkItDown, use pip: &lt;code&gt;pip install 'markitdown[all]'&lt;/code&gt;. Alternatively, you can install it from the source:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone git@github.com:microsoft/markitdown.git
cd markitdown
pip install -e 'packages/markitdown[all]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Usage&lt;/h2&gt; 
&lt;h3&gt;Command-Line&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf &amp;gt; document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or use &lt;code&gt;-o&lt;/code&gt; to specify the output file:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also pipe content:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cat path-to-file.pdf | markitdown
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Optional Dependencies&lt;/h3&gt; 
&lt;p&gt;MarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the &lt;code&gt;[all]&lt;/code&gt; option. However, you can also install them individually for more control. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;pip install 'markitdown[pdf, docx, pptx]'
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;will install only the dependencies for PDF, DOCX, and PPTX files.&lt;/p&gt; 
&lt;p&gt;At the moment, the following optional dependencies are available:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;[all]&lt;/code&gt; Installs all optional dependencies&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pptx]&lt;/code&gt; Installs dependencies for PowerPoint files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[docx]&lt;/code&gt; Installs dependencies for Word files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xlsx]&lt;/code&gt; Installs dependencies for Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[xls]&lt;/code&gt; Installs dependencies for older Excel files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[pdf]&lt;/code&gt; Installs dependencies for PDF files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[outlook]&lt;/code&gt; Installs dependencies for Outlook messages&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[az-doc-intel]&lt;/code&gt; Installs dependencies for Azure Document Intelligence&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[audio-transcription]&lt;/code&gt; Installs dependencies for audio transcription of wav and mp3 files&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;[youtube-transcription]&lt;/code&gt; Installs dependencies for fetching YouTube video transcription&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Plugins&lt;/h3&gt; 
&lt;p&gt;MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --list-plugins
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To enable plugins use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown --use-plugins path-to-file.pdf
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To find available plugins, search GitHub for the hashtag &lt;code&gt;#markitdown-plugin&lt;/code&gt;. To develop a plugin, see &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Azure Document Intelligence&lt;/h3&gt; 
&lt;p&gt;To use Microsoft Document Intelligence for conversion:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;markitdown path-to-file.pdf -o document.md -d -e "&amp;lt;document_intelligence_endpoint&amp;gt;"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;More information about how to set up an Azure Document Intelligence Resource can be found &lt;a href="https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0"&gt;here&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Python API&lt;/h3&gt; 
&lt;p&gt;Basic usage in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
result = md.convert("test.xlsx")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Document Intelligence conversion in Python:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown

md = MarkItDown(docintel_endpoint="&amp;lt;document_intelligence_endpoint&amp;gt;")
result = md.convert("test.pdf")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To use Large Language Models for image descriptions (currently only for pptx and image files), provide &lt;code&gt;llm_client&lt;/code&gt; and &lt;code&gt;llm_model&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from markitdown import MarkItDown
from openai import OpenAI

client = OpenAI()
md = MarkItDown(llm_client=client, llm_model="gpt-4o", llm_prompt="optional custom prompt")
result = md.convert("example.jpg")
print(result.text_content)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docker&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;docker build -t markitdown:latest .
docker run --rm -i markitdown:latest &amp;lt; ~/your-file.pdf &amp;gt; output.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit &lt;a href="https://cla.opensource.microsoft.com"&gt;https://cla.opensource.microsoft.com&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.&lt;/p&gt; 
&lt;p&gt;This project has adopted the &lt;a href="https://opensource.microsoft.com/codeofconduct/"&gt;Microsoft Open Source Code of Conduct&lt;/a&gt;. For more information see the &lt;a href="https://opensource.microsoft.com/codeofconduct/faq/"&gt;Code of Conduct FAQ&lt;/a&gt; or contact &lt;a href="mailto:opencode@microsoft.com"&gt;opencode@microsoft.com&lt;/a&gt; with any additional questions or comments.&lt;/p&gt; 
&lt;h3&gt;How to Contribute&lt;/h3&gt; 
&lt;p&gt;You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as 'open for contribution' and 'open for reviewing' to help facilitate community contributions. These are of course just suggestions and you are welcome to contribute in any way you like.&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;&lt;/th&gt; 
    &lt;th&gt;All&lt;/th&gt; 
    &lt;th&gt;Especially Needs Help from Community&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues"&gt;All Issues&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22"&gt;Issues open for contribution&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;strong&gt;PRs&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls"&gt;All PRs&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;a href="https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22"&gt;PRs open for reviewing&lt;/a&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/div&gt; 
&lt;h3&gt;Running Tests and Checks&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;Navigate to the MarkItDown package:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;cd packages/markitdown
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Install &lt;code&gt;hatch&lt;/code&gt; in your environment and run tests:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
hatch shell
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;(Alternative) Use the Devcontainer which has all the dependencies installed:&lt;/p&gt; &lt;pre&gt;&lt;code class="language-sh"&gt;# Reopen the project in Devcontainer and run:
hatch test
&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Run pre-commit checks before submitting a PR: &lt;code&gt;pre-commit run --all-files&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Contributing 3rd-party Plugins&lt;/h3&gt; 
&lt;p&gt;You can also contribute by creating and sharing 3rd party plugins. See &lt;code&gt;packages/markitdown-sample-plugin&lt;/code&gt; for more details.&lt;/p&gt; 
&lt;h2&gt;Trademarks&lt;/h2&gt; 
&lt;p&gt;This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow &lt;a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general"&gt;Microsoft's Trademark &amp;amp; Brand Guidelines&lt;/a&gt;. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>virattt/ai-hedge-fund</title>
      <link>https://github.com/virattt/ai-hedge-fund</link>
      <description>&lt;p&gt;An AI Hedge Fund Team&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;AI Hedge Fund&lt;/h1&gt; 
&lt;p&gt;This is a proof of concept for an AI-powered hedge fund. The goal of this project is to explore the use of AI to make trading decisions. This project is for &lt;strong&gt;educational&lt;/strong&gt; purposes only and is not intended for real trading or investment.&lt;/p&gt; 
&lt;p&gt;This system employs several agents working together:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation&lt;/li&gt; 
 &lt;li&gt;Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety&lt;/li&gt; 
 &lt;li&gt;Bill Ackman Agent - An activist investor, takes bold positions and pushes for change&lt;/li&gt; 
 &lt;li&gt;Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption&lt;/li&gt; 
 &lt;li&gt;Charlie Munger Agent - Warren Buffett's partner, only buys wonderful businesses at fair prices&lt;/li&gt; 
 &lt;li&gt;Michael Burry Agent - The Big Short contrarian who hunts for deep value&lt;/li&gt; 
 &lt;li&gt;Mohnish Pabrai Agent - The Dhandho investor, who looks for doubles at low risk&lt;/li&gt; 
 &lt;li&gt;Peter Lynch Agent - Practical investor who seeks "ten-baggers" in everyday businesses&lt;/li&gt; 
 &lt;li&gt;Phil Fisher Agent - Meticulous growth investor who uses deep "scuttlebutt" research&lt;/li&gt; 
 &lt;li&gt;Rakesh Jhunjhunwala Agent - The Big Bull of India&lt;/li&gt; 
 &lt;li&gt;Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential&lt;/li&gt; 
 &lt;li&gt;Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price&lt;/li&gt; 
 &lt;li&gt;Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Sentiment Agent - Analyzes market sentiment and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Fundamentals Agent - Analyzes fundamental data and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Technicals Agent - Analyzes technical indicators and generates trading signals&lt;/li&gt; 
 &lt;li&gt;Risk Manager - Calculates risk metrics and sets position limits&lt;/li&gt; 
 &lt;li&gt;Portfolio Manager - Makes final trading decisions and generates orders&lt;/li&gt; 
&lt;/ol&gt; 
&lt;img width="1042" alt="Screenshot 2025-03-22 at 6 19 07 PM" src="https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4" /&gt; 
&lt;p&gt;Note: the system does not actually make any trades.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://twitter.com/virattt"&gt;&lt;img src="https://img.shields.io/twitter/follow/virattt?style=social" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Disclaimer&lt;/h2&gt; 
&lt;p&gt;This project is for &lt;strong&gt;educational and research purposes only&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Not intended for real trading or investment&lt;/li&gt; 
 &lt;li&gt;No investment advice or guarantees provided&lt;/li&gt; 
 &lt;li&gt;Creator assumes no liability for financial losses&lt;/li&gt; 
 &lt;li&gt;Consult a financial advisor for investment decisions&lt;/li&gt; 
 &lt;li&gt;Past performance does not indicate future results&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;By using this software, you agree to use it solely for learning purposes.&lt;/p&gt; 
&lt;h2&gt;Table of Contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-install"&gt;How to Install&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-run"&gt;How to Run&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-command-line-interface"&gt;âŒ¨ï¸ Command Line Interface&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#%EF%B8%8F-web-application"&gt;ğŸ–¥ï¸ Web Application&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#how-to-contribute"&gt;How to Contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#feature-requests"&gt;Feature Requests&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/virattt/ai-hedge-fund/main/#license"&gt;License&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;How to Install&lt;/h2&gt; 
&lt;p&gt;Before you can run the AI Hedge Fund, you'll need to install it and set up your API keys. These steps are common to both the full-stack web application and command line interface.&lt;/p&gt; 
&lt;h3&gt;1. Clone the Repository&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;2. Set up API keys&lt;/h3&gt; 
&lt;p&gt;Create a &lt;code&gt;.env&lt;/code&gt; file for your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Create .env file for your API keys (in the root directory)
cp .env.example .env
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Open and edit the &lt;code&gt;.env&lt;/code&gt; file to add your API keys:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
OPENAI_API_KEY=your-openai-api-key

# For getting financial data to power the hedge fund
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: You must set at least one LLM API key (e.g. &lt;code&gt;OPENAI_API_KEY&lt;/code&gt;, &lt;code&gt;GROQ_API_KEY&lt;/code&gt;, &lt;code&gt;ANTHROPIC_API_KEY&lt;/code&gt;, or &lt;code&gt;DEEPSEEK_API_KEY&lt;/code&gt;) for the hedge fund to work.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Financial Data&lt;/strong&gt;: Data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key. For any other ticker, you will need to set the &lt;code&gt;FINANCIAL_DATASETS_API_KEY&lt;/code&gt; in the .env file.&lt;/p&gt; 
&lt;h2&gt;How to Run&lt;/h2&gt; 
&lt;h3&gt;âŒ¨ï¸ Command Line Interface&lt;/h3&gt; 
&lt;p&gt;You can run the AI Hedge Fund directly via terminal. This approach offers more granular control and is useful for automation, scripting, and integration purposes.&lt;/p&gt; 
&lt;img width="992" alt="Screenshot 2025-01-06 at 5 50 17 PM" src="https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b" /&gt; 
&lt;h4&gt;Quick Start&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;Install Poetry (if not already installed):&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;curl -sSL https://install.python-poetry.org | python3 -
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Install dependencies:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry install
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the AI Hedge Fund&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also specify a &lt;code&gt;--ollama&lt;/code&gt; flag to run the AI hedge fund using local LLMs.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can optionally specify the start and end dates to make decisions over a specific time period.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Run the Backtester&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Example Output:&lt;/strong&gt; &lt;img width="941" alt="Screenshot 2025-01-06 at 5 47 52 PM" src="https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47" /&gt;&lt;/p&gt; 
&lt;p&gt;Note: The &lt;code&gt;--ollama&lt;/code&gt;, &lt;code&gt;--start-date&lt;/code&gt;, and &lt;code&gt;--end-date&lt;/code&gt; flags work for the backtester, as well!&lt;/p&gt; 
&lt;h3&gt;ğŸ–¥ï¸ Web Application&lt;/h3&gt; 
&lt;p&gt;The new way to run the AI Hedge Fund is through our web application that provides a user-friendly interface. This is recommended for users who prefer visual interfaces over command line tools.&lt;/p&gt; 
&lt;p&gt;Please see detailed instructions on how to install and run the web application &lt;a href="https://github.com/virattt/ai-hedge-fund/tree/main/app"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;img width="1721" alt="Screenshot 2025-06-28 at 6 41 03â€¯PM" src="https://github.com/user-attachments/assets/b95ab696-c9f4-416c-9ad1-51feb1f5374b" /&gt; 
&lt;h2&gt;How to Contribute&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a feature branch&lt;/li&gt; 
 &lt;li&gt;Commit your changes&lt;/li&gt; 
 &lt;li&gt;Push to the branch&lt;/li&gt; 
 &lt;li&gt;Create a Pull Request&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: Please keep your pull requests small and focused. This will make it easier to review and merge.&lt;/p&gt; 
&lt;h2&gt;Feature Requests&lt;/h2&gt; 
&lt;p&gt;If you have a feature request, please open an &lt;a href="https://github.com/virattt/ai-hedge-fund/issues"&gt;issue&lt;/a&gt; and make sure it is tagged with &lt;code&gt;enhancement&lt;/code&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the MIT License - see the LICENSE file for details.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ml-explore/mlx-lm</title>
      <link>https://github.com/ml-explore/mlx-lm</link>
      <description>&lt;p&gt;Run LLMs with MLX&lt;/p&gt;&lt;hr&gt;&lt;h2&gt;MLX LM&lt;/h2&gt; 
&lt;p&gt;MLX LM is a Python package for generating text and fine-tuning large language models on Apple silicon with MLX.&lt;/p&gt; 
&lt;p&gt;Some key features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Integration with the Hugging Face Hub to easily use thousands of LLMs with a single command.&lt;/li&gt; 
 &lt;li&gt;Support for quantizing and uploading models to the Hugging Face Hub.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ml-explore/mlx-lm/raw/main/mlx_lm/LORA.md"&gt;Low-rank and full model fine-tuning&lt;/a&gt; with support for quantized models.&lt;/li&gt; 
 &lt;li&gt;Distributed inference and fine-tuning with &lt;code&gt;mx.distributed&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The easiest way to get started is to install the &lt;code&gt;mlx-lm&lt;/code&gt; package:&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;With &lt;code&gt;pip&lt;/code&gt;&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;pip install mlx-lm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;With &lt;code&gt;conda&lt;/code&gt;&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;conda install -c conda-forge mlx-lm
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Quick Start&lt;/h3&gt; 
&lt;p&gt;To generate text with an LLM use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mlx_lm.generate --prompt "How tall is Mt Everest?"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To chat with an LLM use:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mlx_lm.chat
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will give you a chat REPL that you can use to interact with the LLM. The chat context is preserved during the lifetime of the REPL.&lt;/p&gt; 
&lt;p&gt;Commands in &lt;code&gt;mlx-lm&lt;/code&gt; typically take command line options which let you specify the model, sampling parameters, and more. Use &lt;code&gt;-h&lt;/code&gt; to see a list of available options for a command, e.g.:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;mlx_lm.generate -h
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The default model for generation and chat is &lt;code&gt;mlx-community/Llama-3.2-3B-Instruct-4bit&lt;/code&gt;. You can specify any MLX-compatible model with the &lt;code&gt;--model&lt;/code&gt; flag. Thousands are available in the &lt;a href="https://huggingface.co/mlx-community"&gt;MLX Community&lt;/a&gt; Hugging Face organization.&lt;/p&gt; 
&lt;h3&gt;Python API&lt;/h3&gt; 
&lt;p&gt;You can use &lt;code&gt;mlx-lm&lt;/code&gt; as a module:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mlx_lm import load, generate

model, tokenizer = load("mlx-community/Mistral-7B-Instruct-v0.3-4bit")

prompt = "Write a story about Einstein"

messages = [{"role": "user", "content": prompt}]
prompt = tokenizer.apply_chat_template(
    messages, add_generation_prompt=True
)

text = generate(model, tokenizer, prompt=prompt, verbose=True)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To see a description of all the arguments you can do:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; help(generate)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Check out the &lt;a href="https://github.com/ml-explore/mlx-lm/tree/main/mlx_lm/examples/generate_response.py"&gt;generation example&lt;/a&gt; to see how to use the API in more detail. Check out the &lt;a href="https://github.com/ml-explore/mlx-lm/tree/main/mlx_lm/examples/batch_generate_response.py"&gt;batch generation example&lt;/a&gt; to see how to efficiently generate continuations for a batch of prompts.&lt;/p&gt; 
&lt;p&gt;The &lt;code&gt;mlx-lm&lt;/code&gt; package also comes with functionality to quantize and optionally upload models to the Hugging Face Hub.&lt;/p&gt; 
&lt;p&gt;You can convert models using the Python API:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mlx_lm import convert

repo = "mistralai/Mistral-7B-Instruct-v0.3"
upload_repo = "mlx-community/My-Mistral-7B-Instruct-v0.3-4bit"

convert(repo, quantize=True, upload_repo=upload_repo)
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will generate a 4-bit quantized Mistral 7B and upload it to the repo &lt;code&gt;mlx-community/My-Mistral-7B-Instruct-v0.3-4bit&lt;/code&gt;. It will also save the converted model in the path &lt;code&gt;mlx_model&lt;/code&gt; by default.&lt;/p&gt; 
&lt;p&gt;To see a description of all the arguments you can do:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; help(convert)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Streaming&lt;/h4&gt; 
&lt;p&gt;For streaming generation, use the &lt;code&gt;stream_generate&lt;/code&gt; function. This yields a generation response object.&lt;/p&gt; 
&lt;p&gt;For example,&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;from mlx_lm import load, stream_generate

repo = "mlx-community/Mistral-7B-Instruct-v0.3-4bit"
model, tokenizer = load(repo)

prompt = "Write a story about Einstein"

messages = [{"role": "user", "content": prompt}]
prompt = tokenizer.apply_chat_template(
    messages, add_generation_prompt=True
)

for response in stream_generate(model, tokenizer, prompt, max_tokens=512):
    print(response.text, end="", flush=True)
print()
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Sampling&lt;/h4&gt; 
&lt;p&gt;The &lt;code&gt;generate&lt;/code&gt; and &lt;code&gt;stream_generate&lt;/code&gt; functions accept &lt;code&gt;sampler&lt;/code&gt; and &lt;code&gt;logits_processors&lt;/code&gt; keyword arguments. A sampler is any callable which accepts a possibly batched logits array and returns an array of sampled tokens. The &lt;code&gt;logits_processors&lt;/code&gt; must be a list of callables which take the token history and current logits as input and return the processed logits. The logits processors are applied in order.&lt;/p&gt; 
&lt;p&gt;Some standard sampling functions and logits processors are provided in &lt;code&gt;mlx_lm.sample_utils&lt;/code&gt;.&lt;/p&gt; 
&lt;h3&gt;Command Line&lt;/h3&gt; 
&lt;p&gt;You can also use &lt;code&gt;mlx-lm&lt;/code&gt; from the command line with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mlx_lm.generate --model mistralai/Mistral-7B-Instruct-v0.3 --prompt "hello"
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will download a Mistral 7B model from the Hugging Face Hub and generate text using the given prompt.&lt;/p&gt; 
&lt;p&gt;For a full list of options run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mlx_lm.generate --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To quantize a model from the command line run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mlx_lm.convert --hf-path mistralai/Mistral-7B-Instruct-v0.3 -q
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more options run:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mlx_lm.convert --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can upload new models to Hugging Face by specifying &lt;code&gt;--upload-repo&lt;/code&gt; to &lt;code&gt;convert&lt;/code&gt;. For example, to upload a quantized Mistral-7B model to the &lt;a href="https://huggingface.co/mlx-community"&gt;MLX Hugging Face community&lt;/a&gt; you can do:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mlx_lm.convert \
    --hf-path mistralai/Mistral-7B-Instruct-v0.3 \
    -q \
    --upload-repo mlx-community/my-4bit-mistral
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Models can also be converted and quantized directly in the &lt;a href="https://huggingface.co/spaces/mlx-community/mlx-my-repo"&gt;mlx-my-repo&lt;/a&gt; Hugging Face Space.&lt;/p&gt; 
&lt;h3&gt;Long Prompts and Generations&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;mlx-lm&lt;/code&gt; has some tools to scale efficiently to long prompts and generations:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A rotating fixed-size key-value cache.&lt;/li&gt; 
 &lt;li&gt;Prompt caching&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;To use the rotating key-value cache pass the argument &lt;code&gt;--max-kv-size n&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; can be any integer. Smaller values like &lt;code&gt;512&lt;/code&gt; will use very little RAM but result in worse quality. Larger values like &lt;code&gt;4096&lt;/code&gt; or higher will use more RAM but have better quality.&lt;/p&gt; 
&lt;p&gt;Caching prompts can substantially speedup reusing the same long context with different queries. To cache a prompt use &lt;code&gt;mlx_lm.cache_prompt&lt;/code&gt;. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;cat prompt.txt | mlx_lm.cache_prompt \
  --model mistralai/Mistral-7B-Instruct-v0.3 \
  --prompt - \
  --prompt-cache-file mistral_prompt.safetensors
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then use the cached prompt with &lt;code&gt;mlx_lm.generate&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;mlx_lm.generate \
    --prompt-cache-file mistral_prompt.safetensors \
    --prompt "\nSummarize the above text."
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The cached prompt is treated as a prefix to the supplied prompt. Also notice when using a cached prompt, the model to use is read from the cache and need not be supplied explicitly.&lt;/p&gt; 
&lt;p&gt;Prompt caching can also be used in the Python API in order to avoid recomputing the prompt. This is useful in multi-turn dialogues or across requests that use the same context. See the &lt;a href="https://github.com/ml-explore/mlx-lm/raw/main/mlx_lm/examples/chat.py"&gt;example&lt;/a&gt; for more usage details.&lt;/p&gt; 
&lt;h3&gt;Supported Models&lt;/h3&gt; 
&lt;p&gt;&lt;code&gt;mlx-lm&lt;/code&gt; supports thousands of Hugging Face format LLMs. If the model you want to run is not supported, file an &lt;a href="https://github.com/ml-explore/mlx-lm/issues/new"&gt;issue&lt;/a&gt; or better yet, submit a pull request.&lt;/p&gt; 
&lt;p&gt;Here are a few examples of Hugging Face models that work with this example:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/mistralai/Mistral-7B-v0.1"&gt;mistralai/Mistral-7B-v0.1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/meta-llama/Llama-2-7b-hf"&gt;meta-llama/Llama-2-7b-hf&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct"&gt;deepseek-ai/deepseek-coder-6.7b-instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/01-ai/Yi-6B-Chat"&gt;01-ai/Yi-6B-Chat&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/microsoft/phi-2"&gt;microsoft/phi-2&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1"&gt;mistralai/Mixtral-8x7B-Instruct-v0.1&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/Qwen/Qwen-7B"&gt;Qwen/Qwen-7B&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/pfnet/plamo-13b"&gt;pfnet/plamo-13b&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/pfnet/plamo-13b-instruct"&gt;pfnet/plamo-13b-instruct&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/stabilityai/stablelm-2-zephyr-1_6b"&gt;stabilityai/stablelm-2-zephyr-1_6b&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/internlm/internlm2-7b"&gt;internlm/internlm2-7b&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://huggingface.co/tiiuae/falcon-mamba-7b-instruct"&gt;tiiuae/falcon-mamba-7b-instruct&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Most &lt;a href="https://huggingface.co/models?library=transformers,safetensors&amp;amp;other=mistral&amp;amp;sort=trending"&gt;Mistral&lt;/a&gt;, &lt;a href="https://huggingface.co/models?library=transformers,safetensors&amp;amp;other=llama&amp;amp;sort=trending"&gt;Llama&lt;/a&gt;, &lt;a href="https://huggingface.co/models?library=transformers,safetensors&amp;amp;other=phi&amp;amp;sort=trending"&gt;Phi-2&lt;/a&gt;, and &lt;a href="https://huggingface.co/models?library=transformers,safetensors&amp;amp;other=mixtral&amp;amp;sort=trending"&gt;Mixtral&lt;/a&gt; style models should work out of the box.&lt;/p&gt; 
&lt;p&gt;For some models (such as &lt;code&gt;Qwen&lt;/code&gt; and &lt;code&gt;plamo&lt;/code&gt;) the tokenizer requires you to enable the &lt;code&gt;trust_remote_code&lt;/code&gt; option. You can do this by passing &lt;code&gt;--trust-remote-code&lt;/code&gt; in the command line. If you don't specify the flag explicitly, you will be prompted to trust remote code in the terminal when running the model.&lt;/p&gt; 
&lt;p&gt;For &lt;code&gt;Qwen&lt;/code&gt; models you must also specify the &lt;code&gt;eos_token&lt;/code&gt;. You can do this by passing &lt;code&gt;--eos-token "&amp;lt;|endoftext|&amp;gt;"&lt;/code&gt; in the command line.&lt;/p&gt; 
&lt;p&gt;These options can also be set in the Python API. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-python"&gt;model, tokenizer = load(
    "qwen/Qwen-7B",
    tokenizer_config={"eos_token": "&amp;lt;|endoftext|&amp;gt;", "trust_remote_code": True},
)
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Large Models&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] This requires macOS 15.0 or higher to work.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Models which are large relative to the total RAM available on the machine can be slow. &lt;code&gt;mlx-lm&lt;/code&gt; will attempt to make them faster by wiring the memory occupied by the model and cache. This requires macOS 15 or higher to work.&lt;/p&gt; 
&lt;p&gt;If you see the following warning message:&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[WARNING] Generating with a model that requires ...&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;then the model will likely be slow on the given machine. If the model fits in RAM then it can often be sped up by increasing the system wired memory limit. To increase the limit, set the following &lt;code&gt;sysctl&lt;/code&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;sudo sysctl iogpu.wired_limit_mb=N
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;The value &lt;code&gt;N&lt;/code&gt; should be larger than the size of the model in megabytes but smaller than the memory size of the machine.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>modelcontextprotocol/registry</title>
      <link>https://github.com/modelcontextprotocol/registry</link>
      <description>&lt;p&gt;A community driven registry service for Model Context Protocol (MCP) servers.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;MCP Registry&lt;/h1&gt; 
&lt;p&gt;The MCP registry provides MCP clients with a list of MCP servers, like an app store for MCP servers.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docs/guides/publishing/publish-server.md"&gt;&lt;strong&gt;ğŸ“¤ Publish my MCP server&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://registry.modelcontextprotocol.io/docs"&gt;&lt;strong&gt;âš¡ï¸ Live API docs&lt;/strong&gt;&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docs/explanations/ecosystem-vision.md"&gt;&lt;strong&gt;ğŸ‘€ Ecosystem vision&lt;/strong&gt;&lt;/a&gt; | ğŸ“– &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docs"&gt;Full documentation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;h2&gt;Development Status&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;2025-09-08 update&lt;/strong&gt;: The registry has launched in preview ğŸ‰ (&lt;a href="https://blog.modelcontextprotocol.io/posts/2025-09-08-mcp-registry-preview/"&gt;announcement blog post&lt;/a&gt;). While the system is now more stable, this is still a preview release and breaking changes or data resets may occur. A general availability (GA) release will follow later. We'd love your feedback in &lt;a href="https://github.com/modelcontextprotocol/registry/discussions/new?category=ideas"&gt;GitHub discussions&lt;/a&gt; or in the &lt;a href="https://discord.com/channels/1358869848138059966/1369487942862504016"&gt;#registry-dev Discord&lt;/a&gt; (&lt;a href="https://modelcontextprotocol.io/community/communication"&gt;joining details here&lt;/a&gt;).&lt;/p&gt; 
&lt;p&gt;Current key maintainers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Adam Jones&lt;/strong&gt; (Anthropic) &lt;a href="https://github.com/domdomegg"&gt;@domdomegg&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Tadas Antanavicius&lt;/strong&gt; (PulseMCP) &lt;a href="https://github.com/tadasant"&gt;@tadasant&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Toby Padilla&lt;/strong&gt; (GitHub) &lt;a href="https://github.com/toby"&gt;@toby&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We use multiple channels for collaboration - see &lt;a href="https://modelcontextprotocol.io/community/communication"&gt;modelcontextprotocol.io/community/communication&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Often (but not always) ideas flow through this pipeline:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://modelcontextprotocol.io/community/communication"&gt;Discord&lt;/a&gt;&lt;/strong&gt; - Real-time community discussions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/modelcontextprotocol/registry/discussions"&gt;Discussions&lt;/a&gt;&lt;/strong&gt; - Propose and discuss product/technical requirements&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/modelcontextprotocol/registry/issues"&gt;Issues&lt;/a&gt;&lt;/strong&gt; - Track well-scoped technical work&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/modelcontextprotocol/registry/pulls"&gt;Pull Requests&lt;/a&gt;&lt;/strong&gt; - Contribute work towards issues&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Quick start:&lt;/h3&gt; 
&lt;h4&gt;Pre-requisites&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Go 1.24.x&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;golangci-lint v2.4.0&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Running the server&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Start full development environment
make dev-compose
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This starts the registry at &lt;a href="http://localhost:8080"&gt;&lt;code&gt;localhost:8080&lt;/code&gt;&lt;/a&gt; with PostgreSQL and seed data. It can be configured with environment variables in &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docker-compose.yml"&gt;docker-compose.yml&lt;/a&gt; - see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/.env.example"&gt;.env.example&lt;/a&gt; for a reference.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;Alternative: Local setup without Docker&lt;/summary&gt; 
 &lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;PostgreSQL running locally&lt;/li&gt; 
  &lt;li&gt;Go 1.24.x installed&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Build and run locally
make build
make dev-local
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The service runs on &lt;a href="http://localhost:8080"&gt;&lt;code&gt;localhost:8080&lt;/code&gt;&lt;/a&gt; by default. This can be configured with environment variables in &lt;code&gt;.env&lt;/code&gt; - see &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/.env.example"&gt;.env.example&lt;/a&gt; for a reference.&lt;/p&gt; 
&lt;/details&gt; 
&lt;details&gt; 
 &lt;summary&gt;Alternative: Running a pre-built Docker image&lt;/summary&gt; 
 &lt;p&gt;Pre-built Docker images are automatically published to GitHub Container Registry:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Run latest stable release
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:latest

# Run latest from main branch (continuous deployment)
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:main

# Run specific release version
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:v1.0.0

# Run development build from main branch
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:main-20250906-abc123d
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;&lt;strong&gt;Available tags:&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;Releases&lt;/strong&gt;: &lt;code&gt;latest&lt;/code&gt;, &lt;code&gt;v1.0.0&lt;/code&gt;, &lt;code&gt;v1.1.0&lt;/code&gt;, etc.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Continuous&lt;/strong&gt;: &lt;code&gt;main&lt;/code&gt; (latest main branch build)&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Development&lt;/strong&gt;: &lt;code&gt;main-&amp;lt;date&amp;gt;-&amp;lt;sha&amp;gt;&lt;/code&gt; (specific commit builds)&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h4&gt;Publishing a server&lt;/h4&gt; 
&lt;p&gt;To publish a server, we've built a simple CLI. You can use it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Build the latest CLI
make publisher

# Use it!
./bin/mcp-publisher --help
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docs/guides/publishing/publish-server.md"&gt;the publisher guide&lt;/a&gt; for more details.&lt;/p&gt; 
&lt;h4&gt;Other commands&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Run lint, unit tests and integration tests
make check
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are also a few more helpful commands for development. Run &lt;code&gt;make help&lt;/code&gt; to learn more, or look in &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/Makefile"&gt;Makefile&lt;/a&gt;.&lt;/p&gt; 
&lt;!--
For Claude and other AI tools: Always prefer make targets over custom commands where possible.
--&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;h3&gt;Project Structure&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;â”œâ”€â”€ cmd/                     # Application entry points
â”‚   â””â”€â”€ publisher/           # Server publishing tool
â”œâ”€â”€ data/                    # Seed data
â”œâ”€â”€ deploy/                  # Deployment configuration (Pulumi)
â”œâ”€â”€ docs/                    # Documentation
â”œâ”€â”€ internal/                # Private application code
â”‚   â”œâ”€â”€ api/                 # HTTP handlers and routing
â”‚   â”œâ”€â”€ auth/                # Authentication (GitHub OAuth, JWT, namespace blocking)
â”‚   â”œâ”€â”€ config/              # Configuration management
â”‚   â”œâ”€â”€ database/            # Data persistence (PostgreSQL, in-memory)
â”‚   â”œâ”€â”€ service/             # Business logic
â”‚   â”œâ”€â”€ telemetry/           # Metrics and monitoring
â”‚   â””â”€â”€ validators/          # Input validation
â”œâ”€â”€ pkg/                     # Public packages
â”‚   â”œâ”€â”€ api/                 # API types and structures
â”‚   â”‚   â””â”€â”€ v0/              # Version 0 API types
â”‚   â””â”€â”€ model/               # Data models for server.json
â”œâ”€â”€ scripts/                 # Development and testing scripts
â”œâ”€â”€ tests/                   # Integration tests
â””â”€â”€ tools/                   # CLI tools and utilities
    â””â”€â”€ validate-*.sh        # Schema validation tools
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Authentication&lt;/h3&gt; 
&lt;p&gt;Publishing supports multiple authentication methods:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub OAuth&lt;/strong&gt; - For publishing by logging into GitHub&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;GitHub OIDC&lt;/strong&gt; - For publishing from GitHub Actions&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;DNS verification&lt;/strong&gt; - For proving ownership of a domain and its subdomains&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;HTTP verification&lt;/strong&gt; - For proving ownership of a domain&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The registry validates namespace ownership when publishing. E.g. to publish...:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;io.github.domdomegg/my-cool-mcp&lt;/code&gt; you must login to GitHub as &lt;code&gt;domdomegg&lt;/code&gt;, or be in a GitHub Action on domdomegg's repos&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;me.adamjones/my-cool-mcp&lt;/code&gt; you must prove ownership of &lt;code&gt;adamjones.me&lt;/code&gt; via DNS or HTTP challenge&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;More documentation&lt;/h2&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/modelcontextprotocol/registry/main/docs"&gt;documentation&lt;/a&gt; for more details if your question has not been answered here!&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>