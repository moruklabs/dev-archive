<rss version="2.0">
  <channel>
    <title>GitHub JavaScript Daily Trending</title>
    <description>Daily Trending of JavaScript in GitHub</description>
    <pubDate>Mon, 01 Sep 2025 01:35:39 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>GitSquared/edex-ui</title>
      <link>https://github.com/GitSquared/edex-ui</link>
      <description>&lt;p&gt;A cross-platform, customizable science fiction terminal emulator with advanced monitoring &amp; touchscreen support.&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;br /&gt; &lt;img alt="Logo" src="https://raw.githubusercontent.com/GitSquared/edex-ui/master/media/logo.png" /&gt; &lt;br /&gt;&lt;br /&gt; &lt;a href="https://lgtm.com/projects/g/GitSquared/edex-ui/context:javascript"&gt;&lt;img alt="undefined" src="https://img.shields.io/lgtm/grade/javascript/g/GitSquared/edex-ui.svg?logo=lgtm&amp;amp;logoWidth=18" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/GitSquared/edex-ui/releases/latest"&gt;&lt;img alt="undefined" src="https://img.shields.io/github/release/GitSquared/edex-ui.svg?style=popout" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/GitSquared/edex-ui/master/#featured-in"&gt;&lt;img alt="undefined" src="https://img.shields.io/github/downloads/GitSquared/edex-ui/total.svg?style=popout" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GitSquared/edex-ui/raw/master/LICENSE"&gt;&lt;img alt="undefined" src="https://img.shields.io/github/license/GitSquared/edex-ui.svg?style=popout" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/GitSquared/edex-ui/releases/download/v2.2.8/eDEX-UI-Windows.exe" target="_blank"&gt;&lt;img alt="undefined" src="https://badgen.net/badge/Download/Windows/?color=blue&amp;amp;icon=windows&amp;amp;label" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GitSquared/edex-ui/releases/download/v2.2.8/eDEX-UI-macOS.dmg" target="_blank"&gt;&lt;img alt="undefined" src="https://badgen.net/badge/Download/macOS/?color=grey&amp;amp;icon=apple&amp;amp;label" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GitSquared/edex-ui/releases/download/v2.2.8/eDEX-UI-Linux-x86_64.AppImage" target="_blank"&gt;&lt;img alt="undefined" src="https://badgen.net/badge/Download/Linux64/?color=orange&amp;amp;icon=terminal&amp;amp;label" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GitSquared/edex-ui/releases/download/v2.2.8/eDEX-UI-Linux-arm64-AppImage" target="_blank"&gt;&lt;img alt="undefined" src="https://badgen.net/badge/Download/LinuxArm64/?color=orange&amp;amp;icon=terminal&amp;amp;label" /&gt;&lt;/a&gt; &lt;a href="https://aur.archlinux.org/packages/edex-ui" target="_blank"&gt;&lt;img alt="undefined" src="https://badgen.net/badge/AUR/Package/cyan" /&gt;&lt;/a&gt; &lt;br /&gt; &lt;a href="https://github.com/GitSquared/edex-ui/releases/tag/v2.2.8"&gt;&lt;strong&gt;&lt;i&gt;(Project archived oct. 18th 2021)&lt;/i&gt;&lt;/strong&gt;&lt;/a&gt; &lt;br /&gt;&lt;br /&gt;&lt;br /&gt; &lt;/p&gt; 
&lt;p&gt;eDEX-UI is a fullscreen, cross-platform terminal emulator and system monitor that looks and feels like a sci-fi computer interface.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;a href="https://youtu.be/BGeY1rK19zA"&gt; &lt;img align="right" width="400" alt="Demo on YouTube" src="https://raw.githubusercontent.com/GitSquared/edex-ui/master/media/youtube-demo-teaser.gif" /&gt; &lt;/a&gt; 
&lt;p&gt;Heavily inspired from the &lt;a href="https://web.archive.org/web/20170511000410/http://jtnimoy.com/blogs/projects/14881671"&gt;TRON Legacy movie effects&lt;/a&gt; (especially the &lt;a href="https://gmunk.com/TRON-Board-Room"&gt;Board Room sequence&lt;/a&gt;), the eDEX-UI project was originally meant to be &lt;em&gt;"&lt;a href="https://github.com/seenaburns/dex-ui"&gt;DEX-UI&lt;/a&gt; with less « art » and more « distributable software »"&lt;/em&gt;.&lt;/p&gt; 
&lt;p&gt;While keeping a futuristic look and feel, it strives to maintain a certain level of functionality and to be usable in real-life scenarios, with the larger goal of bringing science-fiction UXs to the mainstream.&lt;/p&gt; 
&lt;br /&gt; 
&lt;p&gt;It might or might not be a joke taken too seriously.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;em&gt;Jump to: &lt;br /&gt;&lt;a href="https://raw.githubusercontent.com/GitSquared/edex-ui/master/#features"&gt;Features&lt;/a&gt; — &lt;a href="https://raw.githubusercontent.com/GitSquared/edex-ui/master/#screenshots"&gt;Screenshots&lt;/a&gt; — &lt;a href="https://raw.githubusercontent.com/GitSquared/edex-ui/master/#qa"&gt;Questions &amp;amp; Answers&lt;/a&gt; — &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/GitSquared/edex-ui/master/#how-do-i-get-it"&gt;Download&lt;/a&gt;&lt;/strong&gt; — &lt;a href="https://raw.githubusercontent.com/GitSquared/edex-ui/master/#featured-in"&gt;Featured In&lt;/a&gt; — &lt;a href="https://raw.githubusercontent.com/GitSquared/edex-ui/master/#useful-commands-for-the-nerds"&gt;Contributor Instructions&lt;/a&gt; — &lt;a href="https://raw.githubusercontent.com/GitSquared/edex-ui/master/#credits"&gt;Credits&lt;/a&gt;&lt;/em&gt; &lt;/p&gt; 
&lt;h2&gt;Sponsor&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Want to help support my open-source experiments and learn some cool JavaScript tricks at the same time?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Click the banner below and sign up to &lt;strong&gt;Bytes&lt;/strong&gt;, the only newsletter cool enough to be recommended by eDEX-UI.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://ui.dev/bytes/?r=gabriel"&gt;&lt;img src="https://raw.githubusercontent.com/GitSquared/edex-ui/master/media/sponsor-uidev-bytes.jpg" alt="Bytes by UI.dev" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Fully featured terminal emulator with tabs, colors, mouse events, and support for &lt;code&gt;curses&lt;/code&gt; and &lt;code&gt;curses&lt;/code&gt;-like applications.&lt;/li&gt; 
 &lt;li&gt;Real-time system (CPU, RAM, swap, processes) and network (GeoIP, active connections, transfer rates) monitoring.&lt;/li&gt; 
 &lt;li&gt;Full support for touch-enabled displays, including an on-screen keyboard.&lt;/li&gt; 
 &lt;li&gt;Directory viewer that follows the CWD (current working directory) of the terminal.&lt;/li&gt; 
 &lt;li&gt;Advanced customization using themes, on-screen keyboard layouts, CSS injections. See the &lt;a href="https://github.com/GitSquared/edex-ui/wiki"&gt;wiki&lt;/a&gt; for more info.&lt;/li&gt; 
 &lt;li&gt;Optional sound effects made by a talented sound designer for maximum hollywood hacking vibe.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/GitSquared/edex-ui/master/media/screenshot_default.png" alt="Default screenshot" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/dylanaraps/neofetch"&gt;neofetch&lt;/a&gt; on eDEX-UI 2.2 with the default "tron" theme &amp;amp; QWERTY keyboard&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/GitSquared/edex-ui/master/media/screenshot_blade.png" alt="Blade screenshot" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Checking out available themes in &lt;a href="https://github.com/GitSquared/edex-ui/wiki/userData"&gt;eDEX's config dir&lt;/a&gt; with &lt;a href="https://github.com/ranger/ranger"&gt;&lt;code&gt;ranger&lt;/code&gt;&lt;/a&gt; on eDEX-UI 2.2 with the "blade" theme&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/GitSquared/edex-ui/master/media/screenshot_disrupted.png" alt="Disrupted screenshot" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;a href="https://github.com/abishekvashok/cmatrix"&gt;cmatrix&lt;/a&gt; on eDEX-UI 2.2 with the experimental "tron-disrupted" theme, and the user-contributed DVORAK keyboard&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/GitSquared/edex-ui/master/media/screenshot_horizon.png" alt="Horizon screenshot" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Editing eDEX-UI source code with &lt;code&gt;nvim&lt;/code&gt; on eDEX-UI 2.2 with the custom &lt;a href="https://github.com/GitSquared/horizon-edex-theme"&gt;&lt;code&gt;horizon-full&lt;/code&gt;&lt;/a&gt; theme&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Q&amp;amp;A&lt;/h2&gt; 
&lt;h4&gt;How do I get it?&lt;/h4&gt; 
&lt;p&gt;Click on the little badges under the eDEX logo at the top of this page, or go to the &lt;a href="https://github.com/GitSquared/edex-ui/releases"&gt;Releases&lt;/a&gt; tab, or download it through &lt;a href="https://repology.org/project/edex-ui/versions"&gt;one of the available repositories&lt;/a&gt; (Homebrew, AUR...).&lt;/p&gt; 
&lt;p&gt;Public release binaries are unsigned (&lt;a href="https://gaby.dev/posts/code-signing"&gt;why&lt;/a&gt;). On Linux, you will need to &lt;code&gt;chmod +x&lt;/code&gt; the AppImage file in order to run it.&lt;/p&gt; 
&lt;h4&gt;I have a problem!&lt;/h4&gt; 
&lt;p&gt;Search through the &lt;a href="https://github.com/GitSquared/edex-ui/issues"&gt;Issues&lt;/a&gt; to see if yours has already been reported. If you're confident it hasn't been reported yet, feel free to open up a new one. If you see your issue and it's been closed, it probably means that the fix for it will ship in the next version, and you'll have to wait a bit.&lt;/p&gt; 
&lt;h4&gt;Can you disable the keyboard/the filesystem display?&lt;/h4&gt; 
&lt;p&gt;You can't disable them (yet) but you can hide them. See the &lt;code&gt;tron-notype&lt;/code&gt; theme.&lt;/p&gt; 
&lt;h4&gt;Why is the file browser saying that "Tracking Failed"? (Windows only)&lt;/h4&gt; 
&lt;p&gt;On Linux and macOS, eDEX tracks where you're going in your terminal tab to display the content of the current folder on-screen. Sadly, this is technically impossible to do on Windows right now, so the file browser reverts back to a "detached" mode. You can still use it to browse files &amp;amp; directories and click on files to input their path in the terminal.&lt;/p&gt; 
&lt;h4&gt;Can this run on a Raspberry Pi / ARM device?&lt;/h4&gt; 
&lt;p&gt;We provide prebuilt arm64 builds. For other platforms, see &lt;a href="https://github.com/GitSquared/edex-ui/issues/313#issuecomment-443465345"&gt;this issue comment&lt;/a&gt;, and the thread on issue &lt;a href="https://github.com/GitSquared/edex-ui/issues/818"&gt;#818&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Is this repo actively maintained?&lt;/h4&gt; 
&lt;p&gt;No, after a 3 years run, this project has been archived. See the &lt;a href="https://github.com/GitSquared/edex-ui/releases/tag/v2.2.8"&gt;announcement&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;How did you make this?&lt;/h4&gt; 
&lt;p&gt;Glad you're interested! See &lt;a href="https://github.com/GitSquared/edex-ui/issues/272"&gt;#272&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;This is so cool.&lt;/h4&gt; 
&lt;p&gt;Thanks! If you feel like it, you can &lt;a href="https://gaby.dev/twitter"&gt;follow me on Twitter&lt;/a&gt; to hear about new stuff I'm making.&lt;/p&gt; 
&lt;img width="220" src="https://78.media.tumblr.com/35d4ef4447e0112f776b629bffd99188/tumblr_mk4gf8zvyC1s567uwo1_500.gif" /&gt; 
&lt;h2&gt;Featured in...&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.linuxuprising.com/2018/11/edex-ui-fully-functioning-sci-fi.html"&gt;Linux Uprising Blog&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.reddit.com/r/unixporn/comments/9ysbx7/oc_a_little_project_that_ive_been_working_on/"&gt;My post on r/unixporn&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://korben.info/une-interface-futuriste-pour-vos-ecrans-tactiles.html"&gt;Korben article (in french)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=18509828"&gt;Hacker News&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://twitter.com/mikemaccana/status/1065615451940667396"&gt;This tweet that made me smile&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://boingboing.net/2018/11/23/simulacrum-sf.html"&gt;BoingBoing article&lt;/a&gt; - Apparently i'm a "French hacker"&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oreilly.com/ideas/four-short-links-23-november-2018"&gt;OReilly 4 short links&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://hackaday.com/2018/11/23/look-like-a-movie-hacker/"&gt;Hackaday&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.developpez.com/actu/234808/Une-application-de-bureau-ressemble-a-une-interface-d-ordinateur-de-science-fiction-inspiree-des-effets-du-film-TRON-Legacy/"&gt;Developpez.com (another french link)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://blog.github.com/2018-12-21-release-radar-november-2018/"&gt;GitHub Blog's Release Radar November 2018&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opensource.com/article/19/1/productivity-tool-edex-ui"&gt;opensource.com Productive Tools for 2019&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.oreilly.com/radar/four-short-links-7-july-2020/"&gt;O'Reilly 4 short links (again)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.linuxlinks.com/linux-candy-edex-ui-sci-fi-computer-terminal-emulator-system-monitor/"&gt;LinuxLinks&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=gbzqCAjm--g"&gt;Linux For Everyone (Youtube)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://risingstars.js.org/2020/en#edex-ui"&gt;BestOfJS Rising Stars 2020&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://youtu.be/TSjMIeLG0Sk"&gt;The Geek Freaks (Youtube/German)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://osawards.com/javascript/#nominees"&gt;JSNation Open Source Awards 2021&lt;/a&gt; (Nominee - Fun Side Project of the Year)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Useful commands for the nerds&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;IMPORTANT NOTE:&lt;/strong&gt; the following instructions are meant for running eDEX from the latest unoptimized, unreleased, development version. If you'd like to get stable software instead, refer to &lt;a href="https://raw.githubusercontent.com/GitSquared/edex-ui/master/#how-do-i-get-it"&gt;these&lt;/a&gt; instructions.&lt;/p&gt; 
&lt;h4&gt;Starting from source:&lt;/h4&gt; 
&lt;p&gt;on *nix systems (You'll need the Xcode command line tools on macOS):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;clone the repository&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm run install-linux&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm run start&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;on Windows:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;start cmd or powershell &lt;strong&gt;as administrator&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;clone the repository&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm run install-windows&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm run start&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Building&lt;/h4&gt; 
&lt;p&gt;Note: Due to native modules, you can only build targets for the host OS you are using.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;npm install&lt;/code&gt; (NOT &lt;code&gt;install-linux&lt;/code&gt; or &lt;code&gt;install-windows&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;npm run build-linux&lt;/code&gt; or &lt;code&gt;build-windows&lt;/code&gt; or &lt;code&gt;build-darwin&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The script will minify the source code, recompile native dependencies and create distributable assets in the &lt;code&gt;dist&lt;/code&gt; folder.&lt;/p&gt; 
&lt;h4&gt;Getting the bleeding edge&lt;/h4&gt; 
&lt;p&gt;If you're interested in running the latest in-development version but don't want to compile source code yourself, you can can get pre-built nightly binaries on &lt;a href="https://github.com/GitSquared/edex-ui/actions"&gt;GitHub Actions&lt;/a&gt;: click the latest commits, and download the artifacts bundle for your OS.&lt;/p&gt; 
&lt;h2&gt;Credits&lt;/h2&gt; 
&lt;p&gt;eDEX-UI's source code was primarily written by me, &lt;a href="https://github.com/GitSquared"&gt;Squared&lt;/a&gt;. If you want to get in touch with me or find other projects I'm involved in, check out &lt;a href="https://gaby.dev"&gt;my website&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/PixelyIon"&gt;PixelyIon&lt;/a&gt; helped me get started with Windows compatibility and offered some precious advice when I started to work on this project seriously.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://soundcloud.com/iamicewolf"&gt;IceWolf&lt;/a&gt; composed the sound effects on v2.1.x and above. He makes really cool stuff, check out his music!&lt;/p&gt; 
&lt;h2&gt;Thanks&lt;/h2&gt; 
&lt;p&gt;Of course, eDEX would never have existed if I hadn't stumbled upon the amazing work of &lt;a href="https://github.com/seenaburns"&gt;Seena&lt;/a&gt; on &lt;a href="https://reddit.com/r/unixporn"&gt;r/unixporn&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;This project uses a bunch of open-source libraries, frameworks and tools, see &lt;a href="https://github.com/GitSquared/edex-ui/network/dependencies"&gt;the full dependency graph&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;I want to namely thank the developers behind &lt;a href="https://github.com/xtermjs/xterm.js"&gt;xterm.js&lt;/a&gt;, &lt;a href="https://github.com/sebhildebrandt/systeminformation"&gt;systeminformation&lt;/a&gt; and &lt;a href="https://github.com/joewalnes/smoothie"&gt;SmoothieCharts&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Huge thanks to &lt;a href="https://github.com/arscan"&gt;Rob "Arscan" Scanlon&lt;/a&gt; for making the fantastic &lt;a href="https://github.com/arscan/encom-globe"&gt;ENCOM Globe&lt;/a&gt;, also inspired by the TRON: Legacy movie, and distributing it freely. His work really puts the icing on the cake.&lt;/p&gt; 
&lt;h2&gt;Licensing&lt;/h2&gt; 
&lt;p&gt;Licensed under the &lt;a href="https://github.com/GitSquared/edex-ui/raw/master/LICENSE"&gt;GPLv3.0&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>brave/brave-browser</title>
      <link>https://github.com/brave/brave-browser</link>
      <description>&lt;p&gt;Brave browser for Android, iOS, Linux, macOS, Windows.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/brave/brave-browser/master/docs/source/_static/Brave.svg?sanitize=true" alt="Brave Browser" /&gt;&lt;/p&gt; 
&lt;h2&gt;Overview&lt;/h2&gt; 
&lt;p&gt;This repository holds the build tools needed to build the Brave desktop browser for macOS, Windows, and Linux. In particular, it fetches and syncs code from the projects defined in &lt;code&gt;package.json&lt;/code&gt; and &lt;code&gt;src/brave/DEPS&lt;/code&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://chromium.googlesource.com/chromium/src.git"&gt;Chromium&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Fetches code via &lt;code&gt;depot_tools&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Sets the branch for Chromium (ex: 65.0.3325.181).&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brave/brave-core"&gt;brave-core&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Mounted at &lt;code&gt;src/brave&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;Maintains patches for 3rd party Chromium code.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brave/adblock-rust"&gt;adblock-rust&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;Implements Brave's ad-block engine.&lt;/li&gt; 
   &lt;li&gt;Linked through &lt;a href="https://github.com/brave/brave-core/tree/master/components/adblock_rust_ffi"&gt;brave/adblock-rust-ffi&lt;/a&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Downloads&lt;/h2&gt; 
&lt;p&gt;You can &lt;a href="https://brave.com/download"&gt;visit our website&lt;/a&gt; to get the latest stable release.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Please see the &lt;a href="https://raw.githubusercontent.com/brave/brave-browser/master/CONTRIBUTING.md"&gt;contributing guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Our &lt;a href="https://github.com/brave/brave-browser/wiki"&gt;Wiki&lt;/a&gt; also has some useful technical information.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://community.brave.app/"&gt;Join the Q&amp;amp;A community&lt;/a&gt; if you'd like to get more involved with Brave. You can &lt;a href="https://community.brave.app/c/support-and-troubleshooting"&gt;ask for help&lt;/a&gt;, &lt;a href="https://community.brave.app/c/brave-feature-requests"&gt;discuss features you'd like to see&lt;/a&gt;, and a lot more. We'd love to have your help so that we can continue improving Brave.&lt;/p&gt; 
&lt;p&gt;Help us translate Brave to your language by submitting translations at &lt;a href="https://explore.transifex.com/brave/brave_en/"&gt;https://explore.transifex.com/brave/brave_en/&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Follow &lt;a href="https://x.com/brave"&gt;@brave&lt;/a&gt; on X for important news and announcements.&lt;/p&gt; 
&lt;h2&gt;Install prerequisites&lt;/h2&gt; 
&lt;p&gt;Follow the instructions for your platform:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brave/brave-browser/wiki/macOS-Development-Environment"&gt;macOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brave/brave-browser/wiki/iOS-Development-Environment"&gt;iOS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brave/brave-browser/wiki/Windows-Development-Environment"&gt;Windows&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brave/brave-browser/wiki/Linux-Development-Environment"&gt;Linux&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brave/brave-browser/wiki/Android-Development-Environment"&gt;Android&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Clone and initialize the repo&lt;/h2&gt; 
&lt;p&gt;Once you have the prerequisites installed, you can get the code and initialize the build environment.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone git@github.com:brave/brave-core.git path-to-your-project-folder/src/brave
cd path-to-your-project-folder/src/brave
npm install

# the Chromium source is downloaded, which has a large history (gigabytes of data)
# this might take really long to finish depending on internet speed

npm run init
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;brave-core based android builds should use &lt;code&gt;npm run init -- --target_os=android --target_arch=arm&lt;/code&gt; (or whichever CPU type you want to build for) brave-core based iOS builds should use &lt;code&gt;npm run init -- --target_os=ios&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;You can also set the target_os and target_arch for init and build using:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;npm config set target_os android
npm config set target_arch arm
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Additional parameters needed to build are documented at &lt;a href="https://github.com/brave/brave-browser/wiki/Build-configuration"&gt;https://github.com/brave/brave-browser/wiki/Build-configuration&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Internal developers can find more information at &lt;a href="https://github.com/brave/devops/wiki/%60.env%60-config-for-Brave-Developers"&gt;https://github.com/brave/devops/wiki/%60.env%60-config-for-Brave-Developers&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Build Brave&lt;/h2&gt; 
&lt;p&gt;The default build type is component.&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# start the component build compile
npm run build
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To do a release build:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;# start the release compile
npm run build Release
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;brave-core based android builds should use &lt;code&gt;npm run build -- --target_os=android --target_arch=arm&lt;/code&gt; or set the npm config variables as specified above for &lt;code&gt;init&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;brave-core based iOS builds should use the Xcode project found in &lt;code&gt;ios/brave-ios/App&lt;/code&gt;. You can open this project directly or run &lt;code&gt;npm run ios_bootstrap -- --open_xcodeproj&lt;/code&gt; to have it opened in Xcode. See the &lt;a href="https://github.com/brave/brave-browser/wiki/iOS-Development-Environment#Building"&gt;iOS Developer Environment&lt;/a&gt; for more information on iOS builds.&lt;/p&gt; 
&lt;h3&gt;Build Configurations&lt;/h3&gt; 
&lt;p&gt;Running a release build with &lt;code&gt;npm run build Release&lt;/code&gt; can be very slow and use a lot of RAM, especially on Linux with the Gold LLVM plugin.&lt;/p&gt; 
&lt;p&gt;To run a statically linked build (takes longer to build, but starts faster):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm run build -- Static
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;To run a debug build (Component build with is_debug=true):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;npm run build -- Debug
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;NOTE: the build will take a while to complete. Depending on your processor and memory, it could potentially take a few hours.&lt;/p&gt; 
&lt;h2&gt;Run Brave&lt;/h2&gt; 
&lt;p&gt;To start the build:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;npm start [Release|Component|Static|Debug]&lt;/code&gt;&lt;/p&gt; 
&lt;h1&gt;Update Brave&lt;/h1&gt; 
&lt;p&gt;&lt;code&gt;npm run sync -- [--force] [--init] [--create] [brave_core_ref]&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;This will attempt to stash your local changes in brave-core, but it's safer to commit local changes before running this&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;npm run sync&lt;/code&gt; will (depending on the below flags):&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;📥 Update sub-projects (chromium, brave-core) to latest commit of a git ref (e.g. tag or branch)&lt;/li&gt; 
 &lt;li&gt;🤕 Apply patches&lt;/li&gt; 
 &lt;li&gt;🔄 Update gclient DEPS dependencies&lt;/li&gt; 
 &lt;li&gt;⏩ Run hooks (e.g. to perform &lt;code&gt;npm install&lt;/code&gt; on child projects)&lt;/li&gt; 
&lt;/ol&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;flag&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;[no flags]&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;updates chromium if needed and re-applies patches. If the chromium version did not change, it will only re-apply patches that have changed. Will update child dependencies &lt;strong&gt;only if any project needed updating during this script run&lt;/strong&gt;. &lt;br /&gt; **Use this if you want the script to manage keeping you up to date instead of pulling or switching branches manually. **&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--force&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;updates both &lt;em&gt;Chromium&lt;/em&gt; and &lt;em&gt;brave-core&lt;/em&gt; to the latest remote commit for the current brave-core branch and the &lt;em&gt;Chromium&lt;/em&gt; ref specified in brave-browser/package.json (e.g. &lt;code&gt;master&lt;/code&gt; or &lt;code&gt;74.0.0.103&lt;/code&gt;). Will re-apply all patches. Will force update all child dependencies. &lt;br /&gt; **Use this if you're having trouble and want to force the branches back to a known state. **&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--init&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;force update both &lt;em&gt;Chromium&lt;/em&gt; and &lt;em&gt;brave-core&lt;/em&gt; to the versions specified in brave-browser/package.json and force updates all dependent repos - same as &lt;code&gt;npm run init&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;--sync_chromium (true/false)&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Will force or skip the chromium version update when applicable. Useful if you want to avoid a minor update when not ready for the larger build time a chromium update may result in. A warning will be output about the current code state expecting a different chromium version. Your build may fail as a result.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;code&gt;-D, --delete_unused_deps&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;Will delete from the working copy any dependencies that have been removed since the last sync. Mimics &lt;code&gt;gclient sync -D&lt;/code&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;Run &lt;code&gt;npm run sync brave_core_ref&lt;/code&gt; to checkout the specified &lt;em&gt;brave-core&lt;/em&gt; ref and update all dependent repos including chromium if needed.&lt;/p&gt; 
&lt;h2&gt;Scenarios&lt;/h2&gt; 
&lt;h4&gt;Create a new branch:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brave-browser&amp;gt; cd src/brave
brave-browser/src/brave&amp;gt; git checkout -b branch_name
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Checkout an existing branch or tag:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brave-browser/src/brave&amp;gt; git fetch origin
brave-browser/src/brave&amp;gt; git checkout [-b] branch_name
brave-browser/src/brave&amp;gt; npm run sync
...Updating 2 patches...
...Updating child dependencies...
...Running hooks...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Update the current branch to the latest remote:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brave-browser/src/brave&amp;gt; git pull
brave-browser/src/brave&amp;gt; npm run sync
...Updating 2 patches...
...Updating child dependencies...
...Running hooks...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Reset to latest brave-browser master and brave-core master (via &lt;code&gt;init&lt;/code&gt;, will always result in a longer build and will remove any pending changes in your brave-core working directory):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brave-browser&amp;gt; git checkout master
brave-browser&amp;gt; git pull
brave-browser&amp;gt; npm run sync -- --init
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;When you know that DEPS didn't change, but .patch files did (quickest attempt to perform a mini-sync before a build):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;brave-browser/src/brave&amp;gt; git checkout featureB
brave-browser/src/brave&amp;gt; git pull
brave-browser/src/brave&amp;gt; cd ../..
brave-browser&amp;gt; npm run apply_patches
...Applying 2 patches...
&lt;/code&gt;&lt;/pre&gt; 
&lt;h1&gt;Enabling third-party APIs:&lt;/h1&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;strong&gt;Google Safe Browsing&lt;/strong&gt;: Get an API key with SafeBrowsing API enabled from &lt;a href="https://console.developers.google.com/"&gt;https://console.developers.google.com/&lt;/a&gt;. Update the &lt;code&gt;GOOGLE_API_KEY&lt;/code&gt; environment variable with your key as per &lt;a href="https://www.chromium.org/developers/how-tos/api-keys"&gt;https://www.chromium.org/developers/how-tos/api-keys&lt;/a&gt; to enable Google SafeBrowsing.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Development&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://chromium.googlesource.com/chromium/src/+/refs/heads/main/docs/security/rules.md"&gt;Security rules from Chromium&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://chromium.googlesource.com/chromium/src/+/HEAD/docs/security/ipc-reviews.md"&gt;IPC review guidelines&lt;/a&gt; (in particular &lt;a href="https://docs.google.com/document/d/1Kw4aTuISF7csHnjOpDJGc7JYIjlvOAKRprCTBVWw_E4/edit#heading=h.84bpc1e9z1bg"&gt;this reference&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brave/internal/wiki/Pull-request-security-audit-checklist"&gt;Brave's internal security guidelines&lt;/a&gt; (for employees only)&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/brave/brave-core/raw/master/docs/rust.md"&gt;Rust usage&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Troubleshooting&lt;/h1&gt; 
&lt;p&gt;See &lt;a href="https://github.com/brave/brave-browser/wiki/Troubleshooting"&gt;Troubleshooting&lt;/a&gt; for solutions to common problems.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>manga-download/hakuneko</title>
      <link>https://github.com/manga-download/hakuneko</link>
      <description>&lt;p&gt;Manga &amp; Anime Downloader for Linux, Windows &amp; MacOS&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;HakuNeko&lt;/h1&gt; 
&lt;div id="toc" class="toc"&gt; 
 &lt;div id="toctitle"&gt;
  Table of Contents
 &lt;/div&gt; 
 &lt;ul class="sectlevel2"&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/manga-download/hakuneko/master/#_download"&gt;1. Download&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/manga-download/hakuneko/master/#_status"&gt;2. Status&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/manga-download/hakuneko/master/#_introduction"&gt;3. Introduction&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/manga-download/hakuneko/master/#_development"&gt;4. Development&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/div&gt; 
&lt;div id="preamble"&gt; 
 &lt;div class="sectionbody"&gt; 
  &lt;hr /&gt; 
  &lt;div class="paragraph"&gt; 
   &lt;p&gt;🏡 Website : &lt;a href="https://hakuneko.download" class="bare"&gt;https://hakuneko.download&lt;/a&gt;&lt;/p&gt; 
  &lt;/div&gt; 
  &lt;div class="paragraph"&gt; 
   &lt;p&gt;&lt;span class="image"&gt;&lt;a class="image" href="https://discord.gg/A5d3NDf" target="_blank" rel="noopener"&gt;&lt;img src="https://hakuneko.download/assets/images/discord-small.png" alt="discord small" title="Join us on discord" /&gt;&lt;/a&gt;&lt;/span&gt; Discord : &lt;a href="https://discord.gg/A5d3NDf" class="bare"&gt;https://discord.gg/A5d3NDf&lt;/a&gt;&lt;/p&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;div class="sect2"&gt; 
 &lt;h3 id="_download"&gt;1. Download&lt;/h3&gt; 
 &lt;div class="paragraph"&gt; 
  &lt;p&gt;&lt;span class="image"&gt;&lt;a class="image" href="https://github.com/manga-download/hakuneko/releases/latest" target="_blank" rel="noopener"&gt;&lt;img src="https://img.shields.io/github/downloads/manga-download/hakuneko/latest/total?label=HakuNeko%20%28Stable%29&amp;amp;logo=github" alt="total?label=HakuNeko%20%28Stable%29&amp;amp;logo=github" title="Download the latest stable release of HakuNeko" /&gt;&lt;/a&gt;&lt;/span&gt; &lt;span class="image"&gt;&lt;a class="image" href="https://github.com/manga-download/hakuneko/releases" target="_blank" rel="noopener"&gt;&lt;img src="https://img.shields.io/github/downloads-pre/manga-download/hakuneko/latest/total?color=blue&amp;amp;label=HakuNeko%20%28Nightly%29&amp;amp;logo=azure-devops" alt="total?color=blue&amp;amp;label=HakuNeko%20%28Nightly%29&amp;amp;logo=azure devops" title="Download the latest pre-release (nightly build) of HakuNeko" /&gt;&lt;/a&gt;&lt;/span&gt; &lt;span class="image"&gt;&lt;a class="image" href="https://community.chocolatey.org/packages/hakunekonightly" target="_blank" rel="noopener"&gt;&lt;img src="https://img.shields.io/chocolatey/dt/hakunekonightly?color=blue&amp;amp;label=Chocolatey%20package" alt="hakunekonightly?color=blue&amp;amp;label=Chocolatey%20package" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div class="paragraph"&gt; 
  &lt;p&gt;Yes, the download section comes first, because this is what most users are looking for anyway. You can download and run the installer/archive for your operating system from one of the mirror sites above. There is also a portable version available for Windows which stores all its application data inside the application folder.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;div class="sect2"&gt; 
 &lt;h3 id="_status"&gt;2. Status&lt;/h3&gt; 
 &lt;div class="paragraph"&gt; 
  &lt;p&gt;This section shows the latest build and test results for the master branch of the mirrored repository on &lt;a href="https://dev.azure.com/manga-download/hakuneko/_build"&gt;Azure&lt;/a&gt;.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div class="paragraph"&gt; 
  &lt;p&gt;&lt;span class="image"&gt;&lt;a class="image" href="https://dev.azure.com/manga-download/hakuneko/_testManagement/runs?_a=runQuery"&gt;&lt;img src="https://img.shields.io/azure-devops/tests/manga-download/hakuneko/8?label=CI%20Tests&amp;amp;logo=azure-pipelines" alt="Test Results" title="List of CI Test Results" /&gt;&lt;/a&gt;&lt;/span&gt; &lt;span class="image"&gt;&lt;a class="image" href="https://dev.azure.com/manga-download/hakuneko/_build/latest?definitionId=5&amp;amp;branchName=master"&gt;&lt;img src="https://dev.azure.com/manga-download/hakuneko/_apis/build/status/CI?branchName=master&amp;amp;label=CI%20Pipeline" alt="Build Status" title="Latest CI Pipeline Summary" /&gt;&lt;/a&gt;&lt;/span&gt; &lt;span class="image"&gt;&lt;a class="image" href="https://dev.azure.com/manga-download/hakuneko/_build/latest?definitionId=7&amp;amp;branchName=master"&gt;&lt;img src="https://dev.azure.com/manga-download/hakuneko/_apis/build/status/Nightly?branchName=master&amp;amp;label=Nightly%20Build" alt="Build Status" title="Latest Nightly Build Summary" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;details&gt; 
  &lt;summary class="title"&gt;Details&lt;/summary&gt; 
  &lt;div class="content"&gt; 
   &lt;div class="dlist"&gt; 
    &lt;dl&gt; 
     &lt;dt class="hdlist1"&gt;
      Continuous Integration
     &lt;/dt&gt; 
     &lt;dd&gt; 
      &lt;p&gt;&lt;span class="image"&gt;&lt;img src="https://dev.azure.com/manga-download/hakuneko/_apis/build/status/CI?branchName=master&amp;amp;jobName=CI&amp;amp;configuration=CI%20Windows&amp;amp;label=CI%20-%20Windows" alt="CI?branchName=master&amp;amp;jobName=CI&amp;amp;configuration=CI%20Windows&amp;amp;label=CI%20 %20Windows" title="CI Pipeline: Windows" /&gt;&lt;/span&gt; &lt;br /&gt; &lt;span class="image"&gt;&lt;img src="https://dev.azure.com/manga-download/hakuneko/_apis/build/status/CI?branchName=master&amp;amp;jobName=CI&amp;amp;configuration=CI%20Ubuntu&amp;amp;label=CI%20-%20Ubuntu" alt="CI?branchName=master&amp;amp;jobName=CI&amp;amp;configuration=CI%20Ubuntu&amp;amp;label=CI%20 %20Ubuntu" title="CI Pipeline: Ubuntu" /&gt;&lt;/span&gt; &lt;br /&gt; &lt;span class="image"&gt;&lt;img src="https://dev.azure.com/manga-download/hakuneko/_apis/build/status/CI?branchName=master&amp;amp;jobName=CI&amp;amp;configuration=CI%20macOS&amp;amp;label=CI%20-%20macOS" alt="CI?branchName=master&amp;amp;jobName=CI&amp;amp;configuration=CI%20macOS&amp;amp;label=CI%20 %20macOS" title="CI Pipeline: macOS" /&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;/dd&gt; 
     &lt;dt class="hdlist1"&gt;
      Nightly Builds
     &lt;/dt&gt; 
     &lt;dd&gt; 
      &lt;p&gt;&lt;span class="image"&gt;&lt;img src="https://dev.azure.com/manga-download/hakuneko/_apis/build/status/Nightly?branchName=master&amp;amp;jobName=Windows&amp;amp;label=Nightly%20-%20Windows" alt="Nightly?branchName=master&amp;amp;jobName=Windows&amp;amp;label=Nightly%20 %20Windows" title="Nightly Build: Windows" /&gt;&lt;/span&gt; &lt;br /&gt; &lt;span class="image"&gt;&lt;img src="https://dev.azure.com/manga-download/hakuneko/_apis/build/status/Nightly?branchName=master&amp;amp;jobName=Ubuntu&amp;amp;label=Nightly%20-%20Ubuntu" alt="Nightly?branchName=master&amp;amp;jobName=Ubuntu&amp;amp;label=Nightly%20 %20Ubuntu" title="Nightly Build: Ubuntu" /&gt;&lt;/span&gt; &lt;br /&gt; &lt;span class="image"&gt;&lt;img src="https://dev.azure.com/manga-download/hakuneko/_apis/build/status/Nightly?branchName=master&amp;amp;jobName=macOS&amp;amp;label=Nightly%20-%20macOS" alt="Nightly?branchName=master&amp;amp;jobName=macOS&amp;amp;label=Nightly%20 %20macOS" title="Nightly Build: macOS" /&gt;&lt;/span&gt;&lt;/p&gt; 
     &lt;/dd&gt; 
    &lt;/dl&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/details&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;div class="sect2"&gt; 
 &lt;h3 id="_introduction"&gt;3. Introduction&lt;/h3&gt; 
 &lt;div class="paragraph"&gt; 
  &lt;p&gt;HakuNeko is a cross-platform downloader for manga and anime from various websites. HakuNeko was made to help users downloading media for circumstances that require offline usage. The philosophy is ad-hoc consumption, get it when you going to read/watch it. It is not meant to be a mass downloader to stock up thousands of chapters that are just collected and will probably never be read.&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;div class="openblock clearfix"&gt; 
  &lt;div class="content"&gt; 
   &lt;div class="imageblock center"&gt; 
    &lt;div class="content"&gt; 
     &lt;a class="image" href="https://raw.githubusercontent.com/manga-download/hakuneko/master/screenshot-pages.png" target="_blank" rel="noopener"&gt;&lt;img src="https://raw.githubusercontent.com/manga-download/hakuneko/master/assets/screenshot-pages.png" alt="screenshot pages" width="720" /&gt;&lt;/a&gt; 
    &lt;/div&gt; 
    &lt;div class="title"&gt;
     Figure 1. HakuNeko - Chapter Page Preview
    &lt;/div&gt; 
   &lt;/div&gt; 
   &lt;div class="paragraph"&gt; 
    &lt;p&gt;&amp;nbsp;&lt;br /&gt;&lt;/p&gt; 
   &lt;/div&gt; 
   &lt;div class="imageblock"&gt; 
    &lt;div class="content"&gt; 
     &lt;a class="image" href="https://raw.githubusercontent.com/manga-download/hakuneko/master/screenshot-video.png" target="_blank" rel="noopener"&gt;&lt;img src="https://raw.githubusercontent.com/manga-download/hakuneko/master/assets/screenshot-video.png" alt="screenshot video" width="720" /&gt;&lt;/a&gt; 
    &lt;/div&gt; 
    &lt;div class="title"&gt;
     Figure 2. HakuNeko - Anime Playback
    &lt;/div&gt; 
   &lt;/div&gt; 
  &lt;/div&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
&lt;/div&gt; 
&lt;div class="sect2"&gt; 
 &lt;h3 id="_development"&gt;4. Development&lt;/h3&gt; 
 &lt;div class="paragraph"&gt; 
  &lt;p&gt;For developer documentation please check the &lt;a href="https://github.com/manga-download/hakuneko/wiki/Developer-Manual"&gt;Wiki&lt;/a&gt;&lt;/p&gt; 
 &lt;/div&gt; 
 &lt;hr /&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>vercel/next.js</title>
      <link>https://github.com/vercel/next.js</link>
      <description>&lt;p&gt;The React Framework&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;a href="https://nextjs.org"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://assets.vercel.com/image/upload/v1662130559/nextjs/Icon_dark_background.png" /&gt; 
   &lt;img alt="Next.js logo" src="https://assets.vercel.com/image/upload/v1662130559/nextjs/Icon_light_background.png" height="128" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
 &lt;h1&gt;Next.js&lt;/h1&gt; 
 &lt;p&gt;&lt;a href="https://vercel.com"&gt;&lt;img alt="Vercel logo" src="https://img.shields.io/badge/MADE%20BY%20Vercel-000000.svg?style=for-the-badge&amp;amp;logo=Vercel&amp;amp;labelColor=000" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/next"&gt;&lt;img alt="NPM version" src="https://img.shields.io/npm/v/next.svg?style=for-the-badge&amp;amp;labelColor=000000" /&gt;&lt;/a&gt; &lt;a href="https://github.com/vercel/next.js/raw/canary/license.md"&gt;&lt;img alt="License" src="https://img.shields.io/npm/l/next.svg?style=for-the-badge&amp;amp;labelColor=000000" /&gt;&lt;/a&gt; &lt;a href="https://github.com/vercel/next.js/discussions"&gt;&lt;img alt="Join the community on GitHub" src="https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&amp;amp;logo=Next.js&amp;amp;labelColor=000000&amp;amp;logoWidth=20" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;Used by some of the world's largest companies, Next.js enables you to create full-stack web applications by extending the latest React features, and integrating powerful Rust-based JavaScript tooling for the fastest builds.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Visit our &lt;a href="https://nextjs.org/learn"&gt;Learn Next.js&lt;/a&gt; course to get started with Next.js.&lt;/li&gt; 
 &lt;li&gt;Visit the &lt;a href="https://nextjs.org/showcase"&gt;Next.js Showcase&lt;/a&gt; to see more sites built with Next.js.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;Visit &lt;a href="https://nextjs.org/docs"&gt;https://nextjs.org/docs&lt;/a&gt; to view the full documentation.&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;The Next.js community can be found on &lt;a href="https://github.com/vercel/next.js/discussions"&gt;GitHub Discussions&lt;/a&gt; where you can ask questions, voice ideas, and share your projects with other people.&lt;/p&gt; 
&lt;p&gt;To chat with other community members you can join the Next.js &lt;a href="https://nextjs.org/discord"&gt;Discord&lt;/a&gt; server.&lt;/p&gt; 
&lt;p&gt;Do note that our &lt;a href="https://github.com/vercel/next.js/raw/canary/CODE_OF_CONDUCT.md"&gt;Code of Conduct&lt;/a&gt; applies to all Next.js community channels. Users are &lt;strong&gt;highly encouraged&lt;/strong&gt; to read and adhere to it to avoid repercussions.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Contributions to Next.js are welcome and highly appreciated. However, before you jump right into it, we would like you to review our &lt;a href="https://raw.githubusercontent.com/vercel/next.js/canary/contributing.md"&gt;Contribution Guidelines&lt;/a&gt; to make sure you have a smooth experience contributing to Next.js.&lt;/p&gt; 
&lt;h3&gt;Good First Issues:&lt;/h3&gt; 
&lt;p&gt;We have a list of &lt;strong&gt;&lt;a href="https://github.com/vercel/next.js/labels/%22good%20first%20issue%22"&gt;good first issues&lt;/a&gt;&lt;/strong&gt; that contain bugs that have a relatively limited scope. This is a great place for newcomers and beginners alike to get started, gain experience, and get familiar with our contribution process.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Security&lt;/h2&gt; 
&lt;p&gt;If you believe you have found a security vulnerability in Next.js, we encourage you to &lt;strong&gt;&lt;em&gt;responsibly disclose this and NOT open a public issue&lt;/em&gt;&lt;/strong&gt;. We will investigate all legitimate reports.&lt;/p&gt; 
&lt;p&gt;Our preference is that you make use of GitHub's private vulnerability reporting feature to disclose potential security vulnerabilities in our Open Source Software. To do this, please visit &lt;a href="https://github.com/vercel/next.js/security"&gt;https://github.com/vercel/next.js/security&lt;/a&gt; and click the "Report a vulnerability" button.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>met4citizen/TalkingHead</title>
      <link>https://github.com/met4citizen/TalkingHead</link>
      <description>&lt;p&gt;Talking Head (3D): A JavaScript class for real-time lip-sync using Ready Player Me full-body 3D avatars.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Talking Head (3D)&lt;/h1&gt; 
&lt;h3&gt;Demo Videos&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;All the demo videos are real-time screen captures from a Chrome browser running the TalkingHead test web app without any post-processing.&lt;/em&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Video&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;span style="display: block; min-width:400px"&gt;&lt;a href="https://youtu.be/YUbDIWkskuw"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/dynamicbones.jpg" width="400" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href="https://youtu.be/4Y9NFnENH5s"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/dynamicbones2.jpg" width="400" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;Having a good hair day! – A two-part introduction to the TalkingHead's dynamic bones feature 🦴🦴 and built-in physics engine. Using custom models with rigged hair and two different hairstyles. See Appendix E for more details.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/OA6LBZjkzJI"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/screenshot4.jpg" width="400" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;I chat with Jenny and Harri. The close-up view allows you to evaluate the accuracy of lip-sync in both English and Finnish. Using GPT-3.5 and Microsoft text-to-speech.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/fJrYGaGCAGo"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/screenshot5.jpg" width="400" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;A short demo of how AI can control the avatar's movements. Using OpenAI's function calling and Google TTS with the TalkingHead's built-in viseme generation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/6XRxALY1Iwg"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/screenshot6.jpg" width="400" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Michael lip-syncs to two MP3 audio tracks using OpenAI's Whisper and TalkingHead's &lt;code&gt;speakAudio&lt;/code&gt; method. He kicks things off with some casual talk, but then goes all out by trying to tackle an old Meat Loaf classic. 🤘 Keep rockin', Michael! 🎤😂&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://youtu.be/SfnqRnWKT40"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/screenshot3.jpg" width="400" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Julia and I showcase some of the features of the TalkingHead class and the test app including the settings, some poses and animations.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Use Case Examples&lt;/h3&gt; 
&lt;p&gt;&lt;em&gt;Some videos, apps, and projects using the TalkingHead class:&lt;/em&gt;&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Video/App&lt;/th&gt; 
   &lt;th&gt;Use Case&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;span style="display: block; min-width:400px"&gt;&lt;a href="https://youtu.be/9GeXwjuslnQ"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/olivia.jpg" width="400" /&gt;&lt;/a&gt;&lt;/span&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Video conferencing&lt;/strong&gt;. A video conferencing solution with real-time transcription, contextual AI responses, and voice lip-sync. The app and demo, featuring Olivia, by &lt;a href="https://github.com/namnm"&gt;namnm&lt;/a&gt; 👍&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.edgespeaker.com/"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/edgespeaker.png" width="400" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Fully in-browser AI you can talk to&lt;/strong&gt;. Uses TalkingHead, &lt;a href="https://github.com/met4citizen/HeadTTS"&gt;HeadTTS (with Kokoro)&lt;/a&gt;, &lt;a href="https://github.com/xenova/whisper-web"&gt;whisper-web&lt;/a&gt;, and &lt;a href="https://github.com/mlc-ai/web-llm"&gt;WebLLM (with Llama 3.2)&lt;/a&gt;. No APIs, no accounts. For more details, see &lt;a href="https://github.com/met4citizen/TalkingHead/issues/115"&gt;#115&lt;/a&gt;. — For best performance and WebGPU support, use a desktop version of Chrome or Edge: 👉 &lt;a href="https://www.edgespeaker.com/"&gt;EdgeSpeaker.com&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=Dl2o9kRvbLQ"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/geminicompetition.jpg" width="400" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Recycling Advisor 3D&lt;/strong&gt;. Snap a photo and get local recycling advice from a talking avatar. My entry for the &lt;a href="https://ai.google.dev/competition/projects/recycling-advisor-3d"&gt;Gemini API Developer Competition&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=OG1vwOit_Yk"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/evertrail.jpg" width="400" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Live Twitch adventure&lt;/strong&gt;. &lt;a href="https://evertrail.app"&gt;Evertrail&lt;/a&gt; is an infinite, real-time generated world where all of your choices shape the outcome. Video clip and the app by &lt;a href="https://github.com/JPhilipp"&gt;JPhilipp&lt;/a&gt; 👏👏&lt;br /&gt;&lt;strong&gt;NEWS&lt;/strong&gt;: Featured at the AI Film Awards during the 2025 Cannes Film Festival!&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=vNJ9Ifv-as8"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/cliquevm.jpg" width="400" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Quantum physics using a blackboard&lt;/strong&gt;. David introduces us to the CHSH game and explores the mystery of quantum entanglement. For more information about the research project, see &lt;a href="https://github.com/met4citizen/CliqueVM"&gt;CliqueVM&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://akshatrastogi.in/"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/interactiveportfolio.jpg" width="400" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Interactive Portfolio&lt;/strong&gt;. Click the image to open the app, where you can interview the virtual persona of its developer, &lt;a href="https://github.com/AkshatRastogi-1nC0re"&gt;AkshatRastogi-1nC0re&lt;/a&gt; 👋&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=Hv-ItCZ0qc4"&gt;&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/datingprofile.jpg" width="400" /&gt;&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;strong&gt;Interactive Dating Profiles&lt;/strong&gt;. ❤️ Researchers from the MIT Media Lab and Harvard used the TalkingHead class and data-driven AI to create digital twins that potential dating partners could interact with. Their paper (Baradari et al., 2025) was presented at &lt;a href="https://programs.sigchi.org/chi/2025/program/content/194739"&gt;CHI 2025&lt;/a&gt; in Japan.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Introduction&lt;/h3&gt; 
&lt;p&gt;Talking Head (3D) is a browser JavaScript class featuring a 3D avatar that can speak and lip-sync in real-time. The class supports &lt;a href="https://readyplayer.me/"&gt;Ready Player Me&lt;/a&gt; / &lt;a href="https://playerzero.me/"&gt;PlayerZero&lt;/a&gt; full-body 3D avatars (GLB) and &lt;a href="https://www.mixamo.com"&gt;Mixamo&lt;/a&gt; animations (FBX). It also knows a set of emojis and can convert them into facial expressions.&lt;/p&gt; 
&lt;p&gt;You can create your own 3D avatar for free using the Ready Player Me or PlayerZero service. Alternatively, you can create a custom 3D avatar by making it compatible with RPM models. See Appendix A for more details.&lt;/p&gt; 
&lt;p&gt;By default, the class uses &lt;a href="https://cloud.google.com/text-to-speech"&gt;Google Cloud TTS&lt;/a&gt; for text-to-speech and has a built-in lip-sync support for English, Finnish, and Lithuanian (beta). New lip-sync languages can be added by creating new lip-sync language modules.&lt;/p&gt; 
&lt;p&gt;It is also possible to integrate the TalkingHead class with any external TTS service that can provide word-level timestamps, such as the &lt;a href="https://elevenlabs.io"&gt;ElevenLabs WebSocket API&lt;/a&gt;. Note that a lip-sync language module is not required if your TTS engine can output viseme IDs or blend shape data directly. For example, by using the &lt;a href="https://github.com/microsoft/cognitive-services-speech-sdk-js"&gt;Microsoft Azure Speech SDK&lt;/a&gt;, you can extend TalkingHead's lip-sync support to 100+ languages.&lt;/p&gt; 
&lt;p&gt;The class uses &lt;a href="https://github.com/mrdoob/three.js/"&gt;ThreeJS&lt;/a&gt; / WebGL for 3D rendering.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] If you're looking for a free English TTS that can output timestamps and viseme IDs, check out &lt;a href="https://github.com/met4citizen/HeadTTS"&gt;HeadTTS&lt;/a&gt;. It offers Kokoro neural voices, phoneme-level timestamps, and can run locally or even entirely in a browser using WebGPU. And best of all, it's fully compatible with the TalkingHead class.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Talking Head class&lt;/h3&gt; 
&lt;p&gt;You can download the TalkingHead modules from &lt;a href="https://github.com/met4citizen/TalkingHead/releases"&gt;releases&lt;/a&gt; (without dependencies). Alternatively, you can install them from &lt;a href="https://www.npmjs.com/package/@met4citizen/talkinghead"&gt;NPM&lt;/a&gt;, or import all the needed modules from a CDN:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;&amp;lt;script type="importmap"&amp;gt;
{ "imports":
  {
    "three": "https://cdn.jsdelivr.net/npm/three@0.170.0/build/three.module.js/+esm",
    "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.170.0/examples/jsm/",
    "talkinghead": "https://cdn.jsdelivr.net/gh/met4citizen/TalkingHead@1.5/modules/talkinghead.mjs"
  }
}
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] &lt;strong&gt;FOR HOBBYISTS:&lt;/strong&gt; If you're just looking to experiment on your personal laptop without dealing with proxies, JSON Web Tokens, or Single Sign-On, take a look at the &lt;a href="https://github.com/met4citizen/TalkingHead/raw/main/examples/minimal.html"&gt;minimal code example&lt;/a&gt;. Simply download the file, add your Google TTS API key, and you'll have a basic web app template with a talking head.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;If you want to use the built-in Google TTS and lip-sync using Single Sign-On (SSO) functionality, give the class your TTS proxy endpoint and a function from which to obtain the JSON Web Token needed to use that proxy. Refer to Appendix B for one way to implement JWT SSO.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;import { TalkingHead } from "talkinghead";

// Create the talking head avatar
const nodeAvatar = document.getElementById('avatar');
const head = new TalkingHead( nodeAvatar, {
  ttsEndpoint: "/gtts/",
  jwtGet: jwtGet,
  lipsyncModules: ["en", "fi"],
  mixerGainSpeech: 3
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;CLICK HERE to see all the available OPTIONS.&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Option&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Default&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;jwsGet&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Function to get the JSON Web Token (JWT). See Appendix B for more information.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ttsEndpoint&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Text-to-speech backend/endpoint/proxy implementing the Google Text-to-Speech API.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ttsApikey&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If you don't want to use a proxy or JWT, you can use Google TTS endpoint directly and provide your API key here. &lt;strong&gt;NOTE: I recommend that you don't use this in production and never put your API key in any client-side code.&lt;/strong&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ttsLang&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Google text-to-speech language.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;"fi-FI"&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ttsVoice&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Google text-to-speech voice. The used voice must support SSML and &amp;lt;mark&amp;gt; tags that are needed to get word-level timestamps. Currently, Google supports SSML and &amp;lt;mark&amp;gt; tags when using Standard, Wavenet, Neural2, News, or Casual voice types.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;"fi-FI-Standard-A"&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ttsRate&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Google text-to-speech rate in the range [0.25, 4.0].&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1.0&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ttsPitch&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Google text-to-speech pitch in the range [-20.0, 20.0].&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ttsVolume&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Google text-to-speech volume gain (in dB) in the range [-96.0, 16.0].&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ttsTrimStart&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Trim the viseme sequence start relative to the beginning of the audio (shift in milliseconds).&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;ttsTrimEnd&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Trim the viseme sequence end relative to the end of the audio (shift in milliseconds).&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;400&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;mixerGainSpeech&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The amount of gain for speech. See Web Audio API / GainNode for more information.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;mixerGainBackground&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The amount of gain for background audio. See Web Audio API / GainNode for more information.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lipsyncModules&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Lip-sync modules to load dynamically at start-up. Limiting the number of language modules improves the loading time and memory usage.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;["en", "fi", "lt"]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lipsyncLang&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Lip-sync language.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;"fi"&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;pcmSampleRate&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;PCM (signed 16bit little endian) sample rate used in &lt;code&gt;speakAudio&lt;/code&gt; in Hz.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;22050&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;modelRoot&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The root name of the armature.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;Armature&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;modelPixelRatio&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Sets the device's pixel ratio.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;modelFPS&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Frames per second. Note that actual frame rate will be a bit lower than the set value.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;30&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;modelMovementFactor&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;A factor in the range [0,1] limiting the avatar's upper body movement when standing.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;dracoEnabled&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If &lt;code&gt;true&lt;/code&gt;, use Draco geometry compression. [≥&lt;code&gt;v1.5&lt;/code&gt;]&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;dracoDecoderPath&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Draco decoder library path. [≥&lt;code&gt;v1.5&lt;/code&gt;]&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;"https://www.gstatic.com/&lt;/code&gt;&lt;br /&gt;&lt;code&gt;draco/v1/decoders/"&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;cameraView&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Initial view. Supported views are &lt;code&gt;"full"&lt;/code&gt;, &lt;code&gt;"mid"&lt;/code&gt;, &lt;code&gt;"upper"&lt;/code&gt; and &lt;code&gt;"head"&lt;/code&gt;.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;"full"&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;cameraDistance&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Camera distance offset for initial view in meters.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;cameraX&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Camera position offset in X direction in meters.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;cameraY&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Camera position offset in Y direction in meters.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;cameraRotateX&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Camera rotation offset in X direction in radians.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;cameraRotateY&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Camera rotation offset in Y direction in radians.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;cameraRotateEnable&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If true, the user is allowed to rotate the 3D model.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;cameraPanEnable&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If true, the user is allowed to pan the 3D model.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;cameraZoomEnable&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If true, the user is allowed to zoom the 3D model.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lightAmbientColor&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Ambient light color. The value can be a hexadecimal color or CSS-style string.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0xffffff&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lightAmbientIntensity&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Ambient light intensity.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lightDirectColor&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Direction light color. The value can be a hexadecimal color or CSS-style string.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0x8888aa&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lightDirectIntensity&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Direction light intensity.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;30&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lightDirectPhi&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Direction light phi angle.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0.1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lightDirectTheta&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Direction light theta angle.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lightSpotColor&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Spot light color. The value can be a hexadecimal color or CSS-style string.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0x3388ff&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lightSpotIntensity&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Spot light intensity.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lightSpotPhi&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Spot light phi angle.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0.1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lightSpotTheta&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Spot light theta angle.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;4&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lightSpotDispersion&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Spot light dispersion.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;avatarMood&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The mood of the avatar. Supported moods: &lt;code&gt;"neutral"&lt;/code&gt;, &lt;code&gt;"happy"&lt;/code&gt;, &lt;code&gt;"angry"&lt;/code&gt;, &lt;code&gt;"sad"&lt;/code&gt;, &lt;code&gt;"fear"&lt;/code&gt;, &lt;code&gt;"disgust"&lt;/code&gt;, &lt;code&gt;"love"&lt;/code&gt;, &lt;code&gt;"sleep"&lt;/code&gt;.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;"neutral"&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;avatarMute&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Mute the avatar. This can be helpful option if you want to output subtitles without audio and lip-sync.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;avatarIdle&lt;/code&gt;&lt;br /&gt;&lt;code&gt;EyeContact&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The average proportion of eye contact while idle in the range [0,1].&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0.2&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;avatarIdle&lt;/code&gt;&lt;br /&gt;&lt;code&gt;HeadMove&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The average proportion of head movement while idle in the range [0,1].&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0.5&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;avatarSpeaking&lt;/code&gt;&lt;br /&gt;&lt;code&gt;EyeContact&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The average proportion of eye contact while speaking in the range [0,1].&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0.5&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;avatarSpeaking&lt;/code&gt;&lt;br /&gt;&lt;code&gt;HeadMove&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The average proportion of head movement while speaking in the range [0,1].&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0.5&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;avatarIgnoreCamera&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If set to &lt;code&gt;true&lt;/code&gt;, makes the avatar to ignore the camera and speak to whatever it is facing.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;listeningSilence&lt;/code&gt;&lt;br /&gt;&lt;code&gt;ThresholdLevel&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Silence detection threshold in the range of [0,100]. If the volume stays below the level for the set duration, a &lt;code&gt;"stop"&lt;/code&gt; event is triggered.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;40&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;listeningSilence&lt;/code&gt;&lt;br /&gt;&lt;code&gt;ThresholdMs&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Silence detection duration in milliseconds. If the volume stays below the level for the set duration, a &lt;code&gt;"stop"&lt;/code&gt; event is triggered.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;2000&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;listeningSilence&lt;/code&gt;&lt;br /&gt;&lt;code&gt;DurationMax&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum silence in milliseconds before &lt;code&gt;"maxsilence"&lt;/code&gt; event is triggered.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;10000&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;listeningActive&lt;/code&gt;&lt;br /&gt;&lt;code&gt;ThresholdLevel&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Activity detection threshold in the range of [0,100]. If the volume stays above the set level for the set duration, a &lt;code&gt;"start"&lt;/code&gt; event is triggered.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;90&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;listeningActive&lt;/code&gt;&lt;br /&gt;&lt;code&gt;ThresholdMs&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Activity detection duration in milliseconds. If the volume stays above the set level for the set duration, a &lt;code&gt;"start"&lt;/code&gt; event is triggered.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;400&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;listeningActive&lt;/code&gt;&lt;br /&gt;&lt;code&gt;DurationMax&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Maximum activity in milliseconds before &lt;code&gt;"maxactive"&lt;/code&gt; event is triggered.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;240000&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;avatarOnly&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If &lt;code&gt;true&lt;/code&gt;, creates an avatar armature object instead of a standalone instance with a 3D scene, lights, and renderer. Read Appendix H for more details about the &lt;code&gt;avatarOnly&lt;/code&gt; mode. (EXPERIMENTAL)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;avatarOnlyCamera&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;In &lt;code&gt;avatarOnly&lt;/code&gt; mode, sets the camera to which the avatar is linked.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;avatarOnlyScene&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If set in &lt;code&gt;avatarOnly&lt;/code&gt; mode, the armature object is automatically added to the specified scene.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;update&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Custom callback function inside the &lt;code&gt;requestAnimationFrame&lt;/code&gt; animation loop. Enables the app to do custom processing before rendering the 3D scene. If &lt;code&gt;null&lt;/code&gt;, disabled.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;statsNode&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Parent DOM element for the three.js stats display. If &lt;code&gt;null&lt;/code&gt;, don't use.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;statsStyle&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;CSS style for the stats element. If &lt;code&gt;null&lt;/code&gt;, use the three.js default style.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;p&gt;Once the instance has been created, you can load and display your avatar. Refer to Appendix A for how to make your avatar:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;// Load and show the avatar
try {
  await head.showAvatar( {
    url: './avatars/brunette.glb',
    body: 'F',
    avatarMood: 'neutral',
    ttsLang: "en-GB",
    ttsVoice: "en-GB-Standard-A",
    lipsyncLang: 'en'
  });
} catch (error) {
  console.log(error);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;An example of how to make the avatar speak the text on input &lt;code&gt;text&lt;/code&gt; when the button &lt;code&gt;speak&lt;/code&gt; is clicked:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;// Speak 'text' when the button 'speak' is clicked
const nodeSpeak = document.getElementById('speak');
nodeSpeak.addEventListener('click', function () {
  try {
    const text = document.getElementById('text').value;
    if ( text ) {
      head.speakText( text );
    }
  } catch (error) {
    console.log(error);
  }
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;details&gt; 
 &lt;summary&gt;CLICK HERE to see the key METHODS.&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Method&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;showAvatar(avatar, [onprogress=null])&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Load and show the specified avatar. The &lt;code&gt;avatar&lt;/code&gt; object must include the &lt;code&gt;url&lt;/code&gt; for GLB file. Optional properties are &lt;code&gt;body&lt;/code&gt; for either male &lt;code&gt;M&lt;/code&gt; or female &lt;code&gt;F&lt;/code&gt; body form, &lt;code&gt;lipsyncLang&lt;/code&gt;, &lt;code&gt;lipsyncHeadMovement&lt;/code&gt;, &lt;code&gt;baseline&lt;/code&gt; object for blend shape baseline, &lt;code&gt;modelDynamicBones&lt;/code&gt; for dynamic bones (see Appendix E), &lt;code&gt;ttsLang&lt;/code&gt;, &lt;code&gt;ttsVoice&lt;/code&gt;, &lt;code&gt;ttsRate&lt;/code&gt;, &lt;code&gt;ttsPitch&lt;/code&gt;, &lt;code&gt;ttsVolume&lt;/code&gt;, &lt;code&gt;avatarMood&lt;/code&gt;, &lt;code&gt;avatarMute&lt;/code&gt;, &lt;code&gt;avatarIdleEyeContact&lt;/code&gt;, &lt;code&gt;avatarSpeakingEyeContact&lt;/code&gt;, &lt;code&gt;avatarListeningEyeContact&lt;/code&gt;, and &lt;code&gt;avatarIgnoreCamera&lt;/code&gt;.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;setView(view, [opt])&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Set view. Supported views are &lt;code&gt;"full"&lt;/code&gt;, &lt;code&gt;"mid"&lt;/code&gt;, &lt;code&gt;"upper"&lt;/code&gt; and &lt;code&gt;"head"&lt;/code&gt;. The &lt;code&gt;opt&lt;/code&gt; object can be used to set &lt;code&gt;cameraDistance&lt;/code&gt;, &lt;code&gt;cameraX&lt;/code&gt;, &lt;code&gt;cameraY&lt;/code&gt;, &lt;code&gt;cameraRotateX&lt;/code&gt;, &lt;code&gt;cameraRotateY&lt;/code&gt;.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;setLighting(opt)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Change lighting settings. The &lt;code&gt;opt&lt;/code&gt; object can be used to set &lt;code&gt;lightAmbientColor&lt;/code&gt;, &lt;code&gt;lightAmbientIntensity&lt;/code&gt;, &lt;code&gt;lightDirectColor&lt;/code&gt;, &lt;code&gt;lightDirectIntensity&lt;/code&gt;, &lt;code&gt;lightDirectPhi&lt;/code&gt;, &lt;code&gt;lightDirectTheta&lt;/code&gt;, &lt;code&gt;lightSpotColor&lt;/code&gt;, &lt;code&gt;lightSpotIntensity&lt;/code&gt;, &lt;code&gt;lightSpotPhi&lt;/code&gt;, &lt;code&gt;lightSpotTheta&lt;/code&gt;, &lt;code&gt;lightSpotDispersion&lt;/code&gt;.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;speakText(text, [opt={}], [onsubtitles=null], [excludes=[]])&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Add the &lt;code&gt;text&lt;/code&gt; string to the speech queue. The text can contain face emojis. Options &lt;code&gt;opt&lt;/code&gt; can be used to set text-specific &lt;code&gt;lipsyncLang&lt;/code&gt;, &lt;code&gt;ttsLang&lt;/code&gt;, &lt;code&gt;ttsVoice&lt;/code&gt;, &lt;code&gt;ttsRate&lt;/code&gt;, &lt;code&gt;ttsPitch&lt;/code&gt;, &lt;code&gt;ttsVolume&lt;/code&gt;, &lt;code&gt;avatarMood&lt;/code&gt;, &lt;code&gt;avatarMute&lt;/code&gt;. Optional callback function &lt;code&gt;onsubtitles&lt;/code&gt; is called whenever a new subtitle is to be written with the parameter of the added string. The optional &lt;code&gt;excludes&lt;/code&gt; is an array of [start,end] indices to be excluded from audio but to be included in the subtitles.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;speakAudio(audio, [opt={}], [onsubtitles=null])&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Add a new &lt;code&gt;audio&lt;/code&gt; object to the speech queue. In audio object, property &lt;code&gt;audio&lt;/code&gt; is either &lt;code&gt;AudioBuffer&lt;/code&gt; or an array of PCM 16bit LE audio chunks. Property &lt;code&gt;words&lt;/code&gt; is an array of words, &lt;code&gt;wtimes&lt;/code&gt; is an array of corresponding starting times in milliseconds, and &lt;code&gt;wdurations&lt;/code&gt; an array of durations in milliseconds. If the Oculus viseme IDs are known, they can be given in optional &lt;code&gt;visemes&lt;/code&gt;, &lt;code&gt;vtimes&lt;/code&gt; and &lt;code&gt;vdurations&lt;/code&gt; arrays. The object also supports optional timed callbacks using &lt;code&gt;markers&lt;/code&gt; and &lt;code&gt;mtimes&lt;/code&gt;. In addition, you can provide an optional &lt;code&gt;anim&lt;/code&gt; as an animation template object that can drive your own blendshape or morph target data in sync with audio playback. See Appendix F for more details. The &lt;code&gt;opt&lt;/code&gt; object can be used to set text-specific &lt;code&gt;lipsyncLang&lt;/code&gt;.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;streamStart(opt={}, onAudioStart = null, onAudioEnd = null, onSubtitles = null, onMetrics = null)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Sets the talking head in streaming mode. See Appendix G for streaming instructions.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;streamAudio(audio)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Starts feeding audio chunks to talkinghead in the streaming mode. See Appendix G for streaming instructions.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;streamNotifyEnd()&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Signals the end of streaming audio chunks to the talkinghead. See Appendix G for streaming instructions.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;streamInterrupt()&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Interrupts ongoing audio and lip-sync in streaming mode without ending the session. See Appendix G for streaming instructions.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;streamStop()&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Exits the streaming mode and ends the session. See Appendix G for streaming instructions.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;speakEmoji(e)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Add an emoji &lt;code&gt;e&lt;/code&gt; to the speech queue.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;speakBreak(t)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Add a break of &lt;code&gt;t&lt;/code&gt; milliseconds to the speech queue.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;speakMarker(onmarker)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Add a marker to the speech queue. The callback function &lt;code&gt;onmarker&lt;/code&gt; is called when the queue processes the marker.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lookAt(x,y,t)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Make the avatar's head turn to look at the screen position (&lt;code&gt;x&lt;/code&gt;,&lt;code&gt;y&lt;/code&gt;) for &lt;code&gt;t&lt;/code&gt; milliseconds.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lookAhead(t)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Make avatar look ahead for &lt;code&gt;t&lt;/code&gt; milliseconds.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;lookAtCamera(t)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Make the avatar's head turn to look at the camera for &lt;code&gt;t&lt;/code&gt; milliseconds. If &lt;code&gt;avatarIgnoreCamera&lt;/code&gt; is set to &lt;code&gt;true&lt;/code&gt;, looks ahead for &lt;code&gt;t&lt;/code&gt; milliseconds.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;makeEyeContact(t)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Make the avatar maintain eye contact with the person in front of it for (at least) &lt;code&gt;t&lt;/code&gt; milliseconds.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;setMood(mood)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Set avatar mood.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;playBackgroundAudio(url)&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Play background audio such as ambient sounds/music in a loop.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;stopBackgroundAudio()&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Stop playing the background audio.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;setMixerGain(speech, [background=null], [fadeSecs=0])&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The amount of gain for speech and background audio (see Web Audio API / GainNode for more information). Value &lt;code&gt;null&lt;/code&gt; means no change. Optional &lt;code&gt;fadeSecs&lt;/code&gt; parameter sets exponential fade in/out time in seconds.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;playAnimation(url, [onprogress=null], [dur=10], [ndx=0], [scale=0.01])&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Play Mixamo animation file for &lt;code&gt;dur&lt;/code&gt; seconds, but full rounds and at least once. If the FBX file includes several animations, the parameter &lt;code&gt;ndx&lt;/code&gt; specifies the index. Since Mixamo rigs have a scale 100 and RPM a scale 1, the &lt;code&gt;scale&lt;/code&gt; factor can be used to scale the positions.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;stopAnimation()&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Stop the current animation started by &lt;code&gt;playAnimation&lt;/code&gt;.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;playPose(url, [onprogress=null], [dur=5], [ndx=0], [scale=0.01])&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Play the initial pose of a Mixamo animation file for &lt;code&gt;dur&lt;/code&gt; seconds. If the FBX file includes several animations, the parameter &lt;code&gt;ndx&lt;/code&gt; specifies the index. Since Mixamo rigs have a scale 100 and RPM a scale 1, the &lt;code&gt;scale&lt;/code&gt; factor can be used to scale the positions.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;stopPose()&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Stop the current pose started by &lt;code&gt;playPose&lt;/code&gt;.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;playGesture(name, [dur=3], [mirror=false], [ms=1000])&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Play a named hand gesture and/or animated emoji for &lt;code&gt;dur&lt;/code&gt; seconds with the &lt;code&gt;ms&lt;/code&gt; transition time. The available hand gestures are &lt;code&gt;handup&lt;/code&gt;, &lt;code&gt;index&lt;/code&gt;, &lt;code&gt;ok&lt;/code&gt;, &lt;code&gt;thumbup&lt;/code&gt;, &lt;code&gt;thumbdown&lt;/code&gt;, &lt;code&gt;side&lt;/code&gt;, &lt;code&gt;shrug&lt;/code&gt;. By default, hand gestures are done with the left hand. If you want the right handed version, set &lt;code&gt;mirror&lt;/code&gt; to true. You can also use &lt;code&gt;playGesture&lt;/code&gt; to play emojis. See Appendix D for more details.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;stopGesture([ms=1000])&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Stop the gesture with &lt;code&gt;ms&lt;/code&gt; transition time.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;startListening(analyzer, [opt={}], [onchange=null])&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Start listening &lt;code&gt;analyzer&lt;/code&gt; AnalyserNode. The &lt;code&gt;opt&lt;/code&gt; object can be used to set options &lt;code&gt;listeningSilenceThresholdLevel&lt;/code&gt;, &lt;code&gt;listeningSilenceThresholdMs&lt;/code&gt;, &lt;code&gt;listeningSilenceDurationMax&lt;/code&gt;, &lt;code&gt;listeningActiveThresholdLevel&lt;/code&gt;, &lt;code&gt;listeningActiveThresholdMs&lt;/code&gt;, &lt;code&gt;listeningActiveDurationMax&lt;/code&gt;. The callback function &lt;code&gt;onchange&lt;/code&gt; is called, when the state changes with one of the following parameter: &lt;code&gt;start&lt;/code&gt;, &lt;code&gt;stop&lt;/code&gt;, &lt;code&gt;maxsilence&lt;/code&gt;, &lt;code&gt;maxactive&lt;/code&gt;.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;stopListening&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Stop listening the incoming audio.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;start&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Start/re-start the Talking Head animation loop.&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;stop&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Stop the Talking Head animation loop.&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;p&gt;The class has been tested on the latest Chrome, Firefox, Safari, and Edge desktop browsers, as well as on iPad.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;The &lt;code&gt;index.html&lt;/code&gt; Test App&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; &lt;em&gt;The &lt;code&gt;index.html&lt;/code&gt; app was created for testing and developing the TalkingHead class. It includes various integrations with several paid services. If you only want to use the TalkingHead class in your own app, there is no need to install and configure the &lt;code&gt;index.html&lt;/code&gt; app.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;In addition to testing and development, the test app be used as an example of how to integrate the TalkingHead class with &lt;a href="https://elevenlabs.io"&gt;ElevenLabs WebSocket API&lt;/a&gt;, &lt;a href="https://github.com/microsoft/cognitive-services-speech-sdk-js"&gt;Microsoft Azure Speech SDK&lt;/a&gt;, &lt;a href="https://openai.com"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://ai.google.dev/gemini-api"&gt;Gemini&lt;/a&gt; and &lt;a href="https://docs.x.ai"&gt;Grok&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can try out the test app online &lt;a href="https://met4citizen.github.io/TalkingHead/"&gt;here on GitHub&lt;/a&gt;. By default, the text-to-speech and AI features will not work, but you can activate them by navigating to the settings menu (☰) and pasting your own API key in the relevant field(s). Your API keys will not be stored, so you will need to re-enter them each time you reload the page.&lt;/p&gt; 
&lt;p&gt;To set up the test app in your local environment, follow these steps:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Copy the latest files to your own web server, for example:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone --depth 1 https://github.com/met4citizen/TalkingHead.git &amp;amp;&amp;amp; rm -r TalkingHead/.git
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Optional: Create API proxies as described in Appendix B and check/update your proxy configuration in &lt;code&gt;index.html&lt;/code&gt;:&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;// API proxys
const jwtEndpoint = "/app/jwt/get"; // Get JSON Web Token for Single Sign-On
const openaiChatCompletionsProxy = "/openai/v1/chat/completions";
const openaiModerationsProxy = "/openai/v1/moderations";
const openaiAudioTranscriptionsProxy = "/openai/v1/audio/transcriptions";
const vertexaiChatCompletionsProxy = "/vertexai/";
const googleTTSProxy = "/gtts/";
const elevenTTSProxy = [
  "wss://" + window.location.host + "/elevenlabs/",
  "/v1/text-to-speech/",
  "/stream-input?model_id=eleven_multilingual_v2&amp;amp;output_format=pcm_22050"
];
const microsoftTTSProxy = [
  "wss://" + window.location.host + "/mstts/",
  "/cognitiveservices/websocket/v1"
];
const grokChatCompletionsProxy = "/grok/v1/chat/completions"; // Grok-beta
const llamaChatCompletionsProxy = "/llama/v1/chat/completions"; // Local llama.cpp
const localWhisperCppProxy = "/whisper/"; // Local whisper.cpp
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt; &lt;p&gt;The test app's UI supports Finnish and English. If you want to add another language, you need to add an another entry to the &lt;code&gt;i18n&lt;/code&gt; object.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Add you own background images, videos, audio files, avatars etc. in the directory structure and update your site configuration &lt;code&gt;siteconfig.js&lt;/code&gt; accordingly. The keys are in English, but the entries can include translations to other languages.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Licenses, attributions and notes related to the &lt;code&gt;index.html&lt;/code&gt; web app assets:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;The app uses &lt;a href="https://github.com/markedjs/marked"&gt;Marked&lt;/a&gt; Markdown parser and &lt;a href="https://github.com/cure53/DOMPurify"&gt;DOMPurify&lt;/a&gt; XSS sanitizer.&lt;/li&gt; 
 &lt;li&gt;Fira Sans Condensed and Fira Sans Extra Condensed fonts are licensed under the SIL Open Font License, version 1.1, available with a FAQ at &lt;a href="http://scripts.sil.org/OFL"&gt;http://scripts.sil.org/OFL&lt;/a&gt;. Digitized data copyright (c) 2012-2015, The Mozilla Foundation and Telefonica S.A.&lt;/li&gt; 
 &lt;li&gt;SVG icons from &lt;a href="https://github.com/astrit/css.gg"&gt;css.gg&lt;/a&gt;, MIT License (versions prior to license update).&lt;/li&gt; 
 &lt;li&gt;Example avatar "brunette.glb" was created at &lt;a href="https://readyplayer.me/"&gt;Ready Player Me&lt;/a&gt;. The avatar is free to all developers for non-commercial use under the &lt;a href="https://creativecommons.org/licenses/by-nc/4.0/"&gt;CC BY-NC 4.0 DEED&lt;/a&gt;. If you want to integrate Ready Player Me avatars into a commercial app or game, you must sign up as a Ready Player Me developer.&lt;/li&gt; 
 &lt;li&gt;Example animation &lt;code&gt;walking.fbx&lt;/code&gt; and the pose &lt;code&gt;dance.fbx&lt;/code&gt; are from Mixamo, a subsidiary of Adobe Inc. &lt;a href="https://www.mixamo.com"&gt;Mixamo&lt;/a&gt; service is free and its animations/poses (&amp;gt;2000) can be used royalty free for personal, commercial, and non-profit projects. Raw animation files can't be distributed outside the project team and can't be used to train ML models.&lt;/li&gt; 
 &lt;li&gt;Background view examples are from &lt;a href="https://virtualbackgrounds.site"&gt;Virtual Backgrounds&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Impulse response (IR) files for reverb effects: 
  &lt;ul&gt; 
   &lt;li&gt;ir-room: &lt;a href="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/www.openairlib.net"&gt;OpenAir&lt;/a&gt;, Public Domain Creative Commons license&lt;/li&gt; 
   &lt;li&gt;ir-basement: &lt;a href="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/www.openairlib.net"&gt;OpenAir&lt;/a&gt;, Public Domain Creative Commons license&lt;/li&gt; 
   &lt;li&gt;ir-forest (Abies Grandis Forest, Wheldrake Wood): &lt;a href="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/www.openairlib.net"&gt;OpenAir&lt;/a&gt;, Creative Commons Attribution 4.0 International License&lt;/li&gt; 
   &lt;li&gt;ir-church (St. Andrews Church): &lt;a href="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/www.openairlib.net"&gt;OpenAir&lt;/a&gt;, Share Alike Creative Commons 3.0&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Ambient sounds/music attributions: 
  &lt;ul&gt; 
   &lt;li&gt;murmur.mp3: &lt;a href="https://github.com/siwalikm/coffitivity-offline"&gt;https://github.com/siwalikm/coffitivity-offline&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; None of the assets described above are used or distributed as part of the TalkingHead class releases. If you wish to use them in your own application, please refer to the exact terms of use provided by the copyright holders.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;FAQ&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Why not use the free Web Speech API?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The free Web Speech API can't provide word-to-audio timestamps, which are essential for accurate lip-sync. As far as I know, there is no way even to get Web Speech API speech synthesis as an audio file or determine its duration in advance. At some point I tried to use the Web Speech API events for syncronization, but the results were not good.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;What paid text-to-speech service should I use?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;It depends on your use case and budget. If the built-in lip-sync support is sufficient for your needs, I would recommend Google TTS, because it gives you up to 4 million characters for free each month. If your app needs to support multiple languages, I would consider Microsoft Speech SDK.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;I would like to have lip-sync support for language X.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You have two options. First, you can implement a word-to-viseme class similar to those that currently exist for English and Finnish. See Appendix C for detailed instructions. Alternatively, you can check if Microsoft Azure TTS can provide visemes for your language and use Microsoft Speech SDK integration (&lt;code&gt;speakAudio&lt;/code&gt;) instead of Google TTS and the built-in lip-sync (&lt;code&gt;speakText&lt;/code&gt;).&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Can I use a custom 3D model?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The class supports full-body Ready Player Me avatars. You can also make your own custom model, but it needs to have a RPM compatible rig/bone structure and all their blend shapes. Please refer to Appendix A and readyplayer.me documentation for more details.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Any future plans for the project?&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This is just a small side-project for me, so I don't have any big plans for it. That said, there are several companies that are currently developing text-to-3D-avatar and text-to-3D-animation features. If and when they get released as APIs, I will probably take a look at them and see if they can be used/integrated in some way to the project.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;References&lt;/h3&gt; 
&lt;p&gt;[1] &lt;a href="https://en.wiktionary.org/wiki/Appendix:Finnish_pronunciation"&gt;Finnish pronunciation&lt;/a&gt;, Wiktionary&lt;/p&gt; 
&lt;p&gt;[2] Elovitz, H. S., Johnson, R. W., McHugh, A., Shore, J. E., Automatic Translation of English Text to Phonetics by Means of Letter-to-Sound Rules (NRL Report 7948). Naval Research Laboratory (NRL). Washington, D. C., 1976. &lt;a href="https://apps.dtic.mil/sti/pdfs/ADA021929.pdf"&gt;https://apps.dtic.mil/sti/pdfs/ADA021929.pdf&lt;/a&gt;&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Appendix A: Create Your Own 3D Avatar&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;FOR HOBBYISTS:&lt;/strong&gt;&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;Create your own full-body avatar free at &lt;a href="https://readyplayer.me/avatar/"&gt;https://readyplayer.me/avatar/&lt;/a&gt; or &lt;a href="https://playerzero.readyplayer.me/"&gt;https://playerzero.readyplayer.me/&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;Copy your avatar’s unique ID (e.g., &lt;code&gt;64bfa15f0e72c63d7c3934a6&lt;/code&gt;) and download the GLB file using one of the links below. Replace the ID with your own, and make sure to keep the URL parameters to include the necessary morph targets (blend shapes).&lt;br /&gt;&lt;br /&gt;Ready Player Me:&lt;br /&gt;&lt;code&gt;https://models.readyplayer.me/64bfa15f0e72c63d7c3934a6.glb?morphTargets=ARKit,Oculus+Visemes,mouthOpen,mouthSmile,eyesClosed,eyesLookUp,eyesLookDown&amp;amp;textureSizeLimit=1024&amp;amp;textureFormat=png&lt;/code&gt;&lt;br /&gt;&lt;br /&gt;PlayerZero:&lt;br /&gt;&lt;code&gt;https://avatars.readyplayer.me/67ebd62a688cd661ebe09988.glb?morphTargetsGroup=ARKit,Oculus+Visemes&amp;amp;morphTargets=mouthSmile,mouthOpen,eyesClosed,eyesLookUp,eyesLookDown&amp;amp;textureSizeLimit=1024&amp;amp;textureFormat=png&lt;/code&gt;&lt;br /&gt;&lt;br /&gt;Depending on your use case, you can customize the texture format and texture quality (e.g. &lt;code&gt;textureFormat=webp&amp;amp;textureQuality=high&lt;/code&gt;), the triangle count (e.g. &lt;code&gt;lod=1&lt;/code&gt;), use Draco mesh compression (&lt;code&gt;useDracoMeshCompression=true&lt;/code&gt;), and so on. See the full list of option &lt;a href="https://docs.readyplayer.me/ready-player-me/api-reference/rest-api/avatars/get-3d-avatars"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;FOR 3D MODELERS:&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;You can create and use your own 3D full-body model, but it has to be Ready Player Me compatible. Their rig has a Mixamo-compatible bone structure described here:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.readyplayer.me/ready-player-me/api-reference/avatars/full-body-avatars"&gt;https://docs.readyplayer.me/ready-player-me/api-reference/avatars/full-body-avatars&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;For lip-sync and facial expressions, you also need to have ARKit and Oculus compatible blend shapes, and a few additional ones, all listed in the following two pages:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://docs.readyplayer.me/ready-player-me/api-reference/avatars/morph-targets/apple-arkit"&gt;https://docs.readyplayer.me/ready-player-me/api-reference/avatars/morph-targets/apple-arkit&lt;/a&gt; &lt;a href="https://docs.readyplayer.me/ready-player-me/api-reference/avatars/morph-targets/oculus-ovr-libsync"&gt;https://docs.readyplayer.me/ready-player-me/api-reference/avatars/morph-targets/oculus-ovr-libsync&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP]&lt;br /&gt; The additional blend shapes mentioned in the specs (&lt;code&gt;"mouthOpen"&lt;/code&gt;, &lt;code&gt;"mouthSmile"&lt;/code&gt;, &lt;code&gt;"eyesClosed"&lt;/code&gt;, &lt;code&gt;"eyesLookUp"&lt;/code&gt;, &lt;code&gt;"eyesLookDown"&lt;/code&gt;) are not strictly required, as the TalkingHead class will automatically generate them from ARKit blend shapes if they are missing.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;The TalkingHead class supports both separated mesh and texture atlasing.&lt;/p&gt; 
&lt;p&gt;Here are some Blender Python scripts that could be useful in converting custom models:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Script&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/met4citizen/TalkingHead/raw/main/blender/rename-mixamo-bones.py"&gt;rename-mixamo-bones.py&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;If your model doesn't have a compatible rig, you can auto-rig your model easily at &lt;a href="https://www.mixamo.com"&gt;Mixamo&lt;/a&gt; and use this Blender script to rename the Mixamo bones.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/met4citizen/TalkingHead/raw/main/blender/rename-rocketbox-shapekeys.py"&gt;rename-rocketbox-shapekeys.py&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;Rename &lt;a href="https://github.com/microsoft/Microsoft-Rocketbox"&gt;Microsoft Rocketbox&lt;/a&gt; model shape keys.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/met4citizen/TalkingHead/raw/main/blender/rename-avatarsdk-shapekeys.py"&gt;rename-avatarsdk-shapekeys.py&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;Rename &lt;a href="https://github.com/avatarsdk"&gt;Avatar SDK MetaPerson&lt;/a&gt; model shape keys.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/met4citizen/TalkingHead/raw/main/blender/build-extras-from-arkit.py"&gt;build-extras-from-arkit.py&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;Build RPM extras (mouthOpen, mouthSmile, eyesClosed, eyesLookUp, eyesLookDown) from ARKit blendshapes. Note: The TalkingHead will generate these automatically if they're missing. However, building them yourself allows you to fine-tune them to your taste.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;a href="https://github.com/met4citizen/TalkingHead/raw/main/blender/build-visemes-from-arkit.py"&gt;build-visemes-from-arkit.py&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;&amp;nbsp;Build Oculus visemes from ARKit blendshapes. As models are all different, you should fine-tune the script for best result. EXPERIMENTAL&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Appendix B: Create API Proxies with JSON Web Token (JWT) Single Sign-On (SSO)&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Make a CGI script that generates a new JSON Web Token with an expiration time (exp). See &lt;a href="https://jwt.io"&gt;jwt.io&lt;/a&gt; for more information about JWT and libraries that best fit your needs and architecture. In my own test setup, I return the generated JWT as JSON.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{ "jwt": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c" }
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="2"&gt; 
 &lt;li&gt;Protect your CGI script with some authentication scheme. Below is an example Apache 2.4 directory config that uses Basic authentication (remember to always use HTTPS/SSL!). Put your CGI script &lt;code&gt;get&lt;/code&gt; in the &lt;code&gt;jwt&lt;/code&gt; directory.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-apacheconf"&gt;# Restricted applications
&amp;lt;Directory "/var/www/app"&amp;gt;
  AuthType Basic
  AuthName "Restricted apps"
  AuthUserFile /etc/httpd/.htpasswd
  Require valid-user
&amp;lt;/Directory&amp;gt;

# JSON Web Token
&amp;lt;Directory "/var/www/app/jwt" &amp;gt;
  Options ExecCGI
  SetEnv REMOTE_USER %{REMOTE_USER}
  SetHandler cgi-script
&amp;lt;/Directory&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="3"&gt; 
 &lt;li&gt;Make an &lt;a href="https://httpd.apache.org/docs/2.4/rewrite/rewritemap.html#prg"&gt;External Rewriting Program&lt;/a&gt; script that verifies JSON Web Tokens. The script should return &lt;code&gt;OK&lt;/code&gt; if the given token is not expired and its signature is valid. Start the script in Apache 2.4 config. User's don't use the verifier script directly, so put it in some internal directory, not under document root.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-apacheconf"&gt;# JSON Web Token verifier
RewriteEngine On
RewriteMap jwtverify "prg:/etc/httpd/jwtverify" apache:apache
&lt;/code&gt;&lt;/pre&gt; 
&lt;ol start="4"&gt; 
 &lt;li&gt;Make a proxy configuration for each service you want to use. Add the required API keys and protect the proxies with the JWT token verifier. Below are some example configs for Apache 2.4 web server. Note that when opening a WebSocket connection (ElevenLabs, Azure) you can't add authentication headers in browser JavaScript. This problem is solved here by including the JWT token as a part of the request URL. The downside is that the token might end up in server log files. This is typically not a problem as long as you are controlling the proxy server, you are using HTTPS/SSL, and the token has an expiration time.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-apacheconf"&gt;# OpenAI API
&amp;lt;Location /openai/&amp;gt;
  RewriteCond ${jwtverify:%{http:Authorization}} !=OK
  RewriteRule .+ - [F]
  ProxyPass https://api.openai.com/
  ProxyPassReverse  https://api.openai.com/
  ProxyPassReverseCookiePath "/"  "/openai/"
  ProxyPassReverseCookieDomain ".api.openai.com" ".&amp;lt;insert-your-proxy-domain-here&amp;gt;"
  RequestHeader set Authorization "Bearer &amp;lt;insert-your-openai-api-key-here&amp;gt;"
&amp;lt;/Location&amp;gt;

# Google TTS API
&amp;lt;Location /gtts/&amp;gt;
  RewriteCond ${jwtverify:%{http:Authorization}} !=OK
  RewriteRule .+ - [F]
  ProxyPass https://eu-texttospeech.googleapis.com/v1beta1/text:synthesize?key=&amp;lt;insert-your-api-key-here&amp;gt; nocanon
  RequestHeader unset Authorization
&amp;lt;/Location&amp;gt;

# Microsoft Azure TTS WebSocket API (Speech SDK)
&amp;lt;LocationMatch /mstts/(?&amp;lt;jwt&amp;gt;[^/]+)/&amp;gt;
  RewriteCond ${jwtverify:%{env:MATCH_JWT}} !=OK
  RewriteRule .+ - [F]
  RewriteCond %{HTTP:Connection} Upgrade [NC]
  RewriteCond %{HTTP:Upgrade} websocket [NC]
  RewriteRule /mstts/[^/]+/(.+) "wss://&amp;lt;insert-your-region-here&amp;gt;.tts.speech.microsoft.com/$1" [P]
  RequestHeader set "Ocp-Apim-Subscription-Key" &amp;lt;insert-your-subscription-key-here&amp;gt;
&amp;lt;/LocationMatch&amp;gt;

# ElevenLabs Text-to-speech WebSocket API
&amp;lt;LocationMatch /elevenlabs/(?&amp;lt;jwt&amp;gt;[^/]+)/&amp;gt;
  RewriteCond ${jwtverify:%{env:MATCH_JWT}} !=OK
  RewriteRule .+ - [F]
  RewriteCond %{HTTP:Connection} Upgrade [NC]
  RewriteCond %{HTTP:Upgrade} websocket [NC]
  RewriteRule /elevenlabs/[^/]+/(.+) "wss://api.elevenlabs.io/$1" [P]
  RequestHeader set "xi-api-key" "&amp;lt;add-your-elevenlabs-api-key-here&amp;gt;"
&amp;lt;/LocationMatch&amp;gt;
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Appendix C: Create A New Lip-sync Module&lt;/h3&gt; 
&lt;p&gt;The steps that are common to all new languages:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Create a new file named &lt;code&gt;lipsync-xx.mjs&lt;/code&gt; where &lt;code&gt;xx&lt;/code&gt; is your language code, and place the file in the &lt;code&gt;./modules/&lt;/code&gt; directory. The language module should have a class named &lt;code&gt;LipsyncXx&lt;/code&gt; where Xx is the language code. The naming in important, because the modules are loaded dynamically based on their names.&lt;/li&gt; 
 &lt;li&gt;The class should have (at least) the following two methods: &lt;code&gt;preProcessText&lt;/code&gt; and &lt;code&gt;wordsToVisemes&lt;/code&gt;. These are the methods used in the TalkingHead class.&lt;/li&gt; 
 &lt;li&gt;The purpose of the &lt;code&gt;preProcessText&lt;/code&gt; method is to preprocess the given text by converting symbols to words, numbers to words, and filtering out characters that should be left unspoken (if any), etc. This is often needed to prevent ambiguities between TTS and lip-sync engines. This method takes a string as a parameter and returns the preprocessed string.&lt;/li&gt; 
 &lt;li&gt;The purpose of the &lt;code&gt;wordsToVisemes&lt;/code&gt; method is to convert the given text into visemes and timestamps. The method takes a string as a parameter and returns a lip-sync object. The lipsync object has three required properties: &lt;code&gt;visemes&lt;/code&gt;, &lt;code&gt;times&lt;/code&gt;and &lt;code&gt;durations&lt;/code&gt;. 
  &lt;ul&gt; 
   &lt;li&gt;Property &lt;code&gt;visemes&lt;/code&gt; is an array of Oculus OVR viseme codes. Each viseme is one of the strings: &lt;code&gt;'aa'&lt;/code&gt;, &lt;code&gt;'E'&lt;/code&gt;, &lt;code&gt;'I'&lt;/code&gt;, &lt;code&gt;'O'&lt;/code&gt;, &lt;code&gt;'U'&lt;/code&gt;, &lt;code&gt;'PP'&lt;/code&gt;, &lt;code&gt;'SS'&lt;/code&gt;, &lt;code&gt;'TH'&lt;/code&gt;, &lt;code&gt;'CH'&lt;/code&gt;, &lt;code&gt;'FF'&lt;/code&gt;, &lt;code&gt;'kk'&lt;/code&gt;, &lt;code&gt;'nn'&lt;/code&gt;, &lt;code&gt;'RR'&lt;/code&gt;, &lt;code&gt;'DD'&lt;/code&gt;, &lt;code&gt;'sil'&lt;/code&gt;. See the reference images here: &lt;a href="https://developer.oculus.com/documentation/unity/audio-ovrlipsync-viseme-reference/"&gt;https://developer.oculus.com/documentation/unity/audio-ovrlipsync-viseme-reference/&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;Property &lt;code&gt;times&lt;/code&gt; is an array of starting times, one entry for each viseme in &lt;code&gt;visemes&lt;/code&gt;. Starting times are to be given in relative units. They will be scaled later on based on the word timestamps that we get from the TTS engine.&lt;/li&gt; 
   &lt;li&gt;Property &lt;code&gt;durations&lt;/code&gt; is an array of relative durations, one entry for each viseme in &lt;code&gt;visemes&lt;/code&gt;. Durations are to be given in relative units. They will be scaled later on based on the word timestamps that we get from the TTS engine.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The difficult part is to actually make the conversion from words to visemes. What is the best approach depends on the language. Here are some typical approaches to consider (not a comprehensive list):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Direct mapping from graphemes to phonemes to visemes&lt;/strong&gt;. This works well for languages that have a consistent one-to-one mapping between individual letters and phonemes. This was used as the approach for the Finnish language (&lt;code&gt;lipsync-fi.mjs&lt;/code&gt;) giving &amp;gt;99.9% lip-sync accuracy compared to the Finnish phoneme dictionary. Implementation size was ~4k. Unfortunately not all languages are phonetically orthographic languages.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Rule-based mapping&lt;/strong&gt;. This was used as the approach for the English language (&lt;code&gt;lipsync-en.mjs&lt;/code&gt;) giving around 80% lip-sync accuracy compared to the English phoneme dictionary. However, since the rules cover the most common words, the effective accuracy is higher. Implementation size ~12k.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Dictionary based approach&lt;/strong&gt;. If neither of the previous approaches work for your language, make a search from some open source phoneme dictionary. Note that you still need some backup algorithm for those words that are not in the dictionary. The problem with phoneme dictionaries is their size. For example, the CMU phoneme dictionary for English is ~5M.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Neural-net approach based on transformer models&lt;/strong&gt;. Typically this should be done on server-side as the model size can be &amp;gt;50M.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;TalkingHead is supposed to be a real-time class, so latency is always something to consider. It is often better to be small and fast than to aim for 100% accuracy.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Appendix D: Adding Custom Poses, Moods, Gestures, and Emojis (ADVANCED)&lt;/h3&gt; 
&lt;p&gt;In the TalkingHead class, the avatar's movements are based on four data structures: &lt;code&gt;head.poseTemplates&lt;/code&gt;, &lt;code&gt;head.animMoods&lt;/code&gt;, &lt;code&gt;head.gestureTemplates&lt;/code&gt;, and &lt;code&gt;head.animEmojis&lt;/code&gt;. By using these objects, you can give your avatar its own personal body language.&lt;/p&gt; 
&lt;p&gt;In &lt;code&gt;head.poseTemplates&lt;/code&gt; the hip position is defined as an {x, y, z} coordinate in meters, and bone rotations as Euler XYZ rotations in radians. In each pose, the avatar should have its weight on the left leg, if any, as the class automatically mirrors it for the right side. Setting the boolean properties &lt;code&gt;standing&lt;/code&gt;, &lt;code&gt;sitting&lt;/code&gt;, &lt;code&gt;bend&lt;/code&gt;, &lt;code&gt;kneeling&lt;/code&gt;, and &lt;code&gt;lying&lt;/code&gt; helps the class make the transitions between different poses in proper steps.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;head.poseTemplates["custom-pose-1"] = {
  standing: true, sitting: false, bend: false, kneeling: false, lying: false,
  props: {
    'Hips.position':{x:0, y:0.989, z:0.001}, 'Hips.rotation':{x:0.047, y:0.007, z:-0.007}, 'Spine.rotation':{x:-0.143, y:-0.007, z:0.005}, 'Spine1.rotation':{x:-0.043, y:-0.014, z:0.012}, 'Spine2.rotation':{x:0.072, y:-0.013, z:0.013}, 'Neck.rotation':{x:0.048, y:-0.003, z:0.012}, 'Head.rotation':{x:0.05, y:-0.02, z:-0.017}, 'LeftShoulder.rotation':{x:1.62, y:-0.166, z:-1.605}, 'LeftArm.rotation':{x:1.275, y:0.544, z:-0.092}, 'LeftForeArm.rotation':{x:0, y:0, z:0.302}, 'LeftHand.rotation':{x:-0.225, y:-0.154, z:0.11}, 'LeftHandThumb1.rotation':{x:0.435, y:-0.044, z:0.457}, 'LeftHandThumb2.rotation':{x:-0.028, y:0.002, z:-0.246}, 'LeftHandThumb3.rotation':{x:-0.236, y:-0.025, z:0.113}, 'LeftHandIndex1.rotation':{x:0.218, y:0.008, z:-0.081}, 'LeftHandIndex2.rotation':{x:0.165, y:-0.001, z:-0.017}, 'LeftHandIndex3.rotation':{x:0.165, y:-0.001, z:-0.017}, 'LeftHandMiddle1.rotation':{x:0.235, y:-0.011, z:-0.065}, 'LeftHandMiddle2.rotation':{x:0.182, y:-0.002, z:-0.019}, 'LeftHandMiddle3.rotation':{x:0.182, y:-0.002, z:-0.019}, 'LeftHandRing1.rotation':{x:0.316, y:-0.017, z:0.008}, 'LeftHandRing2.rotation':{x:0.253, y:-0.003, z:-0.026}, 'LeftHandRing3.rotation':{x:0.255, y:-0.003, z:-0.026}, 'LeftHandPinky1.rotation':{x:0.336, y:-0.062, z:0.088}, 'LeftHandPinky2.rotation':{x:0.276, y:-0.004, z:-0.028}, 'LeftHandPinky3.rotation':{x:0.276, y:-0.004, z:-0.028}, 'RightShoulder.rotation':{x:1.615, y:0.064, z:1.53}, 'RightArm.rotation':{x:1.313, y:-0.424, z:0.131}, 'RightForeArm.rotation':{x:0, y:0, z:-0.317}, 'RightHand.rotation':{x:-0.158, y:-0.639, z:-0.196}, 'RightHandThumb1.rotation':{x:0.44, y:0.048, z:-0.549}, 'RightHandThumb2.rotation':{x:-0.056, y:-0.008, z:0.274}, 'RightHandThumb3.rotation':{x:-0.258, y:0.031, z:-0.095}, 'RightHandIndex1.rotation':{x:0.169, y:-0.011, z:0.105}, 'RightHandIndex2.rotation':{x:0.134, y:0.001, z:0.011}, 'RightHandIndex3.rotation':{x:0.134, y:0.001, z:0.011}, 'RightHandMiddle1.rotation':{x:0.288, y:0.014, z:0.092}, 'RightHandMiddle2.rotation':{x:0.248, y:0.003, z:0.02}, 'RightHandMiddle3.rotation':{x:0.249, y:0.003, z:0.02}, 'RightHandRing1.rotation':{x:0.369, y:0.019, z:0.006}, 'RightHandRing2.rotation':{x:0.321, y:0.004, z:0.026}, 'RightHandRing3.rotation':{x:0.323, y:0.004, z:0.026}, 'RightHandPinky1.rotation':{x:0.468, y:0.085, z:-0.03}, 'RightHandPinky2.rotation':{x:0.427, y:0.007, z:0.034}, 'RightHandPinky3.rotation':{x:0.142, y:0.001, z:0.012}, 'LeftUpLeg.rotation':{x:-0.077, y:-0.058, z:3.126}, 'LeftLeg.rotation':{x:-0.252, y:0.001, z:-0.018}, 'LeftFoot.rotation':{x:1.315, y:-0.064, z:0.315}, 'LeftToeBase.rotation':{x:0.577, y:-0.07, z:-0.009}, 'RightUpLeg.rotation':{x:-0.083, y:-0.032, z:3.124}, 'RightLeg.rotation':{x:-0.272, y:-0.003, z:0.021}, 'RightFoot.rotation':{x:1.342, y:0.076, z:-0.222}, 'RightToeBase.rotation':{x:0.44, y:0.069, z:0.016}
  }
};
head.playPose("custom-pose-1");
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In &lt;code&gt;head.animMoods&lt;/code&gt; the syntax is more complex, so I suggest that you take a look at the existing moods. In &lt;code&gt;anims&lt;/code&gt;, each leaf object is an animation loop template. Whenever a loop starts, the class iterates through the nested hierarchy of objects by following keys that match the current state (&lt;code&gt;idle&lt;/code&gt;, &lt;code&gt;talking&lt;/code&gt;), body form (&lt;code&gt;M&lt;/code&gt;, &lt;code&gt;F&lt;/code&gt;), current view (&lt;code&gt;full&lt;/code&gt;, &lt;code&gt;upper&lt;/code&gt;, &lt;code&gt;mid&lt;/code&gt;, &lt;code&gt;head&lt;/code&gt;), and/or probabilities (&lt;code&gt;alt&lt;/code&gt; + &lt;code&gt;p&lt;/code&gt;). The next animation will be created internally by using the &lt;code&gt;animFactory&lt;/code&gt; method. The property &lt;code&gt;delay&lt;/code&gt; (ms) determines how long that pose is held, &lt;code&gt;dt&lt;/code&gt; defines durations (ms) for each part in the sequence, and &lt;code&gt;vs&lt;/code&gt; defines the shapekeys and their target values for each part.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;
head.animMoods["custom-mood-1"] = {
  baseline: { eyesLookDown: 0.1 },
  speech: { deltaRate: 0, deltaPitch: 0, deltaVolume: 0 },
  anims: [
    { name: 'breathing', delay: 1500, dt: [ 1200,500,1000 ], vs: { chestInhale: [0.5,0.5,0] } },
    { name: 'pose', alt: [
      { p: 0.2, delay: [5000,20000], vs: { pose: ['side'] } },
      { p: 0.2, delay: [5000,20000], vs: { pose: ['hip'] },
        'M': { delay: [5000,20000], vs: { pose: ['wide'] } }
      },
      { delay: [5000,20000], vs: { pose: ['custom-pose-1'] } }
    ]},
    { name: 'head',
      idle: { delay: [0,1000], dt: [ [200,5000] ], vs: { headRotateX: [[-0.04,0.10]], headRotateY: [[-0.3,0.3]], headRotateZ: [[-0.08,0.08]] } },
      talking: { dt: [ [0,1000,0] ], vs: { headRotateX: [[-0.05,0.15,1,2]], headRotateY: [[-0.1,0.1]], headRotateZ: [[-0.1,0.1]] } }
    },
    { name: 'eyes', delay: [200,5000], dt: [ [100,500],[100,5000,2] ], vs: { eyesRotateY: [[-0.6,0.6]], eyesRotateX: [[-0.2,0.6]] } },
    { name: 'blink', delay: [1000,8000,1,2], dt: [50,[100,300],100], vs: { eyeBlinkLeft: [1,1,0], eyeBlinkRight: [1,1,0] } },
    { name: 'mouth', delay: [1000,5000], dt: [ [100,500],[100,5000,2] ], vs : { mouthRollLower: [[0,0.3,2]], mouthRollUpper: [[0,0.3,2]], mouthStretchLeft: [[0,0.3]], mouthStretchRight: [[0,0.3]], mouthPucker: [[0,0.3]] } },
    { name: 'misc', delay: [100,5000], dt: [ [100,500],[100,5000,2] ], vs : { eyeSquintLeft: [[0,0.3,3]], eyeSquintRight: [[0,0.3,3]], browInnerUp: [[0,0.3]], browOuterUpLeft: [[0,0.3]], browOuterUpRight: [[0,0.3]] } }
  ]
};
head.setMood("custom-mood-1");

&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Typical value range is [0,1] or [-1,1]. At the end of each animation, the value will automatically return to its baseline value. If the value is an array, it defines a range for a uniform/Gaussian random value (approximated using CLT). See the class method &lt;code&gt;gaussianRandom&lt;/code&gt; for more information.&lt;/p&gt; 
&lt;p&gt;In &lt;code&gt;head.gestureTemplates&lt;/code&gt; each property is a subset of bone rotations that will be used to override the current pose.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;head.gestureTemplates["salute"] = {
  'LeftShoulder.rotation':{x:1.706, y:-0.171, z:-1.756}, 'LeftArm.rotation':{x:0.883, y:-0.288, z:0.886}, 'LeftForeArm.rotation':{x:0, y:0, z:2.183}, 'LeftHand.rotation':{x:0.029, y:-0.298, z:0.346}, 'LeftHandThumb1.rotation':{x:1.43, y:-0.887, z:0.956}, 'LeftHandThumb2.rotation':{x:-0.406, y:0.243, z:0.094}, 'LeftHandThumb3.rotation':{x:-0.024, y:0.008, z:-0.012}, 'LeftHandIndex1.rotation':{x:0.247, y:-0.011, z:-0.084}, 'LeftHandIndex2.rotation':{x:0.006, y:0, z:0}, 'LeftHandIndex3.rotation':{x:-0.047, y:0, z:0.004}, 'LeftHandMiddle1.rotation':{x:0.114, y:-0.004, z:-0.055}, 'LeftHandMiddle2.rotation':{x:0.09, y:0, z:-0.007}, 'LeftHandMiddle3.rotation':{x:0.078, y:0, z:-0.006}, 'LeftHandRing1.rotation':{x:0.205, y:-0.009, z:0.023}, 'LeftHandRing2.rotation':{x:0.109, y:0, z:-0.009}, 'LeftHandRing3.rotation':{x:-0.015, y:0, z:0.001}, 'LeftHandPinky1.rotation':{x:0.267, y:-0.012, z:0.031}, 'LeftHandPinky2.rotation':{x:0.063, y:0, z:-0.005}, 'LeftHandPinky3.rotation':{x:0.178, y:-0.001, z:-0.014}
};
head.playGesture("salute",3);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;In &lt;code&gt;head.animEmojis&lt;/code&gt; each object is an animated emoji. Note that you can also use &lt;code&gt;head.playGesture&lt;/code&gt; to play animated emojis. This makes it easy to combine a hand gesture and a facial expression by giving the gesture and the emoji the same name.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;head.animEmojis["🫤"] = { dt: [300,2000], vs: {
    browInnerUp: [0.5], eyeWideLeft: [0.5], eyeWideRight: [0.5], mouthLeft: [0.5], mouthPressLeft: [0.8], mouthPressRight: [0.2], mouthRollLower: [0.5], mouthStretchLeft: [0.7],   mouthStretchRight: [0.7]
  }
};
head.playGesture("🫤",3);
&lt;/code&gt;&lt;/pre&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Appendix E: Dynamic Bones (ADVANCED)&lt;/h3&gt; 
&lt;p&gt;If you want your character's hair or other body parts to wiggle as the character moves, you can use TalkingHead's Dynamic Bones feature. The built-in physics engine simulates Newton's equations of motions using a spring-damper model and the &lt;a href="https://en.wikipedia.org/wiki/Verlet_integration"&gt;velocity Verlet integration&lt;/a&gt; method.&lt;/p&gt; 
&lt;p&gt;Standard Ready Player Me 3D avatars don't yet include features like hair bones. Until they do, you'll need to add the dynamic bones and weights to the model yourself. Here's an example of rigged hair in Blender.&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/images/ponytail.jpg" /&gt; 
&lt;p&gt;Once your custom rig is in place, you can configure the dynamic bones by setting the &lt;code&gt;modelDynamicBones&lt;/code&gt; property to the &lt;code&gt;avatar&lt;/code&gt; object of the &lt;code&gt;showAvatar&lt;/code&gt; method. Here's an example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;// Load and show the avatar
try {
  await head.showAvatar( {
    url: './avatars/custom.glb',
    body: 'F',
    avatarMood: 'neutral',
    ttsLang: "en-GB",
    ttsVoice: "en-GB-Standard-A",
    lipsyncLang: 'en',
    modelDynamicBones: [
      {
        bone: "ponytail1", type: "full", stiffness: 20, damping: 2,
        limits: [null,null,[null,0.01],null],
      },
      {
        bone: "ponytail2", type: "full", stiffness: 200, damping: 10,
        pivot: true
      },
      {
        bone: "ponytail3", type: "full", stiffness: 400, damping: 10,
        excludes: [{"bone":"Head","deltaLocal":[0,0.05,0.02],"radius":0.13}]
      }
    ]
  });
} catch (error) {
  console.log(error);
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Each item in &lt;code&gt;modelDynamicBones&lt;/code&gt; array represents one dynamic bone, which can be configured separately.&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;CLICK HERE to see all the available PROPERTIES.&lt;/summary&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Property&lt;/th&gt; 
    &lt;th&gt;Description&lt;/th&gt; 
    &lt;th&gt;Example&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;bone&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;The name of the bone in your custom skeleton. Note that each dynamic bone must have a parent bone.&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;"ponytail1"&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;type&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;
     &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;"point"&lt;/code&gt; updates only the bone's local position [x,y,z]. It is fast to calculate, but may cause skinned meshes to deform unnaturally.&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;"link"&lt;/code&gt; updates only the parent's quaternions (XZ rotations).&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;"mix1"&lt;/code&gt; mixes XZ rotations with a stretch (bone length, position change).&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;"mix2"&lt;/code&gt; mixes XZ rotations with a twist (Y rotations).&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;"full"&lt;/code&gt; link with both stretch and twist.&lt;/li&gt;
     &lt;/ul&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;"full"&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;stiffness&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Mass-normalized spring constant &lt;code&gt;k&lt;/code&gt; [m/s^2]. Either a non-negative number or an array with separate values for each dimension [x, y, z, t].&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;20&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;damping&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Mass-normalized damping coefficient &lt;code&gt;c&lt;/code&gt; [1/s]. Either a non-negative number or an array with separate values for each dimension [x, y, z, t].&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;external&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;External scaling factor between [0,1] that can be used to scale down the external forces caused by parent's movement. If set to &lt;code&gt;0&lt;/code&gt;, the bone is rigid and moves with its parent without experiencing any external force. If set to &lt;code&gt;1&lt;/code&gt;, the bone follows its parent with a lag (inertia) and feels the force. OPTIONAL, default value &lt;code&gt;1.0&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;0.7&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;limits&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Sets the limiting range [low, high] for each dimension [x, y, z, t] in meters [m]. This can help prevent situations in which meshes overlap due to sudden movements or when the amplitude becomes unrealistic. Limits are applied in local space. OPTIONAL, default &lt;code&gt;null&lt;/code&gt; (no limit)&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;[null,null,[null,0.01],null]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;deltaLocal&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Local position translation [dx,dy,dz] in meters [m]. OPTIONAL, default &lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;[0,0.01,0]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;deltaWorld&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;World position translation [dx,dy,dz] in meters [m]. OPTIONAL, default &lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;[0,-0.02,0]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;pivot&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If &lt;code&gt;true&lt;/code&gt;, the bone becomes a free-hanging bone along the Y-axis. This means that the parent's X/Z rotations are automatically compensated. Use with caution, as this requires additional computational effort, and the &lt;code&gt;limits&lt;/code&gt; do not apply as usual. OPTIONAL, default &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;excludes&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;Sets one or more spherical excluded zones that act as invisible force fields, limiting the movement of the bone. An array of objects in the format &lt;code&gt;{ bone, deltaLocal, radius}&lt;/code&gt; in which &lt;code&gt;bone&lt;/code&gt; specifies the center bone name, &lt;code&gt;deltaLocal&lt;/code&gt; (optional) offset [x,y,z] relative to center bone, and &lt;code&gt;radius&lt;/code&gt; in meters. OPTIONAL, default &lt;code&gt;null&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&amp;nbsp;&lt;code&gt;[ { bone: "Head", deltaLocal: [0,0.05,0.02], radius: 0.13 } ]&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;code&gt;helper&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;If &lt;code&gt;true&lt;/code&gt;, add a helper object to the scene to assist with visualizing the bone during testing. If the dynamic bone type is "point", displays only a square, otherwise also the line from parent to the bone. OPTIONAL, default &lt;code&gt;false&lt;/code&gt;&lt;/td&gt; 
    &lt;td&gt;&lt;code&gt;true&lt;/code&gt;&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
&lt;/details&gt; 
&lt;p&gt;Finding a good combination of &lt;code&gt;stiffness&lt;/code&gt;, &lt;code&gt;damping&lt;/code&gt;, and &lt;code&gt;external&lt;/code&gt;, is mostly a matter of trial and error. Turn on the helper property or use the test app to fine-tune the settings while running animations typical to your use case.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!TIP] For dynamic bones of type &lt;code&gt;"point"&lt;/code&gt;, you can simulate gravity by applying a &lt;code&gt;deltaWorld&lt;/code&gt; translation down the Y-axis and compensating for the initial stretch in the rest pose by applying &lt;code&gt;deltaLocal&lt;/code&gt; translation up the Y-axis.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Appendix F: Controlling Blendshapes Directly (Advanced)&lt;/h3&gt; 
&lt;p&gt;The TalkingHead class provides basic facial expressions and animations by controlling the 3D avatar's blendshapes (a.k.a. morph targets). It also possible to control these blendshapes directly from your app. Below are some of the available approaches, with simple code examples:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use &lt;code&gt;setFixedValue&lt;/code&gt; method to smoothly transition from the current blendshape value to some fixed value. The fixed value will override all other methods as well as internal/external animations. To return back to normal operation, set the fixed value to &lt;code&gt;null&lt;/code&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;head.setFixedValue("jawOpen",1);
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use the &lt;code&gt;realtime&lt;/code&gt; value of the &lt;code&gt;head.mtAvatar&lt;/code&gt; property to set the blend shape value without any smooth transition. This is useful for cases like face landmark detection, where you need to stay in sync with real-time input. To return back to normal operation, set the realtime value to &lt;code&gt;null&lt;/code&gt;:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;Object.assign( head.mtAvatar["jawOpen"],{ realtime: 1, needsUpdate: true });
&lt;/code&gt;&lt;/pre&gt; 
&lt;ul&gt; 
 &lt;li&gt;Add an animation template object &lt;code&gt;anim&lt;/code&gt; to the audio data in &lt;code&gt;speakAudio&lt;/code&gt; to drive blendshapes in sync with audio playback. This is especially useful when using facial animation data from external sources (e.g., Azure TTS 3D blendshapes or motion capture) and want to play it alongside spoken audio:&lt;/li&gt; 
&lt;/ul&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;head.speakAudio({
  audio: audio,
  anim: {
    name: "blendshapes",
    dt: [ 33, 33, 33, ... ],  // durations in milliseconds for each frame
    vs: { // Blend shape keys and values for each frame
      "jawOpen": [ 0, 0.2, 0.4, ... ],
      "mouthRollLower": [ 0, 0.05, 0.1, ... ],
      // ... additional blendshape keys
    }
  }
});
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;See a full code example using Azure blendshape output &lt;a href="https://raw.githubusercontent.com/met4citizen/TalkingHead/main/examples/azure-blendshapes.html"&gt;here&lt;/a&gt;. - &lt;strong&gt;Note&lt;/strong&gt;: Azure's output relies solely on ARKit blendshapes and is not optimized for RPM avatars. As a result, the quality of lip-sync may be less natural compared to using Oculus visemes and the TalkingHead's internal lip-sync language module. For example, the mouth may open too widely, or the lips may fail to touch for certain phonemes they should.&lt;/p&gt; 
&lt;p&gt;See also the next Appendix G for how to stream audio with lip-sync.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Appendix G: Streaming Audio and Lip-sync (Advanced)&lt;/h3&gt; 
&lt;p&gt;This low-level streaming interface is designed for real-time scenarios, such as speech-to-speech or live TTS integrations where latency must be minimized. Use this interface if you require direct, chunked audio playback and on-the-fly lip-sync updates. You can, for instance, integrate a real-time TTS pipeline (like Azure Speech SDK or another live audio source) that continuously streams audio and word/viseme data into TalkingHead.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; The calling application must handle all aspects of managing and synchronizing the data streams (e.g., facial expressions, eye contact, hand gestures), as well as preventing concurrency issues and buffering multiple sources. The system is designed to handle one stream at a time.&lt;/p&gt; 
&lt;h4&gt;Stream Session Reusability&lt;/h4&gt; 
&lt;p&gt;Once a streaming session is started with &lt;code&gt;streamStart()&lt;/code&gt;, the session remains active and reusable until explicitly ended with &lt;code&gt;streamStop()&lt;/code&gt;. You can:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Natural completion&lt;/strong&gt;: Call &lt;code&gt;streamNotifyEnd()&lt;/code&gt; after streaming all data with &lt;code&gt;streamAudio()&lt;/code&gt; to signal the end of an utterance. The session remains active for reuse.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Interruption&lt;/strong&gt;: Call &lt;code&gt;streamInterrupt()&lt;/code&gt; to immediately stop ongoing audio and lip-sync. The session remains active for reuse.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Reconfiguration&lt;/strong&gt;: Call &lt;code&gt;streamStart()&lt;/code&gt; again at any time to reconfigure the session with new options.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Session termination&lt;/strong&gt;: Call &lt;code&gt;streamStop()&lt;/code&gt; to completely end the streaming session.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;API Overview&lt;/h4&gt; 
&lt;h5&gt;1. &lt;code&gt;streamStart(opt={}, onAudioStart, onAudioEnd, onSubtitles, onMetrics)&lt;/code&gt;&lt;/h5&gt; 
&lt;p&gt;Enters streaming mode using an &lt;code&gt;AudioWorklet&lt;/code&gt; for low-latency playback. Parameters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;opt&lt;/code&gt; &lt;em&gt;(object, optional)&lt;/em&gt; – Settings controlling streaming behavior: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;code&gt;sampleRate&lt;/code&gt; – A number in the range [8000, 96000].&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;gain&lt;/code&gt; – Sets the playback gain (volume) for the streaming audio.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;lipsyncLang&lt;/code&gt; – Specifies lip-sync language if you want viseme generation using words. Defaults to avatar &lt;code&gt;lipsyncLang&lt;/code&gt;, or to options &lt;code&gt;lipsyncLang&lt;/code&gt; value.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;lipsyncType&lt;/code&gt; – Specifies lip-sync data type. Can take one of the values &lt;code&gt;visemes&lt;/code&gt; (default), &lt;code&gt;blendshapes&lt;/code&gt;, and &lt;code&gt;words&lt;/code&gt;.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;waitForAudioChunks&lt;/code&gt; – Boolean (default: &lt;code&gt;true&lt;/code&gt;). If &lt;code&gt;false&lt;/code&gt;, lip-sync will play immediately without waiting for audio chunks. This can be used to play lip-sync without audio.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;mood&lt;/code&gt; – Sets avatar mood upon starting the stream.&lt;/li&gt; 
   &lt;li&gt;&lt;code&gt;metrics&lt;/code&gt; – Used for in development performance monitoring: &lt;code&gt;{enabled: true, intervalHz: 2}&lt;/code&gt;. Enables queue depth and underrun tracking in the audio worklet. Do not set in production.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;onAudioStart&lt;/code&gt; &lt;em&gt;(function, optional)&lt;/em&gt; – Callback invoked the moment audio playback starts.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;onAudioEnd&lt;/code&gt; &lt;em&gt;(function, optional)&lt;/em&gt; – Callback invoked automatically once audio playback concludes.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;onSubtitles&lt;/code&gt; &lt;em&gt;(function, optional)&lt;/em&gt; – Callback to handle showing subtitle text.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;onMetrics&lt;/code&gt; &lt;em&gt;(function, optional)&lt;/em&gt; – Callback receiving performance monitoring data: queue depth, underruns, playback state.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Upon calling &lt;code&gt;streamStart&lt;/code&gt;, all queued speech (&lt;code&gt;speakText&lt;/code&gt;, &lt;code&gt;speakAudio&lt;/code&gt;) is stopped, the engine enters streaming mode, and the avatar prepares for real-time lip-sync. You can then feed audio via &lt;code&gt;streamAudio()&lt;/code&gt;. The session remains active until &lt;code&gt;streamStop()&lt;/code&gt; is called.&lt;/p&gt; 
&lt;h5&gt;2. &lt;code&gt;streamAudio(r)&lt;/code&gt;&lt;/h5&gt; 
&lt;p&gt;Sends one chunk of PCM audio data (16-bit little-endian) plus lip-sync data. Parameters:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;r.audio&lt;/code&gt; – An &lt;code&gt;ArrayBuffer&lt;/code&gt; or typed array of &lt;strong&gt;16-bit LE PCM&lt;/strong&gt; samples. These are played immediately.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;r.visemes&lt;/code&gt;, &lt;code&gt;r.vtimes&lt;/code&gt;, &lt;code&gt;r.vdurations&lt;/code&gt; &lt;em&gt;(optional)&lt;/em&gt; – Directly schedule lip-sync visemes at specific times with specific durations. This is the default type of lip-sync data.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;r.words&lt;/code&gt;, &lt;code&gt;r.wtimes&lt;/code&gt;, &lt;code&gt;r.wdurations&lt;/code&gt; &lt;em&gt;(optional)&lt;/em&gt; – Per-word timings and durations (e.g. TTS), allowing the library to create subtitles and/or calculate visemes if the &lt;code&gt;lipsyncType&lt;/code&gt; option is set to &lt;code&gt;words&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;r.anims&lt;/code&gt; &lt;em&gt;(optional)&lt;/em&gt; – An array of blendshape animations that play in sync with the audio. Requires setting &lt;code&gt;lipsyncType&lt;/code&gt; option to &lt;code&gt;blendshapes&lt;/code&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each call to &lt;code&gt;streamAudio()&lt;/code&gt; schedules an immediate chunk for playback and any included lip-sync or subtitle data on the animation timeline. Include only lip-sync data as specified in the &lt;code&gt;lipsyncType&lt;/code&gt; option via the &lt;code&gt;streamStart&lt;/code&gt; call. You can include any number of visemes, anims, or words which are not necessarily associated with the included audio chunk. You need to buffer the lip-sync data in the application and send it alongside the audio chunks.&lt;/p&gt; 
&lt;h5&gt;3. &lt;code&gt;streamNotifyEnd()&lt;/code&gt;&lt;/h5&gt; 
&lt;p&gt;Signals that no more chunks are expected for the current streaming utterance. Playback stops automatically once queued audio finishes. This is useful for gracefully concluding real-time TTS streams when your pipeline has no additional data to send. The streaming session remains active and can be reused by calling &lt;code&gt;streamAudio()&lt;/code&gt; again.&lt;/p&gt; 
&lt;h5&gt;4. &lt;code&gt;streamInterrupt()&lt;/code&gt;&lt;/h5&gt; 
&lt;p&gt;Immediately interrupts any ongoing audio playback and lip-sync animations in the streaming session. This method stops the current utterance but keeps the streaming session active for reuse. You can continue using the session by calling &lt;code&gt;streamAudio()&lt;/code&gt; again after interruption.&lt;/p&gt; 
&lt;h5&gt;5. &lt;code&gt;streamStop()&lt;/code&gt;&lt;/h5&gt; 
&lt;p&gt;Forces an immediate end to the streaming session. All queued audio and lip-sync animations are cleared, the avatar reverts to its idle state, and the audio worklet is disconnected and cleaned up. To start streaming again after calling &lt;code&gt;streamStop()&lt;/code&gt;, you must call &lt;code&gt;streamStart()&lt;/code&gt; to create a new session.&lt;/p&gt; 
&lt;h4&gt;Example Usage&lt;/h4&gt; 
&lt;p&gt;Refer to the example provided in the repository &lt;code&gt;azure-audio-streaming.html&lt;/code&gt; on how to integrate this interface with Azure TTS streamed audio.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;h3&gt;Appendix H: Avatar-Only Mode (EXPERIMENTAL)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!WARNING] This is still an experimental feature, so expect rapid changes.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;By default, the TalkingHead class operates in standalone mode, creating its own 3D scene, renderer, lights, and other 3D components. If you already have your own 3D scene, you can create an avatar-only instance and call the &lt;code&gt;head.animate(dt)&lt;/code&gt; update function from within your own renderer. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;// Create avatarOnly instance and load
const head = new TalkingHead( container, {
  /* ... */
  avatarOnly: true, // set avatarOnly mode
  avatarOnlyCamera: camera // Your camera avatar talks to
});
await head.showAvatar({ /* ... */ });

// Add to your own scene
head.armature.position.set(1,0,0);
head.armature.rotation.set(0,0.5,0);
scene.add(head.armature);

// You own animation loop
const clock = new THREE.Clock();
function animate() {
  const delta = clock.getDelta();
  head.animate(delta * 1000); // Update avatar
  renderer.render( scene, camera );
}
renderer.setAnimationLoop(animate);
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;You can also add &lt;code&gt;avatarOnly&lt;/code&gt; armatures to your standalone TalkingHead scene to have multiple avatars in one scene. For example:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;let headStandalone, headAvatarOnly;

// Standalone instance
headStandalone = new TalkingHead( container, {
  /* ... */
  update: (dt) =&amp;gt; { headAvatarOnly?.animate(dt); }
});
await headStandalone.showAvatar({ /* ... */ });

// avatarOnly instance
headAvatarOnly = new TalkingHead( container, {
  /* ... */
  avatarOnly: true, // set avatarOnly mode
  avatarOnlyCamera: headStandalone.camera // Standalone camera
});
await headAvatarOnly.showAvatar({ /* ... */ });

// Add avatarOnly to standalone scene
headAvatarOnly.armature.position.set(1,0,0);
headStandalone.scene.add( headAvatarOnly.armature );
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want one TalkingHead avatar to speak to another, set its &lt;code&gt;speakTo&lt;/code&gt; property. The value can be another TalkingHead instance, any 3D object, or a world position. For example, to make two avatars talk to each other:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-javascript"&gt;headAvatarOnly.speakTo = headStandalone;
headStandalone.speakTo = headAvatarOnly;
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;If you want the avatar to address the user again, set &lt;code&gt;speakTo&lt;/code&gt; value to &lt;code&gt;null&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GoogleChrome/lighthouse</title>
      <link>https://github.com/GoogleChrome/lighthouse</link>
      <description>&lt;p&gt;Automated auditing, performance metrics, and best practices for the web.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Lighthouse &lt;a href="https://github.com/GoogleChrome/lighthouse/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/GoogleChrome/lighthouse/workflows/CI/badge.svg?sanitize=true" alt="GitHub Actions Status Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GoogleChrome/lighthouse/actions/workflows/unit.yml"&gt;&lt;img src="https://github.com/GoogleChrome/lighthouse/workflows/unit/badge.svg?sanitize=true" alt="GitHub Actions Status Badge" /&gt;&lt;/a&gt; &lt;a href="https://github.com/GoogleChrome/lighthouse/actions/workflows/smoke.yml"&gt;&lt;img src="https://github.com/GoogleChrome/lighthouse/workflows/smoke/badge.svg?sanitize=true" alt="GitHub Actions Status Badge" /&gt;&lt;/a&gt; &lt;a href="https://codecov.io/gh/GoogleChrome/lighthouse"&gt;&lt;img src="https://codecov.io/gh/GoogleChrome/lighthouse/branch/main/graph/badge.svg?sanitize=true" alt="Coverage Status" /&gt;&lt;/a&gt; &lt;a href="https://lh-build-tracker.herokuapp.com/"&gt;&lt;img src="https://img.shields.io/badge/buildtracker-ok-blue" alt="Build tracker for Lighthouse" /&gt;&lt;/a&gt; &lt;a href="https://npmjs.org/package/lighthouse"&gt;&lt;img src="https://img.shields.io/npm/v/lighthouse.svg?sanitize=true" alt="NPM lighthouse package" /&gt;&lt;/a&gt;&lt;/h1&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Lighthouse analyzes web apps and web pages, collecting modern performance metrics and insights on developer best practices.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;Using Lighthouse 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#using-lighthouse-in-chrome-devtools"&gt;Using Lighthouse in Chrome DevTools&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#using-the-chrome-extension"&gt;Using the Chrome extension&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#using-the-node-cli"&gt;Using the Node CLI&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#cli-options"&gt;CLI options&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#using-the-node-module"&gt;Using the Node module&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#viewing-a-report"&gt;Viewing a report&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#online-viewer"&gt;Online Viewer&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#docs--recipes"&gt;Docs &amp;amp; Recipes&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#develop"&gt;Developing Lighthouse&lt;/a&gt; 
    &lt;ul&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#setup"&gt;Setup&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#run"&gt;Run&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#tests"&gt;Tests&lt;/a&gt;&lt;/li&gt; 
     &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#docs"&gt;Docs&lt;/a&gt;&lt;/li&gt; 
    &lt;/ul&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Associated Products and Projects 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#lighthouse-integrations-in-web-perf-services"&gt;Lighthouse Integrations in Web Perf services&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#lighthouse-integrations-in-non-web-perf-services"&gt;Lighthouse Integrations in non-Web Perf services&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#plugins"&gt;Plugins&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#related-projects"&gt;Related projects&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#faq"&gt;FAQ&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#how-does-lighthouse-work"&gt;How does Lighthouse work?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#can-i-configure-the-lighthouse-run"&gt;Can I configure the lighthouse run?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#how-does-lighthouse-use-network-throttling-and-how-can-i-make-it-better"&gt;How does Lighthouse use network throttling, and how can I make it better?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#are-results-sent-to-a-remote-server"&gt;Are results sent to a remote server?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#how-do-i-get-localized-lighthouse-results-via-the-cli"&gt;How do I get localized Lighthouse results?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#how-do-i-author-custom-audits-to-extend-lighthouse"&gt;How do I author custom audits to extend Lighthouse?&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/#how-do-i-contribute"&gt;How do I contribute?&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Using Lighthouse in Chrome DevTools&lt;/h2&gt; 
&lt;p&gt;Lighthouse is integrated directly into the Chrome DevTools, under the "Lighthouse" panel.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Installation&lt;/strong&gt;: install &lt;a href="https://www.google.com/chrome/browser"&gt;Chrome&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Run it&lt;/strong&gt;: open Chrome DevTools, select the Lighthouse panel, and hit "Generate report".&lt;/p&gt; 
&lt;img width="550" alt="Lighthouse integration in Chrome DevTools." src="https://user-images.githubusercontent.com/2766281/204185043-9c49abe5-baee-4b26-b5ce-ece410661213.png" /&gt; 
&lt;h2&gt;Using the Chrome extension&lt;/h2&gt; 
&lt;p&gt;The Chrome extension was available prior to Lighthouse being available in Chrome Developer Tools, and offers similar functionality.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Installation&lt;/strong&gt;: &lt;a href="https://chrome.google.com/webstore/detail/lighthouse/blipmdconlkpinefehnmjammfjpmpbjk"&gt;install the extension&lt;/a&gt; from the Chrome Web Store.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Run it&lt;/strong&gt;: follow the &lt;a href="https://developers.google.com/web/tools/lighthouse/#extension"&gt;extension quick-start guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Using the Node CLI&lt;/h2&gt; 
&lt;p&gt;The Node CLI provides the most flexibility in how Lighthouse runs can be configured and reported. Users who want more advanced usage, or want to run Lighthouse in an automated fashion should use the Node CLI.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] Lighthouse requires Node 18.20 or later.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Installation&lt;/strong&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm install -g lighthouse
# or use yarn:
# yarn global add lighthouse
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Run it&lt;/strong&gt;: &lt;code&gt;lighthouse https://airhorner.com/&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;By default, Lighthouse writes the report to an HTML file. You can control the output format by passing flags.&lt;/p&gt; 
&lt;h3&gt;CLI options&lt;/h3&gt; 
&lt;!-- To update the help output:
  node cli --help | pbcopy
--&gt; 
&lt;pre&gt;&lt;code&gt;$ lighthouse --help

lighthouse &amp;lt;url&amp;gt; &amp;lt;options&amp;gt;

Logging:
  --verbose  Displays verbose logging  [boolean] [default: false]
  --quiet    Displays no progress, debug logs, or errors  [boolean] [default: false]

Configuration:
  --save-assets                  Save the trace contents &amp;amp; devtools logs to disk  [boolean] [default: false]
  --list-all-audits              Prints a list of all available audits and exits  [boolean] [default: false]
  --list-trace-categories        Prints a list of all required trace categories and exits  [boolean] [default: false]
  --additional-trace-categories  Additional categories to capture with the trace (comma-delimited).  [string]
  --config-path                  The path to the config JSON.
                                 An example config file: core/config/lr-desktop-config.js  [string]
  --preset                       Use a built-in configuration.
                                 WARNING: If the --config-path flag is provided, this preset will be ignored.  [string] [choices: "perf", "experimental", "desktop"]
  --chrome-flags                 Custom flags to pass to Chrome (space-delimited). For a full list of flags, see https://bit.ly/chrome-flags
                                 Additionally, use the CHROME_PATH environment variable to use a specific Chrome binary. Requires Chromium version 66.0 or later. If omitted, any detected Chrome Canary or Chrome stable will be used.  [string] [default: ""]
  --port                         The port to use for the debugging protocol. Use 0 for a random port  [number] [default: 0]
  --hostname                     The hostname to use for the debugging protocol.  [string] [default: "localhost"]
  --form-factor                  Determines how performance metrics are scored and if mobile-only audits are skipped. For desktop, --preset=desktop instead.  [string] [choices: "mobile", "desktop"]
  --screenEmulation              Sets screen emulation parameters. See also --preset. Use --screenEmulation.disabled to disable. Otherwise set these 4 parameters individually: --screenEmulation.mobile --screenEmulation.width=360 --screenEmulation.height=640 --screenEmulation.deviceScaleFactor=2
  --emulatedUserAgent            Sets useragent emulation  [string]
  --max-wait-for-load            The timeout (in milliseconds) to wait before the page is considered done loading and the run should continue. WARNING: Very high values can lead to large traces and instability  [number]
  --enable-error-reporting       Enables error reporting, overriding any saved preference. --no-enable-error-reporting will do the opposite. More: https://github.com/GoogleChrome/lighthouse/blob/main/docs/error-reporting.md  [boolean]
  --gather-mode, -G              Collect artifacts from a connected browser and save to disk. (Artifacts folder path may optionally be provided). If audit-mode is not also enabled, the run will quit early.
  --audit-mode, -A               Process saved artifacts from disk. (Artifacts folder path may be provided, otherwise defaults to ./latest-run/)
  --only-audits                  Only run the specified audits  [array]
  --only-categories              Only run the specified categories. Available categories: accessibility, best-practices, performance, seo  [array]
  --skip-audits                  Run everything except these audits  [array]
  --disable-full-page-screenshot Disables collection of the full page screenshot, which can be quite large  [boolean]

Output:
  --output       Reporter for the results, supports multiple values. choices: "json", "html", "csv"  [array] [default: ["html"]]
  --output-path  The file path to output the results. Use 'stdout' to write to stdout.
                   If using JSON output, default is stdout.
                   If using HTML or CSV output, default is a file in the working directory with a name based on the test URL and date.
                   If using multiple outputs, --output-path is appended with the standard extension for each output type. "reports/my-run" -&amp;gt; "reports/my-run.report.html", "reports/my-run.report.json", etc.
                   Example: --output-path=./lighthouse-results.html  [string]
  --view         Open HTML report in your browser  [boolean] [default: false]

Options:
  --version                            Show version number  [boolean]
  --help                               Show help  [boolean]
  --cli-flags-path                     The path to a JSON file that contains the desired CLI flags to apply. Flags specified at the command line will still override the file-based ones.
  --locale                             The locale/language the report should be formatted in
  --blocked-url-patterns               Block any network requests to the specified URL patterns  [array]
  --disable-storage-reset              Disable clearing the browser cache and other storage APIs before a run  [boolean]
  --throttling-method                  Controls throttling method  [string] [choices: "devtools", "provided", "simulate"]
  --throttling
  --throttling.rttMs                   Controls simulated network RTT (TCP layer)
  --throttling.throughputKbps          Controls simulated network download throughput
  --throttling.requestLatencyMs        Controls emulated network RTT (HTTP layer)
  --throttling.downloadThroughputKbps  Controls emulated network download throughput
  --throttling.uploadThroughputKbps    Controls emulated network upload throughput
  --throttling.cpuSlowdownMultiplier   Controls simulated + emulated CPU throttling
  --extra-headers                      Set extra HTTP Headers to pass with request
  --precomputed-lantern-data-path      Path to the file where lantern simulation data should be read from, overwriting the lantern observed estimates for RTT and server latency.  [string]
  --lantern-data-output-path           Path to the file where lantern simulation data should be written to, can be used in a future run with the `precomputed-lantern-data-path` flag.  [string]
  --plugins                            Run the specified plugins  [array]
  --channel  [string] [default: "cli"]
  --chrome-ignore-default-flags  [boolean] [default: false]

Examples:
  lighthouse &amp;lt;url&amp;gt; --view                                                                          Opens the HTML report in a browser after the run completes
  lighthouse &amp;lt;url&amp;gt; --config-path=./myconfig.js                                                     Runs Lighthouse with your own configuration: custom audits, report generation, etc.
  lighthouse &amp;lt;url&amp;gt; --output=json --output-path=./report.json --save-assets                         Save trace, screenshots, and named JSON report.
  lighthouse &amp;lt;url&amp;gt; --screenEmulation.disabled --throttling-method=provided --no-emulatedUserAgent  Disable device emulation and all throttling
  lighthouse &amp;lt;url&amp;gt; --chrome-flags="--window-size=412,660"                                          Launch Chrome with a specific window size
  lighthouse &amp;lt;url&amp;gt; --quiet --chrome-flags="--headless"                                             Launch Headless Chrome, turn off logging
  lighthouse &amp;lt;url&amp;gt; --extra-headers "{\"Cookie\":\"monster=blue\", \"x-men\":\"wolverine\"}"        Stringify'd JSON HTTP Header key/value pairs to send in requests
  lighthouse &amp;lt;url&amp;gt; --extra-headers=./path/to/file.json                                             Path to JSON file of HTTP Header key/value pairs to send in requests
  lighthouse &amp;lt;url&amp;gt; --only-categories=performance,seo                                               Only run the specified categories. Available categories: accessibility, best-practices, performance, seo

For more information on Lighthouse, see https://developers.google.com/web/tools/lighthouse/.
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Output Examples&lt;/h5&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;lighthouse
# saves `./&amp;lt;HOST&amp;gt;_&amp;lt;DATE&amp;gt;.report.html`

lighthouse --output json
# json output sent to stdout

lighthouse --output html --output-path ./report.html
# saves `./report.html`

# NOTE: specifying an output path with multiple formats ignores your specified extension for *ALL* formats
lighthouse --output json --output html --output-path ./myfile.json
# saves `./myfile.report.json` and `./myfile.report.html`

lighthouse --output json --output html
# saves `./&amp;lt;HOST&amp;gt;_&amp;lt;DATE&amp;gt;.report.json` and `./&amp;lt;HOST&amp;gt;_&amp;lt;DATE&amp;gt;.report.html`

lighthouse --output-path=~/mydir/foo.out --save-assets
# saves `~/mydir/foo.report.html`
# saves `~/mydir/foo-0.trace.json` and `~/mydir/foo-0.devtoolslog.json`

lighthouse --output-path=./report.json --output json
# saves `./report.json`
&lt;/code&gt;&lt;/pre&gt; 
&lt;h5&gt;Lifecycle Examples&lt;/h5&gt; 
&lt;p&gt;You can run a subset of Lighthouse's lifecycle if desired via the &lt;code&gt;--gather-mode&lt;/code&gt; (&lt;code&gt;-G&lt;/code&gt;) and &lt;code&gt;--audit-mode&lt;/code&gt; (&lt;code&gt;-A&lt;/code&gt;) CLI flags.&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;lighthouse http://example.com -G
# launches browser, collects artifacts, saves them to disk (in `./latest-run/`) and quits

lighthouse http://example.com -A
# skips browser interaction, loads artifacts from disk (in `./latest-run/`), runs audits on them, generates report

lighthouse http://example.com -GA
# Normal gather + audit run, but also saves collected artifacts to disk for subsequent -A runs.


# You can optionally provide a custom folder destination to -G/-A/-GA. Without a value, the default will be `$PWD/latest-run`.
lighthouse -GA=./gmailartifacts https://gmail.com
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Notes on Error Reporting&lt;/h4&gt; 
&lt;p&gt;The first time you run the CLI you will be prompted with a message asking you if Lighthouse can anonymously report runtime exceptions. The Lighthouse team uses this information to detect new bugs and avoid regressions. Opting out will not affect your ability to use Lighthouse in any way. &lt;a href="https://github.com/GoogleChrome/lighthouse/raw/main/docs/error-reporting.md"&gt;Learn more&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Using the Node module&lt;/h2&gt; 
&lt;p&gt;You can also use Lighthouse programmatically with the Node module.&lt;/p&gt; 
&lt;p&gt;Read &lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/readme.md#using-programmatically"&gt;Using Lighthouse programmatically&lt;/a&gt; for help getting started.&lt;br /&gt; Read &lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/configuration.md"&gt;Lighthouse Configuration&lt;/a&gt; to learn more about the configuration options available.&lt;/p&gt; 
&lt;h2&gt;Viewing a report&lt;/h2&gt; 
&lt;p&gt;Lighthouse can produce a report as JSON or HTML.&lt;/p&gt; 
&lt;p&gt;HTML report:&lt;/p&gt; 
&lt;img src="https://raw.githubusercontent.com/GoogleChrome/lighthouse/443ff2c8a297dfd2297dfaca86c4966a87c8574a/assets/example_audit.png" alt="Lighthouse example audit" width="500px" /&gt; 
&lt;h3&gt;Online Viewer&lt;/h3&gt; 
&lt;p&gt;Running Lighthouse with the &lt;code&gt;--output=json&lt;/code&gt; flag generates a JSON dump of the run. You can view this report online by visiting &lt;a href="https://googlechrome.github.io/lighthouse/viewer/"&gt;https://googlechrome.github.io/lighthouse/viewer/&lt;/a&gt; and dragging the file onto the app. You can also use the "Export" button from the top of any Lighthouse HTML report and open the report in the &lt;a href="https://googlechrome.github.io/lighthouse/viewer/"&gt;Lighthouse Viewer&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;In the Viewer, reports can be shared by clicking the share icon in the top right corner and signing in to GitHub.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] shared reports are stashed as a secret Gist in GitHub, under your account.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Docs &amp;amp; Recipes&lt;/h2&gt; 
&lt;p&gt;Useful documentation, examples, and recipes to get you started.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Docs&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/variability.md"&gt;Dealing with variance&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/readme.md#using-programmatically"&gt;Using Lighthouse programmatically&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/authenticated-pages.md"&gt;Testing a site with authentication&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/plugins.md"&gt;Developing Plugins&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/new-audits.md"&gt;Making a New Audit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/readme.md#testing-on-a-mobile-device"&gt;Testing on a mobile device&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/architecture.md"&gt;Lighthouse Architecture&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Recipes&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/recipes/lighthouse-plugin-example"&gt;Plugin&lt;/a&gt; - example Lighthouse plugin&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/recipes/custom-audit"&gt;Custom Audit example&lt;/a&gt; - extend Lighthouse, run your own audits&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Videos&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The session from Google I/O 2018 covers the new performance engine, upcoming Lighthouse REST API, and using the Chrome UX report to evaluate real-user data.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=UvK9zAsSM8Q"&gt;&lt;img src="https://img.youtube.com/vi/UvK9zAsSM8Q/0.jpg" alt="Watch the Lighthouse @ Google I/O 2018 session." /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The session from Google I/O 2017 covers architecture, writing custom audits, GitHub/Travis/CI integration, headless Chrome, and more:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=NoRYn6gOtVo"&gt;&lt;img src="https://img.youtube.com/vi/NoRYn6gOtVo/0.jpg" alt="Watch the Lighthouse @ Google I/O 2017 session." /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;Click the image to watch the video on YouTube.&lt;/em&gt;&lt;/p&gt; 
&lt;h2&gt;Develop&lt;/h2&gt; 
&lt;p&gt;Read on for the basics of hacking on Lighthouse. Also, see &lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt; for detailed information.&lt;/p&gt; 
&lt;h3&gt;Setup&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# yarn should be installed first

git clone https://github.com/GoogleChrome/lighthouse

cd lighthouse
yarn
yarn build-all
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Run&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;node cli http://example.com
# append --chrome-flags="--no-sandbox --headless --disable-gpu" if you run into problems connecting to Chrome
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Getting started tip&lt;/strong&gt;: &lt;code&gt;node --inspect-brk cli http://example.com&lt;/code&gt; to open up Chrome DevTools and step through the entire app. See &lt;a href="https://medium.com/@paul_irish/debugging-node-js-nightlies-with-chrome-devtools-7c4a1b95ae27#.59rma3ukm"&gt;Debugging Node.js with Chrome DevTools&lt;/a&gt; for more info.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Tests&lt;/h3&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;# lint and test all files
yarn test

# run all unit tests
yarn unit

# run a given unit test (e.g. core/test/audits/byte-efficiency/uses-long-cache-ttl-test.js)
yarn mocha uses-long-cache-ttl

# watch for file changes and run tests
#   Requires http://entrproject.org : brew install entr
yarn watch

## run linting, unit, and smoke tests separately
yarn lint
yarn unit
yarn smoke

## run tsc compiler
yarn type-check
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Docs&lt;/h3&gt; 
&lt;p&gt;Some of our docs have tests that run only in CI by default. To modify our documentation, you'll need to run &lt;code&gt;yarn build-pack &amp;amp;&amp;amp; yarn test-docs&lt;/code&gt; locally to make sure they pass.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Additional Dependencies&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;brew install jq&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Lighthouse Integrations in Web Perf services&lt;/h2&gt; 
&lt;p&gt;This section details services that have integrated Lighthouse data. If you're working on a cool project integrating Lighthouse and would like to be featured here, file an issue to this repo or tweet at us &lt;a href="https://twitter.com/____lighthouse"&gt;@_____lighthouse&lt;/a&gt;!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.webpagetest.org"&gt;Web Page Test&lt;/a&gt;&lt;/strong&gt; — An &lt;a href="https://github.com/WPO-Foundation/webpagetest"&gt;open source&lt;/a&gt; tool for measuring and analyzing the performance of web pages on real devices. Users can choose to produce a Lighthouse report alongside the analysis of WebPageTest results.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="http://httparchive.org/"&gt;HTTPArchive&lt;/a&gt;&lt;/strong&gt; - HTTPArchive tracks how the web is built by crawling 500k pages with Web Page Test, including Lighthouse results, and stores the information in BigQuery where it is &lt;a href="https://discuss.httparchive.org/t/quickstart-guide-to-exploring-the-http-archive/682"&gt;publicly available&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://calibreapp.com"&gt;Calibre&lt;/a&gt;&lt;/strong&gt; - Calibre is a comprehensive performance monitoring platform running on Lighthouse. See the performance impact of your work before it hits production with GitHub Pull Request Reviews. Track the impact of Third Party scripts. Automate your performance system with a developer-first Node.js API. Try Calibre with a free 15-day trial.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.debugbear.com/"&gt;DebugBear&lt;/a&gt;&lt;/strong&gt; - DebugBear is a website monitoring tool based on Lighthouse. See how your scores and metrics changed over time, with a focus on understanding what caused each change. DebugBear is a paid product with a free 30-day trial.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://treo.sh"&gt;Treo&lt;/a&gt;&lt;/strong&gt; - Treo is Lighthouse as a Service. It provides regression testing, geographical regions, custom networks, and integrations with GitHub &amp;amp; Slack. Treo is a paid product with plans for solo-developers and teams.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://pagevitals.com"&gt;PageVitals&lt;/a&gt;&lt;/strong&gt; - PageVitals combines Lighthouse, CrUX and field testing to monitor the performance of websites. See how your website performs over time and get alerted if it gets too slow. Drill down and find the real cause of any performance issue. PageVitals is a paid product with a free 14-day trial.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://screpy.com"&gt;Screpy&lt;/a&gt;&lt;/strong&gt; - Screpy is a web analysis tool that can analyze all pages of your websites in one dashboard and monitor them with your team. It's powered by Lighthouse and it also includes some different analysis tools (SERP, W3C, Uptime, etc). Screpy has free and paid plans.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://siteimprove.com/en/performance/"&gt;Siteimprove Performance&lt;/a&gt;&lt;/strong&gt; — Siteimprove Performance is a web Performance monitoring solution that enables a marketer, manager or decision maker to understand and optimize website load times. Get easy-to-use insights with a focus on quick and impactful wins. Siteimprove Performance is a paid product with a free 14-day trial.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://speedcurve.com"&gt;SpeedCurve&lt;/a&gt;&lt;/strong&gt; — SpeedCurve is a tool for continuously monitoring web performance across different browsers, devices, and regions. It can aggregate any metric including Lighthouse scores across multiple pages and sites, and allows you to set performance budgets with Slack or email alerts. SpeedCurve is a paid product with a free 30-day trial.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://www.foo.software/lighthouse"&gt;Foo&lt;/a&gt;&lt;/strong&gt; - Lighthouse-as-a-service offering free and premium plans. Provides monitoring and historical reporting of Lighthouse audits with CircleCI, GitHub, and other integrations. Features include Slack notifications, PR comment reporting and more.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://apdex.co"&gt;Apdex&lt;/a&gt;&lt;/strong&gt; - Apdex is a website performance service. The main features are historical Lighthouse report visualizations, mobile/desktop options, alerts, uptime monitoring, and more. There are flexible paid plans and a 30-day free trial.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://websu.io"&gt;Websu&lt;/a&gt;&lt;/strong&gt; - Websu is an open source project to provide Lighthouse-as-a-Service through a simple HTTP REST API. The main features are ability to host and deploy in your own environment and historical Lighthouse report summaries.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://dtekt.io"&gt;DTEKT.IO&lt;/a&gt;&lt;/strong&gt; - DTEKT is a website performance and uptime monitoring service. It uses lighthouse to provide visibility into the performance of websites from multiple locations on multiple devices. It offers three months free trial and paid plans.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://speedvitals.com"&gt;SpeedVitals&lt;/a&gt;&lt;/strong&gt; - SpeedVitals is a Lighthouse powered tool to measure web performance across multiple devices and locations. It has various features like Layout Shift Visualization, Waterfall Chart, Field Data and Resource Graphs. SpeedVitals offers both free and paid plans.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://lighthouse-metrics.com/"&gt;Lighthouse Metrics&lt;/a&gt;&lt;/strong&gt; - Lighthouse Metrics gives you global performance insights with a single test. You can also monitor your websites on a daily or hourly base. Lighthouse Metrics offers free global one-time tests and performance monitoring as a paid feature with a free 14-day trial.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://auditzy.com"&gt;Auditzy&lt;/a&gt;&lt;/strong&gt; - Auditzy™ is a robust website auditing &amp;amp; monitoring tool which lets you analyze your web page(s) pre-user journey. Analyze the Competitor Health Metric, Core Web Vitals, and Technology. Compare your web pages with your competitors to understand where you are leading or lagging. Real-time notification with Slack. Have Seamless Collaboration with Multiple Teams. Automate your Audits hourly, daily, weekly, and so on. It has a free trial with pay as you go plans.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="http://lighthousemetricschina.com"&gt;Lighthouse Metrics China&lt;/a&gt;&lt;/strong&gt; - The first Lighthouse metrics tool specifically designed for China. Experience unparalleled website monitoring capabilities with Lighthouse. Gain insights into the fluctuations of your scores and metrics within the realm of the &lt;a href="https://www.chinafirewalltest.co"&gt;Great Firewall of China&lt;/a&gt;, enabling a comprehensive understanding of the factors influencing each change. Lighthouse Metrics China offers both free and paid plans.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://deploymenthawk.com"&gt;DeploymentHawk&lt;/a&gt;&lt;/strong&gt; - DeploymentHawk is an automated site auditing tool powered by Lighthouse. Effortlessly catch performance, accessibility, and SEO issues before they impact your users. DeploymentHawk is a paid product with a free 7-day trial.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://guardius.io"&gt;Guardius&lt;/a&gt;&lt;/strong&gt; - Guardius is a DevOps and DevSecOps SaaS platform that integrates Lighthouse to deliver automated web performance analysis. It not only provides metrics evaluation and automatic scanning but also enables performance comparisons across different periods and ongoing observation over time. Additionally, Guardius offers predefined and customized alerts tailored to your specific requirements. A free version of Guardius is available for users to explore its features.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://getsona.io"&gt;Sonā&lt;/a&gt;&lt;/strong&gt; - Powered by Lighthouse amongst others, Sonā delivers in-depth insights into your website’s health. Track changes over time, share reports, and receive actionable recommendations to improve performance, accessibility, SEO, best practices, and security. Sonā is free during its beta period.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Lighthouse Integrations in non-Web Perf services&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://pagewatch.dev/"&gt;PageWatch&lt;/a&gt;&lt;/strong&gt; — PageWatch is a tool to find problem pages on your website. It provides insights into spelling errors, layout issues, slow pages (powered by Lighthouse) and more. PageWatch is offered via free and paid plans.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://fluxguard.com/"&gt;Fluxguard&lt;/a&gt;&lt;/strong&gt; - Fluxguard provides website DOM change monitoring orchestrated with Google Puppeteer, and audited by Lighthouse. Fluxguard is a freemium product, with monthly monitoring of up to 75 pages for free.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://microlink.io"&gt;Microlink&lt;/a&gt;&lt;/strong&gt; — Microlink is a cloud browser as API. It offers Lighthouse reports on demand, making it easy to build any service on top. Similar functionality is available via the underlying open-source project named browserless.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://wattspeed.com/"&gt;Wattspeed&lt;/a&gt;&lt;/strong&gt; — Wattspeed is a free tool that generates snapshots - historical captures of your web pages that include Lighthouse scores, a list of technologies, W3C HTML validator results, DOM size, mixed content info, and more.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Plugins&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/treosh/lighthouse-plugin-field-performance"&gt;lighthouse-plugin-field-performance&lt;/a&gt;&lt;/strong&gt; - a plugin that adds real-user performance metrics for the URL using the data from &lt;a href="https://developers.google.com/web/tools/chrome-user-experience-report/"&gt;Chrome UX Report&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/googleads/publisher-ads-lighthouse-plugin"&gt;lighthouse-plugin-publisher-ads&lt;/a&gt;&lt;/strong&gt; - a tool to improve ad speed and overall quality through a series of automated audits. At the moment, this is primarily targeted at sites using Google Ad Manager. This tool will aid in resolving discovered problems, providing a tool to be used to evaluate effectiveness of iterative changes while suggesting actionable feedback.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;&lt;a href="https://github.com/dvelasquez/lighthouse-plugin-crux"&gt;lighthouse-plugin-crux&lt;/a&gt;&lt;/strong&gt; - a plugin that quickly gathers real-user-metrics data from the &lt;a href="https://developers.google.com/web/tools/chrome-user-experience-report/api/reference"&gt;Chrome UX Report API&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Related projects&lt;/h2&gt; 
&lt;p&gt;Other awesome open source projects that use Lighthouse.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/TGiles/auto-lighthouse"&gt;auto-lighthouse&lt;/a&gt;&lt;/strong&gt; - a CLI for crawling a domain and generating mobile and desktop reports for each page.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/treosh/exthouse"&gt;Exthouse&lt;/a&gt;&lt;/strong&gt; - Analyze the impact of a browser extension on web performance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://labs.moduscreate.com/gimbal-web-performance-audit-budgeting"&gt;Gimbal&lt;/a&gt;&lt;/strong&gt; - An &lt;a href="https://github.com/ModusCreateOrg/gimbal"&gt;open source (MIT licensed)&lt;/a&gt; tool used to measure, analyze, and budget aspects of a web application. Gimbal also integrates reports with GitHub pull requests.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/Cognifide/gradle-lighthouse-plugin"&gt;Gradle Lighthouse Plugin&lt;/a&gt;&lt;/strong&gt; - An open source Gradle plugin that runs Lighthouse tests on multiple URLs and asserts category score thresholds (useful in continuous integration).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/emazzotta/lighthouse-badges"&gt;lighthouse-badges&lt;/a&gt;&lt;/strong&gt; - Generate gh-badges (shields.io) based on Lighthouse performance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/mikestead/lighthouse-batch"&gt;lighthouse-batch&lt;/a&gt;&lt;/strong&gt; - Run Lighthouse over a number of sites and generate a summary of their metrics/scores.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/Carr1005/lighthouse-batch-parallel"&gt;lighthouse-batch-parallel&lt;/a&gt;&lt;/strong&gt; - Run multiple Lighthouse runs in parallel to accelerate the data collecting process, get the result stream (csv, json, js object) in your own process (warning: performance results may be volatile).&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/foo-software/lighthouse-check-action"&gt;lighthouse-check-action&lt;/a&gt;&lt;/strong&gt; - A GitHub Action to run Lighthouse in a workflow, featuring Slack notifications and report upload to S3.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://circleci.com/orbs/registry/orb/foo-software/lighthouse-check"&gt;lighthouse-check-orb&lt;/a&gt;&lt;/strong&gt; - A CircleCI Orb to run Lighthouse in a workflow, featuring Slack notifications and report upload to S3.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/andreasonny83/lighthouse-ci"&gt;andreasonny83/lighthouse-ci&lt;/a&gt;&lt;/strong&gt; - Run Lighthouse and assert scores satisfy your custom thresholds.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/GoogleChrome/lighthouse-ci"&gt;GoogleChrome/lighthouse-ci&lt;/a&gt;&lt;/strong&gt; - (&lt;strong&gt;official&lt;/strong&gt;) Automate running Lighthouse for every commit, viewing the changes, and preventing regressions.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/treosh/lighthouse-ci-action"&gt;lighthouse-ci-action&lt;/a&gt;&lt;/strong&gt; - A GitHub Action that makes it easy to run Lighthouse in CI and keep your pages small using performance budgets.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/carlesnunez/lighthouse-gh-reporter"&gt;lighthouse-gh-reporter&lt;/a&gt;&lt;/strong&gt; - Run Lighthouse in CI and report back in a comment on your pull requests&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/justinribeiro/lighthouse-jest-example"&gt;lighthouse-jest-example&lt;/a&gt;&lt;/strong&gt; - Gather performance metrics via Lighthouse and assert results with Jest; uses Puppeteer to start Chrome with network emulation settings defined by WebPageTest.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/Otterseer/lighthouse-lambda"&gt;lighthouse-lambda&lt;/a&gt;&lt;/strong&gt; - Run Lighthouse on AWS Lambda with prebuilt stable desktop Headless Chrome.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/ackama/lighthouse-matchers"&gt;lighthouse-matchers&lt;/a&gt;&lt;/strong&gt; - Provides RSpec matchers for executing and evaluating Google Chrome Lighthouse audit scores.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/rishichawda/lighthouse-mocha-example"&gt;lighthouse-mocha-example&lt;/a&gt;&lt;/strong&gt; - Run Lighthouse performance tests with Mocha and chrome-launcher.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/verivox/lighthouse-monitor"&gt;lighthouse-monitor&lt;/a&gt;&lt;/strong&gt; - Run Lighthouse against all your URLs. Send metrics to any backend you want, save all reports with automatic data retention, and compare any two results in a web UI.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/foo-software/lighthouse-persist"&gt;lighthouse-persist&lt;/a&gt;&lt;/strong&gt; - Run Lighthouse and upload HTML reports to an AWS S3 bucket.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/dvelasquez/lighthouse-viewer/tree/main/packages/lighthouse-viewer"&gt;lighthouse-viewer&lt;/a&gt;&lt;/strong&gt; - Render the Lighthouse JSON into a report, using the Lighthouse Report Renderer repackaged as UMD and ESM. Also available with React, Svelte and Vue wrappers.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/godaddy/lighthouse4u"&gt;lighthouse4u&lt;/a&gt;&lt;/strong&gt; - LH4U provides Google Lighthouse as a service, surfaced by both a friendly UI+API, and backed by Elastic Search for easy querying and visualization.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://www.npmjs.com/package/react-lighthouse-viewer"&gt;react-lighthouse-viewer&lt;/a&gt;&lt;/strong&gt; - Render a Lighthouse JSON report in a React Component.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/viasite/site-audit-seo"&gt;site-audit-seo&lt;/a&gt;&lt;/strong&gt; - CLI tool for SEO site audit, crawl site, lighthouse each page. Output to console and tables in csv, xlsx, json, web or Google Drive.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/addyosmani/webpack-lighthouse-plugin"&gt;webpack-lighthouse-plugin&lt;/a&gt;&lt;/strong&gt; - Run Lighthouse from a Webpack build.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/mfrachet/cypress-audit"&gt;cypress-audit&lt;/a&gt;&lt;/strong&gt; - Run Lighthouse and Pa11y audits directly in your E2E test suites.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/adityadees/laravel-lighthouse"&gt;laravel-lighthouse&lt;/a&gt;&lt;/strong&gt; - Google Lighthouse wrapper for laravel framework to run Google Lighthouse CLI with custom option and can automatically save result in your server directory.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;&lt;a href="https://github.com/Xceptance/neodymium/wiki/Accessibility"&gt;Neodymium&lt;/a&gt;&lt;/strong&gt; - The Neodymium test automation framework integrates Lighthouse for accessibility and Web Vitals verification, allowing programmatic validation and assertion of all audit values.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;FAQ&lt;/h2&gt; 
&lt;h3&gt;How does Lighthouse work?&lt;/h3&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/architecture.md"&gt;Lighthouse Architecture&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Why is the performance score so low? It looks fine to me.&lt;/h3&gt; 
&lt;p&gt;Lighthouse reports the performance metrics as they would be experienced by a typical mobile user on a 4G connection and a mid-tier ~$200 phone. Even if it loads quickly on your device and network, users in other environments will experience the site very differently.&lt;/p&gt; 
&lt;p&gt;Read more in our &lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/throttling.md"&gt;guide to throttling&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Why does the performance score change so much?&lt;/h3&gt; 
&lt;p&gt;Lighthouse performance scores will change due to inherent variability in web and network technologies, even if there hasn't been a code change. Test in consistent environments, run Lighthouse multiple times, and beware of variability before drawing conclusions about a performance-impacting change.&lt;/p&gt; 
&lt;p&gt;Read more in our &lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/variability.md"&gt;guide to reducing variability&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Can I configure the lighthouse run?&lt;/h3&gt; 
&lt;p&gt;Yes! Details in &lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/configuration.md"&gt;Lighthouse configuration&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;How does Lighthouse use network throttling, and how can I make it better?&lt;/h3&gt; 
&lt;p&gt;Good question. Network and CPU throttling are applied by default in a Lighthouse run. The network attempts to emulate slow 4G connectivity and the CPU is slowed down 4x from your machine's default speed. If you prefer to run Lighthouse without throttling, you'll have to use the CLI and disable it with the &lt;code&gt;--throttling.*&lt;/code&gt; flags mentioned above.&lt;/p&gt; 
&lt;p&gt;Read more in our &lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/throttling.md"&gt;guide to network throttling&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Are results sent to a remote server?&lt;/h3&gt; 
&lt;p&gt;Nope. Lighthouse runs locally, auditing a page using a local version of the Chrome browser installed on the machine. Report results are never processed or beaconed to a remote server.&lt;/p&gt; 
&lt;h3&gt;How do I get localized Lighthouse results via the CLI?&lt;/h3&gt; 
&lt;p&gt;Starting in Lighthouse 8.0, Lighthouse relies entirely on native &lt;code&gt;Intl&lt;/code&gt; support and no longer uses an &lt;code&gt;Intl&lt;/code&gt; polyfill. If you're using Node 14 or later, there should be no issue because Node is now &lt;a href="https://nodejs.medium.com/node-js-12-to-lts-and-node-js-13-is-here-e28d6a4a2bd#9514"&gt;built with &lt;code&gt;full-icu&lt;/code&gt; by default&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;However, if you're using a &lt;code&gt;small-icu&lt;/code&gt; Node build, you may see Lighthouse log messages about your locale not being available. To remedy this, you can manually install ICU data by using the &lt;a href="https://www.npmjs.com/package/full-icu"&gt;&lt;code&gt;full-icu&lt;/code&gt;&lt;/a&gt; module and the &lt;a href="https://nodejs.org/api/intl.html#intl_providing_icu_data_at_runtime"&gt;&lt;code&gt;--icu-data-dir&lt;/code&gt; node flag&lt;/a&gt; at launch.&lt;/p&gt; 
&lt;h3&gt;How do I author custom audits to extend Lighthouse?&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: see &lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/architecture.md"&gt;Lighthouse Architecture&lt;/a&gt; for more information on terminology and architecture.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Lighthouse can be extended to run custom audits and gatherers that you author. This is great if you're already tracking performance metrics in your site and want to surface those metrics within a Lighthouse report.&lt;/p&gt; 
&lt;p&gt;If you're interested in running your own custom audits, check out our &lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/docs/recipes/custom-audit"&gt;Custom Audit Example&lt;/a&gt; over in recipes.&lt;/p&gt; 
&lt;h3&gt;How do I contribute?&lt;/h3&gt; 
&lt;p&gt;We'd love help writing audits, fixing bugs, and making the tool more useful! See &lt;a href="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt; to get started.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p align="center"&gt; &lt;img src="https://raw.githubusercontent.com/GoogleChrome/lighthouse/main/assets/lighthouse-logo_512px.png" alt="Lighthouse logo" height="150" /&gt; &lt;br /&gt; &lt;b&gt;Lighthouse&lt;/b&gt;, ˈlītˌhous (n): a &lt;s&gt;tower or other structure&lt;/s&gt; tool containing a beacon light to warn or guide &lt;s&gt;ships at sea&lt;/s&gt; developers. &lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NaiboWang/EasySpider</title>
      <link>https://github.com/NaiboWang/EasySpider</link>
      <description>&lt;p&gt;A visual no-code/code-free web crawler/spider易采集：一个可视化浏览器自动化测试/数据采集/爬虫软件，可以无代码图形化的设计和执行爬虫任务。别名：ServiceWrapper面向Web应用的智能化服务封装系统。&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;易采集/EasySpider: Visual Code-Free Web Crawler&lt;/h1&gt; 
&lt;p&gt;一个&lt;strong&gt;完全免费&lt;/strong&gt;（&lt;strong&gt;包括商业使用和二次开发&lt;/strong&gt;）的可视化浏览器自动化测试/数据采集/爬虫软件，可以使用图形化界面，无代码可视化的设计和执行任务。只需要在网页上选择自己想要操作的内容并根据提示框操作即可完成任务的设计和执行。同时软件还可以单独以命令行的方式进行执行，从而可以很方便的嵌入到其他系统中。&lt;/p&gt; 
&lt;p&gt;A &lt;strong&gt;completely free (including for commercial use and secondary development)&lt;/strong&gt; visual browser automation test/data collection/crawler software, which can be used to design and execute tasks in a code-free visual way. You only need to select the content you want to operate on the web page and follow the prompts to complete the design and execution of the task. At the same time, the software can also be executed separately in the command line, so that it can be easily embedded into other systems.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://trendshift.io/repositories/3367" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/3367" alt="NaiboWang%2FEasySpider | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;下载易采集/Download EasySpider&lt;/h2&gt; 
&lt;p&gt;进入 &lt;a href="https://github.com/NaiboWang/EasySpider/releases"&gt;Releases Page&lt;/a&gt; 下载最新版本。如果下载速度慢，可以考虑中国境内下载地址：&lt;a href="https://www.easyspider.cn/download.html"&gt;中国境内下载地址&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;Refer to the &lt;a href="https://github.com/NaiboWang/EasySpider/releases"&gt;Releases Page&lt;/a&gt; to download the latest version of EasySpider.&lt;/p&gt; 
&lt;h2&gt;赞助者/Sponsors&lt;/h2&gt; 
&lt;p&gt;&lt;a target="_blank" href="https://get.brightdata.com/njx4r"&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/BrightData.png" width="850" /&gt;&lt;/a&gt; &lt;a href="https://get.brightdata.com/njx4r"&gt;亮数据BrightData&lt;/a&gt;是代理市场领导者，覆盖全球的7200万IP，提供真人住宅IP，即时批量采集网络公开数据，成功率亲测有保证。需要性价比高代理IP的可&lt;strong&gt;点击上方图片注册&lt;/strong&gt;后联系中文客服，开通后免费试用，&lt;strong&gt;现在有首充多少就送多少的活动&lt;/strong&gt;。BrightData可配合EasySpider进行数据采集。&lt;/p&gt; 
&lt;!-- &lt;a target="_blank" href="https://www.thordata.com/?ls=github&amp;lk=wnb"&gt;&lt;img src="media/thordata.jpg" width=850&gt;&lt;/img&gt;&lt;/a&gt;
[Thordata](https://www.thordata.com/?ls=github&amp;lk=wnb)是全球代理IP解决方案提供商，支持大规模采集公共网络数据，提供 195+ 国家城市、6000 万住宅IP，价格低至 $0.65/GB，支持不限流量、不限IP、不限并发；还包括本土独享ISP静态代理和高性能数据中心代理（均为 $0.75/IP，弹性定价）。点击图片注册后联系中文客服即可免费试用，现在首充还有赠送同额金额活动。可与EasySpider工具配合使用，高效采集网络数据。 --&gt; 
&lt;p&gt;&lt;a target="_blank" href="https://bestproxy.com/?keyword=48xywxar"&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/best_proxy.png" width="850" /&gt;&lt;/a&gt; &lt;a href="https://bestproxy.com/?keyword=48xywxar"&gt;BestProxy&lt;/a&gt;全球独享专属资源池，优选海外195+国家/地区高质量住宅IP，本地ISP原生IP，不限量住宅代理、长效ISP代理、静态数据中心代理、网页爬虫API，城市级精准定位，支持HTTP(S)和SOCKS5协议，低检测风险，全方位代理服务解决方案，助力各种场景业务IP代理需求。$0.66/G起按需付费和长期套餐，适合不同预算需求，24/7多语言支持，联系客服免费试用500M。可与EasySpider工具配合使用，高效采集网络数据。&lt;/p&gt; 
&lt;p&gt;&lt;a target="_blank" href="https://www.ipdodo.com/account/register?invite_code=GE1XXDLJ"&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/IPdodo.png" width="850" /&gt;&lt;/a&gt; &lt;a href="https://www.ipdodo.com/account/register?invite_code=GE1XXDLJ"&gt;IPdodo&lt;/a&gt;专注为跨境用户，提供独享/纯净/家宽/原生/双ISP的全球代理IP，不限流量。全球8000万真实住宅IP，覆盖200+国家/地区，99.9%匿名保护，且支持Http/Https/Socks5协议，满足爬虫、数据采集、跨境电商、tk/fb流媒体等业务场景。现在前往IPdodo注册，支持免费试用。&lt;/p&gt; 
&lt;!-- &lt;a target="_blank" href="https://www.ipwo.net/?code=KK9YVWI2L"&gt;&lt;img src="media/IPWO_Proxy.gif" width=850&gt;&lt;/img&gt;&lt;/a&gt;

&lt;!-- [IPWO](https://www.ipwo.net/?code=KK9YVWI2L)支持免费测试，作为行业领先的代理IP提供商，拥有 9000万+真实住宅IP，覆盖200+国家和地区，支持无限并发，可用率高达99.9%，帮助用户轻松突破地理限制，实现高效、安全的全球网络访问，与EasySpider完美结合，助力数据采集，尽享无缝体验。 --&gt; 
&lt;!-- &lt;a target="_blank" href="https://www.capsolver.com/zh?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider"&gt;&lt;img src="media/capsolver.jpg" width=850&gt;&lt;/img&gt;&lt;/a&gt; --&gt; 
&lt;!-- [![Capsolver](media/capsolver.jpg)](https://www.capsolver.com/zh?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider) --&gt; 
&lt;!-- [Capsolver.com](https://www.capsolver.com/?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider) is an AI-powered service that specializes in solving various types of captchas automatically. It supports captchas such as [reCAPTCHA V2](https://docs.capsolver.com/guide/captcha/ReCaptchaV2.html?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider), [reCAPTCHA V3](https://docs.capsolver.com/guide/captcha/ReCaptchaV3.html?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider), [DataDome](https://docs.capsolver.com/guide/captcha/DataDome.html?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider), [AWS Captcha](https://docs.capsolver.com/guide/captcha/awsWaf.html?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider), [Geetest](https://docs.capsolver.com/guide/captcha/Geetest.html?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider), and Cloudflare [Captcha](https://docs.capsolver.com/guide/antibots/cloudflare_turnstile.html?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider) / [Challenge 5s](https://docs.capsolver.com/guide/antibots/cloudflare_challenge.html?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider), [Imperva / Incapsula](https://docs.capsolver.com/guide/antibots/imperva.html?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider), among others.
For developers, Capsolver offers API integration options detailed in their [documentation](https://docs.capsolver.com/?utm_source=github&amp;utm_medium=banner_github&amp;utm_campaign=easyspider), facilitating the integration of captcha solving into applications. They also provide browser extensions for [Chrome](https://chromewebstore.google.com/detail/captcha-solver-auto-captc/pgojnojmmhpofjgdmaebadhbocahppod) and [Firefox](https://addons.mozilla.org/es/firefox/addon/capsolver-captcha-solver/), making it easy to use their service directly within a browser. Different pricing packages are available to accommodate varying needs, ensuring flexibility for users. --&gt; 
&lt;!-- &lt;a target="_blank" href="https://www.proxy302.com/?ref=wangnaibo"&gt;&lt;img src="media/Proxy302.jpg" width=850&gt;&lt;/img&gt;&lt;/a&gt;

[Proxy302](https://www.proxy302.com/?ref=wangnaibo)是一个全球代理IP自助超市。按需付费，无需套餐捆绑购买；无阶梯式定价，充值即可使用所有类型的代理IP；免费测试，注册获取$1测试额度。覆盖全球240＋国家和地区，6500万个住宅IP可供选择。Proxy302可配合EasySpider进行数据采集。

&lt;a target="_blank" href="https://www.123proxy.cn/?utm_source=EasySpider"&gt;&lt;img src="media/123proxy.png" width=850&gt;&lt;/img&gt;&lt;/a&gt;

[123Proxy](https://www.123proxy.cn/?utm_source=EasySpider)是企业级海外代理IP提供商, 拥有独家的8000万+代理IP池，190+国家覆盖，真实家庭住宅IP，适合各种用途的数据采集类任务。它支持免费测试2-4小时，**点击上方图片注册**联系客服即可获取；它还支持15%返现活动，给公司购买代理可以返现到个人，直接微信/支付宝返现，打工人的小福利。123Proxy可配合EasySpider进行数据采集。

&lt;a target="_blank" href="https://koala-ip.com/"&gt;&lt;img src="media/Koala-IP.png" width=850&gt;&lt;/img&gt;&lt;/a&gt;

[Koala-IP](https://koala-ip.com/)提供海量低价高质量代理IP服务，致力于为客户提供[最优价格](https://zh-cn.koala-ip.com/var-ip)和最稳定的代理IP解决方案。无论你是需要网络爬虫、数据抓取、隐私保护还是跨地域访问，[Koala-IP（中文）](https://zh-cn.koala-ip.com/) 都能满足你的所有需求。[立即注册Koala-IP](https://koala-ip.com/admin/register)，享受超高性价比的代理IP服务，提升你的业务效益！ --&gt; 
&lt;h2&gt;官方网站/Official Website&lt;/h2&gt; 
&lt;p&gt;访问易采集官网：&lt;a href="http://www.easyspider.cn"&gt;www.easyspider.cn&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Visit the official website of EasySpider: &lt;a href="http://www.easyspider.net"&gt;www.easyspider.net&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;软件使用示例/Software Usage Example&lt;/h2&gt; 
&lt;h3&gt;示例1/Example 1&lt;/h3&gt; 
&lt;p&gt;（右键）选中一个大商品块 -&amp;gt; 软件自动检测到同类型商品块 -&amp;gt; 点击“选中全部”选项 -&amp;gt; 点击“选中子元素”选项 -&amp;gt; 点击“采集数据”选项，即可采集到所有商品的所有信息，并分成不同字段保存。&lt;/p&gt; 
&lt;p&gt;(Right click) Select a large product block -&amp;gt; The software will automatically detect similar blocks -&amp;gt; Click the 'Select All' option -&amp;gt; Click the 'Select Child Elements' option -&amp;gt; Click the 'Collect Data' option, you can collect the information of all products, and will be saved by sub-field.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/animation_zh.gif" alt="animation_zh" /&gt;&lt;/p&gt; 
&lt;h3&gt;示例2/Example 2&lt;/h3&gt; 
&lt;p&gt;（右键）选中一个商品标题，同类型标题会被自动匹配，点击“选中全部”选项 -&amp;gt; 点击“采集数据”选项，即可采集到所有商品的标题信息。&lt;/p&gt; 
&lt;p&gt;同时，选中全部后如果选择“循环点击每个元素”选项，即可自动打开每个商品的详情页，然后可以再继续设置采集详情页的信息。&lt;/p&gt; 
&lt;p&gt;(Right Click) Select a product title, the same type of title will be automatically matched, click the 'Select All' option -&amp;gt; Click the 'Collect Data' option, you can collect the title information of all products.&lt;/p&gt; 
&lt;p&gt;At the same time, if you select the 'Loop-click every element' option after selecting all, you can automatically open the details page of each product, and then can set to collect the information of the details page.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/animation_en.gif" alt="animation_en" /&gt;&lt;/p&gt; 
&lt;h3&gt;更多特性/More Features&lt;/h3&gt; 
&lt;p&gt;更多特性请翻到页面底部查看。&lt;/p&gt; 
&lt;p&gt;More features please scroll to the bottom of this page to view.&lt;/p&gt; 
&lt;h2&gt;支持作者/Support Author&lt;/h2&gt; 
&lt;p&gt;易采集EasySpider是一款完全免费且使用中无广告的开源软件，软件开发和维护全靠作者用爱发电，因此您可以选择支持作者让作者有更多的热情和精力维护此软件，或者您使用了此软件进行了盈利，欢迎您通过下面的方式支持作者：&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Github Sponsor：直接点击右侧&lt;strong&gt;Sponsor&lt;/strong&gt;按钮赞助。&lt;/li&gt; 
 &lt;li&gt;支付宝账号：&lt;a href="mailto:naibowang@foxmail.com"&gt;naibowang@foxmail.com&lt;/a&gt;，也可以扫描下方二维码。&lt;/li&gt; 
 &lt;li&gt;微信收款：扫描下方二维码。&lt;/li&gt; 
 &lt;li&gt;PayPal账号：naibowang，也可以扫描下方二维码。&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;You can support the author by clicking the &lt;strong&gt;Sponsor&lt;/strong&gt; button at right side or pay via paypal: naibowang.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/QRCODES.png" alt="QRCodes" /&gt;&lt;/p&gt; 
&lt;h2&gt;文档/Documentation&lt;/h2&gt; 
&lt;p&gt;请点此进入&lt;a href="https://github.com/NaiboWang/EasySpider/wiki"&gt;教程文档&lt;/a&gt;，如有英文可暂时翻译一下，或看作者的&lt;a href="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/Docs/%E9%9D%A2%E5%90%91WEB%E5%BA%94%E7%94%A8%E7%9A%84%E6%99%BA%E8%83%BD%E5%8C%96%E6%9C%8D%E5%8A%A1%E5%B0%81%E8%A3%85%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"&gt;硕士毕业论文&lt;/a&gt;（主要看第三章和第五章）。&lt;/p&gt; 
&lt;p&gt;Ebay样例博客：&lt;a href="https://blog.csdn.net/ihero/article/details/130805504"&gt;https://blog.csdn.net/ihero/article/details/130805504&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;Documentation can be found from &lt;a href="https://github.com/NaiboWang/EasySpider/wiki"&gt;GitHub Wiki&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;视频教程/Video Tutorials&lt;/h2&gt; 
&lt;p&gt;Bilibili/B站视频教程:&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1th411A7ey/"&gt;EasySpider介绍 - 中国地震台网采集案例&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1G14y1o7Qa/"&gt;设置页面向下滚动&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1BN411t71C/"&gt;如何无代码可视化的爬取需要登录才能爬的网站 - 知乎网站案例&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV12V411D7RZ"&gt;循环点击列表中每个链接进入详情页采集详情页内容+设计时动态调试+动态JS&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV14u4y1x7S5/"&gt;实战采集汽车网文章内容并下载文章内图片&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1N94y1a7Lp/"&gt;定时执行任务+选中子元素多种模式+将提取值作为变量输入&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV18C4y1V7J7/"&gt;【重要】自定义条件判断之使用循环项内的JS命令返回值 - 第二弹&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV14N4y1o73Y/"&gt;流程图执行逻辑解析 - 58同城房源描述采集案例&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1E34y137fT/"&gt;MacOS系统设计和执行eBay网站爬虫任务教程&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1UH4y1f7BM/"&gt;如何执行自己写的JS代码和系统代码 （自定义操作）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV18w411a77e/"&gt;如何自定义循环和判断条件 - 第一弹&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1ch4y1E7cn/"&gt;如何对元素和网页截图及命令行执行指南&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1GP411y7u4/"&gt;OCR识别元素内容功能（常用于文字验证码）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1Rw411C7Hs/"&gt;如何爬需要输入验证码的网站&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1zw411w7BN/"&gt;如何切换IP池和使用隧道IP - 打开详情页采集案例&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1Dj411b77M/"&gt;如何同时执行多个任务（并行多开）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1kF411R7VJ/"&gt;Python代码运算后的结果作为文本框的输入&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1XH4y1Z78i/"&gt;实例 - 反人类网站文章采集和代码调试&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1os4y1679S/"&gt;写入MySQL数据库教程&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.bilibili.com/video/BV1VE421P7yj/"&gt;从源代码编译程序并设计运行和调试任务指南（基于Ubuntu24.04）&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Refer to &lt;a href="https://youtube.com/playlist?list=PL0kEFEkWrT7mt9MUlEBV2DTo1QsaanUTp"&gt;Youtube Playlist&lt;/a&gt; to see the video tutorials of EasySpider.&lt;/p&gt; 
&lt;h2&gt;样例任务/Sample Tasks&lt;/h2&gt; 
&lt;p&gt;从本项目的&lt;a href="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/Examples"&gt;Examples&lt;/a&gt;文件夹中下载样例任务，更名为大于0的数字，导入到EasySpider中的&lt;code&gt;tasks&lt;/code&gt;文件夹中，然后在EasySpider中打开即可。&lt;/p&gt; 
&lt;p&gt;Download sample tasks from the &lt;a href="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/Examples"&gt;Examples&lt;/a&gt; folder of this project, rename them to numbers greater than 0, import them into the &lt;code&gt;tasks&lt;/code&gt; folder in EasySpider, and then open them in EasySpider.&lt;/p&gt; 
&lt;h2&gt;声明/Declaration&lt;/h2&gt; 
&lt;p&gt;本软件仅供学习交流使用，&lt;strong&gt;严禁使用软件进行任何违法违规的操作，如爬取不允许爬取的政府/军事机关网站等&lt;/strong&gt;。使用本软件所造成的&lt;strong&gt;一切后果由使用者自负&lt;/strong&gt;，与作者本人无关，&lt;strong&gt;作者不会承担任何责任&lt;/strong&gt;。&lt;/p&gt; 
&lt;p&gt;This software is for learning and communication only. &lt;strong&gt;It is strictly forbidden to use the software for any illegal operations, such as crawling government/military websites that are not allowed to be crawled.&lt;/strong&gt; All consequences caused by the use of this software are &lt;strong&gt;at the user's own risk, and the author is not responsible for any consequences&lt;/strong&gt;.&lt;/p&gt; 
&lt;p&gt;对于政府和军事机关等网站的爬虫操作，&lt;strong&gt;作者将不会进行任何答疑&lt;/strong&gt;，以免违反国家相关法律法规和政策。&lt;/p&gt; 
&lt;p&gt;For the crawler operations of government and military websites, &lt;strong&gt;the author will not answer any questions&lt;/strong&gt; in order to avoid violating relevant national laws, regulations and policies.&lt;/p&gt; 
&lt;p&gt;EasySpider遵循AGPL-3.0协议，&lt;strong&gt;任何个人和企业都可以免费使用软件本身或使用源代码进行二次开发，无需联系作者进行商业（专利）授权&lt;/strong&gt;，但需要注意AGPL-3.0协议的相关规则：&lt;/p&gt; 
&lt;p&gt;EasySpider complies with the AGPL-3.0 agreement. &lt;strong&gt;Any individual or enterprise can use the software for free and use the software source code for secondary development without contacting the author for commercial (patent) authorization.&lt;/strong&gt; However, it is necessary to pay attention to the related rules of the AGPL-3.0 agreement:&lt;/p&gt; 
&lt;h3&gt;1. Copyleft（传染性） / Copyleft (Viral Clause)&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;衍生作品 / Derivative Works&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;任何基于 AGPL 代码的修改或衍生作品，必须&lt;strong&gt;以相同许可证（AGPL-3.0）发布&lt;/strong&gt;。&lt;/li&gt; 
   &lt;li&gt;Any modifications or derivative works based on AGPL code must be &lt;strong&gt;licensed under AGPL-3.0&lt;/strong&gt;.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;联动范围 / Scope of Copyleft&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;若 AGPL 代码与其他代码结合（如静态链接、紧密集成），整个作品需遵守 AGPL。&lt;/li&gt; 
   &lt;li&gt;If AGPL code is combined with other code (e.g., static linking), the entire work must comply with AGPL.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;2. 网络使用条款 / Network Use Clause&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;SaaS 触发开源义务 / SaaS Trigger&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;若软件以服务形式提供（如网站、API），必须向所有用户公开&lt;strong&gt;完整对应源代码&lt;/strong&gt;（包括修改后的代码）。&lt;/li&gt; 
   &lt;li&gt;If the software is provided as a service (e.g., website, API), the &lt;strong&gt;full corresponding source code&lt;/strong&gt; (including modifications) must be made available to all users.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;用户权利 / User Rights&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;服务的接收者可通过下载或书面请求获取源码。&lt;/li&gt; 
   &lt;li&gt;Service recipients may obtain the source code via download or written request.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;3. 源码提供要求 / Source Code Provision&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;二进制分发 / Binary Distribution&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;必须附带源码或提供获取渠道（如下载链接）。&lt;/li&gt; 
   &lt;li&gt;Source code must be included or a download link provided.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;网络服务场景 / Network Service Scenario&lt;/strong&gt; 
  &lt;ul&gt; 
   &lt;li&gt;需通过服务界面&lt;strong&gt;显式提供源码链接&lt;/strong&gt;，或向用户书面承诺提供源码。&lt;/li&gt; 
   &lt;li&gt;The service interface must &lt;strong&gt;explicitly provide a source code link&lt;/strong&gt; or offer a written offer for source code.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;4. 专利授权 / Patent Grant&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;贡献者自动授予用户与软件相关的专利许可，禁止专利诉讼。&lt;/li&gt; 
 &lt;li&gt;Contributors automatically grant users patent rights related to the software, and prohibit patent litigation.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;5. 免责声明 / Disclaimer&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;软件按“原样”提供，作者&lt;strong&gt;不承担任何责任&lt;/strong&gt;（无担保条款）。&lt;/li&gt; 
 &lt;li&gt;The software is provided "as is" with &lt;strong&gt;no warranties or liabilities&lt;/strong&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;答疑QQ群&lt;/h2&gt; 
&lt;p&gt;群号：&lt;strong&gt;682921940&lt;/strong&gt;，建议通过Github提Issue的方式答疑，如果实在有需要才请加QQ群，因为群人数有上限，&lt;strong&gt;QQ群不提供软件下载功能&lt;/strong&gt;。&lt;/p&gt; 
&lt;h2&gt;出版物/Publications&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;This software has been accepted by The Web Conference (WWW) 2023 (中国计算机学会顶级会议，CCF A): &lt;a href="https://dl.acm.org/doi/abs/10.1145/3543873.3587345"&gt;EasySpider: A No-Code Visual System for Crawling the Web&lt;/a&gt;, April 2023.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;中国国家知识产权局发明专利，&lt;a href="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/patent.png"&gt;一种自定义提取流程的服务封装系统&lt;/a&gt;， 2022年5月。&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;a href="https://d.wanfangdata.com.cn/thesis/Y3691829"&gt;浙江大学硕士论文&lt;/a&gt;，&lt;a href="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/Docs/%E9%9D%A2%E5%90%91WEB%E5%BA%94%E7%94%A8%E7%9A%84%E6%99%BA%E8%83%BD%E5%8C%96%E6%9C%8D%E5%8A%A1%E5%B0%81%E8%A3%85%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0.pdf"&gt;面向WEB应用的智能化服务封装系统设计与实现&lt;/a&gt;，2020年6月。&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;!-- - See the [Copyright Declaration Page](https://github.com/NaiboWang/EasySpider/blob/master/media/readme_back.md) here.
 --&gt; 
&lt;h2&gt;编译说明/Compilation Instructions&lt;/h2&gt; 
&lt;p&gt;查看&lt;a href="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/ElectronJS/README.md"&gt;编译说明&lt;/a&gt;。&lt;/p&gt; 
&lt;p&gt;Refer to &lt;a href="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/ElectronJS/README.md"&gt;Compilation Instructions&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;支持特性/Supported Features&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/features_CN.png" alt="pic" /&gt; &lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/features_EN.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h2&gt;中文界面截图&lt;/h2&gt; 
&lt;h4&gt;软件界面示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;块和子块及表单定义&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture2.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;已选中和待选择示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture7.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;京东商品块选择示例：&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture1.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;京东商品标题自动匹配选择示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture5.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;分块选择所有子元素示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture6.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;同类型元素自动和手动匹配示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture8.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;四种选择方式示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture90.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;输入文字示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture10.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;循环点击58同城房屋标题以进入详情页采集示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture12.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;采集元素文本示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture14.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;流程图界面介绍&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture4.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;循环选项示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture9.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;循环点击下一页示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture11.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;条件分支示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture13.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;完整采集流程图示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture16.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;完整采集流程图转换为常规流程图示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture91.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;服务信息示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture15.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;服务调用示例&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture17.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;h4&gt;58 同城房源信息采集服务部分采集结果展示&lt;/h4&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/NaiboWang/EasySpider/master/media/Picture18.png" alt="pic" /&gt;&lt;/p&gt; 
&lt;!-- ## Ethics Discussion
Various fields can benefit from web crawlers due to their open access nature.
Inevitably, there will be some risk of malicious use or data infringement issue, e.g., automatic order swiping and ticket grabbing, but this is contrary to our expectations. As a tool developer, we only hope that it can be used for legitimate purposes. We advocate the reasonable and legal utilization of our system, respecting and protecting the data security and privacy. --&gt;</description>
    </item>
    
    <item>
      <title>mickael-kerjean/filestash</title>
      <link>https://github.com/mickael-kerjean/filestash</link>
      <description>&lt;p&gt;📁 A file manager / web client for SFTP, S3, FTP, WebDAV, Git, Minio, LDAP, CalDAV, CardDAV, Mysql, Backblaze, ...&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/mickael-kerjean/filestash_images/master/.assets/photo.jpg" alt="screenshot" /&gt;&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/mickael-kerjean/contributors" alt="Contributors"&gt; &lt;img src="https://img.shields.io/github/contributors/mickael-kerjean/filestash" style="max-width:100%;" /&gt; &lt;/a&gt; &lt;a href="https://hub.docker.com/r/machines/filestash" alt="Docker Hub"&gt; &lt;img src="https://img.shields.io/docker/pulls/machines/filestash" style="max-width:100%;" /&gt; &lt;/a&gt; &lt;a href="https://kiwiirc.com/nextclient/#irc://irc.libera.chat/#filestash?nick=guest??" alt="Chat on IRC"&gt; &lt;img src="https://img.shields.io/badge/IRC-%23filestash-brightgreen.svg?sanitize=true" style="max-width:100%;" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; A Dropbox-like file manager that let you manage your data anywhere it is located:&lt;br /&gt; &lt;a href="https://www.filestash.app/ftp-client.html"&gt;FTP&lt;/a&gt; • &lt;a href="https://www.filestash.app/ftp-client.html"&gt;FTPS&lt;/a&gt; • &lt;a href="https://www.filestash.app/ssh-file-transfer.html"&gt;SFTP&lt;/a&gt; • &lt;a href="https://www.filestash.app/webdav-client.html"&gt;WebDAV&lt;/a&gt; • Git • &lt;a href="https://www.filestash.app/s3-browser.html"&gt;S3&lt;/a&gt; • NFS • &lt;a href="https://www.filestash.app/smb-client.html"&gt;SMB&lt;/a&gt; • Artifactory • &lt;a href="https://www.filestash.app/ldap-browser.html"&gt;LDAP&lt;/a&gt; • Mysql &lt;br /&gt; Storj • CardDAV • CalDAV • Backblaze B2 • &lt;a href="https://www.filestash.app/s3-browser.html"&gt;Minio&lt;/a&gt; &lt;br /&gt;Dropbox • Google Drive &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="http://demo.filestash.app"&gt; &lt;img src="https://raw.githubusercontent.com/mickael-kerjean/filestash_images/master/.assets/button_demo.png" alt="demo button" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h1&gt;Key Features&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Manage files from your browser&lt;/li&gt; 
 &lt;li&gt;Sleek, Speedy, Snappy, works great on Desktop and Mobile&lt;/li&gt; 
 &lt;li&gt;Extensible / Customisable / Hackable via a rich ecosystem of plugins&lt;/li&gt; 
 &lt;li&gt;Shared Links which you can mount locally as network drives&lt;/li&gt; 
 &lt;li&gt;Builtin Music, Video, Image viewers with optional transcoding and Chromecast support&lt;/li&gt; 
 &lt;li&gt;API and LLM integration via &lt;a href="https://www.filestash.app/docs/api/#mcp"&gt;MCP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.filestash.app/docs/plugin/#theme"&gt;Themes&lt;/a&gt; replicating the UX of &lt;a href="https://www.filestash.app/img/screenshots/theme_dropbox.png"&gt;dropbox&lt;/a&gt;, &lt;a href="https://www.filestash.app/img/screenshots/theme_gdrive.png"&gt;gdrive&lt;/a&gt;, &lt;a href="https://www.filestash.app/img/screenshots/theme_github.png"&gt;github&lt;/a&gt;, &lt;a href="https://www.filestash.app/img/screenshots/theme_ibm.png"&gt;ibm&lt;/a&gt;, &lt;a href="https://www.filestash.app/img/screenshots/theme_onedrive.png"&gt;onedrive&lt;/a&gt;, &lt;a href="https://www.filestash.app/img/screenshots/theme_untitled.png"&gt;and more&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;... and much &lt;sub&gt;much &lt;sub&gt;much&lt;/sub&gt;&lt;/sub&gt; more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Documentation&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.filestash.app/docs/"&gt;Getting started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.filestash.app/docs/install-and-upgrade/"&gt;Installation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.filestash.app/docs/api/#api"&gt;API&lt;/a&gt; and &lt;a href="https://www.filestash.app/docs/api/#mcp"&gt;MCP&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.filestash.app/docs/plugin/"&gt;Plugins Inventory&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://downloads.filestash.app/upload/hardening-guide.pdf"&gt;Hardening Guide&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Vision &amp;amp; Philosophy&lt;/h1&gt; 
&lt;p&gt;Our goal is simple: &lt;strong&gt;to build the best web based file manager ever made. Period.&lt;/strong&gt; But "best" means different things to different people, and making Filestash modular is the only sane model to accomplish that. Anything that isn't a fundamental truth of the universe and might spark a debate belongs in a plugin.&lt;/p&gt; 
&lt;p&gt;This modularity is made possible by the magic of programming interfaces. For example, if you want a &lt;a href="https://news.ycombinator.com/item?id=9224"&gt;Dropbox-like frontend for FTP&lt;/a&gt;, you will find out the &lt;a href="https://github.com/mickael-kerjean/filestash/tree/master/server/plugin/plg_backend_ftp"&gt;FTP plugin&lt;/a&gt; simply implements this interface:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-go"&gt;type IBackend interface {
	Ls(path string) ([]os.FileInfo, error)           // list files in a folder
	Cat(path string) (io.ReadCloser, error)          // download a file
	Mkdir(path string) error                         // create a folder
	Rm(path string) error                            // remove something
	Mv(from string, to string) error                 // rename something
	Save(path string, file io.Reader) error          // save a file
	Touch(path string) error                         // create a file

	// I have omitted 2 other methods, a first one to enable connections reuse and
	// another one to declare what should the login form be like.
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;There are interfaces you can implement for every key component of Filestash: from storage, to authentication, authorisation, custom apps, search, thumbnailing, frontend patches, middleware, endpoint creation and a &lt;a href="https://github.com/mickael-kerjean/filestash/raw/master/server/common/plugin.go"&gt;few others&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To see what's currently installed in your instance, head over to &lt;a href="https://demo.filestash.app/about"&gt;/about&lt;/a&gt;. The inventory of plugins is &lt;a href="https://www.filestash.app/docs/plugin/"&gt;documented here&lt;/a&gt;.&lt;/p&gt; 
&lt;h1&gt;Roadmap&lt;/h1&gt; 
&lt;p&gt;There are 2 major pieces of work currently underway:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Making Filestash able to open virtually anything. Thanks to plugin, we're adding support for files your browser has never heard of, from astrophysics to embroidery patterns. Concretly we have added support for: 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_photography.zip"&gt;photography&lt;/a&gt;: heif, nef, raf, tiff, raw, arw, sr2, srf, nrw, cr2, crw, x3f, pef, rw2, orf, mrw, mdc, mef, mos, dcr, kdc, 3fr, erf and srw&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_photography.zip"&gt;astronomy&lt;/a&gt;: fits, xisf&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_science.zip"&gt;science&lt;/a&gt;: with latex, plantuml &amp;amp; pandoc compilers&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_musician.zip"&gt;music&lt;/a&gt;: mid, midi, gp4 and gp5&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_gis.zip"&gt;GIS&lt;/a&gt;: &lt;a href="https://www.filestash.app/tools/geojson-viewer.html"&gt;geojson&lt;/a&gt;, &lt;a href="https://www.filestash.app/tools/shp-viewer.html"&gt;shp&lt;/a&gt;, gpx, wms and &lt;a href="https://www.filestash.app/tools/dbf-viewer.html"&gt;dbf&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_engineering.zip"&gt;data engineering&lt;/a&gt;: &lt;a href="https://www.filestash.app/tools/parquet-viewer.html"&gt;parquet&lt;/a&gt;, &lt;a href="https://www.filestash.app/tools/arrow-viewer.html"&gt;arrow&lt;/a&gt;, &lt;a href="https://www.filestash.app/tools/feather-viewer.html"&gt;feather&lt;/a&gt;, &lt;a href="https://www.filestash.app/tools/avro-viewer.html"&gt;avro&lt;/a&gt;, &lt;a href="https://www.filestash.app/tools/orc-viewer.html"&gt;orc&lt;/a&gt;, hdf5, h5, netcdf, nc, rds, rda and rdata&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_dev.zip"&gt;dev&lt;/a&gt;: a, so, o, dylib, dll, har, cap, pcap, pcapng and &lt;a href="https://www.filestash.app/tools/sqlite-viewer.html"&gt;sqlite&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_creative.zip"&gt;creative work&lt;/a&gt;: svg, &lt;a href="https://www.filestash.app/tools/psd-viewer.html"&gt;psd&lt;/a&gt;, ai, &lt;a href="https://www.filestash.app/tools/sketch-viewer.html"&gt;sketch&lt;/a&gt;, &lt;a href="https://www.filestash.app/tools/cdr-viewer.html"&gt;cdr&lt;/a&gt;, woff, woff2, ttf, otf, eot, exr, tga, pgm, ppm, dds, ktx, dpx, pcx, xpm, pnm, xbm, aai, xwd, cin, pbm, pcd, sgi, wbmp and rgb&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_biomed.zip"&gt;biomedical&lt;/a&gt;: dicom, sam, bam, cif, pdb, xyz, sdf, mol, mol2 and mmtf&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_autodesk.zip"&gt;autodesk&lt;/a&gt;: &lt;a href="https://www.filestash.app/tools/dwg-viewer.html"&gt;dwg&lt;/a&gt; and &lt;a href="https://www.filestash.app/tools/dxf-viewer.html"&gt;dxf&lt;/a&gt;&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_adobe.zip"&gt;adobe&lt;/a&gt;: &lt;a href="https://www.filestash.app/tools/psd-viewer.html"&gt;psd&lt;/a&gt;, ai, &lt;a href="https://www.filestash.app/tools/xd-viewer.html"&gt;xd&lt;/a&gt;, &lt;a href="https://www.filestash.app/tools/dng-viewer.html"&gt;dng&lt;/a&gt;, &lt;a href="https://www.filestash.app/tools/eps-viewer.html"&gt;postscript&lt;/a&gt;, aco, ase, swf&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_3d.zip"&gt;3d&lt;/a&gt;: fbx, gltf, obj, stl, step, mesh, ifc, dae&lt;/li&gt; 
   &lt;li&gt;&lt;a href="https://demo.filestash.app/assets/plugin/application_embroidery.zip"&gt;embroidery&lt;/a&gt;: dgt, dst, dsb, dsz, edr, exp, 10o, col, hus, inf, jef, ksm, pcm, pcs, pes, sew, shv, sst, tap, u01, vip, vp3 and xxx&lt;/li&gt; 
   &lt;li&gt;there is more to come as we stumbled upon new niches and spend time talking to real people.&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;Getting to v1.0. Filestash is already rock solid, it has been in active development for over 8 years. But the bar for v1.0 will be reached when Filestash is objectively better than Dropbox, Google Drive, and Box by every single measurable metric we care about. That's the mission.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h1&gt;Support&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;Commercial Users → &lt;a href="https://www.filestash.app/pricing/?origin=github"&gt;support contract&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;For individuals → &lt;a href="https://kiwiirc.com/nextclient/#irc://irc.libera.chat/#filestash?nick=guest??"&gt;#filestash&lt;/a&gt; on IRC (libera.chat).&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Want to help us sprinkle some toppings on our noodle cups?&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Bitcoin: &lt;code&gt;3LX5KGmSmHDj5EuXrmUvcg77EJxCxmdsgW&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://opencollective.com/filestash"&gt;Open Collective&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Credits&lt;/h1&gt; 
&lt;p&gt;Filestash stands on the shoulder of: &lt;a href="https://github.com/mickael-kerjean/filestash/graphs/contributors"&gt;contributors&lt;/a&gt;, folks developing &lt;a href="https://github.com/mickael-kerjean/filestash/raw/master/go.mod"&gt;awesome libraries&lt;/a&gt;, a whole bunch of C stuff (the &lt;a href="https://imgs.xkcd.com/comics/dependency.png"&gt;C standard library&lt;/a&gt;, &lt;a href="https://libjpeg-turbo.org/"&gt;libjpeg&lt;/a&gt;, &lt;a href="https://www.libpng.org/pub/png/libpng.html"&gt;libpng&lt;/a&gt;, &lt;a href="https://giflib.sourceforge.net/"&gt;libgif&lt;/a&gt;, &lt;a href="https://www.libraw.org/about"&gt;libraw&lt;/a&gt; and many more), &lt;a href="https://fontawesome.com"&gt;fontawesome&lt;/a&gt;, &lt;a href="https://material.io/icons/"&gt;material&lt;/a&gt;, &lt;a href="https://www.browserstack.com/"&gt;Browser stack&lt;/a&gt; to let us test on real devices, and the many guys from Nebraska and elsewhere who have been thanklessly maintaining the critical pieces that Filestash sits on top:&lt;/p&gt; 
&lt;img src="https://imgs.xkcd.com/comics/dependency.png" alt="credit to the nebraska guy on xkcd" /&gt;</description>
    </item>
    
    <item>
      <title>popcorn-official/popcorn-desktop</title>
      <link>https://github.com/popcorn-official/popcorn-desktop</link>
      <description>&lt;p&gt;Popcorn Time is a multi-platform, free software BitTorrent client that includes an integrated media player ( Windows / Mac / Linux ) A Butter-Project Fork&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;a href="https://popcorn-time.site"&gt;&lt;img src="https://avatars2.githubusercontent.com/u/7267937?s=200" alt="Popcorn Time" width="200" /&gt;&lt;/a&gt; &lt;br /&gt; Popcorn Time &lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;h4 align="center"&gt;A multi-platform, free software BitTorrent client that includes an integrated media player.&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/popcorn-official/popcorn-desktop/releases/latest"&gt;&lt;img src="https://img.shields.io/github/v/release/popcorn-official/popcorn-desktop?color=brightgreen&amp;amp;label=latest%20release" /&gt;&lt;/a&gt; &lt;a href="https://github.com/popcorn-official/popcorn-desktop/releases/latest"&gt;&lt;img src="https://img.shields.io/github/release-date/popcorn-official/popcorn-desktop?label=" /&gt;&lt;/a&gt; &lt;a href="https://github.com/popcorn-official/popcorn-desktop/compare/master...development"&gt;&lt;img src="https://img.shields.io/github/commits-since/popcorn-official/popcorn-desktop/latest?label=commits%20since" /&gt;&lt;/a&gt; &lt;a href="https://github.com/popcorn-official/popcorn-desktop/commit/development"&gt;&lt;img src="https://img.shields.io/github/last-commit/popcorn-official/popcorn-desktop?label=latest%20commit" /&gt;&lt;/a&gt; &lt;a href="https://github.com/popcorn-official/popcorn-desktop/actions"&gt;&lt;img src="https://img.shields.io/github/actions/workflow/status/popcorn-official/popcorn-desktop/build.yml?branch=development&amp;amp;label=latest%20build" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://popcorn-time.site"&gt;&lt;img src="https://img.shields.io/website?down_color=red&amp;amp;down_message=offline&amp;amp;label=popcorn-time.site&amp;amp;up_color=brightgreen&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Fpopcorn-time.site" /&gt;&lt;/a&gt; &lt;a href="https://github.com/popcorn-official"&gt;&lt;img src="https://img.shields.io/website?down_color=red&amp;amp;down_message=offline&amp;amp;label=github&amp;amp;up_color=brightgreen&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Fgithub.com%2Fpopcorn-official" /&gt;&lt;/a&gt; &lt;a href="https://www.reddit.com/r/PopCornTimeApp"&gt;&lt;img src="https://img.shields.io/website?down_color=red&amp;amp;down_message=offline&amp;amp;label=reddit&amp;amp;up_color=brightgreen&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fpopcorntimeapp%2F" /&gt;&lt;/a&gt; &lt;a href="https://github.com/popcorn-official/popcorn-desktop/wiki/"&gt;&lt;img src="https://img.shields.io/website?down_color=red&amp;amp;down_message=offline&amp;amp;label=wiki&amp;amp;up_color=brightgreen&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Fgithub.com%2Fpopcorn-official%2Fpopcorn-desktop%2Fwiki%2F" /&gt;&lt;/a&gt; &lt;a href="https://github.com/popcorn-official/popcorn-desktop/wiki/FAQ"&gt;&lt;img src="https://img.shields.io/website?down_color=red&amp;amp;down_message=offline&amp;amp;label=faq&amp;amp;up_color=brightgreen&amp;amp;up_message=online&amp;amp;url=https%3A%2F%2Fgithub.com%2Fpopcorn-official%2Fpopcorn-desktop%2Fwiki%2FFAQ" /&gt;&lt;/a&gt; &lt;/p&gt;
&lt;h4 align="center"&gt;Visit the project's website at &lt;a href="https://popcorn-time.site"&gt;popcorn-time.site&lt;/a&gt;&lt;/h4&gt; 
&lt;hr /&gt; 
&lt;h2&gt;Install&lt;/h2&gt; 
&lt;h3&gt;Windows:&lt;/h3&gt; 
&lt;p&gt;Download and install:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Latest release&lt;/strong&gt;: check &lt;a href="https://popcorn-time.site"&gt;popcorn-time.site&lt;/a&gt; or the repo's &lt;a href="https://github.com/popcorn-official/popcorn-desktop/releases"&gt;releases page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Or &lt;strong&gt;latest dev build (for testers)&lt;/strong&gt;: check the repo's &lt;a href="https://github.com/popcorn-official/popcorn-desktop/actions"&gt;actions page&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;macOS:&lt;/h3&gt; 
&lt;p&gt;Download and install:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Latest release&lt;/strong&gt;: check &lt;a href="https://popcorn-time.site"&gt;popcorn-time.site&lt;/a&gt; or the repo's &lt;a href="https://github.com/popcorn-official/popcorn-desktop/releases"&gt;releases page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Or &lt;strong&gt;latest dev build (for testers)&lt;/strong&gt;: check the repo's &lt;a href="https://github.com/popcorn-official/popcorn-desktop/actions"&gt;actions page&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Easily install Popcorn Time via &lt;em&gt;&lt;a href="https://brew.sh"&gt;Homebrew&lt;/a&gt; (&lt;a href="https://docs.brew.sh/Cask-Cookbook"&gt;Cask&lt;/a&gt;):&lt;/em&gt;&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rb"&gt;brew tap popcorn-official/popcorn-desktop https://github.com/popcorn-official/popcorn-desktop.git
#export HOMEBREW_POPCORN_TIME_BUILD=false
brew install --cask popcorn-time #--no-quarantine
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Also, if you keep a &lt;a href="https://github.com/Homebrew/homebrew-bundle#usage"&gt;&lt;em&gt;Brewfile&lt;/em&gt;&lt;/a&gt;, you can add something like this:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-rb"&gt;repo = "popcorn-official/popcorn-desktop"
tap repo, "https://github.com/#{repo}.git"
#ENV["HOMEBREW_POPCORN_TIME_BUILD"] = "false"
cask "popcorn-time" #, args: { "no-quarantine": true }
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Apple Silicon:&lt;/h4&gt; 
&lt;p&gt;If you have Apple Silicon (M-series chips), you need to use the &lt;code&gt;arm64&lt;/code&gt; release. Apple Silicon apps are required to be signed and notarised with an Apple developer account. So it is necessary to manually remove the quarantine flag:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;xattr -c "/Applications/Popcorn-Time.app/"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Linux - Debian/Ubuntu based distros:&lt;/h3&gt; 
&lt;p&gt;Download and install:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Latest release&lt;/strong&gt;: check &lt;a href="https://popcorn-time.site"&gt;popcorn-time.site&lt;/a&gt; or the repo's &lt;a href="https://github.com/popcorn-official/popcorn-desktop/releases"&gt;releases page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Or &lt;strong&gt;latest dev build (for testers)&lt;/strong&gt;: check the repo's &lt;a href="https://github.com/popcorn-official/popcorn-desktop/actions"&gt;actions page&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Via .deb package:&lt;/p&gt; 
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Firstly, be aware&lt;/strong&gt; in some cases, missings dependencies packages (libatomic1, libgconf-2-4, libcanberra-gtk-module) were reported to be required for the app to works.&lt;br /&gt; &lt;strong&gt;If the app don't start for you too&lt;/strong&gt;, in this case, &lt;strong&gt;try &lt;code&gt;sudo apt update &amp;amp;&amp;amp; sudo apt install libatomic1 libgconf-2-4 libcanberra-gtk-module&lt;/code&gt;&lt;/strong&gt; to be sure your system have the required dependencies.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;Via archive and command line (tested on ubuntu 18.04 and 20.04):&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download Popcorn Time archive from the github repo for the &lt;strong&gt;latest release&lt;/strong&gt; : &lt;code&gt;wget -c https://github.com/popcorn-official/popcorn-desktop/releases/download/v0.5.1/Popcorn-Time-0.5.1-linux64.zip&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Create popcorn-time folder in /opt/:&lt;br /&gt; &lt;code&gt;sudo mkdir /opt/popcorn-time&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Install unzip &amp;amp;&amp;amp; dependencies (they should not be always required but some users needed them to make Popcorn Time working):&lt;br /&gt; &lt;code&gt;sudo apt update &amp;amp;&amp;amp; sudo apt install unzip libcanberra-gtk-module libgconf-2-4 libatomic1&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Extract the zip in /opt/popcorn-time:&lt;br /&gt; &lt;code&gt;sudo unzip Popcorn-Time-0.5.1-linux64.zip -d /opt/popcorn-time&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Create symlink of Popcorn-Time in /usr/bin:&lt;br /&gt; &lt;code&gt;sudo ln -sf /opt/popcorn-time/Popcorn-Time /usr/bin/popcorn-time&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Create .desktop file (so the launcher):&lt;br /&gt; &lt;code&gt;sudo nano /usr/share/applications/popcorntime.desktop&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;and copy paste the following text in the editor and save&lt;/li&gt; 
&lt;/ol&gt; 
&lt;pre&gt;&lt;code class="language-desktop"&gt;[Desktop Entry]
Version = 1.0
Type = Application
Terminal = false
Name = Popcorn Time
Exec = /usr/bin/popcorn-time
Icon = /opt/popcorn-time/src/app/images/icon.png
Categories = Application;
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Getting Started&lt;/h2&gt; 
&lt;p&gt;If you're comfortable getting up and running from a &lt;code&gt;git clone&lt;/code&gt;, this method is for you.&lt;/p&gt; 
&lt;p&gt;The &lt;a href="https://github.com/popcorn-official/popcorn-desktop/tree/development"&gt;development&lt;/a&gt; branch contains the latest changes.&lt;br /&gt; The &lt;a href="https://github.com/popcorn-official/popcorn-desktop/tree/master"&gt;master&lt;/a&gt; branch contains the latest release.&lt;/p&gt; 
&lt;h4&gt;Quickstart:&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;yarn start&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;If you encounter trouble with the above method, you can try:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;yarn config set yarn-offline-mirror ./node_modules/&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn install --ignore-engines&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn build&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn start&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;Optionally, you may simply run &lt;code&gt;./make_popcorn.sh&lt;/code&gt; if you are on a linux or mac based operating system.&lt;/p&gt; 
&lt;p&gt;Full instructions &amp;amp; troubleshooting tips can be found in the &lt;a href="https://raw.githubusercontent.com/popcorn-official/popcorn-desktop/development/docs/Contributing.md#contributing-to-popcorn-time"&gt;Contributing Guide&lt;/a&gt;.&lt;/p&gt; 
&lt;h4&gt;Building redistributable packages/installers:&lt;/h4&gt; 
&lt;ol&gt; 
 &lt;li&gt;&lt;code&gt;yarn config set yarn-offline-mirror ./node_modules/&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn install --ignore-engines&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;yarn dist --platforms=&amp;lt;platform&amp;gt;&lt;/code&gt;&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;code&gt;&amp;lt;platform&amp;gt;&lt;/code&gt; can be one or more of the folowing values (separated by a comma &lt;code&gt;,&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;win64&lt;/code&gt;, &lt;code&gt;win32&lt;/code&gt;, &lt;code&gt;linux64&lt;/code&gt;, &lt;code&gt;linux32&lt;/code&gt;, &lt;code&gt;osx64&lt;/code&gt;, &lt;code&gt;all&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Redistributable packages are saved into &lt;code&gt;build/&lt;/code&gt; subfolder.&lt;/p&gt; 
&lt;h2&gt;Getting Involved&lt;/h2&gt; 
&lt;p&gt;Want to report a bug, request a feature, contribute to or translate Popcorn Time?&lt;br /&gt; Check out our in-depth guide to &lt;a href="https://raw.githubusercontent.com/popcorn-official/popcorn-desktop/development/docs/Contributing.md#contributing-to-popcorn-time"&gt;Contributing to Popcorn Time&lt;/a&gt;. We need all the help we can get!&lt;br /&gt; You can also join our &lt;a href="https://raw.githubusercontent.com/popcorn-official/popcorn-desktop/development/README.md#community"&gt;community&lt;/a&gt; to keep up-to-date and meet other developers.&lt;/p&gt; 
&lt;p&gt;&lt;a name="community"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;p&gt;Keep track of Popcorn Time development and community activity.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Read and contribute to the official &lt;a href="https://github.com/popcorn-official/popcorn-desktop/wiki/"&gt;Popcorn Time Wiki&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Join in discussions on &lt;a href="https://www.reddit.com/r/PopcornTimeApp"&gt;r/PopCornTimeApp&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;p&gt;&lt;img src="https://cloud.githubusercontent.com/assets/8317250/10714437/b1e1dc8c-7b32-11e5-9c25-d9fbd5b2f3bd.png" alt="Popcorn Time" /&gt;&lt;/p&gt; 
&lt;h2&gt;Versioning&lt;/h2&gt; 
&lt;p&gt;For transparency and insight into our release cycle, and for striving to maintain backward compatibility, Popcorn Time will be maintained according to the &lt;a href="http://semver.org/"&gt;Semantic Versioning&lt;/a&gt; guidelines as much as possible.&lt;/p&gt; 
&lt;p&gt;Releases will be numbered with the following format:&lt;/p&gt; 
&lt;p&gt;&lt;code&gt;&amp;lt;major&amp;gt;.&amp;lt;minor&amp;gt;.&amp;lt;patch&amp;gt;-&amp;lt;build&amp;gt;&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Constructed with the following guidelines:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;A new &lt;em&gt;major&lt;/em&gt; release indicates a large change where backward compatibility is broken.&lt;/li&gt; 
 &lt;li&gt;A new &lt;em&gt;minor&lt;/em&gt; release indicates a normal change that maintains backward compatibility.&lt;/li&gt; 
 &lt;li&gt;A new &lt;em&gt;patch&lt;/em&gt; release indicates a bugfix or small change which does not affect compatibility.&lt;/li&gt; 
 &lt;li&gt;A new &lt;em&gt;build&lt;/em&gt; release indicates this is a pre-release of the version.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;hr /&gt; 
&lt;p&gt;If you distribute a copy or make a fork of the project, you have to credit this project as the source.&lt;/p&gt; 
&lt;p&gt;This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.&lt;/p&gt; 
&lt;p&gt;This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.&lt;/p&gt; 
&lt;p&gt;You should have received a copy of the GNU General Public License along with this program. If not, see &lt;a href="http://www.gnu.org/licenses/"&gt;http://www.gnu.org/licenses/&lt;/a&gt;.&lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Copyright © 2025 Popcorn Time Project - Released under the &lt;a href="https://raw.githubusercontent.com/popcorn-official/popcorn-desktop/development/LICENSE.txt"&gt;GPL v3 license&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>sub-store-org/Sub-Store</title>
      <link>https://github.com/sub-store-org/Sub-Store</link>
      <description>&lt;p&gt;Advanced Subscription Manager for QX, Loon, Surge, Stash, Egern and Shadowrocket!&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;br /&gt; 
 &lt;img width="200" src="https://raw.githubusercontent.com/cc63/ICON/main/Sub-Store.png" alt="Sub-Store" /&gt; 
 &lt;br /&gt; 
 &lt;br /&gt; 
 &lt;h2 align="center"&gt;Sub-Store&lt;/h2&gt;
 &lt;h2&gt; &lt;/h2&gt;
&lt;/div&gt; 
&lt;p align="center" color="#6a737d"&gt; Advanced Subscription Manager for QX, Loon, Surge, Stash, Egern and Shadowrocket. &lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/sub-store-org/Sub-Store/actions/workflows/main.yml"&gt;&lt;img src="https://github.com/sub-store-org/Sub-Store/actions/workflows/main.yml/badge.svg?sanitize=true" alt="Build" /&gt;&lt;/a&gt; &lt;img src="https://img.shields.io/github/license/sub-store-org/Sub-Store" alt="GitHub" /&gt; &lt;img src="https://img.shields.io/github/issues/sub-store-org/Sub-Store" alt="GitHub issues" /&gt; &lt;img src="https://img.shields.io/github/issues-pr-closed-raw/Peng-Ym/Sub-Store" alt="GitHub closed pull requests" /&gt; &lt;img src="https://img.shields.io/tokei/lines/github/sub-store-org/Sub-Store" alt="Lines of code" /&gt; &lt;img src="https://img.shields.io/github/languages/code-size/sub-store-org/Sub-Store" alt="Size" /&gt; &lt;a href="https://trendshift.io/repositories/4572" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/4572" alt="sub-store-org%2FSub-Store | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;a href="https://www.buymeacoffee.com/PengYM"&gt;&lt;img src="https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png" alt="&amp;quot;Buy Me A Coffee&amp;quot;" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Core functionalities:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Conversion among various formats.&lt;/li&gt; 
 &lt;li&gt;Subscription formatting.&lt;/li&gt; 
 &lt;li&gt;Collect multiple subscriptions in one URL.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;The following descriptions of features may not be updated in real-time. Please refer to the actual available features for accurate information.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;1. Subscription Conversion&lt;/h2&gt; 
&lt;h3&gt;Supported Input Formats&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;⚠️ Do not use &lt;code&gt;Shadowrocket&lt;/code&gt; or &lt;code&gt;NekoBox&lt;/code&gt; to export URI and then import it as input. The URIs exported in this way may not be standard URIs. However, we have already supported some very common non-standard URIs (such as VMess, VLESS).&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;Proxy URI Scheme(&lt;code&gt;socks5&lt;/code&gt;, &lt;code&gt;socks5+tls&lt;/code&gt;, &lt;code&gt;http&lt;/code&gt;, &lt;code&gt;https&lt;/code&gt;(it's ok))&lt;/p&gt; &lt;p&gt;example: &lt;code&gt;socks5+tls://user:pass@ip:port#name&lt;/code&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;URI(AnyTLS, SOCKS, SS, SSR, VMess, VLESS, Trojan, Hysteria, Hysteria 2, TUIC v5, WireGuard)&lt;/p&gt; 
  &lt;blockquote&gt; 
   &lt;p&gt;Please note, HTTP(s) does not have a standard URI format, so it is not supported. Please use other formats.&lt;/p&gt; 
  &lt;/blockquote&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;Clash Proxies YAML&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;Clash Proxy JSON(single line)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;QX (SS, SSR, VMess, Trojan, HTTP, SOCKS5, VLESS)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;Loon (SS, SSR, VMess, Trojan, HTTP, SOCKS5, SOCKS5-TLS, WireGuard, VLESS, Hysteria 2)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;Surge (Direct, SS, VMess, Trojan, HTTP, SOCKS5, SOCKS5-TLS, TUIC, Snell, Hysteria 2, SSH(Password authentication only), External Proxy Program(only for macOS), WireGuard(Surge to Surge))&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;Surfboard (SS, VMess, Trojan, HTTP, SOCKS5, SOCKS5-TLS, WireGuard(Surfboard to Surfboard))&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;Clash.Meta (Direct, SS, SSR, VMess, Trojan, HTTP, SOCKS5, Snell, VLESS, WireGuard, Hysteria, Hysteria 2, TUIC, SSH, mieru, AnyTLS)&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;p&gt;Stash (SS, SSR, VMess, Trojan, HTTP, SOCKS5, Snell, VLESS, WireGuard, Hysteria, TUIC, Juicity, SSH)&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Deprecated(The frontend doesn't show it, but the backend still supports it, with the query parameter &lt;code&gt;target=Clash&lt;/code&gt;):&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Clash (SS, SSR, VMess, Trojan, HTTP, SOCKS5, Snell, VLESS, WireGuard)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Supported Target Platforms&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Plain JSON&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Stash&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Clash.Meta(mihomo)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Surfboard&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Surge&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; SurgeMac(Use mihomo to support protocols that are not supported by Surge itself)&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Loon&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Egern&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Shadowrocket&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; QX&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; sing-box&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; V2Ray&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; V2Ray URI&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Deprecated:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; Clash&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;2. Subscription Formatting&lt;/h2&gt; 
&lt;h3&gt;Filtering&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Regex filter&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Discard regex filter&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Region filter&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Type filter&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Useless proxies filter&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Script filter&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Proxy Operations&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Set property operator&lt;/strong&gt;: set some proxy properties such as &lt;code&gt;udp&lt;/code&gt;,&lt;code&gt;tfo&lt;/code&gt;, &lt;code&gt;skip-cert-verify&lt;/code&gt; etc.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Flag operator&lt;/strong&gt;: add flags or remove flags for proxies.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Sort operator&lt;/strong&gt;: sort proxies by name.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Regex sort operator&lt;/strong&gt;: sort proxies by keywords (fallback to normal sort).&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Regex rename operator&lt;/strong&gt;: replace by regex in proxy names.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Regex delete operator&lt;/strong&gt;: delete by regex in proxy names.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Script operator&lt;/strong&gt;: modify proxy by script.&lt;/li&gt; 
 &lt;li&gt;&lt;input type="checkbox" checked disabled /&gt; &lt;strong&gt;Resolve Domain Operator&lt;/strong&gt;: resolve the domain of nodes to an IP address.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Development&lt;/h3&gt; 
&lt;p&gt;Install &lt;code&gt;pnpm&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;Go to &lt;code&gt;backend&lt;/code&gt; directories, install node dependencies:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;pnpm i
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;SUB_STORE_BACKEND_API_PORT=3000 pnpm run --parallel "/^dev:.*/"
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Build&lt;/h3&gt; 
&lt;pre&gt;&lt;code&gt;pnpm bundle:esbuild
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;LICENSE&lt;/h2&gt; 
&lt;p&gt;This project is under the GPL V3 LICENSE.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2FPeng-YM%2FSub-Store?ref=badge_large"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2FPeng-YM%2FSub-Store.svg?type=large" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#sub-store-org/sub-store&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=sub-store-org/sub-store&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Special thanks to @KOP-XIAO for his awesome resource-parser. Please give a &lt;a href="https://github.com/KOP-XIAO/QuantumultX"&gt;star&lt;/a&gt; for his great work!&lt;/li&gt; 
 &lt;li&gt;Special thanks to @Orz-3 and @58xinian for their awesome icons.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Sponsors&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://yxvm.com"&gt;&lt;img src="https://raw.githubusercontent.com/sub-store-org/Sub-Store/master/support.nodeseek.com_page_promotion_id=8.png" alt="image" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/NodeSeekDev/NodeSupport"&gt;NodeSupport&lt;/a&gt; sponsored this project.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>projectdiscovery/nuclei-templates</title>
      <link>https://github.com/projectdiscovery/nuclei-templates</link>
      <description>&lt;p&gt;Community curated list of templates for the nuclei engine to find security vulnerabilities.&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; Nuclei Templates &lt;/h1&gt; 
&lt;h4 align="center"&gt;Community curated list of templates for the nuclei engine to find security vulnerabilities in applications.&lt;/h4&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/projectdiscovery/nuclei-templates/issues"&gt;&lt;img src="https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat" /&gt;&lt;/a&gt; &lt;a href="https://github.com/projectdiscovery/nuclei-templates/releases"&gt;&lt;img src="https://img.shields.io/github/release/projectdiscovery/nuclei-templates" /&gt;&lt;/a&gt; &lt;a href="https://twitter.com/pdnuclei"&gt;&lt;img src="https://img.shields.io/twitter/follow/pdnuclei.svg?logo=twitter" /&gt;&lt;/a&gt; &lt;a href="https://discord.gg/projectdiscovery"&gt;&lt;img src="https://img.shields.io/discord/695645237418131507.svg?logo=discord" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://nuclei.projectdiscovery.io/templating-guide/"&gt;Documentation&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/projectdiscovery/nuclei-templates/main/#-contributions"&gt;Contributions&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/projectdiscovery/nuclei-templates/main/#-discussion"&gt;Discussion&lt;/a&gt; • &lt;a href="https://raw.githubusercontent.com/projectdiscovery/nuclei-templates/main/#-community"&gt;Community&lt;/a&gt; • &lt;a href="https://nuclei.projectdiscovery.io/faq/templates/"&gt;FAQs&lt;/a&gt; • &lt;a href="https://discord.gg/projectdiscovery"&gt;Join Discord&lt;/a&gt; &lt;/p&gt; 
&lt;hr /&gt; 
&lt;p&gt;Templates are the core of the &lt;a href="https://github.com/projectdiscovery/nuclei"&gt;nuclei scanner&lt;/a&gt; which powers the actual scanning engine. This repository stores and houses various templates for the scanner provided by our team, as well as contributed by the community. We hope that you also contribute by sending templates via &lt;strong&gt;pull requests&lt;/strong&gt; or &lt;a href="https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&amp;amp;labels=&amp;amp;template=submit-template.md&amp;amp;title=%5Bnuclei-template%5D+"&gt;Github issues&lt;/a&gt; to grow the list.&lt;/p&gt; 
&lt;h2&gt;Nuclei Templates overview&lt;/h2&gt; 
&lt;p&gt;An overview of the nuclei template project, including statistics on unique tags, author, directory, severity, and type of templates. The table below contains the top ten statistics for each matrix; an expanded version of this is &lt;a href="https://raw.githubusercontent.com/projectdiscovery/nuclei-templates/main/TEMPLATES-STATS.md"&gt;available here&lt;/a&gt;, and also available in &lt;a href="https://raw.githubusercontent.com/projectdiscovery/nuclei-templates/main/TEMPLATES-STATS.json"&gt;JSON&lt;/a&gt; format for integration.&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td&gt; &lt;h2&gt;Nuclei Templates Top 10 statistics&lt;/h2&gt; 
    &lt;table&gt; 
     &lt;thead&gt; 
      &lt;tr&gt; 
       &lt;th&gt;TAG&lt;/th&gt; 
       &lt;th&gt;COUNT&lt;/th&gt; 
       &lt;th&gt;AUTHOR&lt;/th&gt; 
       &lt;th&gt;COUNT&lt;/th&gt; 
       &lt;th&gt;DIRECTORY&lt;/th&gt; 
       &lt;th&gt;COUNT&lt;/th&gt; 
       &lt;th&gt;SEVERITY&lt;/th&gt; 
       &lt;th&gt;COUNT&lt;/th&gt; 
       &lt;th&gt;TYPE&lt;/th&gt; 
       &lt;th&gt;COUNT&lt;/th&gt; 
      &lt;/tr&gt; 
     &lt;/thead&gt; 
     &lt;tbody&gt; 
      &lt;tr&gt; 
       &lt;td&gt;cve&lt;/td&gt; 
       &lt;td&gt;3288&lt;/td&gt; 
       &lt;td&gt;dhiyaneshdk&lt;/td&gt; 
       &lt;td&gt;1882&lt;/td&gt; 
       &lt;td&gt;http&lt;/td&gt; 
       &lt;td&gt;8967&lt;/td&gt; 
       &lt;td&gt;info&lt;/td&gt; 
       &lt;td&gt;4190&lt;/td&gt; 
       &lt;td&gt;file&lt;/td&gt; 
       &lt;td&gt;435&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;panel&lt;/td&gt; 
       &lt;td&gt;1342&lt;/td&gt; 
       &lt;td&gt;daffainfo&lt;/td&gt; 
       &lt;td&gt;868&lt;/td&gt; 
       &lt;td&gt;cloud&lt;/td&gt; 
       &lt;td&gt;657&lt;/td&gt; 
       &lt;td&gt;high&lt;/td&gt; 
       &lt;td&gt;2446&lt;/td&gt; 
       &lt;td&gt;dns&lt;/td&gt; 
       &lt;td&gt;26&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;xss&lt;/td&gt; 
       &lt;td&gt;1257&lt;/td&gt; 
       &lt;td&gt;princechaddha&lt;/td&gt; 
       &lt;td&gt;854&lt;/td&gt; 
       &lt;td&gt;file&lt;/td&gt; 
       &lt;td&gt;435&lt;/td&gt; 
       &lt;td&gt;medium&lt;/td&gt; 
       &lt;td&gt;2379&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;wordpress&lt;/td&gt; 
       &lt;td&gt;1181&lt;/td&gt; 
       &lt;td&gt;dwisiswant0&lt;/td&gt; 
       &lt;td&gt;806&lt;/td&gt; 
       &lt;td&gt;dast&lt;/td&gt; 
       &lt;td&gt;255&lt;/td&gt; 
       &lt;td&gt;critical&lt;/td&gt; 
       &lt;td&gt;1425&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;exposure&lt;/td&gt; 
       &lt;td&gt;1107&lt;/td&gt; 
       &lt;td&gt;ritikchaddha&lt;/td&gt; 
       &lt;td&gt;649&lt;/td&gt; 
       &lt;td&gt;workflows&lt;/td&gt; 
       &lt;td&gt;202&lt;/td&gt; 
       &lt;td&gt;low&lt;/td&gt; 
       &lt;td&gt;318&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;wp-plugin&lt;/td&gt; 
       &lt;td&gt;1032&lt;/td&gt; 
       &lt;td&gt;pussycat0x&lt;/td&gt; 
       &lt;td&gt;532&lt;/td&gt; 
       &lt;td&gt;code&lt;/td&gt; 
       &lt;td&gt;198&lt;/td&gt; 
       &lt;td&gt;unknown&lt;/td&gt; 
       &lt;td&gt;56&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;osint&lt;/td&gt; 
       &lt;td&gt;841&lt;/td&gt; 
       &lt;td&gt;pikpikcu&lt;/td&gt; 
       &lt;td&gt;352&lt;/td&gt; 
       &lt;td&gt;network&lt;/td&gt; 
       &lt;td&gt;145&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;tech&lt;/td&gt; 
       &lt;td&gt;803&lt;/td&gt; 
       &lt;td&gt;pdteam&lt;/td&gt; 
       &lt;td&gt;310&lt;/td&gt; 
       &lt;td&gt;javascript&lt;/td&gt; 
       &lt;td&gt;71&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;rce&lt;/td&gt; 
       &lt;td&gt;786&lt;/td&gt; 
       &lt;td&gt;pdresearch&lt;/td&gt; 
       &lt;td&gt;269&lt;/td&gt; 
       &lt;td&gt;ssl&lt;/td&gt; 
       &lt;td&gt;38&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
      &lt;/tr&gt; 
      &lt;tr&gt; 
       &lt;td&gt;lfi&lt;/td&gt; 
       &lt;td&gt;777&lt;/td&gt; 
       &lt;td&gt;iamnoooob&lt;/td&gt; 
       &lt;td&gt;257&lt;/td&gt; 
       &lt;td&gt;dns&lt;/td&gt; 
       &lt;td&gt;23&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
       &lt;td&gt;&lt;/td&gt; 
      &lt;/tr&gt; 
     &lt;/tbody&gt; 
    &lt;/table&gt; &lt;p&gt;&lt;strong&gt;848 directories, 11344 files&lt;/strong&gt;.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;📖 Documentation&lt;/h2&gt; 
&lt;p&gt;Please navigate to &lt;a href="https://nuclei.projectdiscovery.io"&gt;https://nuclei.projectdiscovery.io&lt;/a&gt; for detailed documentation to &lt;strong&gt;build&lt;/strong&gt; new or your own &lt;strong&gt;custom&lt;/strong&gt; templates. We have also added a set of templates to help you understand how things work.&lt;/p&gt; 
&lt;h2&gt;💪 Contributions&lt;/h2&gt; 
&lt;p&gt;Nuclei-templates is powered by major contributions from the community. &lt;a href="https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&amp;amp;labels=&amp;amp;template=submit-template.md&amp;amp;title=%5Bnuclei-template%5D+"&gt;Template contributions &lt;/a&gt;, &lt;a href="https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&amp;amp;labels=&amp;amp;template=feature_request.md&amp;amp;title=%5BFeature%5D+"&gt;Feature Requests&lt;/a&gt; and &lt;a href="https://github.com/projectdiscovery/nuclei-templates/issues/new?assignees=&amp;amp;labels=&amp;amp;template=bug_report.md&amp;amp;title=%5BBug%5D+"&gt;Bug Reports&lt;/a&gt; are more than welcome.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://repobeats.axiom.co/api/embed/55ee65543bb9a0f9c797626c4e66d472a517d17c.svg?sanitize=true" alt="Alt" title="Repobeats analytics image" /&gt;&lt;/p&gt; 
&lt;h2&gt;💬 Discussion&lt;/h2&gt; 
&lt;p&gt;Have questions / doubts / ideas to discuss? Feel free to open a discussion on &lt;a href="https://github.com/projectdiscovery/nuclei-templates/discussions"&gt;Github discussions&lt;/a&gt; board.&lt;/p&gt; 
&lt;h2&gt;👨‍💻 Community&lt;/h2&gt; 
&lt;p&gt;You are welcome to join the active &lt;a href="https://discord.gg/projectdiscovery"&gt;Discord Community&lt;/a&gt; to discuss directly with project maintainers and share things with others around security and automation. Additionally, you may follow us on &lt;a href="https://twitter.com/pdnuclei"&gt;Twitter&lt;/a&gt; to be updated on all the things about Nuclei.&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/projectdiscovery/nuclei-templates/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=projectdiscovery/nuclei-templates&amp;amp;max=300" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p&gt;Thanks again for your contribution and keeping this community vibrant. &lt;span&gt;❤️&lt;/span&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>eyaltoledano/claude-task-master</title>
      <link>https://github.com/eyaltoledano/claude-task-master</link>
      <description>&lt;p&gt;An AI-powered task-management system you can drop into Cursor, Lovable, Windsurf, Roo, and others.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;a name="readme-top"&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://trendshift.io/repositories/13971" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/13971" alt="eyaltoledano%2Fclaude-task-master | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;p align="center"&gt; &lt;a href="https://task-master.dev"&gt;&lt;img src="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/images/logo.png?raw=true" alt="Taskmaster logo" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;b&gt;Taskmaster&lt;/b&gt;: A task management system for AI-driven development, designed to work seamlessly with any AI chat. &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://discord.gg/taskmasterai" target="_blank"&gt;&lt;img src="https://dcbadge.limes.pink/api/server/https://discord.gg/taskmasterai?style=flat" alt="Discord" /&gt;&lt;/a&gt; | &lt;a href="https://docs.task-master.dev" target="_blank"&gt;Docs&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/eyaltoledano/claude-task-master/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/eyaltoledano/claude-task-master/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="CI" /&gt;&lt;/a&gt; &lt;a href="https://github.com/eyaltoledano/claude-task-master/stargazers"&gt;&lt;img src="https://img.shields.io/github/stars/eyaltoledano/claude-task-master?style=social" alt="GitHub stars" /&gt;&lt;/a&gt; &lt;a href="https://badge.fury.io/js/task-master-ai"&gt;&lt;img src="https://badge.fury.io/js/task-master-ai.svg?sanitize=true" alt="npm version" /&gt;&lt;/a&gt; &lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/LICENSE"&gt;&lt;img src="https://img.shields.io/badge/license-MIT%20with%20Commons%20Clause-blue.svg?sanitize=true" alt="License" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.npmjs.com/package/task-master-ai"&gt;&lt;img src="https://img.shields.io/npm/d18m/task-master-ai?style=flat" alt="NPM Downloads" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/task-master-ai"&gt;&lt;img src="https://img.shields.io/npm/dm/task-master-ai?style=flat" alt="NPM Downloads" /&gt;&lt;/a&gt; &lt;a href="https://www.npmjs.com/package/task-master-ai"&gt;&lt;img src="https://img.shields.io/npm/dw/task-master-ai?style=flat" alt="NPM Downloads" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;h2&gt;By &lt;a href="https://x.com/eyaltoledano"&gt;@eyaltoledano&lt;/a&gt; &amp;amp; &lt;a href="https://x.com/RalphEcom"&gt;@RalphEcom&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://x.com/eyaltoledano"&gt;&lt;img src="https://img.shields.io/twitter/follow/eyaltoledano" alt="Twitter Follow" /&gt;&lt;/a&gt; &lt;a href="https://x.com/RalphEcom"&gt;&lt;img src="https://img.shields.io/twitter/follow/RalphEcom" alt="Twitter Follow" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A task management system for AI-driven development with Claude, designed to work seamlessly with Cursor AI.&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;📚 &lt;strong&gt;&lt;a href="https://docs.task-master.dev"&gt;View Full Documentation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;For detailed guides, API references, and comprehensive examples, visit our documentation site.&lt;/p&gt; 
&lt;h3&gt;Quick Reference&lt;/h3&gt; 
&lt;p&gt;The following documentation is also available in the &lt;code&gt;docs&lt;/code&gt; directory:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/docs/configuration.md"&gt;Configuration Guide&lt;/a&gt; - Set up environment variables and customize Task Master&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/docs/tutorial.md"&gt;Tutorial&lt;/a&gt; - Step-by-step guide to getting started with Task Master&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/docs/command-reference.md"&gt;Command Reference&lt;/a&gt; - Complete list of all available commands&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/docs/task-structure.md"&gt;Task Structure&lt;/a&gt; - Understanding the task format and features&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/docs/examples.md"&gt;Example Interactions&lt;/a&gt; - Common Cursor AI interaction examples&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/docs/migration-guide.md"&gt;Migration Guide&lt;/a&gt; - Guide to migrating to the new project structure&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Quick Install for Cursor 1.0+ (One-Click)&lt;/h4&gt; 
&lt;p&gt;&lt;a href="https://cursor.com/en/install-mcp?name=task-master-ai&amp;amp;config=eyJjb21tYW5kIjoibnB4IC15IC0tcGFja2FnZT10YXNrLW1hc3Rlci1haSB0YXNrLW1hc3Rlci1haSIsImVudiI6eyJBTlRIUk9QSUNfQVBJX0tFWSI6IllPVVJfQU5USFJPUElDX0FQSV9LRVlfSEVSRSIsIlBFUlBMRVhJVFlfQVBJX0tFWSI6IllPVVJfUEVSUExFWElUWV9BUElfS0VZX0hFUkUiLCJPUEVOQUlfQVBJX0tFWSI6IllPVVJfT1BFTkFJX0tFWV9IRVJFIiwiR09PR0xFX0FQSV9LRVkiOiJZT1VSX0dPT0dMRV9LRVlfSEVSRSIsIk1JU1RSQUxfQVBJX0tFWSI6IllPVVJfTUlTVFJBTF9LRVlfSEVSRSIsIkdST1FfQVBJX0tFWSI6IllPVVJfR1JPUV9LRVlfSEVSRSIsIk9QRU5ST1VURVJfQVBJX0tFWSI6IllPVVJfT1BFTlJPVVRFUl9LRVlfSEVSRSIsIlhBSV9BUElfS0VZIjoiWU9VUl9YQUlfS0VZX0hFUkUiLCJBWlVSRV9PUEVOQUlfQVBJX0tFWSI6IllPVVJfQVpVUkVfS0VZX0hFUkUiLCJPTExBTUFfQVBJX0tFWSI6IllPVVJfT0xMQU1BX0FQSV9LRVlfSEVSRSJ9fQ%3D%3D"&gt;&lt;img src="https://cursor.com/deeplink/mcp-install-dark.svg?sanitize=true" alt="Add task-master-ai MCP server to Cursor" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; After clicking the link, you'll still need to add your API keys to the configuration. The link installs the MCP server with placeholder keys that you'll need to replace with your actual API keys.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Requirements&lt;/h2&gt; 
&lt;p&gt;Taskmaster utilizes AI across several commands, and those require a separate API key. You can use a variety of models from different AI providers provided you add your API keys. For example, if you want to use Claude 3.7, you'll need an Anthropic API key.&lt;/p&gt; 
&lt;p&gt;You can define 3 types of models to be used: the main model, the research model, and the fallback model (in case either the main or research fail). Whatever model you use, its provider API key must be present in either mcp.json or .env.&lt;/p&gt; 
&lt;p&gt;At least one (1) of the following is required:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Anthropic API key (Claude API)&lt;/li&gt; 
 &lt;li&gt;OpenAI API key&lt;/li&gt; 
 &lt;li&gt;Google Gemini API key&lt;/li&gt; 
 &lt;li&gt;Perplexity API key (for research model)&lt;/li&gt; 
 &lt;li&gt;xAI API Key (for research or main model)&lt;/li&gt; 
 &lt;li&gt;OpenRouter API Key (for research or main model)&lt;/li&gt; 
 &lt;li&gt;Claude Code (no API key required - requires Claude Code CLI)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Using the research model is optional but highly recommended. You will need at least ONE API key (unless using Claude Code). Adding all API keys enables you to seamlessly switch between model providers at will.&lt;/p&gt; 
&lt;h2&gt;Quick Start&lt;/h2&gt; 
&lt;h3&gt;Option 1: MCP (Recommended)&lt;/h3&gt; 
&lt;p&gt;MCP (Model Control Protocol) lets you run Task Master directly from your editor.&lt;/p&gt; 
&lt;h4&gt;1. Add your MCP config at the following path depending on your editor&lt;/h4&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Editor&lt;/th&gt; 
   &lt;th&gt;Scope&lt;/th&gt; 
   &lt;th&gt;Linux/macOS Path&lt;/th&gt; 
   &lt;th&gt;Windows Path&lt;/th&gt; 
   &lt;th&gt;Key&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Cursor&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Global&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;~/.cursor/mcp.json&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;%USERPROFILE%\.cursor\mcp.json&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mcpServers&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;Project&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;lt;project_folder&amp;gt;/.cursor/mcp.json&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;lt;project_folder&amp;gt;\.cursor\mcp.json&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mcpServers&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Windsurf&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Global&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;~/.codeium/windsurf/mcp_config.json&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;%USERPROFILE%\.codeium\windsurf\mcp_config.json&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;mcpServers&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;VS Code&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Project&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;lt;project_folder&amp;gt;/.vscode/mcp.json&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;&amp;lt;project_folder&amp;gt;\.vscode\mcp.json&lt;/code&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;code&gt;servers&lt;/code&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h5&gt;Manual Configuration&lt;/h5&gt; 
&lt;h6&gt;Cursor &amp;amp; Windsurf (&lt;code&gt;mcpServers&lt;/code&gt;)&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "mcpServers": {
    "task-master-ai": {
      "command": "npx",
      "args": ["-y", "--package=task-master-ai", "task-master-ai"],
      "env": {
        "ANTHROPIC_API_KEY": "YOUR_ANTHROPIC_API_KEY_HERE",
        "PERPLEXITY_API_KEY": "YOUR_PERPLEXITY_API_KEY_HERE",
        "OPENAI_API_KEY": "YOUR_OPENAI_KEY_HERE",
        "GOOGLE_API_KEY": "YOUR_GOOGLE_KEY_HERE",
        "MISTRAL_API_KEY": "YOUR_MISTRAL_KEY_HERE",
        "GROQ_API_KEY": "YOUR_GROQ_KEY_HERE",
        "OPENROUTER_API_KEY": "YOUR_OPENROUTER_KEY_HERE",
        "XAI_API_KEY": "YOUR_XAI_KEY_HERE",
        "AZURE_OPENAI_API_KEY": "YOUR_AZURE_KEY_HERE",
        "OLLAMA_API_KEY": "YOUR_OLLAMA_API_KEY_HERE"
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🔑 Replace &lt;code&gt;YOUR_…_KEY_HERE&lt;/code&gt; with your real API keys. You can remove keys you don't use.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you see &lt;code&gt;0 tools enabled&lt;/code&gt; in the MCP settings, try removing the &lt;code&gt;--package=task-master-ai&lt;/code&gt; flag from &lt;code&gt;args&lt;/code&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h6&gt;VS Code (&lt;code&gt;servers&lt;/code&gt; + &lt;code&gt;type&lt;/code&gt;)&lt;/h6&gt; 
&lt;pre&gt;&lt;code class="language-json"&gt;{
  "servers": {
    "task-master-ai": {
      "command": "npx",
      "args": ["-y", "--package=task-master-ai", "task-master-ai"],
      "env": {
        "ANTHROPIC_API_KEY": "YOUR_ANTHROPIC_API_KEY_HERE",
        "PERPLEXITY_API_KEY": "YOUR_PERPLEXITY_API_KEY_HERE",
        "OPENAI_API_KEY": "YOUR_OPENAI_KEY_HERE",
        "GOOGLE_API_KEY": "YOUR_GOOGLE_KEY_HERE",
        "MISTRAL_API_KEY": "YOUR_MISTRAL_KEY_HERE",
        "GROQ_API_KEY": "YOUR_GROQ_KEY_HERE",
        "OPENROUTER_API_KEY": "YOUR_OPENROUTER_KEY_HERE",
        "XAI_API_KEY": "YOUR_XAI_KEY_HERE",
        "AZURE_OPENAI_API_KEY": "YOUR_AZURE_KEY_HERE",
        "OLLAMA_API_KEY": "YOUR_OLLAMA_API_KEY_HERE"
      },
      "type": "stdio"
    }
  }
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;🔑 Replace &lt;code&gt;YOUR_…_KEY_HERE&lt;/code&gt; with your real API keys. You can remove keys you don't use.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;2. (Cursor-only) Enable Taskmaster MCP&lt;/h4&gt; 
&lt;p&gt;Open Cursor Settings (Ctrl+Shift+J) ➡ Click on MCP tab on the left ➡ Enable task-master-ai with the toggle&lt;/p&gt; 
&lt;h4&gt;3. (Optional) Configure the models you want to use&lt;/h4&gt; 
&lt;p&gt;In your editor's AI chat pane, say:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-txt"&gt;Change the main, research and fallback models to &amp;lt;model_name&amp;gt;, &amp;lt;model_name&amp;gt; and &amp;lt;model_name&amp;gt; respectively.
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For example, to use Claude Code (no API key required):&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-txt"&gt;Change the main model to claude-code/sonnet
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/docs/models.md"&gt;Table of available models&lt;/a&gt; | &lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/docs/examples/claude-code-usage.md"&gt;Claude Code setup&lt;/a&gt;&lt;/p&gt; 
&lt;h4&gt;4. Initialize Task Master&lt;/h4&gt; 
&lt;p&gt;In your editor's AI chat pane, say:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-txt"&gt;Initialize taskmaster-ai in my project
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;5. Make sure you have a PRD (Recommended)&lt;/h4&gt; 
&lt;p&gt;For &lt;strong&gt;new projects&lt;/strong&gt;: Create your PRD at &lt;code&gt;.taskmaster/docs/prd.txt&lt;/code&gt;&lt;br /&gt; For &lt;strong&gt;existing projects&lt;/strong&gt;: You can use &lt;code&gt;scripts/prd.txt&lt;/code&gt; or migrate with &lt;code&gt;task-master migrate&lt;/code&gt;&lt;/p&gt; 
&lt;p&gt;An example PRD template is available after initialization in &lt;code&gt;.taskmaster/templates/example_prd.txt&lt;/code&gt;.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!NOTE] While a PRD is recommended for complex projects, you can always create individual tasks by asking "Can you help me implement [description of what you want to do]?" in chat.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;strong&gt;Always start with a detailed PRD.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;The more detailed your PRD, the better the generated tasks will be.&lt;/p&gt; 
&lt;h4&gt;6. Common Commands&lt;/h4&gt; 
&lt;p&gt;Use your AI assistant to:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Parse requirements: &lt;code&gt;Can you parse my PRD at scripts/prd.txt?&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Plan next step: &lt;code&gt;What's the next task I should work on?&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Implement a task: &lt;code&gt;Can you help me implement task 3?&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;View multiple tasks: &lt;code&gt;Can you show me tasks 1, 3, and 5?&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;Expand a task: &lt;code&gt;Can you help me expand task 4?&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Research fresh information&lt;/strong&gt;: &lt;code&gt;Research the latest best practices for implementing JWT authentication with Node.js&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Research with context&lt;/strong&gt;: &lt;code&gt;Research React Query v5 migration strategies for our current API implementation in src/api.js&lt;/code&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/docs/examples.md"&gt;More examples on how to use Task Master in chat&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;Option 2: Using Command Line&lt;/h3&gt; 
&lt;h4&gt;Installation&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Install globally
npm install -g task-master-ai

# OR install locally within your project
npm install task-master-ai
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Initialize a new project&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# If installed globally
task-master init

# If installed locally
npx task-master init

# Initialize project with specific rules
task-master init --rules cursor,windsurf,vscode
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;This will prompt you for project details and set up a new project with the necessary files and structure.&lt;/p&gt; 
&lt;h4&gt;Common Commands&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Initialize a new project
task-master init

# Parse a PRD and generate tasks
task-master parse-prd your-prd.txt

# List all tasks
task-master list

# Show the next task to work on
task-master next

# Show specific task(s) - supports comma-separated IDs
task-master show 1,3,5

# Research fresh information with project context
task-master research "What are the latest best practices for JWT authentication?"

# Move tasks between tags (cross-tag movement)
task-master move --from=5 --from-tag=backlog --to-tag=in-progress
task-master move --from=5,6,7 --from-tag=backlog --to-tag=done --with-dependencies
task-master move --from=5 --from-tag=backlog --to-tag=in-progress --ignore-dependencies

# Generate task files
task-master generate

# Add rules after initialization
task-master rules add windsurf,roo,vscode
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Claude Code Support&lt;/h2&gt; 
&lt;p&gt;Task Master now supports Claude models through the Claude Code CLI, which requires no API key:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Models&lt;/strong&gt;: &lt;code&gt;claude-code/opus&lt;/code&gt; and &lt;code&gt;claude-code/sonnet&lt;/code&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Requirements&lt;/strong&gt;: Claude Code CLI installed&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Benefits&lt;/strong&gt;: No API key needed, uses your local Claude instance&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/docs/examples/claude-code-usage.md"&gt;Learn more about Claude Code setup&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Troubleshooting&lt;/h2&gt; 
&lt;h3&gt;If &lt;code&gt;task-master init&lt;/code&gt; doesn't respond&lt;/h3&gt; 
&lt;p&gt;Try running it with Node directly:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;node node_modules/claude-task-master/scripts/init.js
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Or clone the repository and run:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/eyaltoledano/claude-task-master.git
cd claude-task-master
node scripts/init.js
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/eyaltoledano/claude-task-master/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=eyaltoledano/claude-task-master" alt="Task Master project contributors" /&gt; &lt;/a&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://www.star-history.com/#eyaltoledano/claude-task-master&amp;amp;Timeline"&gt;&lt;img src="https://api.star-history.com/svg?repos=eyaltoledano/claude-task-master&amp;amp;type=Timeline" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Licensing&lt;/h2&gt; 
&lt;p&gt;Task Master is licensed under the MIT License with Commons Clause. This means you can:&lt;/p&gt; 
&lt;p&gt;✅ &lt;strong&gt;Allowed&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Use Task Master for any purpose (personal, commercial, academic)&lt;/li&gt; 
 &lt;li&gt;Modify the code&lt;/li&gt; 
 &lt;li&gt;Distribute copies&lt;/li&gt; 
 &lt;li&gt;Create and sell products built using Task Master&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;❌ &lt;strong&gt;Not Allowed&lt;/strong&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Sell Task Master itself&lt;/li&gt; 
 &lt;li&gt;Offer Task Master as a hosted service&lt;/li&gt; 
 &lt;li&gt;Create competing products based on Task Master&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;See the &lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for the complete license text and &lt;a href="https://raw.githubusercontent.com/eyaltoledano/claude-task-master/main/docs/licensing.md"&gt;licensing details&lt;/a&gt; for more information.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>viarotel-org/escrcpy</title>
      <link>https://github.com/viarotel-org/escrcpy</link>
      <description>&lt;p&gt;📱 Display and control your Android device graphically with scrcpy.&lt;/p&gt;&lt;hr&gt;&lt;div style="display:flex;"&gt; 
 &lt;img src="https://cdn.jsdelivr.net/gh/viarotel-org/escrcpy@main/electron/resources/build/logo.png" alt="viarotel-escrcpy" width="108px" /&gt; 
&lt;/div&gt; 
&lt;h1&gt;Escrcpy&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://gitcode.com/viarotel-org/escrcpy"&gt;&lt;img src="https://gitcode.com/viarotel-org/escrcpy/star/badge.svg?sanitize=true" alt="GitCode" /&gt;&lt;/a&gt; &lt;a href="https://gitee.com/viarotel-org/escrcpy"&gt;&lt;img src="https://gitee.com/viarotel-org/escrcpy/badge/star.svg?theme=dark" alt="Gitee" /&gt;&lt;/a&gt; &lt;a href="https://github.com/viarotel-org/escrcpy"&gt;&lt;img src="https://img.shields.io/github/stars/viarotel-org/escrcpy?label=Github%20Stars" alt="GitHub" /&gt;&lt;/a&gt; &lt;a href="https://deepwiki.com/viarotel-org/escrcpy"&gt;&lt;img src="https://deepwiki.com/badge.svg?sanitize=true" alt="Ask DeepWiki" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;📱 Display and control your Android device graphically with scrcpy, powered by Electron. &lt;a href="https://github.com/viarotel-org/escrcpy/raw/main/README-CN.md"&gt;中文文档&lt;/a&gt;&lt;/p&gt; 
&lt;div style="display:flex;"&gt; 
 &lt;img src="https://raw.githubusercontent.com/viarotel-org/escrcpy/main/screenshots/zh-CN/overview.jpg" alt="viarotel-escrcpy" width="100%" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;🏃 Synchronization: Faster synchronization with Scrcpy thanks to web technology&lt;/li&gt; 
 &lt;li&gt;🤖 Automation: Auto-connect devices, auto-execute mirroring, custom scripts, scheduled tasks&lt;/li&gt; 
 &lt;li&gt;💡 Customization: Multi-device management, independent configurations, custom notes, config import/export&lt;/li&gt; 
 &lt;li&gt;📡 Wireless: Quick connection via QR code scanning&lt;/li&gt; 
 &lt;li&gt;🔗 Reverse Tethering: Gnirehtet reverse tethering&lt;/li&gt; 
 &lt;li&gt;🎨 Themes: Light mode, dark mode, system theme following&lt;/li&gt; 
 &lt;li&gt;😎 Lightweight: Native support, displays only the device screen&lt;/li&gt; 
 &lt;li&gt;⚡️ Performance: 30~120 FPS, depending on the device&lt;/li&gt; 
 &lt;li&gt;🌟 Quality: 1920×1080 or higher&lt;/li&gt; 
 &lt;li&gt;🕒 Low Latency: 35~70 ms&lt;/li&gt; 
 &lt;li&gt;🚀 Fast Startup: First image displayed in about 1 second&lt;/li&gt; 
 &lt;li&gt;🙅‍♂️ Non-intrusive: No installation files left on Android devices&lt;/li&gt; 
 &lt;li&gt;🤩 User Benefits: No accounts, no ads, no internet connection required&lt;/li&gt; 
 &lt;li&gt;🗽 Freedom: Free and open-source software&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;h3&gt;Manual Installation via Released Packages&lt;/h3&gt; 
&lt;p&gt;Check the &lt;a href="https://github.com/viarotel-org/escrcpy/releases"&gt;Releases Page&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;macOS Installation via Homebrew&lt;/h3&gt; 
&lt;p&gt;Refer to &lt;a href="https://github.com/viarotel-org/homebrew-escrcpy"&gt;homebrew-escrcpy&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://escrcpy.viarotel.eu.org/guide/started"&gt;Getting Started&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://escrcpy.viarotel.eu.org/reference/scrcpy/shortcuts"&gt;Shortcuts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://escrcpy.viarotel.eu.org/guide/operation"&gt;Device Operations&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://escrcpy.viarotel.eu.org/guide/preferences"&gt;Preferences&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://escrcpy.viarotel.eu.org/reference/gnirehtet/"&gt;Reverse Tethering&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;For Developers&lt;/h2&gt; 
&lt;p&gt;If you are a developer and wish to run or help improve this project, refer to the &lt;a href="https://github.com/viarotel-org/escrcpy/raw/main/develop.md"&gt;Development Documentation&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Get Help&lt;/h2&gt; 
&lt;p&gt;As an open-source project powered by passion, support is limited, and updates are irregular.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://escrcpy.viarotel.eu.org/help/escrcpy"&gt;FAQ&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/viarotel-org/escrcpy/issues"&gt;Report Issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/viarotel-org/escrcpy/main/viarotel@qq.com"&gt;Contact Email&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;What's Next?&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://escrcpy.viarotel.eu.org/guide/milestones"&gt;Milestones&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Acknowledgments&lt;/h2&gt; 
&lt;p&gt;This project owes its existence to the following open-source projects:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Genymobile/scrcpy"&gt;scrcpy&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/DeviceFarmer/adbkit"&gt;adbkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.electronjs.org/"&gt;electron&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://vuejs.org/"&gt;vue&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Genymobile/gnirehtet/"&gt;gnirehtet&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Donate&lt;/h2&gt; 
&lt;p&gt;If this project has helped you, consider buying me a coffee to keep me motivated for further improvements 😛&lt;/p&gt; 
&lt;div style="display:flex;"&gt; 
 &lt;img src="https://cdn.jsdelivr.net/gh/viarotel-org/escrcpy@main/src/assets/sponsor/viarotel-wepay.png" alt="viarotel-wepay" width="30%" /&gt; 
 &lt;img src="https://cdn.jsdelivr.net/gh/viarotel-org/escrcpy@main/src/assets/sponsor/viarotel-alipay.png" alt="viarotel-alipay" width="30%" /&gt; 
 &lt;a href="https://www.paypal.com/paypalme/viarotel" target="_blank" rel="noopener noreferrer"&gt; &lt;img src="https://cdn.jsdelivr.net/gh/viarotel-org/escrcpy@main/src/assets/sponsor/viarotel-paypal.png" alt="viarotel-paypal" width="30%" /&gt; &lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;p&gt;Thanks to all who contributed!&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://github.com/viarotel/escrcpy/graphs/contributors"&gt;Contributors&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Star History&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#viarotel-org/escrcpy&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=viarotel-org/escrcpy&amp;amp;type=Date" alt="Star History Chart" /&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>alyssaxuu/screenity</title>
      <link>https://github.com/alyssaxuu/screenity</link>
      <description>&lt;p&gt;The free and privacy-friendly screen recorder with no limits 🎥&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Screenity&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://screenity.io"&gt;&lt;img src="https://github.com/alyssaxuu/screenity/assets/7581348/ed55e52e-4adf-442b-b774-6856abacdffb" alt="jiewjjc232" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;The free and privacy-friendly screen recorder with no limits 🎥&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://chrome.google.com/webstore/detail/screenity-screen-recorder/kbbdabhdfibnancpjfhlkhafgdilcnji"&gt;Get it now - it's free!&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Screenity is a powerful privacy-friendly screen recorder and annotation tool to make better videos for work, education, and more. You can create stunning product demos, tutorials, presentations, or share feedback with your team - all for free.&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;You can support this project (and many others) through &lt;a href="https://github.com/sponsors/alyssaxuu"&gt;GitHub Sponsors&lt;/a&gt;! ❤️&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Made by &lt;a href="https://alyssax.com"&gt;Alyssa X&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://www.producthunt.com/posts/screenity?utm_source=badge-top-post-badge&amp;amp;utm_medium=badge&amp;amp;utm_souce=badge-screenity" target="_blank"&gt;&lt;img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=275308&amp;amp;theme=light&amp;amp;period=daily" alt="Screenity - The most powerful screen recorder for Chrome | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /&gt;&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=25150804" target="_blank"&gt;&lt;img height="53" src="https://hackerbadge.now.sh/api?id=25150804&amp;amp;type=orange" alt="Featured on HackerNews" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;❗️ Screenity has been rebuilt from the ground up, and updated to MV3. &lt;a href="https://help.screenity.io/getting-started/77KizPC8MHVGfpKpqdux9D/what%E2%80%99s-changed-in-the-new-version-of-screenity/bDtvcwAtw9PPesQeNH4zjE"&gt;Click here&lt;/a&gt; to here to learn more about why, and what's changed in the new version. Also note that &lt;strong&gt;the license has changed to &lt;a href="https://github.com/alyssaxuu/screenity/raw/master/LICENSE"&gt;GPLv3&lt;/a&gt;&lt;/strong&gt;, but the older MV2 version remains MIT licensed. Make sure you read the license and the &lt;a href="https://screenity.io/en/terms/"&gt;Terms of Service&lt;/a&gt; regarding intellectual property.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h2&gt;Table of contents&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/alyssaxuu/screenity/master/#features"&gt;Features&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/alyssaxuu/screenity/master/#self-hosting-screenity"&gt;Self-hosting Screenity&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/alyssaxuu/screenity/master/#creating-a-development-version"&gt;Creating a development version&lt;/a&gt; 
  &lt;ul&gt; 
   &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/alyssaxuu/screenity/master/#enabling-save-to-google-drive"&gt;Enabling Save to Google Drive&lt;/a&gt;&lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/alyssaxuu/screenity/master/#acknowledgements"&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Features&lt;/h2&gt; 
&lt;p&gt;🎥 Make unlimited recordings of your tab, a specific area, desktop, any application, or camera&lt;br /&gt; 🎙️ Record your microphone or internal audio, and use features like push to talk&lt;br /&gt; ✏️ Annotate by drawing anywhere on the screen, adding text, arrows, shapes, and more&lt;br /&gt; ✨ Use AI-powered camera backgrounds or blur to enhance your recordings&lt;br /&gt; 🔎 Zoom in smoothly in your recordings to focus on specific areas&lt;br /&gt; 🪄 Blur out any sensitive content of any page to keep it private&lt;br /&gt; ✂️ Remove or add audio, cut, trim, or crop your recordings with a comprehensive editor&lt;br /&gt; 👀 Highlight your clicks and cursor, and go in spotlight mode&lt;br /&gt; ⏱️ Set up alarms to automatically stop your recording&lt;br /&gt; 💾 Export as mp4, gif, and webm, or save the video directly to Google Drive to share a link&lt;br /&gt; ⚙️ Set a countdown, hide parts of the UI, or move it anywhere&lt;br /&gt; 🔒 Only you can see your videos, we don’t collect any of your data. You can even go offline!&lt;br /&gt; 💙 No limits, make as many videos as you want, for as long as you want&lt;br /&gt; …and much more - all for free &amp;amp; no sign in needed!&lt;/p&gt; 
&lt;h2&gt;Self-hosting Screenity&lt;/h2&gt; 
&lt;p&gt;You can run Screenity locally without having to install it from the Chrome Store. Here's how:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Download the latest Build.zip from the &lt;a href="https://github.com/alyssaxuu/screenity/releases"&gt;releases page&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Load the extension by pasting &lt;code&gt;chrome://extensions/&lt;/code&gt; in the address bar, and &lt;a href="https://developer.chrome.com/docs/extensions/mv2/faq/#:~:text=You%20can%20start%20by%20turning,a%20packaged%20extension%2C%20and%20more."&gt;enabling developer mode&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Drag the folder that contains the code (make sure it's a folder and not a ZIP file, so unzip first), or click on the "Load unpacked" button and locate the folder.&lt;/li&gt; 
 &lt;li&gt;That's it, you should now be able to use Screenity locally. &lt;a href="https://raw.githubusercontent.com/alyssaxuu/screenity/master/#enabling-save-to-google-drive"&gt;Follow these instructions&lt;/a&gt; to set up the Google Drive integration.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;Creating a development version&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;❗️ Note that the license has changed to &lt;a href="https://github.com/alyssaxuu/screenity/raw/master/LICENSE"&gt;GPLv3&lt;/a&gt; for the current MV3 version (Screenity version 3.0.0 and higher). Make sure to read the license and the &lt;a href="https://screenity.io/en/terms/"&gt;Terms of Service&lt;/a&gt; regarding intellectual property.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;ol&gt; 
 &lt;li&gt;Check if your &lt;a href="https://nodejs.org/"&gt;Node.js&lt;/a&gt; version is &amp;gt;= &lt;strong&gt;14&lt;/strong&gt;.&lt;/li&gt; 
 &lt;li&gt;Clone this repository.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;npm install&lt;/code&gt; to install the dependencies.&lt;/li&gt; 
 &lt;li&gt;Run &lt;code&gt;npm start&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Load the extension by going to &lt;code&gt;chrome://extensions/&lt;/code&gt; , and &lt;a href="https://developer.chrome.com/docs/extensions/mv2/faq/#:~:text=You%20can%20start%20by%20turning,a%20packaged%20extension%2C%20and%20more."&gt;enabling developer mode&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Click on &lt;code&gt;Load unpacked extension&lt;/code&gt;.&lt;/li&gt; 
 &lt;li&gt;Select the &lt;code&gt;build&lt;/code&gt; folder.&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h3&gt;Enabling Save to Google Drive&lt;/h3&gt; 
&lt;p&gt;To enable the Google Drive Upload (authorization consent screen) you must change the client_id in the manifest.json file with your linked extension key.&lt;/p&gt; 
&lt;p&gt;You can create it accessing &lt;a href="https://console.cloud.google.com/apis/credentials"&gt;Google Cloud Console&lt;/a&gt; and selecting Create Credential &amp;gt; OAuth Client ID &amp;gt; Chrome App. To create a persistent extension key, you can follow the steps detailed &lt;a href="https://developer.chrome.com/docs/extensions/reference/manifest/key"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Libraries used&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://ffmpegwasm.netlify.app/"&gt;FFmpeg WASM&lt;/a&gt; for editing and encoding videos&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tensorflow/tfjs"&gt;Tensorflow&lt;/a&gt; with the &lt;a href="https://blog.tensorflow.org/2022/01/body-segmentation.html"&gt;Selfie Segmentation&lt;/a&gt; model&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/fabricjs/fabric.js"&gt;Fabric.js&lt;/a&gt; for drawing and annotating&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.radix-ui.com/primitives"&gt;Radix Primitives&lt;/a&gt; for the UI components&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://uiwjs.github.io/react-color/"&gt;react-color&lt;/a&gt; for the color wheel&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/localForage/localForage"&gt;localForage&lt;/a&gt; to help store videos offline with IndexedDB&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://wavesurfer.xyz/"&gt;Wavesurfer.js&lt;/a&gt; to create audio waveforms in the popup and the editor&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://advanced-cropper.github.io/react-advanced-cropper/"&gt;React Advanced Cropper&lt;/a&gt; for the cropping UI in the editor&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/yusitnikov/fix-webm-duration"&gt;fix-webm-duration&lt;/a&gt; to add missing metadata to WEBM files&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Acknowledgements&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://www.helpkit.so/"&gt;HelpKit&lt;/a&gt; for sponsoring this project by hosting the &lt;a href="https://help.screenity.io/"&gt;Screenity Help Center&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;Thanks to &lt;a href="https://www.behance.net/meixuanloo"&gt;Mei Xuan&lt;/a&gt; for helping with the Chinese translation of the extension.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;If you need any help, or want to become a Screenity expert, you can browse articles and guides in the &lt;a href="https://help.screenity.io"&gt;help center&lt;/a&gt;. You can also submit any feedback or ideas in this &lt;a href="https://tally.so/r/3ElpXq"&gt;form&lt;/a&gt;, or contact through &lt;a href="https://help.screenity.io/contact"&gt;this page&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Feel free to reach out to me through email at &lt;a href="mailto:hi@alyssax.com"&gt;hi@alyssax.com&lt;/a&gt; or &lt;a href="https://twitter.com/alyssaxuu"&gt;on Twitter&lt;/a&gt; if you have any questions or feedback! Hope you find this useful 💜&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>CodeWithHarry/Sigma-Web-Dev-Course</title>
      <link>https://github.com/CodeWithHarry/Sigma-Web-Dev-Course</link>
      <description>&lt;p&gt;Source Code for Sigma Web Development Course&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Welcome to Sigma's Web Development Course - Hindi Web Development Tutorials! 🚀&lt;/h1&gt; 
&lt;h2&gt;What's Inside:&lt;/h2&gt; 
&lt;p&gt;If you've been itching to dive into the world of web development but feel lost in a sea of English tutorials, you're in the right place! Our course is exclusively in Hindi and is crafted to guide you from being an absolute beginner to a seasoned pro, one step at a time.&lt;/p&gt; 
&lt;h2&gt;Who Can Benefit?&lt;/h2&gt; 
&lt;h3&gt;This course is a perfect fit for:&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;Beginners eager to start their web development journey&lt;/li&gt; 
 &lt;li&gt;Intermediate developers looking to refine their skills&lt;/li&gt; 
 &lt;li&gt;Individuals who prefer learning in Hindi&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;What You'll Master:&lt;/h2&gt; 
&lt;h3&gt;During this course, you'll delve into:&lt;/h3&gt; 
&lt;ol&gt; 
 &lt;li&gt;The fundamentals of HTML, CSS, and JavaScript&lt;/li&gt; 
 &lt;li&gt;Both front-end and back-end development&lt;/li&gt; 
 &lt;li&gt;How to seamlessly integrate databases&lt;/li&gt; 
 &lt;li&gt;Real-world project implementation&lt;/li&gt; 
 &lt;li&gt;And a whole lot more!&lt;/li&gt; 
&lt;/ol&gt; 
&lt;h2&gt;The Schedule:&lt;/h2&gt; 
&lt;p&gt;We're committed to your growth. Expect fresh source code additions nearly every day. Keep up the pace with our schedule and watch your skills soar! 📅&lt;/p&gt; 
&lt;p&gt;Get ready to embark on an exciting coding journey! 👨‍💻🌟&lt;/p&gt; 
&lt;p&gt;Ready to start? &lt;a href="https://www.youtube.com/playlist?list=PLu0W_9lII9agq5TrH9XLIKQvv0iaF2X3w"&gt;Click here&lt;/a&gt; to access the complete YouTube playlist.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>