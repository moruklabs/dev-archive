<rss version="2.0">
  <channel>
    <title>GitHub All Languages Daily Trending</title>
    <description>Daily Trending of All Languages in GitHub</description>
    <pubDate>Fri, 16 Jan 2026 01:31:51 GMT</pubDate>
    <link>http://mshibanami.github.io/GitHubTrendingRSS</link>
    
    <item>
      <title>ultralytics/ultralytics</title>
      <link>https://github.com/ultralytics/ultralytics</link>
      <description>&lt;p&gt;Ultralytics YOLO üöÄ&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt; 
 &lt;p&gt; &lt;a href="https://www.ultralytics.com/events/yolovision?utm_source=github&amp;amp;utm_medium=org&amp;amp;utm_campaign=yv25_event" target="_blank"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png" alt="Ultralytics YOLO banner" /&gt;&lt;/a&gt; &lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://docs.ultralytics.com/zh/"&gt;‰∏≠Êñá&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/ko/"&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/ja/"&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/ru/"&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/de/"&gt;Deutsch&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/fr/"&gt;Fran√ßais&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/es"&gt;Espa√±ol&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/pt/"&gt;Portugu√™s&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/tr/"&gt;T√ºrk√ße&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/vi/"&gt;Ti·∫øng Vi·ªát&lt;/a&gt; | &lt;a href="https://docs.ultralytics.com/ar/"&gt;ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&lt;/a&gt; &lt;br /&gt;&lt;/p&gt; 
 &lt;div&gt; 
  &lt;a href="https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml"&gt;&lt;img src="https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg?sanitize=true" alt="Ultralytics CI" /&gt;&lt;/a&gt; 
  &lt;a href="https://clickpy.clickhouse.com/dashboard/ultralytics"&gt;&lt;img src="https://static.pepy.tech/badge/ultralytics" alt="Ultralytics Downloads" /&gt;&lt;/a&gt; 
  &lt;a href="https://discord.com/invite/ultralytics"&gt;&lt;img alt="Ultralytics Discord" src="https://img.shields.io/discord/1089800235347353640?logo=discord&amp;amp;logoColor=white&amp;amp;label=Discord&amp;amp;color=blue" /&gt;&lt;/a&gt; 
  &lt;a href="https://community.ultralytics.com/"&gt;&lt;img alt="Ultralytics Forums" src="https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&amp;amp;logo=discourse&amp;amp;label=Forums&amp;amp;color=blue" /&gt;&lt;/a&gt; 
  &lt;a href="https://www.reddit.com/r/ultralytics/"&gt;&lt;img alt="Ultralytics Reddit" src="https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&amp;amp;logo=reddit&amp;amp;logoColor=white&amp;amp;label=Reddit&amp;amp;color=blue" /&gt;&lt;/a&gt; 
  &lt;br /&gt; 
  &lt;a href="https://console.paperspace.com/github/ultralytics/ultralytics"&gt;&lt;img src="https://assets.paperspace.io/img/gradient-badge.svg?sanitize=true" alt="Run Ultralytics on Gradient" /&gt;&lt;/a&gt; 
  &lt;a href="https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb"&gt;&lt;img src="https://colab.research.google.com/assets/colab-badge.svg?sanitize=true" alt="Open Ultralytics In Colab" /&gt;&lt;/a&gt; 
  &lt;a href="https://www.kaggle.com/models/ultralytics/yolo11"&gt;&lt;img src="https://kaggle.com/static/images/open-in-kaggle.svg?sanitize=true" alt="Open Ultralytics In Kaggle" /&gt;&lt;/a&gt; 
  &lt;a href="https://mybinder.org/v2/gh/ultralytics/ultralytics/HEAD?labpath=examples%2Ftutorial.ipynb"&gt;&lt;img src="https://mybinder.org/badge_logo.svg?sanitize=true" alt="Open Ultralytics In Binder" /&gt;&lt;/a&gt; 
 &lt;/div&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://www.ultralytics.com/"&gt;Ultralytics&lt;/a&gt; creates cutting-edge, state-of-the-art (SOTA) &lt;a href="https://www.ultralytics.com/yolo"&gt;YOLO models&lt;/a&gt; built on years of foundational research in computer vision and AI. Constantly updated for performance and flexibility, our models are &lt;strong&gt;fast&lt;/strong&gt;, &lt;strong&gt;accurate&lt;/strong&gt;, and &lt;strong&gt;easy to use&lt;/strong&gt;. They excel at &lt;a href="https://docs.ultralytics.com/tasks/detect/"&gt;object detection&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/modes/track/"&gt;tracking&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/tasks/segment/"&gt;instance segmentation&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/tasks/classify/"&gt;image classification&lt;/a&gt;, and &lt;a href="https://docs.ultralytics.com/tasks/pose/"&gt;pose estimation&lt;/a&gt; tasks.&lt;/p&gt; 
&lt;p&gt;Find detailed documentation in the &lt;a href="https://docs.ultralytics.com/"&gt;Ultralytics Docs&lt;/a&gt;. Get support via &lt;a href="https://github.com/ultralytics/ultralytics/issues/new/choose"&gt;GitHub Issues&lt;/a&gt;. Join discussions on &lt;a href="https://discord.com/invite/ultralytics"&gt;Discord&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/ultralytics/"&gt;Reddit&lt;/a&gt;, and the &lt;a href="https://community.ultralytics.com/"&gt;Ultralytics Community Forums&lt;/a&gt;!&lt;/p&gt; 
&lt;p&gt;Request an Enterprise License for commercial use at &lt;a href="https://www.ultralytics.com/license"&gt;Ultralytics Licensing&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://docs.ultralytics.com/models/yolo11/" target="_blank"&gt; &lt;img width="100%" src="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/yolo/performance-comparison.png" alt="YOLO11 performance plots" /&gt; &lt;/a&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-github.png" width="2%" alt="Ultralytics GitHub" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://www.linkedin.com/company/ultralytics/"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-linkedin.png" width="2%" alt="Ultralytics LinkedIn" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://twitter.com/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-twitter.png" width="2%" alt="Ultralytics Twitter" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://www.youtube.com/ultralytics?sub_confirmation=1"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-youtube.png" width="2%" alt="Ultralytics YouTube" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://www.tiktok.com/@ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-tiktok.png" width="2%" alt="Ultralytics TikTok" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://ultralytics.com/bilibili"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-bilibili.png" width="2%" alt="Ultralytics BiliBili" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="2%" alt="space" /&gt; 
 &lt;a href="https://discord.com/invite/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-discord.png" width="2%" alt="Ultralytics Discord" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;üìÑ Documentation&lt;/h2&gt; 
&lt;p&gt;See below for quickstart installation and usage examples. For comprehensive guidance on training, validation, prediction, and deployment, refer to our full &lt;a href="https://docs.ultralytics.com/"&gt;Ultralytics Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Install&lt;/summary&gt; 
 &lt;p&gt;Install the &lt;code&gt;ultralytics&lt;/code&gt; package, including all &lt;a href="https://github.com/ultralytics/ultralytics/raw/main/pyproject.toml"&gt;requirements&lt;/a&gt;, in a &lt;a href="https://www.python.org/"&gt;&lt;strong&gt;Python&amp;gt;=3.8&lt;/strong&gt;&lt;/a&gt; environment with &lt;a href="https://pytorch.org/get-started/locally/"&gt;&lt;strong&gt;PyTorch&amp;gt;=1.8&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://pypi.org/project/ultralytics/"&gt;&lt;img src="https://img.shields.io/pypi/v/ultralytics?logo=pypi&amp;amp;logoColor=white" alt="PyPI - Version" /&gt;&lt;/a&gt; &lt;a href="https://clickpy.clickhouse.com/dashboard/ultralytics"&gt;&lt;img src="https://static.pepy.tech/badge/ultralytics" alt="Ultralytics Downloads" /&gt;&lt;/a&gt; &lt;a href="https://pypi.org/project/ultralytics/"&gt;&lt;img src="https://img.shields.io/pypi/pyversions/ultralytics?logo=python&amp;amp;logoColor=gold" alt="PyPI - Python Version" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;pip install ultralytics
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;For alternative installation methods, including &lt;a href="https://anaconda.org/conda-forge/ultralytics"&gt;Conda&lt;/a&gt;, &lt;a href="https://hub.docker.com/r/ultralytics/ultralytics"&gt;Docker&lt;/a&gt;, and building from source via Git, please consult the &lt;a href="https://docs.ultralytics.com/quickstart/"&gt;Quickstart Guide&lt;/a&gt;.&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://anaconda.org/conda-forge/ultralytics"&gt;&lt;img src="https://img.shields.io/conda/vn/conda-forge/ultralytics?logo=condaforge" alt="Conda Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/ultralytics/ultralytics"&gt;&lt;img src="https://img.shields.io/docker/v/ultralytics/ultralytics?sort=semver&amp;amp;logo=docker" alt="Docker Image Version" /&gt;&lt;/a&gt; &lt;a href="https://hub.docker.com/r/ultralytics/ultralytics"&gt;&lt;img src="https://img.shields.io/docker/pulls/ultralytics/ultralytics?logo=docker" alt="Ultralytics Docker Pulls" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/details&gt; 
&lt;details open&gt; 
 &lt;summary&gt;Usage&lt;/summary&gt; 
 &lt;h3&gt;CLI&lt;/h3&gt; 
 &lt;p&gt;You can use Ultralytics YOLO directly from the Command Line Interface (CLI) with the &lt;code&gt;yolo&lt;/code&gt; command:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-bash"&gt;# Predict using a pretrained YOLO model (e.g., YOLO26n) on an image
yolo predict model=yolo26n.pt source='https://ultralytics.com/images/bus.jpg'
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;The &lt;code&gt;yolo&lt;/code&gt; command supports various tasks and modes, accepting additional arguments like &lt;code&gt;imgsz=640&lt;/code&gt;. Explore the YOLO &lt;a href="https://docs.ultralytics.com/usage/cli/"&gt;CLI Docs&lt;/a&gt; for more examples.&lt;/p&gt; 
 &lt;h3&gt;Python&lt;/h3&gt; 
 &lt;p&gt;Ultralytics YOLO can also be integrated directly into your Python projects. It accepts the same &lt;a href="https://docs.ultralytics.com/usage/cfg/"&gt;configuration arguments&lt;/a&gt; as the CLI:&lt;/p&gt; 
 &lt;pre&gt;&lt;code class="language-python"&gt;from ultralytics import YOLO

# Load a pretrained YOLO26n model
model = YOLO("yolo26n.pt")

# Train the model on the COCO8 dataset for 100 epochs
train_results = model.train(
    data="coco8.yaml",  # Path to dataset configuration file
    epochs=100,  # Number of training epochs
    imgsz=640,  # Image size for training
    device="cpu",  # Device to run on (e.g., 'cpu', 0, [0,1,2,3])
)

# Evaluate the model's performance on the validation set
metrics = model.val()

# Perform object detection on an image
results = model("path/to/image.jpg")  # Predict on an image
results[0].show()  # Display results

# Export the model to ONNX format for deployment
path = model.export(format="onnx")  # Returns the path to the exported model
&lt;/code&gt;&lt;/pre&gt; 
 &lt;p&gt;Discover more examples in the YOLO &lt;a href="https://docs.ultralytics.com/usage/python/"&gt;Python Docs&lt;/a&gt;.&lt;/p&gt; 
&lt;/details&gt; 
&lt;h2&gt;‚ú® Models&lt;/h2&gt; 
&lt;p&gt;Ultralytics supports a wide range of YOLO models, from early versions like &lt;a href="https://docs.ultralytics.com/models/yolov3/"&gt;YOLOv3&lt;/a&gt; to the latest &lt;a href="https://docs.ultralytics.com/models/yolo26/"&gt;YOLO26&lt;/a&gt;. The tables below showcase YOLO26 models pretrained on the &lt;a href="https://docs.ultralytics.com/datasets/detect/coco/"&gt;COCO&lt;/a&gt; dataset for &lt;a href="https://docs.ultralytics.com/tasks/detect/"&gt;Detection&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/tasks/segment/"&gt;Segmentation&lt;/a&gt;, and &lt;a href="https://docs.ultralytics.com/tasks/pose/"&gt;Pose Estimation&lt;/a&gt;. Additionally, &lt;a href="https://docs.ultralytics.com/tasks/classify/"&gt;Classification&lt;/a&gt; models pretrained on the &lt;a href="https://docs.ultralytics.com/datasets/classify/imagenet/"&gt;ImageNet&lt;/a&gt; dataset are available. &lt;a href="https://docs.ultralytics.com/modes/track/"&gt;Tracking&lt;/a&gt; mode is compatible with all Detection, Segmentation, and Pose models. All &lt;a href="https://docs.ultralytics.com/models/"&gt;Models&lt;/a&gt; are automatically downloaded from the latest Ultralytics &lt;a href="https://github.com/ultralytics/assets/releases"&gt;release&lt;/a&gt; upon first use.&lt;/p&gt; 
&lt;a href="https://docs.ultralytics.com/tasks/" target="_blank"&gt; &lt;img width="100%" src="https://github.com/ultralytics/docs/releases/download/0/ultralytics-yolov8-tasks-banner.avif" alt="Ultralytics YOLO supported tasks" /&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;details open&gt;
 &lt;summary&gt;Detection (COCO)&lt;/summary&gt; 
 &lt;p&gt;Explore the &lt;a href="https://docs.ultralytics.com/tasks/detect/"&gt;Detection Docs&lt;/a&gt; for usage examples. These models are trained on the &lt;a href="https://cocodataset.org/"&gt;COCO dataset&lt;/a&gt;, featuring 80 object classes.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;size&lt;br /&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;val&lt;br /&gt;50-95&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;val&lt;br /&gt;50-95(e2e)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;CPU ONNX&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;T4 TensorRT10&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;params&lt;br /&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;FLOPs&lt;br /&gt;&lt;sup&gt;(B)&lt;/sup&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt"&gt;YOLO26n&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;40.9&lt;/td&gt; 
    &lt;td&gt;40.1&lt;/td&gt; 
    &lt;td&gt;38.9 ¬± 0.7&lt;/td&gt; 
    &lt;td&gt;1.7 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;2.4&lt;/td&gt; 
    &lt;td&gt;5.4&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26s.pt"&gt;YOLO26s&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;48.6&lt;/td&gt; 
    &lt;td&gt;47.8&lt;/td&gt; 
    &lt;td&gt;87.2 ¬± 0.9&lt;/td&gt; 
    &lt;td&gt;2.5 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;9.5&lt;/td&gt; 
    &lt;td&gt;20.7&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26m.pt"&gt;YOLO26m&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;53.1&lt;/td&gt; 
    &lt;td&gt;52.5&lt;/td&gt; 
    &lt;td&gt;220.0 ¬± 1.4&lt;/td&gt; 
    &lt;td&gt;4.7 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;20.4&lt;/td&gt; 
    &lt;td&gt;68.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26l.pt"&gt;YOLO26l&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;55.0&lt;/td&gt; 
    &lt;td&gt;54.4&lt;/td&gt; 
    &lt;td&gt;286.2 ¬± 2.0&lt;/td&gt; 
    &lt;td&gt;6.2 ¬± 0.2&lt;/td&gt; 
    &lt;td&gt;24.8&lt;/td&gt; 
    &lt;td&gt;86.4&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26x.pt"&gt;YOLO26x&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;57.5&lt;/td&gt; 
    &lt;td&gt;56.9&lt;/td&gt; 
    &lt;td&gt;525.8 ¬± 4.0&lt;/td&gt; 
    &lt;td&gt;11.8 ¬± 0.2&lt;/td&gt; 
    &lt;td&gt;55.7&lt;/td&gt; 
    &lt;td&gt;193.9&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;mAP&lt;sup&gt;val&lt;/sup&gt;&lt;/strong&gt; values refer to single-model single-scale performance on the &lt;a href="https://cocodataset.org/"&gt;COCO val2017&lt;/a&gt; dataset. See &lt;a href="https://docs.ultralytics.com/guides/yolo-performance-metrics/"&gt;YOLO Performance Metrics&lt;/a&gt; for details. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val detect data=coco.yaml device=0&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; metrics are averaged over COCO val images using an &lt;a href="https://aws.amazon.com/ec2/instance-types/p4/"&gt;Amazon EC2 P4d&lt;/a&gt; instance. CPU speeds measured with &lt;a href="https://onnx.ai/"&gt;ONNX&lt;/a&gt; export. GPU speeds measured with &lt;a href="https://developer.nvidia.com/tensorrt"&gt;TensorRT&lt;/a&gt; export. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val detect data=coco.yaml batch=1 device=0|cpu&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Segmentation (COCO)&lt;/summary&gt; 
 &lt;p&gt;Refer to the &lt;a href="https://docs.ultralytics.com/tasks/segment/"&gt;Segmentation Docs&lt;/a&gt; for usage examples. These models are trained on &lt;a href="https://docs.ultralytics.com/datasets/segment/coco/"&gt;COCO-Seg&lt;/a&gt;, including 80 classes.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;size&lt;br /&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;box&lt;br /&gt;50-95(e2e)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;mask&lt;br /&gt;50-95(e2e)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;CPU ONNX&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;T4 TensorRT10&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;params&lt;br /&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;FLOPs&lt;br /&gt;&lt;sup&gt;(B)&lt;/sup&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n-seg.pt"&gt;YOLO26n-seg&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;39.6&lt;/td&gt; 
    &lt;td&gt;33.9&lt;/td&gt; 
    &lt;td&gt;53.3 ¬± 0.5&lt;/td&gt; 
    &lt;td&gt;2.1 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;2.7&lt;/td&gt; 
    &lt;td&gt;9.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26s-seg.pt"&gt;YOLO26s-seg&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;47.3&lt;/td&gt; 
    &lt;td&gt;40.0&lt;/td&gt; 
    &lt;td&gt;118.4 ¬± 0.9&lt;/td&gt; 
    &lt;td&gt;3.3 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;10.4&lt;/td&gt; 
    &lt;td&gt;34.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26m-seg.pt"&gt;YOLO26m-seg&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;52.5&lt;/td&gt; 
    &lt;td&gt;44.1&lt;/td&gt; 
    &lt;td&gt;328.2 ¬± 2.4&lt;/td&gt; 
    &lt;td&gt;6.7 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;23.6&lt;/td&gt; 
    &lt;td&gt;121.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26l-seg.pt"&gt;YOLO26l-seg&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;54.4&lt;/td&gt; 
    &lt;td&gt;45.5&lt;/td&gt; 
    &lt;td&gt;387.0 ¬± 3.7&lt;/td&gt; 
    &lt;td&gt;8.0 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;28.0&lt;/td&gt; 
    &lt;td&gt;139.8&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26x-seg.pt"&gt;YOLO26x-seg&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;56.5&lt;/td&gt; 
    &lt;td&gt;47.0&lt;/td&gt; 
    &lt;td&gt;787.0 ¬± 6.8&lt;/td&gt; 
    &lt;td&gt;16.4 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;62.8&lt;/td&gt; 
    &lt;td&gt;313.5&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;mAP&lt;sup&gt;val&lt;/sup&gt;&lt;/strong&gt; values are for single-model single-scale on the &lt;a href="https://cocodataset.org/"&gt;COCO val2017&lt;/a&gt; dataset. See &lt;a href="https://docs.ultralytics.com/guides/yolo-performance-metrics/"&gt;YOLO Performance Metrics&lt;/a&gt; for details. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val segment data=coco.yaml device=0&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; metrics are averaged over COCO val images using an &lt;a href="https://aws.amazon.com/ec2/instance-types/p4/"&gt;Amazon EC2 P4d&lt;/a&gt; instance. CPU speeds measured with &lt;a href="https://onnx.ai/"&gt;ONNX&lt;/a&gt; export. GPU speeds measured with &lt;a href="https://developer.nvidia.com/tensorrt"&gt;TensorRT&lt;/a&gt; export. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val segment data=coco.yaml batch=1 device=0|cpu&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Classification (ImageNet)&lt;/summary&gt; 
 &lt;p&gt;Consult the &lt;a href="https://docs.ultralytics.com/tasks/classify/"&gt;Classification Docs&lt;/a&gt; for usage examples. These models are trained on &lt;a href="https://docs.ultralytics.com/datasets/classify/imagenet/"&gt;ImageNet&lt;/a&gt;, covering 1000 classes.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;size&lt;br /&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;acc&lt;br /&gt;&lt;sup&gt;top1&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;acc&lt;br /&gt;&lt;sup&gt;top5&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;CPU ONNX&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;T4 TensorRT10&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;params&lt;br /&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;FLOPs&lt;br /&gt;&lt;sup&gt;(B) at 224&lt;/sup&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n-cls.pt"&gt;YOLO26n-cls&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;224&lt;/td&gt; 
    &lt;td&gt;71.4&lt;/td&gt; 
    &lt;td&gt;90.1&lt;/td&gt; 
    &lt;td&gt;5.0 ¬± 0.3&lt;/td&gt; 
    &lt;td&gt;1.1 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;2.8&lt;/td&gt; 
    &lt;td&gt;0.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26s-cls.pt"&gt;YOLO26s-cls&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;224&lt;/td&gt; 
    &lt;td&gt;76.0&lt;/td&gt; 
    &lt;td&gt;92.9&lt;/td&gt; 
    &lt;td&gt;7.9 ¬± 0.2&lt;/td&gt; 
    &lt;td&gt;1.3 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;6.7&lt;/td&gt; 
    &lt;td&gt;1.6&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26m-cls.pt"&gt;YOLO26m-cls&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;224&lt;/td&gt; 
    &lt;td&gt;78.1&lt;/td&gt; 
    &lt;td&gt;94.2&lt;/td&gt; 
    &lt;td&gt;17.2 ¬± 0.4&lt;/td&gt; 
    &lt;td&gt;2.0 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;11.6&lt;/td&gt; 
    &lt;td&gt;4.9&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26l-cls.pt"&gt;YOLO26l-cls&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;224&lt;/td&gt; 
    &lt;td&gt;79.0&lt;/td&gt; 
    &lt;td&gt;94.6&lt;/td&gt; 
    &lt;td&gt;23.2 ¬± 0.3&lt;/td&gt; 
    &lt;td&gt;2.8 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;14.1&lt;/td&gt; 
    &lt;td&gt;6.2&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26x-cls.pt"&gt;YOLO26x-cls&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;224&lt;/td&gt; 
    &lt;td&gt;79.9&lt;/td&gt; 
    &lt;td&gt;95.0&lt;/td&gt; 
    &lt;td&gt;41.4 ¬± 0.9&lt;/td&gt; 
    &lt;td&gt;3.8 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;29.6&lt;/td&gt; 
    &lt;td&gt;13.6&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;acc&lt;/strong&gt; values represent model accuracy on the &lt;a href="https://www.image-net.org/"&gt;ImageNet&lt;/a&gt; dataset validation set. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val classify data=path/to/ImageNet device=0&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; metrics are averaged over ImageNet val images using an &lt;a href="https://aws.amazon.com/ec2/instance-types/p4/"&gt;Amazon EC2 P4d&lt;/a&gt; instance. CPU speeds measured with &lt;a href="https://onnx.ai/"&gt;ONNX&lt;/a&gt; export. GPU speeds measured with &lt;a href="https://developer.nvidia.com/tensorrt"&gt;TensorRT&lt;/a&gt; export. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val classify data=path/to/ImageNet batch=1 device=0|cpu&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Pose (COCO)&lt;/summary&gt; 
 &lt;p&gt;See the &lt;a href="https://docs.ultralytics.com/tasks/pose/"&gt;Pose Estimation Docs&lt;/a&gt; for usage examples. These models are trained on &lt;a href="https://docs.ultralytics.com/datasets/pose/coco/"&gt;COCO-Pose&lt;/a&gt;, focusing on the 'person' class.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;size&lt;br /&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;pose&lt;br /&gt;50-95(e2e)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;pose&lt;br /&gt;50(e2e)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;CPU ONNX&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;T4 TensorRT10&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;params&lt;br /&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;FLOPs&lt;br /&gt;&lt;sup&gt;(B)&lt;/sup&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n-pose.pt"&gt;YOLO26n-pose&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;57.2&lt;/td&gt; 
    &lt;td&gt;83.3&lt;/td&gt; 
    &lt;td&gt;40.3 ¬± 0.5&lt;/td&gt; 
    &lt;td&gt;1.8 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;2.9&lt;/td&gt; 
    &lt;td&gt;7.5&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26s-pose.pt"&gt;YOLO26s-pose&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;63.0&lt;/td&gt; 
    &lt;td&gt;86.6&lt;/td&gt; 
    &lt;td&gt;85.3 ¬± 0.9&lt;/td&gt; 
    &lt;td&gt;2.7 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;10.4&lt;/td&gt; 
    &lt;td&gt;23.9&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26m-pose.pt"&gt;YOLO26m-pose&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;68.8&lt;/td&gt; 
    &lt;td&gt;89.6&lt;/td&gt; 
    &lt;td&gt;218.0 ¬± 1.5&lt;/td&gt; 
    &lt;td&gt;5.0 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;21.5&lt;/td&gt; 
    &lt;td&gt;73.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26l-pose.pt"&gt;YOLO26l-pose&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;70.4&lt;/td&gt; 
    &lt;td&gt;90.5&lt;/td&gt; 
    &lt;td&gt;275.4 ¬± 2.4&lt;/td&gt; 
    &lt;td&gt;6.5 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;25.9&lt;/td&gt; 
    &lt;td&gt;91.3&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26x-pose.pt"&gt;YOLO26x-pose&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;640&lt;/td&gt; 
    &lt;td&gt;71.6&lt;/td&gt; 
    &lt;td&gt;91.6&lt;/td&gt; 
    &lt;td&gt;565.4 ¬± 3.0&lt;/td&gt; 
    &lt;td&gt;12.2 ¬± 0.2&lt;/td&gt; 
    &lt;td&gt;57.6&lt;/td&gt; 
    &lt;td&gt;201.7&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;mAP&lt;sup&gt;val&lt;/sup&gt;&lt;/strong&gt; values are for single-model single-scale on the &lt;a href="https://docs.ultralytics.com/datasets/pose/coco/"&gt;COCO Keypoints val2017&lt;/a&gt; dataset. See &lt;a href="https://docs.ultralytics.com/guides/yolo-performance-metrics/"&gt;YOLO Performance Metrics&lt;/a&gt; for details. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val pose data=coco-pose.yaml device=0&lt;/code&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; metrics are averaged over COCO val images using an &lt;a href="https://aws.amazon.com/ec2/instance-types/p4/"&gt;Amazon EC2 P4d&lt;/a&gt; instance. CPU speeds measured with &lt;a href="https://onnx.ai/"&gt;ONNX&lt;/a&gt; export. GPU speeds measured with &lt;a href="https://developer.nvidia.com/tensorrt"&gt;TensorRT&lt;/a&gt; export. &lt;br /&gt;Reproduce with &lt;code&gt;yolo val pose data=coco-pose.yaml batch=1 device=0|cpu&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;details&gt;
 &lt;summary&gt;Oriented Bounding Boxes (DOTAv1)&lt;/summary&gt; 
 &lt;p&gt;Check the &lt;a href="https://docs.ultralytics.com/tasks/obb/"&gt;OBB Docs&lt;/a&gt; for usage examples. These models are trained on &lt;a href="https://docs.ultralytics.com/datasets/obb/dota-v2/#dota-v10/"&gt;DOTAv1&lt;/a&gt;, including 15 classes.&lt;/p&gt; 
 &lt;table&gt; 
  &lt;thead&gt; 
   &lt;tr&gt; 
    &lt;th&gt;Model&lt;/th&gt; 
    &lt;th&gt;size&lt;br /&gt;&lt;sup&gt;(pixels)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;test&lt;br /&gt;50-95(e2e)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;mAP&lt;sup&gt;test&lt;br /&gt;50(e2e)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;CPU ONNX&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;Speed&lt;br /&gt;&lt;sup&gt;T4 TensorRT10&lt;br /&gt;(ms)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;params&lt;br /&gt;&lt;sup&gt;(M)&lt;/sup&gt;&lt;/th&gt; 
    &lt;th&gt;FLOPs&lt;br /&gt;&lt;sup&gt;(B)&lt;/sup&gt;&lt;/th&gt; 
   &lt;/tr&gt; 
  &lt;/thead&gt; 
  &lt;tbody&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n-obb.pt"&gt;YOLO26n-obb&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;1024&lt;/td&gt; 
    &lt;td&gt;52.4&lt;/td&gt; 
    &lt;td&gt;78.9&lt;/td&gt; 
    &lt;td&gt;97.7 ¬± 0.9&lt;/td&gt; 
    &lt;td&gt;2.8 ¬± 0.0&lt;/td&gt; 
    &lt;td&gt;2.5&lt;/td&gt; 
    &lt;td&gt;14.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26s-obb.pt"&gt;YOLO26s-obb&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;1024&lt;/td&gt; 
    &lt;td&gt;54.8&lt;/td&gt; 
    &lt;td&gt;80.9&lt;/td&gt; 
    &lt;td&gt;218.0 ¬± 1.4&lt;/td&gt; 
    &lt;td&gt;4.9 ¬± 0.1&lt;/td&gt; 
    &lt;td&gt;9.8&lt;/td&gt; 
    &lt;td&gt;55.1&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26m-obb.pt"&gt;YOLO26m-obb&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;1024&lt;/td&gt; 
    &lt;td&gt;55.3&lt;/td&gt; 
    &lt;td&gt;81.0&lt;/td&gt; 
    &lt;td&gt;579.2 ¬± 3.8&lt;/td&gt; 
    &lt;td&gt;10.2 ¬± 0.3&lt;/td&gt; 
    &lt;td&gt;21.2&lt;/td&gt; 
    &lt;td&gt;183.3&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26l-obb.pt"&gt;YOLO26l-obb&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;1024&lt;/td&gt; 
    &lt;td&gt;56.2&lt;/td&gt; 
    &lt;td&gt;81.6&lt;/td&gt; 
    &lt;td&gt;735.6 ¬± 3.1&lt;/td&gt; 
    &lt;td&gt;13.0 ¬± 0.2&lt;/td&gt; 
    &lt;td&gt;25.6&lt;/td&gt; 
    &lt;td&gt;230.0&lt;/td&gt; 
   &lt;/tr&gt; 
   &lt;tr&gt; 
    &lt;td&gt;&lt;a href="https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26x-obb.pt"&gt;YOLO26x-obb&lt;/a&gt;&lt;/td&gt; 
    &lt;td&gt;1024&lt;/td&gt; 
    &lt;td&gt;56.7&lt;/td&gt; 
    &lt;td&gt;81.7&lt;/td&gt; 
    &lt;td&gt;1485.7 ¬± 11.5&lt;/td&gt; 
    &lt;td&gt;30.5 ¬± 0.9&lt;/td&gt; 
    &lt;td&gt;57.6&lt;/td&gt; 
    &lt;td&gt;516.5&lt;/td&gt; 
   &lt;/tr&gt; 
  &lt;/tbody&gt; 
 &lt;/table&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;strong&gt;mAP&lt;sup&gt;test&lt;/sup&gt;&lt;/strong&gt; values are for single-model multiscale performance on the &lt;a href="https://captain-whu.github.io/DOTA/dataset.html"&gt;DOTAv1 test set&lt;/a&gt;. &lt;br /&gt;Reproduce by &lt;code&gt;yolo val obb data=DOTAv1.yaml device=0 split=test&lt;/code&gt; and submit merged results to the &lt;a href="https://captain-whu.github.io/DOTA/evaluation.html"&gt;DOTA evaluation server&lt;/a&gt;.&lt;/li&gt; 
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; metrics are averaged over &lt;a href="https://docs.ultralytics.com/datasets/obb/dota-v2/#dota-v10"&gt;DOTAv1 val images&lt;/a&gt; using an &lt;a href="https://aws.amazon.com/ec2/instance-types/p4/"&gt;Amazon EC2 P4d&lt;/a&gt; instance. CPU speeds measured with &lt;a href="https://onnx.ai/"&gt;ONNX&lt;/a&gt; export. GPU speeds measured with &lt;a href="https://developer.nvidia.com/tensorrt"&gt;TensorRT&lt;/a&gt; export. &lt;br /&gt;Reproduce by &lt;code&gt;yolo val obb data=DOTAv1.yaml batch=1 device=0|cpu&lt;/code&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
&lt;/details&gt; 
&lt;h2&gt;üß© Integrations&lt;/h2&gt; 
&lt;p&gt;Our key integrations with leading AI platforms extend the functionality of Ultralytics' offerings, enhancing tasks like dataset labeling, training, visualization, and model management. Discover how Ultralytics, in collaboration with partners like &lt;a href="https://docs.ultralytics.com/integrations/weights-biases/"&gt;Weights &amp;amp; Biases&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/integrations/comet/"&gt;Comet ML&lt;/a&gt;, &lt;a href="https://docs.ultralytics.com/integrations/roboflow/"&gt;Roboflow&lt;/a&gt;, and &lt;a href="https://docs.ultralytics.com/integrations/openvino/"&gt;Intel OpenVINO&lt;/a&gt;, can optimize your AI workflow. Explore more at &lt;a href="https://docs.ultralytics.com/integrations/"&gt;Ultralytics Integrations&lt;/a&gt;.&lt;/p&gt; 
&lt;a href="https://docs.ultralytics.com/integrations/" target="_blank"&gt; &lt;img width="100%" src="https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png" alt="Ultralytics active learning integrations" /&gt; &lt;/a&gt; 
&lt;br /&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://www.ultralytics.com/hub"&gt; &lt;img src="https://github.com/ultralytics/assets/raw/main/partners/logo-ultralytics-hub.png" width="10%" alt="Ultralytics HUB logo" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="15%" height="0" alt="space" /&gt; 
 &lt;a href="https://docs.ultralytics.com/integrations/weights-biases/"&gt; &lt;img src="https://github.com/ultralytics/assets/raw/main/partners/logo-wb.png" width="10%" alt="Weights &amp;amp; Biases logo" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="15%" height="0" alt="space" /&gt; 
 &lt;a href="https://docs.ultralytics.com/integrations/comet/"&gt; &lt;img src="https://github.com/ultralytics/assets/raw/main/partners/logo-comet.png" width="10%" alt="Comet ML logo" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="15%" height="0" alt="space" /&gt; 
 &lt;a href="https://docs.ultralytics.com/integrations/neural-magic/"&gt; &lt;img src="https://github.com/ultralytics/assets/raw/main/partners/logo-neuralmagic.png" width="10%" alt="Neural Magic logo" /&gt;&lt;/a&gt; 
&lt;/div&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th align="center"&gt;Ultralytics HUB üåü&lt;/th&gt; 
   &lt;th align="center"&gt;Weights &amp;amp; Biases&lt;/th&gt; 
   &lt;th align="center"&gt;Comet&lt;/th&gt; 
   &lt;th align="center"&gt;Neural Magic&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td align="center"&gt;Streamline YOLO workflows: Label, train, and deploy effortlessly with &lt;a href="https://hub.ultralytics.com/"&gt;Ultralytics HUB&lt;/a&gt;. Try now!&lt;/td&gt; 
   &lt;td align="center"&gt;Track experiments, hyperparameters, and results with &lt;a href="https://docs.ultralytics.com/integrations/weights-biases/"&gt;Weights &amp;amp; Biases&lt;/a&gt;.&lt;/td&gt; 
   &lt;td align="center"&gt;Free forever, &lt;a href="https://docs.ultralytics.com/integrations/comet/"&gt;Comet ML&lt;/a&gt; lets you save YOLO models, resume training, and interactively visualize predictions.&lt;/td&gt; 
   &lt;td align="center"&gt;Run YOLO inference up to 6x faster with &lt;a href="https://docs.ultralytics.com/integrations/neural-magic/"&gt;Neural Magic DeepSparse&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;ü§ù Contribute&lt;/h2&gt; 
&lt;p&gt;We thrive on community collaboration! Ultralytics YOLO wouldn't be the SOTA framework it is without contributions from developers like you. Please see our &lt;a href="https://docs.ultralytics.com/help/contributing/"&gt;Contributing Guide&lt;/a&gt; to get started. We also welcome your feedback‚Äîshare your experience by completing our &lt;a href="https://www.ultralytics.com/survey?utm_source=github&amp;amp;utm_medium=social&amp;amp;utm_campaign=Survey"&gt;Survey&lt;/a&gt;. A huge &lt;strong&gt;Thank You&lt;/strong&gt; üôè to everyone who contributes!&lt;/p&gt; 
&lt;!-- SVG image from https://opencollective.com/ultralytics/contributors.svg?width=1280 --&gt; 
&lt;p&gt;&lt;a href="https://github.com/ultralytics/ultralytics/graphs/contributors"&gt;&lt;img src="https://raw.githubusercontent.com/ultralytics/assets/main/im/image-contributors.png" alt="Ultralytics open-source contributors" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;We look forward to your contributions to help make the Ultralytics ecosystem even better!&lt;/p&gt; 
&lt;h2&gt;üìú License&lt;/h2&gt; 
&lt;p&gt;Ultralytics offers two licensing options to suit different needs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;AGPL-3.0 License&lt;/strong&gt;: This &lt;a href="https://opensource.org/license/agpl-v3"&gt;OSI-approved&lt;/a&gt; open-source license is perfect for students, researchers, and enthusiasts. It encourages open collaboration and knowledge sharing. See the &lt;a href="https://github.com/ultralytics/ultralytics/raw/main/LICENSE"&gt;LICENSE&lt;/a&gt; file for full details.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Ultralytics Enterprise License&lt;/strong&gt;: Designed for commercial use, this license allows for the seamless integration of Ultralytics software and AI models into commercial products and services, bypassing the open-source requirements of AGPL-3.0. If your use case involves commercial deployment, please contact us via &lt;a href="https://www.ultralytics.com/license"&gt;Ultralytics Licensing&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üìû Contact&lt;/h2&gt; 
&lt;p&gt;For bug reports and feature requests related to Ultralytics software, please visit &lt;a href="https://github.com/ultralytics/ultralytics/issues"&gt;GitHub Issues&lt;/a&gt;. For questions, discussions, and community support, join our active communities on &lt;a href="https://discord.com/invite/ultralytics"&gt;Discord&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/ultralytics/"&gt;Reddit&lt;/a&gt;, and the &lt;a href="https://community.ultralytics.com/"&gt;Ultralytics Community Forums&lt;/a&gt;. We're here to help with all things Ultralytics!&lt;/p&gt; 
&lt;br /&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://github.com/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-github.png" width="3%" alt="Ultralytics GitHub" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://www.linkedin.com/company/ultralytics/"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-linkedin.png" width="3%" alt="Ultralytics LinkedIn" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://twitter.com/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-twitter.png" width="3%" alt="Ultralytics Twitter" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://www.youtube.com/ultralytics?sub_confirmation=1"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-youtube.png" width="3%" alt="Ultralytics YouTube" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://www.tiktok.com/@ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-tiktok.png" width="3%" alt="Ultralytics TikTok" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://ultralytics.com/bilibili"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-bilibili.png" width="3%" alt="Ultralytics BiliBili" /&gt;&lt;/a&gt; 
 &lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-transparent.png" width="3%" alt="space" /&gt; 
 &lt;a href="https://discord.com/invite/ultralytics"&gt;&lt;img src="https://github.com/ultralytics/assets/raw/main/social/logo-social-discord.png" width="3%" alt="Ultralytics Discord" /&gt;&lt;/a&gt; 
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>blakeblackshear/frigate</title>
      <link>https://github.com/blakeblackshear/frigate</link>
      <description>&lt;p&gt;NVR with realtime local object detection for IP cameras&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;img align="center" alt="logo" src="https://raw.githubusercontent.com/blakeblackshear/frigate/dev/docs/static/img/branding/frigate.png" /&gt; &lt;/p&gt; 
&lt;h1&gt;Frigate NVR‚Ñ¢ - Realtime Object Detection for IP Cameras&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://opensource.org/licenses/MIT"&gt;&lt;img src="https://img.shields.io/badge/License-MIT-yellow.svg?sanitize=true" alt="License: MIT" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;a href="https://hosted.weblate.org/engage/frigate-nvr/"&gt; &lt;img src="https://hosted.weblate.org/widget/frigate-nvr/language-badge.svg?sanitize=true" alt="Translation status" /&gt; &lt;/a&gt; 
&lt;p&gt;[English] | &lt;a href="https://github.com/blakeblackshear/frigate/raw/dev/README_CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;A complete and local NVR designed for &lt;a href="https://www.home-assistant.io"&gt;Home Assistant&lt;/a&gt; with AI object detection. Uses OpenCV and Tensorflow to perform realtime object detection locally for IP cameras.&lt;/p&gt; 
&lt;p&gt;Use of a GPU or AI accelerator is highly recommended. AI accelerators will outperform even the best CPUs with very little overhead. See Frigate's supported &lt;a href="https://docs.frigate.video/configuration/object_detectors/"&gt;object detectors&lt;/a&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Tight integration with Home Assistant via a &lt;a href="https://github.com/blakeblackshear/frigate-hass-integration"&gt;custom component&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Designed to minimize resource use and maximize performance by only looking for objects when and where it is necessary&lt;/li&gt; 
 &lt;li&gt;Leverages multiprocessing heavily with an emphasis on realtime over processing every frame&lt;/li&gt; 
 &lt;li&gt;Uses a very low overhead motion detection to determine where to run object detection&lt;/li&gt; 
 &lt;li&gt;Object detection with TensorFlow runs in separate processes for maximum FPS&lt;/li&gt; 
 &lt;li&gt;Communicates over MQTT for easy integration into other systems&lt;/li&gt; 
 &lt;li&gt;Records video with retention settings based on detected objects&lt;/li&gt; 
 &lt;li&gt;24/7 recording&lt;/li&gt; 
 &lt;li&gt;Re-streaming via RTSP to reduce the number of connections to your camera&lt;/li&gt; 
 &lt;li&gt;WebRTC &amp;amp; MSE support for low-latency live view&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Documentation&lt;/h2&gt; 
&lt;p&gt;View the documentation at &lt;a href="https://docs.frigate.video"&gt;https://docs.frigate.video&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Donations&lt;/h2&gt; 
&lt;p&gt;If you would like to make a donation to support development, please use &lt;a href="https://github.com/sponsors/blakeblackshear"&gt;Github Sponsors&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;This project is licensed under the &lt;strong&gt;MIT License&lt;/strong&gt;.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Code:&lt;/strong&gt; The source code, configuration files, and documentation in this repository are available under the &lt;a href="https://raw.githubusercontent.com/blakeblackshear/frigate/dev/LICENSE"&gt;MIT License&lt;/a&gt;. You are free to use, modify, and distribute the code as long as you include the original copyright notice.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Trademarks:&lt;/strong&gt; The "Frigate" name, the "Frigate NVR" brand, and the Frigate logo are &lt;strong&gt;trademarks of Frigate, Inc.&lt;/strong&gt; and are &lt;strong&gt;not&lt;/strong&gt; covered by the MIT License.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Please see our &lt;a href="https://raw.githubusercontent.com/blakeblackshear/frigate/dev/TRADEMARK.md"&gt;Trademark Policy&lt;/a&gt; for details on acceptable use of our brand assets.&lt;/p&gt; 
&lt;h2&gt;Screenshots&lt;/h2&gt; 
&lt;h3&gt;Live dashboard&lt;/h3&gt; 
&lt;div&gt; 
 &lt;img width="800" alt="Live dashboard" src="https://github.com/blakeblackshear/frigate/assets/569905/5e713cb9-9db5-41dc-947a-6937c3bc376e" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Streamlined review workflow&lt;/h3&gt; 
&lt;div&gt; 
 &lt;img width="800" alt="Streamlined review workflow" src="https://github.com/blakeblackshear/frigate/assets/569905/6fed96e8-3b18-40e5-9ddc-31e6f3c9f2ff" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Multi-camera scrubbing&lt;/h3&gt; 
&lt;div&gt; 
 &lt;img width="800" alt="Multi-camera scrubbing" src="https://github.com/blakeblackshear/frigate/assets/569905/d6788a15-0eeb-4427-a8d4-80b93cae3d74" /&gt; 
&lt;/div&gt; 
&lt;h3&gt;Built-in mask and zone editor&lt;/h3&gt; 
&lt;div&gt; 
 &lt;img width="800" alt="Built-in mask and zone editor" src="https://github.com/blakeblackshear/frigate/assets/569905/d7885fc3-bfe6-452f-b7d0-d957cb3e31f5" /&gt; 
&lt;/div&gt; 
&lt;h2&gt;Translations&lt;/h2&gt; 
&lt;p&gt;We use &lt;a href="https://hosted.weblate.org/projects/frigate-nvr/"&gt;Weblate&lt;/a&gt; to support language translations. Contributions are always welcome.&lt;/p&gt; 
&lt;a href="https://hosted.weblate.org/engage/frigate-nvr/"&gt; &lt;img src="https://hosted.weblate.org/widget/frigate-nvr/multi-auto.svg?sanitize=true" alt="Translation status" /&gt; &lt;/a&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Copyright ¬© 2026 Frigate, Inc.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mudler/LocalAI</title>
      <link>https://github.com/mudler/LocalAI</link>
      <description>&lt;p&gt;ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, MCP, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference&lt;/p&gt;&lt;hr&gt;&lt;h1 align="center"&gt; &lt;br /&gt; &lt;img width="300" src="https://raw.githubusercontent.com/mudler/LocalAI/master/core/http/static/logo.png" /&gt; &lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;p align="center"&gt; &lt;a href="https://github.com/go-skynet/LocalAI/fork" target="blank"&gt; &lt;img src="https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI forks" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/stargazers" target="blank"&gt; &lt;img src="https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI stars" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/pulls" target="blank"&gt; &lt;img src="https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge" alt="LocalAI pull-requests" /&gt; &lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/releases"&gt; &lt;img src="https://img.shields.io/github/release/go-skynet/LocalAI?&amp;amp;label=Latest&amp;amp;style=for-the-badge" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://hub.docker.com/r/localai/localai" target="blank"&gt; &lt;img src="https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker" alt="LocalAI Docker hub" /&gt; &lt;/a&gt; &lt;a href="https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;amp;tag=latest" target="blank"&gt; &lt;img src="https://img.shields.io/badge/quay.io-images-important.svg?" alt="LocalAI Quay.io" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://twitter.com/LocalAI_API" target="blank"&gt; &lt;img src="https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;amp;logo=X&amp;amp;logoColor=white&amp;amp;label=LocalAI_API" alt="Follow LocalAI_API" /&gt; &lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy" target="blank"&gt; &lt;img src="https://img.shields.io/badge/dynamic/json?color=blue&amp;amp;label=Discord&amp;amp;style=for-the-badge&amp;amp;query=approximate_member_count&amp;amp;url=https%3A%2F%2Fdiscordapp.com%2Fapi%2Finvites%2FuJAeKSAGDy%3Fwith_counts%3Dtrue&amp;amp;logo=discord" alt="Join LocalAI Discord Community" /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://trendshift.io/repositories/5539" target="_blank"&gt;&lt;img src="https://trendshift.io/api/badge/repositories/5539" alt="mudler%2FLocalAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55" /&gt;&lt;/a&gt; &lt;/p&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;span&gt;üí°&lt;/span&gt; Get help - &lt;a href="https://localai.io/faq/"&gt;‚ùìFAQ&lt;/a&gt; &lt;a href="https://github.com/go-skynet/LocalAI/discussions"&gt;üí≠Discussions&lt;/a&gt; &lt;a href="https://discord.gg/uJAeKSAGDy"&gt;&lt;span&gt;üí¨&lt;/span&gt; Discord&lt;/a&gt; &lt;a href="https://localai.io/"&gt;&lt;span&gt;üìñ&lt;/span&gt; Documentation website&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://localai.io/basics/getting_started/"&gt;üíª Quickstart&lt;/a&gt; &lt;a href="https://models.localai.io/"&gt;üñºÔ∏è Models&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;üöÄ Roadmap&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;üõ´ Examples&lt;/a&gt; Try on &lt;a href="https://t.me/localaiofficial_bot"&gt;&lt;img src="https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;amp;logo=telegram&amp;amp;logoColor=white" alt="Telegram" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg?sanitize=true" alt="tests" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg?sanitize=true" alt="Build and Release" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg?sanitize=true" alt="build container images" /&gt;&lt;/a&gt;&lt;a href="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml"&gt;&lt;img src="https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg?sanitize=true" alt="Bump dependencies" /&gt;&lt;/a&gt;&lt;a href="https://artifacthub.io/packages/search?repo=localai"&gt;&lt;img src="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai" alt="Artifact Hub" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;LocalAI&lt;/strong&gt; is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by &lt;a href="https://github.com/mudler"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üìöüÜï Local Stack Family&lt;/h2&gt; 
&lt;p&gt;üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:&lt;/p&gt; 
&lt;table&gt; 
 &lt;tbody&gt;
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalAGI"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png" width="300" alt="LocalAGI Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI's Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;a href="https://github.com/mudler/LocalRecall"&gt; &lt;img src="https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png" width="300" alt="LocalRecall Logo" /&gt; &lt;/a&gt; &lt;/td&gt; 
   &lt;td width="50%" valign="top"&gt; &lt;h3&gt;&lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt; &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt; &lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt;
&lt;/table&gt; 
&lt;h2&gt;Screenshots / Video&lt;/h2&gt; 
&lt;h3&gt;Youtube video&lt;/h3&gt; 
&lt;h1 align="center"&gt; &lt;br /&gt; &lt;a href="https://www.youtube.com/watch?v=PDqYhB9nNHA" target="_blank"&gt; &lt;img width="300" src="https://img.youtube.com/vi/PDqYhB9nNHA/0.jpg" /&gt; &lt;/a&gt;&lt;br /&gt; &lt;br /&gt; &lt;/h1&gt; 
&lt;h3&gt;Screenshots&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Talk Interface&lt;/th&gt; 
   &lt;th&gt;Generate Audio&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_tts.png" alt="Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Models Overview&lt;/th&gt; 
   &lt;th&gt;Generate Images&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_gallery.png" alt="Screenshot 2025-03-31 at 12-01-20 LocalAI - Models" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_image.png" alt="Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Chat Interface&lt;/th&gt; 
   &lt;th&gt;Home&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_chat.png" alt="Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5" /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_home.png" alt="Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Login&lt;/th&gt; 
   &lt;th&gt;Swarm&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_login.png" alt="Screenshot 2025-03-31 at 12-09-59 " /&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;img src="https://raw.githubusercontent.com/mudler/LocalAI/master/docs/assets/images/screenshots/screenshot_p2p.png" alt="Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard" /&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;üíª Quickstart&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö†Ô∏è &lt;strong&gt;Note:&lt;/strong&gt; The &lt;code&gt;install.sh&lt;/code&gt; script is currently experiencing issues due to the heavy changes currently undergoing in LocalAI and may produce broken or misconfigured installations. Please use Docker installation (see below) or manual binary installation until &lt;a href="https://github.com/mudler/LocalAI/issues/8032"&gt;issue #8032&lt;/a&gt; is resolved.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Run the installer script:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# Basic installation
curl https://localai.io/install.sh | sh
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more installation options, see &lt;a href="https://localai.io/installation/"&gt;Installer Options&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;macOS Download:&lt;/h3&gt; 
&lt;a href="https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg"&gt; &lt;img src="https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;amp;logo=apple&amp;amp;logoColor=white" alt="Download LocalAI for macOS" /&gt; &lt;/a&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: the DMGs are not signed by Apple as quarantined. See &lt;a href="https://github.com/mudler/LocalAI/issues/6268"&gt;https://github.com/mudler/LocalAI/issues/6268&lt;/a&gt; for a workaround, fix is tracked here: &lt;a href="https://github.com/mudler/LocalAI/issues/6244"&gt;https://github.com/mudler/LocalAI/issues/6244&lt;/a&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;Containers (Docker, podman, ...)&lt;/h3&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üí° Docker Run vs Docker Start&lt;/strong&gt;&lt;/p&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;code&gt;docker run&lt;/code&gt; creates and starts a new container. If a container with the same name already exists, this command will fail.&lt;/li&gt; 
  &lt;li&gt;&lt;code&gt;docker start&lt;/code&gt; starts an existing container that was previously created with &lt;code&gt;docker run&lt;/code&gt;.&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;p&gt;If you've already run LocalAI before and want to start it again, use: &lt;code&gt;docker start -i local-ai&lt;/code&gt;&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h4&gt;CPU only image:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;NVIDIA GPU Images:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CUDA 13.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-13

# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# NVIDIA Jetson (L4T) ARM64
# CUDA 12 (for Nvidia AGX Orin and similar platforms)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64

# CUDA 13 (for Nvidia DGX Spark)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64-cuda-13
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;AMD GPU Images (ROCm):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Intel GPU Images (oneAPI):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;Vulkan GPU Images:&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
&lt;/code&gt;&lt;/pre&gt; 
&lt;h4&gt;AIO Images (pre-downloaded models):&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 13 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-13

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;For more information about the AIO images and pre-downloaded models, see &lt;a href="https://localai.io/basics/container/"&gt;Container Documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;To load models:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;‚ö° &lt;strong&gt;Automatic Backend Detection&lt;/strong&gt;: When you install models from the gallery or YAML files, LocalAI automatically detects your system's GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see &lt;a href="https://localai.io/features/gpu-acceleration/#automatic-backend-detection"&gt;GPU Acceleration&lt;/a&gt;.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;For more information, see &lt;a href="https://localai.io/basics/getting_started/index.html"&gt;üíª Getting started&lt;/a&gt;, if you are interested in our roadmap items and future enhancements, you can see the &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;Issues labeled as Roadmap here&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üì∞ Latest project news&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;December 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/7583"&gt;Dynamic Memory Resource reclaimer&lt;/a&gt;, &lt;a href="https://github.com/mudler/LocalAI/pull/7584"&gt;Automatic fitting of models to multiple GPUS(llama.cpp)&lt;/a&gt;, &lt;a href="https://github.com/mudler/LocalAI/pull/7494"&gt;Added Vibevoice backend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;November 2025: Major improvements to the UX. Among these: &lt;a href="https://github.com/mudler/LocalAI/pull/7245"&gt;Import models via URL&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalAI/pull/7325"&gt;Multiple chats and history&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;October 2025: üîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; support added for agentic capabilities with external tools&lt;/li&gt; 
 &lt;li&gt;September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.&lt;/li&gt; 
 &lt;li&gt;August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with &lt;code&gt;development&lt;/code&gt; suffix in the gallery ): &lt;a href="https://github.com/mudler/LocalAI/pull/6049"&gt;https://github.com/mudler/LocalAI/pull/6049&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6119"&gt;https://github.com/mudler/LocalAI/pull/6119&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6121"&gt;https://github.com/mudler/LocalAI/pull/6121&lt;/a&gt; &lt;a href="https://github.com/mudler/LocalAI/pull/6060"&gt;https://github.com/mudler/LocalAI/pull/6060&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July/August 2025: üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt; added to the API featuring &lt;a href="https://github.com/roboflow/rf-detr"&gt;rf-detr&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v3.2.0"&gt;Read the release notes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;June 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;Backend management&lt;/a&gt; has been added. Attention: extras images are going to be deprecated from the next release! Read &lt;a href="https://github.com/mudler/LocalAI/pull/5607"&gt;the backend management PR&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;May 2025: &lt;a href="https://github.com/mudler/LocalAI/pull/5466"&gt;Audio input&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalAI/pull/5396"&gt;Reranking&lt;/a&gt; in llama.cpp backend, &lt;a href="https://github.com/mudler/LocalAI/pull/5392"&gt;Realtime API&lt;/a&gt;, Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).&lt;/li&gt; 
 &lt;li&gt;May 2025: Important: image name changes &lt;a href="https://github.com/mudler/LocalAI/releases/tag/v2.29.0"&gt;See release&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Apr 2025: Rebrand, WebUI enhancements&lt;/li&gt; 
 &lt;li&gt;Apr 2025: &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI&lt;/a&gt; and &lt;a href="https://github.com/mudler/LocalRecall"&gt;LocalRecall&lt;/a&gt; join the LocalAI family stack.&lt;/li&gt; 
 &lt;li&gt;Apr 2025: WebUI overhaul, AIO images updates&lt;/li&gt; 
 &lt;li&gt;Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images&lt;/li&gt; 
 &lt;li&gt;Jan 2025: LocalAI model release: &lt;a href="https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3"&gt;https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3&lt;/a&gt;, SANA support in diffusers: &lt;a href="https://github.com/mudler/LocalAI/pull/4603"&gt;https://github.com/mudler/LocalAI/pull/4603&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Dec 2024: stablediffusion.cpp backend (ggml) added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4289"&gt;https://github.com/mudler/LocalAI/pull/4289&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Bark.cpp backend added ( &lt;a href="https://github.com/mudler/LocalAI/pull/4287"&gt;https://github.com/mudler/LocalAI/pull/4287&lt;/a&gt; )&lt;/li&gt; 
 &lt;li&gt;Nov 2024: Voice activity detection models (&lt;strong&gt;VAD&lt;/strong&gt;) added to the API: &lt;a href="https://github.com/mudler/LocalAI/pull/4204"&gt;https://github.com/mudler/LocalAI/pull/4204&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Oct 2024: examples moved to &lt;a href="https://github.com/mudler/LocalAI-examples"&gt;LocalAI-examples&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Aug 2024: üÜï FLUX-1, &lt;a href="https://explorer.localai.io"&gt;P2P Explorer&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: &lt;a href="https://github.com/mudler/LocalAI/pull/2723"&gt;https://github.com/mudler/LocalAI/pull/2723&lt;/a&gt;. P2P Global community pools: &lt;a href="https://github.com/mudler/LocalAI/issues/3113"&gt;https://github.com/mudler/LocalAI/issues/3113&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Decentralized P2P llama.cpp: &lt;a href="https://github.com/mudler/LocalAI/pull/2343"&gt;https://github.com/mudler/LocalAI/pull/2343&lt;/a&gt; (peer2peer llama.cpp!) üëâ Docs &lt;a href="https://localai.io/features/distribute/"&gt;https://localai.io/features/distribute/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;May 2024: üî•üî• Distributed inferencing: &lt;a href="https://github.com/mudler/LocalAI/pull/2324"&gt;https://github.com/mudler/LocalAI/pull/2324&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;April 2024: Reranker API: &lt;a href="https://github.com/mudler/LocalAI/pull/2121"&gt;https://github.com/mudler/LocalAI/pull/2121&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Roadmap items: &lt;a href="https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap"&gt;List of issues&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üöÄ &lt;a href="https://localai.io/features/"&gt;Features&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;üß© &lt;a href="https://localai.io/backends/"&gt;Backend Gallery&lt;/a&gt;: Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.&lt;/li&gt; 
 &lt;li&gt;üìñ &lt;a href="https://localai.io/features/text-generation/"&gt;Text generation with GPTs&lt;/a&gt; (&lt;code&gt;llama.cpp&lt;/code&gt;, &lt;code&gt;transformers&lt;/code&gt;, &lt;code&gt;vllm&lt;/code&gt; ... &lt;a href="https://localai.io/model-compatibility/index.html#model-compatibility-table"&gt;&lt;span&gt;üìñ&lt;/span&gt; and more&lt;/a&gt;)&lt;/li&gt; 
 &lt;li&gt;üó£ &lt;a href="https://localai.io/features/text-to-audio/"&gt;Text to Audio&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîà &lt;a href="https://localai.io/features/audio-to-text/"&gt;Audio to Text&lt;/a&gt; (Audio transcription with &lt;code&gt;whisper.cpp&lt;/code&gt;)&lt;/li&gt; 
 &lt;li&gt;üé® &lt;a href="https://localai.io/features/image-generation"&gt;Image generation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üî• &lt;a href="https://localai.io/features/openai-functions/"&gt;OpenAI-alike tools API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üß† &lt;a href="https://localai.io/features/embeddings/"&gt;Embeddings generation for vector databases&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;‚úçÔ∏è &lt;a href="https://localai.io/features/constrained_grammars/"&gt;Constrained grammars&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üñºÔ∏è &lt;a href="https://localai.io/models/"&gt;Download Models directly from Huggingface &lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;ü•Ω &lt;a href="https://localai.io/features/gpt-vision/"&gt;Vision API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîç &lt;a href="https://localai.io/features/object-detection/"&gt;Object Detection&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üìà &lt;a href="https://localai.io/features/reranker/"&gt;Reranker API&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüñß &lt;a href="https://localai.io/features/distribute/"&gt;P2P Inferencing&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜïüîå &lt;a href="https://localai.io/docs/features/mcp/"&gt;Model Context Protocol (MCP)&lt;/a&gt; - Agentic capabilities with external tools and &lt;a href="https://github.com/mudler/LocalAGI"&gt;LocalAGI's Agentic capabilities&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üîä Voice activity detection (Silero-VAD support)&lt;/li&gt; 
 &lt;li&gt;üåç Integrated WebUI!&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üß© Supported Backends &amp;amp; Acceleration&lt;/h2&gt; 
&lt;p&gt;LocalAI supports a comprehensive range of AI backends with multiple acceleration options:&lt;/p&gt; 
&lt;h3&gt;Text Generation &amp;amp; Language Models&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;LLM inference in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel SYCL, Vulkan, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vLLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast LLM inference with PagedAttention&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;transformers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace transformers framework&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;exllama2&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;GPTQ inference library&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon LLM inference&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;MLX-VLM&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Apple Silicon Vision-Language Models&lt;/td&gt; 
   &lt;td&gt;Metal (M1/M2/M3+)&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Audio &amp;amp; Speech Processing&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;whisper.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;OpenAI Whisper in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;faster-whisper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast Whisper with CTranslate2&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-audio generation&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;bark-cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;C++ implementation of Bark&lt;/td&gt; 
   &lt;td&gt;CUDA, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;coqui&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Advanced TTS with 1100+ languages&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kokoro&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Lightweight TTS model&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;chatterbox&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Production-grade TTS&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;piper&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Fast neural TTS system&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;kitten-tts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Kitten TTS models&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;silero-vad&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Voice Activity Detection&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;neutts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Text-to-speech with voice cloning&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;vibevoice&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time TTS with voice cloning&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;pocket-tts&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Lightweight CPU-based TTS&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Image &amp;amp; Video Generation&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;stablediffusion.cpp&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Stable Diffusion in C/C++&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, Intel SYCL, Vulkan, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;diffusers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace diffusion models&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, Metal, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Specialized AI Tasks&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Backend&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
   &lt;th&gt;Acceleration Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rfdetr&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time object detection&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;rerankers&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Document reranking API&lt;/td&gt; 
   &lt;td&gt;CUDA 12/13, ROCm, Intel, CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;local-store&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;Vector database&lt;/td&gt; 
   &lt;td&gt;CPU&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;huggingface&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;HuggingFace API integration&lt;/td&gt; 
   &lt;td&gt;API-based&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Hardware Acceleration Matrix&lt;/h3&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Acceleration Type&lt;/th&gt; 
   &lt;th&gt;Supported Backends&lt;/th&gt; 
   &lt;th&gt;Hardware Support&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 12&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All CUDA-compatible backends&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA CUDA 13&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All CUDA-compatible backends&lt;/td&gt; 
   &lt;td&gt;Nvidia hardware&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;AMD ROCm&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts, vibevoice, pocket-tts&lt;/td&gt; 
   &lt;td&gt;AMD Graphics&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Intel oneAPI&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark, vibevoice, pocket-tts&lt;/td&gt; 
   &lt;td&gt;Intel Arc, Intel iGPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Apple Metal&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp&lt;/td&gt; 
   &lt;td&gt;Apple M1/M2/M3+&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Vulkan&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion&lt;/td&gt; 
   &lt;td&gt;Cross-platform GPUs&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA Jetson (CUDA 12)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rfdetr&lt;/td&gt; 
   &lt;td&gt;ARM64 embedded AI (AGX Orin, etc.)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;NVIDIA Jetson (CUDA 13)&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;llama.cpp, whisper, stablediffusion, diffusers, rfdetr&lt;/td&gt; 
   &lt;td&gt;ARM64 embedded AI (DGX Spark)&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;CPU Optimized&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;All backends&lt;/td&gt; 
   &lt;td&gt;AVX/AVX2/AVX512, quantization support&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;üîó Community and integrations&lt;/h3&gt; 
&lt;p&gt;Build and deploy custom containers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/sozercan/aikit"&gt;https://github.com/sozercan/aikit&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;WebUIs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/Jirubizu/localai-admin"&gt;https://github.com/Jirubizu/localai-admin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/LocalAI-frontend"&gt;https://github.com/go-skynet/LocalAI-frontend&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) &lt;a href="https://github.com/reid41/QA-Pilot"&gt;https://github.com/reid41/QA-Pilot&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Agentic Libraries:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/cogito"&gt;https://github.com/mudler/cogito&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;MCPs:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/mudler/MCPs"&gt;https://github.com/mudler/MCPs&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Model galleries&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/go-skynet/model-gallery"&gt;https://github.com/go-skynet/model-gallery&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Voice:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/richiejp/VoxInput"&gt;https://github.com/richiejp/VoxInput&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Other:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Helm chart &lt;a href="https://github.com/go-skynet/helm-charts"&gt;https://github.com/go-skynet/helm-charts&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;VSCode extension &lt;a href="https://github.com/badgooooor/localai-vscode-plugin"&gt;https://github.com/badgooooor/localai-vscode-plugin&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Langchain: &lt;a href="https://python.langchain.com/docs/integrations/providers/localai/"&gt;https://python.langchain.com/docs/integrations/providers/localai/&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Terminal utility &lt;a href="https://github.com/djcopley/ShellOracle"&gt;https://github.com/djcopley/ShellOracle&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Local Smart assistant &lt;a href="https://github.com/mudler/LocalAGI"&gt;https://github.com/mudler/LocalAGI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Home Assistant &lt;a href="https://github.com/sammcj/homeassistant-localai"&gt;https://github.com/sammcj/homeassistant-localai&lt;/a&gt; / &lt;a href="https://github.com/drndos/hass-openai-custom-conversation"&gt;https://github.com/drndos/hass-openai-custom-conversation&lt;/a&gt; / &lt;a href="https://github.com/valentinfrlch/ha-gpt4vision"&gt;https://github.com/valentinfrlch/ha-gpt4vision&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/discord"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/discord&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Slack bot &lt;a href="https://github.com/mudler/LocalAGI/tree/main/examples/slack"&gt;https://github.com/mudler/LocalAGI/tree/main/examples/slack&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) &lt;a href="https://github.com/reid41/shell-pilot"&gt;https://github.com/reid41/shell-pilot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Telegram bot &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot"&gt;https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Another Telegram Bot &lt;a href="https://github.com/JackBekket/Hellper"&gt;https://github.com/JackBekket/Hellper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Auto-documentation &lt;a href="https://github.com/JackBekket/Reflexia"&gt;https://github.com/JackBekket/Reflexia&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github bot which answer on issues, with code and documentation as context &lt;a href="https://github.com/JackBekket/GitHelper"&gt;https://github.com/JackBekket/GitHelper&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Github Actions: &lt;a href="https://github.com/marketplace/actions/start-localai"&gt;https://github.com/marketplace/actions/start-localai&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Examples: &lt;a href="https://github.com/mudler/LocalAI/tree/master/examples/"&gt;https://github.com/mudler/LocalAI/tree/master/examples/&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;üîó Resources&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/advanced/fine-tuning/"&gt;LLM finetuning guide&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/build/index.html"&gt;How to build locally&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes"&gt;How to install in Kubernetes&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://localai.io/docs/integrations/"&gt;Projects integrating LocalAI&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://io.midori-ai.xyz/howtos/"&gt;How tos section&lt;/a&gt; (curated by our community)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;&lt;span&gt;üìñ&lt;/span&gt; üé• &lt;a href="https://localai.io/basics/news/#media-blogs-social"&gt;Media, Blogs, Social&lt;/a&gt;&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.suse.com/c/running-ai-locally/"&gt;Run Visual studio code with LocalAI (SUSE)&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;üÜï &lt;a href="https://mudler.pm/posts/local-ai-jetson-nano-devkit/"&gt;Run LocalAI on Jetson Nano Devkit&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/"&gt;Run LocalAI on AWS EKS with Pulumi&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance"&gt;Run LocalAI on AWS&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/smart-slackbot-for-teams/"&gt;Create a slackbot for teams and OSS projects that answer to documentation&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=PKrDNuJ_dfE"&gt;LocalAI meets k8sgpt&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mudler.pm/posts/localai-question-answering/"&gt;Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65"&gt;Tutorial to use k8sgpt with LocalAI&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Citation&lt;/h2&gt; 
&lt;p&gt;If you utilize this repository, data in a downstream project, please consider citing it with:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;@misc{localai,
  author = {Ettore Di Giacinto},
  title = {LocalAI: The free, Open source OpenAI alternative},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/go-skynet/LocalAI}},
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;‚ù§Ô∏è Sponsors&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Do you find LocalAI useful?&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;Support the project by becoming &lt;a href="https://github.com/sponsors/mudler"&gt;a backer or sponsor&lt;/a&gt;. Your logo will show up here with a link to your website.&lt;/p&gt; 
&lt;p&gt;A huge thank you to our generous sponsors who support this project covering CI expenses, and our &lt;a href="https://github.com/sponsors/mudler"&gt;Sponsor list&lt;/a&gt;:&lt;/p&gt; 
&lt;p align="center"&gt; &lt;a href="https://www.spectrocloud.com/" target="blank"&gt; &lt;img height="200" src="https://github.com/user-attachments/assets/72eab1dd-8b93-4fc0-9ade-84db49f24962" /&gt; &lt;/a&gt; &lt;a href="https://www.premai.io/" target="blank"&gt; &lt;img height="200" src="https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6" /&gt; &lt;br /&gt; &lt;/a&gt; &lt;/p&gt; 
&lt;h3&gt;Individual sponsors&lt;/h3&gt; 
&lt;p&gt;A special thanks to individual sponsors that contributed to the project, a full list is in &lt;a href="https://github.com/sponsors/mudler"&gt;Github&lt;/a&gt; and &lt;a href="https://buymeacoffee.com/mudler"&gt;buymeacoffee&lt;/a&gt;, a special shout out goes to &lt;a href="https://github.com/drikster80"&gt;drikster80&lt;/a&gt; for being generous. Thank you everyone!&lt;/p&gt; 
&lt;h2&gt;üåü Star history&lt;/h2&gt; 
&lt;p&gt;&lt;a href="https://star-history.com/#go-skynet/LocalAI&amp;amp;Date"&gt;&lt;img src="https://api.star-history.com/svg?repos=go-skynet/LocalAI&amp;amp;type=Date" alt="LocalAI Star history Chart" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üìñ License&lt;/h2&gt; 
&lt;p&gt;LocalAI is a community-driven project created by &lt;a href="https://github.com/mudler/"&gt;Ettore Di Giacinto&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;MIT - Author Ettore Di Giacinto &lt;a href="mailto:mudler@localai.io"&gt;mudler@localai.io&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;üôá Acknowledgements&lt;/h2&gt; 
&lt;p&gt;LocalAI couldn't have been built without the help of great software already available from the community. Thank you!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/llama.cpp"&gt;llama.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/tatsu-lab/stanford_alpaca"&gt;https://github.com/tatsu-lab/stanford_alpaca&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/cornelk/llama-go"&gt;https://github.com/cornelk/llama-go&lt;/a&gt; for the initial ideas&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/antimatter15/alpaca.cpp"&gt;https://github.com/antimatter15/alpaca.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/EdVince/Stable-Diffusion-NCNN"&gt;https://github.com/EdVince/Stable-Diffusion-NCNN&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/ggerganov/whisper.cpp"&gt;https://github.com/ggerganov/whisper.cpp&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/rhasspy/piper"&gt;https://github.com/rhasspy/piper&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;ü§ó Contributors&lt;/h2&gt; 
&lt;p&gt;This is a community project, a special thanks to our contributors! ü§ó &lt;a href="https://github.com/go-skynet/LocalAI/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=go-skynet/LocalAI" /&gt; &lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>obra/superpowers</title>
      <link>https://github.com/obra/superpowers</link>
      <description>&lt;p&gt;An agentic skills framework &amp; software development methodology that works.&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;Superpowers&lt;/h1&gt; 
&lt;p&gt;Superpowers is a complete software development workflow for your coding agents, built on top of a set of composable "skills" and some initial instructions that make sure your agent uses them.&lt;/p&gt; 
&lt;h2&gt;How it works&lt;/h2&gt; 
&lt;p&gt;It starts from the moment you fire up your coding agent. As soon as it sees that you're building something, it &lt;em&gt;doesn't&lt;/em&gt; just jump into trying to write code. Instead, it steps back and asks you what you're really trying to do.&lt;/p&gt; 
&lt;p&gt;Once it's teased a spec out of the conversation, it shows it to you in chunks short enough to actually read and digest.&lt;/p&gt; 
&lt;p&gt;After you've signed off on the design, your agent puts together an implementation plan that's clear enough for an enthusiastic junior engineer with poor taste, no judgement, no project context, and an aversion to testing to follow. It emphasizes true red/green TDD, YAGNI (You Aren't Gonna Need It), and DRY.&lt;/p&gt; 
&lt;p&gt;Next up, once you say "go", it launches a &lt;em&gt;subagent-driven-development&lt;/em&gt; process, having agents work through each engineering task, inspecting and reviewing their work, and continuing forward. It's not uncommon for Claude to be able to work autonomously for a couple hours at a time without deviating from the plan you put together.&lt;/p&gt; 
&lt;p&gt;There's a bunch more to it, but that's the core of the system. And because the skills trigger automatically, you don't need to do anything special. Your coding agent just has Superpowers.&lt;/p&gt; 
&lt;h2&gt;Sponsorship&lt;/h2&gt; 
&lt;p&gt;If Superpowers has helped you do stuff that makes money and you are so inclined, I'd greatly appreciate it if you'd consider &lt;a href="https://github.com/sponsors/obra"&gt;sponsoring my opensource work&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Thanks!&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Jesse&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Installation differs by platform. Claude Code has a built-in plugin system. Codex and OpenCode require manual setup.&lt;/p&gt; 
&lt;h3&gt;Claude Code (via Plugin Marketplace)&lt;/h3&gt; 
&lt;p&gt;In Claude Code, register the marketplace first:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin marketplace add obra/superpowers-marketplace
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Then install the plugin from this marketplace:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin install superpowers@superpowers-marketplace
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Verify Installation&lt;/h3&gt; 
&lt;p&gt;Check that commands appear:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/help
&lt;/code&gt;&lt;/pre&gt; 
&lt;pre&gt;&lt;code&gt;# Should see:
# /superpowers:brainstorm - Interactive design refinement
# /superpowers:write-plan - Create implementation plan
# /superpowers:execute-plan - Execute plan in batches
&lt;/code&gt;&lt;/pre&gt; 
&lt;h3&gt;Codex&lt;/h3&gt; 
&lt;p&gt;Tell Codex:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.codex/INSTALL.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Detailed docs:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/obra/superpowers/main/docs/README.codex.md"&gt;docs/README.codex.md&lt;/a&gt;&lt;/p&gt; 
&lt;h3&gt;OpenCode&lt;/h3&gt; 
&lt;p&gt;Tell OpenCode:&lt;/p&gt; 
&lt;pre&gt;&lt;code&gt;Fetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.opencode/INSTALL.md
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;&lt;strong&gt;Detailed docs:&lt;/strong&gt; &lt;a href="https://raw.githubusercontent.com/obra/superpowers/main/docs/README.opencode.md"&gt;docs/README.opencode.md&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;The Basic Workflow&lt;/h2&gt; 
&lt;ol&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;brainstorming&lt;/strong&gt; - Activates before writing code. Refines rough ideas through questions, explores alternatives, presents design in sections for validation. Saves design document.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;using-git-worktrees&lt;/strong&gt; - Activates after design approval. Creates isolated workspace on new branch, runs project setup, verifies clean test baseline.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;writing-plans&lt;/strong&gt; - Activates with approved design. Breaks work into bite-sized tasks (2-5 minutes each). Every task has exact file paths, complete code, verification steps.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;subagent-driven-development&lt;/strong&gt; or &lt;strong&gt;executing-plans&lt;/strong&gt; - Activates with plan. Dispatches fresh subagent per task with two-stage review (spec compliance, then code quality), or executes in batches with human checkpoints.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;test-driven-development&lt;/strong&gt; - Activates during implementation. Enforces RED-GREEN-REFACTOR: write failing test, watch it fail, write minimal code, watch it pass, commit. Deletes code written before tests.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;requesting-code-review&lt;/strong&gt; - Activates between tasks. Reviews against plan, reports issues by severity. Critical issues block progress.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;finishing-a-development-branch&lt;/strong&gt; - Activates when tasks complete. Verifies tests, presents options (merge/PR/keep/discard), cleans up worktree.&lt;/p&gt; &lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;&lt;strong&gt;The agent checks for relevant skills before any task.&lt;/strong&gt; Mandatory workflows, not suggestions.&lt;/p&gt; 
&lt;h2&gt;What's Inside&lt;/h2&gt; 
&lt;h3&gt;Skills Library&lt;/h3&gt; 
&lt;p&gt;&lt;strong&gt;Testing&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;test-driven-development&lt;/strong&gt; - RED-GREEN-REFACTOR cycle (includes testing anti-patterns reference)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Debugging&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;systematic-debugging&lt;/strong&gt; - 4-phase root cause process (includes root-cause-tracing, defense-in-depth, condition-based-waiting techniques)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;verification-before-completion&lt;/strong&gt; - Ensure it's actually fixed&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Collaboration&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;brainstorming&lt;/strong&gt; - Socratic design refinement&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;writing-plans&lt;/strong&gt; - Detailed implementation plans&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;executing-plans&lt;/strong&gt; - Batch execution with checkpoints&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;dispatching-parallel-agents&lt;/strong&gt; - Concurrent subagent workflows&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;requesting-code-review&lt;/strong&gt; - Pre-review checklist&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;receiving-code-review&lt;/strong&gt; - Responding to feedback&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;using-git-worktrees&lt;/strong&gt; - Parallel development branches&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;finishing-a-development-branch&lt;/strong&gt; - Merge/PR decision workflow&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;subagent-driven-development&lt;/strong&gt; - Fast iteration with two-stage review (spec compliance, then code quality)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;strong&gt;Meta&lt;/strong&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;writing-skills&lt;/strong&gt; - Create new skills following best practices (includes testing methodology)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;using-superpowers&lt;/strong&gt; - Introduction to the skills system&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Philosophy&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Test-Driven Development&lt;/strong&gt; - Write tests first, always&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Systematic over ad-hoc&lt;/strong&gt; - Process over guessing&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Complexity reduction&lt;/strong&gt; - Simplicity as primary goal&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Evidence over claims&lt;/strong&gt; - Verify before declaring success&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Read more: &lt;a href="https://blog.fsck.com/2025/10/09/superpowers/"&gt;Superpowers for Claude Code&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Skills live directly in this repository. To contribute:&lt;/p&gt; 
&lt;ol&gt; 
 &lt;li&gt;Fork the repository&lt;/li&gt; 
 &lt;li&gt;Create a branch for your skill&lt;/li&gt; 
 &lt;li&gt;Follow the &lt;code&gt;writing-skills&lt;/code&gt; skill for creating and testing new skills&lt;/li&gt; 
 &lt;li&gt;Submit a PR&lt;/li&gt; 
&lt;/ol&gt; 
&lt;p&gt;See &lt;code&gt;skills/writing-skills/SKILL.md&lt;/code&gt; for the complete guide.&lt;/p&gt; 
&lt;h2&gt;Updating&lt;/h2&gt; 
&lt;p&gt;Skills update automatically when you update the plugin:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;/plugin update superpowers
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT License - see LICENSE file for details&lt;/p&gt; 
&lt;h2&gt;Support&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Issues&lt;/strong&gt;: &lt;a href="https://github.com/obra/superpowers/issues"&gt;https://github.com/obra/superpowers/issues&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Marketplace&lt;/strong&gt;: &lt;a href="https://github.com/obra/superpowers-marketplace"&gt;https://github.com/obra/superpowers-marketplace&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>eigent-ai/eigent</title>
      <link>https://github.com/eigent-ai/eigent</link>
      <description>&lt;p&gt;Eigent: The Open Source Cowork Desktop to Unlock Your Exceptional Productivity.&lt;/p&gt;&lt;hr&gt;&lt;div align="center"&gt;
 &lt;a name="readme-top"&gt;&lt;/a&gt; 
 &lt;p&gt;&lt;a href="https://www.eigent.ai"&gt;&lt;img src="https://eigent-ai.github.io/.github/assets/head.png" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://www.eigent.ai"&gt;&lt;img src="https://eigent-ai.github.io/.github/assets/seperator.png" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
 &lt;h3&gt;Eigent: The Open Source Cowork Desktop to Unlock Your Exceptional Productivity&lt;/h3&gt; 
 &lt;!-- SHIELD GROUP --&gt; 
 &lt;p&gt;&lt;a href="https://www.eigent.ai/download"&gt;&lt;img src="https://img.shields.io/badge/Download%20Eigent-363AF5?style=plastic" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/eigent-ai/eigent"&gt;&lt;img src="https://img.shields.io/github/stars/eigent-ai?color=F5F4F0&amp;amp;labelColor=gray&amp;amp;style=plastic&amp;amp;logo=github" alt="" /&gt;&lt;/a&gt; &lt;a href="https://x.com/Eigent_AI"&gt;&lt;img src="https://img.shields.io/badge/-%40Eigent_AI-white?labelColor=gray&amp;amp;logo=x&amp;amp;logoColor=white&amp;amp;style=plastic" alt="" /&gt;&lt;/a&gt; &lt;a href="https://discord.camel-ai.org/"&gt;&lt;img src="https://img.shields.io/discord/1082486657678311454?logo=discord&amp;amp;labelColor=%20%235462eb&amp;amp;logoColor=%20%23f5f5f5&amp;amp;color=%20%235462eb" alt="" /&gt;&lt;/a&gt;&lt;br /&gt; &lt;a href="https://www.reddit.com/r/CamelAI/"&gt;&lt;img src="https://img.shields.io/reddit/subreddit-subscribers/CamelAI?style=plastic&amp;amp;logo=reddit&amp;amp;label=r%2FCAMEL&amp;amp;labelColor=white" alt="Reddit" /&gt;&lt;/a&gt; &lt;a href="https://ghli.org/camel/wechat.png"&gt;&lt;img src="https://img.shields.io/badge/WeChat-CamelAIOrg-brightgreen?logo=wechat&amp;amp;logoColor=white" alt="Wechat" /&gt;&lt;/a&gt; &lt;a href="https://github.com/sponsors/camel-ai"&gt;&lt;img src="https://img.shields.io/badge/-Sponsor%20CAMEL--AI-1d1d1d?logo=github&amp;amp;logoColor=white&amp;amp;style=plastic" alt="" /&gt;&lt;/a&gt; &lt;a href="https://github.com/camel-ai/camel"&gt;&lt;img src="https://img.shields.io/badge/-Built--with--CAMEL-4C19E8.svg?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQ4IiBoZWlnaHQ9IjI3MiIgdmlld0JveD0iMCAwIDI0OCAyNzIiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+CjxwYXRoIGQ9Ik04LjgzMTE3IDE4LjU4NjVMMCAzMC44MjY3QzUuNDY2OTIgMzUuMDQzMiAxNS4xMzkxIDM4LjgyNTggMjQuODExNCAzNi4yOTU5QzMwLjY5ODggNDAuOTM0MSAzOS42NzAyIDQwLjIzMTMgNDQuMTU1OSA0MC4wOTA4QzQzLjQ1NSA0Ny4zOTk0IDQyLjQ3MzcgNzAuOTU1OCA0NC4xNTU5IDEwNi43MTJDNDUuODM4IDE0Mi40NjggNzEuNzcwOCAxNjYuODY4IDg0LjUyNjkgMTc0LjU5OEw3Ni4wMDAyIDIyMEw4NC41MjY5IDI3MkgxMDguOTE4TDk4LjAwMDIgMjIwTDEwOC45MTggMTc0LjU5OEwxMjkuOTQ0IDI3MkgxNTQuNzU2TDEzNC4xNSAxNzQuNTk4SDE4Ny4xMzdMMTY2LjUzMSAyNzJIMTkxLjc2M0wyMTIuMzY5IDE3NC41OThMMjI2IDIyMEwyMTIuMzY5IDI3MkgyMzcuNjAxTDI0OC4wMDEgMjIwTDIzNy4xOCAxNzQuNTk4QzIzOS4yODMgMTY5LjExNyAyNDAuNDAxIDE2Ni45NzYgMjQxLjgwNiAxNjEuMTA1QzI0OS4zNzUgMTI5LjQ4MSAyMzUuMDc3IDEwMy45MDEgMjI2LjY2NyA5NC40ODRMMjA2LjQ4MSA3My44MjNDMTk3LjY1IDY0Ljk2ODMgMTgyLjUxMSA2NC41NDY3IDE3Mi44MzkgNzIuNTU4MUMxNjUuNzI4IDc4LjQ0NzcgMTYxLjcwMSA3OC43NzI3IDE1NC43NTYgNzIuNTU4MUMxNTEuODEyIDcwLjAyODEgMTQ0LjUzNSA2MS40ODg5IDEzNC45OTEgNTMuNTgzN0MxMjUuMzE5IDQ1LjU3MjMgMTA4LjQ5NyA0OC45NDU1IDEwMi4xODkgNTUuNjkxOUw3My41OTMxIDg0LjM2NDRWNy42MjM0OUw3OS4xMjczIDBDNjAuOTA0MiAzLjY1NDMzIDIzLjgwMjEgOS41NjMwOSAxOS43NjUgMTAuNTc1MUMxNS43Mjc5IDExLjU4NyAxMC43OTM3IDE2LjMzNzcgOC44MzExNyAxOC41ODY1WiIgZmlsbD0id2hpdGUiLz4KPHBhdGggZD0iTTQzLjIwMzggMTguNzE4N0w0OS4wOTEyIDEzLjA0OTNMNTQuOTc4NyAxOC43MTg3TDQ5LjA5MTIgMjQuODI0Mkw0My4yMDM4IDE4LjcxODdaIiBmaWxsPSIjNEMxOUU4Ii8+Cjwvc3ZnPgo=" alt="" /&gt;&lt;/a&gt; &lt;a href="https://eigent-ai.notion.site/eigent-ai-careers"&gt;&lt;img src="https://img.shields.io/badge/Join%20Us-yellow?style=plastic" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;hr /&gt; 
&lt;div align="center"&gt; 
 &lt;p&gt;&lt;strong&gt;English&lt;/strong&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/README_CN.md"&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; ¬∑ &lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/README_JA.md"&gt;Êó•Êú¨Ë™û&lt;/a&gt; ¬∑ &lt;a href="https://www.eigent.ai"&gt;Official Site&lt;/a&gt; ¬∑ &lt;a href="https://docs.eigent.ai"&gt;Documents&lt;/a&gt; ¬∑ &lt;a href="https://github.com/eigent-ai/eigent/issues"&gt;Feedback&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;strong&gt;Eigent&lt;/strong&gt;&amp;nbsp;is the open source cowork desktop application, empowering you to build, manage, and deploy a custom AI workforce that can turn your most complex workflows into automated tasks.&lt;/p&gt; 
&lt;p&gt;Built on &lt;a href="https://www.camel-ai.org"&gt;CAMEL-AI&lt;/a&gt;'s acclaimed open-source project, our system introduces a &lt;strong&gt;Multi-Agent Workforce&lt;/strong&gt; that &lt;strong&gt;boosts productivity&lt;/strong&gt; through parallel execution, customization, and privacy protection.&lt;/p&gt; 
&lt;h3&gt;‚≠ê 100% Open Source - ü•á Local Deployment - üèÜ MCP Integration&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Zero Setup&lt;/strong&gt; - No technical configuration required&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Multi-Agent Coordination&lt;/strong&gt; - Handle complex multi-agent workflows&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Enterprise Feature&lt;/strong&gt; - SSO/Access control&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Local Deploymen&lt;/strong&gt;t&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Open Source&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;Custom Model Support&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;‚úÖ &lt;strong&gt;MCP Integration&lt;/strong&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://eigent-ai.notion.site/eigent-ai-careers"&gt;&lt;img src="https://camel-ai.github.io/camel_asset/graphics/join_us.png" alt="" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;kbd&gt;Table of contents&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;h4&gt;TOC&lt;/h4&gt; 
 &lt;ul&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-getting-started"&gt;üöÄ Getting Started&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-local-deployment-recommended"&gt;üè† Local Deployment (Recommended)&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-quick-start-cloud-connected"&gt;‚ö° Quick Start (Cloud-Connected)&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-enterprise"&gt;üè¢ Enterprise&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#%EF%B8%8F-cloud-version"&gt;‚òÅÔ∏è Cloud Version&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-key-features"&gt;‚ú® Key features&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-workforce"&gt;üè≠ Workforce&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-comprehensive-model-support"&gt;üß† Comprehensive Model Support&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-mcp-tools-integration-mcp"&gt;üîå MCP Tools Integration (MCP)&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-human-in-the-loop"&gt;‚úã Human-in-the-Loop&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-100-open-source"&gt;üëê 100% Open Source&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-use-cases"&gt;üß© Use Cases&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-tech-stack"&gt;üõ†Ô∏è Tech Stack&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#backend"&gt;Backend&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#frontend"&gt;Frontend&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#staying-ahead"&gt;üåü&amp;nbsp;Staying ahead&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-roadmap"&gt;üó∫Ô∏è Roadmap&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-contributing"&gt;üìñ&amp;nbsp;Contributing&lt;/a&gt; 
   &lt;ul&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#main-contributors"&gt;Main Contributors&lt;/a&gt;&lt;/li&gt; 
    &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#distinguished-amabssador"&gt;Distinguished amabssador&lt;/a&gt;&lt;/li&gt; 
   &lt;/ul&gt; &lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#ecosystem"&gt;Ecosystem&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-open-source-license"&gt;üìÑ&amp;nbsp;Open Source License&lt;/a&gt;&lt;/li&gt; 
  &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-community--contact"&gt;üåê&amp;nbsp;Community &amp;amp; contact&lt;/a&gt;&lt;/li&gt; 
 &lt;/ul&gt; 
 &lt;h4&gt;&lt;/h4&gt; 
 &lt;br /&gt; 
&lt;/details&gt; 
&lt;h2&gt;&lt;strong&gt;üöÄ Getting Started&lt;/strong&gt;&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;&lt;strong&gt;üîì Build in Public&lt;/strong&gt; ‚Äî Eigent is &lt;strong&gt;100% open source&lt;/strong&gt; from day one. Every feature, every commit, every decision is transparent. We believe the best AI tools should be built openly with the community, not behind closed doors.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üè† Local Deployment (Recommended)&lt;/h3&gt; 
&lt;p&gt;The recommended way to run Eigent ‚Äî fully standalone with complete control over your data, no cloud account required.&lt;/p&gt; 
&lt;p&gt;üëâ &lt;strong&gt;&lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/server/README_EN.md"&gt;Full Local Deployment Guide&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;This setup includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Local backend server with full API&lt;/li&gt; 
 &lt;li&gt;Local model integration (vLLM, Ollama, LM Studio, etc.)&lt;/li&gt; 
 &lt;li&gt;Complete isolation from cloud services&lt;/li&gt; 
 &lt;li&gt;Zero external dependencies&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;‚ö° Quick Start (Cloud-Connected)&lt;/h3&gt; 
&lt;p&gt;For a quick preview using our cloud backend ‚Äî get started in seconds:&lt;/p&gt; 
&lt;h4&gt;Prerequisites&lt;/h4&gt; 
&lt;ul&gt; 
 &lt;li&gt;Node.js (version 18-22) and npm&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h4&gt;Steps&lt;/h4&gt; 
&lt;pre&gt;&lt;code class="language-bash"&gt;git clone https://github.com/eigent-ai/eigent.git
cd eigent
npm install
npm run dev
&lt;/code&gt;&lt;/pre&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;Note: This mode connects to Eigent cloud services and requires account registration. For a fully standalone experience, use &lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/#-local-deployment-recommended"&gt;Local Deployment&lt;/a&gt; instead.&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;h3&gt;üè¢ Enterprise&lt;/h3&gt; 
&lt;p&gt;For organizations requiring maximum security, customization, and control:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Exclusive Features&lt;/strong&gt; (like SSO &amp;amp; custom development)&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Scalable Enterprise Deployment&lt;/strong&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Negotiated SLAs&lt;/strong&gt; &amp;amp; implementation services&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;üìß For further details, please contact us at &lt;a href="mailto:info@eigent.ai"&gt;info@eigent.ai&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;‚òÅÔ∏è Cloud Version&lt;/h3&gt; 
&lt;p&gt;For teams who prefer managed infrastructure, we also offer a cloud platform. The fastest way to experience Eigent's multi-agent AI capabilities without setup complexity. We'll host the models, APIs, and cloud storage, ensuring Eigent runs flawlessly.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Instant Access&lt;/strong&gt; - Start building multi-agent workflows in minutes.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Managed Infrastructure&lt;/strong&gt; - We handle scaling, updates, and maintenance.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Premium Support&lt;/strong&gt; - Subscribe and get priority assistance from our engineering team.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;br /&gt; 
&lt;p&gt;&lt;a href="https://www.eigent.ai/download"&gt;&lt;img src="https://eigent-ai.github.io/.github/assets/banner.png" alt="image-public-beta" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;div align="right"&gt; 
 &lt;a href="https://www.eigent.ai/download"&gt;Get started at Eigent.ai ‚Üí&lt;/a&gt; 
&lt;/div&gt; 
&lt;h2&gt;&lt;strong&gt;‚ú® Key features&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;Unlock the full potential of exceptional productivity with Eigent‚Äôs powerful features‚Äîbuilt for seamless integration, smarter task execution, and boundless automation.&lt;/p&gt; 
&lt;h3&gt;üè≠ Workforce&lt;/h3&gt; 
&lt;p&gt;Employs a team of specialized AI agents that collaborate to solve complex tasks. Eigent dynamically breaks down tasks and activates multiple agents to work&amp;nbsp;&lt;strong&gt;in parallel.&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Eigent pre-defined the following agent workers:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Developer Agent:&lt;/strong&gt;&amp;nbsp;Writes and executes code, runs terminal commands.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Search Agent:&lt;/strong&gt;&amp;nbsp;Searches the web and extracts content.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Document Agent:&lt;/strong&gt;&amp;nbsp;Creates and manages documents.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-Modal Agent:&lt;/strong&gt;&amp;nbsp;Processes images and audio.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;&lt;img src="https://eigent-ai.github.io/.github/assets/gif/feature_dynamic_workforce.gif" alt="Workforce" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;üß† Comprehensive Model Support&lt;/h3&gt; 
&lt;p&gt;Deploy Eigent locally with your preferred models.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://eigent-ai.github.io/.github/assets/gif/feature_local_model.gif" alt="Model" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;üîå MCP Tools Integration (MCP)&lt;/h3&gt; 
&lt;p&gt;Eigent comes with massive built-in&amp;nbsp;&lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt;&amp;nbsp;tools (for web browsing, code execution, Notion, Google suite, Slack etc.), and also lets you&amp;nbsp;&lt;strong&gt;install your own tools&lt;/strong&gt;. Equip agents with exactly the right tools for your scenarios ‚Äì even integrate internal APIs or custom functions ‚Äì to enhance their capabilities.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://eigent-ai.github.io/.github/assets/gif/feature_add_mcps.gif" alt="MCP" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;‚úã Human-in-the-Loop&lt;/h3&gt; 
&lt;p&gt;If a task gets stuck or encounters uncertainty, Eigent will automatically request human input.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://eigent-ai.github.io/.github/assets/gif/feature_human_in_the_loop.gif" alt="Human-in-the-loop" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h3&gt;üëê 100% Open Source&lt;/h3&gt; 
&lt;p&gt;Eigent is completely open-sourced. You can download, inspect, and modify the code, ensuring transparency and fostering a community-driven ecosystem for multi-agent innovation.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://eigent-ai.github.io/.github/assets/opensource.png" alt="Opensource" /&gt;&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;üß© Use Cases&lt;/h2&gt; 
&lt;h3&gt;1. Palm Springs Tennis Trip Itinerary with Slack Summary &lt;a href="https://www.eigent.ai/download?share_token=IjE3NTM0MzUxNTEzMzctNzExMyI.aIeysw.MUeG6ZcBxI1GqvPDvn4dcv-CDWw__1753435151337-7113"&gt;Replay ‚ñ∂Ô∏è&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; &lt;kbd&gt;We are two tennis fans and want to go see the tennis tournament ... &lt;kbd&gt;&lt;/kbd&gt;&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;br /&gt; We are two tennis fans and want to go see the tennis tournament in Palm Springs 2026. I live in SF - please prepare a detailed itinerary with flights, hotels, things to do for 3 days - around the time semifinal/finals are happening. We like hiking, vegan food and spas. Our budget is $5K. The itinerary should be a detailed timeline of time, activity, cost, other details and if applicable a link to buy tickets/make reservations etc. for the item. Some preferences .Spa access would be nice but not necessary. When you finish this task, please generate a html report about this trip; write a summary of this plan and send text summary and report html link to slack #tennis-trip-sf channel. 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h3&gt;2. Generate Q2 Report from CSV Bank Data &lt;a href="https://www.eigent.ai/download?share_token=IjE3NTM1MjY4OTE4MDgtODczOSI.aIjJmQ.WTdoX9mATwrcBr_w53BmGEHPo8U__1753526891808-8739"&gt;Replay ‚ñ∂Ô∏è&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; &lt;kbd&gt;Please help me prepare a Q2 financial statement based on my bank ... &lt;kbd&gt;&lt;/kbd&gt;&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;br /&gt; Please help me prepare a Q2 financial statement based on my bank transfer record file bank_transacation.csv in my desktop to a html report with chart to investors how much we have spent. 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h3&gt;3. UK Healthcare Market Research Report Automation &lt;a href="https://www.eigent.ai/download?share_token=IjE3NTMzOTM1NTg3OTctODcwNyI.aIey-Q.Jh9QXzYrRYarY0kz_qsgoj3ewX0__1753393558797-8707"&gt;Replay ‚ñ∂Ô∏è&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; &lt;kbd&gt;Analyze the UK healthcare industry to support the planning ... &lt;kbd&gt;&lt;/kbd&gt;&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;br /&gt; Analyze the UK healthcare industry to support the planning of my next company. Provide a comprehensive market overview, including current trends, growth projections, and relevant regulations. Identify the top 5‚Äì10 major opportunities, gaps, or underserved segments within the market. Present all findings in a well-structured, professional HTML report. Then send a message to slack #eigentr-product-test channel when this task is done to align the report content with my teammates. 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h3&gt;4. German Electric Skateboard Market Feasibility &lt;a href="https://www.eigent.ai/download?share_token=IjE3NTM2NTI4MjY3ODctNjk2Ig.aIjGiA.t-qIXxk_BZ4ENqa-yVIm0wMVyXU__1753652826787-696"&gt;Replay ‚ñ∂Ô∏è&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; &lt;kbd&gt;We are a company that produces high-end electric skateboards ... &lt;kbd&gt;&lt;/kbd&gt;&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;br /&gt; We are a company that produces high-end electric skateboards, and we are considering entering the German market. Please prepare a detailed market entry feasibility report for me. The report needs to cover the following aspects: 1. Market Size &amp;amp; Regulations: Research the market size, annual growth rate, key players, and market share for Personal Light Electric Vehicles (PLEVs) in Germany. Simultaneously, provide a detailed breakdown and summary of German laws and regulations concerning the use of electric skateboards on public roads, including certification requirements (such as ABE certification) and insurance policies. 2. Consumer Profile: Analyze the profile of potential German consumers, including their age, income level, primary usage scenarios (commuting, recreation), key purchasing decision drivers (price, performance, brand, design), and the channels they typically use to gather information (forums, social media, offline retail stores). 3. Channels &amp;amp; Distribution: Investigate Germany‚Äôs mainstream online electronics sales platforms (e.g., Amazon.de, MediaMarkt.de) and high-end sporting goods offline retail chains. List the top 5 potential online and offline distribution partners and find the contact information for their purchasing departments, if possible. 4. Costing &amp;amp; Pricing: Based on the product cost structure in my Product_Cost.csv file on my desktop, and taking into account German customs duties, Value Added Tax (VAT), logistics and warehousing costs, and potential marketing expenses, estimate a Manufacturer‚Äôs Suggested Retail Price (MSRP) and analyze its competitiveness in the market. 5. Comprehensive Report &amp;amp; Presentation: Summarize all research findings into an HTML report file. The content should include data charts, key findings, and a final market entry strategy recommendation (Recommended / Not Recommended / Recommended with Conditions). 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h3&gt;5. SEO Audit for Workforce Multiagent Launch &lt;a href="https://www.eigent.ai/download?share_token=IjE3NTM2OTk5NzExNDQtNTY5NiI.aIex0w.jc_NIPmfIf9e3zGt-oG9fbMi3K4__1753699971144-5696"&gt;Replay ‚ñ∂Ô∏è&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; &lt;kbd&gt;To support the launch of our new Workforce Multiagent product ... &lt;kbd&gt;&lt;/kbd&gt;&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;br /&gt; To support the launch of our new Workforce Multiagent product, please run a thorough SEO audit on our official website (https://www.camel-ai.org/) and deliver a detailed optimization report with actionable recommendations. 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h3&gt;6. Identify Duplicate Files in Downloads &lt;a href="https://www.eigent.ai/download?share_token=IjE3NTM3NjAzODgxNzEtMjQ4Ig.aIhKLQ.epOG--0Nj0o4Bqjtdqm9OZdaqRQ__1753760388171-248"&gt;Replay ‚ñ∂Ô∏è&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; &lt;kbd&gt;I have a folder named mydocs inside my Documents directory ... &lt;kbd&gt;&lt;/kbd&gt;&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;br /&gt; I have a folder named mydocs inside my Documents directory. Please scan it and identify all files that are exact or near duplicates ‚Äî including those with identical content, file size, or format (even if file names or extensions differ). List them clearly, grouped by similarity. 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h3&gt;7. Add Signature to PDF &lt;a href="https://www.eigent.ai/download?share_token=IjE3NTQwOTU0ODM0NTItNTY2MSI.aJCHrA.Mg5yPOFqj86H_GQvvRNditzepXc__1754095483452-5661"&gt;Replay ‚ñ∂Ô∏è&lt;/a&gt;&lt;/h3&gt; 
&lt;details&gt; 
 &lt;summary&gt;&lt;strong&gt;Prompt:&lt;/strong&gt; &lt;kbd&gt;Please add this signature image to the Signature Areas in the PDF ... &lt;kbd&gt;&lt;/kbd&gt;&lt;/kbd&gt;&lt;/summary&gt; 
 &lt;br /&gt; Please add this signature image to the Signature Areas in the PDF. You could install the CLI tool ‚Äòtesseract‚Äô (needed for reliable location of ‚ÄòSignature Areas‚Äô via OCR) to help finish this task. 
&lt;/details&gt; 
&lt;br /&gt; 
&lt;h2&gt;üõ†Ô∏è Tech Stack&lt;/h2&gt; 
&lt;h3&gt;Backend&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework:&lt;/strong&gt;&amp;nbsp;FastAPI&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Package Manager:&lt;/strong&gt;&amp;nbsp;uv&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Async Server:&lt;/strong&gt;&amp;nbsp;Uvicorn&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Authentication:&lt;/strong&gt;&amp;nbsp;OAuth 2.0, Passlib.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Multi-agent framework:&lt;/strong&gt; CAMEL&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Frontend&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Framework:&lt;/strong&gt;&amp;nbsp;React&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Desktop App Framework:&lt;/strong&gt;&amp;nbsp;Electron&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Language:&lt;/strong&gt;&amp;nbsp;TypeScript&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;UI:&lt;/strong&gt;&amp;nbsp;Tailwind CSS, Radix UI, Lucide React, Framer Motion&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;State Management:&lt;/strong&gt;&amp;nbsp;Zustand&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Flow Editor:&lt;/strong&gt;&amp;nbsp;React Flow&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;üåü&amp;nbsp;Staying ahead&lt;/h2&gt; 
&lt;blockquote&gt; 
 &lt;p&gt;[!IMPORTANT]&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Star Eigent&lt;/strong&gt;, You will receive all release notifications from GitHub without any delay ~ ‚≠êÔ∏è&lt;/p&gt; 
&lt;/blockquote&gt; 
&lt;p&gt;&lt;img src="https://eigent-ai.github.io/.github/assets/star-us.gif" alt="" /&gt;&lt;/p&gt; 
&lt;h2&gt;üó∫Ô∏è Roadmap&lt;/h2&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Topics&lt;/th&gt; 
   &lt;th&gt;Issues&lt;/th&gt; 
   &lt;th&gt;Discord Channel&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Context Engineering&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;- Prompt caching&lt;br /&gt; - System prompt optimize&lt;br /&gt; - Toolkit docstring optimize&lt;br /&gt; - Context compression&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/D2e3rBWD"&gt;&lt;strong&gt;Join Discord ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Multi-modal Enhancement&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;- More accurate image understanding when using browser&lt;br /&gt; - Advanced video generation&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/kyapNCeJ"&gt;&lt;strong&gt;Join Discord ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Multi-agent system&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;- Workforce support fixed workflow&lt;br /&gt; - Workforce support multi-round conversion&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/bFRmPuDB"&gt;&lt;strong&gt;Join Discord ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Browser Toolkit&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;- BrowseCamp integration&lt;br /&gt; - Benchmark improvement&lt;br /&gt; - Forbid repeated page visiting&lt;br /&gt; - Automatic cache button clicking&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/NF73ze5v"&gt;&lt;strong&gt;Join Discord ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Document Toolkit&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;- Support dynamic file editing&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/4yAWJxYr"&gt;&lt;strong&gt;Join Discord ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Terminal Toolkit&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;- Benchmark improvement&lt;br /&gt; - Terminal-Bench integration&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/FjQfnsrV"&gt;&lt;strong&gt;Join Discord ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;strong&gt;Environment &amp;amp; RL&lt;/strong&gt;&lt;/td&gt; 
   &lt;td&gt;- Environment design&lt;br /&gt; - Data-generation&lt;br /&gt; - RL framework integration (VERL, TRL, OpenRLHF)&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://discord.gg/MaVZXEn8"&gt;&lt;strong&gt;Join Discord ‚Üí&lt;/strong&gt;&lt;/a&gt;&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;&lt;a href="https://github.com/eigent-ai/eigent/raw/main/CONTRIBUTING.md"&gt;ü§ù Contributing&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;We believe in building trust and embracing all forms of open-source collaborations. Your creative contributions help drive the innovation of &lt;code&gt;Eigent&lt;/code&gt;. Explore our GitHub issues and projects to dive in and show us what you‚Äôve got ü§ù‚ù§Ô∏è &lt;a href="https://github.com/eigent-ai/eigent/raw/main/CONTRIBUTING.md"&gt;Contribution Guideline&lt;/a&gt;&lt;/p&gt; 
&lt;h2&gt;Contributors&lt;/h2&gt; 
&lt;a href="https://github.com/eigent-ai/eigent/graphs/contributors"&gt; &lt;img src="https://contrib.rocks/image?repo=eigent-ai/eigent" /&gt; &lt;/a&gt; 
&lt;p&gt;Made with &lt;a href="https://contrib.rocks"&gt;contrib.rocks&lt;/a&gt;.&lt;/p&gt; 
&lt;br /&gt; 
&lt;h2&gt;&lt;a href="https://github.com/sponsors/camel-ai"&gt;‚ù§Ô∏è Sponsor&lt;/a&gt;&lt;/h2&gt; 
&lt;p&gt;Eigent is built on top of &lt;a href="https://github.com/camel-ai"&gt;CAMEL-AI.org&lt;/a&gt;'s research and infrastructures. &lt;a href="https://github.com/sponsors/camel-ai"&gt;Sponsoring CAMEL-AI.org&lt;/a&gt; will make &lt;code&gt;Eigent&lt;/code&gt; better.&lt;/p&gt; 
&lt;h2&gt;&lt;strong&gt;üìÑ&amp;nbsp;Open Source License&lt;/strong&gt;&lt;/h2&gt; 
&lt;p&gt;This repository is licensed under the &lt;a href="https://raw.githubusercontent.com/eigent-ai/eigent/main/LICENSE"&gt;Apache License 2.0&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;üåê Community &amp;amp; Contact&lt;/h2&gt; 
&lt;p&gt;For more information please contact &lt;a href="mailto:info@eigent.ai"&gt;info@eigent.ai&lt;/a&gt;&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;GitHub Issues:&lt;/strong&gt; Report bugs, request features, and track development. &lt;a href="https://github.com/eigent-ai/eigent/issues"&gt;Submit an issue&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Discord:&lt;/strong&gt; Get real-time support, chat with the community, and stay updated. &lt;a href="https://discord.camel-ai.org/"&gt;Join us&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;X (Twitter):&lt;/strong&gt; Follow for updates, AI insights, and key announcements. &lt;a href="https://x.com/Eigent_AI"&gt;Follow us&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;WeChat Community:&lt;/strong&gt; Scan the QR code below to add our WeChat assistant, and join our WeChat community group.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;div align="center"&gt; 
 &lt;img src="https://raw.githubusercontent.com/eigent-ai/eigent/main/src/assets/wechat_qr.jpg" width="200" style="display: inline-block; margin: 10px;" /&gt; 
&lt;/div&gt; 
&lt;!-- LINK GROUP --&gt; 
&lt;!-- Social --&gt; 
&lt;!-- camel &amp; eigent --&gt; 
&lt;!-- marketing --&gt; 
&lt;!-- feature --&gt;</description>
    </item>
    
    <item>
      <title>google-ai-edge/mediapipe</title>
      <link>https://github.com/google-ai-edge/mediapipe</link>
      <description>&lt;p&gt;Cross-platform, customizable ML solutions for live and streaming media.&lt;/p&gt;&lt;hr&gt;&lt;hr /&gt; 
&lt;h2&gt;layout: forward target: &lt;a href="https://developers.google.com/mediapipe"&gt;https://developers.google.com/mediapipe&lt;/a&gt; title: Home nav_order: 1&lt;/h2&gt; 
&lt;hr /&gt; 
&lt;p&gt;&lt;strong&gt;Attention:&lt;/strong&gt; &lt;em&gt;We have moved to &lt;a href="https://developers.google.com/mediapipe"&gt;https://developers.google.com/mediapipe&lt;/a&gt; as the primary developer documentation site for MediaPipe as of April 3, 2023.&lt;/em&gt;&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://developers.google.com/static/mediapipe/images/home/hero_01_1920.png" alt="MediaPipe" /&gt;&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;Attention&lt;/strong&gt;: MediaPipe Solutions Preview is an early release. &lt;a href="https://developers.google.com/mediapipe/solutions/about#notice"&gt;Learn more&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;&lt;strong&gt;On-device machine learning for everyone&lt;/strong&gt;&lt;/p&gt; 
&lt;p&gt;Delight your customers with innovative machine learning features. MediaPipe contains everything that you need to customize and deploy to mobile (Android, iOS), web, desktop, edge devices, and IoT, effortlessly.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://goo.gle/mediapipe-studio"&gt;See demos&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.google.com/mediapipe/solutions"&gt;Learn more&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Get started&lt;/h2&gt; 
&lt;p&gt;You can get started with MediaPipe Solutions by by checking out any of the developer guides for &lt;a href="https://developers.google.com/mediapipe/solutions/vision/object_detector"&gt;vision&lt;/a&gt;, &lt;a href="https://developers.google.com/mediapipe/solutions/text/text_classifier"&gt;text&lt;/a&gt;, and &lt;a href="https://developers.google.com/mediapipe/solutions/audio/audio_classifier"&gt;audio&lt;/a&gt; tasks. If you need help setting up a development environment for use with MediaPipe Tasks, check out the setup guides for &lt;a href="https://developers.google.com/mediapipe/solutions/setup_android"&gt;Android&lt;/a&gt;, &lt;a href="https://developers.google.com/mediapipe/solutions/setup_web"&gt;web apps&lt;/a&gt;, and &lt;a href="https://developers.google.com/mediapipe/solutions/setup_python"&gt;Python&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Solutions&lt;/h2&gt; 
&lt;p&gt;MediaPipe Solutions provides a suite of libraries and tools for you to quickly apply artificial intelligence (AI) and machine learning (ML) techniques in your applications. You can plug these solutions into your applications immediately, customize them to your needs, and use them across multiple development platforms. MediaPipe Solutions is part of the MediaPipe &lt;a href="https://github.com/google/mediapipe"&gt;open source project&lt;/a&gt;, so you can further customize the solutions code to meet your application needs.&lt;/p&gt; 
&lt;p&gt;These libraries and resources provide the core functionality for each MediaPipe Solution:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MediaPipe Tasks&lt;/strong&gt;: Cross-platform APIs and libraries for deploying solutions. &lt;a href="https://developers.google.com/mediapipe/solutions/tasks"&gt;Learn more&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MediaPipe models&lt;/strong&gt;: Pre-trained, ready-to-run models for use with each solution.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;These tools let you customize and evaluate solutions:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;MediaPipe Model Maker&lt;/strong&gt;: Customize models for solutions with your data. &lt;a href="https://developers.google.com/mediapipe/solutions/model_maker"&gt;Learn more&lt;/a&gt;.&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;MediaPipe Studio&lt;/strong&gt;: Visualize, evaluate, and benchmark solutions in your browser. &lt;a href="https://developers.google.com/mediapipe/solutions/studio"&gt;Learn more&lt;/a&gt;.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Legacy solutions&lt;/h3&gt; 
&lt;p&gt;We have ended support for &lt;a href="https://developers.google.com/mediapipe/solutions/guide#legacy"&gt;these MediaPipe Legacy Solutions&lt;/a&gt; as of March 1, 2023. All other MediaPipe Legacy Solutions will be upgraded to a new MediaPipe Solution. See the &lt;a href="https://developers.google.com/mediapipe/solutions/guide#legacy"&gt;Solutions guide&lt;/a&gt; for details. The &lt;a href="https://github.com/google/mediapipe/tree/master/mediapipe"&gt;code repository&lt;/a&gt; and prebuilt binaries for all MediaPipe Legacy Solutions will continue to be provided on an as-is basis.&lt;/p&gt; 
&lt;p&gt;For more on the legacy solutions, see the &lt;a href="https://github.com/google/mediapipe/tree/master/docs/solutions"&gt;documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Framework&lt;/h2&gt; 
&lt;p&gt;To start using MediaPipe Framework, &lt;a href="https://developers.google.com/mediapipe/framework/getting_started/install"&gt;install MediaPipe Framework&lt;/a&gt; and start building example applications in C++, Android, and iOS.&lt;/p&gt; 
&lt;p&gt;&lt;a href="https://developers.google.com/mediapipe/framework"&gt;MediaPipe Framework&lt;/a&gt; is the low-level component used to build efficient on-device machine learning pipelines, similar to the premade MediaPipe Solutions.&lt;/p&gt; 
&lt;p&gt;Before using MediaPipe Framework, familiarize yourself with the following key &lt;a href="https://developers.google.com/mediapipe/framework/framework_concepts/overview.md"&gt;Framework concepts&lt;/a&gt;:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developers.google.com/mediapipe/framework/framework_concepts/packets.md"&gt;Packets&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.google.com/mediapipe/framework/framework_concepts/graphs.md"&gt;Graphs&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.google.com/mediapipe/framework/framework_concepts/calculators.md"&gt;Calculators&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://mediapipe.page.link/joinslack"&gt;Slack community&lt;/a&gt; for MediaPipe users.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://groups.google.com/forum/#!forum/mediapipe"&gt;Discuss&lt;/a&gt; - General community discussion around MediaPipe.&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://mediapipe.page.link/awesome-mediapipe"&gt;Awesome MediaPipe&lt;/a&gt; - A curated list of awesome MediaPipe related frameworks, libraries and software.&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We welcome contributions. Please follow these &lt;a href="https://github.com/google/mediapipe/raw/master/CONTRIBUTING.md"&gt;guidelines&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;We use GitHub issues for tracking requests and bugs. Please post questions to the MediaPipe Stack Overflow with a &lt;code&gt;mediapipe&lt;/code&gt; tag.&lt;/p&gt; 
&lt;h2&gt;Resources&lt;/h2&gt; 
&lt;h3&gt;Publications&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://developers.googleblog.com/2021/07/bringing-artworks-to-life-with-ar.html"&gt;Bringing artworks to life with AR&lt;/a&gt; in Google Developers Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.googleblog.com/2021/05/control-your-mirru-prosthesis-with-mediapipe-hand-tracking.html"&gt;Prosthesis control via Mirru App using MediaPipe hand tracking&lt;/a&gt; in Google Developers Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.googleblog.com/2021/04/signall-sdk-sign-language-interface-using-mediapipe-now-available.html"&gt;SignAll SDK: Sign language interface using MediaPipe is now available for developers&lt;/a&gt; in Google Developers Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ai.googleblog.com/2020/12/mediapipe-holistic-simultaneous-face.html"&gt;MediaPipe Holistic - Simultaneous Face, Hand and Pose Prediction, on Device&lt;/a&gt; in Google AI Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ai.googleblog.com/2020/10/background-features-in-google-meet.html"&gt;Background Features in Google Meet, Powered by Web ML&lt;/a&gt; in Google AI Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.googleblog.com/2020/09/mediapipe-3d-face-transform.html"&gt;MediaPipe 3D Face Transform&lt;/a&gt; in Google Developers Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.googleblog.com/2020/08/instant-motion-tracking-with-mediapipe.html"&gt;Instant Motion Tracking With MediaPipe&lt;/a&gt; in Google Developers Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ai.googleblog.com/2020/08/on-device-real-time-body-pose-tracking.html"&gt;BlazePose - On-device Real-time Body Pose Tracking&lt;/a&gt; in Google AI Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ai.googleblog.com/2020/08/mediapipe-iris-real-time-iris-tracking.html"&gt;MediaPipe Iris: Real-time Eye Tracking and Depth Estimation&lt;/a&gt; in Google AI Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.googleblog.com/2020/04/mediapipe-knift-template-based-feature-matching.html"&gt;MediaPipe KNIFT: Template-based feature matching&lt;/a&gt; in Google Developers Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.googleblog.com/2020/03/alfred-camera-smart-camera-features-using-mediapipe.html"&gt;Alfred Camera: Smart camera features using MediaPipe&lt;/a&gt; in Google Developers Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ai.googleblog.com/2020/03/real-time-3d-object-detection-on-mobile.html"&gt;Real-Time 3D Object Detection on Mobile Devices with MediaPipe&lt;/a&gt; in Google AI Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ai.googleblog.com/2020/02/autoflip-open-source-framework-for.html"&gt;AutoFlip: An Open Source Framework for Intelligent Video Reframing&lt;/a&gt; in Google AI Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.googleblog.com/2020/01/mediapipe-on-web.html"&gt;MediaPipe on the Web&lt;/a&gt; in Google Developers Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://developers.googleblog.com/2019/12/object-detection-and-tracking-using-mediapipe.html"&gt;Object Detection and Tracking using MediaPipe&lt;/a&gt; in Google Developers Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html"&gt;On-Device, Real-Time Hand Tracking with MediaPipe&lt;/a&gt; in Google AI Blog&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://arxiv.org/abs/1906.08172"&gt;MediaPipe: A Framework for Building Perception Pipelines&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h3&gt;Videos&lt;/h3&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://www.youtube.com/c/MediaPipe"&gt;YouTube Channel&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>cilium/cilium</title>
      <link>https://github.com/cilium/cilium</link>
      <description>&lt;p&gt;eBPF-based Networking, Security, and Observability&lt;/p&gt;&lt;hr&gt;&lt;p&gt;.. raw:: html&lt;/p&gt; 
&lt;picture&gt; 
 &lt;source media="(prefers-color-scheme: light)" srcset="https://cdn.jsdelivr.net/gh/cilium/cilium@main/Documentation/images/logo.png" width="350" alt="Cilium Logo" /&gt; 
 &lt;img src="https://cdn.jsdelivr.net/gh/cilium/cilium@main/Documentation/images/logo-dark.png" width="350" alt="Cilium Logo" /&gt; 
&lt;/picture&gt; 
&lt;p&gt;|cii| |go-report| |clomonitor| |artifacthub| |slack| |go-doc| |rtd| |apache| |bsd| |gpl| |fossa| |gateway-api| |codespaces|&lt;/p&gt; 
&lt;p&gt;Cilium is a networking, observability, and security solution with an eBPF-based dataplane. It provides a simple flat Layer 3 network with the ability to span multiple clusters in either a native routing or overlay mode. It is L7-protocol aware and can enforce network policies on L3-L7 using an identity based security model that is decoupled from network addressing.&lt;/p&gt; 
&lt;p&gt;Cilium implements distributed load balancing for traffic between pods and to external services, and is able to fully replace kube-proxy, using efficient hash tables in eBPF allowing for almost unlimited scale. It also supports advanced functionality like integrated ingress and egress gateway, bandwidth management and service mesh, and provides deep network and security visibility and monitoring.&lt;/p&gt; 
&lt;p&gt;A new Linux kernel technology called eBPF_ is at the foundation of Cilium. It supports dynamic insertion of eBPF bytecode into the Linux kernel at various integration points such as: network IO, application sockets, and tracepoints to implement security, networking and visibility logic. eBPF is highly efficient and flexible. To learn more about eBPF, visit &lt;code&gt;eBPF.io&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;.. image:: Documentation/images/cilium-overview.png :alt: Overview of Cilium features for networking, observability, service mesh, and runtime security&lt;/p&gt; 
&lt;p&gt;.. raw:: html&lt;/p&gt; 
&lt;a href="https://cncf.io/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset="https://github.com/cncf/artwork/blob/main/other/cncf-member/graduated/color/cncf-graduated-color.svg" /&gt; 
  &lt;img src="https://github.com/cncf/artwork/raw/main/other/cncf-member/graduated/white/cncf-graduated-white.svg?sanitize=true" alt="CNCF Graduated Project" height="80" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;a href="https://ebpf.io/"&gt; 
 &lt;picture&gt; 
  &lt;source media="(prefers-color-scheme: light)" srcset=".github/assets/ebpf-horizontal.svg" /&gt; 
  &lt;img src="https://raw.githubusercontent.com/cilium/cilium/main/.github/assets/ebpf-horizontal-dark-back.svg?sanitize=true" alt="eBPF Logo" height="80" align="right" /&gt; 
 &lt;/picture&gt; &lt;/a&gt; 
&lt;h1&gt;Stable Releases&lt;/h1&gt; 
&lt;p&gt;The Cilium community maintains minor stable releases for the last three minor Cilium versions. Older Cilium stable versions from minor releases prior to that are considered EOL.&lt;/p&gt; 
&lt;p&gt;For upgrades to new minor releases please consult the &lt;code&gt;Cilium Upgrade Guide&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;Listed below are the actively maintained release branches along with their latest patch release, corresponding image pull tags and their release notes:&lt;/p&gt; 
&lt;p&gt;+---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+ | &lt;code&gt;v1.18 &amp;lt;https://github.com/cilium/cilium/tree/v1.18&amp;gt;&lt;/code&gt;__ | 2026-01-13 | &lt;code&gt;quay.io/cilium/cilium:v1.18.6&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.18.6&amp;gt;&lt;/code&gt;__ | +---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+ | &lt;code&gt;v1.17 &amp;lt;https://github.com/cilium/cilium/tree/v1.17&amp;gt;&lt;/code&gt;__ | 2026-01-13 | &lt;code&gt;quay.io/cilium/cilium:v1.17.12&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.17.12&amp;gt;&lt;/code&gt;__ | +---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+ | &lt;code&gt;v1.16 &amp;lt;https://github.com/cilium/cilium/tree/v1.16&amp;gt;&lt;/code&gt;__ | 2026-01-13 | &lt;code&gt;quay.io/cilium/cilium:v1.16.19&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.16.19&amp;gt;&lt;/code&gt;__ | +---------------------------------------------------------+------------+------------------------------------+----------------------------------------------------------------------------+&lt;/p&gt; 
&lt;h2&gt;Architectures&lt;/h2&gt; 
&lt;p&gt;Cilium images are distributed for AMD64 and AArch64 architectures.&lt;/p&gt; 
&lt;h2&gt;Software Bill of Materials&lt;/h2&gt; 
&lt;p&gt;Starting with Cilium version 1.13.0, all images include a Software Bill of Materials (SBOM). The SBOM is generated in &lt;code&gt;SPDX&lt;/code&gt;_ format. More information on this is available on &lt;code&gt;Cilium SBOM&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;.. _&lt;code&gt;SPDX&lt;/code&gt;: &lt;a href="https://spdx.dev/"&gt;https://spdx.dev/&lt;/a&gt; .. _&lt;code&gt;Cilium SBOM&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/latest/configuration/sbom/"&gt;https://docs.cilium.io/en/latest/configuration/sbom/&lt;/a&gt;&lt;/p&gt; 
&lt;h1&gt;Development&lt;/h1&gt; 
&lt;p&gt;For development and testing purpose, the Cilium community publishes snapshots, early release candidates (RC) and CI container images build from the &lt;code&gt;main branch &amp;lt;https://github.com/cilium/cilium/commits/main&amp;gt;&lt;/code&gt;_. These images are not for use in production.&lt;/p&gt; 
&lt;p&gt;For testing upgrades to new development releases please consult the latest development build of the &lt;code&gt;Cilium Upgrade Guide&lt;/code&gt;_.&lt;/p&gt; 
&lt;p&gt;Listed below are branches for testing along with their snapshots or RC releases, corresponding image pull tags and their release notes where applicable:&lt;/p&gt; 
&lt;p&gt;+----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+ | &lt;code&gt;main &amp;lt;https://github.com/cilium/cilium/commits/main&amp;gt;&lt;/code&gt;__ | daily | &lt;code&gt;quay.io/cilium/cilium-ci:latest&lt;/code&gt; | N/A | +----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+ | &lt;code&gt;v1.19.0-rc.0 &amp;lt;https://github.com/cilium/cilium/commits/v1.19.0-rc.0&amp;gt;&lt;/code&gt;__ | 2026-01-15 | &lt;code&gt;quay.io/cilium/cilium:v1.19.0-rc.0&lt;/code&gt; | &lt;code&gt;Release Notes &amp;lt;https://github.com/cilium/cilium/releases/tag/v1.19.0-rc.0&amp;gt;&lt;/code&gt;__ | +----------------------------------------------------------------------------+------------+-----------------------------------------+---------------------------------------------------------------------------------+&lt;/p&gt; 
&lt;h1&gt;Functionality Overview&lt;/h1&gt; 
&lt;p&gt;.. begin-functionality-overview&lt;/p&gt; 
&lt;h2&gt;CNI (Container Network Interface)&lt;/h2&gt; 
&lt;p&gt;&lt;code&gt;Cilium as a CNI plugin &amp;lt;https://cilium.io/use-cases/cni/&amp;gt;&lt;/code&gt;_ provides a fast, scalable, and secure networking layer for Kubernetes clusters. Built on eBPF, it offers several deployment options:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Overlay networking:&lt;/strong&gt; encapsulation-based virtual network spanning all hosts with support for VXLAN and Geneve. It works on almost any network infrastructure as the only requirement is IP connectivity between hosts which is typically already given.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Native routing mode:&lt;/strong&gt; Use of the regular routing table of the Linux host. The network is required to be capable of routing the IP addresses of the application containers. It integrates with cloud routers, routing daemons, and IPv6-native infrastructure.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Flexible routing options:&lt;/strong&gt; Cilium can automate route learning and advertisement in common topologies such as using L2 neighbor discovery when nodes share a layer 2 domain, or BGP when routing across layer 3 boundaries.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Each mode is designed for maximum interoperability with existing infrastructure while minimizing operational burden.&lt;/p&gt; 
&lt;h2&gt;Load Balancing&lt;/h2&gt; 
&lt;p&gt;Cilium implements distributed load balancing for traffic between application containers and to/from external services. The load balancing is implemented in eBPF using efficient hashtables enabling high service density and low latency at scale.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;East-west load balancing&lt;/strong&gt; rewrites service connections at the socket level (&lt;code&gt;connect()&lt;/code&gt;), avoiding the overhead of per-packet NAT and fully &lt;code&gt;replacing kube-proxy &amp;lt;https://cilium.io/use-cases/kube-proxy/&amp;gt;&lt;/code&gt;_.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;North-south load balancing&lt;/strong&gt; supports XDP for high-throughput scenarios and &lt;code&gt;layer 4 load balancing &amp;lt;https://cilium.io/use-cases/load-balancer/&amp;gt;&lt;/code&gt;_ including Direct Server Return (DSR), and Maglev consistent hashing.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Cluster Mesh&lt;/h2&gt; 
&lt;p&gt;Cilium &lt;code&gt;Cluster Mesh &amp;lt;https://cilium.io/use-cases/cluster-mesh/&amp;gt;&lt;/code&gt;_ enables secure, seamless connectivity across multiple Kubernetes clusters. For operators running hybrid or multi-cloud environments, Cluster Mesh ensures a consistent security and connectivity experience.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Global service discovery&lt;/strong&gt;: Workloads across clusters can discover and connect to services as if they were local. This enables fault tolerance, like automatically failing over to backends in another cluster, and exposes shared services like logging, auth, or databases across environments.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Unified identity model:&lt;/strong&gt; Security policies are enforced based on identity, not IP address, across all clusters.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Network Policy&lt;/h2&gt; 
&lt;p&gt;Cilium &lt;code&gt;Network Policy &amp;lt;https://cilium.io/use-cases/network-policy/&amp;gt;&lt;/code&gt;_ provides identity-aware enforcement across L3-L7. Typical container firewalls secure workloads by filtering on source IP addresses and destination ports. This concept requires the firewalls on all servers to be manipulated whenever a container is started anywhere in the cluster.&lt;/p&gt; 
&lt;p&gt;In order to avoid this situation which limits scale, Cilium assigns a security identity to groups of application containers which share identical security policies. The identity is then associated with all network packets emitted by the application containers, allowing to validate the identity at the receiving node.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Identity-based security&lt;/strong&gt; removes reliance on brittle IP addresses.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L3/L4 policies&lt;/strong&gt; restrict traffic based on labels, protocols, and ports.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;DNS-based policies:&lt;/strong&gt; Allow or deny traffic to FQDNs or wildcard domains (e.g., &lt;code&gt;api.example.com&lt;/code&gt;, &lt;code&gt;*.trusted.com&lt;/code&gt;). This is especially useful for securing egress traffic to third-party services.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L7-aware policies&lt;/strong&gt; allow filtering by HTTP method, URL path, gRPC call, and more:&lt;/p&gt; 
  &lt;ul&gt; 
   &lt;li&gt; &lt;p&gt;Example: Allow only GET requests to &lt;code&gt;/public/.*&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
   &lt;li&gt; &lt;p&gt;Enforce the presence of headers like &lt;code&gt;X-Token: [0-9]+&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; 
  &lt;/ul&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;CIDR-based egress and ingress policies are also supported for controlling access to external IPs, ideal for integrating with legacy systems or regulatory boundaries.&lt;/p&gt; 
&lt;h2&gt;Service Mesh&lt;/h2&gt; 
&lt;p&gt;With Cilium &lt;code&gt;Service Mesh &amp;lt;https://cilium.io/use-cases/service-mesh/&amp;gt;&lt;/code&gt;_, operators gain the benefits of fine-grained traffic control, encryption, observability, access control, without the cost and complexity of traditional proxy-based designs. Key features include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Mutual authentication&lt;/strong&gt; with automatic identity-based encryption between workloads using IPSec or WireGuard.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;L7-aware policy enforcement&lt;/strong&gt; for security and compliance.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Deep integration with the Kubernetes Gateway API :&lt;/strong&gt; Acts as a &lt;code&gt;Gateway API &amp;lt;https://cilium.io/use-cases/gateway-api/&amp;gt;&lt;/code&gt;_ compliant data plane, allowing you to declaratively manage ingress, traffic splitting, and routing behavior using Kubernetes-native CRDs.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Observability and Troubleshooting&lt;/h2&gt; 
&lt;p&gt;Observability is built into Cilium from the ground up, providing rich visibility that helps operators diagnose and understand system behavior including:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Hubble&lt;/strong&gt;: A fully integrated observability platform that offers real-time service maps, flow visibility with identity and label metadata, and DNS-aware filtering and protocol-specific insights&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Metrics and alerting&lt;/strong&gt;: Integration with Prometheus, Grafana, and other monitoring systems.&lt;/p&gt; &lt;/li&gt; 
 &lt;li&gt; &lt;p&gt;&lt;strong&gt;Drop reasons and audit trails&lt;/strong&gt;: Get actionable insights into why traffic was dropped, including policy or port violations and issues like failed DNS lookups.&lt;/p&gt; &lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;.. end-functionality-overview&lt;/p&gt; 
&lt;h1&gt;Getting Started&lt;/h1&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;code&gt;Why Cilium?&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Getting Started&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Architecture and Concepts&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Installing Cilium&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;&lt;code&gt;Frequently Asked Questions&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;Contributing_&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h1&gt;Community&lt;/h1&gt; 
&lt;h2&gt;Slack&lt;/h2&gt; 
&lt;p&gt;Join the Cilium &lt;code&gt;Slack channel &amp;lt;https://slack.cilium.io&amp;gt;&lt;/code&gt;_ to chat with Cilium developers and other Cilium users. This is a good place to learn about Cilium, ask questions, and share your experiences.&lt;/p&gt; 
&lt;h2&gt;Special Interest Groups (SIG)&lt;/h2&gt; 
&lt;p&gt;See &lt;code&gt;Special Interest groups &amp;lt;https://github.com/cilium/community/blob/main/sigs.yaml&amp;gt;&lt;/code&gt;_ for a list of all SIGs and their meeting times.&lt;/p&gt; 
&lt;h2&gt;Developer meetings&lt;/h2&gt; 
&lt;p&gt;The Cilium developer community hangs out on Zoom to chat. Everybody is welcome.&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;Weekly, Wednesday, 5:00 pm &lt;code&gt;Europe/Zurich time &amp;lt;https://time.is/Canton_of_Zurich&amp;gt;&lt;/code&gt;__ (CET/CEST), usually equivalent to 8:00 am PT, or 11:00 am ET. &lt;code&gt;Meeting Notes and Zoom Info&lt;/code&gt;_&lt;/li&gt; 
 &lt;li&gt;Third Wednesday of each month, 9:00 am &lt;code&gt;Japan time &amp;lt;https://time.is/Tokyo&amp;gt;&lt;/code&gt;__ (JST). &lt;code&gt;APAC Meeting Notes and Zoom Info&lt;/code&gt;_&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;eBPF &amp;amp; Cilium Office Hours livestream&lt;/h2&gt; 
&lt;p&gt;We host a weekly community &lt;code&gt;YouTube livestream called eCHO &amp;lt;https://www.youtube.com/channel/UCJFUxkVQTBJh3LD1wYBWvuQ&amp;gt;&lt;/code&gt;_ which (very loosely!) stands for eBPF &amp;amp; Cilium Office Hours. Join us live, catch up with past episodes, or head over to the &lt;code&gt;eCHO repo &amp;lt;https://github.com/isovalent/eCHO&amp;gt;&lt;/code&gt;_ and let us know your ideas for topics we should cover.&lt;/p&gt; 
&lt;h2&gt;Governance&lt;/h2&gt; 
&lt;p&gt;The Cilium project is governed by a group of &lt;code&gt;Maintainers and Committers &amp;lt;https://raw.githubusercontent.com/cilium/cilium/main/MAINTAINERS.md&amp;gt;&lt;/code&gt;&lt;strong&gt;. How they are selected and govern is outlined in our &lt;code&gt;governance document &amp;lt;https://github.com/cilium/community/blob/main/GOVERNANCE.md&amp;gt;&lt;/code&gt;&lt;/strong&gt;.&lt;/p&gt; 
&lt;h2&gt;Adopters&lt;/h2&gt; 
&lt;p&gt;A list of adopters of the Cilium project who are deploying it in production, and of their use cases, can be found in file &lt;code&gt;USERS.md &amp;lt;https://github.com/cilium/cilium/blob/main/USERS.md&amp;gt;&lt;/code&gt;__.&lt;/p&gt; 
&lt;h1&gt;License&lt;/h1&gt; 
&lt;p&gt;.. _apache-license: LICENSE .. _bsd-license: bpf/LICENSE.BSD-2-Clause .. _gpl-license: bpf/LICENSE.GPL-2.0&lt;/p&gt; 
&lt;p&gt;The Cilium user space components are licensed under the &lt;code&gt;Apache License, Version 2.0 &amp;lt;apache-license_&amp;gt;&lt;/code&gt;&lt;strong&gt;. The BPF code templates are dual-licensed under the &lt;code&gt;General Public License, Version 2.0 (only) &amp;lt;gpl-license_&amp;gt;&lt;/code&gt;&lt;/strong&gt; and the &lt;code&gt;2-Clause BSD License &amp;lt;bsd-license_&amp;gt;&lt;/code&gt;__ (you can use the terms of either license, at your option).&lt;/p&gt; 
&lt;p&gt;.. _&lt;code&gt;Cilium Upgrade Guide&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/operations/upgrade/"&gt;https://docs.cilium.io/en/stable/operations/upgrade/&lt;/a&gt; .. _&lt;code&gt;Why Cilium?&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/overview/intro"&gt;https://docs.cilium.io/en/stable/overview/intro&lt;/a&gt; .. _&lt;code&gt;Getting Started&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/#getting-started"&gt;https://docs.cilium.io/en/stable/#getting-started&lt;/a&gt; .. _&lt;code&gt;Architecture and Concepts&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/overview/component-overview/"&gt;https://docs.cilium.io/en/stable/overview/component-overview/&lt;/a&gt; .. _&lt;code&gt;Installing Cilium&lt;/code&gt;: &lt;a href="https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/"&gt;https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/&lt;/a&gt; .. _&lt;code&gt;Frequently Asked Questions&lt;/code&gt;: &lt;a href="https://github.com/cilium/cilium/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue+label%3Akind%2Fquestion+"&gt;https://github.com/cilium/cilium/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue+label%3Akind%2Fquestion+&lt;/a&gt; .. _Contributing: &lt;a href="https://docs.cilium.io/en/stable/contributing/development/"&gt;https://docs.cilium.io/en/stable/contributing/development/&lt;/a&gt; .. _Prerequisites: &lt;a href="https://docs.cilium.io/en/stable/operations/system_requirements/"&gt;https://docs.cilium.io/en/stable/operations/system_requirements/&lt;/a&gt; .. _&lt;code&gt;eBPF&lt;/code&gt;: &lt;a href="https://ebpf.io"&gt;https://ebpf.io&lt;/a&gt; .. _&lt;code&gt;eBPF.io&lt;/code&gt;: &lt;a href="https://ebpf.io"&gt;https://ebpf.io&lt;/a&gt; .. _&lt;code&gt;Meeting Notes and Zoom Info&lt;/code&gt;: &lt;a href="https://docs.google.com/document/d/1Y_4chDk4rznD6UgXPlPvn3Dc7l-ZutGajUv1eF0VDwQ/edit#"&gt;https://docs.google.com/document/d/1Y_4chDk4rznD6UgXPlPvn3Dc7l-ZutGajUv1eF0VDwQ/edit#&lt;/a&gt; .. _&lt;code&gt;APAC Meeting Notes and Zoom Info&lt;/code&gt;: &lt;a href="https://docs.google.com/document/d/1egv4qLydr0geP-GjQexYKm4tz3_tHy-LCBjVQcXcT5M/edit#"&gt;https://docs.google.com/document/d/1egv4qLydr0geP-GjQexYKm4tz3_tHy-LCBjVQcXcT5M/edit#&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |go-report| image:: &lt;a href="https://goreportcard.com/badge/github.com/cilium/cilium"&gt;https://goreportcard.com/badge/github.com/cilium/cilium&lt;/a&gt; :alt: Go Report Card :target: &lt;a href="https://goreportcard.com/report/github.com/cilium/cilium"&gt;https://goreportcard.com/report/github.com/cilium/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |go-doc| image:: &lt;a href="https://godoc.org/github.com/cilium/cilium?status.svg"&gt;https://godoc.org/github.com/cilium/cilium?status.svg&lt;/a&gt; :alt: GoDoc :target: &lt;a href="https://godoc.org/github.com/cilium/cilium"&gt;https://godoc.org/github.com/cilium/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |rtd| image:: &lt;a href="https://readthedocs.org/projects/docs/badge/?version=latest"&gt;https://readthedocs.org/projects/docs/badge/?version=latest&lt;/a&gt; :alt: Read the Docs :target: &lt;a href="https://docs.cilium.io/"&gt;https://docs.cilium.io/&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |apache| image:: &lt;a href="https://img.shields.io/badge/license-Apache-blue.svg"&gt;https://img.shields.io/badge/license-Apache-blue.svg&lt;/a&gt; :alt: Apache licensed :target: apache-license_&lt;/p&gt; 
&lt;p&gt;.. |bsd| image:: &lt;a href="https://img.shields.io/badge/license-BSD-blue.svg"&gt;https://img.shields.io/badge/license-BSD-blue.svg&lt;/a&gt; :alt: BSD licensed :target: bsd-license_&lt;/p&gt; 
&lt;p&gt;.. |gpl| image:: &lt;a href="https://img.shields.io/badge/license-GPL-blue.svg"&gt;https://img.shields.io/badge/license-GPL-blue.svg&lt;/a&gt; :alt: GPL licensed :target: gpl-license_&lt;/p&gt; 
&lt;p&gt;.. |slack| image:: &lt;a href="https://img.shields.io/badge/slack-cilium-brightgreen.svg?logo=slack"&gt;https://img.shields.io/badge/slack-cilium-brightgreen.svg?logo=slack&lt;/a&gt; :alt: Join the Cilium slack channel :target: &lt;a href="https://slack.cilium.io"&gt;https://slack.cilium.io&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |cii| image:: &lt;a href="https://bestpractices.coreinfrastructure.org/projects/1269/badge"&gt;https://bestpractices.coreinfrastructure.org/projects/1269/badge&lt;/a&gt; :alt: CII Best Practices :target: &lt;a href="https://bestpractices.coreinfrastructure.org/projects/1269"&gt;https://bestpractices.coreinfrastructure.org/projects/1269&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |clomonitor| image:: &lt;a href="https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/cilium/badge"&gt;https://img.shields.io/endpoint?url=https://clomonitor.io/api/projects/cncf/cilium/badge&lt;/a&gt; :alt: CLOMonitor :target: &lt;a href="https://clomonitor.io/projects/cncf/cilium"&gt;https://clomonitor.io/projects/cncf/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |artifacthub| image:: &lt;a href="https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/cilium"&gt;https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/cilium&lt;/a&gt; :alt: Artifact Hub :target: &lt;a href="https://artifacthub.io/packages/helm/cilium/cilium"&gt;https://artifacthub.io/packages/helm/cilium/cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |fossa| image:: &lt;a href="https://app.fossa.com/api/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git.svg?type=shield"&gt;https://app.fossa.com/api/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git.svg?type=shield&lt;/a&gt; :alt: FOSSA Status :target: &lt;a href="https://app.fossa.com/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git?ref=badge_shield"&gt;https://app.fossa.com/projects/custom%2B162%2Fgit%40github.com%3Acilium%2Fcilium.git?ref=badge_shield&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |gateway-api| image:: &lt;a href="https://img.shields.io/badge/Gateway%20API%20Conformance%20v1.2.0-Cilium-green"&gt;https://img.shields.io/badge/Gateway%20API%20Conformance%20v1.2.0-Cilium-green&lt;/a&gt; :alt: Gateway API Status :target: &lt;a href="https://github.com/kubernetes-sigs/gateway-api/tree/main/conformance/reports/v1.2.0/cilium-cilium"&gt;https://github.com/kubernetes-sigs/gateway-api/tree/main/conformance/reports/v1.2.0/cilium-cilium&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;.. |codespaces| image:: &lt;a href="https://img.shields.io/badge/Open_in_GitHub_Codespaces-gray?logo=github"&gt;https://img.shields.io/badge/Open_in_GitHub_Codespaces-gray?logo=github&lt;/a&gt; :alt: Github Codespaces :target: &lt;a href="https://github.com/codespaces/new?hide_repo_select=true&amp;amp;ref=master&amp;amp;repo=48109239&amp;amp;machine=standardLinux32gb&amp;amp;location=WestEurope"&gt;https://github.com/codespaces/new?hide_repo_select=true&amp;amp;ref=master&amp;amp;repo=48109239&amp;amp;machine=standardLinux32gb&amp;amp;location=WestEurope&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>twitter/the-algorithm</title>
      <link>https://github.com/twitter/the-algorithm</link>
      <description>&lt;p&gt;Source code for the X Recommendation Algorithm&lt;/p&gt;&lt;hr&gt;&lt;h1&gt;X's Recommendation Algorithm&lt;/h1&gt; 
&lt;p&gt;X's Recommendation Algorithm is a set of services and jobs that are responsible for serving feeds of posts and other content across all X product surfaces (e.g. For You Timeline, Search, Explore, Notifications). For an introduction to how the algorithm works, please refer to our &lt;a href="https://blog.x.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm"&gt;engineering blog&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Architecture&lt;/h2&gt; 
&lt;p&gt;Product surfaces at X are built on a shared set of data, models, and software frameworks. The shared components included in this repository are listed below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Data&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/tweetypie/server/README.md"&gt;tweetypie&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Core service that handles the reading and writing of post data.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/unified_user_actions/README.md"&gt;unified-user-actions&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Real-time stream of user actions on X.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/user-signal-service/README.md"&gt;user-signal-service&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Centralized platform to retrieve explicit (e.g. likes, replies) and implicit (e.g. profile visits, tweet clicks) user signals.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Model&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/simclusters_v2/README.md"&gt;SimClusters&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Community detection and sparse embeddings into those communities.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/twitter/the-algorithm-ml/raw/main/projects/twhin/README.md"&gt;TwHIN&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Dense knowledge graph embeddings for Users and Posts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/trust_and_safety_models/README.md"&gt;trust-and-safety-models&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Models for detecting NSFW or abusive content.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/interaction_graph/README.md"&gt;real-graph&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Model to predict the likelihood of an X User interacting with another User.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/graph/batch/job/tweepcred/README"&gt;tweepcred&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Page-Rank algorithm for calculating X User reputation.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/recos-injector/README.md"&gt;recos-injector&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Streaming event processor for building input streams for &lt;a href="https://github.com/twitter/GraphJet"&gt;GraphJet&lt;/a&gt; based services.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/graph-feature-service/README.md"&gt;graph-feature-service&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Serves graph features for a directed pair of users (e.g. how many of User A's following liked posts from User B).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/topic-social-proof/README.md"&gt;topic-social-proof&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Identifies topics related to individual posts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/representation-scorer/README.md"&gt;representation-scorer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Compute scores between pairs of entities (Users, Posts, etc.) using embedding similarity.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Software framework&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/navi/README.md"&gt;navi&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;High performance, machine learning model serving written in Rust.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/product-mixer/README.md"&gt;product-mixer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Software framework for building feeds of content.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/timelines/data_processing/ml_util/aggregation_framework/README.md"&gt;timelines-aggregation-framework&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Framework for generating aggregate features in batch or real time.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/representation-manager/README.md"&gt;representation-manager&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Service to retrieve embeddings (i.e. SimClusers and TwHIN).&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/twml/README.md"&gt;twml&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Legacy machine learning framework built on TensorFlow v1.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;p&gt;The product surfaces currently included in this repository are the For You Timeline and Recommended Notifications.&lt;/p&gt; 
&lt;h3&gt;For You Timeline&lt;/h3&gt; 
&lt;p&gt;The diagram below illustrates how major services and jobs interconnect to construct a For You Timeline.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/twitter/the-algorithm/main/docs/system-diagram.png" alt="" /&gt;&lt;/p&gt; 
&lt;p&gt;The core components of the For You Timeline included in this repository are listed below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Candidate Source&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/java/com/twitter/search/README.md"&gt;search-index&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Find and rank In-Network posts. ~50% of posts come from this candidate source.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/tweet-mixer"&gt;tweet-mixer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Coordination layer for fetching Out-of-Network tweet candidates from underlying compute services.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/recos/user_tweet_entity_graph/README.md"&gt;user-tweet-entity-graph&lt;/a&gt; (UTEG)&lt;/td&gt; 
   &lt;td&gt;Maintains an in memory User to Post interaction graph, and finds candidates based on traversals of this graph. This is built on the &lt;a href="https://github.com/twitter/GraphJet"&gt;GraphJet&lt;/a&gt; framework. Several other GraphJet based features and candidate sources are located &lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/scala/com/twitter/recos"&gt;here&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/follow-recommendations-service/README.md"&gt;follow-recommendation-service&lt;/a&gt; (FRS)&lt;/td&gt; 
   &lt;td&gt;Provides Users with recommendations for accounts to follow, and posts from those accounts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ranking&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/src/python/twitter/deepbird/projects/timelines/scripts/models/earlybird/README.md"&gt;light-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Light Ranker model used by search index (Earlybird) to rank posts.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://github.com/twitter/the-algorithm-ml/raw/main/projects/home/recap/README.md"&gt;heavy-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Neural network for ranking candidate posts. One of the main signals used to select timeline posts post candidate sourcing.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Post mixing &amp;amp; filtering&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/home-mixer/README.md"&gt;home-mixer&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Main service used to construct and serve the Home Timeline. Built on &lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/product-mixer/README.md"&gt;product-mixer&lt;/a&gt;.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/visibilitylib/README.md"&gt;visibility-filters&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Responsible for filtering X content to support legal compliance, improve product quality, increase user trust, protect revenue through the use of hard-filtering, visible product treatments, and coarse-grained downranking.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/timelineranker/README.md"&gt;timelineranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Legacy service which provides relevance-scored posts from the Earlybird Search Index and UTEG service.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h3&gt;Recommended Notifications&lt;/h3&gt; 
&lt;p&gt;The core components of Recommended Notifications included in this repository are listed below:&lt;/p&gt; 
&lt;table&gt; 
 &lt;thead&gt; 
  &lt;tr&gt; 
   &lt;th&gt;Type&lt;/th&gt; 
   &lt;th&gt;Component&lt;/th&gt; 
   &lt;th&gt;Description&lt;/th&gt; 
  &lt;/tr&gt; 
 &lt;/thead&gt; 
 &lt;tbody&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Service&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/pushservice/README.md"&gt;pushservice&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Main recommendation service at X used to surface recommendations to our users via notifications.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;Ranking&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/pushservice/src/main/python/models/light_ranking/README.md"&gt;pushservice-light-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Light Ranker model used by pushservice to rank posts. Bridges candidate generation and heavy ranking by pre-selecting highly-relevant candidates from the initial huge candidate pool.&lt;/td&gt; 
  &lt;/tr&gt; 
  &lt;tr&gt; 
   &lt;td&gt;&lt;/td&gt; 
   &lt;td&gt;&lt;a href="https://raw.githubusercontent.com/twitter/the-algorithm/main/pushservice/src/main/python/models/heavy_ranking/README.md"&gt;pushservice-heavy-ranker&lt;/a&gt;&lt;/td&gt; 
   &lt;td&gt;Multi-task learning model to predict the probabilities that the target users will open and engage with the sent notifications.&lt;/td&gt; 
  &lt;/tr&gt; 
 &lt;/tbody&gt; 
&lt;/table&gt; 
&lt;h2&gt;Build and test code&lt;/h2&gt; 
&lt;p&gt;We include Bazel BUILD files for most components, but not a top-level BUILD or WORKSPACE file. We plan to add a more complete build and test system in the future.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;We invite the community to submit GitHub issues and pull requests for suggestions on improving the recommendation algorithm. We are working on tools to manage these suggestions and sync changes to our internal repository. Any security concerns or issues should be routed to our official &lt;a href="https://hackerone.com/x"&gt;bug bounty program&lt;/a&gt; through HackerOne. We hope to benefit from the collective intelligence and expertise of the global community in helping us identify issues and suggest improvements, ultimately leading to a better X.&lt;/p&gt; 
&lt;p&gt;Read our blog on the open source initiative &lt;a href="https://blog.x.com/en_us/topics/company/2023/a-new-era-of-transparency-for-twitter"&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>puckeditor/puck</title>
      <link>https://github.com/puckeditor/puck</link>
      <description>&lt;p&gt;The visual editor for React&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt; 
&lt;div align="center"&gt; 
 &lt;a href="https://puckeditor.com?utm_source=readme&amp;amp;utm_medium=code&amp;amp;utm_campaign=repo&amp;amp;utm_contents=logo"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="https://res.cloudinary.com/die3nptcg/image/upload/Puck_Logo_White_RGB_j2rwgg.svg" height="100px" aria-label="Puck logo" /&gt; 
   &lt;img src="https://res.cloudinary.com/die3nptcg/image/upload/Puck_Logo_Black_RGB_dqsjag.svg?sanitize=true" height="100px" aria-label="Puck logo" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; 
 &lt;p&gt;&lt;em&gt;The visual editor for React&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;a href="https://puckeditor.com/docs?utm_source=readme&amp;amp;utm_medium=code&amp;amp;utm_campaign=repo&amp;amp;utm_contents=docs_link"&gt;Documentation&lt;/a&gt; ‚Ä¢ &lt;a href="https://demo.puckeditor.com/edit?utm_source=readme&amp;amp;utm_medium=code&amp;amp;utm_campaign=repo&amp;amp;utm_contents=demo_link"&gt;Demo&lt;/a&gt; ‚Ä¢ &lt;a href="https://discord.gg/V9mDAhuxyZ"&gt;Discord&lt;/a&gt; ‚Ä¢ &lt;a href="https://github.com/puckeditor/puck/raw/main/CONTRIBUTING.md"&gt;Contributing&lt;/a&gt;&lt;/p&gt; 
 &lt;p&gt;‚≠êÔ∏è Enjoying Puck? Please &lt;a href="https://github.com/puckeditor/puck"&gt;leave a star&lt;/a&gt;!&lt;/p&gt; 
 &lt;br /&gt; 
 &lt;p&gt;&lt;a href="https://demo.puckeditor.com/edit"&gt;&lt;img src="https://github.com/user-attachments/assets/25e1ae25-ca5e-450f-afa0-01816830b731" alt="GIF showing a page being created in the Puck Editor, with components being added, arranged, and customized in real time" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;/div&gt; 
&lt;h2&gt;What is Puck?&lt;/h2&gt; 
&lt;p&gt;Puck is a modular, open-source visual editor for React.js. You can use Puck to build custom drag-and-drop experiences with your own application and React components.&lt;/p&gt; 
&lt;p&gt;Because Puck is just a React component, it plays well with all React.js environments, including Next.js. You own your data and there‚Äôs no vendor lock-in.&lt;/p&gt; 
&lt;p&gt;Puck is also &lt;a href="https://github.com/puckeditor/puck?tab=MIT-1-ov-file#readme"&gt;licensed under MIT&lt;/a&gt;, making it suitable for both internal systems and commercial applications.&lt;/p&gt; 
&lt;h2&gt;Quick start&lt;/h2&gt; 
&lt;p&gt;Install the package:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npm i @puckeditor/core --save # or npx create-puck-app my-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Render the editor:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-jsx"&gt;// Editor.jsx
import { Puck } from "@puckeditor/core";
import "@puckeditor/core/puck.css";

// Create Puck component config
const config = {
  components: {
    HeadingBlock: {
      fields: {
        children: {
          type: "text",
        },
      },
      render: ({ children }) =&amp;gt; {
        return &amp;lt;h1&amp;gt;{children}&amp;lt;/h1&amp;gt;;
      },
    },
  },
};

// Describe the initial data
const initialData = {};

// Save the data to your database
const save = (data) =&amp;gt; {};

// Render Puck editor
export function Editor() {
  return &amp;lt;Puck config={config} data={initialData} onPublish={save} /&amp;gt;;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Render the page:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-jsx"&gt;// Page.jsx
import { Render } from "@puckeditor/core";
import "@puckeditor/core/puck.css";

export function Page() {
  return &amp;lt;Render config={config} data={data} /&amp;gt;;
}
&lt;/code&gt;&lt;/pre&gt; 
&lt;h2&gt;Recipes&lt;/h2&gt; 
&lt;p&gt;Use &lt;code&gt;create-puck-app&lt;/code&gt; to quickly spin up a a pre-configured app based on our provided &lt;a href="https://github.com/puckeditor/puck/tree/main/recipes"&gt;recipes&lt;/a&gt;:&lt;/p&gt; 
&lt;pre&gt;&lt;code class="language-sh"&gt;npx create-puck-app my-app
&lt;/code&gt;&lt;/pre&gt; 
&lt;p&gt;Available recipes include:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://github.com/puckeditor/puck/tree/main/recipes/next"&gt;&lt;strong&gt;next&lt;/strong&gt;&lt;/a&gt;: Next.js example, using App Router and static page generation&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/puckeditor/puck/tree/main/recipes/remix"&gt;&lt;strong&gt;remix&lt;/strong&gt;&lt;/a&gt;: Remix Run v2 example, using dynamic routes at root-level&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/puckeditor/puck/tree/main/recipes/react-router"&gt;&lt;strong&gt;react-router&lt;/strong&gt;&lt;/a&gt;: React Router v7 app example, using dynamic routes to create pages at any level&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Community&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://discord.gg/D9e4E3MQVZ"&gt;Discord server&lt;/a&gt; for discussions&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://github.com/puckeditor/awesome-puck"&gt;awesome-puck&lt;/a&gt; community repo for plugins, custom fields &amp;amp; more&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Get support&lt;/h2&gt; 
&lt;p&gt;If you have any questions about Puck, please open a &lt;a href="https://github.com/puckeditor/puck/issues"&gt;GitHub issue&lt;/a&gt; or join us on &lt;a href="https://discord.gg/D9e4E3MQVZ"&gt;Discord&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Or &lt;a href="https://app.cal.com/chrisvxd/puck-enquiry/"&gt;book a discovery call&lt;/a&gt; for hands-on support and consultancy.&lt;/p&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;MIT ¬© &lt;a href="https://github.com/puckeditor/puck/graphs/contributors"&gt;The Puck Contributors&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>wavetermdev/waveterm</title>
      <link>https://github.com/wavetermdev/waveterm</link>
      <description>&lt;p&gt;An open-source, cross-platform terminal for seamless workflows&lt;/p&gt;&lt;hr&gt;&lt;p align="center"&gt; &lt;a href="https://www.waveterm.dev"&gt; 
  &lt;picture&gt; 
   &lt;source media="(prefers-color-scheme: dark)" srcset="./assets/wave-dark.png" /&gt; 
   &lt;source media="(prefers-color-scheme: light)" srcset="./assets/wave-light.png" /&gt; 
   &lt;img alt="Wave Terminal Logo" src="https://raw.githubusercontent.com/wavetermdev/waveterm/main/assets/wave-light.png" width="240" /&gt; 
  &lt;/picture&gt; &lt;/a&gt; &lt;br /&gt; &lt;/p&gt; 
&lt;h1&gt;Wave Terminal&lt;/h1&gt; 
&lt;p&gt;&lt;a href="https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield"&gt;&lt;img src="https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield" alt="FOSSA Status" /&gt;&lt;/a&gt;&lt;/p&gt; 
&lt;p&gt;Wave is an open-source terminal that combines traditional terminal features with graphical capabilities like file previews, web browsing, and AI assistance. It runs on MacOS, Linux, and Windows.&lt;/p&gt; 
&lt;p&gt;Modern development involves constantly switching between terminals and browsers - checking documentation, previewing files, monitoring systems, and using AI tools. Wave brings these graphical tools directly into the terminal, letting you control them from the command line. This means you can stay in your terminal workflow while still having access to the visual interfaces you need.&lt;/p&gt; 
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/wavetermdev/waveterm/main/assets/wave-screenshot.webp" alt="WaveTerm Screenshot" /&gt;&lt;/p&gt; 
&lt;h2&gt;Key Features&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Flexible drag &amp;amp; drop interface to organize terminal blocks, editors, web browsers, and AI assistants&lt;/li&gt; 
 &lt;li&gt;Built-in editor for seamlessly editing remote files with syntax highlighting and modern editor features&lt;/li&gt; 
 &lt;li&gt;Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)&lt;/li&gt; 
 &lt;li&gt;Quick full-screen toggle for any block - expand terminals, editors, and previews for better visibility, then instantly return to multi-block view&lt;/li&gt; 
 &lt;li&gt;Wave AI - Context-aware terminal assistant that reads your terminal output, analyzes widgets, and performs file operations&lt;/li&gt; 
 &lt;li&gt;AI chat widget with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)&lt;/li&gt; 
 &lt;li&gt;Command Blocks for isolating and monitoring individual commands with auto-close options&lt;/li&gt; 
 &lt;li&gt;One-click remote connections with full terminal and file system access&lt;/li&gt; 
 &lt;li&gt;Secure secret storage using native system backends - store API keys and credentials locally, access them across SSH sessions&lt;/li&gt; 
 &lt;li&gt;Rich customization including tab themes, terminal styles, and background images&lt;/li&gt; 
 &lt;li&gt;Powerful &lt;code&gt;wsh&lt;/code&gt; command system for managing your workspace from the CLI and sharing data between terminal sessions&lt;/li&gt; 
 &lt;li&gt;Connected file management with &lt;code&gt;wsh file&lt;/code&gt; - seamlessly copy and sync files between local, remote SSH hosts, Wave filesystem, and S3&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Wave AI&lt;/h2&gt; 
&lt;p&gt;Wave AI is your context-aware terminal assistant with access to your workspace:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;strong&gt;Terminal Context&lt;/strong&gt;: Reads terminal output and scrollback for debugging and analysis&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;File Operations&lt;/strong&gt;: Read, write, and edit files with automatic backups and user approval&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;CLI Integration&lt;/strong&gt;: Use &lt;code&gt;wsh ai&lt;/code&gt; to pipe output or attach files directly from the command line&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Free Beta&lt;/strong&gt;: Included AI credits while we refine the experience&lt;/li&gt; 
 &lt;li&gt;&lt;strong&gt;Coming Soon&lt;/strong&gt;: Command execution (with approval), local model support, and alternate AI providers (BYOK)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;Learn more in our &lt;a href="https://docs.waveterm.dev/waveai"&gt;Wave AI documentation&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Installation&lt;/h2&gt; 
&lt;p&gt;Wave Terminal works on macOS, Linux, and Windows.&lt;/p&gt; 
&lt;p&gt;Platform-specific installation instructions can be found &lt;a href="https://docs.waveterm.dev/gettingstarted"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;You can also install Wave Terminal directly from: &lt;a href="https://www.waveterm.dev/download"&gt;www.waveterm.dev/download&lt;/a&gt;.&lt;/p&gt; 
&lt;h3&gt;Minimum requirements&lt;/h3&gt; 
&lt;p&gt;Wave Terminal runs on the following platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;macOS 11 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Windows 10 1809 or later (x64)&lt;/li&gt; 
 &lt;li&gt;Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;p&gt;The WSH helper runs on the following platforms:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;macOS 11 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Windows 10 or later (arm64, x64)&lt;/li&gt; 
 &lt;li&gt;Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Roadmap&lt;/h2&gt; 
&lt;p&gt;Wave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/ROADMAP.md"&gt;here&lt;/a&gt;.&lt;/p&gt; 
&lt;p&gt;Want to provide input to our future releases? Connect with us on &lt;a href="https://discord.gg/XfvZ334gwU"&gt;Discord&lt;/a&gt; or open a &lt;a href="https://github.com/wavetermdev/waveterm/issues/new/choose"&gt;Feature Request&lt;/a&gt;!&lt;/p&gt; 
&lt;h2&gt;Links&lt;/h2&gt; 
&lt;ul&gt; 
 &lt;li&gt;Homepage ‚Äî &lt;a href="https://www.waveterm.dev"&gt;https://www.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Download Page ‚Äî &lt;a href="https://www.waveterm.dev/download"&gt;https://www.waveterm.dev/download&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Documentation ‚Äî &lt;a href="https://docs.waveterm.dev"&gt;https://docs.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Legacy Documentation ‚Äî &lt;a href="https://legacydocs.waveterm.dev"&gt;https://legacydocs.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Blog ‚Äî &lt;a href="https://blog.waveterm.dev"&gt;https://blog.waveterm.dev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;X ‚Äî &lt;a href="https://x.com/wavetermdev"&gt;https://x.com/wavetermdev&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;Discord Community ‚Äî &lt;a href="https://discord.gg/XfvZ334gwU"&gt;https://discord.gg/XfvZ334gwU&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;Building from Source&lt;/h2&gt; 
&lt;p&gt;See &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/BUILD.md"&gt;Building Wave Terminal&lt;/a&gt;.&lt;/p&gt; 
&lt;h2&gt;Contributing&lt;/h2&gt; 
&lt;p&gt;Wave uses GitHub Issues for issue tracking.&lt;/p&gt; 
&lt;p&gt;Find more information in our &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md"&gt;Contributions Guide&lt;/a&gt;, which includes:&lt;/p&gt; 
&lt;ul&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md#contributing-to-wave-terminal"&gt;Ways to contribute&lt;/a&gt;&lt;/li&gt; 
 &lt;li&gt;&lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/CONTRIBUTING.md#before-you-start"&gt;Contribution guidelines&lt;/a&gt;&lt;/li&gt; 
&lt;/ul&gt; 
&lt;h2&gt;License&lt;/h2&gt; 
&lt;p&gt;Wave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see &lt;a href="https://raw.githubusercontent.com/wavetermdev/waveterm/main/ACKNOWLEDGEMENTS.md"&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>